{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_drop.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z = model.module.dropout(z)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, conditional=True, controlled_tol=True, conv=True, data='mnist', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_8K_drop_0_5_run1/epoch_365_checkpt.pth', rtol=0.0001, save='../experiments_published/cnf_conditional_8K_drop_0_5_run1', seed=0, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=113.0, weight_decay=0.0, weight_y=0.5)\n",
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=1568, bias=True)\n",
      "  (project_class): LinearZeros(in_features=784, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 828890\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 2556 | Time 68.8081(31.0555) | Bit/dim 1.1132(1.1225) | Xent 0.0440(0.0438) | Loss 1.1352(1.1444) | Error 0.0128(0.0136) Steps 416(424.06) | Grad Norm 1.7023(3.3306) | Total Time 10.00(10.00)\n",
      "Iter 2557 | Time 30.2874(31.0324) | Bit/dim 1.1125(1.1222) | Xent 0.0408(0.0437) | Loss 1.1329(1.1441) | Error 0.0124(0.0135) Steps 410(423.64) | Grad Norm 1.2656(3.2686) | Total Time 10.00(10.00)\n",
      "Iter 2558 | Time 28.8953(30.9683) | Bit/dim 1.1110(1.1219) | Xent 0.0443(0.0437) | Loss 1.1331(1.1437) | Error 0.0119(0.0135) Steps 416(423.41) | Grad Norm 0.5868(3.1881) | Total Time 10.00(10.00)\n",
      "Iter 2559 | Time 29.5932(30.9271) | Bit/dim 1.1113(1.1216) | Xent 0.0480(0.0438) | Loss 1.1353(1.1435) | Error 0.0152(0.0135) Steps 416(423.19) | Grad Norm 0.3971(3.1044) | Total Time 10.00(10.00)\n",
      "Iter 2560 | Time 28.7874(30.8629) | Bit/dim 1.1131(1.1213) | Xent 0.0374(0.0436) | Loss 1.1318(1.1431) | Error 0.0105(0.0134) Steps 416(422.97) | Grad Norm 1.5551(3.0579) | Total Time 10.00(10.00)\n",
      "Iter 2561 | Time 28.6999(30.7980) | Bit/dim 1.1147(1.1211) | Xent 0.0426(0.0436) | Loss 1.1360(1.1429) | Error 0.0132(0.0134) Steps 416(422.76) | Grad Norm 1.5038(3.0113) | Total Time 10.00(10.00)\n",
      "Iter 2562 | Time 28.7823(30.7375) | Bit/dim 1.1127(1.1209) | Xent 0.0400(0.0435) | Loss 1.1327(1.1426) | Error 0.0126(0.0134) Steps 416(422.56) | Grad Norm 1.1782(2.9563) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 27.3815, Epoch Time 283.8549(239.9955), Bit/dim 1.1066(best: inf), Xent 0.0299, Loss 1.1216, Error 0.0091(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2563 | Time 30.9558(30.7441) | Bit/dim 1.1097(1.1205) | Xent 0.0415(0.0434) | Loss 1.1305(1.1422) | Error 0.0136(0.0134) Steps 416(422.36) | Grad Norm 0.5010(2.8827) | Total Time 10.00(10.00)\n",
      "Iter 2564 | Time 28.6102(30.6800) | Bit/dim 1.1116(1.1203) | Xent 0.0453(0.0435) | Loss 1.1342(1.1420) | Error 0.0151(0.0135) Steps 422(422.35) | Grad Norm 0.6401(2.8154) | Total Time 10.00(10.00)\n",
      "Iter 2565 | Time 30.6876(30.6803) | Bit/dim 1.1120(1.1200) | Xent 0.0359(0.0433) | Loss 1.1299(1.1416) | Error 0.0108(0.0134) Steps 416(422.16) | Grad Norm 0.9401(2.7591) | Total Time 10.00(10.00)\n",
      "Iter 2566 | Time 29.0333(30.6309) | Bit/dim 1.1073(1.1196) | Xent 0.0422(0.0432) | Loss 1.1284(1.1412) | Error 0.0146(0.0134) Steps 410(421.80) | Grad Norm 1.2783(2.7147) | Total Time 10.00(10.00)\n",
      "Iter 2567 | Time 28.9633(30.5808) | Bit/dim 1.1142(1.1195) | Xent 0.0387(0.0431) | Loss 1.1336(1.1410) | Error 0.0112(0.0134) Steps 416(421.62) | Grad Norm 1.0302(2.6642) | Total Time 10.00(10.00)\n",
      "Iter 2568 | Time 29.8445(30.5587) | Bit/dim 1.1118(1.1192) | Xent 0.0359(0.0429) | Loss 1.1298(1.1407) | Error 0.0108(0.0133) Steps 416(421.46) | Grad Norm 0.2529(2.5918) | Total Time 10.00(10.00)\n",
      "Iter 2569 | Time 30.1360(30.5461) | Bit/dim 1.1174(1.1192) | Xent 0.0352(0.0427) | Loss 1.1350(1.1405) | Error 0.0116(0.0132) Steps 422(421.47) | Grad Norm 0.2723(2.5222) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 16.6017, Epoch Time 237.3894(239.9173), Bit/dim 1.1064(best: 1.1066), Xent 0.0263, Loss 1.1196, Error 0.0092(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2570 | Time 29.3971(30.5116) | Bit/dim 1.1104(1.1189) | Xent 0.0407(0.0426) | Loss 1.1308(1.1402) | Error 0.0139(0.0133) Steps 416(421.31) | Grad Norm 0.8643(2.4725) | Total Time 10.00(10.00)\n",
      "Iter 2571 | Time 29.8647(30.4922) | Bit/dim 1.1125(1.1187) | Xent 0.0386(0.0425) | Loss 1.1318(1.1400) | Error 0.0114(0.0132) Steps 416(421.15) | Grad Norm 0.9030(2.4254) | Total Time 10.00(10.00)\n",
      "Iter 2572 | Time 28.5228(30.4331) | Bit/dim 1.1117(1.1185) | Xent 0.0388(0.0424) | Loss 1.1311(1.1397) | Error 0.0106(0.0131) Steps 428(421.35) | Grad Norm 0.9577(2.3814) | Total Time 10.00(10.00)\n",
      "Iter 2573 | Time 28.9408(30.3883) | Bit/dim 1.1145(1.1184) | Xent 0.0383(0.0422) | Loss 1.1336(1.1395) | Error 0.0111(0.0131) Steps 416(421.19) | Grad Norm 0.3647(2.3209) | Total Time 10.00(10.00)\n",
      "Iter 2574 | Time 28.8097(30.3410) | Bit/dim 1.1154(1.1183) | Xent 0.0441(0.0423) | Loss 1.1375(1.1395) | Error 0.0131(0.0131) Steps 416(421.04) | Grad Norm 0.2443(2.2586) | Total Time 10.00(10.00)\n",
      "Iter 2575 | Time 30.0090(30.3310) | Bit/dim 1.1143(1.1182) | Xent 0.0394(0.0422) | Loss 1.1340(1.1393) | Error 0.0134(0.0131) Steps 416(420.89) | Grad Norm 0.8602(2.2166) | Total Time 10.00(10.00)\n",
      "Iter 2576 | Time 28.9968(30.2910) | Bit/dim 1.1092(1.1179) | Xent 0.0422(0.0422) | Loss 1.1303(1.1390) | Error 0.0129(0.0131) Steps 416(420.74) | Grad Norm 0.7960(2.1740) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 16.4301, Epoch Time 233.6521(239.7294), Bit/dim 1.1056(best: 1.1064), Xent 0.0287, Loss 1.1200, Error 0.0102(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2577 | Time 29.3672(30.2633) | Bit/dim 1.1098(1.1177) | Xent 0.0393(0.0421) | Loss 1.1295(1.1387) | Error 0.0110(0.0130) Steps 410(420.42) | Grad Norm 0.6572(2.1285) | Total Time 10.00(10.00)\n",
      "Iter 2578 | Time 28.5347(30.2114) | Bit/dim 1.1130(1.1175) | Xent 0.0388(0.0420) | Loss 1.1324(1.1385) | Error 0.0112(0.0130) Steps 416(420.28) | Grad Norm 0.1775(2.0700) | Total Time 10.00(10.00)\n",
      "Iter 2579 | Time 29.9827(30.2046) | Bit/dim 1.1086(1.1173) | Xent 0.0419(0.0420) | Loss 1.1296(1.1383) | Error 0.0124(0.0129) Steps 416(420.16) | Grad Norm 0.2353(2.0149) | Total Time 10.00(10.00)\n",
      "Iter 2580 | Time 28.6951(30.1593) | Bit/dim 1.1113(1.1171) | Xent 0.0375(0.0419) | Loss 1.1300(1.1380) | Error 0.0102(0.0129) Steps 416(420.03) | Grad Norm 0.8447(1.9798) | Total Time 10.00(10.00)\n",
      "Iter 2581 | Time 29.7193(30.1461) | Bit/dim 1.1077(1.1168) | Xent 0.0442(0.0420) | Loss 1.1298(1.1378) | Error 0.0148(0.0129) Steps 416(419.91) | Grad Norm 0.4840(1.9350) | Total Time 10.00(10.00)\n",
      "Iter 2582 | Time 30.5638(30.1586) | Bit/dim 1.1129(1.1167) | Xent 0.0388(0.0419) | Loss 1.1323(1.1376) | Error 0.0130(0.0129) Steps 422(419.97) | Grad Norm 0.4317(1.8899) | Total Time 10.00(10.00)\n",
      "Iter 2583 | Time 28.6541(30.1135) | Bit/dim 1.1172(1.1167) | Xent 0.0384(0.0418) | Loss 1.1364(1.1376) | Error 0.0111(0.0129) Steps 416(419.85) | Grad Norm 0.2733(1.8414) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 16.9311, Epoch Time 234.8032(239.5816), Bit/dim 1.1058(best: 1.1056), Xent 0.0270, Loss 1.1193, Error 0.0094(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2584 | Time 30.4305(30.1230) | Bit/dim 1.1159(1.1167) | Xent 0.0417(0.0418) | Loss 1.1367(1.1376) | Error 0.0135(0.0129) Steps 416(419.74) | Grad Norm 0.2307(1.7930) | Total Time 10.00(10.00)\n",
      "Iter 2585 | Time 30.2244(30.1260) | Bit/dim 1.1105(1.1165) | Xent 0.0416(0.0418) | Loss 1.1313(1.1374) | Error 0.0122(0.0129) Steps 416(419.63) | Grad Norm 0.3858(1.7508) | Total Time 10.00(10.00)\n",
      "Iter 2586 | Time 29.6291(30.1111) | Bit/dim 1.1165(1.1165) | Xent 0.0411(0.0417) | Loss 1.1371(1.1374) | Error 0.0140(0.0129) Steps 416(419.52) | Grad Norm 0.5659(1.7153) | Total Time 10.00(10.00)\n",
      "Iter 2587 | Time 29.0105(30.0781) | Bit/dim 1.1088(1.1163) | Xent 0.0450(0.0418) | Loss 1.1313(1.1372) | Error 0.0144(0.0129) Steps 422(419.59) | Grad Norm 0.6491(1.6833) | Total Time 10.00(10.00)\n",
      "Iter 2588 | Time 29.4452(30.0591) | Bit/dim 1.1121(1.1161) | Xent 0.0451(0.0419) | Loss 1.1346(1.1371) | Error 0.0128(0.0129) Steps 416(419.48) | Grad Norm 0.2931(1.6416) | Total Time 10.00(10.00)\n",
      "Iter 2589 | Time 30.1140(30.0608) | Bit/dim 1.1096(1.1159) | Xent 0.0410(0.0419) | Loss 1.1301(1.1369) | Error 0.0132(0.0129) Steps 416(419.38) | Grad Norm 0.2351(1.5994) | Total Time 10.00(10.00)\n",
      "Iter 2590 | Time 29.1145(30.0324) | Bit/dim 1.1105(1.1158) | Xent 0.0416(0.0419) | Loss 1.1313(1.1367) | Error 0.0129(0.0129) Steps 416(419.28) | Grad Norm 0.5128(1.5668) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 16.6880, Epoch Time 237.3955(239.5160), Bit/dim 1.1064(best: 1.1056), Xent 0.0293, Loss 1.1210, Error 0.0098(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2591 | Time 30.3256(30.0412) | Bit/dim 1.1127(1.1157) | Xent 0.0390(0.0418) | Loss 1.1322(1.1366) | Error 0.0134(0.0130) Steps 416(419.18) | Grad Norm 0.4091(1.5321) | Total Time 10.00(10.00)\n",
      "Iter 2592 | Time 28.9553(30.0086) | Bit/dim 1.1132(1.1156) | Xent 0.0452(0.0419) | Loss 1.1358(1.1366) | Error 0.0135(0.0130) Steps 416(419.08) | Grad Norm 0.5589(1.5029) | Total Time 10.00(10.00)\n",
      "Iter 2593 | Time 28.8084(29.9726) | Bit/dim 1.1127(1.1155) | Xent 0.0417(0.0419) | Loss 1.1336(1.1365) | Error 0.0129(0.0130) Steps 416(418.99) | Grad Norm 0.3248(1.4675) | Total Time 10.00(10.00)\n",
      "Iter 2594 | Time 29.2086(29.9497) | Bit/dim 1.1109(1.1154) | Xent 0.0377(0.0418) | Loss 1.1297(1.1363) | Error 0.0131(0.0130) Steps 422(419.08) | Grad Norm 0.2407(1.4307) | Total Time 10.00(10.00)\n",
      "Iter 2595 | Time 28.8498(29.9167) | Bit/dim 1.1068(1.1151) | Xent 0.0399(0.0417) | Loss 1.1267(1.1360) | Error 0.0111(0.0129) Steps 416(418.99) | Grad Norm 0.2385(1.3950) | Total Time 10.00(10.00)\n",
      "Iter 2596 | Time 28.4733(29.8734) | Bit/dim 1.1151(1.1151) | Xent 0.0452(0.0418) | Loss 1.1377(1.1360) | Error 0.0146(0.0130) Steps 416(418.90) | Grad Norm 0.5995(1.3711) | Total Time 10.00(10.00)\n",
      "Iter 2597 | Time 29.6311(29.8661) | Bit/dim 1.1134(1.1151) | Xent 0.0355(0.0416) | Loss 1.1312(1.1359) | Error 0.0090(0.0128) Steps 416(418.81) | Grad Norm 0.2154(1.3364) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 16.7752, Epoch Time 233.6692(239.3406), Bit/dim 1.1057(best: 1.1056), Xent 0.0271, Loss 1.1193, Error 0.0095(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2598 | Time 28.5442(29.8264) | Bit/dim 1.1161(1.1151) | Xent 0.0333(0.0414) | Loss 1.1328(1.1358) | Error 0.0115(0.0128) Steps 416(418.73) | Grad Norm 0.1321(1.3003) | Total Time 10.00(10.00)\n",
      "Iter 2599 | Time 29.2400(29.8089) | Bit/dim 1.1187(1.1152) | Xent 0.0542(0.0418) | Loss 1.1458(1.1361) | Error 0.0151(0.0129) Steps 416(418.65) | Grad Norm 0.2765(1.2696) | Total Time 10.00(10.00)\n",
      "Iter 2600 | Time 28.3782(29.7659) | Bit/dim 1.1123(1.1151) | Xent 0.0377(0.0416) | Loss 1.1311(1.1359) | Error 0.0124(0.0129) Steps 416(418.57) | Grad Norm 0.3822(1.2430) | Total Time 10.00(10.00)\n",
      "Iter 2601 | Time 28.9542(29.7416) | Bit/dim 1.1080(1.1149) | Xent 0.0426(0.0417) | Loss 1.1293(1.1357) | Error 0.0119(0.0128) Steps 416(418.49) | Grad Norm 0.2529(1.2133) | Total Time 10.00(10.00)\n",
      "Iter 2602 | Time 28.4982(29.7043) | Bit/dim 1.1091(1.1147) | Xent 0.0424(0.0417) | Loss 1.1303(1.1356) | Error 0.0122(0.0128) Steps 416(418.42) | Grad Norm 0.2852(1.1854) | Total Time 10.00(10.00)\n",
      "Iter 2603 | Time 28.4213(29.6658) | Bit/dim 1.1095(1.1146) | Xent 0.0447(0.0418) | Loss 1.1318(1.1355) | Error 0.0132(0.0128) Steps 422(418.52) | Grad Norm 0.2672(1.1579) | Total Time 10.00(10.00)\n",
      "Iter 2604 | Time 29.1987(29.6518) | Bit/dim 1.1092(1.1144) | Xent 0.0387(0.0417) | Loss 1.1286(1.1353) | Error 0.0111(0.0128) Steps 416(418.45) | Grad Norm 0.2411(1.1304) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 16.7858, Epoch Time 230.7543(239.0830), Bit/dim 1.1059(best: 1.1056), Xent 0.0296, Loss 1.1207, Error 0.0105(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2605 | Time 28.4293(29.6151) | Bit/dim 1.1150(1.1144) | Xent 0.0368(0.0415) | Loss 1.1334(1.1352) | Error 0.0115(0.0127) Steps 416(418.37) | Grad Norm 0.2827(1.1049) | Total Time 10.00(10.00)\n",
      "Iter 2606 | Time 30.0239(29.6274) | Bit/dim 1.1121(1.1144) | Xent 0.0410(0.0415) | Loss 1.1326(1.1351) | Error 0.0122(0.0127) Steps 422(418.48) | Grad Norm 0.2239(1.0785) | Total Time 10.00(10.00)\n",
      "Iter 2607 | Time 29.9548(29.6372) | Bit/dim 1.1061(1.1141) | Xent 0.0350(0.0413) | Loss 1.1236(1.1348) | Error 0.0115(0.0127) Steps 416(418.41) | Grad Norm 0.3193(1.0557) | Total Time 10.00(10.00)\n",
      "Iter 2608 | Time 28.5115(29.6034) | Bit/dim 1.1109(1.1140) | Xent 0.0405(0.0413) | Loss 1.1311(1.1347) | Error 0.0121(0.0127) Steps 416(418.34) | Grad Norm 0.1732(1.0293) | Total Time 10.00(10.00)\n",
      "Iter 2609 | Time 28.6415(29.5746) | Bit/dim 1.1094(1.1139) | Xent 0.0483(0.0415) | Loss 1.1336(1.1346) | Error 0.0138(0.0127) Steps 416(418.27) | Grad Norm 0.2298(1.0053) | Total Time 10.00(10.00)\n",
      "Iter 2610 | Time 28.8172(29.5518) | Bit/dim 1.1136(1.1139) | Xent 0.0452(0.0416) | Loss 1.1362(1.1347) | Error 0.0132(0.0127) Steps 422(418.38) | Grad Norm 0.2031(0.9812) | Total Time 10.00(10.00)\n",
      "Iter 2611 | Time 29.8760(29.5616) | Bit/dim 1.1144(1.1139) | Xent 0.0393(0.0416) | Loss 1.1340(1.1347) | Error 0.0139(0.0128) Steps 422(418.49) | Grad Norm 0.2149(0.9582) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 16.3949, Epoch Time 233.1591(238.9053), Bit/dim 1.1062(best: 1.1056), Xent 0.0277, Loss 1.1200, Error 0.0093(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2612 | Time 28.1347(29.5188) | Bit/dim 1.1123(1.1138) | Xent 0.0340(0.0413) | Loss 1.1293(1.1345) | Error 0.0105(0.0127) Steps 422(418.59) | Grad Norm 0.2081(0.9357) | Total Time 10.00(10.00)\n",
      "Iter 2613 | Time 29.8363(29.5283) | Bit/dim 1.1103(1.1137) | Xent 0.0451(0.0414) | Loss 1.1329(1.1345) | Error 0.0134(0.0127) Steps 416(418.51) | Grad Norm 0.1881(0.9133) | Total Time 10.00(10.00)\n",
      "Iter 2614 | Time 28.8506(29.5080) | Bit/dim 1.1137(1.1137) | Xent 0.0402(0.0414) | Loss 1.1338(1.1344) | Error 0.0120(0.0127) Steps 416(418.44) | Grad Norm 0.4770(0.9002) | Total Time 10.00(10.00)\n",
      "Iter 2615 | Time 28.9140(29.4901) | Bit/dim 1.1089(1.1136) | Xent 0.0397(0.0414) | Loss 1.1288(1.1343) | Error 0.0122(0.0127) Steps 422(418.55) | Grad Norm 0.2104(0.8795) | Total Time 10.00(10.00)\n",
      "Iter 2616 | Time 28.7252(29.4672) | Bit/dim 1.1138(1.1136) | Xent 0.0432(0.0414) | Loss 1.1354(1.1343) | Error 0.0126(0.0127) Steps 416(418.47) | Grad Norm 0.3302(0.8630) | Total Time 10.00(10.00)\n",
      "Iter 2617 | Time 28.8147(29.4476) | Bit/dim 1.1068(1.1134) | Xent 0.0331(0.0412) | Loss 1.1233(1.1340) | Error 0.0099(0.0126) Steps 416(418.40) | Grad Norm 0.1992(0.8431) | Total Time 10.00(10.00)\n",
      "Iter 2618 | Time 28.2670(29.4122) | Bit/dim 1.1149(1.1134) | Xent 0.0347(0.0410) | Loss 1.1323(1.1339) | Error 0.0118(0.0126) Steps 416(418.32) | Grad Norm 0.3151(0.8273) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 16.5987, Epoch Time 230.4328(238.6511), Bit/dim 1.1060(best: 1.1056), Xent 0.0280, Loss 1.1200, Error 0.0094(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2619 | Time 28.5821(29.3873) | Bit/dim 1.1097(1.1133) | Xent 0.0376(0.0409) | Loss 1.1285(1.1338) | Error 0.0099(0.0125) Steps 416(418.25) | Grad Norm 0.1868(0.8081) | Total Time 10.00(10.00)\n",
      "Iter 2620 | Time 28.9884(29.3753) | Bit/dim 1.1127(1.1133) | Xent 0.0343(0.0407) | Loss 1.1299(1.1336) | Error 0.0105(0.0124) Steps 422(418.37) | Grad Norm 0.1759(0.7891) | Total Time 10.00(10.00)\n",
      "Iter 2621 | Time 28.5763(29.3514) | Bit/dim 1.1083(1.1132) | Xent 0.0411(0.0407) | Loss 1.1289(1.1335) | Error 0.0110(0.0124) Steps 422(418.48) | Grad Norm 0.2161(0.7719) | Total Time 10.00(10.00)\n",
      "Iter 2622 | Time 28.5896(29.3285) | Bit/dim 1.1125(1.1131) | Xent 0.0434(0.0408) | Loss 1.1342(1.1335) | Error 0.0139(0.0124) Steps 422(418.58) | Grad Norm 0.2994(0.7577) | Total Time 10.00(10.00)\n",
      "Iter 2623 | Time 28.7875(29.3123) | Bit/dim 1.1161(1.1132) | Xent 0.0426(0.0408) | Loss 1.1374(1.1336) | Error 0.0135(0.0125) Steps 416(418.50) | Grad Norm 0.2037(0.7411) | Total Time 10.00(10.00)\n",
      "Iter 2624 | Time 29.1731(29.3081) | Bit/dim 1.1140(1.1133) | Xent 0.0361(0.0407) | Loss 1.1321(1.1336) | Error 0.0110(0.0124) Steps 422(418.61) | Grad Norm 0.2082(0.7251) | Total Time 10.00(10.00)\n",
      "Iter 2625 | Time 28.9858(29.2984) | Bit/dim 1.1108(1.1132) | Xent 0.0382(0.0406) | Loss 1.1299(1.1335) | Error 0.0108(0.0124) Steps 416(418.53) | Grad Norm 0.2428(0.7106) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 16.5785, Epoch Time 230.6810(238.4120), Bit/dim 1.1063(best: 1.1056), Xent 0.0270, Loss 1.1197, Error 0.0095(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2626 | Time 29.5835(29.3070) | Bit/dim 1.1104(1.1131) | Xent 0.0441(0.0407) | Loss 1.1324(1.1334) | Error 0.0139(0.0124) Steps 422(418.63) | Grad Norm 0.4426(0.7026) | Total Time 10.00(10.00)\n",
      "Iter 2627 | Time 30.2558(29.3354) | Bit/dim 1.1170(1.1132) | Xent 0.0407(0.0407) | Loss 1.1373(1.1336) | Error 0.0125(0.0124) Steps 422(418.74) | Grad Norm 0.2118(0.6879) | Total Time 10.00(10.00)\n",
      "Iter 2628 | Time 28.4994(29.3104) | Bit/dim 1.1153(1.1133) | Xent 0.0429(0.0408) | Loss 1.1367(1.1337) | Error 0.0136(0.0124) Steps 416(418.65) | Grad Norm 0.4778(0.6816) | Total Time 10.00(10.00)\n",
      "Iter 2629 | Time 28.8820(29.2975) | Bit/dim 1.1087(1.1131) | Xent 0.0345(0.0406) | Loss 1.1259(1.1334) | Error 0.0110(0.0124) Steps 416(418.57) | Grad Norm 0.2067(0.6673) | Total Time 10.00(10.00)\n",
      "Iter 2630 | Time 30.0950(29.3214) | Bit/dim 1.1066(1.1129) | Xent 0.0409(0.0406) | Loss 1.1270(1.1332) | Error 0.0144(0.0125) Steps 416(418.50) | Grad Norm 0.2536(0.6549) | Total Time 10.00(10.00)\n",
      "Iter 2631 | Time 29.0962(29.3147) | Bit/dim 1.1132(1.1129) | Xent 0.0455(0.0407) | Loss 1.1359(1.1333) | Error 0.0134(0.0125) Steps 416(418.42) | Grad Norm 0.2528(0.6429) | Total Time 10.00(10.00)\n",
      "Iter 2632 | Time 29.4778(29.3196) | Bit/dim 1.1085(1.1128) | Xent 0.0402(0.0407) | Loss 1.1286(1.1332) | Error 0.0112(0.0125) Steps 416(418.35) | Grad Norm 0.2280(0.6304) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 16.8053, Epoch Time 235.3754(238.3209), Bit/dim 1.1052(best: 1.1056), Xent 0.0287, Loss 1.1195, Error 0.0105(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2633 | Time 28.6934(29.3008) | Bit/dim 1.1138(1.1128) | Xent 0.0386(0.0407) | Loss 1.1331(1.1332) | Error 0.0125(0.0125) Steps 416(418.28) | Grad Norm 0.2516(0.6190) | Total Time 10.00(10.00)\n",
      "Iter 2634 | Time 30.2214(29.3284) | Bit/dim 1.1107(1.1128) | Xent 0.0397(0.0406) | Loss 1.1305(1.1331) | Error 0.0118(0.0124) Steps 416(418.21) | Grad Norm 0.1977(0.6064) | Total Time 10.00(10.00)\n",
      "Iter 2635 | Time 28.9630(29.3174) | Bit/dim 1.1073(1.1126) | Xent 0.0400(0.0406) | Loss 1.1273(1.1329) | Error 0.0125(0.0124) Steps 416(418.14) | Grad Norm 0.3069(0.5974) | Total Time 10.00(10.00)\n",
      "Iter 2636 | Time 28.9695(29.3070) | Bit/dim 1.1129(1.1126) | Xent 0.0323(0.0404) | Loss 1.1291(1.1328) | Error 0.0115(0.0124) Steps 416(418.08) | Grad Norm 0.2628(0.5874) | Total Time 10.00(10.00)\n",
      "Iter 2637 | Time 28.5896(29.2855) | Bit/dim 1.1110(1.1126) | Xent 0.0424(0.0404) | Loss 1.1322(1.1328) | Error 0.0126(0.0124) Steps 416(418.02) | Grad Norm 0.2199(0.5764) | Total Time 10.00(10.00)\n",
      "Iter 2638 | Time 28.7881(29.2706) | Bit/dim 1.1124(1.1126) | Xent 0.0381(0.0404) | Loss 1.1314(1.1327) | Error 0.0135(0.0124) Steps 416(417.96) | Grad Norm 0.3375(0.5692) | Total Time 10.00(10.00)\n",
      "Iter 2639 | Time 28.9559(29.2611) | Bit/dim 1.1120(1.1126) | Xent 0.0466(0.0405) | Loss 1.1353(1.1328) | Error 0.0142(0.0125) Steps 416(417.90) | Grad Norm 0.2128(0.5585) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 16.4615, Epoch Time 232.1479(238.1357), Bit/dim 1.1058(best: 1.1052), Xent 0.0273, Loss 1.1194, Error 0.0095(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2640 | Time 29.6938(29.2741) | Bit/dim 1.1100(1.1125) | Xent 0.0356(0.0404) | Loss 1.1278(1.1327) | Error 0.0109(0.0125) Steps 422(418.02) | Grad Norm 0.3010(0.5508) | Total Time 10.00(10.00)\n",
      "Iter 2641 | Time 29.0139(29.2663) | Bit/dim 1.1113(1.1124) | Xent 0.0379(0.0403) | Loss 1.1303(1.1326) | Error 0.0119(0.0124) Steps 416(417.96) | Grad Norm 0.3009(0.5433) | Total Time 10.00(10.00)\n",
      "Iter 2642 | Time 28.9037(29.2554) | Bit/dim 1.1156(1.1125) | Xent 0.0359(0.0402) | Loss 1.1336(1.1326) | Error 0.0121(0.0124) Steps 422(418.08) | Grad Norm 0.3246(0.5367) | Total Time 10.00(10.00)\n",
      "Iter 2643 | Time 28.8700(29.2439) | Bit/dim 1.1132(1.1126) | Xent 0.0374(0.0401) | Loss 1.1318(1.1326) | Error 0.0111(0.0124) Steps 422(418.20) | Grad Norm 0.1959(0.5265) | Total Time 10.00(10.00)\n",
      "Iter 2644 | Time 28.7441(29.2289) | Bit/dim 1.1069(1.1124) | Xent 0.0383(0.0400) | Loss 1.1260(1.1324) | Error 0.0119(0.0124) Steps 416(418.13) | Grad Norm 0.2526(0.5183) | Total Time 10.00(10.00)\n",
      "Iter 2645 | Time 28.3831(29.2035) | Bit/dim 1.1095(1.1123) | Xent 0.0442(0.0402) | Loss 1.1316(1.1324) | Error 0.0124(0.0124) Steps 416(418.07) | Grad Norm 0.3961(0.5146) | Total Time 10.00(10.00)\n",
      "Iter 2646 | Time 28.7065(29.1886) | Bit/dim 1.1146(1.1124) | Xent 0.0471(0.0404) | Loss 1.1382(1.1326) | Error 0.0144(0.0124) Steps 416(418.01) | Grad Norm 0.3556(0.5098) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 16.3621, Epoch Time 231.3034(237.9308), Bit/dim 1.1059(best: 1.1052), Xent 0.0271, Loss 1.1194, Error 0.0092(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2647 | Time 28.5293(29.1688) | Bit/dim 1.1099(1.1123) | Xent 0.0403(0.0404) | Loss 1.1300(1.1325) | Error 0.0131(0.0125) Steps 416(417.95) | Grad Norm 0.2627(0.5024) | Total Time 10.00(10.00)\n",
      "Iter 2648 | Time 28.6978(29.1547) | Bit/dim 1.1097(1.1122) | Xent 0.0392(0.0403) | Loss 1.1293(1.1324) | Error 0.0130(0.0125) Steps 416(417.89) | Grad Norm 0.1625(0.4922) | Total Time 10.00(10.00)\n",
      "Iter 2649 | Time 28.9620(29.1489) | Bit/dim 1.1122(1.1122) | Xent 0.0370(0.0402) | Loss 1.1307(1.1323) | Error 0.0116(0.0124) Steps 416(417.83) | Grad Norm 0.3157(0.4869) | Total Time 10.00(10.00)\n",
      "Iter 2650 | Time 29.0731(29.1466) | Bit/dim 1.1128(1.1122) | Xent 0.0413(0.0403) | Loss 1.1334(1.1324) | Error 0.0140(0.0125) Steps 422(417.96) | Grad Norm 0.2529(0.4799) | Total Time 10.00(10.00)\n",
      "Iter 2651 | Time 28.6877(29.1329) | Bit/dim 1.1121(1.1122) | Xent 0.0406(0.0403) | Loss 1.1324(1.1324) | Error 0.0119(0.0125) Steps 416(417.90) | Grad Norm 0.2250(0.4723) | Total Time 10.00(10.00)\n",
      "Iter 2652 | Time 28.6095(29.1172) | Bit/dim 1.1170(1.1124) | Xent 0.0480(0.0405) | Loss 1.1409(1.1326) | Error 0.0141(0.0125) Steps 416(417.84) | Grad Norm 0.1928(0.4639) | Total Time 10.00(10.00)\n",
      "Iter 2653 | Time 28.7839(29.1072) | Bit/dim 1.1108(1.1123) | Xent 0.0420(0.0406) | Loss 1.1319(1.1326) | Error 0.0136(0.0126) Steps 416(417.79) | Grad Norm 0.2244(0.4567) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 16.7744, Epoch Time 230.5962(237.7107), Bit/dim 1.1063(best: 1.1052), Xent 0.0284, Loss 1.1205, Error 0.0091(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2654 | Time 30.0927(29.1367) | Bit/dim 1.1067(1.1122) | Xent 0.0472(0.0408) | Loss 1.1303(1.1325) | Error 0.0128(0.0126) Steps 422(417.91) | Grad Norm 0.2219(0.4497) | Total Time 10.00(10.00)\n",
      "Iter 2655 | Time 28.8189(29.1272) | Bit/dim 1.1082(1.1120) | Xent 0.0475(0.0410) | Loss 1.1319(1.1325) | Error 0.0152(0.0126) Steps 416(417.85) | Grad Norm 0.2145(0.4426) | Total Time 10.00(10.00)\n",
      "Iter 2656 | Time 28.6420(29.1126) | Bit/dim 1.1149(1.1121) | Xent 0.0388(0.0409) | Loss 1.1343(1.1326) | Error 0.0115(0.0126) Steps 416(417.80) | Grad Norm 0.4338(0.4423) | Total Time 10.00(10.00)\n",
      "Iter 2657 | Time 28.8867(29.1059) | Bit/dim 1.1124(1.1121) | Xent 0.0388(0.0408) | Loss 1.1318(1.1325) | Error 0.0126(0.0126) Steps 416(417.75) | Grad Norm 0.3994(0.4411) | Total Time 10.00(10.00)\n",
      "Iter 2658 | Time 28.9254(29.1004) | Bit/dim 1.1155(1.1122) | Xent 0.0397(0.0408) | Loss 1.1353(1.1326) | Error 0.0110(0.0126) Steps 416(417.69) | Grad Norm 0.4417(0.4411) | Total Time 10.00(10.00)\n",
      "Iter 2659 | Time 30.1643(29.1324) | Bit/dim 1.1132(1.1123) | Xent 0.0389(0.0407) | Loss 1.1326(1.1326) | Error 0.0118(0.0125) Steps 416(417.64) | Grad Norm 0.5195(0.4434) | Total Time 10.00(10.00)\n",
      "Iter 2660 | Time 28.9878(29.1280) | Bit/dim 1.1073(1.1121) | Xent 0.0436(0.0408) | Loss 1.1291(1.1325) | Error 0.0140(0.0126) Steps 416(417.59) | Grad Norm 0.4153(0.4426) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 16.6684, Epoch Time 233.9252(237.5972), Bit/dim 1.1060(best: 1.1052), Xent 0.0277, Loss 1.1199, Error 0.0093(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2661 | Time 31.6232(29.2029) | Bit/dim 1.1119(1.1121) | Xent 0.0386(0.0408) | Loss 1.1312(1.1325) | Error 0.0121(0.0126) Steps 422(417.73) | Grad Norm 0.3322(0.4393) | Total Time 10.00(10.00)\n",
      "Iter 2662 | Time 30.4422(29.2401) | Bit/dim 1.1105(1.1121) | Xent 0.0381(0.0407) | Loss 1.1295(1.1324) | Error 0.0119(0.0125) Steps 416(417.67) | Grad Norm 0.2370(0.4332) | Total Time 10.00(10.00)\n",
      "Iter 2663 | Time 27.9608(29.2017) | Bit/dim 1.1136(1.1121) | Xent 0.0413(0.0407) | Loss 1.1342(1.1324) | Error 0.0131(0.0126) Steps 422(417.80) | Grad Norm 0.6603(0.4400) | Total Time 10.00(10.00)\n",
      "Iter 2664 | Time 29.8360(29.2207) | Bit/dim 1.1104(1.1120) | Xent 0.0448(0.0408) | Loss 1.1328(1.1325) | Error 0.0140(0.0126) Steps 422(417.93) | Grad Norm 0.2728(0.4350) | Total Time 10.00(10.00)\n",
      "Iter 2665 | Time 28.8456(29.2095) | Bit/dim 1.1097(1.1120) | Xent 0.0366(0.0407) | Loss 1.1280(1.1323) | Error 0.0111(0.0126) Steps 422(418.05) | Grad Norm 0.1602(0.4268) | Total Time 10.00(10.00)\n",
      "Iter 2666 | Time 28.4030(29.1853) | Bit/dim 1.1138(1.1120) | Xent 0.0402(0.0407) | Loss 1.1339(1.1324) | Error 0.0119(0.0125) Steps 416(417.99) | Grad Norm 0.1784(0.4193) | Total Time 10.00(10.00)\n",
      "Iter 2667 | Time 28.9393(29.1779) | Bit/dim 1.1113(1.1120) | Xent 0.0401(0.0407) | Loss 1.1314(1.1323) | Error 0.0120(0.0125) Steps 416(417.93) | Grad Norm 0.2596(0.4145) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 16.3772, Epoch Time 234.9446(237.5176), Bit/dim 1.1057(best: 1.1052), Xent 0.0280, Loss 1.1197, Error 0.0096(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2668 | Time 29.0737(29.1748) | Bit/dim 1.1147(1.1121) | Xent 0.0378(0.0406) | Loss 1.1337(1.1324) | Error 0.0118(0.0125) Steps 416(417.87) | Grad Norm 0.3674(0.4131) | Total Time 10.00(10.00)\n",
      "Iter 2669 | Time 28.5815(29.1570) | Bit/dim 1.1115(1.1121) | Xent 0.0428(0.0406) | Loss 1.1329(1.1324) | Error 0.0136(0.0125) Steps 416(417.82) | Grad Norm 0.2225(0.4074) | Total Time 10.00(10.00)\n",
      "Iter 2670 | Time 29.0252(29.1530) | Bit/dim 1.1147(1.1122) | Xent 0.0404(0.0406) | Loss 1.1349(1.1325) | Error 0.0126(0.0125) Steps 416(417.76) | Grad Norm 0.2795(0.4035) | Total Time 10.00(10.00)\n",
      "Iter 2671 | Time 28.6893(29.1391) | Bit/dim 1.1138(1.1122) | Xent 0.0452(0.0408) | Loss 1.1364(1.1326) | Error 0.0139(0.0126) Steps 422(417.89) | Grad Norm 0.2265(0.3982) | Total Time 10.00(10.00)\n",
      "Iter 2672 | Time 28.6619(29.1248) | Bit/dim 1.1117(1.1122) | Xent 0.0430(0.0408) | Loss 1.1332(1.1326) | Error 0.0135(0.0126) Steps 416(417.83) | Grad Norm 0.1643(0.3912) | Total Time 10.00(10.00)\n",
      "Iter 2673 | Time 28.2292(29.0979) | Bit/dim 1.1073(1.1120) | Xent 0.0407(0.0408) | Loss 1.1276(1.1325) | Error 0.0139(0.0126) Steps 422(417.96) | Grad Norm 0.2361(0.3866) | Total Time 10.00(10.00)\n",
      "Iter 2674 | Time 29.8201(29.1196) | Bit/dim 1.1050(1.1118) | Xent 0.0359(0.0407) | Loss 1.1229(1.1322) | Error 0.0120(0.0126) Steps 416(417.90) | Grad Norm 0.5630(0.3919) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 16.5817, Epoch Time 231.1014(237.3251), Bit/dim 1.1050(best: 1.1052), Xent 0.0295, Loss 1.1197, Error 0.0103(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2675 | Time 28.9139(29.1134) | Bit/dim 1.1094(1.1118) | Xent 0.0432(0.0408) | Loss 1.1310(1.1321) | Error 0.0132(0.0126) Steps 416(417.84) | Grad Norm 0.1952(0.3860) | Total Time 10.00(10.00)\n",
      "Iter 2676 | Time 29.0243(29.1107) | Bit/dim 1.1127(1.1118) | Xent 0.0392(0.0407) | Loss 1.1323(1.1321) | Error 0.0122(0.0126) Steps 416(417.79) | Grad Norm 0.1761(0.3797) | Total Time 10.00(10.00)\n",
      "Iter 2677 | Time 29.0680(29.1095) | Bit/dim 1.1072(1.1116) | Xent 0.0382(0.0406) | Loss 1.1263(1.1320) | Error 0.0114(0.0126) Steps 422(417.91) | Grad Norm 0.3797(0.3797) | Total Time 10.00(10.00)\n",
      "Iter 2678 | Time 28.9897(29.1059) | Bit/dim 1.1113(1.1116) | Xent 0.0382(0.0406) | Loss 1.1304(1.1319) | Error 0.0119(0.0126) Steps 422(418.04) | Grad Norm 0.2979(0.3772) | Total Time 10.00(10.00)\n",
      "Iter 2679 | Time 30.4673(29.1467) | Bit/dim 1.1112(1.1116) | Xent 0.0412(0.0406) | Loss 1.1318(1.1319) | Error 0.0120(0.0126) Steps 416(417.97) | Grad Norm 0.2513(0.3734) | Total Time 10.00(10.00)\n",
      "Iter 2680 | Time 28.4553(29.1260) | Bit/dim 1.1082(1.1115) | Xent 0.0395(0.0406) | Loss 1.1280(1.1318) | Error 0.0122(0.0125) Steps 422(418.09) | Grad Norm 0.2222(0.3689) | Total Time 10.00(10.00)\n",
      "Iter 2681 | Time 28.7288(29.1140) | Bit/dim 1.1178(1.1117) | Xent 0.0394(0.0405) | Loss 1.1375(1.1320) | Error 0.0112(0.0125) Steps 422(418.21) | Grad Norm 0.3139(0.3672) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 16.5758, Epoch Time 232.6431(237.1846), Bit/dim 1.1056(best: 1.1050), Xent 0.0295, Loss 1.1204, Error 0.0104(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2682 | Time 29.2565(29.1183) | Bit/dim 1.1123(1.1117) | Xent 0.0354(0.0404) | Loss 1.1300(1.1319) | Error 0.0115(0.0125) Steps 416(418.15) | Grad Norm 0.4921(0.3710) | Total Time 10.00(10.00)\n",
      "Iter 2683 | Time 29.6820(29.1352) | Bit/dim 1.1057(1.1115) | Xent 0.0406(0.0404) | Loss 1.1260(1.1317) | Error 0.0130(0.0125) Steps 416(418.08) | Grad Norm 0.1722(0.3650) | Total Time 10.00(10.00)\n",
      "Iter 2684 | Time 30.9593(29.1900) | Bit/dim 1.1082(1.1114) | Xent 0.0399(0.0404) | Loss 1.1282(1.1316) | Error 0.0146(0.0126) Steps 416(418.02) | Grad Norm 0.2188(0.3606) | Total Time 10.00(10.00)\n",
      "Iter 2685 | Time 29.3113(29.1936) | Bit/dim 1.1107(1.1114) | Xent 0.0404(0.0404) | Loss 1.1308(1.1316) | Error 0.0131(0.0126) Steps 416(417.96) | Grad Norm 0.2391(0.3570) | Total Time 10.00(10.00)\n",
      "Iter 2686 | Time 30.1423(29.2221) | Bit/dim 1.1104(1.1114) | Xent 0.0442(0.0405) | Loss 1.1325(1.1316) | Error 0.0136(0.0126) Steps 416(417.90) | Grad Norm 0.4170(0.3588) | Total Time 10.00(10.00)\n",
      "Iter 2687 | Time 29.6128(29.2338) | Bit/dim 1.1128(1.1114) | Xent 0.0425(0.0405) | Loss 1.1340(1.1317) | Error 0.0125(0.0126) Steps 416(417.84) | Grad Norm 0.2503(0.3555) | Total Time 10.00(10.00)\n",
      "Iter 2688 | Time 29.0119(29.2271) | Bit/dim 1.1147(1.1115) | Xent 0.0385(0.0405) | Loss 1.1339(1.1318) | Error 0.0118(0.0126) Steps 422(417.97) | Grad Norm 0.2039(0.3510) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 16.7597, Epoch Time 237.2100(237.1854), Bit/dim 1.1054(best: 1.1050), Xent 0.0264, Loss 1.1186, Error 0.0085(best: 0.0091)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2689 | Time 30.0358(29.2514) | Bit/dim 1.1122(1.1116) | Xent 0.0451(0.0406) | Loss 1.1347(1.1319) | Error 0.0145(0.0126) Steps 416(417.91) | Grad Norm 0.3013(0.3495) | Total Time 10.00(10.00)\n",
      "Iter 2690 | Time 29.5547(29.2605) | Bit/dim 1.1074(1.1114) | Xent 0.0396(0.0406) | Loss 1.1272(1.1317) | Error 0.0122(0.0126) Steps 416(417.85) | Grad Norm 0.2946(0.3479) | Total Time 10.00(10.00)\n",
      "Iter 2691 | Time 29.7006(29.2737) | Bit/dim 1.1121(1.1114) | Xent 0.0434(0.0407) | Loss 1.1338(1.1318) | Error 0.0148(0.0127) Steps 416(417.80) | Grad Norm 0.4125(0.3498) | Total Time 10.00(10.00)\n",
      "Iter 2692 | Time 30.5342(29.3115) | Bit/dim 1.1146(1.1115) | Xent 0.0374(0.0406) | Loss 1.1333(1.1318) | Error 0.0112(0.0126) Steps 416(417.74) | Grad Norm 0.2195(0.3459) | Total Time 10.00(10.00)\n",
      "Iter 2693 | Time 29.0418(29.3034) | Bit/dim 1.1078(1.1114) | Xent 0.0347(0.0404) | Loss 1.1252(1.1316) | Error 0.0118(0.0126) Steps 422(417.87) | Grad Norm 0.2386(0.3427) | Total Time 10.00(10.00)\n",
      "Iter 2694 | Time 28.4421(29.2776) | Bit/dim 1.1066(1.1113) | Xent 0.0400(0.0404) | Loss 1.1266(1.1315) | Error 0.0120(0.0126) Steps 416(417.81) | Grad Norm 0.2206(0.3390) | Total Time 10.00(10.00)\n",
      "Iter 2695 | Time 28.9889(29.2689) | Bit/dim 1.1163(1.1114) | Xent 0.0416(0.0404) | Loss 1.1371(1.1316) | Error 0.0148(0.0127) Steps 416(417.76) | Grad Norm 0.6467(0.3482) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 16.7975, Epoch Time 235.3691(237.1309), Bit/dim 1.1052(best: 1.1050), Xent 0.0284, Loss 1.1194, Error 0.0101(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2696 | Time 29.2058(29.2670) | Bit/dim 1.1126(1.1115) | Xent 0.0466(0.0406) | Loss 1.1359(1.1318) | Error 0.0138(0.0127) Steps 416(417.71) | Grad Norm 0.3338(0.3478) | Total Time 10.00(10.00)\n",
      "Iter 2697 | Time 29.0032(29.2591) | Bit/dim 1.1132(1.1115) | Xent 0.0439(0.0407) | Loss 1.1352(1.1319) | Error 0.0135(0.0127) Steps 416(417.65) | Grad Norm 0.2497(0.3449) | Total Time 10.00(10.00)\n",
      "Iter 2698 | Time 28.8149(29.2458) | Bit/dim 1.1179(1.1117) | Xent 0.0394(0.0407) | Loss 1.1376(1.1320) | Error 0.0131(0.0127) Steps 416(417.61) | Grad Norm 0.5299(0.3504) | Total Time 10.00(10.00)\n",
      "Iter 2699 | Time 29.8241(29.2631) | Bit/dim 1.1101(1.1117) | Xent 0.0349(0.0405) | Loss 1.1275(1.1319) | Error 0.0115(0.0127) Steps 422(417.74) | Grad Norm 0.4032(0.3520) | Total Time 10.00(10.00)\n",
      "Iter 2700 | Time 29.0412(29.2565) | Bit/dim 1.1119(1.1117) | Xent 0.0424(0.0405) | Loss 1.1331(1.1319) | Error 0.0121(0.0127) Steps 416(417.68) | Grad Norm 0.4227(0.3541) | Total Time 10.00(10.00)\n",
      "Iter 2701 | Time 29.7315(29.2707) | Bit/dim 1.1101(1.1116) | Xent 0.0432(0.0406) | Loss 1.1317(1.1319) | Error 0.0134(0.0127) Steps 416(417.63) | Grad Norm 0.3516(0.3540) | Total Time 10.00(10.00)\n",
      "Iter 2702 | Time 29.2298(29.2695) | Bit/dim 1.1075(1.1115) | Xent 0.0385(0.0406) | Loss 1.1268(1.1318) | Error 0.0130(0.0127) Steps 416(417.59) | Grad Norm 0.4402(0.3566) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 16.3212, Epoch Time 233.4877(237.0216), Bit/dim 1.1053(best: 1.1050), Xent 0.0296, Loss 1.1200, Error 0.0091(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2703 | Time 28.7843(29.2549) | Bit/dim 1.1090(1.1114) | Xent 0.0423(0.0406) | Loss 1.1301(1.1317) | Error 0.0122(0.0127) Steps 422(417.72) | Grad Norm 0.1912(0.3517) | Total Time 10.00(10.00)\n",
      "Iter 2704 | Time 29.5896(29.2650) | Bit/dim 1.1127(1.1115) | Xent 0.0403(0.0406) | Loss 1.1329(1.1318) | Error 0.0132(0.0127) Steps 416(417.67) | Grad Norm 0.4913(0.3559) | Total Time 10.00(10.00)\n",
      "Iter 2705 | Time 28.8594(29.2528) | Bit/dim 1.1106(1.1114) | Xent 0.0373(0.0405) | Loss 1.1292(1.1317) | Error 0.0116(0.0127) Steps 422(417.80) | Grad Norm 0.2368(0.3523) | Total Time 10.00(10.00)\n",
      "Iter 2706 | Time 28.5882(29.2329) | Bit/dim 1.1097(1.1114) | Xent 0.0343(0.0403) | Loss 1.1268(1.1315) | Error 0.0108(0.0126) Steps 416(417.74) | Grad Norm 0.1946(0.3476) | Total Time 10.00(10.00)\n",
      "Iter 2707 | Time 28.8387(29.2211) | Bit/dim 1.1106(1.1114) | Xent 0.0400(0.0403) | Loss 1.1306(1.1315) | Error 0.0130(0.0126) Steps 416(417.69) | Grad Norm 0.4526(0.3507) | Total Time 10.00(10.00)\n",
      "Iter 2708 | Time 29.2433(29.2217) | Bit/dim 1.1072(1.1112) | Xent 0.0502(0.0406) | Loss 1.1323(1.1315) | Error 0.0160(0.0127) Steps 416(417.64) | Grad Norm 0.3321(0.3501) | Total Time 10.00(10.00)\n",
      "Iter 2709 | Time 30.1491(29.2495) | Bit/dim 1.1168(1.1114) | Xent 0.0437(0.0407) | Loss 1.1387(1.1318) | Error 0.0131(0.0127) Steps 416(417.59) | Grad Norm 0.2489(0.3471) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 16.5902, Epoch Time 233.0175(236.9015), Bit/dim 1.1055(best: 1.1050), Xent 0.0263, Loss 1.1187, Error 0.0090(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2710 | Time 28.4428(29.2253) | Bit/dim 1.1095(1.1113) | Xent 0.0405(0.0407) | Loss 1.1297(1.1317) | Error 0.0126(0.0127) Steps 416(417.54) | Grad Norm 0.2402(0.3439) | Total Time 10.00(10.00)\n",
      "Iter 2711 | Time 28.9867(29.2182) | Bit/dim 1.1091(1.1113) | Xent 0.0355(0.0405) | Loss 1.1268(1.1315) | Error 0.0112(0.0127) Steps 422(417.68) | Grad Norm 0.1937(0.3394) | Total Time 10.00(10.00)\n",
      "Iter 2712 | Time 28.5142(29.1971) | Bit/dim 1.1142(1.1114) | Xent 0.0464(0.0407) | Loss 1.1374(1.1317) | Error 0.0145(0.0127) Steps 416(417.63) | Grad Norm 0.2848(0.3378) | Total Time 10.00(10.00)\n",
      "Iter 2713 | Time 28.5469(29.1776) | Bit/dim 1.1148(1.1115) | Xent 0.0333(0.0405) | Loss 1.1314(1.1317) | Error 0.0095(0.0127) Steps 422(417.76) | Grad Norm 0.2208(0.3342) | Total Time 10.00(10.00)\n",
      "Iter 2714 | Time 28.2561(29.1499) | Bit/dim 1.1096(1.1114) | Xent 0.0474(0.0407) | Loss 1.1333(1.1318) | Error 0.0129(0.0127) Steps 416(417.70) | Grad Norm 0.3850(0.3358) | Total Time 10.00(10.00)\n",
      "Iter 2715 | Time 29.3795(29.1568) | Bit/dim 1.1112(1.1114) | Xent 0.0426(0.0408) | Loss 1.1325(1.1318) | Error 0.0114(0.0126) Steps 422(417.83) | Grad Norm 0.2298(0.3326) | Total Time 10.00(10.00)\n",
      "Iter 2716 | Time 28.9495(29.1506) | Bit/dim 1.1122(1.1114) | Xent 0.0371(0.0406) | Loss 1.1307(1.1317) | Error 0.0114(0.0126) Steps 422(417.96) | Grad Norm 0.1733(0.3278) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 16.9257, Epoch Time 230.4045(236.7066), Bit/dim 1.1054(best: 1.1050), Xent 0.0260, Loss 1.1184, Error 0.0090(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2717 | Time 29.9908(29.1758) | Bit/dim 1.1077(1.1113) | Xent 0.0422(0.0407) | Loss 1.1288(1.1317) | Error 0.0124(0.0126) Steps 422(418.08) | Grad Norm 0.2178(0.3245) | Total Time 10.00(10.00)\n",
      "Iter 2718 | Time 29.7357(29.1926) | Bit/dim 1.1108(1.1113) | Xent 0.0370(0.0406) | Loss 1.1293(1.1316) | Error 0.0114(0.0125) Steps 416(418.02) | Grad Norm 0.3593(0.3256) | Total Time 10.00(10.00)\n",
      "Iter 2719 | Time 29.6293(29.2057) | Bit/dim 1.1112(1.1113) | Xent 0.0372(0.0405) | Loss 1.1298(1.1315) | Error 0.0109(0.0125) Steps 416(417.96) | Grad Norm 0.5270(0.3316) | Total Time 10.00(10.00)\n",
      "Iter 2720 | Time 28.7287(29.1914) | Bit/dim 1.1107(1.1113) | Xent 0.0431(0.0406) | Loss 1.1323(1.1316) | Error 0.0119(0.0125) Steps 416(417.90) | Grad Norm 0.2885(0.3303) | Total Time 10.00(10.00)\n",
      "Iter 2721 | Time 28.6797(29.1760) | Bit/dim 1.1148(1.1114) | Xent 0.0399(0.0405) | Loss 1.1348(1.1317) | Error 0.0119(0.0125) Steps 416(417.84) | Grad Norm 0.2000(0.3264) | Total Time 10.00(10.00)\n",
      "Iter 2722 | Time 28.5378(29.1569) | Bit/dim 1.1072(1.1113) | Xent 0.0402(0.0405) | Loss 1.1273(1.1315) | Error 0.0121(0.0124) Steps 422(417.97) | Grad Norm 0.4245(0.3293) | Total Time 10.00(10.00)\n",
      "Iter 2723 | Time 29.1170(29.1557) | Bit/dim 1.1143(1.1114) | Xent 0.0399(0.0405) | Loss 1.1343(1.1316) | Error 0.0121(0.0124) Steps 416(417.91) | Grad Norm 0.1957(0.3253) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 16.5964, Epoch Time 233.4004(236.6074), Bit/dim 1.1047(best: 1.1050), Xent 0.0265, Loss 1.1179, Error 0.0087(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2724 | Time 28.2172(29.1275) | Bit/dim 1.1120(1.1114) | Xent 0.0464(0.0407) | Loss 1.1352(1.1317) | Error 0.0139(0.0125) Steps 416(417.85) | Grad Norm 0.3933(0.3274) | Total Time 10.00(10.00)\n",
      "Iter 2725 | Time 30.0527(29.1553) | Bit/dim 1.1117(1.1114) | Xent 0.0425(0.0407) | Loss 1.1330(1.1318) | Error 0.0148(0.0125) Steps 416(417.79) | Grad Norm 0.2728(0.3257) | Total Time 10.00(10.00)\n",
      "Iter 2726 | Time 28.7471(29.1430) | Bit/dim 1.1103(1.1114) | Xent 0.0416(0.0408) | Loss 1.1311(1.1317) | Error 0.0142(0.0126) Steps 416(417.74) | Grad Norm 0.2170(0.3225) | Total Time 10.00(10.00)\n",
      "Iter 2727 | Time 28.6961(29.1296) | Bit/dim 1.1138(1.1114) | Xent 0.0400(0.0407) | Loss 1.1338(1.1318) | Error 0.0119(0.0126) Steps 416(417.69) | Grad Norm 0.5360(0.3289) | Total Time 10.00(10.00)\n",
      "Iter 2728 | Time 30.1202(29.1593) | Bit/dim 1.1141(1.1115) | Xent 0.0421(0.0408) | Loss 1.1352(1.1319) | Error 0.0141(0.0126) Steps 416(417.64) | Grad Norm 0.1799(0.3244) | Total Time 10.00(10.00)\n",
      "Iter 2729 | Time 28.6553(29.1442) | Bit/dim 1.1055(1.1113) | Xent 0.0430(0.0408) | Loss 1.1270(1.1318) | Error 0.0134(0.0126) Steps 422(417.77) | Grad Norm 0.1931(0.3205) | Total Time 10.00(10.00)\n",
      "Iter 2730 | Time 28.4892(29.1246) | Bit/dim 1.1113(1.1113) | Xent 0.0392(0.0408) | Loss 1.1309(1.1317) | Error 0.0124(0.0126) Steps 416(417.72) | Grad Norm 0.3188(0.3204) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 16.4943, Epoch Time 231.8100(236.4635), Bit/dim 1.1056(best: 1.1047), Xent 0.0268, Loss 1.1190, Error 0.0101(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2731 | Time 28.6219(29.1095) | Bit/dim 1.1116(1.1113) | Xent 0.0371(0.0407) | Loss 1.1301(1.1317) | Error 0.0114(0.0126) Steps 416(417.66) | Grad Norm 0.2342(0.3178) | Total Time 10.00(10.00)\n",
      "Iter 2732 | Time 28.8434(29.1015) | Bit/dim 1.1088(1.1113) | Xent 0.0435(0.0408) | Loss 1.1305(1.1316) | Error 0.0148(0.0127) Steps 416(417.61) | Grad Norm 0.3987(0.3203) | Total Time 10.00(10.00)\n",
      "Iter 2733 | Time 28.7937(29.0923) | Bit/dim 1.1151(1.1114) | Xent 0.0411(0.0408) | Loss 1.1357(1.1318) | Error 0.0140(0.0127) Steps 422(417.75) | Grad Norm 0.3049(0.3198) | Total Time 10.00(10.00)\n",
      "Iter 2734 | Time 30.1596(29.1243) | Bit/dim 1.1096(1.1113) | Xent 0.0380(0.0407) | Loss 1.1285(1.1317) | Error 0.0130(0.0127) Steps 416(417.69) | Grad Norm 0.1643(0.3151) | Total Time 10.00(10.00)\n",
      "Iter 2735 | Time 28.9900(29.1203) | Bit/dim 1.1138(1.1114) | Xent 0.0432(0.0408) | Loss 1.1354(1.1318) | Error 0.0132(0.0127) Steps 416(417.64) | Grad Norm 0.4101(0.3180) | Total Time 10.00(10.00)\n",
      "Iter 2736 | Time 28.8210(29.1113) | Bit/dim 1.1070(1.1113) | Xent 0.0422(0.0408) | Loss 1.1281(1.1317) | Error 0.0134(0.0127) Steps 416(417.59) | Grad Norm 0.2686(0.3165) | Total Time 10.00(10.00)\n",
      "Iter 2737 | Time 29.4535(29.1216) | Bit/dim 1.1096(1.1112) | Xent 0.0345(0.0406) | Loss 1.1268(1.1315) | Error 0.0105(0.0127) Steps 416(417.55) | Grad Norm 0.3333(0.3170) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 16.5478, Epoch Time 232.8247(236.3543), Bit/dim 1.1048(best: 1.1047), Xent 0.0278, Loss 1.1187, Error 0.0093(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2738 | Time 28.7672(29.1109) | Bit/dim 1.1091(1.1111) | Xent 0.0398(0.0406) | Loss 1.1290(1.1314) | Error 0.0130(0.0127) Steps 416(417.50) | Grad Norm 0.2027(0.3136) | Total Time 10.00(10.00)\n",
      "Iter 2739 | Time 29.4330(29.1206) | Bit/dim 1.1165(1.1113) | Xent 0.0412(0.0406) | Loss 1.1371(1.1316) | Error 0.0124(0.0127) Steps 422(417.63) | Grad Norm 0.4018(0.3162) | Total Time 10.00(10.00)\n",
      "Iter 2740 | Time 29.2890(29.1256) | Bit/dim 1.1099(1.1113) | Xent 0.0492(0.0409) | Loss 1.1345(1.1317) | Error 0.0151(0.0128) Steps 422(417.76) | Grad Norm 0.4480(0.3202) | Total Time 10.00(10.00)\n",
      "Iter 2741 | Time 28.3048(29.1010) | Bit/dim 1.1086(1.1112) | Xent 0.0405(0.0409) | Loss 1.1288(1.1316) | Error 0.0125(0.0127) Steps 416(417.71) | Grad Norm 0.2058(0.3167) | Total Time 10.00(10.00)\n",
      "Iter 2742 | Time 29.5180(29.1135) | Bit/dim 1.1111(1.1112) | Xent 0.0385(0.0408) | Loss 1.1304(1.1316) | Error 0.0116(0.0127) Steps 416(417.66) | Grad Norm 0.2585(0.3150) | Total Time 10.00(10.00)\n",
      "Iter 2743 | Time 28.6692(29.1002) | Bit/dim 1.1113(1.1112) | Xent 0.0352(0.0406) | Loss 1.1288(1.1315) | Error 0.0106(0.0127) Steps 416(417.61) | Grad Norm 0.4651(0.3195) | Total Time 10.00(10.00)\n",
      "Iter 2744 | Time 28.6200(29.0858) | Bit/dim 1.1104(1.1112) | Xent 0.0364(0.0405) | Loss 1.1286(1.1314) | Error 0.0112(0.0126) Steps 416(417.56) | Grad Norm 0.3207(0.3195) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 16.6975, Epoch Time 231.4878(236.2083), Bit/dim 1.1050(best: 1.1047), Xent 0.0293, Loss 1.1197, Error 0.0100(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2745 | Time 29.0453(29.0846) | Bit/dim 1.1097(1.1111) | Xent 0.0393(0.0405) | Loss 1.1293(1.1313) | Error 0.0126(0.0126) Steps 422(417.70) | Grad Norm 0.1822(0.3154) | Total Time 10.00(10.00)\n",
      "Iter 2746 | Time 28.6315(29.0710) | Bit/dim 1.1129(1.1112) | Xent 0.0412(0.0405) | Loss 1.1334(1.1314) | Error 0.0119(0.0126) Steps 422(417.82) | Grad Norm 0.2113(0.3123) | Total Time 10.00(10.00)\n",
      "Iter 2747 | Time 28.3657(29.0498) | Bit/dim 1.1094(1.1111) | Xent 0.0436(0.0406) | Loss 1.1312(1.1314) | Error 0.0141(0.0126) Steps 422(417.95) | Grad Norm 0.4176(0.3155) | Total Time 10.00(10.00)\n",
      "Iter 2748 | Time 28.7211(29.0400) | Bit/dim 1.1078(1.1110) | Xent 0.0371(0.0405) | Loss 1.1264(1.1313) | Error 0.0101(0.0126) Steps 416(417.89) | Grad Norm 0.2147(0.3124) | Total Time 10.00(10.00)\n",
      "Iter 2749 | Time 29.2511(29.0463) | Bit/dim 1.1106(1.1110) | Xent 0.0376(0.0404) | Loss 1.1294(1.1312) | Error 0.0115(0.0125) Steps 422(418.01) | Grad Norm 0.2291(0.3099) | Total Time 10.00(10.00)\n",
      "Iter 2750 | Time 28.7547(29.0375) | Bit/dim 1.1126(1.1110) | Xent 0.0401(0.0404) | Loss 1.1327(1.1312) | Error 0.0134(0.0126) Steps 416(417.95) | Grad Norm 0.1889(0.3063) | Total Time 10.00(10.00)\n",
      "Iter 2751 | Time 28.8481(29.0319) | Bit/dim 1.1081(1.1110) | Xent 0.0390(0.0403) | Loss 1.1276(1.1311) | Error 0.0106(0.0125) Steps 416(417.90) | Grad Norm 0.2400(0.3043) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 16.6295, Epoch Time 230.5583(236.0388), Bit/dim 1.1050(best: 1.1047), Xent 0.0298, Loss 1.1199, Error 0.0105(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2752 | Time 28.6058(29.0191) | Bit/dim 1.1119(1.1110) | Xent 0.0368(0.0402) | Loss 1.1303(1.1311) | Error 0.0114(0.0125) Steps 416(417.84) | Grad Norm 0.2482(0.3026) | Total Time 10.00(10.00)\n",
      "Iter 2753 | Time 28.2677(28.9965) | Bit/dim 1.1061(1.1108) | Xent 0.0465(0.0404) | Loss 1.1293(1.1311) | Error 0.0145(0.0125) Steps 416(417.78) | Grad Norm 0.3396(0.3037) | Total Time 10.00(10.00)\n",
      "Iter 2754 | Time 29.9835(29.0261) | Bit/dim 1.1122(1.1109) | Xent 0.0384(0.0404) | Loss 1.1314(1.1311) | Error 0.0109(0.0125) Steps 416(417.73) | Grad Norm 0.2250(0.3014) | Total Time 10.00(10.00)\n",
      "Iter 2755 | Time 30.1271(29.0592) | Bit/dim 1.1105(1.1109) | Xent 0.0359(0.0402) | Loss 1.1285(1.1310) | Error 0.0120(0.0125) Steps 416(417.68) | Grad Norm 0.1859(0.2979) | Total Time 10.00(10.00)\n",
      "Iter 2756 | Time 30.0251(29.0882) | Bit/dim 1.1142(1.1110) | Xent 0.0440(0.0403) | Loss 1.1362(1.1311) | Error 0.0132(0.0125) Steps 416(417.63) | Grad Norm 0.2168(0.2955) | Total Time 10.00(10.00)\n",
      "Iter 2757 | Time 29.3599(29.0963) | Bit/dim 1.1118(1.1110) | Xent 0.0409(0.0404) | Loss 1.1322(1.1312) | Error 0.0139(0.0125) Steps 416(417.58) | Grad Norm 0.2680(0.2947) | Total Time 10.00(10.00)\n",
      "Iter 2758 | Time 28.5489(29.0799) | Bit/dim 1.1053(1.1108) | Xent 0.0423(0.0404) | Loss 1.1265(1.1310) | Error 0.0128(0.0125) Steps 422(417.71) | Grad Norm 0.3666(0.2968) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 16.6532, Epoch Time 234.0742(235.9799), Bit/dim 1.1053(best: 1.1047), Xent 0.0314, Loss 1.1210, Error 0.0103(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2759 | Time 29.6004(29.0955) | Bit/dim 1.1099(1.1108) | Xent 0.0429(0.0405) | Loss 1.1314(1.1310) | Error 0.0130(0.0125) Steps 416(417.66) | Grad Norm 0.3736(0.2991) | Total Time 10.00(10.00)\n",
      "Iter 2760 | Time 29.4019(29.1047) | Bit/dim 1.1085(1.1107) | Xent 0.0369(0.0404) | Loss 1.1269(1.1309) | Error 0.0115(0.0125) Steps 416(417.61) | Grad Norm 0.2383(0.2973) | Total Time 10.00(10.00)\n",
      "Iter 2761 | Time 30.2970(29.1405) | Bit/dim 1.1108(1.1107) | Xent 0.0412(0.0404) | Loss 1.1314(1.1309) | Error 0.0136(0.0125) Steps 416(417.56) | Grad Norm 0.1944(0.2942) | Total Time 10.00(10.00)\n",
      "Iter 2762 | Time 28.6282(29.1251) | Bit/dim 1.1142(1.1108) | Xent 0.0422(0.0405) | Loss 1.1353(1.1311) | Error 0.0138(0.0126) Steps 422(417.70) | Grad Norm 0.2662(0.2934) | Total Time 10.00(10.00)\n",
      "Iter 2763 | Time 28.4041(29.1035) | Bit/dim 1.1082(1.1108) | Xent 0.0448(0.0406) | Loss 1.1306(1.1311) | Error 0.0135(0.0126) Steps 416(417.64) | Grad Norm 0.5399(0.3008) | Total Time 10.00(10.00)\n",
      "Iter 2764 | Time 30.3897(29.1421) | Bit/dim 1.1139(1.1109) | Xent 0.0362(0.0405) | Loss 1.1320(1.1311) | Error 0.0121(0.0126) Steps 422(417.78) | Grad Norm 0.3164(0.3012) | Total Time 10.00(10.00)\n",
      "Iter 2765 | Time 29.7048(29.1589) | Bit/dim 1.1111(1.1109) | Xent 0.0400(0.0404) | Loss 1.1311(1.1311) | Error 0.0115(0.0126) Steps 416(417.72) | Grad Norm 0.2574(0.2999) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 16.8501, Epoch Time 235.7680(235.9735), Bit/dim 1.1048(best: 1.1047), Xent 0.0297, Loss 1.1197, Error 0.0100(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2766 | Time 29.0262(29.1550) | Bit/dim 1.1113(1.1109) | Xent 0.0449(0.0406) | Loss 1.1337(1.1312) | Error 0.0142(0.0126) Steps 416(417.67) | Grad Norm 0.2635(0.2988) | Total Time 10.00(10.00)\n",
      "Iter 2767 | Time 30.3771(29.1916) | Bit/dim 1.1113(1.1109) | Xent 0.0324(0.0403) | Loss 1.1275(1.1311) | Error 0.0098(0.0125) Steps 416(417.62) | Grad Norm 0.4057(0.3020) | Total Time 10.00(10.00)\n",
      "Iter 2768 | Time 30.4729(29.2301) | Bit/dim 1.1087(1.1108) | Xent 0.0383(0.0403) | Loss 1.1279(1.1310) | Error 0.0135(0.0126) Steps 416(417.57) | Grad Norm 0.4379(0.3061) | Total Time 10.00(10.00)\n",
      "Iter 2769 | Time 28.5555(29.2098) | Bit/dim 1.1115(1.1108) | Xent 0.0423(0.0403) | Loss 1.1327(1.1310) | Error 0.0129(0.0126) Steps 416(417.52) | Grad Norm 0.1752(0.3022) | Total Time 10.00(10.00)\n",
      "Iter 2770 | Time 28.8206(29.1981) | Bit/dim 1.1056(1.1107) | Xent 0.0440(0.0404) | Loss 1.1276(1.1309) | Error 0.0135(0.0126) Steps 422(417.66) | Grad Norm 0.5814(0.3106) | Total Time 10.00(10.00)\n",
      "Iter 2771 | Time 28.6308(29.1811) | Bit/dim 1.1132(1.1108) | Xent 0.0384(0.0404) | Loss 1.1324(1.1309) | Error 0.0121(0.0126) Steps 416(417.61) | Grad Norm 0.3082(0.3105) | Total Time 10.00(10.00)\n",
      "Iter 2772 | Time 28.7773(29.1690) | Bit/dim 1.1105(1.1107) | Xent 0.0351(0.0402) | Loss 1.1280(1.1309) | Error 0.0116(0.0126) Steps 422(417.74) | Grad Norm 0.5024(0.3162) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 16.7286, Epoch Time 233.9636(235.9132), Bit/dim 1.1054(best: 1.1047), Xent 0.0286, Loss 1.1198, Error 0.0094(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2773 | Time 30.2492(29.2014) | Bit/dim 1.1149(1.1109) | Xent 0.0391(0.0402) | Loss 1.1345(1.1310) | Error 0.0124(0.0125) Steps 416(417.69) | Grad Norm 0.1928(0.3125) | Total Time 10.00(10.00)\n",
      "Iter 2774 | Time 28.8297(29.1903) | Bit/dim 1.1142(1.1110) | Xent 0.0347(0.0400) | Loss 1.1316(1.1310) | Error 0.0109(0.0125) Steps 416(417.64) | Grad Norm 0.3580(0.3139) | Total Time 10.00(10.00)\n",
      "Iter 2775 | Time 30.2438(29.2219) | Bit/dim 1.1144(1.1111) | Xent 0.0480(0.0403) | Loss 1.1384(1.1312) | Error 0.0142(0.0125) Steps 422(417.77) | Grad Norm 0.6584(0.3242) | Total Time 10.00(10.00)\n",
      "Iter 2776 | Time 29.7109(29.2365) | Bit/dim 1.1063(1.1109) | Xent 0.0381(0.0402) | Loss 1.1253(1.1310) | Error 0.0120(0.0125) Steps 416(417.72) | Grad Norm 0.4046(0.3267) | Total Time 10.00(10.00)\n",
      "Iter 2777 | Time 29.5865(29.2470) | Bit/dim 1.1099(1.1109) | Xent 0.0409(0.0402) | Loss 1.1303(1.1310) | Error 0.0122(0.0125) Steps 416(417.66) | Grad Norm 0.3542(0.3275) | Total Time 10.00(10.00)\n",
      "Iter 2778 | Time 29.5948(29.2575) | Bit/dim 1.1084(1.1108) | Xent 0.0419(0.0403) | Loss 1.1294(1.1310) | Error 0.0131(0.0125) Steps 416(417.61) | Grad Norm 0.3576(0.3284) | Total Time 10.00(10.00)\n",
      "Iter 2779 | Time 29.5152(29.2652) | Bit/dim 1.1063(1.1107) | Xent 0.0423(0.0403) | Loss 1.1275(1.1309) | Error 0.0122(0.0125) Steps 416(417.57) | Grad Norm 0.4698(0.3326) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 16.8062, Epoch Time 237.0250(235.9466), Bit/dim 1.1044(best: 1.1047), Xent 0.0270, Loss 1.1179, Error 0.0098(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2780 | Time 28.5360(29.2433) | Bit/dim 1.1068(1.1106) | Xent 0.0387(0.0403) | Loss 1.1262(1.1307) | Error 0.0129(0.0125) Steps 416(417.52) | Grad Norm 0.2481(0.3301) | Total Time 10.00(10.00)\n",
      "Iter 2781 | Time 28.4126(29.2184) | Bit/dim 1.1084(1.1105) | Xent 0.0289(0.0399) | Loss 1.1229(1.1305) | Error 0.0095(0.0125) Steps 422(417.65) | Grad Norm 0.2872(0.3288) | Total Time 10.00(10.00)\n",
      "Iter 2782 | Time 29.3092(29.2211) | Bit/dim 1.1175(1.1107) | Xent 0.0429(0.0400) | Loss 1.1390(1.1307) | Error 0.0131(0.0125) Steps 416(417.60) | Grad Norm 0.4281(0.3318) | Total Time 10.00(10.00)\n",
      "Iter 2783 | Time 28.7730(29.2077) | Bit/dim 1.1086(1.1107) | Xent 0.0462(0.0402) | Loss 1.1317(1.1308) | Error 0.0128(0.0125) Steps 416(417.56) | Grad Norm 0.5982(0.3398) | Total Time 10.00(10.00)\n",
      "Iter 2784 | Time 30.2920(29.2402) | Bit/dim 1.1135(1.1107) | Xent 0.0439(0.0403) | Loss 1.1354(1.1309) | Error 0.0146(0.0125) Steps 416(417.51) | Grad Norm 0.4341(0.3426) | Total Time 10.00(10.00)\n",
      "Iter 2785 | Time 29.5669(29.2500) | Bit/dim 1.1094(1.1107) | Xent 0.0340(0.0401) | Loss 1.1264(1.1308) | Error 0.0111(0.0125) Steps 416(417.46) | Grad Norm 0.2382(0.3395) | Total Time 10.00(10.00)\n",
      "Iter 2786 | Time 29.5693(29.2596) | Bit/dim 1.1110(1.1107) | Xent 0.0368(0.0400) | Loss 1.1294(1.1307) | Error 0.0110(0.0125) Steps 422(417.60) | Grad Norm 0.2807(0.3377) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 16.8657, Epoch Time 233.5980(235.8761), Bit/dim 1.1049(best: 1.1044), Xent 0.0304, Loss 1.1201, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2787 | Time 29.7767(29.2751) | Bit/dim 1.1124(1.1108) | Xent 0.0365(0.0399) | Loss 1.1307(1.1307) | Error 0.0124(0.0125) Steps 416(417.55) | Grad Norm 0.5577(0.3443) | Total Time 10.00(10.00)\n",
      "Iter 2788 | Time 29.4622(29.2807) | Bit/dim 1.1159(1.1109) | Xent 0.0438(0.0400) | Loss 1.1377(1.1309) | Error 0.0128(0.0125) Steps 416(417.51) | Grad Norm 0.2892(0.3427) | Total Time 10.00(10.00)\n",
      "Iter 2789 | Time 30.1087(29.3056) | Bit/dim 1.1121(1.1110) | Xent 0.0365(0.0399) | Loss 1.1304(1.1309) | Error 0.0108(0.0124) Steps 416(417.46) | Grad Norm 0.2511(0.3399) | Total Time 10.00(10.00)\n",
      "Iter 2790 | Time 29.1290(29.3003) | Bit/dim 1.1098(1.1109) | Xent 0.0519(0.0403) | Loss 1.1357(1.1311) | Error 0.0165(0.0125) Steps 416(417.42) | Grad Norm 0.3426(0.3400) | Total Time 10.00(10.00)\n",
      "Iter 2791 | Time 29.4043(29.3034) | Bit/dim 1.1080(1.1108) | Xent 0.0470(0.0405) | Loss 1.1315(1.1311) | Error 0.0149(0.0126) Steps 416(417.37) | Grad Norm 0.3882(0.3414) | Total Time 10.00(10.00)\n",
      "Iter 2792 | Time 28.7757(29.2876) | Bit/dim 1.1105(1.1108) | Xent 0.0363(0.0404) | Loss 1.1286(1.1310) | Error 0.0111(0.0126) Steps 422(417.51) | Grad Norm 0.1771(0.3365) | Total Time 10.00(10.00)\n",
      "Iter 2793 | Time 29.0049(29.2791) | Bit/dim 1.1069(1.1107) | Xent 0.0371(0.0403) | Loss 1.1255(1.1308) | Error 0.0109(0.0125) Steps 416(417.47) | Grad Norm 0.2433(0.3337) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 16.4557, Epoch Time 234.8900(235.8465), Bit/dim 1.1052(best: 1.1044), Xent 0.0295, Loss 1.1199, Error 0.0106(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2794 | Time 28.7583(29.2634) | Bit/dim 1.1052(1.1105) | Xent 0.0429(0.0404) | Loss 1.1267(1.1307) | Error 0.0141(0.0126) Steps 416(417.42) | Grad Norm 0.2325(0.3307) | Total Time 10.00(10.00)\n",
      "Iter 2795 | Time 28.6263(29.2443) | Bit/dim 1.1136(1.1106) | Xent 0.0368(0.0402) | Loss 1.1319(1.1308) | Error 0.0120(0.0125) Steps 422(417.56) | Grad Norm 0.4585(0.3345) | Total Time 10.00(10.00)\n",
      "Iter 2796 | Time 30.4663(29.2810) | Bit/dim 1.1066(1.1105) | Xent 0.0377(0.0402) | Loss 1.1255(1.1306) | Error 0.0126(0.0125) Steps 416(417.51) | Grad Norm 0.2942(0.3333) | Total Time 10.00(10.00)\n",
      "Iter 2797 | Time 29.2129(29.2789) | Bit/dim 1.1100(1.1105) | Xent 0.0404(0.0402) | Loss 1.1302(1.1306) | Error 0.0131(0.0126) Steps 416(417.47) | Grad Norm 0.2202(0.3299) | Total Time 10.00(10.00)\n",
      "Iter 2798 | Time 29.0631(29.2725) | Bit/dim 1.1130(1.1106) | Xent 0.0349(0.0400) | Loss 1.1305(1.1306) | Error 0.0115(0.0125) Steps 416(417.42) | Grad Norm 0.2618(0.3279) | Total Time 10.00(10.00)\n",
      "Iter 2799 | Time 28.6283(29.2531) | Bit/dim 1.1127(1.1106) | Xent 0.0443(0.0401) | Loss 1.1348(1.1307) | Error 0.0131(0.0125) Steps 422(417.56) | Grad Norm 0.6108(0.3364) | Total Time 10.00(10.00)\n",
      "Iter 2800 | Time 28.9866(29.2452) | Bit/dim 1.1127(1.1107) | Xent 0.0436(0.0402) | Loss 1.1345(1.1308) | Error 0.0124(0.0125) Steps 416(417.51) | Grad Norm 0.3611(0.3371) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 16.5935, Epoch Time 233.1155(235.7646), Bit/dim 1.1045(best: 1.1044), Xent 0.0277, Loss 1.1183, Error 0.0092(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2801 | Time 28.7985(29.2318) | Bit/dim 1.1085(1.1106) | Xent 0.0398(0.0402) | Loss 1.1284(1.1307) | Error 0.0118(0.0125) Steps 416(417.47) | Grad Norm 0.2225(0.3337) | Total Time 10.00(10.00)\n",
      "Iter 2802 | Time 28.7857(29.2184) | Bit/dim 1.1043(1.1104) | Xent 0.0432(0.0403) | Loss 1.1259(1.1306) | Error 0.0130(0.0125) Steps 416(417.43) | Grad Norm 0.2205(0.3303) | Total Time 10.00(10.00)\n",
      "Iter 2803 | Time 28.5801(29.1992) | Bit/dim 1.1074(1.1103) | Xent 0.0400(0.0403) | Loss 1.1274(1.1305) | Error 0.0119(0.0125) Steps 416(417.38) | Grad Norm 0.4724(0.3345) | Total Time 10.00(10.00)\n",
      "Iter 2804 | Time 30.3238(29.2330) | Bit/dim 1.1118(1.1104) | Xent 0.0404(0.0403) | Loss 1.1320(1.1306) | Error 0.0120(0.0125) Steps 428(417.70) | Grad Norm 0.2659(0.3325) | Total Time 10.00(10.00)\n",
      "Iter 2805 | Time 29.7384(29.2481) | Bit/dim 1.1146(1.1105) | Xent 0.0446(0.0404) | Loss 1.1369(1.1307) | Error 0.0146(0.0126) Steps 422(417.83) | Grad Norm 0.2461(0.3299) | Total Time 10.00(10.00)\n",
      "Iter 2806 | Time 28.3362(29.2208) | Bit/dim 1.1129(1.1106) | Xent 0.0404(0.0404) | Loss 1.1331(1.1308) | Error 0.0116(0.0125) Steps 416(417.77) | Grad Norm 0.2574(0.3277) | Total Time 10.00(10.00)\n",
      "Iter 2807 | Time 28.8490(29.2096) | Bit/dim 1.1158(1.1107) | Xent 0.0385(0.0404) | Loss 1.1351(1.1309) | Error 0.0121(0.0125) Steps 416(417.72) | Grad Norm 0.2710(0.3260) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 16.5426, Epoch Time 232.6284(235.6705), Bit/dim 1.1037(best: 1.1044), Xent 0.0266, Loss 1.1170, Error 0.0085(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2808 | Time 30.3383(29.2435) | Bit/dim 1.1081(1.1107) | Xent 0.0387(0.0403) | Loss 1.1274(1.1308) | Error 0.0128(0.0125) Steps 416(417.67) | Grad Norm 0.2368(0.3233) | Total Time 10.00(10.00)\n",
      "Iter 2809 | Time 29.0074(29.2364) | Bit/dim 1.1145(1.1108) | Xent 0.0439(0.0404) | Loss 1.1365(1.1310) | Error 0.0125(0.0125) Steps 416(417.62) | Grad Norm 0.2749(0.3219) | Total Time 10.00(10.00)\n",
      "Iter 2810 | Time 29.9564(29.2580) | Bit/dim 1.1086(1.1107) | Xent 0.0358(0.0403) | Loss 1.1265(1.1309) | Error 0.0121(0.0125) Steps 416(417.57) | Grad Norm 0.4044(0.3244) | Total Time 10.00(10.00)\n",
      "Iter 2811 | Time 28.8975(29.2472) | Bit/dim 1.1077(1.1106) | Xent 0.0388(0.0403) | Loss 1.1271(1.1308) | Error 0.0114(0.0125) Steps 416(417.52) | Grad Norm 0.3088(0.3239) | Total Time 10.00(10.00)\n",
      "Iter 2812 | Time 28.3638(29.2207) | Bit/dim 1.1086(1.1106) | Xent 0.0373(0.0402) | Loss 1.1272(1.1306) | Error 0.0112(0.0124) Steps 416(417.48) | Grad Norm 0.1835(0.3197) | Total Time 10.00(10.00)\n",
      "Iter 2813 | Time 28.1292(29.1879) | Bit/dim 1.1109(1.1106) | Xent 0.0375(0.0401) | Loss 1.1297(1.1306) | Error 0.0121(0.0124) Steps 416(417.43) | Grad Norm 0.3564(0.3208) | Total Time 10.00(10.00)\n",
      "Iter 2814 | Time 28.8648(29.1782) | Bit/dim 1.1134(1.1107) | Xent 0.0416(0.0401) | Loss 1.1341(1.1307) | Error 0.0125(0.0124) Steps 416(417.39) | Grad Norm 0.2110(0.3175) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 16.6934, Epoch Time 232.5389(235.5766), Bit/dim 1.1047(best: 1.1037), Xent 0.0294, Loss 1.1195, Error 0.0098(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2815 | Time 28.6748(29.1631) | Bit/dim 1.1119(1.1107) | Xent 0.0444(0.0403) | Loss 1.1341(1.1308) | Error 0.0141(0.0125) Steps 416(417.35) | Grad Norm 0.3617(0.3188) | Total Time 10.00(10.00)\n",
      "Iter 2816 | Time 29.1821(29.1637) | Bit/dim 1.1081(1.1106) | Xent 0.0305(0.0400) | Loss 1.1234(1.1306) | Error 0.0084(0.0124) Steps 416(417.31) | Grad Norm 0.2678(0.3173) | Total Time 10.00(10.00)\n",
      "Iter 2817 | Time 29.2383(29.1659) | Bit/dim 1.1071(1.1105) | Xent 0.0377(0.0399) | Loss 1.1259(1.1305) | Error 0.0112(0.0123) Steps 416(417.27) | Grad Norm 0.6258(0.3265) | Total Time 10.00(10.00)\n",
      "Iter 2818 | Time 29.0671(29.1630) | Bit/dim 1.1082(1.1104) | Xent 0.0431(0.0400) | Loss 1.1298(1.1304) | Error 0.0126(0.0123) Steps 416(417.23) | Grad Norm 0.2222(0.3234) | Total Time 10.00(10.00)\n",
      "Iter 2819 | Time 29.0861(29.1607) | Bit/dim 1.1153(1.1106) | Xent 0.0371(0.0399) | Loss 1.1338(1.1305) | Error 0.0116(0.0123) Steps 416(417.19) | Grad Norm 0.2741(0.3219) | Total Time 10.00(10.00)\n",
      "Iter 2820 | Time 28.8251(29.1506) | Bit/dim 1.1102(1.1106) | Xent 0.0424(0.0400) | Loss 1.1314(1.1306) | Error 0.0134(0.0123) Steps 416(417.16) | Grad Norm 0.2144(0.3187) | Total Time 10.00(10.00)\n",
      "Iter 2821 | Time 29.0198(29.1467) | Bit/dim 1.1108(1.1106) | Xent 0.0435(0.0401) | Loss 1.1325(1.1306) | Error 0.0134(0.0124) Steps 416(417.12) | Grad Norm 0.2166(0.3156) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 16.3153, Epoch Time 232.0227(235.4700), Bit/dim 1.1047(best: 1.1037), Xent 0.0280, Loss 1.1187, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2822 | Time 30.4994(29.1873) | Bit/dim 1.1163(1.1108) | Xent 0.0350(0.0399) | Loss 1.1337(1.1307) | Error 0.0109(0.0123) Steps 416(417.09) | Grad Norm 0.4687(0.3202) | Total Time 10.00(10.00)\n",
      "Iter 2823 | Time 29.8266(29.2064) | Bit/dim 1.1105(1.1107) | Xent 0.0430(0.0400) | Loss 1.1320(1.1308) | Error 0.0126(0.0123) Steps 416(417.06) | Grad Norm 0.4360(0.3237) | Total Time 10.00(10.00)\n",
      "Iter 2824 | Time 28.6409(29.1895) | Bit/dim 1.1091(1.1107) | Xent 0.0355(0.0399) | Loss 1.1269(1.1306) | Error 0.0118(0.0123) Steps 422(417.21) | Grad Norm 0.2185(0.3205) | Total Time 10.00(10.00)\n",
      "Iter 2825 | Time 29.7923(29.2076) | Bit/dim 1.1090(1.1106) | Xent 0.0480(0.0401) | Loss 1.1330(1.1307) | Error 0.0134(0.0124) Steps 422(417.35) | Grad Norm 0.2597(0.3187) | Total Time 10.00(10.00)\n",
      "Iter 2826 | Time 30.0429(29.2326) | Bit/dim 1.1115(1.1107) | Xent 0.0458(0.0403) | Loss 1.1344(1.1308) | Error 0.0135(0.0124) Steps 416(417.31) | Grad Norm 0.4143(0.3216) | Total Time 10.00(10.00)\n",
      "Iter 2827 | Time 30.0778(29.2580) | Bit/dim 1.1072(1.1106) | Xent 0.0407(0.0403) | Loss 1.1276(1.1307) | Error 0.0128(0.0124) Steps 422(417.45) | Grad Norm 0.3118(0.3213) | Total Time 10.00(10.00)\n",
      "Iter 2828 | Time 28.8221(29.2449) | Bit/dim 1.1070(1.1105) | Xent 0.0325(0.0401) | Loss 1.1233(1.1305) | Error 0.0114(0.0124) Steps 416(417.41) | Grad Norm 0.3624(0.3225) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 16.6826, Epoch Time 236.7020(235.5069), Bit/dim 1.1046(best: 1.1037), Xent 0.0282, Loss 1.1187, Error 0.0091(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2829 | Time 29.5313(29.2535) | Bit/dim 1.1116(1.1105) | Xent 0.0405(0.0401) | Loss 1.1318(1.1305) | Error 0.0132(0.0124) Steps 416(417.36) | Grad Norm 0.3278(0.3227) | Total Time 10.00(10.00)\n",
      "Iter 2830 | Time 30.8450(29.3012) | Bit/dim 1.1161(1.1107) | Xent 0.0424(0.0402) | Loss 1.1373(1.1307) | Error 0.0119(0.0124) Steps 416(417.32) | Grad Norm 0.2835(0.3215) | Total Time 10.00(10.00)\n",
      "Iter 2831 | Time 28.6441(29.2815) | Bit/dim 1.1086(1.1106) | Xent 0.0441(0.0403) | Loss 1.1306(1.1307) | Error 0.0126(0.0124) Steps 422(417.46) | Grad Norm 0.3825(0.3233) | Total Time 10.00(10.00)\n",
      "Iter 2832 | Time 29.2056(29.2792) | Bit/dim 1.1088(1.1105) | Xent 0.0413(0.0403) | Loss 1.1295(1.1307) | Error 0.0140(0.0124) Steps 416(417.42) | Grad Norm 0.2461(0.3210) | Total Time 10.00(10.00)\n",
      "Iter 2833 | Time 28.4085(29.2531) | Bit/dim 1.1109(1.1106) | Xent 0.0410(0.0403) | Loss 1.1314(1.1307) | Error 0.0132(0.0125) Steps 416(417.38) | Grad Norm 0.2363(0.3185) | Total Time 10.00(10.00)\n",
      "Iter 2834 | Time 28.9709(29.2447) | Bit/dim 1.1112(1.1106) | Xent 0.0409(0.0404) | Loss 1.1316(1.1308) | Error 0.0125(0.0125) Steps 422(417.52) | Grad Norm 0.1784(0.3143) | Total Time 10.00(10.00)\n",
      "Iter 2835 | Time 28.8107(29.2316) | Bit/dim 1.1055(1.1104) | Xent 0.0393(0.0403) | Loss 1.1252(1.1306) | Error 0.0131(0.0125) Steps 422(417.65) | Grad Norm 0.2007(0.3109) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 16.7044, Epoch Time 233.6935(235.4525), Bit/dim 1.1044(best: 1.1037), Xent 0.0283, Loss 1.1186, Error 0.0093(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2836 | Time 28.7899(29.2184) | Bit/dim 1.1118(1.1105) | Xent 0.0406(0.0403) | Loss 1.1321(1.1306) | Error 0.0110(0.0124) Steps 416(417.60) | Grad Norm 0.3197(0.3111) | Total Time 10.00(10.00)\n",
      "Iter 2837 | Time 28.4640(29.1958) | Bit/dim 1.1131(1.1105) | Xent 0.0375(0.0402) | Loss 1.1318(1.1307) | Error 0.0104(0.0124) Steps 422(417.73) | Grad Norm 0.3522(0.3124) | Total Time 10.00(10.00)\n",
      "Iter 2838 | Time 29.2692(29.1980) | Bit/dim 1.1054(1.1104) | Xent 0.0395(0.0402) | Loss 1.1252(1.1305) | Error 0.0106(0.0123) Steps 422(417.86) | Grad Norm 0.1778(0.3083) | Total Time 10.00(10.00)\n",
      "Iter 2839 | Time 28.6879(29.1827) | Bit/dim 1.1120(1.1104) | Xent 0.0383(0.0402) | Loss 1.1311(1.1305) | Error 0.0131(0.0123) Steps 422(417.98) | Grad Norm 0.3794(0.3105) | Total Time 10.00(10.00)\n",
      "Iter 2840 | Time 28.4584(29.1609) | Bit/dim 1.1104(1.1104) | Xent 0.0413(0.0402) | Loss 1.1310(1.1305) | Error 0.0135(0.0124) Steps 416(417.93) | Grad Norm 0.2465(0.3085) | Total Time 10.00(10.00)\n",
      "Iter 2841 | Time 28.2506(29.1336) | Bit/dim 1.1086(1.1104) | Xent 0.0455(0.0404) | Loss 1.1313(1.1306) | Error 0.0126(0.0124) Steps 422(418.05) | Grad Norm 0.2866(0.3079) | Total Time 10.00(10.00)\n",
      "Iter 2842 | Time 28.7694(29.1227) | Bit/dim 1.1114(1.1104) | Xent 0.0411(0.0404) | Loss 1.1319(1.1306) | Error 0.0128(0.0124) Steps 416(417.99) | Grad Norm 0.3280(0.3085) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 16.6725, Epoch Time 230.0567(235.2906), Bit/dim 1.1042(best: 1.1037), Xent 0.0270, Loss 1.1177, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2843 | Time 28.6411(29.1082) | Bit/dim 1.1137(1.1105) | Xent 0.0410(0.0404) | Loss 1.1342(1.1307) | Error 0.0121(0.0124) Steps 416(417.93) | Grad Norm 0.2593(0.3070) | Total Time 10.00(10.00)\n",
      "Iter 2844 | Time 28.5933(29.0928) | Bit/dim 1.1141(1.1106) | Xent 0.0325(0.0402) | Loss 1.1303(1.1307) | Error 0.0109(0.0123) Steps 416(417.87) | Grad Norm 0.1944(0.3036) | Total Time 10.00(10.00)\n",
      "Iter 2845 | Time 28.8819(29.0865) | Bit/dim 1.1077(1.1105) | Xent 0.0454(0.0403) | Loss 1.1303(1.1307) | Error 0.0160(0.0125) Steps 422(417.99) | Grad Norm 0.2543(0.3022) | Total Time 10.00(10.00)\n",
      "Iter 2846 | Time 28.6955(29.0747) | Bit/dim 1.1097(1.1105) | Xent 0.0372(0.0402) | Loss 1.1283(1.1306) | Error 0.0120(0.0124) Steps 416(417.93) | Grad Norm 0.2351(0.3001) | Total Time 10.00(10.00)\n",
      "Iter 2847 | Time 28.4613(29.0563) | Bit/dim 1.1053(1.1103) | Xent 0.0437(0.0403) | Loss 1.1271(1.1305) | Error 0.0140(0.0125) Steps 416(417.87) | Grad Norm 0.2018(0.2972) | Total Time 10.00(10.00)\n",
      "Iter 2848 | Time 28.6906(29.0454) | Bit/dim 1.1109(1.1104) | Xent 0.0349(0.0402) | Loss 1.1283(1.1304) | Error 0.0119(0.0125) Steps 416(417.82) | Grad Norm 0.4501(0.3018) | Total Time 10.00(10.00)\n",
      "Iter 2849 | Time 29.1255(29.0478) | Bit/dim 1.1083(1.1103) | Xent 0.0386(0.0401) | Loss 1.1276(1.1304) | Error 0.0116(0.0124) Steps 416(417.76) | Grad Norm 0.2704(0.3008) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 16.4593, Epoch Time 230.0026(235.1320), Bit/dim 1.1046(best: 1.1037), Xent 0.0280, Loss 1.1186, Error 0.0106(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2850 | Time 28.8583(29.0421) | Bit/dim 1.1111(1.1103) | Xent 0.0525(0.0405) | Loss 1.1374(1.1306) | Error 0.0164(0.0126) Steps 416(417.71) | Grad Norm 0.2560(0.2995) | Total Time 10.00(10.00)\n",
      "Iter 2851 | Time 28.6956(29.0317) | Bit/dim 1.1086(1.1103) | Xent 0.0413(0.0405) | Loss 1.1292(1.1305) | Error 0.0132(0.0126) Steps 416(417.66) | Grad Norm 0.2774(0.2988) | Total Time 10.00(10.00)\n",
      "Iter 2852 | Time 28.6761(29.0210) | Bit/dim 1.1117(1.1103) | Xent 0.0401(0.0405) | Loss 1.1318(1.1306) | Error 0.0116(0.0126) Steps 416(417.61) | Grad Norm 0.2284(0.2967) | Total Time 10.00(10.00)\n",
      "Iter 2853 | Time 28.9713(29.0195) | Bit/dim 1.1084(1.1103) | Xent 0.0395(0.0405) | Loss 1.1282(1.1305) | Error 0.0134(0.0126) Steps 416(417.56) | Grad Norm 0.2879(0.2964) | Total Time 10.00(10.00)\n",
      "Iter 2854 | Time 28.8198(29.0135) | Bit/dim 1.1109(1.1103) | Xent 0.0432(0.0406) | Loss 1.1325(1.1306) | Error 0.0149(0.0126) Steps 416(417.51) | Grad Norm 0.3765(0.2989) | Total Time 10.00(10.00)\n",
      "Iter 2855 | Time 28.7993(29.0071) | Bit/dim 1.1096(1.1103) | Xent 0.0380(0.0405) | Loss 1.1286(1.1305) | Error 0.0120(0.0126) Steps 416(417.47) | Grad Norm 0.2327(0.2969) | Total Time 10.00(10.00)\n",
      "Iter 2856 | Time 28.3391(28.9871) | Bit/dim 1.1087(1.1102) | Xent 0.0297(0.0402) | Loss 1.1236(1.1303) | Error 0.0092(0.0125) Steps 416(417.43) | Grad Norm 0.2365(0.2951) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 16.5462, Epoch Time 229.9789(234.9774), Bit/dim 1.1044(best: 1.1037), Xent 0.0281, Loss 1.1185, Error 0.0103(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2857 | Time 28.8196(28.9820) | Bit/dim 1.1059(1.1101) | Xent 0.0407(0.0402) | Loss 1.1262(1.1302) | Error 0.0115(0.0125) Steps 416(417.38) | Grad Norm 0.2771(0.2945) | Total Time 10.00(10.00)\n",
      "Iter 2858 | Time 28.8038(28.9767) | Bit/dim 1.1106(1.1101) | Xent 0.0359(0.0400) | Loss 1.1285(1.1301) | Error 0.0114(0.0125) Steps 422(417.52) | Grad Norm 0.1801(0.2911) | Total Time 10.00(10.00)\n",
      "Iter 2859 | Time 28.3709(28.9585) | Bit/dim 1.1127(1.1102) | Xent 0.0406(0.0401) | Loss 1.1329(1.1302) | Error 0.0130(0.0125) Steps 416(417.48) | Grad Norm 0.2417(0.2896) | Total Time 10.00(10.00)\n",
      "Iter 2860 | Time 28.6922(28.9505) | Bit/dim 1.1129(1.1103) | Xent 0.0392(0.0400) | Loss 1.1326(1.1303) | Error 0.0126(0.0125) Steps 416(417.43) | Grad Norm 0.2254(0.2877) | Total Time 10.00(10.00)\n",
      "Iter 2861 | Time 28.7914(28.9458) | Bit/dim 1.1104(1.1103) | Xent 0.0405(0.0401) | Loss 1.1306(1.1303) | Error 0.0124(0.0125) Steps 416(417.39) | Grad Norm 0.2489(0.2865) | Total Time 10.00(10.00)\n",
      "Iter 2862 | Time 29.3885(28.9590) | Bit/dim 1.1088(1.1102) | Xent 0.0400(0.0400) | Loss 1.1288(1.1302) | Error 0.0124(0.0125) Steps 416(417.35) | Grad Norm 0.2296(0.2848) | Total Time 10.00(10.00)\n",
      "Iter 2863 | Time 28.8776(28.9566) | Bit/dim 1.1078(1.1101) | Xent 0.0415(0.0401) | Loss 1.1286(1.1302) | Error 0.0138(0.0125) Steps 416(417.31) | Grad Norm 0.2188(0.2828) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 16.3908, Epoch Time 230.6438(234.8474), Bit/dim 1.1043(best: 1.1037), Xent 0.0258, Loss 1.1172, Error 0.0091(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2864 | Time 29.1672(28.9629) | Bit/dim 1.1139(1.1103) | Xent 0.0406(0.0401) | Loss 1.1342(1.1303) | Error 0.0128(0.0125) Steps 416(417.27) | Grad Norm 0.3272(0.2842) | Total Time 10.00(10.00)\n",
      "Iter 2865 | Time 28.7722(28.9572) | Bit/dim 1.1051(1.1101) | Xent 0.0391(0.0401) | Loss 1.1247(1.1301) | Error 0.0125(0.0125) Steps 422(417.41) | Grad Norm 0.2100(0.2819) | Total Time 10.00(10.00)\n",
      "Iter 2866 | Time 29.9109(28.9858) | Bit/dim 1.1125(1.1102) | Xent 0.0392(0.0401) | Loss 1.1321(1.1302) | Error 0.0118(0.0125) Steps 416(417.37) | Grad Norm 0.2061(0.2797) | Total Time 10.00(10.00)\n",
      "Iter 2867 | Time 28.7275(28.9781) | Bit/dim 1.1134(1.1103) | Xent 0.0495(0.0403) | Loss 1.1381(1.1304) | Error 0.0152(0.0126) Steps 416(417.33) | Grad Norm 0.2581(0.2790) | Total Time 10.00(10.00)\n",
      "Iter 2868 | Time 28.6003(28.9667) | Bit/dim 1.1111(1.1103) | Xent 0.0365(0.0402) | Loss 1.1293(1.1304) | Error 0.0119(0.0126) Steps 416(417.29) | Grad Norm 0.1801(0.2760) | Total Time 10.00(10.00)\n",
      "Iter 2869 | Time 29.1951(28.9736) | Bit/dim 1.1074(1.1102) | Xent 0.0405(0.0402) | Loss 1.1276(1.1303) | Error 0.0130(0.0126) Steps 422(417.43) | Grad Norm 0.2173(0.2743) | Total Time 10.00(10.00)\n",
      "Iter 2870 | Time 29.0766(28.9767) | Bit/dim 1.1065(1.1101) | Xent 0.0401(0.0402) | Loss 1.1266(1.1302) | Error 0.0130(0.0126) Steps 416(417.38) | Grad Norm 0.3285(0.2759) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 16.5652, Epoch Time 232.5845(234.7795), Bit/dim 1.1037(best: 1.1037), Xent 0.0283, Loss 1.1179, Error 0.0101(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2871 | Time 28.9819(28.9768) | Bit/dim 1.1119(1.1101) | Xent 0.0394(0.0402) | Loss 1.1316(1.1302) | Error 0.0134(0.0126) Steps 416(417.34) | Grad Norm 0.2458(0.2750) | Total Time 10.00(10.00)\n",
      "Iter 2872 | Time 29.0164(28.9780) | Bit/dim 1.1108(1.1102) | Xent 0.0418(0.0402) | Loss 1.1318(1.1303) | Error 0.0136(0.0126) Steps 416(417.30) | Grad Norm 0.3446(0.2771) | Total Time 10.00(10.00)\n",
      "Iter 2873 | Time 28.8238(28.9734) | Bit/dim 1.1088(1.1101) | Xent 0.0396(0.0402) | Loss 1.1286(1.1302) | Error 0.0109(0.0126) Steps 416(417.26) | Grad Norm 0.2156(0.2752) | Total Time 10.00(10.00)\n",
      "Iter 2874 | Time 28.9951(28.9740) | Bit/dim 1.1072(1.1100) | Xent 0.0346(0.0401) | Loss 1.1245(1.1301) | Error 0.0120(0.0126) Steps 416(417.23) | Grad Norm 0.2459(0.2744) | Total Time 10.00(10.00)\n",
      "Iter 2875 | Time 28.6089(28.9631) | Bit/dim 1.1130(1.1101) | Xent 0.0422(0.0401) | Loss 1.1341(1.1302) | Error 0.0126(0.0126) Steps 416(417.19) | Grad Norm 0.3203(0.2757) | Total Time 10.00(10.00)\n",
      "Iter 2876 | Time 28.9829(28.9637) | Bit/dim 1.1102(1.1101) | Xent 0.0480(0.0404) | Loss 1.1342(1.1303) | Error 0.0148(0.0126) Steps 416(417.15) | Grad Norm 0.3392(0.2776) | Total Time 10.00(10.00)\n",
      "Iter 2877 | Time 29.4219(28.9774) | Bit/dim 1.1104(1.1101) | Xent 0.0361(0.0402) | Loss 1.1284(1.1303) | Error 0.0108(0.0126) Steps 422(417.30) | Grad Norm 0.4306(0.2822) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 16.2886, Epoch Time 231.4855(234.6807), Bit/dim 1.1043(best: 1.1037), Xent 0.0286, Loss 1.1186, Error 0.0106(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2878 | Time 29.0744(28.9803) | Bit/dim 1.1088(1.1101) | Xent 0.0462(0.0404) | Loss 1.1319(1.1303) | Error 0.0140(0.0126) Steps 416(417.26) | Grad Norm 0.2380(0.2809) | Total Time 10.00(10.00)\n",
      "Iter 2879 | Time 28.4542(28.9645) | Bit/dim 1.1111(1.1101) | Xent 0.0424(0.0405) | Loss 1.1323(1.1304) | Error 0.0142(0.0127) Steps 422(417.40) | Grad Norm 0.2814(0.2809) | Total Time 10.00(10.00)\n",
      "Iter 2880 | Time 28.5669(28.9526) | Bit/dim 1.1123(1.1102) | Xent 0.0350(0.0403) | Loss 1.1298(1.1303) | Error 0.0116(0.0126) Steps 422(417.54) | Grad Norm 0.2864(0.2811) | Total Time 10.00(10.00)\n",
      "Iter 2881 | Time 28.7143(28.9455) | Bit/dim 1.1083(1.1101) | Xent 0.0373(0.0402) | Loss 1.1269(1.1302) | Error 0.0122(0.0126) Steps 416(417.49) | Grad Norm 0.4943(0.2875) | Total Time 10.00(10.00)\n",
      "Iter 2882 | Time 28.5288(28.9330) | Bit/dim 1.1100(1.1101) | Xent 0.0350(0.0401) | Loss 1.1275(1.1302) | Error 0.0102(0.0126) Steps 416(417.45) | Grad Norm 0.1882(0.2845) | Total Time 10.00(10.00)\n",
      "Iter 2883 | Time 29.1510(28.9395) | Bit/dim 1.1100(1.1101) | Xent 0.0359(0.0399) | Loss 1.1279(1.1301) | Error 0.0119(0.0125) Steps 416(417.41) | Grad Norm 0.2114(0.2823) | Total Time 10.00(10.00)\n",
      "Iter 2884 | Time 29.6847(28.9619) | Bit/dim 1.1121(1.1102) | Xent 0.0411(0.0400) | Loss 1.1326(1.1302) | Error 0.0129(0.0125) Steps 416(417.36) | Grad Norm 0.3946(0.2857) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 16.6043, Epoch Time 231.2356(234.5773), Bit/dim 1.1041(best: 1.1037), Xent 0.0285, Loss 1.1184, Error 0.0097(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2885 | Time 28.7030(28.9541) | Bit/dim 1.1065(1.1101) | Xent 0.0385(0.0399) | Loss 1.1257(1.1300) | Error 0.0109(0.0125) Steps 416(417.32) | Grad Norm 0.4678(0.2911) | Total Time 10.00(10.00)\n",
      "Iter 2886 | Time 28.5330(28.9415) | Bit/dim 1.1099(1.1101) | Xent 0.0401(0.0399) | Loss 1.1299(1.1300) | Error 0.0119(0.0125) Steps 416(417.28) | Grad Norm 0.2794(0.2908) | Total Time 10.00(10.00)\n",
      "Iter 2887 | Time 28.8890(28.9399) | Bit/dim 1.1136(1.1102) | Xent 0.0402(0.0399) | Loss 1.1337(1.1301) | Error 0.0136(0.0125) Steps 422(417.42) | Grad Norm 0.2224(0.2887) | Total Time 10.00(10.00)\n",
      "Iter 2888 | Time 28.9429(28.9400) | Bit/dim 1.1119(1.1102) | Xent 0.0431(0.0400) | Loss 1.1334(1.1302) | Error 0.0131(0.0125) Steps 416(417.38) | Grad Norm 0.4973(0.2950) | Total Time 10.00(10.00)\n",
      "Iter 2889 | Time 28.5634(28.9287) | Bit/dim 1.1074(1.1101) | Xent 0.0447(0.0402) | Loss 1.1298(1.1302) | Error 0.0129(0.0125) Steps 416(417.34) | Grad Norm 0.5155(0.3016) | Total Time 10.00(10.00)\n",
      "Iter 2890 | Time 28.8734(28.9270) | Bit/dim 1.1093(1.1101) | Xent 0.0403(0.0402) | Loss 1.1294(1.1302) | Error 0.0125(0.0125) Steps 416(417.30) | Grad Norm 0.3040(0.3017) | Total Time 10.00(10.00)\n",
      "Iter 2891 | Time 29.9344(28.9572) | Bit/dim 1.1095(1.1101) | Xent 0.0420(0.0402) | Loss 1.1305(1.1302) | Error 0.0131(0.0126) Steps 422(417.44) | Grad Norm 0.2223(0.2993) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 16.5048, Epoch Time 231.4183(234.4826), Bit/dim 1.1038(best: 1.1037), Xent 0.0255, Loss 1.1166, Error 0.0087(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2892 | Time 28.9387(28.9567) | Bit/dim 1.1107(1.1101) | Xent 0.0376(0.0402) | Loss 1.1295(1.1302) | Error 0.0121(0.0125) Steps 416(417.40) | Grad Norm 0.3900(0.3020) | Total Time 10.00(10.00)\n",
      "Iter 2893 | Time 28.5356(28.9441) | Bit/dim 1.1101(1.1101) | Xent 0.0429(0.0402) | Loss 1.1315(1.1302) | Error 0.0134(0.0126) Steps 422(417.54) | Grad Norm 0.6090(0.3112) | Total Time 10.00(10.00)\n",
      "Iter 2894 | Time 28.6559(28.9354) | Bit/dim 1.1128(1.1102) | Xent 0.0351(0.0401) | Loss 1.1304(1.1302) | Error 0.0116(0.0125) Steps 416(417.49) | Grad Norm 0.4454(0.3153) | Total Time 10.00(10.00)\n",
      "Iter 2895 | Time 29.4516(28.9509) | Bit/dim 1.1065(1.1101) | Xent 0.0362(0.0400) | Loss 1.1246(1.1301) | Error 0.0108(0.0125) Steps 416(417.44) | Grad Norm 0.2736(0.3140) | Total Time 10.00(10.00)\n",
      "Iter 2896 | Time 30.0884(28.9850) | Bit/dim 1.1080(1.1100) | Xent 0.0503(0.0403) | Loss 1.1332(1.1302) | Error 0.0152(0.0126) Steps 416(417.40) | Grad Norm 0.5460(0.3210) | Total Time 10.00(10.00)\n",
      "Iter 2897 | Time 29.8991(29.0124) | Bit/dim 1.1094(1.1100) | Xent 0.0327(0.0400) | Loss 1.1257(1.1300) | Error 0.0104(0.0125) Steps 416(417.36) | Grad Norm 0.2918(0.3201) | Total Time 10.00(10.00)\n",
      "Iter 2898 | Time 28.8665(29.0081) | Bit/dim 1.1091(1.1100) | Xent 0.0424(0.0401) | Loss 1.1303(1.1300) | Error 0.0128(0.0125) Steps 422(417.50) | Grad Norm 0.2274(0.3173) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 16.7515, Epoch Time 233.7896(234.4618), Bit/dim 1.1034(best: 1.1037), Xent 0.0286, Loss 1.1177, Error 0.0094(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2899 | Time 28.3751(28.9891) | Bit/dim 1.1093(1.1100) | Xent 0.0380(0.0401) | Loss 1.1283(1.1300) | Error 0.0119(0.0125) Steps 422(417.63) | Grad Norm 0.3607(0.3186) | Total Time 10.00(10.00)\n",
      "Iter 2900 | Time 29.4194(29.0020) | Bit/dim 1.1095(1.1099) | Xent 0.0350(0.0399) | Loss 1.1269(1.1299) | Error 0.0102(0.0124) Steps 422(417.76) | Grad Norm 0.2466(0.3165) | Total Time 10.00(10.00)\n",
      "Iter 2901 | Time 28.8473(28.9973) | Bit/dim 1.1133(1.1100) | Xent 0.0403(0.0399) | Loss 1.1334(1.1300) | Error 0.0116(0.0124) Steps 416(417.71) | Grad Norm 0.5513(0.3235) | Total Time 10.00(10.00)\n",
      "Iter 2902 | Time 29.0714(28.9996) | Bit/dim 1.1127(1.1101) | Xent 0.0340(0.0397) | Loss 1.1297(1.1300) | Error 0.0110(0.0124) Steps 422(417.84) | Grad Norm 0.2915(0.3225) | Total Time 10.00(10.00)\n",
      "Iter 2903 | Time 28.6691(28.9897) | Bit/dim 1.1087(1.1101) | Xent 0.0391(0.0397) | Loss 1.1282(1.1299) | Error 0.0135(0.0124) Steps 416(417.79) | Grad Norm 0.2325(0.3198) | Total Time 10.00(10.00)\n",
      "Iter 2904 | Time 29.5100(29.0053) | Bit/dim 1.1098(1.1101) | Xent 0.0332(0.0395) | Loss 1.1264(1.1298) | Error 0.0111(0.0124) Steps 422(417.91) | Grad Norm 0.1803(0.3157) | Total Time 10.00(10.00)\n",
      "Iter 2905 | Time 28.8999(29.0021) | Bit/dim 1.1063(1.1100) | Xent 0.0370(0.0394) | Loss 1.1248(1.1297) | Error 0.0116(0.0123) Steps 416(417.85) | Grad Norm 0.4288(0.3190) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 16.4153, Epoch Time 231.6679(234.3780), Bit/dim 1.1040(best: 1.1034), Xent 0.0277, Loss 1.1178, Error 0.0088(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2906 | Time 29.3753(29.0133) | Bit/dim 1.1092(1.1099) | Xent 0.0363(0.0394) | Loss 1.1274(1.1296) | Error 0.0111(0.0123) Steps 416(417.80) | Grad Norm 0.4310(0.3224) | Total Time 10.00(10.00)\n",
      "Iter 2907 | Time 28.4581(28.9966) | Bit/dim 1.1114(1.1100) | Xent 0.0414(0.0394) | Loss 1.1321(1.1297) | Error 0.0140(0.0123) Steps 416(417.74) | Grad Norm 0.3066(0.3219) | Total Time 10.00(10.00)\n",
      "Iter 2908 | Time 29.0727(28.9989) | Bit/dim 1.1119(1.1100) | Xent 0.0357(0.0393) | Loss 1.1298(1.1297) | Error 0.0118(0.0123) Steps 416(417.69) | Grad Norm 0.4013(0.3243) | Total Time 10.00(10.00)\n",
      "Iter 2909 | Time 30.4403(29.0422) | Bit/dim 1.1075(1.1100) | Xent 0.0398(0.0393) | Loss 1.1274(1.1296) | Error 0.0119(0.0123) Steps 416(417.64) | Grad Norm 0.5027(0.3297) | Total Time 10.00(10.00)\n",
      "Iter 2910 | Time 28.5464(29.0273) | Bit/dim 1.1128(1.1100) | Xent 0.0432(0.0394) | Loss 1.1344(1.1298) | Error 0.0132(0.0123) Steps 416(417.59) | Grad Norm 0.3986(0.3317) | Total Time 10.00(10.00)\n",
      "Iter 2911 | Time 29.3381(29.0366) | Bit/dim 1.1080(1.1100) | Xent 0.0413(0.0395) | Loss 1.1287(1.1297) | Error 0.0121(0.0123) Steps 416(417.54) | Grad Norm 0.1968(0.3277) | Total Time 10.00(10.00)\n",
      "Iter 2912 | Time 28.9081(29.0328) | Bit/dim 1.1112(1.1100) | Xent 0.0424(0.0396) | Loss 1.1324(1.1298) | Error 0.0138(0.0124) Steps 416(417.50) | Grad Norm 0.3868(0.3295) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 16.2361, Epoch Time 232.7936(234.3304), Bit/dim 1.1036(best: 1.1034), Xent 0.0286, Loss 1.1179, Error 0.0095(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2913 | Time 29.5320(29.0477) | Bit/dim 1.1120(1.1101) | Xent 0.0430(0.0397) | Loss 1.1335(1.1299) | Error 0.0145(0.0124) Steps 416(417.45) | Grad Norm 0.5219(0.3352) | Total Time 10.00(10.00)\n",
      "Iter 2914 | Time 28.6282(29.0352) | Bit/dim 1.1179(1.1103) | Xent 0.0378(0.0396) | Loss 1.1369(1.1301) | Error 0.0119(0.0124) Steps 416(417.41) | Grad Norm 0.1579(0.3299) | Total Time 10.00(10.00)\n",
      "Iter 2915 | Time 29.3114(29.0434) | Bit/dim 1.1069(1.1102) | Xent 0.0418(0.0397) | Loss 1.1279(1.1301) | Error 0.0136(0.0125) Steps 416(417.37) | Grad Norm 0.2438(0.3273) | Total Time 10.00(10.00)\n",
      "Iter 2916 | Time 28.4634(29.0260) | Bit/dim 1.1043(1.1100) | Xent 0.0380(0.0396) | Loss 1.1233(1.1299) | Error 0.0115(0.0124) Steps 416(417.33) | Grad Norm 0.2412(0.3247) | Total Time 10.00(10.00)\n",
      "Iter 2917 | Time 28.8752(29.0215) | Bit/dim 1.1068(1.1099) | Xent 0.0382(0.0396) | Loss 1.1259(1.1297) | Error 0.0112(0.0124) Steps 416(417.29) | Grad Norm 0.4949(0.3298) | Total Time 10.00(10.00)\n",
      "Iter 2918 | Time 28.6406(29.0101) | Bit/dim 1.1077(1.1099) | Xent 0.0385(0.0396) | Loss 1.1270(1.1297) | Error 0.0126(0.0124) Steps 416(417.25) | Grad Norm 0.3501(0.3305) | Total Time 10.00(10.00)\n",
      "Iter 2919 | Time 28.1549(28.9844) | Bit/dim 1.1080(1.1098) | Xent 0.0377(0.0395) | Loss 1.1269(1.1296) | Error 0.0125(0.0124) Steps 416(417.21) | Grad Norm 0.2599(0.3283) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 16.6953, Epoch Time 230.6842(234.2210), Bit/dim 1.1033(best: 1.1034), Xent 0.0284, Loss 1.1175, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2920 | Time 28.3537(28.9655) | Bit/dim 1.1075(1.1097) | Xent 0.0359(0.0394) | Loss 1.1254(1.1295) | Error 0.0111(0.0124) Steps 416(417.17) | Grad Norm 0.2307(0.3254) | Total Time 10.00(10.00)\n",
      "Iter 2921 | Time 30.0059(28.9967) | Bit/dim 1.1114(1.1098) | Xent 0.0414(0.0395) | Loss 1.1321(1.1295) | Error 0.0120(0.0124) Steps 416(417.14) | Grad Norm 0.2828(0.3241) | Total Time 10.00(10.00)\n",
      "Iter 2922 | Time 28.2900(28.9755) | Bit/dim 1.1072(1.1097) | Xent 0.0397(0.0395) | Loss 1.1270(1.1295) | Error 0.0120(0.0123) Steps 416(417.10) | Grad Norm 0.4635(0.3283) | Total Time 10.00(10.00)\n",
      "Iter 2923 | Time 28.7975(28.9702) | Bit/dim 1.1095(1.1097) | Xent 0.0430(0.0396) | Loss 1.1310(1.1295) | Error 0.0141(0.0124) Steps 416(417.07) | Grad Norm 0.4515(0.3320) | Total Time 10.00(10.00)\n",
      "Iter 2924 | Time 29.8244(28.9958) | Bit/dim 1.1107(1.1097) | Xent 0.0394(0.0396) | Loss 1.1304(1.1295) | Error 0.0126(0.0124) Steps 416(417.04) | Grad Norm 0.3111(0.3314) | Total Time 10.00(10.00)\n",
      "Iter 2925 | Time 29.1941(29.0018) | Bit/dim 1.1059(1.1096) | Xent 0.0341(0.0394) | Loss 1.1229(1.1293) | Error 0.0111(0.0124) Steps 416(417.01) | Grad Norm 0.2965(0.3303) | Total Time 10.00(10.00)\n",
      "Iter 2926 | Time 28.4182(28.9843) | Bit/dim 1.1125(1.1097) | Xent 0.0388(0.0394) | Loss 1.1320(1.1294) | Error 0.0128(0.0124) Steps 416(416.98) | Grad Norm 0.3505(0.3309) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 16.6307, Epoch Time 231.8432(234.1497), Bit/dim 1.1039(best: 1.1033), Xent 0.0277, Loss 1.1178, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2927 | Time 28.3519(28.9653) | Bit/dim 1.1052(1.1096) | Xent 0.0433(0.0395) | Loss 1.1269(1.1293) | Error 0.0140(0.0124) Steps 416(416.95) | Grad Norm 0.2345(0.3280) | Total Time 10.00(10.00)\n",
      "Iter 2928 | Time 28.4843(28.9509) | Bit/dim 1.1119(1.1096) | Xent 0.0385(0.0395) | Loss 1.1311(1.1294) | Error 0.0128(0.0124) Steps 416(416.92) | Grad Norm 0.1946(0.3240) | Total Time 10.00(10.00)\n",
      "Iter 2929 | Time 29.6432(28.9716) | Bit/dim 1.1077(1.1096) | Xent 0.0444(0.0396) | Loss 1.1299(1.1294) | Error 0.0140(0.0125) Steps 422(417.07) | Grad Norm 0.4032(0.3264) | Total Time 10.00(10.00)\n",
      "Iter 2930 | Time 28.8720(28.9686) | Bit/dim 1.1087(1.1096) | Xent 0.0388(0.0396) | Loss 1.1282(1.1294) | Error 0.0129(0.0125) Steps 416(417.04) | Grad Norm 0.2158(0.3231) | Total Time 10.00(10.00)\n",
      "Iter 2931 | Time 28.8162(28.9641) | Bit/dim 1.1136(1.1097) | Xent 0.0376(0.0395) | Loss 1.1324(1.1295) | Error 0.0118(0.0125) Steps 416(417.01) | Grad Norm 0.2199(0.3200) | Total Time 10.00(10.00)\n",
      "Iter 2932 | Time 29.7485(28.9876) | Bit/dim 1.1068(1.1096) | Xent 0.0375(0.0395) | Loss 1.1255(1.1293) | Error 0.0111(0.0124) Steps 416(416.98) | Grad Norm 0.3300(0.3203) | Total Time 10.00(10.00)\n",
      "Iter 2933 | Time 29.0403(28.9892) | Bit/dim 1.1091(1.1096) | Xent 0.0431(0.0396) | Loss 1.1306(1.1294) | Error 0.0139(0.0125) Steps 416(416.95) | Grad Norm 0.2069(0.3169) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 16.8491, Epoch Time 232.2294(234.0921), Bit/dim 1.1036(best: 1.1033), Xent 0.0287, Loss 1.1179, Error 0.0095(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2934 | Time 29.4823(29.0040) | Bit/dim 1.1117(1.1096) | Xent 0.0388(0.0396) | Loss 1.1312(1.1294) | Error 0.0131(0.0125) Steps 416(416.92) | Grad Norm 0.1816(0.3128) | Total Time 10.00(10.00)\n",
      "Iter 2935 | Time 28.6625(28.9937) | Bit/dim 1.1155(1.1098) | Xent 0.0341(0.0394) | Loss 1.1326(1.1295) | Error 0.0115(0.0125) Steps 416(416.89) | Grad Norm 0.1754(0.3087) | Total Time 10.00(10.00)\n",
      "Iter 2936 | Time 29.3204(29.0035) | Bit/dim 1.1037(1.1096) | Xent 0.0340(0.0392) | Loss 1.1207(1.1293) | Error 0.0102(0.0124) Steps 416(416.87) | Grad Norm 0.1701(0.3046) | Total Time 10.00(10.00)\n",
      "Iter 2937 | Time 30.2518(29.0410) | Bit/dim 1.1080(1.1096) | Xent 0.0343(0.0391) | Loss 1.1252(1.1291) | Error 0.0119(0.0124) Steps 416(416.84) | Grad Norm 0.2052(0.3016) | Total Time 10.00(10.00)\n",
      "Iter 2938 | Time 28.6197(29.0283) | Bit/dim 1.1107(1.1096) | Xent 0.0414(0.0392) | Loss 1.1314(1.1292) | Error 0.0135(0.0124) Steps 416(416.82) | Grad Norm 0.3148(0.3020) | Total Time 10.00(10.00)\n",
      "Iter 2939 | Time 28.2609(29.0053) | Bit/dim 1.1108(1.1097) | Xent 0.0503(0.0395) | Loss 1.1359(1.1294) | Error 0.0164(0.0125) Steps 416(416.79) | Grad Norm 0.3739(0.3041) | Total Time 10.00(10.00)\n",
      "Iter 2940 | Time 28.9307(29.0031) | Bit/dim 1.1088(1.1096) | Xent 0.0459(0.0397) | Loss 1.1318(1.1295) | Error 0.0148(0.0126) Steps 416(416.77) | Grad Norm 0.2957(0.3039) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 16.4889, Epoch Time 232.4842(234.0439), Bit/dim 1.1040(best: 1.1033), Xent 0.0284, Loss 1.1182, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2941 | Time 28.8348(28.9980) | Bit/dim 1.1098(1.1096) | Xent 0.0386(0.0397) | Loss 1.1291(1.1295) | Error 0.0112(0.0126) Steps 416(416.74) | Grad Norm 0.2311(0.3017) | Total Time 10.00(10.00)\n",
      "Iter 2942 | Time 28.7846(28.9916) | Bit/dim 1.1129(1.1097) | Xent 0.0430(0.0398) | Loss 1.1344(1.1296) | Error 0.0129(0.0126) Steps 416(416.72) | Grad Norm 0.3813(0.3041) | Total Time 10.00(10.00)\n",
      "Iter 2943 | Time 29.3174(29.0014) | Bit/dim 1.1048(1.1096) | Xent 0.0437(0.0399) | Loss 1.1266(1.1295) | Error 0.0134(0.0126) Steps 416(416.70) | Grad Norm 0.2690(0.3030) | Total Time 10.00(10.00)\n",
      "Iter 2944 | Time 29.1860(29.0069) | Bit/dim 1.1104(1.1096) | Xent 0.0378(0.0398) | Loss 1.1293(1.1295) | Error 0.0114(0.0126) Steps 416(416.68) | Grad Norm 0.3570(0.3047) | Total Time 10.00(10.00)\n",
      "Iter 2945 | Time 28.8515(29.0023) | Bit/dim 1.1098(1.1096) | Xent 0.0373(0.0397) | Loss 1.1284(1.1295) | Error 0.0124(0.0126) Steps 422(416.84) | Grad Norm 0.2603(0.3033) | Total Time 10.00(10.00)\n",
      "Iter 2946 | Time 28.8931(28.9990) | Bit/dim 1.1094(1.1096) | Xent 0.0401(0.0397) | Loss 1.1294(1.1295) | Error 0.0116(0.0125) Steps 416(416.81) | Grad Norm 0.3567(0.3049) | Total Time 10.00(10.00)\n",
      "Iter 2947 | Time 29.8063(29.0232) | Bit/dim 1.1122(1.1097) | Xent 0.0336(0.0396) | Loss 1.1290(1.1295) | Error 0.0095(0.0124) Steps 416(416.79) | Grad Norm 0.4796(0.3102) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 16.4447, Epoch Time 232.5078(233.9978), Bit/dim 1.1038(best: 1.1033), Xent 0.0278, Loss 1.1177, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2948 | Time 29.0668(29.0245) | Bit/dim 1.1081(1.1096) | Xent 0.0446(0.0397) | Loss 1.1304(1.1295) | Error 0.0126(0.0124) Steps 422(416.95) | Grad Norm 0.1862(0.3064) | Total Time 10.00(10.00)\n",
      "Iter 2949 | Time 29.8169(29.0483) | Bit/dim 1.1063(1.1095) | Xent 0.0394(0.0397) | Loss 1.1260(1.1294) | Error 0.0122(0.0124) Steps 416(416.92) | Grad Norm 0.2628(0.3051) | Total Time 10.00(10.00)\n",
      "Iter 2950 | Time 30.0920(29.0796) | Bit/dim 1.1131(1.1096) | Xent 0.0375(0.0396) | Loss 1.1319(1.1295) | Error 0.0120(0.0124) Steps 416(416.89) | Grad Norm 0.2437(0.3033) | Total Time 10.00(10.00)\n",
      "Iter 2951 | Time 29.2788(29.0856) | Bit/dim 1.1124(1.1097) | Xent 0.0361(0.0395) | Loss 1.1305(1.1295) | Error 0.0105(0.0124) Steps 416(416.86) | Grad Norm 0.1980(0.3001) | Total Time 10.00(10.00)\n",
      "Iter 2952 | Time 28.6510(29.0725) | Bit/dim 1.1068(1.1096) | Xent 0.0419(0.0396) | Loss 1.1278(1.1294) | Error 0.0130(0.0124) Steps 416(416.84) | Grad Norm 0.1968(0.2970) | Total Time 10.00(10.00)\n",
      "Iter 2953 | Time 28.6593(29.0602) | Bit/dim 1.1127(1.1097) | Xent 0.0445(0.0397) | Loss 1.1349(1.1296) | Error 0.0150(0.0125) Steps 416(416.81) | Grad Norm 0.4397(0.3013) | Total Time 10.00(10.00)\n",
      "Iter 2954 | Time 29.5093(29.0736) | Bit/dim 1.1088(1.1097) | Xent 0.0336(0.0396) | Loss 1.1256(1.1295) | Error 0.0104(0.0124) Steps 422(416.97) | Grad Norm 0.3926(0.3041) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 16.4635, Epoch Time 233.9622(233.9967), Bit/dim 1.1035(best: 1.1033), Xent 0.0300, Loss 1.1185, Error 0.0104(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2955 | Time 28.9973(29.0713) | Bit/dim 1.1080(1.1097) | Xent 0.0445(0.0397) | Loss 1.1302(1.1295) | Error 0.0128(0.0124) Steps 416(416.94) | Grad Norm 0.3384(0.3051) | Total Time 10.00(10.00)\n",
      "Iter 2956 | Time 30.1737(29.1044) | Bit/dim 1.1118(1.1097) | Xent 0.0393(0.0397) | Loss 1.1314(1.1296) | Error 0.0138(0.0125) Steps 416(416.91) | Grad Norm 0.2348(0.3030) | Total Time 10.00(10.00)\n",
      "Iter 2957 | Time 29.9404(29.1295) | Bit/dim 1.1114(1.1098) | Xent 0.0378(0.0396) | Loss 1.1303(1.1296) | Error 0.0122(0.0124) Steps 422(417.06) | Grad Norm 0.1915(0.2996) | Total Time 10.00(10.00)\n",
      "Iter 2958 | Time 28.9118(29.1230) | Bit/dim 1.1088(1.1097) | Xent 0.0382(0.0396) | Loss 1.1279(1.1295) | Error 0.0120(0.0124) Steps 416(417.03) | Grad Norm 0.4107(0.3030) | Total Time 10.00(10.00)\n",
      "Iter 2959 | Time 28.6077(29.1075) | Bit/dim 1.1059(1.1096) | Xent 0.0390(0.0396) | Loss 1.1254(1.1294) | Error 0.0112(0.0124) Steps 416(417.00) | Grad Norm 0.4807(0.3083) | Total Time 10.00(10.00)\n",
      "Iter 2960 | Time 29.1854(29.1098) | Bit/dim 1.1104(1.1096) | Xent 0.0457(0.0398) | Loss 1.1332(1.1295) | Error 0.0159(0.0125) Steps 416(416.97) | Grad Norm 0.2135(0.3055) | Total Time 10.00(10.00)\n",
      "Iter 2961 | Time 28.6334(29.0955) | Bit/dim 1.1100(1.1097) | Xent 0.0384(0.0397) | Loss 1.1292(1.1295) | Error 0.0132(0.0125) Steps 416(416.94) | Grad Norm 0.1968(0.3022) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 16.6629, Epoch Time 233.5426(233.9831), Bit/dim 1.1040(best: 1.1033), Xent 0.0292, Loss 1.1186, Error 0.0094(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2962 | Time 29.1205(29.0963) | Bit/dim 1.1128(1.1098) | Xent 0.0380(0.0397) | Loss 1.1319(1.1296) | Error 0.0116(0.0125) Steps 416(416.91) | Grad Norm 0.6226(0.3118) | Total Time 10.00(10.00)\n",
      "Iter 2963 | Time 28.0040(29.0635) | Bit/dim 1.1100(1.1098) | Xent 0.0396(0.0397) | Loss 1.1298(1.1296) | Error 0.0121(0.0125) Steps 416(416.89) | Grad Norm 0.6677(0.3225) | Total Time 10.00(10.00)\n",
      "Iter 2964 | Time 28.6375(29.0507) | Bit/dim 1.1055(1.1096) | Xent 0.0387(0.0396) | Loss 1.1249(1.1295) | Error 0.0130(0.0125) Steps 416(416.86) | Grad Norm 0.1939(0.3186) | Total Time 10.00(10.00)\n",
      "Iter 2965 | Time 29.4702(29.0633) | Bit/dim 1.1070(1.1096) | Xent 0.0390(0.0396) | Loss 1.1265(1.1294) | Error 0.0129(0.0125) Steps 416(416.83) | Grad Norm 0.2722(0.3172) | Total Time 10.00(10.00)\n",
      "Iter 2966 | Time 28.9935(29.0612) | Bit/dim 1.1098(1.1096) | Xent 0.0494(0.0399) | Loss 1.1345(1.1295) | Error 0.0155(0.0126) Steps 416(416.81) | Grad Norm 0.8655(0.3337) | Total Time 10.00(10.00)\n",
      "Iter 2967 | Time 28.2921(29.0382) | Bit/dim 1.1091(1.1095) | Xent 0.0393(0.0399) | Loss 1.1288(1.1295) | Error 0.0111(0.0126) Steps 416(416.78) | Grad Norm 0.5468(0.3401) | Total Time 10.00(10.00)\n",
      "Iter 2968 | Time 28.8392(29.0322) | Bit/dim 1.1086(1.1095) | Xent 0.0369(0.0398) | Loss 1.1271(1.1294) | Error 0.0115(0.0125) Steps 416(416.76) | Grad Norm 0.2950(0.3387) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 16.4690, Epoch Time 230.2080(233.8698), Bit/dim 1.1033(best: 1.1033), Xent 0.0276, Loss 1.1171, Error 0.0097(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2969 | Time 28.7103(29.0225) | Bit/dim 1.1077(1.1095) | Xent 0.0446(0.0399) | Loss 1.1300(1.1294) | Error 0.0152(0.0126) Steps 422(416.92) | Grad Norm 0.5350(0.3446) | Total Time 10.00(10.00)\n",
      "Iter 2970 | Time 29.8104(29.0462) | Bit/dim 1.1136(1.1096) | Xent 0.0421(0.0400) | Loss 1.1346(1.1296) | Error 0.0126(0.0126) Steps 416(416.89) | Grad Norm 0.6851(0.3548) | Total Time 10.00(10.00)\n",
      "Iter 2971 | Time 29.7783(29.0681) | Bit/dim 1.1059(1.1095) | Xent 0.0384(0.0400) | Loss 1.1251(1.1295) | Error 0.0116(0.0126) Steps 422(417.04) | Grad Norm 0.1766(0.3495) | Total Time 10.00(10.00)\n",
      "Iter 2972 | Time 28.0719(29.0382) | Bit/dim 1.1071(1.1094) | Xent 0.0397(0.0400) | Loss 1.1270(1.1294) | Error 0.0112(0.0125) Steps 422(417.19) | Grad Norm 0.3366(0.3491) | Total Time 10.00(10.00)\n",
      "Iter 2973 | Time 28.3575(29.0178) | Bit/dim 1.1071(1.1093) | Xent 0.0418(0.0400) | Loss 1.1280(1.1293) | Error 0.0118(0.0125) Steps 416(417.16) | Grad Norm 0.6181(0.3572) | Total Time 10.00(10.00)\n",
      "Iter 2974 | Time 28.3663(28.9983) | Bit/dim 1.1112(1.1094) | Xent 0.0423(0.0401) | Loss 1.1323(1.1294) | Error 0.0116(0.0125) Steps 416(417.12) | Grad Norm 0.2042(0.3526) | Total Time 10.00(10.00)\n",
      "Iter 2975 | Time 29.8955(29.0252) | Bit/dim 1.1086(1.1094) | Xent 0.0372(0.0400) | Loss 1.1272(1.1294) | Error 0.0101(0.0124) Steps 416(417.09) | Grad Norm 0.3240(0.3517) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 16.5624, Epoch Time 232.1200(233.8173), Bit/dim 1.1037(best: 1.1033), Xent 0.0295, Loss 1.1184, Error 0.0099(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2976 | Time 29.2652(29.0324) | Bit/dim 1.1046(1.1092) | Xent 0.0422(0.0401) | Loss 1.1257(1.1293) | Error 0.0139(0.0125) Steps 416(417.06) | Grad Norm 0.4752(0.3554) | Total Time 10.00(10.00)\n",
      "Iter 2977 | Time 28.6981(29.0224) | Bit/dim 1.1096(1.1092) | Xent 0.0399(0.0401) | Loss 1.1296(1.1293) | Error 0.0125(0.0125) Steps 416(417.02) | Grad Norm 0.2259(0.3515) | Total Time 10.00(10.00)\n",
      "Iter 2978 | Time 28.7267(29.0135) | Bit/dim 1.1098(1.1093) | Xent 0.0444(0.0402) | Loss 1.1320(1.1293) | Error 0.0136(0.0125) Steps 416(416.99) | Grad Norm 0.5646(0.3579) | Total Time 10.00(10.00)\n",
      "Iter 2979 | Time 28.7342(29.0051) | Bit/dim 1.1125(1.1094) | Xent 0.0416(0.0402) | Loss 1.1332(1.1295) | Error 0.0126(0.0125) Steps 416(416.96) | Grad Norm 0.3398(0.3574) | Total Time 10.00(10.00)\n",
      "Iter 2980 | Time 29.5629(29.0218) | Bit/dim 1.1097(1.1094) | Xent 0.0423(0.0403) | Loss 1.1308(1.1295) | Error 0.0129(0.0125) Steps 416(416.93) | Grad Norm 0.2499(0.3542) | Total Time 10.00(10.00)\n",
      "Iter 2981 | Time 29.9300(29.0491) | Bit/dim 1.1107(1.1094) | Xent 0.0409(0.0403) | Loss 1.1312(1.1296) | Error 0.0134(0.0125) Steps 416(416.91) | Grad Norm 0.3743(0.3548) | Total Time 10.00(10.00)\n",
      "Iter 2982 | Time 29.0060(29.0478) | Bit/dim 1.1105(1.1094) | Xent 0.0450(0.0404) | Loss 1.1330(1.1297) | Error 0.0142(0.0126) Steps 422(417.06) | Grad Norm 0.2486(0.3516) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 16.5491, Epoch Time 233.2261(233.7996), Bit/dim 1.1034(best: 1.1033), Xent 0.0265, Loss 1.1167, Error 0.0091(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2983 | Time 30.0487(29.0778) | Bit/dim 1.1093(1.1094) | Xent 0.0380(0.0404) | Loss 1.1283(1.1296) | Error 0.0115(0.0126) Steps 416(417.03) | Grad Norm 0.4474(0.3545) | Total Time 10.00(10.00)\n",
      "Iter 2984 | Time 30.2885(29.1141) | Bit/dim 1.1099(1.1094) | Xent 0.0346(0.0402) | Loss 1.1272(1.1295) | Error 0.0110(0.0125) Steps 422(417.18) | Grad Norm 0.2460(0.3512) | Total Time 10.00(10.00)\n",
      "Iter 2985 | Time 29.5220(29.1264) | Bit/dim 1.1098(1.1095) | Xent 0.0410(0.0402) | Loss 1.1303(1.1296) | Error 0.0122(0.0125) Steps 416(417.14) | Grad Norm 0.3272(0.3505) | Total Time 10.00(10.00)\n",
      "Iter 2986 | Time 29.2198(29.1292) | Bit/dim 1.1099(1.1095) | Xent 0.0444(0.0403) | Loss 1.1321(1.1296) | Error 0.0129(0.0125) Steps 416(417.11) | Grad Norm 0.3566(0.3507) | Total Time 10.00(10.00)\n",
      "Iter 2987 | Time 30.1288(29.1592) | Bit/dim 1.1113(1.1095) | Xent 0.0431(0.0404) | Loss 1.1328(1.1297) | Error 0.0138(0.0126) Steps 416(417.07) | Grad Norm 0.1921(0.3459) | Total Time 10.00(10.00)\n",
      "Iter 2988 | Time 29.4720(29.1686) | Bit/dim 1.1100(1.1095) | Xent 0.0398(0.0404) | Loss 1.1299(1.1297) | Error 0.0125(0.0125) Steps 416(417.04) | Grad Norm 0.2421(0.3428) | Total Time 10.00(10.00)\n",
      "Iter 2989 | Time 28.7260(29.1553) | Bit/dim 1.1042(1.1094) | Xent 0.0339(0.0402) | Loss 1.1211(1.1295) | Error 0.0112(0.0125) Steps 428(417.37) | Grad Norm 0.2019(0.3386) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 16.6745, Epoch Time 236.5539(233.8822), Bit/dim 1.1039(best: 1.1033), Xent 0.0288, Loss 1.1184, Error 0.0100(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2990 | Time 29.8981(29.1776) | Bit/dim 1.1073(1.1093) | Xent 0.0408(0.0402) | Loss 1.1277(1.1294) | Error 0.0126(0.0125) Steps 416(417.33) | Grad Norm 0.2122(0.3348) | Total Time 10.00(10.00)\n",
      "Iter 2991 | Time 29.4920(29.1870) | Bit/dim 1.1116(1.1094) | Xent 0.0359(0.0401) | Loss 1.1295(1.1294) | Error 0.0116(0.0125) Steps 416(417.29) | Grad Norm 0.2035(0.3308) | Total Time 10.00(10.00)\n",
      "Iter 2992 | Time 28.4146(29.1638) | Bit/dim 1.1093(1.1094) | Xent 0.0436(0.0402) | Loss 1.1311(1.1295) | Error 0.0122(0.0125) Steps 416(417.25) | Grad Norm 0.2302(0.3278) | Total Time 10.00(10.00)\n",
      "Iter 2993 | Time 28.5842(29.1464) | Bit/dim 1.1114(1.1094) | Xent 0.0416(0.0402) | Loss 1.1322(1.1296) | Error 0.0141(0.0125) Steps 416(417.21) | Grad Norm 0.3199(0.3276) | Total Time 10.00(10.00)\n",
      "Iter 2994 | Time 30.5145(29.1875) | Bit/dim 1.1096(1.1094) | Xent 0.0394(0.0402) | Loss 1.1293(1.1296) | Error 0.0130(0.0125) Steps 422(417.36) | Grad Norm 0.1737(0.3230) | Total Time 10.00(10.00)\n",
      "Iter 2995 | Time 28.9522(29.1804) | Bit/dim 1.1028(1.1092) | Xent 0.0347(0.0401) | Loss 1.1201(1.1293) | Error 0.0111(0.0125) Steps 416(417.32) | Grad Norm 0.2639(0.3212) | Total Time 10.00(10.00)\n",
      "Iter 2996 | Time 28.1882(29.1507) | Bit/dim 1.1140(1.1094) | Xent 0.0395(0.0400) | Loss 1.1337(1.1294) | Error 0.0120(0.0125) Steps 416(417.28) | Grad Norm 0.1813(0.3170) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 16.7608, Epoch Time 233.2843(233.8643), Bit/dim 1.1043(best: 1.1033), Xent 0.0310, Loss 1.1198, Error 0.0103(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2997 | Time 30.3785(29.1875) | Bit/dim 1.1051(1.1093) | Xent 0.0392(0.0400) | Loss 1.1247(1.1293) | Error 0.0121(0.0125) Steps 416(417.24) | Grad Norm 0.1789(0.3129) | Total Time 10.00(10.00)\n",
      "Iter 2998 | Time 29.8571(29.2076) | Bit/dim 1.1095(1.1093) | Xent 0.0348(0.0399) | Loss 1.1269(1.1292) | Error 0.0112(0.0124) Steps 416(417.20) | Grad Norm 0.3514(0.3140) | Total Time 10.00(10.00)\n",
      "Iter 2999 | Time 29.7200(29.2230) | Bit/dim 1.1080(1.1092) | Xent 0.0483(0.0401) | Loss 1.1321(1.1293) | Error 0.0140(0.0125) Steps 422(417.35) | Grad Norm 0.3212(0.3142) | Total Time 10.00(10.00)\n",
      "Iter 3000 | Time 28.5336(29.2023) | Bit/dim 1.1093(1.1092) | Xent 0.0402(0.0401) | Loss 1.1295(1.1293) | Error 0.0129(0.0125) Steps 416(417.30) | Grad Norm 0.2616(0.3126) | Total Time 10.00(10.00)\n",
      "Iter 3001 | Time 28.6661(29.1862) | Bit/dim 1.1099(1.1093) | Xent 0.0348(0.0400) | Loss 1.1273(1.1292) | Error 0.0131(0.0125) Steps 416(417.27) | Grad Norm 0.4030(0.3154) | Total Time 10.00(10.00)\n",
      "Iter 3002 | Time 28.9099(29.1779) | Bit/dim 1.1088(1.1092) | Xent 0.0418(0.0400) | Loss 1.1297(1.1292) | Error 0.0129(0.0125) Steps 416(417.23) | Grad Norm 0.1972(0.3118) | Total Time 10.00(10.00)\n",
      "Iter 3003 | Time 30.2069(29.2088) | Bit/dim 1.1130(1.1093) | Xent 0.0340(0.0398) | Loss 1.1300(1.1293) | Error 0.0091(0.0124) Steps 422(417.37) | Grad Norm 0.3202(0.3121) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 16.6998, Epoch Time 235.8615(233.9242), Bit/dim 1.1038(best: 1.1033), Xent 0.0273, Loss 1.1175, Error 0.0101(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3004 | Time 28.8309(29.1974) | Bit/dim 1.1094(1.1094) | Xent 0.0433(0.0399) | Loss 1.1311(1.1293) | Error 0.0151(0.0125) Steps 416(417.33) | Grad Norm 0.2336(0.3097) | Total Time 10.00(10.00)\n",
      "Iter 3005 | Time 29.5919(29.2093) | Bit/dim 1.1107(1.1094) | Xent 0.0443(0.0401) | Loss 1.1328(1.1294) | Error 0.0140(0.0125) Steps 416(417.29) | Grad Norm 0.2129(0.3068) | Total Time 10.00(10.00)\n",
      "Iter 3006 | Time 28.6088(29.1913) | Bit/dim 1.1130(1.1095) | Xent 0.0485(0.0403) | Loss 1.1372(1.1297) | Error 0.0148(0.0126) Steps 416(417.25) | Grad Norm 0.5026(0.3127) | Total Time 10.00(10.00)\n",
      "Iter 3007 | Time 29.3397(29.1957) | Bit/dim 1.1082(1.1095) | Xent 0.0384(0.0403) | Loss 1.1274(1.1296) | Error 0.0121(0.0126) Steps 416(417.21) | Grad Norm 0.2659(0.3113) | Total Time 10.00(10.00)\n",
      "Iter 3008 | Time 28.3886(29.1715) | Bit/dim 1.1106(1.1095) | Xent 0.0425(0.0403) | Loss 1.1318(1.1297) | Error 0.0135(0.0126) Steps 422(417.36) | Grad Norm 0.2218(0.3086) | Total Time 10.00(10.00)\n",
      "Iter 3009 | Time 29.5826(29.1838) | Bit/dim 1.1066(1.1094) | Xent 0.0313(0.0401) | Loss 1.1222(1.1294) | Error 0.0106(0.0126) Steps 416(417.32) | Grad Norm 0.4261(0.3121) | Total Time 10.00(10.00)\n",
      "Iter 3010 | Time 29.5329(29.1943) | Bit/dim 1.1109(1.1095) | Xent 0.0363(0.0399) | Loss 1.1291(1.1294) | Error 0.0121(0.0126) Steps 416(417.28) | Grad Norm 0.2873(0.3114) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 16.5669, Epoch Time 232.8399(233.8917), Bit/dim 1.1023(best: 1.1033), Xent 0.0280, Loss 1.1163, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3011 | Time 28.8949(29.1853) | Bit/dim 1.1101(1.1095) | Xent 0.0398(0.0399) | Loss 1.1300(1.1294) | Error 0.0125(0.0126) Steps 416(417.24) | Grad Norm 0.3036(0.3111) | Total Time 10.00(10.00)\n",
      "Iter 3012 | Time 28.6788(29.1701) | Bit/dim 1.1105(1.1095) | Xent 0.0390(0.0399) | Loss 1.1300(1.1295) | Error 0.0124(0.0125) Steps 416(417.20) | Grad Norm 0.3819(0.3133) | Total Time 10.00(10.00)\n",
      "Iter 3013 | Time 28.6417(29.1543) | Bit/dim 1.1053(1.1094) | Xent 0.0443(0.0400) | Loss 1.1274(1.1294) | Error 0.0135(0.0126) Steps 416(417.17) | Grad Norm 0.3950(0.3157) | Total Time 10.00(10.00)\n",
      "Iter 3014 | Time 28.7448(29.1420) | Bit/dim 1.1120(1.1095) | Xent 0.0394(0.0400) | Loss 1.1317(1.1295) | Error 0.0119(0.0126) Steps 416(417.13) | Grad Norm 0.3817(0.3177) | Total Time 10.00(10.00)\n",
      "Iter 3015 | Time 29.6641(29.1577) | Bit/dim 1.1071(1.1094) | Xent 0.0438(0.0401) | Loss 1.1290(1.1295) | Error 0.0144(0.0126) Steps 422(417.28) | Grad Norm 0.2229(0.3148) | Total Time 10.00(10.00)\n",
      "Iter 3016 | Time 28.9710(29.1521) | Bit/dim 1.1083(1.1094) | Xent 0.0417(0.0402) | Loss 1.1291(1.1294) | Error 0.0136(0.0126) Steps 416(417.24) | Grad Norm 0.2678(0.3134) | Total Time 10.00(10.00)\n",
      "Iter 3017 | Time 28.9777(29.1468) | Bit/dim 1.1133(1.1095) | Xent 0.0391(0.0402) | Loss 1.1329(1.1295) | Error 0.0109(0.0126) Steps 416(417.20) | Grad Norm 0.2344(0.3111) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 16.6432, Epoch Time 231.6020(233.8230), Bit/dim 1.1032(best: 1.1023), Xent 0.0293, Loss 1.1178, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3018 | Time 29.3504(29.1529) | Bit/dim 1.1113(1.1095) | Xent 0.0415(0.0402) | Loss 1.1320(1.1296) | Error 0.0144(0.0126) Steps 416(417.17) | Grad Norm 0.2856(0.3103) | Total Time 10.00(10.00)\n",
      "Iter 3019 | Time 28.5296(29.1342) | Bit/dim 1.1041(1.1094) | Xent 0.0440(0.0403) | Loss 1.1261(1.1295) | Error 0.0135(0.0127) Steps 422(417.31) | Grad Norm 0.3058(0.3102) | Total Time 10.00(10.00)\n",
      "Iter 3020 | Time 28.6466(29.1196) | Bit/dim 1.1105(1.1094) | Xent 0.0357(0.0402) | Loss 1.1283(1.1295) | Error 0.0112(0.0126) Steps 422(417.45) | Grad Norm 0.2970(0.3098) | Total Time 10.00(10.00)\n",
      "Iter 3021 | Time 28.5542(29.1026) | Bit/dim 1.1106(1.1094) | Xent 0.0349(0.0400) | Loss 1.1280(1.1294) | Error 0.0121(0.0126) Steps 416(417.41) | Grad Norm 0.4787(0.3148) | Total Time 10.00(10.00)\n",
      "Iter 3022 | Time 28.3646(29.0805) | Bit/dim 1.1103(1.1095) | Xent 0.0382(0.0400) | Loss 1.1295(1.1294) | Error 0.0114(0.0126) Steps 416(417.37) | Grad Norm 0.4601(0.3192) | Total Time 10.00(10.00)\n",
      "Iter 3023 | Time 29.1604(29.0829) | Bit/dim 1.1066(1.1094) | Xent 0.0401(0.0400) | Loss 1.1267(1.1294) | Error 0.0124(0.0126) Steps 422(417.50) | Grad Norm 0.2694(0.3177) | Total Time 10.00(10.00)\n",
      "Iter 3024 | Time 30.1967(29.1163) | Bit/dim 1.1109(1.1094) | Xent 0.0347(0.0398) | Loss 1.1282(1.1293) | Error 0.0109(0.0125) Steps 416(417.46) | Grad Norm 0.4870(0.3228) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 16.6913, Epoch Time 231.7804(233.7617), Bit/dim 1.1023(best: 1.1023), Xent 0.0257, Loss 1.1151, Error 0.0088(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3025 | Time 30.4866(29.1574) | Bit/dim 1.1117(1.1095) | Xent 0.0385(0.0398) | Loss 1.1310(1.1294) | Error 0.0122(0.0125) Steps 428(417.78) | Grad Norm 0.2927(0.3219) | Total Time 10.00(10.00)\n",
      "Iter 3026 | Time 28.7183(29.1442) | Bit/dim 1.1075(1.1094) | Xent 0.0407(0.0398) | Loss 1.1279(1.1293) | Error 0.0125(0.0125) Steps 422(417.90) | Grad Norm 0.2781(0.3206) | Total Time 10.00(10.00)\n",
      "Iter 3027 | Time 28.5968(29.1278) | Bit/dim 1.1101(1.1094) | Xent 0.0413(0.0398) | Loss 1.1307(1.1294) | Error 0.0125(0.0125) Steps 416(417.84) | Grad Norm 0.2035(0.3171) | Total Time 10.00(10.00)\n",
      "Iter 3028 | Time 31.4731(29.1982) | Bit/dim 1.1073(1.1094) | Xent 0.0406(0.0399) | Loss 1.1275(1.1293) | Error 0.0130(0.0125) Steps 428(418.15) | Grad Norm 0.2088(0.3138) | Total Time 10.00(10.00)\n",
      "Iter 3029 | Time 29.7804(29.2156) | Bit/dim 1.1054(1.1093) | Xent 0.0376(0.0398) | Loss 1.1242(1.1292) | Error 0.0118(0.0125) Steps 422(418.27) | Grad Norm 0.2067(0.3106) | Total Time 10.00(10.00)\n",
      "Iter 3030 | Time 30.0511(29.2407) | Bit/dim 1.1124(1.1094) | Xent 0.0392(0.0398) | Loss 1.1320(1.1292) | Error 0.0129(0.0125) Steps 422(418.38) | Grad Norm 0.2565(0.3090) | Total Time 10.00(10.00)\n",
      "Iter 3031 | Time 30.5363(29.2796) | Bit/dim 1.1110(1.1094) | Xent 0.0421(0.0398) | Loss 1.1321(1.1293) | Error 0.0134(0.0125) Steps 416(418.31) | Grad Norm 0.3551(0.3104) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 16.6162, Epoch Time 238.5507(233.9054), Bit/dim 1.1040(best: 1.1023), Xent 0.0263, Loss 1.1171, Error 0.0094(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3032 | Time 30.3447(29.3115) | Bit/dim 1.1065(1.1093) | Xent 0.0367(0.0398) | Loss 1.1249(1.1292) | Error 0.0110(0.0125) Steps 422(418.42) | Grad Norm 0.3806(0.3125) | Total Time 10.00(10.00)\n",
      "Iter 3033 | Time 30.9722(29.3614) | Bit/dim 1.1119(1.1094) | Xent 0.0326(0.0395) | Loss 1.1282(1.1292) | Error 0.0101(0.0124) Steps 416(418.34) | Grad Norm 0.1774(0.3084) | Total Time 10.00(10.00)\n",
      "Iter 3034 | Time 29.7830(29.3740) | Bit/dim 1.1117(1.1095) | Xent 0.0441(0.0397) | Loss 1.1337(1.1293) | Error 0.0148(0.0125) Steps 416(418.27) | Grad Norm 0.4575(0.3129) | Total Time 10.00(10.00)\n",
      "Iter 3035 | Time 30.3759(29.4041) | Bit/dim 1.1092(1.1095) | Xent 0.0432(0.0398) | Loss 1.1309(1.1294) | Error 0.0139(0.0125) Steps 416(418.21) | Grad Norm 0.2893(0.3122) | Total Time 10.00(10.00)\n",
      "Iter 3036 | Time 29.1836(29.3974) | Bit/dim 1.1061(1.1094) | Xent 0.0374(0.0397) | Loss 1.1248(1.1292) | Error 0.0126(0.0125) Steps 422(418.32) | Grad Norm 0.3023(0.3119) | Total Time 10.00(10.00)\n",
      "Iter 3037 | Time 29.4358(29.3986) | Bit/dim 1.1092(1.1094) | Xent 0.0450(0.0399) | Loss 1.1317(1.1293) | Error 0.0151(0.0126) Steps 416(418.25) | Grad Norm 0.4441(0.3158) | Total Time 10.00(10.00)\n",
      "Iter 3038 | Time 29.2354(29.3937) | Bit/dim 1.1108(1.1094) | Xent 0.0407(0.0399) | Loss 1.1311(1.1293) | Error 0.0138(0.0126) Steps 422(418.36) | Grad Norm 0.2972(0.3153) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 16.6735, Epoch Time 238.4954(234.0431), Bit/dim 1.1033(best: 1.1023), Xent 0.0267, Loss 1.1167, Error 0.0092(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3039 | Time 30.1486(29.4163) | Bit/dim 1.1091(1.1094) | Xent 0.0349(0.0397) | Loss 1.1266(1.1293) | Error 0.0115(0.0126) Steps 416(418.29) | Grad Norm 0.2379(0.3130) | Total Time 10.00(10.00)\n",
      "Iter 3040 | Time 28.5629(29.3907) | Bit/dim 1.1092(1.1094) | Xent 0.0297(0.0394) | Loss 1.1241(1.1291) | Error 0.0092(0.0125) Steps 416(418.22) | Grad Norm 0.1985(0.3095) | Total Time 10.00(10.00)\n",
      "Iter 3041 | Time 30.4474(29.4224) | Bit/dim 1.1082(1.1093) | Xent 0.0386(0.0394) | Loss 1.1275(1.1291) | Error 0.0134(0.0125) Steps 422(418.34) | Grad Norm 0.2259(0.3070) | Total Time 10.00(10.00)\n",
      "Iter 3042 | Time 29.0762(29.4121) | Bit/dim 1.1091(1.1093) | Xent 0.0422(0.0395) | Loss 1.1302(1.1291) | Error 0.0140(0.0126) Steps 416(418.27) | Grad Norm 0.2862(0.3064) | Total Time 10.00(10.00)\n",
      "Iter 3043 | Time 28.8635(29.3956) | Bit/dim 1.1043(1.1092) | Xent 0.0416(0.0396) | Loss 1.1250(1.1290) | Error 0.0135(0.0126) Steps 422(418.38) | Grad Norm 0.2041(0.3033) | Total Time 10.00(10.00)\n",
      "Iter 3044 | Time 29.6806(29.4041) | Bit/dim 1.1111(1.1092) | Xent 0.0448(0.0397) | Loss 1.1335(1.1291) | Error 0.0139(0.0126) Steps 416(418.31) | Grad Norm 0.3170(0.3037) | Total Time 10.00(10.00)\n",
      "Iter 3045 | Time 28.2525(29.3696) | Bit/dim 1.1096(1.1093) | Xent 0.0383(0.0397) | Loss 1.1287(1.1291) | Error 0.0111(0.0126) Steps 416(418.24) | Grad Norm 0.2635(0.3025) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 16.4443, Epoch Time 233.9313(234.0397), Bit/dim 1.1035(best: 1.1023), Xent 0.0278, Loss 1.1174, Error 0.0087(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3046 | Time 28.6009(29.3465) | Bit/dim 1.1137(1.1094) | Xent 0.0443(0.0398) | Loss 1.1359(1.1293) | Error 0.0141(0.0126) Steps 416(418.17) | Grad Norm 0.2015(0.2995) | Total Time 10.00(10.00)\n",
      "Iter 3047 | Time 29.9525(29.3647) | Bit/dim 1.1044(1.1092) | Xent 0.0394(0.0398) | Loss 1.1240(1.1291) | Error 0.0114(0.0126) Steps 422(418.29) | Grad Norm 0.2248(0.2973) | Total Time 10.00(10.00)\n",
      "Iter 3048 | Time 30.0501(29.3853) | Bit/dim 1.1062(1.1091) | Xent 0.0404(0.0398) | Loss 1.1264(1.1291) | Error 0.0118(0.0126) Steps 416(418.22) | Grad Norm 0.4479(0.3018) | Total Time 10.00(10.00)\n",
      "Iter 3049 | Time 28.9109(29.3710) | Bit/dim 1.1120(1.1092) | Xent 0.0382(0.0398) | Loss 1.1311(1.1291) | Error 0.0118(0.0126) Steps 416(418.15) | Grad Norm 0.3964(0.3046) | Total Time 10.00(10.00)\n",
      "Iter 3050 | Time 29.7722(29.3831) | Bit/dim 1.1138(1.1094) | Xent 0.0430(0.0399) | Loss 1.1353(1.1293) | Error 0.0122(0.0125) Steps 416(418.09) | Grad Norm 0.1907(0.3012) | Total Time 10.00(10.00)\n",
      "Iter 3051 | Time 28.8854(29.3681) | Bit/dim 1.1052(1.1092) | Xent 0.0380(0.0398) | Loss 1.1242(1.1291) | Error 0.0128(0.0126) Steps 416(418.02) | Grad Norm 0.4577(0.3059) | Total Time 10.00(10.00)\n",
      "Iter 3052 | Time 30.0465(29.3885) | Bit/dim 1.1096(1.1093) | Xent 0.0370(0.0397) | Loss 1.1281(1.1291) | Error 0.0116(0.0125) Steps 422(418.14) | Grad Norm 0.3934(0.3085) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 16.8849, Epoch Time 235.5083(234.0838), Bit/dim 1.1028(best: 1.1023), Xent 0.0301, Loss 1.1178, Error 0.0103(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3053 | Time 29.2390(29.3840) | Bit/dim 1.1098(1.1093) | Xent 0.0378(0.0397) | Loss 1.1287(1.1291) | Error 0.0121(0.0125) Steps 422(418.26) | Grad Norm 0.2572(0.3070) | Total Time 10.00(10.00)\n",
      "Iter 3054 | Time 28.5581(29.3592) | Bit/dim 1.1087(1.1093) | Xent 0.0414(0.0397) | Loss 1.1294(1.1291) | Error 0.0121(0.0125) Steps 416(418.19) | Grad Norm 0.5272(0.3136) | Total Time 10.00(10.00)\n",
      "Iter 3055 | Time 28.4304(29.3314) | Bit/dim 1.1087(1.1092) | Xent 0.0377(0.0397) | Loss 1.1276(1.1291) | Error 0.0124(0.0125) Steps 416(418.12) | Grad Norm 0.1936(0.3100) | Total Time 10.00(10.00)\n",
      "Iter 3056 | Time 29.9758(29.3507) | Bit/dim 1.1062(1.1091) | Xent 0.0371(0.0396) | Loss 1.1248(1.1289) | Error 0.0116(0.0125) Steps 416(418.06) | Grad Norm 0.2085(0.3069) | Total Time 10.00(10.00)\n",
      "Iter 3057 | Time 29.7430(29.3625) | Bit/dim 1.1144(1.1093) | Xent 0.0360(0.0395) | Loss 1.1324(1.1290) | Error 0.0108(0.0124) Steps 422(418.18) | Grad Norm 0.2934(0.3065) | Total Time 10.00(10.00)\n",
      "Iter 3058 | Time 30.4132(29.3940) | Bit/dim 1.1042(1.1092) | Xent 0.0429(0.0396) | Loss 1.1257(1.1289) | Error 0.0128(0.0124) Steps 416(418.11) | Grad Norm 0.2796(0.3057) | Total Time 10.00(10.00)\n",
      "Iter 3059 | Time 29.0616(29.3840) | Bit/dim 1.1099(1.1092) | Xent 0.0473(0.0398) | Loss 1.1336(1.1291) | Error 0.0131(0.0125) Steps 416(418.05) | Grad Norm 0.3164(0.3060) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 16.6581, Epoch Time 234.4341(234.0943), Bit/dim 1.1027(best: 1.1023), Xent 0.0281, Loss 1.1168, Error 0.0093(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3060 | Time 29.5403(29.3887) | Bit/dim 1.1085(1.1092) | Xent 0.0425(0.0399) | Loss 1.1297(1.1291) | Error 0.0132(0.0125) Steps 422(418.17) | Grad Norm 0.3980(0.3088) | Total Time 10.00(10.00)\n",
      "Iter 3061 | Time 29.4703(29.3912) | Bit/dim 1.1072(1.1091) | Xent 0.0382(0.0398) | Loss 1.1263(1.1290) | Error 0.0132(0.0125) Steps 422(418.28) | Grad Norm 0.3789(0.3109) | Total Time 10.00(10.00)\n",
      "Iter 3062 | Time 28.4591(29.3632) | Bit/dim 1.1105(1.1091) | Xent 0.0400(0.0398) | Loss 1.1305(1.1291) | Error 0.0134(0.0125) Steps 416(418.22) | Grad Norm 0.4289(0.3144) | Total Time 10.00(10.00)\n",
      "Iter 3063 | Time 28.7877(29.3459) | Bit/dim 1.1103(1.1092) | Xent 0.0417(0.0399) | Loss 1.1311(1.1291) | Error 0.0134(0.0126) Steps 422(418.33) | Grad Norm 0.4545(0.3187) | Total Time 10.00(10.00)\n",
      "Iter 3064 | Time 31.0531(29.3971) | Bit/dim 1.1093(1.1092) | Xent 0.0383(0.0399) | Loss 1.1285(1.1291) | Error 0.0101(0.0125) Steps 422(418.44) | Grad Norm 0.3284(0.3189) | Total Time 10.00(10.00)\n",
      "Iter 3065 | Time 29.4401(29.3984) | Bit/dim 1.1094(1.1092) | Xent 0.0364(0.0398) | Loss 1.1276(1.1291) | Error 0.0115(0.0124) Steps 416(418.37) | Grad Norm 0.2456(0.3167) | Total Time 10.00(10.00)\n",
      "Iter 3066 | Time 29.0819(29.3889) | Bit/dim 1.1066(1.1091) | Xent 0.0377(0.0397) | Loss 1.1255(1.1290) | Error 0.0124(0.0124) Steps 416(418.29) | Grad Norm 0.2355(0.3143) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 16.5676, Epoch Time 234.7904(234.1152), Bit/dim 1.1030(best: 1.1023), Xent 0.0291, Loss 1.1176, Error 0.0100(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3067 | Time 28.1004(29.3503) | Bit/dim 1.1069(1.1090) | Xent 0.0375(0.0396) | Loss 1.1256(1.1289) | Error 0.0115(0.0124) Steps 416(418.23) | Grad Norm 0.2535(0.3125) | Total Time 10.00(10.00)\n",
      "Iter 3068 | Time 29.1580(29.3445) | Bit/dim 1.1081(1.1090) | Xent 0.0373(0.0396) | Loss 1.1267(1.1288) | Error 0.0114(0.0124) Steps 416(418.16) | Grad Norm 0.3696(0.3142) | Total Time 10.00(10.00)\n",
      "Iter 3069 | Time 30.2405(29.3714) | Bit/dim 1.1134(1.1091) | Xent 0.0413(0.0396) | Loss 1.1341(1.1289) | Error 0.0129(0.0124) Steps 422(418.27) | Grad Norm 0.4246(0.3175) | Total Time 10.00(10.00)\n",
      "Iter 3070 | Time 28.9089(29.3575) | Bit/dim 1.1122(1.1092) | Xent 0.0389(0.0396) | Loss 1.1316(1.1290) | Error 0.0132(0.0124) Steps 416(418.21) | Grad Norm 0.2339(0.3150) | Total Time 10.00(10.00)\n",
      "Iter 3071 | Time 29.5177(29.3623) | Bit/dim 1.1030(1.1090) | Xent 0.0439(0.0397) | Loss 1.1249(1.1289) | Error 0.0149(0.0125) Steps 416(418.14) | Grad Norm 0.3402(0.3158) | Total Time 10.00(10.00)\n",
      "Iter 3072 | Time 29.4497(29.3649) | Bit/dim 1.1114(1.1091) | Xent 0.0406(0.0397) | Loss 1.1317(1.1290) | Error 0.0132(0.0125) Steps 422(418.26) | Grad Norm 0.3075(0.3155) | Total Time 10.00(10.00)\n",
      "Iter 3073 | Time 30.8031(29.4081) | Bit/dim 1.1053(1.1090) | Xent 0.0383(0.0397) | Loss 1.1244(1.1289) | Error 0.0125(0.0125) Steps 422(418.37) | Grad Norm 0.3710(0.3172) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 16.7441, Epoch Time 235.3230(234.1514), Bit/dim 1.1026(best: 1.1023), Xent 0.0255, Loss 1.1153, Error 0.0090(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3074 | Time 29.8413(29.4211) | Bit/dim 1.1054(1.1089) | Xent 0.0419(0.0398) | Loss 1.1263(1.1288) | Error 0.0136(0.0126) Steps 416(418.30) | Grad Norm 0.3761(0.3189) | Total Time 10.00(10.00)\n",
      "Iter 3075 | Time 30.5202(29.4541) | Bit/dim 1.1099(1.1089) | Xent 0.0337(0.0396) | Loss 1.1267(1.1287) | Error 0.0122(0.0125) Steps 416(418.23) | Grad Norm 0.2167(0.3159) | Total Time 10.00(10.00)\n",
      "Iter 3076 | Time 29.4142(29.4529) | Bit/dim 1.1052(1.1088) | Xent 0.0332(0.0394) | Loss 1.1218(1.1285) | Error 0.0104(0.0125) Steps 416(418.16) | Grad Norm 0.2077(0.3126) | Total Time 10.00(10.00)\n",
      "Iter 3077 | Time 29.7432(29.4616) | Bit/dim 1.1093(1.1088) | Xent 0.0369(0.0393) | Loss 1.1277(1.1285) | Error 0.0118(0.0125) Steps 422(418.28) | Grad Norm 0.3123(0.3126) | Total Time 10.00(10.00)\n",
      "Iter 3078 | Time 30.7242(29.4995) | Bit/dim 1.1122(1.1089) | Xent 0.0487(0.0396) | Loss 1.1365(1.1287) | Error 0.0160(0.0126) Steps 422(418.39) | Grad Norm 0.2950(0.3121) | Total Time 10.00(10.00)\n",
      "Iter 3079 | Time 30.3986(29.5264) | Bit/dim 1.1104(1.1090) | Xent 0.0398(0.0396) | Loss 1.1303(1.1288) | Error 0.0126(0.0126) Steps 422(418.50) | Grad Norm 0.3826(0.3142) | Total Time 10.00(10.00)\n",
      "Iter 3080 | Time 29.7316(29.5326) | Bit/dim 1.1065(1.1089) | Xent 0.0389(0.0396) | Loss 1.1260(1.1287) | Error 0.0111(0.0125) Steps 422(418.60) | Grad Norm 0.5755(0.3220) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 16.5652, Epoch Time 239.6074(234.3151), Bit/dim 1.1024(best: 1.1023), Xent 0.0293, Loss 1.1171, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3081 | Time 30.7504(29.5691) | Bit/dim 1.1068(1.1088) | Xent 0.0365(0.0395) | Loss 1.1251(1.1286) | Error 0.0114(0.0125) Steps 428(418.88) | Grad Norm 0.1989(0.3183) | Total Time 10.00(10.00)\n",
      "Iter 3082 | Time 28.6885(29.5427) | Bit/dim 1.1120(1.1089) | Xent 0.0349(0.0394) | Loss 1.1295(1.1286) | Error 0.0100(0.0124) Steps 416(418.80) | Grad Norm 0.5949(0.3266) | Total Time 10.00(10.00)\n",
      "Iter 3083 | Time 29.0379(29.5276) | Bit/dim 1.1127(1.1090) | Xent 0.0386(0.0393) | Loss 1.1320(1.1287) | Error 0.0105(0.0124) Steps 416(418.71) | Grad Norm 0.5879(0.3345) | Total Time 10.00(10.00)\n",
      "Iter 3084 | Time 28.2380(29.4889) | Bit/dim 1.1067(1.1090) | Xent 0.0367(0.0392) | Loss 1.1250(1.1286) | Error 0.0130(0.0124) Steps 416(418.63) | Grad Norm 0.2559(0.3321) | Total Time 10.00(10.00)\n",
      "Iter 3085 | Time 30.1853(29.5098) | Bit/dim 1.1094(1.1090) | Xent 0.0424(0.0393) | Loss 1.1305(1.1287) | Error 0.0135(0.0124) Steps 422(418.73) | Grad Norm 0.2053(0.3283) | Total Time 10.00(10.00)\n",
      "Iter 3086 | Time 30.8118(29.5488) | Bit/dim 1.1088(1.1090) | Xent 0.0413(0.0394) | Loss 1.1294(1.1287) | Error 0.0126(0.0124) Steps 422(418.83) | Grad Norm 0.5556(0.3351) | Total Time 10.00(10.00)\n",
      "Iter 3087 | Time 28.8878(29.5290) | Bit/dim 1.1061(1.1089) | Xent 0.0411(0.0395) | Loss 1.1267(1.1286) | Error 0.0111(0.0124) Steps 416(418.75) | Grad Norm 0.7486(0.3475) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 16.5929, Epoch Time 235.9579(234.3644), Bit/dim 1.1031(best: 1.1023), Xent 0.0271, Loss 1.1166, Error 0.0091(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3088 | Time 28.4224(29.4958) | Bit/dim 1.1118(1.1090) | Xent 0.0409(0.0395) | Loss 1.1322(1.1287) | Error 0.0142(0.0124) Steps 416(418.66) | Grad Norm 0.4141(0.3495) | Total Time 10.00(10.00)\n",
      "Iter 3089 | Time 29.2057(29.4871) | Bit/dim 1.1081(1.1090) | Xent 0.0361(0.0394) | Loss 1.1262(1.1287) | Error 0.0121(0.0124) Steps 422(418.76) | Grad Norm 0.6337(0.3581) | Total Time 10.00(10.00)\n",
      "Iter 3090 | Time 28.9705(29.4716) | Bit/dim 1.1103(1.1090) | Xent 0.0345(0.0392) | Loss 1.1275(1.1286) | Error 0.0106(0.0124) Steps 416(418.68) | Grad Norm 0.7622(0.3702) | Total Time 10.00(10.00)\n",
      "Iter 3091 | Time 29.9072(29.4847) | Bit/dim 1.1093(1.1090) | Xent 0.0384(0.0392) | Loss 1.1285(1.1286) | Error 0.0098(0.0123) Steps 422(418.78) | Grad Norm 0.5005(0.3741) | Total Time 10.00(10.00)\n",
      "Iter 3092 | Time 30.2847(29.5087) | Bit/dim 1.1030(1.1088) | Xent 0.0355(0.0391) | Loss 1.1207(1.1284) | Error 0.0118(0.0123) Steps 428(419.06) | Grad Norm 0.2026(0.3690) | Total Time 10.00(10.00)\n",
      "Iter 3093 | Time 29.0389(29.4946) | Bit/dim 1.1052(1.1087) | Xent 0.0383(0.0391) | Loss 1.1243(1.1283) | Error 0.0125(0.0123) Steps 416(418.97) | Grad Norm 0.7803(0.3813) | Total Time 10.00(10.00)\n",
      "Iter 3094 | Time 28.8634(29.4756) | Bit/dim 1.1129(1.1088) | Xent 0.0435(0.0392) | Loss 1.1347(1.1284) | Error 0.0142(0.0123) Steps 416(418.88) | Grad Norm 0.5921(0.3876) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 16.5343, Epoch Time 233.7582(234.3462), Bit/dim 1.1021(best: 1.1023), Xent 0.0265, Loss 1.1154, Error 0.0092(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3095 | Time 28.6139(29.4498) | Bit/dim 1.1106(1.1089) | Xent 0.0410(0.0393) | Loss 1.1311(1.1285) | Error 0.0121(0.0123) Steps 416(418.79) | Grad Norm 0.4493(0.3895) | Total Time 10.00(10.00)\n",
      "Iter 3096 | Time 30.2279(29.4731) | Bit/dim 1.1064(1.1088) | Xent 0.0368(0.0392) | Loss 1.1248(1.1284) | Error 0.0101(0.0123) Steps 422(418.89) | Grad Norm 0.6407(0.3970) | Total Time 10.00(10.00)\n",
      "Iter 3097 | Time 28.7171(29.4504) | Bit/dim 1.1071(1.1088) | Xent 0.0396(0.0392) | Loss 1.1269(1.1284) | Error 0.0121(0.0123) Steps 422(418.98) | Grad Norm 0.8469(0.4105) | Total Time 10.00(10.00)\n",
      "Iter 3098 | Time 28.8581(29.4327) | Bit/dim 1.1078(1.1087) | Xent 0.0430(0.0393) | Loss 1.1293(1.1284) | Error 0.0124(0.0123) Steps 416(418.89) | Grad Norm 0.3101(0.4075) | Total Time 10.00(10.00)\n",
      "Iter 3099 | Time 29.7069(29.4409) | Bit/dim 1.1074(1.1087) | Xent 0.0375(0.0393) | Loss 1.1262(1.1283) | Error 0.0124(0.0123) Steps 416(418.80) | Grad Norm 0.4908(0.4100) | Total Time 10.00(10.00)\n",
      "Iter 3100 | Time 29.3156(29.4371) | Bit/dim 1.1126(1.1088) | Xent 0.0398(0.0393) | Loss 1.1325(1.1285) | Error 0.0129(0.0123) Steps 416(418.72) | Grad Norm 0.3306(0.4076) | Total Time 10.00(10.00)\n",
      "Iter 3101 | Time 28.7248(29.4158) | Bit/dim 1.1090(1.1088) | Xent 0.0435(0.0394) | Loss 1.1308(1.1285) | Error 0.0148(0.0124) Steps 422(418.82) | Grad Norm 0.5356(0.4114) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 16.6471, Epoch Time 233.1704(234.3109), Bit/dim 1.1023(best: 1.1021), Xent 0.0277, Loss 1.1161, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3102 | Time 29.3964(29.4152) | Bit/dim 1.1085(1.1088) | Xent 0.0435(0.0395) | Loss 1.1303(1.1286) | Error 0.0128(0.0124) Steps 416(418.73) | Grad Norm 0.2294(0.4060) | Total Time 10.00(10.00)\n",
      "Iter 3103 | Time 28.2153(29.3792) | Bit/dim 1.1068(1.1087) | Xent 0.0386(0.0395) | Loss 1.1261(1.1285) | Error 0.0121(0.0124) Steps 416(418.65) | Grad Norm 0.4764(0.4081) | Total Time 10.00(10.00)\n",
      "Iter 3104 | Time 29.9473(29.3962) | Bit/dim 1.1065(1.1087) | Xent 0.0359(0.0394) | Loss 1.1244(1.1284) | Error 0.0116(0.0123) Steps 428(418.93) | Grad Norm 0.4817(0.4103) | Total Time 10.00(10.00)\n",
      "Iter 3105 | Time 29.1489(29.3888) | Bit/dim 1.1101(1.1087) | Xent 0.0423(0.0395) | Loss 1.1313(1.1285) | Error 0.0130(0.0124) Steps 416(418.84) | Grad Norm 0.2678(0.4060) | Total Time 10.00(10.00)\n",
      "Iter 3106 | Time 28.7918(29.3709) | Bit/dim 1.1049(1.1086) | Xent 0.0442(0.0396) | Loss 1.1270(1.1284) | Error 0.0135(0.0124) Steps 422(418.94) | Grad Norm 0.2110(0.4002) | Total Time 10.00(10.00)\n",
      "Iter 3107 | Time 30.1419(29.3940) | Bit/dim 1.1102(1.1087) | Xent 0.0341(0.0395) | Loss 1.1272(1.1284) | Error 0.0100(0.0123) Steps 434(419.39) | Grad Norm 0.3364(0.3983) | Total Time 10.00(10.00)\n",
      "Iter 3108 | Time 30.3952(29.4241) | Bit/dim 1.1092(1.1087) | Xent 0.0418(0.0395) | Loss 1.1301(1.1284) | Error 0.0132(0.0124) Steps 422(419.47) | Grad Norm 0.3078(0.3956) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 16.4919, Epoch Time 235.2703(234.3397), Bit/dim 1.1030(best: 1.1021), Xent 0.0303, Loss 1.1182, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3109 | Time 28.7070(29.4026) | Bit/dim 1.1127(1.1088) | Xent 0.0409(0.0396) | Loss 1.1331(1.1286) | Error 0.0126(0.0124) Steps 422(419.54) | Grad Norm 0.1919(0.3894) | Total Time 10.00(10.00)\n",
      "Iter 3110 | Time 30.8892(29.4472) | Bit/dim 1.1039(1.1086) | Xent 0.0472(0.0398) | Loss 1.1275(1.1285) | Error 0.0135(0.0124) Steps 416(419.44) | Grad Norm 0.2632(0.3857) | Total Time 10.00(10.00)\n",
      "Iter 3111 | Time 30.1183(29.4673) | Bit/dim 1.1067(1.1086) | Xent 0.0386(0.0398) | Loss 1.1260(1.1285) | Error 0.0128(0.0124) Steps 416(419.34) | Grad Norm 0.3422(0.3844) | Total Time 10.00(10.00)\n",
      "Iter 3112 | Time 28.9553(29.4519) | Bit/dim 1.1072(1.1085) | Xent 0.0418(0.0398) | Loss 1.1281(1.1285) | Error 0.0119(0.0124) Steps 416(419.24) | Grad Norm 0.2352(0.3799) | Total Time 10.00(10.00)\n",
      "Iter 3113 | Time 29.3448(29.4487) | Bit/dim 1.1072(1.1085) | Xent 0.0383(0.0398) | Loss 1.1263(1.1284) | Error 0.0106(0.0123) Steps 422(419.32) | Grad Norm 0.2396(0.3757) | Total Time 10.00(10.00)\n",
      "Iter 3114 | Time 28.7636(29.4282) | Bit/dim 1.1108(1.1086) | Xent 0.0357(0.0397) | Loss 1.1286(1.1284) | Error 0.0121(0.0123) Steps 416(419.22) | Grad Norm 0.2853(0.3730) | Total Time 10.00(10.00)\n",
      "Iter 3115 | Time 29.9590(29.4441) | Bit/dim 1.1130(1.1087) | Xent 0.0380(0.0396) | Loss 1.1320(1.1285) | Error 0.0120(0.0123) Steps 416(419.12) | Grad Norm 0.2682(0.3698) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 16.3551, Epoch Time 235.4774(234.3738), Bit/dim 1.1029(best: 1.1021), Xent 0.0271, Loss 1.1165, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3116 | Time 28.6397(29.4200) | Bit/dim 1.1132(1.1088) | Xent 0.0428(0.0397) | Loss 1.1346(1.1287) | Error 0.0134(0.0124) Steps 416(419.03) | Grad Norm 0.2878(0.3674) | Total Time 10.00(10.00)\n",
      "Iter 3117 | Time 31.1292(29.4712) | Bit/dim 1.1082(1.1088) | Xent 0.0317(0.0395) | Loss 1.1240(1.1286) | Error 0.0110(0.0123) Steps 416(418.94) | Grad Norm 0.1731(0.3615) | Total Time 10.00(10.00)\n",
      "Iter 3118 | Time 30.2790(29.4955) | Bit/dim 1.1103(1.1089) | Xent 0.0412(0.0395) | Loss 1.1309(1.1286) | Error 0.0131(0.0123) Steps 422(419.03) | Grad Norm 0.2406(0.3579) | Total Time 10.00(10.00)\n",
      "Iter 3119 | Time 30.7634(29.5335) | Bit/dim 1.1089(1.1089) | Xent 0.0420(0.0396) | Loss 1.1299(1.1287) | Error 0.0128(0.0123) Steps 428(419.30) | Grad Norm 0.4150(0.3596) | Total Time 10.00(10.00)\n",
      "Iter 3120 | Time 31.3642(29.5884) | Bit/dim 1.1082(1.1088) | Xent 0.0388(0.0396) | Loss 1.1276(1.1286) | Error 0.0121(0.0123) Steps 422(419.38) | Grad Norm 0.2515(0.3564) | Total Time 10.00(10.00)\n",
      "Iter 3121 | Time 30.9426(29.6291) | Bit/dim 1.1085(1.1088) | Xent 0.0422(0.0396) | Loss 1.1296(1.1287) | Error 0.0105(0.0123) Steps 428(419.64) | Grad Norm 0.3437(0.3560) | Total Time 10.00(10.00)\n",
      "Iter 3122 | Time 30.9697(29.6693) | Bit/dim 1.1040(1.1087) | Xent 0.0477(0.0399) | Loss 1.1279(1.1286) | Error 0.0146(0.0124) Steps 428(419.89) | Grad Norm 0.4073(0.3575) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 16.7131, Epoch Time 243.2235(234.6393), Bit/dim 1.1029(best: 1.1021), Xent 0.0283, Loss 1.1170, Error 0.0101(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3123 | Time 32.1941(29.7450) | Bit/dim 1.1117(1.1088) | Xent 0.0343(0.0397) | Loss 1.1289(1.1286) | Error 0.0111(0.0123) Steps 422(419.95) | Grad Norm 0.6033(0.3649) | Total Time 10.00(10.00)\n",
      "Iter 3124 | Time 29.5032(29.7378) | Bit/dim 1.1031(1.1086) | Xent 0.0349(0.0396) | Loss 1.1205(1.1284) | Error 0.0100(0.0123) Steps 422(420.01) | Grad Norm 0.2845(0.3625) | Total Time 10.00(10.00)\n",
      "Iter 3125 | Time 31.7873(29.7992) | Bit/dim 1.1121(1.1087) | Xent 0.0396(0.0396) | Loss 1.1319(1.1285) | Error 0.0111(0.0122) Steps 422(420.07) | Grad Norm 0.4113(0.3640) | Total Time 10.00(10.00)\n",
      "Iter 3126 | Time 29.9756(29.8045) | Bit/dim 1.1057(1.1086) | Xent 0.0392(0.0396) | Loss 1.1252(1.1284) | Error 0.0116(0.0122) Steps 422(420.13) | Grad Norm 0.3363(0.3631) | Total Time 10.00(10.00)\n",
      "Iter 3127 | Time 30.5275(29.8262) | Bit/dim 1.1075(1.1086) | Xent 0.0455(0.0397) | Loss 1.1303(1.1285) | Error 0.0119(0.0122) Steps 416(420.01) | Grad Norm 0.5407(0.3684) | Total Time 10.00(10.00)\n",
      "Iter 3128 | Time 29.3999(29.8134) | Bit/dim 1.1086(1.1086) | Xent 0.0411(0.0398) | Loss 1.1291(1.1285) | Error 0.0121(0.0122) Steps 422(420.07) | Grad Norm 0.2894(0.3661) | Total Time 10.00(10.00)\n",
      "Iter 3129 | Time 30.8105(29.8433) | Bit/dim 1.1103(1.1086) | Xent 0.0410(0.0398) | Loss 1.1308(1.1286) | Error 0.0134(0.0122) Steps 422(420.12) | Grad Norm 0.2006(0.3611) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 16.2567, Epoch Time 243.0861(234.8927), Bit/dim 1.1027(best: 1.1021), Xent 0.0287, Loss 1.1170, Error 0.0091(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3130 | Time 28.9827(29.8175) | Bit/dim 1.1121(1.1087) | Xent 0.0365(0.0397) | Loss 1.1304(1.1286) | Error 0.0122(0.0122) Steps 416(420.00) | Grad Norm 0.4678(0.3643) | Total Time 10.00(10.00)\n",
      "Iter 3131 | Time 29.2256(29.7998) | Bit/dim 1.1100(1.1088) | Xent 0.0424(0.0398) | Loss 1.1312(1.1287) | Error 0.0128(0.0122) Steps 422(420.06) | Grad Norm 0.3017(0.3624) | Total Time 10.00(10.00)\n",
      "Iter 3132 | Time 28.3525(29.7564) | Bit/dim 1.1048(1.1087) | Xent 0.0337(0.0396) | Loss 1.1217(1.1285) | Error 0.0108(0.0122) Steps 416(419.94) | Grad Norm 0.2454(0.3589) | Total Time 10.00(10.00)\n",
      "Iter 3133 | Time 29.6814(29.7541) | Bit/dim 1.1063(1.1086) | Xent 0.0402(0.0396) | Loss 1.1263(1.1284) | Error 0.0138(0.0122) Steps 416(419.82) | Grad Norm 0.4390(0.3613) | Total Time 10.00(10.00)\n",
      "Iter 3134 | Time 31.2131(29.7979) | Bit/dim 1.1052(1.1085) | Xent 0.0381(0.0396) | Loss 1.1243(1.1283) | Error 0.0122(0.0122) Steps 428(420.07) | Grad Norm 0.2340(0.3575) | Total Time 10.00(10.00)\n",
      "Iter 3135 | Time 29.0578(29.7757) | Bit/dim 1.1073(1.1085) | Xent 0.0437(0.0397) | Loss 1.1291(1.1283) | Error 0.0139(0.0123) Steps 416(419.94) | Grad Norm 0.2375(0.3539) | Total Time 10.00(10.00)\n",
      "Iter 3136 | Time 29.2324(29.7594) | Bit/dim 1.1112(1.1085) | Xent 0.0385(0.0397) | Loss 1.1305(1.1284) | Error 0.0136(0.0123) Steps 422(420.01) | Grad Norm 0.3625(0.3542) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 16.3733, Epoch Time 234.6830(234.8864), Bit/dim 1.1025(best: 1.1021), Xent 0.0289, Loss 1.1169, Error 0.0093(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3137 | Time 28.7300(29.7285) | Bit/dim 1.1094(1.1086) | Xent 0.0383(0.0396) | Loss 1.1285(1.1284) | Error 0.0120(0.0123) Steps 416(419.89) | Grad Norm 0.2267(0.3503) | Total Time 10.00(10.00)\n",
      "Iter 3138 | Time 29.1253(29.7104) | Bit/dim 1.1043(1.1084) | Xent 0.0332(0.0394) | Loss 1.1209(1.1282) | Error 0.0096(0.0122) Steps 416(419.77) | Grad Norm 0.5257(0.3556) | Total Time 10.00(10.00)\n",
      "Iter 3139 | Time 30.5100(29.7344) | Bit/dim 1.1081(1.1084) | Xent 0.0389(0.0394) | Loss 1.1275(1.1281) | Error 0.0119(0.0122) Steps 422(419.84) | Grad Norm 0.2736(0.3531) | Total Time 10.00(10.00)\n",
      "Iter 3140 | Time 30.4765(29.7566) | Bit/dim 1.1116(1.1085) | Xent 0.0396(0.0394) | Loss 1.1314(1.1282) | Error 0.0138(0.0123) Steps 416(419.72) | Grad Norm 0.4170(0.3551) | Total Time 10.00(10.00)\n",
      "Iter 3141 | Time 28.7781(29.7273) | Bit/dim 1.1091(1.1085) | Xent 0.0441(0.0396) | Loss 1.1312(1.1283) | Error 0.0138(0.0123) Steps 416(419.61) | Grad Norm 0.2984(0.3534) | Total Time 10.00(10.00)\n",
      "Iter 3142 | Time 30.6628(29.7554) | Bit/dim 1.1095(1.1086) | Xent 0.0390(0.0396) | Loss 1.1290(1.1283) | Error 0.0131(0.0123) Steps 416(419.50) | Grad Norm 0.3029(0.3518) | Total Time 10.00(10.00)\n",
      "Iter 3143 | Time 31.6568(29.8124) | Bit/dim 1.1107(1.1086) | Xent 0.0368(0.0395) | Loss 1.1290(1.1284) | Error 0.0126(0.0124) Steps 422(419.58) | Grad Norm 0.2851(0.3498) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 16.7286, Epoch Time 239.3096(235.0191), Bit/dim 1.1027(best: 1.1021), Xent 0.0270, Loss 1.1163, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3144 | Time 30.8354(29.8431) | Bit/dim 1.1140(1.1088) | Xent 0.0366(0.0394) | Loss 1.1323(1.1285) | Error 0.0114(0.0123) Steps 428(419.83) | Grad Norm 0.2481(0.3468) | Total Time 10.00(10.00)\n",
      "Iter 3145 | Time 30.5516(29.8643) | Bit/dim 1.1107(1.1088) | Xent 0.0389(0.0394) | Loss 1.1302(1.1285) | Error 0.0121(0.0123) Steps 428(420.07) | Grad Norm 0.3700(0.3475) | Total Time 10.00(10.00)\n",
      "Iter 3146 | Time 31.8322(29.9234) | Bit/dim 1.1079(1.1088) | Xent 0.0374(0.0393) | Loss 1.1266(1.1285) | Error 0.0120(0.0123) Steps 434(420.49) | Grad Norm 0.2764(0.3454) | Total Time 10.00(10.00)\n",
      "Iter 3147 | Time 30.4336(29.9387) | Bit/dim 1.1027(1.1086) | Xent 0.0373(0.0393) | Loss 1.1213(1.1283) | Error 0.0115(0.0123) Steps 416(420.36) | Grad Norm 0.1808(0.3404) | Total Time 10.00(10.00)\n",
      "Iter 3148 | Time 31.4867(29.9851) | Bit/dim 1.1104(1.1087) | Xent 0.0379(0.0392) | Loss 1.1294(1.1283) | Error 0.0119(0.0123) Steps 428(420.59) | Grad Norm 0.3246(0.3399) | Total Time 10.00(10.00)\n",
      "Iter 3149 | Time 30.2396(29.9928) | Bit/dim 1.1036(1.1085) | Xent 0.0408(0.0393) | Loss 1.1240(1.1282) | Error 0.0130(0.0123) Steps 422(420.63) | Grad Norm 0.3369(0.3399) | Total Time 10.00(10.00)\n",
      "Iter 3150 | Time 31.2304(30.0299) | Bit/dim 1.1097(1.1086) | Xent 0.0387(0.0392) | Loss 1.1291(1.1282) | Error 0.0119(0.0123) Steps 428(420.85) | Grad Norm 0.5079(0.3449) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 16.5995, Epoch Time 245.9586(235.3473), Bit/dim 1.1024(best: 1.1021), Xent 0.0257, Loss 1.1153, Error 0.0091(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3151 | Time 31.2577(30.0667) | Bit/dim 1.1084(1.1086) | Xent 0.0389(0.0392) | Loss 1.1278(1.1282) | Error 0.0115(0.0123) Steps 416(420.70) | Grad Norm 0.2005(0.3406) | Total Time 10.00(10.00)\n",
      "Iter 3152 | Time 30.6730(30.0849) | Bit/dim 1.1088(1.1086) | Xent 0.0471(0.0395) | Loss 1.1323(1.1283) | Error 0.0156(0.0124) Steps 422(420.74) | Grad Norm 0.3749(0.3416) | Total Time 10.00(10.00)\n",
      "Iter 3153 | Time 30.4451(30.0957) | Bit/dim 1.1091(1.1086) | Xent 0.0386(0.0394) | Loss 1.1283(1.1283) | Error 0.0119(0.0123) Steps 416(420.60) | Grad Norm 0.2771(0.3397) | Total Time 10.00(10.00)\n",
      "Iter 3154 | Time 30.3106(30.1022) | Bit/dim 1.1075(1.1086) | Xent 0.0364(0.0393) | Loss 1.1257(1.1282) | Error 0.0130(0.0124) Steps 422(420.64) | Grad Norm 0.2459(0.3368) | Total Time 10.00(10.00)\n",
      "Iter 3155 | Time 29.4395(30.0823) | Bit/dim 1.1086(1.1086) | Xent 0.0423(0.0394) | Loss 1.1298(1.1283) | Error 0.0124(0.0124) Steps 422(420.68) | Grad Norm 0.2630(0.3346) | Total Time 10.00(10.00)\n",
      "Iter 3156 | Time 29.6634(30.0697) | Bit/dim 1.1104(1.1086) | Xent 0.0350(0.0393) | Loss 1.1279(1.1283) | Error 0.0114(0.0123) Steps 422(420.72) | Grad Norm 0.2357(0.3317) | Total Time 10.00(10.00)\n",
      "Iter 3157 | Time 31.4415(30.1109) | Bit/dim 1.1101(1.1087) | Xent 0.0455(0.0395) | Loss 1.1328(1.1284) | Error 0.0145(0.0124) Steps 422(420.76) | Grad Norm 0.2194(0.3283) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 16.7824, Epoch Time 242.4092(235.5592), Bit/dim 1.1028(best: 1.1021), Xent 0.0292, Loss 1.1173, Error 0.0101(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3158 | Time 30.4198(30.1201) | Bit/dim 1.1085(1.1087) | Xent 0.0419(0.0396) | Loss 1.1295(1.1284) | Error 0.0122(0.0124) Steps 428(420.98) | Grad Norm 0.3215(0.3281) | Total Time 10.00(10.00)\n",
      "Iter 3159 | Time 29.3363(30.0966) | Bit/dim 1.1058(1.1086) | Xent 0.0372(0.0395) | Loss 1.1244(1.1283) | Error 0.0120(0.0124) Steps 422(421.01) | Grad Norm 0.2794(0.3266) | Total Time 10.00(10.00)\n",
      "Iter 3160 | Time 29.5479(30.0802) | Bit/dim 1.1040(1.1084) | Xent 0.0466(0.0397) | Loss 1.1273(1.1283) | Error 0.0131(0.0124) Steps 422(421.04) | Grad Norm 0.1996(0.3228) | Total Time 10.00(10.00)\n",
      "Iter 3161 | Time 31.9364(30.1359) | Bit/dim 1.1104(1.1085) | Xent 0.0382(0.0397) | Loss 1.1295(1.1283) | Error 0.0109(0.0124) Steps 434(421.43) | Grad Norm 0.4657(0.3271) | Total Time 10.00(10.00)\n",
      "Iter 3162 | Time 31.2382(30.1689) | Bit/dim 1.1096(1.1085) | Xent 0.0366(0.0396) | Loss 1.1279(1.1283) | Error 0.0109(0.0123) Steps 428(421.63) | Grad Norm 0.2680(0.3253) | Total Time 10.00(10.00)\n",
      "Iter 3163 | Time 30.9873(30.1935) | Bit/dim 1.1088(1.1085) | Xent 0.0405(0.0396) | Loss 1.1291(1.1283) | Error 0.0128(0.0123) Steps 434(422.00) | Grad Norm 0.2877(0.3242) | Total Time 10.00(10.00)\n",
      "Iter 3164 | Time 30.1883(30.1933) | Bit/dim 1.1104(1.1086) | Xent 0.0360(0.0395) | Loss 1.1284(1.1283) | Error 0.0119(0.0123) Steps 428(422.18) | Grad Norm 0.3241(0.3242) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 16.6499, Epoch Time 242.6719(235.7725), Bit/dim 1.1019(best: 1.1021), Xent 0.0310, Loss 1.1174, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3165 | Time 31.4555(30.2312) | Bit/dim 1.1091(1.1086) | Xent 0.0424(0.0396) | Loss 1.1303(1.1284) | Error 0.0141(0.0124) Steps 434(422.53) | Grad Norm 0.2080(0.3207) | Total Time 10.00(10.00)\n",
      "Iter 3166 | Time 29.9299(30.2221) | Bit/dim 1.1086(1.1086) | Xent 0.0356(0.0395) | Loss 1.1264(1.1283) | Error 0.0118(0.0123) Steps 422(422.52) | Grad Norm 0.2945(0.3199) | Total Time 10.00(10.00)\n",
      "Iter 3167 | Time 29.5655(30.2024) | Bit/dim 1.1098(1.1086) | Xent 0.0398(0.0395) | Loss 1.1297(1.1284) | Error 0.0122(0.0123) Steps 428(422.68) | Grad Norm 0.2002(0.3163) | Total Time 10.00(10.00)\n",
      "Iter 3168 | Time 30.9565(30.2251) | Bit/dim 1.1110(1.1087) | Xent 0.0371(0.0394) | Loss 1.1296(1.1284) | Error 0.0109(0.0123) Steps 422(422.66) | Grad Norm 0.5798(0.3242) | Total Time 10.00(10.00)\n",
      "Iter 3169 | Time 31.3487(30.2588) | Bit/dim 1.1101(1.1087) | Xent 0.0452(0.0396) | Loss 1.1327(1.1285) | Error 0.0138(0.0123) Steps 428(422.82) | Grad Norm 0.2286(0.3214) | Total Time 10.00(10.00)\n",
      "Iter 3170 | Time 29.2963(30.2299) | Bit/dim 1.1076(1.1087) | Xent 0.0326(0.0394) | Loss 1.1239(1.1284) | Error 0.0095(0.0123) Steps 422(422.79) | Grad Norm 0.2607(0.3196) | Total Time 10.00(10.00)\n",
      "Iter 3171 | Time 30.4636(30.2369) | Bit/dim 1.1051(1.1086) | Xent 0.0371(0.0393) | Loss 1.1237(1.1282) | Error 0.0116(0.0122) Steps 428(422.95) | Grad Norm 0.3552(0.3206) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 16.5359, Epoch Time 242.0790(235.9617), Bit/dim 1.1024(best: 1.1019), Xent 0.0268, Loss 1.1158, Error 0.0088(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3172 | Time 31.8284(30.2847) | Bit/dim 1.1073(1.1086) | Xent 0.0366(0.0392) | Loss 1.1256(1.1282) | Error 0.0096(0.0122) Steps 416(422.74) | Grad Norm 0.2172(0.3175) | Total Time 10.00(10.00)\n",
      "Iter 3173 | Time 30.8890(30.3028) | Bit/dim 1.1101(1.1086) | Xent 0.0391(0.0392) | Loss 1.1297(1.1282) | Error 0.0129(0.0122) Steps 428(422.90) | Grad Norm 0.2523(0.3156) | Total Time 10.00(10.00)\n",
      "Iter 3174 | Time 29.6930(30.2845) | Bit/dim 1.1044(1.1085) | Xent 0.0352(0.0391) | Loss 1.1220(1.1280) | Error 0.0111(0.0122) Steps 422(422.87) | Grad Norm 0.2315(0.3130) | Total Time 10.00(10.00)\n",
      "Iter 3175 | Time 29.8435(30.2713) | Bit/dim 1.1083(1.1085) | Xent 0.0412(0.0392) | Loss 1.1289(1.1281) | Error 0.0142(0.0122) Steps 416(422.67) | Grad Norm 0.3453(0.3140) | Total Time 10.00(10.00)\n",
      "Iter 3176 | Time 29.1258(30.2369) | Bit/dim 1.1073(1.1084) | Xent 0.0378(0.0391) | Loss 1.1262(1.1280) | Error 0.0116(0.0122) Steps 422(422.65) | Grad Norm 0.5138(0.3200) | Total Time 10.00(10.00)\n",
      "Iter 3177 | Time 29.7366(30.2219) | Bit/dim 1.1101(1.1085) | Xent 0.0365(0.0390) | Loss 1.1283(1.1280) | Error 0.0120(0.0122) Steps 416(422.45) | Grad Norm 0.2598(0.3182) | Total Time 10.00(10.00)\n",
      "Iter 3178 | Time 30.4456(30.2286) | Bit/dim 1.1110(1.1086) | Xent 0.0427(0.0391) | Loss 1.1323(1.1281) | Error 0.0131(0.0122) Steps 422(422.43) | Grad Norm 0.2436(0.3160) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 16.7760, Epoch Time 240.6497(236.1024), Bit/dim 1.1025(best: 1.1019), Xent 0.0293, Loss 1.1172, Error 0.0101(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3179 | Time 29.9537(30.2204) | Bit/dim 1.1052(1.1085) | Xent 0.0320(0.0389) | Loss 1.1212(1.1279) | Error 0.0102(0.0122) Steps 422(422.42) | Grad Norm 0.1946(0.3123) | Total Time 10.00(10.00)\n",
      "Iter 3180 | Time 29.2309(30.1907) | Bit/dim 1.1114(1.1086) | Xent 0.0373(0.0389) | Loss 1.1300(1.1280) | Error 0.0119(0.0122) Steps 422(422.41) | Grad Norm 0.2875(0.3116) | Total Time 10.00(10.00)\n",
      "Iter 3181 | Time 28.8719(30.1511) | Bit/dim 1.1101(1.1086) | Xent 0.0438(0.0390) | Loss 1.1320(1.1281) | Error 0.0138(0.0122) Steps 428(422.58) | Grad Norm 0.2544(0.3099) | Total Time 10.00(10.00)\n",
      "Iter 3182 | Time 29.1518(30.1211) | Bit/dim 1.1092(1.1086) | Xent 0.0430(0.0391) | Loss 1.1308(1.1282) | Error 0.0136(0.0122) Steps 422(422.56) | Grad Norm 0.3164(0.3101) | Total Time 10.00(10.00)\n",
      "Iter 3183 | Time 30.1201(30.1211) | Bit/dim 1.1080(1.1086) | Xent 0.0369(0.0391) | Loss 1.1265(1.1281) | Error 0.0112(0.0122) Steps 434(422.90) | Grad Norm 0.3703(0.3119) | Total Time 10.00(10.00)\n",
      "Iter 3184 | Time 30.2007(30.1235) | Bit/dim 1.1059(1.1085) | Xent 0.0439(0.0392) | Loss 1.1278(1.1281) | Error 0.0124(0.0122) Steps 422(422.88) | Grad Norm 0.3982(0.3145) | Total Time 10.00(10.00)\n",
      "Iter 3185 | Time 29.4878(30.1044) | Bit/dim 1.1068(1.1085) | Xent 0.0415(0.0393) | Loss 1.1276(1.1281) | Error 0.0124(0.0122) Steps 422(422.85) | Grad Norm 0.3192(0.3146) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 16.5612, Epoch Time 235.8089(236.0936), Bit/dim 1.1021(best: 1.1019), Xent 0.0289, Loss 1.1166, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3186 | Time 30.2876(30.1099) | Bit/dim 1.1062(1.1084) | Xent 0.0400(0.0393) | Loss 1.1261(1.1281) | Error 0.0131(0.0122) Steps 428(423.00) | Grad Norm 0.2118(0.3115) | Total Time 10.00(10.00)\n",
      "Iter 3187 | Time 29.4403(30.0898) | Bit/dim 1.1082(1.1084) | Xent 0.0347(0.0392) | Loss 1.1255(1.1280) | Error 0.0090(0.0122) Steps 422(422.97) | Grad Norm 0.2388(0.3093) | Total Time 10.00(10.00)\n",
      "Iter 3188 | Time 30.4647(30.1011) | Bit/dim 1.1053(1.1083) | Xent 0.0345(0.0390) | Loss 1.1226(1.1278) | Error 0.0118(0.0121) Steps 428(423.12) | Grad Norm 0.1862(0.3056) | Total Time 10.00(10.00)\n",
      "Iter 3189 | Time 30.5273(30.1139) | Bit/dim 1.1131(1.1084) | Xent 0.0361(0.0389) | Loss 1.1311(1.1279) | Error 0.0115(0.0121) Steps 422(423.09) | Grad Norm 0.2192(0.3030) | Total Time 10.00(10.00)\n",
      "Iter 3190 | Time 29.9740(30.1097) | Bit/dim 1.1061(1.1084) | Xent 0.0425(0.0391) | Loss 1.1274(1.1279) | Error 0.0128(0.0121) Steps 428(423.24) | Grad Norm 0.3562(0.3046) | Total Time 10.00(10.00)\n",
      "Iter 3191 | Time 29.4734(30.0906) | Bit/dim 1.1118(1.1085) | Xent 0.0420(0.0391) | Loss 1.1328(1.1280) | Error 0.0124(0.0121) Steps 428(423.38) | Grad Norm 0.3227(0.3052) | Total Time 10.00(10.00)\n",
      "Iter 3192 | Time 31.2047(30.1240) | Bit/dim 1.1065(1.1084) | Xent 0.0398(0.0392) | Loss 1.1264(1.1280) | Error 0.0126(0.0122) Steps 422(423.34) | Grad Norm 0.1883(0.3017) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 16.6183, Epoch Time 240.7729(236.2340), Bit/dim 1.1019(best: 1.1019), Xent 0.0275, Loss 1.1157, Error 0.0097(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3193 | Time 29.0566(30.0920) | Bit/dim 1.1107(1.1085) | Xent 0.0388(0.0391) | Loss 1.1301(1.1281) | Error 0.0118(0.0121) Steps 434(423.66) | Grad Norm 0.2822(0.3011) | Total Time 10.00(10.00)\n",
      "Iter 3194 | Time 30.5051(30.1044) | Bit/dim 1.1062(1.1084) | Xent 0.0383(0.0391) | Loss 1.1253(1.1280) | Error 0.0118(0.0121) Steps 422(423.61) | Grad Norm 0.2910(0.3008) | Total Time 10.00(10.00)\n",
      "Iter 3195 | Time 28.9255(30.0690) | Bit/dim 1.1053(1.1083) | Xent 0.0396(0.0391) | Loss 1.1251(1.1279) | Error 0.0131(0.0122) Steps 422(423.56) | Grad Norm 0.3497(0.3023) | Total Time 10.00(10.00)\n",
      "Iter 3196 | Time 28.8746(30.0332) | Bit/dim 1.1053(1.1082) | Xent 0.0365(0.0391) | Loss 1.1235(1.1278) | Error 0.0118(0.0122) Steps 428(423.69) | Grad Norm 0.2760(0.3015) | Total Time 10.00(10.00)\n",
      "Iter 3197 | Time 29.1543(30.0068) | Bit/dim 1.1066(1.1082) | Xent 0.0459(0.0393) | Loss 1.1295(1.1278) | Error 0.0141(0.0122) Steps 428(423.82) | Grad Norm 0.4157(0.3049) | Total Time 10.00(10.00)\n",
      "Iter 3198 | Time 31.2138(30.0430) | Bit/dim 1.1094(1.1082) | Xent 0.0406(0.0393) | Loss 1.1297(1.1279) | Error 0.0116(0.0122) Steps 422(423.77) | Grad Norm 0.4732(0.3099) | Total Time 10.00(10.00)\n",
      "Iter 3199 | Time 30.6413(30.0610) | Bit/dim 1.1127(1.1084) | Xent 0.0467(0.0395) | Loss 1.1360(1.1281) | Error 0.0144(0.0123) Steps 428(423.90) | Grad Norm 0.2628(0.3085) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 16.5576, Epoch Time 237.2645(236.2649), Bit/dim 1.1020(best: 1.1019), Xent 0.0303, Loss 1.1171, Error 0.0107(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3200 | Time 29.4395(30.0423) | Bit/dim 1.1070(1.1083) | Xent 0.0448(0.0397) | Loss 1.1294(1.1282) | Error 0.0120(0.0123) Steps 428(424.02) | Grad Norm 0.7312(0.3212) | Total Time 10.00(10.00)\n",
      "Iter 3201 | Time 29.1745(30.0163) | Bit/dim 1.1046(1.1082) | Xent 0.0421(0.0398) | Loss 1.1256(1.1281) | Error 0.0139(0.0123) Steps 422(423.96) | Grad Norm 0.2567(0.3193) | Total Time 10.00(10.00)\n",
      "Iter 3202 | Time 31.1936(30.0516) | Bit/dim 1.1070(1.1082) | Xent 0.0348(0.0396) | Loss 1.1244(1.1280) | Error 0.0126(0.0123) Steps 422(423.90) | Grad Norm 0.4680(0.3237) | Total Time 10.00(10.00)\n",
      "Iter 3203 | Time 30.1118(30.0534) | Bit/dim 1.1109(1.1082) | Xent 0.0465(0.0398) | Loss 1.1341(1.1282) | Error 0.0128(0.0123) Steps 422(423.84) | Grad Norm 0.5223(0.3297) | Total Time 10.00(10.00)\n",
      "Iter 3204 | Time 30.4539(30.0654) | Bit/dim 1.1125(1.1084) | Xent 0.0393(0.0398) | Loss 1.1321(1.1283) | Error 0.0118(0.0123) Steps 422(423.79) | Grad Norm 0.4565(0.3335) | Total Time 10.00(10.00)\n",
      "Iter 3205 | Time 32.0046(30.1236) | Bit/dim 1.1050(1.1083) | Xent 0.0378(0.0397) | Loss 1.1239(1.1281) | Error 0.0114(0.0123) Steps 422(423.73) | Grad Norm 0.7590(0.3463) | Total Time 10.00(10.00)\n",
      "Iter 3206 | Time 31.3952(30.1617) | Bit/dim 1.1067(1.1082) | Xent 0.0361(0.0396) | Loss 1.1248(1.1280) | Error 0.0118(0.0123) Steps 428(423.86) | Grad Norm 0.7859(0.3595) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 16.8424, Epoch Time 243.0581(236.4687), Bit/dim 1.1019(best: 1.1019), Xent 0.0278, Loss 1.1158, Error 0.0094(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3207 | Time 30.2465(30.1643) | Bit/dim 1.1063(1.1082) | Xent 0.0343(0.0395) | Loss 1.1235(1.1279) | Error 0.0110(0.0122) Steps 434(424.17) | Grad Norm 0.2722(0.3568) | Total Time 10.00(10.00)\n",
      "Iter 3208 | Time 30.2889(30.1680) | Bit/dim 1.1078(1.1082) | Xent 0.0361(0.0394) | Loss 1.1259(1.1278) | Error 0.0121(0.0122) Steps 422(424.10) | Grad Norm 0.5361(0.3622) | Total Time 10.00(10.00)\n",
      "Iter 3209 | Time 30.6248(30.1817) | Bit/dim 1.1119(1.1083) | Xent 0.0419(0.0394) | Loss 1.1328(1.1280) | Error 0.0140(0.0123) Steps 428(424.22) | Grad Norm 0.4041(0.3635) | Total Time 10.00(10.00)\n",
      "Iter 3210 | Time 30.5312(30.1922) | Bit/dim 1.1115(1.1084) | Xent 0.0330(0.0392) | Loss 1.1280(1.1280) | Error 0.0105(0.0122) Steps 428(424.33) | Grad Norm 0.2720(0.3607) | Total Time 10.00(10.00)\n",
      "Iter 3211 | Time 31.3596(30.2272) | Bit/dim 1.1044(1.1082) | Xent 0.0392(0.0392) | Loss 1.1240(1.1279) | Error 0.0112(0.0122) Steps 428(424.44) | Grad Norm 0.3457(0.3603) | Total Time 10.00(10.00)\n",
      "Iter 3212 | Time 29.9714(30.2196) | Bit/dim 1.1059(1.1082) | Xent 0.0427(0.0393) | Loss 1.1273(1.1279) | Error 0.0136(0.0122) Steps 428(424.55) | Grad Norm 0.5925(0.3672) | Total Time 10.00(10.00)\n",
      "Iter 3213 | Time 30.2929(30.2218) | Bit/dim 1.1063(1.1081) | Xent 0.0411(0.0394) | Loss 1.1269(1.1278) | Error 0.0132(0.0123) Steps 428(424.65) | Grad Norm 0.2539(0.3638) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 16.8366, Epoch Time 242.5784(236.6520), Bit/dim 1.1017(best: 1.1019), Xent 0.0283, Loss 1.1158, Error 0.0102(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3214 | Time 30.8802(30.2415) | Bit/dim 1.1160(1.1084) | Xent 0.0384(0.0394) | Loss 1.1352(1.1280) | Error 0.0112(0.0122) Steps 440(425.11) | Grad Norm 0.2430(0.3602) | Total Time 10.00(10.00)\n",
      "Iter 3215 | Time 30.5614(30.2511) | Bit/dim 1.1038(1.1082) | Xent 0.0327(0.0392) | Loss 1.1201(1.1278) | Error 0.0096(0.0122) Steps 428(425.20) | Grad Norm 0.4285(0.3623) | Total Time 10.00(10.00)\n",
      "Iter 3216 | Time 29.1738(30.2188) | Bit/dim 1.1040(1.1081) | Xent 0.0365(0.0391) | Loss 1.1222(1.1276) | Error 0.0116(0.0121) Steps 422(425.10) | Grad Norm 0.4652(0.3654) | Total Time 10.00(10.00)\n",
      "Iter 3217 | Time 31.5192(30.2578) | Bit/dim 1.1064(1.1080) | Xent 0.0391(0.0391) | Loss 1.1259(1.1276) | Error 0.0129(0.0122) Steps 434(425.37) | Grad Norm 0.3118(0.3637) | Total Time 10.00(10.00)\n",
      "Iter 3218 | Time 30.4605(30.2639) | Bit/dim 1.1087(1.1081) | Xent 0.0441(0.0392) | Loss 1.1307(1.1277) | Error 0.0146(0.0122) Steps 434(425.63) | Grad Norm 0.5453(0.3692) | Total Time 10.00(10.00)\n",
      "Iter 3219 | Time 29.1130(30.2294) | Bit/dim 1.1073(1.1080) | Xent 0.0400(0.0393) | Loss 1.1272(1.1277) | Error 0.0110(0.0122) Steps 428(425.70) | Grad Norm 0.3304(0.3680) | Total Time 10.00(10.00)\n",
      "Iter 3220 | Time 30.4039(30.2346) | Bit/dim 1.1069(1.1080) | Xent 0.0403(0.0393) | Loss 1.1271(1.1277) | Error 0.0121(0.0122) Steps 428(425.77) | Grad Norm 0.3220(0.3666) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 16.5165, Epoch Time 241.2335(236.7894), Bit/dim 1.1018(best: 1.1017), Xent 0.0290, Loss 1.1163, Error 0.0109(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3221 | Time 31.1594(30.2623) | Bit/dim 1.1069(1.1080) | Xent 0.0411(0.0393) | Loss 1.1274(1.1276) | Error 0.0110(0.0122) Steps 434(426.02) | Grad Norm 0.2214(0.3623) | Total Time 10.00(10.00)\n",
      "Iter 3222 | Time 29.5230(30.2402) | Bit/dim 1.1074(1.1080) | Xent 0.0368(0.0393) | Loss 1.1258(1.1276) | Error 0.0130(0.0122) Steps 422(425.90) | Grad Norm 0.3029(0.3605) | Total Time 10.00(10.00)\n",
      "Iter 3223 | Time 31.0334(30.2640) | Bit/dim 1.1088(1.1080) | Xent 0.0369(0.0392) | Loss 1.1273(1.1276) | Error 0.0120(0.0122) Steps 422(425.78) | Grad Norm 0.3244(0.3594) | Total Time 10.00(10.00)\n",
      "Iter 3224 | Time 30.5563(30.2727) | Bit/dim 1.1044(1.1079) | Xent 0.0429(0.0393) | Loss 1.1258(1.1275) | Error 0.0135(0.0122) Steps 422(425.66) | Grad Norm 0.2181(0.3552) | Total Time 10.00(10.00)\n",
      "Iter 3225 | Time 29.3804(30.2460) | Bit/dim 1.1087(1.1079) | Xent 0.0347(0.0392) | Loss 1.1261(1.1275) | Error 0.0126(0.0122) Steps 428(425.73) | Grad Norm 0.2474(0.3520) | Total Time 10.00(10.00)\n",
      "Iter 3226 | Time 31.1327(30.2726) | Bit/dim 1.1071(1.1079) | Xent 0.0319(0.0390) | Loss 1.1230(1.1274) | Error 0.0114(0.0122) Steps 422(425.62) | Grad Norm 0.3202(0.3510) | Total Time 10.00(10.00)\n",
      "Iter 3227 | Time 30.5350(30.2804) | Bit/dim 1.1107(1.1080) | Xent 0.0389(0.0389) | Loss 1.1301(1.1274) | Error 0.0134(0.0122) Steps 422(425.51) | Grad Norm 0.2260(0.3472) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 16.5356, Epoch Time 242.3173(236.9552), Bit/dim 1.1019(best: 1.1017), Xent 0.0302, Loss 1.1170, Error 0.0097(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3228 | Time 31.9993(30.3320) | Bit/dim 1.1024(1.1078) | Xent 0.0361(0.0389) | Loss 1.1204(1.1272) | Error 0.0108(0.0122) Steps 434(425.77) | Grad Norm 0.3482(0.3473) | Total Time 10.00(10.00)\n",
      "Iter 3229 | Time 30.4366(30.3351) | Bit/dim 1.1083(1.1078) | Xent 0.0391(0.0389) | Loss 1.1279(1.1272) | Error 0.0119(0.0122) Steps 434(426.02) | Grad Norm 0.3377(0.3470) | Total Time 10.00(10.00)\n",
      "Iter 3230 | Time 29.3982(30.3070) | Bit/dim 1.1072(1.1078) | Xent 0.0379(0.0388) | Loss 1.1261(1.1272) | Error 0.0114(0.0122) Steps 416(425.72) | Grad Norm 0.3744(0.3478) | Total Time 10.00(10.00)\n",
      "Iter 3231 | Time 31.6944(30.3486) | Bit/dim 1.1095(1.1078) | Xent 0.0470(0.0391) | Loss 1.1330(1.1274) | Error 0.0138(0.0122) Steps 428(425.78) | Grad Norm 0.5075(0.3526) | Total Time 10.00(10.00)\n",
      "Iter 3232 | Time 32.1476(30.4026) | Bit/dim 1.1095(1.1079) | Xent 0.0330(0.0389) | Loss 1.1260(1.1273) | Error 0.0110(0.0122) Steps 434(426.03) | Grad Norm 0.4325(0.3550) | Total Time 10.00(10.00)\n",
      "Iter 3233 | Time 30.0894(30.3932) | Bit/dim 1.1095(1.1079) | Xent 0.0439(0.0391) | Loss 1.1314(1.1275) | Error 0.0131(0.0122) Steps 434(426.27) | Grad Norm 0.3070(0.3536) | Total Time 10.00(10.00)\n",
      "Iter 3234 | Time 31.8786(30.4378) | Bit/dim 1.1115(1.1080) | Xent 0.0380(0.0390) | Loss 1.1305(1.1276) | Error 0.0126(0.0122) Steps 428(426.32) | Grad Norm 0.5675(0.3600) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 16.7079, Epoch Time 246.7296(237.2485), Bit/dim 1.1017(best: 1.1017), Xent 0.0282, Loss 1.1158, Error 0.0092(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3235 | Time 29.9835(30.4242) | Bit/dim 1.1050(1.1080) | Xent 0.0373(0.0390) | Loss 1.1236(1.1274) | Error 0.0124(0.0122) Steps 434(426.55) | Grad Norm 0.2919(0.3579) | Total Time 10.00(10.00)\n",
      "Iter 3236 | Time 30.8487(30.4369) | Bit/dim 1.1101(1.1080) | Xent 0.0414(0.0390) | Loss 1.1308(1.1275) | Error 0.0126(0.0122) Steps 428(426.60) | Grad Norm 0.2925(0.3560) | Total Time 10.00(10.00)\n",
      "Iter 3237 | Time 29.7082(30.4150) | Bit/dim 1.1106(1.1081) | Xent 0.0380(0.0390) | Loss 1.1296(1.1276) | Error 0.0108(0.0122) Steps 428(426.64) | Grad Norm 0.4078(0.3575) | Total Time 10.00(10.00)\n",
      "Iter 3238 | Time 30.9851(30.4321) | Bit/dim 1.1028(1.1079) | Xent 0.0369(0.0389) | Loss 1.1213(1.1274) | Error 0.0114(0.0122) Steps 422(426.50) | Grad Norm 0.4493(0.3603) | Total Time 10.00(10.00)\n",
      "Iter 3239 | Time 31.3349(30.4592) | Bit/dim 1.1081(1.1079) | Xent 0.0452(0.0391) | Loss 1.1306(1.1275) | Error 0.0138(0.0122) Steps 428(426.54) | Grad Norm 0.3020(0.3585) | Total Time 10.00(10.00)\n",
      "Iter 3240 | Time 30.3324(30.4554) | Bit/dim 1.1087(1.1080) | Xent 0.0427(0.0392) | Loss 1.1301(1.1276) | Error 0.0136(0.0123) Steps 434(426.77) | Grad Norm 0.2721(0.3559) | Total Time 10.00(10.00)\n",
      "Iter 3241 | Time 30.5271(30.4576) | Bit/dim 1.1093(1.1080) | Xent 0.0379(0.0392) | Loss 1.1283(1.1276) | Error 0.0115(0.0122) Steps 434(426.98) | Grad Norm 0.3871(0.3569) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 16.6036, Epoch Time 242.7346(237.4131), Bit/dim 1.1022(best: 1.1017), Xent 0.0252, Loss 1.1148, Error 0.0092(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3242 | Time 30.6714(30.4640) | Bit/dim 1.1043(1.1079) | Xent 0.0395(0.0392) | Loss 1.1240(1.1275) | Error 0.0115(0.0122) Steps 422(426.83) | Grad Norm 0.3252(0.3559) | Total Time 10.00(10.00)\n",
      "Iter 3243 | Time 31.4133(30.4925) | Bit/dim 1.1068(1.1079) | Xent 0.0395(0.0392) | Loss 1.1266(1.1275) | Error 0.0111(0.0122) Steps 428(426.87) | Grad Norm 0.1971(0.3512) | Total Time 10.00(10.00)\n",
      "Iter 3244 | Time 30.9718(30.5068) | Bit/dim 1.1124(1.1080) | Xent 0.0350(0.0391) | Loss 1.1299(1.1275) | Error 0.0106(0.0121) Steps 434(427.08) | Grad Norm 0.2634(0.3485) | Total Time 10.00(10.00)\n",
      "Iter 3245 | Time 30.3551(30.5023) | Bit/dim 1.1040(1.1079) | Xent 0.0358(0.0390) | Loss 1.1219(1.1274) | Error 0.0119(0.0121) Steps 428(427.11) | Grad Norm 0.4129(0.3505) | Total Time 10.00(10.00)\n",
      "Iter 3246 | Time 29.0272(30.4580) | Bit/dim 1.1083(1.1079) | Xent 0.0398(0.0390) | Loss 1.1282(1.1274) | Error 0.0128(0.0121) Steps 428(427.14) | Grad Norm 0.3797(0.3513) | Total Time 10.00(10.00)\n",
      "Iter 3247 | Time 31.1001(30.4773) | Bit/dim 1.1086(1.1079) | Xent 0.0408(0.0391) | Loss 1.1290(1.1274) | Error 0.0124(0.0121) Steps 422(426.98) | Grad Norm 0.3130(0.3502) | Total Time 10.00(10.00)\n",
      "Iter 3248 | Time 31.0931(30.4958) | Bit/dim 1.1092(1.1080) | Xent 0.0418(0.0392) | Loss 1.1301(1.1275) | Error 0.0121(0.0121) Steps 428(427.01) | Grad Norm 0.2024(0.3457) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 16.5479, Epoch Time 244.0220(237.6113), Bit/dim 1.1015(best: 1.1017), Xent 0.0259, Loss 1.1144, Error 0.0089(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3249 | Time 29.5841(30.4684) | Bit/dim 1.1079(1.1080) | Xent 0.0366(0.0391) | Loss 1.1262(1.1275) | Error 0.0109(0.0121) Steps 434(427.22) | Grad Norm 0.3117(0.3447) | Total Time 10.00(10.00)\n",
      "Iter 3250 | Time 30.9889(30.4840) | Bit/dim 1.1065(1.1079) | Xent 0.0405(0.0391) | Loss 1.1267(1.1275) | Error 0.0111(0.0121) Steps 434(427.43) | Grad Norm 0.4298(0.3473) | Total Time 10.00(10.00)\n",
      "Iter 3251 | Time 29.8595(30.4653) | Bit/dim 1.1081(1.1079) | Xent 0.0355(0.0390) | Loss 1.1259(1.1274) | Error 0.0109(0.0120) Steps 434(427.62) | Grad Norm 0.4017(0.3489) | Total Time 10.00(10.00)\n",
      "Iter 3252 | Time 29.7225(30.4430) | Bit/dim 1.1088(1.1079) | Xent 0.0362(0.0389) | Loss 1.1268(1.1274) | Error 0.0112(0.0120) Steps 434(427.82) | Grad Norm 0.5321(0.3544) | Total Time 10.00(10.00)\n",
      "Iter 3253 | Time 31.0081(30.4600) | Bit/dim 1.1071(1.1079) | Xent 0.0370(0.0389) | Loss 1.1255(1.1273) | Error 0.0114(0.0120) Steps 422(427.64) | Grad Norm 0.2349(0.3508) | Total Time 10.00(10.00)\n",
      "Iter 3254 | Time 30.6689(30.4662) | Bit/dim 1.1076(1.1079) | Xent 0.0386(0.0389) | Loss 1.1269(1.1273) | Error 0.0120(0.0120) Steps 428(427.65) | Grad Norm 0.2259(0.3471) | Total Time 10.00(10.00)\n",
      "Iter 3255 | Time 29.8160(30.4467) | Bit/dim 1.1077(1.1079) | Xent 0.0346(0.0387) | Loss 1.1250(1.1273) | Error 0.0111(0.0120) Steps 428(427.66) | Grad Norm 0.2417(0.3439) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 16.7376, Epoch Time 240.7871(237.7066), Bit/dim 1.1021(best: 1.1015), Xent 0.0262, Loss 1.1152, Error 0.0092(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3256 | Time 30.9641(30.4622) | Bit/dim 1.1115(1.1080) | Xent 0.0388(0.0387) | Loss 1.1309(1.1274) | Error 0.0116(0.0120) Steps 428(427.67) | Grad Norm 0.3247(0.3433) | Total Time 10.00(10.00)\n",
      "Iter 3257 | Time 30.6758(30.4687) | Bit/dim 1.1034(1.1079) | Xent 0.0430(0.0389) | Loss 1.1249(1.1273) | Error 0.0131(0.0120) Steps 428(427.68) | Grad Norm 0.3346(0.3431) | Total Time 10.00(10.00)\n",
      "Iter 3258 | Time 31.0046(30.4847) | Bit/dim 1.1126(1.1080) | Xent 0.0361(0.0388) | Loss 1.1306(1.1274) | Error 0.0115(0.0120) Steps 422(427.51) | Grad Norm 0.2686(0.3408) | Total Time 10.00(10.00)\n",
      "Iter 3259 | Time 30.6409(30.4894) | Bit/dim 1.1047(1.1079) | Xent 0.0404(0.0388) | Loss 1.1249(1.1273) | Error 0.0136(0.0120) Steps 428(427.53) | Grad Norm 0.3984(0.3426) | Total Time 10.00(10.00)\n",
      "Iter 3260 | Time 29.4203(30.4573) | Bit/dim 1.1051(1.1078) | Xent 0.0388(0.0388) | Loss 1.1245(1.1272) | Error 0.0119(0.0120) Steps 428(427.54) | Grad Norm 0.2609(0.3401) | Total Time 10.00(10.00)\n",
      "Iter 3261 | Time 30.4354(30.4567) | Bit/dim 1.1083(1.1078) | Xent 0.0399(0.0389) | Loss 1.1283(1.1273) | Error 0.0134(0.0121) Steps 428(427.55) | Grad Norm 0.2233(0.3366) | Total Time 10.00(10.00)\n",
      "Iter 3262 | Time 30.9744(30.4722) | Bit/dim 1.1090(1.1079) | Xent 0.0388(0.0389) | Loss 1.1284(1.1273) | Error 0.0124(0.0121) Steps 434(427.75) | Grad Norm 0.3038(0.3356) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 16.7855, Epoch Time 243.4285(237.8783), Bit/dim 1.1020(best: 1.1015), Xent 0.0288, Loss 1.1164, Error 0.0100(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3263 | Time 29.3944(30.4399) | Bit/dim 1.1127(1.1080) | Xent 0.0417(0.0389) | Loss 1.1335(1.1275) | Error 0.0122(0.0121) Steps 428(427.76) | Grad Norm 0.3462(0.3359) | Total Time 10.00(10.00)\n",
      "Iter 3264 | Time 29.2907(30.4054) | Bit/dim 1.1051(1.1079) | Xent 0.0391(0.0389) | Loss 1.1246(1.1274) | Error 0.0130(0.0121) Steps 434(427.94) | Grad Norm 0.2921(0.3346) | Total Time 10.00(10.00)\n",
      "Iter 3265 | Time 29.6300(30.3821) | Bit/dim 1.1042(1.1078) | Xent 0.0368(0.0389) | Loss 1.1227(1.1273) | Error 0.0119(0.0121) Steps 434(428.12) | Grad Norm 0.2630(0.3325) | Total Time 10.00(10.00)\n",
      "Iter 3266 | Time 29.4092(30.3530) | Bit/dim 1.1086(1.1078) | Xent 0.0345(0.0388) | Loss 1.1258(1.1272) | Error 0.0114(0.0121) Steps 428(428.12) | Grad Norm 0.4196(0.3351) | Total Time 10.00(10.00)\n",
      "Iter 3267 | Time 29.8679(30.3384) | Bit/dim 1.1100(1.1079) | Xent 0.0377(0.0387) | Loss 1.1289(1.1273) | Error 0.0112(0.0121) Steps 434(428.30) | Grad Norm 0.6109(0.3434) | Total Time 10.00(10.00)\n",
      "Iter 3268 | Time 29.3551(30.3089) | Bit/dim 1.1085(1.1079) | Xent 0.0406(0.0388) | Loss 1.1288(1.1273) | Error 0.0122(0.0121) Steps 434(428.47) | Grad Norm 0.1702(0.3382) | Total Time 10.00(10.00)\n",
      "Iter 3269 | Time 29.4937(30.2844) | Bit/dim 1.1047(1.1078) | Xent 0.0352(0.0387) | Loss 1.1223(1.1272) | Error 0.0114(0.0120) Steps 428(428.45) | Grad Norm 0.1997(0.3340) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 16.6349, Epoch Time 235.5282(237.8078), Bit/dim 1.1022(best: 1.1015), Xent 0.0286, Loss 1.1165, Error 0.0101(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3270 | Time 30.2775(30.2842) | Bit/dim 1.1054(1.1078) | Xent 0.0387(0.0387) | Loss 1.1248(1.1271) | Error 0.0108(0.0120) Steps 428(428.44) | Grad Norm 0.2628(0.3319) | Total Time 10.00(10.00)\n",
      "Iter 3271 | Time 29.7887(30.2694) | Bit/dim 1.1032(1.1076) | Xent 0.0381(0.0387) | Loss 1.1223(1.1269) | Error 0.0120(0.0120) Steps 428(428.43) | Grad Norm 0.3602(0.3327) | Total Time 10.00(10.00)\n",
      "Iter 3272 | Time 29.4788(30.2457) | Bit/dim 1.1069(1.1076) | Xent 0.0364(0.0386) | Loss 1.1251(1.1269) | Error 0.0112(0.0120) Steps 428(428.41) | Grad Norm 0.2549(0.3304) | Total Time 10.00(10.00)\n",
      "Iter 3273 | Time 32.0461(30.2997) | Bit/dim 1.1109(1.1077) | Xent 0.0343(0.0385) | Loss 1.1280(1.1269) | Error 0.0102(0.0119) Steps 428(428.40) | Grad Norm 0.3089(0.3298) | Total Time 10.00(10.00)\n",
      "Iter 3274 | Time 31.1747(30.3259) | Bit/dim 1.1131(1.1079) | Xent 0.0375(0.0384) | Loss 1.1319(1.1271) | Error 0.0114(0.0119) Steps 434(428.57) | Grad Norm 0.2491(0.3273) | Total Time 10.00(10.00)\n",
      "Iter 3275 | Time 31.3236(30.3559) | Bit/dim 1.1084(1.1079) | Xent 0.0388(0.0384) | Loss 1.1278(1.1271) | Error 0.0106(0.0119) Steps 428(428.55) | Grad Norm 0.4083(0.3298) | Total Time 10.00(10.00)\n",
      "Iter 3276 | Time 30.0846(30.3477) | Bit/dim 1.1058(1.1078) | Xent 0.0397(0.0385) | Loss 1.1256(1.1270) | Error 0.0125(0.0119) Steps 428(428.54) | Grad Norm 0.7140(0.3413) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 16.5769, Epoch Time 243.1382(237.9677), Bit/dim 1.1012(best: 1.1015), Xent 0.0258, Loss 1.1141, Error 0.0090(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3277 | Time 29.5067(30.3225) | Bit/dim 1.1061(1.1078) | Xent 0.0404(0.0385) | Loss 1.1263(1.1270) | Error 0.0124(0.0119) Steps 440(428.88) | Grad Norm 0.4546(0.3447) | Total Time 10.00(10.00)\n",
      "Iter 3278 | Time 29.2202(30.2894) | Bit/dim 1.1085(1.1078) | Xent 0.0424(0.0387) | Loss 1.1297(1.1271) | Error 0.0125(0.0119) Steps 434(429.03) | Grad Norm 0.6078(0.3526) | Total Time 10.00(10.00)\n",
      "Iter 3279 | Time 29.3525(30.2613) | Bit/dim 1.1089(1.1078) | Xent 0.0382(0.0386) | Loss 1.1280(1.1271) | Error 0.0108(0.0119) Steps 428(429.00) | Grad Norm 0.1851(0.3476) | Total Time 10.00(10.00)\n",
      "Iter 3280 | Time 29.3544(30.2341) | Bit/dim 1.1098(1.1079) | Xent 0.0382(0.0386) | Loss 1.1289(1.1272) | Error 0.0124(0.0119) Steps 428(428.97) | Grad Norm 0.2572(0.3448) | Total Time 10.00(10.00)\n",
      "Iter 3281 | Time 30.9919(30.2568) | Bit/dim 1.1092(1.1079) | Xent 0.0355(0.0385) | Loss 1.1270(1.1272) | Error 0.0099(0.0118) Steps 428(428.94) | Grad Norm 0.2765(0.3428) | Total Time 10.00(10.00)\n",
      "Iter 3282 | Time 30.7057(30.2703) | Bit/dim 1.1080(1.1079) | Xent 0.0375(0.0385) | Loss 1.1267(1.1272) | Error 0.0126(0.0119) Steps 434(429.10) | Grad Norm 0.3928(0.3443) | Total Time 10.00(10.00)\n",
      "Iter 3283 | Time 29.6678(30.2522) | Bit/dim 1.1025(1.1078) | Xent 0.0328(0.0383) | Loss 1.1189(1.1269) | Error 0.0108(0.0118) Steps 428(429.06) | Grad Norm 0.3259(0.3437) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 16.6626, Epoch Time 237.9716(237.9678), Bit/dim 1.1013(best: 1.1012), Xent 0.0265, Loss 1.1146, Error 0.0095(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3284 | Time 29.5982(30.2326) | Bit/dim 1.1060(1.1077) | Xent 0.0391(0.0384) | Loss 1.1255(1.1269) | Error 0.0129(0.0119) Steps 428(429.03) | Grad Norm 0.4942(0.3483) | Total Time 10.00(10.00)\n",
      "Iter 3285 | Time 29.4384(30.2088) | Bit/dim 1.1097(1.1078) | Xent 0.0392(0.0384) | Loss 1.1293(1.1269) | Error 0.0112(0.0118) Steps 440(429.36) | Grad Norm 0.2384(0.3450) | Total Time 10.00(10.00)\n",
      "Iter 3286 | Time 31.6772(30.2528) | Bit/dim 1.1090(1.1078) | Xent 0.0370(0.0383) | Loss 1.1275(1.1270) | Error 0.0121(0.0119) Steps 428(429.32) | Grad Norm 0.3178(0.3441) | Total Time 10.00(10.00)\n",
      "Iter 3287 | Time 29.9624(30.2441) | Bit/dim 1.1050(1.1077) | Xent 0.0445(0.0385) | Loss 1.1273(1.1270) | Error 0.0144(0.0119) Steps 428(429.28) | Grad Norm 0.3218(0.3435) | Total Time 10.00(10.00)\n",
      "Iter 3288 | Time 31.3102(30.2761) | Bit/dim 1.1078(1.1077) | Xent 0.0402(0.0386) | Loss 1.1279(1.1270) | Error 0.0111(0.0119) Steps 428(429.24) | Grad Norm 0.6232(0.3519) | Total Time 10.00(10.00)\n",
      "Iter 3289 | Time 29.1251(30.2416) | Bit/dim 1.1080(1.1077) | Xent 0.0352(0.0385) | Loss 1.1256(1.1270) | Error 0.0098(0.0118) Steps 428(429.20) | Grad Norm 0.3225(0.3510) | Total Time 10.00(10.00)\n",
      "Iter 3290 | Time 31.3150(30.2738) | Bit/dim 1.1050(1.1076) | Xent 0.0349(0.0384) | Loss 1.1225(1.1268) | Error 0.0100(0.0118) Steps 434(429.35) | Grad Norm 0.8468(0.3659) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 16.5218, Epoch Time 241.3421(238.0690), Bit/dim 1.1017(best: 1.1012), Xent 0.0282, Loss 1.1158, Error 0.0097(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3291 | Time 29.4157(30.2480) | Bit/dim 1.1047(1.1076) | Xent 0.0458(0.0386) | Loss 1.1276(1.1268) | Error 0.0132(0.0118) Steps 428(429.31) | Grad Norm 0.3650(0.3658) | Total Time 10.00(10.00)\n",
      "Iter 3292 | Time 29.7272(30.2324) | Bit/dim 1.1090(1.1076) | Xent 0.0353(0.0385) | Loss 1.1266(1.1268) | Error 0.0098(0.0118) Steps 434(429.45) | Grad Norm 0.3674(0.3659) | Total Time 10.00(10.00)\n",
      "Iter 3293 | Time 30.6459(30.2448) | Bit/dim 1.1104(1.1077) | Xent 0.0318(0.0383) | Loss 1.1263(1.1268) | Error 0.0101(0.0117) Steps 434(429.58) | Grad Norm 0.7798(0.3783) | Total Time 10.00(10.00)\n",
      "Iter 3294 | Time 30.5257(30.2532) | Bit/dim 1.1066(1.1076) | Xent 0.0418(0.0384) | Loss 1.1275(1.1268) | Error 0.0146(0.0118) Steps 428(429.54) | Grad Norm 0.8932(0.3937) | Total Time 10.00(10.00)\n",
      "Iter 3295 | Time 30.0823(30.2481) | Bit/dim 1.1103(1.1077) | Xent 0.0408(0.0385) | Loss 1.1307(1.1270) | Error 0.0124(0.0118) Steps 434(429.67) | Grad Norm 0.5799(0.3993) | Total Time 10.00(10.00)\n",
      "Iter 3296 | Time 29.2924(30.2194) | Bit/dim 1.1097(1.1078) | Xent 0.0363(0.0384) | Loss 1.1278(1.1270) | Error 0.0106(0.0118) Steps 428(429.62) | Grad Norm 1.1731(0.4225) | Total Time 10.00(10.00)\n",
      "Iter 3297 | Time 31.6730(30.2630) | Bit/dim 1.1021(1.1076) | Xent 0.0451(0.0386) | Loss 1.1247(1.1269) | Error 0.0142(0.0119) Steps 428(429.57) | Grad Norm 0.4425(0.4231) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 16.6417, Epoch Time 240.8147(238.1514), Bit/dim 1.1015(best: 1.1012), Xent 0.0300, Loss 1.1165, Error 0.0097(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3298 | Time 30.5557(30.2718) | Bit/dim 1.1061(1.1076) | Xent 0.0354(0.0385) | Loss 1.1238(1.1268) | Error 0.0122(0.0119) Steps 428(429.52) | Grad Norm 0.3479(0.4209) | Total Time 10.00(10.00)\n",
      "Iter 3299 | Time 30.0539(30.2653) | Bit/dim 1.1070(1.1076) | Xent 0.0396(0.0385) | Loss 1.1269(1.1268) | Error 0.0120(0.0119) Steps 428(429.48) | Grad Norm 0.5687(0.4253) | Total Time 10.00(10.00)\n",
      "Iter 3300 | Time 30.2236(30.2640) | Bit/dim 1.1066(1.1075) | Xent 0.0452(0.0387) | Loss 1.1292(1.1269) | Error 0.0140(0.0119) Steps 428(429.43) | Grad Norm 0.6653(0.4325) | Total Time 10.00(10.00)\n",
      "Iter 3301 | Time 29.0573(30.2278) | Bit/dim 1.1103(1.1076) | Xent 0.0315(0.0385) | Loss 1.1261(1.1269) | Error 0.0099(0.0119) Steps 428(429.39) | Grad Norm 0.2338(0.4266) | Total Time 10.00(10.00)\n",
      "Iter 3302 | Time 30.0582(30.2227) | Bit/dim 1.1055(1.1075) | Xent 0.0390(0.0385) | Loss 1.1250(1.1268) | Error 0.0122(0.0119) Steps 428(429.35) | Grad Norm 0.7605(0.4366) | Total Time 10.00(10.00)\n",
      "Iter 3303 | Time 30.4958(30.2309) | Bit/dim 1.1068(1.1075) | Xent 0.0386(0.0385) | Loss 1.1261(1.1268) | Error 0.0114(0.0119) Steps 428(429.31) | Grad Norm 0.7147(0.4449) | Total Time 10.00(10.00)\n",
      "Iter 3304 | Time 31.5070(30.2692) | Bit/dim 1.1088(1.1076) | Xent 0.0367(0.0385) | Loss 1.1271(1.1268) | Error 0.0118(0.0119) Steps 440(429.63) | Grad Norm 0.2558(0.4392) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 16.6893, Epoch Time 241.0498(238.2383), Bit/dim 1.1015(best: 1.1012), Xent 0.0255, Loss 1.1142, Error 0.0087(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3305 | Time 30.6080(30.2794) | Bit/dim 1.1053(1.1075) | Xent 0.0431(0.0386) | Loss 1.1269(1.1268) | Error 0.0142(0.0119) Steps 428(429.58) | Grad Norm 0.9895(0.4558) | Total Time 10.00(10.00)\n",
      "Iter 3306 | Time 30.9595(30.2998) | Bit/dim 1.1080(1.1075) | Xent 0.0347(0.0385) | Loss 1.1253(1.1268) | Error 0.0099(0.0119) Steps 434(429.71) | Grad Norm 0.3217(0.4517) | Total Time 10.00(10.00)\n",
      "Iter 3307 | Time 30.2108(30.2971) | Bit/dim 1.1097(1.1076) | Xent 0.0429(0.0386) | Loss 1.1311(1.1269) | Error 0.0128(0.0119) Steps 428(429.66) | Grad Norm 0.3206(0.4478) | Total Time 10.00(10.00)\n",
      "Iter 3308 | Time 31.2168(30.3247) | Bit/dim 1.1072(1.1076) | Xent 0.0383(0.0386) | Loss 1.1264(1.1269) | Error 0.0114(0.0119) Steps 428(429.61) | Grad Norm 0.6024(0.4524) | Total Time 10.00(10.00)\n",
      "Iter 3309 | Time 30.5793(30.3323) | Bit/dim 1.1068(1.1075) | Xent 0.0390(0.0386) | Loss 1.1263(1.1269) | Error 0.0118(0.0119) Steps 428(429.56) | Grad Norm 0.3815(0.4503) | Total Time 10.00(10.00)\n",
      "Iter 3310 | Time 29.4805(30.3068) | Bit/dim 1.1063(1.1075) | Xent 0.0368(0.0386) | Loss 1.1247(1.1268) | Error 0.0111(0.0119) Steps 428(429.52) | Grad Norm 0.3061(0.4460) | Total Time 10.00(10.00)\n",
      "Iter 3311 | Time 29.8990(30.2946) | Bit/dim 1.1107(1.1076) | Xent 0.0358(0.0385) | Loss 1.1286(1.1268) | Error 0.0119(0.0119) Steps 428(429.47) | Grad Norm 0.5602(0.4494) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 16.7824, Epoch Time 242.2868(238.3598), Bit/dim 1.1010(best: 1.1012), Xent 0.0281, Loss 1.1151, Error 0.0091(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3312 | Time 30.9659(30.3147) | Bit/dim 1.1124(1.1077) | Xent 0.0346(0.0384) | Loss 1.1297(1.1269) | Error 0.0102(0.0118) Steps 428(429.43) | Grad Norm 0.2999(0.4449) | Total Time 10.00(10.00)\n",
      "Iter 3313 | Time 29.4983(30.2902) | Bit/dim 1.1112(1.1078) | Xent 0.0352(0.0383) | Loss 1.1288(1.1270) | Error 0.0122(0.0118) Steps 428(429.38) | Grad Norm 0.4521(0.4451) | Total Time 10.00(10.00)\n",
      "Iter 3314 | Time 31.1845(30.3170) | Bit/dim 1.1057(1.1078) | Xent 0.0404(0.0384) | Loss 1.1259(1.1270) | Error 0.0128(0.0119) Steps 428(429.34) | Grad Norm 0.5138(0.4472) | Total Time 10.00(10.00)\n",
      "Iter 3315 | Time 29.7535(30.3001) | Bit/dim 1.1074(1.1078) | Xent 0.0314(0.0381) | Loss 1.1231(1.1268) | Error 0.0110(0.0118) Steps 428(429.30) | Grad Norm 0.3209(0.4434) | Total Time 10.00(10.00)\n",
      "Iter 3316 | Time 29.3834(30.2726) | Bit/dim 1.1047(1.1077) | Xent 0.0370(0.0381) | Loss 1.1232(1.1267) | Error 0.0115(0.0118) Steps 428(429.26) | Grad Norm 0.7310(0.4520) | Total Time 10.00(10.00)\n",
      "Iter 3317 | Time 29.8054(30.2586) | Bit/dim 1.1039(1.1076) | Xent 0.0402(0.0382) | Loss 1.1240(1.1267) | Error 0.0131(0.0119) Steps 428(429.23) | Grad Norm 0.4054(0.4506) | Total Time 10.00(10.00)\n",
      "Iter 3318 | Time 30.2905(30.2596) | Bit/dim 1.1082(1.1076) | Xent 0.0386(0.0382) | Loss 1.1276(1.1267) | Error 0.0116(0.0119) Steps 440(429.55) | Grad Norm 0.3383(0.4473) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 16.7166, Epoch Time 240.1797(238.4144), Bit/dim 1.1015(best: 1.1010), Xent 0.0287, Loss 1.1159, Error 0.0101(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3319 | Time 30.5111(30.2671) | Bit/dim 1.1074(1.1076) | Xent 0.0397(0.0382) | Loss 1.1273(1.1267) | Error 0.0122(0.0119) Steps 434(429.68) | Grad Norm 0.2404(0.4411) | Total Time 10.00(10.00)\n",
      "Iter 3320 | Time 30.3671(30.2701) | Bit/dim 1.1058(1.1075) | Xent 0.0377(0.0382) | Loss 1.1246(1.1266) | Error 0.0115(0.0119) Steps 440(429.99) | Grad Norm 0.4450(0.4412) | Total Time 10.00(10.00)\n",
      "Iter 3321 | Time 30.2447(30.2693) | Bit/dim 1.1060(1.1075) | Xent 0.0443(0.0384) | Loss 1.1282(1.1267) | Error 0.0139(0.0119) Steps 434(430.11) | Grad Norm 0.3113(0.4373) | Total Time 10.00(10.00)\n",
      "Iter 3322 | Time 29.6314(30.2502) | Bit/dim 1.1054(1.1074) | Xent 0.0396(0.0384) | Loss 1.1252(1.1266) | Error 0.0130(0.0119) Steps 422(429.87) | Grad Norm 0.2357(0.4312) | Total Time 10.00(10.00)\n",
      "Iter 3323 | Time 30.7063(30.2639) | Bit/dim 1.1114(1.1075) | Xent 0.0386(0.0384) | Loss 1.1307(1.1268) | Error 0.0114(0.0119) Steps 422(429.63) | Grad Norm 0.2147(0.4247) | Total Time 10.00(10.00)\n",
      "Iter 3324 | Time 29.7944(30.2498) | Bit/dim 1.1074(1.1075) | Xent 0.0391(0.0385) | Loss 1.1270(1.1268) | Error 0.0132(0.0120) Steps 434(429.76) | Grad Norm 0.6737(0.4322) | Total Time 10.00(10.00)\n",
      "Iter 3325 | Time 30.2694(30.2504) | Bit/dim 1.1055(1.1075) | Xent 0.0415(0.0385) | Loss 1.1263(1.1267) | Error 0.0118(0.0120) Steps 428(429.71) | Grad Norm 0.2683(0.4273) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 16.5476, Epoch Time 240.6124(238.4803), Bit/dim 1.1010(best: 1.1010), Xent 0.0276, Loss 1.1148, Error 0.0098(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3326 | Time 29.5835(30.2304) | Bit/dim 1.1142(1.1077) | Xent 0.0345(0.0384) | Loss 1.1314(1.1269) | Error 0.0120(0.0120) Steps 428(429.66) | Grad Norm 0.6766(0.4348) | Total Time 10.00(10.00)\n",
      "Iter 3327 | Time 30.2388(30.2306) | Bit/dim 1.1099(1.1077) | Xent 0.0376(0.0384) | Loss 1.1287(1.1269) | Error 0.0120(0.0120) Steps 428(429.61) | Grad Norm 0.5506(0.4382) | Total Time 10.00(10.00)\n",
      "Iter 3328 | Time 29.0079(30.1940) | Bit/dim 1.0998(1.1075) | Xent 0.0396(0.0384) | Loss 1.1196(1.1267) | Error 0.0111(0.0119) Steps 422(429.38) | Grad Norm 0.2728(0.4333) | Total Time 10.00(10.00)\n",
      "Iter 3329 | Time 31.1130(30.2215) | Bit/dim 1.1055(1.1074) | Xent 0.0360(0.0384) | Loss 1.1235(1.1266) | Error 0.0106(0.0119) Steps 434(429.52) | Grad Norm 0.2505(0.4278) | Total Time 10.00(10.00)\n",
      "Iter 3330 | Time 30.0390(30.2161) | Bit/dim 1.1072(1.1074) | Xent 0.0391(0.0384) | Loss 1.1268(1.1266) | Error 0.0111(0.0119) Steps 428(429.47) | Grad Norm 1.1035(0.4481) | Total Time 10.00(10.00)\n",
      "Iter 3331 | Time 30.6386(30.2287) | Bit/dim 1.1100(1.1075) | Xent 0.0424(0.0385) | Loss 1.1312(1.1268) | Error 0.0124(0.0119) Steps 434(429.61) | Grad Norm 0.2306(0.4415) | Total Time 10.00(10.00)\n",
      "Iter 3332 | Time 29.2097(30.1982) | Bit/dim 1.1066(1.1075) | Xent 0.0403(0.0386) | Loss 1.1268(1.1268) | Error 0.0125(0.0119) Steps 428(429.56) | Grad Norm 0.5370(0.4444) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 16.8210, Epoch Time 239.0235(238.4966), Bit/dim 1.1018(best: 1.1010), Xent 0.0300, Loss 1.1168, Error 0.0107(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3333 | Time 30.0751(30.1945) | Bit/dim 1.1031(1.1074) | Xent 0.0400(0.0386) | Loss 1.1231(1.1267) | Error 0.0129(0.0119) Steps 434(429.70) | Grad Norm 0.3038(0.4402) | Total Time 10.00(10.00)\n",
      "Iter 3334 | Time 29.6092(30.1769) | Bit/dim 1.1086(1.1074) | Xent 0.0374(0.0386) | Loss 1.1273(1.1267) | Error 0.0128(0.0120) Steps 428(429.64) | Grad Norm 0.1916(0.4327) | Total Time 10.00(10.00)\n",
      "Iter 3335 | Time 29.5257(30.1574) | Bit/dim 1.1110(1.1075) | Xent 0.0393(0.0386) | Loss 1.1307(1.1268) | Error 0.0126(0.0120) Steps 428(429.59) | Grad Norm 0.3113(0.4291) | Total Time 10.00(10.00)\n",
      "Iter 3336 | Time 31.0246(30.1834) | Bit/dim 1.1063(1.1075) | Xent 0.0379(0.0386) | Loss 1.1253(1.1267) | Error 0.0119(0.0120) Steps 434(429.73) | Grad Norm 0.3243(0.4259) | Total Time 10.00(10.00)\n",
      "Iter 3337 | Time 29.2207(30.1545) | Bit/dim 1.1083(1.1075) | Xent 0.0400(0.0386) | Loss 1.1283(1.1268) | Error 0.0110(0.0120) Steps 434(429.86) | Grad Norm 0.3612(0.4240) | Total Time 10.00(10.00)\n",
      "Iter 3338 | Time 29.3791(30.1312) | Bit/dim 1.1044(1.1074) | Xent 0.0393(0.0386) | Loss 1.1241(1.1267) | Error 0.0126(0.0120) Steps 434(429.98) | Grad Norm 0.2584(0.4190) | Total Time 10.00(10.00)\n",
      "Iter 3339 | Time 32.9605(30.2161) | Bit/dim 1.1101(1.1075) | Xent 0.0406(0.0387) | Loss 1.1304(1.1268) | Error 0.0124(0.0120) Steps 440(430.28) | Grad Norm 0.2531(0.4141) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 16.5753, Epoch Time 240.6531(238.5613), Bit/dim 1.1014(best: 1.1010), Xent 0.0275, Loss 1.1152, Error 0.0098(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3340 | Time 30.0247(30.2104) | Bit/dim 1.1102(1.1076) | Xent 0.0364(0.0386) | Loss 1.1285(1.1269) | Error 0.0106(0.0119) Steps 428(430.21) | Grad Norm 0.3811(0.4131) | Total Time 10.00(10.00)\n",
      "Iter 3341 | Time 30.0296(30.2050) | Bit/dim 1.1070(1.1075) | Xent 0.0327(0.0384) | Loss 1.1234(1.1268) | Error 0.0094(0.0119) Steps 428(430.15) | Grad Norm 0.2818(0.4091) | Total Time 10.00(10.00)\n",
      "Iter 3342 | Time 31.6992(30.2498) | Bit/dim 1.1091(1.1076) | Xent 0.0398(0.0385) | Loss 1.1290(1.1268) | Error 0.0122(0.0119) Steps 434(430.26) | Grad Norm 0.6715(0.4170) | Total Time 10.00(10.00)\n",
      "Iter 3343 | Time 29.6095(30.2306) | Bit/dim 1.1053(1.1075) | Xent 0.0341(0.0384) | Loss 1.1224(1.1267) | Error 0.0100(0.0118) Steps 428(430.19) | Grad Norm 0.1984(0.4104) | Total Time 10.00(10.00)\n",
      "Iter 3344 | Time 29.7467(30.2161) | Bit/dim 1.1053(1.1075) | Xent 0.0399(0.0384) | Loss 1.1252(1.1267) | Error 0.0121(0.0118) Steps 434(430.31) | Grad Norm 0.4418(0.4114) | Total Time 10.00(10.00)\n",
      "Iter 3345 | Time 30.2088(30.2158) | Bit/dim 1.1114(1.1076) | Xent 0.0439(0.0386) | Loss 1.1334(1.1269) | Error 0.0136(0.0119) Steps 434(430.42) | Grad Norm 0.3506(0.4096) | Total Time 10.00(10.00)\n",
      "Iter 3346 | Time 30.0886(30.2120) | Bit/dim 1.1014(1.1074) | Xent 0.0379(0.0385) | Loss 1.1204(1.1267) | Error 0.0119(0.0119) Steps 428(430.35) | Grad Norm 0.2524(0.4048) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 16.4128, Epoch Time 240.1220(238.6081), Bit/dim 1.1019(best: 1.1010), Xent 0.0289, Loss 1.1164, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3347 | Time 28.8757(30.1719) | Bit/dim 1.1012(1.1072) | Xent 0.0369(0.0385) | Loss 1.1197(1.1265) | Error 0.0119(0.0119) Steps 428(430.28) | Grad Norm 0.2083(0.3990) | Total Time 10.00(10.00)\n",
      "Iter 3348 | Time 29.5487(30.1532) | Bit/dim 1.1105(1.1073) | Xent 0.0384(0.0385) | Loss 1.1297(1.1266) | Error 0.0112(0.0119) Steps 428(430.21) | Grad Norm 0.2548(0.3946) | Total Time 10.00(10.00)\n",
      "Iter 3349 | Time 29.3675(30.1297) | Bit/dim 1.1115(1.1074) | Xent 0.0319(0.0383) | Loss 1.1274(1.1266) | Error 0.0096(0.0118) Steps 428(430.14) | Grad Norm 0.2154(0.3893) | Total Time 10.00(10.00)\n",
      "Iter 3350 | Time 29.9829(30.1253) | Bit/dim 1.1127(1.1076) | Xent 0.0370(0.0383) | Loss 1.1312(1.1267) | Error 0.0104(0.0118) Steps 428(430.08) | Grad Norm 0.4138(0.3900) | Total Time 10.00(10.00)\n",
      "Iter 3351 | Time 31.0528(30.1531) | Bit/dim 1.1009(1.1074) | Xent 0.0377(0.0382) | Loss 1.1198(1.1265) | Error 0.0116(0.0117) Steps 434(430.19) | Grad Norm 0.3016(0.3873) | Total Time 10.00(10.00)\n",
      "Iter 3352 | Time 30.6540(30.1681) | Bit/dim 1.1061(1.1074) | Xent 0.0436(0.0384) | Loss 1.1279(1.1266) | Error 0.0115(0.0117) Steps 440(430.49) | Grad Norm 0.2164(0.3822) | Total Time 10.00(10.00)\n",
      "Iter 3353 | Time 29.3032(30.1422) | Bit/dim 1.1061(1.1073) | Xent 0.0376(0.0384) | Loss 1.1249(1.1265) | Error 0.0132(0.0118) Steps 428(430.41) | Grad Norm 0.3843(0.3823) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 16.3357, Epoch Time 237.5942(238.5777), Bit/dim 1.1018(best: 1.1010), Xent 0.0287, Loss 1.1161, Error 0.0104(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3354 | Time 29.6830(30.1284) | Bit/dim 1.1035(1.1072) | Xent 0.0455(0.0386) | Loss 1.1262(1.1265) | Error 0.0139(0.0119) Steps 428(430.34) | Grad Norm 0.2746(0.3790) | Total Time 10.00(10.00)\n",
      "Iter 3355 | Time 29.7982(30.1185) | Bit/dim 1.1070(1.1072) | Xent 0.0420(0.0387) | Loss 1.1280(1.1265) | Error 0.0125(0.0119) Steps 428(430.27) | Grad Norm 0.3062(0.3769) | Total Time 10.00(10.00)\n",
      "Iter 3356 | Time 32.0066(30.1751) | Bit/dim 1.1045(1.1071) | Xent 0.0379(0.0387) | Loss 1.1234(1.1264) | Error 0.0114(0.0119) Steps 422(430.02) | Grad Norm 0.5453(0.3819) | Total Time 10.00(10.00)\n",
      "Iter 3357 | Time 29.7595(30.1627) | Bit/dim 1.1080(1.1071) | Xent 0.0400(0.0387) | Loss 1.1280(1.1265) | Error 0.0116(0.0118) Steps 428(429.96) | Grad Norm 0.1955(0.3763) | Total Time 10.00(10.00)\n",
      "Iter 3358 | Time 30.0508(30.1593) | Bit/dim 1.1107(1.1072) | Xent 0.0363(0.0386) | Loss 1.1288(1.1266) | Error 0.0108(0.0118) Steps 434(430.08) | Grad Norm 0.2893(0.3737) | Total Time 10.00(10.00)\n",
      "Iter 3359 | Time 29.3321(30.1345) | Bit/dim 1.1084(1.1073) | Xent 0.0384(0.0386) | Loss 1.1276(1.1266) | Error 0.0121(0.0118) Steps 434(430.20) | Grad Norm 0.4598(0.3763) | Total Time 10.00(10.00)\n",
      "Iter 3360 | Time 30.1779(30.1358) | Bit/dim 1.1066(1.1073) | Xent 0.0337(0.0385) | Loss 1.1234(1.1265) | Error 0.0115(0.0118) Steps 422(429.95) | Grad Norm 0.3587(0.3758) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 16.3563, Epoch Time 239.7971(238.6143), Bit/dim 1.1010(best: 1.1010), Xent 0.0269, Loss 1.1145, Error 0.0092(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3361 | Time 29.8412(30.1270) | Bit/dim 1.1064(1.1072) | Xent 0.0366(0.0384) | Loss 1.1247(1.1264) | Error 0.0112(0.0118) Steps 434(430.08) | Grad Norm 0.2712(0.3726) | Total Time 10.00(10.00)\n",
      "Iter 3362 | Time 29.5140(30.1086) | Bit/dim 1.1103(1.1073) | Xent 0.0379(0.0384) | Loss 1.1292(1.1265) | Error 0.0125(0.0118) Steps 434(430.19) | Grad Norm 0.2751(0.3697) | Total Time 10.00(10.00)\n",
      "Iter 3363 | Time 30.0460(30.1067) | Bit/dim 1.1058(1.1073) | Xent 0.0358(0.0383) | Loss 1.1237(1.1264) | Error 0.0114(0.0118) Steps 428(430.13) | Grad Norm 0.3622(0.3695) | Total Time 10.00(10.00)\n",
      "Iter 3364 | Time 30.6658(30.1235) | Bit/dim 1.1092(1.1073) | Xent 0.0439(0.0385) | Loss 1.1311(1.1266) | Error 0.0129(0.0118) Steps 428(430.06) | Grad Norm 0.5210(0.3740) | Total Time 10.00(10.00)\n",
      "Iter 3365 | Time 30.3430(30.1301) | Bit/dim 1.1062(1.1073) | Xent 0.0361(0.0384) | Loss 1.1243(1.1265) | Error 0.0114(0.0118) Steps 428(430.00) | Grad Norm 0.4581(0.3765) | Total Time 10.00(10.00)\n",
      "Iter 3366 | Time 31.3587(30.1669) | Bit/dim 1.1077(1.1073) | Xent 0.0380(0.0384) | Loss 1.1267(1.1265) | Error 0.0112(0.0118) Steps 428(429.94) | Grad Norm 0.4012(0.3773) | Total Time 10.00(10.00)\n",
      "Iter 3367 | Time 30.1836(30.1674) | Bit/dim 1.1043(1.1072) | Xent 0.0405(0.0385) | Loss 1.1246(1.1265) | Error 0.0120(0.0118) Steps 428(429.88) | Grad Norm 0.2902(0.3747) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 16.5611, Epoch Time 240.8441(238.6812), Bit/dim 1.1007(best: 1.1010), Xent 0.0269, Loss 1.1141, Error 0.0094(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3368 | Time 29.2635(30.1403) | Bit/dim 1.1057(1.1072) | Xent 0.0346(0.0384) | Loss 1.1230(1.1264) | Error 0.0102(0.0118) Steps 428(429.83) | Grad Norm 0.4592(0.3772) | Total Time 10.00(10.00)\n",
      "Iter 3369 | Time 29.3780(30.1174) | Bit/dim 1.1041(1.1071) | Xent 0.0339(0.0382) | Loss 1.1210(1.1262) | Error 0.0105(0.0117) Steps 428(429.77) | Grad Norm 0.4690(0.3800) | Total Time 10.00(10.00)\n",
      "Iter 3370 | Time 29.6114(30.1023) | Bit/dim 1.1052(1.1070) | Xent 0.0373(0.0382) | Loss 1.1238(1.1261) | Error 0.0120(0.0117) Steps 428(429.72) | Grad Norm 0.2376(0.3757) | Total Time 10.00(10.00)\n",
      "Iter 3371 | Time 31.1036(30.1323) | Bit/dim 1.1074(1.1070) | Xent 0.0411(0.0383) | Loss 1.1280(1.1262) | Error 0.0122(0.0118) Steps 428(429.67) | Grad Norm 0.7096(0.3857) | Total Time 10.00(10.00)\n",
      "Iter 3372 | Time 29.4006(30.1103) | Bit/dim 1.1074(1.1071) | Xent 0.0402(0.0383) | Loss 1.1275(1.1262) | Error 0.0118(0.0118) Steps 428(429.62) | Grad Norm 0.2191(0.3807) | Total Time 10.00(10.00)\n",
      "Iter 3373 | Time 30.4632(30.1209) | Bit/dim 1.1095(1.1071) | Xent 0.0392(0.0384) | Loss 1.1291(1.1263) | Error 0.0129(0.0118) Steps 440(429.93) | Grad Norm 0.3500(0.3798) | Total Time 10.00(10.00)\n",
      "Iter 3374 | Time 29.2144(30.0937) | Bit/dim 1.1052(1.1071) | Xent 0.0384(0.0384) | Loss 1.1244(1.1263) | Error 0.0116(0.0118) Steps 428(429.87) | Grad Norm 0.6442(0.3877) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 16.6883, Epoch Time 237.4064(238.6430), Bit/dim 1.1011(best: 1.1007), Xent 0.0277, Loss 1.1150, Error 0.0094(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3375 | Time 30.0242(30.0916) | Bit/dim 1.1015(1.1069) | Xent 0.0343(0.0382) | Loss 1.1186(1.1260) | Error 0.0102(0.0117) Steps 428(429.82) | Grad Norm 0.2549(0.3837) | Total Time 10.00(10.00)\n",
      "Iter 3376 | Time 29.4590(30.0727) | Bit/dim 1.1079(1.1069) | Xent 0.0363(0.0382) | Loss 1.1260(1.1260) | Error 0.0109(0.0117) Steps 434(429.94) | Grad Norm 0.3155(0.3817) | Total Time 10.00(10.00)\n",
      "Iter 3377 | Time 30.8473(30.0959) | Bit/dim 1.1083(1.1070) | Xent 0.0341(0.0381) | Loss 1.1254(1.1260) | Error 0.0109(0.0117) Steps 428(429.88) | Grad Norm 0.6096(0.3885) | Total Time 10.00(10.00)\n",
      "Iter 3378 | Time 29.4928(30.0778) | Bit/dim 1.1092(1.1070) | Xent 0.0348(0.0380) | Loss 1.1266(1.1260) | Error 0.0086(0.0116) Steps 428(429.83) | Grad Norm 0.4339(0.3899) | Total Time 10.00(10.00)\n",
      "Iter 3379 | Time 29.9014(30.0725) | Bit/dim 1.1092(1.1071) | Xent 0.0341(0.0379) | Loss 1.1263(1.1260) | Error 0.0112(0.0116) Steps 428(429.77) | Grad Norm 0.6303(0.3971) | Total Time 10.00(10.00)\n",
      "Iter 3380 | Time 29.4386(30.0535) | Bit/dim 1.1091(1.1072) | Xent 0.0433(0.0380) | Loss 1.1307(1.1262) | Error 0.0135(0.0116) Steps 434(429.90) | Grad Norm 0.3893(0.3969) | Total Time 10.00(10.00)\n",
      "Iter 3381 | Time 30.4983(30.0668) | Bit/dim 1.1073(1.1072) | Xent 0.0394(0.0381) | Loss 1.1270(1.1262) | Error 0.0139(0.0117) Steps 428(429.84) | Grad Norm 0.6262(0.4037) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 16.5011, Epoch Time 238.6125(238.6420), Bit/dim 1.1014(best: 1.1007), Xent 0.0248, Loss 1.1138, Error 0.0089(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3382 | Time 29.4938(30.0497) | Bit/dim 1.1052(1.1071) | Xent 0.0344(0.0380) | Loss 1.1224(1.1261) | Error 0.0101(0.0117) Steps 434(429.97) | Grad Norm 0.4069(0.4038) | Total Time 10.00(10.00)\n",
      "Iter 3383 | Time 29.7772(30.0415) | Bit/dim 1.1070(1.1071) | Xent 0.0319(0.0378) | Loss 1.1229(1.1260) | Error 0.0098(0.0116) Steps 428(429.91) | Grad Norm 0.2018(0.3978) | Total Time 10.00(10.00)\n",
      "Iter 3384 | Time 31.1441(30.0746) | Bit/dim 1.1042(1.1070) | Xent 0.0410(0.0379) | Loss 1.1247(1.1259) | Error 0.0111(0.0116) Steps 428(429.85) | Grad Norm 0.2630(0.3937) | Total Time 10.00(10.00)\n",
      "Iter 3385 | Time 29.6958(30.0632) | Bit/dim 1.1091(1.1071) | Xent 0.0372(0.0378) | Loss 1.1277(1.1260) | Error 0.0111(0.0116) Steps 428(429.79) | Grad Norm 0.1844(0.3875) | Total Time 10.00(10.00)\n",
      "Iter 3386 | Time 29.6370(30.0504) | Bit/dim 1.1075(1.1071) | Xent 0.0439(0.0380) | Loss 1.1294(1.1261) | Error 0.0145(0.0117) Steps 428(429.74) | Grad Norm 0.3648(0.3868) | Total Time 10.00(10.00)\n",
      "Iter 3387 | Time 30.0368(30.0500) | Bit/dim 1.1067(1.1071) | Xent 0.0366(0.0380) | Loss 1.1250(1.1261) | Error 0.0114(0.0117) Steps 428(429.69) | Grad Norm 0.2528(0.3828) | Total Time 10.00(10.00)\n",
      "Iter 3388 | Time 29.7916(30.0422) | Bit/dim 1.1056(1.1070) | Xent 0.0375(0.0380) | Loss 1.1243(1.1260) | Error 0.0116(0.0117) Steps 428(429.64) | Grad Norm 0.2102(0.3776) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 16.8412, Epoch Time 238.9055(238.6499), Bit/dim 1.1010(best: 1.1007), Xent 0.0285, Loss 1.1153, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3389 | Time 29.4035(30.0231) | Bit/dim 1.1093(1.1071) | Xent 0.0441(0.0382) | Loss 1.1313(1.1262) | Error 0.0129(0.0117) Steps 428(429.59) | Grad Norm 0.4251(0.3790) | Total Time 10.00(10.00)\n",
      "Iter 3390 | Time 29.7997(30.0164) | Bit/dim 1.1063(1.1071) | Xent 0.0423(0.0383) | Loss 1.1275(1.1262) | Error 0.0134(0.0117) Steps 428(429.54) | Grad Norm 0.6874(0.3883) | Total Time 10.00(10.00)\n",
      "Iter 3391 | Time 31.0876(30.0485) | Bit/dim 1.1005(1.1069) | Xent 0.0356(0.0382) | Loss 1.1182(1.1260) | Error 0.0106(0.0117) Steps 428(429.49) | Grad Norm 0.5530(0.3932) | Total Time 10.00(10.00)\n",
      "Iter 3392 | Time 29.8415(30.0423) | Bit/dim 1.1067(1.1069) | Xent 0.0356(0.0381) | Loss 1.1245(1.1259) | Error 0.0122(0.0117) Steps 434(429.63) | Grad Norm 0.5251(0.3972) | Total Time 10.00(10.00)\n",
      "Iter 3393 | Time 29.9487(30.0395) | Bit/dim 1.1078(1.1069) | Xent 0.0437(0.0383) | Loss 1.1296(1.1260) | Error 0.0135(0.0118) Steps 428(429.58) | Grad Norm 0.6365(0.4043) | Total Time 10.00(10.00)\n",
      "Iter 3394 | Time 30.7644(30.0612) | Bit/dim 1.1072(1.1069) | Xent 0.0379(0.0383) | Loss 1.1262(1.1260) | Error 0.0132(0.0118) Steps 434(429.71) | Grad Norm 0.3070(0.4014) | Total Time 10.00(10.00)\n",
      "Iter 3395 | Time 30.0146(30.0598) | Bit/dim 1.1075(1.1069) | Xent 0.0372(0.0382) | Loss 1.1261(1.1260) | Error 0.0104(0.0118) Steps 434(429.84) | Grad Norm 0.6023(0.4074) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 16.5974, Epoch Time 239.9740(238.6897), Bit/dim 1.1003(best: 1.1007), Xent 0.0284, Loss 1.1145, Error 0.0094(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3396 | Time 29.3275(30.0379) | Bit/dim 1.1097(1.1070) | Xent 0.0338(0.0381) | Loss 1.1266(1.1261) | Error 0.0105(0.0117) Steps 428(429.79) | Grad Norm 0.2202(0.4018) | Total Time 10.00(10.00)\n",
      "Iter 3397 | Time 30.4769(30.0510) | Bit/dim 1.1053(1.1070) | Xent 0.0368(0.0381) | Loss 1.1237(1.1260) | Error 0.0106(0.0117) Steps 428(429.73) | Grad Norm 0.2810(0.3982) | Total Time 10.00(10.00)\n",
      "Iter 3398 | Time 30.0124(30.0499) | Bit/dim 1.1060(1.1069) | Xent 0.0342(0.0380) | Loss 1.1231(1.1259) | Error 0.0119(0.0117) Steps 428(429.68) | Grad Norm 0.4149(0.3987) | Total Time 10.00(10.00)\n",
      "Iter 3399 | Time 30.6164(30.0669) | Bit/dim 1.1061(1.1069) | Xent 0.0404(0.0380) | Loss 1.1263(1.1259) | Error 0.0128(0.0117) Steps 428(429.63) | Grad Norm 0.4838(0.4013) | Total Time 10.00(10.00)\n",
      "Iter 3400 | Time 29.4215(30.0475) | Bit/dim 1.1053(1.1069) | Xent 0.0391(0.0381) | Loss 1.1249(1.1259) | Error 0.0114(0.0117) Steps 434(429.76) | Grad Norm 0.2376(0.3963) | Total Time 10.00(10.00)\n",
      "Iter 3401 | Time 29.4864(30.0307) | Bit/dim 1.1078(1.1069) | Xent 0.0420(0.0382) | Loss 1.1288(1.1260) | Error 0.0134(0.0118) Steps 428(429.71) | Grad Norm 0.6247(0.4032) | Total Time 10.00(10.00)\n",
      "Iter 3402 | Time 29.4409(30.0130) | Bit/dim 1.1090(1.1069) | Xent 0.0385(0.0382) | Loss 1.1283(1.1260) | Error 0.0134(0.0118) Steps 428(429.66) | Grad Norm 0.2665(0.3991) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 16.6413, Epoch Time 237.8247(238.6637), Bit/dim 1.1006(best: 1.1003), Xent 0.0268, Loss 1.1140, Error 0.0095(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3403 | Time 30.2766(30.0209) | Bit/dim 1.1046(1.1069) | Xent 0.0344(0.0381) | Loss 1.1218(1.1259) | Error 0.0111(0.0118) Steps 428(429.61) | Grad Norm 0.2687(0.3952) | Total Time 10.00(10.00)\n",
      "Iter 3404 | Time 30.9732(30.0495) | Bit/dim 1.1098(1.1070) | Xent 0.0392(0.0381) | Loss 1.1294(1.1260) | Error 0.0134(0.0119) Steps 428(429.56) | Grad Norm 0.3676(0.3944) | Total Time 10.00(10.00)\n",
      "Iter 3405 | Time 29.3132(30.0274) | Bit/dim 1.1046(1.1069) | Xent 0.0354(0.0380) | Loss 1.1223(1.1259) | Error 0.0118(0.0118) Steps 428(429.51) | Grad Norm 0.2117(0.3889) | Total Time 10.00(10.00)\n",
      "Iter 3406 | Time 29.4571(30.0103) | Bit/dim 1.1085(1.1069) | Xent 0.0398(0.0381) | Loss 1.1284(1.1260) | Error 0.0121(0.0119) Steps 428(429.47) | Grad Norm 0.2562(0.3849) | Total Time 10.00(10.00)\n",
      "Iter 3407 | Time 30.7391(30.0321) | Bit/dim 1.1067(1.1069) | Xent 0.0339(0.0380) | Loss 1.1236(1.1259) | Error 0.0118(0.0119) Steps 428(429.42) | Grad Norm 0.6413(0.3926) | Total Time 10.00(10.00)\n",
      "Iter 3408 | Time 29.9210(30.0288) | Bit/dim 1.1026(1.1068) | Xent 0.0340(0.0378) | Loss 1.1195(1.1257) | Error 0.0108(0.0118) Steps 434(429.56) | Grad Norm 0.2969(0.3897) | Total Time 10.00(10.00)\n",
      "Iter 3409 | Time 30.6719(30.0481) | Bit/dim 1.1085(1.1069) | Xent 0.0429(0.0380) | Loss 1.1299(1.1258) | Error 0.0125(0.0118) Steps 434(429.69) | Grad Norm 0.5856(0.3956) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 16.6016, Epoch Time 240.5790(238.7212), Bit/dim 1.1009(best: 1.1003), Xent 0.0283, Loss 1.1150, Error 0.0092(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3410 | Time 29.4751(30.0309) | Bit/dim 1.1081(1.1069) | Xent 0.0370(0.0380) | Loss 1.1265(1.1259) | Error 0.0118(0.0118) Steps 428(429.64) | Grad Norm 0.3844(0.3953) | Total Time 10.00(10.00)\n",
      "Iter 3411 | Time 29.2836(30.0085) | Bit/dim 1.1075(1.1069) | Xent 0.0405(0.0380) | Loss 1.1277(1.1259) | Error 0.0132(0.0119) Steps 434(429.77) | Grad Norm 0.2923(0.3922) | Total Time 10.00(10.00)\n",
      "Iter 3412 | Time 30.2399(30.0154) | Bit/dim 1.1056(1.1069) | Xent 0.0354(0.0380) | Loss 1.1233(1.1258) | Error 0.0101(0.0118) Steps 428(429.72) | Grad Norm 1.1295(0.4143) | Total Time 10.00(10.00)\n",
      "Iter 3413 | Time 31.4165(30.0575) | Bit/dim 1.1051(1.1068) | Xent 0.0361(0.0379) | Loss 1.1232(1.1258) | Error 0.0119(0.0118) Steps 428(429.67) | Grad Norm 0.2603(0.4097) | Total Time 10.00(10.00)\n",
      "Iter 3414 | Time 30.6948(30.0766) | Bit/dim 1.1058(1.1068) | Xent 0.0382(0.0379) | Loss 1.1249(1.1257) | Error 0.0109(0.0118) Steps 428(429.62) | Grad Norm 0.7968(0.4213) | Total Time 10.00(10.00)\n",
      "Iter 3415 | Time 31.0187(30.1048) | Bit/dim 1.1062(1.1068) | Xent 0.0385(0.0379) | Loss 1.1254(1.1257) | Error 0.0130(0.0118) Steps 428(429.57) | Grad Norm 0.8318(0.4336) | Total Time 10.00(10.00)\n",
      "Iter 3416 | Time 29.5800(30.0891) | Bit/dim 1.1060(1.1067) | Xent 0.0385(0.0379) | Loss 1.1253(1.1257) | Error 0.0124(0.0119) Steps 428(429.52) | Grad Norm 0.2769(0.4289) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 16.6670, Epoch Time 241.1321(238.7935), Bit/dim 1.1001(best: 1.1003), Xent 0.0299, Loss 1.1151, Error 0.0099(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3417 | Time 29.1972(30.0623) | Bit/dim 1.1046(1.1067) | Xent 0.0419(0.0381) | Loss 1.1256(1.1257) | Error 0.0126(0.0119) Steps 428(429.48) | Grad Norm 0.7205(0.4376) | Total Time 10.00(10.00)\n",
      "Iter 3418 | Time 30.4559(30.0741) | Bit/dim 1.1003(1.1065) | Xent 0.0312(0.0379) | Loss 1.1159(1.1254) | Error 0.0104(0.0118) Steps 428(429.43) | Grad Norm 0.6780(0.4449) | Total Time 10.00(10.00)\n",
      "Iter 3419 | Time 29.1989(30.0479) | Bit/dim 1.1105(1.1066) | Xent 0.0383(0.0379) | Loss 1.1297(1.1255) | Error 0.0111(0.0118) Steps 428(429.39) | Grad Norm 0.3590(0.4423) | Total Time 10.00(10.00)\n",
      "Iter 3420 | Time 30.5307(30.0624) | Bit/dim 1.1081(1.1067) | Xent 0.0340(0.0378) | Loss 1.1251(1.1255) | Error 0.0109(0.0118) Steps 428(429.35) | Grad Norm 0.6826(0.4495) | Total Time 10.00(10.00)\n",
      "Iter 3421 | Time 29.6916(30.0513) | Bit/dim 1.1100(1.1068) | Xent 0.0417(0.0379) | Loss 1.1308(1.1257) | Error 0.0129(0.0118) Steps 434(429.49) | Grad Norm 0.7561(0.4587) | Total Time 10.00(10.00)\n",
      "Iter 3422 | Time 29.3587(30.0305) | Bit/dim 1.1077(1.1068) | Xent 0.0390(0.0379) | Loss 1.1272(1.1257) | Error 0.0124(0.0118) Steps 428(429.44) | Grad Norm 0.3823(0.4564) | Total Time 10.00(10.00)\n",
      "Iter 3423 | Time 29.7293(30.0214) | Bit/dim 1.1075(1.1068) | Xent 0.0380(0.0379) | Loss 1.1265(1.1258) | Error 0.0121(0.0118) Steps 428(429.40) | Grad Norm 0.7255(0.4645) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 16.3962, Epoch Time 237.1905(238.7454), Bit/dim 1.1004(best: 1.1001), Xent 0.0269, Loss 1.1138, Error 0.0089(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3424 | Time 29.5022(30.0059) | Bit/dim 1.1045(1.1067) | Xent 0.0330(0.0378) | Loss 1.1210(1.1256) | Error 0.0100(0.0118) Steps 428(429.36) | Grad Norm 0.5148(0.4660) | Total Time 10.00(10.00)\n",
      "Iter 3425 | Time 29.5484(29.9921) | Bit/dim 1.1073(1.1068) | Xent 0.0382(0.0378) | Loss 1.1264(1.1256) | Error 0.0102(0.0117) Steps 428(429.32) | Grad Norm 0.5141(0.4674) | Total Time 10.00(10.00)\n",
      "Iter 3426 | Time 30.5604(30.0092) | Bit/dim 1.1067(1.1067) | Xent 0.0444(0.0380) | Loss 1.1289(1.1257) | Error 0.0128(0.0118) Steps 428(429.28) | Grad Norm 0.3593(0.4642) | Total Time 10.00(10.00)\n",
      "Iter 3427 | Time 29.8667(30.0049) | Bit/dim 1.1103(1.1069) | Xent 0.0431(0.0381) | Loss 1.1319(1.1259) | Error 0.0136(0.0118) Steps 428(429.24) | Grad Norm 0.8828(0.4767) | Total Time 10.00(10.00)\n",
      "Iter 3428 | Time 29.2212(29.9814) | Bit/dim 1.1060(1.1068) | Xent 0.0407(0.0382) | Loss 1.1264(1.1259) | Error 0.0118(0.0118) Steps 428(429.20) | Grad Norm 0.1914(0.4682) | Total Time 10.00(10.00)\n",
      "Iter 3429 | Time 29.3942(29.9638) | Bit/dim 1.1079(1.1069) | Xent 0.0412(0.0383) | Loss 1.1285(1.1260) | Error 0.0129(0.0119) Steps 428(429.17) | Grad Norm 0.2750(0.4624) | Total Time 10.00(10.00)\n",
      "Iter 3430 | Time 30.4095(29.9772) | Bit/dim 1.1047(1.1068) | Xent 0.0378(0.0383) | Loss 1.1236(1.1259) | Error 0.0100(0.0118) Steps 428(429.13) | Grad Norm 0.8172(0.4730) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 16.8984, Epoch Time 237.7841(238.7166), Bit/dim 1.1014(best: 1.1001), Xent 0.0276, Loss 1.1152, Error 0.0103(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3431 | Time 31.0352(30.0089) | Bit/dim 1.1043(1.1067) | Xent 0.0322(0.0381) | Loss 1.1204(1.1258) | Error 0.0100(0.0117) Steps 434(429.28) | Grad Norm 0.4069(0.4710) | Total Time 10.00(10.00)\n",
      "Iter 3432 | Time 29.7169(30.0001) | Bit/dim 1.1025(1.1066) | Xent 0.0382(0.0381) | Loss 1.1216(1.1256) | Error 0.0112(0.0117) Steps 428(429.24) | Grad Norm 0.3542(0.4675) | Total Time 10.00(10.00)\n",
      "Iter 3433 | Time 29.5205(29.9857) | Bit/dim 1.1057(1.1066) | Xent 0.0413(0.0382) | Loss 1.1263(1.1257) | Error 0.0134(0.0118) Steps 428(429.20) | Grad Norm 0.6633(0.4734) | Total Time 10.00(10.00)\n",
      "Iter 3434 | Time 29.9318(29.9841) | Bit/dim 1.1108(1.1067) | Xent 0.0353(0.0381) | Loss 1.1284(1.1258) | Error 0.0104(0.0117) Steps 428(429.17) | Grad Norm 0.2677(0.4672) | Total Time 10.00(10.00)\n",
      "Iter 3435 | Time 29.1370(29.9587) | Bit/dim 1.1063(1.1067) | Xent 0.0318(0.0379) | Loss 1.1222(1.1256) | Error 0.0090(0.0117) Steps 428(429.13) | Grad Norm 0.1907(0.4589) | Total Time 10.00(10.00)\n",
      "Iter 3436 | Time 29.5995(29.9479) | Bit/dim 1.1027(1.1066) | Xent 0.0472(0.0382) | Loss 1.1263(1.1257) | Error 0.0138(0.0117) Steps 428(429.10) | Grad Norm 0.4736(0.4594) | Total Time 10.00(10.00)\n",
      "Iter 3437 | Time 29.5083(29.9347) | Bit/dim 1.1096(1.1067) | Xent 0.0405(0.0383) | Loss 1.1299(1.1258) | Error 0.0131(0.0118) Steps 428(429.06) | Grad Norm 0.3144(0.4550) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 16.8038, Epoch Time 237.7702(238.6882), Bit/dim 1.1001(best: 1.1001), Xent 0.0282, Loss 1.1142, Error 0.0094(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3438 | Time 29.9448(29.9350) | Bit/dim 1.1059(1.1066) | Xent 0.0418(0.0384) | Loss 1.1268(1.1258) | Error 0.0138(0.0118) Steps 434(429.21) | Grad Norm 0.5171(0.4569) | Total Time 10.00(10.00)\n",
      "Iter 3439 | Time 29.2086(29.9133) | Bit/dim 1.1131(1.1068) | Xent 0.0406(0.0384) | Loss 1.1334(1.1260) | Error 0.0124(0.0118) Steps 428(429.18) | Grad Norm 0.2893(0.4519) | Total Time 10.00(10.00)\n",
      "Iter 3440 | Time 29.6260(29.9046) | Bit/dim 1.1050(1.1068) | Xent 0.0349(0.0383) | Loss 1.1225(1.1259) | Error 0.0120(0.0118) Steps 428(429.14) | Grad Norm 0.6876(0.4589) | Total Time 10.00(10.00)\n",
      "Iter 3441 | Time 31.1064(29.9407) | Bit/dim 1.1019(1.1066) | Xent 0.0346(0.0382) | Loss 1.1193(1.1257) | Error 0.0114(0.0118) Steps 428(429.11) | Grad Norm 0.5253(0.4609) | Total Time 10.00(10.00)\n",
      "Iter 3442 | Time 30.6580(29.9622) | Bit/dim 1.1064(1.1066) | Xent 0.0388(0.0382) | Loss 1.1257(1.1257) | Error 0.0122(0.0118) Steps 428(429.07) | Grad Norm 0.3724(0.4583) | Total Time 10.00(10.00)\n",
      "Iter 3443 | Time 31.0421(29.9946) | Bit/dim 1.1051(1.1066) | Xent 0.0378(0.0382) | Loss 1.1240(1.1257) | Error 0.0112(0.0118) Steps 434(429.22) | Grad Norm 0.9786(0.4739) | Total Time 10.00(10.00)\n",
      "Iter 3444 | Time 30.2082(30.0010) | Bit/dim 1.1063(1.1066) | Xent 0.0412(0.0383) | Loss 1.1269(1.1257) | Error 0.0128(0.0119) Steps 428(429.18) | Grad Norm 0.5022(0.4747) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 16.7401, Epoch Time 241.3497(238.7680), Bit/dim 1.1002(best: 1.1001), Xent 0.0300, Loss 1.1151, Error 0.0105(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3445 | Time 30.4078(30.0132) | Bit/dim 1.1064(1.1066) | Xent 0.0387(0.0383) | Loss 1.1258(1.1257) | Error 0.0112(0.0118) Steps 440(429.51) | Grad Norm 0.4825(0.4750) | Total Time 10.00(10.00)\n",
      "Iter 3446 | Time 29.6697(30.0029) | Bit/dim 1.1056(1.1065) | Xent 0.0386(0.0383) | Loss 1.1249(1.1257) | Error 0.0101(0.0118) Steps 428(429.46) | Grad Norm 0.7167(0.4822) | Total Time 10.00(10.00)\n",
      "Iter 3447 | Time 29.9672(30.0018) | Bit/dim 1.1076(1.1066) | Xent 0.0389(0.0384) | Loss 1.1270(1.1257) | Error 0.0122(0.0118) Steps 434(429.60) | Grad Norm 0.6651(0.4877) | Total Time 10.00(10.00)\n",
      "Iter 3448 | Time 30.0427(30.0031) | Bit/dim 1.1046(1.1065) | Xent 0.0424(0.0385) | Loss 1.1258(1.1257) | Error 0.0126(0.0118) Steps 434(429.73) | Grad Norm 0.2502(0.4806) | Total Time 10.00(10.00)\n",
      "Iter 3449 | Time 30.4893(30.0176) | Bit/dim 1.1047(1.1065) | Xent 0.0367(0.0384) | Loss 1.1230(1.1257) | Error 0.0108(0.0118) Steps 428(429.68) | Grad Norm 1.0409(0.4974) | Total Time 10.00(10.00)\n",
      "Iter 3450 | Time 29.3976(29.9990) | Bit/dim 1.1086(1.1065) | Xent 0.0341(0.0383) | Loss 1.1256(1.1257) | Error 0.0099(0.0117) Steps 434(429.81) | Grad Norm 0.7496(0.5050) | Total Time 10.00(10.00)\n",
      "Iter 3451 | Time 29.3887(29.9807) | Bit/dim 1.1064(1.1065) | Xent 0.0402(0.0384) | Loss 1.1266(1.1257) | Error 0.0115(0.0117) Steps 428(429.75) | Grad Norm 0.4230(0.5025) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 16.6839, Epoch Time 238.4828(238.7595), Bit/dim 1.1010(best: 1.1001), Xent 0.0276, Loss 1.1148, Error 0.0096(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3452 | Time 30.6191(29.9999) | Bit/dim 1.1083(1.1066) | Xent 0.0427(0.0385) | Loss 1.1296(1.1258) | Error 0.0135(0.0118) Steps 434(429.88) | Grad Norm 1.5675(0.5344) | Total Time 10.00(10.00)\n",
      "Iter 3453 | Time 29.9767(29.9992) | Bit/dim 1.1067(1.1066) | Xent 0.0336(0.0383) | Loss 1.1235(1.1257) | Error 0.0116(0.0118) Steps 434(430.01) | Grad Norm 0.4217(0.5311) | Total Time 10.00(10.00)\n",
      "Iter 3454 | Time 29.6445(29.9886) | Bit/dim 1.1078(1.1066) | Xent 0.0406(0.0384) | Loss 1.1281(1.1258) | Error 0.0125(0.0118) Steps 434(430.13) | Grad Norm 1.3257(0.5549) | Total Time 10.00(10.00)\n",
      "Iter 3455 | Time 29.3304(29.9688) | Bit/dim 1.1074(1.1066) | Xent 0.0343(0.0383) | Loss 1.1246(1.1258) | Error 0.0124(0.0118) Steps 428(430.06) | Grad Norm 1.0865(0.5709) | Total Time 10.00(10.00)\n",
      "Iter 3456 | Time 29.8418(29.9650) | Bit/dim 1.1052(1.1066) | Xent 0.0415(0.0384) | Loss 1.1259(1.1258) | Error 0.0134(0.0119) Steps 428(430.00) | Grad Norm 0.3850(0.5653) | Total Time 10.00(10.00)\n",
      "Iter 3457 | Time 29.4888(29.9507) | Bit/dim 1.1065(1.1066) | Xent 0.0412(0.0385) | Loss 1.1271(1.1258) | Error 0.0131(0.0119) Steps 428(429.94) | Grad Norm 1.0363(0.5794) | Total Time 10.00(10.00)\n",
      "Iter 3458 | Time 31.1740(29.9874) | Bit/dim 1.1068(1.1066) | Xent 0.0356(0.0384) | Loss 1.1246(1.1258) | Error 0.0108(0.0119) Steps 428(429.88) | Grad Norm 0.7091(0.5833) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 16.5995, Epoch Time 238.9543(238.7653), Bit/dim 1.1008(best: 1.1001), Xent 0.0290, Loss 1.1153, Error 0.0100(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3459 | Time 29.2992(29.9668) | Bit/dim 1.1042(1.1065) | Xent 0.0380(0.0384) | Loss 1.1232(1.1257) | Error 0.0111(0.0118) Steps 434(430.01) | Grad Norm 0.2162(0.5723) | Total Time 10.00(10.00)\n",
      "Iter 3460 | Time 29.7523(29.9603) | Bit/dim 1.1100(1.1066) | Xent 0.0405(0.0384) | Loss 1.1303(1.1258) | Error 0.0121(0.0118) Steps 428(429.95) | Grad Norm 0.9898(0.5848) | Total Time 10.00(10.00)\n",
      "Iter 3461 | Time 29.4170(29.9440) | Bit/dim 1.1054(1.1066) | Xent 0.0432(0.0386) | Loss 1.1270(1.1259) | Error 0.0146(0.0119) Steps 428(429.89) | Grad Norm 0.9478(0.5957) | Total Time 10.00(10.00)\n",
      "Iter 3462 | Time 29.6103(29.9340) | Bit/dim 1.1070(1.1066) | Xent 0.0376(0.0385) | Loss 1.1258(1.1259) | Error 0.0115(0.0119) Steps 428(429.83) | Grad Norm 0.3149(0.5873) | Total Time 10.00(10.00)\n",
      "Iter 3463 | Time 29.8570(29.9317) | Bit/dim 1.1057(1.1066) | Xent 0.0377(0.0385) | Loss 1.1245(1.1258) | Error 0.0118(0.0119) Steps 434(429.96) | Grad Norm 0.9124(0.5970) | Total Time 10.00(10.00)\n",
      "Iter 3464 | Time 29.9511(29.9323) | Bit/dim 1.1081(1.1066) | Xent 0.0428(0.0387) | Loss 1.1295(1.1259) | Error 0.0119(0.0119) Steps 434(430.08) | Grad Norm 0.9042(0.6062) | Total Time 10.00(10.00)\n",
      "Iter 3465 | Time 30.3701(29.9454) | Bit/dim 1.1088(1.1067) | Xent 0.0374(0.0386) | Loss 1.1275(1.1260) | Error 0.0106(0.0119) Steps 434(430.19) | Grad Norm 0.3478(0.5985) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 16.8573, Epoch Time 237.5546(238.7290), Bit/dim 1.1009(best: 1.1001), Xent 0.0274, Loss 1.1146, Error 0.0084(best: 0.0085)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3466 | Time 30.0358(29.9481) | Bit/dim 1.1064(1.1067) | Xent 0.0391(0.0386) | Loss 1.1260(1.1260) | Error 0.0110(0.0118) Steps 428(430.13) | Grad Norm 0.9872(0.6102) | Total Time 10.00(10.00)\n",
      "Iter 3467 | Time 29.3690(29.9308) | Bit/dim 1.1081(1.1067) | Xent 0.0403(0.0387) | Loss 1.1283(1.1261) | Error 0.0136(0.0119) Steps 428(430.06) | Grad Norm 0.2705(0.6000) | Total Time 10.00(10.00)\n",
      "Iter 3468 | Time 30.4238(29.9456) | Bit/dim 1.1031(1.1066) | Xent 0.0400(0.0387) | Loss 1.1231(1.1260) | Error 0.0122(0.0119) Steps 428(430.00) | Grad Norm 0.5065(0.5972) | Total Time 10.00(10.00)\n",
      "Iter 3469 | Time 29.5957(29.9351) | Bit/dim 1.1031(1.1065) | Xent 0.0373(0.0387) | Loss 1.1217(1.1258) | Error 0.0114(0.0119) Steps 428(429.94) | Grad Norm 0.8607(0.6051) | Total Time 10.00(10.00)\n",
      "Iter 3470 | Time 30.0730(29.9392) | Bit/dim 1.1046(1.1064) | Xent 0.0335(0.0385) | Loss 1.1213(1.1257) | Error 0.0110(0.0119) Steps 428(429.88) | Grad Norm 0.8326(0.6119) | Total Time 10.00(10.00)\n",
      "Iter 3471 | Time 30.4428(29.9543) | Bit/dim 1.1101(1.1066) | Xent 0.0311(0.0383) | Loss 1.1257(1.1257) | Error 0.0100(0.0118) Steps 434(430.01) | Grad Norm 0.2003(0.5995) | Total Time 10.00(10.00)\n",
      "Iter 3472 | Time 30.9041(29.9828) | Bit/dim 1.1100(1.1067) | Xent 0.0357(0.0382) | Loss 1.1278(1.1258) | Error 0.0111(0.0118) Steps 428(429.95) | Grad Norm 0.7205(0.6032) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 16.7840, Epoch Time 240.2640(238.7750), Bit/dim 1.1009(best: 1.1001), Xent 0.0303, Loss 1.1160, Error 0.0100(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3473 | Time 30.5321(29.9993) | Bit/dim 1.1052(1.1066) | Xent 0.0392(0.0382) | Loss 1.1248(1.1257) | Error 0.0132(0.0118) Steps 428(429.89) | Grad Norm 0.6820(0.6055) | Total Time 10.00(10.00)\n",
      "Iter 3474 | Time 29.2244(29.9760) | Bit/dim 1.1063(1.1066) | Xent 0.0469(0.0385) | Loss 1.1298(1.1259) | Error 0.0129(0.0119) Steps 428(429.83) | Grad Norm 0.2378(0.5945) | Total Time 10.00(10.00)\n",
      "Iter 3475 | Time 29.8545(29.9724) | Bit/dim 1.1069(1.1066) | Xent 0.0380(0.0385) | Loss 1.1259(1.1259) | Error 0.0124(0.0119) Steps 428(429.78) | Grad Norm 0.8555(0.6023) | Total Time 10.00(10.00)\n",
      "Iter 3476 | Time 30.7084(29.9945) | Bit/dim 1.1091(1.1067) | Xent 0.0338(0.0384) | Loss 1.1260(1.1259) | Error 0.0122(0.0119) Steps 428(429.72) | Grad Norm 0.5053(0.5994) | Total Time 10.00(10.00)\n",
      "Iter 3477 | Time 29.5723(29.9818) | Bit/dim 1.1107(1.1068) | Xent 0.0394(0.0384) | Loss 1.1304(1.1260) | Error 0.0105(0.0119) Steps 434(429.85) | Grad Norm 0.2300(0.5883) | Total Time 10.00(10.00)\n",
      "Iter 3478 | Time 30.4527(29.9959) | Bit/dim 1.1039(1.1067) | Xent 0.0402(0.0384) | Loss 1.1240(1.1259) | Error 0.0131(0.0119) Steps 428(429.80) | Grad Norm 0.5122(0.5861) | Total Time 10.00(10.00)\n",
      "Iter 3479 | Time 31.1783(30.0314) | Bit/dim 1.1064(1.1067) | Xent 0.0354(0.0383) | Loss 1.1240(1.1259) | Error 0.0111(0.0119) Steps 428(429.74) | Grad Norm 0.7703(0.5916) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 16.6963, Epoch Time 240.8946(238.8386), Bit/dim 1.1008(best: 1.1001), Xent 0.0266, Loss 1.1141, Error 0.0094(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3480 | Time 29.2348(30.0075) | Bit/dim 1.1065(1.1067) | Xent 0.0397(0.0384) | Loss 1.1263(1.1259) | Error 0.0128(0.0119) Steps 428(429.69) | Grad Norm 0.4744(0.5881) | Total Time 10.00(10.00)\n",
      "Iter 3481 | Time 30.0096(30.0076) | Bit/dim 1.1071(1.1067) | Xent 0.0391(0.0384) | Loss 1.1266(1.1259) | Error 0.0119(0.0119) Steps 428(429.64) | Grad Norm 0.1853(0.5760) | Total Time 10.00(10.00)\n",
      "Iter 3482 | Time 30.8795(30.0337) | Bit/dim 1.1082(1.1068) | Xent 0.0380(0.0384) | Loss 1.1272(1.1260) | Error 0.0118(0.0119) Steps 428(429.59) | Grad Norm 0.6404(0.5779) | Total Time 10.00(10.00)\n",
      "Iter 3483 | Time 31.4403(30.0759) | Bit/dim 1.1017(1.1066) | Xent 0.0353(0.0383) | Loss 1.1194(1.1258) | Error 0.0102(0.0118) Steps 428(429.54) | Grad Norm 0.5620(0.5774) | Total Time 10.00(10.00)\n",
      "Iter 3484 | Time 29.6448(30.0630) | Bit/dim 1.1061(1.1066) | Xent 0.0385(0.0383) | Loss 1.1254(1.1257) | Error 0.0104(0.0118) Steps 428(429.50) | Grad Norm 0.7406(0.5823) | Total Time 10.00(10.00)\n",
      "Iter 3485 | Time 29.6916(30.0518) | Bit/dim 1.1079(1.1066) | Xent 0.0351(0.0382) | Loss 1.1255(1.1257) | Error 0.0108(0.0118) Steps 428(429.45) | Grad Norm 0.7727(0.5880) | Total Time 10.00(10.00)\n",
      "Iter 3486 | Time 29.8714(30.0464) | Bit/dim 1.1083(1.1067) | Xent 0.0372(0.0382) | Loss 1.1269(1.1258) | Error 0.0114(0.0118) Steps 428(429.41) | Grad Norm 0.2028(0.5765) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 16.7302, Epoch Time 240.3027(238.8826), Bit/dim 1.1011(best: 1.1001), Xent 0.0279, Loss 1.1150, Error 0.0092(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3487 | Time 29.5259(30.0308) | Bit/dim 1.1087(1.1067) | Xent 0.0303(0.0379) | Loss 1.1239(1.1257) | Error 0.0086(0.0117) Steps 428(429.37) | Grad Norm 0.5464(0.5756) | Total Time 10.00(10.00)\n",
      "Iter 3488 | Time 30.6201(30.0485) | Bit/dim 1.1014(1.1066) | Xent 0.0417(0.0381) | Loss 1.1222(1.1256) | Error 0.0125(0.0117) Steps 434(429.51) | Grad Norm 0.8459(0.5837) | Total Time 10.00(10.00)\n",
      "Iter 3489 | Time 29.5701(30.0341) | Bit/dim 1.1039(1.1065) | Xent 0.0390(0.0381) | Loss 1.1234(1.1255) | Error 0.0121(0.0117) Steps 434(429.64) | Grad Norm 0.3476(0.5766) | Total Time 10.00(10.00)\n",
      "Iter 3490 | Time 30.2821(30.0416) | Bit/dim 1.1097(1.1066) | Xent 0.0395(0.0381) | Loss 1.1295(1.1257) | Error 0.0129(0.0117) Steps 428(429.59) | Grad Norm 0.6983(0.5803) | Total Time 10.00(10.00)\n",
      "Iter 3491 | Time 29.8418(30.0356) | Bit/dim 1.1062(1.1066) | Xent 0.0393(0.0382) | Loss 1.1258(1.1257) | Error 0.0134(0.0118) Steps 428(429.54) | Grad Norm 0.7382(0.5850) | Total Time 10.00(10.00)\n",
      "Iter 3492 | Time 29.8681(30.0306) | Bit/dim 1.1074(1.1066) | Xent 0.0394(0.0382) | Loss 1.1271(1.1257) | Error 0.0135(0.0118) Steps 428(429.50) | Grad Norm 0.3819(0.5789) | Total Time 10.00(10.00)\n",
      "Iter 3493 | Time 29.4689(30.0137) | Bit/dim 1.1082(1.1067) | Xent 0.0404(0.0383) | Loss 1.1284(1.1258) | Error 0.0128(0.0119) Steps 428(429.45) | Grad Norm 0.4584(0.5753) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 16.6129, Epoch Time 238.1671(238.8611), Bit/dim 1.1003(best: 1.1001), Xent 0.0263, Loss 1.1134, Error 0.0087(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3494 | Time 30.6517(30.0329) | Bit/dim 1.1102(1.1068) | Xent 0.0416(0.0384) | Loss 1.1310(1.1259) | Error 0.0114(0.0118) Steps 428(429.41) | Grad Norm 0.4334(0.5710) | Total Time 10.00(10.00)\n",
      "Iter 3495 | Time 30.5031(30.0470) | Bit/dim 1.1030(1.1067) | Xent 0.0341(0.0382) | Loss 1.1200(1.1258) | Error 0.0116(0.0118) Steps 428(429.37) | Grad Norm 0.3740(0.5651) | Total Time 10.00(10.00)\n",
      "Iter 3496 | Time 29.9830(30.0450) | Bit/dim 1.1105(1.1068) | Xent 0.0415(0.0383) | Loss 1.1313(1.1259) | Error 0.0144(0.0119) Steps 428(429.33) | Grad Norm 0.3882(0.5598) | Total Time 10.00(10.00)\n",
      "Iter 3497 | Time 30.8539(30.0693) | Bit/dim 1.1058(1.1067) | Xent 0.0437(0.0385) | Loss 1.1276(1.1260) | Error 0.0134(0.0120) Steps 428(429.29) | Grad Norm 0.5675(0.5600) | Total Time 10.00(10.00)\n",
      "Iter 3498 | Time 30.1122(30.0706) | Bit/dim 1.1044(1.1067) | Xent 0.0359(0.0384) | Loss 1.1223(1.1259) | Error 0.0129(0.0120) Steps 428(429.25) | Grad Norm 0.3487(0.5537) | Total Time 10.00(10.00)\n",
      "Iter 3499 | Time 29.9214(30.0661) | Bit/dim 1.1044(1.1066) | Xent 0.0375(0.0384) | Loss 1.1232(1.1258) | Error 0.0120(0.0120) Steps 434(429.39) | Grad Norm 0.4420(0.5504) | Total Time 10.00(10.00)\n",
      "Iter 3500 | Time 30.7142(30.0856) | Bit/dim 1.1070(1.1066) | Xent 0.0358(0.0383) | Loss 1.1249(1.1258) | Error 0.0121(0.0120) Steps 428(429.35) | Grad Norm 0.4372(0.5470) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 16.6386, Epoch Time 241.8960(238.9521), Bit/dim 1.1006(best: 1.1001), Xent 0.0285, Loss 1.1148, Error 0.0092(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3501 | Time 31.0004(30.1130) | Bit/dim 1.1018(1.1065) | Xent 0.0381(0.0383) | Loss 1.1208(1.1256) | Error 0.0126(0.0120) Steps 428(429.31) | Grad Norm 0.2834(0.5391) | Total Time 10.00(10.00)\n",
      "Iter 3502 | Time 29.7842(30.1031) | Bit/dim 1.1092(1.1066) | Xent 0.0367(0.0383) | Loss 1.1276(1.1257) | Error 0.0110(0.0120) Steps 428(429.27) | Grad Norm 0.4746(0.5371) | Total Time 10.00(10.00)\n",
      "Iter 3503 | Time 28.8896(30.0667) | Bit/dim 1.1073(1.1066) | Xent 0.0369(0.0382) | Loss 1.1257(1.1257) | Error 0.0114(0.0120) Steps 434(429.41) | Grad Norm 0.4625(0.5349) | Total Time 10.00(10.00)\n",
      "Iter 3504 | Time 29.3945(30.0466) | Bit/dim 1.1055(1.1065) | Xent 0.0348(0.0381) | Loss 1.1229(1.1256) | Error 0.0106(0.0119) Steps 428(429.37) | Grad Norm 0.3337(0.5288) | Total Time 10.00(10.00)\n",
      "Iter 3505 | Time 29.8835(30.0417) | Bit/dim 1.1052(1.1065) | Xent 0.0379(0.0381) | Loss 1.1241(1.1256) | Error 0.0121(0.0119) Steps 428(429.33) | Grad Norm 0.6381(0.5321) | Total Time 10.00(10.00)\n",
      "Iter 3506 | Time 29.8407(30.0356) | Bit/dim 1.1072(1.1065) | Xent 0.0373(0.0381) | Loss 1.1259(1.1256) | Error 0.0108(0.0119) Steps 428(429.29) | Grad Norm 0.2486(0.5236) | Total Time 10.00(10.00)\n",
      "Iter 3507 | Time 30.0271(30.0354) | Bit/dim 1.1089(1.1066) | Xent 0.0372(0.0381) | Loss 1.1276(1.1256) | Error 0.0102(0.0118) Steps 434(429.43) | Grad Norm 0.2632(0.5158) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0501 | Time 16.8122, Epoch Time 238.4166(238.9361), Bit/dim 1.1005(best: 1.1001), Xent 0.0282, Loss 1.1146, Error 0.0092(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3508 | Time 31.4008(30.0764) | Bit/dim 1.1060(1.1066) | Xent 0.0409(0.0381) | Loss 1.1265(1.1257) | Error 0.0128(0.0119) Steps 428(429.39) | Grad Norm 0.4305(0.5132) | Total Time 10.00(10.00)\n",
      "Iter 3509 | Time 29.1113(30.0474) | Bit/dim 1.1080(1.1066) | Xent 0.0339(0.0380) | Loss 1.1250(1.1256) | Error 0.0114(0.0119) Steps 428(429.34) | Grad Norm 0.3179(0.5074) | Total Time 10.00(10.00)\n",
      "Iter 3510 | Time 29.0285(30.0168) | Bit/dim 1.1058(1.1066) | Xent 0.0432(0.0382) | Loss 1.1274(1.1257) | Error 0.0130(0.0119) Steps 428(429.30) | Grad Norm 0.3496(0.5027) | Total Time 10.00(10.00)\n",
      "Iter 3511 | Time 29.3046(29.9955) | Bit/dim 1.1058(1.1066) | Xent 0.0341(0.0381) | Loss 1.1228(1.1256) | Error 0.0116(0.0119) Steps 428(429.26) | Grad Norm 0.3547(0.4982) | Total Time 10.00(10.00)\n",
      "Iter 3512 | Time 29.6591(29.9854) | Bit/dim 1.1071(1.1066) | Xent 0.0361(0.0380) | Loss 1.1252(1.1256) | Error 0.0108(0.0118) Steps 428(429.23) | Grad Norm 0.1945(0.4891) | Total Time 10.00(10.00)\n",
      "Iter 3513 | Time 29.0033(29.9559) | Bit/dim 1.1002(1.1064) | Xent 0.0365(0.0380) | Loss 1.1184(1.1254) | Error 0.0112(0.0118) Steps 428(429.19) | Grad Norm 0.3412(0.4847) | Total Time 10.00(10.00)\n",
      "Iter 3514 | Time 29.2936(29.9360) | Bit/dim 1.1096(1.1065) | Xent 0.0326(0.0378) | Loss 1.1260(1.1254) | Error 0.0096(0.0118) Steps 434(429.33) | Grad Norm 0.2533(0.4777) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0502 | Time 16.7998, Epoch Time 236.1422(238.8523), Bit/dim 1.1002(best: 1.1001), Xent 0.0278, Loss 1.1141, Error 0.0098(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3515 | Time 29.5738(29.9252) | Bit/dim 1.1042(1.1064) | Xent 0.0343(0.0377) | Loss 1.1213(1.1253) | Error 0.0094(0.0117) Steps 428(429.29) | Grad Norm 0.3245(0.4731) | Total Time 10.00(10.00)\n",
      "Iter 3516 | Time 29.6078(29.9157) | Bit/dim 1.1029(1.1063) | Xent 0.0373(0.0377) | Loss 1.1215(1.1252) | Error 0.0126(0.0117) Steps 428(429.26) | Grad Norm 0.3361(0.4690) | Total Time 10.00(10.00)\n",
      "Iter 3517 | Time 31.3518(29.9587) | Bit/dim 1.1085(1.1064) | Xent 0.0351(0.0376) | Loss 1.1260(1.1252) | Error 0.0118(0.0117) Steps 428(429.22) | Grad Norm 0.2059(0.4611) | Total Time 10.00(10.00)\n",
      "Iter 3518 | Time 29.2243(29.9367) | Bit/dim 1.1059(1.1064) | Xent 0.0431(0.0378) | Loss 1.1274(1.1252) | Error 0.0128(0.0118) Steps 434(429.36) | Grad Norm 0.2369(0.4544) | Total Time 10.00(10.00)\n",
      "Iter 3519 | Time 29.4746(29.9228) | Bit/dim 1.1100(1.1065) | Xent 0.0405(0.0378) | Loss 1.1303(1.1254) | Error 0.0124(0.0118) Steps 428(429.32) | Grad Norm 0.2942(0.4496) | Total Time 10.00(10.00)\n",
      "Iter 3520 | Time 30.0492(29.9266) | Bit/dim 1.1038(1.1064) | Xent 0.0399(0.0379) | Loss 1.1237(1.1253) | Error 0.0110(0.0117) Steps 428(429.28) | Grad Norm 0.2130(0.4425) | Total Time 10.00(10.00)\n",
      "Iter 3521 | Time 31.3036(29.9679) | Bit/dim 1.1089(1.1065) | Xent 0.0366(0.0379) | Loss 1.1272(1.1254) | Error 0.0111(0.0117) Steps 428(429.24) | Grad Norm 0.2575(0.4369) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0503 | Time 16.5805, Epoch Time 239.6542(238.8763), Bit/dim 1.1004(best: 1.1001), Xent 0.0284, Loss 1.1146, Error 0.0108(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3522 | Time 29.7263(29.9607) | Bit/dim 1.1031(1.1064) | Xent 0.0418(0.0380) | Loss 1.1240(1.1254) | Error 0.0126(0.0118) Steps 428(429.20) | Grad Norm 0.3410(0.4341) | Total Time 10.00(10.00)\n",
      "Iter 3523 | Time 30.2217(29.9685) | Bit/dim 1.0998(1.1062) | Xent 0.0355(0.0379) | Loss 1.1176(1.1251) | Error 0.0109(0.0117) Steps 428(429.17) | Grad Norm 0.3106(0.4304) | Total Time 10.00(10.00)\n",
      "Iter 3524 | Time 29.9664(29.9685) | Bit/dim 1.1075(1.1062) | Xent 0.0408(0.0380) | Loss 1.1279(1.1252) | Error 0.0115(0.0117) Steps 428(429.13) | Grad Norm 0.2028(0.4235) | Total Time 10.00(10.00)\n",
      "Iter 3525 | Time 28.9623(29.9383) | Bit/dim 1.1102(1.1063) | Xent 0.0420(0.0381) | Loss 1.1312(1.1254) | Error 0.0121(0.0117) Steps 428(429.10) | Grad Norm 0.4885(0.4255) | Total Time 10.00(10.00)\n",
      "Iter 3526 | Time 29.9219(29.9378) | Bit/dim 1.1075(1.1064) | Xent 0.0358(0.0380) | Loss 1.1254(1.1254) | Error 0.0106(0.0117) Steps 428(429.07) | Grad Norm 0.2974(0.4216) | Total Time 10.00(10.00)\n",
      "Iter 3527 | Time 29.1136(29.9131) | Bit/dim 1.1050(1.1063) | Xent 0.0417(0.0382) | Loss 1.1258(1.1254) | Error 0.0122(0.0117) Steps 428(429.03) | Grad Norm 0.6271(0.4278) | Total Time 10.00(10.00)\n",
      "Iter 3528 | Time 29.8478(29.9111) | Bit/dim 1.1104(1.1064) | Xent 0.0343(0.0380) | Loss 1.1275(1.1255) | Error 0.0110(0.0117) Steps 428(429.00) | Grad Norm 0.2559(0.4226) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0504 | Time 16.7060, Epoch Time 236.9774(238.8193), Bit/dim 1.1007(best: 1.1001), Xent 0.0298, Loss 1.1156, Error 0.0103(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3529 | Time 29.7732(29.9070) | Bit/dim 1.1097(1.1065) | Xent 0.0388(0.0381) | Loss 1.1291(1.1256) | Error 0.0109(0.0117) Steps 428(428.97) | Grad Norm 0.8137(0.4344) | Total Time 10.00(10.00)\n",
      "Iter 3530 | Time 30.6009(29.9278) | Bit/dim 1.1068(1.1065) | Xent 0.0366(0.0380) | Loss 1.1251(1.1256) | Error 0.0126(0.0117) Steps 440(429.30) | Grad Norm 0.2310(0.4283) | Total Time 10.00(10.00)\n",
      "Iter 3531 | Time 30.7783(29.9533) | Bit/dim 1.1049(1.1065) | Xent 0.0376(0.0380) | Loss 1.1237(1.1255) | Error 0.0114(0.0117) Steps 428(429.27) | Grad Norm 0.5059(0.4306) | Total Time 10.00(10.00)\n",
      "Iter 3532 | Time 30.6092(29.9730) | Bit/dim 1.0994(1.1063) | Xent 0.0291(0.0377) | Loss 1.1139(1.1252) | Error 0.0092(0.0116) Steps 428(429.23) | Grad Norm 0.4760(0.4320) | Total Time 10.00(10.00)\n",
      "Iter 3533 | Time 30.0570(29.9755) | Bit/dim 1.1068(1.1063) | Xent 0.0399(0.0378) | Loss 1.1268(1.1252) | Error 0.0122(0.0116) Steps 434(429.37) | Grad Norm 0.4080(0.4312) | Total Time 10.00(10.00)\n",
      "Iter 3534 | Time 31.0071(30.0064) | Bit/dim 1.1088(1.1064) | Xent 0.0411(0.0379) | Loss 1.1293(1.1253) | Error 0.0140(0.0117) Steps 428(429.33) | Grad Norm 0.6545(0.4379) | Total Time 10.00(10.00)\n",
      "Iter 3535 | Time 30.5859(30.0238) | Bit/dim 1.1020(1.1062) | Xent 0.0352(0.0378) | Loss 1.1196(1.1252) | Error 0.0111(0.0117) Steps 434(429.47) | Grad Norm 0.3770(0.4361) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0505 | Time 16.6045, Epoch Time 242.5447(238.9311), Bit/dim 1.1004(best: 1.1001), Xent 0.0278, Loss 1.1143, Error 0.0103(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3536 | Time 29.2954(30.0020) | Bit/dim 1.1082(1.1063) | Xent 0.0371(0.0378) | Loss 1.1267(1.1252) | Error 0.0118(0.0117) Steps 428(429.43) | Grad Norm 0.3221(0.4327) | Total Time 10.00(10.00)\n",
      "Iter 3537 | Time 29.7004(29.9929) | Bit/dim 1.1056(1.1063) | Xent 0.0381(0.0378) | Loss 1.1246(1.1252) | Error 0.0122(0.0117) Steps 428(429.38) | Grad Norm 0.3821(0.4312) | Total Time 10.00(10.00)\n",
      "Iter 3538 | Time 29.2412(29.9704) | Bit/dim 1.1024(1.1062) | Xent 0.0382(0.0378) | Loss 1.1215(1.1251) | Error 0.0105(0.0117) Steps 428(429.34) | Grad Norm 0.5723(0.4354) | Total Time 10.00(10.00)\n",
      "Iter 3539 | Time 30.5980(29.9892) | Bit/dim 1.1093(1.1063) | Xent 0.0416(0.0379) | Loss 1.1300(1.1252) | Error 0.0124(0.0117) Steps 428(429.30) | Grad Norm 0.7672(0.4454) | Total Time 10.00(10.00)\n",
      "Iter 3540 | Time 29.9130(29.9869) | Bit/dim 1.1018(1.1061) | Xent 0.0404(0.0380) | Loss 1.1221(1.1251) | Error 0.0114(0.0117) Steps 428(429.26) | Grad Norm 0.7993(0.4560) | Total Time 10.00(10.00)\n",
      "Iter 3541 | Time 29.1905(29.9630) | Bit/dim 1.1068(1.1061) | Xent 0.0388(0.0380) | Loss 1.1262(1.1252) | Error 0.0110(0.0117) Steps 434(429.40) | Grad Norm 0.5005(0.4573) | Total Time 10.00(10.00)\n",
      "Iter 3542 | Time 29.5027(29.9492) | Bit/dim 1.1048(1.1061) | Xent 0.0367(0.0380) | Loss 1.1232(1.1251) | Error 0.0122(0.0117) Steps 428(429.36) | Grad Norm 0.7462(0.4660) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0506 | Time 16.7751, Epoch Time 236.7864(238.8668), Bit/dim 1.0996(best: 1.1001), Xent 0.0274, Loss 1.1133, Error 0.0090(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3543 | Time 30.5257(29.9665) | Bit/dim 1.1025(1.1060) | Xent 0.0384(0.0380) | Loss 1.1217(1.1250) | Error 0.0128(0.0117) Steps 428(429.32) | Grad Norm 0.3045(0.4611) | Total Time 10.00(10.00)\n",
      "Iter 3544 | Time 30.6011(29.9855) | Bit/dim 1.1093(1.1061) | Xent 0.0396(0.0381) | Loss 1.1291(1.1251) | Error 0.0116(0.0117) Steps 428(429.28) | Grad Norm 0.4311(0.4602) | Total Time 10.00(10.00)\n",
      "Iter 3545 | Time 29.5266(29.9718) | Bit/dim 1.1089(1.1062) | Xent 0.0302(0.0378) | Loss 1.1240(1.1251) | Error 0.0096(0.0116) Steps 428(429.24) | Grad Norm 0.5996(0.4644) | Total Time 10.00(10.00)\n",
      "Iter 3546 | Time 29.4206(29.9552) | Bit/dim 1.1070(1.1062) | Xent 0.0374(0.0378) | Loss 1.1257(1.1251) | Error 0.0120(0.0117) Steps 428(429.21) | Grad Norm 0.5415(0.4667) | Total Time 10.00(10.00)\n",
      "Iter 3547 | Time 30.7509(29.9791) | Bit/dim 1.1062(1.1062) | Xent 0.0389(0.0378) | Loss 1.1257(1.1251) | Error 0.0122(0.0117) Steps 434(429.35) | Grad Norm 0.4482(0.4662) | Total Time 10.00(10.00)\n",
      "Iter 3548 | Time 29.7642(29.9727) | Bit/dim 1.1023(1.1061) | Xent 0.0330(0.0377) | Loss 1.1187(1.1249) | Error 0.0108(0.0116) Steps 434(429.49) | Grad Norm 0.2314(0.4591) | Total Time 10.00(10.00)\n",
      "Iter 3549 | Time 30.0245(29.9742) | Bit/dim 1.1093(1.1062) | Xent 0.0371(0.0377) | Loss 1.1279(1.1250) | Error 0.0124(0.0117) Steps 434(429.62) | Grad Norm 0.6441(0.4647) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0507 | Time 16.5265, Epoch Time 239.7689(238.8938), Bit/dim 1.1002(best: 1.0996), Xent 0.0313, Loss 1.1159, Error 0.0112(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3550 | Time 29.8058(29.9692) | Bit/dim 1.1051(1.1062) | Xent 0.0352(0.0376) | Loss 1.1227(1.1250) | Error 0.0098(0.0116) Steps 428(429.58) | Grad Norm 0.3830(0.4622) | Total Time 10.00(10.00)\n",
      "Iter 3551 | Time 29.4882(29.9547) | Bit/dim 1.1048(1.1061) | Xent 0.0401(0.0377) | Loss 1.1248(1.1249) | Error 0.0120(0.0116) Steps 428(429.53) | Grad Norm 0.2420(0.4556) | Total Time 10.00(10.00)\n",
      "Iter 3552 | Time 29.9750(29.9553) | Bit/dim 1.1030(1.1060) | Xent 0.0314(0.0375) | Loss 1.1187(1.1248) | Error 0.0101(0.0116) Steps 428(429.48) | Grad Norm 0.8145(0.4664) | Total Time 10.00(10.00)\n",
      "Iter 3553 | Time 29.2672(29.9347) | Bit/dim 1.1045(1.1060) | Xent 0.0365(0.0375) | Loss 1.1227(1.1247) | Error 0.0112(0.0116) Steps 428(429.44) | Grad Norm 0.3208(0.4620) | Total Time 10.00(10.00)\n",
      "Iter 3554 | Time 30.8384(29.9618) | Bit/dim 1.1044(1.1059) | Xent 0.0391(0.0375) | Loss 1.1240(1.1247) | Error 0.0116(0.0116) Steps 428(429.39) | Grad Norm 0.3065(0.4574) | Total Time 10.00(10.00)\n",
      "Iter 3555 | Time 29.8257(29.9577) | Bit/dim 1.1063(1.1059) | Xent 0.0423(0.0377) | Loss 1.1275(1.1248) | Error 0.0125(0.0116) Steps 428(429.35) | Grad Norm 0.7957(0.4675) | Total Time 10.00(10.00)\n",
      "Iter 3556 | Time 30.8897(29.9857) | Bit/dim 1.1094(1.1060) | Xent 0.0402(0.0377) | Loss 1.1295(1.1249) | Error 0.0118(0.0116) Steps 428(429.31) | Grad Norm 0.4397(0.4667) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0508 | Time 16.7239, Epoch Time 239.1425(238.9013), Bit/dim 1.1001(best: 1.0996), Xent 0.0283, Loss 1.1143, Error 0.0094(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3557 | Time 29.8118(29.9805) | Bit/dim 1.1098(1.1062) | Xent 0.0361(0.0377) | Loss 1.1278(1.1250) | Error 0.0110(0.0116) Steps 428(429.27) | Grad Norm 0.4983(0.4676) | Total Time 10.00(10.00)\n",
      "Iter 3558 | Time 31.4119(30.0234) | Bit/dim 1.1075(1.1062) | Xent 0.0391(0.0377) | Loss 1.1270(1.1251) | Error 0.0121(0.0116) Steps 428(429.23) | Grad Norm 0.8130(0.4780) | Total Time 10.00(10.00)\n",
      "Iter 3559 | Time 30.6114(30.0411) | Bit/dim 1.1019(1.1061) | Xent 0.0336(0.0376) | Loss 1.1187(1.1249) | Error 0.0094(0.0115) Steps 428(429.20) | Grad Norm 0.4153(0.4761) | Total Time 10.00(10.00)\n",
      "Iter 3560 | Time 29.4084(30.0221) | Bit/dim 1.1078(1.1061) | Xent 0.0376(0.0376) | Loss 1.1266(1.1249) | Error 0.0119(0.0115) Steps 428(429.16) | Grad Norm 0.4713(0.4760) | Total Time 10.00(10.00)\n",
      "Iter 3561 | Time 31.3479(30.0619) | Bit/dim 1.1062(1.1061) | Xent 0.0357(0.0375) | Loss 1.1240(1.1249) | Error 0.0118(0.0116) Steps 428(429.13) | Grad Norm 0.7075(0.4829) | Total Time 10.00(10.00)\n",
      "Iter 3562 | Time 30.9695(30.0891) | Bit/dim 1.1077(1.1062) | Xent 0.0451(0.0378) | Loss 1.1303(1.1251) | Error 0.0130(0.0116) Steps 428(429.09) | Grad Norm 0.5447(0.4848) | Total Time 10.00(10.00)\n",
      "Iter 3563 | Time 29.7288(30.0783) | Bit/dim 1.1031(1.1061) | Xent 0.0373(0.0378) | Loss 1.1217(1.1250) | Error 0.0119(0.0116) Steps 428(429.06) | Grad Norm 0.3425(0.4805) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0509 | Time 16.7166, Epoch Time 242.4605(239.0081), Bit/dim 1.1001(best: 1.0996), Xent 0.0291, Loss 1.1146, Error 0.0096(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3564 | Time 29.3841(30.0574) | Bit/dim 1.1048(1.1060) | Xent 0.0457(0.0380) | Loss 1.1276(1.1250) | Error 0.0136(0.0117) Steps 428(429.03) | Grad Norm 1.3590(0.5068) | Total Time 10.00(10.00)\n",
      "Iter 3565 | Time 29.4598(30.0395) | Bit/dim 1.1057(1.1060) | Xent 0.0361(0.0379) | Loss 1.1237(1.1250) | Error 0.0112(0.0117) Steps 434(429.18) | Grad Norm 0.2438(0.4990) | Total Time 10.00(10.00)\n",
      "Iter 3566 | Time 29.4339(30.0213) | Bit/dim 1.1029(1.1059) | Xent 0.0350(0.0378) | Loss 1.1204(1.1249) | Error 0.0120(0.0117) Steps 428(429.14) | Grad Norm 0.4434(0.4973) | Total Time 10.00(10.00)\n",
      "Iter 3567 | Time 29.7944(30.0145) | Bit/dim 1.1077(1.1060) | Xent 0.0342(0.0377) | Loss 1.1248(1.1249) | Error 0.0115(0.0117) Steps 428(429.11) | Grad Norm 1.0799(0.5148) | Total Time 10.00(10.00)\n",
      "Iter 3568 | Time 29.8306(30.0090) | Bit/dim 1.1073(1.1060) | Xent 0.0415(0.0379) | Loss 1.1280(1.1249) | Error 0.0129(0.0117) Steps 428(429.07) | Grad Norm 0.3479(0.5098) | Total Time 10.00(10.00)\n",
      "Iter 3569 | Time 31.0754(30.0410) | Bit/dim 1.1093(1.1061) | Xent 0.0382(0.0379) | Loss 1.1284(1.1251) | Error 0.0120(0.0117) Steps 428(429.04) | Grad Norm 0.6119(0.5128) | Total Time 10.00(10.00)\n",
      "Iter 3570 | Time 29.8243(30.0345) | Bit/dim 1.1039(1.1061) | Xent 0.0339(0.0377) | Loss 1.1209(1.1249) | Error 0.0105(0.0117) Steps 434(429.19) | Grad Norm 0.5295(0.5133) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0510 | Time 16.6554, Epoch Time 237.9759(238.9771), Bit/dim 1.0996(best: 1.0996), Xent 0.0263, Loss 1.1128, Error 0.0097(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3571 | Time 29.4837(30.0180) | Bit/dim 1.1025(1.1059) | Xent 0.0400(0.0378) | Loss 1.1225(1.1249) | Error 0.0119(0.0117) Steps 428(429.16) | Grad Norm 0.2723(0.5061) | Total Time 10.00(10.00)\n",
      "Iter 3572 | Time 29.6815(30.0079) | Bit/dim 1.1056(1.1059) | Xent 0.0312(0.0376) | Loss 1.1212(1.1247) | Error 0.0105(0.0116) Steps 428(429.12) | Grad Norm 0.3316(0.5009) | Total Time 10.00(10.00)\n",
      "Iter 3573 | Time 30.4677(30.0217) | Bit/dim 1.1050(1.1059) | Xent 0.0449(0.0378) | Loss 1.1274(1.1248) | Error 0.0149(0.0117) Steps 434(429.27) | Grad Norm 0.7166(0.5073) | Total Time 10.00(10.00)\n",
      "Iter 3574 | Time 30.9559(30.0497) | Bit/dim 1.1034(1.1058) | Xent 0.0402(0.0379) | Loss 1.1235(1.1248) | Error 0.0122(0.0117) Steps 428(429.23) | Grad Norm 0.3249(0.5019) | Total Time 10.00(10.00)\n",
      "Iter 3575 | Time 29.4207(30.0308) | Bit/dim 1.1075(1.1059) | Xent 0.0356(0.0378) | Loss 1.1252(1.1248) | Error 0.0116(0.0117) Steps 428(429.19) | Grad Norm 0.6393(0.5060) | Total Time 10.00(10.00)\n",
      "Iter 3576 | Time 31.3152(30.0694) | Bit/dim 1.1084(1.1060) | Xent 0.0375(0.0378) | Loss 1.1272(1.1249) | Error 0.0130(0.0118) Steps 428(429.16) | Grad Norm 0.3123(0.5002) | Total Time 10.00(10.00)\n",
      "Iter 3577 | Time 29.4662(30.0513) | Bit/dim 1.1097(1.1061) | Xent 0.0370(0.0378) | Loss 1.1282(1.1250) | Error 0.0109(0.0118) Steps 428(429.12) | Grad Norm 0.2989(0.4941) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0511 | Time 16.8175, Epoch Time 240.1334(239.0118), Bit/dim 1.1001(best: 1.0996), Xent 0.0304, Loss 1.1153, Error 0.0102(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3578 | Time 29.8839(30.0463) | Bit/dim 1.1054(1.1061) | Xent 0.0412(0.0379) | Loss 1.1260(1.1250) | Error 0.0119(0.0118) Steps 428(429.09) | Grad Norm 0.5888(0.4970) | Total Time 10.00(10.00)\n",
      "Iter 3579 | Time 29.9929(30.0447) | Bit/dim 1.1019(1.1059) | Xent 0.0384(0.0379) | Loss 1.1211(1.1249) | Error 0.0120(0.0118) Steps 428(429.06) | Grad Norm 0.2453(0.4894) | Total Time 10.00(10.00)\n",
      "Iter 3580 | Time 30.6524(30.0629) | Bit/dim 1.1009(1.1058) | Xent 0.0367(0.0379) | Loss 1.1193(1.1247) | Error 0.0116(0.0118) Steps 428(429.02) | Grad Norm 0.4878(0.4894) | Total Time 10.00(10.00)\n",
      "Iter 3581 | Time 29.5053(30.0462) | Bit/dim 1.1091(1.1059) | Xent 0.0341(0.0378) | Loss 1.1262(1.1248) | Error 0.0119(0.0118) Steps 428(428.99) | Grad Norm 0.4458(0.4881) | Total Time 10.00(10.00)\n",
      "Iter 3582 | Time 30.5649(30.0617) | Bit/dim 1.1093(1.1060) | Xent 0.0319(0.0376) | Loss 1.1253(1.1248) | Error 0.0100(0.0117) Steps 428(428.96) | Grad Norm 0.6872(0.4940) | Total Time 10.00(10.00)\n",
      "Iter 3583 | Time 30.8442(30.0852) | Bit/dim 1.1097(1.1061) | Xent 0.0361(0.0375) | Loss 1.1277(1.1249) | Error 0.0111(0.0117) Steps 428(428.93) | Grad Norm 0.3709(0.4903) | Total Time 10.00(10.00)\n",
      "Iter 3584 | Time 30.2341(30.0897) | Bit/dim 1.1023(1.1060) | Xent 0.0379(0.0376) | Loss 1.1212(1.1248) | Error 0.0110(0.0117) Steps 434(429.09) | Grad Norm 0.4470(0.4890) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0512 | Time 16.6657, Epoch Time 240.6585(239.0612), Bit/dim 1.0994(best: 1.0996), Xent 0.0256, Loss 1.1122, Error 0.0085(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3585 | Time 30.0247(30.0877) | Bit/dim 1.1014(1.1058) | Xent 0.0394(0.0376) | Loss 1.1211(1.1246) | Error 0.0121(0.0117) Steps 434(429.23) | Grad Norm 0.3710(0.4855) | Total Time 10.00(10.00)\n",
      "Iter 3586 | Time 30.4099(30.0974) | Bit/dim 1.1111(1.1060) | Xent 0.0422(0.0377) | Loss 1.1322(1.1249) | Error 0.0132(0.0117) Steps 428(429.20) | Grad Norm 0.4730(0.4851) | Total Time 10.00(10.00)\n",
      "Iter 3587 | Time 30.1861(30.1000) | Bit/dim 1.1057(1.1060) | Xent 0.0354(0.0377) | Loss 1.1234(1.1248) | Error 0.0121(0.0117) Steps 428(429.16) | Grad Norm 0.2652(0.4785) | Total Time 10.00(10.00)\n",
      "Iter 3588 | Time 30.0310(30.0980) | Bit/dim 1.1031(1.1059) | Xent 0.0385(0.0377) | Loss 1.1224(1.1248) | Error 0.0109(0.0117) Steps 434(429.31) | Grad Norm 0.4785(0.4785) | Total Time 10.00(10.00)\n",
      "Iter 3589 | Time 29.2299(30.0719) | Bit/dim 1.1059(1.1059) | Xent 0.0341(0.0376) | Loss 1.1229(1.1247) | Error 0.0118(0.0117) Steps 428(429.27) | Grad Norm 0.2809(0.4726) | Total Time 10.00(10.00)\n",
      "Iter 3590 | Time 29.6484(30.0592) | Bit/dim 1.1068(1.1059) | Xent 0.0420(0.0377) | Loss 1.1278(1.1248) | Error 0.0136(0.0118) Steps 428(429.23) | Grad Norm 0.4620(0.4723) | Total Time 10.00(10.00)\n",
      "Iter 3591 | Time 29.5885(30.0451) | Bit/dim 1.1076(1.1060) | Xent 0.0402(0.0378) | Loss 1.1277(1.1249) | Error 0.0136(0.0118) Steps 428(429.19) | Grad Norm 0.2982(0.4671) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0513 | Time 16.5522, Epoch Time 238.2095(239.0356), Bit/dim 1.0999(best: 1.0994), Xent 0.0291, Loss 1.1145, Error 0.0093(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3592 | Time 29.6162(30.0322) | Bit/dim 1.1055(1.1060) | Xent 0.0363(0.0378) | Loss 1.1236(1.1248) | Error 0.0110(0.0118) Steps 428(429.16) | Grad Norm 0.7192(0.4746) | Total Time 10.00(10.00)\n",
      "Iter 3593 | Time 29.7388(30.0234) | Bit/dim 1.1082(1.1060) | Xent 0.0358(0.0377) | Loss 1.1261(1.1249) | Error 0.0106(0.0118) Steps 428(429.12) | Grad Norm 0.3121(0.4697) | Total Time 10.00(10.00)\n",
      "Iter 3594 | Time 30.7502(30.0452) | Bit/dim 1.1015(1.1059) | Xent 0.0414(0.0378) | Loss 1.1222(1.1248) | Error 0.0124(0.0118) Steps 428(429.09) | Grad Norm 0.6394(0.4748) | Total Time 10.00(10.00)\n",
      "Iter 3595 | Time 29.2336(30.0209) | Bit/dim 1.1022(1.1058) | Xent 0.0382(0.0378) | Loss 1.1213(1.1247) | Error 0.0135(0.0118) Steps 428(429.06) | Grad Norm 0.6941(0.4814) | Total Time 10.00(10.00)\n",
      "Iter 3596 | Time 29.4342(30.0033) | Bit/dim 1.1084(1.1059) | Xent 0.0378(0.0378) | Loss 1.1273(1.1248) | Error 0.0116(0.0118) Steps 434(429.20) | Grad Norm 0.3586(0.4777) | Total Time 10.00(10.00)\n",
      "Iter 3597 | Time 29.1630(29.9781) | Bit/dim 1.1038(1.1058) | Xent 0.0424(0.0380) | Loss 1.1250(1.1248) | Error 0.0131(0.0119) Steps 428(429.17) | Grad Norm 0.6646(0.4833) | Total Time 10.00(10.00)\n",
      "Iter 3598 | Time 30.0409(29.9800) | Bit/dim 1.1053(1.1058) | Xent 0.0368(0.0379) | Loss 1.1237(1.1248) | Error 0.0115(0.0119) Steps 428(429.13) | Grad Norm 0.4380(0.4820) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0514 | Time 16.3469, Epoch Time 236.9096(238.9719), Bit/dim 1.0996(best: 1.0994), Xent 0.0281, Loss 1.1136, Error 0.0098(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3599 | Time 30.1342(29.9846) | Bit/dim 1.1017(1.1057) | Xent 0.0399(0.0380) | Loss 1.1217(1.1247) | Error 0.0122(0.0119) Steps 428(429.10) | Grad Norm 0.5666(0.4845) | Total Time 10.00(10.00)\n",
      "Iter 3600 | Time 29.5095(29.9703) | Bit/dim 1.1056(1.1057) | Xent 0.0360(0.0379) | Loss 1.1235(1.1246) | Error 0.0115(0.0119) Steps 428(429.07) | Grad Norm 0.5803(0.4874) | Total Time 10.00(10.00)\n",
      "Iter 3601 | Time 31.0479(30.0027) | Bit/dim 1.1059(1.1057) | Xent 0.0387(0.0379) | Loss 1.1252(1.1246) | Error 0.0111(0.0118) Steps 428(429.03) | Grad Norm 0.2993(0.4817) | Total Time 10.00(10.00)\n",
      "Iter 3602 | Time 29.4633(29.9865) | Bit/dim 1.1101(1.1058) | Xent 0.0327(0.0378) | Loss 1.1265(1.1247) | Error 0.0106(0.0118) Steps 428(429.00) | Grad Norm 0.6972(0.4882) | Total Time 10.00(10.00)\n",
      "Iter 3603 | Time 30.3100(29.9962) | Bit/dim 1.1018(1.1057) | Xent 0.0379(0.0378) | Loss 1.1207(1.1246) | Error 0.0098(0.0117) Steps 428(428.97) | Grad Norm 0.3422(0.4838) | Total Time 10.00(10.00)\n",
      "Iter 3604 | Time 29.9896(29.9960) | Bit/dim 1.1088(1.1058) | Xent 0.0366(0.0378) | Loss 1.1271(1.1247) | Error 0.0109(0.0117) Steps 428(428.94) | Grad Norm 0.4318(0.4823) | Total Time 10.00(10.00)\n",
      "Iter 3605 | Time 29.4941(29.9809) | Bit/dim 1.1077(1.1058) | Xent 0.0372(0.0377) | Loss 1.1264(1.1247) | Error 0.0104(0.0117) Steps 428(428.92) | Grad Norm 0.2527(0.4754) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0515 | Time 16.7294, Epoch Time 239.1498(238.9772), Bit/dim 1.0998(best: 1.0994), Xent 0.0305, Loss 1.1151, Error 0.0100(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3606 | Time 30.4308(29.9944) | Bit/dim 1.1060(1.1058) | Xent 0.0373(0.0377) | Loss 1.1247(1.1247) | Error 0.0129(0.0117) Steps 434(429.07) | Grad Norm 0.7162(0.4826) | Total Time 10.00(10.00)\n",
      "Iter 3607 | Time 29.4770(29.9789) | Bit/dim 1.1037(1.1058) | Xent 0.0386(0.0378) | Loss 1.1230(1.1247) | Error 0.0124(0.0117) Steps 428(429.04) | Grad Norm 0.1933(0.4739) | Total Time 10.00(10.00)\n",
      "Iter 3608 | Time 29.2865(29.9581) | Bit/dim 1.1034(1.1057) | Xent 0.0406(0.0378) | Loss 1.1237(1.1246) | Error 0.0119(0.0117) Steps 428(429.00) | Grad Norm 0.3289(0.4696) | Total Time 10.00(10.00)\n",
      "Iter 3609 | Time 30.1737(29.9646) | Bit/dim 1.1034(1.1056) | Xent 0.0367(0.0378) | Loss 1.1218(1.1245) | Error 0.0110(0.0117) Steps 428(428.97) | Grad Norm 0.2456(0.4629) | Total Time 10.00(10.00)\n",
      "Iter 3610 | Time 29.2124(29.9420) | Bit/dim 1.1036(1.1056) | Xent 0.0348(0.0377) | Loss 1.1210(1.1244) | Error 0.0110(0.0117) Steps 428(428.95) | Grad Norm 0.2163(0.4555) | Total Time 10.00(10.00)\n",
      "Iter 3611 | Time 31.2168(29.9803) | Bit/dim 1.1096(1.1057) | Xent 0.0408(0.0378) | Loss 1.1301(1.1246) | Error 0.0125(0.0117) Steps 428(428.92) | Grad Norm 0.2986(0.4508) | Total Time 10.00(10.00)\n",
      "Iter 3612 | Time 29.6670(29.9709) | Bit/dim 1.1043(1.1057) | Xent 0.0338(0.0377) | Loss 1.1212(1.1245) | Error 0.0104(0.0117) Steps 428(428.89) | Grad Norm 0.2118(0.4436) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0516 | Time 16.7251, Epoch Time 239.0891(238.9806), Bit/dim 1.1001(best: 1.0994), Xent 0.0287, Loss 1.1144, Error 0.0093(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3613 | Time 30.1695(29.9768) | Bit/dim 1.1089(1.1058) | Xent 0.0401(0.0378) | Loss 1.1290(1.1246) | Error 0.0122(0.0117) Steps 428(428.86) | Grad Norm 0.2500(0.4378) | Total Time 10.00(10.00)\n",
      "Iter 3614 | Time 30.0756(29.9798) | Bit/dim 1.1015(1.1056) | Xent 0.0338(0.0376) | Loss 1.1184(1.1244) | Error 0.0111(0.0117) Steps 428(428.84) | Grad Norm 0.3185(0.4342) | Total Time 10.00(10.00)\n",
      "Iter 3615 | Time 30.5682(29.9974) | Bit/dim 1.1109(1.1058) | Xent 0.0362(0.0376) | Loss 1.1290(1.1246) | Error 0.0102(0.0116) Steps 434(428.99) | Grad Norm 0.2089(0.4274) | Total Time 10.00(10.00)\n",
      "Iter 3616 | Time 29.6455(29.9869) | Bit/dim 1.1055(1.1058) | Xent 0.0379(0.0376) | Loss 1.1245(1.1246) | Error 0.0115(0.0116) Steps 428(428.96) | Grad Norm 0.2734(0.4228) | Total Time 10.00(10.00)\n",
      "Iter 3617 | Time 29.7843(29.9808) | Bit/dim 1.1048(1.1057) | Xent 0.0403(0.0377) | Loss 1.1250(1.1246) | Error 0.0115(0.0116) Steps 428(428.93) | Grad Norm 0.2120(0.4165) | Total Time 10.00(10.00)\n",
      "Iter 3618 | Time 29.4504(29.9649) | Bit/dim 1.1023(1.1056) | Xent 0.0404(0.0378) | Loss 1.1225(1.1245) | Error 0.0121(0.0116) Steps 428(428.91) | Grad Norm 0.2667(0.4120) | Total Time 10.00(10.00)\n",
      "Iter 3619 | Time 29.3337(29.9460) | Bit/dim 1.1063(1.1057) | Xent 0.0371(0.0377) | Loss 1.1249(1.1245) | Error 0.0125(0.0117) Steps 428(428.88) | Grad Norm 0.3056(0.4088) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0517 | Time 16.9052, Epoch Time 238.2969(238.9600), Bit/dim 1.0993(best: 1.0994), Xent 0.0313, Loss 1.1150, Error 0.0106(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3620 | Time 29.4737(29.9318) | Bit/dim 1.1046(1.1056) | Xent 0.0418(0.0379) | Loss 1.1255(1.1246) | Error 0.0112(0.0117) Steps 434(429.03) | Grad Norm 0.2139(0.4030) | Total Time 10.00(10.00)\n",
      "Iter 3621 | Time 29.4960(29.9187) | Bit/dim 1.1048(1.1056) | Xent 0.0369(0.0378) | Loss 1.1233(1.1245) | Error 0.0125(0.0117) Steps 428(429.00) | Grad Norm 0.2424(0.3981) | Total Time 10.00(10.00)\n",
      "Iter 3622 | Time 30.2074(29.9274) | Bit/dim 1.1059(1.1056) | Xent 0.0398(0.0379) | Loss 1.1258(1.1246) | Error 0.0128(0.0117) Steps 434(429.15) | Grad Norm 0.3259(0.3960) | Total Time 10.00(10.00)\n",
      "Iter 3623 | Time 28.9898(29.8993) | Bit/dim 1.1076(1.1057) | Xent 0.0367(0.0379) | Loss 1.1259(1.1246) | Error 0.0108(0.0117) Steps 428(429.12) | Grad Norm 0.2492(0.3916) | Total Time 10.00(10.00)\n",
      "Iter 3624 | Time 29.5607(29.8891) | Bit/dim 1.1046(1.1056) | Xent 0.0341(0.0378) | Loss 1.1217(1.1245) | Error 0.0104(0.0116) Steps 428(429.08) | Grad Norm 0.3328(0.3898) | Total Time 10.00(10.00)\n",
      "Iter 3625 | Time 29.3671(29.8734) | Bit/dim 1.1056(1.1056) | Xent 0.0367(0.0377) | Loss 1.1240(1.1245) | Error 0.0116(0.0116) Steps 428(429.05) | Grad Norm 0.3269(0.3879) | Total Time 10.00(10.00)\n",
      "Iter 3626 | Time 29.2283(29.8541) | Bit/dim 1.1077(1.1057) | Xent 0.0397(0.0378) | Loss 1.1276(1.1246) | Error 0.0125(0.0117) Steps 428(429.02) | Grad Norm 0.2511(0.3838) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0518 | Time 16.7395, Epoch Time 235.4582(238.8550), Bit/dim 1.1000(best: 1.0993), Xent 0.0292, Loss 1.1146, Error 0.0103(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3627 | Time 29.4591(29.8422) | Bit/dim 1.1058(1.1057) | Xent 0.0357(0.0377) | Loss 1.1236(1.1246) | Error 0.0108(0.0116) Steps 434(429.17) | Grad Norm 0.4802(0.3867) | Total Time 10.00(10.00)\n",
      "Iter 3628 | Time 29.7502(29.8395) | Bit/dim 1.1047(1.1057) | Xent 0.0359(0.0377) | Loss 1.1226(1.1245) | Error 0.0116(0.0116) Steps 434(429.31) | Grad Norm 0.2951(0.3840) | Total Time 10.00(10.00)\n",
      "Iter 3629 | Time 30.8998(29.8713) | Bit/dim 1.1047(1.1056) | Xent 0.0365(0.0376) | Loss 1.1229(1.1245) | Error 0.0111(0.0116) Steps 434(429.45) | Grad Norm 0.2576(0.3802) | Total Time 10.00(10.00)\n",
      "Iter 3630 | Time 30.9146(29.9026) | Bit/dim 1.1043(1.1056) | Xent 0.0456(0.0379) | Loss 1.1271(1.1245) | Error 0.0139(0.0117) Steps 428(429.41) | Grad Norm 0.3888(0.3804) | Total Time 10.00(10.00)\n",
      "Iter 3631 | Time 29.6220(29.8942) | Bit/dim 1.1070(1.1057) | Xent 0.0340(0.0378) | Loss 1.1240(1.1245) | Error 0.0105(0.0117) Steps 428(429.37) | Grad Norm 0.3104(0.3783) | Total Time 10.00(10.00)\n",
      "Iter 3632 | Time 29.4697(29.8814) | Bit/dim 1.1049(1.1056) | Xent 0.0354(0.0377) | Loss 1.1226(1.1245) | Error 0.0114(0.0116) Steps 434(429.51) | Grad Norm 0.4615(0.3808) | Total Time 10.00(10.00)\n",
      "Iter 3633 | Time 29.6825(29.8755) | Bit/dim 1.1071(1.1057) | Xent 0.0435(0.0379) | Loss 1.1289(1.1246) | Error 0.0144(0.0117) Steps 428(429.46) | Grad Norm 0.3725(0.3806) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0519 | Time 16.7103, Epoch Time 239.1018(238.8624), Bit/dim 1.0996(best: 1.0993), Xent 0.0276, Loss 1.1134, Error 0.0098(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3634 | Time 29.4208(29.8618) | Bit/dim 1.1096(1.1058) | Xent 0.0326(0.0377) | Loss 1.1260(1.1246) | Error 0.0099(0.0117) Steps 434(429.60) | Grad Norm 0.2108(0.3755) | Total Time 10.00(10.00)\n",
      "Iter 3635 | Time 30.2547(29.8736) | Bit/dim 1.1017(1.1057) | Xent 0.0354(0.0376) | Loss 1.1194(1.1245) | Error 0.0121(0.0117) Steps 428(429.55) | Grad Norm 0.3176(0.3737) | Total Time 10.00(10.00)\n",
      "Iter 3636 | Time 29.5332(29.8634) | Bit/dim 1.1007(1.1055) | Xent 0.0372(0.0376) | Loss 1.1193(1.1243) | Error 0.0118(0.0117) Steps 428(429.50) | Grad Norm 0.2189(0.3691) | Total Time 10.00(10.00)\n",
      "Iter 3637 | Time 29.5711(29.8546) | Bit/dim 1.1055(1.1055) | Xent 0.0426(0.0378) | Loss 1.1267(1.1244) | Error 0.0128(0.0117) Steps 428(429.46) | Grad Norm 0.4813(0.3725) | Total Time 10.00(10.00)\n",
      "Iter 3638 | Time 29.2298(29.8359) | Bit/dim 1.1019(1.1054) | Xent 0.0316(0.0376) | Loss 1.1177(1.1242) | Error 0.0110(0.0117) Steps 428(429.41) | Grad Norm 0.2273(0.3681) | Total Time 10.00(10.00)\n",
      "Iter 3639 | Time 29.1534(29.8154) | Bit/dim 1.1106(1.1056) | Xent 0.0319(0.0374) | Loss 1.1265(1.1243) | Error 0.0112(0.0117) Steps 428(429.37) | Grad Norm 0.4903(0.3718) | Total Time 10.00(10.00)\n",
      "Iter 3640 | Time 30.5534(29.8376) | Bit/dim 1.1060(1.1056) | Xent 0.0423(0.0376) | Loss 1.1271(1.1244) | Error 0.0122(0.0117) Steps 428(429.33) | Grad Norm 0.6433(0.3799) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0520 | Time 16.9491, Epoch Time 237.3256(238.8163), Bit/dim 1.0995(best: 1.0993), Xent 0.0283, Loss 1.1136, Error 0.0096(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3641 | Time 29.2632(29.8203) | Bit/dim 1.1089(1.1057) | Xent 0.0418(0.0377) | Loss 1.1298(1.1245) | Error 0.0138(0.0118) Steps 428(429.29) | Grad Norm 0.6364(0.3876) | Total Time 10.00(10.00)\n",
      "Iter 3642 | Time 29.5272(29.8115) | Bit/dim 1.1026(1.1056) | Xent 0.0391(0.0377) | Loss 1.1222(1.1244) | Error 0.0119(0.0118) Steps 428(429.25) | Grad Norm 0.7641(0.3989) | Total Time 10.00(10.00)\n",
      "Iter 3643 | Time 29.9355(29.8152) | Bit/dim 1.1053(1.1056) | Xent 0.0360(0.0377) | Loss 1.1233(1.1244) | Error 0.0112(0.0118) Steps 428(429.21) | Grad Norm 0.3048(0.3961) | Total Time 10.00(10.00)\n",
      "Iter 3644 | Time 29.5873(29.8084) | Bit/dim 1.1065(1.1056) | Xent 0.0333(0.0375) | Loss 1.1232(1.1244) | Error 0.0102(0.0117) Steps 428(429.18) | Grad Norm 0.8472(0.4096) | Total Time 10.00(10.00)\n",
      "Iter 3645 | Time 29.5367(29.8003) | Bit/dim 1.1028(1.1055) | Xent 0.0363(0.0375) | Loss 1.1210(1.1243) | Error 0.0125(0.0117) Steps 428(429.14) | Grad Norm 0.6296(0.4162) | Total Time 10.00(10.00)\n",
      "Iter 3646 | Time 29.3139(29.7857) | Bit/dim 1.1011(1.1054) | Xent 0.0377(0.0375) | Loss 1.1200(1.1241) | Error 0.0118(0.0117) Steps 428(429.11) | Grad Norm 0.5148(0.4192) | Total Time 10.00(10.00)\n",
      "Iter 3647 | Time 29.4661(29.7761) | Bit/dim 1.1094(1.1055) | Xent 0.0423(0.0377) | Loss 1.1305(1.1243) | Error 0.0125(0.0118) Steps 428(429.08) | Grad Norm 0.6254(0.4254) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0521 | Time 16.9399, Epoch Time 236.1307(238.7357), Bit/dim 1.0993(best: 1.0993), Xent 0.0283, Loss 1.1135, Error 0.0092(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3648 | Time 30.7120(29.8042) | Bit/dim 1.1061(1.1055) | Xent 0.0336(0.0375) | Loss 1.1229(1.1243) | Error 0.0099(0.0117) Steps 428(429.04) | Grad Norm 0.4544(0.4262) | Total Time 10.00(10.00)\n",
      "Iter 3649 | Time 30.9456(29.8384) | Bit/dim 1.1050(1.1055) | Xent 0.0350(0.0375) | Loss 1.1225(1.1242) | Error 0.0116(0.0117) Steps 434(429.19) | Grad Norm 0.8691(0.4395) | Total Time 10.00(10.00)\n",
      "Iter 3650 | Time 29.4705(29.8274) | Bit/dim 1.1053(1.1055) | Xent 0.0326(0.0373) | Loss 1.1216(1.1242) | Error 0.0122(0.0117) Steps 428(429.16) | Grad Norm 0.6030(0.4444) | Total Time 10.00(10.00)\n",
      "Iter 3651 | Time 29.1286(29.8064) | Bit/dim 1.1040(1.1055) | Xent 0.0377(0.0373) | Loss 1.1228(1.1241) | Error 0.0114(0.0117) Steps 428(429.12) | Grad Norm 0.2946(0.4399) | Total Time 10.00(10.00)\n",
      "Iter 3652 | Time 29.6675(29.8022) | Bit/dim 1.1073(1.1055) | Xent 0.0365(0.0373) | Loss 1.1255(1.1242) | Error 0.0118(0.0117) Steps 428(429.09) | Grad Norm 0.6554(0.4464) | Total Time 10.00(10.00)\n",
      "Iter 3653 | Time 29.1787(29.7835) | Bit/dim 1.1047(1.1055) | Xent 0.0387(0.0373) | Loss 1.1240(1.1242) | Error 0.0122(0.0117) Steps 428(429.06) | Grad Norm 0.4737(0.4472) | Total Time 10.00(10.00)\n",
      "Iter 3654 | Time 29.9032(29.7871) | Bit/dim 1.1015(1.1054) | Xent 0.0436(0.0375) | Loss 1.1234(1.1241) | Error 0.0126(0.0117) Steps 428(429.02) | Grad Norm 0.5363(0.4499) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0522 | Time 16.6131, Epoch Time 238.2751(238.7219), Bit/dim 1.0993(best: 1.0993), Xent 0.0281, Loss 1.1134, Error 0.0104(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3655 | Time 29.5011(29.7785) | Bit/dim 1.1053(1.1054) | Xent 0.0368(0.0375) | Loss 1.1237(1.1241) | Error 0.0112(0.0117) Steps 428(428.99) | Grad Norm 0.4742(0.4506) | Total Time 10.00(10.00)\n",
      "Iter 3656 | Time 31.0561(29.8169) | Bit/dim 1.1040(1.1053) | Xent 0.0369(0.0375) | Loss 1.1225(1.1241) | Error 0.0124(0.0118) Steps 428(428.96) | Grad Norm 0.3247(0.4468) | Total Time 10.00(10.00)\n",
      "Iter 3657 | Time 30.8724(29.8485) | Bit/dim 1.1047(1.1053) | Xent 0.0354(0.0374) | Loss 1.1224(1.1240) | Error 0.0116(0.0117) Steps 428(428.93) | Grad Norm 0.2955(0.4423) | Total Time 10.00(10.00)\n",
      "Iter 3658 | Time 29.9134(29.8505) | Bit/dim 1.1069(1.1054) | Xent 0.0362(0.0374) | Loss 1.1250(1.1241) | Error 0.0115(0.0117) Steps 428(428.91) | Grad Norm 0.2252(0.4358) | Total Time 10.00(10.00)\n",
      "Iter 3659 | Time 30.8734(29.8812) | Bit/dim 1.1060(1.1054) | Xent 0.0325(0.0372) | Loss 1.1223(1.1240) | Error 0.0101(0.0117) Steps 428(428.88) | Grad Norm 0.2642(0.4306) | Total Time 10.00(10.00)\n",
      "Iter 3660 | Time 29.4372(29.8678) | Bit/dim 1.1014(1.1053) | Xent 0.0445(0.0375) | Loss 1.1237(1.1240) | Error 0.0139(0.0118) Steps 428(428.85) | Grad Norm 0.2488(0.4252) | Total Time 10.00(10.00)\n",
      "Iter 3661 | Time 30.4366(29.8849) | Bit/dim 1.1062(1.1053) | Xent 0.0392(0.0375) | Loss 1.1258(1.1240) | Error 0.0122(0.0118) Steps 428(428.83) | Grad Norm 0.4145(0.4249) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0523 | Time 16.2858, Epoch Time 240.7534(238.7829), Bit/dim 1.0995(best: 1.0993), Xent 0.0284, Loss 1.1137, Error 0.0104(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3662 | Time 29.1670(29.8634) | Bit/dim 1.1063(1.1053) | Xent 0.0400(0.0376) | Loss 1.1263(1.1241) | Error 0.0118(0.0118) Steps 428(428.80) | Grad Norm 0.5403(0.4283) | Total Time 10.00(10.00)\n",
      "Iter 3663 | Time 29.4934(29.8523) | Bit/dim 1.1069(1.1054) | Xent 0.0329(0.0374) | Loss 1.1233(1.1241) | Error 0.0101(0.0117) Steps 428(428.78) | Grad Norm 0.4084(0.4277) | Total Time 10.00(10.00)\n",
      "Iter 3664 | Time 29.4900(29.8414) | Bit/dim 1.1002(1.1052) | Xent 0.0432(0.0376) | Loss 1.1218(1.1240) | Error 0.0125(0.0117) Steps 428(428.75) | Grad Norm 0.3424(0.4252) | Total Time 10.00(10.00)\n",
      "Iter 3665 | Time 30.0449(29.8475) | Bit/dim 1.1044(1.1052) | Xent 0.0362(0.0376) | Loss 1.1225(1.1240) | Error 0.0110(0.0117) Steps 428(428.73) | Grad Norm 0.5843(0.4299) | Total Time 10.00(10.00)\n",
      "Iter 3666 | Time 29.4986(29.8370) | Bit/dim 1.1063(1.1052) | Xent 0.0381(0.0376) | Loss 1.1254(1.1240) | Error 0.0120(0.0117) Steps 428(428.71) | Grad Norm 0.2878(0.4257) | Total Time 10.00(10.00)\n",
      "Iter 3667 | Time 30.2033(29.8480) | Bit/dim 1.1056(1.1052) | Xent 0.0336(0.0375) | Loss 1.1224(1.1240) | Error 0.0115(0.0117) Steps 428(428.69) | Grad Norm 0.6624(0.4328) | Total Time 10.00(10.00)\n",
      "Iter 3668 | Time 29.9255(29.8504) | Bit/dim 1.1054(1.1052) | Xent 0.0340(0.0374) | Loss 1.1224(1.1239) | Error 0.0108(0.0117) Steps 428(428.67) | Grad Norm 0.3012(0.4288) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0524 | Time 17.0759, Epoch Time 237.6667(238.7494), Bit/dim 1.0999(best: 1.0993), Xent 0.0286, Loss 1.1142, Error 0.0103(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3669 | Time 29.3190(29.8344) | Bit/dim 1.1051(1.1052) | Xent 0.0345(0.0373) | Loss 1.1224(1.1239) | Error 0.0106(0.0117) Steps 428(428.65) | Grad Norm 0.8389(0.4411) | Total Time 10.00(10.00)\n",
      "Iter 3670 | Time 29.7522(29.8319) | Bit/dim 1.1083(1.1053) | Xent 0.0385(0.0373) | Loss 1.1276(1.1240) | Error 0.0119(0.0117) Steps 428(428.63) | Grad Norm 0.2954(0.4368) | Total Time 10.00(10.00)\n",
      "Iter 3671 | Time 29.8342(29.8320) | Bit/dim 1.1067(1.1054) | Xent 0.0370(0.0373) | Loss 1.1252(1.1240) | Error 0.0112(0.0117) Steps 428(428.61) | Grad Norm 0.5830(0.4412) | Total Time 10.00(10.00)\n",
      "Iter 3672 | Time 29.8526(29.8326) | Bit/dim 1.0996(1.1052) | Xent 0.0356(0.0373) | Loss 1.1174(1.1238) | Error 0.0105(0.0116) Steps 428(428.59) | Grad Norm 0.3608(0.4387) | Total Time 10.00(10.00)\n",
      "Iter 3673 | Time 29.9526(29.8362) | Bit/dim 1.1052(1.1052) | Xent 0.0325(0.0371) | Loss 1.1215(1.1238) | Error 0.0095(0.0116) Steps 428(428.57) | Grad Norm 0.2797(0.4340) | Total Time 10.00(10.00)\n",
      "Iter 3674 | Time 30.9232(29.8688) | Bit/dim 1.1053(1.1052) | Xent 0.0431(0.0373) | Loss 1.1269(1.1238) | Error 0.0135(0.0116) Steps 428(428.56) | Grad Norm 0.3160(0.4304) | Total Time 10.00(10.00)\n",
      "Iter 3675 | Time 29.4757(29.8570) | Bit/dim 1.1029(1.1051) | Xent 0.0353(0.0372) | Loss 1.1205(1.1237) | Error 0.0124(0.0116) Steps 434(428.72) | Grad Norm 0.2113(0.4239) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0525 | Time 16.5059, Epoch Time 238.0901(238.7296), Bit/dim 1.0994(best: 1.0993), Xent 0.0287, Loss 1.1137, Error 0.0103(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3676 | Time 30.3598(29.8721) | Bit/dim 1.1031(1.1051) | Xent 0.0335(0.0371) | Loss 1.1199(1.1236) | Error 0.0119(0.0116) Steps 428(428.70) | Grad Norm 0.2647(0.4191) | Total Time 10.00(10.00)\n",
      "Iter 3677 | Time 29.8823(29.8724) | Bit/dim 1.1008(1.1049) | Xent 0.0420(0.0373) | Loss 1.1218(1.1236) | Error 0.0116(0.0116) Steps 428(428.68) | Grad Norm 0.2489(0.4140) | Total Time 10.00(10.00)\n",
      "Iter 3678 | Time 30.2409(29.8835) | Bit/dim 1.1028(1.1049) | Xent 0.0361(0.0372) | Loss 1.1209(1.1235) | Error 0.0119(0.0117) Steps 428(428.66) | Grad Norm 0.2516(0.4091) | Total Time 10.00(10.00)\n",
      "Iter 3679 | Time 29.6195(29.8756) | Bit/dim 1.1050(1.1049) | Xent 0.0379(0.0373) | Loss 1.1240(1.1235) | Error 0.0120(0.0117) Steps 428(428.64) | Grad Norm 0.2425(0.4041) | Total Time 10.00(10.00)\n",
      "Iter 3680 | Time 31.3452(29.9197) | Bit/dim 1.1069(1.1049) | Xent 0.0338(0.0372) | Loss 1.1238(1.1235) | Error 0.0114(0.0117) Steps 428(428.62) | Grad Norm 0.2488(0.3994) | Total Time 10.00(10.00)\n",
      "Iter 3681 | Time 29.5835(29.9096) | Bit/dim 1.1072(1.1050) | Xent 0.0330(0.0370) | Loss 1.1237(1.1235) | Error 0.0112(0.0116) Steps 428(428.60) | Grad Norm 0.2755(0.3957) | Total Time 10.00(10.00)\n",
      "Iter 3682 | Time 29.4230(29.8950) | Bit/dim 1.1098(1.1052) | Xent 0.0413(0.0372) | Loss 1.1304(1.1237) | Error 0.0141(0.0117) Steps 428(428.58) | Grad Norm 0.3553(0.3945) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0526 | Time 16.5260, Epoch Time 239.4415(238.7509), Bit/dim 1.0995(best: 1.0993), Xent 0.0272, Loss 1.1130, Error 0.0095(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3683 | Time 29.3098(29.8774) | Bit/dim 1.1029(1.1051) | Xent 0.0357(0.0371) | Loss 1.1207(1.1236) | Error 0.0122(0.0117) Steps 428(428.56) | Grad Norm 0.6394(0.4019) | Total Time 10.00(10.00)\n",
      "Iter 3684 | Time 29.5325(29.8671) | Bit/dim 1.1037(1.1050) | Xent 0.0361(0.0371) | Loss 1.1217(1.1236) | Error 0.0111(0.0117) Steps 428(428.55) | Grad Norm 0.4198(0.4024) | Total Time 10.00(10.00)\n",
      "Iter 3685 | Time 29.3449(29.8514) | Bit/dim 1.1026(1.1050) | Xent 0.0393(0.0371) | Loss 1.1223(1.1235) | Error 0.0121(0.0117) Steps 428(428.53) | Grad Norm 0.3728(0.4015) | Total Time 10.00(10.00)\n",
      "Iter 3686 | Time 30.3522(29.8664) | Bit/dim 1.1100(1.1051) | Xent 0.0357(0.0371) | Loss 1.1279(1.1237) | Error 0.0110(0.0117) Steps 428(428.51) | Grad Norm 0.6598(0.4093) | Total Time 10.00(10.00)\n",
      "Iter 3687 | Time 29.7116(29.8618) | Bit/dim 1.1048(1.1051) | Xent 0.0387(0.0372) | Loss 1.1241(1.1237) | Error 0.0131(0.0117) Steps 428(428.50) | Grad Norm 0.2265(0.4038) | Total Time 10.00(10.00)\n",
      "Iter 3688 | Time 29.8590(29.8617) | Bit/dim 1.1056(1.1051) | Xent 0.0386(0.0372) | Loss 1.1249(1.1237) | Error 0.0121(0.0118) Steps 428(428.48) | Grad Norm 0.4520(0.4052) | Total Time 10.00(10.00)\n",
      "Iter 3689 | Time 29.9432(29.8642) | Bit/dim 1.1057(1.1051) | Xent 0.0401(0.0373) | Loss 1.1257(1.1238) | Error 0.0130(0.0118) Steps 428(428.47) | Grad Norm 0.6878(0.4137) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0527 | Time 16.6325, Epoch Time 236.9738(238.6976), Bit/dim 1.0997(best: 1.0993), Xent 0.0291, Loss 1.1143, Error 0.0094(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3690 | Time 29.6330(29.8572) | Bit/dim 1.1063(1.1052) | Xent 0.0332(0.0372) | Loss 1.1229(1.1238) | Error 0.0101(0.0117) Steps 434(428.64) | Grad Norm 0.4013(0.4133) | Total Time 10.00(10.00)\n",
      "Iter 3691 | Time 29.5524(29.8481) | Bit/dim 1.1111(1.1054) | Xent 0.0352(0.0371) | Loss 1.1287(1.1239) | Error 0.0111(0.0117) Steps 428(428.62) | Grad Norm 1.2881(0.4396) | Total Time 10.00(10.00)\n",
      "Iter 3692 | Time 29.7863(29.8462) | Bit/dim 1.1051(1.1053) | Xent 0.0369(0.0371) | Loss 1.1236(1.1239) | Error 0.0104(0.0117) Steps 428(428.60) | Grad Norm 0.4411(0.4396) | Total Time 10.00(10.00)\n",
      "Iter 3693 | Time 29.6552(29.8405) | Bit/dim 1.1007(1.1052) | Xent 0.0376(0.0371) | Loss 1.1195(1.1238) | Error 0.0132(0.0117) Steps 428(428.58) | Grad Norm 1.2176(0.4630) | Total Time 10.00(10.00)\n",
      "Iter 3694 | Time 30.9656(29.8742) | Bit/dim 1.1058(1.1052) | Xent 0.0353(0.0371) | Loss 1.1235(1.1238) | Error 0.0105(0.0117) Steps 428(428.56) | Grad Norm 0.2548(0.4567) | Total Time 10.00(10.00)\n",
      "Iter 3695 | Time 29.1905(29.8537) | Bit/dim 1.1025(1.1051) | Xent 0.0350(0.0370) | Loss 1.1200(1.1236) | Error 0.0115(0.0117) Steps 428(428.55) | Grad Norm 0.6672(0.4630) | Total Time 10.00(10.00)\n",
      "Iter 3696 | Time 30.5445(29.8745) | Bit/dim 1.1066(1.1052) | Xent 0.0364(0.0370) | Loss 1.1249(1.1237) | Error 0.0122(0.0117) Steps 428(428.53) | Grad Norm 0.8419(0.4744) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0528 | Time 16.6636, Epoch Time 238.4117(238.6891), Bit/dim 1.0992(best: 1.0993), Xent 0.0286, Loss 1.1135, Error 0.0091(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3697 | Time 29.3354(29.8583) | Bit/dim 1.1062(1.1052) | Xent 0.0404(0.0371) | Loss 1.1263(1.1238) | Error 0.0119(0.0117) Steps 428(428.51) | Grad Norm 0.4826(0.4746) | Total Time 10.00(10.00)\n",
      "Iter 3698 | Time 29.7203(29.8541) | Bit/dim 1.1064(1.1053) | Xent 0.0326(0.0369) | Loss 1.1227(1.1237) | Error 0.0098(0.0117) Steps 434(428.68) | Grad Norm 0.3341(0.4704) | Total Time 10.00(10.00)\n",
      "Iter 3699 | Time 29.6937(29.8493) | Bit/dim 1.1028(1.1052) | Xent 0.0351(0.0369) | Loss 1.1204(1.1236) | Error 0.0104(0.0116) Steps 428(428.66) | Grad Norm 0.6872(0.4769) | Total Time 10.00(10.00)\n",
      "Iter 3700 | Time 29.3912(29.8356) | Bit/dim 1.1063(1.1052) | Xent 0.0373(0.0369) | Loss 1.1249(1.1237) | Error 0.0104(0.0116) Steps 434(428.82) | Grad Norm 0.3229(0.4723) | Total Time 10.00(10.00)\n",
      "Iter 3701 | Time 29.9190(29.8381) | Bit/dim 1.1065(1.1053) | Xent 0.0317(0.0367) | Loss 1.1223(1.1236) | Error 0.0104(0.0115) Steps 434(428.97) | Grad Norm 1.1636(0.4930) | Total Time 10.00(10.00)\n",
      "Iter 3702 | Time 30.4608(29.8568) | Bit/dim 1.1062(1.1053) | Xent 0.0326(0.0366) | Loss 1.1225(1.1236) | Error 0.0108(0.0115) Steps 434(429.12) | Grad Norm 0.2906(0.4870) | Total Time 10.00(10.00)\n",
      "Iter 3703 | Time 29.6235(29.8498) | Bit/dim 1.1011(1.1052) | Xent 0.0397(0.0367) | Loss 1.1210(1.1235) | Error 0.0114(0.0115) Steps 428(429.09) | Grad Norm 0.9220(0.5000) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0529 | Time 16.4229, Epoch Time 237.0940(238.6412), Bit/dim 1.0993(best: 1.0992), Xent 0.0291, Loss 1.1139, Error 0.0102(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3704 | Time 29.3720(29.8354) | Bit/dim 1.1064(1.1052) | Xent 0.0363(0.0367) | Loss 1.1246(1.1235) | Error 0.0112(0.0115) Steps 434(429.24) | Grad Norm 0.5715(0.5022) | Total Time 10.00(10.00)\n",
      "Iter 3705 | Time 29.9785(29.8397) | Bit/dim 1.1019(1.1051) | Xent 0.0404(0.0368) | Loss 1.1221(1.1235) | Error 0.0120(0.0115) Steps 428(429.20) | Grad Norm 0.3761(0.4984) | Total Time 10.00(10.00)\n",
      "Iter 3706 | Time 29.8502(29.8400) | Bit/dim 1.1086(1.1052) | Xent 0.0318(0.0367) | Loss 1.1245(1.1235) | Error 0.0096(0.0115) Steps 428(429.16) | Grad Norm 0.7073(0.5047) | Total Time 10.00(10.00)\n",
      "Iter 3707 | Time 30.1382(29.8490) | Bit/dim 1.1053(1.1052) | Xent 0.0334(0.0366) | Loss 1.1220(1.1235) | Error 0.0110(0.0115) Steps 428(429.13) | Grad Norm 0.3882(0.5012) | Total Time 10.00(10.00)\n",
      "Iter 3708 | Time 29.5015(29.8386) | Bit/dim 1.1059(1.1052) | Xent 0.0385(0.0366) | Loss 1.1251(1.1235) | Error 0.0110(0.0114) Steps 428(429.10) | Grad Norm 0.3759(0.4974) | Total Time 10.00(10.00)\n",
      "Iter 3709 | Time 30.0462(29.8448) | Bit/dim 1.1060(1.1052) | Xent 0.0352(0.0366) | Loss 1.1236(1.1235) | Error 0.0118(0.0114) Steps 428(429.06) | Grad Norm 0.5869(0.5001) | Total Time 10.00(10.00)\n",
      "Iter 3710 | Time 29.7090(29.8407) | Bit/dim 1.1036(1.1052) | Xent 0.0401(0.0367) | Loss 1.1237(1.1235) | Error 0.0122(0.0115) Steps 434(429.21) | Grad Norm 0.2868(0.4937) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0530 | Time 16.7146, Epoch Time 237.5634(238.6089), Bit/dim 1.0999(best: 1.0992), Xent 0.0277, Loss 1.1138, Error 0.0093(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3711 | Time 29.3514(29.8260) | Bit/dim 1.1042(1.1052) | Xent 0.0371(0.0367) | Loss 1.1228(1.1235) | Error 0.0125(0.0115) Steps 434(429.35) | Grad Norm 0.5764(0.4962) | Total Time 10.00(10.00)\n",
      "Iter 3712 | Time 29.6412(29.8205) | Bit/dim 1.1040(1.1051) | Xent 0.0360(0.0367) | Loss 1.1220(1.1235) | Error 0.0122(0.0115) Steps 428(429.31) | Grad Norm 0.5252(0.4970) | Total Time 10.00(10.00)\n",
      "Iter 3713 | Time 29.9137(29.8233) | Bit/dim 1.1042(1.1051) | Xent 0.0382(0.0367) | Loss 1.1233(1.1235) | Error 0.0116(0.0115) Steps 428(429.27) | Grad Norm 0.4950(0.4970) | Total Time 10.00(10.00)\n",
      "Iter 3714 | Time 29.2646(29.8065) | Bit/dim 1.1011(1.1050) | Xent 0.0356(0.0367) | Loss 1.1189(1.1233) | Error 0.0114(0.0115) Steps 434(429.42) | Grad Norm 0.8071(0.5063) | Total Time 10.00(10.00)\n",
      "Iter 3715 | Time 31.2685(29.8504) | Bit/dim 1.1101(1.1051) | Xent 0.0424(0.0369) | Loss 1.1313(1.1236) | Error 0.0124(0.0115) Steps 434(429.55) | Grad Norm 0.2253(0.4979) | Total Time 10.00(10.00)\n",
      "Iter 3716 | Time 30.1199(29.8585) | Bit/dim 1.1050(1.1051) | Xent 0.0451(0.0371) | Loss 1.1276(1.1237) | Error 0.0135(0.0116) Steps 428(429.51) | Grad Norm 0.8322(0.5079) | Total Time 10.00(10.00)\n",
      "Iter 3717 | Time 29.6784(29.8531) | Bit/dim 1.1084(1.1052) | Xent 0.0317(0.0369) | Loss 1.1242(1.1237) | Error 0.0104(0.0116) Steps 428(429.46) | Grad Norm 0.7504(0.5152) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0531 | Time 16.6576, Epoch Time 238.7191(238.6122), Bit/dim 1.0986(best: 1.0992), Xent 0.0284, Loss 1.1128, Error 0.0099(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3718 | Time 29.4717(29.8416) | Bit/dim 1.1083(1.1053) | Xent 0.0411(0.0371) | Loss 1.1288(1.1239) | Error 0.0134(0.0116) Steps 428(429.42) | Grad Norm 1.3397(0.5399) | Total Time 10.00(10.00)\n",
      "Iter 3719 | Time 29.8806(29.8428) | Bit/dim 1.1074(1.1054) | Xent 0.0330(0.0369) | Loss 1.1239(1.1239) | Error 0.0115(0.0116) Steps 428(429.38) | Grad Norm 0.3794(0.5351) | Total Time 10.00(10.00)\n",
      "Iter 3720 | Time 29.6020(29.8356) | Bit/dim 1.0975(1.1052) | Xent 0.0345(0.0369) | Loss 1.1148(1.1236) | Error 0.0106(0.0116) Steps 434(429.51) | Grad Norm 0.5252(0.5348) | Total Time 10.00(10.00)\n",
      "Iter 3721 | Time 31.0479(29.8719) | Bit/dim 1.1029(1.1051) | Xent 0.0394(0.0370) | Loss 1.1226(1.1236) | Error 0.0116(0.0116) Steps 434(429.65) | Grad Norm 0.6454(0.5381) | Total Time 10.00(10.00)\n",
      "Iter 3722 | Time 29.0907(29.8485) | Bit/dim 1.1080(1.1052) | Xent 0.0395(0.0370) | Loss 1.1277(1.1237) | Error 0.0121(0.0116) Steps 428(429.60) | Grad Norm 0.2957(0.5308) | Total Time 10.00(10.00)\n",
      "Iter 3723 | Time 29.7802(29.8465) | Bit/dim 1.1091(1.1053) | Xent 0.0429(0.0372) | Loss 1.1306(1.1239) | Error 0.0118(0.0116) Steps 428(429.55) | Grad Norm 0.7685(0.5380) | Total Time 10.00(10.00)\n",
      "Iter 3724 | Time 30.9880(29.8807) | Bit/dim 1.1039(1.1052) | Xent 0.0327(0.0371) | Loss 1.1203(1.1238) | Error 0.0101(0.0116) Steps 428(429.51) | Grad Norm 0.4037(0.5339) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0532 | Time 16.7591, Epoch Time 239.1155(238.6273), Bit/dim 1.0998(best: 1.0986), Xent 0.0263, Loss 1.1129, Error 0.0097(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3725 | Time 29.1928(29.8601) | Bit/dim 1.1010(1.1051) | Xent 0.0382(0.0371) | Loss 1.1201(1.1237) | Error 0.0121(0.0116) Steps 434(429.64) | Grad Norm 0.8525(0.5435) | Total Time 10.00(10.00)\n",
      "Iter 3726 | Time 29.4433(29.8476) | Bit/dim 1.1038(1.1051) | Xent 0.0377(0.0371) | Loss 1.1227(1.1236) | Error 0.0101(0.0115) Steps 428(429.59) | Grad Norm 0.3956(0.5391) | Total Time 10.00(10.00)\n",
      "Iter 3727 | Time 29.0566(29.8238) | Bit/dim 1.1056(1.1051) | Xent 0.0302(0.0369) | Loss 1.1207(1.1236) | Error 0.0092(0.0115) Steps 434(429.72) | Grad Norm 0.4222(0.5355) | Total Time 10.00(10.00)\n",
      "Iter 3728 | Time 29.7132(29.8205) | Bit/dim 1.1028(1.1050) | Xent 0.0344(0.0368) | Loss 1.1199(1.1234) | Error 0.0106(0.0114) Steps 428(429.67) | Grad Norm 1.2117(0.5558) | Total Time 10.00(10.00)\n",
      "Iter 3729 | Time 29.7254(29.8177) | Bit/dim 1.1057(1.1050) | Xent 0.0336(0.0367) | Loss 1.1225(1.1234) | Error 0.0104(0.0114) Steps 434(429.80) | Grad Norm 0.5770(0.5565) | Total Time 10.00(10.00)\n",
      "Iter 3730 | Time 30.7956(29.8470) | Bit/dim 1.1105(1.1052) | Xent 0.0449(0.0370) | Loss 1.1330(1.1237) | Error 0.0142(0.0115) Steps 434(429.93) | Grad Norm 1.2278(0.5766) | Total Time 10.00(10.00)\n",
      "Iter 3731 | Time 29.7224(29.8433) | Bit/dim 1.1065(1.1052) | Xent 0.0404(0.0371) | Loss 1.1266(1.1238) | Error 0.0120(0.0115) Steps 434(430.05) | Grad Norm 0.2304(0.5662) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0533 | Time 16.9075, Epoch Time 237.3794(238.5898), Bit/dim 1.0997(best: 1.0986), Xent 0.0265, Loss 1.1130, Error 0.0098(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3732 | Time 29.7848(29.8415) | Bit/dim 1.1078(1.1053) | Xent 0.0372(0.0371) | Loss 1.1264(1.1239) | Error 0.0111(0.0115) Steps 428(429.99) | Grad Norm 0.8838(0.5757) | Total Time 10.00(10.00)\n",
      "Iter 3733 | Time 29.3954(29.8281) | Bit/dim 1.1004(1.1052) | Xent 0.0375(0.0371) | Loss 1.1191(1.1237) | Error 0.0106(0.0115) Steps 428(429.93) | Grad Norm 0.4284(0.5713) | Total Time 10.00(10.00)\n",
      "Iter 3734 | Time 29.0297(29.8042) | Bit/dim 1.1069(1.1052) | Xent 0.0392(0.0372) | Loss 1.1265(1.1238) | Error 0.0108(0.0115) Steps 428(429.87) | Grad Norm 0.6001(0.5722) | Total Time 10.00(10.00)\n",
      "Iter 3735 | Time 29.4682(29.7941) | Bit/dim 1.1104(1.1054) | Xent 0.0357(0.0371) | Loss 1.1283(1.1239) | Error 0.0128(0.0115) Steps 428(429.81) | Grad Norm 0.4727(0.5692) | Total Time 10.00(10.00)\n",
      "Iter 3736 | Time 28.9407(29.7685) | Bit/dim 1.1039(1.1053) | Xent 0.0377(0.0371) | Loss 1.1228(1.1239) | Error 0.0119(0.0115) Steps 428(429.76) | Grad Norm 0.2839(0.5606) | Total Time 10.00(10.00)\n",
      "Iter 3737 | Time 29.5691(29.7625) | Bit/dim 1.0998(1.1052) | Xent 0.0378(0.0372) | Loss 1.1187(1.1238) | Error 0.0140(0.0116) Steps 428(429.71) | Grad Norm 0.8683(0.5699) | Total Time 10.00(10.00)\n",
      "Iter 3738 | Time 29.0944(29.7425) | Bit/dim 1.1048(1.1052) | Xent 0.0306(0.0370) | Loss 1.1200(1.1236) | Error 0.0090(0.0115) Steps 428(429.66) | Grad Norm 0.3506(0.5633) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0534 | Time 16.9126, Epoch Time 234.7341(238.4742), Bit/dim 1.0991(best: 1.0986), Xent 0.0256, Loss 1.1119, Error 0.0085(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3739 | Time 30.3184(29.7597) | Bit/dim 1.1051(1.1052) | Xent 0.0365(0.0369) | Loss 1.1233(1.1236) | Error 0.0115(0.0115) Steps 428(429.61) | Grad Norm 1.0548(0.5780) | Total Time 10.00(10.00)\n",
      "Iter 3740 | Time 29.8100(29.7613) | Bit/dim 1.1040(1.1051) | Xent 0.0359(0.0369) | Loss 1.1219(1.1236) | Error 0.0121(0.0115) Steps 428(429.56) | Grad Norm 0.2790(0.5691) | Total Time 10.00(10.00)\n",
      "Iter 3741 | Time 30.8649(29.7944) | Bit/dim 1.1060(1.1052) | Xent 0.0395(0.0370) | Loss 1.1258(1.1236) | Error 0.0119(0.0115) Steps 434(429.69) | Grad Norm 0.8950(0.5788) | Total Time 10.00(10.00)\n",
      "Iter 3742 | Time 29.7768(29.7938) | Bit/dim 1.1070(1.1052) | Xent 0.0444(0.0372) | Loss 1.1292(1.1238) | Error 0.0130(0.0116) Steps 434(429.82) | Grad Norm 0.2105(0.5678) | Total Time 10.00(10.00)\n",
      "Iter 3743 | Time 29.5474(29.7864) | Bit/dim 1.1060(1.1052) | Xent 0.0379(0.0372) | Loss 1.1250(1.1239) | Error 0.0128(0.0116) Steps 428(429.77) | Grad Norm 0.5596(0.5676) | Total Time 10.00(10.00)\n",
      "Iter 3744 | Time 30.2795(29.8012) | Bit/dim 1.1046(1.1052) | Xent 0.0346(0.0372) | Loss 1.1219(1.1238) | Error 0.0120(0.0116) Steps 428(429.71) | Grad Norm 0.4132(0.5629) | Total Time 10.00(10.00)\n",
      "Iter 3745 | Time 29.0154(29.7777) | Bit/dim 1.1016(1.1051) | Xent 0.0329(0.0370) | Loss 1.1180(1.1236) | Error 0.0105(0.0116) Steps 428(429.66) | Grad Norm 0.4381(0.5592) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0535 | Time 16.6340, Epoch Time 238.8758(238.4862), Bit/dim 1.0997(best: 1.0986), Xent 0.0269, Loss 1.1132, Error 0.0101(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3746 | Time 29.1461(29.7587) | Bit/dim 1.1028(1.1050) | Xent 0.0379(0.0371) | Loss 1.1218(1.1236) | Error 0.0124(0.0116) Steps 428(429.61) | Grad Norm 0.4861(0.5570) | Total Time 10.00(10.00)\n",
      "Iter 3747 | Time 29.2610(29.7438) | Bit/dim 1.1058(1.1051) | Xent 0.0349(0.0370) | Loss 1.1232(1.1236) | Error 0.0101(0.0116) Steps 428(429.56) | Grad Norm 0.3197(0.5499) | Total Time 10.00(10.00)\n",
      "Iter 3748 | Time 29.5661(29.7385) | Bit/dim 1.1043(1.1050) | Xent 0.0404(0.0371) | Loss 1.1245(1.1236) | Error 0.0108(0.0115) Steps 428(429.52) | Grad Norm 0.3857(0.5449) | Total Time 10.00(10.00)\n",
      "Iter 3749 | Time 29.5949(29.7341) | Bit/dim 1.1044(1.1050) | Xent 0.0304(0.0369) | Loss 1.1196(1.1235) | Error 0.0082(0.0114) Steps 428(429.47) | Grad Norm 0.9901(0.5583) | Total Time 10.00(10.00)\n",
      "Iter 3750 | Time 29.6696(29.7322) | Bit/dim 1.1076(1.1051) | Xent 0.0354(0.0368) | Loss 1.1253(1.1235) | Error 0.0111(0.0114) Steps 428(429.43) | Grad Norm 0.5085(0.5568) | Total Time 10.00(10.00)\n",
      "Iter 3751 | Time 29.3659(29.7212) | Bit/dim 1.1048(1.1051) | Xent 0.0367(0.0368) | Loss 1.1231(1.1235) | Error 0.0109(0.0114) Steps 428(429.38) | Grad Norm 0.8851(0.5666) | Total Time 10.00(10.00)\n",
      "Iter 3752 | Time 30.5620(29.7464) | Bit/dim 1.1057(1.1051) | Xent 0.0395(0.0369) | Loss 1.1255(1.1236) | Error 0.0144(0.0115) Steps 428(429.34) | Grad Norm 0.2439(0.5570) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0536 | Time 16.8334, Epoch Time 236.5863(238.4292), Bit/dim 1.0989(best: 1.0986), Xent 0.0290, Loss 1.1134, Error 0.0099(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3753 | Time 29.6457(29.7434) | Bit/dim 1.1031(1.1050) | Xent 0.0426(0.0371) | Loss 1.1244(1.1236) | Error 0.0129(0.0115) Steps 428(429.30) | Grad Norm 0.7836(0.5638) | Total Time 10.00(10.00)\n",
      "Iter 3754 | Time 29.4778(29.7355) | Bit/dim 1.1078(1.1051) | Xent 0.0401(0.0372) | Loss 1.1278(1.1237) | Error 0.0130(0.0116) Steps 428(429.26) | Grad Norm 0.4093(0.5591) | Total Time 10.00(10.00)\n",
      "Iter 3755 | Time 29.9128(29.7408) | Bit/dim 1.1018(1.1050) | Xent 0.0338(0.0371) | Loss 1.1187(1.1236) | Error 0.0109(0.0116) Steps 428(429.23) | Grad Norm 0.3092(0.5516) | Total Time 10.00(10.00)\n",
      "Iter 3756 | Time 29.4987(29.7335) | Bit/dim 1.1051(1.1050) | Xent 0.0407(0.0372) | Loss 1.1254(1.1236) | Error 0.0118(0.0116) Steps 428(429.19) | Grad Norm 0.6277(0.5539) | Total Time 10.00(10.00)\n",
      "Iter 3757 | Time 30.2211(29.7481) | Bit/dim 1.1067(1.1051) | Xent 0.0361(0.0372) | Loss 1.1248(1.1237) | Error 0.0106(0.0115) Steps 428(429.15) | Grad Norm 0.2582(0.5450) | Total Time 10.00(10.00)\n",
      "Iter 3758 | Time 29.5276(29.7415) | Bit/dim 1.1056(1.1051) | Xent 0.0383(0.0372) | Loss 1.1248(1.1237) | Error 0.0131(0.0116) Steps 428(429.12) | Grad Norm 0.3711(0.5398) | Total Time 10.00(10.00)\n",
      "Iter 3759 | Time 29.7596(29.7421) | Bit/dim 1.1036(1.1050) | Xent 0.0352(0.0371) | Loss 1.1212(1.1236) | Error 0.0111(0.0116) Steps 428(429.08) | Grad Norm 0.5413(0.5399) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0537 | Time 16.6096, Epoch Time 237.0274(238.3872), Bit/dim 1.0989(best: 1.0986), Xent 0.0263, Loss 1.1121, Error 0.0088(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3760 | Time 29.6358(29.7389) | Bit/dim 1.1060(1.1051) | Xent 0.0365(0.0371) | Loss 1.1242(1.1236) | Error 0.0110(0.0116) Steps 428(429.05) | Grad Norm 0.2375(0.5308) | Total Time 10.00(10.00)\n",
      "Iter 3761 | Time 30.3434(29.7570) | Bit/dim 1.1042(1.1051) | Xent 0.0414(0.0372) | Loss 1.1250(1.1237) | Error 0.0118(0.0116) Steps 428(429.02) | Grad Norm 0.9952(0.5447) | Total Time 10.00(10.00)\n",
      "Iter 3762 | Time 30.9035(29.7914) | Bit/dim 1.1048(1.1050) | Xent 0.0334(0.0371) | Loss 1.1215(1.1236) | Error 0.0104(0.0115) Steps 428(428.99) | Grad Norm 0.4997(0.5434) | Total Time 10.00(10.00)\n",
      "Iter 3763 | Time 29.5192(29.7832) | Bit/dim 1.1046(1.1050) | Xent 0.0389(0.0372) | Loss 1.1241(1.1236) | Error 0.0124(0.0116) Steps 428(428.96) | Grad Norm 0.6146(0.5455) | Total Time 10.00(10.00)\n",
      "Iter 3764 | Time 29.9751(29.7890) | Bit/dim 1.1059(1.1051) | Xent 0.0332(0.0371) | Loss 1.1225(1.1236) | Error 0.0106(0.0115) Steps 428(428.93) | Grad Norm 0.2403(0.5364) | Total Time 10.00(10.00)\n",
      "Iter 3765 | Time 29.8032(29.7894) | Bit/dim 1.1065(1.1051) | Xent 0.0421(0.0372) | Loss 1.1275(1.1237) | Error 0.0122(0.0116) Steps 428(428.90) | Grad Norm 0.4794(0.5347) | Total Time 10.00(10.00)\n",
      "Iter 3766 | Time 29.5173(29.7813) | Bit/dim 1.0990(1.1049) | Xent 0.0295(0.0370) | Loss 1.1137(1.1234) | Error 0.0096(0.0115) Steps 434(429.06) | Grad Norm 0.2365(0.5257) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0538 | Time 16.7206, Epoch Time 238.8746(238.4018), Bit/dim 1.0991(best: 1.0986), Xent 0.0290, Loss 1.1136, Error 0.0100(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3767 | Time 29.6438(29.7771) | Bit/dim 1.1078(1.1050) | Xent 0.0347(0.0369) | Loss 1.1251(1.1235) | Error 0.0112(0.0115) Steps 428(429.02) | Grad Norm 0.6622(0.5298) | Total Time 10.00(10.00)\n",
      "Iter 3768 | Time 29.9249(29.7816) | Bit/dim 1.1031(1.1049) | Xent 0.0366(0.0369) | Loss 1.1214(1.1234) | Error 0.0124(0.0115) Steps 428(428.99) | Grad Norm 0.2561(0.5216) | Total Time 10.00(10.00)\n",
      "Iter 3769 | Time 29.9554(29.7868) | Bit/dim 1.1044(1.1049) | Xent 0.0380(0.0369) | Loss 1.1234(1.1234) | Error 0.0108(0.0115) Steps 428(428.96) | Grad Norm 0.4178(0.5185) | Total Time 10.00(10.00)\n",
      "Iter 3770 | Time 29.5481(29.7796) | Bit/dim 1.1031(1.1049) | Xent 0.0400(0.0370) | Loss 1.1231(1.1234) | Error 0.0134(0.0115) Steps 428(428.94) | Grad Norm 0.3429(0.5132) | Total Time 10.00(10.00)\n",
      "Iter 3771 | Time 31.0873(29.8189) | Bit/dim 1.1066(1.1049) | Xent 0.0374(0.0370) | Loss 1.1253(1.1234) | Error 0.0126(0.0116) Steps 428(428.91) | Grad Norm 0.2948(0.5067) | Total Time 10.00(10.00)\n",
      "Iter 3772 | Time 29.2464(29.8017) | Bit/dim 1.1042(1.1049) | Xent 0.0369(0.0370) | Loss 1.1226(1.1234) | Error 0.0121(0.0116) Steps 428(428.88) | Grad Norm 0.8592(0.5172) | Total Time 10.00(10.00)\n",
      "Iter 3773 | Time 28.8993(29.7746) | Bit/dim 1.1040(1.1049) | Xent 0.0426(0.0372) | Loss 1.1253(1.1235) | Error 0.0130(0.0116) Steps 428(428.85) | Grad Norm 0.4665(0.5157) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0539 | Time 16.7685, Epoch Time 237.4010(238.3718), Bit/dim 1.0995(best: 1.0986), Xent 0.0269, Loss 1.1129, Error 0.0094(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3774 | Time 29.4926(29.7661) | Bit/dim 1.1009(1.1048) | Xent 0.0349(0.0371) | Loss 1.1184(1.1233) | Error 0.0111(0.0116) Steps 428(428.83) | Grad Norm 0.3471(0.5107) | Total Time 10.00(10.00)\n",
      "Iter 3775 | Time 29.9086(29.7704) | Bit/dim 1.1046(1.1048) | Xent 0.0346(0.0371) | Loss 1.1219(1.1233) | Error 0.0120(0.0116) Steps 428(428.80) | Grad Norm 0.3230(0.5050) | Total Time 10.00(10.00)\n",
      "Iter 3776 | Time 30.0562(29.7790) | Bit/dim 1.1070(1.1048) | Xent 0.0378(0.0371) | Loss 1.1260(1.1234) | Error 0.0112(0.0116) Steps 428(428.78) | Grad Norm 0.2440(0.4972) | Total Time 10.00(10.00)\n",
      "Iter 3777 | Time 30.5997(29.8036) | Bit/dim 1.0996(1.1047) | Xent 0.0388(0.0371) | Loss 1.1190(1.1232) | Error 0.0121(0.0116) Steps 428(428.76) | Grad Norm 0.4343(0.4953) | Total Time 10.00(10.00)\n",
      "Iter 3778 | Time 29.5523(29.7961) | Bit/dim 1.1071(1.1047) | Xent 0.0346(0.0371) | Loss 1.1244(1.1233) | Error 0.0109(0.0116) Steps 428(428.73) | Grad Norm 0.7793(0.5038) | Total Time 10.00(10.00)\n",
      "Iter 3779 | Time 29.6398(29.7914) | Bit/dim 1.1078(1.1048) | Xent 0.0368(0.0371) | Loss 1.1262(1.1234) | Error 0.0106(0.0116) Steps 428(428.71) | Grad Norm 0.5772(0.5060) | Total Time 10.00(10.00)\n",
      "Iter 3780 | Time 29.9144(29.7951) | Bit/dim 1.1056(1.1049) | Xent 0.0365(0.0370) | Loss 1.1238(1.1234) | Error 0.0104(0.0115) Steps 428(428.69) | Grad Norm 0.9482(0.5193) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0540 | Time 16.8960, Epoch Time 238.4057(238.3728), Bit/dim 1.0986(best: 1.0986), Xent 0.0298, Loss 1.1135, Error 0.0102(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3781 | Time 28.9564(29.7699) | Bit/dim 1.1032(1.1048) | Xent 0.0317(0.0369) | Loss 1.1190(1.1232) | Error 0.0099(0.0115) Steps 428(428.67) | Grad Norm 0.3014(0.5128) | Total Time 10.00(10.00)\n",
      "Iter 3782 | Time 29.4955(29.7617) | Bit/dim 1.1048(1.1048) | Xent 0.0382(0.0369) | Loss 1.1239(1.1233) | Error 0.0116(0.0115) Steps 428(428.65) | Grad Norm 0.6547(0.5170) | Total Time 10.00(10.00)\n",
      "Iter 3783 | Time 29.5609(29.7557) | Bit/dim 1.1074(1.1049) | Xent 0.0451(0.0372) | Loss 1.1299(1.1235) | Error 0.0135(0.0116) Steps 428(428.63) | Grad Norm 0.7023(0.5226) | Total Time 10.00(10.00)\n",
      "Iter 3784 | Time 29.4160(29.7455) | Bit/dim 1.1040(1.1049) | Xent 0.0366(0.0371) | Loss 1.1223(1.1234) | Error 0.0109(0.0115) Steps 428(428.61) | Grad Norm 0.3726(0.5181) | Total Time 10.00(10.00)\n",
      "Iter 3785 | Time 29.7524(29.7457) | Bit/dim 1.1088(1.1050) | Xent 0.0375(0.0372) | Loss 1.1275(1.1235) | Error 0.0115(0.0115) Steps 428(428.59) | Grad Norm 0.5177(0.5181) | Total Time 10.00(10.00)\n",
      "Iter 3786 | Time 29.5569(29.7400) | Bit/dim 1.1048(1.1050) | Xent 0.0390(0.0372) | Loss 1.1243(1.1236) | Error 0.0126(0.0116) Steps 428(428.57) | Grad Norm 0.2592(0.5103) | Total Time 10.00(10.00)\n",
      "Iter 3787 | Time 29.3808(29.7292) | Bit/dim 1.1023(1.1049) | Xent 0.0334(0.0371) | Loss 1.1190(1.1234) | Error 0.0101(0.0115) Steps 428(428.56) | Grad Norm 0.3626(0.5059) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0541 | Time 16.6747, Epoch Time 235.3715(238.2827), Bit/dim 1.0989(best: 1.0986), Xent 0.0263, Loss 1.1121, Error 0.0091(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3788 | Time 29.2377(29.7145) | Bit/dim 1.1082(1.1050) | Xent 0.0363(0.0371) | Loss 1.1264(1.1235) | Error 0.0115(0.0115) Steps 428(428.54) | Grad Norm 0.2984(0.4996) | Total Time 10.00(10.00)\n",
      "Iter 3789 | Time 30.5661(29.7400) | Bit/dim 1.1068(1.1050) | Xent 0.0472(0.0374) | Loss 1.1304(1.1237) | Error 0.0152(0.0116) Steps 434(428.70) | Grad Norm 1.0297(0.5155) | Total Time 10.00(10.00)\n",
      "Iter 3790 | Time 28.7333(29.7098) | Bit/dim 1.1025(1.1050) | Xent 0.0292(0.0371) | Loss 1.1171(1.1235) | Error 0.0102(0.0116) Steps 428(428.68) | Grad Norm 0.6938(0.5209) | Total Time 10.00(10.00)\n",
      "Iter 3791 | Time 29.5233(29.7042) | Bit/dim 1.1064(1.1050) | Xent 0.0372(0.0371) | Loss 1.1250(1.1236) | Error 0.0112(0.0116) Steps 428(428.66) | Grad Norm 0.5348(0.5213) | Total Time 10.00(10.00)\n",
      "Iter 3792 | Time 29.6527(29.7027) | Bit/dim 1.1047(1.1050) | Xent 0.0431(0.0373) | Loss 1.1262(1.1236) | Error 0.0130(0.0116) Steps 434(428.82) | Grad Norm 0.2523(0.5132) | Total Time 10.00(10.00)\n",
      "Iter 3793 | Time 29.6095(29.6999) | Bit/dim 1.1029(1.1049) | Xent 0.0322(0.0372) | Loss 1.1190(1.1235) | Error 0.0101(0.0116) Steps 428(428.80) | Grad Norm 0.2567(0.5055) | Total Time 10.00(10.00)\n",
      "Iter 3794 | Time 30.0304(29.7098) | Bit/dim 1.1057(1.1050) | Xent 0.0362(0.0371) | Loss 1.1238(1.1235) | Error 0.0120(0.0116) Steps 428(428.77) | Grad Norm 0.7129(0.5118) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0542 | Time 16.6525, Epoch Time 236.6953(238.2351), Bit/dim 1.0992(best: 1.0986), Xent 0.0283, Loss 1.1134, Error 0.0095(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3795 | Time 29.4242(29.7012) | Bit/dim 1.1043(1.1049) | Xent 0.0388(0.0372) | Loss 1.1237(1.1235) | Error 0.0116(0.0116) Steps 428(428.75) | Grad Norm 0.2780(0.5048) | Total Time 10.00(10.00)\n",
      "Iter 3796 | Time 29.7925(29.7040) | Bit/dim 1.1015(1.1048) | Xent 0.0334(0.0371) | Loss 1.1182(1.1234) | Error 0.0115(0.0116) Steps 428(428.73) | Grad Norm 0.5326(0.5056) | Total Time 10.00(10.00)\n",
      "Iter 3797 | Time 29.4342(29.6959) | Bit/dim 1.1072(1.1049) | Xent 0.0326(0.0369) | Loss 1.1235(1.1234) | Error 0.0101(0.0116) Steps 428(428.71) | Grad Norm 0.4881(0.5051) | Total Time 10.00(10.00)\n",
      "Iter 3798 | Time 29.1377(29.6791) | Bit/dim 1.1026(1.1048) | Xent 0.0357(0.0369) | Loss 1.1205(1.1233) | Error 0.0114(0.0115) Steps 434(428.87) | Grad Norm 0.6684(0.5100) | Total Time 10.00(10.00)\n",
      "Iter 3799 | Time 29.8635(29.6847) | Bit/dim 1.1091(1.1050) | Xent 0.0327(0.0368) | Loss 1.1255(1.1233) | Error 0.0109(0.0115) Steps 434(429.02) | Grad Norm 0.3549(0.5053) | Total Time 10.00(10.00)\n",
      "Iter 3800 | Time 29.4479(29.6776) | Bit/dim 1.1012(1.1048) | Xent 0.0388(0.0368) | Loss 1.1205(1.1233) | Error 0.0121(0.0115) Steps 428(428.99) | Grad Norm 0.2177(0.4967) | Total Time 10.00(10.00)\n",
      "Iter 3801 | Time 29.6165(29.6757) | Bit/dim 1.1033(1.1048) | Xent 0.0333(0.0367) | Loss 1.1200(1.1232) | Error 0.0114(0.0115) Steps 428(428.96) | Grad Norm 0.7788(0.5051) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0543 | Time 16.7695, Epoch Time 236.2935(238.1769), Bit/dim 1.0991(best: 1.0986), Xent 0.0288, Loss 1.1136, Error 0.0107(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3802 | Time 30.0028(29.6856) | Bit/dim 1.1078(1.1049) | Xent 0.0384(0.0368) | Loss 1.1270(1.1233) | Error 0.0120(0.0116) Steps 428(428.93) | Grad Norm 0.2834(0.4985) | Total Time 10.00(10.00)\n",
      "Iter 3803 | Time 29.2434(29.6723) | Bit/dim 1.1030(1.1048) | Xent 0.0376(0.0368) | Loss 1.1218(1.1232) | Error 0.0114(0.0115) Steps 428(428.90) | Grad Norm 0.3629(0.4944) | Total Time 10.00(10.00)\n",
      "Iter 3804 | Time 30.8419(29.7074) | Bit/dim 1.1004(1.1047) | Xent 0.0349(0.0367) | Loss 1.1178(1.1231) | Error 0.0104(0.0115) Steps 434(429.06) | Grad Norm 0.4011(0.4916) | Total Time 10.00(10.00)\n",
      "Iter 3805 | Time 29.2843(29.6947) | Bit/dim 1.1028(1.1046) | Xent 0.0348(0.0367) | Loss 1.1202(1.1230) | Error 0.0102(0.0115) Steps 428(429.02) | Grad Norm 0.3445(0.4872) | Total Time 10.00(10.00)\n",
      "Iter 3806 | Time 29.8178(29.6984) | Bit/dim 1.1017(1.1046) | Xent 0.0380(0.0367) | Loss 1.1207(1.1229) | Error 0.0111(0.0115) Steps 428(428.99) | Grad Norm 0.3888(0.4843) | Total Time 10.00(10.00)\n",
      "Iter 3807 | Time 29.2702(29.6855) | Bit/dim 1.1109(1.1047) | Xent 0.0324(0.0366) | Loss 1.1271(1.1230) | Error 0.0080(0.0114) Steps 428(428.96) | Grad Norm 0.3593(0.4805) | Total Time 10.00(10.00)\n",
      "Iter 3808 | Time 30.0902(29.6977) | Bit/dim 1.1034(1.1047) | Xent 0.0406(0.0367) | Loss 1.1237(1.1231) | Error 0.0129(0.0114) Steps 434(429.11) | Grad Norm 1.1541(0.5007) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0544 | Time 16.6749, Epoch Time 237.6199(238.1602), Bit/dim 1.0990(best: 1.0986), Xent 0.0274, Loss 1.1127, Error 0.0103(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3809 | Time 29.2885(29.6854) | Bit/dim 1.1057(1.1047) | Xent 0.0371(0.0367) | Loss 1.1243(1.1231) | Error 0.0112(0.0114) Steps 428(429.08) | Grad Norm 0.4795(0.5001) | Total Time 10.00(10.00)\n",
      "Iter 3810 | Time 29.2460(29.6722) | Bit/dim 1.1068(1.1048) | Xent 0.0357(0.0367) | Loss 1.1247(1.1231) | Error 0.0091(0.0113) Steps 428(429.05) | Grad Norm 0.8698(0.5112) | Total Time 10.00(10.00)\n",
      "Iter 3811 | Time 29.1904(29.6578) | Bit/dim 1.1019(1.1047) | Xent 0.0336(0.0366) | Loss 1.1187(1.1230) | Error 0.0104(0.0113) Steps 428(429.02) | Grad Norm 0.2767(0.5041) | Total Time 10.00(10.00)\n",
      "Iter 3812 | Time 30.9262(29.6958) | Bit/dim 1.1073(1.1048) | Xent 0.0419(0.0368) | Loss 1.1283(1.1232) | Error 0.0136(0.0114) Steps 428(428.99) | Grad Norm 1.0199(0.5196) | Total Time 10.00(10.00)\n",
      "Iter 3813 | Time 28.9440(29.6733) | Bit/dim 1.1027(1.1047) | Xent 0.0357(0.0367) | Loss 1.1206(1.1231) | Error 0.0119(0.0114) Steps 428(428.96) | Grad Norm 0.2113(0.5104) | Total Time 10.00(10.00)\n",
      "Iter 3814 | Time 29.7725(29.6762) | Bit/dim 1.1055(1.1048) | Xent 0.0390(0.0368) | Loss 1.1250(1.1232) | Error 0.0135(0.0115) Steps 434(429.11) | Grad Norm 0.4653(0.5090) | Total Time 10.00(10.00)\n",
      "Iter 3815 | Time 29.9063(29.6831) | Bit/dim 1.1028(1.1047) | Xent 0.0283(0.0365) | Loss 1.1169(1.1230) | Error 0.0091(0.0114) Steps 434(429.25) | Grad Norm 0.9517(0.5223) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0545 | Time 16.5437, Epoch Time 236.4435(238.1087), Bit/dim 1.0992(best: 1.0986), Xent 0.0271, Loss 1.1128, Error 0.0096(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3816 | Time 30.0136(29.6931) | Bit/dim 1.1094(1.1048) | Xent 0.0360(0.0365) | Loss 1.1274(1.1231) | Error 0.0109(0.0114) Steps 428(429.22) | Grad Norm 0.7665(0.5296) | Total Time 10.00(10.00)\n",
      "Iter 3817 | Time 29.2933(29.6811) | Bit/dim 1.1040(1.1048) | Xent 0.0404(0.0366) | Loss 1.1242(1.1231) | Error 0.0135(0.0114) Steps 428(429.18) | Grad Norm 1.1777(0.5491) | Total Time 10.00(10.00)\n",
      "Iter 3818 | Time 29.8816(29.6871) | Bit/dim 1.1059(1.1048) | Xent 0.0369(0.0366) | Loss 1.1243(1.1232) | Error 0.0106(0.0114) Steps 428(429.15) | Grad Norm 0.6151(0.5510) | Total Time 10.00(10.00)\n",
      "Iter 3819 | Time 29.4043(29.6786) | Bit/dim 1.1012(1.1047) | Xent 0.0367(0.0367) | Loss 1.1195(1.1231) | Error 0.0115(0.0114) Steps 428(429.11) | Grad Norm 1.3327(0.5745) | Total Time 10.00(10.00)\n",
      "Iter 3820 | Time 29.6472(29.6776) | Bit/dim 1.1025(1.1047) | Xent 0.0411(0.0368) | Loss 1.1231(1.1231) | Error 0.0130(0.0115) Steps 428(429.08) | Grad Norm 0.1996(0.5632) | Total Time 10.00(10.00)\n",
      "Iter 3821 | Time 29.4611(29.6712) | Bit/dim 1.1075(1.1047) | Xent 0.0383(0.0368) | Loss 1.1266(1.1232) | Error 0.0118(0.0115) Steps 428(429.05) | Grad Norm 1.1756(0.5816) | Total Time 10.00(10.00)\n",
      "Iter 3822 | Time 29.2891(29.6597) | Bit/dim 1.1033(1.1047) | Xent 0.0330(0.0367) | Loss 1.1198(1.1231) | Error 0.0112(0.0115) Steps 428(429.01) | Grad Norm 0.7501(0.5867) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0546 | Time 16.7524, Epoch Time 236.3337(238.0554), Bit/dim 1.0991(best: 1.0986), Xent 0.0263, Loss 1.1123, Error 0.0091(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3823 | Time 29.8684(29.6660) | Bit/dim 1.1063(1.1048) | Xent 0.0398(0.0368) | Loss 1.1263(1.1232) | Error 0.0135(0.0115) Steps 428(428.98) | Grad Norm 0.7229(0.5908) | Total Time 10.00(10.00)\n",
      "Iter 3824 | Time 30.9293(29.7039) | Bit/dim 1.1030(1.1047) | Xent 0.0335(0.0367) | Loss 1.1198(1.1231) | Error 0.0112(0.0115) Steps 428(428.95) | Grad Norm 1.2014(0.6091) | Total Time 10.00(10.00)\n",
      "Iter 3825 | Time 31.0002(29.7427) | Bit/dim 1.1074(1.1048) | Xent 0.0427(0.0369) | Loss 1.1288(1.1232) | Error 0.0128(0.0115) Steps 428(428.93) | Grad Norm 0.2929(0.5996) | Total Time 10.00(10.00)\n",
      "Iter 3826 | Time 29.5349(29.7365) | Bit/dim 1.1038(1.1048) | Xent 0.0370(0.0369) | Loss 1.1223(1.1232) | Error 0.0119(0.0116) Steps 428(428.90) | Grad Norm 1.0969(0.6145) | Total Time 10.00(10.00)\n",
      "Iter 3827 | Time 30.2007(29.7504) | Bit/dim 1.1028(1.1047) | Xent 0.0311(0.0367) | Loss 1.1183(1.1231) | Error 0.0100(0.0115) Steps 428(428.87) | Grad Norm 0.8598(0.6219) | Total Time 10.00(10.00)\n",
      "Iter 3828 | Time 29.5610(29.7447) | Bit/dim 1.1044(1.1047) | Xent 0.0391(0.0368) | Loss 1.1240(1.1231) | Error 0.0120(0.0115) Steps 428(428.84) | Grad Norm 0.3529(0.6138) | Total Time 10.00(10.00)\n",
      "Iter 3829 | Time 29.9398(29.7506) | Bit/dim 1.1078(1.1048) | Xent 0.0330(0.0367) | Loss 1.1243(1.1231) | Error 0.0105(0.0115) Steps 434(429.00) | Grad Norm 1.2299(0.6323) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0547 | Time 16.8515, Epoch Time 240.2880(238.1224), Bit/dim 1.0988(best: 1.0986), Xent 0.0302, Loss 1.1139, Error 0.0096(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3830 | Time 28.9291(29.7260) | Bit/dim 1.1055(1.1048) | Xent 0.0330(0.0366) | Loss 1.1221(1.1231) | Error 0.0108(0.0115) Steps 428(428.97) | Grad Norm 0.4510(0.6268) | Total Time 10.00(10.00)\n",
      "Iter 3831 | Time 30.2737(29.7424) | Bit/dim 1.1012(1.1047) | Xent 0.0416(0.0367) | Loss 1.1220(1.1231) | Error 0.0132(0.0115) Steps 428(428.94) | Grad Norm 1.1339(0.6421) | Total Time 10.00(10.00)\n",
      "Iter 3832 | Time 30.4673(29.7641) | Bit/dim 1.1064(1.1047) | Xent 0.0370(0.0367) | Loss 1.1250(1.1231) | Error 0.0114(0.0115) Steps 428(428.91) | Grad Norm 0.5487(0.6393) | Total Time 10.00(10.00)\n",
      "Iter 3833 | Time 29.0892(29.7439) | Bit/dim 1.1064(1.1048) | Xent 0.0394(0.0368) | Loss 1.1261(1.1232) | Error 0.0125(0.0116) Steps 428(428.88) | Grad Norm 0.3068(0.6293) | Total Time 10.00(10.00)\n",
      "Iter 3834 | Time 30.0976(29.7545) | Bit/dim 1.1064(1.1048) | Xent 0.0359(0.0368) | Loss 1.1243(1.1232) | Error 0.0121(0.0116) Steps 428(428.86) | Grad Norm 1.3491(0.6509) | Total Time 10.00(10.00)\n",
      "Iter 3835 | Time 29.2550(29.7395) | Bit/dim 1.1035(1.1048) | Xent 0.0368(0.0368) | Loss 1.1219(1.1232) | Error 0.0114(0.0116) Steps 428(428.83) | Grad Norm 0.2821(0.6398) | Total Time 10.00(10.00)\n",
      "Iter 3836 | Time 29.7412(29.7396) | Bit/dim 1.1044(1.1048) | Xent 0.0315(0.0366) | Loss 1.1201(1.1231) | Error 0.0102(0.0115) Steps 428(428.81) | Grad Norm 0.9042(0.6477) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0548 | Time 16.7285, Epoch Time 237.4374(238.1018), Bit/dim 1.0987(best: 1.0986), Xent 0.0278, Loss 1.1126, Error 0.0089(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3837 | Time 29.9116(29.7447) | Bit/dim 1.1003(1.1047) | Xent 0.0327(0.0365) | Loss 1.1167(1.1229) | Error 0.0092(0.0115) Steps 428(428.78) | Grad Norm 0.7346(0.6504) | Total Time 10.00(10.00)\n",
      "Iter 3838 | Time 30.6828(29.7729) | Bit/dim 1.1046(1.1047) | Xent 0.0329(0.0364) | Loss 1.1211(1.1229) | Error 0.0099(0.0114) Steps 428(428.76) | Grad Norm 0.5274(0.6467) | Total Time 10.00(10.00)\n",
      "Iter 3839 | Time 29.6376(29.7688) | Bit/dim 1.1083(1.1048) | Xent 0.0348(0.0364) | Loss 1.1256(1.1229) | Error 0.0109(0.0114) Steps 428(428.74) | Grad Norm 0.8270(0.6521) | Total Time 10.00(10.00)\n",
      "Iter 3840 | Time 29.9903(29.7755) | Bit/dim 1.1089(1.1049) | Xent 0.0379(0.0364) | Loss 1.1278(1.1231) | Error 0.0120(0.0114) Steps 428(428.71) | Grad Norm 0.3113(0.6419) | Total Time 10.00(10.00)\n",
      "Iter 3841 | Time 29.9423(29.7805) | Bit/dim 1.1043(1.1049) | Xent 0.0375(0.0364) | Loss 1.1230(1.1231) | Error 0.0105(0.0114) Steps 428(428.69) | Grad Norm 0.9291(0.6505) | Total Time 10.00(10.00)\n",
      "Iter 3842 | Time 29.7430(29.7793) | Bit/dim 1.1031(1.1048) | Xent 0.0391(0.0365) | Loss 1.1227(1.1231) | Error 0.0115(0.0114) Steps 428(428.67) | Grad Norm 0.3762(0.6422) | Total Time 10.00(10.00)\n",
      "Iter 3843 | Time 31.2371(29.8231) | Bit/dim 1.1013(1.1047) | Xent 0.0374(0.0365) | Loss 1.1200(1.1230) | Error 0.0122(0.0114) Steps 428(428.65) | Grad Norm 0.8946(0.6498) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0549 | Time 16.6758, Epoch Time 240.1394(238.1630), Bit/dim 1.0985(best: 1.0986), Xent 0.0266, Loss 1.1118, Error 0.0087(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3844 | Time 31.5622(29.8752) | Bit/dim 1.1035(1.1047) | Xent 0.0364(0.0365) | Loss 1.1217(1.1229) | Error 0.0114(0.0114) Steps 428(428.63) | Grad Norm 0.3396(0.6405) | Total Time 10.00(10.00)\n",
      "Iter 3845 | Time 29.4149(29.8614) | Bit/dim 1.1050(1.1047) | Xent 0.0399(0.0366) | Loss 1.1249(1.1230) | Error 0.0121(0.0114) Steps 428(428.61) | Grad Norm 0.6159(0.6398) | Total Time 10.00(10.00)\n",
      "Iter 3846 | Time 29.5712(29.8527) | Bit/dim 1.1071(1.1048) | Xent 0.0370(0.0366) | Loss 1.1256(1.1231) | Error 0.0116(0.0114) Steps 428(428.60) | Grad Norm 0.2724(0.6288) | Total Time 10.00(10.00)\n",
      "Iter 3847 | Time 29.8916(29.8539) | Bit/dim 1.1025(1.1047) | Xent 0.0402(0.0368) | Loss 1.1227(1.1231) | Error 0.0134(0.0115) Steps 434(428.76) | Grad Norm 0.3600(0.6207) | Total Time 10.00(10.00)\n",
      "Iter 3848 | Time 29.4760(29.8426) | Bit/dim 1.1053(1.1047) | Xent 0.0354(0.0367) | Loss 1.1230(1.1231) | Error 0.0115(0.0115) Steps 428(428.73) | Grad Norm 0.3464(0.6125) | Total Time 10.00(10.00)\n",
      "Iter 3849 | Time 30.2089(29.8535) | Bit/dim 1.1005(1.1046) | Xent 0.0373(0.0367) | Loss 1.1192(1.1229) | Error 0.0131(0.0115) Steps 428(428.71) | Grad Norm 0.4287(0.6069) | Total Time 10.00(10.00)\n",
      "Iter 3850 | Time 29.6978(29.8489) | Bit/dim 1.1053(1.1046) | Xent 0.0371(0.0367) | Loss 1.1239(1.1230) | Error 0.0120(0.0116) Steps 428(428.69) | Grad Norm 0.3036(0.5978) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0550 | Time 16.6076, Epoch Time 238.8349(238.1831), Bit/dim 1.0982(best: 1.0985), Xent 0.0279, Loss 1.1121, Error 0.0097(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3851 | Time 30.6684(29.8735) | Bit/dim 1.1042(1.1046) | Xent 0.0404(0.0369) | Loss 1.1243(1.1230) | Error 0.0131(0.0116) Steps 428(428.67) | Grad Norm 0.5658(0.5969) | Total Time 10.00(10.00)\n",
      "Iter 3852 | Time 30.5924(29.8950) | Bit/dim 1.1061(1.1046) | Xent 0.0403(0.0370) | Loss 1.1262(1.1231) | Error 0.0134(0.0117) Steps 428(428.65) | Grad Norm 0.2571(0.5867) | Total Time 10.00(10.00)\n",
      "Iter 3853 | Time 29.5105(29.8835) | Bit/dim 1.1061(1.1047) | Xent 0.0363(0.0369) | Loss 1.1243(1.1231) | Error 0.0124(0.0117) Steps 434(428.81) | Grad Norm 0.9812(0.5985) | Total Time 10.00(10.00)\n",
      "Iter 3854 | Time 30.3352(29.8970) | Bit/dim 1.1032(1.1046) | Xent 0.0379(0.0370) | Loss 1.1221(1.1231) | Error 0.0130(0.0117) Steps 428(428.79) | Grad Norm 0.3172(0.5901) | Total Time 10.00(10.00)\n",
      "Iter 3855 | Time 30.2712(29.9083) | Bit/dim 1.1012(1.1045) | Xent 0.0353(0.0369) | Loss 1.1188(1.1230) | Error 0.0112(0.0117) Steps 428(428.76) | Grad Norm 0.9831(0.6019) | Total Time 10.00(10.00)\n",
      "Iter 3856 | Time 29.7458(29.9034) | Bit/dim 1.1026(1.1045) | Xent 0.0335(0.0368) | Loss 1.1194(1.1229) | Error 0.0095(0.0116) Steps 428(428.74) | Grad Norm 0.2740(0.5920) | Total Time 10.00(10.00)\n",
      "Iter 3857 | Time 28.9167(29.8738) | Bit/dim 1.1051(1.1045) | Xent 0.0355(0.0368) | Loss 1.1228(1.1229) | Error 0.0114(0.0116) Steps 428(428.72) | Grad Norm 0.5427(0.5906) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0551 | Time 16.8026, Epoch Time 239.2017(238.2137), Bit/dim 1.0987(best: 1.0982), Xent 0.0265, Loss 1.1120, Error 0.0087(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3858 | Time 29.9296(29.8755) | Bit/dim 1.1076(1.1046) | Xent 0.0385(0.0368) | Loss 1.1268(1.1230) | Error 0.0116(0.0116) Steps 428(428.70) | Grad Norm 0.2558(0.5805) | Total Time 10.00(10.00)\n",
      "Iter 3859 | Time 30.3232(29.8889) | Bit/dim 1.1064(1.1046) | Xent 0.0346(0.0368) | Loss 1.1237(1.1230) | Error 0.0116(0.0116) Steps 428(428.68) | Grad Norm 0.5319(0.5791) | Total Time 10.00(10.00)\n",
      "Iter 3860 | Time 28.9096(29.8595) | Bit/dim 1.0994(1.1045) | Xent 0.0337(0.0367) | Loss 1.1162(1.1228) | Error 0.0102(0.0116) Steps 428(428.66) | Grad Norm 0.3991(0.5737) | Total Time 10.00(10.00)\n",
      "Iter 3861 | Time 29.6348(29.8528) | Bit/dim 1.1067(1.1045) | Xent 0.0348(0.0366) | Loss 1.1241(1.1229) | Error 0.0105(0.0116) Steps 428(428.64) | Grad Norm 0.3954(0.5683) | Total Time 10.00(10.00)\n",
      "Iter 3862 | Time 29.8966(29.8541) | Bit/dim 1.1007(1.1044) | Xent 0.0348(0.0366) | Loss 1.1181(1.1227) | Error 0.0111(0.0115) Steps 428(428.62) | Grad Norm 0.2990(0.5602) | Total Time 10.00(10.00)\n",
      "Iter 3863 | Time 29.4826(29.8429) | Bit/dim 1.1027(1.1044) | Xent 0.0375(0.0366) | Loss 1.1214(1.1227) | Error 0.0116(0.0115) Steps 428(428.60) | Grad Norm 0.2339(0.5504) | Total Time 10.00(10.00)\n",
      "Iter 3864 | Time 29.6983(29.8386) | Bit/dim 1.1037(1.1044) | Xent 0.0337(0.0365) | Loss 1.1206(1.1226) | Error 0.0109(0.0115) Steps 428(428.58) | Grad Norm 0.2521(0.5415) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0552 | Time 16.6649, Epoch Time 236.8310(238.1722), Bit/dim 1.0985(best: 1.0982), Xent 0.0296, Loss 1.1133, Error 0.0092(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3865 | Time 29.6667(29.8335) | Bit/dim 1.1040(1.1043) | Xent 0.0390(0.0366) | Loss 1.1235(1.1226) | Error 0.0129(0.0116) Steps 434(428.74) | Grad Norm 0.7041(0.5464) | Total Time 10.00(10.00)\n",
      "Iter 3866 | Time 29.2517(29.8160) | Bit/dim 1.1058(1.1044) | Xent 0.0392(0.0366) | Loss 1.1254(1.1227) | Error 0.0121(0.0116) Steps 428(428.72) | Grad Norm 0.4276(0.5428) | Total Time 10.00(10.00)\n",
      "Iter 3867 | Time 29.9379(29.8197) | Bit/dim 1.1013(1.1043) | Xent 0.0355(0.0366) | Loss 1.1190(1.1226) | Error 0.0109(0.0116) Steps 428(428.70) | Grad Norm 0.4796(0.5409) | Total Time 10.00(10.00)\n",
      "Iter 3868 | Time 29.8619(29.8209) | Bit/dim 1.1034(1.1043) | Xent 0.0360(0.0366) | Loss 1.1214(1.1226) | Error 0.0108(0.0115) Steps 428(428.68) | Grad Norm 0.3286(0.5345) | Total Time 10.00(10.00)\n",
      "Iter 3869 | Time 29.5355(29.8124) | Bit/dim 1.1031(1.1042) | Xent 0.0342(0.0365) | Loss 1.1202(1.1225) | Error 0.0108(0.0115) Steps 428(428.66) | Grad Norm 0.3119(0.5279) | Total Time 10.00(10.00)\n",
      "Iter 3870 | Time 29.5971(29.8059) | Bit/dim 1.1076(1.1043) | Xent 0.0385(0.0366) | Loss 1.1269(1.1226) | Error 0.0122(0.0115) Steps 428(428.64) | Grad Norm 0.3574(0.5228) | Total Time 10.00(10.00)\n",
      "Iter 3871 | Time 29.9237(29.8094) | Bit/dim 1.1062(1.1044) | Xent 0.0361(0.0366) | Loss 1.1243(1.1227) | Error 0.0118(0.0115) Steps 428(428.62) | Grad Norm 0.2120(0.5134) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0553 | Time 16.7923, Epoch Time 237.3878(238.1487), Bit/dim 1.0983(best: 1.0982), Xent 0.0319, Loss 1.1142, Error 0.0112(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3872 | Time 29.4810(29.7996) | Bit/dim 1.1087(1.1045) | Xent 0.0318(0.0364) | Loss 1.1246(1.1227) | Error 0.0092(0.0115) Steps 428(428.60) | Grad Norm 0.4502(0.5115) | Total Time 10.00(10.00)\n",
      "Iter 3873 | Time 29.2215(29.7822) | Bit/dim 1.0981(1.1043) | Xent 0.0394(0.0365) | Loss 1.1178(1.1226) | Error 0.0122(0.0115) Steps 428(428.58) | Grad Norm 0.4413(0.5094) | Total Time 10.00(10.00)\n",
      "Iter 3874 | Time 29.9515(29.7873) | Bit/dim 1.1080(1.1044) | Xent 0.0307(0.0363) | Loss 1.1234(1.1226) | Error 0.0095(0.0114) Steps 428(428.56) | Grad Norm 0.4484(0.5076) | Total Time 10.00(10.00)\n",
      "Iter 3875 | Time 29.2040(29.7698) | Bit/dim 1.1000(1.1043) | Xent 0.0345(0.0363) | Loss 1.1172(1.1224) | Error 0.0104(0.0114) Steps 428(428.55) | Grad Norm 0.6112(0.5107) | Total Time 10.00(10.00)\n",
      "Iter 3876 | Time 30.6072(29.7949) | Bit/dim 1.1035(1.1043) | Xent 0.0423(0.0365) | Loss 1.1247(1.1225) | Error 0.0116(0.0114) Steps 428(428.53) | Grad Norm 0.5949(0.5132) | Total Time 10.00(10.00)\n",
      "Iter 3877 | Time 29.8253(29.7959) | Bit/dim 1.1056(1.1043) | Xent 0.0317(0.0363) | Loss 1.1214(1.1225) | Error 0.0102(0.0114) Steps 428(428.52) | Grad Norm 0.3903(0.5095) | Total Time 10.00(10.00)\n",
      "Iter 3878 | Time 29.9571(29.8007) | Bit/dim 1.1035(1.1043) | Xent 0.0377(0.0364) | Loss 1.1223(1.1225) | Error 0.0126(0.0114) Steps 428(428.50) | Grad Norm 0.4053(0.5064) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0554 | Time 16.6810, Epoch Time 237.4171(238.1267), Bit/dim 1.0986(best: 1.0982), Xent 0.0283, Loss 1.1127, Error 0.0095(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3879 | Time 29.5292(29.7925) | Bit/dim 1.1113(1.1045) | Xent 0.0387(0.0364) | Loss 1.1307(1.1227) | Error 0.0130(0.0115) Steps 428(428.48) | Grad Norm 0.2332(0.4982) | Total Time 10.00(10.00)\n",
      "Iter 3880 | Time 30.7077(29.8200) | Bit/dim 1.1026(1.1045) | Xent 0.0296(0.0362) | Loss 1.1174(1.1226) | Error 0.0094(0.0114) Steps 428(428.47) | Grad Norm 0.2151(0.4897) | Total Time 10.00(10.00)\n",
      "Iter 3881 | Time 29.0510(29.7969) | Bit/dim 1.0994(1.1043) | Xent 0.0379(0.0363) | Loss 1.1183(1.1224) | Error 0.0115(0.0114) Steps 428(428.46) | Grad Norm 0.3412(0.4853) | Total Time 10.00(10.00)\n",
      "Iter 3882 | Time 29.9284(29.8009) | Bit/dim 1.1054(1.1043) | Xent 0.0423(0.0365) | Loss 1.1265(1.1226) | Error 0.0135(0.0115) Steps 428(428.44) | Grad Norm 0.2571(0.4784) | Total Time 10.00(10.00)\n",
      "Iter 3883 | Time 30.8929(29.8336) | Bit/dim 1.1016(1.1042) | Xent 0.0418(0.0366) | Loss 1.1225(1.1226) | Error 0.0132(0.0115) Steps 428(428.43) | Grad Norm 0.2312(0.4710) | Total Time 10.00(10.00)\n",
      "Iter 3884 | Time 29.4900(29.8233) | Bit/dim 1.1055(1.1043) | Xent 0.0359(0.0366) | Loss 1.1235(1.1226) | Error 0.0104(0.0115) Steps 428(428.42) | Grad Norm 0.4904(0.4716) | Total Time 10.00(10.00)\n",
      "Iter 3885 | Time 29.7905(29.8223) | Bit/dim 1.1029(1.1042) | Xent 0.0329(0.0365) | Loss 1.1194(1.1225) | Error 0.0108(0.0115) Steps 428(428.40) | Grad Norm 0.3224(0.4671) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0555 | Time 16.6887, Epoch Time 238.6310(238.1419), Bit/dim 1.0985(best: 1.0982), Xent 0.0241, Loss 1.1105, Error 0.0083(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3886 | Time 30.3561(29.8384) | Bit/dim 1.1056(1.1043) | Xent 0.0392(0.0366) | Loss 1.1252(1.1226) | Error 0.0106(0.0114) Steps 428(428.39) | Grad Norm 0.2537(0.4607) | Total Time 10.00(10.00)\n",
      "Iter 3887 | Time 29.7971(29.8371) | Bit/dim 1.1057(1.1043) | Xent 0.0365(0.0366) | Loss 1.1239(1.1226) | Error 0.0110(0.0114) Steps 428(428.38) | Grad Norm 0.1886(0.4525) | Total Time 10.00(10.00)\n",
      "Iter 3888 | Time 29.1947(29.8178) | Bit/dim 1.1010(1.1042) | Xent 0.0351(0.0365) | Loss 1.1186(1.1225) | Error 0.0116(0.0114) Steps 428(428.37) | Grad Norm 0.2730(0.4472) | Total Time 10.00(10.00)\n",
      "Iter 3889 | Time 29.3688(29.8044) | Bit/dim 1.1028(1.1042) | Xent 0.0378(0.0366) | Loss 1.1217(1.1225) | Error 0.0114(0.0114) Steps 428(428.36) | Grad Norm 0.2236(0.4405) | Total Time 10.00(10.00)\n",
      "Iter 3890 | Time 31.3333(29.8502) | Bit/dim 1.1048(1.1042) | Xent 0.0374(0.0366) | Loss 1.1235(1.1225) | Error 0.0126(0.0115) Steps 428(428.35) | Grad Norm 0.2923(0.4360) | Total Time 10.00(10.00)\n",
      "Iter 3891 | Time 30.3546(29.8654) | Bit/dim 1.1041(1.1042) | Xent 0.0332(0.0365) | Loss 1.1207(1.1224) | Error 0.0106(0.0114) Steps 428(428.34) | Grad Norm 0.4017(0.4350) | Total Time 10.00(10.00)\n",
      "Iter 3892 | Time 30.6538(29.8890) | Bit/dim 1.1009(1.1041) | Xent 0.0328(0.0364) | Loss 1.1173(1.1223) | Error 0.0085(0.0114) Steps 428(428.33) | Grad Norm 0.3196(0.4315) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0556 | Time 16.6635, Epoch Time 240.3983(238.2095), Bit/dim 1.0983(best: 1.0982), Xent 0.0269, Loss 1.1117, Error 0.0092(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3893 | Time 29.9841(29.8919) | Bit/dim 1.1037(1.1041) | Xent 0.0342(0.0363) | Loss 1.1208(1.1222) | Error 0.0102(0.0113) Steps 428(428.32) | Grad Norm 0.4542(0.4322) | Total Time 10.00(10.00)\n",
      "Iter 3894 | Time 29.7003(29.8861) | Bit/dim 1.1037(1.1041) | Xent 0.0372(0.0363) | Loss 1.1223(1.1222) | Error 0.0125(0.0114) Steps 428(428.31) | Grad Norm 0.4497(0.4327) | Total Time 10.00(10.00)\n",
      "Iter 3895 | Time 29.8407(29.8848) | Bit/dim 1.1023(1.1040) | Xent 0.0365(0.0363) | Loss 1.1205(1.1222) | Error 0.0115(0.0114) Steps 428(428.30) | Grad Norm 0.6465(0.4391) | Total Time 10.00(10.00)\n",
      "Iter 3896 | Time 30.8003(29.9122) | Bit/dim 1.1037(1.1040) | Xent 0.0383(0.0364) | Loss 1.1229(1.1222) | Error 0.0124(0.0114) Steps 428(428.29) | Grad Norm 0.5360(0.4420) | Total Time 10.00(10.00)\n",
      "Iter 3897 | Time 29.3301(29.8948) | Bit/dim 1.1006(1.1039) | Xent 0.0355(0.0364) | Loss 1.1183(1.1221) | Error 0.0114(0.0114) Steps 428(428.28) | Grad Norm 0.4077(0.4410) | Total Time 10.00(10.00)\n",
      "Iter 3898 | Time 29.8567(29.8936) | Bit/dim 1.1075(1.1040) | Xent 0.0362(0.0364) | Loss 1.1256(1.1222) | Error 0.0115(0.0114) Steps 428(428.27) | Grad Norm 0.9397(0.4560) | Total Time 10.00(10.00)\n",
      "Iter 3899 | Time 29.7152(29.8883) | Bit/dim 1.1075(1.1041) | Xent 0.0359(0.0363) | Loss 1.1255(1.1223) | Error 0.0112(0.0114) Steps 428(428.26) | Grad Norm 0.8331(0.4673) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0557 | Time 16.7155, Epoch Time 238.2462(238.2106), Bit/dim 1.0983(best: 1.0982), Xent 0.0290, Loss 1.1128, Error 0.0105(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3900 | Time 30.9436(29.9199) | Bit/dim 1.1012(1.1040) | Xent 0.0386(0.0364) | Loss 1.1205(1.1222) | Error 0.0124(0.0114) Steps 428(428.26) | Grad Norm 0.6223(0.4719) | Total Time 10.00(10.00)\n",
      "Iter 3901 | Time 28.9732(29.8915) | Bit/dim 1.1049(1.1041) | Xent 0.0308(0.0362) | Loss 1.1203(1.1222) | Error 0.0096(0.0114) Steps 428(428.25) | Grad Norm 0.2925(0.4666) | Total Time 10.00(10.00)\n",
      "Iter 3902 | Time 29.5237(29.8805) | Bit/dim 1.0966(1.1038) | Xent 0.0446(0.0365) | Loss 1.1189(1.1221) | Error 0.0136(0.0114) Steps 428(428.24) | Grad Norm 1.3415(0.4928) | Total Time 10.00(10.00)\n",
      "Iter 3903 | Time 29.7965(29.8780) | Bit/dim 1.1094(1.1040) | Xent 0.0343(0.0364) | Loss 1.1265(1.1222) | Error 0.0111(0.0114) Steps 428(428.23) | Grad Norm 0.4299(0.4909) | Total Time 10.00(10.00)\n",
      "Iter 3904 | Time 29.5092(29.8669) | Bit/dim 1.1078(1.1041) | Xent 0.0340(0.0364) | Loss 1.1248(1.1223) | Error 0.0109(0.0114) Steps 428(428.23) | Grad Norm 1.4364(0.5193) | Total Time 10.00(10.00)\n",
      "Iter 3905 | Time 29.8180(29.8654) | Bit/dim 1.1034(1.1041) | Xent 0.0446(0.0366) | Loss 1.1257(1.1224) | Error 0.0135(0.0115) Steps 428(428.22) | Grad Norm 0.7880(0.5273) | Total Time 10.00(10.00)\n",
      "Iter 3906 | Time 29.7376(29.8616) | Bit/dim 1.1045(1.1041) | Xent 0.0346(0.0365) | Loss 1.1218(1.1224) | Error 0.0101(0.0114) Steps 428(428.21) | Grad Norm 0.7221(0.5332) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0558 | Time 16.8423, Epoch Time 237.4055(238.1865), Bit/dim 1.0985(best: 1.0982), Xent 0.0265, Loss 1.1117, Error 0.0088(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3907 | Time 29.3237(29.8455) | Bit/dim 1.1044(1.1041) | Xent 0.0353(0.0365) | Loss 1.1220(1.1224) | Error 0.0116(0.0114) Steps 428(428.21) | Grad Norm 0.4776(0.5315) | Total Time 10.00(10.00)\n",
      "Iter 3908 | Time 29.8825(29.8466) | Bit/dim 1.1100(1.1043) | Xent 0.0373(0.0365) | Loss 1.1286(1.1226) | Error 0.0118(0.0114) Steps 428(428.20) | Grad Norm 0.5396(0.5318) | Total Time 10.00(10.00)\n",
      "Iter 3909 | Time 30.5956(29.8691) | Bit/dim 1.1028(1.1042) | Xent 0.0338(0.0364) | Loss 1.1197(1.1225) | Error 0.0105(0.0114) Steps 434(428.37) | Grad Norm 0.2457(0.5232) | Total Time 10.00(10.00)\n",
      "Iter 3910 | Time 30.1942(29.8788) | Bit/dim 1.1073(1.1043) | Xent 0.0401(0.0366) | Loss 1.1274(1.1226) | Error 0.0116(0.0114) Steps 428(428.36) | Grad Norm 0.3980(0.5194) | Total Time 10.00(10.00)\n",
      "Iter 3911 | Time 29.8489(29.8779) | Bit/dim 1.0991(1.1042) | Xent 0.0342(0.0365) | Loss 1.1162(1.1224) | Error 0.0098(0.0114) Steps 428(428.35) | Grad Norm 0.4147(0.5163) | Total Time 10.00(10.00)\n",
      "Iter 3912 | Time 29.7160(29.8731) | Bit/dim 1.1015(1.1041) | Xent 0.0338(0.0364) | Loss 1.1185(1.1223) | Error 0.0105(0.0113) Steps 428(428.34) | Grad Norm 0.2933(0.5096) | Total Time 10.00(10.00)\n",
      "Iter 3913 | Time 30.6610(29.8967) | Bit/dim 1.1055(1.1041) | Xent 0.0393(0.0365) | Loss 1.1251(1.1224) | Error 0.0120(0.0114) Steps 428(428.33) | Grad Norm 0.4686(0.5084) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0559 | Time 16.8190, Epoch Time 239.4907(238.2256), Bit/dim 1.0976(best: 1.0982), Xent 0.0260, Loss 1.1106, Error 0.0089(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3914 | Time 29.1517(29.8743) | Bit/dim 1.1044(1.1042) | Xent 0.0386(0.0366) | Loss 1.1237(1.1224) | Error 0.0119(0.0114) Steps 428(428.32) | Grad Norm 0.2923(0.5019) | Total Time 10.00(10.00)\n",
      "Iter 3915 | Time 29.6459(29.8675) | Bit/dim 1.1046(1.1042) | Xent 0.0387(0.0366) | Loss 1.1239(1.1225) | Error 0.0108(0.0114) Steps 428(428.31) | Grad Norm 0.2706(0.4949) | Total Time 10.00(10.00)\n",
      "Iter 3916 | Time 30.4235(29.8842) | Bit/dim 1.1088(1.1043) | Xent 0.0358(0.0366) | Loss 1.1268(1.1226) | Error 0.0111(0.0114) Steps 428(428.30) | Grad Norm 0.2683(0.4881) | Total Time 10.00(10.00)\n",
      "Iter 3917 | Time 30.0317(29.8886) | Bit/dim 1.1050(1.1043) | Xent 0.0355(0.0366) | Loss 1.1228(1.1226) | Error 0.0101(0.0113) Steps 428(428.29) | Grad Norm 0.2696(0.4816) | Total Time 10.00(10.00)\n",
      "Iter 3918 | Time 30.5926(29.9097) | Bit/dim 1.1027(1.1043) | Xent 0.0403(0.0367) | Loss 1.1229(1.1226) | Error 0.0126(0.0114) Steps 434(428.46) | Grad Norm 0.3559(0.4778) | Total Time 10.00(10.00)\n",
      "Iter 3919 | Time 29.4239(29.8951) | Bit/dim 1.1058(1.1043) | Xent 0.0363(0.0367) | Loss 1.1240(1.1227) | Error 0.0119(0.0114) Steps 428(428.45) | Grad Norm 0.5172(0.4790) | Total Time 10.00(10.00)\n",
      "Iter 3920 | Time 29.5640(29.8852) | Bit/dim 1.0977(1.1041) | Xent 0.0347(0.0366) | Loss 1.1151(1.1224) | Error 0.0105(0.0113) Steps 434(428.62) | Grad Norm 0.3358(0.4747) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0560 | Time 16.8760, Epoch Time 238.0559(238.2205), Bit/dim 1.0981(best: 1.0976), Xent 0.0257, Loss 1.1109, Error 0.0085(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3921 | Time 29.4496(29.8721) | Bit/dim 1.0968(1.1039) | Xent 0.0368(0.0366) | Loss 1.1151(1.1222) | Error 0.0115(0.0114) Steps 428(428.60) | Grad Norm 0.3930(0.4722) | Total Time 10.00(10.00)\n",
      "Iter 3922 | Time 29.7348(29.8680) | Bit/dim 1.1072(1.1040) | Xent 0.0389(0.0367) | Loss 1.1267(1.1223) | Error 0.0112(0.0113) Steps 428(428.58) | Grad Norm 0.6919(0.4788) | Total Time 10.00(10.00)\n",
      "Iter 3923 | Time 29.4539(29.8556) | Bit/dim 1.1008(1.1039) | Xent 0.0368(0.0367) | Loss 1.1192(1.1223) | Error 0.0110(0.0113) Steps 428(428.56) | Grad Norm 0.6552(0.4841) | Total Time 10.00(10.00)\n",
      "Iter 3924 | Time 29.8301(29.8548) | Bit/dim 1.1058(1.1040) | Xent 0.0369(0.0367) | Loss 1.1243(1.1223) | Error 0.0121(0.0114) Steps 428(428.55) | Grad Norm 0.4819(0.4841) | Total Time 10.00(10.00)\n",
      "Iter 3925 | Time 29.2500(29.8367) | Bit/dim 1.1065(1.1040) | Xent 0.0356(0.0367) | Loss 1.1243(1.1224) | Error 0.0116(0.0114) Steps 428(428.53) | Grad Norm 0.2382(0.4767) | Total Time 10.00(10.00)\n",
      "Iter 3926 | Time 29.8364(29.8367) | Bit/dim 1.1088(1.1042) | Xent 0.0404(0.0368) | Loss 1.1290(1.1226) | Error 0.0128(0.0114) Steps 428(428.51) | Grad Norm 0.8647(0.4883) | Total Time 10.00(10.00)\n",
      "Iter 3927 | Time 29.1597(29.8164) | Bit/dim 1.1000(1.1041) | Xent 0.0338(0.0367) | Loss 1.1169(1.1224) | Error 0.0110(0.0114) Steps 428(428.50) | Grad Norm 0.4560(0.4874) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0561 | Time 16.7036, Epoch Time 235.9718(238.1531), Bit/dim 1.0977(best: 1.0976), Xent 0.0279, Loss 1.1116, Error 0.0103(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3928 | Time 30.2317(29.8288) | Bit/dim 1.1040(1.1041) | Xent 0.0376(0.0367) | Loss 1.1228(1.1224) | Error 0.0115(0.0114) Steps 434(428.66) | Grad Norm 0.6399(0.4919) | Total Time 10.00(10.00)\n",
      "Iter 3929 | Time 29.4527(29.8175) | Bit/dim 1.1051(1.1041) | Xent 0.0367(0.0367) | Loss 1.1235(1.1224) | Error 0.0115(0.0114) Steps 434(428.82) | Grad Norm 0.6597(0.4970) | Total Time 10.00(10.00)\n",
      "Iter 3930 | Time 29.2048(29.7992) | Bit/dim 1.1024(1.1040) | Xent 0.0387(0.0368) | Loss 1.1218(1.1224) | Error 0.0121(0.0114) Steps 428(428.80) | Grad Norm 0.4142(0.4945) | Total Time 10.00(10.00)\n",
      "Iter 3931 | Time 29.6138(29.7936) | Bit/dim 1.1025(1.1040) | Xent 0.0328(0.0367) | Loss 1.1189(1.1223) | Error 0.0096(0.0114) Steps 428(428.78) | Grad Norm 0.4423(0.4929) | Total Time 10.00(10.00)\n",
      "Iter 3932 | Time 29.8893(29.7965) | Bit/dim 1.1027(1.1040) | Xent 0.0359(0.0366) | Loss 1.1207(1.1223) | Error 0.0121(0.0114) Steps 428(428.75) | Grad Norm 0.9557(0.5068) | Total Time 10.00(10.00)\n",
      "Iter 3933 | Time 30.1499(29.8071) | Bit/dim 1.1106(1.1042) | Xent 0.0393(0.0367) | Loss 1.1302(1.1225) | Error 0.0121(0.0114) Steps 428(428.73) | Grad Norm 0.6096(0.5099) | Total Time 10.00(10.00)\n",
      "Iter 3934 | Time 29.8332(29.8079) | Bit/dim 1.0994(1.1040) | Xent 0.0323(0.0366) | Loss 1.1156(1.1223) | Error 0.0118(0.0114) Steps 428(428.71) | Grad Norm 1.1552(0.5292) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0562 | Time 16.7604, Epoch Time 237.3898(238.1302), Bit/dim 1.0972(best: 1.0976), Xent 0.0277, Loss 1.1110, Error 0.0092(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3935 | Time 30.0946(29.8165) | Bit/dim 1.1045(1.1040) | Xent 0.0332(0.0365) | Loss 1.1211(1.1223) | Error 0.0089(0.0113) Steps 428(428.69) | Grad Norm 0.4933(0.5282) | Total Time 10.00(10.00)\n",
      "Iter 3936 | Time 29.6486(29.8114) | Bit/dim 1.1036(1.1040) | Xent 0.0340(0.0364) | Loss 1.1206(1.1222) | Error 0.0100(0.0113) Steps 428(428.67) | Grad Norm 0.8010(0.5363) | Total Time 10.00(10.00)\n",
      "Iter 3937 | Time 29.8509(29.8126) | Bit/dim 1.1056(1.1041) | Xent 0.0317(0.0363) | Loss 1.1214(1.1222) | Error 0.0095(0.0113) Steps 428(428.65) | Grad Norm 0.2773(0.5286) | Total Time 10.00(10.00)\n",
      "Iter 3938 | Time 29.3693(29.7993) | Bit/dim 1.1003(1.1039) | Xent 0.0394(0.0364) | Loss 1.1200(1.1221) | Error 0.0116(0.0113) Steps 434(428.81) | Grad Norm 0.2606(0.5205) | Total Time 10.00(10.00)\n",
      "Iter 3939 | Time 29.7698(29.7984) | Bit/dim 1.1073(1.1040) | Xent 0.0399(0.0365) | Loss 1.1273(1.1223) | Error 0.0131(0.0113) Steps 428(428.78) | Grad Norm 0.7153(0.5264) | Total Time 10.00(10.00)\n",
      "Iter 3940 | Time 28.9403(29.7727) | Bit/dim 1.1047(1.1041) | Xent 0.0382(0.0365) | Loss 1.1238(1.1223) | Error 0.0120(0.0113) Steps 428(428.76) | Grad Norm 0.2583(0.5183) | Total Time 10.00(10.00)\n",
      "Iter 3941 | Time 29.4063(29.7617) | Bit/dim 1.1015(1.1040) | Xent 0.0428(0.0367) | Loss 1.1229(1.1223) | Error 0.0135(0.0114) Steps 428(428.74) | Grad Norm 1.1496(0.5373) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0563 | Time 16.5759, Epoch Time 235.9606(238.0651), Bit/dim 1.0978(best: 1.0972), Xent 0.0283, Loss 1.1119, Error 0.0096(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3942 | Time 30.9037(29.7959) | Bit/dim 1.1008(1.1039) | Xent 0.0385(0.0368) | Loss 1.1201(1.1223) | Error 0.0118(0.0114) Steps 428(428.71) | Grad Norm 0.6671(0.5412) | Total Time 10.00(10.00)\n",
      "Iter 3943 | Time 31.1644(29.8370) | Bit/dim 1.1061(1.1040) | Xent 0.0336(0.0367) | Loss 1.1229(1.1223) | Error 0.0101(0.0114) Steps 428(428.69) | Grad Norm 1.0225(0.5556) | Total Time 10.00(10.00)\n",
      "Iter 3944 | Time 29.5292(29.8278) | Bit/dim 1.1054(1.1040) | Xent 0.0366(0.0367) | Loss 1.1237(1.1223) | Error 0.0104(0.0113) Steps 428(428.67) | Grad Norm 0.7821(0.5624) | Total Time 10.00(10.00)\n",
      "Iter 3945 | Time 29.9835(29.8324) | Bit/dim 1.1006(1.1039) | Xent 0.0321(0.0365) | Loss 1.1166(1.1222) | Error 0.0091(0.0113) Steps 428(428.65) | Grad Norm 0.7316(0.5675) | Total Time 10.00(10.00)\n",
      "Iter 3946 | Time 29.4892(29.8221) | Bit/dim 1.1015(1.1038) | Xent 0.0354(0.0365) | Loss 1.1191(1.1221) | Error 0.0100(0.0112) Steps 428(428.63) | Grad Norm 0.5168(0.5660) | Total Time 10.00(10.00)\n",
      "Iter 3947 | Time 29.3896(29.8092) | Bit/dim 1.0997(1.1037) | Xent 0.0382(0.0365) | Loss 1.1188(1.1220) | Error 0.0131(0.0113) Steps 428(428.61) | Grad Norm 0.4034(0.5611) | Total Time 10.00(10.00)\n",
      "Iter 3948 | Time 30.8643(29.8408) | Bit/dim 1.1118(1.1039) | Xent 0.0299(0.0363) | Loss 1.1267(1.1221) | Error 0.0099(0.0113) Steps 428(428.59) | Grad Norm 0.2849(0.5528) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0564 | Time 16.9187, Epoch Time 240.5903(238.1408), Bit/dim 1.0981(best: 1.0972), Xent 0.0291, Loss 1.1126, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3949 | Time 29.0108(29.8159) | Bit/dim 1.0971(1.1037) | Xent 0.0328(0.0362) | Loss 1.1136(1.1219) | Error 0.0112(0.0113) Steps 428(428.58) | Grad Norm 0.1893(0.5419) | Total Time 10.00(10.00)\n",
      "Iter 3950 | Time 31.0302(29.8523) | Bit/dim 1.1065(1.1038) | Xent 0.0314(0.0361) | Loss 1.1222(1.1219) | Error 0.0099(0.0112) Steps 428(428.56) | Grad Norm 0.6641(0.5456) | Total Time 10.00(10.00)\n",
      "Iter 3951 | Time 30.5712(29.8739) | Bit/dim 1.1027(1.1038) | Xent 0.0417(0.0363) | Loss 1.1236(1.1219) | Error 0.0135(0.0113) Steps 428(428.54) | Grad Norm 0.5597(0.5460) | Total Time 10.00(10.00)\n",
      "Iter 3952 | Time 29.6719(29.8679) | Bit/dim 1.1072(1.1039) | Xent 0.0295(0.0361) | Loss 1.1219(1.1219) | Error 0.0090(0.0112) Steps 428(428.53) | Grad Norm 1.1137(0.5630) | Total Time 10.00(10.00)\n",
      "Iter 3953 | Time 30.1748(29.8771) | Bit/dim 1.1069(1.1040) | Xent 0.0400(0.0362) | Loss 1.1269(1.1221) | Error 0.0116(0.0112) Steps 428(428.51) | Grad Norm 0.6134(0.5645) | Total Time 10.00(10.00)\n",
      "Iter 3954 | Time 30.1762(29.8860) | Bit/dim 1.1067(1.1041) | Xent 0.0419(0.0363) | Loss 1.1276(1.1222) | Error 0.0124(0.0113) Steps 428(428.50) | Grad Norm 1.2999(0.5866) | Total Time 10.00(10.00)\n",
      "Iter 3955 | Time 29.8016(29.8835) | Bit/dim 1.0992(1.1039) | Xent 0.0341(0.0363) | Loss 1.1163(1.1221) | Error 0.0105(0.0112) Steps 428(428.48) | Grad Norm 0.3352(0.5790) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0565 | Time 16.8791, Epoch Time 240.0058(238.1968), Bit/dim 1.0979(best: 1.0972), Xent 0.0269, Loss 1.1113, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3956 | Time 29.6311(29.8759) | Bit/dim 1.1007(1.1038) | Xent 0.0344(0.0362) | Loss 1.1179(1.1219) | Error 0.0114(0.0112) Steps 434(428.65) | Grad Norm 0.6276(0.5805) | Total Time 10.00(10.00)\n",
      "Iter 3957 | Time 30.2745(29.8879) | Bit/dim 1.1055(1.1039) | Xent 0.0355(0.0362) | Loss 1.1233(1.1220) | Error 0.0108(0.0112) Steps 434(428.81) | Grad Norm 0.4244(0.5758) | Total Time 10.00(10.00)\n",
      "Iter 3958 | Time 29.9318(29.8892) | Bit/dim 1.1024(1.1038) | Xent 0.0406(0.0363) | Loss 1.1227(1.1220) | Error 0.0106(0.0112) Steps 428(428.78) | Grad Norm 0.3042(0.5677) | Total Time 10.00(10.00)\n",
      "Iter 3959 | Time 30.4797(29.9069) | Bit/dim 1.1024(1.1038) | Xent 0.0373(0.0364) | Loss 1.1211(1.1220) | Error 0.0114(0.0112) Steps 428(428.76) | Grad Norm 0.7299(0.5725) | Total Time 10.00(10.00)\n",
      "Iter 3960 | Time 30.0675(29.9117) | Bit/dim 1.1062(1.1039) | Xent 0.0358(0.0363) | Loss 1.1241(1.1220) | Error 0.0122(0.0112) Steps 428(428.74) | Grad Norm 0.6340(0.5744) | Total Time 10.00(10.00)\n",
      "Iter 3961 | Time 29.2939(29.8932) | Bit/dim 1.1035(1.1038) | Xent 0.0343(0.0363) | Loss 1.1207(1.1220) | Error 0.0109(0.0112) Steps 428(428.71) | Grad Norm 0.5798(0.5745) | Total Time 10.00(10.00)\n",
      "Iter 3962 | Time 29.5241(29.8821) | Bit/dim 1.1011(1.1038) | Xent 0.0368(0.0363) | Loss 1.1195(1.1219) | Error 0.0105(0.0112) Steps 428(428.69) | Grad Norm 0.5486(0.5738) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0566 | Time 16.5334, Epoch Time 237.9662(238.1899), Bit/dim 1.0977(best: 1.0972), Xent 0.0290, Loss 1.1122, Error 0.0098(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3963 | Time 30.2874(29.8943) | Bit/dim 1.1045(1.1038) | Xent 0.0381(0.0364) | Loss 1.1236(1.1220) | Error 0.0116(0.0112) Steps 428(428.67) | Grad Norm 0.5110(0.5719) | Total Time 10.00(10.00)\n",
      "Iter 3964 | Time 31.4232(29.9402) | Bit/dim 1.1023(1.1037) | Xent 0.0381(0.0364) | Loss 1.1214(1.1219) | Error 0.0126(0.0113) Steps 428(428.65) | Grad Norm 0.2662(0.5627) | Total Time 10.00(10.00)\n",
      "Iter 3965 | Time 29.6956(29.9328) | Bit/dim 1.1010(1.1037) | Xent 0.0367(0.0364) | Loss 1.1193(1.1219) | Error 0.0115(0.0113) Steps 428(428.63) | Grad Norm 0.4959(0.5607) | Total Time 10.00(10.00)\n",
      "Iter 3966 | Time 31.0794(29.9672) | Bit/dim 1.1010(1.1036) | Xent 0.0362(0.0364) | Loss 1.1190(1.1218) | Error 0.0106(0.0113) Steps 428(428.61) | Grad Norm 0.2539(0.5515) | Total Time 10.00(10.00)\n",
      "Iter 3967 | Time 29.8238(29.9629) | Bit/dim 1.1058(1.1036) | Xent 0.0281(0.0362) | Loss 1.1198(1.1217) | Error 0.0086(0.0112) Steps 428(428.59) | Grad Norm 0.4819(0.5494) | Total Time 10.00(10.00)\n",
      "Iter 3968 | Time 29.4341(29.9470) | Bit/dim 1.1045(1.1037) | Xent 0.0385(0.0362) | Loss 1.1238(1.1218) | Error 0.0128(0.0112) Steps 428(428.58) | Grad Norm 0.3542(0.5436) | Total Time 10.00(10.00)\n",
      "Iter 3969 | Time 28.7875(29.9123) | Bit/dim 1.1032(1.1037) | Xent 0.0392(0.0363) | Loss 1.1229(1.1218) | Error 0.0112(0.0112) Steps 428(428.56) | Grad Norm 0.3593(0.5380) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0567 | Time 16.6540, Epoch Time 239.7343(238.2362), Bit/dim 1.0984(best: 1.0972), Xent 0.0286, Loss 1.1127, Error 0.0105(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3970 | Time 28.8494(29.8804) | Bit/dim 1.1007(1.1036) | Xent 0.0297(0.0361) | Loss 1.1156(1.1216) | Error 0.0096(0.0112) Steps 428(428.54) | Grad Norm 0.5322(0.5379) | Total Time 10.00(10.00)\n",
      "Iter 3971 | Time 29.9733(29.8832) | Bit/dim 1.1032(1.1036) | Xent 0.0400(0.0362) | Loss 1.1232(1.1217) | Error 0.0129(0.0112) Steps 428(428.53) | Grad Norm 1.0578(0.5535) | Total Time 10.00(10.00)\n",
      "Iter 3972 | Time 29.1126(29.8600) | Bit/dim 1.1034(1.1036) | Xent 0.0436(0.0365) | Loss 1.1252(1.1218) | Error 0.0129(0.0113) Steps 428(428.51) | Grad Norm 0.4950(0.5517) | Total Time 10.00(10.00)\n",
      "Iter 3973 | Time 29.4283(29.8471) | Bit/dim 1.1044(1.1036) | Xent 0.0449(0.0367) | Loss 1.1268(1.1219) | Error 0.0136(0.0113) Steps 434(428.68) | Grad Norm 0.3206(0.5448) | Total Time 10.00(10.00)\n",
      "Iter 3974 | Time 30.1652(29.8566) | Bit/dim 1.1091(1.1037) | Xent 0.0313(0.0365) | Loss 1.1247(1.1220) | Error 0.0102(0.0113) Steps 434(428.84) | Grad Norm 0.6608(0.5482) | Total Time 10.00(10.00)\n",
      "Iter 3975 | Time 30.5719(29.8781) | Bit/dim 1.1034(1.1037) | Xent 0.0308(0.0364) | Loss 1.1188(1.1219) | Error 0.0081(0.0112) Steps 428(428.81) | Grad Norm 0.6970(0.5527) | Total Time 10.00(10.00)\n",
      "Iter 3976 | Time 29.1877(29.8574) | Bit/dim 1.1001(1.1036) | Xent 0.0336(0.0363) | Loss 1.1169(1.1218) | Error 0.0105(0.0112) Steps 428(428.79) | Grad Norm 0.6405(0.5553) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0568 | Time 16.4308, Epoch Time 236.1259(238.1729), Bit/dim 1.0979(best: 1.0972), Xent 0.0274, Loss 1.1116, Error 0.0105(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3977 | Time 29.3285(29.8415) | Bit/dim 1.1007(1.1035) | Xent 0.0385(0.0364) | Loss 1.1200(1.1217) | Error 0.0114(0.0112) Steps 428(428.76) | Grad Norm 0.5135(0.5541) | Total Time 10.00(10.00)\n",
      "Iter 3978 | Time 29.0015(29.8163) | Bit/dim 1.1045(1.1036) | Xent 0.0399(0.0365) | Loss 1.1245(1.1218) | Error 0.0114(0.0112) Steps 428(428.74) | Grad Norm 0.8436(0.5628) | Total Time 10.00(10.00)\n",
      "Iter 3979 | Time 30.0218(29.8225) | Bit/dim 1.1053(1.1036) | Xent 0.0357(0.0364) | Loss 1.1231(1.1218) | Error 0.0121(0.0112) Steps 428(428.72) | Grad Norm 0.3256(0.5557) | Total Time 10.00(10.00)\n",
      "Iter 3980 | Time 30.0458(29.8292) | Bit/dim 1.1055(1.1037) | Xent 0.0358(0.0364) | Loss 1.1234(1.1219) | Error 0.0111(0.0112) Steps 428(428.70) | Grad Norm 0.9530(0.5676) | Total Time 10.00(10.00)\n",
      "Iter 3981 | Time 30.2620(29.8422) | Bit/dim 1.1052(1.1037) | Xent 0.0392(0.0365) | Loss 1.1249(1.1220) | Error 0.0115(0.0112) Steps 440(429.03) | Grad Norm 0.4241(0.5633) | Total Time 10.00(10.00)\n",
      "Iter 3982 | Time 29.3745(29.8281) | Bit/dim 1.0970(1.1035) | Xent 0.0370(0.0365) | Loss 1.1155(1.1218) | Error 0.0108(0.0112) Steps 428(429.00) | Grad Norm 0.5776(0.5637) | Total Time 10.00(10.00)\n",
      "Iter 3983 | Time 29.7326(29.8253) | Bit/dim 1.1070(1.1036) | Xent 0.0331(0.0364) | Loss 1.1236(1.1218) | Error 0.0109(0.0112) Steps 428(428.97) | Grad Norm 0.5845(0.5643) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0569 | Time 17.0278, Epoch Time 237.7053(238.1589), Bit/dim 1.0976(best: 1.0972), Xent 0.0268, Loss 1.1111, Error 0.0085(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3984 | Time 30.7486(29.8530) | Bit/dim 1.1018(1.1036) | Xent 0.0333(0.0363) | Loss 1.1185(1.1217) | Error 0.0104(0.0112) Steps 428(428.94) | Grad Norm 0.8364(0.5725) | Total Time 10.00(10.00)\n",
      "Iter 3985 | Time 29.9640(29.8563) | Bit/dim 1.1052(1.1036) | Xent 0.0326(0.0362) | Loss 1.1215(1.1217) | Error 0.0102(0.0112) Steps 428(428.92) | Grad Norm 0.5301(0.5712) | Total Time 10.00(10.00)\n",
      "Iter 3986 | Time 29.6155(29.8491) | Bit/dim 1.1034(1.1036) | Xent 0.0424(0.0364) | Loss 1.1246(1.1218) | Error 0.0132(0.0112) Steps 428(428.89) | Grad Norm 0.7935(0.5779) | Total Time 10.00(10.00)\n",
      "Iter 3987 | Time 30.8041(29.8777) | Bit/dim 1.1056(1.1037) | Xent 0.0291(0.0362) | Loss 1.1201(1.1218) | Error 0.0089(0.0112) Steps 428(428.86) | Grad Norm 0.7278(0.5824) | Total Time 10.00(10.00)\n",
      "Iter 3988 | Time 29.6618(29.8712) | Bit/dim 1.1026(1.1036) | Xent 0.0418(0.0363) | Loss 1.1235(1.1218) | Error 0.0122(0.0112) Steps 428(428.84) | Grad Norm 0.5607(0.5817) | Total Time 10.00(10.00)\n",
      "Iter 3989 | Time 29.6649(29.8651) | Bit/dim 1.1036(1.1036) | Xent 0.0379(0.0364) | Loss 1.1225(1.1218) | Error 0.0119(0.0112) Steps 428(428.81) | Grad Norm 0.6011(0.5823) | Total Time 10.00(10.00)\n",
      "Iter 3990 | Time 29.4666(29.8531) | Bit/dim 1.1014(1.1036) | Xent 0.0332(0.0363) | Loss 1.1180(1.1217) | Error 0.0096(0.0112) Steps 428(428.79) | Grad Norm 0.2550(0.5725) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0570 | Time 16.7333, Epoch Time 239.1397(238.1883), Bit/dim 1.0983(best: 1.0972), Xent 0.0267, Loss 1.1117, Error 0.0099(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3991 | Time 29.3086(29.8368) | Bit/dim 1.1016(1.1035) | Xent 0.0331(0.0362) | Loss 1.1182(1.1216) | Error 0.0108(0.0111) Steps 428(428.76) | Grad Norm 0.4535(0.5689) | Total Time 10.00(10.00)\n",
      "Iter 3992 | Time 30.3678(29.8527) | Bit/dim 1.1069(1.1036) | Xent 0.0351(0.0362) | Loss 1.1245(1.1217) | Error 0.0101(0.0111) Steps 428(428.74) | Grad Norm 0.4783(0.5662) | Total Time 10.00(10.00)\n",
      "Iter 3993 | Time 30.3283(29.8670) | Bit/dim 1.0993(1.1035) | Xent 0.0292(0.0360) | Loss 1.1139(1.1215) | Error 0.0095(0.0111) Steps 428(428.72) | Grad Norm 0.2660(0.5572) | Total Time 10.00(10.00)\n",
      "Iter 3994 | Time 29.4400(29.8542) | Bit/dim 1.1084(1.1036) | Xent 0.0371(0.0360) | Loss 1.1270(1.1216) | Error 0.0126(0.0111) Steps 428(428.70) | Grad Norm 0.6402(0.5597) | Total Time 10.00(10.00)\n",
      "Iter 3995 | Time 29.2980(29.8375) | Bit/dim 1.1068(1.1037) | Xent 0.0325(0.0359) | Loss 1.1230(1.1217) | Error 0.0102(0.0111) Steps 434(428.86) | Grad Norm 0.4200(0.5555) | Total Time 10.00(10.00)\n",
      "Iter 3996 | Time 29.2014(29.8184) | Bit/dim 1.1027(1.1037) | Xent 0.0382(0.0360) | Loss 1.1218(1.1217) | Error 0.0112(0.0111) Steps 428(428.83) | Grad Norm 1.1475(0.5733) | Total Time 10.00(10.00)\n",
      "Iter 3997 | Time 29.5803(29.8113) | Bit/dim 1.1027(1.1037) | Xent 0.0392(0.0361) | Loss 1.1223(1.1217) | Error 0.0128(0.0111) Steps 428(428.81) | Grad Norm 0.3977(0.5680) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0571 | Time 16.6204, Epoch Time 236.8563(238.1483), Bit/dim 1.0974(best: 1.0972), Xent 0.0271, Loss 1.1109, Error 0.0092(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3998 | Time 29.4059(29.7991) | Bit/dim 1.1085(1.1038) | Xent 0.0336(0.0360) | Loss 1.1253(1.1218) | Error 0.0111(0.0111) Steps 428(428.78) | Grad Norm 0.6510(0.5705) | Total Time 10.00(10.00)\n",
      "Iter 3999 | Time 31.5436(29.8514) | Bit/dim 1.1000(1.1037) | Xent 0.0332(0.0359) | Loss 1.1166(1.1216) | Error 0.0121(0.0112) Steps 428(428.76) | Grad Norm 0.2257(0.5601) | Total Time 10.00(10.00)\n",
      "Iter 4000 | Time 29.4688(29.8399) | Bit/dim 1.1017(1.1036) | Xent 0.0382(0.0360) | Loss 1.1208(1.1216) | Error 0.0115(0.0112) Steps 428(428.73) | Grad Norm 0.6007(0.5614) | Total Time 10.00(10.00)\n",
      "Iter 4001 | Time 30.2071(29.8510) | Bit/dim 1.1048(1.1037) | Xent 0.0374(0.0360) | Loss 1.1235(1.1217) | Error 0.0108(0.0112) Steps 428(428.71) | Grad Norm 0.4766(0.5588) | Total Time 10.00(10.00)\n",
      "Iter 4002 | Time 29.5287(29.8413) | Bit/dim 1.1085(1.1038) | Xent 0.0376(0.0361) | Loss 1.1273(1.1218) | Error 0.0109(0.0112) Steps 428(428.69) | Grad Norm 1.0272(0.5729) | Total Time 10.00(10.00)\n",
      "Iter 4003 | Time 29.6096(29.8343) | Bit/dim 1.1032(1.1038) | Xent 0.0337(0.0360) | Loss 1.1200(1.1218) | Error 0.0108(0.0111) Steps 428(428.67) | Grad Norm 0.3257(0.5654) | Total Time 10.00(10.00)\n",
      "Iter 4004 | Time 29.5982(29.8273) | Bit/dim 1.1000(1.1037) | Xent 0.0392(0.0361) | Loss 1.1196(1.1217) | Error 0.0121(0.0112) Steps 428(428.65) | Grad Norm 0.8624(0.5744) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0572 | Time 16.6989, Epoch Time 238.4893(238.1586), Bit/dim 1.0977(best: 1.0972), Xent 0.0267, Loss 1.1110, Error 0.0098(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4005 | Time 30.2493(29.8399) | Bit/dim 1.1027(1.1037) | Xent 0.0371(0.0361) | Loss 1.1212(1.1217) | Error 0.0110(0.0112) Steps 428(428.63) | Grad Norm 0.4657(0.5711) | Total Time 10.00(10.00)\n",
      "Iter 4006 | Time 29.1841(29.8202) | Bit/dim 1.1009(1.1036) | Xent 0.0317(0.0360) | Loss 1.1168(1.1216) | Error 0.0100(0.0111) Steps 428(428.61) | Grad Norm 1.0664(0.5860) | Total Time 10.00(10.00)\n",
      "Iter 4007 | Time 29.5650(29.8126) | Bit/dim 1.1097(1.1038) | Xent 0.0394(0.0361) | Loss 1.1294(1.1218) | Error 0.0121(0.0112) Steps 434(428.77) | Grad Norm 0.4095(0.5807) | Total Time 10.00(10.00)\n",
      "Iter 4008 | Time 29.3045(29.7973) | Bit/dim 1.1043(1.1038) | Xent 0.0373(0.0361) | Loss 1.1230(1.1218) | Error 0.0125(0.0112) Steps 428(428.75) | Grad Norm 0.6653(0.5832) | Total Time 10.00(10.00)\n",
      "Iter 4009 | Time 30.3775(29.8147) | Bit/dim 1.1034(1.1038) | Xent 0.0354(0.0361) | Loss 1.1211(1.1218) | Error 0.0125(0.0112) Steps 428(428.73) | Grad Norm 0.2286(0.5726) | Total Time 10.00(10.00)\n",
      "Iter 4010 | Time 29.8863(29.8169) | Bit/dim 1.1009(1.1037) | Xent 0.0377(0.0361) | Loss 1.1197(1.1217) | Error 0.0114(0.0112) Steps 428(428.71) | Grad Norm 0.2123(0.5618) | Total Time 10.00(10.00)\n",
      "Iter 4011 | Time 30.6015(29.8404) | Bit/dim 1.1009(1.1036) | Xent 0.0359(0.0361) | Loss 1.1189(1.1217) | Error 0.0109(0.0112) Steps 434(428.86) | Grad Norm 0.9047(0.5720) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0573 | Time 17.0380, Epoch Time 238.8229(238.1785), Bit/dim 1.0976(best: 1.0972), Xent 0.0297, Loss 1.1124, Error 0.0102(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4012 | Time 30.1765(29.8505) | Bit/dim 1.1048(1.1036) | Xent 0.0321(0.0360) | Loss 1.1209(1.1216) | Error 0.0092(0.0112) Steps 428(428.84) | Grad Norm 0.7824(0.5784) | Total Time 10.00(10.00)\n",
      "Iter 4013 | Time 29.5614(29.8418) | Bit/dim 1.1026(1.1036) | Xent 0.0392(0.0361) | Loss 1.1222(1.1217) | Error 0.0104(0.0112) Steps 428(428.81) | Grad Norm 0.6090(0.5793) | Total Time 10.00(10.00)\n",
      "Iter 4014 | Time 29.3652(29.8275) | Bit/dim 1.1059(1.1037) | Xent 0.0402(0.0362) | Loss 1.1260(1.1218) | Error 0.0118(0.0112) Steps 428(428.79) | Grad Norm 0.3137(0.5713) | Total Time 10.00(10.00)\n",
      "Iter 4015 | Time 31.4943(29.8775) | Bit/dim 1.1002(1.1036) | Xent 0.0365(0.0362) | Loss 1.1184(1.1217) | Error 0.0110(0.0112) Steps 428(428.77) | Grad Norm 1.2321(0.5911) | Total Time 10.00(10.00)\n",
      "Iter 4016 | Time 29.2663(29.8592) | Bit/dim 1.1027(1.1035) | Xent 0.0309(0.0361) | Loss 1.1182(1.1216) | Error 0.0104(0.0111) Steps 428(428.74) | Grad Norm 0.3860(0.5850) | Total Time 10.00(10.00)\n",
      "Iter 4017 | Time 29.1262(29.8372) | Bit/dim 1.1036(1.1035) | Xent 0.0406(0.0362) | Loss 1.1239(1.1216) | Error 0.0138(0.0112) Steps 428(428.72) | Grad Norm 1.0319(0.5984) | Total Time 10.00(10.00)\n",
      "Iter 4018 | Time 30.7239(29.8638) | Bit/dim 1.1036(1.1035) | Xent 0.0329(0.0361) | Loss 1.1201(1.1216) | Error 0.0111(0.0112) Steps 434(428.88) | Grad Norm 0.4529(0.5940) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0574 | Time 16.7674, Epoch Time 238.9249(238.2009), Bit/dim 1.0971(best: 1.0972), Xent 0.0272, Loss 1.1107, Error 0.0092(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4019 | Time 29.4535(29.8515) | Bit/dim 1.1037(1.1035) | Xent 0.0417(0.0363) | Loss 1.1246(1.1217) | Error 0.0128(0.0113) Steps 428(428.85) | Grad Norm 0.6830(0.5967) | Total Time 10.00(10.00)\n",
      "Iter 4020 | Time 30.0956(29.8588) | Bit/dim 1.1050(1.1036) | Xent 0.0375(0.0363) | Loss 1.1237(1.1217) | Error 0.0118(0.0113) Steps 428(428.83) | Grad Norm 0.2339(0.5858) | Total Time 10.00(10.00)\n",
      "Iter 4021 | Time 30.0780(29.8654) | Bit/dim 1.1058(1.1037) | Xent 0.0318(0.0362) | Loss 1.1217(1.1217) | Error 0.0098(0.0112) Steps 428(428.80) | Grad Norm 0.7671(0.5912) | Total Time 10.00(10.00)\n",
      "Iter 4022 | Time 30.0999(29.8724) | Bit/dim 1.1028(1.1036) | Xent 0.0421(0.0364) | Loss 1.1238(1.1218) | Error 0.0119(0.0113) Steps 428(428.78) | Grad Norm 0.3185(0.5831) | Total Time 10.00(10.00)\n",
      "Iter 4023 | Time 30.4608(29.8901) | Bit/dim 1.1056(1.1037) | Xent 0.0356(0.0363) | Loss 1.1234(1.1219) | Error 0.0126(0.0113) Steps 428(428.75) | Grad Norm 0.3912(0.5773) | Total Time 10.00(10.00)\n",
      "Iter 4024 | Time 29.8218(29.8880) | Bit/dim 1.0949(1.1034) | Xent 0.0394(0.0364) | Loss 1.1146(1.1216) | Error 0.0124(0.0113) Steps 434(428.91) | Grad Norm 0.4747(0.5742) | Total Time 10.00(10.00)\n",
      "Iter 4025 | Time 29.5985(29.8794) | Bit/dim 1.1047(1.1035) | Xent 0.0332(0.0363) | Loss 1.1213(1.1216) | Error 0.0114(0.0113) Steps 428(428.88) | Grad Norm 0.2559(0.5647) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0575 | Time 16.9625, Epoch Time 239.2119(238.2312), Bit/dim 1.0982(best: 1.0971), Xent 0.0265, Loss 1.1114, Error 0.0086(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4026 | Time 29.4991(29.8679) | Bit/dim 1.0987(1.1033) | Xent 0.0359(0.0363) | Loss 1.1167(1.1215) | Error 0.0114(0.0113) Steps 428(428.86) | Grad Norm 1.0865(0.5803) | Total Time 10.00(10.00)\n",
      "Iter 4027 | Time 29.3252(29.8517) | Bit/dim 1.1045(1.1034) | Xent 0.0394(0.0364) | Loss 1.1242(1.1216) | Error 0.0118(0.0113) Steps 428(428.83) | Grad Norm 0.2764(0.5712) | Total Time 10.00(10.00)\n",
      "Iter 4028 | Time 30.7028(29.8772) | Bit/dim 1.1066(1.1035) | Xent 0.0328(0.0363) | Loss 1.1230(1.1216) | Error 0.0105(0.0113) Steps 434(428.99) | Grad Norm 1.0580(0.5858) | Total Time 10.00(10.00)\n",
      "Iter 4029 | Time 29.4034(29.8630) | Bit/dim 1.1048(1.1035) | Xent 0.0293(0.0361) | Loss 1.1194(1.1215) | Error 0.0094(0.0113) Steps 428(428.96) | Grad Norm 0.2395(0.5754) | Total Time 10.00(10.00)\n",
      "Iter 4030 | Time 29.7755(29.8604) | Bit/dim 1.1052(1.1035) | Xent 0.0397(0.0362) | Loss 1.1251(1.1216) | Error 0.0115(0.0113) Steps 434(429.11) | Grad Norm 0.6489(0.5776) | Total Time 10.00(10.00)\n",
      "Iter 4031 | Time 29.7412(29.8568) | Bit/dim 1.1048(1.1036) | Xent 0.0285(0.0360) | Loss 1.1190(1.1216) | Error 0.0092(0.0112) Steps 428(429.08) | Grad Norm 0.6905(0.5810) | Total Time 10.00(10.00)\n",
      "Iter 4032 | Time 31.4849(29.9056) | Bit/dim 1.0990(1.1034) | Xent 0.0337(0.0359) | Loss 1.1159(1.1214) | Error 0.0102(0.0112) Steps 440(429.40) | Grad Norm 1.3239(0.6033) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0576 | Time 16.7640, Epoch Time 239.1687(238.2593), Bit/dim 1.0969(best: 1.0971), Xent 0.0285, Loss 1.1112, Error 0.0096(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4033 | Time 29.8585(29.9042) | Bit/dim 1.1080(1.1036) | Xent 0.0335(0.0358) | Loss 1.1247(1.1215) | Error 0.0109(0.0112) Steps 428(429.36) | Grad Norm 0.3797(0.5966) | Total Time 10.00(10.00)\n",
      "Iter 4034 | Time 30.5652(29.9240) | Bit/dim 1.1032(1.1036) | Xent 0.0367(0.0359) | Loss 1.1216(1.1215) | Error 0.0118(0.0112) Steps 428(429.32) | Grad Norm 1.3338(0.6187) | Total Time 10.00(10.00)\n",
      "Iter 4035 | Time 29.6589(29.9161) | Bit/dim 1.1036(1.1036) | Xent 0.0357(0.0359) | Loss 1.1214(1.1215) | Error 0.0120(0.0112) Steps 428(429.28) | Grad Norm 0.1907(0.6059) | Total Time 10.00(10.00)\n",
      "Iter 4036 | Time 31.1422(29.9529) | Bit/dim 1.0945(1.1033) | Xent 0.0330(0.0358) | Loss 1.1109(1.1212) | Error 0.0095(0.0112) Steps 434(429.42) | Grad Norm 0.8815(0.6141) | Total Time 10.00(10.00)\n",
      "Iter 4037 | Time 29.8331(29.9493) | Bit/dim 1.1053(1.1034) | Xent 0.0409(0.0359) | Loss 1.1258(1.1213) | Error 0.0130(0.0112) Steps 428(429.38) | Grad Norm 0.4303(0.6086) | Total Time 10.00(10.00)\n",
      "Iter 4038 | Time 30.1567(29.9555) | Bit/dim 1.1042(1.1034) | Xent 0.0330(0.0358) | Loss 1.1207(1.1213) | Error 0.0102(0.0112) Steps 428(429.34) | Grad Norm 0.7284(0.6122) | Total Time 10.00(10.00)\n",
      "Iter 4039 | Time 29.4400(29.9400) | Bit/dim 1.1023(1.1033) | Xent 0.0365(0.0359) | Loss 1.1206(1.1213) | Error 0.0114(0.0112) Steps 434(429.48) | Grad Norm 0.6036(0.6120) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0577 | Time 16.7916, Epoch Time 240.0048(238.3117), Bit/dim 1.0971(best: 1.0969), Xent 0.0273, Loss 1.1107, Error 0.0102(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4040 | Time 30.9458(29.9702) | Bit/dim 1.1035(1.1034) | Xent 0.0302(0.0357) | Loss 1.1186(1.1212) | Error 0.0092(0.0111) Steps 434(429.61) | Grad Norm 1.1932(0.6294) | Total Time 10.00(10.00)\n",
      "Iter 4041 | Time 30.4821(29.9856) | Bit/dim 1.1052(1.1034) | Xent 0.0341(0.0356) | Loss 1.1223(1.1212) | Error 0.0105(0.0111) Steps 428(429.57) | Grad Norm 0.4140(0.6229) | Total Time 10.00(10.00)\n",
      "Iter 4042 | Time 30.9615(30.0148) | Bit/dim 1.1054(1.1035) | Xent 0.0380(0.0357) | Loss 1.1244(1.1213) | Error 0.0122(0.0111) Steps 434(429.70) | Grad Norm 0.7453(0.6266) | Total Time 10.00(10.00)\n",
      "Iter 4043 | Time 29.5160(29.9999) | Bit/dim 1.1029(1.1035) | Xent 0.0409(0.0359) | Loss 1.1233(1.1214) | Error 0.0128(0.0112) Steps 428(429.65) | Grad Norm 0.7136(0.6292) | Total Time 10.00(10.00)\n",
      "Iter 4044 | Time 29.4032(29.9820) | Bit/dim 1.1042(1.1035) | Xent 0.0341(0.0358) | Loss 1.1212(1.1214) | Error 0.0111(0.0112) Steps 428(429.60) | Grad Norm 0.3316(0.6203) | Total Time 10.00(10.00)\n",
      "Iter 4045 | Time 31.0560(30.0142) | Bit/dim 1.0974(1.1033) | Xent 0.0418(0.0360) | Loss 1.1183(1.1213) | Error 0.0128(0.0112) Steps 434(429.73) | Grad Norm 0.4257(0.6145) | Total Time 10.00(10.00)\n",
      "Iter 4046 | Time 31.5504(30.0603) | Bit/dim 1.1032(1.1033) | Xent 0.0334(0.0359) | Loss 1.1199(1.1212) | Error 0.0111(0.0112) Steps 428(429.68) | Grad Norm 0.3326(0.6060) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0578 | Time 16.6968, Epoch Time 243.1241(238.4561), Bit/dim 1.0979(best: 1.0969), Xent 0.0286, Loss 1.1122, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4047 | Time 29.7126(30.0499) | Bit/dim 1.1022(1.1033) | Xent 0.0360(0.0359) | Loss 1.1202(1.1212) | Error 0.0111(0.0112) Steps 428(429.63) | Grad Norm 0.3217(0.5975) | Total Time 10.00(10.00)\n",
      "Iter 4048 | Time 29.9113(30.0457) | Bit/dim 1.1030(1.1032) | Xent 0.0441(0.0362) | Loss 1.1251(1.1213) | Error 0.0128(0.0113) Steps 428(429.58) | Grad Norm 0.3520(0.5901) | Total Time 10.00(10.00)\n",
      "Iter 4049 | Time 29.6309(30.0333) | Bit/dim 1.1005(1.1032) | Xent 0.0326(0.0361) | Loss 1.1168(1.1212) | Error 0.0105(0.0113) Steps 428(429.53) | Grad Norm 0.4288(0.5853) | Total Time 10.00(10.00)\n",
      "Iter 4050 | Time 30.6966(30.0532) | Bit/dim 1.1048(1.1032) | Xent 0.0353(0.0360) | Loss 1.1224(1.1212) | Error 0.0108(0.0112) Steps 428(429.49) | Grad Norm 0.3762(0.5790) | Total Time 10.00(10.00)\n",
      "Iter 4051 | Time 30.5977(30.0695) | Bit/dim 1.1046(1.1033) | Xent 0.0328(0.0359) | Loss 1.1210(1.1212) | Error 0.0104(0.0112) Steps 434(429.62) | Grad Norm 0.4379(0.5748) | Total Time 10.00(10.00)\n",
      "Iter 4052 | Time 29.9242(30.0651) | Bit/dim 1.1043(1.1033) | Xent 0.0366(0.0360) | Loss 1.1226(1.1213) | Error 0.0121(0.0112) Steps 428(429.57) | Grad Norm 0.2263(0.5643) | Total Time 10.00(10.00)\n",
      "Iter 4053 | Time 29.5146(30.0486) | Bit/dim 1.1028(1.1033) | Xent 0.0346(0.0359) | Loss 1.1202(1.1212) | Error 0.0102(0.0112) Steps 428(429.53) | Grad Norm 0.7110(0.5687) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0579 | Time 16.7983, Epoch Time 239.2205(238.4790), Bit/dim 1.0976(best: 1.0969), Xent 0.0264, Loss 1.1107, Error 0.0087(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4054 | Time 30.9881(30.0768) | Bit/dim 1.0984(1.1031) | Xent 0.0383(0.0360) | Loss 1.1175(1.1211) | Error 0.0130(0.0113) Steps 428(429.48) | Grad Norm 0.5833(0.5691) | Total Time 10.00(10.00)\n",
      "Iter 4055 | Time 29.6285(30.0634) | Bit/dim 1.1032(1.1031) | Xent 0.0339(0.0359) | Loss 1.1202(1.1211) | Error 0.0116(0.0113) Steps 428(429.44) | Grad Norm 0.2759(0.5604) | Total Time 10.00(10.00)\n",
      "Iter 4056 | Time 30.9403(30.0897) | Bit/dim 1.1028(1.1031) | Xent 0.0314(0.0358) | Loss 1.1185(1.1210) | Error 0.0100(0.0112) Steps 434(429.57) | Grad Norm 0.2323(0.5505) | Total Time 10.00(10.00)\n",
      "Iter 4057 | Time 31.4402(30.1302) | Bit/dim 1.1019(1.1031) | Xent 0.0319(0.0357) | Loss 1.1179(1.1209) | Error 0.0098(0.0112) Steps 428(429.53) | Grad Norm 0.2385(0.5412) | Total Time 10.00(10.00)\n",
      "Iter 4058 | Time 30.3014(30.1353) | Bit/dim 1.1051(1.1031) | Xent 0.0398(0.0358) | Loss 1.1250(1.1210) | Error 0.0114(0.0112) Steps 428(429.48) | Grad Norm 0.4002(0.5369) | Total Time 10.00(10.00)\n",
      "Iter 4059 | Time 31.7233(30.1830) | Bit/dim 1.1027(1.1031) | Xent 0.0387(0.0359) | Loss 1.1221(1.1211) | Error 0.0112(0.0112) Steps 428(429.43) | Grad Norm 0.4343(0.5338) | Total Time 10.00(10.00)\n",
      "Iter 4060 | Time 31.0553(30.2091) | Bit/dim 1.1046(1.1032) | Xent 0.0386(0.0360) | Loss 1.1239(1.1212) | Error 0.0125(0.0112) Steps 428(429.39) | Grad Norm 0.4497(0.5313) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0580 | Time 16.8222, Epoch Time 245.5043(238.6898), Bit/dim 1.0971(best: 1.0969), Xent 0.0274, Loss 1.1108, Error 0.0100(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4061 | Time 31.8740(30.2591) | Bit/dim 1.1036(1.1032) | Xent 0.0295(0.0358) | Loss 1.1184(1.1211) | Error 0.0088(0.0112) Steps 428(429.35) | Grad Norm 0.5623(0.5322) | Total Time 10.00(10.00)\n",
      "Iter 4062 | Time 30.4179(30.2638) | Bit/dim 1.1065(1.1033) | Xent 0.0375(0.0358) | Loss 1.1252(1.1212) | Error 0.0115(0.0112) Steps 434(429.49) | Grad Norm 0.4164(0.5288) | Total Time 10.00(10.00)\n",
      "Iter 4063 | Time 30.9244(30.2837) | Bit/dim 1.1075(1.1034) | Xent 0.0331(0.0357) | Loss 1.1241(1.1213) | Error 0.0095(0.0111) Steps 434(429.62) | Grad Norm 0.2509(0.5204) | Total Time 10.00(10.00)\n",
      "Iter 4064 | Time 31.0651(30.3071) | Bit/dim 1.1049(1.1035) | Xent 0.0354(0.0357) | Loss 1.1226(1.1213) | Error 0.0110(0.0111) Steps 428(429.58) | Grad Norm 0.2518(0.5124) | Total Time 10.00(10.00)\n",
      "Iter 4065 | Time 30.9141(30.3253) | Bit/dim 1.0987(1.1033) | Xent 0.0353(0.0357) | Loss 1.1163(1.1212) | Error 0.0111(0.0111) Steps 434(429.71) | Grad Norm 0.2528(0.5046) | Total Time 10.00(10.00)\n",
      "Iter 4066 | Time 31.2863(30.3541) | Bit/dim 1.1014(1.1033) | Xent 0.0269(0.0355) | Loss 1.1149(1.1210) | Error 0.0090(0.0111) Steps 434(429.84) | Grad Norm 0.6124(0.5078) | Total Time 10.00(10.00)\n",
      "Iter 4067 | Time 30.7888(30.3672) | Bit/dim 1.0975(1.1031) | Xent 0.0399(0.0356) | Loss 1.1174(1.1209) | Error 0.0118(0.0111) Steps 434(429.96) | Grad Norm 0.4967(0.5075) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0581 | Time 16.5510, Epoch Time 246.7911(238.9328), Bit/dim 1.0974(best: 1.0969), Xent 0.0277, Loss 1.1113, Error 0.0091(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4068 | Time 31.4697(30.4002) | Bit/dim 1.1010(1.1030) | Xent 0.0364(0.0356) | Loss 1.1192(1.1208) | Error 0.0108(0.0111) Steps 428(429.90) | Grad Norm 0.2270(0.4991) | Total Time 10.00(10.00)\n",
      "Iter 4069 | Time 30.9304(30.4162) | Bit/dim 1.1081(1.1032) | Xent 0.0327(0.0355) | Loss 1.1244(1.1209) | Error 0.0108(0.0111) Steps 428(429.85) | Grad Norm 0.4099(0.4964) | Total Time 10.00(10.00)\n",
      "Iter 4070 | Time 31.2173(30.4402) | Bit/dim 1.1084(1.1033) | Xent 0.0407(0.0357) | Loss 1.1287(1.1212) | Error 0.0124(0.0111) Steps 434(429.97) | Grad Norm 0.5569(0.4982) | Total Time 10.00(10.00)\n",
      "Iter 4071 | Time 30.3197(30.4366) | Bit/dim 1.0991(1.1032) | Xent 0.0330(0.0356) | Loss 1.1156(1.1210) | Error 0.0109(0.0111) Steps 434(430.09) | Grad Norm 0.2351(0.4903) | Total Time 10.00(10.00)\n",
      "Iter 4072 | Time 30.3428(30.4338) | Bit/dim 1.1021(1.1032) | Xent 0.0340(0.0356) | Loss 1.1191(1.1209) | Error 0.0105(0.0111) Steps 434(430.21) | Grad Norm 0.5443(0.4919) | Total Time 10.00(10.00)\n",
      "Iter 4073 | Time 31.5231(30.4664) | Bit/dim 1.1002(1.1031) | Xent 0.0339(0.0355) | Loss 1.1172(1.1208) | Error 0.0106(0.0111) Steps 434(430.32) | Grad Norm 0.2517(0.4847) | Total Time 10.00(10.00)\n",
      "Iter 4074 | Time 30.8203(30.4771) | Bit/dim 1.1026(1.1031) | Xent 0.0371(0.0355) | Loss 1.1211(1.1208) | Error 0.0115(0.0111) Steps 434(430.43) | Grad Norm 0.7847(0.4937) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0582 | Time 16.5588, Epoch Time 245.6065(239.1330), Bit/dim 1.0969(best: 1.0969), Xent 0.0259, Loss 1.1099, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4075 | Time 31.7724(30.5159) | Bit/dim 1.1005(1.1030) | Xent 0.0356(0.0356) | Loss 1.1183(1.1208) | Error 0.0106(0.0111) Steps 428(430.36) | Grad Norm 1.2560(0.5166) | Total Time 10.00(10.00)\n",
      "Iter 4076 | Time 30.7785(30.5238) | Bit/dim 1.1031(1.1030) | Xent 0.0324(0.0355) | Loss 1.1193(1.1207) | Error 0.0105(0.0110) Steps 434(430.47) | Grad Norm 0.2359(0.5082) | Total Time 10.00(10.00)\n",
      "Iter 4077 | Time 30.8146(30.5325) | Bit/dim 1.1071(1.1031) | Xent 0.0425(0.0357) | Loss 1.1284(1.1210) | Error 0.0125(0.0111) Steps 434(430.58) | Grad Norm 1.1565(0.5276) | Total Time 10.00(10.00)\n",
      "Iter 4078 | Time 31.7355(30.5686) | Bit/dim 1.1030(1.1031) | Xent 0.0356(0.0357) | Loss 1.1208(1.1209) | Error 0.0108(0.0111) Steps 434(430.68) | Grad Norm 0.2166(0.5183) | Total Time 10.00(10.00)\n",
      "Iter 4079 | Time 29.7097(30.5428) | Bit/dim 1.1034(1.1031) | Xent 0.0370(0.0357) | Loss 1.1219(1.1210) | Error 0.0102(0.0111) Steps 428(430.60) | Grad Norm 1.0391(0.5339) | Total Time 10.00(10.00)\n",
      "Iter 4080 | Time 30.3542(30.5372) | Bit/dim 1.1021(1.1031) | Xent 0.0361(0.0357) | Loss 1.1202(1.1210) | Error 0.0102(0.0110) Steps 434(430.70) | Grad Norm 0.2382(0.5251) | Total Time 10.00(10.00)\n",
      "Iter 4081 | Time 30.4425(30.5343) | Bit/dim 1.1062(1.1032) | Xent 0.0351(0.0357) | Loss 1.1237(1.1210) | Error 0.0114(0.0110) Steps 428(430.62) | Grad Norm 0.8659(0.5353) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0583 | Time 16.8725, Epoch Time 245.0507(239.3105), Bit/dim 1.0976(best: 1.0969), Xent 0.0270, Loss 1.1111, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4082 | Time 30.4361(30.5314) | Bit/dim 1.1025(1.1032) | Xent 0.0410(0.0359) | Loss 1.1230(1.1211) | Error 0.0131(0.0111) Steps 440(430.90) | Grad Norm 0.2272(0.5260) | Total Time 10.00(10.00)\n",
      "Iter 4083 | Time 32.0929(30.5782) | Bit/dim 1.1041(1.1032) | Xent 0.0368(0.0359) | Loss 1.1225(1.1211) | Error 0.0122(0.0111) Steps 428(430.81) | Grad Norm 0.8128(0.5346) | Total Time 10.00(10.00)\n",
      "Iter 4084 | Time 30.8971(30.5878) | Bit/dim 1.1032(1.1032) | Xent 0.0312(0.0357) | Loss 1.1188(1.1211) | Error 0.0094(0.0111) Steps 440(431.09) | Grad Norm 0.1985(0.5246) | Total Time 10.00(10.00)\n",
      "Iter 4085 | Time 30.8749(30.5964) | Bit/dim 1.1010(1.1031) | Xent 0.0323(0.0356) | Loss 1.1171(1.1209) | Error 0.0112(0.0111) Steps 434(431.18) | Grad Norm 1.1208(0.5424) | Total Time 10.00(10.00)\n",
      "Iter 4086 | Time 31.8636(30.6344) | Bit/dim 1.1057(1.1032) | Xent 0.0361(0.0357) | Loss 1.1238(1.1210) | Error 0.0122(0.0111) Steps 434(431.26) | Grad Norm 0.5183(0.5417) | Total Time 10.00(10.00)\n",
      "Iter 4087 | Time 30.6018(30.6335) | Bit/dim 1.1034(1.1032) | Xent 0.0326(0.0356) | Loss 1.1198(1.1210) | Error 0.0110(0.0111) Steps 434(431.34) | Grad Norm 1.0926(0.5582) | Total Time 10.00(10.00)\n",
      "Iter 4088 | Time 30.9794(30.6438) | Bit/dim 1.1000(1.1031) | Xent 0.0383(0.0357) | Loss 1.1191(1.1209) | Error 0.0119(0.0111) Steps 434(431.42) | Grad Norm 1.5086(0.5868) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0584 | Time 16.8238, Epoch Time 246.9104(239.5385), Bit/dim 1.0968(best: 1.0969), Xent 0.0284, Loss 1.1110, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4089 | Time 30.9092(30.6518) | Bit/dim 1.1045(1.1032) | Xent 0.0354(0.0356) | Loss 1.1221(1.1210) | Error 0.0115(0.0112) Steps 440(431.68) | Grad Norm 0.3548(0.5798) | Total Time 10.00(10.00)\n",
      "Iter 4090 | Time 30.9776(30.6616) | Bit/dim 1.1004(1.1031) | Xent 0.0343(0.0356) | Loss 1.1176(1.1209) | Error 0.0114(0.0112) Steps 428(431.57) | Grad Norm 0.9305(0.5903) | Total Time 10.00(10.00)\n",
      "Iter 4091 | Time 32.2546(30.7094) | Bit/dim 1.0981(1.1029) | Xent 0.0353(0.0356) | Loss 1.1158(1.1207) | Error 0.0108(0.0111) Steps 434(431.64) | Grad Norm 0.5022(0.5877) | Total Time 10.00(10.00)\n",
      "Iter 4092 | Time 32.2653(30.7560) | Bit/dim 1.1065(1.1030) | Xent 0.0354(0.0356) | Loss 1.1242(1.1208) | Error 0.0108(0.0111) Steps 446(432.07) | Grad Norm 0.6229(0.5887) | Total Time 10.00(10.00)\n",
      "Iter 4093 | Time 31.2304(30.7703) | Bit/dim 1.1042(1.1031) | Xent 0.0347(0.0356) | Loss 1.1215(1.1208) | Error 0.0096(0.0111) Steps 440(432.31) | Grad Norm 0.2836(0.5796) | Total Time 10.00(10.00)\n",
      "Iter 4094 | Time 31.1498(30.7817) | Bit/dim 1.1007(1.1030) | Xent 0.0354(0.0356) | Loss 1.1184(1.1208) | Error 0.0110(0.0111) Steps 428(432.18) | Grad Norm 0.7350(0.5842) | Total Time 10.00(10.00)\n",
      "Iter 4095 | Time 31.1508(30.7927) | Bit/dim 1.1054(1.1031) | Xent 0.0298(0.0354) | Loss 1.1203(1.1208) | Error 0.0089(0.0110) Steps 434(432.24) | Grad Norm 0.2904(0.5754) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0585 | Time 16.9445, Epoch Time 249.3756(239.8337), Bit/dim 1.0977(best: 1.0968), Xent 0.0284, Loss 1.1119, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4096 | Time 30.1782(30.7743) | Bit/dim 1.1056(1.1031) | Xent 0.0314(0.0353) | Loss 1.1213(1.1208) | Error 0.0105(0.0110) Steps 434(432.29) | Grad Norm 0.9637(0.5871) | Total Time 10.00(10.00)\n",
      "Iter 4097 | Time 31.1153(30.7845) | Bit/dim 1.1040(1.1032) | Xent 0.0391(0.0354) | Loss 1.1235(1.1209) | Error 0.0122(0.0110) Steps 440(432.52) | Grad Norm 0.2886(0.5781) | Total Time 10.00(10.00)\n",
      "Iter 4098 | Time 31.1048(30.7941) | Bit/dim 1.1005(1.1031) | Xent 0.0300(0.0352) | Loss 1.1155(1.1207) | Error 0.0106(0.0110) Steps 428(432.38) | Grad Norm 0.6318(0.5797) | Total Time 10.00(10.00)\n",
      "Iter 4099 | Time 31.6594(30.8201) | Bit/dim 1.1026(1.1031) | Xent 0.0360(0.0352) | Loss 1.1206(1.1207) | Error 0.0110(0.0110) Steps 434(432.43) | Grad Norm 0.2947(0.5712) | Total Time 10.00(10.00)\n",
      "Iter 4100 | Time 31.5864(30.8431) | Bit/dim 1.1048(1.1031) | Xent 0.0444(0.0355) | Loss 1.1270(1.1209) | Error 0.0138(0.0111) Steps 434(432.48) | Grad Norm 0.7489(0.5765) | Total Time 10.00(10.00)\n",
      "Iter 4101 | Time 32.1519(30.8823) | Bit/dim 1.1015(1.1031) | Xent 0.0409(0.0357) | Loss 1.1220(1.1209) | Error 0.0118(0.0111) Steps 434(432.53) | Grad Norm 0.3693(0.5703) | Total Time 10.00(10.00)\n",
      "Iter 4102 | Time 31.9918(30.9156) | Bit/dim 1.1015(1.1030) | Xent 0.0392(0.0358) | Loss 1.1211(1.1209) | Error 0.0119(0.0112) Steps 428(432.39) | Grad Norm 1.3398(0.5934) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0586 | Time 16.8382, Epoch Time 249.1387(240.1128), Bit/dim 1.0966(best: 1.0968), Xent 0.0268, Loss 1.1100, Error 0.0104(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4103 | Time 30.0662(30.8901) | Bit/dim 1.1044(1.1031) | Xent 0.0321(0.0357) | Loss 1.1204(1.1209) | Error 0.0099(0.0111) Steps 434(432.44) | Grad Norm 0.2198(0.5822) | Total Time 10.00(10.00)\n",
      "Iter 4104 | Time 30.8707(30.8896) | Bit/dim 1.1000(1.1030) | Xent 0.0360(0.0357) | Loss 1.1180(1.1208) | Error 0.0099(0.0111) Steps 434(432.49) | Grad Norm 1.6410(0.6139) | Total Time 10.00(10.00)\n",
      "Iter 4105 | Time 30.6719(30.8830) | Bit/dim 1.1053(1.1031) | Xent 0.0309(0.0355) | Loss 1.1207(1.1208) | Error 0.0099(0.0110) Steps 428(432.35) | Grad Norm 0.8116(0.6199) | Total Time 10.00(10.00)\n",
      "Iter 4106 | Time 31.1297(30.8904) | Bit/dim 1.1007(1.1030) | Xent 0.0351(0.0355) | Loss 1.1183(1.1207) | Error 0.0116(0.0111) Steps 428(432.22) | Grad Norm 0.7829(0.6248) | Total Time 10.00(10.00)\n",
      "Iter 4107 | Time 30.6585(30.8835) | Bit/dim 1.1042(1.1030) | Xent 0.0334(0.0355) | Loss 1.1209(1.1207) | Error 0.0101(0.0110) Steps 434(432.27) | Grad Norm 0.5485(0.6225) | Total Time 10.00(10.00)\n",
      "Iter 4108 | Time 32.5525(30.9335) | Bit/dim 1.1036(1.1030) | Xent 0.0337(0.0354) | Loss 1.1205(1.1207) | Error 0.0099(0.0110) Steps 434(432.33) | Grad Norm 0.6612(0.6236) | Total Time 10.00(10.00)\n",
      "Iter 4109 | Time 31.2232(30.9422) | Bit/dim 1.1015(1.1030) | Xent 0.0360(0.0354) | Loss 1.1195(1.1207) | Error 0.0115(0.0110) Steps 434(432.38) | Grad Norm 0.7614(0.6278) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0587 | Time 17.0215, Epoch Time 246.7341(240.3114), Bit/dim 1.0973(best: 1.0966), Xent 0.0277, Loss 1.1111, Error 0.0102(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4110 | Time 31.8134(30.9684) | Bit/dim 1.1017(1.1029) | Xent 0.0325(0.0353) | Loss 1.1180(1.1206) | Error 0.0100(0.0110) Steps 434(432.42) | Grad Norm 0.5053(0.6241) | Total Time 10.00(10.00)\n",
      "Iter 4111 | Time 30.8086(30.9636) | Bit/dim 1.1028(1.1029) | Xent 0.0372(0.0354) | Loss 1.1214(1.1206) | Error 0.0119(0.0110) Steps 440(432.65) | Grad Norm 0.5806(0.6228) | Total Time 10.00(10.00)\n",
      "Iter 4112 | Time 30.5175(30.9502) | Bit/dim 1.1051(1.1030) | Xent 0.0346(0.0354) | Loss 1.1224(1.1207) | Error 0.0104(0.0110) Steps 434(432.69) | Grad Norm 0.9239(0.6318) | Total Time 10.00(10.00)\n",
      "Iter 4113 | Time 30.7476(30.9441) | Bit/dim 1.1027(1.1030) | Xent 0.0333(0.0353) | Loss 1.1193(1.1207) | Error 0.0106(0.0110) Steps 428(432.55) | Grad Norm 0.7070(0.6341) | Total Time 10.00(10.00)\n",
      "Iter 4114 | Time 32.0556(30.9775) | Bit/dim 1.1000(1.1029) | Xent 0.0325(0.0352) | Loss 1.1163(1.1205) | Error 0.0094(0.0109) Steps 434(432.59) | Grad Norm 0.9514(0.6436) | Total Time 10.00(10.00)\n",
      "Iter 4115 | Time 30.2865(30.9567) | Bit/dim 1.0959(1.1027) | Xent 0.0359(0.0352) | Loss 1.1138(1.1203) | Error 0.0112(0.0109) Steps 434(432.64) | Grad Norm 0.8246(0.6490) | Total Time 10.00(10.00)\n",
      "Iter 4116 | Time 30.3373(30.9381) | Bit/dim 1.1040(1.1027) | Xent 0.0381(0.0353) | Loss 1.1231(1.1204) | Error 0.0116(0.0110) Steps 440(432.86) | Grad Norm 1.2491(0.6670) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0588 | Time 16.9231, Epoch Time 245.8070(240.4763), Bit/dim 1.0971(best: 1.0966), Xent 0.0266, Loss 1.1104, Error 0.0095(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4117 | Time 30.6575(30.9297) | Bit/dim 1.1018(1.1027) | Xent 0.0332(0.0353) | Loss 1.1184(1.1203) | Error 0.0111(0.0110) Steps 434(432.89) | Grad Norm 1.6781(0.6974) | Total Time 10.00(10.00)\n",
      "Iter 4118 | Time 30.9908(30.9316) | Bit/dim 1.1036(1.1027) | Xent 0.0363(0.0353) | Loss 1.1218(1.1204) | Error 0.0109(0.0110) Steps 434(432.93) | Grad Norm 0.7187(0.6980) | Total Time 10.00(10.00)\n",
      "Iter 4119 | Time 31.9493(30.9621) | Bit/dim 1.1023(1.1027) | Xent 0.0302(0.0351) | Loss 1.1174(1.1203) | Error 0.0104(0.0109) Steps 446(433.32) | Grad Norm 1.5577(0.7238) | Total Time 10.00(10.00)\n",
      "Iter 4120 | Time 30.8375(30.9584) | Bit/dim 1.1006(1.1027) | Xent 0.0342(0.0351) | Loss 1.1177(1.1202) | Error 0.0108(0.0109) Steps 434(433.34) | Grad Norm 0.6027(0.7202) | Total Time 10.00(10.00)\n",
      "Iter 4121 | Time 30.8121(30.9540) | Bit/dim 1.1072(1.1028) | Xent 0.0372(0.0352) | Loss 1.1258(1.1204) | Error 0.0118(0.0110) Steps 428(433.18) | Grad Norm 1.0133(0.7289) | Total Time 10.00(10.00)\n",
      "Iter 4122 | Time 31.7655(30.9783) | Bit/dim 1.1025(1.1028) | Xent 0.0339(0.0351) | Loss 1.1195(1.1204) | Error 0.0108(0.0110) Steps 440(433.38) | Grad Norm 1.1923(0.7428) | Total Time 10.00(10.00)\n",
      "Iter 4123 | Time 30.5379(30.9651) | Bit/dim 1.1025(1.1028) | Xent 0.0368(0.0352) | Loss 1.1209(1.1204) | Error 0.0110(0.0110) Steps 434(433.40) | Grad Norm 1.1186(0.7541) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0589 | Time 16.9367, Epoch Time 246.9086(240.6693), Bit/dim 1.0971(best: 1.0966), Xent 0.0255, Loss 1.1099, Error 0.0090(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4124 | Time 30.6054(30.9543) | Bit/dim 1.1021(1.1028) | Xent 0.0361(0.0352) | Loss 1.1201(1.1204) | Error 0.0102(0.0109) Steps 434(433.42) | Grad Norm 1.0215(0.7621) | Total Time 10.00(10.00)\n",
      "Iter 4125 | Time 30.6349(30.9447) | Bit/dim 1.1028(1.1028) | Xent 0.0360(0.0352) | Loss 1.1208(1.1204) | Error 0.0109(0.0109) Steps 434(433.44) | Grad Norm 0.8354(0.7643) | Total Time 10.00(10.00)\n",
      "Iter 4126 | Time 30.5346(30.9324) | Bit/dim 1.1053(1.1028) | Xent 0.0350(0.0352) | Loss 1.1228(1.1205) | Error 0.0109(0.0109) Steps 434(433.45) | Grad Norm 0.4928(0.7562) | Total Time 10.00(10.00)\n",
      "Iter 4127 | Time 31.4051(30.9466) | Bit/dim 1.1038(1.1029) | Xent 0.0341(0.0352) | Loss 1.1209(1.1205) | Error 0.0100(0.0109) Steps 440(433.65) | Grad Norm 0.2180(0.7400) | Total Time 10.00(10.00)\n",
      "Iter 4128 | Time 31.0377(30.9493) | Bit/dim 1.1030(1.1029) | Xent 0.0301(0.0350) | Loss 1.1180(1.1204) | Error 0.0090(0.0108) Steps 434(433.66) | Grad Norm 0.7915(0.7416) | Total Time 10.00(10.00)\n",
      "Iter 4129 | Time 31.9106(30.9782) | Bit/dim 1.0992(1.1028) | Xent 0.0311(0.0349) | Loss 1.1148(1.1202) | Error 0.0094(0.0108) Steps 434(433.67) | Grad Norm 0.6179(0.7379) | Total Time 10.00(10.00)\n",
      "Iter 4130 | Time 31.6319(30.9978) | Bit/dim 1.1032(1.1028) | Xent 0.0327(0.0349) | Loss 1.1195(1.1202) | Error 0.0114(0.0108) Steps 434(433.68) | Grad Norm 0.2106(0.7221) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0590 | Time 16.7675, Epoch Time 246.9334(240.8572), Bit/dim 1.0971(best: 1.0966), Xent 0.0274, Loss 1.1108, Error 0.0101(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4131 | Time 30.4895(30.9825) | Bit/dim 1.0992(1.1027) | Xent 0.0342(0.0348) | Loss 1.1163(1.1201) | Error 0.0102(0.0108) Steps 434(433.69) | Grad Norm 0.2761(0.7087) | Total Time 10.00(10.00)\n",
      "Iter 4132 | Time 33.0441(31.0444) | Bit/dim 1.1008(1.1026) | Xent 0.0345(0.0348) | Loss 1.1180(1.1200) | Error 0.0095(0.0108) Steps 434(433.70) | Grad Norm 0.3838(0.6989) | Total Time 10.00(10.00)\n",
      "Iter 4133 | Time 31.5661(31.0600) | Bit/dim 1.1003(1.1025) | Xent 0.0289(0.0347) | Loss 1.1148(1.1199) | Error 0.0092(0.0107) Steps 434(433.71) | Grad Norm 1.1642(0.7129) | Total Time 10.00(10.00)\n",
      "Iter 4134 | Time 31.0587(31.0600) | Bit/dim 1.1012(1.1025) | Xent 0.0381(0.0348) | Loss 1.1203(1.1199) | Error 0.0116(0.0107) Steps 440(433.90) | Grad Norm 0.5576(0.7082) | Total Time 10.00(10.00)\n",
      "Iter 4135 | Time 31.5597(31.0750) | Bit/dim 1.1068(1.1026) | Xent 0.0354(0.0348) | Loss 1.1245(1.1200) | Error 0.0115(0.0108) Steps 434(433.90) | Grad Norm 0.6798(0.7074) | Total Time 10.00(10.00)\n",
      "Iter 4136 | Time 30.7797(31.0661) | Bit/dim 1.1024(1.1026) | Xent 0.0316(0.0347) | Loss 1.1182(1.1200) | Error 0.0091(0.0107) Steps 440(434.08) | Grad Norm 0.4878(0.7008) | Total Time 10.00(10.00)\n",
      "Iter 4137 | Time 31.3115(31.0735) | Bit/dim 1.1055(1.1027) | Xent 0.0393(0.0348) | Loss 1.1252(1.1201) | Error 0.0128(0.0108) Steps 434(434.08) | Grad Norm 0.5682(0.6968) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0591 | Time 16.8175, Epoch Time 249.1757(241.1068), Bit/dim 1.0967(best: 1.0966), Xent 0.0275, Loss 1.1105, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4138 | Time 30.2905(31.0500) | Bit/dim 1.1046(1.1028) | Xent 0.0364(0.0349) | Loss 1.1228(1.1202) | Error 0.0108(0.0108) Steps 434(434.08) | Grad Norm 0.6794(0.6963) | Total Time 10.00(10.00)\n",
      "Iter 4139 | Time 30.8053(31.0427) | Bit/dim 1.0974(1.1026) | Xent 0.0335(0.0348) | Loss 1.1142(1.1200) | Error 0.0114(0.0108) Steps 434(434.08) | Grad Norm 0.3723(0.6866) | Total Time 10.00(10.00)\n",
      "Iter 4140 | Time 30.6210(31.0300) | Bit/dim 1.0973(1.1024) | Xent 0.0413(0.0350) | Loss 1.1179(1.1200) | Error 0.0122(0.0108) Steps 446(434.43) | Grad Norm 0.6660(0.6860) | Total Time 10.00(10.00)\n",
      "Iter 4141 | Time 30.5282(31.0150) | Bit/dim 1.1037(1.1025) | Xent 0.0312(0.0349) | Loss 1.1193(1.1199) | Error 0.0102(0.0108) Steps 434(434.42) | Grad Norm 0.5139(0.6808) | Total Time 10.00(10.00)\n",
      "Iter 4142 | Time 30.2968(30.9934) | Bit/dim 1.1028(1.1025) | Xent 0.0333(0.0349) | Loss 1.1194(1.1199) | Error 0.0105(0.0108) Steps 434(434.41) | Grad Norm 0.4288(0.6732) | Total Time 10.00(10.00)\n",
      "Iter 4143 | Time 32.3043(31.0327) | Bit/dim 1.1047(1.1026) | Xent 0.0358(0.0349) | Loss 1.1225(1.1200) | Error 0.0119(0.0108) Steps 434(434.40) | Grad Norm 1.1950(0.6889) | Total Time 10.00(10.00)\n",
      "Iter 4144 | Time 30.4855(31.0163) | Bit/dim 1.1027(1.1026) | Xent 0.0365(0.0349) | Loss 1.1210(1.1200) | Error 0.0102(0.0108) Steps 434(434.38) | Grad Norm 0.3385(0.6784) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0592 | Time 16.9514, Epoch Time 245.1615(241.2284), Bit/dim 1.0966(best: 1.0966), Xent 0.0296, Loss 1.1114, Error 0.0098(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4145 | Time 31.2212(31.0225) | Bit/dim 1.1077(1.1027) | Xent 0.0396(0.0351) | Loss 1.1275(1.1203) | Error 0.0121(0.0109) Steps 434(434.37) | Grad Norm 1.0171(0.6885) | Total Time 10.00(10.00)\n",
      "Iter 4146 | Time 30.6080(31.0100) | Bit/dim 1.0971(1.1025) | Xent 0.0322(0.0350) | Loss 1.1132(1.1200) | Error 0.0106(0.0109) Steps 434(434.36) | Grad Norm 0.2284(0.6747) | Total Time 10.00(10.00)\n",
      "Iter 4147 | Time 30.8133(31.0041) | Bit/dim 1.1056(1.1026) | Xent 0.0361(0.0350) | Loss 1.1237(1.1202) | Error 0.0101(0.0108) Steps 434(434.35) | Grad Norm 0.9224(0.6822) | Total Time 10.00(10.00)\n",
      "Iter 4148 | Time 31.2811(31.0124) | Bit/dim 1.1021(1.1026) | Xent 0.0401(0.0352) | Loss 1.1221(1.1202) | Error 0.0122(0.0109) Steps 434(434.34) | Grad Norm 0.3267(0.6715) | Total Time 10.00(10.00)\n",
      "Iter 4149 | Time 31.7065(31.0333) | Bit/dim 1.0992(1.1025) | Xent 0.0322(0.0351) | Loss 1.1153(1.1201) | Error 0.0105(0.0109) Steps 446(434.69) | Grad Norm 0.8384(0.6765) | Total Time 10.00(10.00)\n",
      "Iter 4150 | Time 31.3607(31.0431) | Bit/dim 1.1006(1.1025) | Xent 0.0281(0.0349) | Loss 1.1147(1.1199) | Error 0.0100(0.0108) Steps 440(434.85) | Grad Norm 0.6202(0.6748) | Total Time 10.00(10.00)\n",
      "Iter 4151 | Time 31.2490(31.0493) | Bit/dim 1.1028(1.1025) | Xent 0.0369(0.0349) | Loss 1.1212(1.1199) | Error 0.0116(0.0109) Steps 434(434.82) | Grad Norm 0.6122(0.6729) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0593 | Time 16.9835, Epoch Time 247.7213(241.4232), Bit/dim 1.0967(best: 1.0966), Xent 0.0277, Loss 1.1106, Error 0.0092(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4152 | Time 30.7279(31.0396) | Bit/dim 1.1026(1.1025) | Xent 0.0361(0.0350) | Loss 1.1206(1.1200) | Error 0.0109(0.0109) Steps 440(434.98) | Grad Norm 0.4956(0.6676) | Total Time 10.00(10.00)\n",
      "Iter 4153 | Time 30.6114(31.0268) | Bit/dim 1.1010(1.1024) | Xent 0.0262(0.0347) | Loss 1.1140(1.1198) | Error 0.0089(0.0108) Steps 434(434.95) | Grad Norm 0.7774(0.6709) | Total Time 10.00(10.00)\n",
      "Iter 4154 | Time 30.5918(31.0137) | Bit/dim 1.0999(1.1024) | Xent 0.0323(0.0346) | Loss 1.1160(1.1197) | Error 0.0104(0.0108) Steps 440(435.10) | Grad Norm 0.3725(0.6620) | Total Time 10.00(10.00)\n",
      "Iter 4155 | Time 31.3374(31.0234) | Bit/dim 1.1027(1.1024) | Xent 0.0377(0.0347) | Loss 1.1215(1.1197) | Error 0.0108(0.0108) Steps 446(435.43) | Grad Norm 1.4044(0.6842) | Total Time 10.00(10.00)\n",
      "Iter 4156 | Time 31.4588(31.0365) | Bit/dim 1.1045(1.1024) | Xent 0.0406(0.0349) | Loss 1.1248(1.1199) | Error 0.0116(0.0108) Steps 434(435.39) | Grad Norm 0.7036(0.6848) | Total Time 10.00(10.00)\n",
      "Iter 4157 | Time 31.1013(31.0384) | Bit/dim 1.1055(1.1025) | Xent 0.0336(0.0349) | Loss 1.1223(1.1200) | Error 0.0119(0.0108) Steps 434(435.34) | Grad Norm 1.1674(0.6993) | Total Time 10.00(10.00)\n",
      "Iter 4158 | Time 30.3026(31.0164) | Bit/dim 1.1048(1.1026) | Xent 0.0368(0.0349) | Loss 1.1232(1.1200) | Error 0.0108(0.0108) Steps 434(435.30) | Grad Norm 0.3816(0.6898) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0594 | Time 16.6541, Epoch Time 245.1753(241.5358), Bit/dim 1.0967(best: 1.0966), Xent 0.0303, Loss 1.1119, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4159 | Time 31.2438(31.0232) | Bit/dim 1.1065(1.1027) | Xent 0.0362(0.0350) | Loss 1.1246(1.1202) | Error 0.0096(0.0108) Steps 434(435.26) | Grad Norm 0.9050(0.6962) | Total Time 10.00(10.00)\n",
      "Iter 4160 | Time 30.9176(31.0200) | Bit/dim 1.0995(1.1026) | Xent 0.0382(0.0351) | Loss 1.1186(1.1201) | Error 0.0110(0.0108) Steps 434(435.23) | Grad Norm 0.3707(0.6865) | Total Time 10.00(10.00)\n",
      "Iter 4161 | Time 30.3041(30.9985) | Bit/dim 1.0991(1.1025) | Xent 0.0340(0.0350) | Loss 1.1161(1.1200) | Error 0.0112(0.0108) Steps 434(435.19) | Grad Norm 1.1063(0.6991) | Total Time 10.00(10.00)\n",
      "Iter 4162 | Time 30.6269(30.9874) | Bit/dim 1.1021(1.1025) | Xent 0.0320(0.0349) | Loss 1.1181(1.1200) | Error 0.0088(0.0108) Steps 434(435.15) | Grad Norm 0.5951(0.6959) | Total Time 10.00(10.00)\n",
      "Iter 4163 | Time 30.3507(30.9683) | Bit/dim 1.1051(1.1026) | Xent 0.0311(0.0348) | Loss 1.1206(1.1200) | Error 0.0102(0.0107) Steps 434(435.12) | Grad Norm 0.6610(0.6949) | Total Time 10.00(10.00)\n",
      "Iter 4164 | Time 30.4956(30.9541) | Bit/dim 1.1009(1.1025) | Xent 0.0330(0.0348) | Loss 1.1174(1.1199) | Error 0.0116(0.0108) Steps 434(435.09) | Grad Norm 0.6699(0.6941) | Total Time 10.00(10.00)\n",
      "Iter 4165 | Time 31.3806(30.9669) | Bit/dim 1.1068(1.1026) | Xent 0.0366(0.0348) | Loss 1.1251(1.1201) | Error 0.0108(0.0108) Steps 434(435.05) | Grad Norm 0.7816(0.6968) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0595 | Time 16.7581, Epoch Time 244.5336(241.6257), Bit/dim 1.0963(best: 1.0966), Xent 0.0284, Loss 1.1104, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4166 | Time 30.8562(30.9636) | Bit/dim 1.1053(1.1027) | Xent 0.0371(0.0349) | Loss 1.1239(1.1202) | Error 0.0115(0.0108) Steps 434(435.02) | Grad Norm 0.4489(0.6893) | Total Time 10.00(10.00)\n",
      "Iter 4167 | Time 30.8922(30.9614) | Bit/dim 1.1026(1.1027) | Xent 0.0394(0.0350) | Loss 1.1223(1.1202) | Error 0.0119(0.0108) Steps 434(434.99) | Grad Norm 0.9308(0.6966) | Total Time 10.00(10.00)\n",
      "Iter 4168 | Time 30.4891(30.9473) | Bit/dim 1.1035(1.1027) | Xent 0.0370(0.0351) | Loss 1.1220(1.1203) | Error 0.0124(0.0109) Steps 434(434.96) | Grad Norm 0.3304(0.6856) | Total Time 10.00(10.00)\n",
      "Iter 4169 | Time 30.5420(30.9351) | Bit/dim 1.1011(1.1027) | Xent 0.0307(0.0350) | Loss 1.1164(1.1202) | Error 0.0095(0.0108) Steps 434(434.93) | Grad Norm 1.4552(0.7087) | Total Time 10.00(10.00)\n",
      "Iter 4170 | Time 32.0115(30.9674) | Bit/dim 1.0990(1.1026) | Xent 0.0428(0.0352) | Loss 1.1203(1.1202) | Error 0.0122(0.0109) Steps 446(435.26) | Grad Norm 0.5504(0.7039) | Total Time 10.00(10.00)\n",
      "Iter 4171 | Time 30.9560(30.9671) | Bit/dim 1.1024(1.1026) | Xent 0.0374(0.0353) | Loss 1.1211(1.1202) | Error 0.0116(0.0109) Steps 434(435.23) | Grad Norm 1.4339(0.7258) | Total Time 10.00(10.00)\n",
      "Iter 4172 | Time 31.1895(30.9737) | Bit/dim 1.1010(1.1025) | Xent 0.0344(0.0352) | Loss 1.1182(1.1201) | Error 0.0114(0.0109) Steps 434(435.19) | Grad Norm 0.6673(0.7241) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0596 | Time 16.9720, Epoch Time 246.4481(241.7704), Bit/dim 1.0974(best: 1.0963), Xent 0.0286, Loss 1.1117, Error 0.0095(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4173 | Time 30.8907(30.9712) | Bit/dim 1.1040(1.1026) | Xent 0.0354(0.0352) | Loss 1.1217(1.1202) | Error 0.0104(0.0109) Steps 434(435.15) | Grad Norm 1.1844(0.7379) | Total Time 10.00(10.00)\n",
      "Iter 4174 | Time 30.0332(30.9431) | Bit/dim 1.1027(1.1026) | Xent 0.0279(0.0350) | Loss 1.1167(1.1201) | Error 0.0085(0.0108) Steps 434(435.12) | Grad Norm 0.5130(0.7311) | Total Time 10.00(10.00)\n",
      "Iter 4175 | Time 30.9439(30.9431) | Bit/dim 1.1039(1.1026) | Xent 0.0384(0.0351) | Loss 1.1232(1.1202) | Error 0.0120(0.0109) Steps 446(435.45) | Grad Norm 1.8067(0.7634) | Total Time 10.00(10.00)\n",
      "Iter 4176 | Time 31.7493(30.9673) | Bit/dim 1.0994(1.1025) | Xent 0.0310(0.0350) | Loss 1.1149(1.1200) | Error 0.0089(0.0108) Steps 434(435.40) | Grad Norm 1.5499(0.7870) | Total Time 10.00(10.00)\n",
      "Iter 4177 | Time 30.6100(30.9566) | Bit/dim 1.1039(1.1026) | Xent 0.0418(0.0352) | Loss 1.1248(1.1202) | Error 0.0115(0.0108) Steps 434(435.36) | Grad Norm 1.0092(0.7937) | Total Time 10.00(10.00)\n",
      "Iter 4178 | Time 30.8066(30.9521) | Bit/dim 1.0997(1.1025) | Xent 0.0366(0.0352) | Loss 1.1180(1.1201) | Error 0.0121(0.0109) Steps 434(435.32) | Grad Norm 1.8685(0.8259) | Total Time 10.00(10.00)\n",
      "Iter 4179 | Time 32.3605(30.9943) | Bit/dim 1.1030(1.1025) | Xent 0.0354(0.0352) | Loss 1.1207(1.1201) | Error 0.0124(0.0109) Steps 434(435.28) | Grad Norm 0.3186(0.8107) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0597 | Time 16.7503, Epoch Time 246.6746(241.9175), Bit/dim 1.0963(best: 1.0963), Xent 0.0274, Loss 1.1100, Error 0.0093(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4180 | Time 30.8633(30.9904) | Bit/dim 1.1075(1.1026) | Xent 0.0376(0.0353) | Loss 1.1263(1.1203) | Error 0.0110(0.0109) Steps 434(435.24) | Grad Norm 0.9868(0.8160) | Total Time 10.00(10.00)\n",
      "Iter 4181 | Time 30.9536(30.9893) | Bit/dim 1.0978(1.1025) | Xent 0.0324(0.0352) | Loss 1.1140(1.1201) | Error 0.0095(0.0109) Steps 440(435.38) | Grad Norm 0.2402(0.7987) | Total Time 10.00(10.00)\n",
      "Iter 4182 | Time 31.5689(31.0067) | Bit/dim 1.0989(1.1024) | Xent 0.0425(0.0354) | Loss 1.1201(1.1201) | Error 0.0132(0.0109) Steps 434(435.34) | Grad Norm 0.8295(0.7996) | Total Time 10.00(10.00)\n",
      "Iter 4183 | Time 31.0335(31.0075) | Bit/dim 1.1005(1.1023) | Xent 0.0332(0.0354) | Loss 1.1172(1.1200) | Error 0.0111(0.0109) Steps 434(435.30) | Grad Norm 0.2673(0.7837) | Total Time 10.00(10.00)\n",
      "Iter 4184 | Time 30.9295(31.0052) | Bit/dim 1.1061(1.1024) | Xent 0.0336(0.0353) | Loss 1.1229(1.1201) | Error 0.0098(0.0109) Steps 434(435.26) | Grad Norm 0.7652(0.7831) | Total Time 10.00(10.00)\n",
      "Iter 4185 | Time 33.0622(31.0669) | Bit/dim 1.1008(1.1024) | Xent 0.0354(0.0353) | Loss 1.1185(1.1201) | Error 0.0109(0.0109) Steps 440(435.41) | Grad Norm 0.5264(0.7754) | Total Time 10.00(10.00)\n",
      "Iter 4186 | Time 30.8037(31.0590) | Bit/dim 1.1036(1.1024) | Xent 0.0351(0.0353) | Loss 1.1212(1.1201) | Error 0.0115(0.0109) Steps 434(435.36) | Grad Norm 1.1921(0.7879) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0598 | Time 16.4217, Epoch Time 248.1313(242.1039), Bit/dim 1.0968(best: 1.0963), Xent 0.0290, Loss 1.1113, Error 0.0089(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4187 | Time 32.3342(31.0972) | Bit/dim 1.0994(1.1023) | Xent 0.0345(0.0353) | Loss 1.1166(1.1200) | Error 0.0109(0.0109) Steps 434(435.32) | Grad Norm 0.6464(0.7837) | Total Time 10.00(10.00)\n",
      "Iter 4188 | Time 30.6013(31.0824) | Bit/dim 1.1102(1.1026) | Xent 0.0319(0.0352) | Loss 1.1262(1.1202) | Error 0.0094(0.0109) Steps 434(435.28) | Grad Norm 1.5411(0.8064) | Total Time 10.00(10.00)\n",
      "Iter 4189 | Time 31.1793(31.0853) | Bit/dim 1.1018(1.1026) | Xent 0.0300(0.0350) | Loss 1.1169(1.1201) | Error 0.0092(0.0108) Steps 434(435.24) | Grad Norm 0.3390(0.7924) | Total Time 10.00(10.00)\n",
      "Iter 4190 | Time 31.4178(31.0952) | Bit/dim 1.0982(1.1024) | Xent 0.0297(0.0349) | Loss 1.1131(1.1199) | Error 0.0104(0.0108) Steps 446(435.57) | Grad Norm 1.3855(0.8102) | Total Time 10.00(10.00)\n",
      "Iter 4191 | Time 32.7623(31.1453) | Bit/dim 1.1022(1.1024) | Xent 0.0400(0.0350) | Loss 1.1221(1.1199) | Error 0.0121(0.0109) Steps 434(435.52) | Grad Norm 0.7034(0.8070) | Total Time 10.00(10.00)\n",
      "Iter 4192 | Time 31.2733(31.1491) | Bit/dim 1.1030(1.1024) | Xent 0.0363(0.0351) | Loss 1.1212(1.1200) | Error 0.0108(0.0109) Steps 446(435.83) | Grad Norm 1.6990(0.8337) | Total Time 10.00(10.00)\n",
      "Iter 4193 | Time 31.2843(31.1532) | Bit/dim 1.0991(1.1023) | Xent 0.0324(0.0350) | Loss 1.1153(1.1198) | Error 0.0102(0.0108) Steps 434(435.78) | Grad Norm 0.6462(0.8281) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0599 | Time 16.8825, Epoch Time 250.4356(242.3539), Bit/dim 1.0965(best: 1.0963), Xent 0.0271, Loss 1.1100, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4194 | Time 31.4526(31.1621) | Bit/dim 1.1055(1.1024) | Xent 0.0335(0.0349) | Loss 1.1223(1.1199) | Error 0.0118(0.0109) Steps 434(435.73) | Grad Norm 2.1198(0.8668) | Total Time 10.00(10.00)\n",
      "Iter 4195 | Time 30.3117(31.1366) | Bit/dim 1.0964(1.1023) | Xent 0.0314(0.0348) | Loss 1.1121(1.1197) | Error 0.0101(0.0108) Steps 434(435.67) | Grad Norm 0.2313(0.8478) | Total Time 10.00(10.00)\n",
      "Iter 4196 | Time 30.1667(31.1075) | Bit/dim 1.1048(1.1023) | Xent 0.0409(0.0350) | Loss 1.1253(1.1198) | Error 0.0105(0.0108) Steps 440(435.80) | Grad Norm 2.1753(0.8876) | Total Time 10.00(10.00)\n",
      "Iter 4197 | Time 32.3413(31.1445) | Bit/dim 1.1023(1.1023) | Xent 0.0407(0.0352) | Loss 1.1226(1.1199) | Error 0.0122(0.0109) Steps 434(435.75) | Grad Norm 0.9489(0.8894) | Total Time 10.00(10.00)\n",
      "Iter 4198 | Time 30.9662(31.1392) | Bit/dim 1.1012(1.1023) | Xent 0.0327(0.0351) | Loss 1.1176(1.1199) | Error 0.0109(0.0109) Steps 434(435.70) | Grad Norm 1.1925(0.8985) | Total Time 10.00(10.00)\n",
      "Iter 4199 | Time 31.4519(31.1486) | Bit/dim 1.1017(1.1023) | Xent 0.0341(0.0351) | Loss 1.1188(1.1198) | Error 0.0101(0.0108) Steps 434(435.65) | Grad Norm 0.8081(0.8958) | Total Time 10.00(10.00)\n",
      "Iter 4200 | Time 31.5521(31.1607) | Bit/dim 1.1049(1.1024) | Xent 0.0354(0.0351) | Loss 1.1225(1.1199) | Error 0.0118(0.0109) Steps 434(435.60) | Grad Norm 0.4814(0.8834) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0600 | Time 16.8379, Epoch Time 247.4348(242.5063), Bit/dim 1.0962(best: 1.0963), Xent 0.0292, Loss 1.1108, Error 0.0091(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4201 | Time 31.7214(31.1775) | Bit/dim 1.1049(1.1024) | Xent 0.0301(0.0349) | Loss 1.1199(1.1199) | Error 0.0096(0.0108) Steps 434(435.55) | Grad Norm 0.2710(0.8650) | Total Time 10.00(10.00)\n",
      "Iter 4202 | Time 30.7024(31.1632) | Bit/dim 1.0962(1.1022) | Xent 0.0314(0.0348) | Loss 1.1119(1.1197) | Error 0.0104(0.0108) Steps 434(435.50) | Grad Norm 1.1112(0.8724) | Total Time 10.00(10.00)\n",
      "Iter 4203 | Time 32.2422(31.1956) | Bit/dim 1.1018(1.1022) | Xent 0.0284(0.0346) | Loss 1.1160(1.1196) | Error 0.0098(0.0108) Steps 434(435.46) | Grad Norm 0.5378(0.8624) | Total Time 10.00(10.00)\n",
      "Iter 4204 | Time 31.2983(31.1987) | Bit/dim 1.1007(1.1022) | Xent 0.0416(0.0349) | Loss 1.1215(1.1196) | Error 0.0116(0.0108) Steps 434(435.41) | Grad Norm 0.5855(0.8541) | Total Time 10.00(10.00)\n",
      "Iter 4205 | Time 30.7793(31.1861) | Bit/dim 1.1014(1.1022) | Xent 0.0312(0.0347) | Loss 1.1170(1.1195) | Error 0.0091(0.0108) Steps 434(435.37) | Grad Norm 0.3850(0.8400) | Total Time 10.00(10.00)\n",
      "Iter 4206 | Time 31.9643(31.2095) | Bit/dim 1.1036(1.1022) | Xent 0.0360(0.0348) | Loss 1.1216(1.1196) | Error 0.0112(0.0108) Steps 434(435.33) | Grad Norm 1.2069(0.8510) | Total Time 10.00(10.00)\n",
      "Iter 4207 | Time 31.0634(31.2051) | Bit/dim 1.1061(1.1023) | Xent 0.0321(0.0347) | Loss 1.1221(1.1197) | Error 0.0096(0.0107) Steps 434(435.29) | Grad Norm 0.4800(0.8399) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0601 | Time 17.0877, Epoch Time 249.3047(242.7102), Bit/dim 1.0960(best: 1.0962), Xent 0.0246, Loss 1.1083, Error 0.0087(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4208 | Time 31.6228(31.2176) | Bit/dim 1.1061(1.1024) | Xent 0.0348(0.0347) | Loss 1.1234(1.1198) | Error 0.0110(0.0108) Steps 434(435.25) | Grad Norm 0.7317(0.8366) | Total Time 10.00(10.00)\n",
      "Iter 4209 | Time 30.5606(31.1979) | Bit/dim 1.0997(1.1023) | Xent 0.0383(0.0348) | Loss 1.1189(1.1198) | Error 0.0120(0.0108) Steps 434(435.21) | Grad Norm 0.6827(0.8320) | Total Time 10.00(10.00)\n",
      "Iter 4210 | Time 31.2608(31.1998) | Bit/dim 1.1032(1.1024) | Xent 0.0364(0.0349) | Loss 1.1214(1.1198) | Error 0.0100(0.0108) Steps 434(435.18) | Grad Norm 0.3031(0.8161) | Total Time 10.00(10.00)\n",
      "Iter 4211 | Time 30.8319(31.1887) | Bit/dim 1.0970(1.1022) | Xent 0.0313(0.0348) | Loss 1.1127(1.1196) | Error 0.0108(0.0108) Steps 434(435.14) | Grad Norm 0.3992(0.8036) | Total Time 10.00(10.00)\n",
      "Iter 4212 | Time 30.6491(31.1726) | Bit/dim 1.0944(1.1020) | Xent 0.0355(0.0348) | Loss 1.1121(1.1194) | Error 0.0111(0.0108) Steps 434(435.11) | Grad Norm 0.5828(0.7970) | Total Time 10.00(10.00)\n",
      "Iter 4213 | Time 30.7493(31.1599) | Bit/dim 1.1065(1.1021) | Xent 0.0336(0.0347) | Loss 1.1232(1.1195) | Error 0.0110(0.0108) Steps 434(435.07) | Grad Norm 0.5409(0.7893) | Total Time 10.00(10.00)\n",
      "Iter 4214 | Time 31.2459(31.1624) | Bit/dim 1.1075(1.1023) | Xent 0.0342(0.0347) | Loss 1.1246(1.1196) | Error 0.0106(0.0108) Steps 434(435.04) | Grad Norm 0.8332(0.7906) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0602 | Time 17.1029, Epoch Time 246.7188(242.8305), Bit/dim 1.0962(best: 1.0960), Xent 0.0266, Loss 1.1095, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4215 | Time 31.2602(31.1654) | Bit/dim 1.1102(1.1025) | Xent 0.0344(0.0347) | Loss 1.1274(1.1199) | Error 0.0104(0.0108) Steps 434(435.01) | Grad Norm 1.0504(0.7984) | Total Time 10.00(10.00)\n",
      "Iter 4216 | Time 30.7682(31.1535) | Bit/dim 1.0977(1.1024) | Xent 0.0340(0.0347) | Loss 1.1147(1.1197) | Error 0.0095(0.0107) Steps 434(434.98) | Grad Norm 0.5486(0.7909) | Total Time 10.00(10.00)\n",
      "Iter 4217 | Time 31.2020(31.1549) | Bit/dim 1.1030(1.1024) | Xent 0.0332(0.0347) | Loss 1.1196(1.1197) | Error 0.0100(0.0107) Steps 434(434.95) | Grad Norm 1.0885(0.7999) | Total Time 10.00(10.00)\n",
      "Iter 4218 | Time 31.6815(31.1707) | Bit/dim 1.0999(1.1023) | Xent 0.0353(0.0347) | Loss 1.1176(1.1197) | Error 0.0096(0.0107) Steps 446(435.28) | Grad Norm 0.4021(0.7879) | Total Time 10.00(10.00)\n",
      "Iter 4219 | Time 31.6703(31.1857) | Bit/dim 1.1036(1.1024) | Xent 0.0330(0.0346) | Loss 1.1201(1.1197) | Error 0.0109(0.0107) Steps 446(435.60) | Grad Norm 1.3611(0.8051) | Total Time 10.00(10.00)\n",
      "Iter 4220 | Time 31.2728(31.1883) | Bit/dim 1.1017(1.1023) | Xent 0.0364(0.0347) | Loss 1.1198(1.1197) | Error 0.0128(0.0107) Steps 440(435.74) | Grad Norm 0.5463(0.7974) | Total Time 10.00(10.00)\n",
      "Iter 4221 | Time 31.0477(31.1841) | Bit/dim 1.0992(1.1022) | Xent 0.0319(0.0346) | Loss 1.1151(1.1195) | Error 0.0096(0.0107) Steps 434(435.68) | Grad Norm 0.7450(0.7958) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0603 | Time 16.8425, Epoch Time 248.2680(242.9936), Bit/dim 1.0964(best: 1.0960), Xent 0.0284, Loss 1.1106, Error 0.0091(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4222 | Time 31.8946(31.2054) | Bit/dim 1.1046(1.1023) | Xent 0.0395(0.0347) | Loss 1.1244(1.1197) | Error 0.0112(0.0107) Steps 434(435.63) | Grad Norm 0.2481(0.7794) | Total Time 10.00(10.00)\n",
      "Iter 4223 | Time 32.3344(31.2393) | Bit/dim 1.1016(1.1023) | Xent 0.0342(0.0347) | Loss 1.1187(1.1196) | Error 0.0098(0.0107) Steps 434(435.58) | Grad Norm 0.6992(0.7769) | Total Time 10.00(10.00)\n",
      "Iter 4224 | Time 30.6369(31.2212) | Bit/dim 1.1012(1.1023) | Xent 0.0372(0.0348) | Loss 1.1198(1.1197) | Error 0.0138(0.0108) Steps 434(435.54) | Grad Norm 0.4089(0.7659) | Total Time 10.00(10.00)\n",
      "Iter 4225 | Time 31.3756(31.2258) | Bit/dim 1.1005(1.1022) | Xent 0.0368(0.0349) | Loss 1.1189(1.1196) | Error 0.0128(0.0108) Steps 434(435.49) | Grad Norm 1.3071(0.7821) | Total Time 10.00(10.00)\n",
      "Iter 4226 | Time 31.9747(31.2483) | Bit/dim 1.1040(1.1023) | Xent 0.0392(0.0350) | Loss 1.1236(1.1198) | Error 0.0114(0.0109) Steps 434(435.45) | Grad Norm 0.3821(0.7701) | Total Time 10.00(10.00)\n",
      "Iter 4227 | Time 29.8490(31.2063) | Bit/dim 1.1014(1.1022) | Xent 0.0320(0.0349) | Loss 1.1174(1.1197) | Error 0.0100(0.0108) Steps 434(435.40) | Grad Norm 0.9840(0.7766) | Total Time 10.00(10.00)\n",
      "Iter 4228 | Time 32.6824(31.2506) | Bit/dim 1.1022(1.1022) | Xent 0.0331(0.0348) | Loss 1.1187(1.1197) | Error 0.0098(0.0108) Steps 434(435.36) | Grad Norm 0.6272(0.7721) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0604 | Time 16.8391, Epoch Time 250.0320(243.2048), Bit/dim 1.0961(best: 1.0960), Xent 0.0279, Loss 1.1100, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4229 | Time 32.3441(31.2834) | Bit/dim 1.1065(1.1024) | Xent 0.0312(0.0347) | Loss 1.1221(1.1197) | Error 0.0110(0.0108) Steps 434(435.32) | Grad Norm 0.8091(0.7732) | Total Time 10.00(10.00)\n",
      "Iter 4230 | Time 31.6841(31.2954) | Bit/dim 1.0988(1.1023) | Xent 0.0438(0.0350) | Loss 1.1207(1.1198) | Error 0.0122(0.0109) Steps 434(435.28) | Grad Norm 0.7949(0.7738) | Total Time 10.00(10.00)\n",
      "Iter 4231 | Time 31.8855(31.3131) | Bit/dim 1.1020(1.1022) | Xent 0.0388(0.0351) | Loss 1.1214(1.1198) | Error 0.0125(0.0109) Steps 434(435.24) | Grad Norm 0.8426(0.7759) | Total Time 10.00(10.00)\n",
      "Iter 4232 | Time 31.5088(31.3190) | Bit/dim 1.1030(1.1023) | Xent 0.0308(0.0350) | Loss 1.1184(1.1198) | Error 0.0088(0.0108) Steps 434(435.20) | Grad Norm 0.4991(0.7676) | Total Time 10.00(10.00)\n",
      "Iter 4233 | Time 31.1557(31.3141) | Bit/dim 1.0993(1.1022) | Xent 0.0293(0.0348) | Loss 1.1139(1.1196) | Error 0.0090(0.0108) Steps 434(435.17) | Grad Norm 1.2756(0.7828) | Total Time 10.00(10.00)\n",
      "Iter 4234 | Time 31.0618(31.3065) | Bit/dim 1.1014(1.1022) | Xent 0.0400(0.0350) | Loss 1.1214(1.1196) | Error 0.0125(0.0108) Steps 434(435.13) | Grad Norm 0.7177(0.7809) | Total Time 10.00(10.00)\n",
      "Iter 4235 | Time 31.7201(31.3189) | Bit/dim 1.1006(1.1021) | Xent 0.0375(0.0351) | Loss 1.1193(1.1196) | Error 0.0118(0.0109) Steps 434(435.10) | Grad Norm 0.9193(0.7850) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0605 | Time 16.8416, Epoch Time 250.6297(243.4275), Bit/dim 1.0967(best: 1.0960), Xent 0.0274, Loss 1.1104, Error 0.0095(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4236 | Time 31.2189(31.3159) | Bit/dim 1.1033(1.1021) | Xent 0.0401(0.0352) | Loss 1.1234(1.1197) | Error 0.0134(0.0109) Steps 434(435.07) | Grad Norm 0.9893(0.7912) | Total Time 10.00(10.00)\n",
      "Iter 4237 | Time 31.5976(31.3244) | Bit/dim 1.0986(1.1020) | Xent 0.0364(0.0352) | Loss 1.1168(1.1197) | Error 0.0109(0.0109) Steps 434(435.03) | Grad Norm 0.2996(0.7764) | Total Time 10.00(10.00)\n",
      "Iter 4238 | Time 30.6782(31.3050) | Bit/dim 1.1018(1.1020) | Xent 0.0321(0.0351) | Loss 1.1178(1.1196) | Error 0.0110(0.0109) Steps 434(435.00) | Grad Norm 0.3996(0.7651) | Total Time 10.00(10.00)\n",
      "Iter 4239 | Time 30.8858(31.2924) | Bit/dim 1.1002(1.1020) | Xent 0.0314(0.0350) | Loss 1.1159(1.1195) | Error 0.0118(0.0110) Steps 434(434.97) | Grad Norm 0.8308(0.7671) | Total Time 10.00(10.00)\n",
      "Iter 4240 | Time 30.5477(31.2701) | Bit/dim 1.1015(1.1020) | Xent 0.0379(0.0351) | Loss 1.1204(1.1195) | Error 0.0122(0.0110) Steps 434(434.94) | Grad Norm 1.0999(0.7771) | Total Time 10.00(10.00)\n",
      "Iter 4241 | Time 32.1201(31.2956) | Bit/dim 1.1079(1.1021) | Xent 0.0360(0.0351) | Loss 1.1259(1.1197) | Error 0.0108(0.0110) Steps 434(434.92) | Grad Norm 0.2497(0.7612) | Total Time 10.00(10.00)\n",
      "Iter 4242 | Time 30.5588(31.2735) | Bit/dim 1.1000(1.1021) | Xent 0.0397(0.0353) | Loss 1.1199(1.1197) | Error 0.0128(0.0110) Steps 434(434.89) | Grad Norm 0.3913(0.7501) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0606 | Time 16.9469, Epoch Time 246.9794(243.5341), Bit/dim 1.0963(best: 1.0960), Xent 0.0254, Loss 1.1090, Error 0.0089(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4243 | Time 31.3018(31.2743) | Bit/dim 1.1042(1.1021) | Xent 0.0326(0.0352) | Loss 1.1205(1.1197) | Error 0.0098(0.0110) Steps 434(434.86) | Grad Norm 0.8488(0.7531) | Total Time 10.00(10.00)\n",
      "Iter 4244 | Time 30.8056(31.2603) | Bit/dim 1.1006(1.1021) | Xent 0.0399(0.0353) | Loss 1.1205(1.1198) | Error 0.0128(0.0111) Steps 446(435.20) | Grad Norm 1.1589(0.7653) | Total Time 10.00(10.00)\n",
      "Iter 4245 | Time 31.0888(31.2551) | Bit/dim 1.1012(1.1021) | Xent 0.0305(0.0352) | Loss 1.1164(1.1197) | Error 0.0092(0.0110) Steps 440(435.34) | Grad Norm 0.3495(0.7528) | Total Time 10.00(10.00)\n",
      "Iter 4246 | Time 31.8746(31.2737) | Bit/dim 1.1013(1.1020) | Xent 0.0390(0.0353) | Loss 1.1208(1.1197) | Error 0.0114(0.0110) Steps 434(435.30) | Grad Norm 0.5507(0.7467) | Total Time 10.00(10.00)\n",
      "Iter 4247 | Time 31.2854(31.2741) | Bit/dim 1.0975(1.1019) | Xent 0.0360(0.0353) | Loss 1.1155(1.1196) | Error 0.0122(0.0111) Steps 434(435.26) | Grad Norm 0.4056(0.7365) | Total Time 10.00(10.00)\n",
      "Iter 4248 | Time 30.9603(31.2647) | Bit/dim 1.1078(1.1021) | Xent 0.0361(0.0354) | Loss 1.1258(1.1198) | Error 0.0111(0.0111) Steps 446(435.58) | Grad Norm 1.5992(0.7624) | Total Time 10.00(10.00)\n",
      "Iter 4249 | Time 31.0616(31.2586) | Bit/dim 1.0997(1.1020) | Xent 0.0435(0.0356) | Loss 1.1215(1.1198) | Error 0.0129(0.0111) Steps 434(435.54) | Grad Norm 0.7872(0.7631) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0607 | Time 16.9412, Epoch Time 247.6578(243.6578), Bit/dim 1.0960(best: 1.0960), Xent 0.0267, Loss 1.1094, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4250 | Time 30.8334(31.2458) | Bit/dim 1.1013(1.1020) | Xent 0.0352(0.0356) | Loss 1.1189(1.1198) | Error 0.0102(0.0111) Steps 434(435.49) | Grad Norm 0.7611(0.7631) | Total Time 10.00(10.00)\n",
      "Iter 4251 | Time 31.0479(31.2399) | Bit/dim 1.1014(1.1020) | Xent 0.0372(0.0356) | Loss 1.1200(1.1198) | Error 0.0125(0.0111) Steps 446(435.80) | Grad Norm 0.2983(0.7491) | Total Time 10.00(10.00)\n",
      "Iter 4252 | Time 30.9686(31.2317) | Bit/dim 1.1013(1.1019) | Xent 0.0369(0.0357) | Loss 1.1197(1.1198) | Error 0.0116(0.0111) Steps 434(435.75) | Grad Norm 0.6538(0.7463) | Total Time 10.00(10.00)\n",
      "Iter 4253 | Time 31.5728(31.2420) | Bit/dim 1.0991(1.1019) | Xent 0.0321(0.0356) | Loss 1.1151(1.1196) | Error 0.0101(0.0111) Steps 434(435.70) | Grad Norm 0.3918(0.7356) | Total Time 10.00(10.00)\n",
      "Iter 4254 | Time 30.8478(31.2301) | Bit/dim 1.1047(1.1019) | Xent 0.0355(0.0356) | Loss 1.1224(1.1197) | Error 0.0115(0.0111) Steps 434(435.65) | Grad Norm 0.7946(0.7374) | Total Time 10.00(10.00)\n",
      "Iter 4255 | Time 30.7561(31.2159) | Bit/dim 1.0995(1.1019) | Xent 0.0407(0.0357) | Loss 1.1198(1.1197) | Error 0.0110(0.0111) Steps 434(435.60) | Grad Norm 0.2708(0.7234) | Total Time 10.00(10.00)\n",
      "Iter 4256 | Time 30.8468(31.2048) | Bit/dim 1.1061(1.1020) | Xent 0.0389(0.0358) | Loss 1.1255(1.1199) | Error 0.0125(0.0112) Steps 434(435.55) | Grad Norm 0.6597(0.7215) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0608 | Time 16.8215, Epoch Time 246.1840(243.7336), Bit/dim 1.0957(best: 1.0960), Xent 0.0296, Loss 1.1105, Error 0.0099(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4257 | Time 30.9408(31.1969) | Bit/dim 1.1032(1.1020) | Xent 0.0299(0.0356) | Loss 1.1182(1.1199) | Error 0.0100(0.0111) Steps 434(435.50) | Grad Norm 0.3126(0.7092) | Total Time 10.00(10.00)\n",
      "Iter 4258 | Time 31.0974(31.1939) | Bit/dim 1.1043(1.1021) | Xent 0.0345(0.0356) | Loss 1.1215(1.1199) | Error 0.0105(0.0111) Steps 434(435.46) | Grad Norm 0.3749(0.6992) | Total Time 10.00(10.00)\n",
      "Iter 4259 | Time 31.3216(31.1978) | Bit/dim 1.0957(1.1019) | Xent 0.0381(0.0357) | Loss 1.1148(1.1197) | Error 0.0130(0.0112) Steps 434(435.41) | Grad Norm 0.6600(0.6980) | Total Time 10.00(10.00)\n",
      "Iter 4260 | Time 30.4586(31.1756) | Bit/dim 1.0972(1.1018) | Xent 0.0344(0.0356) | Loss 1.1144(1.1196) | Error 0.0095(0.0111) Steps 434(435.37) | Grad Norm 0.3609(0.6879) | Total Time 10.00(10.00)\n",
      "Iter 4261 | Time 31.0233(31.1710) | Bit/dim 1.1056(1.1019) | Xent 0.0349(0.0356) | Loss 1.1230(1.1197) | Error 0.0106(0.0111) Steps 434(435.33) | Grad Norm 0.2913(0.6760) | Total Time 10.00(10.00)\n",
      "Iter 4262 | Time 31.5550(31.1825) | Bit/dim 1.1014(1.1019) | Xent 0.0364(0.0356) | Loss 1.1196(1.1197) | Error 0.0106(0.0111) Steps 434(435.29) | Grad Norm 0.4493(0.6692) | Total Time 10.00(10.00)\n",
      "Iter 4263 | Time 30.8764(31.1734) | Bit/dim 1.1033(1.1019) | Xent 0.0380(0.0357) | Loss 1.1223(1.1198) | Error 0.0108(0.0111) Steps 434(435.25) | Grad Norm 0.2777(0.6575) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0609 | Time 17.0139, Epoch Time 246.8139(243.8260), Bit/dim 1.0958(best: 1.0957), Xent 0.0278, Loss 1.1097, Error 0.0088(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4264 | Time 31.1229(31.1718) | Bit/dim 1.1000(1.1019) | Xent 0.0346(0.0357) | Loss 1.1173(1.1197) | Error 0.0104(0.0111) Steps 434(435.21) | Grad Norm 0.6022(0.6558) | Total Time 10.00(10.00)\n",
      "Iter 4265 | Time 31.3586(31.1774) | Bit/dim 1.1003(1.1018) | Xent 0.0308(0.0355) | Loss 1.1157(1.1196) | Error 0.0092(0.0110) Steps 434(435.18) | Grad Norm 0.3427(0.6464) | Total Time 10.00(10.00)\n",
      "Iter 4266 | Time 30.9490(31.1706) | Bit/dim 1.1027(1.1018) | Xent 0.0405(0.0357) | Loss 1.1230(1.1197) | Error 0.0115(0.0110) Steps 446(435.50) | Grad Norm 0.2361(0.6341) | Total Time 10.00(10.00)\n",
      "Iter 4267 | Time 32.6179(31.2140) | Bit/dim 1.1059(1.1020) | Xent 0.0368(0.0357) | Loss 1.1242(1.1198) | Error 0.0106(0.0110) Steps 452(436.00) | Grad Norm 0.5918(0.6328) | Total Time 10.00(10.00)\n",
      "Iter 4268 | Time 31.1836(31.2131) | Bit/dim 1.1008(1.1019) | Xent 0.0330(0.0356) | Loss 1.1173(1.1197) | Error 0.0102(0.0110) Steps 434(435.94) | Grad Norm 0.9323(0.6418) | Total Time 10.00(10.00)\n",
      "Iter 4269 | Time 30.3532(31.1873) | Bit/dim 1.0979(1.1018) | Xent 0.0349(0.0356) | Loss 1.1153(1.1196) | Error 0.0104(0.0110) Steps 434(435.88) | Grad Norm 0.3105(0.6319) | Total Time 10.00(10.00)\n",
      "Iter 4270 | Time 32.5854(31.2292) | Bit/dim 1.1006(1.1018) | Xent 0.0361(0.0356) | Loss 1.1186(1.1196) | Error 0.0121(0.0110) Steps 434(435.82) | Grad Norm 0.7040(0.6340) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0610 | Time 16.8767, Epoch Time 249.4381(243.9943), Bit/dim 1.0959(best: 1.0957), Xent 0.0273, Loss 1.1096, Error 0.0086(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4271 | Time 30.8695(31.2185) | Bit/dim 1.1045(1.1018) | Xent 0.0326(0.0355) | Loss 1.1208(1.1196) | Error 0.0106(0.0110) Steps 434(435.77) | Grad Norm 0.3983(0.6270) | Total Time 10.00(10.00)\n",
      "Iter 4272 | Time 31.2928(31.2207) | Bit/dim 1.1035(1.1019) | Xent 0.0383(0.0356) | Loss 1.1227(1.1197) | Error 0.0115(0.0110) Steps 440(435.90) | Grad Norm 0.3446(0.6185) | Total Time 10.00(10.00)\n",
      "Iter 4273 | Time 32.2475(31.2515) | Bit/dim 1.1032(1.1019) | Xent 0.0317(0.0355) | Loss 1.1190(1.1197) | Error 0.0090(0.0109) Steps 452(436.38) | Grad Norm 0.8643(0.6259) | Total Time 10.00(10.00)\n",
      "Iter 4274 | Time 31.3976(31.2559) | Bit/dim 1.1054(1.1020) | Xent 0.0335(0.0354) | Loss 1.1222(1.1198) | Error 0.0116(0.0110) Steps 434(436.31) | Grad Norm 0.7087(0.6284) | Total Time 10.00(10.00)\n",
      "Iter 4275 | Time 31.1867(31.2538) | Bit/dim 1.1022(1.1020) | Xent 0.0398(0.0356) | Loss 1.1222(1.1198) | Error 0.0121(0.0110) Steps 446(436.60) | Grad Norm 0.3655(0.6205) | Total Time 10.00(10.00)\n",
      "Iter 4276 | Time 31.3143(31.2556) | Bit/dim 1.1015(1.1020) | Xent 0.0343(0.0355) | Loss 1.1186(1.1198) | Error 0.0102(0.0110) Steps 434(436.52) | Grad Norm 0.3709(0.6130) | Total Time 10.00(10.00)\n",
      "Iter 4277 | Time 31.2338(31.2550) | Bit/dim 1.0995(1.1020) | Xent 0.0363(0.0356) | Loss 1.1176(1.1197) | Error 0.0112(0.0110) Steps 446(436.80) | Grad Norm 0.4081(0.6068) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0611 | Time 17.4181, Epoch Time 249.1950(244.1504), Bit/dim 1.0965(best: 1.0957), Xent 0.0282, Loss 1.1106, Error 0.0103(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4278 | Time 31.3852(31.2589) | Bit/dim 1.1022(1.1020) | Xent 0.0420(0.0357) | Loss 1.1232(1.1198) | Error 0.0118(0.0110) Steps 434(436.72) | Grad Norm 0.2467(0.5960) | Total Time 10.00(10.00)\n",
      "Iter 4279 | Time 30.8623(31.2470) | Bit/dim 1.0999(1.1019) | Xent 0.0394(0.0359) | Loss 1.1196(1.1198) | Error 0.0119(0.0110) Steps 434(436.64) | Grad Norm 0.8078(0.6024) | Total Time 10.00(10.00)\n",
      "Iter 4280 | Time 31.7889(31.2632) | Bit/dim 1.1002(1.1018) | Xent 0.0362(0.0359) | Loss 1.1183(1.1198) | Error 0.0122(0.0111) Steps 446(436.92) | Grad Norm 0.6989(0.6053) | Total Time 10.00(10.00)\n",
      "Iter 4281 | Time 31.3337(31.2653) | Bit/dim 1.1004(1.1018) | Xent 0.0419(0.0360) | Loss 1.1214(1.1198) | Error 0.0148(0.0112) Steps 434(436.83) | Grad Norm 0.5581(0.6039) | Total Time 10.00(10.00)\n",
      "Iter 4282 | Time 31.4801(31.2718) | Bit/dim 1.1007(1.1018) | Xent 0.0344(0.0360) | Loss 1.1179(1.1198) | Error 0.0109(0.0112) Steps 434(436.75) | Grad Norm 0.7760(0.6090) | Total Time 10.00(10.00)\n",
      "Iter 4283 | Time 31.8398(31.2888) | Bit/dim 1.1046(1.1019) | Xent 0.0299(0.0358) | Loss 1.1195(1.1198) | Error 0.0098(0.0111) Steps 434(436.66) | Grad Norm 0.3687(0.6018) | Total Time 10.00(10.00)\n",
      "Iter 4284 | Time 31.1426(31.2844) | Bit/dim 1.1025(1.1019) | Xent 0.0347(0.0358) | Loss 1.1198(1.1198) | Error 0.0102(0.0111) Steps 434(436.58) | Grad Norm 0.7078(0.6050) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0612 | Time 16.7600, Epoch Time 249.0648(244.2978), Bit/dim 1.0968(best: 1.0957), Xent 0.0280, Loss 1.1108, Error 0.0101(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4285 | Time 32.5563(31.3226) | Bit/dim 1.1023(1.1019) | Xent 0.0355(0.0358) | Loss 1.1200(1.1198) | Error 0.0118(0.0111) Steps 452(437.05) | Grad Norm 0.6859(0.6074) | Total Time 10.00(10.00)\n",
      "Iter 4286 | Time 31.0529(31.3145) | Bit/dim 1.1051(1.1020) | Xent 0.0329(0.0357) | Loss 1.1216(1.1198) | Error 0.0112(0.0111) Steps 434(436.96) | Grad Norm 0.4380(0.6023) | Total Time 10.00(10.00)\n",
      "Iter 4287 | Time 30.7345(31.2971) | Bit/dim 1.1017(1.1020) | Xent 0.0378(0.0357) | Loss 1.1206(1.1198) | Error 0.0115(0.0111) Steps 434(436.87) | Grad Norm 0.9660(0.6133) | Total Time 10.00(10.00)\n",
      "Iter 4288 | Time 31.4755(31.3025) | Bit/dim 1.0978(1.1019) | Xent 0.0428(0.0360) | Loss 1.1193(1.1198) | Error 0.0130(0.0112) Steps 434(436.78) | Grad Norm 0.6813(0.6153) | Total Time 10.00(10.00)\n",
      "Iter 4289 | Time 31.9080(31.3206) | Bit/dim 1.1056(1.1020) | Xent 0.0307(0.0358) | Loss 1.1210(1.1199) | Error 0.0108(0.0112) Steps 446(437.06) | Grad Norm 0.5082(0.6121) | Total Time 10.00(10.00)\n",
      "Iter 4290 | Time 31.5412(31.3272) | Bit/dim 1.0970(1.1018) | Xent 0.0356(0.0358) | Loss 1.1149(1.1197) | Error 0.0118(0.0112) Steps 434(436.97) | Grad Norm 1.1250(0.6275) | Total Time 10.00(10.00)\n",
      "Iter 4291 | Time 31.8840(31.3439) | Bit/dim 1.1012(1.1018) | Xent 0.0325(0.0357) | Loss 1.1175(1.1196) | Error 0.0102(0.0112) Steps 446(437.24) | Grad Norm 0.4155(0.6211) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0613 | Time 16.6612, Epoch Time 250.3137(244.4783), Bit/dim 1.0960(best: 1.0957), Xent 0.0281, Loss 1.1101, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4292 | Time 31.0366(31.3347) | Bit/dim 1.1022(1.1018) | Xent 0.0302(0.0355) | Loss 1.1173(1.1196) | Error 0.0082(0.0111) Steps 434(437.14) | Grad Norm 1.1857(0.6380) | Total Time 10.00(10.00)\n",
      "Iter 4293 | Time 30.4518(31.3082) | Bit/dim 1.0997(1.1017) | Xent 0.0335(0.0355) | Loss 1.1164(1.1195) | Error 0.0108(0.0111) Steps 434(437.05) | Grad Norm 1.1069(0.6521) | Total Time 10.00(10.00)\n",
      "Iter 4294 | Time 31.3289(31.3089) | Bit/dim 1.1030(1.1018) | Xent 0.0328(0.0354) | Loss 1.1194(1.1195) | Error 0.0099(0.0110) Steps 434(436.95) | Grad Norm 0.5634(0.6495) | Total Time 10.00(10.00)\n",
      "Iter 4295 | Time 31.0935(31.3024) | Bit/dim 1.1008(1.1018) | Xent 0.0359(0.0354) | Loss 1.1188(1.1195) | Error 0.0104(0.0110) Steps 434(436.87) | Grad Norm 1.3841(0.6715) | Total Time 10.00(10.00)\n",
      "Iter 4296 | Time 31.2458(31.3007) | Bit/dim 1.1036(1.1018) | Xent 0.0350(0.0354) | Loss 1.1211(1.1195) | Error 0.0101(0.0110) Steps 440(436.96) | Grad Norm 0.8550(0.6770) | Total Time 10.00(10.00)\n",
      "Iter 4297 | Time 30.7255(31.2834) | Bit/dim 1.1052(1.1019) | Xent 0.0360(0.0354) | Loss 1.1232(1.1196) | Error 0.0115(0.0110) Steps 434(436.87) | Grad Norm 0.7585(0.6794) | Total Time 10.00(10.00)\n",
      "Iter 4298 | Time 30.8068(31.2691) | Bit/dim 1.0984(1.1018) | Xent 0.0417(0.0356) | Loss 1.1193(1.1196) | Error 0.0126(0.0111) Steps 434(436.78) | Grad Norm 1.2211(0.6957) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0614 | Time 16.9615, Epoch Time 246.0034(244.5240), Bit/dim 1.0954(best: 1.0957), Xent 0.0281, Loss 1.1094, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4299 | Time 31.1039(31.2642) | Bit/dim 1.1005(1.1018) | Xent 0.0370(0.0356) | Loss 1.1191(1.1196) | Error 0.0109(0.0110) Steps 434(436.70) | Grad Norm 0.4260(0.6876) | Total Time 10.00(10.00)\n",
      "Iter 4300 | Time 31.2897(31.2649) | Bit/dim 1.1042(1.1018) | Xent 0.0341(0.0356) | Loss 1.1213(1.1196) | Error 0.0106(0.0110) Steps 434(436.62) | Grad Norm 0.8633(0.6929) | Total Time 10.00(10.00)\n",
      "Iter 4301 | Time 32.0885(31.2897) | Bit/dim 1.1005(1.1018) | Xent 0.0312(0.0355) | Loss 1.1161(1.1195) | Error 0.0095(0.0110) Steps 452(437.08) | Grad Norm 0.3401(0.6823) | Total Time 10.00(10.00)\n",
      "Iter 4302 | Time 30.7725(31.2741) | Bit/dim 1.1001(1.1018) | Xent 0.0356(0.0355) | Loss 1.1180(1.1195) | Error 0.0104(0.0110) Steps 434(436.99) | Grad Norm 0.9793(0.6912) | Total Time 10.00(10.00)\n",
      "Iter 4303 | Time 30.9352(31.2640) | Bit/dim 1.1007(1.1017) | Xent 0.0409(0.0356) | Loss 1.1211(1.1195) | Error 0.0125(0.0110) Steps 434(436.90) | Grad Norm 0.3960(0.6823) | Total Time 10.00(10.00)\n",
      "Iter 4304 | Time 31.4033(31.2681) | Bit/dim 1.1067(1.1019) | Xent 0.0358(0.0356) | Loss 1.1247(1.1197) | Error 0.0115(0.0110) Steps 434(436.81) | Grad Norm 1.0839(0.6944) | Total Time 10.00(10.00)\n",
      "Iter 4305 | Time 32.4620(31.3040) | Bit/dim 1.1008(1.1018) | Xent 0.0387(0.0357) | Loss 1.1201(1.1197) | Error 0.0104(0.0110) Steps 434(436.73) | Grad Norm 0.2555(0.6812) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0615 | Time 17.1499, Epoch Time 249.6244(244.6770), Bit/dim 1.0959(best: 1.0954), Xent 0.0263, Loss 1.1090, Error 0.0096(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4306 | Time 31.6619(31.3147) | Bit/dim 1.1013(1.1018) | Xent 0.0449(0.0360) | Loss 1.1237(1.1198) | Error 0.0121(0.0110) Steps 446(437.01) | Grad Norm 0.8552(0.6864) | Total Time 10.00(10.00)\n",
      "Iter 4307 | Time 30.9010(31.3023) | Bit/dim 1.0962(1.1017) | Xent 0.0333(0.0359) | Loss 1.1129(1.1196) | Error 0.0101(0.0110) Steps 434(436.92) | Grad Norm 0.4803(0.6803) | Total Time 10.00(10.00)\n",
      "Iter 4308 | Time 30.6114(31.2816) | Bit/dim 1.0998(1.1016) | Xent 0.0325(0.0358) | Loss 1.1160(1.1195) | Error 0.0109(0.0110) Steps 434(436.83) | Grad Norm 1.1324(0.6938) | Total Time 10.00(10.00)\n",
      "Iter 4309 | Time 33.1996(31.3391) | Bit/dim 1.1020(1.1016) | Xent 0.0415(0.0360) | Loss 1.1227(1.1196) | Error 0.0125(0.0111) Steps 434(436.74) | Grad Norm 0.2531(0.6806) | Total Time 10.00(10.00)\n",
      "Iter 4310 | Time 31.4762(31.3432) | Bit/dim 1.1042(1.1017) | Xent 0.0337(0.0359) | Loss 1.1210(1.1196) | Error 0.0104(0.0110) Steps 434(436.66) | Grad Norm 1.2416(0.6974) | Total Time 10.00(10.00)\n",
      "Iter 4311 | Time 33.2003(31.3989) | Bit/dim 1.1046(1.1018) | Xent 0.0370(0.0360) | Loss 1.1231(1.1198) | Error 0.0109(0.0110) Steps 440(436.76) | Grad Norm 0.4739(0.6907) | Total Time 10.00(10.00)\n",
      "Iter 4312 | Time 30.9986(31.3869) | Bit/dim 1.1023(1.1018) | Xent 0.0318(0.0358) | Loss 1.1182(1.1197) | Error 0.0099(0.0110) Steps 434(436.68) | Grad Norm 1.0547(0.7016) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0616 | Time 17.0193, Epoch Time 251.4444(244.8801), Bit/dim 1.0962(best: 1.0954), Xent 0.0261, Loss 1.1092, Error 0.0085(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4313 | Time 30.8958(31.3722) | Bit/dim 1.1003(1.1017) | Xent 0.0290(0.0356) | Loss 1.1148(1.1196) | Error 0.0094(0.0109) Steps 434(436.60) | Grad Norm 0.8438(0.7059) | Total Time 10.00(10.00)\n",
      "Iter 4314 | Time 30.8817(31.3575) | Bit/dim 1.1022(1.1018) | Xent 0.0401(0.0358) | Loss 1.1222(1.1196) | Error 0.0129(0.0110) Steps 434(436.52) | Grad Norm 1.0372(0.7158) | Total Time 10.00(10.00)\n",
      "Iter 4315 | Time 31.3169(31.3562) | Bit/dim 1.1027(1.1018) | Xent 0.0318(0.0356) | Loss 1.1186(1.1196) | Error 0.0101(0.0110) Steps 446(436.80) | Grad Norm 1.7103(0.7457) | Total Time 10.00(10.00)\n",
      "Iter 4316 | Time 31.3463(31.3560) | Bit/dim 1.1000(1.1017) | Xent 0.0313(0.0355) | Loss 1.1156(1.1195) | Error 0.0098(0.0109) Steps 446(437.08) | Grad Norm 0.3984(0.7353) | Total Time 10.00(10.00)\n",
      "Iter 4317 | Time 31.0653(31.3472) | Bit/dim 1.0976(1.1016) | Xent 0.0337(0.0355) | Loss 1.1145(1.1193) | Error 0.0115(0.0110) Steps 440(437.17) | Grad Norm 1.1735(0.7484) | Total Time 10.00(10.00)\n",
      "Iter 4318 | Time 32.9015(31.3939) | Bit/dim 1.1033(1.1017) | Xent 0.0322(0.0354) | Loss 1.1194(1.1193) | Error 0.0108(0.0110) Steps 446(437.43) | Grad Norm 0.9872(0.7556) | Total Time 10.00(10.00)\n",
      "Iter 4319 | Time 34.3487(31.4825) | Bit/dim 1.1036(1.1017) | Xent 0.0368(0.0354) | Loss 1.1219(1.1194) | Error 0.0125(0.0110) Steps 446(437.69) | Grad Norm 0.3337(0.7429) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0617 | Time 16.6011, Epoch Time 251.7794(245.0870), Bit/dim 1.0961(best: 1.0954), Xent 0.0274, Loss 1.1098, Error 0.0084(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4320 | Time 30.9832(31.4675) | Bit/dim 1.1021(1.1017) | Xent 0.0394(0.0355) | Loss 1.1218(1.1195) | Error 0.0114(0.0110) Steps 434(437.58) | Grad Norm 0.4816(0.7351) | Total Time 10.00(10.00)\n",
      "Iter 4321 | Time 31.6437(31.4728) | Bit/dim 1.1027(1.1018) | Xent 0.0312(0.0354) | Loss 1.1183(1.1195) | Error 0.0101(0.0110) Steps 434(437.47) | Grad Norm 0.5060(0.7282) | Total Time 10.00(10.00)\n",
      "Iter 4322 | Time 30.6692(31.4487) | Bit/dim 1.0970(1.1016) | Xent 0.0366(0.0354) | Loss 1.1153(1.1193) | Error 0.0130(0.0110) Steps 434(437.37) | Grad Norm 0.7993(0.7303) | Total Time 10.00(10.00)\n",
      "Iter 4323 | Time 30.6180(31.4238) | Bit/dim 1.0999(1.1016) | Xent 0.0369(0.0355) | Loss 1.1184(1.1193) | Error 0.0121(0.0111) Steps 440(437.45) | Grad Norm 0.3505(0.7189) | Total Time 10.00(10.00)\n",
      "Iter 4324 | Time 31.3308(31.4210) | Bit/dim 1.0991(1.1015) | Xent 0.0342(0.0354) | Loss 1.1162(1.1192) | Error 0.0108(0.0111) Steps 440(437.52) | Grad Norm 0.4818(0.7118) | Total Time 10.00(10.00)\n",
      "Iter 4325 | Time 31.0583(31.4101) | Bit/dim 1.1023(1.1015) | Xent 0.0372(0.0355) | Loss 1.1209(1.1193) | Error 0.0105(0.0110) Steps 446(437.78) | Grad Norm 0.4670(0.7045) | Total Time 10.00(10.00)\n",
      "Iter 4326 | Time 30.9585(31.3966) | Bit/dim 1.1074(1.1017) | Xent 0.0299(0.0353) | Loss 1.1223(1.1194) | Error 0.0094(0.0110) Steps 434(437.66) | Grad Norm 0.4439(0.6967) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0618 | Time 17.0280, Epoch Time 246.7465(245.1368), Bit/dim 1.0961(best: 1.0954), Xent 0.0268, Loss 1.1095, Error 0.0089(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4327 | Time 31.2063(31.3909) | Bit/dim 1.0985(1.1016) | Xent 0.0349(0.0353) | Loss 1.1160(1.1192) | Error 0.0105(0.0110) Steps 434(437.55) | Grad Norm 0.4709(0.6899) | Total Time 10.00(10.00)\n",
      "Iter 4328 | Time 31.5163(31.3946) | Bit/dim 1.1073(1.1018) | Xent 0.0372(0.0354) | Loss 1.1259(1.1194) | Error 0.0118(0.0110) Steps 446(437.81) | Grad Norm 0.7715(0.6923) | Total Time 10.00(10.00)\n",
      "Iter 4329 | Time 32.6092(31.4311) | Bit/dim 1.1068(1.1019) | Xent 0.0359(0.0354) | Loss 1.1248(1.1196) | Error 0.0115(0.0110) Steps 446(438.05) | Grad Norm 1.0577(0.7033) | Total Time 10.00(10.00)\n",
      "Iter 4330 | Time 30.9913(31.4179) | Bit/dim 1.0987(1.1018) | Xent 0.0404(0.0355) | Loss 1.1189(1.1196) | Error 0.0121(0.0111) Steps 434(437.93) | Grad Norm 0.2524(0.6898) | Total Time 10.00(10.00)\n",
      "Iter 4331 | Time 31.3441(31.4156) | Bit/dim 1.0989(1.1017) | Xent 0.0326(0.0354) | Loss 1.1152(1.1195) | Error 0.0111(0.0111) Steps 446(438.17) | Grad Norm 0.8319(0.6940) | Total Time 10.00(10.00)\n",
      "Iter 4332 | Time 31.5676(31.4202) | Bit/dim 1.1035(1.1018) | Xent 0.0284(0.0352) | Loss 1.1177(1.1194) | Error 0.0091(0.0110) Steps 434(438.05) | Grad Norm 0.4587(0.6870) | Total Time 10.00(10.00)\n",
      "Iter 4333 | Time 31.2520(31.4152) | Bit/dim 1.0995(1.1017) | Xent 0.0342(0.0352) | Loss 1.1166(1.1193) | Error 0.0106(0.0110) Steps 434(437.93) | Grad Norm 0.4562(0.6801) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0619 | Time 16.7378, Epoch Time 249.6909(245.2734), Bit/dim 1.0956(best: 1.0954), Xent 0.0281, Loss 1.1096, Error 0.0099(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4334 | Time 30.8653(31.3987) | Bit/dim 1.1072(1.1019) | Xent 0.0379(0.0353) | Loss 1.1261(1.1195) | Error 0.0128(0.0110) Steps 434(437.81) | Grad Norm 0.5544(0.6763) | Total Time 10.00(10.00)\n",
      "Iter 4335 | Time 30.8660(31.3827) | Bit/dim 1.1040(1.1019) | Xent 0.0333(0.0352) | Loss 1.1207(1.1196) | Error 0.0118(0.0111) Steps 446(438.06) | Grad Norm 0.2279(0.6628) | Total Time 10.00(10.00)\n",
      "Iter 4336 | Time 31.5000(31.3862) | Bit/dim 1.0986(1.1018) | Xent 0.0375(0.0353) | Loss 1.1173(1.1195) | Error 0.0115(0.0111) Steps 434(437.93) | Grad Norm 0.6415(0.6622) | Total Time 10.00(10.00)\n",
      "Iter 4337 | Time 31.0954(31.3775) | Bit/dim 1.0964(1.1017) | Xent 0.0391(0.0354) | Loss 1.1160(1.1194) | Error 0.0126(0.0111) Steps 434(437.82) | Grad Norm 0.9310(0.6703) | Total Time 10.00(10.00)\n",
      "Iter 4338 | Time 31.4887(31.3808) | Bit/dim 1.1034(1.1017) | Xent 0.0373(0.0355) | Loss 1.1220(1.1195) | Error 0.0110(0.0111) Steps 446(438.06) | Grad Norm 0.2884(0.6588) | Total Time 10.00(10.00)\n",
      "Iter 4339 | Time 31.2064(31.3756) | Bit/dim 1.1010(1.1017) | Xent 0.0371(0.0355) | Loss 1.1195(1.1195) | Error 0.0120(0.0111) Steps 434(437.94) | Grad Norm 0.8070(0.6633) | Total Time 10.00(10.00)\n",
      "Iter 4340 | Time 32.0152(31.3948) | Bit/dim 1.1006(1.1017) | Xent 0.0387(0.0356) | Loss 1.1200(1.1195) | Error 0.0125(0.0112) Steps 434(437.82) | Grad Norm 1.0194(0.6739) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0620 | Time 17.0539, Epoch Time 248.5786(245.3726), Bit/dim 1.0956(best: 1.0954), Xent 0.0280, Loss 1.1097, Error 0.0099(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4341 | Time 31.6139(31.4013) | Bit/dim 1.1033(1.1017) | Xent 0.0338(0.0356) | Loss 1.1202(1.1195) | Error 0.0111(0.0112) Steps 452(438.25) | Grad Norm 0.2993(0.6627) | Total Time 10.00(10.00)\n",
      "Iter 4342 | Time 30.9669(31.3883) | Bit/dim 1.1017(1.1017) | Xent 0.0381(0.0356) | Loss 1.1208(1.1195) | Error 0.0124(0.0112) Steps 434(438.12) | Grad Norm 1.0618(0.6747) | Total Time 10.00(10.00)\n",
      "Iter 4343 | Time 31.5786(31.3940) | Bit/dim 1.1021(1.1017) | Xent 0.0288(0.0354) | Loss 1.1165(1.1194) | Error 0.0092(0.0112) Steps 434(438.00) | Grad Norm 0.6340(0.6734) | Total Time 10.00(10.00)\n",
      "Iter 4344 | Time 31.3200(31.3918) | Bit/dim 1.1025(1.1018) | Xent 0.0385(0.0355) | Loss 1.1218(1.1195) | Error 0.0108(0.0111) Steps 446(438.24) | Grad Norm 0.9533(0.6818) | Total Time 10.00(10.00)\n",
      "Iter 4345 | Time 30.6035(31.3682) | Bit/dim 1.1031(1.1018) | Xent 0.0324(0.0354) | Loss 1.1193(1.1195) | Error 0.0099(0.0111) Steps 446(438.47) | Grad Norm 1.0002(0.6914) | Total Time 10.00(10.00)\n",
      "Iter 4346 | Time 31.0364(31.3582) | Bit/dim 1.0981(1.1017) | Xent 0.0317(0.0353) | Loss 1.1140(1.1193) | Error 0.0102(0.0111) Steps 446(438.69) | Grad Norm 0.3571(0.6814) | Total Time 10.00(10.00)\n",
      "Iter 4347 | Time 31.1265(31.3513) | Bit/dim 1.0995(1.1016) | Xent 0.0356(0.0353) | Loss 1.1173(1.1193) | Error 0.0118(0.0111) Steps 434(438.55) | Grad Norm 1.0491(0.6924) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0621 | Time 17.0564, Epoch Time 247.6461(245.4408), Bit/dim 1.0963(best: 1.0954), Xent 0.0311, Loss 1.1118, Error 0.0098(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4348 | Time 31.7353(31.3628) | Bit/dim 1.1079(1.1018) | Xent 0.0408(0.0355) | Loss 1.1283(1.1196) | Error 0.0141(0.0112) Steps 440(438.60) | Grad Norm 0.4538(0.6852) | Total Time 10.00(10.00)\n",
      "Iter 4349 | Time 31.9860(31.3815) | Bit/dim 1.1039(1.1019) | Xent 0.0336(0.0354) | Loss 1.1207(1.1196) | Error 0.0108(0.0112) Steps 446(438.82) | Grad Norm 0.7126(0.6861) | Total Time 10.00(10.00)\n",
      "Iter 4350 | Time 31.3381(31.3802) | Bit/dim 1.0975(1.1017) | Xent 0.0353(0.0354) | Loss 1.1151(1.1195) | Error 0.0105(0.0112) Steps 434(438.67) | Grad Norm 0.7253(0.6872) | Total Time 10.00(10.00)\n",
      "Iter 4351 | Time 31.6414(31.3880) | Bit/dim 1.1022(1.1018) | Xent 0.0321(0.0353) | Loss 1.1182(1.1194) | Error 0.0108(0.0111) Steps 446(438.89) | Grad Norm 0.2981(0.6756) | Total Time 10.00(10.00)\n",
      "Iter 4352 | Time 31.1710(31.3815) | Bit/dim 1.0987(1.1017) | Xent 0.0407(0.0355) | Loss 1.1191(1.1194) | Error 0.0112(0.0112) Steps 446(439.11) | Grad Norm 0.3249(0.6650) | Total Time 10.00(10.00)\n",
      "Iter 4353 | Time 30.9843(31.3696) | Bit/dim 1.0967(1.1015) | Xent 0.0368(0.0355) | Loss 1.1151(1.1193) | Error 0.0119(0.0112) Steps 434(438.95) | Grad Norm 0.3140(0.6545) | Total Time 10.00(10.00)\n",
      "Iter 4354 | Time 31.7823(31.3820) | Bit/dim 1.1020(1.1015) | Xent 0.0327(0.0354) | Loss 1.1184(1.1193) | Error 0.0101(0.0111) Steps 434(438.81) | Grad Norm 0.2948(0.6437) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0622 | Time 16.9307, Epoch Time 250.3690(245.5886), Bit/dim 1.0957(best: 1.0954), Xent 0.0294, Loss 1.1104, Error 0.0100(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4355 | Time 31.4445(31.3838) | Bit/dim 1.0958(1.1014) | Xent 0.0366(0.0355) | Loss 1.1141(1.1191) | Error 0.0124(0.0112) Steps 446(439.02) | Grad Norm 0.3321(0.6344) | Total Time 10.00(10.00)\n",
      "Iter 4356 | Time 31.1351(31.3764) | Bit/dim 1.1031(1.1014) | Xent 0.0332(0.0354) | Loss 1.1197(1.1191) | Error 0.0106(0.0112) Steps 446(439.23) | Grad Norm 0.5952(0.6332) | Total Time 10.00(10.00)\n",
      "Iter 4357 | Time 32.7140(31.4165) | Bit/dim 1.1015(1.1014) | Xent 0.0403(0.0356) | Loss 1.1216(1.1192) | Error 0.0124(0.0112) Steps 452(439.61) | Grad Norm 0.9295(0.6421) | Total Time 10.00(10.00)\n",
      "Iter 4358 | Time 31.2586(31.4118) | Bit/dim 1.1038(1.1015) | Xent 0.0361(0.0356) | Loss 1.1219(1.1193) | Error 0.0118(0.0112) Steps 434(439.45) | Grad Norm 0.6109(0.6412) | Total Time 10.00(10.00)\n",
      "Iter 4359 | Time 31.8434(31.4247) | Bit/dim 1.0986(1.1014) | Xent 0.0290(0.0354) | Loss 1.1131(1.1191) | Error 0.0089(0.0111) Steps 446(439.64) | Grad Norm 0.2736(0.6301) | Total Time 10.00(10.00)\n",
      "Iter 4360 | Time 31.1892(31.4177) | Bit/dim 1.1068(1.1016) | Xent 0.0403(0.0355) | Loss 1.1269(1.1193) | Error 0.0126(0.0112) Steps 434(439.47) | Grad Norm 0.2794(0.6196) | Total Time 10.00(10.00)\n",
      "Iter 4361 | Time 31.0059(31.4053) | Bit/dim 1.1011(1.1015) | Xent 0.0400(0.0357) | Loss 1.1211(1.1194) | Error 0.0125(0.0112) Steps 434(439.31) | Grad Norm 0.4718(0.6152) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0623 | Time 17.1160, Epoch Time 250.5563(245.7377), Bit/dim 1.0955(best: 1.0954), Xent 0.0296, Loss 1.1103, Error 0.0109(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4362 | Time 31.1743(31.3984) | Bit/dim 1.1023(1.1016) | Xent 0.0368(0.0357) | Loss 1.1207(1.1194) | Error 0.0115(0.0112) Steps 434(439.15) | Grad Norm 0.6652(0.6167) | Total Time 10.00(10.00)\n",
      "Iter 4363 | Time 31.3022(31.3955) | Bit/dim 1.0950(1.1014) | Xent 0.0337(0.0356) | Loss 1.1119(1.1192) | Error 0.0109(0.0112) Steps 434(438.99) | Grad Norm 0.5996(0.6162) | Total Time 10.00(10.00)\n",
      "Iter 4364 | Time 31.0817(31.3861) | Bit/dim 1.1051(1.1015) | Xent 0.0362(0.0356) | Loss 1.1232(1.1193) | Error 0.0106(0.0112) Steps 434(438.85) | Grad Norm 0.3199(0.6073) | Total Time 10.00(10.00)\n",
      "Iter 4365 | Time 31.1860(31.3801) | Bit/dim 1.0995(1.1014) | Xent 0.0325(0.0356) | Loss 1.1158(1.1192) | Error 0.0108(0.0112) Steps 446(439.06) | Grad Norm 0.5391(0.6052) | Total Time 10.00(10.00)\n",
      "Iter 4366 | Time 31.1085(31.3719) | Bit/dim 1.1012(1.1014) | Xent 0.0376(0.0356) | Loss 1.1200(1.1192) | Error 0.0125(0.0112) Steps 446(439.27) | Grad Norm 0.7401(0.6093) | Total Time 10.00(10.00)\n",
      "Iter 4367 | Time 31.1737(31.3660) | Bit/dim 1.1039(1.1015) | Xent 0.0309(0.0355) | Loss 1.1194(1.1192) | Error 0.0092(0.0112) Steps 446(439.47) | Grad Norm 0.4245(0.6037) | Total Time 10.00(10.00)\n",
      "Iter 4368 | Time 33.0544(31.4166) | Bit/dim 1.1031(1.1015) | Xent 0.0379(0.0355) | Loss 1.1221(1.1193) | Error 0.0102(0.0111) Steps 446(439.67) | Grad Norm 0.3869(0.5972) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0624 | Time 16.8009, Epoch Time 249.1273(245.8394), Bit/dim 1.0948(best: 1.0954), Xent 0.0274, Loss 1.1085, Error 0.0098(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4369 | Time 31.5724(31.4213) | Bit/dim 1.1021(1.1016) | Xent 0.0308(0.0354) | Loss 1.1175(1.1193) | Error 0.0089(0.0111) Steps 446(439.86) | Grad Norm 0.6447(0.5986) | Total Time 10.00(10.00)\n",
      "Iter 4370 | Time 31.2538(31.4163) | Bit/dim 1.1043(1.1016) | Xent 0.0361(0.0354) | Loss 1.1223(1.1194) | Error 0.0119(0.0111) Steps 446(440.04) | Grad Norm 0.2571(0.5884) | Total Time 10.00(10.00)\n",
      "Iter 4371 | Time 31.1709(31.4089) | Bit/dim 1.1000(1.1016) | Xent 0.0388(0.0355) | Loss 1.1195(1.1194) | Error 0.0111(0.0111) Steps 446(440.22) | Grad Norm 0.5515(0.5873) | Total Time 10.00(10.00)\n",
      "Iter 4372 | Time 31.4812(31.4111) | Bit/dim 1.1001(1.1015) | Xent 0.0325(0.0354) | Loss 1.1164(1.1193) | Error 0.0099(0.0111) Steps 434(440.03) | Grad Norm 0.2587(0.5774) | Total Time 10.00(10.00)\n",
      "Iter 4373 | Time 30.9522(31.3973) | Bit/dim 1.0995(1.1015) | Xent 0.0398(0.0356) | Loss 1.1194(1.1193) | Error 0.0114(0.0111) Steps 434(439.85) | Grad Norm 0.5651(0.5771) | Total Time 10.00(10.00)\n",
      "Iter 4374 | Time 31.0077(31.3856) | Bit/dim 1.1001(1.1014) | Xent 0.0350(0.0356) | Loss 1.1176(1.1192) | Error 0.0110(0.0111) Steps 434(439.68) | Grad Norm 0.3459(0.5701) | Total Time 10.00(10.00)\n",
      "Iter 4375 | Time 32.5925(31.4218) | Bit/dim 1.1036(1.1015) | Xent 0.0355(0.0355) | Loss 1.1213(1.1193) | Error 0.0118(0.0111) Steps 434(439.51) | Grad Norm 0.7728(0.5762) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0625 | Time 16.8895, Epoch Time 249.4312(245.9471), Bit/dim 1.0959(best: 1.0948), Xent 0.0277, Loss 1.1097, Error 0.0092(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4376 | Time 30.6587(31.3989) | Bit/dim 1.1014(1.1015) | Xent 0.0380(0.0356) | Loss 1.1204(1.1193) | Error 0.0119(0.0111) Steps 446(439.70) | Grad Norm 0.5959(0.5768) | Total Time 10.00(10.00)\n",
      "Iter 4377 | Time 30.3831(31.3685) | Bit/dim 1.1034(1.1016) | Xent 0.0375(0.0357) | Loss 1.1222(1.1194) | Error 0.0122(0.0112) Steps 440(439.71) | Grad Norm 0.2740(0.5677) | Total Time 10.00(10.00)\n",
      "Iter 4378 | Time 31.0445(31.3587) | Bit/dim 1.1019(1.1016) | Xent 0.0334(0.0356) | Loss 1.1187(1.1194) | Error 0.0109(0.0111) Steps 434(439.54) | Grad Norm 0.4987(0.5656) | Total Time 10.00(10.00)\n",
      "Iter 4379 | Time 30.8573(31.3437) | Bit/dim 1.1008(1.1016) | Xent 0.0359(0.0356) | Loss 1.1187(1.1194) | Error 0.0100(0.0111) Steps 434(439.37) | Grad Norm 0.3164(0.5582) | Total Time 10.00(10.00)\n",
      "Iter 4380 | Time 31.8108(31.3577) | Bit/dim 1.1008(1.1015) | Xent 0.0345(0.0356) | Loss 1.1180(1.1193) | Error 0.0109(0.0111) Steps 446(439.57) | Grad Norm 0.7054(0.5626) | Total Time 10.00(10.00)\n",
      "Iter 4381 | Time 30.8107(31.3413) | Bit/dim 1.0975(1.1014) | Xent 0.0314(0.0355) | Loss 1.1132(1.1191) | Error 0.0095(0.0111) Steps 434(439.40) | Grad Norm 0.5549(0.5624) | Total Time 10.00(10.00)\n",
      "Iter 4382 | Time 30.8944(31.3279) | Bit/dim 1.1028(1.1014) | Xent 0.0340(0.0354) | Loss 1.1198(1.1192) | Error 0.0115(0.0111) Steps 446(439.60) | Grad Norm 0.2877(0.5541) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0626 | Time 17.1613, Epoch Time 245.9781(245.9481), Bit/dim 1.0951(best: 1.0948), Xent 0.0283, Loss 1.1092, Error 0.0106(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4383 | Time 32.5093(31.3633) | Bit/dim 1.1019(1.1015) | Xent 0.0374(0.0355) | Loss 1.1205(1.1192) | Error 0.0120(0.0111) Steps 446(439.79) | Grad Norm 0.5521(0.5540) | Total Time 10.00(10.00)\n",
      "Iter 4384 | Time 31.2844(31.3610) | Bit/dim 1.1061(1.1016) | Xent 0.0386(0.0356) | Loss 1.1254(1.1194) | Error 0.0104(0.0111) Steps 446(439.98) | Grad Norm 0.2867(0.5460) | Total Time 10.00(10.00)\n",
      "Iter 4385 | Time 31.1332(31.3541) | Bit/dim 1.1009(1.1016) | Xent 0.0362(0.0356) | Loss 1.1190(1.1194) | Error 0.0104(0.0111) Steps 446(440.16) | Grad Norm 0.6220(0.5483) | Total Time 10.00(10.00)\n",
      "Iter 4386 | Time 30.9999(31.3435) | Bit/dim 1.0977(1.1015) | Xent 0.0349(0.0356) | Loss 1.1151(1.1192) | Error 0.0100(0.0110) Steps 446(440.34) | Grad Norm 0.4304(0.5448) | Total Time 10.00(10.00)\n",
      "Iter 4387 | Time 30.7827(31.3267) | Bit/dim 1.1037(1.1015) | Xent 0.0314(0.0354) | Loss 1.1194(1.1192) | Error 0.0094(0.0110) Steps 434(440.15) | Grad Norm 0.3207(0.5380) | Total Time 10.00(10.00)\n",
      "Iter 4388 | Time 31.1419(31.3211) | Bit/dim 1.0988(1.1014) | Xent 0.0346(0.0354) | Loss 1.1161(1.1192) | Error 0.0112(0.0110) Steps 446(440.32) | Grad Norm 0.3265(0.5317) | Total Time 10.00(10.00)\n",
      "Iter 4389 | Time 30.8779(31.3079) | Bit/dim 1.0969(1.1013) | Xent 0.0356(0.0354) | Loss 1.1147(1.1190) | Error 0.0108(0.0110) Steps 446(440.49) | Grad Norm 0.4186(0.5283) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0627 | Time 17.1455, Epoch Time 248.3971(246.0215), Bit/dim 1.0956(best: 1.0948), Xent 0.0270, Loss 1.1091, Error 0.0092(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4390 | Time 31.2672(31.3066) | Bit/dim 1.1041(1.1014) | Xent 0.0335(0.0354) | Loss 1.1208(1.1191) | Error 0.0105(0.0110) Steps 434(440.30) | Grad Norm 0.4941(0.5273) | Total Time 10.00(10.00)\n",
      "Iter 4391 | Time 31.4027(31.3095) | Bit/dim 1.1000(1.1014) | Xent 0.0366(0.0354) | Loss 1.1184(1.1191) | Error 0.0105(0.0109) Steps 434(440.11) | Grad Norm 0.8653(0.5374) | Total Time 10.00(10.00)\n",
      "Iter 4392 | Time 30.9344(31.2983) | Bit/dim 1.0997(1.1013) | Xent 0.0398(0.0355) | Loss 1.1195(1.1191) | Error 0.0121(0.0110) Steps 446(440.28) | Grad Norm 0.8280(0.5461) | Total Time 10.00(10.00)\n",
      "Iter 4393 | Time 31.6669(31.3093) | Bit/dim 1.0996(1.1012) | Xent 0.0426(0.0357) | Loss 1.1209(1.1191) | Error 0.0129(0.0110) Steps 446(440.46) | Grad Norm 0.4448(0.5431) | Total Time 10.00(10.00)\n",
      "Iter 4394 | Time 31.8424(31.3253) | Bit/dim 1.0979(1.1011) | Xent 0.0319(0.0356) | Loss 1.1138(1.1190) | Error 0.0095(0.0110) Steps 446(440.62) | Grad Norm 1.3590(0.5676) | Total Time 10.00(10.00)\n",
      "Iter 4395 | Time 31.9961(31.3454) | Bit/dim 1.1080(1.1014) | Xent 0.0313(0.0355) | Loss 1.1237(1.1191) | Error 0.0104(0.0110) Steps 446(440.78) | Grad Norm 1.6265(0.5993) | Total Time 10.00(10.00)\n",
      "Iter 4396 | Time 31.1076(31.3383) | Bit/dim 1.0978(1.1012) | Xent 0.0343(0.0355) | Loss 1.1150(1.1190) | Error 0.0108(0.0110) Steps 446(440.94) | Grad Norm 0.4764(0.5957) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0628 | Time 16.9905, Epoch Time 249.6848(246.1314), Bit/dim 1.0954(best: 1.0948), Xent 0.0268, Loss 1.1088, Error 0.0084(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4397 | Time 31.6852(31.3487) | Bit/dim 1.1060(1.1014) | Xent 0.0330(0.0354) | Loss 1.1225(1.1191) | Error 0.0106(0.0110) Steps 452(441.27) | Grad Norm 1.2950(0.6166) | Total Time 10.00(10.00)\n",
      "Iter 4398 | Time 31.2669(31.3463) | Bit/dim 1.1044(1.1015) | Xent 0.0358(0.0354) | Loss 1.1223(1.1192) | Error 0.0105(0.0109) Steps 452(441.59) | Grad Norm 1.4481(0.6416) | Total Time 10.00(10.00)\n",
      "Iter 4399 | Time 30.9984(31.3358) | Bit/dim 1.0998(1.1014) | Xent 0.0354(0.0354) | Loss 1.1175(1.1191) | Error 0.0122(0.0110) Steps 434(441.37) | Grad Norm 0.3741(0.6336) | Total Time 10.00(10.00)\n",
      "Iter 4400 | Time 33.4978(31.4007) | Bit/dim 1.1000(1.1014) | Xent 0.0330(0.0353) | Loss 1.1165(1.1191) | Error 0.0100(0.0110) Steps 446(441.51) | Grad Norm 1.1335(0.6486) | Total Time 10.00(10.00)\n",
      "Iter 4401 | Time 32.4384(31.4318) | Bit/dim 1.0988(1.1013) | Xent 0.0338(0.0353) | Loss 1.1156(1.1190) | Error 0.0106(0.0109) Steps 452(441.82) | Grad Norm 0.8285(0.6540) | Total Time 10.00(10.00)\n",
      "Iter 4402 | Time 32.0790(31.4512) | Bit/dim 1.1042(1.1014) | Xent 0.0318(0.0352) | Loss 1.1202(1.1190) | Error 0.0102(0.0109) Steps 434(441.59) | Grad Norm 0.5119(0.6497) | Total Time 10.00(10.00)\n",
      "Iter 4403 | Time 31.9401(31.4659) | Bit/dim 1.1007(1.1014) | Xent 0.0347(0.0352) | Loss 1.1181(1.1190) | Error 0.0102(0.0109) Steps 446(441.72) | Grad Norm 1.1035(0.6633) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0629 | Time 16.8346, Epoch Time 253.2957(246.3463), Bit/dim 1.0953(best: 1.0948), Xent 0.0292, Loss 1.1099, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4404 | Time 30.7909(31.4456) | Bit/dim 1.1002(1.1013) | Xent 0.0405(0.0353) | Loss 1.1204(1.1190) | Error 0.0124(0.0109) Steps 434(441.49) | Grad Norm 0.6344(0.6624) | Total Time 10.00(10.00)\n",
      "Iter 4405 | Time 31.2778(31.4406) | Bit/dim 1.1013(1.1013) | Xent 0.0332(0.0353) | Loss 1.1179(1.1190) | Error 0.0102(0.0109) Steps 446(441.62) | Grad Norm 0.9479(0.6710) | Total Time 10.00(10.00)\n",
      "Iter 4406 | Time 31.9065(31.4546) | Bit/dim 1.0990(1.1013) | Xent 0.0331(0.0352) | Loss 1.1156(1.1189) | Error 0.0108(0.0109) Steps 434(441.39) | Grad Norm 0.4360(0.6640) | Total Time 10.00(10.00)\n",
      "Iter 4407 | Time 31.4763(31.4552) | Bit/dim 1.1009(1.1013) | Xent 0.0352(0.0352) | Loss 1.1185(1.1189) | Error 0.0115(0.0109) Steps 446(441.53) | Grad Norm 0.7477(0.6665) | Total Time 10.00(10.00)\n",
      "Iter 4408 | Time 32.0230(31.4723) | Bit/dim 1.1012(1.1013) | Xent 0.0332(0.0351) | Loss 1.1178(1.1188) | Error 0.0100(0.0109) Steps 446(441.67) | Grad Norm 0.6572(0.6662) | Total Time 10.00(10.00)\n",
      "Iter 4409 | Time 31.0993(31.4611) | Bit/dim 1.1004(1.1012) | Xent 0.0306(0.0350) | Loss 1.1157(1.1187) | Error 0.0100(0.0109) Steps 446(441.80) | Grad Norm 0.3409(0.6564) | Total Time 10.00(10.00)\n",
      "Iter 4410 | Time 31.1149(31.4507) | Bit/dim 1.0993(1.1012) | Xent 0.0398(0.0351) | Loss 1.1191(1.1187) | Error 0.0121(0.0109) Steps 446(441.92) | Grad Norm 0.5446(0.6531) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0630 | Time 17.2638, Epoch Time 249.5347(246.4420), Bit/dim 1.0956(best: 1.0948), Xent 0.0299, Loss 1.1105, Error 0.0101(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4411 | Time 30.5535(31.4238) | Bit/dim 1.1051(1.1013) | Xent 0.0371(0.0352) | Loss 1.1237(1.1189) | Error 0.0105(0.0109) Steps 446(442.04) | Grad Norm 0.6600(0.6533) | Total Time 10.00(10.00)\n",
      "Iter 4412 | Time 32.1712(31.4462) | Bit/dim 1.0959(1.1011) | Xent 0.0294(0.0350) | Loss 1.1106(1.1186) | Error 0.0096(0.0109) Steps 446(442.16) | Grad Norm 0.2607(0.6415) | Total Time 10.00(10.00)\n",
      "Iter 4413 | Time 31.3007(31.4418) | Bit/dim 1.1003(1.1011) | Xent 0.0359(0.0351) | Loss 1.1182(1.1186) | Error 0.0112(0.0109) Steps 434(441.92) | Grad Norm 0.4806(0.6367) | Total Time 10.00(10.00)\n",
      "Iter 4414 | Time 32.1119(31.4619) | Bit/dim 1.0999(1.1011) | Xent 0.0437(0.0353) | Loss 1.1218(1.1187) | Error 0.0145(0.0110) Steps 446(442.04) | Grad Norm 0.4202(0.6302) | Total Time 10.00(10.00)\n",
      "Iter 4415 | Time 31.3441(31.4584) | Bit/dim 1.1006(1.1011) | Xent 0.0299(0.0352) | Loss 1.1156(1.1186) | Error 0.0094(0.0109) Steps 434(441.80) | Grad Norm 0.3388(0.6214) | Total Time 10.00(10.00)\n",
      "Iter 4416 | Time 31.1896(31.4503) | Bit/dim 1.0998(1.1010) | Xent 0.0347(0.0351) | Loss 1.1171(1.1186) | Error 0.0108(0.0109) Steps 434(441.56) | Grad Norm 0.6000(0.6208) | Total Time 10.00(10.00)\n",
      "Iter 4417 | Time 31.2390(31.4440) | Bit/dim 1.1011(1.1010) | Xent 0.0347(0.0351) | Loss 1.1184(1.1186) | Error 0.0111(0.0109) Steps 434(441.34) | Grad Norm 0.6594(0.6220) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0631 | Time 17.1016, Epoch Time 249.4039(246.5309), Bit/dim 1.0951(best: 1.0948), Xent 0.0285, Loss 1.1094, Error 0.0101(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4418 | Time 32.0098(31.4610) | Bit/dim 1.1029(1.1011) | Xent 0.0373(0.0352) | Loss 1.1215(1.1187) | Error 0.0109(0.0109) Steps 452(441.66) | Grad Norm 0.6565(0.6230) | Total Time 10.00(10.00)\n",
      "Iter 4419 | Time 32.7149(31.4986) | Bit/dim 1.1015(1.1011) | Xent 0.0318(0.0351) | Loss 1.1174(1.1186) | Error 0.0101(0.0109) Steps 440(441.61) | Grad Norm 0.3940(0.6161) | Total Time 10.00(10.00)\n",
      "Iter 4420 | Time 32.2742(31.5219) | Bit/dim 1.1021(1.1011) | Xent 0.0419(0.0353) | Loss 1.1231(1.1188) | Error 0.0130(0.0110) Steps 446(441.74) | Grad Norm 0.5357(0.6137) | Total Time 10.00(10.00)\n",
      "Iter 4421 | Time 31.7045(31.5273) | Bit/dim 1.1011(1.1011) | Xent 0.0304(0.0351) | Loss 1.1162(1.1187) | Error 0.0098(0.0109) Steps 434(441.51) | Grad Norm 0.9313(0.6232) | Total Time 10.00(10.00)\n",
      "Iter 4422 | Time 31.0555(31.5132) | Bit/dim 1.0993(1.1011) | Xent 0.0339(0.0351) | Loss 1.1163(1.1186) | Error 0.0100(0.0109) Steps 434(441.28) | Grad Norm 0.8739(0.6308) | Total Time 10.00(10.00)\n",
      "Iter 4423 | Time 31.4586(31.5115) | Bit/dim 1.1018(1.1011) | Xent 0.0404(0.0353) | Loss 1.1220(1.1187) | Error 0.0128(0.0110) Steps 446(441.42) | Grad Norm 0.3103(0.6211) | Total Time 10.00(10.00)\n",
      "Iter 4424 | Time 31.2762(31.5045) | Bit/dim 1.0959(1.1009) | Xent 0.0328(0.0352) | Loss 1.1122(1.1185) | Error 0.0090(0.0109) Steps 446(441.56) | Grad Norm 0.8256(0.6273) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0632 | Time 17.0299, Epoch Time 251.9101(246.6922), Bit/dim 1.0953(best: 1.0948), Xent 0.0287, Loss 1.1097, Error 0.0101(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4425 | Time 31.0599(31.4912) | Bit/dim 1.1025(1.1010) | Xent 0.0279(0.0350) | Loss 1.1164(1.1185) | Error 0.0095(0.0109) Steps 446(441.69) | Grad Norm 0.9133(0.6359) | Total Time 10.00(10.00)\n",
      "Iter 4426 | Time 31.7284(31.4983) | Bit/dim 1.1000(1.1009) | Xent 0.0416(0.0352) | Loss 1.1208(1.1185) | Error 0.0124(0.0109) Steps 434(441.46) | Grad Norm 0.3282(0.6266) | Total Time 10.00(10.00)\n",
      "Iter 4427 | Time 30.8369(31.4784) | Bit/dim 1.1054(1.1011) | Xent 0.0364(0.0352) | Loss 1.1236(1.1187) | Error 0.0106(0.0109) Steps 434(441.24) | Grad Norm 1.0457(0.6392) | Total Time 10.00(10.00)\n",
      "Iter 4428 | Time 31.7944(31.4879) | Bit/dim 1.0943(1.1009) | Xent 0.0311(0.0351) | Loss 1.1098(1.1184) | Error 0.0094(0.0109) Steps 446(441.38) | Grad Norm 0.4760(0.6343) | Total Time 10.00(10.00)\n",
      "Iter 4429 | Time 31.3383(31.4834) | Bit/dim 1.1003(1.1009) | Xent 0.0422(0.0353) | Loss 1.1214(1.1185) | Error 0.0130(0.0109) Steps 446(441.52) | Grad Norm 0.8059(0.6395) | Total Time 10.00(10.00)\n",
      "Iter 4430 | Time 31.5253(31.4847) | Bit/dim 1.1039(1.1010) | Xent 0.0373(0.0354) | Loss 1.1226(1.1186) | Error 0.0109(0.0109) Steps 434(441.30) | Grad Norm 0.6500(0.6398) | Total Time 10.00(10.00)\n",
      "Iter 4431 | Time 31.1934(31.4759) | Bit/dim 1.0990(1.1009) | Xent 0.0328(0.0353) | Loss 1.1154(1.1185) | Error 0.0106(0.0109) Steps 434(441.08) | Grad Norm 0.6847(0.6411) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0633 | Time 17.0614, Epoch Time 248.9168(246.7590), Bit/dim 1.0949(best: 1.0948), Xent 0.0266, Loss 1.1082, Error 0.0095(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4432 | Time 30.7457(31.4540) | Bit/dim 1.0989(1.1008) | Xent 0.0395(0.0354) | Loss 1.1186(1.1185) | Error 0.0125(0.0110) Steps 446(441.22) | Grad Norm 0.9928(0.6517) | Total Time 10.00(10.00)\n",
      "Iter 4433 | Time 31.6568(31.4601) | Bit/dim 1.1018(1.1009) | Xent 0.0317(0.0353) | Loss 1.1176(1.1185) | Error 0.0105(0.0109) Steps 446(441.37) | Grad Norm 0.2895(0.6408) | Total Time 10.00(10.00)\n",
      "Iter 4434 | Time 30.9534(31.4449) | Bit/dim 1.0972(1.1007) | Xent 0.0390(0.0354) | Loss 1.1167(1.1185) | Error 0.0116(0.0110) Steps 446(441.51) | Grad Norm 1.2370(0.6587) | Total Time 10.00(10.00)\n",
      "Iter 4435 | Time 31.1693(31.4366) | Bit/dim 1.1020(1.1008) | Xent 0.0365(0.0354) | Loss 1.1203(1.1185) | Error 0.0112(0.0110) Steps 446(441.64) | Grad Norm 0.7927(0.6627) | Total Time 10.00(10.00)\n",
      "Iter 4436 | Time 31.2208(31.4302) | Bit/dim 1.1016(1.1008) | Xent 0.0344(0.0354) | Loss 1.1188(1.1185) | Error 0.0112(0.0110) Steps 446(441.77) | Grad Norm 0.4323(0.6558) | Total Time 10.00(10.00)\n",
      "Iter 4437 | Time 32.0633(31.4492) | Bit/dim 1.1055(1.1010) | Xent 0.0372(0.0355) | Loss 1.1241(1.1187) | Error 0.0115(0.0110) Steps 446(441.90) | Grad Norm 0.2309(0.6431) | Total Time 10.00(10.00)\n",
      "Iter 4438 | Time 31.2616(31.4435) | Bit/dim 1.0967(1.1008) | Xent 0.0325(0.0354) | Loss 1.1129(1.1185) | Error 0.0091(0.0109) Steps 434(441.66) | Grad Norm 0.7882(0.6474) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0634 | Time 16.9321, Epoch Time 248.4709(246.8103), Bit/dim 1.0945(best: 1.0948), Xent 0.0294, Loss 1.1092, Error 0.0102(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4439 | Time 31.2992(31.4392) | Bit/dim 1.1071(1.1010) | Xent 0.0323(0.0353) | Loss 1.1233(1.1187) | Error 0.0091(0.0109) Steps 446(441.79) | Grad Norm 0.4712(0.6421) | Total Time 10.00(10.00)\n",
      "Iter 4440 | Time 30.8288(31.4209) | Bit/dim 1.0984(1.1009) | Xent 0.0383(0.0354) | Loss 1.1175(1.1186) | Error 0.0111(0.0109) Steps 446(441.92) | Grad Norm 1.0133(0.6533) | Total Time 10.00(10.00)\n",
      "Iter 4441 | Time 31.5949(31.4261) | Bit/dim 1.1004(1.1009) | Xent 0.0308(0.0352) | Loss 1.1158(1.1185) | Error 0.0102(0.0109) Steps 446(442.04) | Grad Norm 1.2956(0.6725) | Total Time 10.00(10.00)\n",
      "Iter 4442 | Time 30.9430(31.4116) | Bit/dim 1.1013(1.1009) | Xent 0.0332(0.0352) | Loss 1.1179(1.1185) | Error 0.0106(0.0109) Steps 434(441.80) | Grad Norm 0.3155(0.6618) | Total Time 10.00(10.00)\n",
      "Iter 4443 | Time 31.2887(31.4079) | Bit/dim 1.0958(1.1008) | Xent 0.0346(0.0352) | Loss 1.1131(1.1184) | Error 0.0104(0.0109) Steps 434(441.57) | Grad Norm 1.1091(0.6752) | Total Time 10.00(10.00)\n",
      "Iter 4444 | Time 30.8206(31.3903) | Bit/dim 1.0952(1.1006) | Xent 0.0369(0.0352) | Loss 1.1137(1.1182) | Error 0.0109(0.0109) Steps 446(441.70) | Grad Norm 0.4071(0.6672) | Total Time 10.00(10.00)\n",
      "Iter 4445 | Time 32.6073(31.4268) | Bit/dim 1.1016(1.1006) | Xent 0.0348(0.0352) | Loss 1.1190(1.1182) | Error 0.0109(0.0109) Steps 446(441.83) | Grad Norm 0.8915(0.6739) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0635 | Time 16.7946, Epoch Time 248.6117(246.8644), Bit/dim 1.0946(best: 1.0945), Xent 0.0271, Loss 1.1082, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4446 | Time 31.1191(31.4176) | Bit/dim 1.0988(1.1006) | Xent 0.0350(0.0352) | Loss 1.1163(1.1182) | Error 0.0112(0.0109) Steps 446(441.95) | Grad Norm 0.5110(0.6690) | Total Time 10.00(10.00)\n",
      "Iter 4447 | Time 30.9701(31.4042) | Bit/dim 1.1032(1.1007) | Xent 0.0355(0.0352) | Loss 1.1210(1.1183) | Error 0.0118(0.0109) Steps 446(442.07) | Grad Norm 1.2843(0.6875) | Total Time 10.00(10.00)\n",
      "Iter 4448 | Time 31.0986(31.3950) | Bit/dim 1.1013(1.1007) | Xent 0.0379(0.0353) | Loss 1.1203(1.1183) | Error 0.0116(0.0109) Steps 434(441.83) | Grad Norm 1.3239(0.7066) | Total Time 10.00(10.00)\n",
      "Iter 4449 | Time 31.2169(31.3896) | Bit/dim 1.1033(1.1008) | Xent 0.0335(0.0352) | Loss 1.1200(1.1184) | Error 0.0106(0.0109) Steps 446(441.96) | Grad Norm 0.9810(0.7148) | Total Time 10.00(10.00)\n",
      "Iter 4450 | Time 31.3710(31.3891) | Bit/dim 1.1005(1.1008) | Xent 0.0363(0.0353) | Loss 1.1186(1.1184) | Error 0.0116(0.0109) Steps 446(442.08) | Grad Norm 1.9073(0.7506) | Total Time 10.00(10.00)\n",
      "Iter 4451 | Time 31.2951(31.3863) | Bit/dim 1.1027(1.1008) | Xent 0.0333(0.0352) | Loss 1.1193(1.1184) | Error 0.0105(0.0109) Steps 452(442.38) | Grad Norm 0.4220(0.7407) | Total Time 10.00(10.00)\n",
      "Iter 4452 | Time 31.2815(31.3831) | Bit/dim 1.0962(1.1007) | Xent 0.0364(0.0352) | Loss 1.1144(1.1183) | Error 0.0109(0.0109) Steps 434(442.12) | Grad Norm 1.3550(0.7592) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0636 | Time 16.9739, Epoch Time 247.7837(246.8919), Bit/dim 1.0942(best: 1.0945), Xent 0.0280, Loss 1.1081, Error 0.0092(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4453 | Time 31.6383(31.3908) | Bit/dim 1.1043(1.1008) | Xent 0.0392(0.0354) | Loss 1.1239(1.1185) | Error 0.0119(0.0109) Steps 446(442.24) | Grad Norm 1.5010(0.7814) | Total Time 10.00(10.00)\n",
      "Iter 4454 | Time 30.9966(31.3790) | Bit/dim 1.1020(1.1008) | Xent 0.0331(0.0353) | Loss 1.1185(1.1185) | Error 0.0110(0.0109) Steps 446(442.35) | Grad Norm 0.4614(0.7718) | Total Time 10.00(10.00)\n",
      "Iter 4455 | Time 30.8389(31.3628) | Bit/dim 1.1019(1.1008) | Xent 0.0359(0.0353) | Loss 1.1198(1.1185) | Error 0.0111(0.0109) Steps 440(442.28) | Grad Norm 0.5908(0.7664) | Total Time 10.00(10.00)\n",
      "Iter 4456 | Time 32.4971(31.3968) | Bit/dim 1.1023(1.1009) | Xent 0.0444(0.0356) | Loss 1.1245(1.1187) | Error 0.0128(0.0110) Steps 434(442.03) | Grad Norm 0.4889(0.7581) | Total Time 10.00(10.00)\n",
      "Iter 4457 | Time 31.1323(31.3889) | Bit/dim 1.0980(1.1008) | Xent 0.0315(0.0355) | Loss 1.1138(1.1185) | Error 0.0089(0.0109) Steps 434(441.79) | Grad Norm 0.2291(0.7422) | Total Time 10.00(10.00)\n",
      "Iter 4458 | Time 31.2066(31.3834) | Bit/dim 1.1025(1.1009) | Xent 0.0263(0.0352) | Loss 1.1157(1.1184) | Error 0.0082(0.0109) Steps 446(441.92) | Grad Norm 0.2988(0.7289) | Total Time 10.00(10.00)\n",
      "Iter 4459 | Time 31.1023(31.3749) | Bit/dim 1.0921(1.1006) | Xent 0.0346(0.0352) | Loss 1.1095(1.1182) | Error 0.0104(0.0108) Steps 446(442.04) | Grad Norm 0.2845(0.7156) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0637 | Time 17.0382, Epoch Time 249.1353(246.9592), Bit/dim 1.0948(best: 1.0942), Xent 0.0292, Loss 1.1094, Error 0.0104(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4460 | Time 30.7949(31.3575) | Bit/dim 1.0994(1.1006) | Xent 0.0386(0.0353) | Loss 1.1187(1.1182) | Error 0.0118(0.0109) Steps 446(442.16) | Grad Norm 0.3417(0.7043) | Total Time 10.00(10.00)\n",
      "Iter 4461 | Time 31.4540(31.3604) | Bit/dim 1.0984(1.1005) | Xent 0.0321(0.0352) | Loss 1.1145(1.1181) | Error 0.0101(0.0108) Steps 446(442.28) | Grad Norm 0.4608(0.6970) | Total Time 10.00(10.00)\n",
      "Iter 4462 | Time 31.5515(31.3662) | Bit/dim 1.0966(1.1004) | Xent 0.0323(0.0351) | Loss 1.1127(1.1179) | Error 0.0095(0.0108) Steps 446(442.39) | Grad Norm 0.3127(0.6855) | Total Time 10.00(10.00)\n",
      "Iter 4463 | Time 31.6374(31.3743) | Bit/dim 1.1027(1.1004) | Xent 0.0343(0.0351) | Loss 1.1198(1.1180) | Error 0.0104(0.0108) Steps 446(442.50) | Grad Norm 0.2660(0.6729) | Total Time 10.00(10.00)\n",
      "Iter 4464 | Time 32.0180(31.3936) | Bit/dim 1.1025(1.1005) | Xent 0.0388(0.0352) | Loss 1.1219(1.1181) | Error 0.0118(0.0108) Steps 446(442.60) | Grad Norm 0.6334(0.6717) | Total Time 10.00(10.00)\n",
      "Iter 4465 | Time 31.2364(31.3889) | Bit/dim 1.1031(1.1006) | Xent 0.0317(0.0351) | Loss 1.1190(1.1181) | Error 0.0091(0.0108) Steps 434(442.34) | Grad Norm 1.3809(0.6930) | Total Time 10.00(10.00)\n",
      "Iter 4466 | Time 32.2602(31.4150) | Bit/dim 1.1022(1.1006) | Xent 0.0416(0.0353) | Loss 1.1230(1.1183) | Error 0.0132(0.0108) Steps 446(442.45) | Grad Norm 1.3549(0.7129) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0638 | Time 17.0907, Epoch Time 250.5523(247.0670), Bit/dim 1.0950(best: 1.0942), Xent 0.0283, Loss 1.1091, Error 0.0093(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4467 | Time 31.0923(31.4054) | Bit/dim 1.1011(1.1007) | Xent 0.0347(0.0353) | Loss 1.1185(1.1183) | Error 0.0098(0.0108) Steps 446(442.56) | Grad Norm 0.2169(0.6980) | Total Time 10.00(10.00)\n",
      "Iter 4468 | Time 32.7580(31.4459) | Bit/dim 1.1002(1.1006) | Xent 0.0415(0.0354) | Loss 1.1210(1.1184) | Error 0.0128(0.0109) Steps 434(442.30) | Grad Norm 1.4101(0.7194) | Total Time 10.00(10.00)\n",
      "Iter 4469 | Time 30.8467(31.4280) | Bit/dim 1.0993(1.1006) | Xent 0.0325(0.0353) | Loss 1.1155(1.1183) | Error 0.0099(0.0108) Steps 452(442.59) | Grad Norm 1.3264(0.7376) | Total Time 10.00(10.00)\n",
      "Iter 4470 | Time 31.3491(31.4256) | Bit/dim 1.1004(1.1006) | Xent 0.0370(0.0354) | Loss 1.1190(1.1183) | Error 0.0108(0.0108) Steps 446(442.70) | Grad Norm 0.3325(0.7254) | Total Time 10.00(10.00)\n",
      "Iter 4471 | Time 30.6961(31.4037) | Bit/dim 1.1044(1.1007) | Xent 0.0326(0.0353) | Loss 1.1208(1.1184) | Error 0.0101(0.0108) Steps 434(442.43) | Grad Norm 1.2540(0.7413) | Total Time 10.00(10.00)\n",
      "Iter 4472 | Time 31.6390(31.4108) | Bit/dim 1.1027(1.1008) | Xent 0.0373(0.0354) | Loss 1.1214(1.1185) | Error 0.0108(0.0108) Steps 446(442.54) | Grad Norm 0.9847(0.7486) | Total Time 10.00(10.00)\n",
      "Iter 4473 | Time 31.2701(31.4065) | Bit/dim 1.0993(1.1007) | Xent 0.0355(0.0354) | Loss 1.1170(1.1184) | Error 0.0126(0.0109) Steps 434(442.29) | Grad Norm 0.7331(0.7481) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0639 | Time 17.0999, Epoch Time 249.2583(247.1328), Bit/dim 1.0954(best: 1.0942), Xent 0.0266, Loss 1.1087, Error 0.0085(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4474 | Time 31.2510(31.4019) | Bit/dim 1.1003(1.1007) | Xent 0.0372(0.0354) | Loss 1.1189(1.1184) | Error 0.0109(0.0109) Steps 446(442.40) | Grad Norm 2.1374(0.7898) | Total Time 10.00(10.00)\n",
      "Iter 4475 | Time 31.4949(31.4047) | Bit/dim 1.0980(1.1006) | Xent 0.0433(0.0357) | Loss 1.1197(1.1185) | Error 0.0128(0.0109) Steps 446(442.51) | Grad Norm 1.7763(0.8194) | Total Time 10.00(10.00)\n",
      "Iter 4476 | Time 31.3691(31.4036) | Bit/dim 1.1026(1.1007) | Xent 0.0263(0.0354) | Loss 1.1157(1.1184) | Error 0.0080(0.0108) Steps 446(442.61) | Grad Norm 0.2653(0.8028) | Total Time 10.00(10.00)\n",
      "Iter 4477 | Time 31.1803(31.3969) | Bit/dim 1.1019(1.1007) | Xent 0.0348(0.0354) | Loss 1.1193(1.1184) | Error 0.0108(0.0108) Steps 446(442.71) | Grad Norm 1.1742(0.8139) | Total Time 10.00(10.00)\n",
      "Iter 4478 | Time 30.5289(31.3709) | Bit/dim 1.0962(1.1006) | Xent 0.0316(0.0353) | Loss 1.1120(1.1182) | Error 0.0105(0.0108) Steps 434(442.45) | Grad Norm 0.7139(0.8109) | Total Time 10.00(10.00)\n",
      "Iter 4479 | Time 30.9403(31.3579) | Bit/dim 1.1037(1.1007) | Xent 0.0365(0.0353) | Loss 1.1220(1.1183) | Error 0.0104(0.0108) Steps 434(442.20) | Grad Norm 0.5851(0.8041) | Total Time 10.00(10.00)\n",
      "Iter 4480 | Time 31.3663(31.3582) | Bit/dim 1.1009(1.1007) | Xent 0.0306(0.0352) | Loss 1.1162(1.1183) | Error 0.0088(0.0108) Steps 446(442.31) | Grad Norm 1.1028(0.8131) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0640 | Time 17.1589, Epoch Time 247.7903(247.1525), Bit/dim 1.0947(best: 1.0942), Xent 0.0274, Loss 1.1085, Error 0.0092(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4481 | Time 31.1318(31.3514) | Bit/dim 1.1003(1.1007) | Xent 0.0346(0.0351) | Loss 1.1176(1.1182) | Error 0.0111(0.0108) Steps 434(442.06) | Grad Norm 0.6730(0.8089) | Total Time 10.00(10.00)\n",
      "Iter 4482 | Time 31.5018(31.3559) | Bit/dim 1.1041(1.1008) | Xent 0.0344(0.0351) | Loss 1.1213(1.1183) | Error 0.0104(0.0108) Steps 446(442.18) | Grad Norm 0.8042(0.8087) | Total Time 10.00(10.00)\n",
      "Iter 4483 | Time 31.1704(31.3504) | Bit/dim 1.0965(1.1007) | Xent 0.0366(0.0352) | Loss 1.1148(1.1182) | Error 0.0101(0.0107) Steps 434(441.93) | Grad Norm 1.3846(0.8260) | Total Time 10.00(10.00)\n",
      "Iter 4484 | Time 32.3635(31.3807) | Bit/dim 1.1008(1.1007) | Xent 0.0343(0.0351) | Loss 1.1180(1.1182) | Error 0.0102(0.0107) Steps 452(442.24) | Grad Norm 0.3159(0.8107) | Total Time 10.00(10.00)\n",
      "Iter 4485 | Time 31.4462(31.3827) | Bit/dim 1.1008(1.1007) | Xent 0.0298(0.0350) | Loss 1.1156(1.1181) | Error 0.0091(0.0107) Steps 446(442.35) | Grad Norm 2.2663(0.8544) | Total Time 10.00(10.00)\n",
      "Iter 4486 | Time 32.4877(31.4159) | Bit/dim 1.1038(1.1008) | Xent 0.0334(0.0349) | Loss 1.1205(1.1182) | Error 0.0102(0.0107) Steps 434(442.10) | Grad Norm 1.8393(0.8839) | Total Time 10.00(10.00)\n",
      "Iter 4487 | Time 30.9552(31.4020) | Bit/dim 1.0964(1.1006) | Xent 0.0316(0.0348) | Loss 1.1122(1.1180) | Error 0.0092(0.0106) Steps 452(442.40) | Grad Norm 0.6067(0.8756) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0641 | Time 17.2172, Epoch Time 250.6492(247.2574), Bit/dim 1.0946(best: 1.0942), Xent 0.0299, Loss 1.1095, Error 0.0094(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4488 | Time 32.2906(31.4287) | Bit/dim 1.1008(1.1006) | Xent 0.0407(0.0350) | Loss 1.1211(1.1181) | Error 0.0119(0.0107) Steps 434(442.14) | Grad Norm 1.7595(0.9021) | Total Time 10.00(10.00)\n",
      "Iter 4489 | Time 31.5271(31.4316) | Bit/dim 1.1035(1.1007) | Xent 0.0338(0.0350) | Loss 1.1204(1.1182) | Error 0.0108(0.0107) Steps 434(441.90) | Grad Norm 1.0650(0.9070) | Total Time 10.00(10.00)\n",
      "Iter 4490 | Time 31.4044(31.4308) | Bit/dim 1.1018(1.1007) | Xent 0.0415(0.0352) | Loss 1.1226(1.1183) | Error 0.0135(0.0107) Steps 446(442.02) | Grad Norm 0.6067(0.8980) | Total Time 10.00(10.00)\n",
      "Iter 4491 | Time 31.3889(31.4296) | Bit/dim 1.1023(1.1008) | Xent 0.0333(0.0351) | Loss 1.1190(1.1183) | Error 0.0105(0.0107) Steps 452(442.32) | Grad Norm 1.4147(0.9135) | Total Time 10.00(10.00)\n",
      "Iter 4492 | Time 32.6442(31.4660) | Bit/dim 1.1012(1.1008) | Xent 0.0365(0.0351) | Loss 1.1194(1.1184) | Error 0.0114(0.0108) Steps 446(442.43) | Grad Norm 0.8219(0.9108) | Total Time 10.00(10.00)\n",
      "Iter 4493 | Time 32.0297(31.4829) | Bit/dim 1.0991(1.1008) | Xent 0.0303(0.0350) | Loss 1.1143(1.1183) | Error 0.0109(0.0108) Steps 434(442.18) | Grad Norm 0.7063(0.9046) | Total Time 10.00(10.00)\n",
      "Iter 4494 | Time 32.6042(31.5166) | Bit/dim 1.0952(1.1006) | Xent 0.0365(0.0350) | Loss 1.1135(1.1181) | Error 0.0118(0.0108) Steps 446(442.29) | Grad Norm 1.1965(0.9134) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0642 | Time 16.7227, Epoch Time 253.0869(247.4323), Bit/dim 1.0946(best: 1.0942), Xent 0.0261, Loss 1.1077, Error 0.0097(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4495 | Time 32.3742(31.5423) | Bit/dim 1.1055(1.1007) | Xent 0.0321(0.0350) | Loss 1.1215(1.1182) | Error 0.0099(0.0108) Steps 434(442.05) | Grad Norm 0.5830(0.9035) | Total Time 10.00(10.00)\n",
      "Iter 4496 | Time 32.3559(31.5667) | Bit/dim 1.1016(1.1008) | Xent 0.0313(0.0348) | Loss 1.1172(1.1182) | Error 0.0109(0.0108) Steps 434(441.80) | Grad Norm 0.3456(0.8867) | Total Time 10.00(10.00)\n",
      "Iter 4497 | Time 31.1953(31.5556) | Bit/dim 1.0951(1.1006) | Xent 0.0343(0.0348) | Loss 1.1123(1.1180) | Error 0.0118(0.0108) Steps 446(441.93) | Grad Norm 0.7988(0.8841) | Total Time 10.00(10.00)\n",
      "Iter 4498 | Time 31.9686(31.5679) | Bit/dim 1.1056(1.1007) | Xent 0.0362(0.0349) | Loss 1.1237(1.1182) | Error 0.0115(0.0108) Steps 446(442.05) | Grad Norm 1.2463(0.8950) | Total Time 10.00(10.00)\n",
      "Iter 4499 | Time 32.4517(31.5945) | Bit/dim 1.0962(1.1006) | Xent 0.0348(0.0349) | Loss 1.1136(1.1180) | Error 0.0122(0.0109) Steps 446(442.17) | Grad Norm 0.3950(0.8800) | Total Time 10.00(10.00)\n",
      "Iter 4500 | Time 31.7714(31.5998) | Bit/dim 1.1033(1.1007) | Xent 0.0391(0.0350) | Loss 1.1228(1.1182) | Error 0.0126(0.0109) Steps 446(442.29) | Grad Norm 1.0523(0.8851) | Total Time 10.00(10.00)\n",
      "Iter 4501 | Time 31.2472(31.5892) | Bit/dim 1.1005(1.1007) | Xent 0.0390(0.0351) | Loss 1.1200(1.1182) | Error 0.0110(0.0109) Steps 434(442.04) | Grad Norm 0.9570(0.8873) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0643 | Time 16.9104, Epoch Time 252.6405(247.5885), Bit/dim 1.0952(best: 1.0942), Xent 0.0283, Loss 1.1093, Error 0.0100(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4502 | Time 33.4411(31.6448) | Bit/dim 1.1012(1.1007) | Xent 0.0309(0.0350) | Loss 1.1167(1.1182) | Error 0.0104(0.0109) Steps 446(442.16) | Grad Norm 0.2926(0.8694) | Total Time 10.00(10.00)\n",
      "Iter 4503 | Time 31.5038(31.6405) | Bit/dim 1.1016(1.1007) | Xent 0.0380(0.0351) | Loss 1.1206(1.1183) | Error 0.0111(0.0109) Steps 446(442.27) | Grad Norm 0.3406(0.8536) | Total Time 10.00(10.00)\n",
      "Iter 4504 | Time 31.6488(31.6408) | Bit/dim 1.0997(1.1007) | Xent 0.0356(0.0351) | Loss 1.1175(1.1182) | Error 0.0115(0.0109) Steps 446(442.38) | Grad Norm 1.0812(0.8604) | Total Time 10.00(10.00)\n",
      "Iter 4505 | Time 31.5425(31.6378) | Bit/dim 1.0988(1.1006) | Xent 0.0293(0.0349) | Loss 1.1135(1.1181) | Error 0.0101(0.0109) Steps 446(442.49) | Grad Norm 1.0434(0.8659) | Total Time 10.00(10.00)\n",
      "Iter 4506 | Time 31.6871(31.6393) | Bit/dim 1.0985(1.1006) | Xent 0.0335(0.0349) | Loss 1.1152(1.1180) | Error 0.0094(0.0109) Steps 434(442.24) | Grad Norm 0.5739(0.8571) | Total Time 10.00(10.00)\n",
      "Iter 4507 | Time 32.5207(31.6657) | Bit/dim 1.1001(1.1006) | Xent 0.0391(0.0350) | Loss 1.1197(1.1181) | Error 0.0116(0.0109) Steps 446(442.35) | Grad Norm 1.4792(0.8758) | Total Time 10.00(10.00)\n",
      "Iter 4508 | Time 32.8673(31.7018) | Bit/dim 1.1003(1.1005) | Xent 0.0330(0.0349) | Loss 1.1168(1.1180) | Error 0.0108(0.0109) Steps 446(442.46) | Grad Norm 0.8812(0.8760) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0644 | Time 17.0561, Epoch Time 254.8549(247.8065), Bit/dim 1.0944(best: 1.0942), Xent 0.0259, Loss 1.1073, Error 0.0095(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4509 | Time 32.3978(31.7227) | Bit/dim 1.1036(1.1006) | Xent 0.0349(0.0349) | Loss 1.1211(1.1181) | Error 0.0120(0.0109) Steps 446(442.57) | Grad Norm 0.2232(0.8564) | Total Time 10.00(10.00)\n",
      "Iter 4510 | Time 32.5528(31.7476) | Bit/dim 1.1017(1.1007) | Xent 0.0388(0.0351) | Loss 1.1211(1.1182) | Error 0.0116(0.0109) Steps 446(442.67) | Grad Norm 0.3756(0.8420) | Total Time 10.00(10.00)\n",
      "Iter 4511 | Time 32.1483(31.7596) | Bit/dim 1.0957(1.1005) | Xent 0.0335(0.0350) | Loss 1.1125(1.1180) | Error 0.0111(0.0109) Steps 434(442.41) | Grad Norm 0.3067(0.8259) | Total Time 10.00(10.00)\n",
      "Iter 4512 | Time 30.8579(31.7326) | Bit/dim 1.1026(1.1006) | Xent 0.0386(0.0351) | Loss 1.1219(1.1182) | Error 0.0116(0.0110) Steps 434(442.16) | Grad Norm 0.3977(0.8131) | Total Time 10.00(10.00)\n",
      "Iter 4513 | Time 31.5459(31.7270) | Bit/dim 1.0983(1.1005) | Xent 0.0358(0.0351) | Loss 1.1162(1.1181) | Error 0.0112(0.0110) Steps 446(442.27) | Grad Norm 0.6857(0.8092) | Total Time 10.00(10.00)\n",
      "Iter 4514 | Time 31.6747(31.7254) | Bit/dim 1.1014(1.1005) | Xent 0.0342(0.0351) | Loss 1.1185(1.1181) | Error 0.0096(0.0109) Steps 434(442.02) | Grad Norm 1.6107(0.8333) | Total Time 10.00(10.00)\n",
      "Iter 4515 | Time 31.3417(31.7139) | Bit/dim 1.1026(1.1006) | Xent 0.0305(0.0350) | Loss 1.1178(1.1181) | Error 0.0104(0.0109) Steps 446(442.14) | Grad Norm 1.0863(0.8409) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0645 | Time 17.0328, Epoch Time 252.0522(247.9339), Bit/dim 1.0950(best: 1.0942), Xent 0.0273, Loss 1.1086, Error 0.0089(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4516 | Time 31.5532(31.7091) | Bit/dim 1.1003(1.1006) | Xent 0.0314(0.0349) | Loss 1.1159(1.1180) | Error 0.0108(0.0109) Steps 434(441.90) | Grad Norm 0.6374(0.8348) | Total Time 10.00(10.00)\n",
      "Iter 4517 | Time 31.2842(31.6963) | Bit/dim 1.0959(1.1005) | Xent 0.0388(0.0350) | Loss 1.1154(1.1180) | Error 0.0126(0.0110) Steps 434(441.66) | Grad Norm 0.7957(0.8336) | Total Time 10.00(10.00)\n",
      "Iter 4518 | Time 31.3976(31.6873) | Bit/dim 1.1019(1.1005) | Xent 0.0300(0.0348) | Loss 1.1169(1.1179) | Error 0.0098(0.0109) Steps 434(441.43) | Grad Norm 0.7280(0.8304) | Total Time 10.00(10.00)\n",
      "Iter 4519 | Time 31.5916(31.6845) | Bit/dim 1.1006(1.1005) | Xent 0.0307(0.0347) | Loss 1.1160(1.1179) | Error 0.0094(0.0109) Steps 446(441.57) | Grad Norm 1.2041(0.8416) | Total Time 10.00(10.00)\n",
      "Iter 4520 | Time 31.9167(31.6914) | Bit/dim 1.0995(1.1005) | Xent 0.0326(0.0346) | Loss 1.1158(1.1178) | Error 0.0104(0.0109) Steps 446(441.70) | Grad Norm 0.3028(0.8255) | Total Time 10.00(10.00)\n",
      "Iter 4521 | Time 31.5225(31.6864) | Bit/dim 1.1022(1.1005) | Xent 0.0377(0.0347) | Loss 1.1211(1.1179) | Error 0.0114(0.0109) Steps 446(441.83) | Grad Norm 1.2954(0.8396) | Total Time 10.00(10.00)\n",
      "Iter 4522 | Time 33.3458(31.7362) | Bit/dim 1.0997(1.1005) | Xent 0.0438(0.0350) | Loss 1.1216(1.1180) | Error 0.0140(0.0110) Steps 446(441.96) | Grad Norm 0.8551(0.8400) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0646 | Time 17.0368, Epoch Time 252.1497(248.0604), Bit/dim 1.0952(best: 1.0942), Xent 0.0248, Loss 1.1076, Error 0.0082(best: 0.0083)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4523 | Time 32.3649(31.7550) | Bit/dim 1.1014(1.1005) | Xent 0.0379(0.0351) | Loss 1.1203(1.1181) | Error 0.0120(0.0110) Steps 446(442.08) | Grad Norm 0.6922(0.8356) | Total Time 10.00(10.00)\n",
      "Iter 4524 | Time 31.2833(31.7409) | Bit/dim 1.1029(1.1006) | Xent 0.0317(0.0350) | Loss 1.1188(1.1181) | Error 0.0114(0.0110) Steps 434(441.83) | Grad Norm 1.3393(0.8507) | Total Time 10.00(10.00)\n",
      "Iter 4525 | Time 31.1593(31.7234) | Bit/dim 1.0990(1.1006) | Xent 0.0381(0.0351) | Loss 1.1180(1.1181) | Error 0.0120(0.0110) Steps 446(441.96) | Grad Norm 0.3825(0.8367) | Total Time 10.00(10.00)\n",
      "Iter 4526 | Time 31.6169(31.7202) | Bit/dim 1.0954(1.1004) | Xent 0.0318(0.0350) | Loss 1.1113(1.1179) | Error 0.0101(0.0110) Steps 446(442.08) | Grad Norm 0.8114(0.8359) | Total Time 10.00(10.00)\n",
      "Iter 4527 | Time 31.5788(31.7160) | Bit/dim 1.0999(1.1004) | Xent 0.0378(0.0351) | Loss 1.1188(1.1179) | Error 0.0121(0.0110) Steps 446(442.20) | Grad Norm 0.2341(0.8179) | Total Time 10.00(10.00)\n",
      "Iter 4528 | Time 31.0635(31.6964) | Bit/dim 1.0981(1.1003) | Xent 0.0317(0.0350) | Loss 1.1139(1.1178) | Error 0.0104(0.0110) Steps 446(442.31) | Grad Norm 0.6821(0.8138) | Total Time 10.00(10.00)\n",
      "Iter 4529 | Time 32.9945(31.7353) | Bit/dim 1.1040(1.1004) | Xent 0.0351(0.0350) | Loss 1.1216(1.1179) | Error 0.0109(0.0110) Steps 446(442.42) | Grad Norm 0.4592(0.8031) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0647 | Time 17.2402, Epoch Time 251.6898(248.1693), Bit/dim 1.0945(best: 1.0942), Xent 0.0279, Loss 1.1084, Error 0.0105(best: 0.0082)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4530 | Time 32.6787(31.7636) | Bit/dim 1.0969(1.1003) | Xent 0.0326(0.0349) | Loss 1.1132(1.1178) | Error 0.0114(0.0110) Steps 446(442.53) | Grad Norm 0.4198(0.7916) | Total Time 10.00(10.00)\n",
      "Iter 4531 | Time 31.2649(31.7487) | Bit/dim 1.1004(1.1003) | Xent 0.0257(0.0346) | Loss 1.1133(1.1176) | Error 0.0080(0.0109) Steps 446(442.63) | Grad Norm 0.6571(0.7876) | Total Time 10.00(10.00)\n",
      "Iter 4532 | Time 31.3922(31.7380) | Bit/dim 1.1029(1.1004) | Xent 0.0322(0.0346) | Loss 1.1190(1.1177) | Error 0.0096(0.0109) Steps 452(442.92) | Grad Norm 0.8497(0.7895) | Total Time 10.00(10.00)\n",
      "Iter 4533 | Time 32.5665(31.7628) | Bit/dim 1.1031(1.1005) | Xent 0.0355(0.0346) | Loss 1.1208(1.1178) | Error 0.0110(0.0109) Steps 446(443.01) | Grad Norm 1.1773(0.8011) | Total Time 10.00(10.00)\n",
      "Iter 4534 | Time 31.5940(31.7578) | Bit/dim 1.0969(1.1004) | Xent 0.0329(0.0345) | Loss 1.1134(1.1176) | Error 0.0109(0.0109) Steps 452(443.28) | Grad Norm 1.1305(0.8110) | Total Time 10.00(10.00)\n",
      "Iter 4535 | Time 31.3620(31.7459) | Bit/dim 1.1008(1.1004) | Xent 0.0432(0.0348) | Loss 1.1224(1.1178) | Error 0.0110(0.0109) Steps 446(443.36) | Grad Norm 0.4855(0.8012) | Total Time 10.00(10.00)\n",
      "Iter 4536 | Time 31.4543(31.7372) | Bit/dim 1.0982(1.1003) | Xent 0.0329(0.0347) | Loss 1.1147(1.1177) | Error 0.0090(0.0108) Steps 446(443.44) | Grad Norm 0.4150(0.7896) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0648 | Time 17.1012, Epoch Time 252.0502(248.2857), Bit/dim 1.0946(best: 1.0942), Xent 0.0304, Loss 1.1098, Error 0.0096(best: 0.0082)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4537 | Time 31.3523(31.7256) | Bit/dim 1.1016(1.1004) | Xent 0.0347(0.0347) | Loss 1.1189(1.1177) | Error 0.0110(0.0109) Steps 446(443.52) | Grad Norm 0.4061(0.7781) | Total Time 10.00(10.00)\n",
      "Iter 4538 | Time 31.3581(31.7146) | Bit/dim 1.1011(1.1004) | Xent 0.0391(0.0349) | Loss 1.1206(1.1178) | Error 0.0121(0.0109) Steps 446(443.59) | Grad Norm 0.3505(0.7653) | Total Time 10.00(10.00)\n",
      "Iter 4539 | Time 32.7674(31.7462) | Bit/dim 1.1008(1.1004) | Xent 0.0352(0.0349) | Loss 1.1184(1.1178) | Error 0.0108(0.0109) Steps 446(443.66) | Grad Norm 0.2548(0.7500) | Total Time 10.00(10.00)\n",
      "Iter 4540 | Time 31.4517(31.7373) | Bit/dim 1.1000(1.1004) | Xent 0.0329(0.0348) | Loss 1.1164(1.1178) | Error 0.0098(0.0109) Steps 446(443.73) | Grad Norm 0.4001(0.7395) | Total Time 10.00(10.00)\n",
      "Iter 4541 | Time 31.2329(31.7222) | Bit/dim 1.0970(1.1003) | Xent 0.0386(0.0349) | Loss 1.1163(1.1177) | Error 0.0118(0.0109) Steps 440(443.62) | Grad Norm 0.5017(0.7324) | Total Time 10.00(10.00)\n",
      "Iter 4542 | Time 32.2111(31.7369) | Bit/dim 1.1002(1.1003) | Xent 0.0338(0.0349) | Loss 1.1170(1.1177) | Error 0.0100(0.0109) Steps 446(443.69) | Grad Norm 0.2492(0.7179) | Total Time 10.00(10.00)\n",
      "Iter 4543 | Time 31.2350(31.7218) | Bit/dim 1.1010(1.1003) | Xent 0.0337(0.0349) | Loss 1.1178(1.1177) | Error 0.0110(0.0109) Steps 446(443.76) | Grad Norm 0.3382(0.7065) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0649 | Time 17.0051, Epoch Time 251.1845(248.3726), Bit/dim 1.0942(best: 1.0942), Xent 0.0297, Loss 1.1090, Error 0.0101(best: 0.0082)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4544 | Time 32.3496(31.7407) | Bit/dim 1.1013(1.1003) | Xent 0.0388(0.0350) | Loss 1.1207(1.1178) | Error 0.0134(0.0109) Steps 446(443.83) | Grad Norm 0.3327(0.6953) | Total Time 10.00(10.00)\n",
      "Iter 4545 | Time 32.5401(31.7646) | Bit/dim 1.0964(1.1002) | Xent 0.0374(0.0351) | Loss 1.1151(1.1177) | Error 0.0112(0.0109) Steps 446(443.89) | Grad Norm 0.4013(0.6864) | Total Time 10.00(10.00)\n",
      "Iter 4546 | Time 30.7519(31.7343) | Bit/dim 1.0986(1.1002) | Xent 0.0330(0.0350) | Loss 1.1151(1.1177) | Error 0.0105(0.0109) Steps 446(443.96) | Grad Norm 0.4596(0.6796) | Total Time 10.00(10.00)\n",
      "Iter 4547 | Time 31.5251(31.7280) | Bit/dim 1.0978(1.1001) | Xent 0.0347(0.0350) | Loss 1.1151(1.1176) | Error 0.0112(0.0109) Steps 446(444.02) | Grad Norm 0.5609(0.6761) | Total Time 10.00(10.00)\n",
      "Iter 4548 | Time 31.3357(31.7162) | Bit/dim 1.1017(1.1001) | Xent 0.0317(0.0349) | Loss 1.1176(1.1176) | Error 0.0095(0.0109) Steps 446(444.08) | Grad Norm 0.3120(0.6651) | Total Time 10.00(10.00)\n",
      "Iter 4549 | Time 31.2780(31.7031) | Bit/dim 1.1023(1.1002) | Xent 0.0266(0.0346) | Loss 1.1156(1.1175) | Error 0.0082(0.0108) Steps 446(444.13) | Grad Norm 0.3265(0.6550) | Total Time 10.00(10.00)\n",
      "Iter 4550 | Time 31.8982(31.7089) | Bit/dim 1.1021(1.1003) | Xent 0.0320(0.0346) | Loss 1.1181(1.1175) | Error 0.0119(0.0108) Steps 446(444.19) | Grad Norm 0.7118(0.6567) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0650 | Time 17.2409, Epoch Time 251.3204(248.4611), Bit/dim 1.0946(best: 1.0942), Xent 0.0241, Loss 1.1067, Error 0.0076(best: 0.0082)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4551 | Time 31.2635(31.6956) | Bit/dim 1.1022(1.1003) | Xent 0.0313(0.0345) | Loss 1.1178(1.1175) | Error 0.0099(0.0108) Steps 446(444.25) | Grad Norm 0.5382(0.6531) | Total Time 10.00(10.00)\n",
      "Iter 4552 | Time 31.3968(31.6866) | Bit/dim 1.0965(1.1002) | Xent 0.0272(0.0342) | Loss 1.1101(1.1173) | Error 0.0088(0.0108) Steps 446(444.30) | Grad Norm 0.8413(0.6588) | Total Time 10.00(10.00)\n",
      "Iter 4553 | Time 31.7690(31.6891) | Bit/dim 1.1000(1.1002) | Xent 0.0338(0.0342) | Loss 1.1169(1.1173) | Error 0.0116(0.0108) Steps 446(444.35) | Grad Norm 1.4855(0.6836) | Total Time 10.00(10.00)\n",
      "Iter 4554 | Time 30.9768(31.6677) | Bit/dim 1.0960(1.1001) | Xent 0.0279(0.0340) | Loss 1.1099(1.1171) | Error 0.0096(0.0107) Steps 452(444.58) | Grad Norm 0.4817(0.6775) | Total Time 10.00(10.00)\n",
      "Iter 4555 | Time 31.5749(31.6649) | Bit/dim 1.0987(1.1000) | Xent 0.0391(0.0342) | Loss 1.1183(1.1171) | Error 0.0116(0.0108) Steps 434(444.26) | Grad Norm 1.4361(0.7003) | Total Time 10.00(10.00)\n",
      "Iter 4556 | Time 31.3334(31.6550) | Bit/dim 1.1014(1.1001) | Xent 0.0392(0.0343) | Loss 1.1210(1.1172) | Error 0.0120(0.0108) Steps 446(444.31) | Grad Norm 1.8172(0.7338) | Total Time 10.00(10.00)\n",
      "Iter 4557 | Time 31.4488(31.6488) | Bit/dim 1.0990(1.1000) | Xent 0.0365(0.0344) | Loss 1.1173(1.1172) | Error 0.0098(0.0108) Steps 434(444.00) | Grad Norm 0.3134(0.7212) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0651 | Time 16.9743, Epoch Time 249.2067(248.4834), Bit/dim 1.0945(best: 1.0942), Xent 0.0273, Loss 1.1082, Error 0.0092(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4558 | Time 31.5790(31.6467) | Bit/dim 1.1008(1.1001) | Xent 0.0385(0.0345) | Loss 1.1201(1.1173) | Error 0.0109(0.0108) Steps 446(444.06) | Grad Norm 2.6665(0.7795) | Total Time 10.00(10.00)\n",
      "Iter 4559 | Time 31.4599(31.6411) | Bit/dim 1.0961(1.0999) | Xent 0.0298(0.0344) | Loss 1.1110(1.1171) | Error 0.0099(0.0108) Steps 446(444.12) | Grad Norm 2.4393(0.8293) | Total Time 10.00(10.00)\n",
      "Iter 4560 | Time 31.7073(31.6431) | Bit/dim 1.1038(1.1001) | Xent 0.0294(0.0342) | Loss 1.1185(1.1172) | Error 0.0086(0.0107) Steps 446(444.18) | Grad Norm 1.0790(0.8368) | Total Time 10.00(10.00)\n",
      "Iter 4561 | Time 31.5766(31.6411) | Bit/dim 1.0997(1.1000) | Xent 0.0321(0.0342) | Loss 1.1157(1.1171) | Error 0.0109(0.0107) Steps 446(444.23) | Grad Norm 4.2891(0.9404) | Total Time 10.00(10.00)\n",
      "Iter 4562 | Time 31.8147(31.6463) | Bit/dim 1.0984(1.1000) | Xent 0.0300(0.0341) | Loss 1.1134(1.1170) | Error 0.0109(0.0107) Steps 446(444.29) | Grad Norm 3.1273(1.0060) | Total Time 10.00(10.00)\n",
      "Iter 4563 | Time 31.0089(31.6272) | Bit/dim 1.1003(1.1000) | Xent 0.0412(0.0343) | Loss 1.1209(1.1171) | Error 0.0131(0.0108) Steps 446(444.34) | Grad Norm 1.7143(1.0273) | Total Time 10.00(10.00)\n",
      "Iter 4564 | Time 31.0639(31.6103) | Bit/dim 1.1025(1.1001) | Xent 0.0333(0.0342) | Loss 1.1191(1.1172) | Error 0.0106(0.0108) Steps 446(444.39) | Grad Norm 4.5417(1.1327) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0652 | Time 16.6613, Epoch Time 249.4065(248.5111), Bit/dim 1.0944(best: 1.0942), Xent 0.0303, Loss 1.1095, Error 0.0096(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4565 | Time 31.3825(31.6034) | Bit/dim 1.1058(1.1003) | Xent 0.0325(0.0342) | Loss 1.1221(1.1173) | Error 0.0105(0.0108) Steps 446(444.44) | Grad Norm 2.0576(1.1604) | Total Time 10.00(10.00)\n",
      "Iter 4566 | Time 31.5371(31.6015) | Bit/dim 1.1017(1.1003) | Xent 0.0310(0.0341) | Loss 1.1172(1.1173) | Error 0.0094(0.0107) Steps 446(444.48) | Grad Norm 2.7905(1.2093) | Total Time 10.00(10.00)\n",
      "Iter 4567 | Time 31.3683(31.5945) | Bit/dim 1.1018(1.1003) | Xent 0.0364(0.0342) | Loss 1.1199(1.1174) | Error 0.0112(0.0107) Steps 446(444.53) | Grad Norm 4.6389(1.3122) | Total Time 10.00(10.00)\n",
      "Iter 4568 | Time 31.2867(31.5852) | Bit/dim 1.0985(1.1003) | Xent 0.0315(0.0341) | Loss 1.1142(1.1173) | Error 0.0092(0.0107) Steps 446(444.57) | Grad Norm 1.7856(1.3264) | Total Time 10.00(10.00)\n",
      "Iter 4569 | Time 31.7912(31.5914) | Bit/dim 1.1007(1.1003) | Xent 0.0368(0.0342) | Loss 1.1191(1.1174) | Error 0.0121(0.0107) Steps 452(444.79) | Grad Norm 2.5258(1.3624) | Total Time 10.00(10.00)\n",
      "Iter 4570 | Time 31.6129(31.5920) | Bit/dim 1.0958(1.1002) | Xent 0.0329(0.0341) | Loss 1.1122(1.1172) | Error 0.0110(0.0107) Steps 446(444.83) | Grad Norm 3.5559(1.4282) | Total Time 10.00(10.00)\n",
      "Iter 4571 | Time 31.3143(31.5837) | Bit/dim 1.0975(1.1001) | Xent 0.0381(0.0342) | Loss 1.1165(1.1172) | Error 0.0106(0.0107) Steps 446(444.87) | Grad Norm 0.9768(1.4147) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0653 | Time 17.0103, Epoch Time 250.1229(248.5595), Bit/dim 1.0946(best: 1.0942), Xent 0.0273, Loss 1.1083, Error 0.0096(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4572 | Time 31.3560(31.5769) | Bit/dim 1.0995(1.1001) | Xent 0.0453(0.0346) | Loss 1.1222(1.1174) | Error 0.0121(0.0108) Steps 446(444.90) | Grad Norm 1.8595(1.4280) | Total Time 10.00(10.00)\n",
      "Iter 4573 | Time 31.9415(31.5878) | Bit/dim 1.0956(1.0999) | Xent 0.0325(0.0345) | Loss 1.1118(1.1172) | Error 0.0106(0.0108) Steps 446(444.93) | Grad Norm 2.4648(1.4591) | Total Time 10.00(10.00)\n",
      "Iter 4574 | Time 32.6335(31.6192) | Bit/dim 1.1001(1.0999) | Xent 0.0336(0.0345) | Loss 1.1169(1.1172) | Error 0.0095(0.0107) Steps 446(444.97) | Grad Norm 0.6159(1.4338) | Total Time 10.00(10.00)\n",
      "Iter 4575 | Time 30.6273(31.5894) | Bit/dim 1.1007(1.1000) | Xent 0.0320(0.0344) | Loss 1.1167(1.1172) | Error 0.0094(0.0107) Steps 446(445.00) | Grad Norm 2.2144(1.4572) | Total Time 10.00(10.00)\n",
      "Iter 4576 | Time 31.4124(31.5841) | Bit/dim 1.1013(1.1000) | Xent 0.0306(0.0343) | Loss 1.1166(1.1171) | Error 0.0099(0.0107) Steps 446(445.03) | Grad Norm 2.9716(1.5027) | Total Time 10.00(10.00)\n",
      "Iter 4577 | Time 31.1540(31.5712) | Bit/dim 1.1033(1.1001) | Xent 0.0283(0.0341) | Loss 1.1174(1.1172) | Error 0.0091(0.0106) Steps 446(445.06) | Grad Norm 1.1197(1.4912) | Total Time 10.00(10.00)\n",
      "Iter 4578 | Time 31.5035(31.5692) | Bit/dim 1.0969(1.1000) | Xent 0.0309(0.0340) | Loss 1.1124(1.1170) | Error 0.0101(0.0106) Steps 446(445.08) | Grad Norm 1.3942(1.4883) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0654 | Time 17.1902, Epoch Time 250.1471(248.6071), Bit/dim 1.0944(best: 1.0942), Xent 0.0282, Loss 1.1085, Error 0.0095(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4579 | Time 31.3946(31.5640) | Bit/dim 1.1009(1.1000) | Xent 0.0316(0.0339) | Loss 1.1167(1.1170) | Error 0.0102(0.0106) Steps 446(445.11) | Grad Norm 2.2211(1.5103) | Total Time 10.00(10.00)\n",
      "Iter 4580 | Time 31.5915(31.5648) | Bit/dim 1.1024(1.1001) | Xent 0.0347(0.0340) | Loss 1.1198(1.1171) | Error 0.0120(0.0106) Steps 446(445.14) | Grad Norm 1.2040(1.5011) | Total Time 10.00(10.00)\n",
      "Iter 4581 | Time 31.2852(31.5564) | Bit/dim 1.1003(1.1001) | Xent 0.0362(0.0340) | Loss 1.1184(1.1171) | Error 0.0108(0.0106) Steps 452(445.34) | Grad Norm 0.6198(1.4746) | Total Time 10.00(10.00)\n",
      "Iter 4582 | Time 31.3230(31.5494) | Bit/dim 1.1011(1.1001) | Xent 0.0343(0.0340) | Loss 1.1182(1.1172) | Error 0.0102(0.0106) Steps 446(445.36) | Grad Norm 1.4534(1.4740) | Total Time 10.00(10.00)\n",
      "Iter 4583 | Time 31.3724(31.5441) | Bit/dim 1.0950(1.1000) | Xent 0.0345(0.0341) | Loss 1.1123(1.1170) | Error 0.0108(0.0106) Steps 446(445.38) | Grad Norm 1.2314(1.4667) | Total Time 10.00(10.00)\n",
      "Iter 4584 | Time 31.6814(31.5482) | Bit/dim 1.0995(1.1000) | Xent 0.0348(0.0341) | Loss 1.1169(1.1170) | Error 0.0100(0.0106) Steps 446(445.40) | Grad Norm 0.3038(1.4318) | Total Time 10.00(10.00)\n",
      "Iter 4585 | Time 31.4355(31.5448) | Bit/dim 1.0978(1.0999) | Xent 0.0342(0.0341) | Loss 1.1149(1.1169) | Error 0.0098(0.0106) Steps 446(445.42) | Grad Norm 1.0643(1.4208) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0655 | Time 17.2050, Epoch Time 249.6051(248.6371), Bit/dim 1.0945(best: 1.0942), Xent 0.0273, Loss 1.1082, Error 0.0095(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4586 | Time 31.0911(31.5312) | Bit/dim 1.1007(1.0999) | Xent 0.0329(0.0340) | Loss 1.1172(1.1169) | Error 0.0114(0.0106) Steps 446(445.44) | Grad Norm 1.0521(1.4097) | Total Time 10.00(10.00)\n",
      "Iter 4587 | Time 31.2293(31.5221) | Bit/dim 1.1021(1.1000) | Xent 0.0361(0.0341) | Loss 1.1201(1.1170) | Error 0.0116(0.0106) Steps 446(445.45) | Grad Norm 0.4425(1.3807) | Total Time 10.00(10.00)\n",
      "Iter 4588 | Time 31.3018(31.5155) | Bit/dim 1.0968(1.0999) | Xent 0.0414(0.0343) | Loss 1.1175(1.1171) | Error 0.0118(0.0107) Steps 446(445.47) | Grad Norm 1.7497(1.3918) | Total Time 10.00(10.00)\n",
      "Iter 4589 | Time 31.6302(31.5190) | Bit/dim 1.1041(1.1000) | Xent 0.0312(0.0342) | Loss 1.1197(1.1171) | Error 0.0112(0.0107) Steps 446(445.49) | Grad Norm 1.3108(1.3894) | Total Time 10.00(10.00)\n",
      "Iter 4590 | Time 31.2899(31.5121) | Bit/dim 1.0992(1.1000) | Xent 0.0318(0.0342) | Loss 1.1151(1.1171) | Error 0.0095(0.0107) Steps 434(445.14) | Grad Norm 0.5287(1.3635) | Total Time 10.00(10.00)\n",
      "Iter 4591 | Time 31.8229(31.5214) | Bit/dim 1.0981(1.0999) | Xent 0.0341(0.0342) | Loss 1.1151(1.1170) | Error 0.0106(0.0107) Steps 446(445.17) | Grad Norm 1.0784(1.3550) | Total Time 10.00(10.00)\n",
      "Iter 4592 | Time 31.2850(31.5143) | Bit/dim 1.0979(1.0999) | Xent 0.0331(0.0341) | Loss 1.1144(1.1169) | Error 0.0108(0.0107) Steps 446(445.19) | Grad Norm 0.6577(1.3341) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0656 | Time 17.2511, Epoch Time 249.5536(248.6646), Bit/dim 1.0937(best: 1.0942), Xent 0.0275, Loss 1.1075, Error 0.0092(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4593 | Time 31.2038(31.5050) | Bit/dim 1.1024(1.1000) | Xent 0.0291(0.0340) | Loss 1.1170(1.1169) | Error 0.0090(0.0106) Steps 434(444.86) | Grad Norm 0.2836(1.3026) | Total Time 10.00(10.00)\n",
      "Iter 4594 | Time 31.4362(31.5030) | Bit/dim 1.1022(1.1000) | Xent 0.0386(0.0341) | Loss 1.1215(1.1171) | Error 0.0122(0.0107) Steps 446(444.89) | Grad Norm 0.6059(1.2817) | Total Time 10.00(10.00)\n",
      "Iter 4595 | Time 30.9029(31.4850) | Bit/dim 1.0972(1.0999) | Xent 0.0345(0.0341) | Loss 1.1144(1.1170) | Error 0.0112(0.0107) Steps 446(444.92) | Grad Norm 0.8098(1.2675) | Total Time 10.00(10.00)\n",
      "Iter 4596 | Time 31.6067(31.4886) | Bit/dim 1.1063(1.1001) | Xent 0.0366(0.0342) | Loss 1.1246(1.1172) | Error 0.0116(0.0107) Steps 446(444.96) | Grad Norm 0.8308(1.2544) | Total Time 10.00(10.00)\n",
      "Iter 4597 | Time 32.8408(31.5292) | Bit/dim 1.0977(1.1001) | Xent 0.0360(0.0343) | Loss 1.1158(1.1172) | Error 0.0116(0.0107) Steps 446(444.99) | Grad Norm 0.4986(1.2317) | Total Time 10.00(10.00)\n",
      "Iter 4598 | Time 31.5604(31.5301) | Bit/dim 1.0986(1.1000) | Xent 0.0379(0.0344) | Loss 1.1175(1.1172) | Error 0.0118(0.0108) Steps 446(445.02) | Grad Norm 2.2131(1.2612) | Total Time 10.00(10.00)\n",
      "Iter 4599 | Time 31.1749(31.5194) | Bit/dim 1.0952(1.0999) | Xent 0.0308(0.0343) | Loss 1.1106(1.1170) | Error 0.0102(0.0107) Steps 452(445.23) | Grad Norm 1.8496(1.2788) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0657 | Time 17.4704, Epoch Time 250.5804(248.7220), Bit/dim 1.0937(best: 1.0937), Xent 0.0266, Loss 1.1070, Error 0.0093(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4600 | Time 31.3316(31.5138) | Bit/dim 1.1027(1.1000) | Xent 0.0284(0.0341) | Loss 1.1169(1.1170) | Error 0.0090(0.0107) Steps 446(445.25) | Grad Norm 0.5879(1.2581) | Total Time 10.00(10.00)\n",
      "Iter 4601 | Time 32.9351(31.5565) | Bit/dim 1.0983(1.0999) | Xent 0.0374(0.0342) | Loss 1.1170(1.1170) | Error 0.0118(0.0107) Steps 446(445.27) | Grad Norm 1.9612(1.2792) | Total Time 10.00(10.00)\n",
      "Iter 4602 | Time 32.2950(31.5786) | Bit/dim 1.1005(1.0999) | Xent 0.0336(0.0342) | Loss 1.1173(1.1170) | Error 0.0100(0.0107) Steps 446(445.29) | Grad Norm 0.7899(1.2645) | Total Time 10.00(10.00)\n",
      "Iter 4603 | Time 32.1924(31.5970) | Bit/dim 1.1018(1.1000) | Xent 0.0402(0.0343) | Loss 1.1219(1.1172) | Error 0.0120(0.0107) Steps 446(445.32) | Grad Norm 1.5975(1.2745) | Total Time 10.00(10.00)\n",
      "Iter 4604 | Time 31.0700(31.5812) | Bit/dim 1.0984(1.0999) | Xent 0.0326(0.0343) | Loss 1.1147(1.1171) | Error 0.0106(0.0107) Steps 446(445.34) | Grad Norm 2.1534(1.3009) | Total Time 10.00(10.00)\n",
      "Iter 4605 | Time 31.0692(31.5659) | Bit/dim 1.0991(1.0999) | Xent 0.0329(0.0343) | Loss 1.1156(1.1170) | Error 0.0091(0.0107) Steps 446(445.36) | Grad Norm 0.3950(1.2737) | Total Time 10.00(10.00)\n",
      "Iter 4606 | Time 31.5462(31.5653) | Bit/dim 1.0979(1.0998) | Xent 0.0304(0.0341) | Loss 1.1132(1.1169) | Error 0.0106(0.0107) Steps 446(445.38) | Grad Norm 2.9847(1.3250) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0658 | Time 17.1189, Epoch Time 251.8698(248.8165), Bit/dim 1.0944(best: 1.0937), Xent 0.0288, Loss 1.1088, Error 0.0100(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4607 | Time 31.1075(31.5515) | Bit/dim 1.0985(1.0998) | Xent 0.0341(0.0341) | Loss 1.1156(1.1169) | Error 0.0101(0.0107) Steps 446(445.39) | Grad Norm 2.3855(1.3568) | Total Time 10.00(10.00)\n",
      "Iter 4608 | Time 31.4119(31.5473) | Bit/dim 1.1071(1.1000) | Xent 0.0402(0.0343) | Loss 1.1272(1.1172) | Error 0.0131(0.0107) Steps 446(445.41) | Grad Norm 0.5577(1.3329) | Total Time 10.00(10.00)\n",
      "Iter 4609 | Time 31.9549(31.5596) | Bit/dim 1.0977(1.1000) | Xent 0.0381(0.0344) | Loss 1.1168(1.1172) | Error 0.0101(0.0107) Steps 452(445.61) | Grad Norm 1.8278(1.3477) | Total Time 10.00(10.00)\n",
      "Iter 4610 | Time 31.2640(31.5507) | Bit/dim 1.0956(1.0998) | Xent 0.0355(0.0345) | Loss 1.1134(1.1171) | Error 0.0116(0.0108) Steps 446(445.62) | Grad Norm 0.2842(1.3158) | Total Time 10.00(10.00)\n",
      "Iter 4611 | Time 31.9087(31.5614) | Bit/dim 1.0962(1.0997) | Xent 0.0313(0.0344) | Loss 1.1119(1.1169) | Error 0.0106(0.0108) Steps 446(445.63) | Grad Norm 2.1991(1.3423) | Total Time 10.00(10.00)\n",
      "Iter 4612 | Time 31.8365(31.5697) | Bit/dim 1.0996(1.0997) | Xent 0.0330(0.0343) | Loss 1.1161(1.1169) | Error 0.0101(0.0107) Steps 446(445.64) | Grad Norm 2.0273(1.3629) | Total Time 10.00(10.00)\n",
      "Iter 4613 | Time 31.9022(31.5797) | Bit/dim 1.0991(1.0997) | Xent 0.0296(0.0342) | Loss 1.1139(1.1168) | Error 0.0091(0.0107) Steps 446(445.65) | Grad Norm 0.2437(1.3293) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0659 | Time 17.1039, Epoch Time 251.0238(248.8827), Bit/dim 1.0940(best: 1.0937), Xent 0.0273, Loss 1.1077, Error 0.0093(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4614 | Time 31.3707(31.5734) | Bit/dim 1.0948(1.0996) | Xent 0.0343(0.0342) | Loss 1.1120(1.1166) | Error 0.0114(0.0107) Steps 446(445.67) | Grad Norm 1.2828(1.3279) | Total Time 10.00(10.00)\n",
      "Iter 4615 | Time 31.7351(31.5782) | Bit/dim 1.1010(1.0996) | Xent 0.0301(0.0341) | Loss 1.1161(1.1166) | Error 0.0086(0.0106) Steps 446(445.68) | Grad Norm 0.2546(1.2957) | Total Time 10.00(10.00)\n",
      "Iter 4616 | Time 33.7978(31.6448) | Bit/dim 1.1048(1.0998) | Xent 0.0301(0.0339) | Loss 1.1199(1.1167) | Error 0.0100(0.0106) Steps 446(445.69) | Grad Norm 1.0787(1.2892) | Total Time 10.00(10.00)\n",
      "Iter 4617 | Time 31.4201(31.6381) | Bit/dim 1.1003(1.0998) | Xent 0.0338(0.0339) | Loss 1.1172(1.1167) | Error 0.0088(0.0106) Steps 446(445.69) | Grad Norm 0.3314(1.2604) | Total Time 10.00(10.00)\n",
      "Iter 4618 | Time 31.7022(31.6400) | Bit/dim 1.1033(1.0999) | Xent 0.0276(0.0338) | Loss 1.1171(1.1168) | Error 0.0090(0.0105) Steps 446(445.70) | Grad Norm 1.1560(1.2573) | Total Time 10.00(10.00)\n",
      "Iter 4619 | Time 31.5932(31.6386) | Bit/dim 1.0982(1.0998) | Xent 0.0375(0.0339) | Loss 1.1170(1.1168) | Error 0.0101(0.0105) Steps 446(445.71) | Grad Norm 0.4209(1.2322) | Total Time 10.00(10.00)\n",
      "Iter 4620 | Time 32.2877(31.6581) | Bit/dim 1.0953(1.0997) | Xent 0.0354(0.0339) | Loss 1.1130(1.1166) | Error 0.0101(0.0105) Steps 446(445.72) | Grad Norm 1.8865(1.2518) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0660 | Time 16.8397, Epoch Time 253.2159(249.0127), Bit/dim 1.0943(best: 1.0937), Xent 0.0278, Loss 1.1082, Error 0.0088(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4621 | Time 31.6554(31.6580) | Bit/dim 1.1014(1.0997) | Xent 0.0340(0.0339) | Loss 1.1184(1.1167) | Error 0.0108(0.0105) Steps 446(445.73) | Grad Norm 2.1443(1.2786) | Total Time 10.00(10.00)\n",
      "Iter 4622 | Time 31.6779(31.6586) | Bit/dim 1.1042(1.0999) | Xent 0.0300(0.0338) | Loss 1.1192(1.1168) | Error 0.0099(0.0105) Steps 446(445.74) | Grad Norm 0.5987(1.2582) | Total Time 10.00(10.00)\n",
      "Iter 4623 | Time 31.2147(31.6453) | Bit/dim 1.0937(1.0997) | Xent 0.0311(0.0337) | Loss 1.1093(1.1165) | Error 0.0100(0.0105) Steps 446(445.75) | Grad Norm 2.9136(1.3079) | Total Time 10.00(10.00)\n",
      "Iter 4624 | Time 31.4763(31.6402) | Bit/dim 1.1042(1.0998) | Xent 0.0294(0.0336) | Loss 1.1189(1.1166) | Error 0.0098(0.0104) Steps 446(445.75) | Grad Norm 1.9808(1.3281) | Total Time 10.00(10.00)\n",
      "Iter 4625 | Time 31.7611(31.6438) | Bit/dim 1.1002(1.0998) | Xent 0.0473(0.0340) | Loss 1.1238(1.1168) | Error 0.0132(0.0105) Steps 446(445.76) | Grad Norm 0.9248(1.3160) | Total Time 10.00(10.00)\n",
      "Iter 4626 | Time 31.9157(31.6520) | Bit/dim 1.1011(1.0999) | Xent 0.0347(0.0340) | Loss 1.1185(1.1169) | Error 0.0105(0.0105) Steps 446(445.77) | Grad Norm 2.3613(1.3473) | Total Time 10.00(10.00)\n",
      "Iter 4627 | Time 32.8002(31.6864) | Bit/dim 1.0927(1.0997) | Xent 0.0366(0.0341) | Loss 1.1111(1.1167) | Error 0.0112(0.0106) Steps 446(445.77) | Grad Norm 1.2283(1.3438) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0661 | Time 17.1264, Epoch Time 252.4366(249.1154), Bit/dim 1.0933(best: 1.0937), Xent 0.0271, Loss 1.1069, Error 0.0098(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4628 | Time 31.8151(31.6903) | Bit/dim 1.1032(1.0998) | Xent 0.0326(0.0341) | Loss 1.1195(1.1168) | Error 0.0086(0.0105) Steps 446(445.78) | Grad Norm 0.7952(1.3273) | Total Time 10.00(10.00)\n",
      "Iter 4629 | Time 31.6693(31.6897) | Bit/dim 1.0986(1.0997) | Xent 0.0374(0.0342) | Loss 1.1173(1.1168) | Error 0.0115(0.0105) Steps 446(445.79) | Grad Norm 1.5640(1.3344) | Total Time 10.00(10.00)\n",
      "Iter 4630 | Time 31.4345(31.6820) | Bit/dim 1.0993(1.0997) | Xent 0.0376(0.0343) | Loss 1.1181(1.1168) | Error 0.0121(0.0106) Steps 446(445.79) | Grad Norm 0.8643(1.3203) | Total Time 10.00(10.00)\n",
      "Iter 4631 | Time 32.4044(31.7037) | Bit/dim 1.0992(1.0997) | Xent 0.0297(0.0341) | Loss 1.1141(1.1168) | Error 0.0090(0.0105) Steps 446(445.80) | Grad Norm 0.6920(1.3014) | Total Time 10.00(10.00)\n",
      "Iter 4632 | Time 30.9606(31.6814) | Bit/dim 1.1023(1.0998) | Xent 0.0395(0.0343) | Loss 1.1221(1.1169) | Error 0.0118(0.0106) Steps 446(445.81) | Grad Norm 1.5479(1.3088) | Total Time 10.00(10.00)\n",
      "Iter 4633 | Time 31.4011(31.6730) | Bit/dim 1.0962(1.0997) | Xent 0.0339(0.0343) | Loss 1.1131(1.1168) | Error 0.0108(0.0106) Steps 446(445.81) | Grad Norm 1.0192(1.3002) | Total Time 10.00(10.00)\n",
      "Iter 4634 | Time 31.7285(31.6746) | Bit/dim 1.0983(1.0996) | Xent 0.0327(0.0342) | Loss 1.1146(1.1167) | Error 0.0109(0.0106) Steps 446(445.82) | Grad Norm 0.8852(1.2877) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0662 | Time 17.1328, Epoch Time 250.9011(249.1690), Bit/dim 1.0942(best: 1.0933), Xent 0.0261, Loss 1.1072, Error 0.0086(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4635 | Time 32.6717(31.7046) | Bit/dim 1.0975(1.0996) | Xent 0.0355(0.0343) | Loss 1.1152(1.1167) | Error 0.0112(0.0106) Steps 452(446.00) | Grad Norm 1.9202(1.3067) | Total Time 10.00(10.00)\n",
      "Iter 4636 | Time 31.3932(31.6952) | Bit/dim 1.1016(1.0996) | Xent 0.0314(0.0342) | Loss 1.1173(1.1167) | Error 0.0105(0.0106) Steps 446(446.00) | Grad Norm 1.1514(1.3020) | Total Time 10.00(10.00)\n",
      "Iter 4637 | Time 31.3014(31.6834) | Bit/dim 1.1037(1.0997) | Xent 0.0367(0.0343) | Loss 1.1221(1.1169) | Error 0.0111(0.0106) Steps 446(446.00) | Grad Norm 0.8107(1.2873) | Total Time 10.00(10.00)\n",
      "Iter 4638 | Time 31.4943(31.6777) | Bit/dim 1.0999(1.0998) | Xent 0.0411(0.0345) | Loss 1.1205(1.1170) | Error 0.0135(0.0107) Steps 446(446.00) | Grad Norm 2.2780(1.3170) | Total Time 10.00(10.00)\n",
      "Iter 4639 | Time 31.7874(31.6810) | Bit/dim 1.0992(1.0997) | Xent 0.0385(0.0346) | Loss 1.1185(1.1170) | Error 0.0112(0.0107) Steps 446(446.00) | Grad Norm 1.4925(1.3223) | Total Time 10.00(10.00)\n",
      "Iter 4640 | Time 32.0500(31.6921) | Bit/dim 1.0955(1.0996) | Xent 0.0302(0.0344) | Loss 1.1106(1.1168) | Error 0.0109(0.0107) Steps 446(446.00) | Grad Norm 1.3640(1.3235) | Total Time 10.00(10.00)\n",
      "Iter 4641 | Time 32.0313(31.7023) | Bit/dim 1.0970(1.0995) | Xent 0.0278(0.0342) | Loss 1.1109(1.1167) | Error 0.0084(0.0106) Steps 446(446.00) | Grad Norm 3.2190(1.3804) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0663 | Time 17.1887, Epoch Time 252.4994(249.2689), Bit/dim 1.0942(best: 1.0933), Xent 0.0275, Loss 1.1079, Error 0.0097(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4642 | Time 31.6371(31.7003) | Bit/dim 1.0983(1.0995) | Xent 0.0320(0.0342) | Loss 1.1143(1.1166) | Error 0.0102(0.0106) Steps 446(446.00) | Grad Norm 1.8515(1.3945) | Total Time 10.00(10.00)\n",
      "Iter 4643 | Time 31.4010(31.6913) | Bit/dim 1.1026(1.0996) | Xent 0.0372(0.0343) | Loss 1.1212(1.1167) | Error 0.0109(0.0106) Steps 452(446.18) | Grad Norm 1.5710(1.3998) | Total Time 10.00(10.00)\n",
      "Iter 4644 | Time 32.2798(31.7090) | Bit/dim 1.0979(1.0995) | Xent 0.0307(0.0342) | Loss 1.1133(1.1166) | Error 0.0085(0.0106) Steps 446(446.18) | Grad Norm 3.1845(1.4534) | Total Time 10.00(10.00)\n",
      "Iter 4645 | Time 31.8217(31.7124) | Bit/dim 1.0949(1.0994) | Xent 0.0348(0.0342) | Loss 1.1123(1.1165) | Error 0.0122(0.0106) Steps 446(446.17) | Grad Norm 1.5740(1.4570) | Total Time 10.00(10.00)\n",
      "Iter 4646 | Time 31.6808(31.7114) | Bit/dim 1.0991(1.0994) | Xent 0.0356(0.0342) | Loss 1.1169(1.1165) | Error 0.0105(0.0106) Steps 446(446.17) | Grad Norm 1.6890(1.4639) | Total Time 10.00(10.00)\n",
      "Iter 4647 | Time 32.7779(31.7434) | Bit/dim 1.0981(1.0994) | Xent 0.0296(0.0341) | Loss 1.1129(1.1164) | Error 0.0090(0.0106) Steps 446(446.16) | Grad Norm 3.2952(1.5189) | Total Time 10.00(10.00)\n",
      "Iter 4648 | Time 31.5776(31.7384) | Bit/dim 1.1022(1.0994) | Xent 0.0403(0.0343) | Loss 1.1223(1.1166) | Error 0.0121(0.0106) Steps 446(446.16) | Grad Norm 1.4964(1.5182) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0664 | Time 17.2404, Epoch Time 253.0869(249.3834), Bit/dim 1.0940(best: 1.0933), Xent 0.0325, Loss 1.1102, Error 0.0104(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4649 | Time 31.4261(31.7291) | Bit/dim 1.0984(1.0994) | Xent 0.0329(0.0342) | Loss 1.1148(1.1165) | Error 0.0112(0.0106) Steps 446(446.15) | Grad Norm 2.2878(1.5413) | Total Time 10.00(10.00)\n",
      "Iter 4650 | Time 33.2560(31.7749) | Bit/dim 1.0967(1.0993) | Xent 0.0342(0.0342) | Loss 1.1138(1.1164) | Error 0.0119(0.0107) Steps 446(446.15) | Grad Norm 4.2262(1.6218) | Total Time 10.00(10.00)\n",
      "Iter 4651 | Time 31.1335(31.7556) | Bit/dim 1.1012(1.0994) | Xent 0.0324(0.0342) | Loss 1.1174(1.1165) | Error 0.0090(0.0106) Steps 452(446.32) | Grad Norm 1.6904(1.6239) | Total Time 10.00(10.00)\n",
      "Iter 4652 | Time 32.0152(31.7634) | Bit/dim 1.0992(1.0994) | Xent 0.0322(0.0341) | Loss 1.1154(1.1164) | Error 0.0094(0.0106) Steps 446(446.31) | Grad Norm 2.7175(1.6567) | Total Time 10.00(10.00)\n",
      "Iter 4653 | Time 31.8009(31.7646) | Bit/dim 1.1025(1.0995) | Xent 0.0451(0.0344) | Loss 1.1251(1.1167) | Error 0.0121(0.0106) Steps 446(446.30) | Grad Norm 4.4529(1.7406) | Total Time 10.00(10.00)\n",
      "Iter 4654 | Time 31.5929(31.7594) | Bit/dim 1.0982(1.0994) | Xent 0.0345(0.0344) | Loss 1.1154(1.1167) | Error 0.0114(0.0107) Steps 446(446.29) | Grad Norm 2.5984(1.7663) | Total Time 10.00(10.00)\n",
      "Iter 4655 | Time 32.4859(31.7812) | Bit/dim 1.1019(1.0995) | Xent 0.0361(0.0345) | Loss 1.1199(1.1168) | Error 0.0116(0.0107) Steps 446(446.29) | Grad Norm 1.5849(1.7609) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0665 | Time 17.2184, Epoch Time 253.4130(249.5043), Bit/dim 1.0934(best: 1.0933), Xent 0.0261, Loss 1.1064, Error 0.0092(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4656 | Time 32.2970(31.7967) | Bit/dim 1.0994(1.0995) | Xent 0.0337(0.0345) | Loss 1.1163(1.1167) | Error 0.0101(0.0107) Steps 446(446.28) | Grad Norm 4.1498(1.8325) | Total Time 10.00(10.00)\n",
      "Iter 4657 | Time 31.0504(31.7743) | Bit/dim 1.1036(1.0996) | Xent 0.0336(0.0344) | Loss 1.1204(1.1169) | Error 0.0110(0.0107) Steps 446(446.27) | Grad Norm 2.0509(1.8391) | Total Time 10.00(10.00)\n",
      "Iter 4658 | Time 31.8588(31.7768) | Bit/dim 1.1006(1.0997) | Xent 0.0300(0.0343) | Loss 1.1156(1.1168) | Error 0.0098(0.0107) Steps 446(446.26) | Grad Norm 2.4811(1.8584) | Total Time 10.00(10.00)\n",
      "Iter 4659 | Time 31.7597(31.7763) | Bit/dim 1.0999(1.0997) | Xent 0.0302(0.0342) | Loss 1.1150(1.1168) | Error 0.0088(0.0106) Steps 446(446.25) | Grad Norm 3.9816(1.9221) | Total Time 10.00(10.00)\n",
      "Iter 4660 | Time 31.5943(31.7708) | Bit/dim 1.1043(1.0998) | Xent 0.0358(0.0342) | Loss 1.1222(1.1169) | Error 0.0121(0.0106) Steps 446(446.25) | Grad Norm 1.5938(1.9122) | Total Time 10.00(10.00)\n",
      "Iter 4661 | Time 31.5225(31.7634) | Bit/dim 1.0928(1.0996) | Xent 0.0335(0.0342) | Loss 1.1096(1.1167) | Error 0.0105(0.0106) Steps 446(446.24) | Grad Norm 1.0186(1.8854) | Total Time 10.00(10.00)\n",
      "Iter 4662 | Time 31.4310(31.7534) | Bit/dim 1.0962(1.0995) | Xent 0.0361(0.0343) | Loss 1.1142(1.1166) | Error 0.0118(0.0107) Steps 446(446.23) | Grad Norm 1.0865(1.8614) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0666 | Time 16.9301, Epoch Time 251.0250(249.5499), Bit/dim 1.0939(best: 1.0933), Xent 0.0279, Loss 1.1079, Error 0.0094(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4663 | Time 32.7940(31.7846) | Bit/dim 1.0995(1.0995) | Xent 0.0330(0.0342) | Loss 1.1160(1.1166) | Error 0.0108(0.0107) Steps 446(446.22) | Grad Norm 0.3918(1.8173) | Total Time 10.00(10.00)\n",
      "Iter 4664 | Time 32.3144(31.8005) | Bit/dim 1.0984(1.0995) | Xent 0.0362(0.0343) | Loss 1.1165(1.1166) | Error 0.0115(0.0107) Steps 446(446.22) | Grad Norm 0.9686(1.7919) | Total Time 10.00(10.00)\n",
      "Iter 4665 | Time 32.7140(31.8279) | Bit/dim 1.0965(1.0994) | Xent 0.0365(0.0344) | Loss 1.1148(1.1165) | Error 0.0110(0.0107) Steps 446(446.21) | Grad Norm 0.6188(1.7567) | Total Time 10.00(10.00)\n",
      "Iter 4666 | Time 31.7319(31.8251) | Bit/dim 1.0983(1.0993) | Xent 0.0336(0.0343) | Loss 1.1151(1.1165) | Error 0.0102(0.0107) Steps 446(446.20) | Grad Norm 0.3266(1.7138) | Total Time 10.00(10.00)\n",
      "Iter 4667 | Time 32.0170(31.8308) | Bit/dim 1.1019(1.0994) | Xent 0.0389(0.0345) | Loss 1.1213(1.1166) | Error 0.0115(0.0107) Steps 446(446.20) | Grad Norm 0.2307(1.6693) | Total Time 10.00(10.00)\n",
      "Iter 4668 | Time 31.8010(31.8299) | Bit/dim 1.0996(1.0994) | Xent 0.0344(0.0345) | Loss 1.1168(1.1167) | Error 0.0108(0.0107) Steps 446(446.19) | Grad Norm 0.3692(1.6303) | Total Time 10.00(10.00)\n",
      "Iter 4669 | Time 32.3369(31.8451) | Bit/dim 1.1012(1.0995) | Xent 0.0315(0.0344) | Loss 1.1170(1.1167) | Error 0.0101(0.0107) Steps 446(446.19) | Grad Norm 0.5245(1.5971) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0667 | Time 17.1463, Epoch Time 255.4323(249.7264), Bit/dim 1.0945(best: 1.0933), Xent 0.0277, Loss 1.1083, Error 0.0099(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4670 | Time 31.5568(31.8365) | Bit/dim 1.0975(1.0994) | Xent 0.0376(0.0345) | Loss 1.1164(1.1167) | Error 0.0115(0.0107) Steps 452(446.36) | Grad Norm 0.5285(1.5651) | Total Time 10.00(10.00)\n",
      "Iter 4671 | Time 31.6290(31.8303) | Bit/dim 1.1020(1.0995) | Xent 0.0298(0.0343) | Loss 1.1169(1.1167) | Error 0.0101(0.0107) Steps 446(446.35) | Grad Norm 0.3201(1.5277) | Total Time 10.00(10.00)\n",
      "Iter 4672 | Time 32.3628(31.8462) | Bit/dim 1.1025(1.0996) | Xent 0.0311(0.0342) | Loss 1.1180(1.1167) | Error 0.0094(0.0107) Steps 446(446.34) | Grad Norm 0.6682(1.5019) | Total Time 10.00(10.00)\n",
      "Iter 4673 | Time 31.7318(31.8428) | Bit/dim 1.0977(1.0995) | Xent 0.0421(0.0345) | Loss 1.1188(1.1168) | Error 0.0142(0.0108) Steps 446(446.33) | Grad Norm 0.2633(1.4648) | Total Time 10.00(10.00)\n",
      "Iter 4674 | Time 32.4074(31.8597) | Bit/dim 1.1004(1.0996) | Xent 0.0367(0.0345) | Loss 1.1188(1.1168) | Error 0.0115(0.0108) Steps 446(446.32) | Grad Norm 0.9456(1.4492) | Total Time 10.00(10.00)\n",
      "Iter 4675 | Time 31.8208(31.8586) | Bit/dim 1.0975(1.0995) | Xent 0.0368(0.0346) | Loss 1.1159(1.1168) | Error 0.0108(0.0108) Steps 446(446.31) | Grad Norm 0.7416(1.4280) | Total Time 10.00(10.00)\n",
      "Iter 4676 | Time 31.3415(31.8431) | Bit/dim 1.0985(1.0995) | Xent 0.0352(0.0346) | Loss 1.1160(1.1168) | Error 0.0114(0.0108) Steps 446(446.30) | Grad Norm 1.1782(1.4205) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0668 | Time 17.1717, Epoch Time 252.5083(249.8099), Bit/dim 1.0939(best: 1.0933), Xent 0.0269, Loss 1.1073, Error 0.0089(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4677 | Time 31.7120(31.8391) | Bit/dim 1.1026(1.0996) | Xent 0.0350(0.0346) | Loss 1.1201(1.1169) | Error 0.0119(0.0108) Steps 446(446.29) | Grad Norm 2.0074(1.4381) | Total Time 10.00(10.00)\n",
      "Iter 4678 | Time 31.5228(31.8296) | Bit/dim 1.0986(1.0995) | Xent 0.0376(0.0347) | Loss 1.1173(1.1169) | Error 0.0110(0.0108) Steps 446(446.28) | Grad Norm 0.9021(1.4220) | Total Time 10.00(10.00)\n",
      "Iter 4679 | Time 31.4224(31.8174) | Bit/dim 1.0929(1.0993) | Xent 0.0358(0.0348) | Loss 1.1108(1.1167) | Error 0.0102(0.0108) Steps 446(446.27) | Grad Norm 0.4098(1.3916) | Total Time 10.00(10.00)\n",
      "Iter 4680 | Time 31.4146(31.8053) | Bit/dim 1.0990(1.0993) | Xent 0.0333(0.0347) | Loss 1.1156(1.1167) | Error 0.0114(0.0108) Steps 446(446.27) | Grad Norm 0.4495(1.3634) | Total Time 10.00(10.00)\n",
      "Iter 4681 | Time 32.9029(31.8383) | Bit/dim 1.1001(1.0993) | Xent 0.0402(0.0349) | Loss 1.1202(1.1168) | Error 0.0124(0.0109) Steps 446(446.26) | Grad Norm 0.5351(1.3385) | Total Time 10.00(10.00)\n",
      "Iter 4682 | Time 32.1140(31.8465) | Bit/dim 1.1003(1.0994) | Xent 0.0287(0.0347) | Loss 1.1146(1.1167) | Error 0.0076(0.0108) Steps 446(446.25) | Grad Norm 0.8995(1.3254) | Total Time 10.00(10.00)\n",
      "Iter 4683 | Time 31.2217(31.8278) | Bit/dim 1.0999(1.0994) | Xent 0.0361(0.0347) | Loss 1.1180(1.1168) | Error 0.0108(0.0108) Steps 446(446.24) | Grad Norm 0.9694(1.3147) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0669 | Time 17.1376, Epoch Time 251.8466(249.8710), Bit/dim 1.0937(best: 1.0933), Xent 0.0272, Loss 1.1073, Error 0.0094(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4684 | Time 32.0954(31.8358) | Bit/dim 1.0963(1.0993) | Xent 0.0321(0.0347) | Loss 1.1123(1.1166) | Error 0.0096(0.0108) Steps 446(446.24) | Grad Norm 1.1181(1.3088) | Total Time 10.00(10.00)\n",
      "Iter 4685 | Time 32.5284(31.8566) | Bit/dim 1.1025(1.0994) | Xent 0.0325(0.0346) | Loss 1.1188(1.1167) | Error 0.0106(0.0108) Steps 446(446.23) | Grad Norm 1.1772(1.3048) | Total Time 10.00(10.00)\n",
      "Iter 4686 | Time 32.4171(31.8734) | Bit/dim 1.1001(1.0994) | Xent 0.0344(0.0346) | Loss 1.1173(1.1167) | Error 0.0106(0.0108) Steps 446(446.22) | Grad Norm 0.4869(1.2803) | Total Time 10.00(10.00)\n",
      "Iter 4687 | Time 31.3779(31.8585) | Bit/dim 1.0962(1.0993) | Xent 0.0336(0.0346) | Loss 1.1131(1.1166) | Error 0.0100(0.0107) Steps 446(446.22) | Grad Norm 0.9505(1.2704) | Total Time 10.00(10.00)\n",
      "Iter 4688 | Time 31.8653(31.8587) | Bit/dim 1.1009(1.0994) | Xent 0.0370(0.0346) | Loss 1.1195(1.1167) | Error 0.0109(0.0107) Steps 446(446.21) | Grad Norm 1.4196(1.2749) | Total Time 10.00(10.00)\n",
      "Iter 4689 | Time 31.7765(31.8563) | Bit/dim 1.0992(1.0994) | Xent 0.0318(0.0345) | Loss 1.1151(1.1166) | Error 0.0109(0.0107) Steps 452(446.38) | Grad Norm 0.3345(1.2467) | Total Time 10.00(10.00)\n",
      "Iter 4690 | Time 31.4877(31.8452) | Bit/dim 1.1016(1.0994) | Xent 0.0316(0.0345) | Loss 1.1174(1.1167) | Error 0.0100(0.0107) Steps 446(446.37) | Grad Norm 1.3093(1.2485) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0670 | Time 17.0336, Epoch Time 253.1001(249.9678), Bit/dim 1.0937(best: 1.0933), Xent 0.0269, Loss 1.1072, Error 0.0089(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4691 | Time 31.0167(31.8204) | Bit/dim 1.1050(1.0996) | Xent 0.0319(0.0344) | Loss 1.1209(1.1168) | Error 0.0101(0.0107) Steps 446(446.36) | Grad Norm 1.2478(1.2485) | Total Time 10.00(10.00)\n",
      "Iter 4692 | Time 31.5662(31.8127) | Bit/dim 1.0957(1.0995) | Xent 0.0365(0.0344) | Loss 1.1139(1.1167) | Error 0.0116(0.0107) Steps 446(446.35) | Grad Norm 0.3367(1.2212) | Total Time 10.00(10.00)\n",
      "Iter 4693 | Time 31.2730(31.7966) | Bit/dim 1.0995(1.0995) | Xent 0.0387(0.0346) | Loss 1.1189(1.1168) | Error 0.0119(0.0108) Steps 446(446.34) | Grad Norm 1.3141(1.2240) | Total Time 10.00(10.00)\n",
      "Iter 4694 | Time 31.2068(31.7789) | Bit/dim 1.0999(1.0995) | Xent 0.0310(0.0345) | Loss 1.1154(1.1167) | Error 0.0104(0.0107) Steps 446(446.33) | Grad Norm 1.1923(1.2230) | Total Time 10.00(10.00)\n",
      "Iter 4695 | Time 31.7501(31.7780) | Bit/dim 1.0959(1.0994) | Xent 0.0340(0.0345) | Loss 1.1129(1.1166) | Error 0.0110(0.0108) Steps 446(446.32) | Grad Norm 0.3332(1.1963) | Total Time 10.00(10.00)\n",
      "Iter 4696 | Time 30.5480(31.7411) | Bit/dim 1.0995(1.0994) | Xent 0.0326(0.0344) | Loss 1.1158(1.1166) | Error 0.0098(0.0107) Steps 446(446.31) | Grad Norm 0.4963(1.1753) | Total Time 10.00(10.00)\n",
      "Iter 4697 | Time 31.6722(31.7390) | Bit/dim 1.1000(1.0994) | Xent 0.0428(0.0347) | Loss 1.1213(1.1167) | Error 0.0138(0.0108) Steps 446(446.30) | Grad Norm 0.2981(1.1490) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0671 | Time 17.1663, Epoch Time 248.9312(249.9367), Bit/dim 1.0935(best: 1.0933), Xent 0.0260, Loss 1.1064, Error 0.0091(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4698 | Time 31.4574(31.7306) | Bit/dim 1.0992(1.0994) | Xent 0.0323(0.0346) | Loss 1.1154(1.1167) | Error 0.0110(0.0108) Steps 446(446.29) | Grad Norm 0.8144(1.1390) | Total Time 10.00(10.00)\n",
      "Iter 4699 | Time 32.4975(31.7536) | Bit/dim 1.0957(1.0993) | Xent 0.0317(0.0345) | Loss 1.1115(1.1165) | Error 0.0110(0.0108) Steps 452(446.46) | Grad Norm 1.3611(1.1456) | Total Time 10.00(10.00)\n",
      "Iter 4700 | Time 31.7713(31.7541) | Bit/dim 1.0980(1.0992) | Xent 0.0323(0.0344) | Loss 1.1141(1.1165) | Error 0.0112(0.0108) Steps 446(446.45) | Grad Norm 1.0234(1.1420) | Total Time 10.00(10.00)\n",
      "Iter 4701 | Time 31.9511(31.7600) | Bit/dim 1.1026(1.0993) | Xent 0.0390(0.0346) | Loss 1.1221(1.1166) | Error 0.0124(0.0109) Steps 446(446.43) | Grad Norm 0.4145(1.1201) | Total Time 10.00(10.00)\n",
      "Iter 4702 | Time 31.2103(31.7435) | Bit/dim 1.0983(1.0993) | Xent 0.0389(0.0347) | Loss 1.1178(1.1167) | Error 0.0120(0.0109) Steps 446(446.42) | Grad Norm 1.9823(1.1460) | Total Time 10.00(10.00)\n",
      "Iter 4703 | Time 32.6377(31.7704) | Bit/dim 1.0993(1.0993) | Xent 0.0355(0.0347) | Loss 1.1171(1.1167) | Error 0.0112(0.0109) Steps 446(446.41) | Grad Norm 2.1777(1.1769) | Total Time 10.00(10.00)\n",
      "Iter 4704 | Time 31.2895(31.7559) | Bit/dim 1.0962(1.0992) | Xent 0.0332(0.0347) | Loss 1.1128(1.1166) | Error 0.0094(0.0109) Steps 446(446.40) | Grad Norm 0.3045(1.1508) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0672 | Time 17.0932, Epoch Time 252.5008(250.0137), Bit/dim 1.0939(best: 1.0933), Xent 0.0264, Loss 1.1071, Error 0.0092(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4705 | Time 31.4447(31.7466) | Bit/dim 1.0978(1.0992) | Xent 0.0306(0.0346) | Loss 1.1131(1.1165) | Error 0.0091(0.0108) Steps 446(446.38) | Grad Norm 2.7819(1.1997) | Total Time 10.00(10.00)\n",
      "Iter 4706 | Time 31.2678(31.7322) | Bit/dim 1.0970(1.0991) | Xent 0.0359(0.0346) | Loss 1.1149(1.1164) | Error 0.0105(0.0108) Steps 446(446.37) | Grad Norm 3.1965(1.2596) | Total Time 10.00(10.00)\n",
      "Iter 4707 | Time 31.8365(31.7354) | Bit/dim 1.0962(1.0990) | Xent 0.0444(0.0349) | Loss 1.1184(1.1165) | Error 0.0121(0.0109) Steps 446(446.36) | Grad Norm 0.3721(1.2330) | Total Time 10.00(10.00)\n",
      "Iter 4708 | Time 31.1955(31.7192) | Bit/dim 1.0994(1.0990) | Xent 0.0334(0.0348) | Loss 1.1161(1.1165) | Error 0.0100(0.0108) Steps 446(446.35) | Grad Norm 3.5874(1.3036) | Total Time 10.00(10.00)\n",
      "Iter 4709 | Time 31.3068(31.7068) | Bit/dim 1.1018(1.0991) | Xent 0.0314(0.0347) | Loss 1.1175(1.1165) | Error 0.0105(0.0108) Steps 446(446.34) | Grad Norm 3.1151(1.3580) | Total Time 10.00(10.00)\n",
      "Iter 4710 | Time 31.6016(31.7036) | Bit/dim 1.1024(1.0992) | Xent 0.0335(0.0347) | Loss 1.1191(1.1166) | Error 0.0101(0.0108) Steps 446(446.33) | Grad Norm 0.5213(1.3329) | Total Time 10.00(10.00)\n",
      "Iter 4711 | Time 31.5802(31.6999) | Bit/dim 1.1032(1.0993) | Xent 0.0336(0.0347) | Loss 1.1200(1.1167) | Error 0.0094(0.0108) Steps 446(446.32) | Grad Norm 3.3485(1.3933) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0673 | Time 17.2632, Epoch Time 250.0644(250.0152), Bit/dim 1.0936(best: 1.0933), Xent 0.0287, Loss 1.1079, Error 0.0086(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4712 | Time 32.4641(31.7229) | Bit/dim 1.1006(1.0994) | Xent 0.0375(0.0348) | Loss 1.1194(1.1167) | Error 0.0118(0.0108) Steps 446(446.31) | Grad Norm 2.9076(1.4388) | Total Time 10.00(10.00)\n",
      "Iter 4713 | Time 30.7309(31.6931) | Bit/dim 1.0980(1.0993) | Xent 0.0305(0.0346) | Loss 1.1132(1.1166) | Error 0.0091(0.0107) Steps 446(446.30) | Grad Norm 0.6937(1.4164) | Total Time 10.00(10.00)\n",
      "Iter 4714 | Time 31.7197(31.6939) | Bit/dim 1.0957(1.0992) | Xent 0.0323(0.0346) | Loss 1.1119(1.1165) | Error 0.0096(0.0107) Steps 446(446.29) | Grad Norm 4.1231(1.4976) | Total Time 10.00(10.00)\n",
      "Iter 4715 | Time 31.4007(31.6851) | Bit/dim 1.0996(1.0992) | Xent 0.0350(0.0346) | Loss 1.1171(1.1165) | Error 0.0096(0.0107) Steps 446(446.28) | Grad Norm 3.5336(1.5587) | Total Time 10.00(10.00)\n",
      "Iter 4716 | Time 31.8717(31.6907) | Bit/dim 1.0983(1.0992) | Xent 0.0308(0.0345) | Loss 1.1138(1.1164) | Error 0.0099(0.0106) Steps 446(446.28) | Grad Norm 0.7439(1.5342) | Total Time 10.00(10.00)\n",
      "Iter 4717 | Time 31.9334(31.6980) | Bit/dim 1.1025(1.0993) | Xent 0.0329(0.0344) | Loss 1.1190(1.1165) | Error 0.0114(0.0107) Steps 452(446.45) | Grad Norm 3.2320(1.5852) | Total Time 10.00(10.00)\n",
      "Iter 4718 | Time 31.5016(31.6921) | Bit/dim 1.1013(1.0994) | Xent 0.0404(0.0346) | Loss 1.1215(1.1167) | Error 0.0119(0.0107) Steps 446(446.43) | Grad Norm 2.4224(1.6103) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0674 | Time 17.3090, Epoch Time 251.4072(250.0569), Bit/dim 1.0939(best: 1.0933), Xent 0.0302, Loss 1.1090, Error 0.0098(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4719 | Time 31.1664(31.6763) | Bit/dim 1.1035(1.0995) | Xent 0.0336(0.0346) | Loss 1.1203(1.1168) | Error 0.0106(0.0107) Steps 446(446.42) | Grad Norm 0.9357(1.5901) | Total Time 10.00(10.00)\n",
      "Iter 4720 | Time 31.2425(31.6633) | Bit/dim 1.1064(1.0997) | Xent 0.0388(0.0347) | Loss 1.1258(1.1170) | Error 0.0118(0.0107) Steps 446(446.41) | Grad Norm 3.6698(1.6525) | Total Time 10.00(10.00)\n",
      "Iter 4721 | Time 32.0628(31.6753) | Bit/dim 1.1004(1.0997) | Xent 0.0341(0.0347) | Loss 1.1174(1.1171) | Error 0.0100(0.0107) Steps 446(446.40) | Grad Norm 2.9105(1.6902) | Total Time 10.00(10.00)\n",
      "Iter 4722 | Time 32.2051(31.6912) | Bit/dim 1.0928(1.0995) | Xent 0.0337(0.0346) | Loss 1.1097(1.1168) | Error 0.0100(0.0107) Steps 446(446.38) | Grad Norm 1.0116(1.6698) | Total Time 10.00(10.00)\n",
      "Iter 4723 | Time 31.6874(31.6911) | Bit/dim 1.0938(1.0993) | Xent 0.0321(0.0346) | Loss 1.1099(1.1166) | Error 0.0104(0.0107) Steps 446(446.37) | Grad Norm 4.0793(1.7421) | Total Time 10.00(10.00)\n",
      "Iter 4724 | Time 31.6892(31.6910) | Bit/dim 1.0993(1.0993) | Xent 0.0365(0.0346) | Loss 1.1176(1.1166) | Error 0.0122(0.0107) Steps 446(446.36) | Grad Norm 3.1620(1.7847) | Total Time 10.00(10.00)\n",
      "Iter 4725 | Time 31.6446(31.6896) | Bit/dim 1.0981(1.0993) | Xent 0.0343(0.0346) | Loss 1.1152(1.1166) | Error 0.0104(0.0107) Steps 446(446.35) | Grad Norm 1.1992(1.7671) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0675 | Time 17.0472, Epoch Time 251.1200(250.0888), Bit/dim 1.0938(best: 1.0933), Xent 0.0277, Loss 1.1077, Error 0.0096(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4726 | Time 31.2947(31.6778) | Bit/dim 1.1006(1.0993) | Xent 0.0327(0.0346) | Loss 1.1170(1.1166) | Error 0.0099(0.0107) Steps 446(446.34) | Grad Norm 5.0572(1.8659) | Total Time 10.00(10.00)\n",
      "Iter 4727 | Time 31.4719(31.6716) | Bit/dim 1.0971(1.0993) | Xent 0.0328(0.0345) | Loss 1.1135(1.1165) | Error 0.0101(0.0107) Steps 446(446.33) | Grad Norm 4.4174(1.9424) | Total Time 10.00(10.00)\n",
      "Iter 4728 | Time 32.0097(31.6817) | Bit/dim 1.0997(1.0993) | Xent 0.0360(0.0345) | Loss 1.1177(1.1166) | Error 0.0109(0.0107) Steps 446(446.32) | Grad Norm 1.4054(1.9263) | Total Time 10.00(10.00)\n",
      "Iter 4729 | Time 31.5298(31.6772) | Bit/dim 1.0981(1.0993) | Xent 0.0350(0.0346) | Loss 1.1157(1.1165) | Error 0.0109(0.0107) Steps 446(446.31) | Grad Norm 7.0352(2.0796) | Total Time 10.00(10.00)\n",
      "Iter 4730 | Time 31.2709(31.6650) | Bit/dim 1.1025(1.0993) | Xent 0.0357(0.0346) | Loss 1.1203(1.1166) | Error 0.0108(0.0107) Steps 446(446.30) | Grad Norm 5.4558(2.1808) | Total Time 10.00(10.00)\n",
      "Iter 4731 | Time 31.3964(31.6569) | Bit/dim 1.1050(1.0995) | Xent 0.0315(0.0345) | Loss 1.1207(1.1168) | Error 0.0096(0.0107) Steps 446(446.29) | Grad Norm 2.6687(2.1955) | Total Time 10.00(10.00)\n",
      "Iter 4732 | Time 31.2049(31.6434) | Bit/dim 1.1003(1.0995) | Xent 0.0364(0.0346) | Loss 1.1185(1.1168) | Error 0.0110(0.0107) Steps 446(446.28) | Grad Norm 9.0239(2.4003) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0676 | Time 17.1762, Epoch Time 249.7245(250.0779), Bit/dim 1.0957(best: 1.0933), Xent 0.0267, Loss 1.1091, Error 0.0098(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4733 | Time 31.6628(31.6440) | Bit/dim 1.1030(1.0996) | Xent 0.0330(0.0345) | Loss 1.1195(1.1169) | Error 0.0098(0.0106) Steps 446(446.27) | Grad Norm 6.1304(2.5122) | Total Time 10.00(10.00)\n",
      "Iter 4734 | Time 32.3798(31.6660) | Bit/dim 1.0993(1.0996) | Xent 0.0295(0.0344) | Loss 1.1141(1.1168) | Error 0.0096(0.0106) Steps 446(446.27) | Grad Norm 4.3480(2.5673) | Total Time 10.00(10.00)\n",
      "Iter 4735 | Time 31.6571(31.6658) | Bit/dim 1.1073(1.0999) | Xent 0.0374(0.0345) | Loss 1.1260(1.1171) | Error 0.0121(0.0107) Steps 446(446.26) | Grad Norm 11.3166(2.8298) | Total Time 10.00(10.00)\n",
      "Iter 4736 | Time 31.9721(31.6750) | Bit/dim 1.0997(1.0999) | Xent 0.0339(0.0344) | Loss 1.1166(1.1171) | Error 0.0106(0.0107) Steps 446(446.25) | Grad Norm 6.5116(2.9402) | Total Time 10.00(10.00)\n",
      "Iter 4737 | Time 31.5079(31.6699) | Bit/dim 1.1026(1.0999) | Xent 0.0316(0.0343) | Loss 1.1184(1.1171) | Error 0.0091(0.0106) Steps 446(446.24) | Grad Norm 5.3450(3.0124) | Total Time 10.00(10.00)\n",
      "Iter 4738 | Time 30.9489(31.6483) | Bit/dim 1.0977(1.0999) | Xent 0.0358(0.0344) | Loss 1.1156(1.1171) | Error 0.0115(0.0106) Steps 446(446.24) | Grad Norm 11.1000(3.2550) | Total Time 10.00(10.00)\n",
      "Iter 4739 | Time 32.4382(31.6720) | Bit/dim 1.1003(1.0999) | Xent 0.0343(0.0344) | Loss 1.1174(1.1171) | Error 0.0098(0.0106) Steps 446(446.23) | Grad Norm 4.6901(3.2981) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0677 | Time 17.2977, Epoch Time 252.2028(250.1416), Bit/dim 1.0958(best: 1.0933), Xent 0.0260, Loss 1.1088, Error 0.0096(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4740 | Time 31.5176(31.6674) | Bit/dim 1.1025(1.1000) | Xent 0.0325(0.0343) | Loss 1.1187(1.1171) | Error 0.0101(0.0106) Steps 446(446.22) | Grad Norm 5.5937(3.3669) | Total Time 10.00(10.00)\n",
      "Iter 4741 | Time 31.1923(31.6531) | Bit/dim 1.0974(1.0999) | Xent 0.0298(0.0342) | Loss 1.1123(1.1170) | Error 0.0088(0.0105) Steps 446(446.22) | Grad Norm 6.9026(3.4730) | Total Time 10.00(10.00)\n",
      "Iter 4742 | Time 31.5688(31.6506) | Bit/dim 1.0985(1.0998) | Xent 0.0358(0.0342) | Loss 1.1164(1.1170) | Error 0.0114(0.0106) Steps 446(446.21) | Grad Norm 0.2271(3.3756) | Total Time 10.00(10.00)\n",
      "Iter 4743 | Time 31.2629(31.6390) | Bit/dim 1.0951(1.0997) | Xent 0.0367(0.0343) | Loss 1.1134(1.1169) | Error 0.0104(0.0106) Steps 446(446.20) | Grad Norm 4.9402(3.4226) | Total Time 10.00(10.00)\n",
      "Iter 4744 | Time 33.1203(31.6834) | Bit/dim 1.0967(1.0996) | Xent 0.0349(0.0343) | Loss 1.1141(1.1168) | Error 0.0104(0.0106) Steps 452(446.38) | Grad Norm 3.2634(3.4178) | Total Time 10.00(10.00)\n",
      "Iter 4745 | Time 31.3057(31.6721) | Bit/dim 1.1023(1.0997) | Xent 0.0394(0.0345) | Loss 1.1220(1.1169) | Error 0.0132(0.0106) Steps 446(446.37) | Grad Norm 2.1696(3.3803) | Total Time 10.00(10.00)\n",
      "Iter 4746 | Time 31.8782(31.6783) | Bit/dim 1.1051(1.0999) | Xent 0.0298(0.0343) | Loss 1.1200(1.1170) | Error 0.0090(0.0106) Steps 446(446.35) | Grad Norm 3.9185(3.3965) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0678 | Time 17.2343, Epoch Time 251.4888(250.1821), Bit/dim 1.0934(best: 1.0933), Xent 0.0269, Loss 1.1068, Error 0.0093(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4747 | Time 31.7481(31.6804) | Bit/dim 1.1037(1.1000) | Xent 0.0330(0.0343) | Loss 1.1202(1.1171) | Error 0.0090(0.0105) Steps 446(446.34) | Grad Norm 0.3412(3.3048) | Total Time 10.00(10.00)\n",
      "Iter 4748 | Time 31.2657(31.6679) | Bit/dim 1.1024(1.1000) | Xent 0.0338(0.0343) | Loss 1.1193(1.1172) | Error 0.0122(0.0106) Steps 446(446.33) | Grad Norm 4.3163(3.3352) | Total Time 10.00(10.00)\n",
      "Iter 4749 | Time 31.8765(31.6742) | Bit/dim 1.0991(1.1000) | Xent 0.0384(0.0344) | Loss 1.1183(1.1172) | Error 0.0118(0.0106) Steps 452(446.50) | Grad Norm 2.8398(3.3203) | Total Time 10.00(10.00)\n",
      "Iter 4750 | Time 31.4075(31.6662) | Bit/dim 1.1028(1.1001) | Xent 0.0306(0.0343) | Loss 1.1181(1.1172) | Error 0.0091(0.0106) Steps 446(446.49) | Grad Norm 2.4438(3.2940) | Total Time 10.00(10.00)\n",
      "Iter 4751 | Time 32.2414(31.6834) | Bit/dim 1.0953(1.1000) | Xent 0.0350(0.0343) | Loss 1.1128(1.1171) | Error 0.0105(0.0106) Steps 446(446.47) | Grad Norm 4.6463(3.3346) | Total Time 10.00(10.00)\n",
      "Iter 4752 | Time 31.5543(31.6796) | Bit/dim 1.0979(1.0999) | Xent 0.0315(0.0342) | Loss 1.1137(1.1170) | Error 0.0091(0.0105) Steps 446(446.46) | Grad Norm 1.6107(3.2829) | Total Time 10.00(10.00)\n",
      "Iter 4753 | Time 32.9760(31.7184) | Bit/dim 1.0938(1.0997) | Xent 0.0299(0.0341) | Loss 1.1088(1.1168) | Error 0.0096(0.0105) Steps 446(446.45) | Grad Norm 2.8974(3.2713) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0679 | Time 17.0193, Epoch Time 252.6971(250.2575), Bit/dim 1.0925(best: 1.0933), Xent 0.0260, Loss 1.1055, Error 0.0084(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4754 | Time 31.9242(31.7246) | Bit/dim 1.0951(1.0996) | Xent 0.0293(0.0340) | Loss 1.1097(1.1166) | Error 0.0092(0.0105) Steps 446(446.43) | Grad Norm 3.6311(3.2821) | Total Time 10.00(10.00)\n",
      "Iter 4755 | Time 32.9365(31.7610) | Bit/dim 1.0977(1.0995) | Xent 0.0388(0.0341) | Loss 1.1171(1.1166) | Error 0.0129(0.0105) Steps 446(446.42) | Grad Norm 0.2996(3.1926) | Total Time 10.00(10.00)\n",
      "Iter 4756 | Time 31.7112(31.7595) | Bit/dim 1.1011(1.0996) | Xent 0.0307(0.0340) | Loss 1.1164(1.1166) | Error 0.0099(0.0105) Steps 446(446.41) | Grad Norm 2.6229(3.1755) | Total Time 10.00(10.00)\n",
      "Iter 4757 | Time 31.6423(31.7560) | Bit/dim 1.0989(1.0995) | Xent 0.0390(0.0342) | Loss 1.1184(1.1166) | Error 0.0125(0.0106) Steps 446(446.39) | Grad Norm 2.2234(3.1470) | Total Time 10.00(10.00)\n",
      "Iter 4758 | Time 31.2521(31.7408) | Bit/dim 1.0975(1.0995) | Xent 0.0320(0.0341) | Loss 1.1135(1.1165) | Error 0.0085(0.0105) Steps 446(446.38) | Grad Norm 0.4561(3.0662) | Total Time 10.00(10.00)\n",
      "Iter 4759 | Time 31.2965(31.7275) | Bit/dim 1.1049(1.0996) | Xent 0.0314(0.0340) | Loss 1.1206(1.1166) | Error 0.0106(0.0105) Steps 446(446.37) | Grad Norm 0.8845(3.0008) | Total Time 10.00(10.00)\n",
      "Iter 4760 | Time 31.3602(31.7165) | Bit/dim 1.0967(1.0996) | Xent 0.0326(0.0340) | Loss 1.1130(1.1165) | Error 0.0106(0.0105) Steps 446(446.36) | Grad Norm 0.7227(2.9324) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0680 | Time 17.2550, Epoch Time 251.8426(250.3051), Bit/dim 1.0927(best: 1.0925), Xent 0.0262, Loss 1.1058, Error 0.0093(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4761 | Time 30.7980(31.6889) | Bit/dim 1.1001(1.0996) | Xent 0.0275(0.0338) | Loss 1.1139(1.1165) | Error 0.0090(0.0105) Steps 446(446.35) | Grad Norm 0.6854(2.8650) | Total Time 10.00(10.00)\n",
      "Iter 4762 | Time 31.4248(31.6810) | Bit/dim 1.0968(1.0995) | Xent 0.0372(0.0339) | Loss 1.1154(1.1164) | Error 0.0129(0.0105) Steps 446(446.34) | Grad Norm 1.1055(2.8122) | Total Time 10.00(10.00)\n",
      "Iter 4763 | Time 31.3657(31.6716) | Bit/dim 1.0975(1.0994) | Xent 0.0310(0.0338) | Loss 1.1130(1.1163) | Error 0.0098(0.0105) Steps 446(446.33) | Grad Norm 0.4703(2.7420) | Total Time 10.00(10.00)\n",
      "Iter 4764 | Time 30.9743(31.6506) | Bit/dim 1.1050(1.0996) | Xent 0.0345(0.0338) | Loss 1.1222(1.1165) | Error 0.0090(0.0105) Steps 446(446.32) | Grad Norm 1.4030(2.7018) | Total Time 10.00(10.00)\n",
      "Iter 4765 | Time 32.4272(31.6739) | Bit/dim 1.0952(1.0995) | Xent 0.0360(0.0339) | Loss 1.1132(1.1164) | Error 0.0108(0.0105) Steps 446(446.31) | Grad Norm 0.7379(2.6429) | Total Time 10.00(10.00)\n",
      "Iter 4766 | Time 31.4906(31.6684) | Bit/dim 1.0969(1.0994) | Xent 0.0322(0.0338) | Loss 1.1130(1.1163) | Error 0.0098(0.0105) Steps 452(446.48) | Grad Norm 1.0892(2.5963) | Total Time 10.00(10.00)\n",
      "Iter 4767 | Time 32.8112(31.7027) | Bit/dim 1.1017(1.0995) | Xent 0.0327(0.0338) | Loss 1.1180(1.1164) | Error 0.0112(0.0105) Steps 446(446.47) | Grad Norm 1.7997(2.5724) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0681 | Time 17.4447, Epoch Time 251.1551(250.3306), Bit/dim 1.0930(best: 1.0925), Xent 0.0263, Loss 1.1062, Error 0.0086(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4768 | Time 31.9568(31.7103) | Bit/dim 1.0980(1.0994) | Xent 0.0378(0.0339) | Loss 1.1169(1.1164) | Error 0.0118(0.0105) Steps 446(446.45) | Grad Norm 0.6713(2.5154) | Total Time 10.00(10.00)\n",
      "Iter 4769 | Time 31.9368(31.7171) | Bit/dim 1.0962(1.0993) | Xent 0.0316(0.0338) | Loss 1.1120(1.1162) | Error 0.0092(0.0105) Steps 446(446.44) | Grad Norm 1.0847(2.4724) | Total Time 10.00(10.00)\n",
      "Iter 4770 | Time 30.9125(31.6930) | Bit/dim 1.1004(1.0993) | Xent 0.0323(0.0338) | Loss 1.1165(1.1162) | Error 0.0105(0.0105) Steps 446(446.42) | Grad Norm 1.6952(2.4491) | Total Time 10.00(10.00)\n",
      "Iter 4771 | Time 30.7756(31.6655) | Bit/dim 1.0977(1.0993) | Xent 0.0334(0.0338) | Loss 1.1144(1.1162) | Error 0.0096(0.0105) Steps 446(446.41) | Grad Norm 0.7181(2.3972) | Total Time 10.00(10.00)\n",
      "Iter 4772 | Time 31.5267(31.6613) | Bit/dim 1.1020(1.0994) | Xent 0.0354(0.0338) | Loss 1.1197(1.1163) | Error 0.0115(0.0105) Steps 446(446.40) | Grad Norm 1.2181(2.3618) | Total Time 10.00(10.00)\n",
      "Iter 4773 | Time 31.2235(31.6482) | Bit/dim 1.0990(1.0994) | Xent 0.0378(0.0340) | Loss 1.1179(1.1163) | Error 0.0111(0.0105) Steps 446(446.39) | Grad Norm 1.4799(2.3354) | Total Time 10.00(10.00)\n",
      "Iter 4774 | Time 31.1643(31.6337) | Bit/dim 1.1026(1.0995) | Xent 0.0340(0.0340) | Loss 1.1196(1.1164) | Error 0.0100(0.0105) Steps 446(446.38) | Grad Norm 0.7134(2.2867) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0682 | Time 17.3971, Epoch Time 249.2689(250.2987), Bit/dim 1.0928(best: 1.0925), Xent 0.0270, Loss 1.1063, Error 0.0090(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4775 | Time 30.8848(31.6112) | Bit/dim 1.0975(1.0994) | Xent 0.0356(0.0340) | Loss 1.1153(1.1164) | Error 0.0111(0.0105) Steps 446(446.36) | Grad Norm 0.5650(2.2351) | Total Time 10.00(10.00)\n",
      "Iter 4776 | Time 31.3321(31.6028) | Bit/dim 1.0936(1.0992) | Xent 0.0306(0.0339) | Loss 1.1089(1.1162) | Error 0.0091(0.0105) Steps 446(446.35) | Grad Norm 1.0007(2.1980) | Total Time 10.00(10.00)\n",
      "Iter 4777 | Time 31.2234(31.5914) | Bit/dim 1.1024(1.0993) | Xent 0.0354(0.0339) | Loss 1.1201(1.1163) | Error 0.0112(0.0105) Steps 446(446.34) | Grad Norm 0.6451(2.1514) | Total Time 10.00(10.00)\n",
      "Iter 4778 | Time 31.2465(31.5811) | Bit/dim 1.1037(1.0995) | Xent 0.0356(0.0340) | Loss 1.1214(1.1165) | Error 0.0118(0.0105) Steps 446(446.33) | Grad Norm 0.4088(2.0992) | Total Time 10.00(10.00)\n",
      "Iter 4779 | Time 32.1141(31.5971) | Bit/dim 1.0971(1.0994) | Xent 0.0317(0.0339) | Loss 1.1130(1.1163) | Error 0.0106(0.0105) Steps 446(446.32) | Grad Norm 0.3925(2.0480) | Total Time 10.00(10.00)\n",
      "Iter 4780 | Time 31.7406(31.6014) | Bit/dim 1.0985(1.0994) | Xent 0.0333(0.0339) | Loss 1.1151(1.1163) | Error 0.0108(0.0105) Steps 446(446.31) | Grad Norm 0.3769(1.9978) | Total Time 10.00(10.00)\n",
      "Iter 4781 | Time 31.7635(31.6063) | Bit/dim 1.0967(1.0993) | Xent 0.0305(0.0338) | Loss 1.1119(1.1162) | Error 0.0091(0.0105) Steps 452(446.48) | Grad Norm 0.3850(1.9494) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0683 | Time 17.2664, Epoch Time 250.0803(250.2922), Bit/dim 1.0926(best: 1.0925), Xent 0.0273, Loss 1.1063, Error 0.0088(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4782 | Time 31.8293(31.6129) | Bit/dim 1.0972(1.0992) | Xent 0.0391(0.0340) | Loss 1.1167(1.1162) | Error 0.0119(0.0105) Steps 446(446.47) | Grad Norm 0.3217(1.9006) | Total Time 10.00(10.00)\n",
      "Iter 4783 | Time 31.1549(31.5992) | Bit/dim 1.0972(1.0992) | Xent 0.0320(0.0339) | Loss 1.1132(1.1161) | Error 0.0102(0.0105) Steps 446(446.46) | Grad Norm 0.7671(1.8666) | Total Time 10.00(10.00)\n",
      "Iter 4784 | Time 32.8721(31.6374) | Bit/dim 1.1027(1.0993) | Xent 0.0337(0.0339) | Loss 1.1196(1.1162) | Error 0.0109(0.0105) Steps 446(446.44) | Grad Norm 0.8362(1.8357) | Total Time 10.00(10.00)\n",
      "Iter 4785 | Time 30.9019(31.6153) | Bit/dim 1.1010(1.0993) | Xent 0.0341(0.0339) | Loss 1.1180(1.1163) | Error 0.0108(0.0106) Steps 446(446.43) | Grad Norm 0.5750(1.7979) | Total Time 10.00(10.00)\n",
      "Iter 4786 | Time 30.7833(31.5904) | Bit/dim 1.0973(1.0993) | Xent 0.0336(0.0339) | Loss 1.1141(1.1162) | Error 0.0104(0.0105) Steps 446(446.42) | Grad Norm 0.2937(1.7527) | Total Time 10.00(10.00)\n",
      "Iter 4787 | Time 31.6197(31.5912) | Bit/dim 1.0991(1.0992) | Xent 0.0362(0.0340) | Loss 1.1172(1.1162) | Error 0.0112(0.0106) Steps 446(446.40) | Grad Norm 0.7714(1.7233) | Total Time 10.00(10.00)\n",
      "Iter 4788 | Time 31.7008(31.5945) | Bit/dim 1.0950(1.0991) | Xent 0.0338(0.0340) | Loss 1.1119(1.1161) | Error 0.0120(0.0106) Steps 446(446.39) | Grad Norm 0.2746(1.6798) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0684 | Time 17.1317, Epoch Time 250.5468(250.2998), Bit/dim 1.0929(best: 1.0925), Xent 0.0265, Loss 1.1061, Error 0.0092(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4789 | Time 31.9233(31.6044) | Bit/dim 1.0971(1.0991) | Xent 0.0348(0.0340) | Loss 1.1145(1.1161) | Error 0.0110(0.0106) Steps 446(446.38) | Grad Norm 0.6404(1.6487) | Total Time 10.00(10.00)\n",
      "Iter 4790 | Time 31.7702(31.6094) | Bit/dim 1.0990(1.0991) | Xent 0.0371(0.0341) | Loss 1.1176(1.1161) | Error 0.0110(0.0106) Steps 446(446.37) | Grad Norm 0.6013(1.6172) | Total Time 10.00(10.00)\n",
      "Iter 4791 | Time 31.7944(31.6149) | Bit/dim 1.0928(1.0989) | Xent 0.0304(0.0340) | Loss 1.1081(1.1159) | Error 0.0100(0.0106) Steps 446(446.36) | Grad Norm 0.2928(1.5775) | Total Time 10.00(10.00)\n",
      "Iter 4792 | Time 32.1970(31.6324) | Bit/dim 1.1014(1.0989) | Xent 0.0351(0.0340) | Loss 1.1190(1.1159) | Error 0.0104(0.0106) Steps 446(446.35) | Grad Norm 1.0516(1.5617) | Total Time 10.00(10.00)\n",
      "Iter 4793 | Time 32.1278(31.6472) | Bit/dim 1.0994(1.0990) | Xent 0.0363(0.0341) | Loss 1.1176(1.1160) | Error 0.0109(0.0106) Steps 446(446.34) | Grad Norm 1.1308(1.5488) | Total Time 10.00(10.00)\n",
      "Iter 4794 | Time 33.6450(31.7072) | Bit/dim 1.0995(1.0990) | Xent 0.0306(0.0340) | Loss 1.1148(1.1160) | Error 0.0088(0.0106) Steps 446(446.33) | Grad Norm 0.3586(1.5131) | Total Time 10.00(10.00)\n",
      "Iter 4795 | Time 31.9910(31.7157) | Bit/dim 1.0996(1.0990) | Xent 0.0328(0.0339) | Loss 1.1160(1.1160) | Error 0.0108(0.0106) Steps 446(446.32) | Grad Norm 1.2128(1.5041) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0685 | Time 17.0821, Epoch Time 255.1303(250.4447), Bit/dim 1.0924(best: 1.0925), Xent 0.0281, Loss 1.1065, Error 0.0094(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4796 | Time 32.5718(31.7414) | Bit/dim 1.0923(1.0988) | Xent 0.0335(0.0339) | Loss 1.1091(1.1158) | Error 0.0096(0.0105) Steps 446(446.31) | Grad Norm 0.4664(1.4730) | Total Time 10.00(10.00)\n",
      "Iter 4797 | Time 31.1571(31.7238) | Bit/dim 1.0965(1.0987) | Xent 0.0290(0.0338) | Loss 1.1110(1.1156) | Error 0.0101(0.0105) Steps 446(446.30) | Grad Norm 1.1086(1.4620) | Total Time 10.00(10.00)\n",
      "Iter 4798 | Time 31.2605(31.7099) | Bit/dim 1.0983(1.0987) | Xent 0.0338(0.0338) | Loss 1.1152(1.1156) | Error 0.0114(0.0105) Steps 446(446.29) | Grad Norm 1.7513(1.4707) | Total Time 10.00(10.00)\n",
      "Iter 4799 | Time 31.4585(31.7024) | Bit/dim 1.0984(1.0987) | Xent 0.0306(0.0337) | Loss 1.1137(1.1155) | Error 0.0098(0.0105) Steps 446(446.28) | Grad Norm 0.9477(1.4550) | Total Time 10.00(10.00)\n",
      "Iter 4800 | Time 31.4584(31.6951) | Bit/dim 1.0992(1.0987) | Xent 0.0331(0.0337) | Loss 1.1157(1.1155) | Error 0.0096(0.0105) Steps 452(446.45) | Grad Norm 0.8883(1.4380) | Total Time 10.00(10.00)\n",
      "Iter 4801 | Time 31.9071(31.7014) | Bit/dim 1.1045(1.0989) | Xent 0.0310(0.0336) | Loss 1.1201(1.1157) | Error 0.0100(0.0105) Steps 446(446.44) | Grad Norm 1.0384(1.4260) | Total Time 10.00(10.00)\n",
      "Iter 4802 | Time 31.3681(31.6914) | Bit/dim 1.1025(1.0990) | Xent 0.0376(0.0337) | Loss 1.1213(1.1159) | Error 0.0115(0.0105) Steps 446(446.42) | Grad Norm 0.6523(1.4028) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0686 | Time 17.2500, Epoch Time 250.9652(250.4603), Bit/dim 1.0935(best: 1.0924), Xent 0.0280, Loss 1.1075, Error 0.0093(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4803 | Time 31.1304(31.6746) | Bit/dim 1.1009(1.0991) | Xent 0.0358(0.0338) | Loss 1.1188(1.1159) | Error 0.0110(0.0105) Steps 452(446.59) | Grad Norm 1.1807(1.3961) | Total Time 10.00(10.00)\n",
      "Iter 4804 | Time 31.6671(31.6744) | Bit/dim 1.0996(1.0991) | Xent 0.0311(0.0337) | Loss 1.1152(1.1159) | Error 0.0096(0.0105) Steps 446(446.57) | Grad Norm 0.3883(1.3659) | Total Time 10.00(10.00)\n",
      "Iter 4805 | Time 31.0028(31.6542) | Bit/dim 1.0983(1.0990) | Xent 0.0330(0.0337) | Loss 1.1148(1.1159) | Error 0.0099(0.0105) Steps 452(446.74) | Grad Norm 1.3829(1.3664) | Total Time 10.00(10.00)\n",
      "Iter 4806 | Time 32.6359(31.6837) | Bit/dim 1.0957(1.0989) | Xent 0.0287(0.0335) | Loss 1.1101(1.1157) | Error 0.0085(0.0104) Steps 446(446.71) | Grad Norm 1.0180(1.3560) | Total Time 10.00(10.00)\n",
      "Iter 4807 | Time 33.3629(31.7341) | Bit/dim 1.0988(1.0989) | Xent 0.0321(0.0335) | Loss 1.1149(1.1157) | Error 0.0104(0.0104) Steps 446(446.69) | Grad Norm 0.5026(1.3304) | Total Time 10.00(10.00)\n",
      "Iter 4808 | Time 31.4722(31.7262) | Bit/dim 1.1005(1.0990) | Xent 0.0341(0.0335) | Loss 1.1175(1.1157) | Error 0.0101(0.0104) Steps 446(446.67) | Grad Norm 1.0368(1.3216) | Total Time 10.00(10.00)\n",
      "Iter 4809 | Time 31.3901(31.7161) | Bit/dim 1.0992(1.0990) | Xent 0.0338(0.0335) | Loss 1.1161(1.1158) | Error 0.0110(0.0104) Steps 446(446.65) | Grad Norm 1.3089(1.3212) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0687 | Time 16.9087, Epoch Time 252.0296(250.5074), Bit/dim 1.0930(best: 1.0924), Xent 0.0301, Loss 1.1081, Error 0.0107(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4810 | Time 31.1234(31.6983) | Bit/dim 1.1014(1.0991) | Xent 0.0316(0.0335) | Loss 1.1172(1.1158) | Error 0.0114(0.0105) Steps 446(446.63) | Grad Norm 0.7278(1.3034) | Total Time 10.00(10.00)\n",
      "Iter 4811 | Time 31.4936(31.6922) | Bit/dim 1.1022(1.0992) | Xent 0.0351(0.0335) | Loss 1.1198(1.1159) | Error 0.0116(0.0105) Steps 446(446.61) | Grad Norm 0.6936(1.2851) | Total Time 10.00(10.00)\n",
      "Iter 4812 | Time 31.0836(31.6739) | Bit/dim 1.0969(1.0991) | Xent 0.0347(0.0335) | Loss 1.1143(1.1159) | Error 0.0094(0.0105) Steps 446(446.60) | Grad Norm 1.4671(1.2905) | Total Time 10.00(10.00)\n",
      "Iter 4813 | Time 31.1299(31.6576) | Bit/dim 1.0952(1.0990) | Xent 0.0331(0.0335) | Loss 1.1117(1.1157) | Error 0.0100(0.0104) Steps 446(446.58) | Grad Norm 1.2298(1.2887) | Total Time 10.00(10.00)\n",
      "Iter 4814 | Time 32.5209(31.6835) | Bit/dim 1.0988(1.0990) | Xent 0.0315(0.0335) | Loss 1.1146(1.1157) | Error 0.0102(0.0104) Steps 446(446.56) | Grad Norm 0.8058(1.2742) | Total Time 10.00(10.00)\n",
      "Iter 4815 | Time 31.6988(31.6840) | Bit/dim 1.0987(1.0990) | Xent 0.0316(0.0334) | Loss 1.1145(1.1157) | Error 0.0094(0.0104) Steps 446(446.54) | Grad Norm 2.6979(1.3170) | Total Time 10.00(10.00)\n",
      "Iter 4816 | Time 31.7462(31.6858) | Bit/dim 1.0959(1.0989) | Xent 0.0345(0.0334) | Loss 1.1132(1.1156) | Error 0.0110(0.0104) Steps 446(446.53) | Grad Norm 1.5130(1.3228) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0688 | Time 16.9711, Epoch Time 250.2795(250.5006), Bit/dim 1.0930(best: 1.0924), Xent 0.0275, Loss 1.1067, Error 0.0096(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4817 | Time 31.1804(31.6707) | Bit/dim 1.0999(1.0989) | Xent 0.0332(0.0334) | Loss 1.1165(1.1156) | Error 0.0102(0.0104) Steps 446(446.51) | Grad Norm 2.0843(1.3457) | Total Time 10.00(10.00)\n",
      "Iter 4818 | Time 31.5048(31.6657) | Bit/dim 1.0982(1.0989) | Xent 0.0304(0.0333) | Loss 1.1134(1.1156) | Error 0.0098(0.0104) Steps 446(446.50) | Grad Norm 2.9459(1.3937) | Total Time 10.00(10.00)\n",
      "Iter 4819 | Time 33.1410(31.7100) | Bit/dim 1.1014(1.0990) | Xent 0.0383(0.0335) | Loss 1.1205(1.1157) | Error 0.0116(0.0104) Steps 446(446.48) | Grad Norm 0.3829(1.3634) | Total Time 10.00(10.00)\n",
      "Iter 4820 | Time 31.7535(31.7113) | Bit/dim 1.0972(1.0989) | Xent 0.0315(0.0334) | Loss 1.1129(1.1156) | Error 0.0092(0.0104) Steps 446(446.47) | Grad Norm 3.3822(1.4239) | Total Time 10.00(10.00)\n",
      "Iter 4821 | Time 33.0336(31.7509) | Bit/dim 1.0986(1.0989) | Xent 0.0362(0.0335) | Loss 1.1167(1.1156) | Error 0.0109(0.0104) Steps 446(446.45) | Grad Norm 2.4351(1.4543) | Total Time 10.00(10.00)\n",
      "Iter 4822 | Time 31.3250(31.7382) | Bit/dim 1.0920(1.0987) | Xent 0.0348(0.0335) | Loss 1.1094(1.1155) | Error 0.0108(0.0104) Steps 452(446.62) | Grad Norm 1.3679(1.4517) | Total Time 10.00(10.00)\n",
      "Iter 4823 | Time 30.8859(31.7126) | Bit/dim 1.0960(1.0986) | Xent 0.0303(0.0334) | Loss 1.1112(1.1153) | Error 0.0094(0.0104) Steps 446(446.60) | Grad Norm 3.5515(1.5147) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0689 | Time 17.3796, Epoch Time 252.7169(250.5671), Bit/dim 1.0928(best: 1.0924), Xent 0.0270, Loss 1.1062, Error 0.0081(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4824 | Time 31.1715(31.6964) | Bit/dim 1.0969(1.0986) | Xent 0.0262(0.0332) | Loss 1.1100(1.1152) | Error 0.0084(0.0103) Steps 446(446.58) | Grad Norm 2.0077(1.5295) | Total Time 10.00(10.00)\n",
      "Iter 4825 | Time 32.5508(31.7220) | Bit/dim 1.1027(1.0987) | Xent 0.0235(0.0329) | Loss 1.1144(1.1151) | Error 0.0066(0.0102) Steps 446(446.56) | Grad Norm 1.8607(1.5394) | Total Time 10.00(10.00)\n",
      "Iter 4826 | Time 31.4913(31.7151) | Bit/dim 1.1029(1.0988) | Xent 0.0421(0.0332) | Loss 1.1239(1.1154) | Error 0.0122(0.0103) Steps 446(446.55) | Grad Norm 3.8634(1.6091) | Total Time 10.00(10.00)\n",
      "Iter 4827 | Time 31.5480(31.7101) | Bit/dim 1.0956(1.0987) | Xent 0.0333(0.0332) | Loss 1.1123(1.1153) | Error 0.0104(0.0103) Steps 446(446.53) | Grad Norm 1.3748(1.6021) | Total Time 10.00(10.00)\n",
      "Iter 4828 | Time 31.3611(31.6996) | Bit/dim 1.1006(1.0988) | Xent 0.0400(0.0334) | Loss 1.1206(1.1155) | Error 0.0114(0.0103) Steps 446(446.52) | Grad Norm 2.9446(1.6424) | Total Time 10.00(10.00)\n",
      "Iter 4829 | Time 31.6354(31.6977) | Bit/dim 1.0946(1.0986) | Xent 0.0321(0.0334) | Loss 1.1107(1.1153) | Error 0.0089(0.0103) Steps 446(446.50) | Grad Norm 3.6610(1.7029) | Total Time 10.00(10.00)\n",
      "Iter 4830 | Time 31.3086(31.6860) | Bit/dim 1.0980(1.0986) | Xent 0.0315(0.0333) | Loss 1.1137(1.1153) | Error 0.0099(0.0103) Steps 446(446.49) | Grad Norm 0.4086(1.6641) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0690 | Time 17.1651, Epoch Time 250.6270(250.5689), Bit/dim 1.0932(best: 1.0924), Xent 0.0275, Loss 1.1070, Error 0.0099(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4831 | Time 31.6746(31.6856) | Bit/dim 1.1000(1.0987) | Xent 0.0322(0.0333) | Loss 1.1161(1.1153) | Error 0.0102(0.0103) Steps 446(446.47) | Grad Norm 2.4386(1.6873) | Total Time 10.00(10.00)\n",
      "Iter 4832 | Time 32.3756(31.7063) | Bit/dim 1.0987(1.0987) | Xent 0.0355(0.0334) | Loss 1.1164(1.1153) | Error 0.0105(0.0103) Steps 446(446.46) | Grad Norm 1.1827(1.6722) | Total Time 10.00(10.00)\n",
      "Iter 4833 | Time 31.6567(31.7049) | Bit/dim 1.0972(1.0986) | Xent 0.0325(0.0333) | Loss 1.1134(1.1153) | Error 0.0086(0.0102) Steps 446(446.44) | Grad Norm 2.5129(1.6974) | Total Time 10.00(10.00)\n",
      "Iter 4834 | Time 31.7953(31.7076) | Bit/dim 1.0941(1.0985) | Xent 0.0359(0.0334) | Loss 1.1121(1.1152) | Error 0.0098(0.0102) Steps 446(446.43) | Grad Norm 3.5876(1.7541) | Total Time 10.00(10.00)\n",
      "Iter 4835 | Time 31.7624(31.7092) | Bit/dim 1.0968(1.0984) | Xent 0.0331(0.0334) | Loss 1.1133(1.1151) | Error 0.0096(0.0102) Steps 452(446.60) | Grad Norm 0.4939(1.7163) | Total Time 10.00(10.00)\n",
      "Iter 4836 | Time 32.9036(31.7450) | Bit/dim 1.0965(1.0984) | Xent 0.0367(0.0335) | Loss 1.1149(1.1151) | Error 0.0121(0.0102) Steps 446(446.58) | Grad Norm 2.8863(1.7514) | Total Time 10.00(10.00)\n",
      "Iter 4837 | Time 31.0120(31.7231) | Bit/dim 1.1006(1.0984) | Xent 0.0325(0.0335) | Loss 1.1168(1.1152) | Error 0.0108(0.0103) Steps 446(446.56) | Grad Norm 2.1864(1.7645) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0691 | Time 17.0951, Epoch Time 252.8262(250.6366), Bit/dim 1.0929(best: 1.0924), Xent 0.0296, Loss 1.1077, Error 0.0093(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4838 | Time 32.5845(31.7489) | Bit/dim 1.1019(1.0985) | Xent 0.0344(0.0335) | Loss 1.1191(1.1153) | Error 0.0109(0.0103) Steps 446(446.54) | Grad Norm 1.8882(1.7682) | Total Time 10.00(10.00)\n",
      "Iter 4839 | Time 32.8836(31.7829) | Bit/dim 1.0971(1.0985) | Xent 0.0388(0.0337) | Loss 1.1165(1.1153) | Error 0.0124(0.0103) Steps 446(446.53) | Grad Norm 4.3562(1.8458) | Total Time 10.00(10.00)\n",
      "Iter 4840 | Time 31.2706(31.7676) | Bit/dim 1.1035(1.0986) | Xent 0.0301(0.0335) | Loss 1.1185(1.1154) | Error 0.0106(0.0104) Steps 446(446.51) | Grad Norm 2.5006(1.8654) | Total Time 10.00(10.00)\n",
      "Iter 4841 | Time 32.4909(31.7893) | Bit/dim 1.1014(1.0987) | Xent 0.0364(0.0336) | Loss 1.1196(1.1155) | Error 0.0109(0.0104) Steps 446(446.50) | Grad Norm 1.2906(1.8482) | Total Time 10.00(10.00)\n",
      "Iter 4842 | Time 31.3678(31.7766) | Bit/dim 1.0924(1.0985) | Xent 0.0369(0.0337) | Loss 1.1108(1.1154) | Error 0.0124(0.0104) Steps 446(446.48) | Grad Norm 2.6646(1.8727) | Total Time 10.00(10.00)\n",
      "Iter 4843 | Time 32.0289(31.7842) | Bit/dim 1.0981(1.0985) | Xent 0.0286(0.0336) | Loss 1.1124(1.1153) | Error 0.0081(0.0104) Steps 446(446.47) | Grad Norm 0.7990(1.8405) | Total Time 10.00(10.00)\n",
      "Iter 4844 | Time 31.2845(31.7692) | Bit/dim 1.0964(1.0985) | Xent 0.0368(0.0337) | Loss 1.1148(1.1153) | Error 0.0110(0.0104) Steps 446(446.45) | Grad Norm 1.6151(1.8337) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0692 | Time 17.5289, Epoch Time 253.8959(250.7344), Bit/dim 1.0924(best: 1.0924), Xent 0.0278, Loss 1.1063, Error 0.0096(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4845 | Time 31.1195(31.7497) | Bit/dim 1.0967(1.0984) | Xent 0.0332(0.0337) | Loss 1.1133(1.1152) | Error 0.0104(0.0104) Steps 446(446.44) | Grad Norm 2.3147(1.8482) | Total Time 10.00(10.00)\n",
      "Iter 4846 | Time 31.1519(31.7318) | Bit/dim 1.0961(1.0983) | Xent 0.0366(0.0337) | Loss 1.1144(1.1152) | Error 0.0119(0.0104) Steps 446(446.43) | Grad Norm 1.1673(1.8277) | Total Time 10.00(10.00)\n",
      "Iter 4847 | Time 31.7265(31.7316) | Bit/dim 1.0977(1.0983) | Xent 0.0303(0.0336) | Loss 1.1129(1.1151) | Error 0.0085(0.0104) Steps 446(446.41) | Grad Norm 0.9582(1.8016) | Total Time 10.00(10.00)\n",
      "Iter 4848 | Time 31.7677(31.7327) | Bit/dim 1.1001(1.0984) | Xent 0.0367(0.0337) | Loss 1.1184(1.1152) | Error 0.0110(0.0104) Steps 446(446.40) | Grad Norm 1.6767(1.7979) | Total Time 10.00(10.00)\n",
      "Iter 4849 | Time 31.1067(31.7139) | Bit/dim 1.0984(1.0984) | Xent 0.0316(0.0337) | Loss 1.1142(1.1152) | Error 0.0088(0.0103) Steps 446(446.39) | Grad Norm 0.3888(1.7556) | Total Time 10.00(10.00)\n",
      "Iter 4850 | Time 33.2454(31.7599) | Bit/dim 1.1019(1.0985) | Xent 0.0317(0.0336) | Loss 1.1177(1.1153) | Error 0.0100(0.0103) Steps 446(446.38) | Grad Norm 1.6481(1.7524) | Total Time 10.00(10.00)\n",
      "Iter 4851 | Time 31.3819(31.7485) | Bit/dim 1.1007(1.0985) | Xent 0.0355(0.0337) | Loss 1.1184(1.1154) | Error 0.0095(0.0103) Steps 446(446.37) | Grad Norm 1.7722(1.7530) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0693 | Time 17.2837, Epoch Time 251.1998(250.7483), Bit/dim 1.0933(best: 1.0924), Xent 0.0310, Loss 1.1088, Error 0.0097(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4852 | Time 31.5001(31.7411) | Bit/dim 1.0941(1.0984) | Xent 0.0330(0.0336) | Loss 1.1106(1.1152) | Error 0.0105(0.0103) Steps 446(446.36) | Grad Norm 0.4731(1.7146) | Total Time 10.00(10.00)\n",
      "Iter 4853 | Time 31.7365(31.7409) | Bit/dim 1.0988(1.0984) | Xent 0.0344(0.0337) | Loss 1.1160(1.1153) | Error 0.0116(0.0103) Steps 446(446.34) | Grad Norm 1.3050(1.7023) | Total Time 10.00(10.00)\n",
      "Iter 4854 | Time 31.3972(31.7306) | Bit/dim 1.1005(1.0985) | Xent 0.0310(0.0336) | Loss 1.1160(1.1153) | Error 0.0078(0.0103) Steps 452(446.51) | Grad Norm 1.3912(1.6930) | Total Time 10.00(10.00)\n",
      "Iter 4855 | Time 32.0425(31.7400) | Bit/dim 1.0988(1.0985) | Xent 0.0373(0.0337) | Loss 1.1175(1.1153) | Error 0.0114(0.0103) Steps 446(446.50) | Grad Norm 0.3809(1.6536) | Total Time 10.00(10.00)\n",
      "Iter 4856 | Time 31.4727(31.7320) | Bit/dim 1.0964(1.0984) | Xent 0.0342(0.0337) | Loss 1.1135(1.1153) | Error 0.0096(0.0103) Steps 446(446.48) | Grad Norm 1.0414(1.6352) | Total Time 10.00(10.00)\n",
      "Iter 4857 | Time 31.7106(31.7313) | Bit/dim 1.0999(1.0985) | Xent 0.0310(0.0336) | Loss 1.1154(1.1153) | Error 0.0085(0.0102) Steps 452(446.65) | Grad Norm 0.3689(1.5973) | Total Time 10.00(10.00)\n",
      "Iter 4858 | Time 32.5734(31.7566) | Bit/dim 1.0946(1.0984) | Xent 0.0297(0.0335) | Loss 1.1095(1.1151) | Error 0.0098(0.0102) Steps 446(446.63) | Grad Norm 1.0770(1.5816) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0694 | Time 17.2228, Epoch Time 252.1466(250.7903), Bit/dim 1.0923(best: 1.0924), Xent 0.0292, Loss 1.1068, Error 0.0091(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4859 | Time 32.7068(31.7851) | Bit/dim 1.0982(1.0984) | Xent 0.0334(0.0335) | Loss 1.1149(1.1151) | Error 0.0105(0.0102) Steps 446(446.61) | Grad Norm 0.7473(1.5566) | Total Time 10.00(10.00)\n",
      "Iter 4860 | Time 31.1766(31.7668) | Bit/dim 1.0966(1.0983) | Xent 0.0300(0.0334) | Loss 1.1116(1.1150) | Error 0.0090(0.0102) Steps 446(446.59) | Grad Norm 0.8689(1.5360) | Total Time 10.00(10.00)\n",
      "Iter 4861 | Time 31.2341(31.7509) | Bit/dim 1.0991(1.0983) | Xent 0.0290(0.0333) | Loss 1.1136(1.1150) | Error 0.0089(0.0101) Steps 446(446.58) | Grad Norm 2.1826(1.5554) | Total Time 10.00(10.00)\n",
      "Iter 4862 | Time 31.3349(31.7384) | Bit/dim 1.0934(1.0982) | Xent 0.0339(0.0333) | Loss 1.1103(1.1148) | Error 0.0094(0.0101) Steps 446(446.56) | Grad Norm 1.3849(1.5503) | Total Time 10.00(10.00)\n",
      "Iter 4863 | Time 31.4785(31.7306) | Bit/dim 1.0988(1.0982) | Xent 0.0295(0.0332) | Loss 1.1136(1.1148) | Error 0.0085(0.0101) Steps 446(446.54) | Grad Norm 0.6678(1.5238) | Total Time 10.00(10.00)\n",
      "Iter 4864 | Time 31.0550(31.7103) | Bit/dim 1.0995(1.0982) | Xent 0.0362(0.0333) | Loss 1.1176(1.1149) | Error 0.0111(0.0101) Steps 446(446.52) | Grad Norm 1.4559(1.5218) | Total Time 10.00(10.00)\n",
      "Iter 4865 | Time 31.1902(31.6947) | Bit/dim 1.1027(1.0984) | Xent 0.0287(0.0331) | Loss 1.1171(1.1149) | Error 0.0089(0.0101) Steps 446(446.51) | Grad Norm 1.1514(1.5106) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0695 | Time 17.1269, Epoch Time 249.7272(250.7584), Bit/dim 1.0917(best: 1.0923), Xent 0.0286, Loss 1.1060, Error 0.0101(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4866 | Time 31.6589(31.6936) | Bit/dim 1.1020(1.0985) | Xent 0.0331(0.0331) | Loss 1.1185(1.1150) | Error 0.0115(0.0101) Steps 446(446.49) | Grad Norm 0.4192(1.4779) | Total Time 10.00(10.00)\n",
      "Iter 4867 | Time 32.1275(31.7066) | Bit/dim 1.0975(1.0984) | Xent 0.0300(0.0330) | Loss 1.1125(1.1150) | Error 0.0094(0.0101) Steps 446(446.48) | Grad Norm 0.8416(1.4588) | Total Time 10.00(10.00)\n",
      "Iter 4868 | Time 31.7598(31.7082) | Bit/dim 1.0985(1.0985) | Xent 0.0305(0.0330) | Loss 1.1138(1.1149) | Error 0.0101(0.0101) Steps 446(446.46) | Grad Norm 1.2446(1.4524) | Total Time 10.00(10.00)\n",
      "Iter 4869 | Time 32.3186(31.7266) | Bit/dim 1.1005(1.0985) | Xent 0.0311(0.0329) | Loss 1.1161(1.1150) | Error 0.0095(0.0101) Steps 446(446.45) | Grad Norm 0.4189(1.4214) | Total Time 10.00(10.00)\n",
      "Iter 4870 | Time 33.5979(31.7827) | Bit/dim 1.0956(1.0984) | Xent 0.0371(0.0330) | Loss 1.1141(1.1149) | Error 0.0109(0.0101) Steps 446(446.44) | Grad Norm 0.9080(1.4060) | Total Time 10.00(10.00)\n",
      "Iter 4871 | Time 31.9599(31.7880) | Bit/dim 1.0972(1.0984) | Xent 0.0348(0.0331) | Loss 1.1146(1.1149) | Error 0.0120(0.0102) Steps 452(446.60) | Grad Norm 1.0954(1.3967) | Total Time 10.00(10.00)\n",
      "Iter 4872 | Time 31.4113(31.7767) | Bit/dim 1.0968(1.0983) | Xent 0.0338(0.0331) | Loss 1.1137(1.1149) | Error 0.0101(0.0102) Steps 446(446.59) | Grad Norm 0.3363(1.3649) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0696 | Time 17.4108, Epoch Time 255.1558(250.8903), Bit/dim 1.0919(best: 1.0917), Xent 0.0265, Loss 1.1052, Error 0.0090(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4873 | Time 31.4967(31.7683) | Bit/dim 1.0940(1.0982) | Xent 0.0295(0.0330) | Loss 1.1088(1.1147) | Error 0.0090(0.0101) Steps 446(446.57) | Grad Norm 0.8092(1.3482) | Total Time 10.00(10.00)\n",
      "Iter 4874 | Time 33.2929(31.8140) | Bit/dim 1.0991(1.0982) | Xent 0.0321(0.0330) | Loss 1.1151(1.1147) | Error 0.0095(0.0101) Steps 446(446.55) | Grad Norm 1.0251(1.3385) | Total Time 10.00(10.00)\n",
      "Iter 4875 | Time 32.0865(31.8222) | Bit/dim 1.0987(1.0983) | Xent 0.0343(0.0330) | Loss 1.1158(1.1148) | Error 0.0114(0.0101) Steps 446(446.53) | Grad Norm 0.7496(1.3208) | Total Time 10.00(10.00)\n",
      "Iter 4876 | Time 31.5987(31.8155) | Bit/dim 1.1007(1.0983) | Xent 0.0265(0.0328) | Loss 1.1140(1.1147) | Error 0.0089(0.0101) Steps 446(446.52) | Grad Norm 0.4134(1.2936) | Total Time 10.00(10.00)\n",
      "Iter 4877 | Time 31.6392(31.8102) | Bit/dim 1.0989(1.0983) | Xent 0.0338(0.0329) | Loss 1.1158(1.1148) | Error 0.0116(0.0101) Steps 446(446.50) | Grad Norm 1.1022(1.2879) | Total Time 10.00(10.00)\n",
      "Iter 4878 | Time 30.9723(31.7851) | Bit/dim 1.0934(1.0982) | Xent 0.0311(0.0328) | Loss 1.1090(1.1146) | Error 0.0082(0.0101) Steps 446(446.49) | Grad Norm 0.7214(1.2709) | Total Time 10.00(10.00)\n",
      "Iter 4879 | Time 31.6443(31.7809) | Bit/dim 1.1008(1.0983) | Xent 0.0334(0.0328) | Loss 1.1175(1.1147) | Error 0.0109(0.0101) Steps 446(446.47) | Grad Norm 0.6097(1.2510) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0697 | Time 17.0471, Epoch Time 252.2071(250.9298), Bit/dim 1.0927(best: 1.0917), Xent 0.0286, Loss 1.1070, Error 0.0102(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4880 | Time 33.0110(31.8178) | Bit/dim 1.0919(1.0981) | Xent 0.0290(0.0327) | Loss 1.1064(1.1144) | Error 0.0084(0.0101) Steps 446(446.46) | Grad Norm 1.3993(1.2555) | Total Time 10.00(10.00)\n",
      "Iter 4881 | Time 31.7356(31.8153) | Bit/dim 1.1014(1.0982) | Xent 0.0346(0.0328) | Loss 1.1187(1.1146) | Error 0.0109(0.0101) Steps 446(446.45) | Grad Norm 1.2881(1.2565) | Total Time 10.00(10.00)\n",
      "Iter 4882 | Time 32.8710(31.8470) | Bit/dim 1.0998(1.0982) | Xent 0.0379(0.0329) | Loss 1.1188(1.1147) | Error 0.0109(0.0101) Steps 446(446.43) | Grad Norm 0.4470(1.2322) | Total Time 10.00(10.00)\n",
      "Iter 4883 | Time 31.9941(31.8514) | Bit/dim 1.0965(1.0982) | Xent 0.0304(0.0328) | Loss 1.1117(1.1146) | Error 0.0095(0.0101) Steps 446(446.42) | Grad Norm 0.3398(1.2054) | Total Time 10.00(10.00)\n",
      "Iter 4884 | Time 31.8009(31.8499) | Bit/dim 1.1003(1.0982) | Xent 0.0348(0.0329) | Loss 1.1177(1.1147) | Error 0.0122(0.0102) Steps 452(446.59) | Grad Norm 0.4047(1.1814) | Total Time 10.00(10.00)\n",
      "Iter 4885 | Time 32.0417(31.8556) | Bit/dim 1.0998(1.0983) | Xent 0.0307(0.0328) | Loss 1.1152(1.1147) | Error 0.0090(0.0101) Steps 446(446.57) | Grad Norm 1.2407(1.1832) | Total Time 10.00(10.00)\n",
      "Iter 4886 | Time 32.8166(31.8845) | Bit/dim 1.0935(1.0981) | Xent 0.0304(0.0328) | Loss 1.1087(1.1145) | Error 0.0090(0.0101) Steps 452(446.73) | Grad Norm 1.2904(1.1864) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0698 | Time 17.3268, Epoch Time 256.1473(251.0863), Bit/dim 1.0933(best: 1.0917), Xent 0.0309, Loss 1.1087, Error 0.0102(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4887 | Time 31.2867(31.8665) | Bit/dim 1.0976(1.0981) | Xent 0.0381(0.0329) | Loss 1.1166(1.1146) | Error 0.0125(0.0102) Steps 446(446.71) | Grad Norm 0.2966(1.1597) | Total Time 10.00(10.00)\n",
      "Iter 4888 | Time 32.4264(31.8833) | Bit/dim 1.0956(1.0981) | Xent 0.0334(0.0329) | Loss 1.1123(1.1145) | Error 0.0090(0.0101) Steps 446(446.69) | Grad Norm 1.2917(1.1636) | Total Time 10.00(10.00)\n",
      "Iter 4889 | Time 31.3994(31.8688) | Bit/dim 1.0962(1.0980) | Xent 0.0326(0.0329) | Loss 1.1125(1.1145) | Error 0.0094(0.0101) Steps 446(446.67) | Grad Norm 0.9803(1.1581) | Total Time 10.00(10.00)\n",
      "Iter 4890 | Time 31.5656(31.8597) | Bit/dim 1.0957(1.0979) | Xent 0.0396(0.0331) | Loss 1.1155(1.1145) | Error 0.0094(0.0101) Steps 446(446.65) | Grad Norm 0.6385(1.1426) | Total Time 10.00(10.00)\n",
      "Iter 4891 | Time 31.6602(31.8537) | Bit/dim 1.0991(1.0980) | Xent 0.0362(0.0332) | Loss 1.1173(1.1146) | Error 0.0116(0.0101) Steps 446(446.63) | Grad Norm 2.1255(1.1720) | Total Time 10.00(10.00)\n",
      "Iter 4892 | Time 31.2146(31.8345) | Bit/dim 1.0989(1.0980) | Xent 0.0286(0.0331) | Loss 1.1132(1.1145) | Error 0.0091(0.0101) Steps 446(446.61) | Grad Norm 2.1078(1.2001) | Total Time 10.00(10.00)\n",
      "Iter 4893 | Time 31.2330(31.8165) | Bit/dim 1.0999(1.0981) | Xent 0.0308(0.0330) | Loss 1.1153(1.1146) | Error 0.0095(0.0101) Steps 446(446.59) | Grad Norm 0.2747(1.1724) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0699 | Time 17.5990, Epoch Time 250.8407(251.0790), Bit/dim 1.0923(best: 1.0917), Xent 0.0274, Loss 1.1060, Error 0.0102(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4894 | Time 31.4600(31.8058) | Bit/dim 1.0954(1.0980) | Xent 0.0347(0.0331) | Loss 1.1127(1.1145) | Error 0.0114(0.0101) Steps 446(446.57) | Grad Norm 2.6772(1.2175) | Total Time 10.00(10.00)\n",
      "Iter 4895 | Time 31.9428(31.8099) | Bit/dim 1.1038(1.0981) | Xent 0.0290(0.0329) | Loss 1.1183(1.1146) | Error 0.0089(0.0101) Steps 446(446.56) | Grad Norm 2.6196(1.2596) | Total Time 10.00(10.00)\n",
      "Iter 4896 | Time 31.3475(31.7960) | Bit/dim 1.1002(1.0982) | Xent 0.0313(0.0329) | Loss 1.1159(1.1147) | Error 0.0099(0.0101) Steps 446(446.54) | Grad Norm 0.2938(1.2306) | Total Time 10.00(10.00)\n",
      "Iter 4897 | Time 31.5702(31.7893) | Bit/dim 1.0980(1.0982) | Xent 0.0272(0.0327) | Loss 1.1117(1.1146) | Error 0.0085(0.0100) Steps 446(446.52) | Grad Norm 2.4485(1.2671) | Total Time 10.00(10.00)\n",
      "Iter 4898 | Time 31.9257(31.7934) | Bit/dim 1.0986(1.0982) | Xent 0.0336(0.0327) | Loss 1.1154(1.1146) | Error 0.0101(0.0100) Steps 446(446.51) | Grad Norm 2.9795(1.3185) | Total Time 10.00(10.00)\n",
      "Iter 4899 | Time 31.6140(31.7880) | Bit/dim 1.0943(1.0981) | Xent 0.0381(0.0329) | Loss 1.1134(1.1146) | Error 0.0115(0.0101) Steps 446(446.49) | Grad Norm 1.7994(1.3329) | Total Time 10.00(10.00)\n",
      "Iter 4900 | Time 31.8616(31.7902) | Bit/dim 1.0947(1.0980) | Xent 0.0285(0.0328) | Loss 1.1090(1.1144) | Error 0.0088(0.0100) Steps 446(446.48) | Grad Norm 0.6071(1.3112) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0700 | Time 17.3227, Epoch Time 251.4875(251.0912), Bit/dim 1.0918(best: 1.0917), Xent 0.0272, Loss 1.1053, Error 0.0095(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4901 | Time 31.8330(31.7915) | Bit/dim 1.0937(1.0979) | Xent 0.0344(0.0328) | Loss 1.1109(1.1143) | Error 0.0111(0.0101) Steps 446(446.46) | Grad Norm 0.2854(1.2804) | Total Time 10.00(10.00)\n",
      "Iter 4902 | Time 31.1865(31.7733) | Bit/dim 1.0990(1.0979) | Xent 0.0352(0.0329) | Loss 1.1166(1.1143) | Error 0.0106(0.0101) Steps 446(446.45) | Grad Norm 0.4350(1.2550) | Total Time 10.00(10.00)\n",
      "Iter 4903 | Time 31.6495(31.7696) | Bit/dim 1.0975(1.0979) | Xent 0.0317(0.0329) | Loss 1.1134(1.1143) | Error 0.0098(0.0101) Steps 446(446.44) | Grad Norm 1.1270(1.2512) | Total Time 10.00(10.00)\n",
      "Iter 4904 | Time 31.6834(31.7670) | Bit/dim 1.0992(1.0979) | Xent 0.0343(0.0329) | Loss 1.1163(1.1144) | Error 0.0096(0.0101) Steps 452(446.60) | Grad Norm 1.6041(1.2618) | Total Time 10.00(10.00)\n",
      "Iter 4905 | Time 31.9522(31.7726) | Bit/dim 1.0985(1.0979) | Xent 0.0311(0.0328) | Loss 1.1140(1.1144) | Error 0.0082(0.0100) Steps 446(446.58) | Grad Norm 0.2679(1.2319) | Total Time 10.00(10.00)\n",
      "Iter 4906 | Time 31.4650(31.7633) | Bit/dim 1.0978(1.0979) | Xent 0.0366(0.0330) | Loss 1.1161(1.1144) | Error 0.0114(0.0100) Steps 446(446.57) | Grad Norm 2.0889(1.2577) | Total Time 10.00(10.00)\n",
      "Iter 4907 | Time 33.0566(31.8021) | Bit/dim 1.0987(1.0980) | Xent 0.0388(0.0331) | Loss 1.1180(1.1145) | Error 0.0129(0.0101) Steps 446(446.55) | Grad Norm 1.2624(1.2578) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0701 | Time 17.4163, Epoch Time 252.7489(251.1410), Bit/dim 1.0925(best: 1.0917), Xent 0.0287, Loss 1.1068, Error 0.0099(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4908 | Time 31.7580(31.8008) | Bit/dim 1.0963(1.0979) | Xent 0.0296(0.0330) | Loss 1.1111(1.1144) | Error 0.0094(0.0101) Steps 452(446.71) | Grad Norm 1.7676(1.2731) | Total Time 10.00(10.00)\n",
      "Iter 4909 | Time 31.2926(31.7856) | Bit/dim 1.0986(1.0979) | Xent 0.0322(0.0330) | Loss 1.1147(1.1144) | Error 0.0098(0.0101) Steps 446(446.69) | Grad Norm 3.7125(1.3463) | Total Time 10.00(10.00)\n",
      "Iter 4910 | Time 32.7910(31.8157) | Bit/dim 1.0936(1.0978) | Xent 0.0337(0.0330) | Loss 1.1105(1.1143) | Error 0.0104(0.0101) Steps 446(446.67) | Grad Norm 2.8556(1.3916) | Total Time 10.00(10.00)\n",
      "Iter 4911 | Time 32.0557(31.8229) | Bit/dim 1.1022(1.0979) | Xent 0.0333(0.0330) | Loss 1.1188(1.1145) | Error 0.0094(0.0101) Steps 446(446.65) | Grad Norm 0.3268(1.3596) | Total Time 10.00(10.00)\n",
      "Iter 4912 | Time 31.6254(31.8170) | Bit/dim 1.0985(1.0980) | Xent 0.0361(0.0331) | Loss 1.1166(1.1145) | Error 0.0121(0.0101) Steps 446(446.63) | Grad Norm 2.8919(1.4056) | Total Time 10.00(10.00)\n",
      "Iter 4913 | Time 32.2731(31.8307) | Bit/dim 1.1015(1.0981) | Xent 0.0283(0.0330) | Loss 1.1157(1.1146) | Error 0.0096(0.0101) Steps 446(446.61) | Grad Norm 3.0133(1.4538) | Total Time 10.00(10.00)\n",
      "Iter 4914 | Time 30.7617(31.7986) | Bit/dim 1.0980(1.0981) | Xent 0.0328(0.0330) | Loss 1.1144(1.1145) | Error 0.0106(0.0101) Steps 446(446.59) | Grad Norm 0.2914(1.4189) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0702 | Time 17.3468, Epoch Time 252.2482(251.1742), Bit/dim 1.0923(best: 1.0917), Xent 0.0270, Loss 1.1058, Error 0.0099(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4915 | Time 32.2748(31.8129) | Bit/dim 1.0993(1.0981) | Xent 0.0382(0.0331) | Loss 1.1184(1.1147) | Error 0.0119(0.0102) Steps 446(446.58) | Grad Norm 2.9445(1.4647) | Total Time 10.00(10.00)\n",
      "Iter 4916 | Time 32.7432(31.8408) | Bit/dim 1.0981(1.0981) | Xent 0.0296(0.0330) | Loss 1.1129(1.1146) | Error 0.0099(0.0102) Steps 446(446.56) | Grad Norm 3.3805(1.5222) | Total Time 10.00(10.00)\n",
      "Iter 4917 | Time 32.3890(31.8573) | Bit/dim 1.0921(1.0979) | Xent 0.0339(0.0331) | Loss 1.1091(1.1144) | Error 0.0109(0.0102) Steps 446(446.54) | Grad Norm 0.5950(1.4944) | Total Time 10.00(10.00)\n",
      "Iter 4918 | Time 31.1917(31.8373) | Bit/dim 1.0965(1.0979) | Xent 0.0288(0.0329) | Loss 1.1109(1.1143) | Error 0.0092(0.0102) Steps 446(446.53) | Grad Norm 2.8671(1.5356) | Total Time 10.00(10.00)\n",
      "Iter 4919 | Time 32.0898(31.8449) | Bit/dim 1.1017(1.0980) | Xent 0.0411(0.0332) | Loss 1.1222(1.1146) | Error 0.0124(0.0102) Steps 446(446.51) | Grad Norm 3.2213(1.5861) | Total Time 10.00(10.00)\n",
      "Iter 4920 | Time 31.5500(31.8360) | Bit/dim 1.0982(1.0980) | Xent 0.0301(0.0331) | Loss 1.1133(1.1145) | Error 0.0100(0.0102) Steps 446(446.50) | Grad Norm 0.4122(1.5509) | Total Time 10.00(10.00)\n",
      "Iter 4921 | Time 31.4365(31.8240) | Bit/dim 1.0977(1.0980) | Xent 0.0299(0.0330) | Loss 1.1126(1.1145) | Error 0.0085(0.0102) Steps 446(446.48) | Grad Norm 3.1925(1.6002) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0703 | Time 17.3999, Epoch Time 253.6316(251.2479), Bit/dim 1.0924(best: 1.0917), Xent 0.0265, Loss 1.1056, Error 0.0088(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4922 | Time 32.5622(31.8462) | Bit/dim 1.1001(1.0980) | Xent 0.0323(0.0330) | Loss 1.1162(1.1145) | Error 0.0110(0.0102) Steps 452(446.65) | Grad Norm 2.9270(1.6400) | Total Time 10.00(10.00)\n",
      "Iter 4923 | Time 31.8447(31.8461) | Bit/dim 1.0948(1.0979) | Xent 0.0300(0.0329) | Loss 1.1098(1.1144) | Error 0.0089(0.0102) Steps 446(446.63) | Grad Norm 1.2015(1.6268) | Total Time 10.00(10.00)\n",
      "Iter 4924 | Time 31.2796(31.8291) | Bit/dim 1.0987(1.0980) | Xent 0.0391(0.0331) | Loss 1.1183(1.1145) | Error 0.0108(0.0102) Steps 446(446.61) | Grad Norm 4.6895(1.7187) | Total Time 10.00(10.00)\n",
      "Iter 4925 | Time 31.1406(31.8085) | Bit/dim 1.0987(1.0980) | Xent 0.0281(0.0329) | Loss 1.1127(1.1145) | Error 0.0082(0.0101) Steps 446(446.59) | Grad Norm 3.9789(1.7865) | Total Time 10.00(10.00)\n",
      "Iter 4926 | Time 31.4270(31.7970) | Bit/dim 1.0996(1.0980) | Xent 0.0308(0.0329) | Loss 1.1150(1.1145) | Error 0.0102(0.0101) Steps 446(446.57) | Grad Norm 0.9959(1.7628) | Total Time 10.00(10.00)\n",
      "Iter 4927 | Time 31.4284(31.7860) | Bit/dim 1.0959(1.0980) | Xent 0.0300(0.0328) | Loss 1.1109(1.1144) | Error 0.0099(0.0101) Steps 446(446.55) | Grad Norm 5.9551(1.8885) | Total Time 10.00(10.00)\n",
      "Iter 4928 | Time 31.5517(31.7790) | Bit/dim 1.1026(1.0981) | Xent 0.0351(0.0328) | Loss 1.1201(1.1145) | Error 0.0130(0.0102) Steps 446(446.54) | Grad Norm 5.2314(1.9888) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0704 | Time 17.2770, Epoch Time 250.9807(251.2399), Bit/dim 1.0925(best: 1.0917), Xent 0.0272, Loss 1.1061, Error 0.0096(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4929 | Time 31.4851(31.7701) | Bit/dim 1.0995(1.0982) | Xent 0.0352(0.0329) | Loss 1.1172(1.1146) | Error 0.0115(0.0103) Steps 446(446.52) | Grad Norm 1.4736(1.9734) | Total Time 10.00(10.00)\n",
      "Iter 4930 | Time 32.6764(31.7973) | Bit/dim 1.0999(1.0982) | Xent 0.0332(0.0329) | Loss 1.1165(1.1147) | Error 0.0104(0.0103) Steps 446(446.51) | Grad Norm 7.6037(2.1423) | Total Time 10.00(10.00)\n",
      "Iter 4931 | Time 32.5512(31.8199) | Bit/dim 1.1015(1.0983) | Xent 0.0273(0.0327) | Loss 1.1152(1.1147) | Error 0.0080(0.0102) Steps 446(446.49) | Grad Norm 5.8520(2.2536) | Total Time 10.00(10.00)\n",
      "Iter 4932 | Time 31.7437(31.8177) | Bit/dim 1.0950(1.0982) | Xent 0.0312(0.0327) | Loss 1.1106(1.1146) | Error 0.0091(0.0102) Steps 446(446.48) | Grad Norm 3.3222(2.2856) | Total Time 10.00(10.00)\n",
      "Iter 4933 | Time 31.9337(31.8211) | Bit/dim 1.0945(1.0981) | Xent 0.0334(0.0327) | Loss 1.1112(1.1145) | Error 0.0095(0.0101) Steps 452(446.64) | Grad Norm 10.6612(2.5369) | Total Time 10.00(10.00)\n",
      "Iter 4934 | Time 31.0000(31.7965) | Bit/dim 1.1016(1.0982) | Xent 0.0304(0.0327) | Loss 1.1168(1.1145) | Error 0.0101(0.0101) Steps 446(446.62) | Grad Norm 6.8668(2.6668) | Total Time 10.00(10.00)\n",
      "Iter 4935 | Time 33.0255(31.8334) | Bit/dim 1.1042(1.0984) | Xent 0.0323(0.0326) | Loss 1.1204(1.1147) | Error 0.0099(0.0101) Steps 446(446.60) | Grad Norm 4.9260(2.7346) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0705 | Time 17.2557, Epoch Time 254.3215(251.3323), Bit/dim 1.0953(best: 1.0917), Xent 0.0294, Loss 1.1100, Error 0.0098(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4936 | Time 31.6580(31.8281) | Bit/dim 1.1018(1.0985) | Xent 0.0345(0.0327) | Loss 1.1191(1.1148) | Error 0.0118(0.0102) Steps 446(446.59) | Grad Norm 11.0055(2.9827) | Total Time 10.00(10.00)\n",
      "Iter 4937 | Time 32.1151(31.8367) | Bit/dim 1.0993(1.0985) | Xent 0.0320(0.0327) | Loss 1.1153(1.1148) | Error 0.0094(0.0102) Steps 452(446.75) | Grad Norm 4.9779(3.0426) | Total Time 10.00(10.00)\n",
      "Iter 4938 | Time 32.3802(31.8530) | Bit/dim 1.0986(1.0985) | Xent 0.0355(0.0328) | Loss 1.1163(1.1149) | Error 0.0095(0.0101) Steps 452(446.91) | Grad Norm 5.6022(3.1193) | Total Time 10.00(10.00)\n",
      "Iter 4939 | Time 31.7711(31.8506) | Bit/dim 1.0936(1.0984) | Xent 0.0321(0.0327) | Loss 1.1097(1.1147) | Error 0.0109(0.0102) Steps 446(446.88) | Grad Norm 8.1367(3.2699) | Total Time 10.00(10.00)\n",
      "Iter 4940 | Time 32.9389(31.8832) | Bit/dim 1.1018(1.0985) | Xent 0.0329(0.0327) | Loss 1.1182(1.1148) | Error 0.0102(0.0102) Steps 446(446.85) | Grad Norm 1.8467(3.2272) | Total Time 10.00(10.00)\n",
      "Iter 4941 | Time 32.5149(31.9022) | Bit/dim 1.1006(1.0985) | Xent 0.0328(0.0327) | Loss 1.1170(1.1149) | Error 0.0100(0.0102) Steps 452(447.01) | Grad Norm 3.9329(3.2483) | Total Time 10.00(10.00)\n",
      "Iter 4942 | Time 30.9699(31.8742) | Bit/dim 1.0976(1.0985) | Xent 0.0376(0.0329) | Loss 1.1164(1.1150) | Error 0.0120(0.0102) Steps 446(446.98) | Grad Norm 2.7560(3.2336) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0706 | Time 17.2484, Epoch Time 254.4983(251.4273), Bit/dim 1.0918(best: 1.0917), Xent 0.0291, Loss 1.1063, Error 0.0096(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4943 | Time 30.7864(31.8416) | Bit/dim 1.0985(1.0985) | Xent 0.0339(0.0329) | Loss 1.1155(1.1150) | Error 0.0118(0.0103) Steps 446(446.95) | Grad Norm 2.4743(3.2108) | Total Time 10.00(10.00)\n",
      "Iter 4944 | Time 32.5427(31.8626) | Bit/dim 1.1024(1.0986) | Xent 0.0280(0.0328) | Loss 1.1164(1.1150) | Error 0.0074(0.0102) Steps 446(446.92) | Grad Norm 4.3890(3.2461) | Total Time 10.00(10.00)\n",
      "Iter 4945 | Time 33.1796(31.9021) | Bit/dim 1.0923(1.0984) | Xent 0.0364(0.0329) | Loss 1.1105(1.1149) | Error 0.0118(0.0102) Steps 452(447.07) | Grad Norm 1.0697(3.1809) | Total Time 10.00(10.00)\n",
      "Iter 4946 | Time 31.2438(31.8824) | Bit/dim 1.0994(1.0985) | Xent 0.0307(0.0328) | Loss 1.1148(1.1149) | Error 0.0108(0.0102) Steps 452(447.22) | Grad Norm 2.9069(3.1726) | Total Time 10.00(10.00)\n",
      "Iter 4947 | Time 32.1454(31.8902) | Bit/dim 1.0960(1.0984) | Xent 0.0349(0.0329) | Loss 1.1135(1.1148) | Error 0.0108(0.0102) Steps 452(447.36) | Grad Norm 2.4968(3.1524) | Total Time 10.00(10.00)\n",
      "Iter 4948 | Time 31.2464(31.8709) | Bit/dim 1.0950(1.0983) | Xent 0.0333(0.0329) | Loss 1.1116(1.1147) | Error 0.0108(0.0103) Steps 446(447.32) | Grad Norm 1.4116(3.1001) | Total Time 10.00(10.00)\n",
      "Iter 4949 | Time 31.9468(31.8732) | Bit/dim 1.0995(1.0983) | Xent 0.0359(0.0330) | Loss 1.1174(1.1148) | Error 0.0110(0.0103) Steps 446(447.28) | Grad Norm 3.5327(3.1131) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0707 | Time 17.1878, Epoch Time 252.6786(251.4648), Bit/dim 1.0922(best: 1.0917), Xent 0.0281, Loss 1.1062, Error 0.0101(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4950 | Time 30.9597(31.8458) | Bit/dim 1.1045(1.0985) | Xent 0.0335(0.0330) | Loss 1.1212(1.1150) | Error 0.0090(0.0102) Steps 446(447.24) | Grad Norm 2.3013(3.0888) | Total Time 10.00(10.00)\n",
      "Iter 4951 | Time 32.2711(31.8586) | Bit/dim 1.0981(1.0985) | Xent 0.0365(0.0331) | Loss 1.1163(1.1150) | Error 0.0115(0.0103) Steps 446(447.21) | Grad Norm 0.7980(3.0200) | Total Time 10.00(10.00)\n",
      "Iter 4952 | Time 31.7998(31.8568) | Bit/dim 1.0936(1.0983) | Xent 0.0349(0.0332) | Loss 1.1110(1.1149) | Error 0.0114(0.0103) Steps 446(447.17) | Grad Norm 3.0920(3.0222) | Total Time 10.00(10.00)\n",
      "Iter 4953 | Time 31.8330(31.8561) | Bit/dim 1.0945(1.0982) | Xent 0.0309(0.0331) | Loss 1.1099(1.1148) | Error 0.0092(0.0103) Steps 446(447.14) | Grad Norm 2.4461(3.0049) | Total Time 10.00(10.00)\n",
      "Iter 4954 | Time 31.3320(31.8404) | Bit/dim 1.1021(1.0983) | Xent 0.0293(0.0330) | Loss 1.1168(1.1148) | Error 0.0089(0.0102) Steps 446(447.10) | Grad Norm 0.4523(2.9283) | Total Time 10.00(10.00)\n",
      "Iter 4955 | Time 31.3749(31.8264) | Bit/dim 1.0925(1.0982) | Xent 0.0371(0.0331) | Loss 1.1111(1.1147) | Error 0.0130(0.0103) Steps 446(447.07) | Grad Norm 3.0016(2.9305) | Total Time 10.00(10.00)\n",
      "Iter 4956 | Time 31.7963(31.8255) | Bit/dim 1.1005(1.0982) | Xent 0.0343(0.0331) | Loss 1.1176(1.1148) | Error 0.0094(0.0103) Steps 446(447.04) | Grad Norm 2.8371(2.9277) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0708 | Time 16.9896, Epoch Time 250.9544(251.4495), Bit/dim 1.0918(best: 1.0917), Xent 0.0282, Loss 1.1059, Error 0.0094(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4957 | Time 32.0961(31.8336) | Bit/dim 1.1045(1.0984) | Xent 0.0298(0.0330) | Loss 1.1194(1.1149) | Error 0.0095(0.0103) Steps 452(447.18) | Grad Norm 0.5208(2.8555) | Total Time 10.00(10.00)\n",
      "Iter 4958 | Time 31.1911(31.8143) | Bit/dim 1.1009(1.0985) | Xent 0.0331(0.0330) | Loss 1.1175(1.1150) | Error 0.0106(0.0103) Steps 452(447.33) | Grad Norm 3.3441(2.8702) | Total Time 10.00(10.00)\n",
      "Iter 4959 | Time 32.8038(31.8440) | Bit/dim 1.0968(1.0985) | Xent 0.0363(0.0331) | Loss 1.1149(1.1150) | Error 0.0119(0.0103) Steps 446(447.29) | Grad Norm 2.3911(2.8558) | Total Time 10.00(10.00)\n",
      "Iter 4960 | Time 33.0911(31.8814) | Bit/dim 1.0963(1.0984) | Xent 0.0361(0.0332) | Loss 1.1144(1.1150) | Error 0.0108(0.0103) Steps 446(447.25) | Grad Norm 1.8807(2.8266) | Total Time 10.00(10.00)\n",
      "Iter 4961 | Time 31.3865(31.8666) | Bit/dim 1.0969(1.0983) | Xent 0.0347(0.0333) | Loss 1.1143(1.1150) | Error 0.0106(0.0104) Steps 446(447.21) | Grad Norm 4.1087(2.8650) | Total Time 10.00(10.00)\n",
      "Iter 4962 | Time 31.6799(31.8610) | Bit/dim 1.0933(1.0982) | Xent 0.0315(0.0332) | Loss 1.1091(1.1148) | Error 0.0098(0.0103) Steps 446(447.18) | Grad Norm 2.0589(2.8408) | Total Time 10.00(10.00)\n",
      "Iter 4963 | Time 31.0453(31.8365) | Bit/dim 1.0942(1.0981) | Xent 0.0326(0.0332) | Loss 1.1105(1.1147) | Error 0.0096(0.0103) Steps 446(447.14) | Grad Norm 1.3328(2.7956) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0709 | Time 17.3897, Epoch Time 253.1240(251.4998), Bit/dim 1.0924(best: 1.0917), Xent 0.0282, Loss 1.1065, Error 0.0088(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4964 | Time 31.3498(31.8219) | Bit/dim 1.0942(1.0980) | Xent 0.0347(0.0332) | Loss 1.1115(1.1146) | Error 0.0125(0.0104) Steps 446(447.11) | Grad Norm 2.7282(2.7936) | Total Time 10.00(10.00)\n",
      "Iter 4965 | Time 31.6942(31.8181) | Bit/dim 1.1014(1.0981) | Xent 0.0322(0.0332) | Loss 1.1174(1.1147) | Error 0.0106(0.0104) Steps 446(447.07) | Grad Norm 0.8867(2.7364) | Total Time 10.00(10.00)\n",
      "Iter 4966 | Time 31.7132(31.8149) | Bit/dim 1.0973(1.0980) | Xent 0.0295(0.0331) | Loss 1.1121(1.1146) | Error 0.0091(0.0103) Steps 446(447.04) | Grad Norm 2.0157(2.7147) | Total Time 10.00(10.00)\n",
      "Iter 4967 | Time 31.3537(31.8011) | Bit/dim 1.0966(1.0980) | Xent 0.0340(0.0331) | Loss 1.1136(1.1146) | Error 0.0094(0.0103) Steps 446(447.01) | Grad Norm 2.4027(2.7054) | Total Time 10.00(10.00)\n",
      "Iter 4968 | Time 32.0679(31.8091) | Bit/dim 1.0957(1.0979) | Xent 0.0318(0.0331) | Loss 1.1116(1.1145) | Error 0.0089(0.0103) Steps 446(446.98) | Grad Norm 0.5481(2.6407) | Total Time 10.00(10.00)\n",
      "Iter 4969 | Time 31.6774(31.8052) | Bit/dim 1.1034(1.0981) | Xent 0.0343(0.0331) | Loss 1.1206(1.1147) | Error 0.0108(0.0103) Steps 452(447.13) | Grad Norm 1.2610(2.5993) | Total Time 10.00(10.00)\n",
      "Iter 4970 | Time 31.2075(31.7872) | Bit/dim 1.0961(1.0980) | Xent 0.0321(0.0331) | Loss 1.1121(1.1146) | Error 0.0095(0.0103) Steps 446(447.10) | Grad Norm 0.7571(2.5440) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0710 | Time 17.3894, Epoch Time 250.9029(251.4819), Bit/dim 1.0920(best: 1.0917), Xent 0.0293, Loss 1.1066, Error 0.0101(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4971 | Time 31.4431(31.7769) | Bit/dim 1.0950(1.0979) | Xent 0.0323(0.0331) | Loss 1.1111(1.1145) | Error 0.0110(0.0103) Steps 446(447.06) | Grad Norm 0.9055(2.4949) | Total Time 10.00(10.00)\n",
      "Iter 4972 | Time 31.7620(31.7764) | Bit/dim 1.0987(1.0980) | Xent 0.0347(0.0331) | Loss 1.1160(1.1145) | Error 0.0109(0.0103) Steps 446(447.03) | Grad Norm 1.4008(2.4620) | Total Time 10.00(10.00)\n",
      "Iter 4973 | Time 32.2363(31.7902) | Bit/dim 1.0966(1.0979) | Xent 0.0314(0.0331) | Loss 1.1122(1.1144) | Error 0.0096(0.0103) Steps 446(447.00) | Grad Norm 0.3142(2.3976) | Total Time 10.00(10.00)\n",
      "Iter 4974 | Time 31.5602(31.7833) | Bit/dim 1.1001(1.0980) | Xent 0.0314(0.0330) | Loss 1.1158(1.1145) | Error 0.0099(0.0103) Steps 446(446.97) | Grad Norm 1.5869(2.3733) | Total Time 10.00(10.00)\n",
      "Iter 4975 | Time 31.8585(31.7856) | Bit/dim 1.1013(1.0981) | Xent 0.0315(0.0330) | Loss 1.1171(1.1146) | Error 0.0092(0.0102) Steps 446(446.94) | Grad Norm 1.1147(2.3355) | Total Time 10.00(10.00)\n",
      "Iter 4976 | Time 32.3396(31.8022) | Bit/dim 1.0958(1.0980) | Xent 0.0300(0.0329) | Loss 1.1108(1.1145) | Error 0.0082(0.0102) Steps 446(446.91) | Grad Norm 1.3888(2.3071) | Total Time 10.00(10.00)\n",
      "Iter 4977 | Time 31.3009(31.7872) | Bit/dim 1.0954(1.0979) | Xent 0.0375(0.0330) | Loss 1.1142(1.1144) | Error 0.0108(0.0102) Steps 446(446.89) | Grad Norm 2.4621(2.3118) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0711 | Time 17.3416, Epoch Time 252.5750(251.5147), Bit/dim 1.0911(best: 1.0917), Xent 0.0262, Loss 1.1042, Error 0.0091(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4978 | Time 31.2789(31.7719) | Bit/dim 1.1011(1.0980) | Xent 0.0337(0.0330) | Loss 1.1180(1.1146) | Error 0.0102(0.0102) Steps 446(446.86) | Grad Norm 1.3634(2.2833) | Total Time 10.00(10.00)\n",
      "Iter 4979 | Time 31.5159(31.7643) | Bit/dim 1.0942(1.0979) | Xent 0.0321(0.0330) | Loss 1.1103(1.1144) | Error 0.0091(0.0102) Steps 446(446.83) | Grad Norm 0.5122(2.2302) | Total Time 10.00(10.00)\n",
      "Iter 4980 | Time 30.9565(31.7400) | Bit/dim 1.0945(1.0978) | Xent 0.0303(0.0329) | Loss 1.1097(1.1143) | Error 0.0089(0.0101) Steps 446(446.81) | Grad Norm 1.3833(2.2048) | Total Time 10.00(10.00)\n",
      "Iter 4981 | Time 31.7732(31.7410) | Bit/dim 1.0999(1.0979) | Xent 0.0348(0.0330) | Loss 1.1173(1.1144) | Error 0.0106(0.0101) Steps 446(446.78) | Grad Norm 0.4926(2.1534) | Total Time 10.00(10.00)\n",
      "Iter 4982 | Time 30.9418(31.7170) | Bit/dim 1.0957(1.0978) | Xent 0.0312(0.0329) | Loss 1.1113(1.1143) | Error 0.0100(0.0101) Steps 446(446.76) | Grad Norm 0.9769(2.1181) | Total Time 10.00(10.00)\n",
      "Iter 4983 | Time 31.6786(31.7159) | Bit/dim 1.0952(1.0977) | Xent 0.0382(0.0331) | Loss 1.1143(1.1143) | Error 0.0112(0.0102) Steps 446(446.74) | Grad Norm 1.1049(2.0877) | Total Time 10.00(10.00)\n",
      "Iter 4984 | Time 31.1978(31.7003) | Bit/dim 1.0997(1.0978) | Xent 0.0308(0.0330) | Loss 1.1151(1.1143) | Error 0.0112(0.0102) Steps 446(446.72) | Grad Norm 0.4990(2.0401) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0712 | Time 17.3384, Epoch Time 249.1239(251.4429), Bit/dim 1.0926(best: 1.0911), Xent 0.0267, Loss 1.1059, Error 0.0090(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4985 | Time 31.8020(31.7034) | Bit/dim 1.1024(1.0979) | Xent 0.0322(0.0330) | Loss 1.1185(1.1144) | Error 0.0105(0.0102) Steps 446(446.69) | Grad Norm 1.6537(2.0285) | Total Time 10.00(10.00)\n",
      "Iter 4986 | Time 31.2755(31.6906) | Bit/dim 1.0991(1.0980) | Xent 0.0345(0.0330) | Loss 1.1164(1.1145) | Error 0.0108(0.0102) Steps 446(446.67) | Grad Norm 1.0081(1.9979) | Total Time 10.00(10.00)\n",
      "Iter 4987 | Time 31.1637(31.6747) | Bit/dim 1.1009(1.0981) | Xent 0.0364(0.0331) | Loss 1.1192(1.1146) | Error 0.0109(0.0102) Steps 446(446.65) | Grad Norm 0.8738(1.9641) | Total Time 10.00(10.00)\n",
      "Iter 4988 | Time 31.7049(31.6757) | Bit/dim 1.0920(1.0979) | Xent 0.0310(0.0331) | Loss 1.1075(1.1144) | Error 0.0089(0.0102) Steps 452(446.81) | Grad Norm 1.6881(1.9559) | Total Time 10.00(10.00)\n",
      "Iter 4989 | Time 30.9447(31.6537) | Bit/dim 1.0954(1.0978) | Xent 0.0358(0.0332) | Loss 1.1133(1.1144) | Error 0.0111(0.0102) Steps 446(446.79) | Grad Norm 1.2388(1.9343) | Total Time 10.00(10.00)\n",
      "Iter 4990 | Time 33.3454(31.7045) | Bit/dim 1.0975(1.0978) | Xent 0.0326(0.0331) | Loss 1.1137(1.1144) | Error 0.0106(0.0102) Steps 446(446.77) | Grad Norm 0.6558(1.8960) | Total Time 10.00(10.00)\n",
      "Iter 4991 | Time 31.5579(31.7001) | Bit/dim 1.0946(1.0977) | Xent 0.0363(0.0332) | Loss 1.1127(1.1143) | Error 0.0112(0.0103) Steps 452(446.92) | Grad Norm 1.6720(1.8893) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0713 | Time 17.1581, Epoch Time 251.4683(251.4437), Bit/dim 1.0922(best: 1.0911), Xent 0.0286, Loss 1.1065, Error 0.0089(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4992 | Time 33.0226(31.7398) | Bit/dim 1.1000(1.0978) | Xent 0.0311(0.0332) | Loss 1.1155(1.1143) | Error 0.0102(0.0103) Steps 446(446.90) | Grad Norm 1.3626(1.8735) | Total Time 10.00(10.00)\n",
      "Iter 4993 | Time 32.6416(31.7668) | Bit/dim 1.0990(1.0978) | Xent 0.0367(0.0333) | Loss 1.1173(1.1144) | Error 0.0109(0.0103) Steps 446(446.87) | Grad Norm 0.4737(1.8315) | Total Time 10.00(10.00)\n",
      "Iter 4994 | Time 32.9739(31.8030) | Bit/dim 1.0997(1.0979) | Xent 0.0345(0.0333) | Loss 1.1170(1.1145) | Error 0.0101(0.0103) Steps 446(446.84) | Grad Norm 1.2073(1.8127) | Total Time 10.00(10.00)\n",
      "Iter 4995 | Time 31.0852(31.7815) | Bit/dim 1.0940(1.0977) | Xent 0.0293(0.0332) | Loss 1.1086(1.1143) | Error 0.0096(0.0103) Steps 452(447.00) | Grad Norm 0.8625(1.7842) | Total Time 10.00(10.00)\n",
      "Iter 4996 | Time 31.6569(31.7777) | Bit/dim 1.0989(1.0978) | Xent 0.0356(0.0333) | Loss 1.1167(1.1144) | Error 0.0106(0.0103) Steps 446(446.97) | Grad Norm 0.6846(1.7513) | Total Time 10.00(10.00)\n",
      "Iter 4997 | Time 31.2580(31.7622) | Bit/dim 1.0968(1.0977) | Xent 0.0384(0.0334) | Loss 1.1160(1.1145) | Error 0.0101(0.0103) Steps 446(446.94) | Grad Norm 1.4390(1.7419) | Total Time 10.00(10.00)\n",
      "Iter 4998 | Time 31.3898(31.7510) | Bit/dim 1.0970(1.0977) | Xent 0.0349(0.0335) | Loss 1.1145(1.1145) | Error 0.0110(0.0103) Steps 446(446.91) | Grad Norm 1.2227(1.7263) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0714 | Time 17.0733, Epoch Time 253.6060(251.5086), Bit/dim 1.0914(best: 1.0911), Xent 0.0278, Loss 1.1052, Error 0.0098(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4999 | Time 32.0242(31.7592) | Bit/dim 1.0966(1.0977) | Xent 0.0293(0.0333) | Loss 1.1113(1.1144) | Error 0.0096(0.0103) Steps 446(446.88) | Grad Norm 0.3350(1.6846) | Total Time 10.00(10.00)\n",
      "Iter 5000 | Time 31.0651(31.7384) | Bit/dim 1.1005(1.0978) | Xent 0.0370(0.0334) | Loss 1.1189(1.1145) | Error 0.0112(0.0103) Steps 446(446.86) | Grad Norm 1.0448(1.6654) | Total Time 10.00(10.00)\n",
      "Iter 5001 | Time 31.4035(31.7283) | Bit/dim 1.0942(1.0977) | Xent 0.0327(0.0334) | Loss 1.1105(1.1144) | Error 0.0101(0.0103) Steps 446(446.83) | Grad Norm 0.6690(1.6355) | Total Time 10.00(10.00)\n",
      "Iter 5002 | Time 32.0884(31.7391) | Bit/dim 1.1006(1.0978) | Xent 0.0330(0.0334) | Loss 1.1171(1.1145) | Error 0.0111(0.0103) Steps 446(446.81) | Grad Norm 0.8033(1.6105) | Total Time 10.00(10.00)\n",
      "Iter 5003 | Time 31.6567(31.7366) | Bit/dim 1.1003(1.0978) | Xent 0.0355(0.0335) | Loss 1.1181(1.1146) | Error 0.0108(0.0103) Steps 446(446.78) | Grad Norm 1.6716(1.6124) | Total Time 10.00(10.00)\n",
      "Iter 5004 | Time 30.9788(31.7139) | Bit/dim 1.0910(1.0976) | Xent 0.0328(0.0335) | Loss 1.1074(1.1144) | Error 0.0101(0.0103) Steps 446(446.76) | Grad Norm 1.4455(1.6073) | Total Time 10.00(10.00)\n",
      "Iter 5005 | Time 32.1786(31.7279) | Bit/dim 1.1001(1.0977) | Xent 0.0337(0.0335) | Loss 1.1169(1.1144) | Error 0.0098(0.0103) Steps 446(446.74) | Grad Norm 0.5635(1.5760) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0715 | Time 17.3895, Epoch Time 251.1496(251.4978), Bit/dim 1.0913(best: 1.0911), Xent 0.0259, Loss 1.1043, Error 0.0084(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 5006 | Time 32.9649(31.7650) | Bit/dim 1.1007(1.0978) | Xent 0.0332(0.0335) | Loss 1.1173(1.1145) | Error 0.0098(0.0103) Steps 446(446.71) | Grad Norm 0.5679(1.5458) | Total Time 10.00(10.00)\n",
      "Iter 5007 | Time 31.8908(31.7687) | Bit/dim 1.0989(1.0978) | Xent 0.0318(0.0334) | Loss 1.1148(1.1145) | Error 0.0100(0.0103) Steps 446(446.69) | Grad Norm 0.8664(1.5254) | Total Time 10.00(10.00)\n",
      "Iter 5008 | Time 33.1656(31.8106) | Bit/dim 1.0979(1.0978) | Xent 0.0392(0.0336) | Loss 1.1175(1.1146) | Error 0.0119(0.0103) Steps 446(446.67) | Grad Norm 0.7700(1.5027) | Total Time 10.00(10.00)\n",
      "Iter 5009 | Time 31.4286(31.7992) | Bit/dim 1.0959(1.0978) | Xent 0.0323(0.0335) | Loss 1.1121(1.1145) | Error 0.0109(0.0104) Steps 446(446.65) | Grad Norm 0.5671(1.4747) | Total Time 10.00(10.00)\n",
      "Iter 5010 | Time 31.2780(31.7836) | Bit/dim 1.1002(1.0978) | Xent 0.0326(0.0335) | Loss 1.1165(1.1146) | Error 0.0109(0.0104) Steps 452(446.81) | Grad Norm 0.3369(1.4405) | Total Time 10.00(10.00)\n",
      "Iter 5011 | Time 31.9614(31.7889) | Bit/dim 1.0945(1.0977) | Xent 0.0238(0.0332) | Loss 1.1063(1.1143) | Error 0.0076(0.0103) Steps 446(446.79) | Grad Norm 0.3071(1.4065) | Total Time 10.00(10.00)\n",
      "Iter 5012 | Time 31.0252(31.7660) | Bit/dim 1.0959(1.0977) | Xent 0.0361(0.0333) | Loss 1.1140(1.1143) | Error 0.0109(0.0103) Steps 446(446.76) | Grad Norm 0.6758(1.3846) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0716 | Time 17.4943, Epoch Time 253.5774(251.5602), Bit/dim 1.0914(best: 1.0911), Xent 0.0282, Loss 1.1055, Error 0.0096(best: 0.0076)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 5013 | Time 31.9873(31.7726) | Bit/dim 1.0970(1.0977) | Xent 0.0355(0.0334) | Loss 1.1148(1.1144) | Error 0.0109(0.0103) Steps 446(446.74) | Grad Norm 0.5030(1.3582) | Total Time 10.00(10.00)\n",
      "Iter 5014 | Time 32.3773(31.7908) | Bit/dim 1.0981(1.0977) | Xent 0.0269(0.0332) | Loss 1.1115(1.1143) | Error 0.0085(0.0103) Steps 446(446.72) | Grad Norm 0.8800(1.3438) | Total Time 10.00(10.00)\n",
      "Iter 5015 | Time 31.2645(31.7750) | Bit/dim 1.0979(1.0977) | Xent 0.0313(0.0331) | Loss 1.1135(1.1142) | Error 0.0088(0.0102) Steps 446(446.70) | Grad Norm 1.6327(1.3525) | Total Time 10.00(10.00)\n",
      "Iter 5016 | Time 31.2113(31.7581) | Bit/dim 1.0983(1.0977) | Xent 0.0317(0.0331) | Loss 1.1141(1.1142) | Error 0.0108(0.0102) Steps 446(446.68) | Grad Norm 0.9449(1.3403) | Total Time 10.00(10.00)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tancode/repos/tan-ffjord/train_cnf_drop.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                 \u001b[0mloss_nll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_xent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_bits_per_dim_conditional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"semisup\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mloss_nll\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_y\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_xent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/train_cnf_drop.py\u001b[0m in \u001b[0;36mcompute_bits_per_dim_conditional\u001b[0;34m(x, y, model)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m#     model = model.module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_logp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run model forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         1958086679 function calls (1938325250 primitive calls) in 89152.323 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "     2461 49094.411   19.949 49094.411   19.949 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
       "   323984 34288.843    0.106 34288.843    0.106 {method 'acquire' of '_thread.lock' objects}\n",
       " 23206000  750.268    0.000 1079.538    0.000 train_cnf_drop.py:128(add_noise)\n",
       " 23206000  464.383    0.000 1983.683    0.000 functional.py:32(to_tensor)\n",
       " 23206000  371.901    0.000  371.901    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
       " 23206000  331.466    0.000 4921.689    0.000 mnist.py:59(__getitem__)\n",
       " 23206084  210.620    0.000  210.620    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
       " 23206000  188.298    0.000  188.298    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
       " 23206702  187.467    0.000 1061.683    0.000 Image.py:2457(fromarray)\n",
       " 23206000  164.326    0.000  526.034    0.000 Image.py:711(tobytes)\n",
       " 46412000  149.272    0.000  149.272    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
       "   230265  148.802    0.001  148.802    0.001 {method '_write_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "275257986/275251631  136.468    0.000  136.655    0.000 {built-in method builtins.isinstance}\n",
       " 23206702  127.088    0.000  464.545    0.000 Image.py:2322(new)\n",
       " 23209514  124.511    0.000  124.511    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
       " 23206702  121.757    0.000  847.667    0.000 Image.py:2396(frombuffer)\n",
       " 23206000  117.948    0.000 3397.858    0.000 transforms.py:47(__call__)\n",
       " 46413053  114.317    0.000  183.566    0.000 Image.py:553(_new)\n",
       " 23206702  104.450    0.000  162.800    0.000 Image.py:451(_getencoder)\n",
       "69683476/69683462   85.668    0.000   85.691    0.000 {built-in method builtins.hasattr}\n",
       " 46414106   78.716    0.000  120.739    0.000 Image.py:2304(_check_size)\n",
       "     6328   78.522    0.012   78.522    0.012 {built-in method stack}\n",
       " 69619755   77.196    0.000   77.196    0.000 Image.py:529(__init__)\n",
       " 69619755   76.279    0.000  161.824    0.000 Image.py:601(__del__)\n",
       " 23206000   74.684    0.000  138.896    0.000 functional.py:172(resize)\n",
       " 23206702   73.167    0.000   73.167    0.000 {built-in method PIL._imaging.fill}\n",
       "164409316/164405707   70.619    0.000   70.634    0.000 {built-in method builtins.len}\n",
       " 23206351   69.211    0.000   69.211    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
       " 23206000   65.088    0.000   65.088    0.000 {method 'resize_as_' of 'torch._C._TensorBase' objects}\n",
       " 17590766   63.664    0.000   97.783    0.000 module.py:537(__setattr__)\n",
       " 23206000   63.444    0.000   63.444    0.000 {built-in method PIL._imaging.map_buffer}\n",
       " 23254805   54.554    0.000   54.554    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
       " 23206545   53.572    0.000   53.572    0.000 {method 'new' of 'torch._C._TensorBase' objects}\n",
       " 23206000   48.382    0.000   48.382    0.000 {built-in method from_buffer}\n",
       " 46412000   45.153    0.000   64.237    0.000 functional.py:17(_is_pil_image)\n",
       " 23206000   42.337    0.000 2026.019    0.000 transforms.py:68(__call__)\n",
       " 92827159   40.359    0.000   40.359    0.000 Image.py:549(size)\n",
       "     3164   38.648    0.012 4960.337    1.568 dataloader.py:615(<listcomp>)\n",
       " 23206000   35.456    0.000  174.352    0.000 transforms.py:167(__call__)\n",
       " 23207755   33.747    0.000   49.443    0.000 Image.py:809(load)\n",
       " 76008117   32.658    0.000   32.658    0.000 {method 'get' of 'dict' objects}\n",
       "     3515   28.412    0.008  179.350    0.051 replicate.py:5(replicate)\n",
       "    34047   26.396    0.001   26.396    0.001 {method 'sort' of 'numpy.ndarray' objects}\n",
       " 50771655   25.771    0.000   25.771    0.000 {method 'copy' of 'dict' objects}\n",
       " 23206000   25.710    0.000   25.710    0.000 {built-in method PIL._imaging.raw_encoder}\n",
       "     3867   25.623    0.007   45.995    0.012 sampler.py:158(__iter__)\n",
       " 23243994   24.410    0.000   24.410    0.000 {built-in method builtins.max}\n",
       " 23207053   22.954    0.000   33.426    0.000 _util.py:7(isStringType)\n",
       " 52268259   22.672    0.000   22.672    0.000 {method 'append' of 'list' objects}\n",
       " 23459791   22.593    0.000   22.593    0.000 {built-in method builtins.getattr}\n",
       "     3866   20.926    0.005 5134.393    1.328 dataloader.py:612(__next__)\n",
       "20735324/2086972   19.048    0.000   21.406    0.000 module.py:938(named_modules)\n",
       "     6679   17.549    0.003   17.549    0.003 {built-in method torch._C._scatter}\n",
       " 23206702   17.107    0.000   17.107    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
       "     4924   16.842    0.003   16.842    0.003 {method 'pin_memory' of 'torch._C._TensorBase' objects}\n",
       "    34047   15.939    0.000   65.074    0.002 summary.py:150(make_histogram)\n",
       " 23207755   15.697    0.000   15.697    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
       "     7030   15.351    0.002   15.351    0.002 {built-in method torch._C._broadcast_coalesced}\n",
       " 23206000   14.220    0.000   14.220    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
       "        1   12.172   12.172 89152.264 89152.264 train_cnf_drop.py:1(<module>)\n",
       "  6257913   11.949    0.000   20.499    0.000 serialization.py:234(persistent_id)\n",
       " 23207054   11.157    0.000   11.157    0.000 {method 'join' of 'bytes' objects}\n",
       "    16403   11.125    0.001   11.189    0.001 {method 'to' of 'torch._C._TensorBase' objects}\n",
       "9492/3164   10.214    0.001   90.131    0.028 dataloader.py:196(default_collate)\n",
       "     1317   10.167    0.008   10.167    0.008 {built-in method io.open}\n",
       "   238717   10.080    0.000   10.080    0.000 {built-in method norm}\n",
       "   251463    8.923    0.000    8.923    0.000 {built-in method numpy.core.multiarray.array}\n",
       "   477434    8.398    0.000    8.398    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
       "     3520    8.021    0.002    8.021    0.002 {method 'flush' of '_io.TextIOWrapper' objects}\n",
       "      788    8.000    0.010    8.000    0.010 {method 'flush' of '_io.BufferedWriter' objects}\n",
       "   477434    7.620    0.000    7.620    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
       " 13075807    7.364    0.000    7.364    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
       "    45642    7.251    0.000    7.251    0.000 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
       "   276335    5.824    0.000    5.824    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
       "      765    5.284    0.007   28.097    0.037 {method 'dump' of '_pickle.Pickler' objects}\n",
       "    37211    4.873    0.000    4.873    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
       "    16168    4.863    0.000 33996.807    2.103 module.py:483(__call__)\n",
       "     2461    4.495    0.002   30.974    0.013 adam.py:49(step)\n",
       "      765    4.290    0.006  191.176    0.250 serialization.py:221(_save)\n",
       "    34048    4.269    0.000    4.269    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
       "  6257913    3.749    0.000    3.749    0.000 __init__.py:128(is_storage)\n",
       "   238717    3.577    0.000    3.577    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
       "   238717    3.238    0.000    3.238    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
       "   659005    3.048    0.000   23.898    0.000 module.py:771(_named_members)\n",
       "    34047    3.043    0.000   69.270    0.002 summary.py:126(histogram)\n",
       "   238717    2.994    0.000    2.994    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
       "  3675086    2.615    0.000    3.362    0.000 {method 'add' of 'set' objects}\n",
       "   140405    2.615    0.000    2.615    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "  6588939    2.434    0.000    2.434    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
       "812294/4923    2.386    0.000    9.753    0.002 module.py:203(apply)\n",
       "  1851281    2.338    0.000    3.060    0.000 module.py:891(named_children)\n",
       "     6677    2.248    0.000    2.248    0.000 {built-in method torch._C._gather}\n",
       "    16871    2.231    0.000   37.312    0.002 {built-in method apply}\n",
       "    17605    2.071    0.000    2.071    0.000 socket.py:334(send)\n",
       "      351    1.863    0.005    6.361    0.018 summary.py:184(image)\n",
       "  4360741    1.860    0.000    1.860    0.000 {built-in method __new__ of type object at 0x55cc5e9d3d60}\n",
       "  2289441    1.838    0.000    2.757    0.000 tensor.py:416(__hash__)\n",
       "  1851281    1.820    0.000    4.880    0.000 module.py:882(children)\n",
       "     6373    1.739    0.000    1.739    0.000 {built-in method posix.stat}\n",
       "     3164    1.732    0.001    3.115    0.001 odenvp_conditional_tol.py:124(_prior)\n",
       "     2461    1.641    0.001   25.415    0.010 clip_grad.py:6(clip_grad_norm_)\n",
       "    28143    1.624    0.000    1.624    0.000 {built-in method _thread.start_new_thread}\n",
       "    62164    1.617    0.000  505.044    0.008 writer.py:82(add_summary)\n",
       "   406065    1.531    0.000    1.791    0.000 train_misc.py:81(__call__)\n",
       "   231030    1.484    0.000    2.315    0.000 tensor.py:33(__reduce_ex__)\n",
       "    68094    1.427    0.000    1.427    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
       "     3165    1.396    0.000    1.396    0.000 {method 'scatter_' of 'torch._C._TensorBase' objects}\n",
       "   238721    1.395    0.000    1.395    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
       "     3164    1.305    0.000   79.880    0.025 dataloader.py:232(<listcomp>)\n",
       "   983962    1.116    0.000    1.491    0.000 module.py:829(<lambda>)\n",
       "      351    1.063    0.003    1.063    0.003 {method 'encode_to_file' of 'ImagingEncoder' objects}\n",
       "    37913    0.987    0.000    0.987    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "  2440454    0.982    0.000    0.982    0.000 {built-in method builtins.id}\n",
       "140760/765    0.955    0.000    1.194    0.002 module.py:602(state_dict)\n",
       "     3164    0.905    0.000 30861.926    9.754 train_cnf_drop.py:274(compute_bits_per_dim_conditional)\n",
       "    34047    0.837    0.000   41.700    0.001 histograms.py:597(histogram)\n",
       "      351    0.799    0.002    0.799    0.002 {method 'tobytes' of 'numpy.ndarray' objects}\n",
       "      352    0.790    0.002    0.790    0.002 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
       "   231033    0.776    0.000    0.776    0.000 serialization.py:149(_is_compressed_file)\n",
       "     3163    0.729    0.000    0.729    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
       "    62164    0.697    0.000  502.695    0.008 queue.py:115(put)\n",
       "     6327    0.696    0.000    0.696    0.000 {built-in method addmm}\n",
       "     3163    0.670    0.000    0.730    0.000 modules.py:268(likelihood)\n",
       "        1    0.661    0.661    0.661    0.661 {built-in method caffe2.python.caffe2_pybind11_state_gpu.num_cuda_devices}\n",
       "    34087    0.658    0.000    0.658    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "    53145    0.624    0.000  526.446    0.010 threading.py:263(wait)\n",
       "    34047    0.613    0.000   10.453    0.000 histograms.py:297(_get_bin_edges)\n",
       "   620340    0.573    0.000   18.004    0.000 module.py:808(named_parameters)\n",
       "   238717    0.571    0.000   10.768    0.000 functional.py:607(norm)\n",
       "   231033    0.527    0.000    1.511    0.000 serialization.py:157(_should_read_directly)\n",
       "   544825    0.527    0.000    0.718    0.000 module.py:877(<lambda>)\n",
       "    24602    0.520    0.000    3.148    0.000 summary.py:105(scalar)\n",
       "    34398    0.513    0.000    0.513    0.000 {built-in method numpy.core.multiarray.zeros}\n",
       "     2462    0.504    0.000    2.059    0.001 optimizer.py:157(zero_grad)\n",
       "   585942    0.500    0.000   16.917    0.000 module.py:784(parameters)\n",
       "   231030    0.498    0.000    1.180    0.000 serialization.py:102(location_tag)\n",
       "     6327    0.491    0.000    1.522    0.000 modules.py:105(forward)\n",
       "    34047    0.490    0.000    0.601    0.000 function_base.py:1079(diff)\n",
       "    68094    0.483    0.000    0.483    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "    34047    0.448    0.000  571.176    0.017 writer.py:390(add_histogram)\n",
       "   109364    0.442    0.000    0.442    0.000 {method 'release' of '_thread.lock' objects}\n",
       "    24602    0.437    0.000    7.918    0.000 writer.py:344(add_scalars)\n",
       "   548340    0.426    0.000    5.382    0.000 module.py:911(modules)\n",
       "   230265    0.408    0.000    0.525    0.000 serialization.py:57(_cuda_tag)\n",
       "      352    0.397    0.001    0.397    0.001 {built-in method randperm}\n",
       "      765    0.394    0.001    0.394    0.001 {method '_write_file' of 'torch._C.FloatStorageBase' objects}\n",
       "115995/703    0.389    0.000    1.814    0.003 module.py:976(train)\n",
       "    62164    0.384    0.000  503.316    0.008 writer.py:137(_add_event)\n",
       "   406065    0.381    0.000    1.344    0.000 train_misc.py:61(__call__)\n",
       "   238717    0.365    0.000   11.133    0.000 tensor.py:250(norm)\n",
       "    20039    0.364    0.000    0.364    0.000 utils.py:74(update)\n",
       "     3164    0.360    0.000    0.386    0.000 summary.py:380(text)\n",
       "    35207    0.354    0.000    0.354    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}\n",
       "    62164    0.330    0.000    0.888    0.000 threading.py:334(notify)\n",
       "    68094    0.316    0.000    6.293    0.000 fromnumeric.py:2651(ndim)\n",
       "    24602    0.296    0.000    2.547    0.000 writer.py:303(__append_to_scalar_dict)\n",
       "    83602    0.294    0.000    4.695    0.000 x2num.py:10(make_np)\n",
       "     6332    0.281    0.000    0.281    0.000 {built-in method zeros}\n",
       "   181561    0.272    0.000    0.279    0.000 module.py:521(__getattr__)\n",
       "   305546    0.269    0.000    0.269    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
       "     3515    0.267    0.000 33788.889    9.613 parallel_apply.py:21(parallel_apply)\n",
       "   231030    0.266    0.000    0.382    0.000 serialization.py:121(normalize_storage_type)\n",
       "    31665    0.262    0.000   26.416    0.001 threading.py:533(wait)\n",
       "   144704    0.235    0.000    0.366    0.000 _utils.py:5(_get_device_index)\n",
       "473950/472731    0.230    0.000    0.242    0.000 {built-in method builtins.issubclass}\n",
       "      302    0.228    0.001    0.228    0.001 {method '_set_from_file' of 'torch._C.FloatStorageBase' objects}\n",
       "      765    0.227    0.000  191.403    0.250 serialization.py:218(<lambda>)\n",
       "   238717    0.226    0.000    0.226    0.000 clip_grad.py:24(<lambda>)\n",
       "    59328    0.224    0.000    0.224    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
       "    34047    0.220    0.000    0.220    0.000 {built-in method numpy.core.multiarray.concatenate}\n",
       "   231224    0.219    0.000    0.219    0.000 {method 'storage' of 'torch._C._TensorBase' objects}\n",
       "     3515    0.218    0.000    0.571    0.000 replicate.py:12(<dictcomp>)\n",
       "    28143    0.213    0.000   23.970    0.001 threading.py:828(start)\n",
       "     9491    0.208    0.000    0.208    0.000 {built-in method exp}\n",
       "   231030    0.207    0.000    0.207    0.000 {method 'fileno' of '_io.BufferedWriter' objects}\n",
       "      126    0.202    0.002    0.202    0.002 {method 'read' of '_io.BufferedReader' objects}\n",
       "   115309    0.199    0.000    0.344    0.000 threading.py:254(_is_owned)\n",
       "    28143    0.198    0.000    0.549    0.000 threading.py:757(__init__)\n",
       "     6327    0.193    0.000    0.193    0.000 {built-in method sum}\n",
       "   136188    0.191    0.000    8.890    0.000 numeric.py:433(asarray)\n",
       "    34047    0.189    0.000    1.837    0.000 histograms.py:391(_search_sorted_inclusive)\n",
       "    49240    0.184    0.000 33763.696    0.686 threading.py:1062(_wait_for_tstate_lock)\n",
       "     3520    0.184    0.000    0.366    0.000 __init__.py:251(__init__)\n",
       "    34750    0.184    0.000    0.634    0.000 fromnumeric.py:64(_wrapreduction)\n",
       "    93829    0.183    0.000    0.273    0.000 threading.py:239(__enter__)\n",
       "      351    0.180    0.001    0.745    0.002 utils.py:6(make_grid)\n",
       "    27/24    0.180    0.007    0.186    0.008 {built-in method _imp.create_dynamic}\n",
       "    62164    0.179    0.000  502.874    0.008 event_file_writer.py:131(add_event)\n",
       "6628/6624    0.176    0.000    0.260    0.000 {built-in method builtins.__build_class__}\n",
       "    70200    0.176    0.000    0.176    0.000 {method 'narrow' of 'torch._C._TensorBase' objects}\n",
       "      351    0.175    0.000    0.295    0.001 utils.py:70(make_grid)\n",
       "    17086    0.174    0.000    0.390    0.000 {built-in method builtins.all}\n",
       "    59000    0.172    0.000    0.463    0.000 summary.py:64(_clean_tag)\n",
       "   344470    0.169    0.000    0.169    0.000 _functions.py:13(<genexpr>)\n",
       "     6677    0.167    0.000    2.748    0.000 _functions.py:52(forward)\n",
       "    28113    0.161    0.000 33763.894    1.201 threading.py:1024(join)\n",
       "   238717    0.160    0.000    0.160    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}\n",
       "   231030    0.157    0.000    0.157    0.000 serialization.py:52(_cpu_tag)\n",
       "    34047    0.153    0.000    0.153    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "   231224    0.151    0.000    0.151    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
       "    17605    0.150    0.000    2.418    0.000 iostream.py:195(schedule)\n",
       "   231030    0.150    0.000    0.150    0.000 hooks.py:51(warn_if_has_hooks)\n",
       "    93829    0.148    0.000    0.209    0.000 threading.py:242(__exit__)\n",
       "    31734    0.147    0.000    0.147    0.000 threading.py:215(__init__)\n",
       "    34047    0.141    0.000    0.279    0.000 histograms.py:220(_ravel_and_check_weights)\n",
       "    34047    0.141    0.000   27.273    0.001 fromnumeric.py:760(sort)\n",
       "   238927    0.137    0.000    0.137    0.000 {built-in method math.sqrt}\n",
       "   262697    0.136    0.000    0.136    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
       "     3163    0.136    0.000    0.136    0.000 {built-in method torch._C._nn.nll_loss}\n",
       "    83666    0.135    0.000    0.197    0.000 queue.py:202(_qsize)\n",
       "     3515    0.131    0.000   14.458    0.004 _functions.py:11(forward)\n",
       "     3515    0.128    0.000 33789.086    9.613 data_parallel.py:152(parallel_apply)\n",
       "     3515    0.126    0.000    0.126    0.000 _functions.py:28(<listcomp>)\n",
       "   231224    0.124    0.000    0.124    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
       "     8866    0.122    0.000    0.568    0.000 {method 'format' of 'str' objects}\n",
       "    91084    0.121    0.000    0.121    0.000 {built-in method _thread.allocate_lock}\n",
       "    59000    0.121    0.000    0.194    0.000 writer.py:314(_check_caffe2)\n",
       "   230265    0.117    0.000    0.117    0.000 {method 'get_device' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "   230265    0.115    0.000    0.115    0.000 {method 'size' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "    59776    0.110    0.000    0.149    0.000 threading.py:1230(current_thread)\n",
       "    53145    0.109    0.000    0.173    0.000 threading.py:251(_acquire_restore)\n",
       "    49555    0.108    0.000    0.230    0.000 numeric.py:1927(isscalar)\n",
       "      765    0.108    0.000    0.108    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
       "    17715    0.108    0.000    0.176    0.000 abc.py:180(__instancecheck__)\n",
       "      695    0.105    0.000    0.128    0.000 <frozen importlib._bootstrap_external>:830(get_data)\n",
       "    72409    0.105    0.000    0.105    0.000 {built-in method time.time}\n",
       "    34047    0.104    0.000    0.709    0.000 fromnumeric.py:1933(any)\n",
       "     3163    0.104    0.000    0.104    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}\n",
       "      703    0.104    0.000    0.104    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
       "     3163    0.104    0.000    0.104    0.000 {built-in method dropout}\n",
       "     6679    0.101    0.000   17.875    0.003 _functions.py:80(forward)\n",
       "   132914    0.100    0.000    0.100    0.000 {method 'append' of 'collections.deque' objects}\n",
       "     7040    0.099    0.000    2.239    0.000 iostream.py:382(write)\n",
       "    24610    0.098    0.000    0.758    0.000 cnf.py:88(num_evals)\n",
       "11598/3866    0.094    0.000   18.122    0.005 scatter_gather.py:11(scatter_map)\n",
       "    71608    0.094    0.000    0.177    0.000 numeric.py:504(asanyarray)\n",
       "    62164    0.093    0.000    0.139    0.000 queue.py:206(_put)\n",
       "    31665    0.091    0.000    0.264    0.000 threading.py:498(__init__)\n",
       "    34047    0.091    0.000    1.371    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "    93829    0.090    0.000    0.090    0.000 {method '__enter__' of '_thread.lock' objects}\n",
       "     7040    0.090    0.000   15.528    0.002 __init__.py:982(emit)\n",
       "     3515    0.085    0.000 33989.831    9.670 data_parallel.py:136(forward)\n",
       "      765    0.085    0.000    0.148    0.000 optimizer.py:88(<dictcomp>)\n",
       "     3163    0.084    0.000    0.084    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
       "     5975    0.084    0.000    3.954    0.001 x2num.py:27(prepare_pytorch)\n",
       "   173444    0.084    0.000    0.084    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
       "    21127    0.082    0.000    0.172    0.000 threading.py:1104(is_alive)\n",
       "     3514    0.082    0.000    0.234    0.000 _methods.py:58(_mean)\n",
       "9840/3514    0.081    0.000    2.995    0.001 scatter_gather.py:51(gather_map)\n",
       "     7040    0.078    0.000   12.971    0.002 __init__.py:971(flush)\n",
       "    29893    0.073    0.000    0.107    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "    53145    0.071    0.000    0.104    0.000 threading.py:248(_release_save)\n",
       "    59477    0.069    0.000    0.069    0.000 {method 'lstrip' of 'str' objects}\n",
       "    34047    0.068    0.000    1.280    0.000 _methods.py:30(_amin)\n",
       "     3520    0.067    0.000    0.128    0.000 __init__.py:1376(findCaller)\n",
       "    28112    0.065    0.000    0.081    0.000 threading.py:966(_stop)\n",
       "     3515    0.064    0.000    0.613    0.000 parallel_apply.py:67(<listcomp>)\n",
       "        1    0.064    0.064    0.064    0.064 {built-in method torch._C._cuda_init}\n",
       "     3522    0.064    0.000    4.815    0.001 iostream.py:334(flush)\n",
       "     3955    0.064    0.000    0.116    0.000 {built-in method builtins.sorted}\n",
       "    30360    0.064    0.000    0.064    0.000 _weakrefset.py:70(__contains__)\n",
       "    77406    0.063    0.000    0.063    0.000 threading.py:506(is_set)\n",
       "     6327    0.063    0.000    0.063    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
       "    24610    0.061    0.000    0.123    0.000 cnf_regularization.py:30(_num_evals)\n",
       "    93829    0.061    0.000    0.061    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "     3164    0.060    0.000    0.067    0.000 thops.py:47(split_feature)\n",
       "    53432    0.060    0.000    0.193    0.000 _functions.py:82(<lambda>)\n",
       "     3520    0.058    0.000   15.726    0.004 __init__.py:1500(callHandlers)\n",
       "31502/29713    0.057    0.000    1.576    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
       "    34047    0.057    0.000    0.515    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "    34047    0.057    0.000    0.575    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "     7040    0.056    0.000   15.668    0.002 __init__.py:852(handle)\n",
       "     7040    0.056    0.000    0.185    0.000 __init__.py:564(format)\n",
       "     6327    0.056    0.000    0.825    0.000 functional.py:1335(linear)\n",
       "     3164    0.056    0.000    0.703    0.000 writer.py:523(add_text)\n",
       "7386/2462    0.056    0.000   16.985    0.007 dataloader.py:237(pin_memory_batch)\n",
       "    53416    0.054    0.000    0.088    0.000 _functions.py:58(<lambda>)\n",
       "      351    0.054    0.000    0.054    0.000 {method 'close' of '_io.BufferedRandom' objects}\n",
       "    16168    0.053    0.000    0.053    0.000 {built-in method torch._C._get_tracing_state}\n",
       "     3515    0.052    0.000  179.403    0.051 data_parallel.py:146(replicate)\n",
       "      695    0.052    0.000    0.052    0.000 {built-in method marshal.loads}\n",
       "    53416    0.051    0.000    0.096    0.000 _functions.py:67(<lambda>)\n",
       "      702    0.049    0.000    0.049    0.000 {method 'decode' of 'ImagingDecoder' objects}\n",
       "     2462    0.049    0.000    0.049    0.000 {built-in method ones_like}\n",
       "     3325    0.048    0.000    0.265    0.000 module.py:62(__init__)\n",
       "    28112    0.048    0.000    0.066    0.000 _weakrefset.py:38(_remove)\n",
       "     2462    0.048    0.000    0.059    0.000 train_cnf_drop.py:139(update_lr)\n",
       "     3165    0.047    0.000    1.668    0.001 thops.py:4(onehot)\n",
       "    34047    0.047    0.000    0.519    0.000 _methods.py:26(_amax)\n",
       "    66773    0.046    0.000    0.046    0.000 {method 'get_device' of 'torch._C._TensorBase' objects}\n",
       "     3515    0.046    0.000   18.209    0.005 scatter_gather.py:33(scatter_kwargs)\n",
       "      703    0.046    0.000    0.226    0.000 dataloader.py:518(__init__)\n",
       "    24603    0.046    0.000    0.062    0.000 writer.py:204(get_logdir)\n",
       "    67268    0.045    0.000    0.045    0.000 {built-in method _thread.get_ident}\n",
       "    28661    0.045    0.000    0.062    0.000 _weakrefset.py:81(add)\n",
       "    34047    0.043    0.000    0.458    0.000 _methods.py:34(_sum)\n",
       "     3163    0.042    0.000    0.937    0.000 modules.py:277(logp)\n",
       "    38665    0.042    0.000    6.550    0.000 module.py:834(buffers)\n",
       "      765    0.041    0.000    0.073    0.000 optimizer.py:84(<listcomp>)\n",
       "    38665    0.041    0.000    6.508    0.000 module.py:856(named_buffers)\n",
       "    62018    0.041    0.000    0.041    0.000 {method 'items' of 'dict' objects}\n",
       "     3520    0.040    0.000   16.321    0.005 __init__.py:1421(_log)\n",
       "     3163    0.040    0.000    0.824    0.000 odenvp_conditional_tol.py:155(loss_class)\n",
       "     3520    0.040    0.000   16.391    0.005 __init__.py:1298(info)\n",
       "     3060    0.039    0.000    0.039    0.000 {built-in method _pickle.dump}\n",
       "     6327    0.037    0.000    0.874    0.000 linear.py:65(forward)\n",
       "    34961    0.037    0.000    0.037    0.000 {method 'rpartition' of 'str' objects}\n",
       "     2461    0.037    0.000 49094.557   19.949 tensor.py:74(backward)\n",
       "    14080    0.036    0.000    0.056    0.000 __init__.py:809(acquire)\n",
       "    28143    0.036    0.000    0.036    0.000 threading.py:727(_newname)\n",
       "    34047    0.036    0.000    0.036    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "        2    0.035    0.017    0.035    0.017 {method '_set_from_file' of 'torch._C.ByteStorageBase' objects}\n",
       "     3165    0.034    0.000    0.034    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}\n",
       "     3515    0.033    0.000    0.043    0.000 replicate.py:15(<listcomp>)\n",
       "     1147    0.033    0.000    0.033    0.000 {built-in method torch._C._cuda_isDriverSufficient}\n",
       "    34047    0.033    0.000    0.033    0.000 {built-in method numpy.core.multiarray.normalize_axis_index}\n",
       "    17605    0.033    0.000    0.033    0.000 iostream.py:93(_event_pipe)\n",
       "    53416    0.033    0.000    0.033    0.000 _functions.py:54(<lambda>)\n",
       "    14080    0.033    0.000    0.044    0.000 __init__.py:816(release)\n",
       "     3163    0.032    0.000    0.181    0.000 functional.py:1734(nll_loss)\n",
       "     3163    0.032    0.000    0.153    0.000 thops.py:15(sum)\n",
       "     3514    0.030    0.000    0.264    0.000 fromnumeric.py:2817(mean)\n",
       "     4858    0.030    0.000    0.069    0.000 posixpath.py:121(splitext)\n",
       "     4922    0.029    0.000    0.445    0.000 tensor.py:362(__format__)\n",
       "    50007    0.029    0.000    0.029    0.000 {method 'keys' of 'dict' objects}\n",
       "     7040    0.028    0.000    0.213    0.000 __init__.py:829(format)\n",
       "    28120    0.028    0.000    0.096    0.000 parallel_apply.py:45(<lambda>)\n",
       "     3163    0.028    0.000    0.148    0.000 functional.py:728(dropout)\n",
       "    28120    0.028    0.000    0.094    0.000 replicate.py:8(<lambda>)\n",
       "     3515    0.028    0.000    0.067    0.000 replicate.py:19(<dictcomp>)\n",
       "      352    0.027    0.000    0.027    0.000 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
       "     3841    0.027    0.000    0.052    0.000 posixpath.py:144(basename)\n",
       "    28120    0.027    0.000    0.093    0.000 _functions.py:15(<lambda>)\n",
       "        3    0.027    0.009    0.079    0.026 utils.py:70(parse_header)\n",
       "     6679    0.027    0.000   17.575    0.003 comm.py:131(scatter)\n",
       "     2461    0.026    0.000 49094.521   19.949 __init__.py:38(backward)\n",
       "     3520    0.026    0.000   15.761    0.004 __init__.py:1446(handle)\n",
       "     7040    0.025    0.000    0.064    0.000 __init__.py:542(usesTime)\n",
       "    24602    0.025    0.000    0.025    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
       "     3520    0.025    0.000    0.391    0.000 __init__.py:1406(makeRecord)\n",
       "     7040    0.025    0.000    0.202    0.000 iostream.py:320(_schedule_flush)\n",
       "     6327    0.024    0.000    0.024    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
       "     3163    0.024    0.000    0.024    0.000 {method 'squeeze_' of 'torch._C._TensorBase' objects}\n",
       "     7040    0.024    0.000    0.038    0.000 __init__.py:387(usesTime)\n",
       "     3514    0.024    0.000    0.026    0.000 _methods.py:48(_count_reduce_items)\n",
       "    14418    0.024    0.000    0.024    0.000 {method 'rfind' of 'str' objects}\n",
       "      351    0.024    0.000    3.952    0.011 summary.py:248(make_image)\n",
       "     7040    0.024    0.000    0.024    0.000 __init__.py:390(format)\n",
       "     7040    0.023    0.000    0.032    0.000 iostream.py:307(_is_master_process)\n",
       "      695    0.023    0.000    0.023    0.000 {method 'read' of '_io.FileIO' objects}\n",
       "     2461    0.023    0.000    0.080    0.000 __init__.py:20(_make_grads)\n",
       "      412    0.023    0.000    0.023    0.000 {built-in method posix.listdir}\n",
       "    10560    0.023    0.000    0.023    0.000 __init__.py:705(filter)\n",
       "     2461    0.022    0.000    4.584    0.002 train_misc.py:54(count_nfe)\n",
       "     3520    0.022    0.000    0.031    0.000 __init__.py:1544(isEnabledFor)\n",
       "    43892    0.021    0.000    0.021    0.000 {method 'startswith' of 'str' objects}\n",
       "     4858    0.021    0.000    0.032    0.000 genericpath.py:117(_splitext)\n",
       "      351    0.021    0.000    0.021    0.000 {built-in method cat}\n",
       "     4086    0.021    0.000   46.029    0.011 {built-in method builtins.next}\n",
       "     6677    0.021    0.000    2.269    0.000 comm.py:151(gather)\n",
       "     3358    0.021    0.000    3.684    0.001 train_cnf_drop.py:388(<lambda>)\n",
       "  742/127    0.021    0.000    0.071    0.001 sre_parse.py:470(_parse)\n",
       "     3543    0.020    0.000    0.032    0.000 posixpath.py:52(normcase)\n",
       "     3359    0.020    0.000    0.020    0.000 {method 'type' of 'torch._C._TensorBase' objects}\n",
       "    14101    0.020    0.000    0.020    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "     2461    0.020    0.000    5.373    0.002 train_misc.py:74(count_total_time)\n",
       "     3163    0.019    0.000    0.359    0.000 loss.py:22(__init__)\n",
       "    28143    0.019    0.000    0.019    0.000 threading.py:1120(daemon)\n",
       "     1264    0.019    0.000    0.216    0.000 <frozen importlib._bootstrap_external>:1233(find_spec)\n",
       "     7030    0.019    0.000   15.370    0.002 comm.py:24(broadcast_coalesced)\n",
       "     3520    0.019    0.000    8.297    0.002 __init__.py:1063(emit)\n",
       "    28112    0.018    0.000    0.018    0.000 {method 'discard' of 'set' objects}\n",
       "    28107    0.018    0.000    0.018    0.000 {method 'remove' of 'collections.deque' objects}\n",
       "     3163    0.018    0.000    0.320    0.000 functional.py:1923(cross_entropy)\n",
       "      702    0.018    0.000    7.391    0.011 Image.py:1892(save)\n",
       "      702    0.018    0.000    4.070    0.006 ImageFile.py:463(_save)\n",
       "     7040    0.018    0.000    0.024    0.000 __init__.py:329(getMessage)\n",
       "    17296    0.017    0.000    0.017    0.000 {built-in method posix.fspath}\n",
       "     3163    0.017    0.000    0.395    0.000 loss.py:896(__init__)\n",
       "     3163    0.017    0.000    0.340    0.000 loss.py:901(forward)\n",
       "     7040    0.017    0.000    0.041    0.000 __init__.py:548(formatMessage)\n",
       "      351    0.017    0.000    5.333    0.015 utils.py:90(save_image)\n",
       "     3163    0.017    0.000    0.290    0.000 loss.py:13(__init__)\n",
       "     3163    0.017    0.000    0.165    0.000 dropout.py:56(forward)\n",
       "    13354    0.017    0.000    0.020    0.000 _functions.py:59(<genexpr>)\n",
       "     3520    0.016    0.000    0.024    0.000 __init__.py:157(<lambda>)\n",
       "    28112    0.016    0.000    0.016    0.000 {method 'locked' of '_thread.lock' objects}\n",
       "    24603    0.016    0.000    0.016    0.000 event_file_writer.py:118(get_logdir)\n",
       "     8511    0.016    0.000    0.016    0.000 {method 'find' of 'str' objects}\n",
       "     1974    0.016    0.000    0.028    0.000 posixpath.py:75(join)\n",
       "     2106    0.016    0.000    0.016    0.000 {built-in method zlib.crc32}\n",
       "     7040    0.015    0.000    0.015    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
       "      351    0.015    0.000    0.015    0.000 {method 'copy' of 'ImagingCore' objects}\n",
       "     3866    0.015    0.000   18.137    0.005 scatter_gather.py:5(scatter)\n",
       "     3173    0.015    0.000    0.050    0.000 module.py:87(register_buffer)\n",
       "     8743    0.015    0.000    0.042    0.000 <frozen importlib._bootstrap_external>:57(_path_join)\n",
       "     3514    0.015    0.000    3.023    0.001 data_parallel.py:155(gather)\n",
       "     3515    0.015    0.000   18.224    0.005 data_parallel.py:149(scatter)\n",
       "     3163    0.014    0.000    0.121    0.000 functional.py:1271(log_softmax)\n",
       "     3163    0.014    0.000    0.762    0.000 fromnumeric.py:976(argmax)\n",
       " 1482/120    0.014    0.000    0.063    0.001 sre_compile.py:64(_compile)\n",
       "     3187    0.014    0.000    0.014    0.000 {method 'SerializeToString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "      351    0.014    0.000    0.014    0.000 {method 'mul' of 'torch._C._TensorBase' objects}\n",
       "     2462    0.014    0.000   16.889    0.007 dataloader.py:245(<listcomp>)\n",
       "     8743    0.013    0.000    0.022    0.000 <frozen importlib._bootstrap_external>:59(<listcomp>)\n",
       "     3164    0.013    0.000    0.013    0.000 scatter_gather.py:40(<listcomp>)\n",
       "     3514    0.013    0.000    3.008    0.001 scatter_gather.py:46(gather)\n",
       "     4922    0.013    0.000    0.013    0.000 {method '__format__' of 'float' objects}\n",
       "    10565    0.013    0.000    0.013    0.000 {built-in method posix.getpid}\n",
       "    26739    0.013    0.000    0.013    0.000 {method 'rstrip' of 'str' objects}\n",
       "      351    0.012    0.000    1.111    0.003 JpegImagePlugin.py:617(_save)\n",
       "     1528    0.012    0.000    0.030    0.000 version.py:198(__init__)\n",
       "    14811    0.012    0.000    0.021    0.000 sre_parse.py:253(get)\n",
       "     3445    0.012    0.000    0.012    0.000 {method 'encode' of 'str' objects}\n",
       "     3163    0.012    0.000    0.748    0.000 fromnumeric.py:49(_wrapfunc)\n",
       "     6703    0.012    0.000    0.018    0.000 posixpath.py:41(_get_sep)\n",
       "    14101    0.012    0.000    0.012    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "      184    0.012    0.000    0.024    0.000 module.py:647(_load_from_state_dict)\n",
       "     3520    0.011    0.000    0.016    0.000 __init__.py:120(getLevelName)\n",
       "      351    0.011    0.000    3.015    0.009 PngImagePlugin.py:689(_save)\n",
       "       14    0.011    0.001    0.011    0.001 {built-in method _pickle.load}\n",
       "     5975    0.011    0.000    0.014    0.000 variable.py:6(__instancecheck__)\n",
       "     3163    0.011    0.000    0.011    0.000 {method 'long' of 'torch._C._TensorBase' objects}\n",
       "      351    0.011    0.000    0.011    0.000 {method 'byte' of 'torch._C._TensorBase' objects}\n",
       "     3520    0.010    0.000    0.010    0.000 threading.py:1076(name)\n",
       "    16531    0.010    0.000    0.010    0.000 sre_parse.py:232(__next)\n",
       "     1053    0.010    0.000    0.043    0.000 PngImagePlugin.py:667(putchunk)\n",
       "     4167    0.009    0.000    0.025    0.000 enum.py:803(__and__)\n",
       "    719/1    0.009    0.000 89152.324 89152.324 {built-in method builtins.exec}\n",
       "      351    0.009    0.000    0.310    0.001 utils.py:95(convert_to_HWC)\n",
       "      351    0.009    0.000    0.009    0.000 {method 'clamp' of 'torch._C._TensorBase' objects}\n",
       "     9613    0.009    0.000    0.016    0.000 enum.py:267(__call__)\n",
       "     1146    0.009    0.000    0.045    0.000 __init__.py:45(is_available)\n",
       "     3510    0.009    0.000    0.009    0.000 {method 'write' of '_io.BytesIO' objects}\n",
       "     3520    0.009    0.000    0.009    0.000 __init__.py:1530(getEffectiveLevel)\n",
       "     3164    0.009    0.000    0.016    0.000 _VF.py:11(__getattr__)\n",
       "      765    0.008    0.000  198.385    0.259 serialization.py:131(_with_file_like)\n",
       "11942/11870    0.008    0.000    0.010    0.000 {method 'join' of 'str' objects}\n",
       "     3163    0.008    0.000    0.008    0.000 {method 'nelement' of 'torch._C._TensorBase' objects}\n",
       "     3515    0.008    0.000    0.008    0.000 replicate.py:23(<listcomp>)\n",
       "      352    0.008    0.000    4.522    0.013 train_cnf_drop.py:146(get_train_loader)\n",
       "     3901    0.007    0.000    0.007    0.000 {built-in method sys._getframe}\n",
       "      695    0.007    0.000    0.011    0.000 <frozen importlib._bootstrap_external>:430(_validate_bytecode_header)\n",
       "      765    0.007    0.000    0.239    0.000 optimizer.py:72(state_dict)\n",
       "      749    0.007    0.000    0.216    0.000 <frozen importlib._bootstrap>:870(_find_spec)\n",
       "      351    0.007    0.000    0.007    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
       "      351    0.007    0.000    8.415    0.024 writer.py:429(add_images)\n",
       "     1390    0.007    0.000    0.022    0.000 <frozen importlib._bootstrap_external>:263(cache_from_source)\n",
       " 1066/326    0.007    0.000    2.053    0.006 <frozen importlib._bootstrap>:966(_find_and_load)\n",
       "     1986    0.007    0.000    0.012    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "      695    0.007    0.000    0.250    0.000 <frozen importlib._bootstrap_external>:743(get_code)\n",
       "     5477    0.007    0.000    0.007    0.000 {built-in method torch._C.is_grad_enabled}\n",
       "     9612    0.007    0.000    0.007    0.000 enum.py:517(__new__)\n",
       "      353    0.007    0.000    0.023    0.000 dataloader.py:768(__init__)\n",
       "     1758    0.007    0.000    0.009    0.000 tensor.py:395(__len__)\n",
       "     9490    0.006    0.000    0.006    0.000 __init__.py:1408(_unwrap_optional)\n",
       "      614    0.006    0.000    0.011    0.000 sre_compile.py:250(_optimize_charset)\n",
       "     3515    0.006    0.000    0.006    0.000 replicate.py:69(<listcomp>)\n",
       "    10563    0.006    0.000    0.006    0.000 {method 'split' of 'str' objects}\n",
       "     6232    0.006    0.000    0.009    0.000 sre_parse.py:163(__getitem__)\n",
       "     3883    0.006    0.000    0.006    0.000 dataloader.py:811(__setattr__)\n",
       "      836    0.006    0.000    0.010    0.000 posixpath.py:154(dirname)\n",
       "      702    0.006    0.000    0.066    0.000 Image.py:779(frombytes)\n",
       "     3521    0.006    0.000    0.006    0.000 process.py:35(current_process)\n",
       "      724    0.006    0.000    0.026    0.000 <frozen importlib._bootstrap>:504(_init_module_attrs)\n",
       "     3515    0.006    0.000    0.006    0.000 function.py:45(mark_non_differentiable)\n",
       "      765    0.005    0.000  198.390    0.259 serialization.py:191(save)\n",
       "      765    0.005    0.000    0.081    0.000 optimizer.py:82(pack_group)\n",
       "     2735    0.005    0.000    0.005    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
       "     6686    0.005    0.000    0.005    0.000 {built-in method builtins.min}\n",
       "      760    0.005    0.000    0.016    0.000 version.py:131(_legacy_cmpkey)\n",
       "     3312    0.005    0.000    0.009    0.000 version.py:114(_parse_version_parts)\n",
       "      702    0.005    0.000    0.009    0.000 Image.py:430(_getdecoder)\n",
       "      981    0.005    0.000    0.006    0.000 grad_mode.py:31(__enter__)\n",
       "      766    0.005    0.000    1.523    0.002 utils.py:8(makedirs)\n",
       "     4833    0.005    0.000    0.175    0.000 <frozen importlib._bootstrap_external>:75(_path_stat)\n",
       "      702    0.005    0.000    0.035    0.000 fromnumeric.py:1821(sum)\n",
       " 2304/962    0.005    0.000    0.007    0.000 sre_parse.py:173(getwidth)\n",
       "     3520    0.005    0.000    0.005    0.000 process.py:146(name)\n",
       "     3814    0.005    0.000    0.008    0.000 utils.py:51(add_argument)\n",
       "     2461    0.005    0.000    0.005    0.000 train_misc.py:56(AccNumEvals)\n",
       "     3790    0.005    0.000    0.005    0.000 {method 'extend' of 'list' objects}\n",
       "       97    0.005    0.000    0.012    0.000 <frozen importlib._bootstrap_external>:1067(_path_hooks)\n",
       "      981    0.005    0.000    0.011    0.000 grad_mode.py:35(__exit__)\n",
       "     1758    0.005    0.000    0.018    0.000 mnist.py:84(__len__)\n",
       "   738/21    0.005    0.000    2.012    0.096 <frozen importlib._bootstrap>:651(_load_unlocked)\n",
       "    12310    0.005    0.000    0.005    0.000 {method 'strip' of 'str' objects}\n",
       "      702    0.005    0.000    0.144    0.000 Image.py:2353(frombytes)\n",
       "        1    0.005    0.005    0.005    0.005 {built-in method builtins.compile}\n",
       "     3522    0.005    0.000    0.005    0.000 {built-in method _imp.lock_held}\n",
       "     7541    0.005    0.000    0.005    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "      703    0.005    0.000    0.231    0.000 dataloader.py:818(__iter__)\n",
       "       28    0.005    0.000    0.005    0.000 {method 'readlines' of '_io._IOBase' objects}\n",
       "     2461    0.005    0.000    0.005    0.000 train_misc.py:76(Accumulator)\n",
       "  483/175    0.004    0.000    0.013    0.000 abc.py:196(__subclasscheck__)\n",
       "   760/20    0.004    0.000    2.041    0.102 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)\n",
       "     1986    0.004    0.000    0.005    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "     3740    0.004    0.000    0.007    0.000 version.py:65(_compare)\n",
       "     1112    0.004    0.000    1.568    0.001 genericpath.py:16(exists)\n",
       "     3163    0.004    0.000    0.004    0.000 _reduction.py:8(get_enum)\n",
       "      352    0.004    0.000    1.197    0.003 sampler.py:69(__iter__)\n",
       "      981    0.004    0.000    0.006    0.000 grad_mode.py:122(__init__)\n",
       "     3488    0.004    0.000    0.007    0.000 utils.py:81(<lambda>)\n",
       "     3488    0.004    0.000    0.007    0.000 utils.py:79(<lambda>)\n",
       "     1986    0.004    0.000    0.005    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "     2874    0.004    0.000    0.069    0.000 <frozen importlib._bootstrap_external>:85(_path_is_mode_type)\n",
       "     2808    0.004    0.000    0.007    0.000 _binary.py:93(o32be)\n",
       "     8042    0.004    0.000    0.004    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
       "     2461    0.004    0.000    0.004    0.000 train_misc.py:78(__init__)\n",
       "     3163    0.004    0.000    0.004    0.000 modules.py:280(<listcomp>)\n",
       "     2106    0.004    0.000    0.020    0.000 PngImagePlugin.py:90(_crc32)\n",
       "      768    0.004    0.000    0.005    0.000 version.py:343(_cmpkey)\n",
       "  750/749    0.004    0.000    0.199    0.000 <frozen importlib._bootstrap_external>:1117(_get_spec)\n",
       "      107    0.004    0.000    0.004    0.000 {method 'cuda' of 'torch._C._TensorBase' objects}\n",
       "     2461    0.004    0.000    0.004    0.000 train_misc.py:58(__init__)\n",
       "     4226    0.004    0.000    0.005    0.000 utils.py:92(<lambda>)\n",
       "     4133    0.003    0.000    0.003    0.000 {built-in method builtins.setattr}\n",
       "     1531    0.003    0.000    0.003    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n",
       "  498/120    0.003    0.000    0.072    0.001 sre_parse.py:407(_parse_sub)\n",
       "      351    0.003    0.000    0.024    0.000 Image.py:1738(resize)\n",
       "      421    0.003    0.000    0.004    0.000 PyColorize.py:284(_inner_call_)\n",
       "       10    0.003    0.000    0.003    0.000 {built-in method sqrt}\n",
       "        3    0.003    0.001    0.023    0.008 {method 'load' of '_pickle.Unpickler' objects}\n",
       "      352    0.003    0.000    0.010    0.000 inspect.py:2100(_signature_from_function)\n",
       "        1    0.003    0.003    0.003    0.003 {built-in method posix.read}\n",
       "      702    0.003    0.000    0.003    0.000 {method 'flush' of '_io.BufferedRandom' objects}\n",
       "     2583    0.003    0.000    0.005    0.000 {built-in method builtins.any}\n",
       "     3814    0.003    0.000    0.003    0.000 utils.py:61(__init__)\n",
       "     2877    0.003    0.000    0.003    0.000 {built-in method _struct.pack}\n",
       "     1361    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "      695    0.003    0.000    0.056    0.000 <frozen importlib._bootstrap_external>:485(_compile_bytecode)\n",
       "     3488    0.003    0.000    0.004    0.000 utils.py:83(<lambda>)\n",
       "      724    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:524(spec_from_file_location)\n",
       "     3830    0.003    0.000    0.004    0.000 utils.py:75(<lambda>)\n",
       "      715    0.003    0.000    0.003    0.000 {method 'sort' of 'list' objects}\n",
       "     1564    0.003    0.000    0.003    0.000 {built-in method builtins.iter}\n",
       "      351    0.003    0.000    0.003    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
       "     1762    0.003    0.000    0.004    0.000 __init__.py:1972(dist_factory)\n",
       "      320    0.003    0.000    0.048    0.000 __init__.py:2481(from_location)\n",
       "     3488    0.003    0.000    0.004    0.000 utils.py:77(<lambda>)\n",
       "     5821    0.003    0.000    0.003    0.000 {built-in method _imp.acquire_lock}\n",
       "        1    0.003    0.003    0.014    0.014 {built-in method torch._C._initExtension}\n",
       "     2488    0.003    0.000    0.063    0.000 <frozen importlib._bootstrap_external>:94(_path_isfile)\n",
       "      628    0.003    0.000    0.063    0.000 __init__.py:2027(distributions_from_metadata)\n",
       "     5821    0.003    0.000    0.003    0.000 {built-in method _imp.release_lock}\n",
       "      574    0.003    0.000    0.006    0.000 tokenize.py:492(_tokenize)\n",
       "      702    0.003    0.000    0.003    0.000 {built-in method PIL._imaging.raw_decoder}\n",
       "      351    0.003    0.000    0.003    0.000 {built-in method PIL._imaging.jpeg_encoder}\n",
       "      351    0.003    0.000    0.010    0.000 sampler.py:33(__iter__)\n",
       "   695/19    0.003    0.000    2.011    0.106 <frozen importlib._bootstrap_external>:672(exec_module)\n",
       "    893/1    0.003    0.000    0.014    0.014 copy.py:132(deepcopy)\n",
       "     1361    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "       16    0.002    0.000    0.002    0.000 traitlets.py:596(_cross_validate)\n",
       "  724/718    0.002    0.000    0.217    0.000 <frozen importlib._bootstrap>:564(module_from_spec)\n",
       "     4189    0.002    0.000    0.003    0.000 sre_parse.py:248(match)\n",
       "     3423    0.002    0.000    0.002    0.000 {method 'endswith' of 'str' objects}\n",
       "     4703    0.002    0.000    0.002    0.000 {method 'lower' of 'str' objects}\n",
       "     1390    0.002    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:63(_path_split)\n",
       "      990    0.002    0.000    0.150    0.000 re.py:286(_compile)\n",
       "      724    0.002    0.000    0.006    0.000 <frozen importlib._bootstrap>:318(__exit__)\n",
       "      765    0.002    0.000    0.002    0.000 optimizer.py:83(<dictcomp>)\n",
       "        1    0.002    0.002    0.002    0.002 {built-in method _posixsubprocess.fork_exec}\n",
       "      351    0.002    0.000    0.003    0.000 summary.py:59(_calc_scale_factor)\n",
       "      614    0.002    0.000    0.016    0.000 sre_compile.py:223(_compile_charset)\n",
       "      352    0.002    0.000    0.008    0.000 sampler.py:50(__init__)\n",
       "        1    0.002    0.002    0.004    0.004 packages.py:1(<module>)\n",
       "      512    0.002    0.000    0.007    0.000 copy.py:66(copy)\n",
       "     1066    0.002    0.000    0.014    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "    368/2    0.002    0.000    0.007    0.003 module.py:1024(__repr__)\n",
       "     2307    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:847(__exit__)\n",
       "      320    0.002    0.000    0.005    0.000 __init__.py:683(add)\n",
       "      920    0.002    0.000    0.010    0.000 <frozen importlib._bootstrap>:194(_lock_unlock_module)\n",
       "     1076    0.002    0.000    0.032    0.000 version.py:24(parse)\n",
       "      702    0.002    0.000    0.002    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "     2992    0.002    0.000    0.002    0.000 version.py:207(<genexpr>)\n",
       "      724    0.002    0.000    0.007    0.000 <frozen importlib._bootstrap_external>:1228(_get_spec)\n",
       "      352    0.002    0.000    0.005    0.000 inspect.py:2832(_hash_basis)\n",
       "      326    0.002    0.000    0.045    0.000 __init__.py:2094(_handle_ns)\n",
       "      353    0.002    0.000    0.003    0.000 sampler.py:142(__init__)\n",
       "      722    0.002    0.000    0.014    0.000 <frozen importlib._bootstrap_external>:361(_get_cached)\n",
       "     2281    0.002    0.000    0.003    0.000 sre_parse.py:159(__len__)\n",
       "      352    0.002    0.000    0.015    0.000 inspect.py:2181(_signature_from_callable)\n",
       "      744    0.002    0.000    0.004    0.000 inspect.py:2450(__init__)\n",
       "     2307    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:843(__enter__)\n",
       "      765    0.002    0.000    0.083    0.000 optimizer.py:86(<listcomp>)\n",
       "      351    0.002    0.000    0.003    0.000 utils.py:102(<listcomp>)\n",
       "     2103    0.002    0.000    0.003    0.000 sre_parse.py:171(append)\n",
       "      351    0.002    0.000    0.021    0.000 Image.py:1083(copy)\n",
       "      859    0.002    0.000    0.002    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
       "     2288    0.002    0.000    0.002    0.000 {method 'upper' of 'str' objects}\n",
       "     1390    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:52(_r_long)\n",
       "      306    0.002    0.000    0.016    0.000 _utils.py:127(_rebuild_tensor)\n",
       "      306    0.002    0.000    0.003    0.000 serialization.py:513(persistent_load)\n",
       "      691    0.002    0.000    0.018    0.000 __init__.py:2647(_get_metadata)\n",
       "        1    0.002    0.002    0.026    0.026 binding.py:81(build_conditional_library)\n",
       "      351    0.002    0.000    0.003    0.000 JpegImagePlugin.py:626(<listcomp>)\n",
       "     1866    0.002    0.000    0.002    0.000 sre_parse.py:285(tell)\n",
       "      138    0.002    0.000    0.002    0.000 {method 'splitlines' of 'str' objects}\n",
       "       93    0.002    0.000    0.002    0.000 function.py:89(__init__)\n",
       "      194    0.002    0.000    0.008    0.000 tensor.py:16(__deepcopy__)\n",
       "     4226    0.002    0.000    0.002    0.000 utils.py:94(<lambda>)\n",
       "      500    0.002    0.000    0.002    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
       "     1417    0.002    0.000    0.015    0.000 <frozen importlib._bootstrap>:403(cached)\n",
       "        1    0.002    0.002    0.002    0.002 {built-in method normal}\n",
       "     3828    0.002    0.000    0.002    0.000 {method 'partition' of 'str' objects}\n",
       "     1870    0.002    0.000    0.005    0.000 version.py:47(__lt__)\n",
       "       16    0.001    0.000    0.001    0.000 {method 'AddSerializedFile' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "      330    0.001    0.000    0.005    0.000 __init__.py:1958(<genexpr>)\n",
       "      452    0.001    0.000    0.022    0.000 __init__.py:1323(safe_version)\n",
       "     1870    0.001    0.000    0.005    0.000 version.py:53(__eq__)\n",
       "     2896    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:321(<genexpr>)\n",
       "      956    0.001    0.000    0.002    0.000 __init__.py:2540(key)\n",
       "      452    0.001    0.000    0.004    0.000 version.py:236(__str__)\n",
       "      352    0.001    0.000    0.003    0.000 inspect.py:2730(__init__)\n",
       "     1137    0.001    0.000    0.003    0.000 _weakrefset.py:58(__iter__)\n",
       "      150    0.001    0.000    0.024    0.000 utils.py:89(verify_interface)\n",
       "     1066    0.001    0.000    0.005    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "       40    0.001    0.000    0.012    0.000 PyColorize.py:207(format2)\n",
       "      194    0.001    0.000    0.001    0.000 {method 'copy_' of 'torch._C.FloatStorageBase' objects}\n",
       "       52    0.001    0.000    1.362    0.026 __init__.py:1(<module>)\n",
       "      702    0.001    0.000    0.001    0.000 {built-in method builtins.round}\n",
       "      775    0.001    0.000    0.001    0.000 {method 'split' of '_sre.SRE_Pattern' objects}\n",
       "      351    0.001    0.000    0.842    0.002 module.py:992(eval)\n",
       "     1962    0.001    0.000    0.001    0.000 {built-in method torch._C.set_grad_enabled}\n",
       "      342    0.001    0.000    0.131    0.000 __init__.py:1940(find_on_path)\n",
       "      695    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:393(_check_name_wrapper)\n",
       "      695    0.001    0.000    0.035    0.000 <frozen importlib._bootstrap_external>:840(path_stats)\n",
       "      982    0.001    0.000    0.013    0.000 <frozen importlib._bootstrap_external>:1080(_path_importer_cache)\n",
       "      749    0.001    0.000    0.201    0.000 <frozen importlib._bootstrap_external>:1149(find_spec)\n",
       "       68    0.001    0.000    0.001    0.000 {built-in method posix.lstat}\n",
       "      133    0.001    0.000    0.002    0.000 pyparsing.py:3260(__init__)\n",
       "   963/20    0.001    0.000    1.996    0.100 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "      471    0.001    0.000    0.003    0.000 copy.py:268(_reconstruct)\n",
       "      959    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C.FloatStorageBase' objects}\n",
       "     1482    0.001    0.000    0.001    0.000 sre_parse.py:111(__init__)\n",
       "     1054    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "     1172    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
       "       29    0.001    0.000    0.014    0.000 traceback.py:319(extract)\n",
       "        1    0.001    0.001    0.002    0.002 descriptor_pb2.py:4(<module>)\n",
       "   530/46    0.001    0.000    1.589    0.035 {built-in method builtins.__import__}\n",
       "       80    0.001    0.000    0.002    0.000 configurable.py:102(<listcomp>)\n",
       "      697    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
       "       32    0.001    0.000    0.001    0.000 {method 'readline' of '_io.BufferedReader' objects}\n",
       "      120    0.001    0.000    0.005    0.000 sre_compile.py:482(_compile_info)\n",
       "      702    0.001    0.000    0.002    0.000 _util.py:10(isPath)\n",
       "      630    0.001    0.000    0.002    0.000 sre_compile.py:388(_simple)\n",
       "       31    0.001    0.000    0.003    0.000 auto.py:107(_make_function_class)\n",
       "       25    0.001    0.000    0.001    0.000 {built-in method builtins.dir}\n",
       "      537    0.001    0.000    0.003    0.000 __init__.py:2281(yield_lines)\n",
       "      748    0.001    0.000    0.002    0.000 __init__.py:2688(__getattr__)\n",
       "    165/1    0.001    0.000    0.006    0.006 module.py:185(_apply)\n",
       "       84    0.001    0.000    0.001    0.000 init.py:178(_calculate_fan_in_and_fan_out)\n",
       "      507    0.001    0.000    0.001    0.000 _weakrefset.py:36(__init__)\n",
       "     1758    0.001    0.000    0.001    0.000 version.py:244(<genexpr>)\n",
       "     1390    0.001    0.000    0.001    0.000 {built-in method from_bytes}\n",
       "      351    0.001    0.000    0.001    0.000 {built-in method PIL._imaging.zip_encoder}\n",
       "      760    0.001    0.000    0.017    0.000 version.py:74(__init__)\n",
       "      282    0.001    0.000    0.003    0.000 function_base.py:3895(add_newdoc)\n",
       "       86    0.001    0.000    0.004    0.000 abc.py:132(__new__)\n",
       "       20    0.001    0.000    0.001    0.000 {method 'read' of '_io.TextIOWrapper' objects}\n",
       "     1806    0.001    0.000    0.001    0.000 {method 'find' of 'bytearray' objects}\n",
       "      351    0.001    0.000    0.028    0.000 PngImagePlugin.py:685(write)\n",
       "      285    0.001    0.000    0.001    0.000 {built-in method _warnings.warn}\n",
       "      695    0.001    0.000    0.001    0.000 {built-in method _imp._fix_co_filename}\n",
       "      159    0.001    0.000    0.002    0.000 __init__.py:2772(<listcomp>)\n",
       "      366    0.001    0.000    0.002    0.000 module.py:11(_addindent)\n",
       "       40    0.001    0.000    0.015    0.000 conv.py:17(__init__)\n",
       "      194    0.001    0.000    0.003    0.000 storage.py:40(clone)\n",
       "     2304    0.001    0.000    0.001    0.000 version.py:298(_parse_letter_version)\n",
       "      323    0.001    0.000    0.038    0.000 <frozen importlib._bootstrap_external>:413(_find_module_shim)\n",
       "      702    0.001    0.000    0.001    0.000 scatter_gather.py:20(<listcomp>)\n",
       "      697    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:800(__init__)\n",
       "     2552    0.001    0.000    0.001    0.000 {built-in method builtins.ord}\n",
       "      314    0.001    0.000    0.033    0.000 __init__.py:1935(<listcomp>)\n",
       "      702    0.001    0.000    0.001    0.000 {method 'setimage' of 'ImagingDecoder' objects}\n",
       "      120    0.001    0.000    0.145    0.001 sre_compile.py:557(compile)\n",
       "      121    0.001    0.000    0.003    0.000 __init__.py:1521(_get)\n",
       "      320    0.001    0.000    0.019    0.000 __init__.py:2468(__init__)\n",
       "   388/97    0.001    0.000    0.002    0.000 optimizer.py:122(cast)\n",
       "      336    0.001    0.000    0.002    0.000 warnings.py:159(_add_filter)\n",
       "      335    0.001    0.000    0.001    0.000 pyparsing.py:1144(__init__)\n",
       "        1    0.001    0.001 89152.271 89152.271 py3compat.py:184(execfile)\n",
       "     1940    0.001    0.000    0.004    0.000 __init__.py:2248(_normalize_cached)\n",
       "     1096    0.001    0.000    0.001    0.000 inspect.py:2833(<genexpr>)\n",
       "     1066    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:48(<lambda>)\n",
       "      314    0.001    0.000    0.036    0.000 __init__.py:1929(_by_version)\n",
       "      388    0.001    0.000    0.004    0.000 __init__.py:1468(_fn)\n",
       "      703    0.001    0.000    0.001    0.000 dataloader.py:715(__del__)\n",
       "      352    0.001    0.000    0.002    0.000 inspect.py:485(unwrap)\n",
       "    184/1    0.001    0.000    0.025    0.025 module.py:746(load)\n",
       "      351    0.001    0.000    0.001    0.000 {built-in method math.ceil}\n",
       "        3    0.001    0.000    0.349    0.116 __init__.py:9(<module>)\n",
       "       24    0.001    0.000    0.001    0.000 traitlets.py:486(_dynamic_default_callable)\n",
       "     1096    0.001    0.000    0.001    0.000 inspect.py:2779(<genexpr>)\n",
       "      642    0.001    0.000    0.001    0.000 __init__.py:119(is_tensor)\n",
       "     1015    0.001    0.000    0.001    0.000 sre_compile.py:102(fixup)\n",
       "      724    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:311(__enter__)\n",
       "       15    0.001    0.000    0.003    0.000 enum.py:124(__new__)\n",
       "        2    0.001    0.000    0.002    0.001 __init__.py:1420(register_all)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method torch._C._c10d_init}\n",
       "        1    0.001    0.001    0.735    0.735 writer.py:246(__init__)\n",
       "     1006    0.001    0.000    0.001    0.000 {method 'pop' of 'dict' objects}\n",
       "      120    0.001    0.000    0.075    0.001 sre_parse.py:844(parse)\n",
       "      749    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:780(find_spec)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:54(<lambda>)\n",
       "      352    0.001    0.000    0.004    0.000 sampler.py:168(__len__)\n",
       "        1    0.001    0.001    0.004    0.004 caffe2_pb2.py:4(<module>)\n",
       "      159    0.001    0.000    0.004    0.000 __init__.py:2746(insert_on)\n",
       "      176    0.001    0.000    0.006    0.000 inspect.py:2846(__eq__)\n",
       "      803    0.001    0.000    0.001    0.000 inspect.py:159(isfunction)\n",
       "       98    0.001    0.000    0.011    0.000 <frozen importlib._bootstrap_external>:1281(_fill_cache)\n",
       "      702    0.001    0.000    0.016    0.000 Image.py:370(preinit)\n",
       "      724    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:307(__init__)\n",
       "      421    0.001    0.000    0.005    0.000 PyColorize.py:328(__call__)\n",
       "        1    0.001    0.001    0.001    0.001 encoder.py:65(<module>)\n",
       "        3    0.001    0.000    0.002    0.001 six.py:1(<module>)\n",
       "       24    0.001    0.000    0.138    0.006 __init__.py:609(add_entry)\n",
       "      316    0.001    0.000    0.003    0.000 genericpath.py:39(isdir)\n",
       "     1499    0.001    0.000    0.001    0.000 {built-in method _sre.getlower}\n",
       "      355    0.001    0.000    0.001    0.000 _weakrefset.py:26(__exit__)\n",
       "      702    0.001    0.000    0.001    0.000 ImageFile.py:65(_tilesort)\n",
       "    100/1    0.001    0.000    0.014    0.014 copy.py:236(_deepcopy_dict)\n",
       "      636    0.001    0.000    0.149    0.000 re.py:231(compile)\n",
       "       18    0.001    0.000    0.009    0.001 __init__.py:357(namedtuple)\n",
       "      749    0.001    0.000    0.001    0.000 {built-in method _imp.is_frozen}\n",
       "      324    0.001    0.000    0.001    0.000 warnings.py:449(__enter__)\n",
       "       95    0.001    0.000    0.001    0.000 functools.py:44(update_wrapper)\n",
       "       23    0.001    0.000    0.137    0.006 event_file_writer.py:35(__init__)\n",
       "     1375    0.001    0.000    0.001    0.000 {method 'isidentifier' of 'str' objects}\n",
       "      352    0.001    0.000    0.001    0.000 inspect.py:2836(<dictcomp>)\n",
       "      716    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
       "      351    0.001    0.000    0.001    0.000 PngImagePlugin.py:681(__init__)\n",
       "      330    0.001    0.000    0.002    0.000 warnings.py:143(simplefilter)\n",
       "      471    0.001    0.000    0.007    0.000 pyparsing.py:1167(copy)\n",
       "      267    0.001    0.000    0.002    0.000 enum.py:797(__or__)\n",
       "       90    0.001    0.000    0.001    0.000 sre_compile.py:376(_mk_bitmap)\n",
       "      384    0.001    0.000    0.001    0.000 loader.py:150(_is_section_key)\n",
       "     1526    0.001    0.000    0.001    0.000 _structures.py:33(__neg__)\n",
       "      159    0.001    0.000    0.054    0.000 __init__.py:2652(activate)\n",
       "      702    0.001    0.000    0.001    0.000 {method 'cleanup' of 'ImagingEncoder' objects}\n",
       "      656    0.001    0.000    0.001    0.000 sre_parse.py:81(groups)\n",
       "      159    0.001    0.000    0.039    0.000 __init__.py:2193(fixup_namespace_packages)\n",
       "      214    0.001    0.000    0.001    0.000 module.py:17(<listcomp>)\n",
       "      267    0.001    0.000    0.005    0.000 __init__.py:1404(has_metadata)\n",
       "      227    0.001    0.000    0.001    0.000 sre_parse.py:294(_class_escape)\n",
       "      374    0.001    0.000    0.001    0.000 sre_parse.py:342(_escape)\n",
       "        1    0.001    0.001    0.001    0.001 case.py:341(TestCase)\n",
       "        3    0.001    0.000    0.496    0.165 serialization.py:385(_load)\n",
       "       42    0.001    0.000    0.011    0.000 linecache.py:82(updatecache)\n",
       "     1264    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:41(_relax_case)\n",
       "     1488    0.001    0.000    0.001    0.000 inspect.py:2512(kind)\n",
       "      351    0.001    0.000    0.001    0.000 {method 'fileno' of '_io.BufferedRandom' objects}\n",
       "      526    0.001    0.000    0.001    0.000 <string>:12(__new__)\n",
       "        8    0.001    0.000    0.029    0.004 ultratb.py:833(format_record)\n",
       "        8    0.001    0.000    0.001    0.000 traitlets.py:224(getmembers)\n",
       "      324    0.001    0.000    0.002    0.000 re.py:184(sub)\n",
       "  472/114    0.001    0.000    0.006    0.000 {built-in method builtins.repr}\n",
       "      384    0.001    0.000    0.002    0.000 loader.py:231(_has_section)\n",
       "        8    0.001    0.000    0.003    0.000 traitlets.py:961(setup_instance)\n",
       "       98    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:1196(__init__)\n",
       "      283    0.001    0.000    0.001    0.000 {method 'decode' of 'bytes' objects}\n",
       "      396    0.001    0.000    0.001    0.000 __init__.py:2456(is_version_line)\n",
       "      132    0.001    0.000    0.022    0.000 __init__.py:2451(_version_from_file)\n",
       "      202    0.001    0.000    0.001    0.000 sre_parse.py:84(opengroup)\n",
       "      917    0.001    0.000    0.001    0.000 {method 'setdefault' of 'dict' objects}\n",
       "     40/8    0.001    0.000    0.005    0.001 configurable.py:106(_find_my_config)\n",
       "       86    0.001    0.000    0.001    0.000 _oid.py:11(__init__)\n",
       "      306    0.001    0.000    0.013    0.000 __init__.py:108(import_module)\n",
       "      352    0.001    0.000    0.003    0.000 sampler.py:75(__len__)\n",
       "      612    0.001    0.000    0.001    0.000 serialization.py:502(maybe_decode_ascii)\n",
       "      374    0.001    0.000    0.001    0.000 descriptor.py:524(__new__)\n",
       "        1    0.001    0.001    0.011    0.011 utils.py:13(get_logger)\n",
       "      471    0.001    0.000    0.001    0.000 {method '__reduce_ex__' of 'object' objects}\n",
       "      929    0.001    0.000    0.001    0.000 {method 'write' of '_io.StringIO' objects}\n",
       "      324    0.001    0.000    0.001    0.000 warnings.py:468(__exit__)\n",
       "       55    0.001    0.000    0.003    0.000 argparse.py:1307(add_argument)\n",
       "      306    0.000    0.000    0.012    0.000 <frozen importlib._bootstrap>:982(_gcd_import)\n",
       "       40    0.000    0.000    0.009    0.000 conv.py:45(reset_parameters)\n",
       "      355    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
       "     1024    0.000    0.000    0.000    0.000 version.py:352(<lambda>)\n",
       "      376    0.000    0.000    0.001    0.000 tokenize.py:152(_compile)\n",
       "      161    0.000    0.000    0.009    0.000 abc.py:151(register)\n",
       "      355    0.000    0.000    0.001    0.000 _weakrefset.py:20(__enter__)\n",
       "      386    0.000    0.000    0.009    0.000 <frozen importlib._bootstrap_external>:99(_path_isdir)\n",
       "       46    0.000    0.000    0.000    0.000 crc32c.py:77(crc_update)\n",
       "      392    0.000    0.000    0.001    0.000 loader.py:218(__contains__)\n",
       "       86    0.000    0.000    0.001    0.000 abc.py:135(<setcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
       "       27    0.000    0.000    0.001    0.000 {built-in method _imp.exec_dynamic}\n",
       "      372    0.000    0.000    0.001    0.000 inspect.py:2559(__eq__)\n",
       "      386    0.000    0.000    0.008    0.000 traceback.py:283(line)\n",
       "      352    0.000    0.000    0.006    0.000 dataloader.py:821(__len__)\n",
       "      592    0.000    0.000    0.000    0.000 ipstruct.py:125(__getattr__)\n",
       "      320    0.000    0.000    0.002    0.000 __init__.py:1315(safe_name)\n",
       "      471    0.000    0.000    0.001    0.000 copyreg.py:87(__newobj__)\n",
       "      323    0.000    0.000    0.036    0.000 <frozen importlib._bootstrap_external>:1216(find_loader)\n",
       "      121    0.000    0.000    0.005    0.000 __init__.py:1407(get_metadata)\n",
       "      306    0.000    0.000    0.017    0.000 _utils.py:134(_rebuild_tensor_v2)\n",
       "     1134    0.000    0.000    0.000    0.000 __init__.py:1997(__bool__)\n",
       "      296    0.000    0.000    0.001    0.000 copy.py:252(_keep_alive)\n",
       "      193    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
       "      120    0.000    0.000    0.068    0.001 sre_compile.py:542(_code)\n",
       "       23    0.000    0.000    0.180    0.008 event_file_writer.py:90(__init__)\n",
       "      194    0.000    0.000    0.004    0.000 storage.py:24(__deepcopy__)\n",
       "       10    0.000    0.000    0.026    0.003 odefunc.py:99(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 traceback.py:386(format)\n",
       "      118    0.000    0.000    0.001    0.000 enum.py:70(__setitem__)\n",
       "      784    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1202(<genexpr>)\n",
       "       90    0.000    0.000    0.000    0.000 sre_compile.py:378(<listcomp>)\n",
       "      267    0.000    0.000    0.002    0.000 __init__.py:1509(_has)\n",
       "      561    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "      132    0.000    0.000    0.023    0.000 __init__.py:2858(_reload_version)\n",
       "   219/58    0.000    0.000    0.005    0.000 typing.py:1145(__subclasscheck__)\n",
       "      352    0.000    0.000    0.015    0.000 inspect.py:2803(from_callable)\n",
       "      749    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:707(find_spec)\n",
       "    102/2    0.000    0.000    0.001    0.001 pyparsing.py:1370(_parseNoCache)\n",
       "       15    0.000    0.000    0.001    0.000 enum.py:160(<setcomp>)\n",
       "        8    0.000    0.000    0.012    0.002 ultratb.py:379(_format_traceback_lines)\n",
       "     1110    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
       "      984    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
       "      724    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:424(has_location)\n",
       "      352    0.000    0.000    0.016    0.000 inspect.py:3055(signature)\n",
       "      120    0.000    0.000    0.001    0.000 sre_parse.py:223(__init__)\n",
       "        1    0.000    0.000    0.665    0.665 _import_c_extension.py:3(<module>)\n",
       "      351    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_library_init}\n",
       "       21    0.000    0.000    0.000    0.000 {built-in method tensor}\n",
       "      840    0.000    0.000    0.000    0.000 {built-in method builtins.chr}\n",
       "       84    0.000    0.000    0.002    0.000 pyparsing.py:3390(__init__)\n",
       "      374    0.000    0.000    0.000    0.000 {method 'FindFieldByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       98    0.000    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:1322(path_hook_for_FileFinder)\n",
       "      768    0.000    0.000    0.000    0.000 version.py:332(_parse_local_version)\n",
       "      149    0.000    0.000    0.030    0.000 utils.py:38(register_decorator)\n",
       "      695    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:825(get_filename)\n",
       "      188    0.000    0.000    0.008    0.000 linecache.py:15(getline)\n",
       "      744    0.000    0.000    0.000    0.000 inspect.py:2500(name)\n",
       "       82    0.000    0.000    0.001    0.000 pyparsing.py:3719(__init__)\n",
       "        9    0.000    0.000    0.001    0.000 auto.py:14(_make_function_class_criterion)\n",
       "      630    0.000    0.000    0.000    0.000 sre_parse.py:167(__setitem__)\n",
       "      324    0.000    0.000    0.000    0.000 warnings.py:428(__init__)\n",
       "       80    0.000    0.000    0.001    0.000 conv.py:53(extra_repr)\n",
       "      302    0.000    0.000    0.000    0.000 serialization.py:401(restore_location)\n",
       "      704    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
       "       42    0.000    0.000    0.008    0.000 init.py:261(kaiming_uniform_)\n",
       "      160    0.000    0.000    0.054    0.000 __init__.py:3153(<genexpr>)\n",
       "       55    0.000    0.000    0.001    0.000 argparse.py:157(__init__)\n",
       "       16    0.000    0.000    0.008    0.000 traitlets.py:1142(notify_change)\n",
       "        2    0.000    0.000    0.000    0.000 {method '_set_from_file' of 'torch._C.LongStorageBase' objects}\n",
       "      178    0.000    0.000    0.001    0.000 _jit_internal.py:34(createResolutionCallback)\n",
       "        1    0.000    0.000    0.028    0.028 auto.py:268(_generate_function_classes)\n",
       "       60    0.000    0.000    0.003    0.000 six.py:837(wrapper)\n",
       "       36    0.000    0.000    0.001    0.000 posixpath.py:331(normpath)\n",
       "       28    0.000    0.000    0.005    0.000 tokenize.py:448(open)\n",
       "      286    0.000    0.000    0.001    0.000 _tensor_docs.py:8(add_docstr_all)\n",
       "      695    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:669(create_module)\n",
       "      164    0.000    0.000    0.001    0.000 train_misc.py:17(_set)\n",
       "      208    0.000    0.000    0.012    0.000 linecache.py:37(getlines)\n",
       "      193    0.000    0.000    0.001    0.000 codecs.py:318(decode)\n",
       "      200    0.000    0.000    0.004    0.000 utils.py:6(parse)\n",
       "      351    0.000    0.000    0.000    0.000 JpegImagePlugin.py:665(validate_qtables)\n",
       "        1    0.000    0.000    0.004    0.004 summary_pb2.py:4(<module>)\n",
       "       98    0.000    0.000    0.001    0.000 module.py:122(register_parameter)\n",
       "    98/50    0.000    0.000    0.000    0.000 typing.py:1164(__setattr__)\n",
       "      495    0.000    0.000    0.000    0.000 {built-in method torch._C._add_docstr}\n",
       "      196    0.000    0.000    0.006    0.000 train_misc.py:71(<genexpr>)\n",
       "       23    0.000    0.000    0.009    0.000 record_writer.py:114(write)\n",
       "      352    0.000    0.000    0.001    0.000 inspect.py:505(_is_wrapper)\n",
       "      304    0.000    0.000    0.000    0.000 __init__.py:1837(__init__)\n",
       "      184    0.000    0.000    0.000    0.000 module.py:684(<dictcomp>)\n",
       "      306    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:917(_sanity_check)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:1444(_get_optional_kwargs)\n",
       "      120    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:1421(<listcomp>)\n",
       "      355    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 token.py:3(<module>)\n",
       "   131/65    0.000    0.000    0.006    0.000 pyparsing.py:3363(copy)\n",
       "      754    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "      120    0.000    0.000    0.001    0.000 sre_parse.py:828(fix_flags)\n",
       "      136    0.000    0.000    0.000    0.000 enum.py:353(__setattr__)\n",
       "      202    0.000    0.000    0.005    0.000 sre_parse.py:96(closegroup)\n",
       "      704    0.000    0.000    0.000    0.000 inspect.py:2809(parameters)\n",
       "       40    0.000    0.000    0.022    0.001 basic.py:152(__init__)\n",
       "      105    0.000    0.000    0.001    0.000 os.py:664(__getitem__)\n",
       "      586    0.000    0.000    0.000    0.000 {built-in method _CheckCalledFromGeneratedFile}\n",
       "      351    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BytesIO' objects}\n",
       "       57    0.000    0.000    0.000    0.000 sre_parse.py:266(getuntil)\n",
       "      240    0.000    0.000    0.000    0.000 sre_compile.py:539(isstring)\n",
       "        1    0.000    0.000    0.003    0.003 core.py:21(<module>)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:142(formatargspec)\n",
       "      296    0.000    0.000    0.000    0.000 weakref.py:406(__setitem__)\n",
       "      409    0.000    0.000    0.000    0.000 utils.py:47(__init__)\n",
       "      385    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}\n",
       "        1    0.000    0.000    0.002    0.002 numerictypes.py:81(<module>)\n",
       "        1    0.000    0.000    0.033    0.033 pyparsing.py:75(<module>)\n",
       "      350    0.000    0.000    0.001    0.000 pkgutil.py:402(get_importer)\n",
       "      331    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "        1    0.000    0.000    0.001    0.001 step_stats_pb2.py:4(<module>)\n",
       "   131/65    0.000    0.000    0.005    0.000 pyparsing.py:3365(<listcomp>)\n",
       "        1    0.000    0.000 89152.324 89152.324 interactiveshell.py:2637(safe_execfile)\n",
       "       69    0.000    0.000    0.001    0.000 pyparsing.py:2412(__init__)\n",
       "      178    0.000    0.000    0.000    0.000 inspect.py:1493(currentframe)\n",
       "      421    0.000    0.000    0.000    0.000 {method 'read' of '_io.StringIO' objects}\n",
       "       86    0.000    0.000    0.004    0.000 compilerop.py:137(check_linecache_ipython)\n",
       "       86    0.000    0.000    0.004    0.000 linecache.py:53(checkcache)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_load_error_strings}\n",
       "      355    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)\n",
       "       40    0.000    0.000    0.019    0.000 conv.py:307(__init__)\n",
       "       23    0.000    0.000    0.001    0.000 queue.py:27(__init__)\n",
       "    32/31    0.000    0.000    0.001    0.000 typing.py:875(__extrahook__)\n",
       "    61/11    0.000    0.000    0.006    0.001 pyparsing.py:3288(leaveWhitespace)\n",
       "      596    0.000    0.000    0.000    0.000 copy.py:190(_deepcopy_atomic)\n",
       "      194    0.000    0.000    0.001    0.000 __init__.py:219(__init__)\n",
       "       97    0.000    0.000    0.002    0.000 optimizer.py:132(<dictcomp>)\n",
       "       83    0.000    0.000    0.002    0.000 pyparsing.py:1821(__add__)\n",
       "       23    0.000    0.000    0.035    0.002 record_writer.py:35(directory_check)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:104(_init)\n",
       "       28    0.000    0.000    0.002    0.000 tokenize.py:355(detect_encoding)\n",
       "      180    0.000    0.000    0.000    0.000 linecache.py:147(lazycache)\n",
       "   117/99    0.000    0.000    0.000    0.000 sre_compile.py:414(_get_literal_prefix)\n",
       "      421    0.000    0.000    0.000    0.000 {method 'seek' of '_io.StringIO' objects}\n",
       "       42    0.000    0.000    0.000    0.000 init.py:8(calculate_gain)\n",
       "      266    0.000    0.000    0.000    0.000 pyparsing.py:3270(<genexpr>)\n",
       "      160    0.000    0.000    0.000    0.000 __init__.py:666(__iter__)\n",
       "       91    0.000    0.000    0.001    0.000 _jit_internal.py:105(weak_script_method)\n",
       "       48    0.000    0.000    0.002    0.000 pyparsing.py:3540(__init__)\n",
       "        1    0.000    0.000    0.016    0.016 optimizer.py:95(load_state_dict)\n",
       "      166    0.000    0.000    0.000    0.000 six.py:141(__init__)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:393(_joinrealpath)\n",
       "       15    0.000    0.000    0.000    0.000 {built-in method builtins.eval}\n",
       "        3    0.000    0.000    0.502    0.167 serialization.py:300(load)\n",
       "       46    0.000    0.000    0.001    0.000 record_writer.py:127(masked_crc32c)\n",
       "        1    0.000    0.000    0.337    0.337 event_pb2.py:4(<module>)\n",
       "      248    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "      111    0.000    0.000    0.000    0.000 os.py:742(encode)\n",
       "        1    0.000    0.000    0.000    0.000 attr_value_pb2.py:4(<module>)\n",
       "      376    0.000    0.000    0.000    0.000 {method 'span' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.003    0.003 kl.py:1(<module>)\n",
       "      351    0.000    0.000    0.000    0.000 {method 'close' of '_io.BytesIO' objects}\n",
       "       10    0.000    0.000    0.010    0.001 ultratb.py:157(findsource)\n",
       "      121    0.000    0.000    0.005    0.000 __init__.py:1413(get_metadata_lines)\n",
       "        3    0.000    0.000    0.127    0.042 functional.py:1(<module>)\n",
       "       10    0.000    0.000    0.005    0.001 cnf.py:12(__init__)\n",
       "       12    0.000    0.000    0.005    0.000 pyparsing.py:2653(__init__)\n",
       "        1    0.000    0.000    0.006    0.006 __init__.py:57(<module>)\n",
       "       24    0.000    0.000    0.001    0.000 traitlets.py:516(instance_init)\n",
       "      352    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd_init}\n",
       "      146    0.000    0.000    0.000    0.000 traitlets.py:545(__get__)\n",
       "        1    0.000    0.000    0.000    0.000 layout_pb2.py:4(<module>)\n",
       "       53    0.000    0.000    0.001    0.000 core.py:893(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 getlimits.py:3(<module>)\n",
       "       26    0.000    0.000    0.034    0.001 pyparsing.py:2779(__init__)\n",
       "       10    0.000    0.000    0.014    0.001 inspect.py:1430(getframeinfo)\n",
       "       87    0.000    0.000    0.001    0.000 _jit_internal.py:83(weak_script)\n",
       "      148    0.000    0.000    0.000    0.000 _oid.py:58(__hash__)\n",
       "       46    0.000    0.000    0.001    0.000 crc32c.py:114(crc32c)\n",
       "        1    0.000    0.000    0.038    0.038 extensions.py:5(<module>)\n",
       "      198    0.000    0.000    0.000    0.000 traceback.py:290(walk_stack)\n",
       "       86    0.000    0.000    0.001    0.000 module.py:161(add_module)\n",
       "        1    0.000    0.000    0.044    0.044 add_newdocs.py:10(<module>)\n",
       "      120    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1796(get_metadata)\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:2916(extend_all)\n",
       "      368    0.000    0.000    0.000    0.000 module.py:1012(_get_name)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:67(getargs)\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:349(_populate)\n",
       "      252    0.000    0.000    0.000    0.000 six.py:88(__init__)\n",
       "      362    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
       "      392    0.000    0.000    0.000    0.000 {function Config.__contains__ at 0x7f75809c1620}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:50(__init__)\n",
       "       24    0.000    0.000    0.001    0.000 container.py:187(extend)\n",
       "        1    0.000    0.000    0.075    0.075 __init__.py:106(<module>)\n",
       "        1    0.000    0.000    0.029    0.029 ultratb.py:820(format_records)\n",
       "        8    0.000    0.000    0.001    0.000 utils.py:1(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 getlimits.py:65(__init__)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:1364(_add_action)\n",
       "        8    0.000    0.000    0.002    0.000 traitlets.py:1407(traits)\n",
       "      135    0.000    0.000    0.000    0.000 argparse.py:1282(_registry_get)\n",
       "      282    0.000    0.000    0.000    0.000 {method 'zfill' of 'str' objects}\n",
       "       23    0.000    0.000    0.126    0.005 record_writer.py:46(open_file)\n",
       "       23    0.000    0.000    0.126    0.005 record_writer.py:105(__init__)\n",
       "       48    0.000    0.000    0.002    0.000 pyparsing.py:1948(__or__)\n",
       "       27    0.000    0.000    0.003    0.000 pyparsing.py:1039(_trim_arity)\n",
       "      120    0.000    0.000    0.001    0.000 pyparsing.py:2368(__init__)\n",
       "       23    0.000    0.000    0.001    0.000 event_file_writer.py:159(__init__)\n",
       "      352    0.000    0.000    0.000    0.000 inspect.py:2813(return_annotation)\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:317(getmembers)\n",
       "       88    0.000    0.000    0.000    0.000 typing.py:1033(_abc_negative_cache_version)\n",
       "      183    0.000    0.000    0.000    0.000 module.py:538(remove_from)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:118(__repr__)\n",
       "        1    0.000    0.000    0.006    0.006 subprocess.py:1208(_execute_child)\n",
       "        8    0.000    0.000    0.011    0.001 configurable.py:38(__init__)\n",
       "       20    0.000    0.000    0.008    0.000 inspect.py:680(getsourcefile)\n",
       "        1    0.000    0.000    0.312    0.312 __init__.py:16(<module>)\n",
       "       28    0.000    0.000    0.012    0.000 traceback.py:200(extract_stack)\n",
       "      111    0.000    0.000    0.000    0.000 _jit_internal.py:98(weak_module)\n",
       "        2    0.000    0.000    0.004    0.002 ec.py:5(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:930(__init__)\n",
       "      315    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
       "        2    0.000    0.000    0.218    0.109 __init__.py:41(<module>)\n",
       "       42    0.000    0.000    0.001    0.000 init.py:50(uniform_)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1775(_parse_known_args)\n",
       "      277    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.add_docstring}\n",
       "       60    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:861(_find_spec_legacy)\n",
       "       38    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "       98    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
       "        1    0.000    0.000    0.016    0.016 pyparsing.py:5399(pyparsing_common)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:580(_format_args)\n",
       "    82/80    0.000    0.000    0.000    0.000 pyparsing.py:372(__init__)\n",
       "       98    0.000    0.000    0.000    0.000 parameter.py:23(__new__)\n",
       "       23    0.000    0.000    0.010    0.000 event_file_writer.py:54(write_event)\n",
       "      194    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
       "       80    0.000    0.000    0.002    0.000 configurable.py:99(section_names)\n",
       "       25    0.000    0.000    0.003    0.000 pyparsing.py:1250(setParseAction)\n",
       "       86    0.000    0.000    0.000    0.000 six.py:105(__init__)\n",
       "      180    0.000    0.000    0.000    0.000 traceback.py:243(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 markers.py:4(<module>)\n",
       "       23    0.000    0.000    0.180    0.008 writer.py:162(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 zipfile.py:5(<module>)\n",
       "        1    0.000    0.000    0.017    0.017 __init__.py:72(<module>)\n",
       "      127    0.000    0.000    0.000    0.000 typing.py:1019(_abc_negative_cache)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1161(getLogger)\n",
       "      237    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
       "       82    0.000    0.000    0.000    0.000 descriptor.py:281(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:180(ConcatSquashConv2d)\n",
       "      109    0.000    0.000    0.000    0.000 __init__.py:422(<genexpr>)\n",
       "     19/4    0.000    0.000    0.001    0.000 pyparsing.py:3319(streamline)\n",
       "      107    0.000    0.000    0.004    0.000 module.py:260(<lambda>)\n",
       "        1    0.000    0.000    0.003    0.003 numeric.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 _tensor_docs.py:1(<module>)\n",
       "    27/24    0.000    0.000    0.186    0.008 <frozen importlib._bootstrap_external>:919(create_module)\n",
       "       23    0.000    0.000    0.000    0.000 {built-in method _socket.gethostname}\n",
       "       34    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
       "       11    0.000    0.000    0.098    0.009 __init__.py:5(<module>)\n",
       "      132    0.000    0.000    0.000    0.000 {method 'mro' of 'type' objects}\n",
       "      189    0.000    0.000    0.000    0.000 status_codes.py:112(<genexpr>)\n",
       "       51    0.000    0.000    0.000    0.000 _internal.py:715(_ufunc_doc_signature_formatter)\n",
       "       20    0.000    0.000    0.000    0.000 inspect.py:643(getfile)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:2826(__str__)\n",
       "        1    0.000    0.000    0.192    0.192 __init__.py:3126(_initialize_master_working_set)\n",
       "      159    0.000    0.000    0.000    0.000 __init__.py:919(_added_new)\n",
       "        1    0.000    0.000    0.015    0.015 __init__.py:184(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2710(MaskedArray)\n",
       "      118    0.000    0.000    0.000    0.000 enum.py:28(_is_dunder)\n",
       "       68    0.000    0.000    0.001    0.000 posixpath.py:168(islink)\n",
       "        3    0.000    0.000    0.095    0.032 __init__.py:6(<module>)\n",
       "       42    0.000    0.000    0.001    0.000 init.py:251(_calculate_correct_fan)\n",
       "       31    0.000    0.000    0.000    0.000 enum.py:419(_get_mixins_)\n",
       "       24    0.000    0.000    0.000    0.000 genericpath.py:27(isfile)\n",
       "        1    0.000    0.000    0.002    0.002 lapack.py:461(<module>)\n",
       "      302    0.000    0.000    0.000    0.000 train_cnf_drop.py:424(<lambda>)\n",
       "       61    0.000    0.000    0.004    0.000 pyparsing.py:3292(<listcomp>)\n",
       "      108    0.000    0.000    0.000    0.000 utils.py:33(read_only_property)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:68(RegisterMessage)\n",
       "       67    0.000    0.000    0.000    0.000 auto.py:95(_find_buffers)\n",
       "       82    0.000    0.000    0.000    0.000 {method 'FindMessageTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       26    0.000    0.000    0.003    0.000 pyparsing.py:1047(extract_stack)\n",
       "        1    0.000    0.000    0.064    0.064 requirements.py:4(<module>)\n",
       "      103    0.000    0.000    0.000    0.000 TiffTags.py:26(__new__)\n",
       "      113    0.000    0.000    0.000    0.000 descriptor.py:690(__new__)\n",
       "        1    0.000    0.000    0.009    0.009 Image.py:30(<module>)\n",
       "       68    0.000    0.000    0.000    0.000 status_codes.py:111(doc)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:38(register_kl)\n",
       "       32    0.000    0.000    0.000    0.000 traitlets.py:1067(hold_trait_notifications)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:174(add_param_group)\n",
       "        3    0.000    0.000    0.199    0.066 tarfile.py:1411(__init__)\n",
       "       73    0.000    0.000    0.000    0.000 sre_compile.py:441(_get_charset_prefix)\n",
       "      148    0.000    0.000    0.000    0.000 utils.py:34(<lambda>)\n",
       "       60    0.000    0.000    0.000    0.000 enum.py:20(_is_descriptor)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:237(SummaryWriter)\n",
       "        1    0.000    0.000    0.042    0.042 backend.py:5(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:464(_find_new_)\n",
       "      220    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "      194    0.000    0.000    0.000    0.000 __init__.py:231(__exit__)\n",
       "        1    0.000    0.000    0.008    0.008 TiffImagePlugin.py:42(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 summary.py:30(<module>)\n",
       "      188    0.000    0.000    0.000    0.000 __init__.py:2498(_reload_version)\n",
       "       30    0.000    0.000    0.001    0.000 contextlib.py:129(contextmanager)\n",
       "        1    0.000    0.000    0.003    0.003 tensor_pb2.py:4(<module>)\n",
       "      100    0.000    0.000    0.000    0.000 six.py:177(_add_module)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3037(_find_adapter)\n",
       "        1    0.000    0.000    0.001    0.001 _torch_docs.py:1(<module>)\n",
       "      118    0.000    0.000    0.000    0.000 enum.py:36(_is_sunder)\n",
       "      194    0.000    0.000    0.000    0.000 __init__.py:223(__enter__)\n",
       "       44    0.000    0.000    0.000    0.000 posixpath.py:64(isabs)\n",
       "        1    0.000    0.000    0.002    0.002 core.py:47(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 npyio.py:1(<module>)\n",
       "       22    0.000    0.000    0.001    0.000 posixpath.py:369(abspath)\n",
       "        1    0.000    0.000    0.024    0.024 grammar.py:13(<module>)\n",
       "        2    0.000    0.000    0.052    0.026 base.py:5(<module>)\n",
       "      149    0.000    0.000    0.000    0.000 utils.py:37(register_interface)\n",
       "        1    0.000    0.000    0.002    0.002 modules.py:283(sample)\n",
       "       42    0.000    0.000    0.000    0.000 contextlib.py:59(__init__)\n",
       "      109    0.000    0.000    0.000    0.000 __init__.py:420(<genexpr>)\n",
       "      170    0.000    0.000    0.000    0.000 pyparsing.py:2061(setWhitespaceChars)\n",
       "      195    0.000    0.000    0.000    0.000 pyparsing.py:3392(<genexpr>)\n",
       "        1    0.000    0.000    0.718    0.718 workspace.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:120(<listcomp>)\n",
       "       49    0.000    0.000    0.000    0.000 codecs.py:308(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:37(<listcomp>)\n",
       "       96    0.000    0.000    0.000    0.000 pyparsing.py:2153(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 _methods.py:5(<module>)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:1555(_add_action)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1268(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 node_def_pb2.py:4(<module>)\n",
       "      222    0.000    0.000    0.000    0.000 module.py:1015(extra_repr)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:98(getargspec)\n",
       "       82    0.000    0.000    0.000    0.000 types.py:135(__get__)\n",
       "      183    0.000    0.000    0.000    0.000 {method '__subclasshook__' of 'object' objects}\n",
       "       80    0.000    0.000    0.000    0.000 inspect.py:690(<genexpr>)\n",
       "       42    0.000    0.000    0.000    0.000 contextlib.py:85(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 versions_pb2.py:4(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:85(RegisterMessageDescriptor)\n",
       "        1    0.000    0.000    0.003    0.003 oid.py:5(<module>)\n",
       "        2    0.000    0.000    0.006    0.003 {built-in method builtins.sum}\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:204(iterencode)\n",
       "       98    0.000    0.000    0.000    0.000 traitlets.py:526(get)\n",
       "       90    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
       "       82    0.000    0.000    0.000    0.000 pyparsing.py:363(__new__)\n",
       "       54    0.000    0.000    0.000    0.000 argparse.py:835(__init__)\n",
       "      2/1    0.000    0.000    0.001    0.001 copy.py:210(_deepcopy_list)\n",
       "        1    0.000    0.000    0.024    0.024 tokenize.py:26(<module>)\n",
       "       60    0.000    0.000    0.000    0.000 activation.py:617(extra_repr)\n",
       "      128    0.000    0.000    0.000    0.000 typing.py:1089(__eq__)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:564(_metavar_formatter)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1212(_fixupParents)\n",
       "       24    0.000    0.000    0.002    0.000 container.py:119(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:83(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:114(__prepare__)\n",
       "      164    0.000    0.000    0.000    0.000 abc.py:9(abstractmethod)\n",
       "        1    0.000    0.000    0.034    0.034 odenvp_conditional_tol.py:21(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:4(<module>)\n",
       "     20/8    0.000    0.000    0.001    0.000 pyparsing.py:3547(parseImpl)\n",
       "      8/6    0.000    0.000    0.006    0.001 __init__.py:2159(declare_namespace)\n",
       "        1    0.000    0.000    0.033    0.033 utils.py:9(<module>)\n",
       "        1    0.000    0.000    0.133    0.133 pyopenssl.py:43(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 extras.py:10(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 traceback.py:367(from_list)\n",
       "       32    0.000    0.000    0.000    0.000 tokenize.py:385(find_cookie)\n",
       "       11    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "        1    0.000    0.000    0.084    0.084 crypto.py:1(<module>)\n",
       "        2    0.000    0.000    0.003    0.002 dsa.py:5(<module>)\n",
       "      168    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
       "        1    0.000    0.000    0.002    0.002 resource_handle_pb2.py:4(<module>)\n",
       "       24    0.000    0.000    0.001    0.000 __init__.py:1870(find_distributions)\n",
       "       44    0.000    0.000    0.001    0.000 core.py:149(get_object_signature)\n",
       "       55    0.000    0.000    0.001    0.000 argparse.py:2352(_get_formatter)\n",
       "      139    0.000    0.000    0.000    0.000 pyparsing.py:3543(<genexpr>)\n",
       "        2    0.000    0.000    0.007    0.004 ocsp.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:1(<module>)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:1822(take_action)\n",
       "       27    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:927(exec_module)\n",
       "       92    0.000    0.000    0.000    0.000 {method 'write' of '_io.BufferedWriter' objects}\n",
       "    36/11    0.000    0.000    0.007    0.001 pyparsing.py:3743(leaveWhitespace)\n",
       "       69    0.000    0.000    0.000    0.000 __init__.py:1265(<lambda>)\n",
       "       21    0.000    0.000    0.001    0.000 argparse.py:1843(consume_optional)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:1480(_pop_action_class)\n",
       "       26    0.000    0.000    0.000    0.000 sre_compile.py:393(_generate_overlap_table)\n",
       "        3    0.000    0.000    0.033    0.011 odenvp_conditional_tol.py:181(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:98(_Boolean)\n",
       "       42    0.000    0.000    0.000    0.000 contextlib.py:157(helper)\n",
       "       72    0.000    0.000    0.000    0.000 functools.py:74(wraps)\n",
       "       69    0.000    0.000    0.000    0.000 status_codes.py:117(<genexpr>)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:365(__getitem__)\n",
       "       49    0.000    0.000    0.000    0.000 py3compat.py:28(cast_unicode)\n",
       "       10    0.000    0.000    0.001    0.000 odefunc.py:257(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}\n",
       "       20    0.000    0.000    0.000    0.000 pyparsing.py:2813(parseImpl)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:5(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 backend.py:13(register_function)\n",
       "     15/1    0.000    0.000    0.001    0.001 jsonutil.py:109(json_clean)\n",
       "       97    0.000    0.000    0.000    0.000 pyparsing.py:4781(<genexpr>)\n",
       "       23    0.000    0.000    0.009    0.000 event_file_writer.py:63(_write_serialized_event)\n",
       "        3    0.000    0.000    0.003    0.001 distributed.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 adapters.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:299(_add_aliases)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _ctypes.dlopen}\n",
       "       45    0.000    0.000    0.000    0.000 pyparsing.py:1190(setName)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_ldl.py:1(<module>)\n",
       "        1    0.000    0.000    0.019    0.019 keys.py:15(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 numerictypes.py:229(bitname)\n",
       "       74    0.000    0.000    0.000    0.000 {method 'readline' of '_io.StringIO' objects}\n",
       "      188    0.000    0.000    0.000    0.000 pyparsing.py:2656(<genexpr>)\n",
       "       14    0.000    0.000    0.003    0.000 __init__.py:2232(normalize_path)\n",
       "        3    0.000    0.000    0.006    0.002 __init__.py:15(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 hashes.py:5(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 function_base.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1740(parse_known_args)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:720(DataLoader)\n",
       "        1    0.000    0.000    0.000    0.000 stringprep.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:272(<setcomp>)\n",
       "       16    0.000    0.000    0.010    0.001 traitlets.py:558(set)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:988(__init__)\n",
       "       10    0.000    0.000    0.027    0.003 odenvp_conditional_tol.py:196(_make_odefunc)\n",
       "       38    0.000    0.000    0.000    0.000 pyparsing.py:4230(__init__)\n",
       "     10/2    0.000    0.000    0.001    0.001 pyparsing.py:3397(parseImpl)\n",
       "      138    0.000    0.000    0.000    0.000 record_writer.py:132(u32)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3050(Sequence)\n",
       "       40    0.000    0.000    0.000    0.000 loader.py:161(__init__)\n",
       "       42    0.000    0.000    0.000    0.000 contextlib.py:79(__enter__)\n",
       "       23    0.000    0.000    0.000    0.000 pyparsing.py:2742(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:409(_init)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:5(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 pyparsing.py:4565(_escapeRegexRangeChars)\n",
       "        2    0.000    0.000    0.000    0.000 train_cnf_drop.py:161(<lambda>)\n",
       "        1    0.000    0.000    0.038    0.038 odefunc.py:1(<module>)\n",
       "        1    0.000    0.000    0.016    0.016 ultratb.py:343(_fixed_getinnerframes)\n",
       "        1    0.000    0.000    0.009    0.009 _big_num_ctypes.py:20(<module>)\n",
       "       78    0.000    0.000    0.000    0.000 _internal.py:726(<genexpr>)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:1713(_add_action)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:1950(<listcomp>)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2234(_get_values)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:857(<listcomp>)\n",
       "      101    0.000    0.000    0.000    0.000 _inspect.py:133(strseq)\n",
       "        1    0.000    0.000    0.062    0.062 train_cnf_drop.py:160(get_dataset)\n",
       "       24    0.000    0.000    0.003    0.000 traitlets.py:587(_validate)\n",
       "        1    0.000    0.000    0.002    0.002 graph_pb2.py:4(<module>)\n",
       "       60    0.000    0.000    0.000    0.000 pyparsing.py:1351(preParse)\n",
       "        1    0.000    0.000    0.004    0.004 api.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:170(<dictcomp>)\n",
       "        1    0.000    0.000    0.012    0.012 connectionpool.py:1(<module>)\n",
       "        3    0.000    0.000    0.017    0.006 __init__.py:3(<module>)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6573(getdoc)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method torch.cuda._get_device_properties}\n",
       "        3    0.000    0.000    0.032    0.011 _util.py:1(<module>)\n",
       "        1    0.000    0.000    0.016    0.016 cookiejar.py:26(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method zeros_like}\n",
       "        1    0.000    0.000    0.002    0.002 utils.py:4(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 inspect.py:1251(formatargvalues)\n",
       "       14    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:433(spec_from_loader)\n",
       "        1    0.000    0.000    0.000    0.000 types_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:39(EllipticCurveSignatureAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(THNNCudaBackendStateMixin)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:466(find)\n",
       "        8    0.000    0.000    0.005    0.001 configurable.py:131(_load_config)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:793(__init__)\n",
       "       60    0.000    0.000    0.000    0.000 inspect.py:687(<genexpr>)\n",
       "       18    0.000    0.000    0.000    0.000 copyreg.py:96(_slotnames)\n",
       "        1    0.000    0.000    0.002    0.002 modes.py:5(<module>)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:69(decorator)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2050(_match_argument)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:384(realpath)\n",
       "        2    0.000    0.000    0.007    0.003 rsa.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2923(<listcomp>)\n",
       "        1    0.000    0.000    0.006    0.006 dopri5.py:2(<module>)\n",
       "        2    0.000    0.000    0.061    0.031 mnist.py:39(__init__)\n",
       "    14/13    0.000    0.000    0.038    0.003 <frozen importlib._bootstrap>:622(_load_backward_compatible)\n",
       "        8    0.000    0.000    0.007    0.001 configurable.py:170(_config_changed)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.Cryptography_add_osrandom_engine}\n",
       "        1    0.000    0.000    0.008    0.008 general_name.py:5(<module>)\n",
       "        2    0.000    0.000    0.007    0.004 connection.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 optimizer.py:32(__init__)\n",
       "        3    0.000    0.000    0.199    0.066 tarfile.py:1522(open)\n",
       "       36    0.000    0.000    0.000    0.000 getlimits.py:69(<lambda>)\n",
       "       23    0.000    0.000    0.000    0.000 re.py:169(match)\n",
       "     15/4    0.000    0.000    0.000    0.000 pyparsing.py:3762(streamline)\n",
       "       46    0.000    0.000    0.000    0.000 crc32c.py:100(crc_finalize)\n",
       "        1    0.000    0.000    0.002    0.002 models.py:8(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 cookiejar.py:1224(CookieJar)\n",
       "       38    0.000    0.000    0.000    0.000 constraint_registry.py:86(register)\n",
       "        1    0.000    0.000    0.092    0.092 thnn.py:21(_initialize_backend)\n",
       "        1    0.000    0.000    0.090    0.090 auto.py:1(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 util.py:150(_get_soname)\n",
       "       23    0.000    0.000    0.000    0.000 threading.py:1136(daemon)\n",
       "       30    0.000    0.000    0.000    0.000 sre_parse.py:257(getwhile)\n",
       "        6    0.000    0.000    0.002    0.000 warnings.py:119(filterwarnings)\n",
       "        2    0.000    0.000    0.000    0.000 pygram.py:22(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:4875(_makeTags)\n",
       "       24    0.000    0.000    0.000    0.000 pyparsing.py:411(__getitem__)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2707(parseImpl)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(<listcomp>)\n",
       "        1    0.000    0.000    0.006    0.006 cookies.py:127(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:336(BasicConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:185(CertificateRevocationList)\n",
       "        2    0.000    0.000    0.007    0.003 transforms.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 distributed_c10d.py:1(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:296(get_device_properties)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:219(_acquireLock)\n",
       "       60    0.000    0.000    0.000    0.000 {method 'copy' of 'mappingproxy' objects}\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:52(__new__)\n",
       "        1    0.000    0.000    0.005    0.005 plistlib.py:47(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 ocsp.py:25(_requires_successful_response)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:1(<module>)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:118(<listcomp>)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:74(__call__)\n",
       "       40    0.000    0.000    0.000    0.000 bunch.py:11(__getattr__)\n",
       "      102    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
       "       42    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:61(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:285(_add_types)\n",
       "        4    0.000    0.000    0.006    0.002 mnist.py:90(_check_exists)\n",
       "       25    0.000    0.000    0.000    0.000 typing.py:1025(_abc_negative_cache)\n",
       "       25    0.000    0.000    0.000    0.000 argparse.py:2286(_get_value)\n",
       "       16    0.000    0.000    0.008    0.000 traitlets.py:1133(_notify_trait)\n",
       "       40    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
       "      102    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 encode_asn1.py:5(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 algos.py:19(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 loss.py:1(<module>)\n",
       "       62    0.000    0.000    0.000    0.000 numerictypes.py:127(english_lower)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1226(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 inspect.py:1180(getargvalues)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:4(<module>)\n",
       "       28    0.000    0.000    0.000    0.000 pyparsing.py:3997(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:225(_register_default_ciphers)\n",
       "        1    0.000    0.000    0.008    0.008 mbcsgroupprober.py:30(<module>)\n",
       "        2    0.000    0.000    0.008    0.004 __init__.py:45(<module>)\n",
       "       53    0.000    0.000    0.000    0.000 inspect.py:81(ismethod)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:771(__init__)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1838(getLogger)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:83(<listcomp>)\n",
       "       82    0.000    0.000    0.000    0.000 {method 'AddDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       16    0.000    0.000    0.002    0.000 descriptor.py:869(__new__)\n",
       "        1    0.000    0.000    0.001    0.001 pooling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:5(Parameter)\n",
       "        1    0.000    0.000    0.002    0.002 serialization.py:1(<module>)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:1493(_check_conflict)\n",
       "       40    0.000    0.000    0.000    0.000 inspect.py:229(istraceback)\n",
       "        1    0.000    0.000    0.001    0.001 blas.py:202(<module>)\n",
       "        1    0.000    0.000    0.025    0.025 compat.py:9(<module>)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:26(_fr1)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:573(format)\n",
       "       84    0.000    0.000    0.000    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
       "        1    0.000    0.000    0.004    0.004 fractions.py:4(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 six.py:91(__get__)\n",
       "        1    0.000    0.000    0.003    0.003 chardistribution.py:28(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:9(parse_kwargs)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:308(init_reductions)\n",
       "       62    0.000    0.000    0.000    0.000 _inspect.py:146(<lambda>)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:71(<lambda>)\n",
       "        6    0.000    0.000    0.000    0.000 gettext.py:205(_expand_lang)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1604(__init__)\n",
       "        1    0.000    0.000    0.014    0.014 inspect.py:1481(getinnerframes)\n",
       "        8    0.000    0.000    0.000    0.000 inspect.py:1026(_getfullargs)\n",
       "       10    0.000    0.000    0.000    0.000 sre_compile.py:381(_bytes_to_codes)\n",
       "        3    0.000    0.000    0.001    0.000 _utils.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 type_checkers.py:44(<module>)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1813(get_metadata_lines)\n",
       "        1    0.000    0.000    0.349    0.349 writer.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:766(_construct_lookups)\n",
       "        8    0.000    0.000    0.003    0.000 traitlets.py:950(__new__)\n",
       "       50    0.000    0.000    0.000    0.000 inspect.py:239(isframe)\n",
       "        1    0.000    0.000    0.004    0.004 sessions.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:55(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 activation.py:1(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:331(device_count)\n",
       "        1    0.000    0.000    0.005    0.005 zmqshell.py:538(_showtraceback)\n",
       "       16    0.000    0.000    0.001    0.000 traitlets.py:1690(instance_init)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:4(<module>)\n",
       "       95    0.000    0.000    0.000    0.000 pyparsing.py:203(<genexpr>)\n",
       "       50    0.000    0.000    0.000    0.000 six.py:184(find_module)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:1793(has_metadata)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 normalization.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:1(<module>)\n",
       "       18    0.000    0.000    0.000    0.000 core.py:996(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 textwrap.py:414(dedent)\n",
       "       49    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
       "        2    0.000    0.000    0.003    0.001 dh.py:5(<module>)\n",
       "       34    0.000    0.000    0.000    0.000 descriptor_pb2.py:5(<lambda>)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2256(_is_egg_path)\n",
       "        4    0.000    0.000    0.355    0.089 __init__.py:2(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 serialization.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 interfaces.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcssm.py:28(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:174(nti)\n",
       "        8    0.000    0.000    0.011    0.001 PyColorize.py:180(__init__)\n",
       "        1    0.000    0.000    0.009    0.009 JpegImagePlugin.py:35(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 grammar.py:105(load)\n",
       "       43    0.000    0.000    0.000    0.000 caffe2_pb2.py:5(<lambda>)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3581(<genexpr>)\n",
       "        1    0.000    0.000    0.010    0.010 version.py:4(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 _tqdm.py:9(<module>)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:109(has_argument)\n",
       "        1    0.000    0.000    0.046    0.046 ultratb.py:1056(format_exception_as_a_whole)\n",
       "        1    0.000    0.000    0.006    0.006 subprocess.py:588(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 enum.py:874(_power_of_two)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.urandom}\n",
       "       23    0.000    0.000    0.000    0.000 writer.py:53(__init__)\n",
       "        3    0.000    0.000    0.199    0.066 tarfile.py:2276(next)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:86(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 session.py:657(send)\n",
       "       23    0.000    0.000    0.000    0.000 queue.py:199(_init)\n",
       "       25    0.000    0.000    0.000    0.000 typing.py:1039(_abc_negative_cache_version)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:202(__init__)\n",
       "       30    0.000    0.000    0.000    0.000 inspect.py:64(ismodule)\n",
       "       32    0.000    0.000    0.001    0.000 tokenize.py:379(read_or_stop)\n",
       "        3    0.000    0.000    0.002    0.001 __init__.py:10(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 BmpImagePlugin.py:27(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 decoder.py:79(<module>)\n",
       "        3    0.000    0.000    0.004    0.001 misc.py:1(<module>)\n",
       "       12    0.000    0.000    0.008    0.001 pyparsing.py:4251(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3439(<genexpr>)\n",
       "        1    0.000    0.000    0.003    0.003 sbcsgroupprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:126(EventHandle)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method from_numpy}\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:88(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 _internal.py:6(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:15(ismethod)\n",
       "        2    0.000    0.000    0.000    0.000 weakref.py:102(__init__)\n",
       "       40    0.000    0.000    0.000    0.000 {method '__getitem__' of 'dict' objects}\n",
       "        1    0.000    0.000    0.001    0.001 PngImagePlugin.py:34(<module>)\n",
       "        1    0.000    0.000    0.033    0.033 odenvp_conditional_tol.py:65(_build_net)\n",
       "        1    0.000    0.000    0.010    0.010 descriptor.py:33(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 algorithms.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:113(__init__)\n",
       "        1    0.000    0.000    0.049    0.049 odeint.py:1(<module>)\n",
       "       60    0.000    0.000    0.000    0.000 six.py:835(add_metaclass)\n",
       "       22    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "        1    0.000    0.000    0.001    0.001 TiffTags.py:20(<module>)\n",
       "        2    0.000    0.000    0.351    0.176 __init__.py:33(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 onnx_graph.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 response.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 linear.py:47(__init__)\n",
       "       27    0.000    0.000    0.000    0.000 core.py:920(__init__)\n",
       "        1    0.000    0.000    0.005    0.005 index_tricks.py:1(<module>)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2190(_get_nargs_pattern)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:48(<listcomp>)\n",
       "       16    0.000    0.000    0.001    0.000 pyparsing.py:1204(setResultsName)\n",
       "       23    0.000    0.000    0.000    0.000 utils.py:112(__init__)\n",
       "        2    0.000    0.000    0.003    0.002 rnn.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 linalg.py:10(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 case.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 modules.py:96(__init__)\n",
       "       10    0.000    0.000    0.001    0.000 cnf_regularization.py:6(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:146(rng)\n",
       "       34    0.000    0.000    0.000    0.000 argparse.py:1278(register)\n",
       "       38    0.000    0.000    0.000    0.000 inspect.py:253(iscode)\n",
       "       48    0.000    0.000    0.000    0.000 tokenize.py:739(generate_tokens)\n",
       "       42    0.000    0.000    0.000    0.000 {method 'expandtabs' of 'str' objects}\n",
       "        1    0.000    0.000    0.002    0.002 basic.py:7(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 util.py:15(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 poolmanager.py:1(<module>)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6568(__init__)\n",
       "        1    0.000    0.000    0.011    0.011 __init__.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:17(<module>)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:70(<lambda>)\n",
       "       32    0.000    0.000    0.000    0.000 typing.py:889(__extrahook__)\n",
       "       48    0.000    0.000    0.000    0.000 traitlets.py:1047(cross_validation_lock)\n",
       "       16    0.000    0.000    0.000    0.000 _collections_abc.py:664(__contains__)\n",
       "        1    0.000    0.000    0.003    0.003 fixer_util.py:1(<module>)\n",
       "       94    0.000    0.000    0.000    0.000 pyparsing.py:4890(<genexpr>)\n",
       "       78    0.000    0.000    0.000    0.000 pyparsing.py:2052(leaveWhitespace)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:2863(__init__)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2263(_is_unpacked_egg)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:3120(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:63(NDArrayOperatorsMixin)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:28(isfunction)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:321(fix_frame_records_filenames)\n",
       "       40    0.000    0.000    0.000    0.000 traitlets.py:911(__get__)\n",
       "        2    0.000    0.000    0.000    0.000 shutil.py:1048(get_terminal_size)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:65(__init__)\n",
       "        1    0.000    0.000    0.007    0.007 text_format.py:41(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 pytorch_graph.py:1(<module>)\n",
       "       32    0.000    0.000    0.000    0.000 pyparsing.py:209(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 matfuncs.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:5(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 exceptions.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 constraints.py:19(<module>)\n",
       "        3    0.000    0.000    0.005    0.002 container.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 shape_base.py:1(<module>)\n",
       "       40    0.000    0.000    0.000    0.000 numerictypes.py:154(english_upper)\n",
       "       23    0.000    0.000    0.000    0.000 numerictypes.py:216(_evalname)\n",
       "        1    0.000    0.000    0.001    0.001 fromnumeric.py:3(<module>)\n",
       "       35    0.000    0.000    0.000    0.000 enum.py:822(_high_bit)\n",
       "       10    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:980(_recalculate)\n",
       "        3    0.000    0.000    0.000    0.000 utils.py:5(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 sparse.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:411(ImageFileDirectory_v2)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:48(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:663(__iadd__)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:328(ExprBuilder)\n",
       "        2    0.000    0.000    0.001    0.001 tensor.py:1(<module>)\n",
       "        1    0.000    0.000    0.051    0.051 interactiveshell.py:1981(showtraceback)\n",
       "        1    0.000    0.000    0.000    0.000 shutil.py:1093(which)\n",
       "        7    0.000    0.000    0.000    0.000 __init__.py:1109(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.unsetenv}\n",
       "       10    0.000    0.000    0.000    0.000 {method 'tolist' of 'memoryview' objects}\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:1(<module>)\n",
       "     12/2    0.000    0.000    0.000    0.000 pyparsing.py:1926(makeOptionalList)\n",
       "       61    0.000    0.000    0.000    0.000 pyparsing.py:2159(streamline)\n",
       "        1    0.000    0.000    0.031    0.031 binding.py:5(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 name.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ssl_.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 retry.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 constraint_registry.py:66(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:2(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 profiler.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 polynomial.py:56(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:19(ABCPolyBase)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:88(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 pytesttester.py:72(__init__)\n",
       "        1    0.000    0.000    0.034    0.034 train_cnf_drop.py:304(create_model)\n",
       "        1    0.000    0.000    0.005    0.005 __init__.py:206(_sanity_check)\n",
       "       42    0.000    0.000    0.000    0.000 argparse.py:2087(_parse_optional)\n",
       "        8    0.000    0.000    0.000    0.000 inspect.py:1016(getargs)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.putenv}\n",
       "       73    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "        1    0.000    0.000    0.030    0.030 refactor.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:84(<listcomp>)\n",
       "        1    0.000    0.000    0.003    0.003 x509.py:5(<module>)\n",
       "        1    0.000    0.000    0.014    0.014 _elliptic_curve.py:47(<module>)\n",
       "        1    0.000    0.000    0.013    0.013 _int.py:32(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:73(CFUNCTYPE)\n",
       "        2    0.000    0.000    0.005    0.003 mnist.py:94(download)\n",
       "       16    0.000    0.000    0.011    0.001 traitlets.py:576(__set__)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
       "        7    0.000    0.000    0.000    0.000 TiffImagePlugin.py:635(_register_basic)\n",
       "    13/12    0.000    0.000    0.000    0.000 pyparsing.py:3434(__str__)\n",
       "        2    0.000    0.000    0.006    0.003 resnet.py:1(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 _elliptic_curve.py:97(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:147(deprecated)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:94(_check_capability)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:59(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:332(<dictcomp>)\n",
       "        8    0.000    0.000    0.003    0.000 traitlets.py:982(setup_instance)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:1237(observe)\n",
       "       31    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:190(_checkLevel)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:976(_get_parent_path)\n",
       "        2    0.000    0.000    0.000    0.000 spectral_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 pygram.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:49(<listcomp>)\n",
       "       14    0.000    0.000    0.000    0.000 pyparsing.py:3576(__str__)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:4757(<lambda>)\n",
       "       10    0.000    0.000    0.000    0.000 __init__.py:23(find_module)\n",
       "        2    0.000    0.000    0.001    0.001 x25519.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 core.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 request.py:1(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 mixins.py:20(_binary_method)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:118(deprecate)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:358(__getattr__)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:55(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 loader.py:182(merge)\n",
       "       59    0.000    0.000    0.000    0.000 enum.py:594(name)\n",
       "       20    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}\n",
       "        1    0.000    0.000    0.008    0.008 utils.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 well_known_types.py:39(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 descriptor.py:635(__new__)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:116(RegisterFileDescriptor)\n",
       "        6    0.000    0.000    0.038    0.006 __init__.py:35(load_module)\n",
       "        1    0.000    0.000    0.000    0.000 decomp.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_schur.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:1529(Connection)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:1(<module>)\n",
       "       24    0.000    0.000    0.001    0.000 container.py:159(__iadd__)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:1024(frombuf)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:59(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:156(ones)\n",
       "        2    0.000    0.000    0.000    0.000 util.py:301(_findLib_prefix)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:332(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:183(dumps)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:135(<dictcomp>)\n",
       "       46    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:115(copy)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2751(charsAsStr)\n",
       "        8    0.000    0.000    0.000    0.000 six.py:195(load_module)\n",
       "       16    0.000    0.000    0.054    0.003 __init__.py:1914(_by_version_descending)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:11(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 socks.py:23(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:34(OCSPResponseStatus)\n",
       "        1    0.000    0.000    0.014    0.014 universaldetector.py:36(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 reductions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2931(__array_finalize__)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:59(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.empty}\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:440(_set_array_types)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:18(_fr0)\n",
       "       40    0.000    0.000    0.000    0.000 loader.py:165(_ensure_subconfig)\n",
       "       18    0.000    0.000    0.000    0.000 inspect.py:1262(convert)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:366(_create_)\n",
       "       27    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:908(__init__)\n",
       "       10    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:993(__iter__)\n",
       "       67    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
       "       20    0.000    0.000    0.000    0.000 tokenize.py:48(group)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'FindEnumTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.009    0.009 api_implementation.py:32(<module>)\n",
       "     16/2    0.000    0.000    0.001    0.001 pyparsing.py:3737(parseImpl)\n",
       "        1    0.000    0.000    0.000    0.000 dual.py:12(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 Image.py:2810(register_extension)\n",
       "        5    0.000    0.000    0.027    0.005 binding.py:122(_ensure_ffi_initialized)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:52(NameOID)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:11(ExtensionOID)\n",
       "        1    0.000    0.000    0.002    0.002 _iri.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:169(EmbeddingBag)\n",
       "        7    0.000    0.000    0.000    0.000 _jit_internal.py:113(boolean_dispatch)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:271(<dictcomp>)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:43(iscode)\n",
       "        1    0.000    0.000    0.008    0.008 util.py:310(find_library)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 ultratb.py:968(<listcomp>)\n",
       "       17    0.000    0.000    0.000    0.000 __init__.py:685(__init__)\n",
       "       15    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:294(IFDRational)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:130(InceptionA)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:89(_OCSPResponse)\n",
       "       36    0.000    0.000    0.000    0.000 backend.py:218(register_cipher_adapter)\n",
       "       21    0.000    0.000    0.000    0.000 utils.py:126(__getattr__)\n",
       "        1    0.000    0.000    0.004    0.004 sjisprober.py:28(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1414(_get_builtin_table)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:5(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 random.py:1(<module>)\n",
       "        1    0.000    0.000    0.065    0.065 __init__.py:147(_lazy_init)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:340(_add_integer_aliases)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:251(_get_machar)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:65(__init__)\n",
       "        1    0.000    0.000    0.016    0.016 tsit5.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 ImageFilter.py:18(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data.py:23(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1020(prepare_header)\n",
       "       16    0.000    0.000    0.000    0.000 traitlets.py:1673(validate)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:188(parse_notifier_name)\n",
       "       26    0.000    0.000    0.000    0.000 traceback.py:273(__getitem__)\n",
       "        5    0.000    0.000    0.000    0.000 re.py:249(escape)\n",
       "       13    0.000    0.000    0.000    0.000 _collections_abc.py:72(_check_methods)\n",
       "        1    0.000    0.000    0.001    0.001 GifImagePlugin.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scope.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:318(Leaf)\n",
       "        2    0.000    0.000    0.001    0.001 driver.py:117(load_grammar)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3781(__str__)\n",
       "        1    0.000    0.000    0.027    0.027 specifiers.py:4(<module>)\n",
       "       16    0.000    0.000    0.006    0.000 __init__.py:2006(safe_listdir)\n",
       "        1    0.000    0.000    0.002    0.002 record_writer.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:684(Context)\n",
       "       11    0.000    0.000    0.000    0.000 name.py:28(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:74(_check_cryptography)\n",
       "        1    0.000    0.000    0.005    0.005 linear.py:1(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:242(getdoc)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:51(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:418(_construct_char_code_lookup)\n",
       "       30    0.000    0.000    0.000    0.000 numerictypes.py:432(_add_array_type)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2491(seterr)\n",
       "        4    0.000    0.000    0.000    0.000 getlimits.py:376(__new__)\n",
       "        8    0.000    0.000    0.000    0.000 data.py:13(uniq_stable)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:864(__call__)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:839(_decompose)\n",
       "       28    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:30(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 descriptor.py:919(_ParseOptions)\n",
       "       12    0.000    0.000    0.000    0.000 six.py:126(__init__)\n",
       "        6    0.000    0.000    0.001    0.000 __init__.py:2707(from_filename)\n",
       "        1    0.000    0.000    0.338    0.338 event_file_writer.py:15(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:78(contains)\n",
       "        1    0.000    0.000    0.223    0.223 model_zoo.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 module.py:23(Module)\n",
       "        3    0.000    0.000    0.199    0.066 serialization.py:448(legacy_load)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:16(BaseTestSuite)\n",
       "        1    0.000    0.000    0.028    0.028 type_check.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 util.py:136(register_after_fork)\n",
       "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7f7580d6ca60}\n",
       "       18    0.000    0.000    0.000    0.000 argparse.py:568(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:223(_randbelow)\n",
       "        6    0.000    0.000    0.000    0.000 locale.py:379(normalize)\n",
       "        8    0.000    0.000    0.007    0.001 traitlets.py:805(compatible_observer)\n",
       "       16    0.000    0.000    0.000    0.000 traitlets.py:1694(_resolve_classes)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:312(__getattr__)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:2(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:621(decorator)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:31(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:4681(originalTextFor)\n",
       "       14    0.000    0.000    0.001    0.000 pyparsing.py:2026(__call__)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:338(<genexpr>)\n",
       "       13    0.000    0.000    0.000    0.000 six.py:80(_import_module)\n",
       "        1    0.000    0.000    0.005    0.005 train_misc.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 _main.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PoolKey)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2905(_update_from)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8066(getdoc)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:126(doc_note)\n",
       "        1    0.000    0.000    0.000    0.000 scimath.py:17(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:48(_numeric_methods)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:6(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 getlimits.py:507(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:598(serialize)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:87(date_default)\n",
       "        1    0.000    0.000    0.029    0.029 modules.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 path.py:86(compress_user)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:255(choice)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:1059(system)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:923(instance_init)\n",
       "       24    0.000    0.000    0.000    0.000 traitlets.py:215(__init__)\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:228(_releaseLock)\n",
       "       20    0.000    0.000    0.000    0.000 enum.py:581(__hash__)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:4(<module>)\n",
       "        2    0.000    0.000    0.010    0.005 odenvp_conditional_tol.py:208(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 text_encoding.py:31(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:3851(__init__)\n",
       "        2    0.000    0.000    0.001    0.001 pyparsing.py:3859(parseImpl)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1805(_warn_on_replacement)\n",
       "        1    0.000    0.000    0.350    0.350 torchvis.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:135(_declare_state)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:81(Backend)\n",
       "       35    0.000    0.000    0.000    0.000 backend.py:2100(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 constraint_registry.py:105(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:130(ConstantPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1049(MultiMarginLoss)\n",
       "        1    0.000    0.000    0.001    0.001 fftpack.py:32(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:6(BruteForceLayer)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:265(GaussianDiag)\n",
       "        1    0.000    0.000    0.001    0.001 rk_common.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:1933(_get_exc_info)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:182(encode)\n",
       "        6    0.000    0.000    0.000    0.000 weakref.py:354(__init__)\n",
       "       28    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
       "        6    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
       "        2    0.000    0.000    0.000    0.000 __config__.py:3(<module>)\n",
       "       43    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
       "       24    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
       "       34    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4781(<lambda>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:1069(wrapper)\n",
       "       12    0.000    0.000    0.000    0.000 dual.py:52(register_func)\n",
       "        1    0.000    0.000    0.000    0.000 idnadata.py:3(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:23(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 lowrank_multivariate_normal.py:57(LowRankMultivariateNormal)\n",
       "        1    0.000    0.000    0.001    0.001 data_parallel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:1(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 container.py:153(__len__)\n",
       "        2    0.000    0.000    0.000    0.000 linear.py:58(reset_parameters)\n",
       "        1    0.000    0.000    0.093    0.093 module.py:1(<module>)\n",
       "        3    0.000    0.000    0.199    0.066 tarfile.py:1087(fromtarfile)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:15(Tensor)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:25(register_func)\n",
       "       13    0.000    0.000    0.000    0.000 mixins.py:30(_reflected_binary_method)\n",
       "        1    0.000    0.000    0.001    0.001 loader.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:484(cast)\n",
       "        1    0.000    0.000    0.005    0.005 cnf_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interp.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 containers.py:40(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:4017(__str__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4450(delimitedList)\n",
       "       46    0.000    0.000    0.000    0.000 pyparsing.py:1366(postParse)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2045(suppress)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1103(ParserElement)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2431(parseImpl)\n",
       "        7    0.000    0.000    0.000    0.000 specifiers.py:266(_require_version_compare)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3027(_always_object)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:228(_AEADEncryptionContext)\n",
       "        2    0.000    0.000    0.000    0.000 backend.py:128(_get_osurandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:81(SignatureAlgorithmOID)\n",
       "        1    0.000    0.000    0.003    0.003 constant_time.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 certificate_transparency.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 escprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:20(warn_imbalance)\n",
       "        1    0.000    0.000    0.000    0.000 rendezvous.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:1(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:238(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:40(_inplace_binary_method)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:55(_NoValueType)\n",
       "        4    0.000    0.000    0.000    0.000 jsonapi.py:31(dumps)\n",
       "       49    0.000    0.000    0.000    0.000 reduction.py:43(register)\n",
       "        1    0.000    0.000    0.046    0.046 ultratb.py:1128(structured_traceback)\n",
       "       27    0.000    0.000    0.000    0.000 inspect.py:479(getmro)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'isoformat' of 'datetime.datetime' objects}\n",
       "        2    0.000    0.000    0.010    0.005 traceback.py:193(format_stack)\n",
       "       25    0.000    0.000    0.000    0.000 enum.py:332(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:966(_find_parent_path_names)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._multiprocessing_init}\n",
       "        1    0.000    0.000    0.003    0.003 text_format.py:1006(Tokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 extension_loader.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 visdom_writer.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3841(__str__)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:3935(__init__)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:4763(srange)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:1841(__radd__)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:389(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_lu.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:514(Image)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2761(register_open)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:112(tqdm)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:259(Morsel)\n",
       "        1    0.000    0.000    0.006    0.006 ciphers.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.X509_new}\n",
       "        1    0.000    0.000    0.002    0.002 idna.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:79(Certificate)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:154(cached_property)\n",
       "        1    0.000    0.000    0.000    0.000 filepost.py:1(<module>)\n",
       "        1    0.000    0.000    0.015    0.015 __init__.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:104(_has_ipv6)\n",
       "        1    0.000    0.000    0.001    0.001 gumbel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 _distributor_init.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:206(utcoffset)\n",
       "        1    0.000    0.000    0.001    0.001 adams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ImageOps.py:20(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:752(_addHandlerRef)\n",
       "        6    0.000    0.000    0.000    0.000 tokenize.py:344(_get_normal_name)\n",
       "       20    0.000    0.000    0.000    0.000 os.py:746(decode)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'findall' of '_sre.SRE_Pattern' objects}\n",
       "        1    0.000    0.000    0.000    0.000 fractions.py:60(Fraction)\n",
       "        1    0.000    0.000    0.002    0.002 noniterators.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 proto_graph.py:1(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4825(tokenMap)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1790(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:135(create_regularization_fns)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_svd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:46(SemLock)\n",
       "        1    0.000    0.000    0.000    0.000 scrypt.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:148(activate_osrandom_engine)\n",
       "        1    0.000    0.000    0.001    0.001 exceptions.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 lowrank_multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:7(Distribution)\n",
       "        1    0.000    0.000    0.002    0.002 bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:1(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 init.py:403(_make_deprecate)\n",
       "        3    0.000    0.000    0.000    0.000 serialization.py:173(_check_seekable)\n",
       "        1    0.000    0.000    0.003    0.003 random.py:22(manual_seed)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:2551(_arraymethod)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 twodim_base.py:3(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 defmatrix.py:1(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 numerictypes.py:181(english_capitalize)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2592(geterr)\n",
       "        1    0.000    0.000    0.000    0.000 einsumfunc.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:583(sign)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:2045(validate)\n",
       "       46    0.000    0.000    0.000    0.000 inspect.py:358(<lambda>)\n",
       "       24    0.000    0.000    0.000    0.000 traitlets.py:216(__call__)\n",
       "       10    0.000    0.000    0.000    0.000 traceback.py:276(__iter__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(normalize_encoding)\n",
       "        8    0.000    0.000    0.000    0.000 six.py:209(is_package)\n",
       "        8    0.000    0.000    0.000    0.000 six.py:114(_resolve)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:40(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 enum_type_wrapper.py:46(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:1877(__mul__)\n",
       "        1    0.000    0.000    0.072    0.072 __init__.py:554(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1063(ZipFile)\n",
       "        1    0.000    0.000    0.001    0.001 cmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_init}\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:491(PrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:514(X509Name)\n",
       "        1    0.000    0.000    0.000    0.000 utf8prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 escsm.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:8(NegativeBinomial)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:18(add_docstr_all)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:11(_check_balance)\n",
       "        1    0.000    0.000    0.000    0.000 gradcheck.py:1(<module>)\n",
       "        2    0.000    0.000    0.010    0.005 __init__.py:120(_lazy_call)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:279(get_device_capability)\n",
       "        1    0.000    0.000    0.000    0.000 _numpy_fft.py:54(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nanfunctions.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.arange}\n",
       "        1    0.000    0.000    0.000    0.000 histograms.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 main.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jsonutil.py:177(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 context.py:69(RLock)\n",
       "        8    0.000    0.000    0.000    0.000 ultratb.py:917(linereader)\n",
       "        1    0.000    0.000    0.000    0.000 getipython.py:17(get_ipython)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1414(wait)\n",
       "        3    0.000    0.000    0.001    0.000 re.py:179(search)\n",
       "       14    0.000    0.000    0.000    0.000 weakref.py:428(get)\n",
       "        1    0.000    0.000    0.000    0.000 sysconfig.py:612(get_platform)\n",
       "       12    0.000    0.000    0.000    0.000 {built-in method builtins.delattr}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._init_names}\n",
       "        1    0.000    0.000    0.000    0.000 ImageColor.py:20(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 summary_pb2.py:5(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:420(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:324(ParseResults)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3164(__init__)\n",
       "        1    0.000    0.000    0.023    0.023 specifiers.py:275(Specifier)\n",
       "       10    0.000    0.000    0.000    0.000 event_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 special_matrices.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:9(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:294(socksocket)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:185(DHPublicKey)\n",
       "        1    0.000    0.000    0.001    0.001 hmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:275(X509Backend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:581(ReasonFlags)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1078(X509)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:29(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 url.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 relaxed_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:118(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:1(<module>)\n",
       "        1    0.000    0.000    0.092    0.092 thnn.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:267(get_device_name)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'seed' of 'mtrand.RandomState' objects}\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:239(manager_path)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8061(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:1145(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 _version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:156(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:369(_set_up_aliases)\n",
       "        1    0.000    0.000    0.001    0.001 util.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:1669(chararray)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:62(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1533(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:1178(_add_notifiers)\n",
       "        8    0.000    0.000    0.000    0.000 shutil.py:1106(_access_check)\n",
       "        2    0.000    0.000    0.001    0.000 traceback.py:27(format_list)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:767(_create_pseudo_member_)\n",
       "        1    0.000    0.000    0.000    0.000 latin_1.py:41(getregentry)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_manualSeedAll}\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:16(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 ImagePalette.py:19(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:4(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:110(_generate_pickle_name)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:138(_newer)\n",
       "        1    0.000    0.000    0.025    0.025 driver.py:12(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 symbol_database.py:58(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 descriptor_pool.py:56(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3829(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:3098(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:9(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 six.py:189(__get_module)\n",
       "       12    0.000    0.000    0.000    0.000 __init__.py:15(search_path)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_qz.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:21(FFI)\n",
       "        1    0.000    0.000    0.014    0.014 lsun.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:863(DefaultCookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:302(OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:26(_Certificate)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:15(_ASN1Type)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3848(SequenceOf)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:510(DSASignature)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:10(_Reasons)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:116(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:383(PyOpenSSLContext)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1082(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 charsetgroupprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Url)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.224    0.224 alexnet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 bernoulli.py:10(Bernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:21(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:29(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 linear.py:69(extra_repr)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:20(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:57(_load_cudart)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:727(TarInfo)\n",
       "        3    0.000    0.000    0.199    0.066 tarfile.py:1613(taropen)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1385(TarFile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2775(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:493(StringConverter)\n",
       "        1    0.000    0.000    0.000    0.000 financial.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 py3k.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 session.py:102(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:1(<module>)\n",
       "        3    0.000    0.000    0.001    0.000 container.py:8(__init__)\n",
       "        1    0.000    0.000    0.091    0.091 cnf.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:1(<module>)\n",
       "        1    0.000    0.000    0.016    0.016 ultratb.py:307(wrapped)\n",
       "        1    0.000    0.000    0.046    0.046 ultratb.py:1373(structured_traceback)\n",
       "       22    0.000    0.000    0.000    0.000 ultratb.py:1466(nullrepr)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:826(__new__)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1456(addHandler)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:71(search_function)\n",
       "        1    0.000    0.000    0.000    0.000 JpegPresets.py:67(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 decoder.py:263(_StructPackDecoder)\n",
       "        2    0.000    0.000    0.000    0.000 extension_loader.py:16(DlopenGuard)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:24(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:1(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 attr_value_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 visdom_writer.py:23(VisdomWriter)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'ParseFromString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "       16    0.000    0.000    0.000    0.000 {method 'AddFileDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       13    0.000    0.000    0.000    0.000 {method 'AddEnumDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       25    0.000    0.000    0.000    0.000 {method 'append' of 'DescriptorSequence' objects}\n",
       "       13    0.000    0.000    0.000    0.000 symbol_database.py:93(RegisterEnumDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_Version)\n",
       "        2    0.000    0.000    0.006    0.003 train_misc.py:70(count_parameters)\n",
       "        1    0.000    0.000    0.001    0.001 _ccallback.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:586(Response)\n",
       "        1    0.000    0.000    0.000    0.000 parser.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:949(KeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:292(CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:115(inject_into_urllib3)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:124(HTTPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:10(ExpRelaxedCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:10(Normal)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 beta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:38(Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:9(Exponential)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:128(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 _utils_internal.py:16(get_file_path)\n",
       "        1    0.000    0.000    0.000    0.000 _six.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6266(__new__)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:45(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 arraypad.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:934(poly1d)\n",
       "        3    0.000    0.000    0.000    0.000 numerictypes.py:565(obj2sctype)\n",
       "        1    0.000    0.000    0.001    0.001 result.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 session.py:132(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:95(copy)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 terminal.py:109(get_terminal_size)\n",
       "       21    0.000    0.000    0.000    0.000 argparse.py:2312(_check_value)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:572(dgettext)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:746(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:960(__init__)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
       "       18    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_TagInfo)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Int8Tensor)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:3(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 driver.py:147(load_packaged_grammar)\n",
       "        1    0.000    0.000    0.000    0.000 x2num.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 reflection.py:46(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:317(__getitem__)\n",
       "       18    0.000    0.000    0.000    0.000 pyparsing.py:458(__bool__)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:21(BaseSpecifier)\n",
       "        1    0.000    0.000    0.072    0.072 __init__.py:567(_build_master)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:2205(file_ns_handler)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2464(Distribution)\n",
       "        1    0.000    0.000    0.001    0.001 expat.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_cholesky.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_qr.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2932(_apply_env_variables)\n",
       "        1    0.000    0.000    0.000    0.000 _binary.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:102(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:488(DistributionPoint)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:22(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:8(Binomial)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:13(Gamma)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:209(ComposeTransform)\n",
       "        1    0.000    0.000    0.003    0.003 adam.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:217(CosineAnnealingLR)\n",
       "        1    0.000    0.000    0.000    0.000 comm.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:17(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:13(_BatchNorm)\n",
       "        1    0.000    0.000    0.000    0.000 _reduction.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auto_double_backwards.py:1(<module>)\n",
       "       27    0.000    0.000    0.000    0.000 auto.py:339(make_default_double_backwards_fn)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:166(nts)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defmatrix.py:70(matrix)\n",
       "        3    0.000    0.000    0.000    0.000 ufunclike.py:14(_deprecate_out_named_y)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 result.py:12(failfast)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:169(utcnow)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'bind' of '_socket.socket' objects}\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:409(_real_close)\n",
       "        8    0.000    0.000    0.000    0.000 debugger.py:53(make_arrow)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:506(translation)\n",
       "        8    0.000    0.000    0.000    0.000 loader.py:252(__getitem__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:800(createLock)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:1014(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 re.py:204(split)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:196(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'count' of 'bytes' objects}\n",
       "       10    0.000    0.000    0.000    0.000 {method 'cast' of 'memoryview' objects}\n",
       "        4    0.000    0.000    0.000    0.000 fractions.py:294(_operator_fallbacks)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
       "       28    0.000    0.000    0.000    0.000 TiffImagePlugin.py:368(_delegate)\n",
       "        1    0.000    0.000    0.000    0.000 ImageChops.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:5(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 grammar.py:77(__init__)\n",
       "        1    0.000    0.000    0.038    0.038 __init__.py:85(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:187(Default)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:102(DescriptorPool)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:47(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:843(FileDescriptor)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1288(addParseAction)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1567(resetCache)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:1608(parseString)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:3032(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3061(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3353(setResultsName)\n",
       "        1    0.000    0.000    0.000    0.000 py31compat.py:1(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 six.py:181(_get_module)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:2237(_cygwin_patch)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:385(get_build_platform)\n",
       "        1    0.000    0.000    0.000    0.000 _expm_frechet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:171(RequestsCookieJar)\n",
       "        4    0.000    0.000    0.000    0.000 ocsp.py:63(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:264(OCSPRequest)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:214(_CertificateRevocationList)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:109(_register_osrandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_OpenSSLErrorWithText)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:180(RSASSAPSSParams)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:60(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:334(DHBackend)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:217(PKey)\n",
       "        1    0.000    0.000    0.000    0.000 universaldetector.py:51(UniversalDetector)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(RequestHistory)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:9(Poisson)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:8(TransformedDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:58(MultivariateNormal)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:8(Categorical)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:31(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:79(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:2(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 vision.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:341(FormattedTimesMixin)\n",
       "        4    0.000    0.000    0.000    0.000 serialization.py:111(default_restore_location)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:9(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.seterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:942(_register_types)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:561(msg_header)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:564(msg)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_ButcherTableau)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_RungeKuttaState)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:162(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 ImageEnhance.py:21(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 fakedata.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:157(__next__)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1042(format_exception)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:921(uname)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1348(_handle_exitstatus)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:193(total_ordering)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method sys.setdlopenflags}\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.open}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.get_terminal_size}\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 compatibility.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:32(Base)\n",
       "        1    0.000    0.000    0.001    0.001 parse.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:171(RefactoringTool)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:37(<listcomp>)\n",
       "        9    0.000    0.000    0.000    0.000 step_stats_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:38(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 descriptor.py:729(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:44(Message)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1455(_UnboundedCache)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2376(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:2963(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2991(__init__)\n",
       "        1    0.000    0.000    0.008    0.008 version.py:191(Version)\n",
       "       16    0.000    0.000    0.000    0.000 six.py:75(_add_doc)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:469(Module_six_moves_urllib)\n",
       "        5    0.000    0.000    0.000    0.000 six.py:159(_resolve)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:32(EventsWriter)\n",
       "        1    0.000    0.000    0.000    0.000 _procrustes.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ArgSpec)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:26(LowLevelCallable)\n",
       "        1    0.000    0.000    0.000    0.000 linalg_version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:499(_SignedCertificateTimestamp)\n",
       "        7    0.000    0.000    0.000    0.000 ocsp.py:43(<genexpr>)\n",
       "        7    0.000    0.000    0.000    0.000 decode_asn1.py:187(__init__)\n",
       "        2    0.000    0.000    0.027    0.013 binding.py:136(init_static_locks)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:613(EncryptionAlgorithm)\n",
       "        3    0.000    0.000    0.000    0.000 extensions.py:915(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:92(PrimePoint)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:183(EllipticCurveBackend)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:80(DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:150(DSAParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:15(EllipticCurveOID)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:69(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:32(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:137(_validate_dependencies_met)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:872(X509Req)\n",
       "        1    0.000    0.000    0.000    0.000 utf8prober.py:35(UTF8Prober)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:11(StudentT)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:49(check_compatibility)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:10(Geometric)\n",
       "        1    0.000    0.000    0.000    0.000 beta.py:10(Beta)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:164(_InverseTransform)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:63(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:225(StmtBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:18(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 scatter_gather.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:12(_ConvNd)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:451(__set__)\n",
       "        1    0.000    0.000    0.025    0.025 module.py:723(load_state_dict)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:7(Stream)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:7(cudaOutputMode)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:7(_StorageBase)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:2109(Chebyshev)\n",
       "        1    0.000    0.000    0.000    0.000 arraysetops.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:246(_ctypes)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 ufunclike.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _inspect.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:845(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2478(prod)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Mismatch)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:388(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:110(Conv2d)\n",
       "        2    0.000    0.000    0.000    0.000 squeeze.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:142(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:160(<listcomp>)\n",
       "        1    0.000    0.000    0.046    0.046 ultratb.py:1276(structured_traceback)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'copy' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 random.py:96(seed)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1354(add_argument_group)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:1115(append)\n",
       "       10    0.000    0.000    0.000    0.000 copy.py:111(_copy_immutable)\n",
       "        1    0.000    0.000    0.002    0.002 traceback.py:59(extract_tb)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:104(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:331(__iter__)\n",
       "       23    0.000    0.000    0.000    0.000 enum.py:599(value)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:339(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:334(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._tracer_warn_use_python}\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:110(GzipFile)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:115(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:375(EncodeVarint)\n",
       "       14    0.000    0.000    0.000    0.000 visdom_writer.py:13(_check_connection)\n",
       "        1    0.000    0.000    0.002    0.002 odenvp_conditional_tol.py:212(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 resource_handle_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:392(FieldDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(manifest_mod)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:4783(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:2020(__invert__)\n",
       "        1    0.000    0.000    0.002    0.002 specifiers.py:214(LegacySpecifier)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2310(EntryPoint)\n",
       "        1    0.000    0.000    0.002    0.002 train_misc.py:15(set_cnf_options)\n",
       "        1    0.000    0.000    0.000    0.000 flinalg.py:5(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 Image.py:2821(register_extensions)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:264(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 _utils.py:8(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:114(_make_name)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:332(Event)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:371(Barrier)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_pandas.py:1(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 api.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:340(Session)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:8(<module>)\n",
       "        1    0.000    0.000    0.025    0.025 _internal_utils.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_MemoryBIO)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:76(Blowfish)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:325(_OCSPRequest)\n",
       "        5    0.000    0.000    0.000    0.000 SSL.py:701(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:33(HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:183(PublicFormat)\n",
       "        1    0.000    0.000    0.000    0.000 _types.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(Any)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:971(Choice)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(Concat)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1044(NameConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:964(PublicKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:142(AuthorityKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2111(CRL)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:22(SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:33(SingleByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:714(X509Extension)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:36(EUCJPProber)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:70(HTTPConnection)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:28(Retry)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:7(OneHotCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:10(Multinomial)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:10(LogitRelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:9(Uniform)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:7(Independent)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ScriptMethodStub)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:44(__setstate__)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ASMoutput)\n",
       "        1    0.000    0.000    0.000    0.000 parallel_apply.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:9(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:608(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:459(CudnnModule)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 function.py:183(once_differentiable)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:54(with_metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 serialization.py:46(register_package)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3080(view)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:323(_get_typecodes)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:224(_FFTCache)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.geterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:74(_determine_error_states)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2891(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:24(TestResult)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:450(decorating_function)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:121(new_id)\n",
       "        4    0.000    0.000    0.000    0.000 hmac.py:90(update)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:342(_FuncPtr)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:425(LoadLibrary)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:70(set)\n",
       "        2    0.000    0.000    0.000    0.000 odefunc.py:75(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:12(PhotoTour)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:611(gettext)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:133(_get_kwargs)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:960(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1236(_fixupChildren)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1280(setLevel)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'datetime.datetime' objects}\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:219(_deepcopy_tuple)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:773(_get_devnull)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1154(_get_handles)\n",
       "        4    0.000    0.000    0.000    0.000 genericpath.py:53(getmtime)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:252(__subclasshook__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:349(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:672(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:806(fsdecode)\n",
       "       12    0.000    0.000    0.000    0.000 {method 'groupdict' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.access}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_cudnn_benchmark}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:947(TiffImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:16(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:504(_StructPackEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:14(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:93(StrictVersion)\n",
       "        1    0.000    0.000    0.002    0.002 version.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:10(ODENVP)\n",
       "        2    0.000    0.000    0.000    0.000 message_factory.py:50(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:5(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'FindOneofByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:230(RepeatedScalarFieldContainer)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4003(parseImpl)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4214(copy)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:4292(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:506(haskeys)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:668(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1972(__xor__)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:4(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 version.py:261(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1525(_register)\n",
       "        1    0.000    0.000    0.000    0.000 _sketches.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_polar.py:1(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2787(register_save)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:102(PrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:25(MockRequest)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:106(ARC4)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:387(_CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:26(AES)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:197(_DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:15(_HMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:117(activate_builtin_random)\n",
       "        1    0.000    0.000    0.000    0.000 aead.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_get_default_RAND}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.OpenSSL_add_all_algorithms}\n",
       "        3    0.000    0.000    0.000    0.000 binding.py:106(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:120(ExtendedKeyUsageOID)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:22(_OpenSSLError)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:172(Encoding)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:220(SignedDigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:168(Asn1Value)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:764(Void)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:862(TLSFeature)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:904(TLSFeatureType)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:170(__mul__)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:12(CipherBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:48(HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:232(SubjectKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:103(EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:268(RSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2665(_PassphraseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(Version)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:598(CertificateRevocationListBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 langthaimodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:128(HebrewProber)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:247(WrappedSocket)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:102(HTTPHeaderDict)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:736(HTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:87(RelaxedOneHotCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:8(Laplace)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:11(Cauchy)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:379(AffineTransform)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1262(_get_methods)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1450(_register_builtin)\n",
       "        1    0.000    0.000    0.001    0.001 replicate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nccl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 clip_grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 profiler.py:337(attr_formatter)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 random.py:77(manual_seed_all)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6256(MaskedConstant)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6440(_extrema_operation)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:1814(Hermite)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:1811(HermiteE)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:1764(Laguerre)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:1606(Polynomial)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:1794(Legendre)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.copyto}\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1923(suppress_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:29(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 case.py:1316(_deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_LoggingWatcher)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2887(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2896(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:532(max)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:1506(set_string_function)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:63(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:242(extract_header)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:739(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:11(CNF_augment)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:66(reset)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:8(MultiscaleParallelCNF)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:32(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:6(AdaptiveStepsizeODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:55(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:46(__exit__)\n",
       "        1    0.000    0.000    0.016    0.016 ultratb.py:1090(get_records)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1011(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:586(iteritems)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1401(_try_wait)\n",
       "        2    0.000    0.000    0.000    0.000 weakref.py:288(update)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:678(__delitem__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.TextIOWrapper' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.uname}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:1552(AppendingTiffWriter)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:418(TagBytes)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:542(_FloatingPointEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 literals.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:19(LParen)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:208(Node)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:327(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:252(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:49(any)\n",
       "        7    0.000    0.000    0.000    0.000 node_def_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:31(Version)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:105(calc_output_size)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:31(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 tensor_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:241(Duration)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4163(__lshift__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:315(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2765(Regex)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3015(parseImpl)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:407(AppDirs)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:248(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:589(SpecifierSet)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:28(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:78(_IndividualSpecifier)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:164(_SixMetaPathImporter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:551(WorkingSet)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1381(NullProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1506(DefaultProvider)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:1583(MemoizedZipManifests)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1603(ZipProvider)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2876(DistInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3114(_initialize)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:11(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 torchvis.py:19(TorchVis)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:156(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:138(DeprecatedImport)\n",
       "        5    0.000    0.000    0.000    0.000 Image.py:2776(register_mime)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:7(DistributedSampler)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:58(ResNeXt)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:13(CaseInsensitiveDict)\n",
       "        1    0.000    0.000    0.002    0.002 certs.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:13(where)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1961(MozillaCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 makefile.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:29(OCSPResponderEncoding)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:57(OCSPCertStatus)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:80(DHParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:142(DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:126(_EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:176(_RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:141(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:14(Mode)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:12(MACContext)\n",
       "        5    0.000    0.000    0.000    0.000 backend.py:114(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 ciphers.py:13(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:426(_ALPNSelectHelper)\n",
       "       10    0.000    0.000    0.000    0.000 SSL.py:646(_requires_decorator)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:96(Binding)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:40(NameAttribute)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:142(Name)\n",
       "        6    0.000    0.000    0.000    0.000 binding.py:54(_openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:178(PrivateFormat)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2286(IntegerBitString)\n",
       "        1    0.000    0.000    0.000    0.000 _ordereddict.py:23(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:50(_ForceNullParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:475(RSAESOAEPParams)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1126(Extension)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:54(OtherPrimeInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:329(NamedCurve)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:388(extended_datetime)\n",
       "        1    0.000    0.000    0.000    0.000 _errors.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:131(DSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:253(DERSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:300(AccessDescription)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:378(DeltaCRLIndicator)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:48(EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:313(EllipticCurvePublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:10(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:21(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:13(LogEntryType)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:18(Version)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:46(register_decorator)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(AsymmetricSignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:33(EUCTWProber)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:375(_EllipticCurve)\n",
       "        6    0.000    0.000    0.000    0.000 crypto.py:625(_cmp)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1573(X509Store)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:132(EUCKRDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:35(CharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:8(is_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:18(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 url.py:14(Url)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:9(Pareto)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:8(LogNormal)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:10(Weibull)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:19(cuFFTPlanCache)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(CUDAModule)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:68(_Ops)\n",
       "        1    0.000    0.000    0.000    0.000 gumbel.py:13(Gumbel)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:11(HalfCauchy)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:11(HalfNormal)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:340(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:11(FisherSnedecor)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:8(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:10(DistributedDataParallelCPU)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:27(DistributedDataParallel)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:113(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:19(DistributedDataParallel)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:4(is_available)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:10(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:22(Sequential)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:202(ModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:451(_ConvTransposeMixin)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:27(L1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:223(PoissonNLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:713(SmoothL1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(FilterDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:13(EmbeddingBag)\n",
       "        1    0.000    0.000    0.001    0.001 auto_symbolic.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:331(NestedIOFunction)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(Argument)\n",
       "        1    0.000    0.000    0.000    0.000 nvtx.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:612(_FileInFile)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:2363(_check)\n",
       "        4    0.000    0.000    0.000    0.000 serialization.py:62(_cpu_deserialize)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:312(_LowLevelFile)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:3350(dtype)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6060(mvoid)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6348(__setattr__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6449(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:270(NameValidator)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:18(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:17(__enter__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'tobytes' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 info.py:34(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:47(PytestTester)\n",
       "        3    0.000    0.000    0.000    0.000 index_tricks.py:241(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:66(TestLoader)\n",
       "        1    0.000    0.000    0.000    0.000 main.py:49(TestProgram)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:120(TextTestRunner)\n",
       "        6    0.000    0.000    0.000    0.000 case.py:420(addTypeEqualityFunc)\n",
       "        9    0.000    0.000    0.000    0.000 _globals.py:73(__repr__)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:156(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:260(send_multipart)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:236(msg_header)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:509(msg_id)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:34(_ensure_tzinfo)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:108(_current)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:127(hexdigest)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:99(CFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(MovingBatchNormNd)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:62(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:176(AutoencoderDiffEqNet)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:13(HyperLinear)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:36(FixedGridODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 dopri5.py:58(Dopri5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:24(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:17(SEMEION)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:12(MNIST)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:436(find_recursion)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1725(_get_positional_actions)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1484(_get_handler)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:188(iteritems)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:829(__prepare__)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:824(metaclass)\n",
       "       11    0.000    0.000    0.000    0.000 traceback.py:303(walk_tb)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:758(__del__)\n",
       "        3    0.000    0.000    0.000    0.000 threading.py:74(RLock)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:12(pickle)\n",
       "        4    0.000    0.000    0.000    0.000 sre_parse.py:161(__delitem__)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:93(__new__)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'bytes' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.charmap_build}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register_error}\n",
       "       14    0.000    0.000    0.000    0.000 {method 'end' of '_sre.SRE_Match' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isalnum' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:854(ImageFileDirectory_v1)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:630(decorator)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:629(_register_writer)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:137(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:286(PngStream)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:97(ChunkStream)\n",
       "        1    0.000    0.000    0.000    0.000 GifImagePlugin.py:46(GifImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:56(BmpImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:561(PyDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:377(_GzipReader)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:822(_FieldSkipper)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:409(_VarintBytes)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:49(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:33(olddict)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:37(oldstr)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:593(_Parser)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:1022(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:82(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:10(ParserGenerator)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:50(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:415(BasePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:606(WildcardPattern)\n",
       "        1    0.000    0.000    0.000    0.000 workspace.py:494(_BlobDict)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:27(Parser)\n",
       "        3    0.000    0.000    0.000    0.000 graph_pb2.py:5(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 versions_pb2.py:5(<lambda>)\n",
       "        6    0.000    0.000    0.000    0.000 layout_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:96(_calc_n_scale)\n",
       "        3    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:191(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:107(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:541(_FieldMaskTree)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:788(ListValue)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:343(RepeatedCompositeFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:222(Descriptor)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:434(ScalarMap)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3591(Each)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4141(Forward)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4296(postParse)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:644(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2545(CloseMatch)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3064(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3066(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3233(WordEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3256(ParseExpression)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3458(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:72(LegacyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:20(with_metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:103(MovedModule)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:173(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:957(Environment)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1123(ResourceManager)\n",
       "        2    0.000    0.000    0.192    0.096 __init__.py:3109(_call_aside)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:127(Plist)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:312(_PlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:764(_BinaryPlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:10(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 thops.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crc32c.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 embedding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:175(get_supported_platform)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(VersionConflict)\n",
       "        2    0.000    0.000    0.000    0.000 Image.py:2798(register_save_all)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lock.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:12(qualify)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:297(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:341(StructOrUnion)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:5(Sampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:46(ConcatDataset)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:84(HTTPAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:91(set_self_blocking)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:110(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:485(BaseCookie)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:90(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:60(RequestEncodingMixin)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:91(CAST5)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:148(ChaCha20)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:318(ZipInfo)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:740(_Tellable)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:760(ZipExtFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:989(_ZipWriteFile)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:329(_RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:418(_RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:14(X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:31(X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:42(Camellia)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:118(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:52(Prehashed)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:228(_EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:13(_HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:20(CipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:85(CBC)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:100(XTS)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:197(GCM)\n",
       "        1    0.000    0.000    0.000    0.000 cmac.py:16(_CMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:217(_DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:46(CRLEntryExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:130(AuthorityInformationAccessOID)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:135(CertificatePoliciesOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:18(HashAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:146(BLAKE2b)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:115(DNSName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:317(OtherName)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:64(register)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:272(SignedDigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:561(EncryptionAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:918(InhibitAnyPolicy)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1165(GeneralNames)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1343(InvalidityDate)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1421(OCSPNonce)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1449(UnrecognizedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:54(PrimeCurve)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:202(extended_date)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:33(HashBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:64(CMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:96(RSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:594(PolicyConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:694(PolicyInformation)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:744(UserNotice)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:781(NoticeReference)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:65(DSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:227(DSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:88(EllipticCurvePrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1941(Revoked)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:369(RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:431(CertificateBuilder)\n",
       "        2    0.000    0.000    0.000    0.000 utils.py:123(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(AsymmetricVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:14(DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:23(DSAParametersWithNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 langcyrillicmodel.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:204(_X509NameInvalidator)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1550(X509StoreFlags)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:34(EUCKRProber)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:96(Latin1Prober)\n",
       "        1    0.000    0.000    0.000    0.000 sjisprober.py:36(SJISProber)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:34(MultiByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:116(JapaneseContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 compat.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 charsetgroupprober.py:32(CharSetGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 escprober.py:35(EscCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:33(CodingStateMachine)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:18(is_local_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:95(HTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:92(RelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:8(LogisticNormal)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:24(_Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:6(Chi2)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:26(Transform)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:228(_HalfOpenInterval)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:38(_parse_env)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:784(OrderedDictWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:106(UnsupportedNodeError)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:112(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:254(ReduceLROnPlateau)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:10(Embedding)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:21(RNNBase)\n",
       "        1    0.000    0.000    0.000    0.000 convert_parameters.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:9(Upsample)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:7(PairwiseDistance)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:47(CosineSimilarity)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:647(FractionalMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:75(LayerNorm)\n",
       "        2    0.000    0.000    0.000    0.000 dropout.py:17(extra_repr)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:41(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:81(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:335(CELU)\n",
       "        4    0.000    0.000    0.000    0.000 utils.py:5(_ntuple)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:460(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:11(Linear)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:129(profile)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:39(__call__)\n",
       "        1    0.000    0.000    0.006    0.006 module.py:246(cuda)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:131(Event)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:86(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:73(_check_driver)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:336(_Stream)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:59(metaclass)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:6260(__has_singleton)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:86(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:805(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:866(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1315(_replace_dtype_fields)\n",
       "        2    0.000    0.000    0.000    0.000 helper.py:245(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:20(Arrayterator)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:184(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:51(BagObj)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:265(DataSource)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:216(_getintp_ctype)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:52(_set_function_name)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1338(FunctionTestCase)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:76(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:29(TextTestResult)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:759(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2902(_setdef)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:92(_str_epsneg)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:96(_str_xmin)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:100(_str_xmax)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:62(MachArLike)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:455(iinfo)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:217(record)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:250(_isdst)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:115(ParallelSumModules)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:17(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:151(AdamsBashforthMoulton)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:5(RegularizedODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:29(Stat)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:16(CIFAR10)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:12(STL10)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:10(SVHN)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:48(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:413(close)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1115(get_chained_exception)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1114(get_parts_of_chained_exception)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1726(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1733(parse_args)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1920(consume_positionals)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:2071(_match_arguments_partial)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:87(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1148(_sys_version)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:819(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:19(encode)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:823(setLevel)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:1056(_open)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method utcnow}\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:220(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:760(_missing_)\n",
       "        2    0.000    0.000    0.000    0.000 _collections_abc.py:271(__subclasshook__)\n",
       "        4    0.000    0.000    0.000    0.000 _collections_abc.py:367(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 _collections_abc.py:406(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:760(getenv)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method sys.getdlopenflags}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'title' of 'str' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._jit_init}\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:620(_register_loader)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:540(PngImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:188(iTXt)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(Iterator)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 JpegImagePlugin.py:300(JpegImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:74(ImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:294(StubImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:324(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 ImagePalette.py:23(ImagePalette)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:69(_PaddedFile)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:98(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:134(_SignedVarintDecoder)\n",
       "       13    0.000    0.000    0.000    0.000 decoder.py:190(_SimpleDecoder)\n",
       "        3    0.000    0.000    0.000    0.000 decoder.py:249(_ModifiedDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:288(_FloatDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:323(_DoubleDecoder)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:126(_SimpleSizer)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:429(_SimpleEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:77(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:17(BMNode)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:26(BottomMatcher)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:16(MinNode)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:347(DFAState)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:22(RParen)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(RTs)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:241(Py2Fixer)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:477(suspend_hooks)\n",
       "        1    0.000    0.000    0.000    0.000 driver.py:30(Driver)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:23(Grammar)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:197(Untokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:180(StackedCNFLayers)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:267(LooseVersion)\n",
       "        1    0.000    0.000    0.000    0.000 symbol_database.py:65(SymbolDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:98(Timestamp)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:398(FieldMask)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:185(BaseContainer)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:803(MethodDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:672(EnumValueDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:524(MessageMap)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:41(EnumTypeWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3523(MatchFirst)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3715(ParseElementEnhance)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3914(__str__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:4383(postParse)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:4904(makeHTMLTags)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:205(ParseBaseException)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:460(__iter__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1298(addCondition)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2439(Keyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3151(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3184(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3368(And)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:3461(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:42(_BaseVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:7(Infinity)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:86(_LazyDescr)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:124(_LazyModule)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:139(MovedAttribute)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:229(_MovedItems)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:360(Module_six_moves_urllib_error)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1127(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1778(FileMetadata)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1860(register_finder)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2973(Requirement)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:79(_InternalDict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:204(Data)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:454(_PlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:4(VendorImporter)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:56(S3RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:89(S3RecordWriterFactory)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:40(SummaryToEventTransformer)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:144(FileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:301(DistributionNotFound)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:342(register_loader_type)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:500(IMetadataProvider)\n",
       "        4    0.000    0.000    0.000    0.000 six.py:67(_add_doc)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:25(BaseTypeByIdentity)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:127(_DenseLayer)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:14(LSUNClass)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:300(_DataLoaderIter)\n",
       "        1    0.000    0.000    0.000    0.000 _utils.py:123(Comparable)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:14(TMonitor)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:186(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:210(Condition)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:57(Bottleneck)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:33(Inception3)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:267(_BaseSocket)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:93(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:272(PreparedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:13(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:108(HTTPDigestAuth)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1819(PyZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:732(Cookie)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:830(CookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1755(FileCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:119(IDEA)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:133(SEED)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(KeyDerivationFunction)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:595(LZMACompressor)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:175(OCSPResponseBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:17(AsymmetricPadding)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:57(TripleDES)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:108(_DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:108(_ECDSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:67(AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:30(ModeWithInitializationVector)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:57(ModeWithAuthenticationTag)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:131(OFB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:161(CFB8)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:176(CTR)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:106(_DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_by_id}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_set_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ASN1_STRING_set_default_mask_asc}\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:42(OCSPExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:60(Hash)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:167(BLAKE2s)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'new_allocator' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:41(GeneralName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:50(RFC822Name)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:160(UniformResourceIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:253(RegisteredID)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:279(IPAddress)\n",
       "        1    0.000    0.000    0.000    0.000 intranges.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1776(Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1829(Integer)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1910(BitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2198(OctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2370(OctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2501(ParsableOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2737(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2964(Enumerated)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:43(AlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:372(Pbkdf2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:398(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:463(PSourceAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:693(Constructable)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1572(Primitive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1695(AbstractString)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1210(SubjectAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1245(IssuerAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1280(CertificateIssuer)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1315(CRLReason)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1373(PrecertificateSignedCertificateTimestamps)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:74(RSAPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:86(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:136(_ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:227(FieldType)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:252(Pentanomial)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:264(CharacteristicTwo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:313(SpecifiedECDomain)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:384(ECDomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:454(PrivateKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:944(PublicKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:231(PEMSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:114(CRLNumber)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:261(AuthorityInformationAccess)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:406(CRLDistributionPoints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:447(FreshestCRL)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:655(CertificatePolicies)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:189(DSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:24(EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:288(ECDSA)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:384(EllipticCurvePrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:338(RSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1696(X509StoreContext)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2336(PKCS7)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2387(PKCS12)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:390(CertificateSigningRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 langgreekmodel.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langbulgarianmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langhebrewmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langturkishmodel.py:37(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 crypto.py:205(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:33(GB2312Prober)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:34(CP949Prober)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:34(Big5Prober)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:40(CharDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312freq.py:42(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 big5freq.py:43(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jisfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:183(SJISContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:50(RequestField)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:122(PoolManager)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:362(ProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:8(InputState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:17(LanguageFilter)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:223(HTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:263(VerifiedHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:28(RecentlyUsedContainer)\n",
       "        1    0.000    0.000    0.000    0.000 request.py:10(RequestMethods)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:55(ConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:207(IncompleteRead)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:117(__getattr__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:6(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:5(ExponentialFamily)\n",
       "        2    0.000    0.000    0.000    0.000 constraint_registry.py:83(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:217(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:290(ExpTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(PowerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:42(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:61(_ResourceSharer)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:7(Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:550(ignore_lib_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:817(OrderedModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:960(ScriptModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1164(WeakScriptModuleProxy)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:1279(_make_fail)\n",
       "        2    0.000    0.000    0.000    0.000 annotations.py:15(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:6(Adadelta)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:58(__setstate__)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:119(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:150(update_group)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:154(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:17(Optimizer)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:6(ASGD)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:5(SGD)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:5(RMSprop)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:10(_LRScheduler)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:56(LambdaLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:126(StepLR)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:35(DataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:9(Broadcast)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:6(_DropoutNd)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:22(Dropout)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:61(Dropout2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:10(_ConstantPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:166(_ReflectionPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:270(_ReplicationPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:8(WeightNorm)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:9(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:6(PixelShuffle)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:6(Fold)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:96(ModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:318(ParameterList)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:415(ParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:9(_MaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:29(MaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:444(AvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:502(AvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:707(_LPPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:723(LPPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:766(LPPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:863(AdaptiveMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:948(AdaptiveAvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:971(AdaptiveAvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:172(BatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:6(_InstanceNorm)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:11(LocalResponseNorm)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:58(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:69(Conv1d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:190(Conv2d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:323(Conv3d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:760(ConvTranspose3d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:10(Threshold)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:89(RReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:210(ReLU6)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:295(ELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:380(SELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:425(GLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:459(Hardshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:576(Softplus)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:621(Softshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:663(PReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:728(Softsign)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:868(Softmax2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:96(NLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:289(KLDivLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:507(BCEWithLogitsLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:598(HingeEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:658(MultiLabelMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:773(SoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:815(CrossEntropyLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1001(MarginRankingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1112(TripletMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1188(CTCLoss)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:204(TensorDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:226(TensorDescriptorArray)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:444(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:75(Bilinear)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:24(EventList)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:377(FunctionEvent)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:7(Type)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:25(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:4(detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:108(Function)\n",
       "        4    0.000    0.000    0.000    0.000 function.py:273(_iter_filter)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(FunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:18(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:23(THNNBackendBase)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:10(_ContextMethodMixin)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:211(device)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:68(_Formatter)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1443(MAxisConcatenator)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:3366(shape)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6284(__array_finalize__)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:177(_ndptr)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:206(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:845(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:882(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:976(_MaskedBinaryOperation)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:1362(getmask)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2378(_MaskedPrintOption)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:115(NpzFile)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:621(Repository)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1858(clear_and_catch_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:997(SafeEval)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:115(NoseTester)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:231(AxisConcatenator)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:531(ndindex)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:653(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 function_base.py:1760(vectorize)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:92(TestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:270(_ErrorHolder)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:23(_FailedTest)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:13(_WritelnDecorator)\n",
       "        7    0.000    0.000    0.000    0.000 _inspect.py:144(<lambda>)\n",
       "        5    0.000    0.000    0.000    0.000 _inspect.py:145(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:104(_str_resolution)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:305(finfo)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:44(_Outcome)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:278(_CapturingHandler)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1234(TimedeltaFormat)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:304(recarray)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:20(memmap)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:9(PackageLoader)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:83(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:207(send_multipart)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:7(PlanarFlow)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:9(_ActNorm)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:170(Permute2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:291(Split2d)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:3(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 _testutils.py:26(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:136(__lt__)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:61(VariableCoefficientAdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:7(OdeintAdjointMethod)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:6(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:9(Omniglot)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:25(LogitTransform)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:4(SequentialFlow)\n",
       "        1    0.000    0.000    0.000    0.000 cnf.py:11(CNF)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:5(Euler)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:31(Compose)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:149(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:271(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:481(RandomResizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:606(TenCrop)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:94(MedianFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:306(Color3DLUT)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:483(EnumType)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:7(CocoCaptions)\n",
       "        1    0.000    0.000    0.000    0.000 fakedata.py:6(FakeData)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:44(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:1138(_get_call_pdb)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 configurable.py:381(instance)\n",
       "        1    0.000    0.000    0.000    0.000 configurable.py:426(initialized)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1255(python_implementation)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:60(safe_unicode)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1982(createLock)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method binascii.b2a_hex}\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:537(_generate_next_value_)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:794(fsencode)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rfind' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rstrip' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rjust' of 'str' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getCompiledVersion}\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:48(PpmImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:23(TagInfo)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:678(_idat)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:209(PngInfo)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:249(DibImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:24(GimpPaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:62(GradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:103(GimpGradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:22(PaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:549(PyCodecState)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:92(TypeChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:113(TypeCheckerWithDefault)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:125(IntValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:146(EnumValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:194(Int32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:214(Uint64ValueChecker)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:107(_VarintDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:155(_ModifiedSizer)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:372(_VarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:80(PackTag)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:24(BaseBaseString)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:28(BaseOldDict)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:14(BaseOldStr)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:272(DebugMode)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:100(TextWriter)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:253(_Printer)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:38(PatternCompiler)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:337(NFAState)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:501(LeafPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:545(NodePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:794(NegatedPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pygram.py:20(Symbols)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:24(PatternSyntaxError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(hooks)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:16(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:43(_EveryNode)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:167(FixerError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:692(MultiprocessRefactoringTool)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:164(TokenError)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:166(StopTokenizing)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:19(Node_base)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:38(Node_py)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:63(Node_py_IO)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:72(Node_py_OP)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:79(Graph_py)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:50(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:46(DescriptorDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:47(MessageFactory)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:64(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:68(Any)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:735(Struct)\n",
       "        2    0.000    0.000    0.000    0.000 types_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:748(ServiceDescriptor)\n",
       "        2    0.000    0.000    0.000    0.000 api_implementation.py:136(Type)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:607(EnumDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:712(OneofDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:39(Error)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:40(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:55(TypeTransformationError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:64(DescriptorMetaclass)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:76(_Lock)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:94(DescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:165(_NestedDescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:272(Marker)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:31(UndefinedComparison)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:25(InvalidMarker)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:44(Node)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:59(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:65(Value)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3444(Or)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3792(FollowedBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3818(NotAny)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3850(_MultipleMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3888(OneOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3923(ZeroOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3954(_NullToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3962(Optional)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4026(SkipTo)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4222(_ForwardNoRecurse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4226(TokenConverter)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4234(Combine)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4278(Group)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4299(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4364(Suppress)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4390(OnlyOnce)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:75(Requirement)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:183(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:261(ParseException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:282(ParseFatalException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:287(ParseSyntaxException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:306(RecursiveGrammarException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:314(_ParseResultsWithOffset)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:666(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1478(_FifoCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2372(Empty)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2383(NoMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2504(CaselessLiteral)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2527(CaselessKeyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2606(Word)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2838(QuotedString)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2975(CharsNotIn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3046(White)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3097(_PositionToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3104(GoToColumn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3130(LineStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3160(LineEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3180(StringStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3199(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3195(StringEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3213(WordStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3384(_ErrorStop)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:36(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:39(NegativeInfinity)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:15(InvalidSpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:27(metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:320(Module_six_moves_urllib_parse)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:380(Module_six_moves_urllib_request)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:523(IResourceProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:905(subscribe)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:937(_ReqExtras)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1107(ExtractionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1484(EggProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1549(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1536(EmptyProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1556(ZipManifests)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1817(PathMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1842(EggMetadata)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1907(find_nothing)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1989(NoDists)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:2076(register_namespace_handler)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2857(EggInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2946(RequirementParseError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3165(PkgResourcesDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:109(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:416(_DumbXMLWriter)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:587(InvalidFileException)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:595(_BinaryPlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:64(install)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:126(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:29(register_writer_factory)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:104(RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:79(EventFileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:156(_EventLoggerThread)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(PEP440Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:249(ResolutionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:288(ContextualVersionConflict)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:22(SqrtmError)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:9(CData)\n",
       "        1    0.000    0.000    0.000    0.000 misc.py:11(LinAlgWarning)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2282(ImagePointHandler)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:25(deferred_error)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:20(ModeDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:5(CDefError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:16(VerificationError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:20(VerificationMissing)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:72(BaseType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:88(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:85(VoidType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:97(BasePrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:178(UnknownIntegerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:192(UnknownFloatType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:204(BaseFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:224(RawFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:239(FunctionPtrType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:261(PointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:278(ConstPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:284(NamedPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:293(ArrayType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:324(StructOrUnionOrEnum)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:147(_DenseBlock)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:165(DenseNet)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:59(LSUN)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:23(SequentialSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:40(RandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:96(WeightedRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:126(BatchSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:8(Dataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:26(TensorDataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:90(Subset)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:39(ExceptionWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:40(DecompressionBombWarning)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:44(DecompressionBombError)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:48(_imaging_not_installed)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:479(_E)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:8(TqdmSynchronisationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:123(Semaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:142(BoundedSemaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:159(Lock)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:184(RLock)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:26(tqdm_gui)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:25(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:96(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:16(ResNeXtBottleneckC)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:24(VGG)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:17(Fire)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:40(SqueezeNet)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:162(InceptionB)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:185(InceptionC)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:250(InceptionE)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:292(InceptionAux)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:317(BasicConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:95(SessionRedirectMixin)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:55(BaseAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:59(SOCKSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:129(SOCKSHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:137(SOCKSHTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:141(SOCKSProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:127(ProxyConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:135(SOCKS5Error)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:139(SOCKS4Error)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:36(TqdmTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:40(TqdmKeyError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:44(TqdmWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:67(TqdmMonitorWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:95(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:86(TqdmDefaultWriteLock)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:625(SimpleCookie)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:97(MockResponse)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:165(CookieConflictError)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:87(LookupDict)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:174(RequestHooksMixin)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:198(Request)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:72(AuthBase)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:79(HTTPBasicAuth)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:100(HTTPProxyAuth)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1753(LoadError)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1841(LWPCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:150(CookieError)\n",
       "        1    0.000    0.000    0.000    0.000 scrypt.py:23(Scrypt)\n",
       "        1    0.000    0.000    0.000    0.000 __version__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:47(LargeZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:534(_ZipDecrypter)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:618(LZMADecompressor)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:714(_SharedFile)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:76(OCSPRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:272(_RSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:299(_RSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(PKCS1v15)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:31(PSS)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:49(OAEP)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:62(MGF1)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:13(_X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:32(_X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:49(DHPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:170(DHPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:47(_DSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:68(_DSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:84(_DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:92(_ECDSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:35(BlockCipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:86(AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:96(Cipher)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:164(_AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:39(ModeWithTweak)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:48(ModeWithNonce)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:124(ECB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:146(CFB)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:23(_Integers)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:186(_X509ExtensionParser)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:36(_DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:18(DHPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2099(GetCipherByName)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:118(_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:239(Error)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:249(WantReadError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:261(ZeroReturnError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:269(_CallbackExceptionHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:297(_VerifyHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:336(_NpnAdvertiseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:477(_OCSPServerCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:549(_OCSPClientCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:673(Session)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ERR_clear_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.RAND_cleanup}\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:46(cryptography_has_ssl3_method)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:102(RelativeDistinguishedName)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:104(SHA1)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:118(SHA256)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:125(SHA384)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:139(MD5)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:62(openssl_assert)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:57(make_assert)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'gc' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:189(ParameterFormat)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:193(KeySerializationEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:198(BestAvailableEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:227(DirectoryName)\n",
       "        1    0.000    0.000    0.000    0.000 package_data.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:26(InvalidCodepoint)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:31(InvalidCodepointContext)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2448(IntegerOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2665(ParsableOctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2706(Null)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2956(Real)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4298(Set)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4517(EmbeddedPdv)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4525(NumericString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4534(PrintableString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4543(TeletexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4569(AbstractTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4615(UTCTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4671(GeneralizedTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4754(VisibleString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4763(GeneralString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4792(BMPString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:14(TeletexCodec)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:23(TeletexIncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:29(TeletexIncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:107(HmacAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:120(HmacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:127(DigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:141(DigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:149(DigestInfo)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:156(MaskGenAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:162(MaskGenAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:174(TrailerField)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:365(Pbkdf2Salt)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:381(KdfAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:387(KdfAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:417(KeyExchangeAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:428(Rc2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:435(Rc5ParamVersion)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:441(Rc5Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:450(Pbes1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:457(PSourceAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1084(Pbes2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1098(Pkcs5MacId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1104(Pkcs5MacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1129(AnyAlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:622(ValueMap)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:817(ExtendedKeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:852(OCSPNoCheck)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:857(PrecertPoison)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:66(OtherPrimeInfos)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:105(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:116(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:206(ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:211(ECPointBitString)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:284(FieldID)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:301(Curve)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:407(ECPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:420(DSAParams)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:435(Attribute)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:473(PrivateKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:886(EncryptedPrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:910(DomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:924(PublicKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:146(Codec)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:218(IncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:253(IncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:292(StreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:295(StreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:51(DuplicateExtension)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:57(ExtensionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:63(ExtensionType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:72(Extensions)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:157(SECT283R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:163(SECT233R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:175(SECT571K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:181(SECT409K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:187(SECT283K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:193(SECT233K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:199(SECT163K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:205(SECP521R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:211(SECP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:223(SECP256K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:229(SECP224R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:241(BrainpoolP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:247(BrainpoolP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:253(BrainpoolP512R1)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:24(UnsupportedAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:30(AlreadyFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:38(NotYetFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:42(InvalidTag)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:46(InvalidSignature)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(InternalError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:56(InvalidKey)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2568(NetscapeSPKI)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:73(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:693(RevokedCertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(register_interface_if)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:79(InterfaceNotImplemented)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:115(_DeprecatedValue)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:122(_ModuleWithDeprecations)\n",
       "        1    0.000    0.000    0.000    0.000 sbcsgroupprober.py:43(SBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:12(RequestException)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:28(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:32(ConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:80(InvalidURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:92(ChunkedEncodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:96(ContentDecodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:100(StreamConsumedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:104(RetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:119(FileModeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:124(RequestsDependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:54(UnsupportedExtension)\n",
       "        4    0.000    0.000    0.000    0.000 pyopenssl.py:102(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:76(Error)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1682(X509StoreContextError)\n",
       "        1    0.000    0.000    0.000    0.000 mbcsgroupprober.py:41(MBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 euctwfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:113(EUCTWDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:170(Big5DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:192(SJISDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:217(EUCJPDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 euckrfreq.py:41(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:22(DeflateDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:55(GzipDecoderState)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:62(GzipDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:93(MultiDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:10(LifoQueue)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:32(ProbingState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:41(MachineState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:50(SequenceLikelihood)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:65(CharacterCategory)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:65(DummyConnection)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:13(NoWayToWaitForSocketError)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:14(is_appengine_sandbox)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:23(is_prod_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:29(is_prod_appengine_mvms)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:18(PoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:29(RequestError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:55(ProtocolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:85(HostChangedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:115(ConnectTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:156(SecurityWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:161(SubjectAltNameWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:166(InsecureRequestWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:176(InsecurePlatformWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:181(SNIMissingWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:194(ResponseNotChunked)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:228(ProxySchemeUnknown)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:237(HeaderParsingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:244(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:5(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:28(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:32(_OpNamespace)\n",
       "        1    0.000    0.000    0.000    0.000 alexnet.py:13(AlexNet)\n",
       "        1    0.000    0.000    0.000    0.000 kl.py:77(_Match)\n",
       "        1    0.000    0.000    0.000    0.000 constraint_registry.py:79(ConstraintRegistry)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:77(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:362(AbsTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:446(SoftmaxTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:472(StickBreakingTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:514(LowerCholeskyTransform)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:49(Constraint)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:67(_Dependent)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:106(_IntegerInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:123(_IntegerLessThan)\n",
       "        2    0.000    0.000    0.000    0.000 constraints.py:143(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:155(_Real)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:163(_GreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:183(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:179(_GreaterThanEq)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:195(_LessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:215(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:245(_Simplex)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:254(_LowerTriangular)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:263(_LowerCholesky)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:277(_PositiveDefinite)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:291(_RealVector)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:105(lazy_property)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:20(StorageWeakRef)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:39(SharedCache)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:45(DupFd)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:40(SpawnContext)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:13(ExportTypes)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:234(LegacyTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:408(TracingCheckError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:549(TracerWarning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:649(CompilationUnit)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:847(OrderedParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:868(OrderedBufferDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:926(ScriptMeta)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1292(TracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1349(TopLevelTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1354(_ConstModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1384(_ConstSequential)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1465(_disable_tracing)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:90(FrontendError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:119(FrontendTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:152(SourceContext)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:158(Builder)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:14(Module)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(dist_backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:142(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:153(_DistributedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:9(_RequiredParameter)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:111(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:5(Adagrad)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:6(Adam)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:6(SparseAdam)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:5(Adamax)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:6(Rprop)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:6(LBFGS)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:161(MultiStepLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:198(ExponentialLR)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:35(ReduceAddCoalesced)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:50(Gather)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:78(Scatter)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:29(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:71(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:93(group)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:97(GroupMember)\n",
       "        3    0.000    0.000    0.000    0.000 rendezvous.py:13(register_rendezvous_handler)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:105(Dropout3d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:149(AlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:193(FeatureAlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(ConstantPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:75(ConstantPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:178(ReflectionPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:220(ReflectionPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:282(ReplicationPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:321(ReplicationPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:370(ReplicationPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:232(RNN)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:333(LSTM)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:441(GRU)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:537(RNNCellBase)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:585(RNNCell)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:658(LSTMCell)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:736(GRUCell)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:143(UpsamplingNearest2d)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:188(UpsamplingBilinear2d)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:110(Unfold)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:15(AdaptiveLogSoftmaxWithLoss)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:11(Container)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:84(MaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:151(MaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:222(_MaxUnpoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:231(MaxUnpool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:297(MaxUnpool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:371(MaxUnpool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:434(_AvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:568(AvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:822(_AdaptiveMaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:838(AdaptiveMaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:899(AdaptiveMaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:936(_AdaptiveAvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:98(BatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:246(BatchNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:134(InstanceNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:210(InstanceNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:165(GroupNorm)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:509(ConvTranspose1d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:617(ConvTranspose2d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:59(ReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:146(Hardtanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:242(Sigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:269(Tanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:321(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:551(LogSigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:754(Tanhshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:780(Softmin)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:818(Softmax)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:897(LogSoftmax)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:12(_Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:21(_WeightedLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:438(BCELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:907(MultiLabelSoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:954(CosineEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:196(BroadcastingListCls)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:160(flags_frozen)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:187(CuDNNHandle)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:197(CuDNNError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:321(RNNDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:443(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:464(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:6(VFModule)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:12(range)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:225(emit_nvtx)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:360(Interval)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:369(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:407(FunctionEventAvg)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:431(StringTable)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:497(EnforceUnique)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:5(no_grad)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:47(enable_grad)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:91(set_grad_enabled)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:75(set_detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:61(_HookMixin)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:79(FunctionMeta)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:242(InplaceFunction)\n",
       "        1    0.000    0.000    0.000    0.000 thnn.py:4(THNNFunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:4(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:6(Backends)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(Function)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:5(VariableMeta)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:130(DeferredCudaCallError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:195(cudaStatus)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:200(CudaError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:237(device_of)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:499(_CudaBase)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:510(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:514(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:518(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:522(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:526(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:534(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:716(ExFileObject)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:8(__PrinterOptions)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:7(RemovableHandle)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:275(TarError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:281(ReadError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:293(EmptyHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:302(InvalidHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:582(_StreamProxy)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1489(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1473(mr_class)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:194(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:198(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:202(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:206(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:214(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:218(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:222(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:32(SourceChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2596(MaskedIterator)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6557(_frommethod)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:8048(_convert2ma)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:218(_fromnxfunction)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:273(_fromnxfunction_single)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:304(_fromnxfunction_args)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:329(_fromnxfunction_allargs)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:95(MaskedArrayFutureWarning)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:174(MaskError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:208(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:796(_DomainCheckInterval)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:839(_DomainSafeDivide)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:860(_DomainGreater)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:892(_MaskedUFunc)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:902(_MaskedUnaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1124(_DomainedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(_replace_dtype_fields_recursive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1329(make_mask_descr)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2384(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:58(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:62(PolyError)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:66(PolyDomainError)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:79(PolyBase)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:170(LineSplitter)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:472(ConverterLockError)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:28(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:13(RTLD_for_MKL)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:22(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:138(_FileOpeners)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_string_function}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_typeDict}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:204(dummy_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:239(_missing_ctypes)\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:44(LinAlgError)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:15(DummyArray)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1816(IgnoreException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:57(_Deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:99(skipif)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:98(nd_grid)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:446(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:476(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:451(CClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:481(ndenumerate)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:609(IndexExpression)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1396(_SubTest)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:9(_InterruptHandler)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(KnownFailureException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1212(_Dummy)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:686(AxisError)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:750(_typedict)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2817(_unspecified)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2824(errstate)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:88(_str_eps)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:25(SkipTest)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:38(_UnexpectedSuccess)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:128(_BaseTestCaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:184(_AssertRaisesContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:221(_AssertWarnsContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:297(_AssertLogsContext)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:440(_recursive_guard)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:810(FloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:953(FloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1109(IntegerFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1132(ComplexFloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1161(ComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1168(LongComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1176(_TimelikeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1202(DatetimeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1249(StructuredVoidFormat)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:85(format_parser)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:17(MachAr)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:339(PackageLoaderDebug)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:128(MovingBatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:134(MovingBatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:7(CouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:51(MaskedCouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate.py:20(CNF_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:6(FeedforwardGateI)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:47(FeedforwardGateII)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:4(SequentialFlow_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:40(AverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(RunningAverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:126(ParallelCNFLayers)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:83(ActNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:95(LinearZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:152(Conv2dZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:194(InvertibleConv1x1)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:347(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:16(FPUModeChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:21(PytestTester)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:78(_compare_version)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:114(_compare)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:26(RK4)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:208(AdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:18(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:63(Swish)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:73(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:94(ODEnet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:255(ODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:316(AutoencoderODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:7(SequentialDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:21(MixtureODELayer)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:7(DiffEqWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:29(ReshapeDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:9(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:38(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:36(IgnoreLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:45(ConcatLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:56(ConcatLinear_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:66(SquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:76(ConcatSquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:88(HyperConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:124(IgnoreConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:137(SquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:166(ConcatConv2d_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:196(ConcatCoordConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:214(GatedLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:226(GatedConv)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:242(GatedConvTranspose)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:260(BlendLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:272(BlendConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:8(ZeroMeanTransform)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:43(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 tsit5.py:66(Tsit5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 rk_common.py:8(_RungeKuttaState)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:15(Midpoint)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:61(ToTensor)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:82(ToPILImage)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:120(Normalize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:182(Scale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:192(CenterCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:221(Pad)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(RandomApply)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:352(RandomChoice)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:360(RandomCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:429(RandomHorizontalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:455(RandomVerticalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:557(RandomSizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:567(FiveCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:649(LinearTransformation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:695(ColorJitter)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:767(RandomRotation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:834(RandomAffine)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:954(Grayscale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:984(RandomGrayscale)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:24(_Enhance)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:40(Color)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:58(Contrast)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:74(Brightness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:89(Sharpness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:28(Filter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:36(BuiltinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:43(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:71(RankFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:108(MinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:122(MaxFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:136(ModeFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:153(GaussianBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:167(BoxBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:187(UnsharpMask)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:223(CONTOUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:241(EDGE_ENHANCE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:250(EDGE_ENHANCE_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:259(EMBOSS)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:268(FIND_EDGES)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:277(SHARPEN)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:295(SMOOTH_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:47(DatasetFolder)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:150(ImageFolder)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:82(CocoDetection)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:174(CIFAR100)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:179(EMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:124(synchronize_with_editor)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:45(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:39(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:422(is_recursion_error)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:136(_get_args)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:595(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1211(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'pack' of 'Struct' objects}\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:1253(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:1254(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:287(seek)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:203(_cleanup)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1366(_internal_poll)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:337(__members__)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:868(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:98(checkgroup)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:213(setstate)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
       "        1    0.000    0.000    0.000    0.000 {method '__prepare__' of 'type' objects}\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:166(UnicodeValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:202(Uint32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:208(Int64ValueChecker)\n",
       "        3    0.000    0.000    0.000    0.000 encoder.py:184(_FixedSizer)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:387(_SignedVarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:470(_ModifiedEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:33(basestring)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:73(Error)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:688(MultiprocessingUnsupported)\n",
       "        2    0.000    0.000    0.000    0.000 tokenize.py:50(maybe)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:7(PgenGrammar)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:1056(Default)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:38(Error)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:42(DescriptorDatabaseConflictingDefinitionError)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:60(Error)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:41(EncodeError)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:42(GeneratedProtocolMessageType)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:51(Error)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:37(UndefinedEnvironmentName)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:71(Op)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4335(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:195(_Constants)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2364(Token)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2398(Literal)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:18(InvalidRequirement)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:430(Module_six_moves_urllib_response)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:451(Module_six_moves_urllib_robotparser)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:328(UnknownExtra)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1044(LstsqLapackError)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2287(ImageTransformHandler)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(FFIError)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:475(StructType)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:155(_Transition)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:79(SubsetRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:86(ManagerWatchdog)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:224(InceptionD)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:133(SOCKSHTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:123(GeneralProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:131(SOCKS5AuthError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:143(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:57(TqdmExperimentalWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:62(TqdmDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1222(Absent)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:43(BadZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:113(_SingleResponse)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:76(AEADDecryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:253(WantWriteError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:257(WantX509LookupError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:265(SysCallError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:377(_NpnSelectHelper)\n",
       "        3    0.000    0.000    0.000    0.000 SSL.py:636(_make_requires)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_finish}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_free}\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:154(_verify_openssl_version)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:135(cryptography_has_ssl_st)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:151(cryptography_has_locking_callbacks)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:111(SHA224)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:132(SHA512)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:207(NoEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:35(UnsupportedGeneralNameType)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:16(IDNAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:21(IDNABidiError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2940(ObjectDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2948(InstanceOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3032(UTF8String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3041(RelativeOid)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4484(SetOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4552(VideotexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4560(IA5String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4744(GraphicString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4773(UniversalString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4782(CharacterString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:35(TeletexStreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:40(TeletexStreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:30(LibraryNotFoundError)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:39(FFIEngineError)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:411(KeyExchangeAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1091(Pbmac1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1119(AnyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:649(Castable)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:216(SpecifiedECDomainVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:239(CharacteristicTwoBasis)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:396(ECPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:446(Attributes)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:899(ValidationParms)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:79(PBKDF2HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:389(ScryptBackend)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:145(SECT571R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:151(SECT409R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:169(SECT163R2)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:217(SECP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:235(SECP192R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:420(ECDH)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:54(RSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:34(AlreadyUpdated)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:16(CryptographyDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:36(ProxyError)\n",
       "        2    0.000    0.000    0.000    0.000 exceptions.py:40(SSLError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:44(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:53(ConnectTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:60(ReadTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:64(URLRequired)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:68(TooManyRedirects)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:72(MissingSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:76(InvalidSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:84(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:88(InvalidProxyURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:114(RequestsWarning)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:151(GB2312DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:212(EUCJPContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:13(HTTPWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:45(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:66(MaxRetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:94(TimeoutStateError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:99(TimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(ReadTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:120(NewConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:125(EmptyPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:130(ClosedPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:135(LocationValueError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:140(LocationParseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:150(ResponseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:171(SystemTimeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:186(DependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:199(BodyNotHttplibCompatible)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:223(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:80(_DependentProperty)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:139(_IntegerGreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:167(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:211(_Interval)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:102(NotSupportedError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:149(group)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:120(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:406(ZeroPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:147(SpectralNormLoadStateDictPreHook)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:177(SpectralNormStateDictHook)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:1005(AdaptiveAvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:58(InstanceNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:501(LeakyReLU)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:213(NLLLoss2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:370(MSELoss)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:277(DropoutDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:72(BackwardCFunction)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:249(_nested_map)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:10(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:530(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:538(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:278(ExtractError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:284(CompressionError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:287(StreamError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:290(HeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:296(TruncatedHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:299(EOFHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:305(SubsequentHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:28(prepare_multiprocessing_environment)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:291(_fromnxfunction_seq)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:166(MAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:829(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(_DomainTan)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:876(_DomainGreaterEqual)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:464(ConverterError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:480(ConversionWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:14(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 mixins.py:55(_unary_method)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:351(RClass)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:317(_DebugResult)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:683(TooHardError)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:83(ComplexWarning)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:33(_ShouldStop)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:137(_AssertRaisesBaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:960(LongFloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1122(BoolFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1239(SubArrayFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1286(StructureFormat)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:33(ModuleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:45(VisibleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:151(ConcatConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:289(RandomTransforms)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:341(RandomOrder)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:32(MultibandFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:212(BLUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:232(DETAIL)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:286(SMOOTH)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:479(UnionType)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:155(FashionMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:196(get_start_method)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:743(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:22(constructor)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:101(checklookbehindgroup)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_drop.py --data mnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_conditional_8K_drop_0_5_run1 --resume ../experiments_published/cnf_conditional_8K_drop_0_5_run1/epoch_365_checkpt.pth --seed 0 --conditional True --controlled_tol True --train_mode semisup --lr 0.0001 --warmup_iters 113 --atol 1e-4  --rtol 1e-4 --weight_y 0.5 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
