{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_2cond_nosep.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"colormnist\", \"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional_2cond as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, y_color, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "    y_onehot_color = thops.onehot(y_color, num_classes=model.module.y_color).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "    mean_color, logs_color = model.module._prior_color(y_onehot_color)\n",
      "    \n",
      "    mean_sup = mean + mean_color\n",
      "    logs_sup = 0.5 * torch.log(torch.exp(2.*logs) + torch.exp(2.*logs_color))\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean_sup, logs_sup, z[:, 0:dim_sup]).view(-1,1)\n",
      "\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "    \n",
      "    y_logits_color = model.module.project_color(zsup)\n",
      "    loss_xent_color = model.module.loss_class(y_logits_color, y_color.to(x.get_device()))\n",
      "    y_color_predicted = np.argmax(y_logits_color.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, loss_xent_color, y_predicted, y_color_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class,\n",
      "            y_color = args.y_color)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    xent_color_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    error_color_meter = utils.RunningAverageMeter(0.97)\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        xent_color_meter.set(checkpt['xent_train_color'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        error_color_meter.set(checkpt['error_train_color'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        \n",
      "        fixed_y_color = torch.from_numpy(np.arange(model.module.y_color)).repeat(model.module.y_color).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot_color = thops.onehot(fixed_y_color, num_classes=model.module.y_color)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            mean_color, logs_color = model.module._prior_color(fixed_y_onehot_color)\n",
      "            mean_sup = mean + mean_color\n",
      "            logs_sup = 0.5 * torch.log(torch.exp(2.*logs) + torch.exp(2.*logs_color))\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean_sup, logs_sup)\n",
      "            dim_unsup = np.prod(data_shape) - np.prod(fixed_z_sup.shape[1:])\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    best_error_score_color = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y_all) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            \n",
      "            y = y_all[0]\n",
      "            y_color = y_all[1]\n",
      "            \n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, loss_xent_color, y_predicted, y_color_predicted = compute_bits_per_dim_conditional(x, y, y_color, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * 0.5 * (loss_xent + loss_xent_color)\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  0.5 * (loss_xent + loss_xent_color)\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy()) \n",
      "                error_score_color = 1. - np.mean(y_color_predicted.astype(int) == y_color.numpy())\n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, loss_xent_color, error_score, error_score_color = loss, 0., 0., 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "                xent_color_meter.update(loss_xent_color.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "                xent_color_meter.update(loss_xent_color)\n",
      "            error_meter.update(error_score)\n",
      "            error_color_meter.update(error_score_color)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('xent_color', {'train_iter': xent_color_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('error_color', {'train_iter': error_color_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Xent Color {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) | Error Color {:.4f}({:.4f}) |\"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, xent_color_meter.val, xent_color_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, error_color_meter.val, error_color_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent_color', {'train_epoch': xent_color_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('error_color', {'train_epoch': error_color_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses_xent_color = []; losses = []\n",
      "                total_correct = 0\n",
      "                total_correct_color = 0\n",
      "                \n",
      "                for (x, y_all) in test_loader:\n",
      "                    y = y_all[0]\n",
      "                    y_color = y_all[1]\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, loss_xent_color, y_predicted, y_color_predicted = compute_bits_per_dim_conditional(x, y, y_color, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * 0.5 * (loss_xent + loss_xent_color)\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  0.5 * (loss_xent + loss_xent_color)\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                        total_correct_color += np.sum(y_color_predicted.astype(int) == y_color.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent, loss_xent_color = loss, 0., 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                        losses_xent_color.append(loss_xent_color.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                        losses_xent_color.append(loss_xent_color)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss_xent_color = np.mean(losses_xent_color); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                error_score_color =  1. - total_correct_color / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('xent_color', {'validation': loss_xent_color}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                writer.add_scalars('error_color', {'validation': error_score_color}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Xent Color {:.4f}. Loss {:.4f}, Error {:.4f}(best: {:.4f}), Error Color {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss_xent_color, loss, error_score, best_error_score, error_score_color, best_error_score_color)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"error_color\": error_score_color,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"xent_color\": loss_xent_color,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"best_error_score_color\": best_error_score_color,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"error_train_color\": error_color_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"xent_train_color\": xent_color_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"error_color\": error_score_color,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"xent_color\": loss_xent_color,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"best_error_score_color\": best_error_score_color,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"error_train_color\": error_color_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"xent_train_color\": xent_color_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"error_color\": error_score_color,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"xent_color\": loss_xent_color,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"best_error_score_color\": best_error_score_color,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"error_train_color\": error_color_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"xent_train_color\": xent_color_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"error_color\": error_score_color,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"xent_color\": loss_xent_color,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"best_error_score_color\": best_error_score_color,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"error_train_color\": error_color_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"xent_train_color\": xent_color_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "                    if error_score_color < best_error_score_color:\n",
      "                        best_error_score_color = error_score_color\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"error_color\": error_score_color,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"xent_color\": loss_xent_color,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"best_error_score_color\": best_error_score_color,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"error_train_color\": error_color_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"xent_train_color\": xent_color_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_color_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.33333, conditional=True, controlled_tol=False, conv=True, data='colormnist', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_colormnist_bs900_sratio_1_3th_drop_0_5_2cond_linear_nosep_run1/epoch_72_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_colormnist_bs900_sratio_1_3th_drop_0_5_2cond_linear_nosep_run1', seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n",
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=1566, bias=True)\n",
      "  (project_ycond_color): LinearZeros(in_features=10, out_features=1566, bias=True)\n",
      "  (project_class): LinearZeros(in_features=783, out_features=10, bias=True)\n",
      "  (project_color): LinearZeros(in_features=783, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (dropout_color): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 945374\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 4760 | Time 14.9176(14.8877) | Bit/dim 0.7578(0.7674) | Xent 0.1060(0.1306) | Xent Color 0.0069(0.0095) | Loss 0.7861(0.8024) | Error 0.0356(0.0408) | Error Color 0.0011(0.0013) |Steps 650(646.00) | Grad Norm 3.7559(8.5188) | Total Time 10.00(10.00)\n",
      "Iter 4770 | Time 15.1390(14.9097) | Bit/dim 0.7405(0.7623) | Xent 0.1125(0.1284) | Xent Color 0.0103(0.0095) | Loss 0.7712(0.7967) | Error 0.0344(0.0409) | Error Color 0.0022(0.0013) |Steps 656(647.67) | Grad Norm 2.4177(7.4988) | Total Time 10.00(10.00)\n",
      "Iter 4780 | Time 15.2191(14.9346) | Bit/dim 0.7481(0.7570) | Xent 0.1144(0.1253) | Xent Color 0.0103(0.0096) | Loss 0.7793(0.7907) | Error 0.0389(0.0396) | Error Color 0.0022(0.0014) |Steps 650(648.34) | Grad Norm 2.1900(6.3655) | Total Time 10.00(10.00)\n",
      "Iter 4790 | Time 14.6034(14.9463) | Bit/dim 0.7385(0.7521) | Xent 0.1183(0.1249) | Xent Color 0.0080(0.0093) | Loss 0.7700(0.7857) | Error 0.0367(0.0390) | Error Color 0.0000(0.0013) |Steps 656(649.77) | Grad Norm 1.1447(5.1881) | Total Time 10.00(10.00)\n",
      "Iter 4800 | Time 15.1522(14.9568) | Bit/dim 0.7439(0.7497) | Xent 0.1431(0.1238) | Xent Color 0.0058(0.0092) | Loss 0.7812(0.7829) | Error 0.0522(0.0390) | Error Color 0.0000(0.0013) |Steps 662(651.28) | Grad Norm 1.1905(4.1749) | Total Time 10.00(10.00)\n",
      "Iter 4810 | Time 14.7703(14.9773) | Bit/dim 0.7313(0.7473) | Xent 0.1135(0.1247) | Xent Color 0.0070(0.0090) | Loss 0.7615(0.7807) | Error 0.0389(0.0395) | Error Color 0.0011(0.0012) |Steps 662(652.57) | Grad Norm 0.8832(3.3578) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 92.3878, Epoch Time 1125.7382(950.2903), Bit/dim 0.7375(best: inf), Xent 0.0613, Xent Color 0.0009. Loss 0.7530, Error 0.0192(best: inf), Error Color 0.0000(best: inf)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4820 | Time 14.8266(15.0107) | Bit/dim 0.7375(0.7457) | Xent 0.1196(0.1256) | Xent Color 0.0104(0.0090) | Loss 0.7700(0.7794) | Error 0.0378(0.0395) | Error Color 0.0011(0.0011) |Steps 656(652.95) | Grad Norm 1.1995(2.7309) | Total Time 10.00(10.00)\n",
      "Iter 4830 | Time 15.0064(15.0059) | Bit/dim 0.7407(0.7434) | Xent 0.1215(0.1246) | Xent Color 0.0073(0.0089) | Loss 0.7730(0.7767) | Error 0.0444(0.0393) | Error Color 0.0011(0.0010) |Steps 656(653.95) | Grad Norm 0.7856(2.2340) | Total Time 10.00(10.00)\n",
      "Iter 4840 | Time 15.2219(15.0977) | Bit/dim 0.7389(0.7420) | Xent 0.0959(0.1240) | Xent Color 0.0116(0.0088) | Loss 0.7657(0.7752) | Error 0.0256(0.0387) | Error Color 0.0022(0.0009) |Steps 656(654.93) | Grad Norm 0.9537(1.8594) | Total Time 10.00(10.00)\n",
      "Iter 4850 | Time 15.5170(15.1274) | Bit/dim 0.7343(0.7414) | Xent 0.1261(0.1223) | Xent Color 0.0114(0.0086) | Loss 0.7687(0.7741) | Error 0.0444(0.0385) | Error Color 0.0033(0.0010) |Steps 674(656.13) | Grad Norm 0.7879(1.6166) | Total Time 10.00(10.00)\n",
      "Iter 4860 | Time 15.3007(15.1457) | Bit/dim 0.7343(0.7409) | Xent 0.0988(0.1247) | Xent Color 0.0099(0.0085) | Loss 0.7615(0.7742) | Error 0.0344(0.0389) | Error Color 0.0022(0.0011) |Steps 650(656.90) | Grad Norm 0.8461(1.4368) | Total Time 10.00(10.00)\n",
      "Iter 4870 | Time 15.1632(15.1605) | Bit/dim 0.7481(0.7401) | Xent 0.1308(0.1243) | Xent Color 0.0108(0.0090) | Loss 0.7835(0.7734) | Error 0.0411(0.0391) | Error Color 0.0011(0.0014) |Steps 668(658.05) | Grad Norm 1.2106(1.3031) | Total Time 10.00(10.00)\n",
      "Iter 4880 | Time 15.2601(15.1846) | Bit/dim 0.7433(0.7399) | Xent 0.1531(0.1220) | Xent Color 0.0093(0.0090) | Loss 0.7839(0.7726) | Error 0.0500(0.0381) | Error Color 0.0000(0.0015) |Steps 656(659.10) | Grad Norm 1.0907(1.2140) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 88.9837, Epoch Time 1115.5170(955.2471), Bit/dim 0.7360(best: 0.7375), Xent 0.0578, Xent Color 0.0008. Loss 0.7506, Error 0.0197(best: 0.0192), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4890 | Time 15.4942(15.1847) | Bit/dim 0.7398(0.7397) | Xent 0.1561(0.1223) | Xent Color 0.0137(0.0089) | Loss 0.7822(0.7725) | Error 0.0500(0.0380) | Error Color 0.0044(0.0015) |Steps 674(659.46) | Grad Norm 0.9951(1.1371) | Total Time 10.00(10.00)\n",
      "Iter 4900 | Time 15.0266(15.1574) | Bit/dim 0.7337(0.7381) | Xent 0.1077(0.1232) | Xent Color 0.0079(0.0092) | Loss 0.7626(0.7711) | Error 0.0322(0.0382) | Error Color 0.0011(0.0016) |Steps 656(660.50) | Grad Norm 1.0016(1.0965) | Total Time 10.00(10.00)\n",
      "Iter 4910 | Time 14.7288(15.1514) | Bit/dim 0.7251(0.7379) | Xent 0.1149(0.1214) | Xent Color 0.0102(0.0089) | Loss 0.7564(0.7704) | Error 0.0411(0.0380) | Error Color 0.0011(0.0014) |Steps 662(661.69) | Grad Norm 0.8070(1.0643) | Total Time 10.00(10.00)\n",
      "Iter 4920 | Time 15.1933(15.1745) | Bit/dim 0.7408(0.7374) | Xent 0.1152(0.1227) | Xent Color 0.0100(0.0089) | Loss 0.7721(0.7703) | Error 0.0400(0.0390) | Error Color 0.0022(0.0014) |Steps 674(663.09) | Grad Norm 0.8558(1.0293) | Total Time 10.00(10.00)\n",
      "Iter 4930 | Time 15.2621(15.1759) | Bit/dim 0.7420(0.7376) | Xent 0.1506(0.1275) | Xent Color 0.0099(0.0089) | Loss 0.7821(0.7716) | Error 0.0444(0.0399) | Error Color 0.0011(0.0014) |Steps 662(663.26) | Grad Norm 0.9298(0.9811) | Total Time 10.00(10.00)\n",
      "Iter 4940 | Time 14.9831(15.1846) | Bit/dim 0.7378(0.7372) | Xent 0.1052(0.1251) | Xent Color 0.0131(0.0089) | Loss 0.7673(0.7708) | Error 0.0311(0.0391) | Error Color 0.0011(0.0013) |Steps 656(662.02) | Grad Norm 0.7854(0.9354) | Total Time 10.00(10.00)\n",
      "Iter 4950 | Time 15.0982(15.2063) | Bit/dim 0.7395(0.7376) | Xent 0.1093(0.1238) | Xent Color 0.0084(0.0090) | Loss 0.7689(0.7708) | Error 0.0356(0.0388) | Error Color 0.0022(0.0014) |Steps 668(662.81) | Grad Norm 0.9702(0.9302) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 89.3102, Epoch Time 1115.3864(960.0513), Bit/dim 0.7340(best: 0.7360), Xent 0.0603, Xent Color 0.0009. Loss 0.7493, Error 0.0188(best: 0.0192), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4960 | Time 15.2244(15.2335) | Bit/dim 0.7395(0.7378) | Xent 0.1124(0.1224) | Xent Color 0.0104(0.0088) | Loss 0.7702(0.7706) | Error 0.0333(0.0383) | Error Color 0.0022(0.0012) |Steps 668(662.35) | Grad Norm 1.0766(0.9122) | Total Time 10.00(10.00)\n",
      "Iter 4970 | Time 15.2948(15.2651) | Bit/dim 0.7299(0.7369) | Xent 0.1239(0.1221) | Xent Color 0.0087(0.0088) | Loss 0.7630(0.7697) | Error 0.0444(0.0386) | Error Color 0.0011(0.0013) |Steps 656(662.83) | Grad Norm 0.7717(0.9401) | Total Time 10.00(10.00)\n",
      "Iter 4980 | Time 15.0208(15.2876) | Bit/dim 0.7391(0.7367) | Xent 0.1087(0.1207) | Xent Color 0.0074(0.0087) | Loss 0.7682(0.7691) | Error 0.0344(0.0384) | Error Color 0.0011(0.0012) |Steps 662(663.47) | Grad Norm 1.0195(0.9406) | Total Time 10.00(10.00)\n",
      "Iter 4990 | Time 15.3320(15.2821) | Bit/dim 0.7419(0.7366) | Xent 0.1366(0.1214) | Xent Color 0.0131(0.0088) | Loss 0.7793(0.7691) | Error 0.0522(0.0387) | Error Color 0.0033(0.0013) |Steps 662(663.54) | Grad Norm 1.2363(0.9706) | Total Time 10.00(10.00)\n",
      "Iter 5000 | Time 15.3955(15.2942) | Bit/dim 0.7278(0.7359) | Xent 0.1401(0.1239) | Xent Color 0.0088(0.0088) | Loss 0.7650(0.7691) | Error 0.0489(0.0396) | Error Color 0.0022(0.0014) |Steps 656(662.85) | Grad Norm 1.0832(0.9631) | Total Time 10.00(10.00)\n",
      "Iter 5010 | Time 15.3145(15.2482) | Bit/dim 0.7360(0.7357) | Xent 0.1118(0.1237) | Xent Color 0.0075(0.0086) | Loss 0.7658(0.7688) | Error 0.0389(0.0395) | Error Color 0.0011(0.0013) |Steps 668(662.32) | Grad Norm 0.7667(0.9502) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 88.5900, Epoch Time 1120.4265(964.8626), Bit/dim 0.7336(best: 0.7340), Xent 0.0620, Xent Color 0.0009. Loss 0.7493, Error 0.0193(best: 0.0188), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5020 | Time 14.8078(15.2081) | Bit/dim 0.7325(0.7352) | Xent 0.1626(0.1248) | Xent Color 0.0079(0.0088) | Loss 0.7751(0.7686) | Error 0.0589(0.0398) | Error Color 0.0011(0.0013) |Steps 674(662.62) | Grad Norm 1.2142(0.9324) | Total Time 10.00(10.00)\n",
      "Iter 5030 | Time 15.2532(15.2104) | Bit/dim 0.7437(0.7357) | Xent 0.1221(0.1222) | Xent Color 0.0055(0.0085) | Loss 0.7756(0.7684) | Error 0.0422(0.0392) | Error Color 0.0000(0.0013) |Steps 668(663.51) | Grad Norm 0.7586(0.9284) | Total Time 10.00(10.00)\n",
      "Iter 5040 | Time 15.4878(15.1983) | Bit/dim 0.7350(0.7359) | Xent 0.1557(0.1227) | Xent Color 0.0073(0.0086) | Loss 0.7758(0.7687) | Error 0.0544(0.0388) | Error Color 0.0022(0.0012) |Steps 662(664.02) | Grad Norm 1.5265(0.9630) | Total Time 10.00(10.00)\n",
      "Iter 5050 | Time 15.3911(15.2258) | Bit/dim 0.7438(0.7357) | Xent 0.1301(0.1224) | Xent Color 0.0083(0.0086) | Loss 0.7784(0.7684) | Error 0.0422(0.0387) | Error Color 0.0000(0.0012) |Steps 674(664.44) | Grad Norm 0.8838(0.9401) | Total Time 10.00(10.00)\n",
      "Iter 5060 | Time 15.5075(15.2263) | Bit/dim 0.7327(0.7352) | Xent 0.0941(0.1236) | Xent Color 0.0110(0.0085) | Loss 0.7589(0.7682) | Error 0.0256(0.0388) | Error Color 0.0022(0.0013) |Steps 668(664.62) | Grad Norm 0.8695(0.9400) | Total Time 10.00(10.00)\n",
      "Iter 5070 | Time 14.5345(15.1800) | Bit/dim 0.7397(0.7347) | Xent 0.1078(0.1224) | Xent Color 0.0080(0.0086) | Loss 0.7687(0.7674) | Error 0.0344(0.0389) | Error Color 0.0022(0.0015) |Steps 656(663.62) | Grad Norm 0.9125(0.9477) | Total Time 10.00(10.00)\n",
      "Iter 5080 | Time 14.9559(15.1590) | Bit/dim 0.7379(0.7347) | Xent 0.1137(0.1202) | Xent Color 0.0054(0.0086) | Loss 0.7677(0.7669) | Error 0.0333(0.0384) | Error Color 0.0000(0.0014) |Steps 656(663.34) | Grad Norm 0.8159(0.9326) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 89.1474, Epoch Time 1113.5311(969.3226), Bit/dim 0.7323(best: 0.7336), Xent 0.0646, Xent Color 0.0009. Loss 0.7486, Error 0.0224(best: 0.0188), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5090 | Time 14.8967(15.1598) | Bit/dim 0.7321(0.7337) | Xent 0.1254(0.1231) | Xent Color 0.0087(0.0085) | Loss 0.7656(0.7666) | Error 0.0422(0.0391) | Error Color 0.0011(0.0013) |Steps 674(663.39) | Grad Norm 0.7541(0.9308) | Total Time 10.00(10.00)\n",
      "Iter 5100 | Time 15.2996(15.1548) | Bit/dim 0.7289(0.7335) | Xent 0.0883(0.1213) | Xent Color 0.0084(0.0087) | Loss 0.7531(0.7660) | Error 0.0333(0.0386) | Error Color 0.0011(0.0014) |Steps 674(664.18) | Grad Norm 0.7441(0.9197) | Total Time 10.00(10.00)\n",
      "Iter 5110 | Time 15.1472(15.1628) | Bit/dim 0.7394(0.7345) | Xent 0.1434(0.1210) | Xent Color 0.0100(0.0087) | Loss 0.7777(0.7669) | Error 0.0456(0.0386) | Error Color 0.0033(0.0015) |Steps 662(663.91) | Grad Norm 0.9685(0.9322) | Total Time 10.00(10.00)\n",
      "Iter 5120 | Time 15.5388(15.1954) | Bit/dim 0.7322(0.7345) | Xent 0.1170(0.1214) | Xent Color 0.0066(0.0085) | Loss 0.7631(0.7670) | Error 0.0433(0.0390) | Error Color 0.0011(0.0014) |Steps 668(664.66) | Grad Norm 1.0144(0.9333) | Total Time 10.00(10.00)\n",
      "Iter 5130 | Time 15.2699(15.1959) | Bit/dim 0.7402(0.7342) | Xent 0.1466(0.1228) | Xent Color 0.0119(0.0086) | Loss 0.7798(0.7670) | Error 0.0467(0.0390) | Error Color 0.0044(0.0015) |Steps 656(665.22) | Grad Norm 1.4111(1.0082) | Total Time 10.00(10.00)\n",
      "Iter 5140 | Time 15.1338(15.2031) | Bit/dim 0.7270(0.7333) | Xent 0.1547(0.1242) | Xent Color 0.0069(0.0088) | Loss 0.7674(0.7665) | Error 0.0500(0.0396) | Error Color 0.0011(0.0015) |Steps 662(665.28) | Grad Norm 1.1117(1.0391) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 89.5880, Epoch Time 1115.9470(973.7214), Bit/dim 0.7319(best: 0.7323), Xent 0.0623, Xent Color 0.0009. Loss 0.7477, Error 0.0203(best: 0.0188), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5150 | Time 15.7761(15.2208) | Bit/dim 0.7419(0.7339) | Xent 0.1014(0.1224) | Xent Color 0.0079(0.0087) | Loss 0.7693(0.7667) | Error 0.0322(0.0387) | Error Color 0.0011(0.0014) |Steps 662(665.22) | Grad Norm 0.6567(1.0145) | Total Time 10.00(10.00)\n",
      "Iter 5160 | Time 15.5314(15.2227) | Bit/dim 0.7347(0.7337) | Xent 0.1290(0.1239) | Xent Color 0.0104(0.0086) | Loss 0.7696(0.7668) | Error 0.0389(0.0396) | Error Color 0.0033(0.0013) |Steps 668(666.10) | Grad Norm 0.7569(0.9964) | Total Time 10.00(10.00)\n",
      "Iter 5170 | Time 15.6556(15.2385) | Bit/dim 0.7239(0.7334) | Xent 0.1162(0.1226) | Xent Color 0.0073(0.0087) | Loss 0.7548(0.7662) | Error 0.0389(0.0392) | Error Color 0.0011(0.0014) |Steps 668(667.52) | Grad Norm 0.9751(0.9759) | Total Time 10.00(10.00)\n",
      "Iter 5180 | Time 15.5249(15.2476) | Bit/dim 0.7318(0.7332) | Xent 0.1318(0.1223) | Xent Color 0.0074(0.0086) | Loss 0.7666(0.7659) | Error 0.0411(0.0389) | Error Color 0.0000(0.0013) |Steps 674(665.97) | Grad Norm 1.0032(0.9866) | Total Time 10.00(10.00)\n",
      "Iter 5190 | Time 15.3480(15.2292) | Bit/dim 0.7320(0.7323) | Xent 0.1325(0.1230) | Xent Color 0.0113(0.0085) | Loss 0.7679(0.7652) | Error 0.0444(0.0395) | Error Color 0.0022(0.0013) |Steps 662(667.00) | Grad Norm 1.1421(0.9852) | Total Time 10.00(10.00)\n",
      "Iter 5200 | Time 15.3821(15.2472) | Bit/dim 0.7344(0.7326) | Xent 0.1189(0.1238) | Xent Color 0.0079(0.0084) | Loss 0.7661(0.7657) | Error 0.0433(0.0392) | Error Color 0.0000(0.0012) |Steps 668(667.43) | Grad Norm 1.2047(0.9936) | Total Time 10.00(10.00)\n",
      "Iter 5210 | Time 15.4462(15.2862) | Bit/dim 0.7342(0.7324) | Xent 0.1002(0.1225) | Xent Color 0.0079(0.0083) | Loss 0.7612(0.7651) | Error 0.0333(0.0388) | Error Color 0.0022(0.0013) |Steps 668(667.62) | Grad Norm 0.7234(0.9995) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 90.9035, Epoch Time 1122.7294(978.1916), Bit/dim 0.7296(best: 0.7319), Xent 0.0599, Xent Color 0.0008. Loss 0.7448, Error 0.0196(best: 0.0188), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5220 | Time 15.4930(15.2899) | Bit/dim 0.7283(0.7316) | Xent 0.1078(0.1218) | Xent Color 0.0090(0.0082) | Loss 0.7575(0.7641) | Error 0.0267(0.0374) | Error Color 0.0022(0.0013) |Steps 656(667.36) | Grad Norm 1.5591(1.0052) | Total Time 10.00(10.00)\n",
      "Iter 5230 | Time 15.1144(15.3149) | Bit/dim 0.7355(0.7317) | Xent 0.1291(0.1211) | Xent Color 0.0075(0.0081) | Loss 0.7696(0.7640) | Error 0.0389(0.0378) | Error Color 0.0011(0.0012) |Steps 674(667.83) | Grad Norm 0.9836(1.0100) | Total Time 10.00(10.00)\n",
      "Iter 5240 | Time 14.9705(15.3288) | Bit/dim 0.7315(0.7315) | Xent 0.1023(0.1186) | Xent Color 0.0130(0.0083) | Loss 0.7604(0.7632) | Error 0.0333(0.0373) | Error Color 0.0022(0.0012) |Steps 662(667.78) | Grad Norm 1.3083(1.0537) | Total Time 10.00(10.00)\n",
      "Iter 5250 | Time 15.7607(15.3441) | Bit/dim 0.7322(0.7308) | Xent 0.1092(0.1196) | Xent Color 0.0086(0.0082) | Loss 0.7616(0.7627) | Error 0.0378(0.0380) | Error Color 0.0011(0.0013) |Steps 686(669.60) | Grad Norm 1.1698(1.0701) | Total Time 10.00(10.00)\n",
      "Iter 5260 | Time 15.5307(15.3567) | Bit/dim 0.7315(0.7313) | Xent 0.0899(0.1226) | Xent Color 0.0070(0.0080) | Loss 0.7557(0.7639) | Error 0.0267(0.0381) | Error Color 0.0000(0.0010) |Steps 668(670.39) | Grad Norm 0.9038(1.0288) | Total Time 10.00(10.00)\n",
      "Iter 5270 | Time 15.3577(15.3510) | Bit/dim 0.7268(0.7312) | Xent 0.1019(0.1219) | Xent Color 0.0079(0.0079) | Loss 0.7542(0.7636) | Error 0.0289(0.0380) | Error Color 0.0011(0.0010) |Steps 680(671.10) | Grad Norm 0.6923(0.9847) | Total Time 10.00(10.00)\n",
      "Iter 5280 | Time 14.8205(15.1825) | Bit/dim 0.7329(0.7312) | Xent 0.1205(0.1216) | Xent Color 0.0081(0.0080) | Loss 0.7650(0.7636) | Error 0.0444(0.0383) | Error Color 0.0022(0.0010) |Steps 668(671.99) | Grad Norm 1.1563(0.9641) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 87.0466, Epoch Time 1117.8115(982.3802), Bit/dim 0.7295(best: 0.7296), Xent 0.0622, Xent Color 0.0008. Loss 0.7453, Error 0.0194(best: 0.0188), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5290 | Time 14.9448(15.0775) | Bit/dim 0.7340(0.7314) | Xent 0.1372(0.1224) | Xent Color 0.0082(0.0078) | Loss 0.7703(0.7640) | Error 0.0444(0.0383) | Error Color 0.0011(0.0009) |Steps 674(671.59) | Grad Norm 1.2349(1.0103) | Total Time 10.00(10.00)\n",
      "Iter 5300 | Time 14.6563(14.9977) | Bit/dim 0.7363(0.7313) | Xent 0.1140(0.1225) | Xent Color 0.0076(0.0076) | Loss 0.7667(0.7639) | Error 0.0289(0.0378) | Error Color 0.0000(0.0008) |Steps 680(673.83) | Grad Norm 0.8995(1.0211) | Total Time 10.00(10.00)\n",
      "Iter 5310 | Time 14.7112(14.9314) | Bit/dim 0.7245(0.7310) | Xent 0.1168(0.1211) | Xent Color 0.0089(0.0079) | Loss 0.7559(0.7632) | Error 0.0389(0.0377) | Error Color 0.0000(0.0010) |Steps 662(672.89) | Grad Norm 1.1264(1.0268) | Total Time 10.00(10.00)\n",
      "Iter 5320 | Time 15.2611(14.9225) | Bit/dim 0.7256(0.7309) | Xent 0.0875(0.1187) | Xent Color 0.0087(0.0083) | Loss 0.7496(0.7626) | Error 0.0233(0.0369) | Error Color 0.0022(0.0012) |Steps 680(673.54) | Grad Norm 1.0015(1.0196) | Total Time 10.00(10.00)\n",
      "Iter 5330 | Time 14.5242(14.8975) | Bit/dim 0.7371(0.7309) | Xent 0.1234(0.1201) | Xent Color 0.0082(0.0085) | Loss 0.7700(0.7630) | Error 0.0467(0.0382) | Error Color 0.0011(0.0013) |Steps 668(674.09) | Grad Norm 0.9091(1.0160) | Total Time 10.00(10.00)\n",
      "Iter 5340 | Time 14.9060(14.9150) | Bit/dim 0.7259(0.7302) | Xent 0.1345(0.1202) | Xent Color 0.0107(0.0083) | Loss 0.7622(0.7623) | Error 0.0400(0.0382) | Error Color 0.0022(0.0011) |Steps 674(674.50) | Grad Norm 1.2003(1.0055) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 87.2905, Epoch Time 1087.6295(985.5377), Bit/dim 0.7273(best: 0.7295), Xent 0.0604, Xent Color 0.0008. Loss 0.7426, Error 0.0185(best: 0.0188), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5350 | Time 15.1276(14.8907) | Bit/dim 0.7193(0.7304) | Xent 0.1220(0.1200) | Xent Color 0.0094(0.0080) | Loss 0.7521(0.7624) | Error 0.0367(0.0384) | Error Color 0.0011(0.0009) |Steps 686(675.36) | Grad Norm 1.2215(1.0097) | Total Time 10.00(10.00)\n",
      "Iter 5360 | Time 14.7639(14.8894) | Bit/dim 0.7265(0.7299) | Xent 0.1148(0.1205) | Xent Color 0.0145(0.0083) | Loss 0.7589(0.7621) | Error 0.0400(0.0389) | Error Color 0.0056(0.0012) |Steps 674(676.21) | Grad Norm 1.4383(1.0595) | Total Time 10.00(10.00)\n",
      "Iter 5370 | Time 14.9512(14.9265) | Bit/dim 0.7319(0.7292) | Xent 0.1354(0.1195) | Xent Color 0.0101(0.0085) | Loss 0.7683(0.7612) | Error 0.0478(0.0386) | Error Color 0.0033(0.0014) |Steps 680(676.75) | Grad Norm 1.4092(1.0711) | Total Time 10.00(10.00)\n",
      "Iter 5380 | Time 15.3901(14.9660) | Bit/dim 0.7230(0.7287) | Xent 0.0887(0.1212) | Xent Color 0.0043(0.0082) | Loss 0.7462(0.7611) | Error 0.0322(0.0386) | Error Color 0.0000(0.0013) |Steps 686(677.99) | Grad Norm 0.9883(1.0827) | Total Time 10.00(10.00)\n",
      "Iter 5390 | Time 14.9969(14.9659) | Bit/dim 0.7346(0.7296) | Xent 0.1209(0.1205) | Xent Color 0.0058(0.0081) | Loss 0.7663(0.7617) | Error 0.0378(0.0385) | Error Color 0.0000(0.0011) |Steps 680(679.28) | Grad Norm 1.0113(1.0756) | Total Time 10.00(10.00)\n",
      "Iter 5400 | Time 14.6446(14.9352) | Bit/dim 0.7263(0.7295) | Xent 0.1317(0.1203) | Xent Color 0.0071(0.0079) | Loss 0.7610(0.7615) | Error 0.0433(0.0384) | Error Color 0.0022(0.0011) |Steps 674(679.64) | Grad Norm 0.8493(1.0673) | Total Time 10.00(10.00)\n",
      "Iter 5410 | Time 14.8334(14.8902) | Bit/dim 0.7249(0.7294) | Xent 0.1098(0.1183) | Xent Color 0.0093(0.0079) | Loss 0.7547(0.7610) | Error 0.0389(0.0378) | Error Color 0.0011(0.0011) |Steps 692(680.56) | Grad Norm 0.9910(1.0768) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 87.6632, Epoch Time 1093.2794(988.7699), Bit/dim 0.7272(best: 0.7273), Xent 0.0607, Xent Color 0.0008. Loss 0.7425, Error 0.0198(best: 0.0185), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5420 | Time 15.2236(14.8953) | Bit/dim 0.7297(0.7298) | Xent 0.1291(0.1181) | Xent Color 0.0085(0.0080) | Loss 0.7641(0.7614) | Error 0.0389(0.0371) | Error Color 0.0000(0.0011) |Steps 686(681.02) | Grad Norm 0.8216(1.0738) | Total Time 10.00(10.00)\n",
      "Iter 5430 | Time 14.5373(14.8832) | Bit/dim 0.7268(0.7291) | Xent 0.1141(0.1192) | Xent Color 0.0087(0.0081) | Loss 0.7575(0.7609) | Error 0.0378(0.0372) | Error Color 0.0011(0.0011) |Steps 692(681.48) | Grad Norm 1.0731(1.0851) | Total Time 10.00(10.00)\n",
      "Iter 5440 | Time 14.4535(14.8816) | Bit/dim 0.7262(0.7296) | Xent 0.1459(0.1216) | Xent Color 0.0066(0.0081) | Loss 0.7643(0.7620) | Error 0.0378(0.0383) | Error Color 0.0000(0.0012) |Steps 686(682.38) | Grad Norm 1.0385(1.0672) | Total Time 10.00(10.00)\n",
      "Iter 5450 | Time 14.5162(14.8700) | Bit/dim 0.7273(0.7288) | Xent 0.1225(0.1190) | Xent Color 0.0069(0.0082) | Loss 0.7596(0.7605) | Error 0.0389(0.0375) | Error Color 0.0000(0.0011) |Steps 692(682.20) | Grad Norm 1.0933(1.0942) | Total Time 10.00(10.00)\n",
      "Iter 5460 | Time 14.9435(14.9056) | Bit/dim 0.7248(0.7286) | Xent 0.1119(0.1187) | Xent Color 0.0073(0.0083) | Loss 0.7547(0.7604) | Error 0.0322(0.0377) | Error Color 0.0000(0.0012) |Steps 674(681.79) | Grad Norm 0.9582(1.1251) | Total Time 10.00(10.00)\n",
      "Iter 5470 | Time 15.2723(14.9384) | Bit/dim 0.7273(0.7282) | Xent 0.0841(0.1159) | Xent Color 0.0070(0.0082) | Loss 0.7501(0.7592) | Error 0.0256(0.0368) | Error Color 0.0011(0.0011) |Steps 674(682.41) | Grad Norm 1.0913(1.1065) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 87.9335, Epoch Time 1095.8198(991.9814), Bit/dim 0.7264(best: 0.7272), Xent 0.0605, Xent Color 0.0008. Loss 0.7417, Error 0.0201(best: 0.0185), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5480 | Time 15.3165(15.0040) | Bit/dim 0.7295(0.7282) | Xent 0.1038(0.1172) | Xent Color 0.0068(0.0082) | Loss 0.7572(0.7595) | Error 0.0300(0.0370) | Error Color 0.0011(0.0011) |Steps 680(681.99) | Grad Norm 1.5290(1.1109) | Total Time 10.00(10.00)\n",
      "Iter 5490 | Time 14.9770(15.0575) | Bit/dim 0.7334(0.7282) | Xent 0.1162(0.1166) | Xent Color 0.0080(0.0080) | Loss 0.7645(0.7594) | Error 0.0311(0.0371) | Error Color 0.0011(0.0010) |Steps 686(683.15) | Grad Norm 1.1754(1.1179) | Total Time 10.00(10.00)\n",
      "Iter 5500 | Time 15.5194(15.0488) | Bit/dim 0.7132(0.7282) | Xent 0.1155(0.1157) | Xent Color 0.0059(0.0080) | Loss 0.7435(0.7591) | Error 0.0378(0.0367) | Error Color 0.0000(0.0010) |Steps 686(683.13) | Grad Norm 1.3658(1.1587) | Total Time 10.00(10.00)\n",
      "Iter 5510 | Time 15.2028(15.0151) | Bit/dim 0.7244(0.7284) | Xent 0.1087(0.1152) | Xent Color 0.0077(0.0081) | Loss 0.7536(0.7592) | Error 0.0322(0.0370) | Error Color 0.0011(0.0011) |Steps 686(683.33) | Grad Norm 1.1516(1.2103) | Total Time 10.00(10.00)\n",
      "Iter 5520 | Time 14.9566(15.0002) | Bit/dim 0.7242(0.7276) | Xent 0.1032(0.1182) | Xent Color 0.0108(0.0081) | Loss 0.7527(0.7592) | Error 0.0367(0.0380) | Error Color 0.0022(0.0011) |Steps 686(683.13) | Grad Norm 1.0395(1.2174) | Total Time 10.00(10.00)\n",
      "Iter 5530 | Time 15.1623(15.0316) | Bit/dim 0.7367(0.7276) | Xent 0.1111(0.1182) | Xent Color 0.0080(0.0082) | Loss 0.7664(0.7592) | Error 0.0333(0.0376) | Error Color 0.0022(0.0012) |Steps 698(684.11) | Grad Norm 1.2619(1.2459) | Total Time 10.00(10.00)\n",
      "Iter 5540 | Time 15.1376(15.0359) | Bit/dim 0.7364(0.7269) | Xent 0.1146(0.1164) | Xent Color 0.0085(0.0084) | Loss 0.7672(0.7581) | Error 0.0322(0.0370) | Error Color 0.0011(0.0013) |Steps 692(683.74) | Grad Norm 1.2158(1.2401) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 88.0546, Epoch Time 1102.9909(995.3117), Bit/dim 0.7247(best: 0.7264), Xent 0.0611, Xent Color 0.0008. Loss 0.7401, Error 0.0197(best: 0.0185), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5550 | Time 14.9364(15.0364) | Bit/dim 0.7270(0.7268) | Xent 0.1436(0.1204) | Xent Color 0.0087(0.0083) | Loss 0.7651(0.7590) | Error 0.0444(0.0380) | Error Color 0.0011(0.0012) |Steps 680(683.28) | Grad Norm 1.3238(1.2729) | Total Time 10.00(10.00)\n",
      "Iter 5560 | Time 14.8237(15.0321) | Bit/dim 0.7224(0.7264) | Xent 0.1051(0.1184) | Xent Color 0.0078(0.0081) | Loss 0.7506(0.7581) | Error 0.0333(0.0375) | Error Color 0.0000(0.0013) |Steps 686(683.08) | Grad Norm 1.0770(1.2891) | Total Time 10.00(10.00)\n",
      "Iter 5570 | Time 15.2424(15.0380) | Bit/dim 0.7281(0.7264) | Xent 0.1281(0.1188) | Xent Color 0.0052(0.0078) | Loss 0.7614(0.7581) | Error 0.0367(0.0375) | Error Color 0.0000(0.0012) |Steps 680(683.43) | Grad Norm 1.4248(1.2851) | Total Time 10.00(10.00)\n",
      "Iter 5580 | Time 15.2056(15.0687) | Bit/dim 0.7295(0.7264) | Xent 0.1243(0.1179) | Xent Color 0.0056(0.0077) | Loss 0.7620(0.7578) | Error 0.0356(0.0372) | Error Color 0.0000(0.0012) |Steps 686(684.38) | Grad Norm 1.1664(1.2420) | Total Time 10.00(10.00)\n",
      "Iter 5590 | Time 14.7936(15.1095) | Bit/dim 0.7265(0.7265) | Xent 0.1267(0.1186) | Xent Color 0.0057(0.0077) | Loss 0.7596(0.7581) | Error 0.0433(0.0374) | Error Color 0.0000(0.0011) |Steps 686(684.96) | Grad Norm 1.5397(1.2678) | Total Time 10.00(10.00)\n",
      "Iter 5600 | Time 15.1384(15.1182) | Bit/dim 0.7244(0.7263) | Xent 0.1188(0.1177) | Xent Color 0.0097(0.0078) | Loss 0.7565(0.7577) | Error 0.0356(0.0373) | Error Color 0.0022(0.0012) |Steps 686(684.61) | Grad Norm 1.2069(1.2644) | Total Time 10.00(10.00)\n",
      "Iter 5610 | Time 15.2525(15.1246) | Bit/dim 0.7235(0.7266) | Xent 0.1340(0.1206) | Xent Color 0.0067(0.0079) | Loss 0.7587(0.7587) | Error 0.0356(0.0378) | Error Color 0.0000(0.0012) |Steps 680(684.60) | Grad Norm 1.2521(1.2310) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 88.9588, Epoch Time 1107.0938(998.6652), Bit/dim 0.7243(best: 0.7247), Xent 0.0616, Xent Color 0.0008. Loss 0.7399, Error 0.0199(best: 0.0185), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5620 | Time 15.0868(15.1299) | Bit/dim 0.7344(0.7266) | Xent 0.0980(0.1216) | Xent Color 0.0054(0.0080) | Loss 0.7602(0.7590) | Error 0.0344(0.0377) | Error Color 0.0000(0.0012) |Steps 692(686.49) | Grad Norm 0.9781(1.2256) | Total Time 10.00(10.00)\n",
      "Iter 5630 | Time 15.1265(15.1084) | Bit/dim 0.7266(0.7258) | Xent 0.1379(0.1214) | Xent Color 0.0082(0.0082) | Loss 0.7631(0.7582) | Error 0.0400(0.0375) | Error Color 0.0022(0.0013) |Steps 680(686.46) | Grad Norm 1.2580(1.2674) | Total Time 10.00(10.00)\n",
      "Iter 5640 | Time 15.2835(15.1002) | Bit/dim 0.7211(0.7253) | Xent 0.1387(0.1212) | Xent Color 0.0054(0.0080) | Loss 0.7571(0.7576) | Error 0.0456(0.0381) | Error Color 0.0000(0.0011) |Steps 704(687.66) | Grad Norm 1.3020(1.2640) | Total Time 10.00(10.00)\n",
      "Iter 5650 | Time 15.4039(15.1589) | Bit/dim 0.7187(0.7252) | Xent 0.1245(0.1197) | Xent Color 0.0062(0.0080) | Loss 0.7514(0.7571) | Error 0.0367(0.0382) | Error Color 0.0000(0.0010) |Steps 674(687.82) | Grad Norm 1.1094(1.2014) | Total Time 10.00(10.00)\n",
      "Iter 5660 | Time 15.0817(15.1440) | Bit/dim 0.7256(0.7250) | Xent 0.1109(0.1202) | Xent Color 0.0055(0.0078) | Loss 0.7547(0.7570) | Error 0.0411(0.0383) | Error Color 0.0000(0.0010) |Steps 692(688.59) | Grad Norm 1.4030(1.2047) | Total Time 10.00(10.00)\n",
      "Iter 5670 | Time 15.4177(15.2182) | Bit/dim 0.7240(0.7244) | Xent 0.1050(0.1192) | Xent Color 0.0075(0.0078) | Loss 0.7521(0.7562) | Error 0.0289(0.0377) | Error Color 0.0000(0.0010) |Steps 686(689.01) | Grad Norm 1.2470(1.2488) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 87.4206, Epoch Time 1111.3923(1002.0470), Bit/dim 0.7232(best: 0.7243), Xent 0.0577, Xent Color 0.0008. Loss 0.7378, Error 0.0183(best: 0.0185), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5680 | Time 14.9223(15.2057) | Bit/dim 0.7238(0.7248) | Xent 0.1407(0.1211) | Xent Color 0.0077(0.0079) | Loss 0.7608(0.7571) | Error 0.0433(0.0377) | Error Color 0.0011(0.0011) |Steps 686(688.90) | Grad Norm 1.6123(1.2814) | Total Time 10.00(10.00)\n",
      "Iter 5690 | Time 15.4545(15.2218) | Bit/dim 0.7219(0.7246) | Xent 0.1050(0.1190) | Xent Color 0.0070(0.0079) | Loss 0.7499(0.7564) | Error 0.0322(0.0378) | Error Color 0.0011(0.0011) |Steps 686(688.53) | Grad Norm 1.3325(1.3444) | Total Time 10.00(10.00)\n",
      "Iter 5700 | Time 15.5474(15.2140) | Bit/dim 0.7331(0.7250) | Xent 0.1169(0.1197) | Xent Color 0.0073(0.0080) | Loss 0.7642(0.7569) | Error 0.0289(0.0380) | Error Color 0.0000(0.0011) |Steps 704(689.12) | Grad Norm 1.0806(1.3669) | Total Time 10.00(10.00)\n",
      "Iter 5710 | Time 14.9210(15.1639) | Bit/dim 0.7168(0.7245) | Xent 0.1064(0.1186) | Xent Color 0.0090(0.0079) | Loss 0.7456(0.7561) | Error 0.0411(0.0377) | Error Color 0.0022(0.0012) |Steps 680(687.91) | Grad Norm 1.1504(1.3601) | Total Time 10.00(10.00)\n",
      "Iter 5720 | Time 15.4064(15.2067) | Bit/dim 0.7222(0.7244) | Xent 0.1094(0.1198) | Xent Color 0.0067(0.0080) | Loss 0.7513(0.7564) | Error 0.0367(0.0382) | Error Color 0.0000(0.0011) |Steps 698(689.32) | Grad Norm 1.4879(1.4207) | Total Time 10.00(10.00)\n",
      "Iter 5730 | Time 15.4656(15.2132) | Bit/dim 0.7221(0.7242) | Xent 0.1117(0.1176) | Xent Color 0.0076(0.0080) | Loss 0.7519(0.7556) | Error 0.0356(0.0377) | Error Color 0.0011(0.0011) |Steps 698(689.92) | Grad Norm 1.2559(1.4162) | Total Time 10.00(10.00)\n",
      "Iter 5740 | Time 15.2029(15.2481) | Bit/dim 0.7250(0.7243) | Xent 0.1074(0.1178) | Xent Color 0.0060(0.0076) | Loss 0.7533(0.7557) | Error 0.0311(0.0377) | Error Color 0.0000(0.0010) |Steps 680(689.92) | Grad Norm 1.2137(1.3965) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 87.2392, Epoch Time 1112.3806(1005.3570), Bit/dim 0.7215(best: 0.7232), Xent 0.0580, Xent Color 0.0008. Loss 0.7362, Error 0.0183(best: 0.0183), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5750 | Time 15.8215(15.2756) | Bit/dim 0.7197(0.7237) | Xent 0.0941(0.1174) | Xent Color 0.0086(0.0078) | Loss 0.7453(0.7550) | Error 0.0267(0.0382) | Error Color 0.0022(0.0012) |Steps 686(689.38) | Grad Norm 1.0902(1.3711) | Total Time 10.00(10.00)\n",
      "Iter 5760 | Time 15.1467(15.2748) | Bit/dim 0.7162(0.7233) | Xent 0.0823(0.1162) | Xent Color 0.0072(0.0077) | Loss 0.7385(0.7542) | Error 0.0267(0.0378) | Error Color 0.0011(0.0010) |Steps 680(689.27) | Grad Norm 1.2056(1.3146) | Total Time 10.00(10.00)\n",
      "Iter 5770 | Time 15.2555(15.2703) | Bit/dim 0.7277(0.7226) | Xent 0.1836(0.1176) | Xent Color 0.0089(0.0078) | Loss 0.7759(0.7540) | Error 0.0556(0.0375) | Error Color 0.0011(0.0010) |Steps 686(688.21) | Grad Norm 1.0168(1.2736) | Total Time 10.00(10.00)\n",
      "Iter 5780 | Time 15.4311(15.2732) | Bit/dim 0.7209(0.7221) | Xent 0.1055(0.1164) | Xent Color 0.0087(0.0077) | Loss 0.7495(0.7531) | Error 0.0333(0.0372) | Error Color 0.0011(0.0009) |Steps 692(688.38) | Grad Norm 1.0002(1.2686) | Total Time 10.00(10.00)\n",
      "Iter 5790 | Time 15.1892(15.2584) | Bit/dim 0.7224(0.7227) | Xent 0.1366(0.1161) | Xent Color 0.0086(0.0081) | Loss 0.7588(0.7537) | Error 0.0422(0.0365) | Error Color 0.0011(0.0011) |Steps 698(690.01) | Grad Norm 2.1882(1.3349) | Total Time 10.00(10.00)\n",
      "Iter 5800 | Time 14.9287(15.2296) | Bit/dim 0.7297(0.7237) | Xent 0.1257(0.1170) | Xent Color 0.0091(0.0081) | Loss 0.7634(0.7550) | Error 0.0389(0.0368) | Error Color 0.0022(0.0012) |Steps 692(691.12) | Grad Norm 1.0893(1.3776) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 90.8176, Epoch Time 1118.5965(1008.7542), Bit/dim 0.7211(best: 0.7215), Xent 0.0597, Xent Color 0.0007. Loss 0.7362, Error 0.0199(best: 0.0183), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5810 | Time 14.7210(15.2114) | Bit/dim 0.7156(0.7232) | Xent 0.1242(0.1184) | Xent Color 0.0088(0.0078) | Loss 0.7489(0.7547) | Error 0.0389(0.0373) | Error Color 0.0011(0.0011) |Steps 680(690.54) | Grad Norm 1.1788(1.3702) | Total Time 10.00(10.00)\n",
      "Iter 5820 | Time 14.9773(15.2117) | Bit/dim 0.7243(0.7225) | Xent 0.1188(0.1174) | Xent Color 0.0072(0.0079) | Loss 0.7558(0.7538) | Error 0.0344(0.0369) | Error Color 0.0000(0.0011) |Steps 686(690.83) | Grad Norm 1.3542(1.3924) | Total Time 10.00(10.00)\n",
      "Iter 5830 | Time 15.3865(15.2178) | Bit/dim 0.7279(0.7227) | Xent 0.1319(0.1180) | Xent Color 0.0084(0.0078) | Loss 0.7629(0.7542) | Error 0.0422(0.0373) | Error Color 0.0022(0.0010) |Steps 698(691.04) | Grad Norm 1.0788(1.3647) | Total Time 10.00(10.00)\n",
      "Iter 5840 | Time 15.1462(15.1983) | Bit/dim 0.7221(0.7219) | Xent 0.1118(0.1171) | Xent Color 0.0078(0.0079) | Loss 0.7520(0.7531) | Error 0.0389(0.0374) | Error Color 0.0000(0.0009) |Steps 692(689.37) | Grad Norm 1.0436(1.3910) | Total Time 10.00(10.00)\n",
      "Iter 5850 | Time 14.8369(15.2110) | Bit/dim 0.7260(0.7223) | Xent 0.1121(0.1159) | Xent Color 0.0104(0.0079) | Loss 0.7567(0.7532) | Error 0.0400(0.0376) | Error Color 0.0033(0.0010) |Steps 692(689.83) | Grad Norm 1.0674(1.4202) | Total Time 10.00(10.00)\n",
      "Iter 5860 | Time 15.1678(15.1962) | Bit/dim 0.7285(0.7226) | Xent 0.1276(0.1168) | Xent Color 0.0078(0.0079) | Loss 0.7624(0.7538) | Error 0.0400(0.0376) | Error Color 0.0000(0.0010) |Steps 692(691.49) | Grad Norm 1.1635(1.3562) | Total Time 10.00(10.00)\n",
      "Iter 5870 | Time 15.3539(15.2061) | Bit/dim 0.7126(0.7225) | Xent 0.1281(0.1199) | Xent Color 0.0085(0.0080) | Loss 0.7468(0.7545) | Error 0.0344(0.0379) | Error Color 0.0022(0.0010) |Steps 704(692.02) | Grad Norm 1.1560(1.3549) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 89.2953, Epoch Time 1113.5789(1011.8989), Bit/dim 0.7186(best: 0.7211), Xent 0.0566, Xent Color 0.0007. Loss 0.7330, Error 0.0180(best: 0.0183), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5880 | Time 14.7107(15.2049) | Bit/dim 0.7199(0.7218) | Xent 0.1010(0.1199) | Xent Color 0.0061(0.0080) | Loss 0.7466(0.7538) | Error 0.0311(0.0374) | Error Color 0.0000(0.0010) |Steps 698(692.28) | Grad Norm 1.9969(1.3780) | Total Time 10.00(10.00)\n",
      "Iter 5890 | Time 15.2091(15.2017) | Bit/dim 0.7188(0.7216) | Xent 0.1201(0.1186) | Xent Color 0.0073(0.0080) | Loss 0.7506(0.7532) | Error 0.0333(0.0371) | Error Color 0.0000(0.0010) |Steps 704(692.45) | Grad Norm 1.3852(1.3812) | Total Time 10.00(10.00)\n",
      "Iter 5900 | Time 14.6899(15.1960) | Bit/dim 0.7214(0.7212) | Xent 0.1376(0.1178) | Xent Color 0.0065(0.0077) | Loss 0.7574(0.7526) | Error 0.0322(0.0370) | Error Color 0.0011(0.0009) |Steps 692(692.86) | Grad Norm 1.4276(1.3869) | Total Time 10.00(10.00)\n",
      "Iter 5910 | Time 14.9960(15.2142) | Bit/dim 0.7107(0.7209) | Xent 0.1183(0.1193) | Xent Color 0.0068(0.0078) | Loss 0.7420(0.7526) | Error 0.0311(0.0371) | Error Color 0.0011(0.0010) |Steps 692(692.11) | Grad Norm 1.2449(1.3361) | Total Time 10.00(10.00)\n",
      "Iter 5920 | Time 14.5058(15.1611) | Bit/dim 0.7277(0.7213) | Xent 0.1122(0.1208) | Xent Color 0.0061(0.0075) | Loss 0.7572(0.7534) | Error 0.0378(0.0382) | Error Color 0.0000(0.0009) |Steps 686(690.86) | Grad Norm 1.7639(1.3842) | Total Time 10.00(10.00)\n",
      "Iter 5930 | Time 15.2167(15.1658) | Bit/dim 0.7200(0.7210) | Xent 0.1157(0.1191) | Xent Color 0.0082(0.0075) | Loss 0.7509(0.7526) | Error 0.0389(0.0376) | Error Color 0.0022(0.0010) |Steps 692(692.28) | Grad Norm 1.8359(1.4605) | Total Time 10.00(10.00)\n",
      "Iter 5940 | Time 15.1992(15.1589) | Bit/dim 0.7213(0.7208) | Xent 0.1373(0.1201) | Xent Color 0.0059(0.0074) | Loss 0.7571(0.7526) | Error 0.0456(0.0378) | Error Color 0.0000(0.0009) |Steps 704(691.59) | Grad Norm 2.0514(1.5424) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 88.4732, Epoch Time 1110.0679(1014.8440), Bit/dim 0.7179(best: 0.7186), Xent 0.0562, Xent Color 0.0008. Loss 0.7321, Error 0.0171(best: 0.0180), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5950 | Time 15.3615(15.1926) | Bit/dim 0.7204(0.7215) | Xent 0.1193(0.1183) | Xent Color 0.0053(0.0073) | Loss 0.7515(0.7529) | Error 0.0422(0.0370) | Error Color 0.0000(0.0009) |Steps 680(691.10) | Grad Norm 1.5009(1.5712) | Total Time 10.00(10.00)\n",
      "Iter 5960 | Time 14.9783(15.2125) | Bit/dim 0.7151(0.7208) | Xent 0.1142(0.1175) | Xent Color 0.0057(0.0075) | Loss 0.7451(0.7520) | Error 0.0378(0.0364) | Error Color 0.0000(0.0009) |Steps 692(691.62) | Grad Norm 1.8054(1.6648) | Total Time 10.00(10.00)\n",
      "Iter 5970 | Time 15.0846(15.1912) | Bit/dim 0.7253(0.7207) | Xent 0.1018(0.1180) | Xent Color 0.0084(0.0075) | Loss 0.7528(0.7521) | Error 0.0322(0.0363) | Error Color 0.0011(0.0010) |Steps 692(692.17) | Grad Norm 1.3521(1.6575) | Total Time 10.00(10.00)\n",
      "Iter 5980 | Time 15.5461(15.1766) | Bit/dim 0.7220(0.7206) | Xent 0.0977(0.1190) | Xent Color 0.0089(0.0076) | Loss 0.7486(0.7523) | Error 0.0333(0.0362) | Error Color 0.0022(0.0010) |Steps 686(691.80) | Grad Norm 1.2111(1.5343) | Total Time 10.00(10.00)\n",
      "Iter 5990 | Time 15.0498(15.1842) | Bit/dim 0.7193(0.7199) | Xent 0.1298(0.1175) | Xent Color 0.0096(0.0075) | Loss 0.7542(0.7512) | Error 0.0433(0.0359) | Error Color 0.0011(0.0009) |Steps 692(691.95) | Grad Norm 1.6829(1.5112) | Total Time 10.00(10.00)\n",
      "Iter 6000 | Time 15.0200(15.2035) | Bit/dim 0.7128(0.7197) | Xent 0.1127(0.1174) | Xent Color 0.0059(0.0075) | Loss 0.7425(0.7509) | Error 0.0378(0.0361) | Error Color 0.0000(0.0008) |Steps 692(692.10) | Grad Norm 1.4740(1.4825) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 87.2271, Epoch Time 1111.6218(1017.7473), Bit/dim 0.7171(best: 0.7179), Xent 0.0591, Xent Color 0.0007. Loss 0.7320, Error 0.0185(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6010 | Time 14.7596(15.1647) | Bit/dim 0.7194(0.7193) | Xent 0.1089(0.1161) | Xent Color 0.0065(0.0073) | Loss 0.7483(0.7502) | Error 0.0311(0.0359) | Error Color 0.0000(0.0008) |Steps 692(692.40) | Grad Norm 1.2662(1.4266) | Total Time 10.00(10.00)\n",
      "Iter 6020 | Time 14.7631(15.1475) | Bit/dim 0.7134(0.7190) | Xent 0.0979(0.1161) | Xent Color 0.0048(0.0072) | Loss 0.7391(0.7499) | Error 0.0289(0.0361) | Error Color 0.0000(0.0008) |Steps 692(692.23) | Grad Norm 1.0169(1.4409) | Total Time 10.00(10.00)\n",
      "Iter 6030 | Time 15.0771(15.1760) | Bit/dim 0.7169(0.7195) | Xent 0.1372(0.1180) | Xent Color 0.0081(0.0074) | Loss 0.7532(0.7508) | Error 0.0389(0.0365) | Error Color 0.0022(0.0009) |Steps 692(692.22) | Grad Norm 1.9921(1.5452) | Total Time 10.00(10.00)\n",
      "Iter 6040 | Time 15.2415(15.1601) | Bit/dim 0.7223(0.7195) | Xent 0.1156(0.1152) | Xent Color 0.0139(0.0076) | Loss 0.7547(0.7502) | Error 0.0356(0.0359) | Error Color 0.0056(0.0010) |Steps 692(692.33) | Grad Norm 1.7348(1.6146) | Total Time 10.00(10.00)\n",
      "Iter 6050 | Time 14.8325(15.1590) | Bit/dim 0.7194(0.7192) | Xent 0.1056(0.1159) | Xent Color 0.0065(0.0075) | Loss 0.7474(0.7500) | Error 0.0289(0.0364) | Error Color 0.0011(0.0009) |Steps 680(692.66) | Grad Norm 1.0421(1.5992) | Total Time 10.00(10.00)\n",
      "Iter 6060 | Time 15.0228(15.1847) | Bit/dim 0.7235(0.7189) | Xent 0.1094(0.1160) | Xent Color 0.0080(0.0073) | Loss 0.7528(0.7497) | Error 0.0389(0.0362) | Error Color 0.0000(0.0008) |Steps 698(692.85) | Grad Norm 1.7034(1.5391) | Total Time 10.00(10.00)\n",
      "Iter 6070 | Time 15.4554(15.1834) | Bit/dim 0.7139(0.7183) | Xent 0.1161(0.1177) | Xent Color 0.0060(0.0074) | Loss 0.7444(0.7496) | Error 0.0256(0.0360) | Error Color 0.0000(0.0008) |Steps 698(693.29) | Grad Norm 1.0529(1.5372) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 87.8443, Epoch Time 1110.2228(1020.5216), Bit/dim 0.7166(best: 0.7171), Xent 0.0578, Xent Color 0.0007. Loss 0.7312, Error 0.0183(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6080 | Time 15.2954(15.1879) | Bit/dim 0.7219(0.7187) | Xent 0.1204(0.1163) | Xent Color 0.0051(0.0075) | Loss 0.7533(0.7496) | Error 0.0356(0.0367) | Error Color 0.0000(0.0008) |Steps 698(693.29) | Grad Norm 1.4366(1.5761) | Total Time 10.00(10.00)\n",
      "Iter 6090 | Time 15.3183(15.2001) | Bit/dim 0.7145(0.7189) | Xent 0.1057(0.1146) | Xent Color 0.0071(0.0074) | Loss 0.7427(0.7494) | Error 0.0333(0.0365) | Error Color 0.0000(0.0009) |Steps 692(693.75) | Grad Norm 1.7977(1.5510) | Total Time 10.00(10.00)\n",
      "Iter 6100 | Time 14.6389(15.1953) | Bit/dim 0.7221(0.7185) | Xent 0.1056(0.1148) | Xent Color 0.0053(0.0076) | Loss 0.7498(0.7491) | Error 0.0278(0.0366) | Error Color 0.0000(0.0010) |Steps 686(693.62) | Grad Norm 1.3366(1.5210) | Total Time 10.00(10.00)\n",
      "Iter 6110 | Time 15.3481(15.2145) | Bit/dim 0.6984(0.7178) | Xent 0.1132(0.1151) | Xent Color 0.0066(0.0076) | Loss 0.7283(0.7484) | Error 0.0400(0.0369) | Error Color 0.0011(0.0010) |Steps 692(693.19) | Grad Norm 1.7216(1.5406) | Total Time 10.00(10.00)\n",
      "Iter 6120 | Time 15.2284(15.1878) | Bit/dim 0.7210(0.7178) | Xent 0.1469(0.1161) | Xent Color 0.0068(0.0074) | Loss 0.7595(0.7487) | Error 0.0433(0.0370) | Error Color 0.0000(0.0009) |Steps 692(692.74) | Grad Norm 1.1433(1.5199) | Total Time 10.00(10.00)\n",
      "Iter 6130 | Time 14.9560(15.1534) | Bit/dim 0.7196(0.7173) | Xent 0.0969(0.1154) | Xent Color 0.0060(0.0077) | Loss 0.7453(0.7481) | Error 0.0367(0.0372) | Error Color 0.0011(0.0011) |Steps 692(693.18) | Grad Norm 1.6911(1.5126) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 87.2691, Epoch Time 1108.7899(1023.1696), Bit/dim 0.7143(best: 0.7166), Xent 0.0584, Xent Color 0.0007. Loss 0.7291, Error 0.0190(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6140 | Time 15.1693(15.1263) | Bit/dim 0.7231(0.7175) | Xent 0.1013(0.1184) | Xent Color 0.0093(0.0079) | Loss 0.7508(0.7490) | Error 0.0411(0.0376) | Error Color 0.0022(0.0013) |Steps 692(692.56) | Grad Norm 2.4627(1.5979) | Total Time 10.00(10.00)\n",
      "Iter 6150 | Time 14.5858(15.0885) | Bit/dim 0.7124(0.7170) | Xent 0.0906(0.1186) | Xent Color 0.0111(0.0078) | Loss 0.7379(0.7486) | Error 0.0233(0.0369) | Error Color 0.0033(0.0013) |Steps 692(692.58) | Grad Norm 1.0406(1.5892) | Total Time 10.00(10.00)\n",
      "Iter 6160 | Time 14.9421(15.0794) | Bit/dim 0.7236(0.7168) | Xent 0.1185(0.1185) | Xent Color 0.0058(0.0079) | Loss 0.7547(0.7484) | Error 0.0389(0.0369) | Error Color 0.0011(0.0013) |Steps 692(692.28) | Grad Norm 1.5648(1.6482) | Total Time 10.00(10.00)\n",
      "Iter 6170 | Time 15.1039(15.0969) | Bit/dim 0.7111(0.7166) | Xent 0.1302(0.1166) | Xent Color 0.0063(0.0076) | Loss 0.7453(0.7476) | Error 0.0367(0.0361) | Error Color 0.0000(0.0012) |Steps 692(691.91) | Grad Norm 1.4024(1.6648) | Total Time 10.00(10.00)\n",
      "Iter 6180 | Time 15.1935(15.1090) | Bit/dim 0.7115(0.7169) | Xent 0.0997(0.1155) | Xent Color 0.0094(0.0077) | Loss 0.7388(0.7477) | Error 0.0333(0.0362) | Error Color 0.0022(0.0011) |Steps 698(691.51) | Grad Norm 1.2906(1.6154) | Total Time 10.00(10.00)\n",
      "Iter 6190 | Time 15.2576(15.1293) | Bit/dim 0.7133(0.7170) | Xent 0.1053(0.1156) | Xent Color 0.0072(0.0076) | Loss 0.7414(0.7478) | Error 0.0356(0.0360) | Error Color 0.0011(0.0012) |Steps 698(691.93) | Grad Norm 2.4247(1.6206) | Total Time 10.00(10.00)\n",
      "Iter 6200 | Time 14.6791(15.1189) | Bit/dim 0.7133(0.7162) | Xent 0.1231(0.1177) | Xent Color 0.0064(0.0075) | Loss 0.7457(0.7475) | Error 0.0378(0.0365) | Error Color 0.0000(0.0012) |Steps 698(692.92) | Grad Norm 1.9340(1.6822) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 87.9510, Epoch Time 1104.5848(1025.6121), Bit/dim 0.7133(best: 0.7143), Xent 0.0607, Xent Color 0.0007. Loss 0.7287, Error 0.0200(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6210 | Time 14.9717(15.0838) | Bit/dim 0.7196(0.7159) | Xent 0.0993(0.1166) | Xent Color 0.0095(0.0076) | Loss 0.7468(0.7469) | Error 0.0344(0.0364) | Error Color 0.0033(0.0013) |Steps 692(692.69) | Grad Norm 2.1137(1.7260) | Total Time 10.00(10.00)\n",
      "Iter 6220 | Time 15.3636(15.1103) | Bit/dim 0.7122(0.7156) | Xent 0.1070(0.1139) | Xent Color 0.0095(0.0077) | Loss 0.7413(0.7460) | Error 0.0344(0.0361) | Error Color 0.0033(0.0013) |Steps 686(692.63) | Grad Norm 1.6648(1.7166) | Total Time 10.00(10.00)\n",
      "Iter 6230 | Time 15.2905(15.1503) | Bit/dim 0.7177(0.7153) | Xent 0.0945(0.1154) | Xent Color 0.0070(0.0077) | Loss 0.7430(0.7460) | Error 0.0344(0.0365) | Error Color 0.0022(0.0013) |Steps 698(692.83) | Grad Norm 2.2807(1.7706) | Total Time 10.00(10.00)\n",
      "Iter 6240 | Time 15.0698(15.1454) | Bit/dim 0.7130(0.7157) | Xent 0.1205(0.1161) | Xent Color 0.0084(0.0077) | Loss 0.7452(0.7466) | Error 0.0344(0.0371) | Error Color 0.0011(0.0012) |Steps 686(693.22) | Grad Norm 1.2899(1.7311) | Total Time 10.00(10.00)\n",
      "Iter 6250 | Time 15.2729(15.1557) | Bit/dim 0.7232(0.7160) | Xent 0.0977(0.1135) | Xent Color 0.0049(0.0075) | Loss 0.7489(0.7462) | Error 0.0278(0.0363) | Error Color 0.0000(0.0012) |Steps 692(693.07) | Grad Norm 1.8396(1.7083) | Total Time 10.00(10.00)\n",
      "Iter 6260 | Time 15.2019(15.1696) | Bit/dim 0.7118(0.7155) | Xent 0.1238(0.1107) | Xent Color 0.0076(0.0074) | Loss 0.7447(0.7450) | Error 0.0422(0.0352) | Error Color 0.0022(0.0012) |Steps 698(693.43) | Grad Norm 1.6449(1.7024) | Total Time 10.00(10.00)\n",
      "Iter 6270 | Time 15.2336(15.1282) | Bit/dim 0.7199(0.7152) | Xent 0.0913(0.1114) | Xent Color 0.0088(0.0074) | Loss 0.7449(0.7450) | Error 0.0311(0.0353) | Error Color 0.0033(0.0012) |Steps 692(693.35) | Grad Norm 2.5919(1.7982) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 86.7526, Epoch Time 1107.8314(1028.0787), Bit/dim 0.7129(best: 0.7133), Xent 0.0566, Xent Color 0.0006. Loss 0.7272, Error 0.0181(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6280 | Time 15.3312(15.1236) | Bit/dim 0.7175(0.7144) | Xent 0.1133(0.1114) | Xent Color 0.0059(0.0072) | Loss 0.7473(0.7441) | Error 0.0356(0.0352) | Error Color 0.0000(0.0011) |Steps 692(693.48) | Grad Norm 1.3009(1.7626) | Total Time 10.00(10.00)\n",
      "Iter 6290 | Time 15.2867(15.1381) | Bit/dim 0.7153(0.7148) | Xent 0.1320(0.1135) | Xent Color 0.0063(0.0072) | Loss 0.7499(0.7449) | Error 0.0411(0.0357) | Error Color 0.0011(0.0011) |Steps 680(693.05) | Grad Norm 2.7989(1.7474) | Total Time 10.00(10.00)\n",
      "Iter 6300 | Time 14.6109(15.0978) | Bit/dim 0.7060(0.7144) | Xent 0.0865(0.1151) | Xent Color 0.0082(0.0073) | Loss 0.7296(0.7450) | Error 0.0311(0.0361) | Error Color 0.0011(0.0011) |Steps 698(693.30) | Grad Norm 1.4548(1.7442) | Total Time 10.00(10.00)\n",
      "Iter 6310 | Time 15.0568(15.0899) | Bit/dim 0.7119(0.7147) | Xent 0.1287(0.1157) | Xent Color 0.0084(0.0070) | Loss 0.7462(0.7454) | Error 0.0478(0.0367) | Error Color 0.0022(0.0010) |Steps 692(693.11) | Grad Norm 1.8153(1.7971) | Total Time 10.00(10.00)\n",
      "Iter 6320 | Time 15.2756(15.0889) | Bit/dim 0.7188(0.7138) | Xent 0.1498(0.1150) | Xent Color 0.0112(0.0072) | Loss 0.7590(0.7444) | Error 0.0467(0.0368) | Error Color 0.0044(0.0011) |Steps 698(693.49) | Grad Norm 2.6707(1.8498) | Total Time 10.00(10.00)\n",
      "Iter 6330 | Time 14.7218(15.0827) | Bit/dim 0.7132(0.7142) | Xent 0.1325(0.1148) | Xent Color 0.0053(0.0072) | Loss 0.7477(0.7447) | Error 0.0389(0.0363) | Error Color 0.0000(0.0012) |Steps 686(693.85) | Grad Norm 1.9809(1.7747) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 87.9557, Epoch Time 1104.8414(1030.3816), Bit/dim 0.7115(best: 0.7129), Xent 0.0588, Xent Color 0.0006. Loss 0.7263, Error 0.0192(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6340 | Time 14.6774(15.0838) | Bit/dim 0.7199(0.7144) | Xent 0.0844(0.1141) | Xent Color 0.0087(0.0073) | Loss 0.7432(0.7448) | Error 0.0300(0.0358) | Error Color 0.0033(0.0012) |Steps 692(693.07) | Grad Norm 2.2634(1.8550) | Total Time 10.00(10.00)\n",
      "Iter 6350 | Time 15.1921(15.0731) | Bit/dim 0.7162(0.7142) | Xent 0.1237(0.1162) | Xent Color 0.0055(0.0073) | Loss 0.7486(0.7451) | Error 0.0344(0.0361) | Error Color 0.0000(0.0011) |Steps 692(692.91) | Grad Norm 1.8214(2.0002) | Total Time 10.00(10.00)\n",
      "Iter 6360 | Time 14.8803(15.0854) | Bit/dim 0.7085(0.7142) | Xent 0.1265(0.1174) | Xent Color 0.0090(0.0073) | Loss 0.7424(0.7454) | Error 0.0433(0.0364) | Error Color 0.0000(0.0012) |Steps 692(693.01) | Grad Norm 2.0601(1.9748) | Total Time 10.00(10.00)\n",
      "Iter 6370 | Time 15.4995(15.0940) | Bit/dim 0.7125(0.7135) | Xent 0.0942(0.1158) | Xent Color 0.0060(0.0072) | Loss 0.7375(0.7443) | Error 0.0233(0.0360) | Error Color 0.0000(0.0011) |Steps 698(693.51) | Grad Norm 1.4053(2.0384) | Total Time 10.00(10.00)\n",
      "Iter 6380 | Time 15.4567(15.0988) | Bit/dim 0.7100(0.7129) | Xent 0.1185(0.1136) | Xent Color 0.0112(0.0073) | Loss 0.7425(0.7431) | Error 0.0322(0.0356) | Error Color 0.0044(0.0011) |Steps 698(693.71) | Grad Norm 2.2013(2.0421) | Total Time 10.00(10.00)\n",
      "Iter 6390 | Time 15.4741(15.1087) | Bit/dim 0.7138(0.7125) | Xent 0.1157(0.1128) | Xent Color 0.0063(0.0072) | Loss 0.7443(0.7425) | Error 0.0289(0.0359) | Error Color 0.0000(0.0010) |Steps 698(693.73) | Grad Norm 1.8274(1.9767) | Total Time 10.00(10.00)\n",
      "Iter 6400 | Time 14.8885(15.1084) | Bit/dim 0.7195(0.7124) | Xent 0.0874(0.1129) | Xent Color 0.0090(0.0072) | Loss 0.7436(0.7424) | Error 0.0300(0.0360) | Error Color 0.0033(0.0011) |Steps 698(694.41) | Grad Norm 1.5841(1.9405) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 87.8393, Epoch Time 1105.8132(1032.6445), Bit/dim 0.7112(best: 0.7115), Xent 0.0570, Xent Color 0.0006. Loss 0.7256, Error 0.0184(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6410 | Time 14.9417(15.1232) | Bit/dim 0.7104(0.7125) | Xent 0.0835(0.1125) | Xent Color 0.0057(0.0071) | Loss 0.7327(0.7424) | Error 0.0267(0.0359) | Error Color 0.0000(0.0010) |Steps 692(694.57) | Grad Norm 2.7132(1.9955) | Total Time 10.00(10.00)\n",
      "Iter 6420 | Time 15.0250(15.1392) | Bit/dim 0.7068(0.7126) | Xent 0.1228(0.1145) | Xent Color 0.0068(0.0070) | Loss 0.7392(0.7430) | Error 0.0433(0.0365) | Error Color 0.0000(0.0008) |Steps 698(694.70) | Grad Norm 2.3530(2.0834) | Total Time 10.00(10.00)\n",
      "Iter 6430 | Time 15.2628(15.1203) | Bit/dim 0.7067(0.7124) | Xent 0.1290(0.1149) | Xent Color 0.0053(0.0072) | Loss 0.7403(0.7430) | Error 0.0411(0.0369) | Error Color 0.0000(0.0010) |Steps 692(694.94) | Grad Norm 2.6629(2.1225) | Total Time 10.00(10.00)\n",
      "Iter 6440 | Time 15.0395(15.1349) | Bit/dim 0.7049(0.7121) | Xent 0.1117(0.1166) | Xent Color 0.0079(0.0073) | Loss 0.7348(0.7431) | Error 0.0400(0.0371) | Error Color 0.0011(0.0009) |Steps 698(694.81) | Grad Norm 1.6573(2.0682) | Total Time 10.00(10.00)\n",
      "Iter 6450 | Time 15.3563(15.1315) | Bit/dim 0.7126(0.7117) | Xent 0.0834(0.1158) | Xent Color 0.0039(0.0070) | Loss 0.7344(0.7424) | Error 0.0267(0.0365) | Error Color 0.0000(0.0009) |Steps 698(694.89) | Grad Norm 1.7610(1.9760) | Total Time 10.00(10.00)\n",
      "Iter 6460 | Time 15.2720(15.1214) | Bit/dim 0.7149(0.7113) | Xent 0.1232(0.1155) | Xent Color 0.0049(0.0071) | Loss 0.7470(0.7419) | Error 0.0444(0.0362) | Error Color 0.0000(0.0007) |Steps 698(695.10) | Grad Norm 1.0584(1.9244) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 87.1629, Epoch Time 1106.6553(1034.8648), Bit/dim 0.7096(best: 0.7112), Xent 0.0567, Xent Color 0.0007. Loss 0.7240, Error 0.0187(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6470 | Time 15.2898(15.1348) | Bit/dim 0.7269(0.7118) | Xent 0.1353(0.1149) | Xent Color 0.0082(0.0070) | Loss 0.7628(0.7423) | Error 0.0456(0.0359) | Error Color 0.0022(0.0008) |Steps 698(695.38) | Grad Norm 1.7959(1.7964) | Total Time 10.00(10.00)\n",
      "Iter 6480 | Time 15.1474(15.1643) | Bit/dim 0.7103(0.7119) | Xent 0.1504(0.1161) | Xent Color 0.0057(0.0070) | Loss 0.7493(0.7426) | Error 0.0456(0.0363) | Error Color 0.0011(0.0009) |Steps 692(695.55) | Grad Norm 2.4478(1.9204) | Total Time 10.00(10.00)\n",
      "Iter 6490 | Time 15.2512(15.1441) | Bit/dim 0.7174(0.7111) | Xent 0.1120(0.1179) | Xent Color 0.0066(0.0069) | Loss 0.7470(0.7423) | Error 0.0378(0.0367) | Error Color 0.0011(0.0009) |Steps 698(695.42) | Grad Norm 2.2594(2.0418) | Total Time 10.00(10.00)\n",
      "Iter 6500 | Time 14.6022(15.0916) | Bit/dim 0.7149(0.7110) | Xent 0.1465(0.1184) | Xent Color 0.0040(0.0065) | Loss 0.7525(0.7422) | Error 0.0444(0.0373) | Error Color 0.0000(0.0008) |Steps 692(695.29) | Grad Norm 2.2062(2.1101) | Total Time 10.00(10.00)\n",
      "Iter 6510 | Time 15.0111(15.0659) | Bit/dim 0.7142(0.7112) | Xent 0.1052(0.1173) | Xent Color 0.0072(0.0064) | Loss 0.7424(0.7421) | Error 0.0333(0.0373) | Error Color 0.0000(0.0007) |Steps 692(695.64) | Grad Norm 2.2028(2.1648) | Total Time 10.00(10.00)\n",
      "Iter 6520 | Time 15.1417(15.1168) | Bit/dim 0.7068(0.7115) | Xent 0.0996(0.1169) | Xent Color 0.0077(0.0067) | Loss 0.7336(0.7424) | Error 0.0311(0.0372) | Error Color 0.0011(0.0008) |Steps 698(696.28) | Grad Norm 3.0795(2.2670) | Total Time 10.00(10.00)\n",
      "Iter 6530 | Time 15.4665(15.1734) | Bit/dim 0.7063(0.7101) | Xent 0.1121(0.1135) | Xent Color 0.0050(0.0067) | Loss 0.7356(0.7402) | Error 0.0422(0.0360) | Error Color 0.0000(0.0009) |Steps 698(696.47) | Grad Norm 2.2786(2.3121) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 87.1141, Epoch Time 1108.1387(1037.0630), Bit/dim 0.7087(best: 0.7096), Xent 0.0577, Xent Color 0.0006. Loss 0.7233, Error 0.0190(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6540 | Time 15.0484(15.1655) | Bit/dim 0.7095(0.7102) | Xent 0.0845(0.1116) | Xent Color 0.0085(0.0070) | Loss 0.7328(0.7398) | Error 0.0311(0.0356) | Error Color 0.0011(0.0010) |Steps 698(696.05) | Grad Norm 2.3139(2.3911) | Total Time 10.00(10.00)\n",
      "Iter 6550 | Time 15.5002(15.1681) | Bit/dim 0.7073(0.7096) | Xent 0.0965(0.1139) | Xent Color 0.0061(0.0070) | Loss 0.7330(0.7398) | Error 0.0322(0.0360) | Error Color 0.0011(0.0010) |Steps 698(696.10) | Grad Norm 1.8703(2.3429) | Total Time 10.00(10.00)\n",
      "Iter 6560 | Time 14.9977(15.1930) | Bit/dim 0.7145(0.7091) | Xent 0.0978(0.1109) | Xent Color 0.0089(0.0070) | Loss 0.7412(0.7385) | Error 0.0289(0.0351) | Error Color 0.0011(0.0010) |Steps 704(696.59) | Grad Norm 1.6558(2.2354) | Total Time 10.00(10.00)\n",
      "Iter 6570 | Time 15.4248(15.1815) | Bit/dim 0.7038(0.7093) | Xent 0.1274(0.1118) | Xent Color 0.0058(0.0067) | Loss 0.7371(0.7389) | Error 0.0322(0.0350) | Error Color 0.0000(0.0008) |Steps 704(697.23) | Grad Norm 2.5165(2.1145) | Total Time 10.00(10.00)\n",
      "Iter 6580 | Time 15.1354(15.1744) | Bit/dim 0.7131(0.7099) | Xent 0.0898(0.1113) | Xent Color 0.0055(0.0067) | Loss 0.7369(0.7394) | Error 0.0322(0.0348) | Error Color 0.0011(0.0009) |Steps 698(697.46) | Grad Norm 1.3113(2.1217) | Total Time 10.00(10.00)\n",
      "Iter 6590 | Time 15.2284(15.1731) | Bit/dim 0.7010(0.7098) | Xent 0.1188(0.1119) | Xent Color 0.0083(0.0068) | Loss 0.7328(0.7394) | Error 0.0400(0.0352) | Error Color 0.0022(0.0009) |Steps 704(697.41) | Grad Norm 2.4371(2.0390) | Total Time 10.00(10.00)\n",
      "Iter 6600 | Time 15.6553(15.2033) | Bit/dim 0.7034(0.7097) | Xent 0.0866(0.1132) | Xent Color 0.0084(0.0069) | Loss 0.7271(0.7397) | Error 0.0278(0.0354) | Error Color 0.0011(0.0010) |Steps 704(697.78) | Grad Norm 3.1913(2.2690) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 88.0873, Epoch Time 1111.9932(1039.3109), Bit/dim 0.7066(best: 0.7087), Xent 0.0568, Xent Color 0.0007. Loss 0.7210, Error 0.0186(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6610 | Time 15.2518(15.2255) | Bit/dim 0.7033(0.7093) | Xent 0.1021(0.1117) | Xent Color 0.0057(0.0069) | Loss 0.7302(0.7389) | Error 0.0344(0.0348) | Error Color 0.0011(0.0011) |Steps 704(698.49) | Grad Norm 1.9821(2.3062) | Total Time 10.00(10.00)\n",
      "Iter 6620 | Time 15.2727(15.2304) | Bit/dim 0.7061(0.7093) | Xent 0.1294(0.1131) | Xent Color 0.0046(0.0068) | Loss 0.7396(0.7393) | Error 0.0378(0.0357) | Error Color 0.0000(0.0010) |Steps 692(698.15) | Grad Norm 2.0474(2.3017) | Total Time 10.00(10.00)\n",
      "Iter 6630 | Time 15.3307(15.2124) | Bit/dim 0.7027(0.7097) | Xent 0.1037(0.1122) | Xent Color 0.0077(0.0068) | Loss 0.7305(0.7395) | Error 0.0344(0.0352) | Error Color 0.0000(0.0009) |Steps 704(699.11) | Grad Norm 1.7423(2.2014) | Total Time 10.00(10.00)\n",
      "Iter 6640 | Time 15.1832(15.2176) | Bit/dim 0.7088(0.7092) | Xent 0.1020(0.1135) | Xent Color 0.0051(0.0069) | Loss 0.7355(0.7393) | Error 0.0300(0.0354) | Error Color 0.0000(0.0010) |Steps 692(699.23) | Grad Norm 1.5844(2.2124) | Total Time 10.00(10.00)\n",
      "Iter 6650 | Time 14.8447(15.2493) | Bit/dim 0.7136(0.7087) | Xent 0.1141(0.1125) | Xent Color 0.0087(0.0069) | Loss 0.7443(0.7385) | Error 0.0356(0.0348) | Error Color 0.0022(0.0011) |Steps 704(699.01) | Grad Norm 3.8217(2.2945) | Total Time 10.00(10.00)\n",
      "Iter 6660 | Time 15.6485(15.2696) | Bit/dim 0.7148(0.7080) | Xent 0.0854(0.1143) | Xent Color 0.0068(0.0066) | Loss 0.7378(0.7383) | Error 0.0256(0.0354) | Error Color 0.0011(0.0010) |Steps 698(699.30) | Grad Norm 2.4284(2.3347) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 88.9614, Epoch Time 1118.9153(1041.6991), Bit/dim 0.7074(best: 0.7066), Xent 0.0528, Xent Color 0.0006. Loss 0.7208, Error 0.0179(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6670 | Time 14.9023(15.2727) | Bit/dim 0.7127(0.7077) | Xent 0.1024(0.1147) | Xent Color 0.0094(0.0068) | Loss 0.7407(0.7381) | Error 0.0367(0.0354) | Error Color 0.0022(0.0011) |Steps 692(699.23) | Grad Norm 1.4699(2.4113) | Total Time 10.00(10.00)\n",
      "Iter 6680 | Time 15.0169(15.2337) | Bit/dim 0.7041(0.7074) | Xent 0.1029(0.1137) | Xent Color 0.0058(0.0068) | Loss 0.7312(0.7375) | Error 0.0344(0.0353) | Error Color 0.0000(0.0012) |Steps 698(699.20) | Grad Norm 2.3459(2.4863) | Total Time 10.00(10.00)\n",
      "Iter 6690 | Time 15.5544(15.2720) | Bit/dim 0.7120(0.7075) | Xent 0.1423(0.1157) | Xent Color 0.0064(0.0069) | Loss 0.7492(0.7382) | Error 0.0500(0.0362) | Error Color 0.0011(0.0011) |Steps 698(699.19) | Grad Norm 2.2321(2.5545) | Total Time 10.00(10.00)\n",
      "Iter 6700 | Time 15.2800(15.2942) | Bit/dim 0.7055(0.7065) | Xent 0.1244(0.1152) | Xent Color 0.0070(0.0068) | Loss 0.7383(0.7370) | Error 0.0367(0.0363) | Error Color 0.0000(0.0010) |Steps 704(699.37) | Grad Norm 3.4565(2.5607) | Total Time 10.00(10.00)\n",
      "Iter 6710 | Time 15.2877(15.2848) | Bit/dim 0.7053(0.7066) | Xent 0.0933(0.1144) | Xent Color 0.0072(0.0068) | Loss 0.7304(0.7369) | Error 0.0267(0.0363) | Error Color 0.0000(0.0010) |Steps 698(699.47) | Grad Norm 1.6653(2.7025) | Total Time 10.00(10.00)\n",
      "Iter 6720 | Time 15.4275(15.3084) | Bit/dim 0.6977(0.7065) | Xent 0.0895(0.1118) | Xent Color 0.0047(0.0067) | Loss 0.7213(0.7361) | Error 0.0244(0.0353) | Error Color 0.0000(0.0008) |Steps 698(700.00) | Grad Norm 0.9722(2.4960) | Total Time 10.00(10.00)\n",
      "Iter 6730 | Time 15.2364(15.2878) | Bit/dim 0.7091(0.7070) | Xent 0.1096(0.1115) | Xent Color 0.0054(0.0069) | Loss 0.7379(0.7366) | Error 0.0378(0.0359) | Error Color 0.0011(0.0010) |Steps 704(700.10) | Grad Norm 1.7321(2.2654) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 88.2549, Epoch Time 1117.0960(1043.9610), Bit/dim 0.7053(best: 0.7066), Xent 0.0563, Xent Color 0.0006. Loss 0.7195, Error 0.0184(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6740 | Time 15.3762(15.2712) | Bit/dim 0.7072(0.7065) | Xent 0.0989(0.1114) | Xent Color 0.0069(0.0069) | Loss 0.7336(0.7361) | Error 0.0356(0.0358) | Error Color 0.0000(0.0009) |Steps 698(700.14) | Grad Norm 2.9195(2.3251) | Total Time 10.00(10.00)\n",
      "Iter 6750 | Time 15.5282(15.2930) | Bit/dim 0.7164(0.7067) | Xent 0.1203(0.1106) | Xent Color 0.0065(0.0068) | Loss 0.7481(0.7360) | Error 0.0378(0.0347) | Error Color 0.0011(0.0009) |Steps 704(699.74) | Grad Norm 4.0747(2.5213) | Total Time 10.00(10.00)\n",
      "Iter 6760 | Time 15.1259(15.2594) | Bit/dim 0.6976(0.7061) | Xent 0.0809(0.1103) | Xent Color 0.0055(0.0067) | Loss 0.7191(0.7353) | Error 0.0256(0.0343) | Error Color 0.0000(0.0009) |Steps 692(699.55) | Grad Norm 1.7406(2.6674) | Total Time 10.00(10.00)\n",
      "Iter 6770 | Time 15.2273(15.2621) | Bit/dim 0.7057(0.7064) | Xent 0.1040(0.1109) | Xent Color 0.0082(0.0068) | Loss 0.7337(0.7358) | Error 0.0278(0.0348) | Error Color 0.0011(0.0011) |Steps 704(699.94) | Grad Norm 3.6339(2.7967) | Total Time 10.00(10.00)\n",
      "Iter 6780 | Time 15.2140(15.2657) | Bit/dim 0.7108(0.7061) | Xent 0.1115(0.1128) | Xent Color 0.0071(0.0066) | Loss 0.7404(0.7359) | Error 0.0422(0.0354) | Error Color 0.0000(0.0009) |Steps 704(700.23) | Grad Norm 2.9315(2.8031) | Total Time 10.00(10.00)\n",
      "Iter 6790 | Time 15.5673(15.2619) | Bit/dim 0.7123(0.7061) | Xent 0.1026(0.1146) | Xent Color 0.0046(0.0067) | Loss 0.7391(0.7364) | Error 0.0311(0.0362) | Error Color 0.0000(0.0010) |Steps 704(700.76) | Grad Norm 3.4508(2.9366) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 87.8963, Epoch Time 1115.7483(1046.1146), Bit/dim 0.7033(best: 0.7053), Xent 0.0542, Xent Color 0.0006. Loss 0.7170, Error 0.0168(best: 0.0171), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6800 | Time 15.1675(15.2503) | Bit/dim 0.7049(0.7060) | Xent 0.1236(0.1151) | Xent Color 0.0048(0.0065) | Loss 0.7370(0.7364) | Error 0.0356(0.0362) | Error Color 0.0011(0.0010) |Steps 704(701.30) | Grad Norm 2.0527(2.7707) | Total Time 10.00(10.00)\n",
      "Iter 6810 | Time 15.3311(15.2627) | Bit/dim 0.7078(0.7058) | Xent 0.0940(0.1121) | Xent Color 0.0072(0.0066) | Loss 0.7331(0.7355) | Error 0.0333(0.0359) | Error Color 0.0011(0.0010) |Steps 698(700.74) | Grad Norm 2.1886(2.5782) | Total Time 10.00(10.00)\n",
      "Iter 6820 | Time 15.1752(15.2669) | Bit/dim 0.7050(0.7049) | Xent 0.0997(0.1087) | Xent Color 0.0057(0.0066) | Loss 0.7314(0.7338) | Error 0.0333(0.0348) | Error Color 0.0000(0.0009) |Steps 692(700.29) | Grad Norm 1.8717(2.4327) | Total Time 10.00(10.00)\n",
      "Iter 6830 | Time 15.1062(15.2350) | Bit/dim 0.7085(0.7051) | Xent 0.1066(0.1082) | Xent Color 0.0085(0.0065) | Loss 0.7373(0.7338) | Error 0.0267(0.0344) | Error Color 0.0011(0.0008) |Steps 692(699.96) | Grad Norm 1.3664(2.3388) | Total Time 10.00(10.00)\n",
      "Iter 6840 | Time 15.0992(15.2559) | Bit/dim 0.7053(0.7051) | Xent 0.1469(0.1109) | Xent Color 0.0089(0.0067) | Loss 0.7442(0.7345) | Error 0.0433(0.0352) | Error Color 0.0022(0.0009) |Steps 704(700.70) | Grad Norm 3.4818(2.3371) | Total Time 10.00(10.00)\n",
      "Iter 6850 | Time 15.1928(15.2835) | Bit/dim 0.7059(0.7044) | Xent 0.1193(0.1136) | Xent Color 0.0053(0.0066) | Loss 0.7371(0.7345) | Error 0.0356(0.0357) | Error Color 0.0000(0.0010) |Steps 704(700.80) | Grad Norm 3.7487(2.6344) | Total Time 10.00(10.00)\n",
      "Iter 6860 | Time 15.5048(15.2563) | Bit/dim 0.7079(0.7047) | Xent 0.1215(0.1129) | Xent Color 0.0062(0.0066) | Loss 0.7399(0.7345) | Error 0.0367(0.0356) | Error Color 0.0000(0.0009) |Steps 698(700.52) | Grad Norm 2.9313(2.7630) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 87.3254, Epoch Time 1116.2878(1048.2198), Bit/dim 0.7021(best: 0.7033), Xent 0.0583, Xent Color 0.0005. Loss 0.7168, Error 0.0196(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6870 | Time 15.1403(15.2480) | Bit/dim 0.7131(0.7052) | Xent 0.1111(0.1123) | Xent Color 0.0079(0.0066) | Loss 0.7428(0.7349) | Error 0.0367(0.0354) | Error Color 0.0011(0.0008) |Steps 692(699.85) | Grad Norm 2.1405(2.6662) | Total Time 10.00(10.00)\n",
      "Iter 6880 | Time 15.1012(15.2470) | Bit/dim 0.6969(0.7048) | Xent 0.0949(0.1099) | Xent Color 0.0079(0.0067) | Loss 0.7227(0.7340) | Error 0.0356(0.0350) | Error Color 0.0011(0.0008) |Steps 698(700.30) | Grad Norm 1.4595(2.5633) | Total Time 10.00(10.00)\n",
      "Iter 6890 | Time 15.3537(15.2762) | Bit/dim 0.7026(0.7043) | Xent 0.0971(0.1129) | Xent Color 0.0066(0.0067) | Loss 0.7285(0.7342) | Error 0.0289(0.0357) | Error Color 0.0000(0.0008) |Steps 704(700.64) | Grad Norm 1.7004(2.3811) | Total Time 10.00(10.00)\n",
      "Iter 6900 | Time 15.3218(15.2347) | Bit/dim 0.7058(0.7050) | Xent 0.0916(0.1117) | Xent Color 0.0076(0.0066) | Loss 0.7306(0.7346) | Error 0.0322(0.0358) | Error Color 0.0011(0.0008) |Steps 698(700.69) | Grad Norm 1.4965(2.2454) | Total Time 10.00(10.00)\n",
      "Iter 6910 | Time 15.1292(15.2352) | Bit/dim 0.7028(0.7043) | Xent 0.1246(0.1103) | Xent Color 0.0058(0.0068) | Loss 0.7354(0.7336) | Error 0.0389(0.0351) | Error Color 0.0000(0.0009) |Steps 704(700.62) | Grad Norm 4.1582(2.5042) | Total Time 10.00(10.00)\n",
      "Iter 6920 | Time 15.1843(15.2299) | Bit/dim 0.6910(0.7032) | Xent 0.1175(0.1115) | Xent Color 0.0060(0.0067) | Loss 0.7219(0.7328) | Error 0.0367(0.0356) | Error Color 0.0011(0.0010) |Steps 692(699.74) | Grad Norm 2.4350(2.5209) | Total Time 10.00(10.00)\n",
      "Iter 6930 | Time 15.2893(15.2495) | Bit/dim 0.7099(0.7030) | Xent 0.1040(0.1133) | Xent Color 0.0110(0.0067) | Loss 0.7387(0.7330) | Error 0.0356(0.0359) | Error Color 0.0033(0.0010) |Steps 692(699.89) | Grad Norm 2.7408(2.6527) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 88.3165, Epoch Time 1119.1698(1050.3483), Bit/dim 0.7012(best: 0.7021), Xent 0.0579, Xent Color 0.0007. Loss 0.7159, Error 0.0188(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6940 | Time 15.3252(15.2605) | Bit/dim 0.7027(0.7029) | Xent 0.0948(0.1113) | Xent Color 0.0068(0.0067) | Loss 0.7281(0.7324) | Error 0.0300(0.0353) | Error Color 0.0000(0.0009) |Steps 704(700.34) | Grad Norm 2.6786(2.9281) | Total Time 10.00(10.00)\n",
      "Iter 6950 | Time 15.1886(15.2561) | Bit/dim 0.6968(0.7032) | Xent 0.1053(0.1134) | Xent Color 0.0080(0.0069) | Loss 0.7251(0.7333) | Error 0.0367(0.0359) | Error Color 0.0011(0.0011) |Steps 704(699.93) | Grad Norm 2.1282(3.0136) | Total Time 10.00(10.00)\n",
      "Iter 6960 | Time 15.1880(15.2301) | Bit/dim 0.6992(0.7028) | Xent 0.1124(0.1140) | Xent Color 0.0060(0.0070) | Loss 0.7288(0.7330) | Error 0.0356(0.0360) | Error Color 0.0000(0.0011) |Steps 704(700.06) | Grad Norm 3.3183(3.2278) | Total Time 10.00(10.00)\n",
      "Iter 6970 | Time 16.0342(15.3149) | Bit/dim 0.6955(0.7021) | Xent 0.1126(0.1130) | Xent Color 0.0101(0.0067) | Loss 0.7262(0.7321) | Error 0.0400(0.0359) | Error Color 0.0033(0.0011) |Steps 704(699.35) | Grad Norm 2.7046(3.2195) | Total Time 10.00(10.00)\n",
      "Iter 6980 | Time 15.5602(15.3275) | Bit/dim 0.6979(0.7019) | Xent 0.1079(0.1113) | Xent Color 0.0080(0.0067) | Loss 0.7268(0.7314) | Error 0.0422(0.0350) | Error Color 0.0022(0.0011) |Steps 704(699.46) | Grad Norm 3.4046(3.2185) | Total Time 10.00(10.00)\n",
      "Iter 6990 | Time 15.2246(15.3483) | Bit/dim 0.7021(0.7027) | Xent 0.0793(0.1091) | Xent Color 0.0105(0.0067) | Loss 0.7246(0.7316) | Error 0.0278(0.0339) | Error Color 0.0033(0.0011) |Steps 704(700.05) | Grad Norm 4.1063(3.1879) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 89.1286, Epoch Time 1122.0713(1052.5000), Bit/dim 0.7001(best: 0.7012), Xent 0.0526, Xent Color 0.0006. Loss 0.7134, Error 0.0164(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7000 | Time 15.1346(15.2844) | Bit/dim 0.7043(0.7024) | Xent 0.1323(0.1111) | Xent Color 0.0041(0.0068) | Loss 0.7384(0.7318) | Error 0.0456(0.0344) | Error Color 0.0000(0.0011) |Steps 704(700.29) | Grad Norm 2.6382(3.2360) | Total Time 10.00(10.00)\n",
      "Iter 7010 | Time 14.8032(15.2116) | Bit/dim 0.6980(0.7018) | Xent 0.1035(0.1107) | Xent Color 0.0059(0.0067) | Loss 0.7253(0.7311) | Error 0.0333(0.0341) | Error Color 0.0000(0.0011) |Steps 692(699.98) | Grad Norm 3.2283(3.4070) | Total Time 10.00(10.00)\n",
      "Iter 7020 | Time 15.1008(15.2146) | Bit/dim 0.7072(0.7015) | Xent 0.1051(0.1100) | Xent Color 0.0061(0.0066) | Loss 0.7350(0.7306) | Error 0.0356(0.0343) | Error Color 0.0000(0.0010) |Steps 692(699.52) | Grad Norm 2.1153(3.4688) | Total Time 10.00(10.00)\n",
      "Iter 7030 | Time 15.0723(15.2305) | Bit/dim 0.6997(0.7014) | Xent 0.1044(0.1110) | Xent Color 0.0071(0.0064) | Loss 0.7276(0.7308) | Error 0.0378(0.0346) | Error Color 0.0011(0.0009) |Steps 704(699.63) | Grad Norm 3.2277(3.7646) | Total Time 10.00(10.00)\n",
      "Iter 7040 | Time 14.6668(15.1807) | Bit/dim 0.6961(0.7015) | Xent 0.1310(0.1112) | Xent Color 0.0057(0.0064) | Loss 0.7302(0.7310) | Error 0.0422(0.0348) | Error Color 0.0000(0.0010) |Steps 692(698.71) | Grad Norm 3.8318(3.7418) | Total Time 10.00(10.00)\n",
      "Iter 7050 | Time 14.7146(15.1503) | Bit/dim 0.6942(0.7016) | Xent 0.1193(0.1104) | Xent Color 0.0061(0.0065) | Loss 0.7255(0.7309) | Error 0.0378(0.0348) | Error Color 0.0011(0.0010) |Steps 692(698.13) | Grad Norm 5.0330(3.8078) | Total Time 10.00(10.00)\n",
      "Iter 7060 | Time 15.8543(15.1737) | Bit/dim 0.7030(0.7024) | Xent 0.1117(0.1102) | Xent Color 0.0075(0.0064) | Loss 0.7328(0.7316) | Error 0.0411(0.0351) | Error Color 0.0011(0.0009) |Steps 698(697.91) | Grad Norm 5.6006(4.0577) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 88.5803, Epoch Time 1109.1501(1054.1995), Bit/dim 0.6991(best: 0.7001), Xent 0.0558, Xent Color 0.0005. Loss 0.7132, Error 0.0179(best: 0.0164), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7070 | Time 15.0855(15.2003) | Bit/dim 0.7043(0.7023) | Xent 0.1381(0.1096) | Xent Color 0.0059(0.0063) | Loss 0.7403(0.7313) | Error 0.0456(0.0351) | Error Color 0.0000(0.0008) |Steps 704(697.95) | Grad Norm 4.5270(3.8838) | Total Time 10.00(10.00)\n",
      "Iter 7080 | Time 15.4071(15.2461) | Bit/dim 0.6916(0.7008) | Xent 0.1514(0.1082) | Xent Color 0.0071(0.0065) | Loss 0.7312(0.7294) | Error 0.0489(0.0350) | Error Color 0.0011(0.0010) |Steps 704(698.89) | Grad Norm 2.1280(3.4235) | Total Time 10.00(10.00)\n",
      "Iter 7090 | Time 15.6616(15.2412) | Bit/dim 0.7074(0.7007) | Xent 0.1306(0.1086) | Xent Color 0.0045(0.0062) | Loss 0.7412(0.7294) | Error 0.0389(0.0349) | Error Color 0.0000(0.0009) |Steps 698(698.99) | Grad Norm 4.5784(3.2671) | Total Time 10.00(10.00)\n",
      "Iter 7100 | Time 15.4199(15.2659) | Bit/dim 0.7034(0.7007) | Xent 0.1110(0.1073) | Xent Color 0.0059(0.0060) | Loss 0.7326(0.7290) | Error 0.0322(0.0339) | Error Color 0.0000(0.0009) |Steps 698(698.70) | Grad Norm 2.0778(3.2369) | Total Time 10.00(10.00)\n",
      "Iter 7110 | Time 15.2365(15.2599) | Bit/dim 0.7010(0.7007) | Xent 0.1247(0.1073) | Xent Color 0.0052(0.0062) | Loss 0.7334(0.7290) | Error 0.0378(0.0343) | Error Color 0.0000(0.0009) |Steps 704(698.42) | Grad Norm 2.5745(3.0561) | Total Time 10.00(10.00)\n",
      "Iter 7120 | Time 15.3021(15.2792) | Bit/dim 0.7074(0.7006) | Xent 0.0987(0.1064) | Xent Color 0.0068(0.0062) | Loss 0.7338(0.7287) | Error 0.0311(0.0337) | Error Color 0.0011(0.0008) |Steps 704(698.48) | Grad Norm 3.1209(3.0933) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 88.3133, Epoch Time 1118.8135(1056.1379), Bit/dim 0.6986(best: 0.6991), Xent 0.0550, Xent Color 0.0005. Loss 0.7124, Error 0.0182(best: 0.0164), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7130 | Time 15.0447(15.2728) | Bit/dim 0.7083(0.7004) | Xent 0.0829(0.1053) | Xent Color 0.0055(0.0064) | Loss 0.7304(0.7283) | Error 0.0289(0.0338) | Error Color 0.0011(0.0010) |Steps 704(698.70) | Grad Norm 2.6620(3.0893) | Total Time 10.00(10.00)\n",
      "Iter 7140 | Time 15.1485(15.2693) | Bit/dim 0.6995(0.6997) | Xent 0.1229(0.1066) | Xent Color 0.0057(0.0061) | Loss 0.7317(0.7278) | Error 0.0356(0.0344) | Error Color 0.0000(0.0008) |Steps 692(698.82) | Grad Norm 2.1319(2.9364) | Total Time 10.00(10.00)\n",
      "Iter 7150 | Time 15.2092(15.2097) | Bit/dim 0.6988(0.6991) | Xent 0.0907(0.1101) | Xent Color 0.0053(0.0061) | Loss 0.7228(0.7282) | Error 0.0344(0.0347) | Error Color 0.0011(0.0009) |Steps 698(698.74) | Grad Norm 4.2783(3.1011) | Total Time 10.00(10.00)\n",
      "Iter 7160 | Time 14.7867(15.2277) | Bit/dim 0.7056(0.6997) | Xent 0.1185(0.1101) | Xent Color 0.0052(0.0061) | Loss 0.7365(0.7287) | Error 0.0333(0.0348) | Error Color 0.0000(0.0009) |Steps 698(698.40) | Grad Norm 1.8289(3.0233) | Total Time 10.00(10.00)\n",
      "Iter 7170 | Time 15.3527(15.2460) | Bit/dim 0.6928(0.6989) | Xent 0.1002(0.1085) | Xent Color 0.0072(0.0060) | Loss 0.7196(0.7275) | Error 0.0322(0.0342) | Error Color 0.0000(0.0008) |Steps 692(698.13) | Grad Norm 5.5181(3.2339) | Total Time 10.00(10.00)\n",
      "Iter 7180 | Time 15.1507(15.2143) | Bit/dim 0.6974(0.6986) | Xent 0.0963(0.1076) | Xent Color 0.0052(0.0062) | Loss 0.7228(0.7271) | Error 0.0300(0.0342) | Error Color 0.0011(0.0008) |Steps 692(697.95) | Grad Norm 3.2397(3.2960) | Total Time 10.00(10.00)\n",
      "Iter 7190 | Time 14.8416(15.1857) | Bit/dim 0.7048(0.6992) | Xent 0.0957(0.1060) | Xent Color 0.0039(0.0060) | Loss 0.7297(0.7272) | Error 0.0311(0.0335) | Error Color 0.0000(0.0008) |Steps 692(697.92) | Grad Norm 2.6210(3.1354) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 88.7564, Epoch Time 1111.8041(1057.8079), Bit/dim 0.6948(best: 0.6986), Xent 0.0536, Xent Color 0.0005. Loss 0.7084, Error 0.0176(best: 0.0164), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7200 | Time 15.4573(15.1830) | Bit/dim 0.6964(0.6993) | Xent 0.1185(0.1060) | Xent Color 0.0049(0.0061) | Loss 0.7273(0.7273) | Error 0.0400(0.0336) | Error Color 0.0000(0.0008) |Steps 698(697.15) | Grad Norm 3.6945(3.2151) | Total Time 10.00(10.00)\n",
      "Iter 7210 | Time 15.2250(15.2116) | Bit/dim 0.6967(0.6989) | Xent 0.1127(0.1080) | Xent Color 0.0051(0.0060) | Loss 0.7261(0.7274) | Error 0.0422(0.0342) | Error Color 0.0011(0.0008) |Steps 698(696.92) | Grad Norm 3.6518(3.1518) | Total Time 10.00(10.00)\n",
      "Iter 7220 | Time 15.1531(15.2046) | Bit/dim 0.6932(0.6982) | Xent 0.0954(0.1105) | Xent Color 0.0056(0.0060) | Loss 0.7184(0.7274) | Error 0.0311(0.0348) | Error Color 0.0011(0.0008) |Steps 698(697.33) | Grad Norm 3.6506(3.2850) | Total Time 10.00(10.00)\n",
      "Iter 7230 | Time 14.9729(15.2334) | Bit/dim 0.7007(0.6982) | Xent 0.1080(0.1096) | Xent Color 0.0050(0.0060) | Loss 0.7289(0.7271) | Error 0.0400(0.0346) | Error Color 0.0000(0.0009) |Steps 704(697.82) | Grad Norm 3.4894(3.3239) | Total Time 10.00(10.00)\n",
      "Iter 7240 | Time 15.3637(15.2412) | Bit/dim 0.6951(0.6983) | Xent 0.0868(0.1051) | Xent Color 0.0042(0.0061) | Loss 0.7179(0.7261) | Error 0.0278(0.0328) | Error Color 0.0000(0.0008) |Steps 704(699.27) | Grad Norm 1.8584(3.1264) | Total Time 10.00(10.00)\n",
      "Iter 7250 | Time 15.4413(15.2327) | Bit/dim 0.7028(0.6979) | Xent 0.1268(0.1086) | Xent Color 0.0061(0.0061) | Loss 0.7361(0.7266) | Error 0.0389(0.0335) | Error Color 0.0022(0.0008) |Steps 692(698.73) | Grad Norm 3.3099(2.8986) | Total Time 10.00(10.00)\n",
      "Iter 7260 | Time 15.1544(15.2927) | Bit/dim 0.6931(0.6975) | Xent 0.1087(0.1083) | Xent Color 0.0073(0.0059) | Loss 0.7221(0.7261) | Error 0.0367(0.0341) | Error Color 0.0011(0.0007) |Steps 704(698.69) | Grad Norm 3.9880(3.0332) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 88.9314, Epoch Time 1118.5537(1059.6303), Bit/dim 0.6962(best: 0.6948), Xent 0.0567, Xent Color 0.0005. Loss 0.7105, Error 0.0185(best: 0.0164), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7270 | Time 15.3099(15.2846) | Bit/dim 0.6985(0.6977) | Xent 0.1074(0.1072) | Xent Color 0.0045(0.0058) | Loss 0.7265(0.7259) | Error 0.0333(0.0339) | Error Color 0.0000(0.0007) |Steps 698(698.17) | Grad Norm 4.6079(3.2197) | Total Time 10.00(10.00)\n",
      "Iter 7280 | Time 15.1296(15.2981) | Bit/dim 0.6951(0.6968) | Xent 0.1009(0.1067) | Xent Color 0.0060(0.0058) | Loss 0.7219(0.7249) | Error 0.0256(0.0337) | Error Color 0.0011(0.0007) |Steps 692(698.36) | Grad Norm 3.8109(3.2581) | Total Time 10.00(10.00)\n",
      "Iter 7290 | Time 15.2100(15.2569) | Bit/dim 0.7039(0.6972) | Xent 0.1088(0.1072) | Xent Color 0.0045(0.0058) | Loss 0.7322(0.7254) | Error 0.0333(0.0346) | Error Color 0.0000(0.0007) |Steps 698(698.11) | Grad Norm 3.0418(3.1161) | Total Time 10.00(10.00)\n",
      "Iter 7300 | Time 15.4115(15.2978) | Bit/dim 0.6963(0.6967) | Xent 0.1151(0.1066) | Xent Color 0.0058(0.0057) | Loss 0.7265(0.7248) | Error 0.0311(0.0341) | Error Color 0.0000(0.0007) |Steps 710(699.38) | Grad Norm 3.0844(3.0512) | Total Time 10.00(10.00)\n",
      "Iter 7310 | Time 15.5911(15.3002) | Bit/dim 0.6936(0.6966) | Xent 0.1047(0.1074) | Xent Color 0.0071(0.0056) | Loss 0.7216(0.7248) | Error 0.0367(0.0340) | Error Color 0.0011(0.0007) |Steps 698(699.63) | Grad Norm 4.9203(3.1434) | Total Time 10.00(10.00)\n",
      "Iter 7320 | Time 14.9996(15.3003) | Bit/dim 0.6983(0.6965) | Xent 0.0890(0.1093) | Xent Color 0.0049(0.0058) | Loss 0.7218(0.7253) | Error 0.0256(0.0343) | Error Color 0.0000(0.0007) |Steps 698(699.81) | Grad Norm 4.0380(3.2419) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 87.6846, Epoch Time 1117.8810(1061.3778), Bit/dim 0.6942(best: 0.6948), Xent 0.0539, Xent Color 0.0004. Loss 0.7078, Error 0.0168(best: 0.0164), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7330 | Time 14.9877(15.2696) | Bit/dim 0.6998(0.6967) | Xent 0.1040(0.1086) | Xent Color 0.0082(0.0059) | Loss 0.7278(0.7253) | Error 0.0333(0.0342) | Error Color 0.0011(0.0007) |Steps 698(699.15) | Grad Norm 4.8736(3.7226) | Total Time 10.00(10.00)\n",
      "Iter 7340 | Time 15.1631(15.2375) | Bit/dim 0.6934(0.6961) | Xent 0.1097(0.1091) | Xent Color 0.0040(0.0058) | Loss 0.7218(0.7249) | Error 0.0311(0.0338) | Error Color 0.0000(0.0007) |Steps 698(699.33) | Grad Norm 3.0327(3.7958) | Total Time 10.00(10.00)\n",
      "Iter 7350 | Time 14.9844(15.2329) | Bit/dim 0.7083(0.6960) | Xent 0.1024(0.1087) | Xent Color 0.0087(0.0058) | Loss 0.7360(0.7246) | Error 0.0311(0.0340) | Error Color 0.0011(0.0007) |Steps 692(698.49) | Grad Norm 4.4090(3.9207) | Total Time 10.00(10.00)\n",
      "Iter 7360 | Time 15.2026(15.2557) | Bit/dim 0.7005(0.6961) | Xent 0.0914(0.1075) | Xent Color 0.0065(0.0058) | Loss 0.7250(0.7245) | Error 0.0322(0.0346) | Error Color 0.0011(0.0007) |Steps 698(698.29) | Grad Norm 2.4967(3.6989) | Total Time 10.00(10.00)\n",
      "Iter 7370 | Time 15.3165(15.2421) | Bit/dim 0.6951(0.6959) | Xent 0.0921(0.1073) | Xent Color 0.0084(0.0058) | Loss 0.7202(0.7241) | Error 0.0289(0.0347) | Error Color 0.0011(0.0007) |Steps 692(698.62) | Grad Norm 3.0211(3.4857) | Total Time 10.00(10.00)\n",
      "Iter 7380 | Time 14.8879(15.2936) | Bit/dim 0.7000(0.6956) | Xent 0.0879(0.1083) | Xent Color 0.0049(0.0058) | Loss 0.7232(0.7241) | Error 0.0289(0.0352) | Error Color 0.0000(0.0007) |Steps 698(697.99) | Grad Norm 2.3051(3.3655) | Total Time 10.00(10.00)\n",
      "Iter 7390 | Time 15.1559(15.3055) | Bit/dim 0.6972(0.6965) | Xent 0.0997(0.1065) | Xent Color 0.0037(0.0056) | Loss 0.7231(0.7246) | Error 0.0300(0.0344) | Error Color 0.0000(0.0006) |Steps 698(698.91) | Grad Norm 3.3703(3.3144) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 87.4725, Epoch Time 1116.6832(1063.0370), Bit/dim 0.6937(best: 0.6942), Xent 0.0536, Xent Color 0.0005. Loss 0.7072, Error 0.0191(best: 0.0164), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7400 | Time 15.2063(15.3146) | Bit/dim 0.6897(0.6957) | Xent 0.0868(0.1051) | Xent Color 0.0061(0.0056) | Loss 0.7129(0.7233) | Error 0.0333(0.0342) | Error Color 0.0000(0.0005) |Steps 710(699.37) | Grad Norm 4.7905(3.5451) | Total Time 10.00(10.00)\n",
      "Iter 7410 | Time 15.7181(15.2736) | Bit/dim 0.6969(0.6954) | Xent 0.0957(0.1059) | Xent Color 0.0047(0.0055) | Loss 0.7220(0.7232) | Error 0.0289(0.0339) | Error Color 0.0000(0.0005) |Steps 710(699.36) | Grad Norm 5.4485(3.6519) | Total Time 10.00(10.00)\n",
      "Iter 7420 | Time 14.8096(15.2674) | Bit/dim 0.6898(0.6950) | Xent 0.1091(0.1054) | Xent Color 0.0057(0.0057) | Loss 0.7185(0.7228) | Error 0.0289(0.0333) | Error Color 0.0000(0.0007) |Steps 698(698.87) | Grad Norm 4.4008(3.8235) | Total Time 10.00(10.00)\n",
      "Iter 7430 | Time 15.4272(15.2594) | Bit/dim 0.6935(0.6956) | Xent 0.1007(0.1070) | Xent Color 0.0072(0.0058) | Loss 0.7205(0.7237) | Error 0.0367(0.0341) | Error Color 0.0000(0.0006) |Steps 698(698.45) | Grad Norm 2.6242(4.1346) | Total Time 10.00(10.00)\n",
      "Iter 7440 | Time 15.4061(15.2490) | Bit/dim 0.7030(0.6954) | Xent 0.1010(0.1085) | Xent Color 0.0048(0.0057) | Loss 0.7295(0.7240) | Error 0.0378(0.0344) | Error Color 0.0000(0.0006) |Steps 698(698.49) | Grad Norm 2.1500(3.6277) | Total Time 10.00(10.00)\n",
      "Iter 7450 | Time 15.7957(15.2725) | Bit/dim 0.6951(0.6943) | Xent 0.1289(0.1088) | Xent Color 0.0043(0.0057) | Loss 0.7284(0.7230) | Error 0.0311(0.0340) | Error Color 0.0011(0.0007) |Steps 710(699.13) | Grad Norm 2.5580(3.4342) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 89.7249, Epoch Time 1118.5484(1064.7023), Bit/dim 0.6925(best: 0.6937), Xent 0.0527, Xent Color 0.0005. Loss 0.7058, Error 0.0171(best: 0.0164), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7460 | Time 15.0972(15.2817) | Bit/dim 0.6974(0.6945) | Xent 0.0779(0.1099) | Xent Color 0.0058(0.0056) | Loss 0.7183(0.7234) | Error 0.0244(0.0349) | Error Color 0.0000(0.0007) |Steps 692(699.56) | Grad Norm 5.1031(3.5227) | Total Time 10.00(10.00)\n",
      "Iter 7470 | Time 15.2485(15.2324) | Bit/dim 0.6864(0.6944) | Xent 0.1167(0.1114) | Xent Color 0.0044(0.0056) | Loss 0.7167(0.7237) | Error 0.0344(0.0349) | Error Color 0.0000(0.0007) |Steps 710(699.65) | Grad Norm 4.7095(3.5993) | Total Time 10.00(10.00)\n",
      "Iter 7480 | Time 15.6556(15.2710) | Bit/dim 0.6882(0.6937) | Xent 0.0875(0.1082) | Xent Color 0.0065(0.0056) | Loss 0.7117(0.7222) | Error 0.0278(0.0337) | Error Color 0.0011(0.0008) |Steps 698(698.73) | Grad Norm 3.7008(3.5996) | Total Time 10.00(10.00)\n",
      "Iter 7490 | Time 15.3290(15.2793) | Bit/dim 0.6909(0.6936) | Xent 0.0795(0.1069) | Xent Color 0.0064(0.0056) | Loss 0.7124(0.7217) | Error 0.0256(0.0331) | Error Color 0.0011(0.0007) |Steps 698(699.64) | Grad Norm 3.9625(3.3533) | Total Time 10.00(10.00)\n",
      "Iter 7500 | Time 15.1340(15.2712) | Bit/dim 0.6909(0.6938) | Xent 0.1362(0.1076) | Xent Color 0.0041(0.0056) | Loss 0.7260(0.7221) | Error 0.0422(0.0336) | Error Color 0.0000(0.0008) |Steps 698(699.26) | Grad Norm 3.3626(3.4421) | Total Time 10.00(10.00)\n",
      "Iter 7510 | Time 15.7122(15.2949) | Bit/dim 0.6999(0.6937) | Xent 0.0999(0.1083) | Xent Color 0.0062(0.0055) | Loss 0.7264(0.7221) | Error 0.0300(0.0337) | Error Color 0.0011(0.0008) |Steps 704(700.79) | Grad Norm 3.5569(3.4482) | Total Time 10.00(10.00)\n",
      "Iter 7520 | Time 15.3007(15.3364) | Bit/dim 0.6799(0.6930) | Xent 0.1033(0.1084) | Xent Color 0.0047(0.0054) | Loss 0.7070(0.7215) | Error 0.0344(0.0338) | Error Color 0.0000(0.0007) |Steps 692(700.63) | Grad Norm 3.3889(3.3649) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 88.1843, Epoch Time 1120.2357(1066.3683), Bit/dim 0.6909(best: 0.6925), Xent 0.0548, Xent Color 0.0004. Loss 0.7047, Error 0.0163(best: 0.0164), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7530 | Time 15.3159(15.3709) | Bit/dim 0.6917(0.6928) | Xent 0.0966(0.1054) | Xent Color 0.0050(0.0054) | Loss 0.7171(0.7205) | Error 0.0267(0.0335) | Error Color 0.0000(0.0006) |Steps 698(700.58) | Grad Norm 3.5750(3.2610) | Total Time 10.00(10.00)\n",
      "Iter 7540 | Time 15.3542(15.3606) | Bit/dim 0.6991(0.6927) | Xent 0.0973(0.1031) | Xent Color 0.0055(0.0055) | Loss 0.7248(0.7198) | Error 0.0333(0.0327) | Error Color 0.0000(0.0007) |Steps 710(701.99) | Grad Norm 3.2941(3.1817) | Total Time 10.00(10.00)\n",
      "Iter 7550 | Time 14.9959(15.3762) | Bit/dim 0.6988(0.6922) | Xent 0.1133(0.1049) | Xent Color 0.0044(0.0053) | Loss 0.7282(0.7198) | Error 0.0378(0.0329) | Error Color 0.0011(0.0006) |Steps 710(702.70) | Grad Norm 5.0178(3.3498) | Total Time 10.00(10.00)\n",
      "Iter 7560 | Time 15.1961(15.3853) | Bit/dim 0.6922(0.6917) | Xent 0.1220(0.1049) | Xent Color 0.0062(0.0055) | Loss 0.7243(0.7193) | Error 0.0400(0.0327) | Error Color 0.0011(0.0007) |Steps 692(702.52) | Grad Norm 2.4491(3.2610) | Total Time 10.00(10.00)\n",
      "Iter 7570 | Time 15.3255(15.3977) | Bit/dim 0.6814(0.6916) | Xent 0.1251(0.1049) | Xent Color 0.0041(0.0056) | Loss 0.7137(0.7192) | Error 0.0378(0.0329) | Error Color 0.0000(0.0008) |Steps 698(701.54) | Grad Norm 2.2591(3.1018) | Total Time 10.00(10.00)\n",
      "Iter 7580 | Time 14.8343(15.3849) | Bit/dim 0.7005(0.6925) | Xent 0.1192(0.1055) | Xent Color 0.0060(0.0055) | Loss 0.7318(0.7202) | Error 0.0367(0.0334) | Error Color 0.0011(0.0008) |Steps 692(701.85) | Grad Norm 3.0904(3.2394) | Total Time 10.00(10.00)\n",
      "Iter 7590 | Time 15.8899(15.4492) | Bit/dim 0.6906(0.6918) | Xent 0.1036(0.1059) | Xent Color 0.0057(0.0056) | Loss 0.7180(0.7196) | Error 0.0322(0.0336) | Error Color 0.0000(0.0008) |Steps 710(701.63) | Grad Norm 5.5703(3.4259) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 87.5304, Epoch Time 1126.7767(1068.1806), Bit/dim 0.6886(best: 0.6909), Xent 0.0525, Xent Color 0.0004. Loss 0.7018, Error 0.0173(best: 0.0163), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7600 | Time 15.5588(15.4500) | Bit/dim 0.6881(0.6912) | Xent 0.1184(0.1050) | Xent Color 0.0063(0.0056) | Loss 0.7193(0.7189) | Error 0.0367(0.0336) | Error Color 0.0011(0.0007) |Steps 698(700.85) | Grad Norm 2.5450(3.3999) | Total Time 10.00(10.00)\n",
      "Iter 7610 | Time 15.3861(15.4632) | Bit/dim 0.6991(0.6917) | Xent 0.1041(0.1047) | Xent Color 0.0046(0.0054) | Loss 0.7263(0.7192) | Error 0.0389(0.0340) | Error Color 0.0000(0.0007) |Steps 698(702.22) | Grad Norm 4.8511(3.5576) | Total Time 10.00(10.00)\n",
      "Iter 7620 | Time 15.2477(15.4502) | Bit/dim 0.6851(0.6914) | Xent 0.1020(0.1052) | Xent Color 0.0054(0.0054) | Loss 0.7120(0.7190) | Error 0.0356(0.0341) | Error Color 0.0000(0.0007) |Steps 692(702.34) | Grad Norm 3.4103(3.6671) | Total Time 10.00(10.00)\n",
      "Iter 7630 | Time 15.3516(15.4852) | Bit/dim 0.6882(0.6914) | Xent 0.0899(0.1054) | Xent Color 0.0064(0.0053) | Loss 0.7123(0.7191) | Error 0.0278(0.0340) | Error Color 0.0000(0.0007) |Steps 698(703.37) | Grad Norm 3.6259(3.6861) | Total Time 10.00(10.00)\n",
      "Iter 7640 | Time 15.1074(15.4475) | Bit/dim 0.6856(0.6909) | Xent 0.1294(0.1075) | Xent Color 0.0046(0.0056) | Loss 0.7192(0.7192) | Error 0.0400(0.0343) | Error Color 0.0000(0.0008) |Steps 698(701.96) | Grad Norm 1.3292(3.4108) | Total Time 10.00(10.00)\n",
      "Iter 7650 | Time 15.3461(15.4554) | Bit/dim 0.6980(0.6915) | Xent 0.1105(0.1075) | Xent Color 0.0046(0.0054) | Loss 0.7268(0.7197) | Error 0.0322(0.0338) | Error Color 0.0011(0.0007) |Steps 704(702.29) | Grad Norm 1.8297(3.3490) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 87.2422, Epoch Time 1129.5722(1070.0223), Bit/dim 0.6902(best: 0.6886), Xent 0.0523, Xent Color 0.0004. Loss 0.7034, Error 0.0168(best: 0.0163), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7660 | Time 15.5356(15.4577) | Bit/dim 0.6967(0.6916) | Xent 0.1560(0.1096) | Xent Color 0.0047(0.0054) | Loss 0.7368(0.7204) | Error 0.0378(0.0339) | Error Color 0.0000(0.0007) |Steps 710(702.92) | Grad Norm 4.6579(3.8629) | Total Time 10.00(10.00)\n",
      "Iter 7670 | Time 15.7190(15.4767) | Bit/dim 0.6806(0.6911) | Xent 0.0905(0.1077) | Xent Color 0.0055(0.0054) | Loss 0.7046(0.7194) | Error 0.0300(0.0332) | Error Color 0.0022(0.0007) |Steps 698(702.88) | Grad Norm 3.1103(3.8616) | Total Time 10.00(10.00)\n",
      "Iter 7680 | Time 15.5685(15.4831) | Bit/dim 0.6931(0.6910) | Xent 0.0827(0.1047) | Xent Color 0.0048(0.0054) | Loss 0.7150(0.7185) | Error 0.0256(0.0325) | Error Color 0.0000(0.0006) |Steps 698(702.11) | Grad Norm 5.4616(3.9672) | Total Time 10.00(10.00)\n",
      "Iter 7690 | Time 15.6015(15.4724) | Bit/dim 0.6944(0.6915) | Xent 0.1101(0.1053) | Xent Color 0.0038(0.0056) | Loss 0.7229(0.7192) | Error 0.0378(0.0329) | Error Color 0.0000(0.0008) |Steps 722(703.24) | Grad Norm 7.4876(4.5228) | Total Time 10.00(10.00)\n",
      "Iter 7700 | Time 15.5599(15.4576) | Bit/dim 0.6844(0.6914) | Xent 0.0870(0.1056) | Xent Color 0.0049(0.0056) | Loss 0.7074(0.7192) | Error 0.0278(0.0330) | Error Color 0.0011(0.0008) |Steps 698(703.36) | Grad Norm 4.7166(4.3112) | Total Time 10.00(10.00)\n",
      "Iter 7710 | Time 15.4284(15.4538) | Bit/dim 0.6841(0.6899) | Xent 0.1159(0.1067) | Xent Color 0.0049(0.0056) | Loss 0.7143(0.7180) | Error 0.0389(0.0330) | Error Color 0.0000(0.0008) |Steps 704(702.18) | Grad Norm 3.4733(4.1895) | Total Time 10.00(10.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_2cond_nosep.py --data colormnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_colormnist_bs900_sratio_1_3th_drop_0_5_2cond_linear_nosep_run1 --resume ../experiments_published/cnf_conditional_disentangle_colormnist_bs900_sratio_1_3th_drop_0_5_2cond_linear_nosep_run1/epoch_72_checkpt.pth --seed 1 --lr 0.0001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.33333 --dropout_rate 0.5 --y_color 10 --y_class 10\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
