{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, condition_ratio=0.25, conditional=True, controlled_tol=True, conv=True, data='mnist', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_bs8K_sratio_0_25_drop_0_5_run3/epoch_365_checkpt.pth', rtol=0.0001, save='../experiments_published/cnf_conditional_disentangle_bs8K_sratio_0_25_drop_0_5_run3', seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=113.0, weight_decay=0.0, weight_y=0.5)\n",
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=392, bias=True)\n",
      "  (project_class): LinearZeros(in_features=196, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 807722\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 2556 | Time 71.3095(31.6094) | Bit/dim 1.1093(1.1133) | Xent 0.0393(0.0483) | Loss 1.1289(1.1375) | Error 0.0134(0.0148) Steps 422(421.96) | Grad Norm 4.3904(4.4572) | Total Time 10.00(10.00)\n",
      "Iter 2557 | Time 31.1910(31.5969) | Bit/dim 1.1188(1.1135) | Xent 0.0478(0.0483) | Loss 1.1427(1.1376) | Error 0.0142(0.0148) Steps 422(421.96) | Grad Norm 4.3187(4.4530) | Total Time 10.00(10.00)\n",
      "Iter 2558 | Time 30.4490(31.5624) | Bit/dim 1.1094(1.1133) | Xent 0.0526(0.0484) | Loss 1.1357(1.1376) | Error 0.0170(0.0149) Steps 416(421.78) | Grad Norm 3.3030(4.4185) | Total Time 10.00(10.00)\n",
      "Iter 2559 | Time 30.2734(31.5238) | Bit/dim 1.1103(1.1132) | Xent 0.0472(0.0484) | Loss 1.1339(1.1374) | Error 0.0148(0.0149) Steps 416(421.61) | Grad Norm 1.8176(4.3405) | Total Time 10.00(10.00)\n",
      "Iter 2560 | Time 29.3989(31.4600) | Bit/dim 1.1072(1.1131) | Xent 0.0452(0.0483) | Loss 1.1298(1.1372) | Error 0.0139(0.0149) Steps 416(421.44) | Grad Norm 0.6486(4.2297) | Total Time 10.00(10.00)\n",
      "Iter 2561 | Time 31.4240(31.4589) | Bit/dim 1.1068(1.1129) | Xent 0.0502(0.0484) | Loss 1.1319(1.1371) | Error 0.0146(0.0148) Steps 422(421.46) | Grad Norm 2.8294(4.1877) | Total Time 10.00(10.00)\n",
      "Iter 2562 | Time 30.8415(31.4404) | Bit/dim 1.1039(1.1126) | Xent 0.0472(0.0483) | Loss 1.1274(1.1368) | Error 0.0142(0.0148) Steps 416(421.29) | Grad Norm 3.9340(4.1801) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 27.1831, Epoch Time 295.3959(243.1943), Bit/dim 1.1018(best: inf), Xent 0.0330, Loss 1.1183, Error 0.0105(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2563 | Time 31.6570(31.4469) | Bit/dim 1.1045(1.1124) | Xent 0.0452(0.0482) | Loss 1.1271(1.1365) | Error 0.0144(0.0148) Steps 422(421.31) | Grad Norm 3.8768(4.1710) | Total Time 10.00(10.00)\n",
      "Iter 2564 | Time 30.8121(31.4279) | Bit/dim 1.1087(1.1123) | Xent 0.0505(0.0483) | Loss 1.1340(1.1364) | Error 0.0155(0.0148) Steps 416(421.15) | Grad Norm 2.4082(4.1181) | Total Time 10.00(10.00)\n",
      "Iter 2565 | Time 29.3714(31.3662) | Bit/dim 1.1050(1.1120) | Xent 0.0471(0.0483) | Loss 1.1286(1.1362) | Error 0.0144(0.0148) Steps 416(421.00) | Grad Norm 0.4719(4.0087) | Total Time 10.00(10.00)\n",
      "Iter 2566 | Time 30.4651(31.3391) | Bit/dim 1.1075(1.1119) | Xent 0.0482(0.0483) | Loss 1.1316(1.1360) | Error 0.0146(0.0148) Steps 416(420.85) | Grad Norm 1.2494(3.9260) | Total Time 10.00(10.00)\n",
      "Iter 2567 | Time 29.8029(31.2930) | Bit/dim 1.1149(1.1120) | Xent 0.0478(0.0482) | Loss 1.1389(1.1361) | Error 0.0142(0.0148) Steps 416(420.70) | Grad Norm 2.4231(3.8809) | Total Time 10.00(10.00)\n",
      "Iter 2568 | Time 29.6530(31.2438) | Bit/dim 1.1047(1.1118) | Xent 0.0490(0.0483) | Loss 1.1292(1.1359) | Error 0.0154(0.0148) Steps 416(420.56) | Grad Norm 2.6222(3.8431) | Total Time 10.00(10.00)\n",
      "Iter 2569 | Time 30.7276(31.2284) | Bit/dim 1.1030(1.1115) | Xent 0.0385(0.0480) | Loss 1.1223(1.1355) | Error 0.0111(0.0147) Steps 422(420.61) | Grad Norm 2.5949(3.8057) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 16.1252, Epoch Time 241.4842(243.1430), Bit/dim 1.1017(best: 1.1018), Xent 0.0353, Loss 1.1194, Error 0.0103(best: 0.0105)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2570 | Time 31.0511(31.2230) | Bit/dim 1.1061(1.1113) | Xent 0.0429(0.0478) | Loss 1.1275(1.1353) | Error 0.0136(0.0147) Steps 416(420.47) | Grad Norm 1.4851(3.7360) | Total Time 10.00(10.00)\n",
      "Iter 2571 | Time 30.2840(31.1949) | Bit/dim 1.1042(1.1111) | Xent 0.0431(0.0477) | Loss 1.1258(1.1350) | Error 0.0138(0.0146) Steps 416(420.33) | Grad Norm 0.3512(3.6345) | Total Time 10.00(10.00)\n",
      "Iter 2572 | Time 29.7166(31.1505) | Bit/dim 1.1038(1.1109) | Xent 0.0512(0.0478) | Loss 1.1295(1.1348) | Error 0.0159(0.0147) Steps 416(420.20) | Grad Norm 1.1823(3.5609) | Total Time 10.00(10.00)\n",
      "Iter 2573 | Time 31.5111(31.1613) | Bit/dim 1.1084(1.1108) | Xent 0.0549(0.0480) | Loss 1.1359(1.1348) | Error 0.0161(0.0147) Steps 416(420.08) | Grad Norm 2.0685(3.5162) | Total Time 10.00(10.00)\n",
      "Iter 2574 | Time 29.7405(31.1187) | Bit/dim 1.1032(1.1106) | Xent 0.0425(0.0478) | Loss 1.1245(1.1345) | Error 0.0138(0.0147) Steps 416(419.96) | Grad Norm 2.2550(3.4783) | Total Time 10.00(10.00)\n",
      "Iter 2575 | Time 29.5670(31.0722) | Bit/dim 1.1057(1.1105) | Xent 0.0407(0.0476) | Loss 1.1260(1.1343) | Error 0.0124(0.0146) Steps 416(419.84) | Grad Norm 1.7669(3.4270) | Total Time 10.00(10.00)\n",
      "Iter 2576 | Time 29.7963(31.0339) | Bit/dim 1.1079(1.1104) | Xent 0.0464(0.0476) | Loss 1.1312(1.1342) | Error 0.0145(0.0146) Steps 416(419.72) | Grad Norm 0.8402(3.3494) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 16.2983, Epoch Time 241.1006(243.0817), Bit/dim 1.1002(best: 1.1017), Xent 0.0335, Loss 1.1170, Error 0.0095(best: 0.0103)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2577 | Time 31.0791(31.0352) | Bit/dim 1.1074(1.1103) | Xent 0.0444(0.0475) | Loss 1.1296(1.1340) | Error 0.0136(0.0146) Steps 416(419.61) | Grad Norm 0.3747(3.2601) | Total Time 10.00(10.00)\n",
      "Iter 2578 | Time 30.0563(31.0059) | Bit/dim 1.1092(1.1103) | Xent 0.0487(0.0475) | Loss 1.1335(1.1340) | Error 0.0165(0.0146) Steps 416(419.50) | Grad Norm 1.1806(3.1978) | Total Time 10.00(10.00)\n",
      "Iter 2579 | Time 29.6970(30.9666) | Bit/dim 1.1038(1.1101) | Xent 0.0508(0.0476) | Loss 1.1292(1.1339) | Error 0.0156(0.0147) Steps 416(419.40) | Grad Norm 1.5450(3.1482) | Total Time 10.00(10.00)\n",
      "Iter 2580 | Time 29.9578(30.9363) | Bit/dim 1.1030(1.1099) | Xent 0.0437(0.0475) | Loss 1.1248(1.1336) | Error 0.0142(0.0147) Steps 416(419.29) | Grad Norm 1.6478(3.1032) | Total Time 10.00(10.00)\n",
      "Iter 2581 | Time 29.4313(30.8912) | Bit/dim 1.1072(1.1098) | Xent 0.0471(0.0475) | Loss 1.1307(1.1335) | Error 0.0159(0.0147) Steps 416(419.20) | Grad Norm 1.0035(3.0402) | Total Time 10.00(10.00)\n",
      "Iter 2582 | Time 29.9808(30.8639) | Bit/dim 1.1018(1.1095) | Xent 0.0347(0.0471) | Loss 1.1192(1.1331) | Error 0.0108(0.0146) Steps 416(419.10) | Grad Norm 0.4478(2.9624) | Total Time 10.00(10.00)\n",
      "Iter 2583 | Time 29.8945(30.8348) | Bit/dim 1.1106(1.1096) | Xent 0.0434(0.0470) | Loss 1.1323(1.1331) | Error 0.0148(0.0146) Steps 416(419.01) | Grad Norm 0.4331(2.8865) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 16.3486, Epoch Time 238.8619(242.9551), Bit/dim 1.1001(best: 1.1002), Xent 0.0321, Loss 1.1161, Error 0.0101(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2584 | Time 29.7981(30.8037) | Bit/dim 1.1052(1.1094) | Xent 0.0451(0.0469) | Loss 1.1278(1.1329) | Error 0.0130(0.0145) Steps 416(418.92) | Grad Norm 1.0648(2.8319) | Total Time 10.00(10.00)\n",
      "Iter 2585 | Time 29.5665(30.7666) | Bit/dim 1.1068(1.1094) | Xent 0.0432(0.0468) | Loss 1.1284(1.1328) | Error 0.0136(0.0145) Steps 416(418.83) | Grad Norm 1.3858(2.7885) | Total Time 10.00(10.00)\n",
      "Iter 2586 | Time 30.5050(30.7587) | Bit/dim 1.1095(1.1094) | Xent 0.0538(0.0470) | Loss 1.1364(1.1329) | Error 0.0162(0.0146) Steps 416(418.74) | Grad Norm 1.2015(2.7409) | Total Time 10.00(10.00)\n",
      "Iter 2587 | Time 30.4891(30.7506) | Bit/dim 1.0996(1.1091) | Xent 0.0470(0.0470) | Loss 1.1231(1.1326) | Error 0.0139(0.0145) Steps 416(418.66) | Grad Norm 0.6206(2.6773) | Total Time 10.00(10.00)\n",
      "Iter 2588 | Time 30.0675(30.7301) | Bit/dim 1.1061(1.1090) | Xent 0.0449(0.0470) | Loss 1.1285(1.1325) | Error 0.0145(0.0145) Steps 416(418.58) | Grad Norm 0.3405(2.6072) | Total Time 10.00(10.00)\n",
      "Iter 2589 | Time 30.5745(30.7255) | Bit/dim 1.1100(1.1090) | Xent 0.0475(0.0470) | Loss 1.1337(1.1325) | Error 0.0139(0.0145) Steps 416(418.50) | Grad Norm 0.5212(2.5446) | Total Time 10.00(10.00)\n",
      "Iter 2590 | Time 29.8921(30.7005) | Bit/dim 1.1048(1.1089) | Xent 0.0499(0.0471) | Loss 1.1298(1.1324) | Error 0.0136(0.0145) Steps 416(418.43) | Grad Norm 0.8091(2.4925) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 16.3371, Epoch Time 239.5189(242.8520), Bit/dim 1.1000(best: 1.1001), Xent 0.0344, Loss 1.1172, Error 0.0107(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2591 | Time 29.5537(30.6661) | Bit/dim 1.1061(1.1088) | Xent 0.0446(0.0470) | Loss 1.1284(1.1323) | Error 0.0134(0.0145) Steps 416(418.36) | Grad Norm 0.7704(2.4409) | Total Time 10.00(10.00)\n",
      "Iter 2592 | Time 29.8823(30.6426) | Bit/dim 1.1088(1.1088) | Xent 0.0434(0.0469) | Loss 1.1305(1.1322) | Error 0.0122(0.0144) Steps 416(418.29) | Grad Norm 0.7021(2.3887) | Total Time 10.00(10.00)\n",
      "Iter 2593 | Time 30.5801(30.6407) | Bit/dim 1.1028(1.1086) | Xent 0.0494(0.0470) | Loss 1.1274(1.1321) | Error 0.0152(0.0144) Steps 416(418.22) | Grad Norm 0.3562(2.3277) | Total Time 10.00(10.00)\n",
      "Iter 2594 | Time 30.5815(30.6389) | Bit/dim 1.1039(1.1085) | Xent 0.0496(0.0470) | Loss 1.1287(1.1320) | Error 0.0160(0.0145) Steps 416(418.15) | Grad Norm 0.2995(2.2669) | Total Time 10.00(10.00)\n",
      "Iter 2595 | Time 29.8945(30.6166) | Bit/dim 1.1029(1.1083) | Xent 0.0483(0.0471) | Loss 1.1270(1.1319) | Error 0.0138(0.0144) Steps 416(418.09) | Grad Norm 0.5528(2.2155) | Total Time 10.00(10.00)\n",
      "Iter 2596 | Time 29.9104(30.5954) | Bit/dim 1.1092(1.1083) | Xent 0.0479(0.0471) | Loss 1.1331(1.1319) | Error 0.0151(0.0145) Steps 416(418.02) | Grad Norm 0.8173(2.1735) | Total Time 10.00(10.00)\n",
      "Iter 2597 | Time 30.1487(30.5820) | Bit/dim 1.1037(1.1082) | Xent 0.0436(0.0470) | Loss 1.1255(1.1317) | Error 0.0134(0.0144) Steps 416(417.96) | Grad Norm 0.6012(2.1263) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 16.4752, Epoch Time 239.8260(242.7613), Bit/dim 1.0998(best: 1.1000), Xent 0.0325, Loss 1.1160, Error 0.0097(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2598 | Time 29.2265(30.5413) | Bit/dim 1.1002(1.1080) | Xent 0.0445(0.0469) | Loss 1.1224(1.1314) | Error 0.0119(0.0144) Steps 416(417.90) | Grad Norm 0.3120(2.0719) | Total Time 10.00(10.00)\n",
      "Iter 2599 | Time 29.4716(30.5092) | Bit/dim 1.1038(1.1078) | Xent 0.0413(0.0468) | Loss 1.1244(1.1312) | Error 0.0140(0.0143) Steps 416(417.85) | Grad Norm 0.2877(2.0184) | Total Time 10.00(10.00)\n",
      "Iter 2600 | Time 29.5937(30.4818) | Bit/dim 1.1038(1.1077) | Xent 0.0491(0.0468) | Loss 1.1283(1.1311) | Error 0.0152(0.0144) Steps 416(417.79) | Grad Norm 0.4471(1.9712) | Total Time 10.00(10.00)\n",
      "Iter 2601 | Time 29.7666(30.4603) | Bit/dim 1.1087(1.1077) | Xent 0.0408(0.0466) | Loss 1.1291(1.1311) | Error 0.0139(0.0144) Steps 416(417.74) | Grad Norm 0.5578(1.9288) | Total Time 10.00(10.00)\n",
      "Iter 2602 | Time 29.3510(30.4270) | Bit/dim 1.1108(1.1078) | Xent 0.0406(0.0465) | Loss 1.1311(1.1311) | Error 0.0132(0.0143) Steps 416(417.69) | Grad Norm 0.6554(1.8906) | Total Time 10.00(10.00)\n",
      "Iter 2603 | Time 29.6104(30.4025) | Bit/dim 1.1091(1.1079) | Xent 0.0486(0.0465) | Loss 1.1333(1.1311) | Error 0.0146(0.0143) Steps 416(417.64) | Grad Norm 0.3725(1.8451) | Total Time 10.00(10.00)\n",
      "Iter 2604 | Time 29.7745(30.3837) | Bit/dim 1.1022(1.1077) | Xent 0.0508(0.0467) | Loss 1.1276(1.1310) | Error 0.0159(0.0144) Steps 416(417.59) | Grad Norm 0.2564(1.7974) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 16.7610, Epoch Time 236.3291(242.5683), Bit/dim 1.1002(best: 1.0998), Xent 0.0330, Loss 1.1167, Error 0.0102(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2605 | Time 30.4268(30.3850) | Bit/dim 1.1032(1.1076) | Xent 0.0411(0.0465) | Loss 1.1238(1.1308) | Error 0.0136(0.0144) Steps 416(417.54) | Grad Norm 0.4041(1.7556) | Total Time 10.00(10.00)\n",
      "Iter 2606 | Time 30.0088(30.3737) | Bit/dim 1.1054(1.1075) | Xent 0.0417(0.0463) | Loss 1.1262(1.1307) | Error 0.0139(0.0143) Steps 416(417.49) | Grad Norm 0.3378(1.7131) | Total Time 10.00(10.00)\n",
      "Iter 2607 | Time 29.5628(30.3494) | Bit/dim 1.1049(1.1074) | Xent 0.0468(0.0464) | Loss 1.1283(1.1306) | Error 0.0140(0.0143) Steps 416(417.45) | Grad Norm 0.5761(1.6790) | Total Time 10.00(10.00)\n",
      "Iter 2608 | Time 30.6462(30.3583) | Bit/dim 1.1015(1.1072) | Xent 0.0475(0.0464) | Loss 1.1253(1.1304) | Error 0.0150(0.0144) Steps 416(417.40) | Grad Norm 0.3920(1.6404) | Total Time 10.00(10.00)\n",
      "Iter 2609 | Time 30.2539(30.3552) | Bit/dim 1.1065(1.1072) | Xent 0.0434(0.0463) | Loss 1.1282(1.1304) | Error 0.0140(0.0143) Steps 416(417.36) | Grad Norm 0.2453(1.5985) | Total Time 10.00(10.00)\n",
      "Iter 2610 | Time 31.0668(30.3765) | Bit/dim 1.1070(1.1072) | Xent 0.0438(0.0462) | Loss 1.1289(1.1303) | Error 0.0134(0.0143) Steps 416(417.32) | Grad Norm 0.2649(1.5585) | Total Time 10.00(10.00)\n",
      "Iter 2611 | Time 29.8645(30.3611) | Bit/dim 1.1053(1.1072) | Xent 0.0473(0.0463) | Loss 1.1289(1.1303) | Error 0.0150(0.0143) Steps 416(417.28) | Grad Norm 0.3627(1.5226) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 16.0155, Epoch Time 240.4639(242.5052), Bit/dim 1.0999(best: 1.0998), Xent 0.0336, Loss 1.1166, Error 0.0106(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2612 | Time 30.2307(30.3572) | Bit/dim 1.1012(1.1070) | Xent 0.0528(0.0465) | Loss 1.1276(1.1302) | Error 0.0148(0.0143) Steps 416(417.24) | Grad Norm 0.4391(1.4901) | Total Time 10.00(10.00)\n",
      "Iter 2613 | Time 30.0383(30.3477) | Bit/dim 1.1068(1.1070) | Xent 0.0473(0.0465) | Loss 1.1304(1.1302) | Error 0.0148(0.0144) Steps 416(417.21) | Grad Norm 0.4275(1.4583) | Total Time 10.00(10.00)\n",
      "Iter 2614 | Time 30.7834(30.3607) | Bit/dim 1.1072(1.1070) | Xent 0.0441(0.0464) | Loss 1.1292(1.1302) | Error 0.0131(0.0143) Steps 416(417.17) | Grad Norm 0.2857(1.4231) | Total Time 10.00(10.00)\n",
      "Iter 2615 | Time 30.9103(30.3772) | Bit/dim 1.1086(1.1070) | Xent 0.0495(0.0465) | Loss 1.1333(1.1303) | Error 0.0134(0.0143) Steps 416(417.13) | Grad Norm 0.2587(1.3881) | Total Time 10.00(10.00)\n",
      "Iter 2616 | Time 29.6207(30.3545) | Bit/dim 1.1015(1.1069) | Xent 0.0425(0.0464) | Loss 1.1228(1.1300) | Error 0.0144(0.0143) Steps 416(417.10) | Grad Norm 0.3037(1.3556) | Total Time 10.00(10.00)\n",
      "Iter 2617 | Time 29.8213(30.3385) | Bit/dim 1.1063(1.1068) | Xent 0.0437(0.0463) | Loss 1.1281(1.1300) | Error 0.0140(0.0143) Steps 416(417.07) | Grad Norm 0.2870(1.3236) | Total Time 10.00(10.00)\n",
      "Iter 2618 | Time 31.1984(30.3643) | Bit/dim 1.1036(1.1067) | Xent 0.0413(0.0462) | Loss 1.1242(1.1298) | Error 0.0118(0.0142) Steps 416(417.04) | Grad Norm 0.2845(1.2924) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 16.7105, Epoch Time 241.8536(242.4856), Bit/dim 1.0997(best: 1.0998), Xent 0.0336, Loss 1.1165, Error 0.0103(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2619 | Time 30.7633(30.3763) | Bit/dim 1.0998(1.1065) | Xent 0.0421(0.0460) | Loss 1.1209(1.1295) | Error 0.0135(0.0142) Steps 416(417.00) | Grad Norm 0.2785(1.2620) | Total Time 10.00(10.00)\n",
      "Iter 2620 | Time 29.7992(30.3590) | Bit/dim 1.1033(1.1064) | Xent 0.0448(0.0460) | Loss 1.1257(1.1294) | Error 0.0144(0.0142) Steps 416(416.97) | Grad Norm 0.1942(1.2299) | Total Time 10.00(10.00)\n",
      "Iter 2621 | Time 29.8397(30.3434) | Bit/dim 1.1009(1.1063) | Xent 0.0445(0.0460) | Loss 1.1232(1.1292) | Error 0.0132(0.0142) Steps 416(416.95) | Grad Norm 0.1733(1.1982) | Total Time 10.00(10.00)\n",
      "Iter 2622 | Time 29.7058(30.3243) | Bit/dim 1.1074(1.1063) | Xent 0.0370(0.0457) | Loss 1.1259(1.1291) | Error 0.0120(0.0141) Steps 422(417.10) | Grad Norm 0.2562(1.1700) | Total Time 10.00(10.00)\n",
      "Iter 2623 | Time 30.5995(30.3325) | Bit/dim 1.1054(1.1063) | Xent 0.0454(0.0457) | Loss 1.1281(1.1291) | Error 0.0129(0.0141) Steps 416(417.06) | Grad Norm 0.2511(1.1424) | Total Time 10.00(10.00)\n",
      "Iter 2624 | Time 29.8005(30.3166) | Bit/dim 1.1062(1.1063) | Xent 0.0506(0.0458) | Loss 1.1315(1.1292) | Error 0.0156(0.0141) Steps 422(417.21) | Grad Norm 0.3419(1.1184) | Total Time 10.00(10.00)\n",
      "Iter 2625 | Time 29.7368(30.2992) | Bit/dim 1.1035(1.1062) | Xent 0.0438(0.0458) | Loss 1.1254(1.1291) | Error 0.0151(0.0141) Steps 422(417.36) | Grad Norm 0.1661(1.0898) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 16.4798, Epoch Time 239.2250(242.3878), Bit/dim 1.0994(best: 1.0997), Xent 0.0331, Loss 1.1159, Error 0.0094(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2626 | Time 31.2964(30.3291) | Bit/dim 1.1076(1.1062) | Xent 0.0451(0.0457) | Loss 1.1301(1.1291) | Error 0.0141(0.0141) Steps 440(418.03) | Grad Norm 0.2898(1.0658) | Total Time 10.00(10.00)\n",
      "Iter 2627 | Time 30.5808(30.3366) | Bit/dim 1.1104(1.1064) | Xent 0.0466(0.0458) | Loss 1.1338(1.1292) | Error 0.0142(0.0141) Steps 422(418.15) | Grad Norm 0.3816(1.0453) | Total Time 10.00(10.00)\n",
      "Iter 2628 | Time 29.4118(30.3089) | Bit/dim 1.1045(1.1063) | Xent 0.0416(0.0456) | Loss 1.1253(1.1291) | Error 0.0124(0.0141) Steps 422(418.27) | Grad Norm 0.1635(1.0188) | Total Time 10.00(10.00)\n",
      "Iter 2629 | Time 29.5724(30.2868) | Bit/dim 1.1025(1.1062) | Xent 0.0468(0.0457) | Loss 1.1259(1.1290) | Error 0.0160(0.0141) Steps 422(418.38) | Grad Norm 0.1837(0.9938) | Total Time 10.00(10.00)\n",
      "Iter 2630 | Time 30.0028(30.2783) | Bit/dim 1.1067(1.1062) | Xent 0.0470(0.0457) | Loss 1.1302(1.1291) | Error 0.0149(0.0142) Steps 422(418.49) | Grad Norm 0.2791(0.9724) | Total Time 10.00(10.00)\n",
      "Iter 2631 | Time 30.8595(30.2957) | Bit/dim 1.1020(1.1061) | Xent 0.0549(0.0460) | Loss 1.1295(1.1291) | Error 0.0162(0.0142) Steps 422(418.59) | Grad Norm 0.3837(0.9547) | Total Time 10.00(10.00)\n",
      "Iter 2632 | Time 30.0330(30.2878) | Bit/dim 1.1038(1.1060) | Xent 0.0496(0.0461) | Loss 1.1286(1.1291) | Error 0.0151(0.0143) Steps 422(418.70) | Grad Norm 0.2219(0.9327) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 16.7427, Epoch Time 241.0445(242.3475), Bit/dim 1.0993(best: 1.0994), Xent 0.0341, Loss 1.1163, Error 0.0109(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2633 | Time 29.8946(30.2760) | Bit/dim 1.1043(1.1060) | Xent 0.0454(0.0461) | Loss 1.1270(1.1290) | Error 0.0140(0.0143) Steps 422(418.80) | Grad Norm 0.1637(0.9096) | Total Time 10.00(10.00)\n",
      "Iter 2634 | Time 30.1435(30.2721) | Bit/dim 1.1067(1.1060) | Xent 0.0440(0.0460) | Loss 1.1287(1.1290) | Error 0.0130(0.0142) Steps 434(419.25) | Grad Norm 0.2258(0.8891) | Total Time 10.00(10.00)\n",
      "Iter 2635 | Time 29.9592(30.2627) | Bit/dim 1.1031(1.1059) | Xent 0.0471(0.0461) | Loss 1.1267(1.1289) | Error 0.0144(0.0142) Steps 422(419.33) | Grad Norm 0.2157(0.8689) | Total Time 10.00(10.00)\n",
      "Iter 2636 | Time 30.8848(30.2813) | Bit/dim 1.1031(1.1058) | Xent 0.0451(0.0460) | Loss 1.1256(1.1288) | Error 0.0125(0.0142) Steps 422(419.41) | Grad Norm 0.2216(0.8495) | Total Time 10.00(10.00)\n",
      "Iter 2637 | Time 30.2183(30.2795) | Bit/dim 1.1028(1.1057) | Xent 0.0425(0.0459) | Loss 1.1240(1.1287) | Error 0.0132(0.0141) Steps 422(419.49) | Grad Norm 0.3420(0.8343) | Total Time 10.00(10.00)\n",
      "Iter 2638 | Time 29.6587(30.2608) | Bit/dim 1.1015(1.1056) | Xent 0.0382(0.0457) | Loss 1.1207(1.1284) | Error 0.0119(0.0141) Steps 422(419.57) | Grad Norm 0.3626(0.8201) | Total Time 10.00(10.00)\n",
      "Iter 2639 | Time 30.5784(30.2704) | Bit/dim 1.1094(1.1057) | Xent 0.0540(0.0459) | Loss 1.1365(1.1287) | Error 0.0179(0.0142) Steps 422(419.64) | Grad Norm 0.3718(0.8067) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 16.5981, Epoch Time 240.8203(242.3017), Bit/dim 1.0997(best: 1.0993), Xent 0.0357, Loss 1.1175, Error 0.0112(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2640 | Time 30.0177(30.2628) | Bit/dim 1.1078(1.1058) | Xent 0.0406(0.0458) | Loss 1.1282(1.1287) | Error 0.0122(0.0141) Steps 422(419.71) | Grad Norm 0.2943(0.7913) | Total Time 10.00(10.00)\n",
      "Iter 2641 | Time 29.7804(30.2483) | Bit/dim 1.1061(1.1058) | Xent 0.0446(0.0457) | Loss 1.1284(1.1287) | Error 0.0132(0.0141) Steps 422(419.78) | Grad Norm 0.2002(0.7736) | Total Time 10.00(10.00)\n",
      "Iter 2642 | Time 30.4041(30.2530) | Bit/dim 1.1031(1.1057) | Xent 0.0426(0.0456) | Loss 1.1245(1.1285) | Error 0.0139(0.0141) Steps 422(419.85) | Grad Norm 0.3235(0.7601) | Total Time 10.00(10.00)\n",
      "Iter 2643 | Time 29.9468(30.2438) | Bit/dim 1.0948(1.1054) | Xent 0.0451(0.0456) | Loss 1.1173(1.1282) | Error 0.0139(0.0141) Steps 422(419.91) | Grad Norm 0.3836(0.7488) | Total Time 10.00(10.00)\n",
      "Iter 2644 | Time 30.1432(30.2408) | Bit/dim 1.1104(1.1055) | Xent 0.0405(0.0455) | Loss 1.1306(1.1283) | Error 0.0111(0.0140) Steps 422(419.97) | Grad Norm 0.2575(0.7340) | Total Time 10.00(10.00)\n",
      "Iter 2645 | Time 29.8505(30.2291) | Bit/dim 1.1038(1.1055) | Xent 0.0488(0.0456) | Loss 1.1282(1.1283) | Error 0.0155(0.0140) Steps 422(420.03) | Grad Norm 0.2743(0.7202) | Total Time 10.00(10.00)\n",
      "Iter 2646 | Time 29.5616(30.2090) | Bit/dim 1.1097(1.1056) | Xent 0.0515(0.0458) | Loss 1.1354(1.1285) | Error 0.0155(0.0141) Steps 422(420.09) | Grad Norm 0.2711(0.7068) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 16.6112, Epoch Time 239.0576(242.2044), Bit/dim 1.0993(best: 1.0993), Xent 0.0357, Loss 1.1172, Error 0.0112(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2647 | Time 29.9428(30.2011) | Bit/dim 1.1036(1.1055) | Xent 0.0486(0.0458) | Loss 1.1279(1.1285) | Error 0.0138(0.0141) Steps 422(420.15) | Grad Norm 0.2346(0.6926) | Total Time 10.00(10.00)\n",
      "Iter 2648 | Time 29.6080(30.1833) | Bit/dim 1.1063(1.1056) | Xent 0.0529(0.0461) | Loss 1.1328(1.1286) | Error 0.0161(0.0141) Steps 422(420.21) | Grad Norm 0.3544(0.6825) | Total Time 10.00(10.00)\n",
      "Iter 2649 | Time 29.3473(30.1582) | Bit/dim 1.1047(1.1055) | Xent 0.0526(0.0462) | Loss 1.1309(1.1287) | Error 0.0162(0.0142) Steps 422(420.26) | Grad Norm 0.3079(0.6712) | Total Time 10.00(10.00)\n",
      "Iter 2650 | Time 30.7734(30.1766) | Bit/dim 1.1050(1.1055) | Xent 0.0461(0.0462) | Loss 1.1280(1.1286) | Error 0.0139(0.0142) Steps 440(420.85) | Grad Norm 0.3165(0.6606) | Total Time 10.00(10.00)\n",
      "Iter 2651 | Time 30.4511(30.1849) | Bit/dim 1.1024(1.1054) | Xent 0.0465(0.0463) | Loss 1.1257(1.1286) | Error 0.0150(0.0142) Steps 422(420.89) | Grad Norm 0.2402(0.6480) | Total Time 10.00(10.00)\n",
      "Iter 2652 | Time 31.8458(30.2347) | Bit/dim 1.1040(1.1054) | Xent 0.0489(0.0463) | Loss 1.1285(1.1286) | Error 0.0159(0.0143) Steps 422(420.92) | Grad Norm 0.2196(0.6351) | Total Time 10.00(10.00)\n",
      "Iter 2653 | Time 30.2496(30.2352) | Bit/dim 1.1076(1.1055) | Xent 0.0434(0.0462) | Loss 1.1293(1.1286) | Error 0.0132(0.0142) Steps 422(420.95) | Grad Norm 0.3040(0.6252) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 16.8667, Epoch Time 241.7642(242.1912), Bit/dim 1.0997(best: 1.0993), Xent 0.0320, Loss 1.1157, Error 0.0103(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2654 | Time 29.8157(30.2226) | Bit/dim 1.1056(1.1055) | Xent 0.0492(0.0463) | Loss 1.1303(1.1286) | Error 0.0156(0.0143) Steps 422(420.98) | Grad Norm 0.2328(0.6134) | Total Time 10.00(10.00)\n",
      "Iter 2655 | Time 29.4502(30.1994) | Bit/dim 1.1023(1.1054) | Xent 0.0446(0.0463) | Loss 1.1245(1.1285) | Error 0.0126(0.0142) Steps 422(421.01) | Grad Norm 0.2589(0.6028) | Total Time 10.00(10.00)\n",
      "Iter 2656 | Time 30.0128(30.1938) | Bit/dim 1.1058(1.1054) | Xent 0.0435(0.0462) | Loss 1.1276(1.1285) | Error 0.0129(0.0142) Steps 422(421.04) | Grad Norm 0.2009(0.5907) | Total Time 10.00(10.00)\n",
      "Iter 2657 | Time 29.6892(30.1787) | Bit/dim 1.1018(1.1053) | Xent 0.0485(0.0463) | Loss 1.1260(1.1284) | Error 0.0148(0.0142) Steps 422(421.07) | Grad Norm 0.2321(0.5800) | Total Time 10.00(10.00)\n",
      "Iter 2658 | Time 29.8973(30.1702) | Bit/dim 1.1067(1.1053) | Xent 0.0463(0.0463) | Loss 1.1299(1.1284) | Error 0.0134(0.0142) Steps 422(421.10) | Grad Norm 0.2055(0.5687) | Total Time 10.00(10.00)\n",
      "Iter 2659 | Time 30.0946(30.1680) | Bit/dim 1.1070(1.1054) | Xent 0.0449(0.0462) | Loss 1.1295(1.1285) | Error 0.0128(0.0141) Steps 422(421.13) | Grad Norm 0.2047(0.5578) | Total Time 10.00(10.00)\n",
      "Iter 2660 | Time 30.4345(30.1759) | Bit/dim 1.1035(1.1053) | Xent 0.0474(0.0463) | Loss 1.1272(1.1284) | Error 0.0148(0.0142) Steps 422(421.15) | Grad Norm 0.4200(0.5537) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 16.7052, Epoch Time 239.1688(242.1005), Bit/dim 1.0997(best: 1.0993), Xent 0.0323, Loss 1.1158, Error 0.0094(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2661 | Time 29.5777(30.1580) | Bit/dim 1.1091(1.1054) | Xent 0.0468(0.0463) | Loss 1.1324(1.1286) | Error 0.0142(0.0142) Steps 422(421.18) | Grad Norm 0.2101(0.5434) | Total Time 10.00(10.00)\n",
      "Iter 2662 | Time 29.6124(30.1416) | Bit/dim 1.1036(1.1054) | Xent 0.0433(0.0462) | Loss 1.1253(1.1285) | Error 0.0139(0.0141) Steps 428(421.38) | Grad Norm 0.3379(0.5372) | Total Time 10.00(10.00)\n",
      "Iter 2663 | Time 31.0725(30.1696) | Bit/dim 1.1048(1.1053) | Xent 0.0429(0.0461) | Loss 1.1263(1.1284) | Error 0.0132(0.0141) Steps 422(421.40) | Grad Norm 0.2653(0.5290) | Total Time 10.00(10.00)\n",
      "Iter 2664 | Time 29.9025(30.1615) | Bit/dim 1.1092(1.1055) | Xent 0.0417(0.0460) | Loss 1.1300(1.1284) | Error 0.0158(0.0142) Steps 422(421.42) | Grad Norm 0.2075(0.5194) | Total Time 10.00(10.00)\n",
      "Iter 2665 | Time 30.1944(30.1625) | Bit/dim 1.1001(1.1053) | Xent 0.0471(0.0460) | Loss 1.1236(1.1283) | Error 0.0136(0.0142) Steps 422(421.44) | Grad Norm 0.2337(0.5108) | Total Time 10.00(10.00)\n",
      "Iter 2666 | Time 30.3242(30.1674) | Bit/dim 1.1019(1.1052) | Xent 0.0435(0.0459) | Loss 1.1236(1.1282) | Error 0.0139(0.0141) Steps 422(421.45) | Grad Norm 0.1996(0.5015) | Total Time 10.00(10.00)\n",
      "Iter 2667 | Time 29.7172(30.1539) | Bit/dim 1.1028(1.1051) | Xent 0.0429(0.0458) | Loss 1.1243(1.1280) | Error 0.0140(0.0141) Steps 422(421.47) | Grad Norm 0.2554(0.4941) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 16.6530, Epoch Time 240.0858(242.0400), Bit/dim 1.0996(best: 1.0993), Xent 0.0353, Loss 1.1172, Error 0.0111(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2668 | Time 29.5576(30.1360) | Bit/dim 1.1041(1.1051) | Xent 0.0482(0.0459) | Loss 1.1281(1.1280) | Error 0.0146(0.0142) Steps 422(421.49) | Grad Norm 0.3394(0.4895) | Total Time 10.00(10.00)\n",
      "Iter 2669 | Time 30.0542(30.1335) | Bit/dim 1.1040(1.1051) | Xent 0.0481(0.0460) | Loss 1.1281(1.1280) | Error 0.0149(0.0142) Steps 422(421.50) | Grad Norm 0.2732(0.4830) | Total Time 10.00(10.00)\n",
      "Iter 2670 | Time 30.0287(30.1304) | Bit/dim 1.1027(1.1050) | Xent 0.0374(0.0457) | Loss 1.1214(1.1278) | Error 0.0122(0.0141) Steps 422(421.52) | Grad Norm 0.2859(0.4771) | Total Time 10.00(10.00)\n",
      "Iter 2671 | Time 30.8679(30.1525) | Bit/dim 1.1049(1.1050) | Xent 0.0404(0.0456) | Loss 1.1251(1.1278) | Error 0.0128(0.0141) Steps 428(421.71) | Grad Norm 0.2505(0.4703) | Total Time 10.00(10.00)\n",
      "Iter 2672 | Time 31.5769(30.1952) | Bit/dim 1.1087(1.1051) | Xent 0.0422(0.0455) | Loss 1.1298(1.1278) | Error 0.0122(0.0140) Steps 422(421.72) | Grad Norm 0.3152(0.4656) | Total Time 10.00(10.00)\n",
      "Iter 2673 | Time 29.8737(30.1856) | Bit/dim 1.1071(1.1052) | Xent 0.0437(0.0454) | Loss 1.1290(1.1279) | Error 0.0126(0.0140) Steps 422(421.73) | Grad Norm 0.2878(0.4603) | Total Time 10.00(10.00)\n",
      "Iter 2674 | Time 30.9947(30.2099) | Bit/dim 1.1033(1.1051) | Xent 0.0514(0.0456) | Loss 1.1290(1.1279) | Error 0.0159(0.0140) Steps 422(421.74) | Grad Norm 0.2550(0.4541) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 16.6183, Epoch Time 242.3926(242.0506), Bit/dim 1.0991(best: 1.0993), Xent 0.0330, Loss 1.1156, Error 0.0102(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2675 | Time 29.3646(30.1845) | Bit/dim 1.1029(1.1050) | Xent 0.0474(0.0456) | Loss 1.1266(1.1279) | Error 0.0131(0.0140) Steps 422(421.74) | Grad Norm 0.2687(0.4486) | Total Time 10.00(10.00)\n",
      "Iter 2676 | Time 30.1694(30.1841) | Bit/dim 1.1049(1.1050) | Xent 0.0447(0.0456) | Loss 1.1273(1.1278) | Error 0.0138(0.0140) Steps 422(421.75) | Grad Norm 0.3344(0.4451) | Total Time 10.00(10.00)\n",
      "Iter 2677 | Time 30.0358(30.1796) | Bit/dim 1.1032(1.1050) | Xent 0.0397(0.0454) | Loss 1.1230(1.1277) | Error 0.0126(0.0140) Steps 422(421.76) | Grad Norm 0.4115(0.4441) | Total Time 10.00(10.00)\n",
      "Iter 2678 | Time 30.8658(30.2002) | Bit/dim 1.1009(1.1049) | Xent 0.0384(0.0452) | Loss 1.1201(1.1275) | Error 0.0125(0.0139) Steps 422(421.77) | Grad Norm 0.2864(0.4394) | Total Time 10.00(10.00)\n",
      "Iter 2679 | Time 30.4081(30.2064) | Bit/dim 1.1072(1.1049) | Xent 0.0457(0.0452) | Loss 1.1300(1.1275) | Error 0.0131(0.0139) Steps 422(421.77) | Grad Norm 0.2262(0.4330) | Total Time 10.00(10.00)\n",
      "Iter 2680 | Time 31.3942(30.2421) | Bit/dim 1.1037(1.1049) | Xent 0.0454(0.0452) | Loss 1.1264(1.1275) | Error 0.0151(0.0139) Steps 422(421.78) | Grad Norm 0.2394(0.4272) | Total Time 10.00(10.00)\n",
      "Iter 2681 | Time 30.4397(30.2480) | Bit/dim 1.1081(1.1050) | Xent 0.0445(0.0452) | Loss 1.1303(1.1276) | Error 0.0136(0.0139) Steps 422(421.79) | Grad Norm 0.2962(0.4233) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 16.7437, Epoch Time 242.2257(242.0559), Bit/dim 1.0987(best: 1.0991), Xent 0.0337, Loss 1.1155, Error 0.0097(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2682 | Time 29.8933(30.2374) | Bit/dim 1.1043(1.1050) | Xent 0.0524(0.0454) | Loss 1.1305(1.1277) | Error 0.0154(0.0140) Steps 422(421.79) | Grad Norm 0.3615(0.4214) | Total Time 10.00(10.00)\n",
      "Iter 2683 | Time 30.7647(30.2532) | Bit/dim 1.1026(1.1049) | Xent 0.0463(0.0455) | Loss 1.1258(1.1276) | Error 0.0139(0.0140) Steps 422(421.80) | Grad Norm 0.2429(0.4161) | Total Time 10.00(10.00)\n",
      "Iter 2684 | Time 30.5055(30.2607) | Bit/dim 1.1027(1.1048) | Xent 0.0434(0.0454) | Loss 1.1244(1.1275) | Error 0.0132(0.0139) Steps 422(421.81) | Grad Norm 0.3838(0.4151) | Total Time 10.00(10.00)\n",
      "Iter 2685 | Time 30.6161(30.2714) | Bit/dim 1.1021(1.1047) | Xent 0.0495(0.0455) | Loss 1.1268(1.1275) | Error 0.0158(0.0140) Steps 422(421.81) | Grad Norm 0.2049(0.4088) | Total Time 10.00(10.00)\n",
      "Iter 2686 | Time 31.1880(30.2989) | Bit/dim 1.1097(1.1049) | Xent 0.0463(0.0455) | Loss 1.1329(1.1277) | Error 0.0139(0.0140) Steps 422(421.82) | Grad Norm 0.3447(0.4069) | Total Time 10.00(10.00)\n",
      "Iter 2687 | Time 30.2645(30.2979) | Bit/dim 1.1058(1.1049) | Xent 0.0504(0.0457) | Loss 1.1311(1.1278) | Error 0.0156(0.0140) Steps 422(421.82) | Grad Norm 0.3083(0.4039) | Total Time 10.00(10.00)\n",
      "Iter 2688 | Time 29.8550(30.2846) | Bit/dim 1.1040(1.1049) | Xent 0.0437(0.0456) | Loss 1.1259(1.1277) | Error 0.0151(0.0141) Steps 422(421.83) | Grad Norm 0.2864(0.4004) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 16.7481, Epoch Time 242.4432(242.0675), Bit/dim 1.0992(best: 1.0987), Xent 0.0336, Loss 1.1160, Error 0.0098(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2689 | Time 30.3417(30.2863) | Bit/dim 1.1039(1.1049) | Xent 0.0422(0.0455) | Loss 1.1250(1.1276) | Error 0.0136(0.0141) Steps 422(421.83) | Grad Norm 0.2659(0.3963) | Total Time 10.00(10.00)\n",
      "Iter 2690 | Time 30.5184(30.2933) | Bit/dim 1.1071(1.1049) | Xent 0.0427(0.0454) | Loss 1.1284(1.1277) | Error 0.0125(0.0140) Steps 422(421.84) | Grad Norm 0.1831(0.3899) | Total Time 10.00(10.00)\n",
      "Iter 2691 | Time 31.4962(30.3294) | Bit/dim 1.1032(1.1049) | Xent 0.0459(0.0455) | Loss 1.1262(1.1276) | Error 0.0145(0.0140) Steps 422(421.84) | Grad Norm 0.2994(0.3872) | Total Time 10.00(10.00)\n",
      "Iter 2692 | Time 30.8376(30.3446) | Bit/dim 1.1061(1.1049) | Xent 0.0465(0.0455) | Loss 1.1294(1.1277) | Error 0.0146(0.0140) Steps 422(421.85) | Grad Norm 0.2359(0.3827) | Total Time 10.00(10.00)\n",
      "Iter 2693 | Time 30.3821(30.3457) | Bit/dim 1.1019(1.1048) | Xent 0.0545(0.0458) | Loss 1.1292(1.1277) | Error 0.0159(0.0141) Steps 440(422.39) | Grad Norm 0.2631(0.3791) | Total Time 10.00(10.00)\n",
      "Iter 2694 | Time 29.3884(30.3170) | Bit/dim 1.1044(1.1048) | Xent 0.0468(0.0458) | Loss 1.1278(1.1277) | Error 0.0139(0.0141) Steps 422(422.38) | Grad Norm 0.1977(0.3737) | Total Time 10.00(10.00)\n",
      "Iter 2695 | Time 30.2764(30.3158) | Bit/dim 1.1031(1.1048) | Xent 0.0474(0.0458) | Loss 1.1268(1.1277) | Error 0.0138(0.0141) Steps 422(422.37) | Grad Norm 0.3014(0.3715) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 17.0379, Epoch Time 242.8773(242.0918), Bit/dim 1.0988(best: 1.0987), Xent 0.0332, Loss 1.1154, Error 0.0099(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2696 | Time 31.1412(30.3405) | Bit/dim 1.1057(1.1048) | Xent 0.0476(0.0459) | Loss 1.1295(1.1277) | Error 0.0140(0.0141) Steps 440(422.90) | Grad Norm 0.2500(0.3678) | Total Time 10.00(10.00)\n",
      "Iter 2697 | Time 30.3937(30.3421) | Bit/dim 1.1068(1.1049) | Xent 0.0406(0.0457) | Loss 1.1271(1.1277) | Error 0.0139(0.0141) Steps 422(422.87) | Grad Norm 0.2786(0.3652) | Total Time 10.00(10.00)\n",
      "Iter 2698 | Time 29.6184(30.3204) | Bit/dim 1.1084(1.1050) | Xent 0.0415(0.0456) | Loss 1.1292(1.1278) | Error 0.0136(0.0141) Steps 422(422.85) | Grad Norm 0.2497(0.3617) | Total Time 10.00(10.00)\n",
      "Iter 2699 | Time 30.6614(30.3307) | Bit/dim 1.1045(1.1049) | Xent 0.0419(0.0455) | Loss 1.1255(1.1277) | Error 0.0120(0.0140) Steps 422(422.82) | Grad Norm 0.1873(0.3565) | Total Time 10.00(10.00)\n",
      "Iter 2700 | Time 29.7540(30.3134) | Bit/dim 1.1037(1.1049) | Xent 0.0476(0.0456) | Loss 1.1276(1.1277) | Error 0.0139(0.0140) Steps 422(422.80) | Grad Norm 0.2773(0.3541) | Total Time 10.00(10.00)\n",
      "Iter 2701 | Time 30.1257(30.3077) | Bit/dim 1.1025(1.1048) | Xent 0.0403(0.0454) | Loss 1.1226(1.1275) | Error 0.0129(0.0140) Steps 422(422.77) | Grad Norm 0.3881(0.3551) | Total Time 10.00(10.00)\n",
      "Iter 2702 | Time 29.9095(30.2958) | Bit/dim 1.1022(1.1048) | Xent 0.0477(0.0455) | Loss 1.1260(1.1275) | Error 0.0151(0.0140) Steps 422(422.75) | Grad Norm 0.3449(0.3548) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 16.9824, Epoch Time 241.0328(242.0600), Bit/dim 1.0987(best: 1.0987), Xent 0.0324, Loss 1.1149, Error 0.0103(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2703 | Time 30.4820(30.3014) | Bit/dim 1.1038(1.1047) | Xent 0.0449(0.0455) | Loss 1.1263(1.1275) | Error 0.0132(0.0140) Steps 422(422.73) | Grad Norm 0.2667(0.3522) | Total Time 10.00(10.00)\n",
      "Iter 2704 | Time 30.6304(30.3112) | Bit/dim 1.1025(1.1047) | Xent 0.0455(0.0455) | Loss 1.1253(1.1274) | Error 0.0136(0.0140) Steps 422(422.70) | Grad Norm 0.1762(0.3469) | Total Time 10.00(10.00)\n",
      "Iter 2705 | Time 30.5787(30.3193) | Bit/dim 1.1066(1.1047) | Xent 0.0475(0.0455) | Loss 1.1303(1.1275) | Error 0.0140(0.0140) Steps 422(422.68) | Grad Norm 0.2623(0.3443) | Total Time 10.00(10.00)\n",
      "Iter 2706 | Time 30.4755(30.3240) | Bit/dim 1.1067(1.1048) | Xent 0.0490(0.0456) | Loss 1.1313(1.1276) | Error 0.0156(0.0140) Steps 422(422.66) | Grad Norm 0.3068(0.3432) | Total Time 10.00(10.00)\n",
      "Iter 2707 | Time 30.6743(30.3345) | Bit/dim 1.1054(1.1048) | Xent 0.0431(0.0456) | Loss 1.1270(1.1276) | Error 0.0138(0.0140) Steps 422(422.64) | Grad Norm 0.5630(0.3498) | Total Time 10.00(10.00)\n",
      "Iter 2708 | Time 30.6096(30.3427) | Bit/dim 1.1083(1.1049) | Xent 0.0447(0.0455) | Loss 1.1306(1.1277) | Error 0.0140(0.0140) Steps 422(422.62) | Grad Norm 0.2513(0.3469) | Total Time 10.00(10.00)\n",
      "Iter 2709 | Time 29.9865(30.3320) | Bit/dim 1.0955(1.1046) | Xent 0.0471(0.0456) | Loss 1.1190(1.1274) | Error 0.0140(0.0140) Steps 422(422.60) | Grad Norm 0.2217(0.3431) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 17.0199, Epoch Time 243.3386(242.0984), Bit/dim 1.0997(best: 1.0987), Xent 0.0343, Loss 1.1169, Error 0.0107(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2710 | Time 30.4156(30.3345) | Bit/dim 1.1043(1.1046) | Xent 0.0404(0.0454) | Loss 1.1244(1.1273) | Error 0.0132(0.0140) Steps 422(422.59) | Grad Norm 0.1510(0.3373) | Total Time 10.00(10.00)\n",
      "Iter 2711 | Time 32.3748(30.3957) | Bit/dim 1.1041(1.1046) | Xent 0.0531(0.0456) | Loss 1.1307(1.1274) | Error 0.0151(0.0140) Steps 422(422.57) | Grad Norm 0.2667(0.3352) | Total Time 10.00(10.00)\n",
      "Iter 2712 | Time 30.2658(30.3918) | Bit/dim 1.1011(1.1045) | Xent 0.0468(0.0457) | Loss 1.1245(1.1273) | Error 0.0134(0.0140) Steps 422(422.55) | Grad Norm 0.3221(0.3348) | Total Time 10.00(10.00)\n",
      "Iter 2713 | Time 30.2934(30.3889) | Bit/dim 1.1103(1.1047) | Xent 0.0450(0.0457) | Loss 1.1328(1.1275) | Error 0.0136(0.0140) Steps 422(422.54) | Grad Norm 0.3164(0.3343) | Total Time 10.00(10.00)\n",
      "Iter 2714 | Time 30.0355(30.3783) | Bit/dim 1.1002(1.1045) | Xent 0.0461(0.0457) | Loss 1.1232(1.1274) | Error 0.0152(0.0140) Steps 422(422.52) | Grad Norm 0.1815(0.3297) | Total Time 10.00(10.00)\n",
      "Iter 2715 | Time 30.0670(30.3690) | Bit/dim 1.1033(1.1045) | Xent 0.0429(0.0456) | Loss 1.1247(1.1273) | Error 0.0121(0.0140) Steps 422(422.50) | Grad Norm 0.2663(0.3278) | Total Time 10.00(10.00)\n",
      "Iter 2716 | Time 30.6727(30.3781) | Bit/dim 1.1085(1.1046) | Xent 0.0423(0.0455) | Loss 1.1296(1.1274) | Error 0.0138(0.0140) Steps 422(422.49) | Grad Norm 0.2755(0.3262) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 16.7464, Epoch Time 243.5850(242.1430), Bit/dim 1.0989(best: 1.0987), Xent 0.0331, Loss 1.1154, Error 0.0102(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2717 | Time 30.1405(30.3709) | Bit/dim 1.1084(1.1047) | Xent 0.0415(0.0454) | Loss 1.1291(1.1274) | Error 0.0122(0.0139) Steps 422(422.47) | Grad Norm 0.2237(0.3231) | Total Time 10.00(10.00)\n",
      "Iter 2718 | Time 31.7317(30.4118) | Bit/dim 1.1013(1.1046) | Xent 0.0479(0.0454) | Loss 1.1252(1.1273) | Error 0.0142(0.0139) Steps 440(423.00) | Grad Norm 0.1986(0.3194) | Total Time 10.00(10.00)\n",
      "Iter 2719 | Time 30.9253(30.4272) | Bit/dim 1.1067(1.1047) | Xent 0.0468(0.0455) | Loss 1.1301(1.1274) | Error 0.0138(0.0139) Steps 440(423.51) | Grad Norm 0.2781(0.3182) | Total Time 10.00(10.00)\n",
      "Iter 2720 | Time 30.8172(30.4389) | Bit/dim 1.1077(1.1048) | Xent 0.0433(0.0454) | Loss 1.1294(1.1275) | Error 0.0138(0.0139) Steps 440(424.00) | Grad Norm 0.2609(0.3165) | Total Time 10.00(10.00)\n",
      "Iter 2721 | Time 31.0610(30.4575) | Bit/dim 1.1037(1.1047) | Xent 0.0422(0.0453) | Loss 1.1248(1.1274) | Error 0.0149(0.0139) Steps 422(423.94) | Grad Norm 0.3070(0.3162) | Total Time 10.00(10.00)\n",
      "Iter 2722 | Time 30.0601(30.4456) | Bit/dim 1.1092(1.1049) | Xent 0.0404(0.0452) | Loss 1.1294(1.1275) | Error 0.0118(0.0139) Steps 422(423.89) | Grad Norm 0.1657(0.3117) | Total Time 10.00(10.00)\n",
      "Iter 2723 | Time 30.3941(30.4441) | Bit/dim 1.0973(1.1046) | Xent 0.0437(0.0451) | Loss 1.1192(1.1272) | Error 0.0136(0.0139) Steps 422(423.83) | Grad Norm 0.2116(0.3087) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 17.1580, Epoch Time 245.0574(242.2304), Bit/dim 1.0986(best: 1.0987), Xent 0.0321, Loss 1.1147, Error 0.0100(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2724 | Time 30.6253(30.4495) | Bit/dim 1.1038(1.1046) | Xent 0.0443(0.0451) | Loss 1.1259(1.1272) | Error 0.0146(0.0139) Steps 422(423.77) | Grad Norm 0.2233(0.3061) | Total Time 10.00(10.00)\n",
      "Iter 2725 | Time 30.1111(30.4394) | Bit/dim 1.1010(1.1045) | Xent 0.0448(0.0451) | Loss 1.1234(1.1271) | Error 0.0130(0.0139) Steps 440(424.26) | Grad Norm 0.2255(0.3037) | Total Time 10.00(10.00)\n",
      "Iter 2726 | Time 30.8964(30.4531) | Bit/dim 1.1012(1.1044) | Xent 0.0481(0.0452) | Loss 1.1252(1.1270) | Error 0.0141(0.0139) Steps 422(424.19) | Grad Norm 0.2764(0.3029) | Total Time 10.00(10.00)\n",
      "Iter 2727 | Time 30.9148(30.4669) | Bit/dim 1.1062(1.1045) | Xent 0.0433(0.0451) | Loss 1.1278(1.1270) | Error 0.0129(0.0138) Steps 422(424.13) | Grad Norm 0.2649(0.3017) | Total Time 10.00(10.00)\n",
      "Iter 2728 | Time 30.0599(30.4547) | Bit/dim 1.1064(1.1045) | Xent 0.0435(0.0451) | Loss 1.1281(1.1271) | Error 0.0140(0.0138) Steps 422(424.06) | Grad Norm 0.2136(0.2991) | Total Time 10.00(10.00)\n",
      "Iter 2729 | Time 30.5851(30.4586) | Bit/dim 1.1069(1.1046) | Xent 0.0450(0.0451) | Loss 1.1294(1.1271) | Error 0.0138(0.0138) Steps 422(424.00) | Grad Norm 0.1891(0.2958) | Total Time 10.00(10.00)\n",
      "Iter 2730 | Time 30.6230(30.4635) | Bit/dim 1.1061(1.1046) | Xent 0.0466(0.0451) | Loss 1.1294(1.1272) | Error 0.0145(0.0139) Steps 440(424.48) | Grad Norm 0.2755(0.2952) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 17.0066, Epoch Time 243.6576(242.2732), Bit/dim 1.0987(best: 1.0986), Xent 0.0361, Loss 1.1167, Error 0.0105(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2731 | Time 30.9336(30.4777) | Bit/dim 1.1038(1.1046) | Xent 0.0494(0.0452) | Loss 1.1285(1.1272) | Error 0.0151(0.0139) Steps 440(424.95) | Grad Norm 0.2892(0.2950) | Total Time 10.00(10.00)\n",
      "Iter 2732 | Time 31.6582(30.5131) | Bit/dim 1.1099(1.1048) | Xent 0.0432(0.0452) | Loss 1.1316(1.1274) | Error 0.0124(0.0139) Steps 422(424.86) | Grad Norm 0.1985(0.2921) | Total Time 10.00(10.00)\n",
      "Iter 2733 | Time 30.0603(30.4995) | Bit/dim 1.1016(1.1047) | Xent 0.0475(0.0453) | Loss 1.1254(1.1273) | Error 0.0158(0.0139) Steps 422(424.77) | Grad Norm 0.2319(0.2903) | Total Time 10.00(10.00)\n",
      "Iter 2734 | Time 30.6210(30.5031) | Bit/dim 1.1005(1.1046) | Xent 0.0466(0.0453) | Loss 1.1238(1.1272) | Error 0.0151(0.0139) Steps 440(425.23) | Grad Norm 0.2644(0.2895) | Total Time 10.00(10.00)\n",
      "Iter 2735 | Time 30.5481(30.5045) | Bit/dim 1.1068(1.1046) | Xent 0.0444(0.0453) | Loss 1.1290(1.1273) | Error 0.0135(0.0139) Steps 440(425.67) | Grad Norm 0.2218(0.2875) | Total Time 10.00(10.00)\n",
      "Iter 2736 | Time 30.1603(30.4942) | Bit/dim 1.1041(1.1046) | Xent 0.0475(0.0453) | Loss 1.1278(1.1273) | Error 0.0145(0.0140) Steps 422(425.56) | Grad Norm 0.2440(0.2862) | Total Time 10.00(10.00)\n",
      "Iter 2737 | Time 31.0371(30.5104) | Bit/dim 1.1053(1.1046) | Xent 0.0449(0.0453) | Loss 1.1278(1.1273) | Error 0.0140(0.0140) Steps 422(425.46) | Grad Norm 0.2562(0.2853) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 16.8536, Epoch Time 244.5593(242.3418), Bit/dim 1.0993(best: 1.0986), Xent 0.0340, Loss 1.1163, Error 0.0111(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2738 | Time 30.6581(30.5149) | Bit/dim 1.1046(1.1046) | Xent 0.0474(0.0454) | Loss 1.1283(1.1273) | Error 0.0156(0.0140) Steps 440(425.89) | Grad Norm 0.1698(0.2818) | Total Time 10.00(10.00)\n",
      "Iter 2739 | Time 30.2908(30.5082) | Bit/dim 1.1030(1.1046) | Xent 0.0460(0.0454) | Loss 1.1260(1.1273) | Error 0.0129(0.0140) Steps 422(425.78) | Grad Norm 0.2279(0.2802) | Total Time 10.00(10.00)\n",
      "Iter 2740 | Time 30.3805(30.5043) | Bit/dim 1.1023(1.1045) | Xent 0.0471(0.0455) | Loss 1.1259(1.1272) | Error 0.0149(0.0140) Steps 422(425.66) | Grad Norm 0.2290(0.2787) | Total Time 10.00(10.00)\n",
      "Iter 2741 | Time 30.6633(30.5091) | Bit/dim 1.1081(1.1046) | Xent 0.0414(0.0453) | Loss 1.1288(1.1273) | Error 0.0140(0.0140) Steps 422(425.55) | Grad Norm 0.3817(0.2818) | Total Time 10.00(10.00)\n",
      "Iter 2742 | Time 31.9003(30.5508) | Bit/dim 1.1109(1.1048) | Xent 0.0421(0.0452) | Loss 1.1320(1.1274) | Error 0.0138(0.0140) Steps 422(425.45) | Grad Norm 0.3331(0.2833) | Total Time 10.00(10.00)\n",
      "Iter 2743 | Time 30.4861(30.5489) | Bit/dim 1.1029(1.1047) | Xent 0.0456(0.0453) | Loss 1.1257(1.1274) | Error 0.0139(0.0140) Steps 422(425.34) | Grad Norm 0.2843(0.2833) | Total Time 10.00(10.00)\n",
      "Iter 2744 | Time 30.5901(30.5501) | Bit/dim 1.0999(1.1046) | Xent 0.0438(0.0452) | Loss 1.1218(1.1272) | Error 0.0141(0.0140) Steps 440(425.78) | Grad Norm 0.2090(0.2811) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 17.1825, Epoch Time 244.8616(242.4174), Bit/dim 1.0987(best: 1.0986), Xent 0.0324, Loss 1.1149, Error 0.0100(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2745 | Time 31.0359(30.5647) | Bit/dim 1.1062(1.1046) | Xent 0.0443(0.0452) | Loss 1.1283(1.1272) | Error 0.0141(0.0140) Steps 422(425.67) | Grad Norm 0.2797(0.2811) | Total Time 10.00(10.00)\n",
      "Iter 2746 | Time 30.7271(30.5696) | Bit/dim 1.1015(1.1046) | Xent 0.0472(0.0452) | Loss 1.1251(1.1272) | Error 0.0145(0.0140) Steps 440(426.10) | Grad Norm 0.2540(0.2802) | Total Time 10.00(10.00)\n",
      "Iter 2747 | Time 31.2066(30.5887) | Bit/dim 1.1103(1.1047) | Xent 0.0489(0.0453) | Loss 1.1348(1.1274) | Error 0.0132(0.0140) Steps 422(425.98) | Grad Norm 0.4058(0.2840) | Total Time 10.00(10.00)\n",
      "Iter 2748 | Time 31.5037(30.6161) | Bit/dim 1.1022(1.1047) | Xent 0.0453(0.0453) | Loss 1.1248(1.1273) | Error 0.0144(0.0140) Steps 422(425.86) | Grad Norm 0.2128(0.2819) | Total Time 10.00(10.00)\n",
      "Iter 2749 | Time 30.3441(30.6080) | Bit/dim 1.1035(1.1046) | Xent 0.0425(0.0453) | Loss 1.1248(1.1272) | Error 0.0129(0.0140) Steps 440(426.28) | Grad Norm 0.2735(0.2816) | Total Time 10.00(10.00)\n",
      "Iter 2750 | Time 31.0216(30.6204) | Bit/dim 1.1021(1.1045) | Xent 0.0424(0.0452) | Loss 1.1233(1.1271) | Error 0.0122(0.0139) Steps 422(426.15) | Grad Norm 0.2097(0.2795) | Total Time 10.00(10.00)\n",
      "Iter 2751 | Time 31.0918(30.6345) | Bit/dim 1.1025(1.1045) | Xent 0.0505(0.0453) | Loss 1.1277(1.1271) | Error 0.0165(0.0140) Steps 422(426.03) | Grad Norm 0.2919(0.2798) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 17.0002, Epoch Time 246.5846(242.5424), Bit/dim 1.0991(best: 1.0986), Xent 0.0331, Loss 1.1157, Error 0.0109(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2752 | Time 30.3949(30.6273) | Bit/dim 1.1021(1.1044) | Xent 0.0400(0.0452) | Loss 1.1221(1.1270) | Error 0.0124(0.0139) Steps 440(426.45) | Grad Norm 0.2493(0.2789) | Total Time 10.00(10.00)\n",
      "Iter 2753 | Time 30.9448(30.6369) | Bit/dim 1.1050(1.1044) | Xent 0.0444(0.0452) | Loss 1.1272(1.1270) | Error 0.0144(0.0140) Steps 422(426.31) | Grad Norm 0.2147(0.2770) | Total Time 10.00(10.00)\n",
      "Iter 2754 | Time 30.2090(30.6240) | Bit/dim 1.1045(1.1044) | Xent 0.0446(0.0451) | Loss 1.1268(1.1270) | Error 0.0136(0.0139) Steps 440(426.72) | Grad Norm 0.3437(0.2790) | Total Time 10.00(10.00)\n",
      "Iter 2755 | Time 30.5457(30.6217) | Bit/dim 1.1016(1.1043) | Xent 0.0413(0.0450) | Loss 1.1223(1.1269) | Error 0.0135(0.0139) Steps 422(426.58) | Grad Norm 0.3273(0.2805) | Total Time 10.00(10.00)\n",
      "Iter 2756 | Time 30.9014(30.6301) | Bit/dim 1.0979(1.1042) | Xent 0.0411(0.0449) | Loss 1.1184(1.1266) | Error 0.0139(0.0139) Steps 440(426.98) | Grad Norm 0.2128(0.2784) | Total Time 10.00(10.00)\n",
      "Iter 2757 | Time 30.7341(30.6332) | Bit/dim 1.1065(1.1042) | Xent 0.0474(0.0450) | Loss 1.1302(1.1267) | Error 0.0141(0.0139) Steps 440(427.38) | Grad Norm 0.3086(0.2793) | Total Time 10.00(10.00)\n",
      "Iter 2758 | Time 31.4911(30.6589) | Bit/dim 1.1067(1.1043) | Xent 0.0401(0.0448) | Loss 1.1267(1.1267) | Error 0.0134(0.0139) Steps 422(427.21) | Grad Norm 0.2220(0.2776) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 16.8530, Epoch Time 245.2218(242.6228), Bit/dim 1.0986(best: 1.0986), Xent 0.0334, Loss 1.1153, Error 0.0105(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2759 | Time 31.0907(30.6719) | Bit/dim 1.1026(1.1042) | Xent 0.0431(0.0448) | Loss 1.1241(1.1266) | Error 0.0134(0.0139) Steps 422(427.06) | Grad Norm 0.1925(0.2751) | Total Time 10.00(10.00)\n",
      "Iter 2760 | Time 33.9326(30.7697) | Bit/dim 1.1002(1.1041) | Xent 0.0440(0.0448) | Loss 1.1223(1.1265) | Error 0.0146(0.0139) Steps 440(427.45) | Grad Norm 0.3208(0.2764) | Total Time 10.00(10.00)\n",
      "Iter 2761 | Time 30.5387(30.7628) | Bit/dim 1.1081(1.1042) | Xent 0.0469(0.0448) | Loss 1.1316(1.1267) | Error 0.0154(0.0140) Steps 422(427.28) | Grad Norm 0.2443(0.2755) | Total Time 10.00(10.00)\n",
      "Iter 2762 | Time 31.6505(30.7894) | Bit/dim 1.1075(1.1043) | Xent 0.0498(0.0450) | Loss 1.1324(1.1268) | Error 0.0158(0.0140) Steps 422(427.12) | Grad Norm 0.2533(0.2748) | Total Time 10.00(10.00)\n",
      "Iter 2763 | Time 32.5375(30.8418) | Bit/dim 1.1067(1.1044) | Xent 0.0402(0.0448) | Loss 1.1267(1.1268) | Error 0.0142(0.0140) Steps 440(427.51) | Grad Norm 0.3512(0.2771) | Total Time 10.00(10.00)\n",
      "Iter 2764 | Time 31.1557(30.8513) | Bit/dim 1.1006(1.1043) | Xent 0.0491(0.0450) | Loss 1.1251(1.1268) | Error 0.0140(0.0140) Steps 440(427.89) | Grad Norm 0.2366(0.2759) | Total Time 10.00(10.00)\n",
      "Iter 2765 | Time 30.7617(30.8486) | Bit/dim 1.1010(1.1042) | Xent 0.0479(0.0450) | Loss 1.1249(1.1267) | Error 0.0138(0.0140) Steps 422(427.71) | Grad Norm 0.2316(0.2745) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 16.7690, Epoch Time 251.0484(242.8756), Bit/dim 1.0991(best: 1.0986), Xent 0.0330, Loss 1.1156, Error 0.0103(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2766 | Time 30.5033(30.8382) | Bit/dim 1.1064(1.1043) | Xent 0.0485(0.0451) | Loss 1.1307(1.1268) | Error 0.0115(0.0139) Steps 422(427.54) | Grad Norm 0.2211(0.2729) | Total Time 10.00(10.00)\n",
      "Iter 2767 | Time 31.1614(30.8479) | Bit/dim 1.1002(1.1041) | Xent 0.0446(0.0451) | Loss 1.1225(1.1267) | Error 0.0144(0.0140) Steps 422(427.37) | Grad Norm 0.2152(0.2712) | Total Time 10.00(10.00)\n",
      "Iter 2768 | Time 30.4651(30.8364) | Bit/dim 1.1026(1.1041) | Xent 0.0525(0.0454) | Loss 1.1289(1.1268) | Error 0.0159(0.0140) Steps 440(427.75) | Grad Norm 0.3307(0.2730) | Total Time 10.00(10.00)\n",
      "Iter 2769 | Time 30.5812(30.8288) | Bit/dim 1.1027(1.1041) | Xent 0.0366(0.0451) | Loss 1.1210(1.1266) | Error 0.0122(0.0140) Steps 422(427.58) | Grad Norm 0.2347(0.2718) | Total Time 10.00(10.00)\n",
      "Iter 2770 | Time 31.1095(30.8372) | Bit/dim 1.1014(1.1040) | Xent 0.0483(0.0452) | Loss 1.1256(1.1266) | Error 0.0144(0.0140) Steps 422(427.41) | Grad Norm 0.2519(0.2713) | Total Time 10.00(10.00)\n",
      "Iter 2771 | Time 30.9968(30.8420) | Bit/dim 1.1056(1.1040) | Xent 0.0474(0.0453) | Loss 1.1293(1.1266) | Error 0.0164(0.0140) Steps 422(427.25) | Grad Norm 0.3315(0.2731) | Total Time 10.00(10.00)\n",
      "Iter 2772 | Time 30.7774(30.8400) | Bit/dim 1.1091(1.1042) | Xent 0.0410(0.0451) | Loss 1.1296(1.1267) | Error 0.0131(0.0140) Steps 440(427.63) | Grad Norm 0.2152(0.2713) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 17.0045, Epoch Time 245.2514(242.9468), Bit/dim 1.0980(best: 1.0986), Xent 0.0333, Loss 1.1146, Error 0.0108(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2773 | Time 31.7075(30.8661) | Bit/dim 1.1061(1.1042) | Xent 0.0455(0.0451) | Loss 1.1288(1.1268) | Error 0.0132(0.0140) Steps 422(427.46) | Grad Norm 0.1748(0.2684) | Total Time 10.00(10.00)\n",
      "Iter 2774 | Time 31.6617(30.8899) | Bit/dim 1.1033(1.1042) | Xent 0.0517(0.0453) | Loss 1.1291(1.1269) | Error 0.0168(0.0141) Steps 422(427.30) | Grad Norm 0.3121(0.2697) | Total Time 10.00(10.00)\n",
      "Iter 2775 | Time 30.3930(30.8750) | Bit/dim 1.1034(1.1042) | Xent 0.0497(0.0455) | Loss 1.1282(1.1269) | Error 0.0151(0.0141) Steps 440(427.68) | Grad Norm 0.2458(0.2690) | Total Time 10.00(10.00)\n",
      "Iter 2776 | Time 32.0261(30.9096) | Bit/dim 1.1054(1.1042) | Xent 0.0423(0.0454) | Loss 1.1265(1.1269) | Error 0.0132(0.0141) Steps 440(428.05) | Grad Norm 0.1945(0.2668) | Total Time 10.00(10.00)\n",
      "Iter 2777 | Time 31.1640(30.9172) | Bit/dim 1.1063(1.1043) | Xent 0.0419(0.0453) | Loss 1.1273(1.1269) | Error 0.0130(0.0141) Steps 422(427.87) | Grad Norm 0.2553(0.2664) | Total Time 10.00(10.00)\n",
      "Iter 2778 | Time 31.0013(30.9197) | Bit/dim 1.0999(1.1041) | Xent 0.0379(0.0450) | Loss 1.1188(1.1267) | Error 0.0112(0.0140) Steps 422(427.69) | Grad Norm 0.2308(0.2654) | Total Time 10.00(10.00)\n",
      "Iter 2779 | Time 30.7953(30.9160) | Bit/dim 1.1067(1.1042) | Xent 0.0476(0.0451) | Loss 1.1305(1.1268) | Error 0.0141(0.0140) Steps 440(428.06) | Grad Norm 0.1949(0.2633) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 17.2916, Epoch Time 248.6766(243.1187), Bit/dim 1.0989(best: 1.0980), Xent 0.0312, Loss 1.1145, Error 0.0090(best: 0.0094)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2780 | Time 31.6919(30.9393) | Bit/dim 1.1054(1.1043) | Xent 0.0422(0.0450) | Loss 1.1265(1.1268) | Error 0.0131(0.0139) Steps 422(427.88) | Grad Norm 0.1662(0.2603) | Total Time 10.00(10.00)\n",
      "Iter 2781 | Time 31.3111(30.9504) | Bit/dim 1.1080(1.1044) | Xent 0.0497(0.0452) | Loss 1.1329(1.1270) | Error 0.0146(0.0140) Steps 440(428.24) | Grad Norm 0.3794(0.2639) | Total Time 10.00(10.00)\n",
      "Iter 2782 | Time 31.1025(30.9550) | Bit/dim 1.1010(1.1043) | Xent 0.0469(0.0452) | Loss 1.1244(1.1269) | Error 0.0148(0.0140) Steps 422(428.05) | Grad Norm 0.1605(0.2608) | Total Time 10.00(10.00)\n",
      "Iter 2783 | Time 30.2705(30.9344) | Bit/dim 1.1009(1.1042) | Xent 0.0422(0.0451) | Loss 1.1220(1.1267) | Error 0.0140(0.0140) Steps 440(428.41) | Grad Norm 0.2652(0.2609) | Total Time 10.00(10.00)\n",
      "Iter 2784 | Time 31.1755(30.9417) | Bit/dim 1.1036(1.1042) | Xent 0.0468(0.0452) | Loss 1.1270(1.1267) | Error 0.0125(0.0139) Steps 440(428.76) | Grad Norm 0.1601(0.2579) | Total Time 10.00(10.00)\n",
      "Iter 2785 | Time 31.0186(30.9440) | Bit/dim 1.1068(1.1042) | Xent 0.0480(0.0453) | Loss 1.1308(1.1269) | Error 0.0131(0.0139) Steps 440(429.10) | Grad Norm 0.2611(0.2580) | Total Time 10.00(10.00)\n",
      "Iter 2786 | Time 30.4383(30.9288) | Bit/dim 1.1040(1.1042) | Xent 0.0480(0.0453) | Loss 1.1280(1.1269) | Error 0.0144(0.0139) Steps 422(428.88) | Grad Norm 0.2325(0.2572) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 16.9908, Epoch Time 246.4962(243.2201), Bit/dim 1.0986(best: 1.0980), Xent 0.0335, Loss 1.1154, Error 0.0101(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2787 | Time 30.3554(30.9116) | Bit/dim 1.1031(1.1042) | Xent 0.0476(0.0454) | Loss 1.1269(1.1269) | Error 0.0135(0.0139) Steps 422(428.68) | Grad Norm 0.1858(0.2551) | Total Time 10.00(10.00)\n",
      "Iter 2788 | Time 31.1395(30.9184) | Bit/dim 1.1029(1.1042) | Xent 0.0488(0.0455) | Loss 1.1273(1.1269) | Error 0.0138(0.0139) Steps 422(428.48) | Grad Norm 0.1927(0.2532) | Total Time 10.00(10.00)\n",
      "Iter 2789 | Time 33.0072(30.9811) | Bit/dim 1.1073(1.1042) | Xent 0.0405(0.0454) | Loss 1.1276(1.1269) | Error 0.0132(0.0139) Steps 440(428.82) | Grad Norm 0.2500(0.2531) | Total Time 10.00(10.00)\n",
      "Iter 2790 | Time 30.9795(30.9811) | Bit/dim 1.1013(1.1042) | Xent 0.0491(0.0455) | Loss 1.1258(1.1269) | Error 0.0161(0.0140) Steps 440(429.16) | Grad Norm 0.2181(0.2521) | Total Time 10.00(10.00)\n",
      "Iter 2791 | Time 30.1482(30.9561) | Bit/dim 1.1040(1.1042) | Xent 0.0485(0.0456) | Loss 1.1283(1.1269) | Error 0.0165(0.0140) Steps 440(429.48) | Grad Norm 0.2671(0.2525) | Total Time 10.00(10.00)\n",
      "Iter 2792 | Time 30.5480(30.9438) | Bit/dim 1.1055(1.1042) | Xent 0.0450(0.0456) | Loss 1.1280(1.1270) | Error 0.0140(0.0140) Steps 440(429.80) | Grad Norm 0.1953(0.2508) | Total Time 10.00(10.00)\n",
      "Iter 2793 | Time 30.8977(30.9424) | Bit/dim 1.1012(1.1041) | Xent 0.0408(0.0454) | Loss 1.1216(1.1268) | Error 0.0122(0.0140) Steps 440(430.11) | Grad Norm 0.2340(0.2503) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 16.9021, Epoch Time 246.3469(243.3139), Bit/dim 1.0987(best: 1.0980), Xent 0.0329, Loss 1.1151, Error 0.0094(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2794 | Time 30.7838(30.9377) | Bit/dim 1.1049(1.1041) | Xent 0.0484(0.0455) | Loss 1.1291(1.1269) | Error 0.0138(0.0140) Steps 440(430.40) | Grad Norm 0.2533(0.2504) | Total Time 10.00(10.00)\n",
      "Iter 2795 | Time 30.5781(30.9269) | Bit/dim 1.1053(1.1042) | Xent 0.0495(0.0456) | Loss 1.1301(1.1270) | Error 0.0140(0.0140) Steps 440(430.69) | Grad Norm 0.1518(0.2474) | Total Time 10.00(10.00)\n",
      "Iter 2796 | Time 30.6635(30.9190) | Bit/dim 1.1039(1.1042) | Xent 0.0491(0.0457) | Loss 1.1284(1.1270) | Error 0.0155(0.0140) Steps 440(430.97) | Grad Norm 0.2448(0.2474) | Total Time 10.00(10.00)\n",
      "Iter 2797 | Time 30.9559(30.9201) | Bit/dim 1.1003(1.1040) | Xent 0.0421(0.0456) | Loss 1.1213(1.1268) | Error 0.0145(0.0140) Steps 422(430.70) | Grad Norm 0.2658(0.2479) | Total Time 10.00(10.00)\n",
      "Iter 2798 | Time 30.8584(30.9182) | Bit/dim 1.0997(1.1039) | Xent 0.0472(0.0457) | Loss 1.1233(1.1267) | Error 0.0154(0.0141) Steps 440(430.98) | Grad Norm 0.1849(0.2460) | Total Time 10.00(10.00)\n",
      "Iter 2799 | Time 30.8263(30.9155) | Bit/dim 1.1057(1.1040) | Xent 0.0476(0.0457) | Loss 1.1295(1.1268) | Error 0.0148(0.0141) Steps 422(430.71) | Grad Norm 0.2988(0.2476) | Total Time 10.00(10.00)\n",
      "Iter 2800 | Time 30.8615(30.9139) | Bit/dim 1.1066(1.1040) | Xent 0.0471(0.0458) | Loss 1.1301(1.1269) | Error 0.0155(0.0141) Steps 422(430.45) | Grad Norm 0.2396(0.2474) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 17.3415, Epoch Time 245.2834(243.3729), Bit/dim 1.0985(best: 1.0980), Xent 0.0323, Loss 1.1147, Error 0.0093(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2801 | Time 31.4124(30.9288) | Bit/dim 1.1070(1.1041) | Xent 0.0426(0.0457) | Loss 1.1283(1.1270) | Error 0.0134(0.0141) Steps 440(430.74) | Grad Norm 0.1816(0.2454) | Total Time 10.00(10.00)\n",
      "Iter 2802 | Time 31.0594(30.9327) | Bit/dim 1.1012(1.1040) | Xent 0.0534(0.0459) | Loss 1.1279(1.1270) | Error 0.0168(0.0142) Steps 440(431.01) | Grad Norm 0.4652(0.2520) | Total Time 10.00(10.00)\n",
      "Iter 2803 | Time 32.5907(30.9825) | Bit/dim 1.1004(1.1039) | Xent 0.0493(0.0460) | Loss 1.1251(1.1269) | Error 0.0141(0.0142) Steps 422(430.74) | Grad Norm 0.2782(0.2528) | Total Time 10.00(10.00)\n",
      "Iter 2804 | Time 31.6461(31.0024) | Bit/dim 1.1066(1.1040) | Xent 0.0487(0.0461) | Loss 1.1309(1.1271) | Error 0.0138(0.0142) Steps 422(430.48) | Grad Norm 0.1844(0.2507) | Total Time 10.00(10.00)\n",
      "Iter 2805 | Time 30.8254(30.9971) | Bit/dim 1.1036(1.1040) | Xent 0.0410(0.0459) | Loss 1.1241(1.1270) | Error 0.0138(0.0142) Steps 422(430.23) | Grad Norm 0.2646(0.2511) | Total Time 10.00(10.00)\n",
      "Iter 2806 | Time 30.6925(30.9879) | Bit/dim 1.0997(1.1039) | Xent 0.0463(0.0459) | Loss 1.1229(1.1268) | Error 0.0135(0.0141) Steps 440(430.52) | Grad Norm 0.4287(0.2565) | Total Time 10.00(10.00)\n",
      "Iter 2807 | Time 30.4889(30.9730) | Bit/dim 1.1073(1.1040) | Xent 0.0436(0.0459) | Loss 1.1291(1.1269) | Error 0.0141(0.0141) Steps 440(430.80) | Grad Norm 0.2872(0.2574) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 17.2632, Epoch Time 249.0000(243.5418), Bit/dim 1.0985(best: 1.0980), Xent 0.0324, Loss 1.1147, Error 0.0098(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2808 | Time 30.8337(30.9688) | Bit/dim 1.1010(1.1039) | Xent 0.0426(0.0458) | Loss 1.1224(1.1268) | Error 0.0130(0.0141) Steps 440(431.08) | Grad Norm 0.2317(0.2566) | Total Time 10.00(10.00)\n",
      "Iter 2809 | Time 30.8713(30.9659) | Bit/dim 1.1071(1.1040) | Xent 0.0426(0.0457) | Loss 1.1284(1.1268) | Error 0.0138(0.0141) Steps 440(431.35) | Grad Norm 0.2269(0.2557) | Total Time 10.00(10.00)\n",
      "Iter 2810 | Time 30.7770(30.9602) | Bit/dim 1.1072(1.1041) | Xent 0.0451(0.0457) | Loss 1.1298(1.1269) | Error 0.0142(0.0141) Steps 440(431.61) | Grad Norm 0.3332(0.2581) | Total Time 10.00(10.00)\n",
      "Iter 2811 | Time 31.8754(30.9877) | Bit/dim 1.1022(1.1040) | Xent 0.0398(0.0455) | Loss 1.1221(1.1268) | Error 0.0118(0.0140) Steps 440(431.86) | Grad Norm 0.4626(0.2642) | Total Time 10.00(10.00)\n",
      "Iter 2812 | Time 30.9331(30.9860) | Bit/dim 1.1057(1.1041) | Xent 0.0470(0.0455) | Loss 1.1292(1.1268) | Error 0.0142(0.0140) Steps 440(432.10) | Grad Norm 0.3136(0.2657) | Total Time 10.00(10.00)\n",
      "Iter 2813 | Time 30.6620(30.9763) | Bit/dim 1.1049(1.1041) | Xent 0.0477(0.0456) | Loss 1.1288(1.1269) | Error 0.0145(0.0141) Steps 422(431.80) | Grad Norm 0.2627(0.2656) | Total Time 10.00(10.00)\n",
      "Iter 2814 | Time 30.8700(30.9731) | Bit/dim 1.1030(1.1041) | Xent 0.0411(0.0455) | Loss 1.1236(1.1268) | Error 0.0132(0.0140) Steps 440(432.05) | Grad Norm 0.3510(0.2681) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 16.9181, Epoch Time 246.1163(243.6190), Bit/dim 1.0984(best: 1.0980), Xent 0.0327, Loss 1.1147, Error 0.0100(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2815 | Time 30.8664(30.9699) | Bit/dim 1.0971(1.1039) | Xent 0.0437(0.0454) | Loss 1.1190(1.1266) | Error 0.0139(0.0140) Steps 440(432.28) | Grad Norm 0.3054(0.2693) | Total Time 10.00(10.00)\n",
      "Iter 2816 | Time 32.3832(31.0123) | Bit/dim 1.1051(1.1039) | Xent 0.0425(0.0453) | Loss 1.1264(1.1266) | Error 0.0116(0.0140) Steps 440(432.52) | Grad Norm 0.3479(0.2716) | Total Time 10.00(10.00)\n",
      "Iter 2817 | Time 30.4983(30.9969) | Bit/dim 1.1050(1.1039) | Xent 0.0450(0.0453) | Loss 1.1275(1.1266) | Error 0.0134(0.0139) Steps 422(432.20) | Grad Norm 0.1711(0.2686) | Total Time 10.00(10.00)\n",
      "Iter 2818 | Time 31.9132(31.0244) | Bit/dim 1.1076(1.1040) | Xent 0.0447(0.0453) | Loss 1.1300(1.1267) | Error 0.0138(0.0139) Steps 440(432.43) | Grad Norm 0.2636(0.2685) | Total Time 10.00(10.00)\n",
      "Iter 2819 | Time 30.9558(31.0223) | Bit/dim 1.1028(1.1040) | Xent 0.0483(0.0454) | Loss 1.1269(1.1267) | Error 0.0142(0.0139) Steps 440(432.66) | Grad Norm 0.3362(0.2705) | Total Time 10.00(10.00)\n",
      "Iter 2820 | Time 30.6416(31.0109) | Bit/dim 1.1077(1.1041) | Xent 0.0474(0.0455) | Loss 1.1315(1.1268) | Error 0.0124(0.0139) Steps 440(432.88) | Grad Norm 0.2964(0.2713) | Total Time 10.00(10.00)\n",
      "Iter 2821 | Time 30.7878(31.0042) | Bit/dim 1.1023(1.1041) | Xent 0.0417(0.0453) | Loss 1.1231(1.1267) | Error 0.0125(0.0139) Steps 422(432.56) | Grad Norm 0.3483(0.2736) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 16.9950, Epoch Time 247.7361(243.7425), Bit/dim 1.0986(best: 1.0980), Xent 0.0318, Loss 1.1145, Error 0.0097(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2822 | Time 30.2858(30.9827) | Bit/dim 1.1049(1.1041) | Xent 0.0455(0.0453) | Loss 1.1276(1.1268) | Error 0.0134(0.0138) Steps 422(432.24) | Grad Norm 0.2242(0.2721) | Total Time 10.00(10.00)\n",
      "Iter 2823 | Time 31.4456(30.9965) | Bit/dim 1.1013(1.1040) | Xent 0.0420(0.0452) | Loss 1.1223(1.1266) | Error 0.0130(0.0138) Steps 422(431.93) | Grad Norm 0.2001(0.2699) | Total Time 10.00(10.00)\n",
      "Iter 2824 | Time 30.8000(30.9906) | Bit/dim 1.1036(1.1040) | Xent 0.0448(0.0452) | Loss 1.1260(1.1266) | Error 0.0121(0.0138) Steps 440(432.17) | Grad Norm 0.2808(0.2703) | Total Time 10.00(10.00)\n",
      "Iter 2825 | Time 31.3319(31.0009) | Bit/dim 1.1082(1.1041) | Xent 0.0426(0.0451) | Loss 1.1294(1.1267) | Error 0.0138(0.0138) Steps 440(432.41) | Grad Norm 0.4954(0.2770) | Total Time 10.00(10.00)\n",
      "Iter 2826 | Time 30.9854(31.0004) | Bit/dim 1.1039(1.1041) | Xent 0.0485(0.0452) | Loss 1.1281(1.1267) | Error 0.0158(0.0138) Steps 440(432.64) | Grad Norm 0.3384(0.2789) | Total Time 10.00(10.00)\n",
      "Iter 2827 | Time 32.2931(31.0392) | Bit/dim 1.1036(1.1041) | Xent 0.0396(0.0451) | Loss 1.1234(1.1266) | Error 0.0125(0.0138) Steps 440(432.86) | Grad Norm 0.2426(0.2778) | Total Time 10.00(10.00)\n",
      "Iter 2828 | Time 31.0277(31.0388) | Bit/dim 1.1028(1.1041) | Xent 0.0430(0.0450) | Loss 1.1242(1.1266) | Error 0.0139(0.0138) Steps 440(433.07) | Grad Norm 0.2605(0.2773) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 16.8921, Epoch Time 247.6401(243.8594), Bit/dim 1.0982(best: 1.0980), Xent 0.0332, Loss 1.1148, Error 0.0104(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2829 | Time 30.6749(31.0279) | Bit/dim 1.1049(1.1041) | Xent 0.0481(0.0451) | Loss 1.1290(1.1266) | Error 0.0140(0.0138) Steps 440(433.28) | Grad Norm 0.3856(0.2805) | Total Time 10.00(10.00)\n",
      "Iter 2830 | Time 31.4273(31.0399) | Bit/dim 1.1001(1.1040) | Xent 0.0431(0.0450) | Loss 1.1216(1.1265) | Error 0.0132(0.0138) Steps 440(433.48) | Grad Norm 0.3658(0.2831) | Total Time 10.00(10.00)\n",
      "Iter 2831 | Time 30.1725(31.0139) | Bit/dim 1.1031(1.1039) | Xent 0.0510(0.0452) | Loss 1.1286(1.1265) | Error 0.0155(0.0138) Steps 422(433.14) | Grad Norm 0.2250(0.2813) | Total Time 10.00(10.00)\n",
      "Iter 2832 | Time 32.4248(31.0562) | Bit/dim 1.1043(1.1039) | Xent 0.0434(0.0452) | Loss 1.1260(1.1265) | Error 0.0139(0.0138) Steps 440(433.34) | Grad Norm 0.2908(0.2816) | Total Time 10.00(10.00)\n",
      "Iter 2833 | Time 30.9225(31.0522) | Bit/dim 1.0995(1.1038) | Xent 0.0423(0.0451) | Loss 1.1206(1.1264) | Error 0.0140(0.0138) Steps 440(433.54) | Grad Norm 0.4800(0.2876) | Total Time 10.00(10.00)\n",
      "Iter 2834 | Time 31.7638(31.0735) | Bit/dim 1.1049(1.1038) | Xent 0.0438(0.0450) | Loss 1.1269(1.1264) | Error 0.0142(0.0138) Steps 422(433.20) | Grad Norm 0.3266(0.2887) | Total Time 10.00(10.00)\n",
      "Iter 2835 | Time 30.7098(31.0626) | Bit/dim 1.1088(1.1040) | Xent 0.0554(0.0454) | Loss 1.1365(1.1267) | Error 0.0174(0.0140) Steps 440(433.40) | Grad Norm 0.2577(0.2878) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 17.1111, Epoch Time 247.8320(243.9786), Bit/dim 1.0981(best: 1.0980), Xent 0.0334, Loss 1.1149, Error 0.0098(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2836 | Time 31.0538(31.0624) | Bit/dim 1.1027(1.1040) | Xent 0.0442(0.0453) | Loss 1.1248(1.1266) | Error 0.0146(0.0140) Steps 440(433.60) | Grad Norm 0.3182(0.2887) | Total Time 10.00(10.00)\n",
      "Iter 2837 | Time 32.3874(31.1021) | Bit/dim 1.0995(1.1038) | Xent 0.0410(0.0452) | Loss 1.1200(1.1264) | Error 0.0130(0.0139) Steps 440(433.79) | Grad Norm 0.4799(0.2944) | Total Time 10.00(10.00)\n",
      "Iter 2838 | Time 30.8730(31.0952) | Bit/dim 1.1074(1.1039) | Xent 0.0446(0.0452) | Loss 1.1297(1.1265) | Error 0.0138(0.0139) Steps 440(433.98) | Grad Norm 0.1981(0.2916) | Total Time 10.00(10.00)\n",
      "Iter 2839 | Time 30.9609(31.0912) | Bit/dim 1.1043(1.1039) | Xent 0.0475(0.0452) | Loss 1.1281(1.1266) | Error 0.0144(0.0140) Steps 440(434.16) | Grad Norm 0.2600(0.2906) | Total Time 10.00(10.00)\n",
      "Iter 2840 | Time 31.6911(31.1092) | Bit/dim 1.1063(1.1040) | Xent 0.0430(0.0452) | Loss 1.1278(1.1266) | Error 0.0145(0.0140) Steps 440(434.33) | Grad Norm 0.3259(0.2917) | Total Time 10.00(10.00)\n",
      "Iter 2841 | Time 31.1264(31.1097) | Bit/dim 1.1087(1.1042) | Xent 0.0487(0.0453) | Loss 1.1330(1.1268) | Error 0.0148(0.0140) Steps 440(434.50) | Grad Norm 0.2741(0.2911) | Total Time 10.00(10.00)\n",
      "Iter 2842 | Time 30.9309(31.1044) | Bit/dim 1.1017(1.1041) | Xent 0.0526(0.0455) | Loss 1.1279(1.1268) | Error 0.0174(0.0141) Steps 440(434.67) | Grad Norm 0.3765(0.2937) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 17.2658, Epoch Time 248.9104(244.1266), Bit/dim 1.0983(best: 1.0980), Xent 0.0346, Loss 1.1156, Error 0.0101(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2843 | Time 31.5260(31.1170) | Bit/dim 1.1035(1.1041) | Xent 0.0554(0.0458) | Loss 1.1312(1.1270) | Error 0.0164(0.0142) Steps 440(434.83) | Grad Norm 0.2904(0.2936) | Total Time 10.00(10.00)\n",
      "Iter 2844 | Time 31.3948(31.1253) | Bit/dim 1.1060(1.1041) | Xent 0.0402(0.0456) | Loss 1.1261(1.1269) | Error 0.0125(0.0141) Steps 440(434.98) | Grad Norm 0.3145(0.2942) | Total Time 10.00(10.00)\n",
      "Iter 2845 | Time 31.5028(31.1367) | Bit/dim 1.1050(1.1041) | Xent 0.0408(0.0455) | Loss 1.1254(1.1269) | Error 0.0126(0.0141) Steps 422(434.59) | Grad Norm 0.2315(0.2923) | Total Time 10.00(10.00)\n",
      "Iter 2846 | Time 30.8836(31.1291) | Bit/dim 1.1077(1.1043) | Xent 0.0425(0.0454) | Loss 1.1289(1.1270) | Error 0.0162(0.0141) Steps 440(434.76) | Grad Norm 0.2527(0.2912) | Total Time 10.00(10.00)\n",
      "Iter 2847 | Time 31.1444(31.1295) | Bit/dim 1.1011(1.1042) | Xent 0.0452(0.0454) | Loss 1.1237(1.1269) | Error 0.0131(0.0141) Steps 440(434.91) | Grad Norm 0.2638(0.2903) | Total Time 10.00(10.00)\n",
      "Iter 2848 | Time 31.1089(31.1289) | Bit/dim 1.0997(1.1040) | Xent 0.0398(0.0452) | Loss 1.1196(1.1266) | Error 0.0122(0.0140) Steps 440(435.07) | Grad Norm 0.2700(0.2897) | Total Time 10.00(10.00)\n",
      "Iter 2849 | Time 32.0128(31.1554) | Bit/dim 1.1036(1.1040) | Xent 0.0503(0.0454) | Loss 1.1288(1.1267) | Error 0.0150(0.0141) Steps 440(435.21) | Grad Norm 0.3839(0.2925) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 17.3374, Epoch Time 249.6134(244.2912), Bit/dim 1.0987(best: 1.0980), Xent 0.0344, Loss 1.1159, Error 0.0105(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2850 | Time 31.3292(31.1607) | Bit/dim 1.1025(1.1040) | Xent 0.0453(0.0454) | Loss 1.1252(1.1267) | Error 0.0146(0.0141) Steps 440(435.36) | Grad Norm 0.2540(0.2914) | Total Time 10.00(10.00)\n",
      "Iter 2851 | Time 30.8673(31.1519) | Bit/dim 1.1036(1.1040) | Xent 0.0479(0.0455) | Loss 1.1275(1.1267) | Error 0.0146(0.0141) Steps 440(435.50) | Grad Norm 0.2694(0.2907) | Total Time 10.00(10.00)\n",
      "Iter 2852 | Time 32.4879(31.1919) | Bit/dim 1.0976(1.1038) | Xent 0.0458(0.0455) | Loss 1.1205(1.1265) | Error 0.0144(0.0141) Steps 440(435.63) | Grad Norm 0.2460(0.2894) | Total Time 10.00(10.00)\n",
      "Iter 2853 | Time 30.9940(31.1860) | Bit/dim 1.1074(1.1039) | Xent 0.0484(0.0455) | Loss 1.1316(1.1267) | Error 0.0139(0.0141) Steps 440(435.76) | Grad Norm 0.2624(0.2886) | Total Time 10.00(10.00)\n",
      "Iter 2854 | Time 30.9471(31.1788) | Bit/dim 1.0999(1.1038) | Xent 0.0480(0.0456) | Loss 1.1239(1.1266) | Error 0.0151(0.0141) Steps 440(435.89) | Grad Norm 0.2409(0.2871) | Total Time 10.00(10.00)\n",
      "Iter 2855 | Time 30.6382(31.1626) | Bit/dim 1.1057(1.1038) | Xent 0.0508(0.0458) | Loss 1.1311(1.1267) | Error 0.0166(0.0142) Steps 440(436.01) | Grad Norm 0.2268(0.2853) | Total Time 10.00(10.00)\n",
      "Iter 2856 | Time 31.2195(31.1643) | Bit/dim 1.1053(1.1039) | Xent 0.0409(0.0456) | Loss 1.1258(1.1267) | Error 0.0121(0.0142) Steps 440(436.13) | Grad Norm 0.1947(0.2826) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 17.3573, Epoch Time 248.6457(244.4218), Bit/dim 1.0981(best: 1.0980), Xent 0.0319, Loss 1.1141, Error 0.0105(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2857 | Time 30.9661(31.1584) | Bit/dim 1.1010(1.1038) | Xent 0.0475(0.0457) | Loss 1.1248(1.1266) | Error 0.0144(0.0142) Steps 440(436.25) | Grad Norm 0.2215(0.2808) | Total Time 10.00(10.00)\n",
      "Iter 2858 | Time 31.8625(31.1795) | Bit/dim 1.0998(1.1037) | Xent 0.0465(0.0457) | Loss 1.1230(1.1265) | Error 0.0150(0.0142) Steps 422(435.82) | Grad Norm 0.2500(0.2799) | Total Time 10.00(10.00)\n",
      "Iter 2859 | Time 31.2239(31.1808) | Bit/dim 1.1082(1.1038) | Xent 0.0470(0.0458) | Loss 1.1317(1.1267) | Error 0.0148(0.0142) Steps 440(435.95) | Grad Norm 0.2298(0.2784) | Total Time 10.00(10.00)\n",
      "Iter 2860 | Time 31.2844(31.1839) | Bit/dim 1.1023(1.1038) | Xent 0.0429(0.0457) | Loss 1.1238(1.1266) | Error 0.0126(0.0142) Steps 440(436.07) | Grad Norm 0.2347(0.2771) | Total Time 10.00(10.00)\n",
      "Iter 2861 | Time 30.4651(31.1624) | Bit/dim 1.1079(1.1039) | Xent 0.0455(0.0457) | Loss 1.1306(1.1267) | Error 0.0148(0.0142) Steps 422(435.65) | Grad Norm 0.2810(0.2772) | Total Time 10.00(10.00)\n",
      "Iter 2862 | Time 31.4488(31.1710) | Bit/dim 1.1092(1.1040) | Xent 0.0450(0.0456) | Loss 1.1317(1.1269) | Error 0.0129(0.0141) Steps 440(435.78) | Grad Norm 0.2747(0.2771) | Total Time 10.00(10.00)\n",
      "Iter 2863 | Time 30.6137(31.1542) | Bit/dim 1.1014(1.1040) | Xent 0.0446(0.0456) | Loss 1.1237(1.1268) | Error 0.0152(0.0142) Steps 422(435.36) | Grad Norm 0.2243(0.2755) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 17.4575, Epoch Time 247.7389(244.5213), Bit/dim 1.0983(best: 1.0980), Xent 0.0324, Loss 1.1145, Error 0.0094(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2864 | Time 31.8659(31.1756) | Bit/dim 1.1028(1.1039) | Xent 0.0418(0.0455) | Loss 1.1237(1.1267) | Error 0.0129(0.0141) Steps 440(435.50) | Grad Norm 0.2299(0.2741) | Total Time 10.00(10.00)\n",
      "Iter 2865 | Time 31.0232(31.1710) | Bit/dim 1.1041(1.1039) | Xent 0.0419(0.0454) | Loss 1.1250(1.1266) | Error 0.0131(0.0141) Steps 440(435.64) | Grad Norm 0.2547(0.2736) | Total Time 10.00(10.00)\n",
      "Iter 2866 | Time 30.8252(31.1606) | Bit/dim 1.1036(1.1039) | Xent 0.0438(0.0453) | Loss 1.1255(1.1266) | Error 0.0146(0.0141) Steps 440(435.77) | Grad Norm 0.3816(0.2768) | Total Time 10.00(10.00)\n",
      "Iter 2867 | Time 30.9674(31.1549) | Bit/dim 1.1028(1.1039) | Xent 0.0516(0.0455) | Loss 1.1287(1.1266) | Error 0.0161(0.0142) Steps 440(435.90) | Grad Norm 0.3091(0.2778) | Total Time 10.00(10.00)\n",
      "Iter 2868 | Time 31.0371(31.1513) | Bit/dim 1.1019(1.1038) | Xent 0.0519(0.0457) | Loss 1.1278(1.1267) | Error 0.0156(0.0142) Steps 440(436.02) | Grad Norm 0.2014(0.2755) | Total Time 10.00(10.00)\n",
      "Iter 2869 | Time 32.6163(31.1953) | Bit/dim 1.1061(1.1039) | Xent 0.0447(0.0457) | Loss 1.1285(1.1267) | Error 0.0135(0.0142) Steps 440(436.14) | Grad Norm 0.2178(0.2738) | Total Time 10.00(10.00)\n",
      "Iter 2870 | Time 32.3688(31.2305) | Bit/dim 1.1021(1.1038) | Xent 0.0523(0.0459) | Loss 1.1282(1.1268) | Error 0.0155(0.0142) Steps 440(436.25) | Grad Norm 0.2602(0.2733) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 17.4878, Epoch Time 250.8757(244.7119), Bit/dim 1.0985(best: 1.0980), Xent 0.0329, Loss 1.1150, Error 0.0103(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2871 | Time 30.7616(31.2164) | Bit/dim 1.1045(1.1039) | Xent 0.0475(0.0459) | Loss 1.1283(1.1268) | Error 0.0154(0.0143) Steps 440(436.37) | Grad Norm 0.2071(0.2714) | Total Time 10.00(10.00)\n",
      "Iter 2872 | Time 31.0927(31.2127) | Bit/dim 1.1021(1.1038) | Xent 0.0436(0.0459) | Loss 1.1239(1.1267) | Error 0.0141(0.0143) Steps 440(436.47) | Grad Norm 0.1879(0.2689) | Total Time 10.00(10.00)\n",
      "Iter 2873 | Time 30.6695(31.1964) | Bit/dim 1.1000(1.1037) | Xent 0.0434(0.0458) | Loss 1.1216(1.1266) | Error 0.0129(0.0142) Steps 440(436.58) | Grad Norm 0.2692(0.2689) | Total Time 10.00(10.00)\n",
      "Iter 2874 | Time 30.8912(31.1872) | Bit/dim 1.1016(1.1036) | Xent 0.0462(0.0458) | Loss 1.1247(1.1265) | Error 0.0142(0.0142) Steps 440(436.68) | Grad Norm 0.2886(0.2695) | Total Time 10.00(10.00)\n",
      "Iter 2875 | Time 31.1649(31.1866) | Bit/dim 1.1035(1.1036) | Xent 0.0478(0.0459) | Loss 1.1274(1.1266) | Error 0.0132(0.0142) Steps 440(436.78) | Grad Norm 0.1848(0.2669) | Total Time 10.00(10.00)\n",
      "Iter 2876 | Time 31.7377(31.2031) | Bit/dim 1.1062(1.1037) | Xent 0.0424(0.0458) | Loss 1.1274(1.1266) | Error 0.0140(0.0142) Steps 422(436.34) | Grad Norm 0.2814(0.2674) | Total Time 10.00(10.00)\n",
      "Iter 2877 | Time 31.3175(31.2065) | Bit/dim 1.1035(1.1037) | Xent 0.0486(0.0458) | Loss 1.1278(1.1266) | Error 0.0142(0.0142) Steps 440(436.45) | Grad Norm 0.2187(0.2659) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 17.4398, Epoch Time 247.7622(244.8035), Bit/dim 1.0984(best: 1.0980), Xent 0.0346, Loss 1.1157, Error 0.0106(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2878 | Time 30.9446(31.1987) | Bit/dim 1.1037(1.1037) | Xent 0.0481(0.0459) | Loss 1.1277(1.1266) | Error 0.0139(0.0142) Steps 440(436.56) | Grad Norm 0.3815(0.2694) | Total Time 10.00(10.00)\n",
      "Iter 2879 | Time 31.3520(31.2033) | Bit/dim 1.1058(1.1038) | Xent 0.0497(0.0460) | Loss 1.1306(1.1268) | Error 0.0149(0.0142) Steps 440(436.66) | Grad Norm 0.2023(0.2673) | Total Time 10.00(10.00)\n",
      "Iter 2880 | Time 31.4284(31.2100) | Bit/dim 1.0987(1.1036) | Xent 0.0470(0.0461) | Loss 1.1222(1.1266) | Error 0.0140(0.0142) Steps 440(436.76) | Grad Norm 0.3051(0.2685) | Total Time 10.00(10.00)\n",
      "Iter 2881 | Time 31.0025(31.2038) | Bit/dim 1.0978(1.1034) | Xent 0.0482(0.0461) | Loss 1.1219(1.1265) | Error 0.0141(0.0142) Steps 440(436.86) | Grad Norm 0.3426(0.2707) | Total Time 10.00(10.00)\n",
      "Iter 2882 | Time 30.9729(31.1969) | Bit/dim 1.1076(1.1036) | Xent 0.0383(0.0459) | Loss 1.1268(1.1265) | Error 0.0120(0.0141) Steps 440(436.95) | Grad Norm 0.2207(0.2692) | Total Time 10.00(10.00)\n",
      "Iter 2883 | Time 30.4818(31.1754) | Bit/dim 1.1054(1.1036) | Xent 0.0495(0.0460) | Loss 1.1301(1.1266) | Error 0.0144(0.0141) Steps 440(437.04) | Grad Norm 0.1903(0.2668) | Total Time 10.00(10.00)\n",
      "Iter 2884 | Time 31.0600(31.1720) | Bit/dim 1.1059(1.1037) | Xent 0.0465(0.0460) | Loss 1.1292(1.1267) | Error 0.0142(0.0141) Steps 440(437.13) | Grad Norm 0.2850(0.2674) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 17.4378, Epoch Time 247.2035(244.8755), Bit/dim 1.0976(best: 1.0980), Xent 0.0333, Loss 1.1142, Error 0.0092(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2885 | Time 31.5240(31.1825) | Bit/dim 1.1047(1.1037) | Xent 0.0465(0.0460) | Loss 1.1279(1.1267) | Error 0.0144(0.0141) Steps 440(437.22) | Grad Norm 0.2687(0.2674) | Total Time 10.00(10.00)\n",
      "Iter 2886 | Time 30.7372(31.1692) | Bit/dim 1.1048(1.1037) | Xent 0.0432(0.0459) | Loss 1.1264(1.1267) | Error 0.0131(0.0141) Steps 440(437.30) | Grad Norm 0.1831(0.2649) | Total Time 10.00(10.00)\n",
      "Iter 2887 | Time 30.8480(31.1595) | Bit/dim 1.1057(1.1038) | Xent 0.0446(0.0459) | Loss 1.1280(1.1267) | Error 0.0150(0.0141) Steps 422(436.84) | Grad Norm 0.1626(0.2618) | Total Time 10.00(10.00)\n",
      "Iter 2888 | Time 31.4753(31.1690) | Bit/dim 1.1039(1.1038) | Xent 0.0470(0.0459) | Loss 1.1274(1.1268) | Error 0.0129(0.0141) Steps 440(436.94) | Grad Norm 0.1669(0.2590) | Total Time 10.00(10.00)\n",
      "Iter 2889 | Time 31.1682(31.1690) | Bit/dim 1.1024(1.1038) | Xent 0.0406(0.0458) | Loss 1.1226(1.1266) | Error 0.0111(0.0140) Steps 440(437.03) | Grad Norm 0.2164(0.2577) | Total Time 10.00(10.00)\n",
      "Iter 2890 | Time 30.8615(31.1598) | Bit/dim 1.1005(1.1037) | Xent 0.0406(0.0456) | Loss 1.1208(1.1265) | Error 0.0136(0.0140) Steps 422(436.58) | Grad Norm 0.2321(0.2569) | Total Time 10.00(10.00)\n",
      "Iter 2891 | Time 31.2301(31.1619) | Bit/dim 1.1024(1.1036) | Xent 0.0445(0.0456) | Loss 1.1246(1.1264) | Error 0.0149(0.0140) Steps 440(436.68) | Grad Norm 0.2719(0.2574) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 17.6591, Epoch Time 248.1233(244.9729), Bit/dim 1.0977(best: 1.0976), Xent 0.0312, Loss 1.1133, Error 0.0100(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2892 | Time 31.0472(31.1584) | Bit/dim 1.1061(1.1037) | Xent 0.0454(0.0456) | Loss 1.1288(1.1265) | Error 0.0139(0.0140) Steps 440(436.78) | Grad Norm 0.2440(0.2570) | Total Time 10.00(10.00)\n",
      "Iter 2893 | Time 31.4954(31.1685) | Bit/dim 1.1040(1.1037) | Xent 0.0458(0.0456) | Loss 1.1269(1.1265) | Error 0.0145(0.0140) Steps 440(436.88) | Grad Norm 0.1532(0.2539) | Total Time 10.00(10.00)\n",
      "Iter 2894 | Time 31.0315(31.1644) | Bit/dim 1.1048(1.1037) | Xent 0.0439(0.0455) | Loss 1.1268(1.1265) | Error 0.0145(0.0141) Steps 440(436.97) | Grad Norm 0.2365(0.2533) | Total Time 10.00(10.00)\n",
      "Iter 2895 | Time 30.9304(31.1574) | Bit/dim 1.1042(1.1038) | Xent 0.0479(0.0456) | Loss 1.1282(1.1266) | Error 0.0141(0.0141) Steps 440(437.06) | Grad Norm 0.2971(0.2547) | Total Time 10.00(10.00)\n",
      "Iter 2896 | Time 30.9333(31.1507) | Bit/dim 1.1069(1.1038) | Xent 0.0465(0.0456) | Loss 1.1301(1.1267) | Error 0.0155(0.0141) Steps 440(437.15) | Grad Norm 0.2386(0.2542) | Total Time 10.00(10.00)\n",
      "Iter 2897 | Time 31.0762(31.1484) | Bit/dim 1.1004(1.1037) | Xent 0.0463(0.0456) | Loss 1.1236(1.1266) | Error 0.0148(0.0141) Steps 440(437.23) | Grad Norm 0.2599(0.2543) | Total Time 10.00(10.00)\n",
      "Iter 2898 | Time 31.2512(31.1515) | Bit/dim 1.0952(1.1035) | Xent 0.0420(0.0455) | Loss 1.1162(1.1263) | Error 0.0120(0.0141) Steps 440(437.32) | Grad Norm 0.2788(0.2551) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 17.3841, Epoch Time 247.6040(245.0518), Bit/dim 1.0988(best: 1.0976), Xent 0.0343, Loss 1.1159, Error 0.0098(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2899 | Time 32.3938(31.1888) | Bit/dim 1.1008(1.1034) | Xent 0.0484(0.0456) | Loss 1.1251(1.1262) | Error 0.0151(0.0141) Steps 440(437.40) | Grad Norm 0.2155(0.2539) | Total Time 10.00(10.00)\n",
      "Iter 2900 | Time 31.3046(31.1923) | Bit/dim 1.1065(1.1035) | Xent 0.0437(0.0456) | Loss 1.1283(1.1263) | Error 0.0128(0.0140) Steps 440(437.48) | Grad Norm 0.2662(0.2543) | Total Time 10.00(10.00)\n",
      "Iter 2901 | Time 31.6808(31.2069) | Bit/dim 1.1027(1.1035) | Xent 0.0440(0.0455) | Loss 1.1247(1.1262) | Error 0.0145(0.0141) Steps 440(437.55) | Grad Norm 0.2385(0.2538) | Total Time 10.00(10.00)\n",
      "Iter 2902 | Time 30.9512(31.1992) | Bit/dim 1.1057(1.1035) | Xent 0.0443(0.0455) | Loss 1.1279(1.1263) | Error 0.0141(0.0141) Steps 440(437.63) | Grad Norm 0.1602(0.2510) | Total Time 10.00(10.00)\n",
      "Iter 2903 | Time 32.2559(31.2309) | Bit/dim 1.1001(1.1034) | Xent 0.0463(0.0455) | Loss 1.1233(1.1262) | Error 0.0142(0.0141) Steps 440(437.70) | Grad Norm 0.2320(0.2504) | Total Time 10.00(10.00)\n",
      "Iter 2904 | Time 31.0045(31.2242) | Bit/dim 1.1080(1.1036) | Xent 0.0450(0.0455) | Loss 1.1305(1.1263) | Error 0.0132(0.0140) Steps 440(437.77) | Grad Norm 0.3160(0.2524) | Total Time 10.00(10.00)\n",
      "Iter 2905 | Time 31.1853(31.2230) | Bit/dim 1.1027(1.1036) | Xent 0.0514(0.0457) | Loss 1.1284(1.1264) | Error 0.0161(0.0141) Steps 440(437.83) | Grad Norm 0.1880(0.2504) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 17.5907, Epoch Time 250.8319(245.2252), Bit/dim 1.0986(best: 1.0976), Xent 0.0330, Loss 1.1151, Error 0.0106(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2906 | Time 32.0335(31.2473) | Bit/dim 1.1071(1.1037) | Xent 0.0495(0.0458) | Loss 1.1318(1.1266) | Error 0.0158(0.0142) Steps 440(437.90) | Grad Norm 0.2658(0.2509) | Total Time 10.00(10.00)\n",
      "Iter 2907 | Time 31.2210(31.2465) | Bit/dim 1.1038(1.1037) | Xent 0.0468(0.0458) | Loss 1.1272(1.1266) | Error 0.0156(0.0142) Steps 440(437.96) | Grad Norm 0.2534(0.2510) | Total Time 10.00(10.00)\n",
      "Iter 2908 | Time 30.9910(31.2389) | Bit/dim 1.1018(1.1036) | Xent 0.0413(0.0457) | Loss 1.1224(1.1264) | Error 0.0140(0.0142) Steps 440(438.02) | Grad Norm 0.1857(0.2490) | Total Time 10.00(10.00)\n",
      "Iter 2909 | Time 30.8917(31.2284) | Bit/dim 1.1015(1.1035) | Xent 0.0481(0.0458) | Loss 1.1255(1.1264) | Error 0.0149(0.0142) Steps 440(438.08) | Grad Norm 0.2570(0.2493) | Total Time 10.00(10.00)\n",
      "Iter 2910 | Time 31.0179(31.2221) | Bit/dim 1.1061(1.1036) | Xent 0.0459(0.0458) | Loss 1.1291(1.1265) | Error 0.0139(0.0142) Steps 440(438.14) | Grad Norm 0.3965(0.2537) | Total Time 10.00(10.00)\n",
      "Iter 2911 | Time 31.3137(31.2249) | Bit/dim 1.1025(1.1036) | Xent 0.0536(0.0460) | Loss 1.1293(1.1266) | Error 0.0160(0.0143) Steps 440(438.19) | Grad Norm 0.2361(0.2532) | Total Time 10.00(10.00)\n",
      "Iter 2912 | Time 30.9108(31.2154) | Bit/dim 1.0995(1.1035) | Xent 0.0391(0.0458) | Loss 1.1190(1.1264) | Error 0.0118(0.0142) Steps 440(438.25) | Grad Norm 0.2942(0.2544) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 17.7334, Epoch Time 248.9018(245.3355), Bit/dim 1.0984(best: 1.0976), Xent 0.0330, Loss 1.1149, Error 0.0102(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2913 | Time 31.5263(31.2248) | Bit/dim 1.1011(1.1034) | Xent 0.0491(0.0459) | Loss 1.1256(1.1263) | Error 0.0155(0.0142) Steps 440(438.30) | Grad Norm 0.2794(0.2551) | Total Time 10.00(10.00)\n",
      "Iter 2914 | Time 32.2799(31.2564) | Bit/dim 1.1032(1.1034) | Xent 0.0383(0.0457) | Loss 1.1223(1.1262) | Error 0.0115(0.0141) Steps 440(438.35) | Grad Norm 0.3229(0.2572) | Total Time 10.00(10.00)\n",
      "Iter 2915 | Time 30.8411(31.2440) | Bit/dim 1.1046(1.1034) | Xent 0.0432(0.0456) | Loss 1.1262(1.1262) | Error 0.0130(0.0141) Steps 440(438.40) | Grad Norm 0.2980(0.2584) | Total Time 10.00(10.00)\n",
      "Iter 2916 | Time 30.9384(31.2348) | Bit/dim 1.1056(1.1035) | Xent 0.0433(0.0455) | Loss 1.1273(1.1263) | Error 0.0128(0.0141) Steps 440(438.45) | Grad Norm 0.2449(0.2580) | Total Time 10.00(10.00)\n",
      "Iter 2917 | Time 30.8545(31.2234) | Bit/dim 1.1041(1.1035) | Xent 0.0458(0.0455) | Loss 1.1270(1.1263) | Error 0.0142(0.0141) Steps 440(438.50) | Grad Norm 0.3190(0.2598) | Total Time 10.00(10.00)\n",
      "Iter 2918 | Time 31.2649(31.2246) | Bit/dim 1.1002(1.1034) | Xent 0.0492(0.0456) | Loss 1.1248(1.1262) | Error 0.0162(0.0141) Steps 440(438.54) | Grad Norm 0.2556(0.2597) | Total Time 10.00(10.00)\n",
      "Iter 2919 | Time 31.3874(31.2295) | Bit/dim 1.1036(1.1034) | Xent 0.0461(0.0457) | Loss 1.1267(1.1262) | Error 0.0141(0.0141) Steps 440(438.59) | Grad Norm 0.4040(0.2640) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 17.6200, Epoch Time 249.2787(245.4538), Bit/dim 1.0977(best: 1.0976), Xent 0.0324, Loss 1.1139, Error 0.0097(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2920 | Time 31.5560(31.2393) | Bit/dim 1.1039(1.1034) | Xent 0.0419(0.0455) | Loss 1.1248(1.1262) | Error 0.0121(0.0141) Steps 440(438.63) | Grad Norm 0.3395(0.2663) | Total Time 10.00(10.00)\n",
      "Iter 2921 | Time 32.0500(31.2636) | Bit/dim 1.1027(1.1034) | Xent 0.0444(0.0455) | Loss 1.1249(1.1262) | Error 0.0159(0.0141) Steps 440(438.67) | Grad Norm 0.2443(0.2656) | Total Time 10.00(10.00)\n",
      "Iter 2922 | Time 30.9756(31.2550) | Bit/dim 1.1051(1.1035) | Xent 0.0492(0.0456) | Loss 1.1297(1.1263) | Error 0.0142(0.0141) Steps 440(438.71) | Grad Norm 0.3046(0.2668) | Total Time 10.00(10.00)\n",
      "Iter 2923 | Time 31.0966(31.2502) | Bit/dim 1.1063(1.1035) | Xent 0.0463(0.0456) | Loss 1.1295(1.1264) | Error 0.0126(0.0141) Steps 440(438.75) | Grad Norm 0.2360(0.2659) | Total Time 10.00(10.00)\n",
      "Iter 2924 | Time 31.7154(31.2642) | Bit/dim 1.1000(1.1034) | Xent 0.0466(0.0457) | Loss 1.1233(1.1263) | Error 0.0139(0.0141) Steps 440(438.78) | Grad Norm 0.4048(0.2700) | Total Time 10.00(10.00)\n",
      "Iter 2925 | Time 31.9938(31.2861) | Bit/dim 1.1066(1.1035) | Xent 0.0455(0.0457) | Loss 1.1293(1.1264) | Error 0.0131(0.0141) Steps 440(438.82) | Grad Norm 0.1812(0.2674) | Total Time 10.00(10.00)\n",
      "Iter 2926 | Time 31.3395(31.2877) | Bit/dim 1.1026(1.1035) | Xent 0.0393(0.0455) | Loss 1.1223(1.1262) | Error 0.0138(0.0140) Steps 440(438.86) | Grad Norm 0.2554(0.2670) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 17.8390, Epoch Time 251.2363(245.6273), Bit/dim 1.0984(best: 1.0976), Xent 0.0341, Loss 1.1154, Error 0.0108(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2927 | Time 31.0959(31.2819) | Bit/dim 1.1012(1.1034) | Xent 0.0420(0.0454) | Loss 1.1222(1.1261) | Error 0.0121(0.0140) Steps 440(438.89) | Grad Norm 0.2649(0.2669) | Total Time 10.00(10.00)\n",
      "Iter 2928 | Time 30.9239(31.2712) | Bit/dim 1.1106(1.1037) | Xent 0.0512(0.0455) | Loss 1.1362(1.1264) | Error 0.0136(0.0140) Steps 440(438.92) | Grad Norm 0.2526(0.2665) | Total Time 10.00(10.00)\n",
      "Iter 2929 | Time 30.9862(31.2626) | Bit/dim 1.1012(1.1036) | Xent 0.0435(0.0455) | Loss 1.1229(1.1263) | Error 0.0126(0.0139) Steps 440(438.96) | Grad Norm 0.2445(0.2659) | Total Time 10.00(10.00)\n",
      "Iter 2930 | Time 31.7321(31.2767) | Bit/dim 1.1082(1.1037) | Xent 0.0450(0.0455) | Loss 1.1307(1.1265) | Error 0.0132(0.0139) Steps 440(438.99) | Grad Norm 0.2678(0.2659) | Total Time 10.00(10.00)\n",
      "Iter 2931 | Time 31.5134(31.2838) | Bit/dim 1.1011(1.1036) | Xent 0.0459(0.0455) | Loss 1.1240(1.1264) | Error 0.0138(0.0139) Steps 440(439.02) | Grad Norm 0.2020(0.2640) | Total Time 10.00(10.00)\n",
      "Iter 2932 | Time 31.0186(31.2759) | Bit/dim 1.1042(1.1037) | Xent 0.0476(0.0455) | Loss 1.1280(1.1264) | Error 0.0151(0.0139) Steps 440(439.05) | Grad Norm 0.2630(0.2640) | Total Time 10.00(10.00)\n",
      "Iter 2933 | Time 31.1877(31.2732) | Bit/dim 1.0992(1.1035) | Xent 0.0400(0.0454) | Loss 1.1192(1.1262) | Error 0.0131(0.0139) Steps 440(439.08) | Grad Norm 0.2200(0.2627) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 17.6181, Epoch Time 248.7902(245.7222), Bit/dim 1.0968(best: 1.0976), Xent 0.0326, Loss 1.1131, Error 0.0101(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2934 | Time 30.7962(31.2589) | Bit/dim 1.1038(1.1035) | Xent 0.0397(0.0452) | Loss 1.1237(1.1261) | Error 0.0121(0.0139) Steps 440(439.10) | Grad Norm 0.1867(0.2604) | Total Time 10.00(10.00)\n",
      "Iter 2935 | Time 32.1549(31.2858) | Bit/dim 1.1000(1.1034) | Xent 0.0435(0.0452) | Loss 1.1218(1.1260) | Error 0.0138(0.0139) Steps 440(439.13) | Grad Norm 0.2876(0.2612) | Total Time 10.00(10.00)\n",
      "Iter 2936 | Time 31.0793(31.2796) | Bit/dim 1.1041(1.1034) | Xent 0.0487(0.0453) | Loss 1.1285(1.1261) | Error 0.0129(0.0138) Steps 440(439.16) | Grad Norm 0.2348(0.2604) | Total Time 10.00(10.00)\n",
      "Iter 2937 | Time 32.1125(31.3046) | Bit/dim 1.1041(1.1035) | Xent 0.0431(0.0452) | Loss 1.1257(1.1261) | Error 0.0126(0.0138) Steps 440(439.18) | Grad Norm 0.3283(0.2624) | Total Time 10.00(10.00)\n",
      "Iter 2938 | Time 30.7166(31.2869) | Bit/dim 1.1052(1.1035) | Xent 0.0463(0.0452) | Loss 1.1283(1.1261) | Error 0.0144(0.0138) Steps 440(439.21) | Grad Norm 0.2402(0.2618) | Total Time 10.00(10.00)\n",
      "Iter 2939 | Time 30.9243(31.2761) | Bit/dim 1.1009(1.1034) | Xent 0.0460(0.0453) | Loss 1.1240(1.1261) | Error 0.0151(0.0139) Steps 440(439.23) | Grad Norm 0.3027(0.2630) | Total Time 10.00(10.00)\n",
      "Iter 2940 | Time 32.1992(31.3038) | Bit/dim 1.1033(1.1034) | Xent 0.0530(0.0455) | Loss 1.1298(1.1262) | Error 0.0155(0.0139) Steps 440(439.25) | Grad Norm 0.3458(0.2655) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 17.5087, Epoch Time 250.4139(245.8629), Bit/dim 1.0980(best: 1.0968), Xent 0.0308, Loss 1.1133, Error 0.0098(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2941 | Time 31.0219(31.2953) | Bit/dim 1.1054(1.1035) | Xent 0.0377(0.0453) | Loss 1.1242(1.1261) | Error 0.0099(0.0138) Steps 440(439.28) | Grad Norm 0.1913(0.2633) | Total Time 10.00(10.00)\n",
      "Iter 2942 | Time 31.2761(31.2947) | Bit/dim 1.1073(1.1036) | Xent 0.0461(0.0453) | Loss 1.1303(1.1263) | Error 0.0148(0.0138) Steps 440(439.30) | Grad Norm 0.1974(0.2613) | Total Time 10.00(10.00)\n",
      "Iter 2943 | Time 31.1143(31.2893) | Bit/dim 1.0976(1.1034) | Xent 0.0378(0.0451) | Loss 1.1165(1.1260) | Error 0.0126(0.0138) Steps 440(439.32) | Grad Norm 0.2013(0.2595) | Total Time 10.00(10.00)\n",
      "Iter 2944 | Time 32.7557(31.3333) | Bit/dim 1.1029(1.1034) | Xent 0.0428(0.0450) | Loss 1.1242(1.1259) | Error 0.0134(0.0138) Steps 440(439.34) | Grad Norm 0.3000(0.2607) | Total Time 10.00(10.00)\n",
      "Iter 2945 | Time 31.0897(31.3260) | Bit/dim 1.1035(1.1034) | Xent 0.0515(0.0452) | Loss 1.1292(1.1260) | Error 0.0148(0.0138) Steps 440(439.36) | Grad Norm 0.3423(0.2631) | Total Time 10.00(10.00)\n",
      "Iter 2946 | Time 31.0852(31.3188) | Bit/dim 1.1050(1.1035) | Xent 0.0477(0.0453) | Loss 1.1288(1.1261) | Error 0.0136(0.0138) Steps 440(439.38) | Grad Norm 0.2150(0.2617) | Total Time 10.00(10.00)\n",
      "Iter 2947 | Time 31.5864(31.3268) | Bit/dim 1.1022(1.1034) | Xent 0.0576(0.0456) | Loss 1.1310(1.1262) | Error 0.0162(0.0139) Steps 440(439.40) | Grad Norm 0.2055(0.2600) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 17.6764, Epoch Time 250.4419(246.0003), Bit/dim 1.0982(best: 1.0968), Xent 0.0329, Loss 1.1146, Error 0.0102(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2948 | Time 32.2831(31.3555) | Bit/dim 1.0989(1.1033) | Xent 0.0429(0.0455) | Loss 1.1203(1.1261) | Error 0.0131(0.0138) Steps 440(439.42) | Grad Norm 0.2460(0.2596) | Total Time 10.00(10.00)\n",
      "Iter 2949 | Time 31.8894(31.3715) | Bit/dim 1.1010(1.1032) | Xent 0.0426(0.0455) | Loss 1.1223(1.1259) | Error 0.0121(0.0138) Steps 440(439.43) | Grad Norm 0.3277(0.2616) | Total Time 10.00(10.00)\n",
      "Iter 2950 | Time 31.1907(31.3661) | Bit/dim 1.1031(1.1032) | Xent 0.0526(0.0457) | Loss 1.1294(1.1261) | Error 0.0144(0.0138) Steps 440(439.45) | Grad Norm 0.3240(0.2635) | Total Time 10.00(10.00)\n",
      "Iter 2951 | Time 31.3131(31.3645) | Bit/dim 1.1054(1.1033) | Xent 0.0450(0.0457) | Loss 1.1279(1.1261) | Error 0.0129(0.0138) Steps 440(439.47) | Grad Norm 0.3240(0.2653) | Total Time 10.00(10.00)\n",
      "Iter 2952 | Time 30.6271(31.3424) | Bit/dim 1.1045(1.1033) | Xent 0.0431(0.0456) | Loss 1.1261(1.1261) | Error 0.0148(0.0138) Steps 440(439.48) | Grad Norm 0.2022(0.2634) | Total Time 10.00(10.00)\n",
      "Iter 2953 | Time 31.2832(31.3406) | Bit/dim 1.1050(1.1034) | Xent 0.0426(0.0455) | Loss 1.1262(1.1261) | Error 0.0125(0.0138) Steps 440(439.50) | Grad Norm 0.2582(0.2633) | Total Time 10.00(10.00)\n",
      "Iter 2954 | Time 31.5012(31.3454) | Bit/dim 1.1029(1.1034) | Xent 0.0471(0.0455) | Loss 1.1264(1.1261) | Error 0.0142(0.0138) Steps 440(439.51) | Grad Norm 0.2481(0.2628) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 17.5849, Epoch Time 250.1725(246.1255), Bit/dim 1.0973(best: 1.0968), Xent 0.0329, Loss 1.1138, Error 0.0098(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2955 | Time 31.0491(31.3365) | Bit/dim 1.0989(1.1032) | Xent 0.0530(0.0458) | Loss 1.1254(1.1261) | Error 0.0162(0.0139) Steps 440(439.53) | Grad Norm 0.3933(0.2667) | Total Time 10.00(10.00)\n",
      "Iter 2956 | Time 30.9803(31.3258) | Bit/dim 1.1020(1.1032) | Xent 0.0471(0.0458) | Loss 1.1256(1.1261) | Error 0.0145(0.0139) Steps 440(439.54) | Grad Norm 0.2808(0.2672) | Total Time 10.00(10.00)\n",
      "Iter 2957 | Time 31.5563(31.3328) | Bit/dim 1.1074(1.1033) | Xent 0.0455(0.0458) | Loss 1.1301(1.1262) | Error 0.0126(0.0138) Steps 440(439.56) | Grad Norm 0.2493(0.2666) | Total Time 10.00(10.00)\n",
      "Iter 2958 | Time 31.6982(31.3437) | Bit/dim 1.1050(1.1034) | Xent 0.0454(0.0458) | Loss 1.1276(1.1262) | Error 0.0145(0.0139) Steps 440(439.57) | Grad Norm 0.2463(0.2660) | Total Time 10.00(10.00)\n",
      "Iter 2959 | Time 31.4644(31.3473) | Bit/dim 1.1056(1.1034) | Xent 0.0411(0.0456) | Loss 1.1261(1.1262) | Error 0.0129(0.0138) Steps 440(439.58) | Grad Norm 0.2591(0.2658) | Total Time 10.00(10.00)\n",
      "Iter 2960 | Time 32.0936(31.3697) | Bit/dim 1.1002(1.1033) | Xent 0.0433(0.0456) | Loss 1.1219(1.1261) | Error 0.0142(0.0138) Steps 440(439.59) | Grad Norm 0.1928(0.2636) | Total Time 10.00(10.00)\n",
      "Iter 2961 | Time 33.3773(31.4300) | Bit/dim 1.1056(1.1034) | Xent 0.0439(0.0455) | Loss 1.1275(1.1262) | Error 0.0135(0.0138) Steps 440(439.61) | Grad Norm 0.2154(0.2622) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 17.8483, Epoch Time 252.5782(246.3190), Bit/dim 1.0976(best: 1.0968), Xent 0.0339, Loss 1.1146, Error 0.0098(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2962 | Time 30.9576(31.4158) | Bit/dim 1.1035(1.1034) | Xent 0.0421(0.0454) | Loss 1.1245(1.1261) | Error 0.0130(0.0138) Steps 440(439.62) | Grad Norm 0.2336(0.2613) | Total Time 10.00(10.00)\n",
      "Iter 2963 | Time 30.6906(31.3940) | Bit/dim 1.1043(1.1034) | Xent 0.0460(0.0454) | Loss 1.1273(1.1261) | Error 0.0138(0.0138) Steps 440(439.63) | Grad Norm 0.2689(0.2615) | Total Time 10.00(10.00)\n",
      "Iter 2964 | Time 30.8026(31.3763) | Bit/dim 1.1045(1.1035) | Xent 0.0487(0.0455) | Loss 1.1288(1.1262) | Error 0.0145(0.0138) Steps 440(439.64) | Grad Norm 0.2880(0.2623) | Total Time 10.00(10.00)\n",
      "Iter 2965 | Time 31.4303(31.3779) | Bit/dim 1.1013(1.1034) | Xent 0.0488(0.0456) | Loss 1.1257(1.1262) | Error 0.0162(0.0139) Steps 440(439.65) | Grad Norm 0.2330(0.2615) | Total Time 10.00(10.00)\n",
      "Iter 2966 | Time 31.1510(31.3711) | Bit/dim 1.1021(1.1034) | Xent 0.0458(0.0456) | Loss 1.1250(1.1262) | Error 0.0135(0.0139) Steps 440(439.66) | Grad Norm 0.2633(0.2615) | Total Time 10.00(10.00)\n",
      "Iter 2967 | Time 32.1649(31.3949) | Bit/dim 1.1034(1.1034) | Xent 0.0420(0.0455) | Loss 1.1244(1.1261) | Error 0.0135(0.0139) Steps 440(439.67) | Grad Norm 0.4498(0.2672) | Total Time 10.00(10.00)\n",
      "Iter 2968 | Time 32.9399(31.4413) | Bit/dim 1.1049(1.1034) | Xent 0.0469(0.0456) | Loss 1.1283(1.1262) | Error 0.0141(0.0139) Steps 440(439.68) | Grad Norm 0.2220(0.2658) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 17.5126, Epoch Time 250.3177(246.4390), Bit/dim 1.0976(best: 1.0968), Xent 0.0320, Loss 1.1136, Error 0.0096(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2969 | Time 31.0099(31.4283) | Bit/dim 1.1009(1.1033) | Xent 0.0457(0.0456) | Loss 1.1237(1.1261) | Error 0.0138(0.0139) Steps 440(439.69) | Grad Norm 0.4151(0.2703) | Total Time 10.00(10.00)\n",
      "Iter 2970 | Time 30.9888(31.4151) | Bit/dim 1.1038(1.1033) | Xent 0.0478(0.0456) | Loss 1.1278(1.1262) | Error 0.0149(0.0139) Steps 440(439.70) | Grad Norm 0.4377(0.2753) | Total Time 10.00(10.00)\n",
      "Iter 2971 | Time 31.1673(31.4077) | Bit/dim 1.1069(1.1035) | Xent 0.0429(0.0456) | Loss 1.1284(1.1262) | Error 0.0132(0.0139) Steps 440(439.71) | Grad Norm 0.2767(0.2754) | Total Time 10.00(10.00)\n",
      "Iter 2972 | Time 30.7393(31.3877) | Bit/dim 1.1077(1.1036) | Xent 0.0400(0.0454) | Loss 1.1277(1.1263) | Error 0.0124(0.0138) Steps 440(439.72) | Grad Norm 0.2803(0.2755) | Total Time 10.00(10.00)\n",
      "Iter 2973 | Time 30.9955(31.3759) | Bit/dim 1.1001(1.1035) | Xent 0.0484(0.0455) | Loss 1.1242(1.1262) | Error 0.0145(0.0139) Steps 440(439.73) | Grad Norm 0.3902(0.2789) | Total Time 10.00(10.00)\n",
      "Iter 2974 | Time 31.1161(31.3681) | Bit/dim 1.0982(1.1033) | Xent 0.0476(0.0455) | Loss 1.1220(1.1261) | Error 0.0158(0.0139) Steps 440(439.74) | Grad Norm 0.2500(0.2781) | Total Time 10.00(10.00)\n",
      "Iter 2975 | Time 31.0122(31.3574) | Bit/dim 1.1030(1.1033) | Xent 0.0539(0.0458) | Loss 1.1299(1.1262) | Error 0.0151(0.0140) Steps 440(439.74) | Grad Norm 0.2821(0.2782) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 17.6593, Epoch Time 247.2314(246.4628), Bit/dim 1.0977(best: 1.0968), Xent 0.0320, Loss 1.1137, Error 0.0093(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2976 | Time 31.2177(31.3532) | Bit/dim 1.1023(1.1033) | Xent 0.0497(0.0459) | Loss 1.1272(1.1262) | Error 0.0158(0.0140) Steps 440(439.75) | Grad Norm 0.2256(0.2766) | Total Time 10.00(10.00)\n",
      "Iter 2977 | Time 30.8922(31.3394) | Bit/dim 1.1036(1.1033) | Xent 0.0466(0.0459) | Loss 1.1269(1.1263) | Error 0.0160(0.0141) Steps 440(439.76) | Grad Norm 0.2884(0.2770) | Total Time 10.00(10.00)\n",
      "Iter 2978 | Time 31.1401(31.3334) | Bit/dim 1.1038(1.1033) | Xent 0.0413(0.0458) | Loss 1.1244(1.1262) | Error 0.0121(0.0140) Steps 440(439.77) | Grad Norm 0.3375(0.2788) | Total Time 10.00(10.00)\n",
      "Iter 2979 | Time 31.2748(31.3317) | Bit/dim 1.1053(1.1034) | Xent 0.0405(0.0456) | Loss 1.1255(1.1262) | Error 0.0125(0.0140) Steps 440(439.77) | Grad Norm 0.3192(0.2800) | Total Time 10.00(10.00)\n",
      "Iter 2980 | Time 31.3839(31.3332) | Bit/dim 1.1034(1.1034) | Xent 0.0436(0.0456) | Loss 1.1252(1.1261) | Error 0.0139(0.0140) Steps 440(439.78) | Grad Norm 0.2582(0.2793) | Total Time 10.00(10.00)\n",
      "Iter 2981 | Time 33.9298(31.4111) | Bit/dim 1.1010(1.1033) | Xent 0.0490(0.0457) | Loss 1.1256(1.1261) | Error 0.0159(0.0140) Steps 440(439.79) | Grad Norm 0.4652(0.2849) | Total Time 10.00(10.00)\n",
      "Iter 2982 | Time 31.5449(31.4151) | Bit/dim 1.1036(1.1033) | Xent 0.0520(0.0459) | Loss 1.1296(1.1262) | Error 0.0145(0.0140) Steps 440(439.79) | Grad Norm 0.5246(0.2921) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 17.6415, Epoch Time 252.1739(246.6341), Bit/dim 1.0977(best: 1.0968), Xent 0.0312, Loss 1.1134, Error 0.0092(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2983 | Time 32.0502(31.4342) | Bit/dim 1.1000(1.1032) | Xent 0.0412(0.0457) | Loss 1.1206(1.1261) | Error 0.0122(0.0140) Steps 440(439.80) | Grad Norm 0.2238(0.2901) | Total Time 10.00(10.00)\n",
      "Iter 2984 | Time 31.3524(31.4317) | Bit/dim 1.1047(1.1032) | Xent 0.0423(0.0456) | Loss 1.1259(1.1261) | Error 0.0138(0.0140) Steps 440(439.80) | Grad Norm 0.3502(0.2919) | Total Time 10.00(10.00)\n",
      "Iter 2985 | Time 31.1836(31.4243) | Bit/dim 1.1010(1.1032) | Xent 0.0498(0.0457) | Loss 1.1259(1.1261) | Error 0.0142(0.0140) Steps 440(439.81) | Grad Norm 0.3541(0.2937) | Total Time 10.00(10.00)\n",
      "Iter 2986 | Time 31.4049(31.4237) | Bit/dim 1.1072(1.1033) | Xent 0.0470(0.0458) | Loss 1.1307(1.1262) | Error 0.0132(0.0140) Steps 440(439.82) | Grad Norm 0.2211(0.2916) | Total Time 10.00(10.00)\n",
      "Iter 2987 | Time 31.2327(31.4180) | Bit/dim 1.1004(1.1032) | Xent 0.0488(0.0459) | Loss 1.1248(1.1262) | Error 0.0151(0.0140) Steps 440(439.82) | Grad Norm 0.2013(0.2888) | Total Time 10.00(10.00)\n",
      "Iter 2988 | Time 31.3606(31.4163) | Bit/dim 1.1041(1.1032) | Xent 0.0448(0.0458) | Loss 1.1265(1.1262) | Error 0.0136(0.0140) Steps 440(439.83) | Grad Norm 0.4406(0.2934) | Total Time 10.00(10.00)\n",
      "Iter 2989 | Time 31.2069(31.4100) | Bit/dim 1.1026(1.1032) | Xent 0.0492(0.0459) | Loss 1.1272(1.1262) | Error 0.0154(0.0140) Steps 440(439.83) | Grad Norm 0.4120(0.2970) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 17.4864, Epoch Time 249.7565(246.7278), Bit/dim 1.0979(best: 1.0968), Xent 0.0329, Loss 1.1143, Error 0.0101(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2990 | Time 31.7652(31.4206) | Bit/dim 1.1026(1.1032) | Xent 0.0418(0.0458) | Loss 1.1235(1.1261) | Error 0.0120(0.0140) Steps 440(439.84) | Grad Norm 0.1919(0.2938) | Total Time 10.00(10.00)\n",
      "Iter 2991 | Time 31.4648(31.4220) | Bit/dim 1.1030(1.1032) | Xent 0.0481(0.0459) | Loss 1.1270(1.1261) | Error 0.0151(0.0140) Steps 440(439.84) | Grad Norm 0.2314(0.2919) | Total Time 10.00(10.00)\n",
      "Iter 2992 | Time 30.9207(31.4069) | Bit/dim 1.1003(1.1031) | Xent 0.0458(0.0459) | Loss 1.1231(1.1260) | Error 0.0136(0.0140) Steps 440(439.85) | Grad Norm 0.4757(0.2974) | Total Time 10.00(10.00)\n",
      "Iter 2993 | Time 32.5778(31.4421) | Bit/dim 1.1030(1.1031) | Xent 0.0412(0.0457) | Loss 1.1237(1.1260) | Error 0.0121(0.0139) Steps 440(439.85) | Grad Norm 0.4460(0.3019) | Total Time 10.00(10.00)\n",
      "Iter 2994 | Time 32.5056(31.4740) | Bit/dim 1.1027(1.1031) | Xent 0.0451(0.0457) | Loss 1.1253(1.1260) | Error 0.0142(0.0139) Steps 440(439.86) | Grad Norm 0.2390(0.3000) | Total Time 10.00(10.00)\n",
      "Iter 2995 | Time 31.3748(31.4710) | Bit/dim 1.1002(1.1030) | Xent 0.0457(0.0457) | Loss 1.1230(1.1259) | Error 0.0146(0.0140) Steps 440(439.86) | Grad Norm 0.5114(0.3064) | Total Time 10.00(10.00)\n",
      "Iter 2996 | Time 30.9009(31.4539) | Bit/dim 1.1082(1.1032) | Xent 0.0421(0.0456) | Loss 1.1292(1.1260) | Error 0.0145(0.0140) Steps 440(439.86) | Grad Norm 0.3261(0.3069) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 17.5935, Epoch Time 251.9823(246.8854), Bit/dim 1.0976(best: 1.0968), Xent 0.0331, Loss 1.1142, Error 0.0108(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2997 | Time 30.9145(31.4377) | Bit/dim 1.0983(1.1030) | Xent 0.0495(0.0457) | Loss 1.1231(1.1259) | Error 0.0150(0.0140) Steps 440(439.87) | Grad Norm 0.1948(0.3036) | Total Time 10.00(10.00)\n",
      "Iter 2998 | Time 30.8657(31.4205) | Bit/dim 1.1046(1.1031) | Xent 0.0454(0.0457) | Loss 1.1273(1.1259) | Error 0.0142(0.0140) Steps 440(439.87) | Grad Norm 0.2307(0.3014) | Total Time 10.00(10.00)\n",
      "Iter 2999 | Time 32.3251(31.4477) | Bit/dim 1.1019(1.1030) | Xent 0.0403(0.0456) | Loss 1.1220(1.1258) | Error 0.0128(0.0140) Steps 440(439.88) | Grad Norm 0.5102(0.3077) | Total Time 10.00(10.00)\n",
      "Iter 3000 | Time 31.1295(31.4381) | Bit/dim 1.1052(1.1031) | Xent 0.0439(0.0455) | Loss 1.1272(1.1258) | Error 0.0145(0.0140) Steps 440(439.88) | Grad Norm 0.1898(0.3041) | Total Time 10.00(10.00)\n",
      "Iter 3001 | Time 32.8104(31.4793) | Bit/dim 1.1028(1.1031) | Xent 0.0428(0.0454) | Loss 1.1242(1.1258) | Error 0.0131(0.0140) Steps 440(439.88) | Grad Norm 0.3677(0.3060) | Total Time 10.00(10.00)\n",
      "Iter 3002 | Time 32.2951(31.5038) | Bit/dim 1.0990(1.1030) | Xent 0.0445(0.0454) | Loss 1.1212(1.1257) | Error 0.0125(0.0139) Steps 440(439.89) | Grad Norm 0.2465(0.3042) | Total Time 10.00(10.00)\n",
      "Iter 3003 | Time 32.2970(31.5276) | Bit/dim 1.1065(1.1031) | Xent 0.0501(0.0455) | Loss 1.1315(1.1258) | Error 0.0139(0.0139) Steps 440(439.89) | Grad Norm 0.2648(0.3031) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 17.6704, Epoch Time 253.0114(247.0692), Bit/dim 1.0974(best: 1.0968), Xent 0.0322, Loss 1.1135, Error 0.0100(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3004 | Time 31.0426(31.5130) | Bit/dim 1.1025(1.1030) | Xent 0.0510(0.0457) | Loss 1.1279(1.1259) | Error 0.0151(0.0140) Steps 440(439.89) | Grad Norm 0.2408(0.3012) | Total Time 10.00(10.00)\n",
      "Iter 3005 | Time 31.5171(31.5131) | Bit/dim 1.1022(1.1030) | Xent 0.0466(0.0457) | Loss 1.1256(1.1259) | Error 0.0152(0.0140) Steps 440(439.90) | Grad Norm 0.1895(0.2978) | Total Time 10.00(10.00)\n",
      "Iter 3006 | Time 32.3728(31.5389) | Bit/dim 1.1003(1.1029) | Xent 0.0415(0.0456) | Loss 1.1211(1.1257) | Error 0.0125(0.0140) Steps 440(439.90) | Grad Norm 0.2173(0.2954) | Total Time 10.00(10.00)\n",
      "Iter 3007 | Time 31.1148(31.5262) | Bit/dim 1.1041(1.1030) | Xent 0.0402(0.0454) | Loss 1.1242(1.1257) | Error 0.0135(0.0139) Steps 440(439.90) | Grad Norm 0.2449(0.2939) | Total Time 10.00(10.00)\n",
      "Iter 3008 | Time 32.3214(31.5501) | Bit/dim 1.1039(1.1030) | Xent 0.0501(0.0456) | Loss 1.1289(1.1258) | Error 0.0150(0.0140) Steps 440(439.91) | Grad Norm 0.2294(0.2920) | Total Time 10.00(10.00)\n",
      "Iter 3009 | Time 31.4523(31.5471) | Bit/dim 1.1042(1.1030) | Xent 0.0403(0.0454) | Loss 1.1244(1.1258) | Error 0.0132(0.0139) Steps 440(439.91) | Grad Norm 0.2326(0.2902) | Total Time 10.00(10.00)\n",
      "Iter 3010 | Time 31.0814(31.5332) | Bit/dim 1.1023(1.1030) | Xent 0.0404(0.0453) | Loss 1.1225(1.1257) | Error 0.0125(0.0139) Steps 440(439.91) | Grad Norm 0.1953(0.2873) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 17.5652, Epoch Time 251.0085(247.1874), Bit/dim 1.0974(best: 1.0968), Xent 0.0322, Loss 1.1135, Error 0.0095(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3011 | Time 30.9233(31.5149) | Bit/dim 1.1044(1.1031) | Xent 0.0450(0.0453) | Loss 1.1269(1.1257) | Error 0.0149(0.0139) Steps 440(439.91) | Grad Norm 0.3946(0.2906) | Total Time 10.00(10.00)\n",
      "Iter 3012 | Time 33.0007(31.5594) | Bit/dim 1.1027(1.1031) | Xent 0.0414(0.0451) | Loss 1.1234(1.1256) | Error 0.0126(0.0139) Steps 440(439.92) | Grad Norm 0.2410(0.2891) | Total Time 10.00(10.00)\n",
      "Iter 3013 | Time 30.9170(31.5402) | Bit/dim 1.1013(1.1030) | Xent 0.0377(0.0449) | Loss 1.1202(1.1255) | Error 0.0122(0.0138) Steps 440(439.92) | Grad Norm 0.4721(0.2946) | Total Time 10.00(10.00)\n",
      "Iter 3014 | Time 32.2639(31.5619) | Bit/dim 1.1047(1.1031) | Xent 0.0413(0.0448) | Loss 1.1254(1.1255) | Error 0.0125(0.0138) Steps 440(439.92) | Grad Norm 0.3254(0.2955) | Total Time 10.00(10.00)\n",
      "Iter 3015 | Time 30.9233(31.5427) | Bit/dim 1.1029(1.1030) | Xent 0.0440(0.0448) | Loss 1.1249(1.1254) | Error 0.0136(0.0138) Steps 440(439.92) | Grad Norm 0.2056(0.2928) | Total Time 10.00(10.00)\n",
      "Iter 3016 | Time 31.5722(31.5436) | Bit/dim 1.1024(1.1030) | Xent 0.0508(0.0450) | Loss 1.1278(1.1255) | Error 0.0135(0.0138) Steps 440(439.93) | Grad Norm 0.3133(0.2934) | Total Time 10.00(10.00)\n",
      "Iter 3017 | Time 31.2432(31.5346) | Bit/dim 1.1028(1.1030) | Xent 0.0434(0.0449) | Loss 1.1245(1.1255) | Error 0.0128(0.0138) Steps 440(439.93) | Grad Norm 0.4136(0.2970) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 17.5701, Epoch Time 250.9733(247.3010), Bit/dim 1.0972(best: 1.0968), Xent 0.0325, Loss 1.1135, Error 0.0107(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3018 | Time 31.4525(31.5321) | Bit/dim 1.0986(1.1029) | Xent 0.0489(0.0450) | Loss 1.1230(1.1254) | Error 0.0155(0.0138) Steps 440(439.93) | Grad Norm 0.3318(0.2981) | Total Time 10.00(10.00)\n",
      "Iter 3019 | Time 30.9443(31.5145) | Bit/dim 1.1057(1.1030) | Xent 0.0447(0.0450) | Loss 1.1281(1.1255) | Error 0.0131(0.0138) Steps 440(439.93) | Grad Norm 0.2338(0.2961) | Total Time 10.00(10.00)\n",
      "Iter 3020 | Time 31.1491(31.5035) | Bit/dim 1.1068(1.1031) | Xent 0.0426(0.0450) | Loss 1.1281(1.1256) | Error 0.0132(0.0138) Steps 440(439.93) | Grad Norm 0.3807(0.2987) | Total Time 10.00(10.00)\n",
      "Iter 3021 | Time 31.4258(31.5012) | Bit/dim 1.1021(1.1031) | Xent 0.0448(0.0450) | Loss 1.1245(1.1255) | Error 0.0131(0.0138) Steps 440(439.94) | Grad Norm 0.3686(0.3008) | Total Time 10.00(10.00)\n",
      "Iter 3022 | Time 30.9939(31.4860) | Bit/dim 1.1039(1.1031) | Xent 0.0473(0.0450) | Loss 1.1275(1.1256) | Error 0.0148(0.0138) Steps 440(439.94) | Grad Norm 0.2144(0.2982) | Total Time 10.00(10.00)\n",
      "Iter 3023 | Time 30.9981(31.4713) | Bit/dim 1.1029(1.1031) | Xent 0.0444(0.0450) | Loss 1.1251(1.1256) | Error 0.0138(0.0138) Steps 440(439.94) | Grad Norm 0.1685(0.2943) | Total Time 10.00(10.00)\n",
      "Iter 3024 | Time 30.7649(31.4502) | Bit/dim 1.1043(1.1031) | Xent 0.0438(0.0450) | Loss 1.1262(1.1256) | Error 0.0154(0.0138) Steps 440(439.94) | Grad Norm 0.4250(0.2982) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 17.5441, Epoch Time 247.7177(247.3135), Bit/dim 1.0976(best: 1.0968), Xent 0.0312, Loss 1.1132, Error 0.0093(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3025 | Time 30.8167(31.4312) | Bit/dim 1.1011(1.1031) | Xent 0.0514(0.0452) | Loss 1.1268(1.1256) | Error 0.0168(0.0139) Steps 440(439.94) | Grad Norm 0.2709(0.2974) | Total Time 10.00(10.00)\n",
      "Iter 3026 | Time 30.9386(31.4164) | Bit/dim 1.1026(1.1030) | Xent 0.0418(0.0451) | Loss 1.1235(1.1256) | Error 0.0119(0.0139) Steps 440(439.95) | Grad Norm 0.1950(0.2943) | Total Time 10.00(10.00)\n",
      "Iter 3027 | Time 30.8443(31.3992) | Bit/dim 1.0993(1.1029) | Xent 0.0448(0.0451) | Loss 1.1217(1.1255) | Error 0.0132(0.0138) Steps 440(439.95) | Grad Norm 0.2170(0.2920) | Total Time 10.00(10.00)\n",
      "Iter 3028 | Time 31.0803(31.3896) | Bit/dim 1.1069(1.1030) | Xent 0.0472(0.0451) | Loss 1.1305(1.1256) | Error 0.0152(0.0139) Steps 440(439.95) | Grad Norm 0.3015(0.2923) | Total Time 10.00(10.00)\n",
      "Iter 3029 | Time 31.5992(31.3959) | Bit/dim 1.1026(1.1030) | Xent 0.0520(0.0453) | Loss 1.1286(1.1257) | Error 0.0151(0.0139) Steps 440(439.95) | Grad Norm 0.2876(0.2921) | Total Time 10.00(10.00)\n",
      "Iter 3030 | Time 31.0306(31.3850) | Bit/dim 1.1049(1.1031) | Xent 0.0442(0.0453) | Loss 1.1269(1.1257) | Error 0.0135(0.0139) Steps 440(439.95) | Grad Norm 0.2876(0.2920) | Total Time 10.00(10.00)\n",
      "Iter 3031 | Time 31.2223(31.3801) | Bit/dim 1.1017(1.1030) | Xent 0.0427(0.0452) | Loss 1.1230(1.1257) | Error 0.0130(0.0139) Steps 440(439.95) | Grad Norm 0.3069(0.2925) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 17.6833, Epoch Time 247.7133(247.3255), Bit/dim 1.0970(best: 1.0968), Xent 0.0336, Loss 1.1138, Error 0.0094(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3032 | Time 30.8307(31.3636) | Bit/dim 1.1053(1.1031) | Xent 0.0524(0.0454) | Loss 1.1315(1.1258) | Error 0.0154(0.0139) Steps 440(439.95) | Grad Norm 0.2284(0.2905) | Total Time 10.00(10.00)\n",
      "Iter 3033 | Time 31.1503(31.3572) | Bit/dim 1.1071(1.1032) | Xent 0.0457(0.0454) | Loss 1.1299(1.1260) | Error 0.0139(0.0139) Steps 440(439.96) | Grad Norm 0.1743(0.2870) | Total Time 10.00(10.00)\n",
      "Iter 3034 | Time 32.2989(31.3855) | Bit/dim 1.1005(1.1032) | Xent 0.0414(0.0453) | Loss 1.1212(1.1258) | Error 0.0120(0.0139) Steps 440(439.96) | Grad Norm 0.2853(0.2870) | Total Time 10.00(10.00)\n",
      "Iter 3035 | Time 31.1619(31.3788) | Bit/dim 1.0981(1.1030) | Xent 0.0449(0.0453) | Loss 1.1206(1.1257) | Error 0.0129(0.0138) Steps 440(439.96) | Grad Norm 0.1659(0.2834) | Total Time 10.00(10.00)\n",
      "Iter 3036 | Time 31.8240(31.3921) | Bit/dim 1.1025(1.1030) | Xent 0.0415(0.0452) | Loss 1.1233(1.1256) | Error 0.0121(0.0138) Steps 440(439.96) | Grad Norm 0.2102(0.2812) | Total Time 10.00(10.00)\n",
      "Iter 3037 | Time 31.6381(31.3995) | Bit/dim 1.1041(1.1030) | Xent 0.0447(0.0452) | Loss 1.1264(1.1256) | Error 0.0140(0.0138) Steps 440(439.96) | Grad Norm 0.2713(0.2809) | Total Time 10.00(10.00)\n",
      "Iter 3038 | Time 33.3215(31.4572) | Bit/dim 1.1025(1.1030) | Xent 0.0382(0.0450) | Loss 1.1216(1.1255) | Error 0.0116(0.0137) Steps 440(439.96) | Grad Norm 0.2227(0.2791) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 17.6923, Epoch Time 252.7088(247.4870), Bit/dim 1.0971(best: 1.0968), Xent 0.0317, Loss 1.1130, Error 0.0096(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3039 | Time 31.2645(31.4514) | Bit/dim 1.1017(1.1030) | Xent 0.0445(0.0449) | Loss 1.1239(1.1254) | Error 0.0148(0.0138) Steps 440(439.96) | Grad Norm 0.2269(0.2776) | Total Time 10.00(10.00)\n",
      "Iter 3040 | Time 31.2105(31.4441) | Bit/dim 1.1011(1.1029) | Xent 0.0514(0.0451) | Loss 1.1268(1.1255) | Error 0.0149(0.0138) Steps 440(439.96) | Grad Norm 0.2556(0.2769) | Total Time 10.00(10.00)\n",
      "Iter 3041 | Time 31.0570(31.4325) | Bit/dim 1.0963(1.1027) | Xent 0.0469(0.0452) | Loss 1.1198(1.1253) | Error 0.0141(0.0138) Steps 440(439.97) | Grad Norm 0.5355(0.2847) | Total Time 10.00(10.00)\n",
      "Iter 3042 | Time 31.7333(31.4416) | Bit/dim 1.1081(1.1029) | Xent 0.0471(0.0453) | Loss 1.1317(1.1255) | Error 0.0151(0.0138) Steps 440(439.97) | Grad Norm 0.2189(0.2827) | Total Time 10.00(10.00)\n",
      "Iter 3043 | Time 31.2043(31.4344) | Bit/dim 1.1039(1.1029) | Xent 0.0461(0.0453) | Loss 1.1270(1.1255) | Error 0.0145(0.0139) Steps 440(439.97) | Grad Norm 0.2714(0.2823) | Total Time 10.00(10.00)\n",
      "Iter 3044 | Time 31.5654(31.4384) | Bit/dim 1.0993(1.1028) | Xent 0.0477(0.0454) | Loss 1.1231(1.1255) | Error 0.0149(0.0139) Steps 440(439.97) | Grad Norm 0.3067(0.2831) | Total Time 10.00(10.00)\n",
      "Iter 3045 | Time 31.8489(31.4507) | Bit/dim 1.1065(1.1029) | Xent 0.0434(0.0453) | Loss 1.1282(1.1256) | Error 0.0124(0.0138) Steps 440(439.97) | Grad Norm 0.3948(0.2864) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 17.8184, Epoch Time 250.5421(247.5786), Bit/dim 1.0970(best: 1.0968), Xent 0.0346, Loss 1.1143, Error 0.0094(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3046 | Time 31.0927(31.4399) | Bit/dim 1.0972(1.1027) | Xent 0.0430(0.0452) | Loss 1.1187(1.1253) | Error 0.0141(0.0139) Steps 440(439.97) | Grad Norm 0.1989(0.2838) | Total Time 10.00(10.00)\n",
      "Iter 3047 | Time 30.8998(31.4237) | Bit/dim 1.1076(1.1029) | Xent 0.0404(0.0451) | Loss 1.1278(1.1254) | Error 0.0126(0.0138) Steps 440(439.97) | Grad Norm 0.2365(0.2824) | Total Time 10.00(10.00)\n",
      "Iter 3048 | Time 32.8736(31.4672) | Bit/dim 1.1025(1.1029) | Xent 0.0407(0.0449) | Loss 1.1228(1.1253) | Error 0.0132(0.0138) Steps 440(439.97) | Grad Norm 0.4568(0.2876) | Total Time 10.00(10.00)\n",
      "Iter 3049 | Time 31.0149(31.4537) | Bit/dim 1.1014(1.1028) | Xent 0.0465(0.0450) | Loss 1.1246(1.1253) | Error 0.0125(0.0138) Steps 440(439.97) | Grad Norm 0.4178(0.2915) | Total Time 10.00(10.00)\n",
      "Iter 3050 | Time 31.7084(31.4613) | Bit/dim 1.1015(1.1028) | Xent 0.0424(0.0449) | Loss 1.1227(1.1252) | Error 0.0138(0.0138) Steps 440(439.97) | Grad Norm 0.3032(0.2919) | Total Time 10.00(10.00)\n",
      "Iter 3051 | Time 32.6668(31.4975) | Bit/dim 1.1028(1.1028) | Xent 0.0505(0.0451) | Loss 1.1280(1.1253) | Error 0.0166(0.0138) Steps 440(439.97) | Grad Norm 0.4751(0.2974) | Total Time 10.00(10.00)\n",
      "Iter 3052 | Time 30.9730(31.4817) | Bit/dim 1.1069(1.1029) | Xent 0.0422(0.0450) | Loss 1.1280(1.1254) | Error 0.0130(0.0138) Steps 440(439.98) | Grad Norm 0.5866(0.3061) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 17.6068, Epoch Time 251.3015(247.6903), Bit/dim 1.0976(best: 1.0968), Xent 0.0321, Loss 1.1136, Error 0.0096(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3053 | Time 33.2088(31.5336) | Bit/dim 1.1013(1.1029) | Xent 0.0424(0.0449) | Loss 1.1225(1.1253) | Error 0.0141(0.0138) Steps 440(439.98) | Grad Norm 0.2670(0.3049) | Total Time 10.00(10.00)\n",
      "Iter 3054 | Time 32.4011(31.5596) | Bit/dim 1.1031(1.1029) | Xent 0.0394(0.0448) | Loss 1.1228(1.1252) | Error 0.0122(0.0138) Steps 440(439.98) | Grad Norm 0.2459(0.3031) | Total Time 10.00(10.00)\n",
      "Iter 3055 | Time 30.8413(31.5380) | Bit/dim 1.1002(1.1028) | Xent 0.0552(0.0451) | Loss 1.1278(1.1253) | Error 0.0155(0.0138) Steps 440(439.98) | Grad Norm 0.6003(0.3120) | Total Time 10.00(10.00)\n",
      "Iter 3056 | Time 30.9600(31.5207) | Bit/dim 1.1072(1.1029) | Xent 0.0453(0.0451) | Loss 1.1298(1.1255) | Error 0.0134(0.0138) Steps 440(439.98) | Grad Norm 0.4075(0.3149) | Total Time 10.00(10.00)\n",
      "Iter 3057 | Time 31.1656(31.5100) | Bit/dim 1.1033(1.1029) | Xent 0.0480(0.0452) | Loss 1.1273(1.1255) | Error 0.0138(0.0138) Steps 440(439.98) | Grad Norm 0.3144(0.3149) | Total Time 10.00(10.00)\n",
      "Iter 3058 | Time 31.8708(31.5209) | Bit/dim 1.1011(1.1029) | Xent 0.0478(0.0452) | Loss 1.1250(1.1255) | Error 0.0139(0.0138) Steps 440(439.98) | Grad Norm 0.2947(0.3143) | Total Time 10.00(10.00)\n",
      "Iter 3059 | Time 31.0728(31.5074) | Bit/dim 1.1056(1.1030) | Xent 0.0468(0.0453) | Loss 1.1290(1.1256) | Error 0.0145(0.0138) Steps 440(439.98) | Grad Norm 0.3882(0.3165) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 17.6535, Epoch Time 251.8963(247.8165), Bit/dim 1.0973(best: 1.0968), Xent 0.0323, Loss 1.1134, Error 0.0098(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3060 | Time 31.0045(31.4923) | Bit/dim 1.1027(1.1029) | Xent 0.0521(0.0455) | Loss 1.1288(1.1257) | Error 0.0162(0.0139) Steps 440(439.98) | Grad Norm 0.4721(0.3212) | Total Time 10.00(10.00)\n",
      "Iter 3061 | Time 31.0465(31.4790) | Bit/dim 1.1080(1.1031) | Xent 0.0423(0.0454) | Loss 1.1291(1.1258) | Error 0.0136(0.0139) Steps 440(439.98) | Grad Norm 0.2388(0.3187) | Total Time 10.00(10.00)\n",
      "Iter 3062 | Time 31.0705(31.4667) | Bit/dim 1.0996(1.1030) | Xent 0.0463(0.0454) | Loss 1.1227(1.1257) | Error 0.0138(0.0139) Steps 440(439.98) | Grad Norm 0.2718(0.3173) | Total Time 10.00(10.00)\n",
      "Iter 3063 | Time 31.2989(31.4617) | Bit/dim 1.1022(1.1030) | Xent 0.0424(0.0453) | Loss 1.1234(1.1256) | Error 0.0126(0.0139) Steps 440(439.98) | Grad Norm 0.4483(0.3212) | Total Time 10.00(10.00)\n",
      "Iter 3064 | Time 31.3959(31.4597) | Bit/dim 1.1032(1.1030) | Xent 0.0403(0.0452) | Loss 1.1233(1.1256) | Error 0.0122(0.0138) Steps 440(439.98) | Grad Norm 0.2171(0.3181) | Total Time 10.00(10.00)\n",
      "Iter 3065 | Time 30.9784(31.4453) | Bit/dim 1.1032(1.1030) | Xent 0.0491(0.0453) | Loss 1.1277(1.1256) | Error 0.0158(0.0139) Steps 440(439.98) | Grad Norm 0.2778(0.3169) | Total Time 10.00(10.00)\n",
      "Iter 3066 | Time 32.0785(31.4643) | Bit/dim 1.0977(1.1028) | Xent 0.0481(0.0454) | Loss 1.1217(1.1255) | Error 0.0151(0.0139) Steps 440(439.98) | Grad Norm 0.3184(0.3169) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 17.6702, Epoch Time 249.2872(247.8606), Bit/dim 1.0975(best: 1.0968), Xent 0.0314, Loss 1.1132, Error 0.0094(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3067 | Time 30.8326(31.4453) | Bit/dim 1.1047(1.1029) | Xent 0.0454(0.0454) | Loss 1.1274(1.1256) | Error 0.0136(0.0139) Steps 440(439.98) | Grad Norm 0.3483(0.3179) | Total Time 10.00(10.00)\n",
      "Iter 3068 | Time 31.1002(31.4350) | Bit/dim 1.1051(1.1029) | Xent 0.0412(0.0453) | Loss 1.1257(1.1256) | Error 0.0136(0.0139) Steps 440(439.98) | Grad Norm 0.2229(0.3150) | Total Time 10.00(10.00)\n",
      "Iter 3069 | Time 30.6802(31.4123) | Bit/dim 1.1000(1.1029) | Xent 0.0459(0.0453) | Loss 1.1229(1.1255) | Error 0.0149(0.0139) Steps 440(439.99) | Grad Norm 0.3759(0.3168) | Total Time 10.00(10.00)\n",
      "Iter 3070 | Time 31.5340(31.4160) | Bit/dim 1.0959(1.1026) | Xent 0.0387(0.0451) | Loss 1.1153(1.1252) | Error 0.0122(0.0139) Steps 440(439.99) | Grad Norm 0.1800(0.3127) | Total Time 10.00(10.00)\n",
      "Iter 3071 | Time 30.6632(31.3934) | Bit/dim 1.1061(1.1028) | Xent 0.0427(0.0450) | Loss 1.1274(1.1253) | Error 0.0149(0.0139) Steps 440(439.99) | Grad Norm 0.2615(0.3112) | Total Time 10.00(10.00)\n",
      "Iter 3072 | Time 31.7768(31.4049) | Bit/dim 1.1019(1.1027) | Xent 0.0454(0.0450) | Loss 1.1246(1.1252) | Error 0.0149(0.0139) Steps 440(439.99) | Grad Norm 0.2242(0.3086) | Total Time 10.00(10.00)\n",
      "Iter 3073 | Time 30.8375(31.3879) | Bit/dim 1.1033(1.1027) | Xent 0.0415(0.0449) | Loss 1.1241(1.1252) | Error 0.0131(0.0139) Steps 440(439.99) | Grad Norm 0.3183(0.3089) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 17.5207, Epoch Time 247.3258(247.8446), Bit/dim 1.0971(best: 1.0968), Xent 0.0329, Loss 1.1136, Error 0.0092(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3074 | Time 31.3376(31.3863) | Bit/dim 1.1032(1.1028) | Xent 0.0438(0.0449) | Loss 1.1251(1.1252) | Error 0.0131(0.0139) Steps 440(439.99) | Grad Norm 0.2105(0.3059) | Total Time 10.00(10.00)\n",
      "Iter 3075 | Time 31.1931(31.3806) | Bit/dim 1.0999(1.1027) | Xent 0.0532(0.0451) | Loss 1.1265(1.1252) | Error 0.0160(0.0139) Steps 440(439.99) | Grad Norm 0.3417(0.3070) | Total Time 10.00(10.00)\n",
      "Iter 3076 | Time 30.7798(31.3625) | Bit/dim 1.0979(1.1025) | Xent 0.0526(0.0454) | Loss 1.1242(1.1252) | Error 0.0156(0.0140) Steps 440(439.99) | Grad Norm 0.2819(0.3062) | Total Time 10.00(10.00)\n",
      "Iter 3077 | Time 31.0618(31.3535) | Bit/dim 1.0996(1.1024) | Xent 0.0395(0.0452) | Loss 1.1193(1.1250) | Error 0.0124(0.0139) Steps 440(439.99) | Grad Norm 0.3213(0.3067) | Total Time 10.00(10.00)\n",
      "Iter 3078 | Time 31.3368(31.3530) | Bit/dim 1.1007(1.1024) | Xent 0.0451(0.0452) | Loss 1.1233(1.1250) | Error 0.0145(0.0140) Steps 440(439.99) | Grad Norm 0.2336(0.3045) | Total Time 10.00(10.00)\n",
      "Iter 3079 | Time 31.3482(31.3529) | Bit/dim 1.1025(1.1024) | Xent 0.0493(0.0453) | Loss 1.1272(1.1250) | Error 0.0144(0.0140) Steps 440(439.99) | Grad Norm 0.2724(0.3035) | Total Time 10.00(10.00)\n",
      "Iter 3080 | Time 31.1078(31.3455) | Bit/dim 1.1093(1.1026) | Xent 0.0410(0.0452) | Loss 1.1298(1.1252) | Error 0.0136(0.0140) Steps 440(439.99) | Grad Norm 0.2728(0.3026) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 17.5512, Epoch Time 248.3382(247.8594), Bit/dim 1.0979(best: 1.0968), Xent 0.0321, Loss 1.1139, Error 0.0094(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3081 | Time 31.3575(31.3459) | Bit/dim 1.1069(1.1027) | Xent 0.0420(0.0451) | Loss 1.1279(1.1253) | Error 0.0121(0.0139) Steps 440(439.99) | Grad Norm 0.2445(0.3009) | Total Time 10.00(10.00)\n",
      "Iter 3082 | Time 30.9212(31.3331) | Bit/dim 1.1015(1.1027) | Xent 0.0519(0.0453) | Loss 1.1274(1.1253) | Error 0.0160(0.0140) Steps 440(439.99) | Grad Norm 0.3326(0.3018) | Total Time 10.00(10.00)\n",
      "Iter 3083 | Time 31.6999(31.3441) | Bit/dim 1.1026(1.1027) | Xent 0.0409(0.0452) | Loss 1.1231(1.1253) | Error 0.0130(0.0139) Steps 440(439.99) | Grad Norm 0.1602(0.2976) | Total Time 10.00(10.00)\n",
      "Iter 3084 | Time 31.3159(31.3433) | Bit/dim 1.0996(1.1026) | Xent 0.0430(0.0451) | Loss 1.1211(1.1251) | Error 0.0130(0.0139) Steps 440(439.99) | Grad Norm 0.2998(0.2976) | Total Time 10.00(10.00)\n",
      "Iter 3085 | Time 30.5419(31.3192) | Bit/dim 1.0996(1.1025) | Xent 0.0438(0.0450) | Loss 1.1215(1.1250) | Error 0.0132(0.0139) Steps 440(439.99) | Grad Norm 0.4458(0.3021) | Total Time 10.00(10.00)\n",
      "Iter 3086 | Time 31.4940(31.3245) | Bit/dim 1.1013(1.1025) | Xent 0.0512(0.0452) | Loss 1.1269(1.1251) | Error 0.0158(0.0140) Steps 440(439.99) | Grad Norm 0.3834(0.3045) | Total Time 10.00(10.00)\n",
      "Iter 3087 | Time 32.1154(31.3482) | Bit/dim 1.1047(1.1025) | Xent 0.0389(0.0450) | Loss 1.1242(1.1251) | Error 0.0131(0.0139) Steps 440(439.99) | Grad Norm 0.2225(0.3021) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 17.7092, Epoch Time 249.9093(247.9209), Bit/dim 1.0967(best: 1.0968), Xent 0.0336, Loss 1.1135, Error 0.0096(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3088 | Time 31.2605(31.3456) | Bit/dim 1.1035(1.1026) | Xent 0.0407(0.0449) | Loss 1.1239(1.1250) | Error 0.0118(0.0139) Steps 440(439.99) | Grad Norm 0.3517(0.3036) | Total Time 10.00(10.00)\n",
      "Iter 3089 | Time 30.6336(31.3242) | Bit/dim 1.1018(1.1025) | Xent 0.0429(0.0449) | Loss 1.1233(1.1250) | Error 0.0145(0.0139) Steps 440(439.99) | Grad Norm 0.3207(0.3041) | Total Time 10.00(10.00)\n",
      "Iter 3090 | Time 32.3315(31.3544) | Bit/dim 1.1007(1.1025) | Xent 0.0406(0.0447) | Loss 1.1210(1.1249) | Error 0.0112(0.0138) Steps 440(439.99) | Grad Norm 0.2052(0.3011) | Total Time 10.00(10.00)\n",
      "Iter 3091 | Time 31.1346(31.3478) | Bit/dim 1.0988(1.1024) | Xent 0.0425(0.0447) | Loss 1.1201(1.1247) | Error 0.0135(0.0138) Steps 440(439.99) | Grad Norm 0.2378(0.2992) | Total Time 10.00(10.00)\n",
      "Iter 3092 | Time 30.8125(31.3318) | Bit/dim 1.1038(1.1024) | Xent 0.0413(0.0446) | Loss 1.1244(1.1247) | Error 0.0120(0.0137) Steps 440(439.99) | Grad Norm 0.2362(0.2973) | Total Time 10.00(10.00)\n",
      "Iter 3093 | Time 32.2992(31.3608) | Bit/dim 1.1051(1.1025) | Xent 0.0434(0.0445) | Loss 1.1268(1.1248) | Error 0.0139(0.0137) Steps 440(439.99) | Grad Norm 0.3163(0.2979) | Total Time 10.00(10.00)\n",
      "Iter 3094 | Time 32.3242(31.3897) | Bit/dim 1.1019(1.1025) | Xent 0.0479(0.0446) | Loss 1.1259(1.1248) | Error 0.0154(0.0138) Steps 440(439.99) | Grad Norm 0.2360(0.2960) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 17.6058, Epoch Time 251.1379(248.0174), Bit/dim 1.0969(best: 1.0967), Xent 0.0339, Loss 1.1139, Error 0.0096(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3095 | Time 31.1524(31.3826) | Bit/dim 1.1058(1.1026) | Xent 0.0527(0.0449) | Loss 1.1321(1.1250) | Error 0.0171(0.0139) Steps 440(439.99) | Grad Norm 0.2824(0.2956) | Total Time 10.00(10.00)\n",
      "Iter 3096 | Time 31.0510(31.3726) | Bit/dim 1.0996(1.1025) | Xent 0.0395(0.0447) | Loss 1.1193(1.1248) | Error 0.0139(0.0139) Steps 440(439.99) | Grad Norm 0.2207(0.2934) | Total Time 10.00(10.00)\n",
      "Iter 3097 | Time 31.8431(31.3868) | Bit/dim 1.1009(1.1024) | Xent 0.0406(0.0446) | Loss 1.1212(1.1247) | Error 0.0124(0.0138) Steps 440(439.99) | Grad Norm 0.2575(0.2923) | Total Time 10.00(10.00)\n",
      "Iter 3098 | Time 30.8703(31.3713) | Bit/dim 1.1059(1.1026) | Xent 0.0503(0.0448) | Loss 1.1311(1.1249) | Error 0.0156(0.0139) Steps 440(439.99) | Grad Norm 0.3152(0.2930) | Total Time 10.00(10.00)\n",
      "Iter 3099 | Time 30.9078(31.3574) | Bit/dim 1.0989(1.1024) | Xent 0.0447(0.0447) | Loss 1.1212(1.1248) | Error 0.0139(0.0139) Steps 440(439.99) | Grad Norm 0.2775(0.2925) | Total Time 10.00(10.00)\n",
      "Iter 3100 | Time 32.2348(31.3837) | Bit/dim 1.1032(1.1025) | Xent 0.0514(0.0449) | Loss 1.1289(1.1249) | Error 0.0168(0.0140) Steps 440(439.99) | Grad Norm 0.2434(0.2910) | Total Time 10.00(10.00)\n",
      "Iter 3101 | Time 32.1404(31.4064) | Bit/dim 1.1066(1.1026) | Xent 0.0391(0.0448) | Loss 1.1262(1.1250) | Error 0.0118(0.0139) Steps 440(439.99) | Grad Norm 0.2645(0.2903) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 17.6277, Epoch Time 250.2539(248.0845), Bit/dim 1.0980(best: 1.0967), Xent 0.0338, Loss 1.1149, Error 0.0103(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3102 | Time 31.3518(31.4047) | Bit/dim 1.1073(1.1027) | Xent 0.0454(0.0448) | Loss 1.1299(1.1251) | Error 0.0132(0.0139) Steps 440(439.99) | Grad Norm 0.1999(0.2875) | Total Time 10.00(10.00)\n",
      "Iter 3103 | Time 31.0480(31.3940) | Bit/dim 1.1046(1.1028) | Xent 0.0443(0.0448) | Loss 1.1267(1.1252) | Error 0.0154(0.0139) Steps 440(439.99) | Grad Norm 0.3011(0.2879) | Total Time 10.00(10.00)\n",
      "Iter 3104 | Time 31.3474(31.3926) | Bit/dim 1.1017(1.1028) | Xent 0.0470(0.0448) | Loss 1.1252(1.1252) | Error 0.0151(0.0140) Steps 440(439.99) | Grad Norm 0.2789(0.2877) | Total Time 10.00(10.00)\n",
      "Iter 3105 | Time 31.3751(31.3921) | Bit/dim 1.1022(1.1027) | Xent 0.0386(0.0447) | Loss 1.1215(1.1251) | Error 0.0126(0.0139) Steps 440(440.00) | Grad Norm 0.2403(0.2863) | Total Time 10.00(10.00)\n",
      "Iter 3106 | Time 31.1930(31.3861) | Bit/dim 1.0971(1.1026) | Xent 0.0470(0.0447) | Loss 1.1206(1.1249) | Error 0.0150(0.0140) Steps 440(440.00) | Grad Norm 0.2832(0.2862) | Total Time 10.00(10.00)\n",
      "Iter 3107 | Time 30.9569(31.3733) | Bit/dim 1.1036(1.1026) | Xent 0.0450(0.0447) | Loss 1.1261(1.1250) | Error 0.0131(0.0139) Steps 440(440.00) | Grad Norm 0.1853(0.2831) | Total Time 10.00(10.00)\n",
      "Iter 3108 | Time 31.3809(31.3735) | Bit/dim 1.1030(1.1026) | Xent 0.0488(0.0449) | Loss 1.1274(1.1250) | Error 0.0136(0.0139) Steps 440(440.00) | Grad Norm 0.3279(0.2845) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 17.7031, Epoch Time 248.9508(248.1105), Bit/dim 1.0975(best: 1.0967), Xent 0.0319, Loss 1.1135, Error 0.0104(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3109 | Time 31.1173(31.3658) | Bit/dim 1.1034(1.1026) | Xent 0.0416(0.0448) | Loss 1.1242(1.1250) | Error 0.0125(0.0139) Steps 440(440.00) | Grad Norm 0.4092(0.2882) | Total Time 10.00(10.00)\n",
      "Iter 3110 | Time 31.9512(31.3834) | Bit/dim 1.1078(1.1028) | Xent 0.0480(0.0449) | Loss 1.1318(1.1252) | Error 0.0149(0.0139) Steps 440(440.00) | Grad Norm 0.2425(0.2869) | Total Time 10.00(10.00)\n",
      "Iter 3111 | Time 31.3279(31.3817) | Bit/dim 1.1082(1.1030) | Xent 0.0431(0.0448) | Loss 1.1297(1.1254) | Error 0.0122(0.0139) Steps 440(440.00) | Grad Norm 0.1963(0.2841) | Total Time 10.00(10.00)\n",
      "Iter 3112 | Time 31.4390(31.3834) | Bit/dim 1.0973(1.1028) | Xent 0.0466(0.0449) | Loss 1.1206(1.1252) | Error 0.0139(0.0139) Steps 440(440.00) | Grad Norm 0.3491(0.2861) | Total Time 10.00(10.00)\n",
      "Iter 3113 | Time 30.4296(31.3548) | Bit/dim 1.1015(1.1027) | Xent 0.0424(0.0448) | Loss 1.1227(1.1251) | Error 0.0121(0.0138) Steps 440(440.00) | Grad Norm 0.3380(0.2876) | Total Time 10.00(10.00)\n",
      "Iter 3114 | Time 31.0135(31.3446) | Bit/dim 1.1005(1.1027) | Xent 0.0452(0.0448) | Loss 1.1231(1.1251) | Error 0.0144(0.0138) Steps 440(440.00) | Grad Norm 0.2324(0.2860) | Total Time 10.00(10.00)\n",
      "Iter 3115 | Time 30.6932(31.3250) | Bit/dim 1.0998(1.1026) | Xent 0.0475(0.0449) | Loss 1.1235(1.1250) | Error 0.0139(0.0138) Steps 440(440.00) | Grad Norm 0.2420(0.2847) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 17.5722, Epoch Time 247.9703(248.1063), Bit/dim 1.0972(best: 1.0967), Xent 0.0329, Loss 1.1136, Error 0.0093(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3116 | Time 30.9601(31.3141) | Bit/dim 1.0992(1.1025) | Xent 0.0455(0.0449) | Loss 1.1220(1.1249) | Error 0.0134(0.0138) Steps 440(440.00) | Grad Norm 0.3580(0.2869) | Total Time 10.00(10.00)\n",
      "Iter 3117 | Time 31.9313(31.3326) | Bit/dim 1.1033(1.1025) | Xent 0.0487(0.0450) | Loss 1.1277(1.1250) | Error 0.0136(0.0138) Steps 440(440.00) | Grad Norm 0.2315(0.2852) | Total Time 10.00(10.00)\n",
      "Iter 3118 | Time 30.7918(31.3164) | Bit/dim 1.0983(1.1024) | Xent 0.0406(0.0449) | Loss 1.1186(1.1248) | Error 0.0120(0.0138) Steps 440(440.00) | Grad Norm 0.1815(0.2821) | Total Time 10.00(10.00)\n",
      "Iter 3119 | Time 30.9136(31.3043) | Bit/dim 1.1024(1.1024) | Xent 0.0429(0.0448) | Loss 1.1238(1.1248) | Error 0.0126(0.0137) Steps 440(440.00) | Grad Norm 0.2335(0.2806) | Total Time 10.00(10.00)\n",
      "Iter 3120 | Time 31.9907(31.3249) | Bit/dim 1.1024(1.1024) | Xent 0.0460(0.0449) | Loss 1.1254(1.1248) | Error 0.0146(0.0138) Steps 440(440.00) | Grad Norm 0.3639(0.2831) | Total Time 10.00(10.00)\n",
      "Iter 3121 | Time 31.6531(31.3347) | Bit/dim 1.1069(1.1025) | Xent 0.0446(0.0448) | Loss 1.1292(1.1249) | Error 0.0145(0.0138) Steps 440(440.00) | Grad Norm 0.2405(0.2818) | Total Time 10.00(10.00)\n",
      "Iter 3122 | Time 30.7377(31.3168) | Bit/dim 1.1020(1.1025) | Xent 0.0430(0.0448) | Loss 1.1235(1.1249) | Error 0.0151(0.0138) Steps 440(440.00) | Grad Norm 0.2282(0.2802) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 17.5401, Epoch Time 249.1553(248.1377), Bit/dim 1.0970(best: 1.0967), Xent 0.0336, Loss 1.1138, Error 0.0098(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3123 | Time 31.3689(31.3184) | Bit/dim 1.0999(1.1024) | Xent 0.0473(0.0449) | Loss 1.1235(1.1249) | Error 0.0138(0.0138) Steps 440(440.00) | Grad Norm 0.4687(0.2859) | Total Time 10.00(10.00)\n",
      "Iter 3124 | Time 31.5920(31.3266) | Bit/dim 1.1031(1.1025) | Xent 0.0440(0.0448) | Loss 1.1252(1.1249) | Error 0.0141(0.0138) Steps 440(440.00) | Grad Norm 0.3848(0.2889) | Total Time 10.00(10.00)\n",
      "Iter 3125 | Time 31.5784(31.3341) | Bit/dim 1.1058(1.1026) | Xent 0.0467(0.0449) | Loss 1.1292(1.1250) | Error 0.0155(0.0139) Steps 440(440.00) | Grad Norm 0.2180(0.2867) | Total Time 10.00(10.00)\n",
      "Iter 3126 | Time 32.4538(31.3677) | Bit/dim 1.1025(1.1026) | Xent 0.0384(0.0447) | Loss 1.1218(1.1249) | Error 0.0126(0.0138) Steps 440(440.00) | Grad Norm 0.3065(0.2873) | Total Time 10.00(10.00)\n",
      "Iter 3127 | Time 31.3353(31.3668) | Bit/dim 1.0983(1.1024) | Xent 0.0449(0.0447) | Loss 1.1207(1.1248) | Error 0.0135(0.0138) Steps 440(440.00) | Grad Norm 0.5460(0.2951) | Total Time 10.00(10.00)\n",
      "Iter 3128 | Time 31.0657(31.3577) | Bit/dim 1.1046(1.1025) | Xent 0.0424(0.0446) | Loss 1.1259(1.1248) | Error 0.0138(0.0138) Steps 440(440.00) | Grad Norm 0.4442(0.2996) | Total Time 10.00(10.00)\n",
      "Iter 3129 | Time 31.3202(31.3566) | Bit/dim 1.1017(1.1025) | Xent 0.0436(0.0446) | Loss 1.1235(1.1248) | Error 0.0138(0.0138) Steps 440(440.00) | Grad Norm 0.3205(0.3002) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 17.8283, Epoch Time 251.1861(248.2292), Bit/dim 1.0969(best: 1.0967), Xent 0.0342, Loss 1.1140, Error 0.0117(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3130 | Time 31.0814(31.3483) | Bit/dim 1.1049(1.1025) | Xent 0.0404(0.0445) | Loss 1.1251(1.1248) | Error 0.0125(0.0138) Steps 440(440.00) | Grad Norm 0.4904(0.3059) | Total Time 10.00(10.00)\n",
      "Iter 3131 | Time 31.2172(31.3444) | Bit/dim 1.1010(1.1025) | Xent 0.0444(0.0445) | Loss 1.1232(1.1247) | Error 0.0131(0.0138) Steps 440(440.00) | Grad Norm 0.2844(0.3052) | Total Time 10.00(10.00)\n",
      "Iter 3132 | Time 31.1117(31.3374) | Bit/dim 1.1037(1.1025) | Xent 0.0420(0.0444) | Loss 1.1246(1.1247) | Error 0.0135(0.0138) Steps 440(440.00) | Grad Norm 0.2242(0.3028) | Total Time 10.00(10.00)\n",
      "Iter 3133 | Time 32.2250(31.3641) | Bit/dim 1.1011(1.1025) | Xent 0.0432(0.0444) | Loss 1.1227(1.1247) | Error 0.0132(0.0137) Steps 440(440.00) | Grad Norm 0.2526(0.3013) | Total Time 10.00(10.00)\n",
      "Iter 3134 | Time 31.9457(31.3815) | Bit/dim 1.1001(1.1024) | Xent 0.0441(0.0444) | Loss 1.1222(1.1246) | Error 0.0142(0.0138) Steps 440(440.00) | Grad Norm 0.6620(0.3121) | Total Time 10.00(10.00)\n",
      "Iter 3135 | Time 30.7350(31.3621) | Bit/dim 1.1039(1.1025) | Xent 0.0444(0.0444) | Loss 1.1261(1.1246) | Error 0.0141(0.0138) Steps 440(440.00) | Grad Norm 0.2372(0.3099) | Total Time 10.00(10.00)\n",
      "Iter 3136 | Time 31.2787(31.3596) | Bit/dim 1.1035(1.1025) | Xent 0.0459(0.0444) | Loss 1.1264(1.1247) | Error 0.0135(0.0138) Steps 440(440.00) | Grad Norm 0.1831(0.3061) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 17.8556, Epoch Time 250.0223(248.2830), Bit/dim 1.0974(best: 1.0967), Xent 0.0340, Loss 1.1144, Error 0.0110(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3137 | Time 31.5061(31.3640) | Bit/dim 1.1002(1.1024) | Xent 0.0378(0.0442) | Loss 1.1191(1.1245) | Error 0.0118(0.0137) Steps 440(440.00) | Grad Norm 0.5804(0.3143) | Total Time 10.00(10.00)\n",
      "Iter 3138 | Time 31.5972(31.3710) | Bit/dim 1.1051(1.1025) | Xent 0.0419(0.0441) | Loss 1.1261(1.1246) | Error 0.0124(0.0137) Steps 440(440.00) | Grad Norm 0.2062(0.3111) | Total Time 10.00(10.00)\n",
      "Iter 3139 | Time 30.9680(31.3589) | Bit/dim 1.0986(1.1024) | Xent 0.0447(0.0442) | Loss 1.1209(1.1245) | Error 0.0151(0.0137) Steps 440(440.00) | Grad Norm 0.4906(0.3165) | Total Time 10.00(10.00)\n",
      "Iter 3140 | Time 31.0776(31.3505) | Bit/dim 1.1037(1.1024) | Xent 0.0451(0.0442) | Loss 1.1262(1.1245) | Error 0.0138(0.0137) Steps 440(440.00) | Grad Norm 0.1804(0.3124) | Total Time 10.00(10.00)\n",
      "Iter 3141 | Time 31.5766(31.3573) | Bit/dim 1.1042(1.1025) | Xent 0.0439(0.0442) | Loss 1.1261(1.1246) | Error 0.0141(0.0137) Steps 440(440.00) | Grad Norm 0.2550(0.3107) | Total Time 10.00(10.00)\n",
      "Iter 3142 | Time 33.1888(31.4122) | Bit/dim 1.1001(1.1024) | Xent 0.0453(0.0442) | Loss 1.1228(1.1245) | Error 0.0140(0.0137) Steps 440(440.00) | Grad Norm 0.3251(0.3111) | Total Time 10.00(10.00)\n",
      "Iter 3143 | Time 30.8707(31.3960) | Bit/dim 1.1033(1.1024) | Xent 0.0422(0.0442) | Loss 1.1244(1.1245) | Error 0.0131(0.0137) Steps 440(440.00) | Grad Norm 0.2079(0.3080) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 17.7025, Epoch Time 251.0928(248.3673), Bit/dim 1.0962(best: 1.0967), Xent 0.0321, Loss 1.1122, Error 0.0096(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3144 | Time 30.9141(31.3815) | Bit/dim 1.1000(1.1024) | Xent 0.0464(0.0442) | Loss 1.1232(1.1245) | Error 0.0136(0.0137) Steps 440(440.00) | Grad Norm 0.3303(0.3087) | Total Time 10.00(10.00)\n",
      "Iter 3145 | Time 30.7859(31.3636) | Bit/dim 1.1014(1.1023) | Xent 0.0447(0.0442) | Loss 1.1237(1.1244) | Error 0.0141(0.0137) Steps 440(440.00) | Grad Norm 0.2421(0.3067) | Total Time 10.00(10.00)\n",
      "Iter 3146 | Time 31.1062(31.3559) | Bit/dim 1.0988(1.1022) | Xent 0.0419(0.0442) | Loss 1.1198(1.1243) | Error 0.0139(0.0137) Steps 440(440.00) | Grad Norm 0.2614(0.3053) | Total Time 10.00(10.00)\n",
      "Iter 3147 | Time 31.3151(31.3547) | Bit/dim 1.1068(1.1024) | Xent 0.0382(0.0440) | Loss 1.1259(1.1244) | Error 0.0118(0.0137) Steps 440(440.00) | Grad Norm 0.3069(0.3054) | Total Time 10.00(10.00)\n",
      "Iter 3148 | Time 31.0356(31.3451) | Bit/dim 1.1034(1.1024) | Xent 0.0522(0.0442) | Loss 1.1296(1.1245) | Error 0.0149(0.0137) Steps 440(440.00) | Grad Norm 0.2523(0.3038) | Total Time 10.00(10.00)\n",
      "Iter 3149 | Time 32.0843(31.3673) | Bit/dim 1.1063(1.1025) | Xent 0.0449(0.0443) | Loss 1.1287(1.1246) | Error 0.0140(0.0137) Steps 440(440.00) | Grad Norm 0.1987(0.3006) | Total Time 10.00(10.00)\n",
      "Iter 3150 | Time 31.9368(31.3844) | Bit/dim 1.1003(1.1024) | Xent 0.0489(0.0444) | Loss 1.1247(1.1246) | Error 0.0134(0.0137) Steps 440(440.00) | Grad Norm 0.4044(0.3037) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 17.5559, Epoch Time 249.6827(248.4067), Bit/dim 1.0960(best: 1.0962), Xent 0.0348, Loss 1.1134, Error 0.0103(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3151 | Time 30.6509(31.3624) | Bit/dim 1.1040(1.1025) | Xent 0.0410(0.0443) | Loss 1.1245(1.1246) | Error 0.0115(0.0136) Steps 440(440.00) | Grad Norm 0.3144(0.3040) | Total Time 10.00(10.00)\n",
      "Iter 3152 | Time 31.4507(31.3650) | Bit/dim 1.1019(1.1025) | Xent 0.0375(0.0441) | Loss 1.1207(1.1245) | Error 0.0111(0.0136) Steps 440(440.00) | Grad Norm 0.5807(0.3123) | Total Time 10.00(10.00)\n",
      "Iter 3153 | Time 31.1170(31.3576) | Bit/dim 1.1031(1.1025) | Xent 0.0436(0.0441) | Loss 1.1249(1.1245) | Error 0.0148(0.0136) Steps 440(440.00) | Grad Norm 0.3262(0.3128) | Total Time 10.00(10.00)\n",
      "Iter 3154 | Time 30.8159(31.3413) | Bit/dim 1.1000(1.1024) | Xent 0.0432(0.0440) | Loss 1.1216(1.1244) | Error 0.0136(0.0136) Steps 440(440.00) | Grad Norm 0.3006(0.3124) | Total Time 10.00(10.00)\n",
      "Iter 3155 | Time 32.4719(31.3752) | Bit/dim 1.0986(1.1023) | Xent 0.0500(0.0442) | Loss 1.1236(1.1244) | Error 0.0130(0.0136) Steps 440(440.00) | Grad Norm 0.3513(0.3136) | Total Time 10.00(10.00)\n",
      "Iter 3156 | Time 31.3423(31.3743) | Bit/dim 1.1058(1.1024) | Xent 0.0465(0.0443) | Loss 1.1291(1.1246) | Error 0.0138(0.0136) Steps 440(440.00) | Grad Norm 0.2642(0.3121) | Total Time 10.00(10.00)\n",
      "Iter 3157 | Time 31.0624(31.3649) | Bit/dim 1.1007(1.1024) | Xent 0.0428(0.0442) | Loss 1.1221(1.1245) | Error 0.0141(0.0136) Steps 440(440.00) | Grad Norm 0.2108(0.3090) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 17.7898, Epoch Time 249.5906(248.4422), Bit/dim 1.0965(best: 1.0960), Xent 0.0334, Loss 1.1132, Error 0.0104(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3158 | Time 31.1832(31.3594) | Bit/dim 1.1018(1.1023) | Xent 0.0498(0.0444) | Loss 1.1267(1.1245) | Error 0.0155(0.0137) Steps 440(440.00) | Grad Norm 0.2247(0.3065) | Total Time 10.00(10.00)\n",
      "Iter 3159 | Time 31.3341(31.3587) | Bit/dim 1.1062(1.1025) | Xent 0.0371(0.0442) | Loss 1.1248(1.1246) | Error 0.0110(0.0136) Steps 440(440.00) | Grad Norm 0.1949(0.3032) | Total Time 10.00(10.00)\n",
      "Iter 3160 | Time 31.1104(31.3512) | Bit/dim 1.0989(1.1024) | Xent 0.0478(0.0443) | Loss 1.1228(1.1245) | Error 0.0142(0.0136) Steps 440(440.00) | Grad Norm 0.2682(0.3021) | Total Time 10.00(10.00)\n",
      "Iter 3161 | Time 31.5460(31.3571) | Bit/dim 1.1020(1.1023) | Xent 0.0494(0.0445) | Loss 1.1267(1.1246) | Error 0.0155(0.0137) Steps 440(440.00) | Grad Norm 0.4995(0.3080) | Total Time 10.00(10.00)\n",
      "Iter 3162 | Time 31.5680(31.3634) | Bit/dim 1.1040(1.1024) | Xent 0.0398(0.0443) | Loss 1.1239(1.1245) | Error 0.0116(0.0136) Steps 440(440.00) | Grad Norm 0.2598(0.3066) | Total Time 10.00(10.00)\n",
      "Iter 3163 | Time 31.3002(31.3615) | Bit/dim 1.1027(1.1024) | Xent 0.0435(0.0443) | Loss 1.1244(1.1245) | Error 0.0145(0.0136) Steps 440(440.00) | Grad Norm 0.2665(0.3054) | Total Time 10.00(10.00)\n",
      "Iter 3164 | Time 30.8855(31.3472) | Bit/dim 1.0997(1.1023) | Xent 0.0463(0.0444) | Loss 1.1229(1.1245) | Error 0.0146(0.0136) Steps 440(440.00) | Grad Norm 0.4913(0.3110) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 17.7723, Epoch Time 249.7016(248.4800), Bit/dim 1.0969(best: 1.0960), Xent 0.0320, Loss 1.1129, Error 0.0095(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3165 | Time 30.7611(31.3297) | Bit/dim 1.1029(1.1023) | Xent 0.0450(0.0444) | Loss 1.1254(1.1245) | Error 0.0156(0.0137) Steps 440(440.00) | Grad Norm 0.2122(0.3080) | Total Time 10.00(10.00)\n",
      "Iter 3166 | Time 31.2590(31.3275) | Bit/dim 1.1032(1.1024) | Xent 0.0402(0.0442) | Loss 1.1233(1.1245) | Error 0.0120(0.0137) Steps 440(440.00) | Grad Norm 0.2418(0.3060) | Total Time 10.00(10.00)\n",
      "Iter 3167 | Time 31.3911(31.3294) | Bit/dim 1.0970(1.1022) | Xent 0.0402(0.0441) | Loss 1.1171(1.1243) | Error 0.0129(0.0136) Steps 440(440.00) | Grad Norm 0.4662(0.3108) | Total Time 10.00(10.00)\n",
      "Iter 3168 | Time 31.0523(31.3211) | Bit/dim 1.1023(1.1022) | Xent 0.0431(0.0441) | Loss 1.1239(1.1242) | Error 0.0119(0.0136) Steps 440(440.00) | Grad Norm 0.2765(0.3098) | Total Time 10.00(10.00)\n",
      "Iter 3169 | Time 31.0474(31.3129) | Bit/dim 1.1060(1.1023) | Xent 0.0438(0.0441) | Loss 1.1279(1.1244) | Error 0.0142(0.0136) Steps 440(440.00) | Grad Norm 0.2380(0.3076) | Total Time 10.00(10.00)\n",
      "Iter 3170 | Time 30.7968(31.2974) | Bit/dim 1.1029(1.1023) | Xent 0.0472(0.0442) | Loss 1.1265(1.1244) | Error 0.0139(0.0136) Steps 440(440.00) | Grad Norm 0.2745(0.3066) | Total Time 10.00(10.00)\n",
      "Iter 3171 | Time 31.3380(31.2986) | Bit/dim 1.1023(1.1023) | Xent 0.0415(0.0441) | Loss 1.1230(1.1244) | Error 0.0144(0.0136) Steps 440(440.00) | Grad Norm 0.2322(0.3044) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 17.8204, Epoch Time 248.0835(248.4681), Bit/dim 1.0965(best: 1.0960), Xent 0.0316, Loss 1.1123, Error 0.0099(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3172 | Time 30.8461(31.2851) | Bit/dim 1.1025(1.1023) | Xent 0.0459(0.0442) | Loss 1.1254(1.1244) | Error 0.0130(0.0136) Steps 440(440.00) | Grad Norm 0.3140(0.3047) | Total Time 10.00(10.00)\n",
      "Iter 3173 | Time 32.2583(31.3143) | Bit/dim 1.0979(1.1022) | Xent 0.0457(0.0442) | Loss 1.1208(1.1243) | Error 0.0139(0.0136) Steps 440(440.00) | Grad Norm 0.3148(0.3050) | Total Time 10.00(10.00)\n",
      "Iter 3174 | Time 30.9862(31.3044) | Bit/dim 1.1012(1.1022) | Xent 0.0468(0.0443) | Loss 1.1246(1.1243) | Error 0.0155(0.0137) Steps 440(440.00) | Grad Norm 0.3555(0.3065) | Total Time 10.00(10.00)\n",
      "Iter 3175 | Time 31.4986(31.3103) | Bit/dim 1.1041(1.1022) | Xent 0.0419(0.0442) | Loss 1.1250(1.1243) | Error 0.0126(0.0136) Steps 440(440.00) | Grad Norm 0.3266(0.3071) | Total Time 10.00(10.00)\n",
      "Iter 3176 | Time 31.4192(31.3135) | Bit/dim 1.1010(1.1022) | Xent 0.0441(0.0442) | Loss 1.1230(1.1243) | Error 0.0129(0.0136) Steps 440(440.00) | Grad Norm 0.3106(0.3072) | Total Time 10.00(10.00)\n",
      "Iter 3177 | Time 31.1129(31.3075) | Bit/dim 1.1029(1.1022) | Xent 0.0455(0.0442) | Loss 1.1257(1.1243) | Error 0.0158(0.0137) Steps 440(440.00) | Grad Norm 0.1970(0.3039) | Total Time 10.00(10.00)\n",
      "Iter 3178 | Time 30.9395(31.2965) | Bit/dim 1.1049(1.1023) | Xent 0.0413(0.0442) | Loss 1.1255(1.1244) | Error 0.0124(0.0136) Steps 440(440.00) | Grad Norm 0.3640(0.3057) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 17.6863, Epoch Time 249.7381(248.5062), Bit/dim 1.0967(best: 1.0960), Xent 0.0308, Loss 1.1121, Error 0.0097(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3179 | Time 31.4314(31.3005) | Bit/dim 1.1008(1.1022) | Xent 0.0385(0.0440) | Loss 1.1201(1.1242) | Error 0.0118(0.0136) Steps 440(440.00) | Grad Norm 0.3015(0.3056) | Total Time 10.00(10.00)\n",
      "Iter 3180 | Time 30.5394(31.2777) | Bit/dim 1.1036(1.1023) | Xent 0.0427(0.0439) | Loss 1.1250(1.1243) | Error 0.0145(0.0136) Steps 440(440.00) | Grad Norm 0.1950(0.3023) | Total Time 10.00(10.00)\n",
      "Iter 3181 | Time 31.1798(31.2747) | Bit/dim 1.1039(1.1023) | Xent 0.0483(0.0441) | Loss 1.1281(1.1244) | Error 0.0155(0.0137) Steps 440(440.00) | Grad Norm 0.1779(0.2985) | Total Time 10.00(10.00)\n",
      "Iter 3182 | Time 31.3163(31.2760) | Bit/dim 1.1050(1.1024) | Xent 0.0471(0.0442) | Loss 1.1286(1.1245) | Error 0.0151(0.0137) Steps 440(440.00) | Grad Norm 0.3032(0.2987) | Total Time 10.00(10.00)\n",
      "Iter 3183 | Time 31.2776(31.2760) | Bit/dim 1.1035(1.1025) | Xent 0.0498(0.0443) | Loss 1.1284(1.1246) | Error 0.0156(0.0138) Steps 440(440.00) | Grad Norm 0.3300(0.2996) | Total Time 10.00(10.00)\n",
      "Iter 3184 | Time 31.3514(31.2783) | Bit/dim 1.0962(1.1023) | Xent 0.0494(0.0445) | Loss 1.1209(1.1245) | Error 0.0142(0.0138) Steps 440(440.00) | Grad Norm 0.3844(0.3022) | Total Time 10.00(10.00)\n",
      "Iter 3185 | Time 31.8051(31.2941) | Bit/dim 1.1001(1.1022) | Xent 0.0500(0.0447) | Loss 1.1251(1.1245) | Error 0.0154(0.0138) Steps 440(440.00) | Grad Norm 0.5196(0.3087) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 17.8641, Epoch Time 249.5651(248.5380), Bit/dim 1.0966(best: 1.0960), Xent 0.0338, Loss 1.1135, Error 0.0103(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3186 | Time 31.4048(31.2974) | Bit/dim 1.1068(1.1023) | Xent 0.0466(0.0447) | Loss 1.1301(1.1247) | Error 0.0142(0.0138) Steps 440(440.00) | Grad Norm 0.4886(0.3141) | Total Time 10.00(10.00)\n",
      "Iter 3187 | Time 31.3921(31.3003) | Bit/dim 1.1010(1.1023) | Xent 0.0435(0.0447) | Loss 1.1228(1.1246) | Error 0.0132(0.0138) Steps 440(440.00) | Grad Norm 0.2959(0.3135) | Total Time 10.00(10.00)\n",
      "Iter 3188 | Time 31.0837(31.2938) | Bit/dim 1.1030(1.1023) | Xent 0.0446(0.0447) | Loss 1.1253(1.1247) | Error 0.0146(0.0139) Steps 440(440.00) | Grad Norm 0.3001(0.3131) | Total Time 10.00(10.00)\n",
      "Iter 3189 | Time 31.3687(31.2960) | Bit/dim 1.1024(1.1023) | Xent 0.0429(0.0446) | Loss 1.1238(1.1246) | Error 0.0120(0.0138) Steps 440(440.00) | Grad Norm 0.6612(0.3236) | Total Time 10.00(10.00)\n",
      "Iter 3190 | Time 31.1105(31.2904) | Bit/dim 1.1025(1.1023) | Xent 0.0473(0.0447) | Loss 1.1261(1.1247) | Error 0.0152(0.0138) Steps 440(440.00) | Grad Norm 0.4053(0.3260) | Total Time 10.00(10.00)\n",
      "Iter 3191 | Time 30.9476(31.2802) | Bit/dim 1.0980(1.1022) | Xent 0.0429(0.0446) | Loss 1.1194(1.1245) | Error 0.0126(0.0138) Steps 440(440.00) | Grad Norm 0.2669(0.3243) | Total Time 10.00(10.00)\n",
      "Iter 3192 | Time 31.0395(31.2729) | Bit/dim 1.1040(1.1023) | Xent 0.0416(0.0445) | Loss 1.1248(1.1245) | Error 0.0128(0.0138) Steps 440(440.00) | Grad Norm 0.7896(0.3382) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 17.7322, Epoch Time 248.8714(248.5480), Bit/dim 1.0971(best: 1.0960), Xent 0.0327, Loss 1.1134, Error 0.0092(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3193 | Time 31.7665(31.2877) | Bit/dim 1.1035(1.1023) | Xent 0.0443(0.0445) | Loss 1.1256(1.1246) | Error 0.0130(0.0138) Steps 440(440.00) | Grad Norm 0.2439(0.3354) | Total Time 10.00(10.00)\n",
      "Iter 3194 | Time 31.4178(31.2917) | Bit/dim 1.1015(1.1023) | Xent 0.0406(0.0444) | Loss 1.1218(1.1245) | Error 0.0126(0.0137) Steps 440(440.00) | Grad Norm 0.2649(0.3333) | Total Time 10.00(10.00)\n",
      "Iter 3195 | Time 31.0199(31.2835) | Bit/dim 1.1059(1.1024) | Xent 0.0458(0.0445) | Loss 1.1288(1.1246) | Error 0.0128(0.0137) Steps 440(440.00) | Grad Norm 0.5557(0.3399) | Total Time 10.00(10.00)\n",
      "Iter 3196 | Time 31.8868(31.3016) | Bit/dim 1.1016(1.1023) | Xent 0.0518(0.0447) | Loss 1.1274(1.1247) | Error 0.0164(0.0138) Steps 440(440.00) | Grad Norm 0.4487(0.3432) | Total Time 10.00(10.00)\n",
      "Iter 3197 | Time 31.1971(31.2985) | Bit/dim 1.1055(1.1024) | Xent 0.0466(0.0447) | Loss 1.1288(1.1248) | Error 0.0141(0.0138) Steps 440(440.00) | Grad Norm 0.1790(0.3383) | Total Time 10.00(10.00)\n",
      "Iter 3198 | Time 30.9367(31.2876) | Bit/dim 1.0978(1.1023) | Xent 0.0433(0.0447) | Loss 1.1195(1.1247) | Error 0.0130(0.0138) Steps 440(440.00) | Grad Norm 0.2650(0.3361) | Total Time 10.00(10.00)\n",
      "Iter 3199 | Time 31.8596(31.3048) | Bit/dim 1.1047(1.1024) | Xent 0.0447(0.0447) | Loss 1.1271(1.1247) | Error 0.0130(0.0137) Steps 440(440.00) | Grad Norm 0.4674(0.3400) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 17.8389, Epoch Time 250.6835(248.6121), Bit/dim 1.0968(best: 1.0960), Xent 0.0340, Loss 1.1138, Error 0.0106(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3200 | Time 31.2156(31.3021) | Bit/dim 1.0981(1.1022) | Xent 0.0412(0.0446) | Loss 1.1187(1.1245) | Error 0.0136(0.0137) Steps 440(440.00) | Grad Norm 0.1931(0.3356) | Total Time 10.00(10.00)\n",
      "Iter 3201 | Time 31.2209(31.2997) | Bit/dim 1.1047(1.1023) | Xent 0.0401(0.0445) | Loss 1.1247(1.1245) | Error 0.0124(0.0137) Steps 440(440.00) | Grad Norm 0.2131(0.3319) | Total Time 10.00(10.00)\n",
      "Iter 3202 | Time 31.3448(31.3010) | Bit/dim 1.1031(1.1023) | Xent 0.0406(0.0443) | Loss 1.1234(1.1245) | Error 0.0121(0.0136) Steps 440(440.00) | Grad Norm 0.4496(0.3355) | Total Time 10.00(10.00)\n",
      "Iter 3203 | Time 31.7513(31.3145) | Bit/dim 1.1058(1.1024) | Xent 0.0470(0.0444) | Loss 1.1293(1.1247) | Error 0.0154(0.0137) Steps 440(440.00) | Grad Norm 0.4556(0.3391) | Total Time 10.00(10.00)\n",
      "Iter 3204 | Time 31.5365(31.3212) | Bit/dim 1.1032(1.1025) | Xent 0.0505(0.0446) | Loss 1.1285(1.1248) | Error 0.0152(0.0137) Steps 440(440.00) | Grad Norm 0.2221(0.3356) | Total Time 10.00(10.00)\n",
      "Iter 3205 | Time 32.0299(31.3424) | Bit/dim 1.0967(1.1023) | Xent 0.0368(0.0444) | Loss 1.1151(1.1245) | Error 0.0129(0.0137) Steps 440(440.00) | Grad Norm 0.4171(0.3380) | Total Time 10.00(10.00)\n",
      "Iter 3206 | Time 31.3181(31.3417) | Bit/dim 1.1002(1.1022) | Xent 0.0558(0.0447) | Loss 1.1281(1.1246) | Error 0.0136(0.0137) Steps 440(440.00) | Grad Norm 0.5747(0.3451) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 17.8722, Epoch Time 251.1010(248.6867), Bit/dim 1.0969(best: 1.0960), Xent 0.0332, Loss 1.1135, Error 0.0099(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3207 | Time 31.6678(31.3515) | Bit/dim 1.1061(1.1024) | Xent 0.0424(0.0446) | Loss 1.1273(1.1247) | Error 0.0132(0.0137) Steps 440(440.00) | Grad Norm 0.2312(0.3417) | Total Time 10.00(10.00)\n",
      "Iter 3208 | Time 31.4326(31.3539) | Bit/dim 1.1007(1.1023) | Xent 0.0422(0.0446) | Loss 1.1218(1.1246) | Error 0.0124(0.0137) Steps 440(440.00) | Grad Norm 0.2385(0.3386) | Total Time 10.00(10.00)\n",
      "Iter 3209 | Time 31.1485(31.3478) | Bit/dim 1.1037(1.1023) | Xent 0.0452(0.0446) | Loss 1.1263(1.1246) | Error 0.0139(0.0137) Steps 440(440.00) | Grad Norm 0.4077(0.3407) | Total Time 10.00(10.00)\n",
      "Iter 3210 | Time 31.1638(31.3422) | Bit/dim 1.1053(1.1024) | Xent 0.0419(0.0445) | Loss 1.1263(1.1247) | Error 0.0122(0.0136) Steps 440(440.00) | Grad Norm 0.3109(0.3398) | Total Time 10.00(10.00)\n",
      "Iter 3211 | Time 31.6736(31.3522) | Bit/dim 1.1007(1.1024) | Xent 0.0436(0.0445) | Loss 1.1225(1.1246) | Error 0.0139(0.0136) Steps 440(440.00) | Grad Norm 0.1727(0.3348) | Total Time 10.00(10.00)\n",
      "Iter 3212 | Time 31.3538(31.3522) | Bit/dim 1.1014(1.1024) | Xent 0.0484(0.0446) | Loss 1.1256(1.1247) | Error 0.0146(0.0137) Steps 440(440.00) | Grad Norm 0.3687(0.3358) | Total Time 10.00(10.00)\n",
      "Iter 3213 | Time 31.0142(31.3421) | Bit/dim 1.1024(1.1024) | Xent 0.0468(0.0447) | Loss 1.1258(1.1247) | Error 0.0151(0.0137) Steps 440(440.00) | Grad Norm 0.4152(0.3382) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 17.8724, Epoch Time 250.1224(248.7298), Bit/dim 1.0966(best: 1.0960), Xent 0.0336, Loss 1.1134, Error 0.0096(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3214 | Time 32.4030(31.3739) | Bit/dim 1.1052(1.1024) | Xent 0.0449(0.0447) | Loss 1.1277(1.1248) | Error 0.0145(0.0137) Steps 440(440.00) | Grad Norm 0.2351(0.3351) | Total Time 10.00(10.00)\n",
      "Iter 3215 | Time 31.3817(31.3742) | Bit/dim 1.0998(1.1024) | Xent 0.0473(0.0448) | Loss 1.1235(1.1247) | Error 0.0139(0.0137) Steps 440(440.00) | Grad Norm 0.3264(0.3348) | Total Time 10.00(10.00)\n",
      "Iter 3216 | Time 31.6436(31.3822) | Bit/dim 1.1037(1.1024) | Xent 0.0444(0.0447) | Loss 1.1259(1.1248) | Error 0.0130(0.0137) Steps 440(440.00) | Grad Norm 0.2754(0.3330) | Total Time 10.00(10.00)\n",
      "Iter 3217 | Time 31.4356(31.3838) | Bit/dim 1.1046(1.1025) | Xent 0.0457(0.0448) | Loss 1.1275(1.1249) | Error 0.0135(0.0137) Steps 440(440.00) | Grad Norm 0.3391(0.3332) | Total Time 10.00(10.00)\n",
      "Iter 3218 | Time 31.2752(31.3806) | Bit/dim 1.1005(1.1024) | Xent 0.0426(0.0447) | Loss 1.1218(1.1248) | Error 0.0141(0.0137) Steps 440(440.00) | Grad Norm 0.2424(0.3305) | Total Time 10.00(10.00)\n",
      "Iter 3219 | Time 31.3756(31.3804) | Bit/dim 1.1022(1.1024) | Xent 0.0434(0.0447) | Loss 1.1239(1.1247) | Error 0.0145(0.0137) Steps 440(440.00) | Grad Norm 0.2531(0.3282) | Total Time 10.00(10.00)\n",
      "Iter 3220 | Time 33.0559(31.4307) | Bit/dim 1.0998(1.1023) | Xent 0.0390(0.0445) | Loss 1.1193(1.1246) | Error 0.0115(0.0137) Steps 440(440.00) | Grad Norm 0.4550(0.3320) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 17.7301, Epoch Time 252.7647(248.8508), Bit/dim 1.0968(best: 1.0960), Xent 0.0319, Loss 1.1127, Error 0.0092(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3221 | Time 31.1468(31.4222) | Bit/dim 1.1039(1.1024) | Xent 0.0465(0.0446) | Loss 1.1271(1.1247) | Error 0.0126(0.0136) Steps 440(440.00) | Grad Norm 0.3628(0.3329) | Total Time 10.00(10.00)\n",
      "Iter 3222 | Time 31.1954(31.4154) | Bit/dim 1.1030(1.1024) | Xent 0.0416(0.0445) | Loss 1.1238(1.1246) | Error 0.0128(0.0136) Steps 440(440.00) | Grad Norm 0.2169(0.3294) | Total Time 10.00(10.00)\n",
      "Iter 3223 | Time 31.0241(31.4036) | Bit/dim 1.1032(1.1024) | Xent 0.0470(0.0445) | Loss 1.1267(1.1247) | Error 0.0159(0.0137) Steps 440(440.00) | Grad Norm 0.4232(0.3322) | Total Time 10.00(10.00)\n",
      "Iter 3224 | Time 32.0747(31.4238) | Bit/dim 1.1014(1.1024) | Xent 0.0481(0.0446) | Loss 1.1254(1.1247) | Error 0.0139(0.0137) Steps 440(440.00) | Grad Norm 0.3444(0.3326) | Total Time 10.00(10.00)\n",
      "Iter 3225 | Time 31.2655(31.4190) | Bit/dim 1.0959(1.1022) | Xent 0.0455(0.0447) | Loss 1.1187(1.1245) | Error 0.0130(0.0137) Steps 440(440.00) | Grad Norm 0.2080(0.3289) | Total Time 10.00(10.00)\n",
      "Iter 3226 | Time 30.5012(31.3915) | Bit/dim 1.1025(1.1022) | Xent 0.0396(0.0445) | Loss 1.1222(1.1245) | Error 0.0130(0.0136) Steps 440(440.00) | Grad Norm 0.1871(0.3246) | Total Time 10.00(10.00)\n",
      "Iter 3227 | Time 31.7735(31.4029) | Bit/dim 1.1035(1.1022) | Xent 0.0522(0.0447) | Loss 1.1296(1.1246) | Error 0.0162(0.0137) Steps 440(440.00) | Grad Norm 0.4088(0.3271) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 17.8220, Epoch Time 249.3990(248.8673), Bit/dim 1.0963(best: 1.0960), Xent 0.0332, Loss 1.1129, Error 0.0106(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3228 | Time 31.1086(31.3941) | Bit/dim 1.1003(1.1022) | Xent 0.0390(0.0446) | Loss 1.1198(1.1245) | Error 0.0128(0.0137) Steps 440(440.00) | Grad Norm 0.4701(0.3314) | Total Time 10.00(10.00)\n",
      "Iter 3229 | Time 31.4463(31.3957) | Bit/dim 1.1037(1.1022) | Xent 0.0438(0.0446) | Loss 1.1256(1.1245) | Error 0.0134(0.0137) Steps 440(440.00) | Grad Norm 0.2129(0.3279) | Total Time 10.00(10.00)\n",
      "Iter 3230 | Time 31.5851(31.4014) | Bit/dim 1.1002(1.1022) | Xent 0.0511(0.0448) | Loss 1.1258(1.1245) | Error 0.0158(0.0137) Steps 440(440.00) | Grad Norm 0.8072(0.3422) | Total Time 10.00(10.00)\n",
      "Iter 3231 | Time 32.4215(31.4320) | Bit/dim 1.1006(1.1021) | Xent 0.0434(0.0447) | Loss 1.1223(1.1245) | Error 0.0141(0.0138) Steps 440(440.00) | Grad Norm 0.7287(0.3538) | Total Time 10.00(10.00)\n",
      "Iter 3232 | Time 32.0186(31.4496) | Bit/dim 1.0997(1.1020) | Xent 0.0416(0.0446) | Loss 1.1205(1.1244) | Error 0.0129(0.0137) Steps 440(440.00) | Grad Norm 0.2635(0.3511) | Total Time 10.00(10.00)\n",
      "Iter 3233 | Time 33.7437(31.5184) | Bit/dim 1.1077(1.1022) | Xent 0.0465(0.0447) | Loss 1.1309(1.1245) | Error 0.0144(0.0138) Steps 440(440.00) | Grad Norm 0.7567(0.3633) | Total Time 10.00(10.00)\n",
      "Iter 3234 | Time 31.3439(31.5132) | Bit/dim 1.0996(1.1021) | Xent 0.0474(0.0448) | Loss 1.1233(1.1245) | Error 0.0148(0.0138) Steps 440(440.00) | Grad Norm 0.7770(0.3757) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 17.9324, Epoch Time 254.4613(249.0351), Bit/dim 1.0966(best: 1.0960), Xent 0.0333, Loss 1.1132, Error 0.0100(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3235 | Time 31.2367(31.5049) | Bit/dim 1.0994(1.1021) | Xent 0.0489(0.0449) | Loss 1.1239(1.1245) | Error 0.0162(0.0139) Steps 440(440.00) | Grad Norm 0.2475(0.3719) | Total Time 10.00(10.00)\n",
      "Iter 3236 | Time 32.3888(31.5314) | Bit/dim 1.0974(1.1019) | Xent 0.0405(0.0447) | Loss 1.1176(1.1243) | Error 0.0138(0.0139) Steps 440(440.00) | Grad Norm 0.4299(0.3736) | Total Time 10.00(10.00)\n",
      "Iter 3237 | Time 31.0173(31.5160) | Bit/dim 1.1042(1.1020) | Xent 0.0472(0.0448) | Loss 1.1278(1.1244) | Error 0.0146(0.0139) Steps 440(440.00) | Grad Norm 0.6033(0.3805) | Total Time 10.00(10.00)\n",
      "Iter 3238 | Time 30.8032(31.4946) | Bit/dim 1.1059(1.1021) | Xent 0.0457(0.0448) | Loss 1.1287(1.1245) | Error 0.0139(0.0139) Steps 440(440.00) | Grad Norm 0.4379(0.3822) | Total Time 10.00(10.00)\n",
      "Iter 3239 | Time 31.2934(31.4885) | Bit/dim 1.1026(1.1021) | Xent 0.0460(0.0449) | Loss 1.1256(1.1246) | Error 0.0132(0.0139) Steps 440(440.00) | Grad Norm 0.3456(0.3811) | Total Time 10.00(10.00)\n",
      "Iter 3240 | Time 31.2993(31.4829) | Bit/dim 1.1011(1.1021) | Xent 0.0469(0.0449) | Loss 1.1246(1.1246) | Error 0.0132(0.0138) Steps 440(440.00) | Grad Norm 0.4922(0.3844) | Total Time 10.00(10.00)\n",
      "Iter 3241 | Time 31.1681(31.4734) | Bit/dim 1.0995(1.1020) | Xent 0.0464(0.0450) | Loss 1.1227(1.1245) | Error 0.0141(0.0138) Steps 440(440.00) | Grad Norm 0.4988(0.3879) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 17.7020, Epoch Time 249.5344(249.0501), Bit/dim 1.0965(best: 1.0960), Xent 0.0326, Loss 1.1128, Error 0.0101(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3242 | Time 30.5033(31.4443) | Bit/dim 1.1029(1.1020) | Xent 0.0430(0.0449) | Loss 1.1244(1.1245) | Error 0.0120(0.0138) Steps 440(440.00) | Grad Norm 0.2872(0.3849) | Total Time 10.00(10.00)\n",
      "Iter 3243 | Time 31.9482(31.4594) | Bit/dim 1.1023(1.1020) | Xent 0.0483(0.0450) | Loss 1.1265(1.1246) | Error 0.0154(0.0138) Steps 440(440.00) | Grad Norm 0.3983(0.3853) | Total Time 10.00(10.00)\n",
      "Iter 3244 | Time 30.8738(31.4419) | Bit/dim 1.1029(1.1021) | Xent 0.0420(0.0449) | Loss 1.1239(1.1245) | Error 0.0128(0.0138) Steps 440(440.00) | Grad Norm 0.4668(0.3877) | Total Time 10.00(10.00)\n",
      "Iter 3245 | Time 31.2669(31.4366) | Bit/dim 1.1025(1.1021) | Xent 0.0415(0.0448) | Loss 1.1232(1.1245) | Error 0.0125(0.0138) Steps 440(440.00) | Grad Norm 0.3512(0.3866) | Total Time 10.00(10.00)\n",
      "Iter 3246 | Time 31.2574(31.4312) | Bit/dim 1.0996(1.1020) | Xent 0.0379(0.0446) | Loss 1.1185(1.1243) | Error 0.0122(0.0137) Steps 440(440.00) | Grad Norm 0.4427(0.3883) | Total Time 10.00(10.00)\n",
      "Iter 3247 | Time 32.2876(31.4569) | Bit/dim 1.0989(1.1019) | Xent 0.0400(0.0445) | Loss 1.1189(1.1242) | Error 0.0120(0.0137) Steps 440(440.00) | Grad Norm 0.4030(0.3887) | Total Time 10.00(10.00)\n",
      "Iter 3248 | Time 30.8904(31.4399) | Bit/dim 1.1037(1.1020) | Xent 0.0436(0.0445) | Loss 1.1255(1.1242) | Error 0.0124(0.0136) Steps 440(440.00) | Grad Norm 0.2247(0.3838) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 17.7336, Epoch Time 249.1571(249.0533), Bit/dim 1.0962(best: 1.0960), Xent 0.0331, Loss 1.1127, Error 0.0100(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3249 | Time 32.0483(31.4582) | Bit/dim 1.1053(1.1021) | Xent 0.0445(0.0445) | Loss 1.1275(1.1243) | Error 0.0146(0.0137) Steps 440(440.00) | Grad Norm 0.3630(0.3832) | Total Time 10.00(10.00)\n",
      "Iter 3250 | Time 31.5774(31.4618) | Bit/dim 1.1034(1.1021) | Xent 0.0495(0.0446) | Loss 1.1281(1.1244) | Error 0.0138(0.0137) Steps 440(440.00) | Grad Norm 0.3552(0.3824) | Total Time 10.00(10.00)\n",
      "Iter 3251 | Time 31.1335(31.4519) | Bit/dim 1.1037(1.1022) | Xent 0.0440(0.0446) | Loss 1.1257(1.1245) | Error 0.0141(0.0137) Steps 440(440.00) | Grad Norm 0.1964(0.3768) | Total Time 10.00(10.00)\n",
      "Iter 3252 | Time 31.0485(31.4398) | Bit/dim 1.1042(1.1022) | Xent 0.0402(0.0445) | Loss 1.1243(1.1244) | Error 0.0118(0.0136) Steps 440(440.00) | Grad Norm 0.2350(0.3725) | Total Time 10.00(10.00)\n",
      "Iter 3253 | Time 30.6446(31.4160) | Bit/dim 1.0990(1.1021) | Xent 0.0419(0.0444) | Loss 1.1200(1.1243) | Error 0.0132(0.0136) Steps 440(440.00) | Grad Norm 0.2812(0.3698) | Total Time 10.00(10.00)\n",
      "Iter 3254 | Time 31.1067(31.4067) | Bit/dim 1.0981(1.1020) | Xent 0.0418(0.0443) | Loss 1.1190(1.1242) | Error 0.0146(0.0136) Steps 440(440.00) | Grad Norm 0.1995(0.3647) | Total Time 10.00(10.00)\n",
      "Iter 3255 | Time 31.0741(31.3967) | Bit/dim 1.1000(1.1019) | Xent 0.0452(0.0443) | Loss 1.1226(1.1241) | Error 0.0131(0.0136) Steps 440(440.00) | Grad Norm 0.3061(0.3629) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 17.5970, Epoch Time 248.8901(249.0484), Bit/dim 1.0963(best: 1.0960), Xent 0.0322, Loss 1.1124, Error 0.0094(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3256 | Time 31.1362(31.3889) | Bit/dim 1.1032(1.1020) | Xent 0.0449(0.0444) | Loss 1.1257(1.1242) | Error 0.0130(0.0136) Steps 440(440.00) | Grad Norm 0.2852(0.3606) | Total Time 10.00(10.00)\n",
      "Iter 3257 | Time 31.1650(31.3822) | Bit/dim 1.1010(1.1019) | Xent 0.0502(0.0445) | Loss 1.1261(1.1242) | Error 0.0156(0.0137) Steps 440(440.00) | Grad Norm 0.6095(0.3681) | Total Time 10.00(10.00)\n",
      "Iter 3258 | Time 31.7945(31.3945) | Bit/dim 1.1049(1.1020) | Xent 0.0371(0.0443) | Loss 1.1234(1.1242) | Error 0.0125(0.0136) Steps 440(440.00) | Grad Norm 0.2065(0.3632) | Total Time 10.00(10.00)\n",
      "Iter 3259 | Time 31.3267(31.3925) | Bit/dim 1.1034(1.1021) | Xent 0.0401(0.0442) | Loss 1.1234(1.1242) | Error 0.0120(0.0136) Steps 440(440.00) | Grad Norm 0.3520(0.3629) | Total Time 10.00(10.00)\n",
      "Iter 3260 | Time 31.4173(31.3932) | Bit/dim 1.0996(1.1020) | Xent 0.0477(0.0443) | Loss 1.1234(1.1241) | Error 0.0144(0.0136) Steps 440(440.00) | Grad Norm 0.4574(0.3657) | Total Time 10.00(10.00)\n",
      "Iter 3261 | Time 30.9498(31.3799) | Bit/dim 1.1004(1.1020) | Xent 0.0428(0.0442) | Loss 1.1218(1.1241) | Error 0.0131(0.0136) Steps 440(440.00) | Grad Norm 0.5273(0.3706) | Total Time 10.00(10.00)\n",
      "Iter 3262 | Time 31.9757(31.3978) | Bit/dim 1.1040(1.1020) | Xent 0.0535(0.0445) | Loss 1.1307(1.1243) | Error 0.0160(0.0137) Steps 440(440.00) | Grad Norm 0.3322(0.3694) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 17.6694, Epoch Time 249.7359(249.0690), Bit/dim 1.0962(best: 1.0960), Xent 0.0338, Loss 1.1131, Error 0.0099(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3263 | Time 32.4843(31.4304) | Bit/dim 1.1005(1.1020) | Xent 0.0432(0.0445) | Loss 1.1221(1.1242) | Error 0.0134(0.0137) Steps 440(440.00) | Grad Norm 0.6117(0.3767) | Total Time 10.00(10.00)\n",
      "Iter 3264 | Time 30.9461(31.4159) | Bit/dim 1.1043(1.1020) | Xent 0.0486(0.0446) | Loss 1.1286(1.1243) | Error 0.0160(0.0137) Steps 440(440.00) | Grad Norm 0.2884(0.3740) | Total Time 10.00(10.00)\n",
      "Iter 3265 | Time 31.4288(31.4163) | Bit/dim 1.1049(1.1021) | Xent 0.0470(0.0447) | Loss 1.1283(1.1245) | Error 0.0140(0.0137) Steps 440(440.00) | Grad Norm 0.3292(0.3727) | Total Time 10.00(10.00)\n",
      "Iter 3266 | Time 31.4931(31.4186) | Bit/dim 1.0994(1.1020) | Xent 0.0488(0.0448) | Loss 1.1239(1.1244) | Error 0.0151(0.0138) Steps 440(440.00) | Grad Norm 0.4150(0.3739) | Total Time 10.00(10.00)\n",
      "Iter 3267 | Time 31.2664(31.4140) | Bit/dim 1.1035(1.1021) | Xent 0.0417(0.0447) | Loss 1.1244(1.1244) | Error 0.0135(0.0138) Steps 440(440.00) | Grad Norm 0.4099(0.3750) | Total Time 10.00(10.00)\n",
      "Iter 3268 | Time 31.1305(31.4055) | Bit/dim 1.1013(1.1021) | Xent 0.0441(0.0447) | Loss 1.1233(1.1244) | Error 0.0132(0.0138) Steps 440(440.00) | Grad Norm 0.2852(0.3723) | Total Time 10.00(10.00)\n",
      "Iter 3269 | Time 31.1300(31.3972) | Bit/dim 1.1043(1.1021) | Xent 0.0468(0.0448) | Loss 1.1277(1.1245) | Error 0.0139(0.0138) Steps 440(440.00) | Grad Norm 0.2066(0.3674) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 17.7555, Epoch Time 250.2060(249.1031), Bit/dim 1.0959(best: 1.0960), Xent 0.0347, Loss 1.1133, Error 0.0105(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3270 | Time 31.1325(31.3893) | Bit/dim 1.1010(1.1021) | Xent 0.0383(0.0446) | Loss 1.1202(1.1244) | Error 0.0118(0.0137) Steps 440(440.00) | Grad Norm 0.2569(0.3640) | Total Time 10.00(10.00)\n",
      "Iter 3271 | Time 30.9491(31.3761) | Bit/dim 1.1043(1.1022) | Xent 0.0491(0.0447) | Loss 1.1289(1.1245) | Error 0.0140(0.0137) Steps 440(440.00) | Grad Norm 0.3229(0.3628) | Total Time 10.00(10.00)\n",
      "Iter 3272 | Time 31.7238(31.3865) | Bit/dim 1.1022(1.1022) | Xent 0.0433(0.0447) | Loss 1.1239(1.1245) | Error 0.0142(0.0137) Steps 440(440.00) | Grad Norm 0.1918(0.3577) | Total Time 10.00(10.00)\n",
      "Iter 3273 | Time 31.2388(31.3821) | Bit/dim 1.1039(1.1022) | Xent 0.0459(0.0447) | Loss 1.1269(1.1246) | Error 0.0134(0.0137) Steps 440(440.00) | Grad Norm 0.4022(0.3590) | Total Time 10.00(10.00)\n",
      "Iter 3274 | Time 31.3676(31.3817) | Bit/dim 1.1014(1.1022) | Xent 0.0546(0.0450) | Loss 1.1287(1.1247) | Error 0.0148(0.0137) Steps 440(440.00) | Grad Norm 0.2595(0.3560) | Total Time 10.00(10.00)\n",
      "Iter 3275 | Time 32.6714(31.4204) | Bit/dim 1.1026(1.1022) | Xent 0.0537(0.0452) | Loss 1.1294(1.1248) | Error 0.0169(0.0138) Steps 440(440.00) | Grad Norm 0.4592(0.3591) | Total Time 10.00(10.00)\n",
      "Iter 3276 | Time 31.5638(31.4247) | Bit/dim 1.0998(1.1021) | Xent 0.0375(0.0450) | Loss 1.1186(1.1246) | Error 0.0118(0.0138) Steps 440(440.00) | Grad Norm 0.2254(0.3551) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 17.8471, Epoch Time 251.2713(249.1682), Bit/dim 1.0968(best: 1.0959), Xent 0.0337, Loss 1.1136, Error 0.0112(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3277 | Time 31.0217(31.4126) | Bit/dim 1.1036(1.1022) | Xent 0.0468(0.0451) | Loss 1.1270(1.1247) | Error 0.0136(0.0138) Steps 440(440.00) | Grad Norm 0.2800(0.3529) | Total Time 10.00(10.00)\n",
      "Iter 3278 | Time 32.9559(31.4589) | Bit/dim 1.1023(1.1022) | Xent 0.0443(0.0450) | Loss 1.1245(1.1247) | Error 0.0136(0.0138) Steps 440(440.00) | Grad Norm 0.3121(0.3516) | Total Time 10.00(10.00)\n",
      "Iter 3279 | Time 31.5140(31.4605) | Bit/dim 1.1006(1.1021) | Xent 0.0454(0.0451) | Loss 1.1233(1.1247) | Error 0.0134(0.0138) Steps 440(440.00) | Grad Norm 0.3324(0.3511) | Total Time 10.00(10.00)\n",
      "Iter 3280 | Time 31.0920(31.4495) | Bit/dim 1.1048(1.1022) | Xent 0.0424(0.0450) | Loss 1.1260(1.1247) | Error 0.0131(0.0137) Steps 440(440.00) | Grad Norm 0.2629(0.3484) | Total Time 10.00(10.00)\n",
      "Iter 3281 | Time 32.3367(31.4761) | Bit/dim 1.0992(1.1021) | Xent 0.0378(0.0448) | Loss 1.1181(1.1245) | Error 0.0126(0.0137) Steps 440(440.00) | Grad Norm 0.2648(0.3459) | Total Time 10.00(10.00)\n",
      "Iter 3282 | Time 31.1494(31.4663) | Bit/dim 1.1025(1.1021) | Xent 0.0443(0.0447) | Loss 1.1247(1.1245) | Error 0.0146(0.0137) Steps 440(440.00) | Grad Norm 0.2195(0.3421) | Total Time 10.00(10.00)\n",
      "Iter 3283 | Time 30.9910(31.4520) | Bit/dim 1.0999(1.1021) | Xent 0.0488(0.0449) | Loss 1.1243(1.1245) | Error 0.0155(0.0138) Steps 440(440.00) | Grad Norm 0.2820(0.3403) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 17.7075, Epoch Time 251.7799(249.2465), Bit/dim 1.0964(best: 1.0959), Xent 0.0330, Loss 1.1130, Error 0.0094(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3284 | Time 31.2818(31.4469) | Bit/dim 1.1028(1.1021) | Xent 0.0432(0.0448) | Loss 1.1245(1.1245) | Error 0.0122(0.0137) Steps 440(440.00) | Grad Norm 0.4119(0.3425) | Total Time 10.00(10.00)\n",
      "Iter 3285 | Time 30.9096(31.4308) | Bit/dim 1.1046(1.1022) | Xent 0.0408(0.0447) | Loss 1.1250(1.1245) | Error 0.0120(0.0137) Steps 440(440.00) | Grad Norm 0.3244(0.3419) | Total Time 10.00(10.00)\n",
      "Iter 3286 | Time 31.9610(31.4467) | Bit/dim 1.1001(1.1021) | Xent 0.0462(0.0447) | Loss 1.1232(1.1245) | Error 0.0141(0.0137) Steps 440(440.00) | Grad Norm 0.2470(0.3391) | Total Time 10.00(10.00)\n",
      "Iter 3287 | Time 31.1898(31.4390) | Bit/dim 1.1003(1.1020) | Xent 0.0402(0.0446) | Loss 1.1204(1.1244) | Error 0.0114(0.0136) Steps 440(440.00) | Grad Norm 0.3299(0.3388) | Total Time 10.00(10.00)\n",
      "Iter 3288 | Time 32.1280(31.4597) | Bit/dim 1.1012(1.1020) | Xent 0.0511(0.0448) | Loss 1.1268(1.1244) | Error 0.0150(0.0137) Steps 440(440.00) | Grad Norm 0.2837(0.3371) | Total Time 10.00(10.00)\n",
      "Iter 3289 | Time 32.3592(31.4866) | Bit/dim 1.1023(1.1020) | Xent 0.0475(0.0449) | Loss 1.1260(1.1245) | Error 0.0139(0.0137) Steps 440(440.00) | Grad Norm 0.2944(0.3359) | Total Time 10.00(10.00)\n",
      "Iter 3290 | Time 31.9606(31.5009) | Bit/dim 1.0992(1.1019) | Xent 0.0467(0.0449) | Loss 1.1226(1.1244) | Error 0.0151(0.0137) Steps 440(440.00) | Grad Norm 0.2117(0.3321) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 17.6491, Epoch Time 251.8902(249.3258), Bit/dim 1.0962(best: 1.0959), Xent 0.0326, Loss 1.1125, Error 0.0092(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3291 | Time 30.8357(31.4809) | Bit/dim 1.1046(1.1020) | Xent 0.0451(0.0449) | Loss 1.1271(1.1245) | Error 0.0136(0.0137) Steps 440(440.00) | Grad Norm 0.2192(0.3288) | Total Time 10.00(10.00)\n",
      "Iter 3292 | Time 30.6136(31.4549) | Bit/dim 1.1005(1.1020) | Xent 0.0418(0.0448) | Loss 1.1214(1.1244) | Error 0.0136(0.0137) Steps 440(440.00) | Grad Norm 0.2390(0.3261) | Total Time 10.00(10.00)\n",
      "Iter 3293 | Time 31.3824(31.4527) | Bit/dim 1.1062(1.1021) | Xent 0.0510(0.0450) | Loss 1.1317(1.1246) | Error 0.0156(0.0138) Steps 440(440.00) | Grad Norm 0.2370(0.3234) | Total Time 10.00(10.00)\n",
      "Iter 3294 | Time 30.9377(31.4373) | Bit/dim 1.0968(1.1019) | Xent 0.0430(0.0450) | Loss 1.1183(1.1244) | Error 0.0130(0.0137) Steps 440(440.00) | Grad Norm 0.2358(0.3208) | Total Time 10.00(10.00)\n",
      "Iter 3295 | Time 32.1636(31.4591) | Bit/dim 1.0997(1.1019) | Xent 0.0442(0.0450) | Loss 1.1218(1.1244) | Error 0.0150(0.0138) Steps 440(440.00) | Grad Norm 0.2019(0.3172) | Total Time 10.00(10.00)\n",
      "Iter 3296 | Time 31.4202(31.4579) | Bit/dim 1.1025(1.1019) | Xent 0.0366(0.0447) | Loss 1.1208(1.1242) | Error 0.0116(0.0137) Steps 440(440.00) | Grad Norm 0.3370(0.3178) | Total Time 10.00(10.00)\n",
      "Iter 3297 | Time 30.7597(31.4369) | Bit/dim 1.0996(1.1018) | Xent 0.0446(0.0447) | Loss 1.1220(1.1242) | Error 0.0134(0.0137) Steps 440(440.00) | Grad Norm 0.2855(0.3168) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 17.7289, Epoch Time 248.5508(249.3026), Bit/dim 1.0970(best: 1.0959), Xent 0.0338, Loss 1.1139, Error 0.0109(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3298 | Time 30.8259(31.4186) | Bit/dim 1.1041(1.1019) | Xent 0.0494(0.0448) | Loss 1.1288(1.1243) | Error 0.0149(0.0137) Steps 440(440.00) | Grad Norm 0.2663(0.3153) | Total Time 10.00(10.00)\n",
      "Iter 3299 | Time 31.0509(31.4076) | Bit/dim 1.0961(1.1017) | Xent 0.0373(0.0446) | Loss 1.1147(1.1240) | Error 0.0120(0.0137) Steps 440(440.00) | Grad Norm 0.1868(0.3114) | Total Time 10.00(10.00)\n",
      "Iter 3300 | Time 30.7708(31.3885) | Bit/dim 1.1028(1.1018) | Xent 0.0405(0.0445) | Loss 1.1231(1.1240) | Error 0.0135(0.0137) Steps 440(440.00) | Grad Norm 0.5024(0.3172) | Total Time 10.00(10.00)\n",
      "Iter 3301 | Time 31.5231(31.3925) | Bit/dim 1.1033(1.1018) | Xent 0.0469(0.0446) | Loss 1.1267(1.1241) | Error 0.0159(0.0138) Steps 440(440.00) | Grad Norm 0.3615(0.3185) | Total Time 10.00(10.00)\n",
      "Iter 3302 | Time 30.5917(31.3685) | Bit/dim 1.0980(1.1017) | Xent 0.0512(0.0448) | Loss 1.1236(1.1241) | Error 0.0151(0.0138) Steps 440(440.00) | Grad Norm 0.5161(0.3244) | Total Time 10.00(10.00)\n",
      "Iter 3303 | Time 31.4381(31.3706) | Bit/dim 1.1035(1.1017) | Xent 0.0406(0.0446) | Loss 1.1238(1.1241) | Error 0.0128(0.0138) Steps 440(440.00) | Grad Norm 0.2927(0.3235) | Total Time 10.00(10.00)\n",
      "Iter 3304 | Time 31.2806(31.3679) | Bit/dim 1.1028(1.1018) | Xent 0.0425(0.0446) | Loss 1.1241(1.1241) | Error 0.0140(0.0138) Steps 440(440.00) | Grad Norm 0.5179(0.3293) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 17.6892, Epoch Time 247.8567(249.2592), Bit/dim 1.0960(best: 1.0959), Xent 0.0309, Loss 1.1115, Error 0.0100(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3305 | Time 31.4134(31.3692) | Bit/dim 1.1027(1.1018) | Xent 0.0390(0.0444) | Loss 1.1222(1.1240) | Error 0.0111(0.0137) Steps 440(440.00) | Grad Norm 0.2929(0.3282) | Total Time 10.00(10.00)\n",
      "Iter 3306 | Time 31.5209(31.3738) | Bit/dim 1.1018(1.1018) | Xent 0.0512(0.0446) | Loss 1.1274(1.1241) | Error 0.0156(0.0137) Steps 440(440.00) | Grad Norm 0.4525(0.3320) | Total Time 10.00(10.00)\n",
      "Iter 3307 | Time 32.0151(31.3930) | Bit/dim 1.1008(1.1018) | Xent 0.0395(0.0445) | Loss 1.1206(1.1240) | Error 0.0120(0.0137) Steps 440(440.00) | Grad Norm 0.5440(0.3383) | Total Time 10.00(10.00)\n",
      "Iter 3308 | Time 31.0788(31.3836) | Bit/dim 1.1010(1.1017) | Xent 0.0435(0.0444) | Loss 1.1228(1.1240) | Error 0.0132(0.0137) Steps 440(440.00) | Grad Norm 0.6162(0.3466) | Total Time 10.00(10.00)\n",
      "Iter 3309 | Time 31.0153(31.3726) | Bit/dim 1.1024(1.1018) | Xent 0.0520(0.0447) | Loss 1.1284(1.1241) | Error 0.0151(0.0137) Steps 440(440.00) | Grad Norm 0.2901(0.3450) | Total Time 10.00(10.00)\n",
      "Iter 3310 | Time 31.3270(31.3712) | Bit/dim 1.1066(1.1019) | Xent 0.0371(0.0444) | Loss 1.1252(1.1241) | Error 0.0125(0.0137) Steps 440(440.00) | Grad Norm 0.2385(0.3418) | Total Time 10.00(10.00)\n",
      "Iter 3311 | Time 30.8980(31.3570) | Bit/dim 1.0999(1.1019) | Xent 0.0461(0.0445) | Loss 1.1229(1.1241) | Error 0.0136(0.0137) Steps 440(440.00) | Grad Norm 0.7410(0.3537) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 17.5118, Epoch Time 249.6806(249.2719), Bit/dim 1.0961(best: 1.0959), Xent 0.0337, Loss 1.1129, Error 0.0095(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3312 | Time 32.0461(31.3777) | Bit/dim 1.1044(1.1019) | Xent 0.0372(0.0443) | Loss 1.1230(1.1241) | Error 0.0132(0.0137) Steps 440(440.00) | Grad Norm 0.5448(0.3595) | Total Time 10.00(10.00)\n",
      "Iter 3313 | Time 30.8839(31.3629) | Bit/dim 1.1000(1.1019) | Xent 0.0442(0.0443) | Loss 1.1221(1.1240) | Error 0.0156(0.0137) Steps 440(440.00) | Grad Norm 0.2517(0.3562) | Total Time 10.00(10.00)\n",
      "Iter 3314 | Time 30.9512(31.3505) | Bit/dim 1.0997(1.1018) | Xent 0.0438(0.0442) | Loss 1.1216(1.1239) | Error 0.0136(0.0137) Steps 440(440.00) | Grad Norm 0.8917(0.3723) | Total Time 10.00(10.00)\n",
      "Iter 3315 | Time 31.0359(31.3411) | Bit/dim 1.0956(1.1016) | Xent 0.0415(0.0442) | Loss 1.1163(1.1237) | Error 0.0138(0.0137) Steps 440(440.00) | Grad Norm 0.7883(0.3848) | Total Time 10.00(10.00)\n",
      "Iter 3316 | Time 31.1813(31.3363) | Bit/dim 1.1080(1.1018) | Xent 0.0422(0.0441) | Loss 1.1291(1.1239) | Error 0.0139(0.0137) Steps 440(440.00) | Grad Norm 0.2435(0.3805) | Total Time 10.00(10.00)\n",
      "Iter 3317 | Time 31.2476(31.3336) | Bit/dim 1.1026(1.1018) | Xent 0.0452(0.0441) | Loss 1.1252(1.1239) | Error 0.0145(0.0138) Steps 440(440.00) | Grad Norm 0.5947(0.3870) | Total Time 10.00(10.00)\n",
      "Iter 3318 | Time 31.2538(31.3312) | Bit/dim 1.1034(1.1019) | Xent 0.0478(0.0442) | Loss 1.1273(1.1240) | Error 0.0166(0.0138) Steps 440(440.00) | Grad Norm 0.7311(0.3973) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 17.7958, Epoch Time 248.8547(249.2593), Bit/dim 1.0960(best: 1.0959), Xent 0.0345, Loss 1.1132, Error 0.0098(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3319 | Time 31.5514(31.3378) | Bit/dim 1.1016(1.1019) | Xent 0.0415(0.0442) | Loss 1.1224(1.1240) | Error 0.0130(0.0138) Steps 440(440.00) | Grad Norm 0.4561(0.3991) | Total Time 10.00(10.00)\n",
      "Iter 3320 | Time 32.6262(31.3765) | Bit/dim 1.1014(1.1019) | Xent 0.0442(0.0442) | Loss 1.1235(1.1239) | Error 0.0135(0.0138) Steps 440(440.00) | Grad Norm 0.4670(0.4011) | Total Time 10.00(10.00)\n",
      "Iter 3321 | Time 32.2469(31.4026) | Bit/dim 1.0994(1.1018) | Xent 0.0472(0.0443) | Loss 1.1230(1.1239) | Error 0.0140(0.0138) Steps 440(440.00) | Grad Norm 0.5605(0.4059) | Total Time 10.00(10.00)\n",
      "Iter 3322 | Time 31.9675(31.4195) | Bit/dim 1.1029(1.1018) | Xent 0.0439(0.0442) | Loss 1.1248(1.1239) | Error 0.0139(0.0138) Steps 440(440.00) | Grad Norm 0.4933(0.4085) | Total Time 10.00(10.00)\n",
      "Iter 3323 | Time 31.6301(31.4259) | Bit/dim 1.1044(1.1019) | Xent 0.0414(0.0442) | Loss 1.1251(1.1240) | Error 0.0130(0.0138) Steps 440(440.00) | Grad Norm 0.2908(0.4050) | Total Time 10.00(10.00)\n",
      "Iter 3324 | Time 31.6504(31.4326) | Bit/dim 1.1039(1.1020) | Xent 0.0464(0.0442) | Loss 1.1270(1.1241) | Error 0.0141(0.0138) Steps 440(440.00) | Grad Norm 0.5448(0.4092) | Total Time 10.00(10.00)\n",
      "Iter 3325 | Time 31.2497(31.4271) | Bit/dim 1.0992(1.1019) | Xent 0.0444(0.0442) | Loss 1.1214(1.1240) | Error 0.0144(0.0138) Steps 440(440.00) | Grad Norm 0.3152(0.4063) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 17.3584, Epoch Time 253.0671(249.3736), Bit/dim 1.0962(best: 1.0959), Xent 0.0326, Loss 1.1125, Error 0.0095(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3326 | Time 31.7234(31.4360) | Bit/dim 1.1004(1.1018) | Xent 0.0405(0.0441) | Loss 1.1206(1.1239) | Error 0.0134(0.0138) Steps 440(440.00) | Grad Norm 0.3463(0.4045) | Total Time 10.00(10.00)\n",
      "Iter 3327 | Time 31.2950(31.4318) | Bit/dim 1.1033(1.1019) | Xent 0.0494(0.0443) | Loss 1.1280(1.1240) | Error 0.0138(0.0138) Steps 440(440.00) | Grad Norm 0.2663(0.4004) | Total Time 10.00(10.00)\n",
      "Iter 3328 | Time 30.7550(31.4115) | Bit/dim 1.1013(1.1019) | Xent 0.0426(0.0442) | Loss 1.1225(1.1240) | Error 0.0132(0.0138) Steps 440(440.00) | Grad Norm 0.4532(0.4020) | Total Time 10.00(10.00)\n",
      "Iter 3329 | Time 31.3226(31.4088) | Bit/dim 1.0976(1.1017) | Xent 0.0481(0.0443) | Loss 1.1216(1.1239) | Error 0.0138(0.0138) Steps 440(440.00) | Grad Norm 0.2216(0.3966) | Total Time 10.00(10.00)\n",
      "Iter 3330 | Time 31.1954(31.4024) | Bit/dim 1.1007(1.1017) | Xent 0.0439(0.0443) | Loss 1.1226(1.1239) | Error 0.0135(0.0138) Steps 440(440.00) | Grad Norm 0.2431(0.3920) | Total Time 10.00(10.00)\n",
      "Iter 3331 | Time 31.2585(31.3981) | Bit/dim 1.1048(1.1018) | Xent 0.0424(0.0443) | Loss 1.1260(1.1239) | Error 0.0129(0.0138) Steps 440(440.00) | Grad Norm 0.3598(0.3910) | Total Time 10.00(10.00)\n",
      "Iter 3332 | Time 30.6576(31.3759) | Bit/dim 1.1022(1.1018) | Xent 0.0439(0.0443) | Loss 1.1242(1.1239) | Error 0.0154(0.0138) Steps 440(440.00) | Grad Norm 0.3334(0.3893) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 17.6063, Epoch Time 248.5797(249.3498), Bit/dim 1.0964(best: 1.0959), Xent 0.0345, Loss 1.1137, Error 0.0089(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3333 | Time 31.2397(31.3718) | Bit/dim 1.1008(1.1018) | Xent 0.0450(0.0443) | Loss 1.1233(1.1239) | Error 0.0139(0.0138) Steps 440(440.00) | Grad Norm 0.2215(0.3842) | Total Time 10.00(10.00)\n",
      "Iter 3334 | Time 32.1971(31.3965) | Bit/dim 1.1043(1.1018) | Xent 0.0389(0.0441) | Loss 1.1237(1.1239) | Error 0.0118(0.0137) Steps 440(440.00) | Grad Norm 0.3621(0.3836) | Total Time 10.00(10.00)\n",
      "Iter 3335 | Time 32.1046(31.4178) | Bit/dim 1.1045(1.1019) | Xent 0.0412(0.0440) | Loss 1.1251(1.1239) | Error 0.0142(0.0138) Steps 440(440.00) | Grad Norm 0.2714(0.3802) | Total Time 10.00(10.00)\n",
      "Iter 3336 | Time 30.4686(31.3893) | Bit/dim 1.1033(1.1020) | Xent 0.0487(0.0442) | Loss 1.1276(1.1240) | Error 0.0164(0.0138) Steps 440(440.00) | Grad Norm 0.4592(0.3826) | Total Time 10.00(10.00)\n",
      "Iter 3337 | Time 31.1422(31.3819) | Bit/dim 1.1035(1.1020) | Xent 0.0420(0.0441) | Loss 1.1244(1.1241) | Error 0.0129(0.0138) Steps 440(440.00) | Grad Norm 0.3809(0.3825) | Total Time 10.00(10.00)\n",
      "Iter 3338 | Time 32.5218(31.4161) | Bit/dim 1.0951(1.1018) | Xent 0.0427(0.0441) | Loss 1.1165(1.1238) | Error 0.0130(0.0138) Steps 440(440.00) | Grad Norm 0.4022(0.3831) | Total Time 10.00(10.00)\n",
      "Iter 3339 | Time 31.6430(31.4229) | Bit/dim 1.1016(1.1018) | Xent 0.0502(0.0442) | Loss 1.1267(1.1239) | Error 0.0156(0.0138) Steps 440(440.00) | Grad Norm 0.2695(0.3797) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 17.7198, Epoch Time 251.6480(249.4187), Bit/dim 1.0968(best: 1.0959), Xent 0.0331, Loss 1.1133, Error 0.0094(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3340 | Time 30.8684(31.4063) | Bit/dim 1.1026(1.1018) | Xent 0.0420(0.0442) | Loss 1.1236(1.1239) | Error 0.0142(0.0138) Steps 440(440.00) | Grad Norm 0.2879(0.3769) | Total Time 10.00(10.00)\n",
      "Iter 3341 | Time 30.9346(31.3921) | Bit/dim 1.1041(1.1019) | Xent 0.0376(0.0440) | Loss 1.1229(1.1239) | Error 0.0114(0.0138) Steps 440(440.00) | Grad Norm 0.3388(0.3758) | Total Time 10.00(10.00)\n",
      "Iter 3342 | Time 31.2218(31.3870) | Bit/dim 1.0976(1.1018) | Xent 0.0455(0.0440) | Loss 1.1204(1.1238) | Error 0.0138(0.0138) Steps 440(440.00) | Grad Norm 0.2728(0.3727) | Total Time 10.00(10.00)\n",
      "Iter 3343 | Time 32.0867(31.4080) | Bit/dim 1.0971(1.1016) | Xent 0.0520(0.0443) | Loss 1.1231(1.1238) | Error 0.0169(0.0139) Steps 440(440.00) | Grad Norm 0.4691(0.3756) | Total Time 10.00(10.00)\n",
      "Iter 3344 | Time 31.3113(31.4051) | Bit/dim 1.1010(1.1016) | Xent 0.0432(0.0442) | Loss 1.1227(1.1237) | Error 0.0135(0.0139) Steps 440(440.00) | Grad Norm 0.3251(0.3741) | Total Time 10.00(10.00)\n",
      "Iter 3345 | Time 31.5667(31.4099) | Bit/dim 1.1024(1.1016) | Xent 0.0446(0.0442) | Loss 1.1247(1.1238) | Error 0.0136(0.0138) Steps 440(440.00) | Grad Norm 0.2938(0.3717) | Total Time 10.00(10.00)\n",
      "Iter 3346 | Time 31.2820(31.4061) | Bit/dim 1.1050(1.1017) | Xent 0.0379(0.0441) | Loss 1.1239(1.1238) | Error 0.0126(0.0138) Steps 440(440.00) | Grad Norm 0.3867(0.3721) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 17.7428, Epoch Time 250.1038(249.4393), Bit/dim 1.0962(best: 1.0959), Xent 0.0340, Loss 1.1132, Error 0.0108(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3347 | Time 31.2773(31.4022) | Bit/dim 1.0987(1.1016) | Xent 0.0405(0.0439) | Loss 1.1190(1.1236) | Error 0.0122(0.0138) Steps 440(440.00) | Grad Norm 0.2463(0.3684) | Total Time 10.00(10.00)\n",
      "Iter 3348 | Time 33.0124(31.4505) | Bit/dim 1.1025(1.1017) | Xent 0.0355(0.0437) | Loss 1.1202(1.1235) | Error 0.0115(0.0137) Steps 440(440.00) | Grad Norm 0.2351(0.3644) | Total Time 10.00(10.00)\n",
      "Iter 3349 | Time 31.0177(31.4376) | Bit/dim 1.1040(1.1017) | Xent 0.0502(0.0439) | Loss 1.1291(1.1237) | Error 0.0148(0.0137) Steps 440(440.00) | Grad Norm 0.5982(0.3714) | Total Time 10.00(10.00)\n",
      "Iter 3350 | Time 30.9094(31.4217) | Bit/dim 1.0992(1.1017) | Xent 0.0404(0.0438) | Loss 1.1194(1.1236) | Error 0.0128(0.0137) Steps 440(440.00) | Grad Norm 0.1848(0.3658) | Total Time 10.00(10.00)\n",
      "Iter 3351 | Time 31.9784(31.4384) | Bit/dim 1.1055(1.1018) | Xent 0.0458(0.0438) | Loss 1.1284(1.1237) | Error 0.0145(0.0137) Steps 440(440.00) | Grad Norm 0.5726(0.3720) | Total Time 10.00(10.00)\n",
      "Iter 3352 | Time 31.7236(31.4470) | Bit/dim 1.1017(1.1018) | Xent 0.0439(0.0438) | Loss 1.1236(1.1237) | Error 0.0142(0.0137) Steps 440(440.00) | Grad Norm 0.2579(0.3686) | Total Time 10.00(10.00)\n",
      "Iter 3353 | Time 31.2519(31.4411) | Bit/dim 1.1015(1.1018) | Xent 0.0420(0.0438) | Loss 1.1225(1.1237) | Error 0.0122(0.0137) Steps 440(440.00) | Grad Norm 0.4983(0.3724) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 17.7598, Epoch Time 251.9397(249.5143), Bit/dim 1.0960(best: 1.0959), Xent 0.0355, Loss 1.1138, Error 0.0109(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3354 | Time 31.3566(31.4386) | Bit/dim 1.0986(1.1017) | Xent 0.0465(0.0439) | Loss 1.1219(1.1236) | Error 0.0145(0.0137) Steps 440(440.00) | Grad Norm 0.2037(0.3674) | Total Time 10.00(10.00)\n",
      "Iter 3355 | Time 33.2059(31.4916) | Bit/dim 1.1056(1.1018) | Xent 0.0417(0.0438) | Loss 1.1265(1.1237) | Error 0.0129(0.0137) Steps 440(440.00) | Grad Norm 0.3367(0.3665) | Total Time 10.00(10.00)\n",
      "Iter 3356 | Time 31.6560(31.4965) | Bit/dim 1.0972(1.1017) | Xent 0.0416(0.0437) | Loss 1.1180(1.1235) | Error 0.0131(0.0137) Steps 440(440.00) | Grad Norm 0.3331(0.3655) | Total Time 10.00(10.00)\n",
      "Iter 3357 | Time 31.4291(31.4945) | Bit/dim 1.1080(1.1018) | Xent 0.0480(0.0439) | Loss 1.1320(1.1238) | Error 0.0151(0.0137) Steps 440(440.00) | Grad Norm 0.4758(0.3688) | Total Time 10.00(10.00)\n",
      "Iter 3358 | Time 31.1420(31.4839) | Bit/dim 1.1004(1.1018) | Xent 0.0495(0.0440) | Loss 1.1252(1.1238) | Error 0.0158(0.0138) Steps 440(440.00) | Grad Norm 0.3245(0.3674) | Total Time 10.00(10.00)\n",
      "Iter 3359 | Time 32.6253(31.5182) | Bit/dim 1.0972(1.1017) | Xent 0.0431(0.0440) | Loss 1.1187(1.1237) | Error 0.0129(0.0138) Steps 440(440.00) | Grad Norm 0.2817(0.3649) | Total Time 10.00(10.00)\n",
      "Iter 3360 | Time 31.0950(31.5055) | Bit/dim 1.1016(1.1017) | Xent 0.0380(0.0438) | Loss 1.1206(1.1236) | Error 0.0121(0.0137) Steps 440(440.00) | Grad Norm 0.3703(0.3650) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 17.4273, Epoch Time 252.2740(249.5971), Bit/dim 1.0961(best: 1.0959), Xent 0.0315, Loss 1.1119, Error 0.0098(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3361 | Time 31.8311(31.5152) | Bit/dim 1.1026(1.1017) | Xent 0.0514(0.0441) | Loss 1.1283(1.1237) | Error 0.0159(0.0138) Steps 440(440.00) | Grad Norm 0.2922(0.3628) | Total Time 10.00(10.00)\n",
      "Iter 3362 | Time 31.8333(31.5248) | Bit/dim 1.1014(1.1017) | Xent 0.0486(0.0442) | Loss 1.1257(1.1238) | Error 0.0135(0.0138) Steps 440(440.00) | Grad Norm 0.2879(0.3606) | Total Time 10.00(10.00)\n",
      "Iter 3363 | Time 30.9012(31.5061) | Bit/dim 1.1009(1.1017) | Xent 0.0432(0.0442) | Loss 1.1225(1.1237) | Error 0.0139(0.0138) Steps 440(440.00) | Grad Norm 0.2331(0.3568) | Total Time 10.00(10.00)\n",
      "Iter 3364 | Time 31.2257(31.4977) | Bit/dim 1.0982(1.1015) | Xent 0.0409(0.0441) | Loss 1.1186(1.1236) | Error 0.0119(0.0137) Steps 440(440.00) | Grad Norm 0.2192(0.3526) | Total Time 10.00(10.00)\n",
      "Iter 3365 | Time 31.5797(31.5001) | Bit/dim 1.0981(1.1014) | Xent 0.0443(0.0441) | Loss 1.1202(1.1235) | Error 0.0131(0.0137) Steps 440(440.00) | Grad Norm 0.2889(0.3507) | Total Time 10.00(10.00)\n",
      "Iter 3366 | Time 32.0676(31.5172) | Bit/dim 1.1049(1.1015) | Xent 0.0421(0.0440) | Loss 1.1260(1.1236) | Error 0.0118(0.0136) Steps 440(440.00) | Grad Norm 0.4033(0.3523) | Total Time 10.00(10.00)\n",
      "Iter 3367 | Time 31.7457(31.5240) | Bit/dim 1.1032(1.1016) | Xent 0.0434(0.0440) | Loss 1.1249(1.1236) | Error 0.0136(0.0136) Steps 440(440.00) | Grad Norm 0.3334(0.3517) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 17.8107, Epoch Time 251.4265(249.6520), Bit/dim 1.0962(best: 1.0959), Xent 0.0332, Loss 1.1128, Error 0.0098(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3368 | Time 30.7697(31.5014) | Bit/dim 1.1023(1.1016) | Xent 0.0473(0.0441) | Loss 1.1259(1.1237) | Error 0.0149(0.0137) Steps 440(440.00) | Grad Norm 0.2913(0.3499) | Total Time 10.00(10.00)\n",
      "Iter 3369 | Time 31.0072(31.4866) | Bit/dim 1.0992(1.1015) | Xent 0.0477(0.0442) | Loss 1.1231(1.1236) | Error 0.0135(0.0137) Steps 440(440.00) | Grad Norm 0.5218(0.3551) | Total Time 10.00(10.00)\n",
      "Iter 3370 | Time 31.3045(31.4811) | Bit/dim 1.1011(1.1015) | Xent 0.0375(0.0440) | Loss 1.1199(1.1235) | Error 0.0125(0.0136) Steps 440(440.00) | Grad Norm 0.2868(0.3530) | Total Time 10.00(10.00)\n",
      "Iter 3371 | Time 31.2690(31.4747) | Bit/dim 1.1014(1.1015) | Xent 0.0450(0.0440) | Loss 1.1239(1.1235) | Error 0.0144(0.0137) Steps 440(440.00) | Grad Norm 0.2446(0.3498) | Total Time 10.00(10.00)\n",
      "Iter 3372 | Time 30.9375(31.4586) | Bit/dim 1.0983(1.1014) | Xent 0.0432(0.0440) | Loss 1.1199(1.1234) | Error 0.0129(0.0136) Steps 440(440.00) | Grad Norm 0.4808(0.3537) | Total Time 10.00(10.00)\n",
      "Iter 3373 | Time 31.0841(31.4474) | Bit/dim 1.1027(1.1015) | Xent 0.0378(0.0438) | Loss 1.1216(1.1234) | Error 0.0122(0.0136) Steps 440(440.00) | Grad Norm 0.3292(0.3530) | Total Time 10.00(10.00)\n",
      "Iter 3374 | Time 31.2751(31.4422) | Bit/dim 1.1045(1.1016) | Xent 0.0427(0.0438) | Loss 1.1258(1.1235) | Error 0.0136(0.0136) Steps 440(440.00) | Grad Norm 0.2476(0.3498) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 17.5965, Epoch Time 247.6649(249.5923), Bit/dim 1.0959(best: 1.0959), Xent 0.0328, Loss 1.1123, Error 0.0099(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3375 | Time 31.2397(31.4361) | Bit/dim 1.1026(1.1016) | Xent 0.0436(0.0438) | Loss 1.1245(1.1235) | Error 0.0141(0.0136) Steps 440(440.00) | Grad Norm 0.4083(0.3516) | Total Time 10.00(10.00)\n",
      "Iter 3376 | Time 31.3621(31.4339) | Bit/dim 1.0978(1.1015) | Xent 0.0380(0.0436) | Loss 1.1168(1.1233) | Error 0.0116(0.0135) Steps 440(440.00) | Grad Norm 0.5451(0.3574) | Total Time 10.00(10.00)\n",
      "Iter 3377 | Time 31.3754(31.4322) | Bit/dim 1.1020(1.1015) | Xent 0.0465(0.0437) | Loss 1.1252(1.1233) | Error 0.0134(0.0135) Steps 440(440.00) | Grad Norm 0.2646(0.3546) | Total Time 10.00(10.00)\n",
      "Iter 3378 | Time 31.1542(31.4238) | Bit/dim 1.1015(1.1015) | Xent 0.0471(0.0438) | Loss 1.1251(1.1234) | Error 0.0145(0.0136) Steps 440(440.00) | Grad Norm 0.4563(0.3576) | Total Time 10.00(10.00)\n",
      "Iter 3379 | Time 31.2124(31.4175) | Bit/dim 1.1012(1.1015) | Xent 0.0491(0.0440) | Loss 1.1257(1.1235) | Error 0.0146(0.0136) Steps 440(440.00) | Grad Norm 0.4130(0.3593) | Total Time 10.00(10.00)\n",
      "Iter 3380 | Time 31.2701(31.4131) | Bit/dim 1.0969(1.1013) | Xent 0.0408(0.0439) | Loss 1.1173(1.1233) | Error 0.0125(0.0136) Steps 440(440.00) | Grad Norm 0.2249(0.3553) | Total Time 10.00(10.00)\n",
      "Iter 3381 | Time 31.2911(31.4094) | Bit/dim 1.1055(1.1015) | Xent 0.0432(0.0438) | Loss 1.1271(1.1234) | Error 0.0136(0.0136) Steps 440(440.00) | Grad Norm 0.3290(0.3545) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 17.6228, Epoch Time 249.6093(249.5928), Bit/dim 1.0962(best: 1.0959), Xent 0.0336, Loss 1.1130, Error 0.0095(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3382 | Time 31.2924(31.4059) | Bit/dim 1.0989(1.1014) | Xent 0.0419(0.0438) | Loss 1.1198(1.1233) | Error 0.0135(0.0136) Steps 440(440.00) | Grad Norm 0.5286(0.3597) | Total Time 10.00(10.00)\n",
      "Iter 3383 | Time 30.9330(31.3917) | Bit/dim 1.1051(1.1015) | Xent 0.0474(0.0439) | Loss 1.1288(1.1235) | Error 0.0144(0.0136) Steps 440(440.00) | Grad Norm 0.1913(0.3547) | Total Time 10.00(10.00)\n",
      "Iter 3384 | Time 31.8652(31.4059) | Bit/dim 1.0983(1.1014) | Xent 0.0434(0.0439) | Loss 1.1199(1.1233) | Error 0.0130(0.0136) Steps 440(440.00) | Grad Norm 0.3545(0.3547) | Total Time 10.00(10.00)\n",
      "Iter 3385 | Time 32.7081(31.4450) | Bit/dim 1.1022(1.1014) | Xent 0.0498(0.0441) | Loss 1.1271(1.1235) | Error 0.0148(0.0136) Steps 440(440.00) | Grad Norm 0.3478(0.3544) | Total Time 10.00(10.00)\n",
      "Iter 3386 | Time 31.8307(31.4565) | Bit/dim 1.1052(1.1015) | Xent 0.0453(0.0441) | Loss 1.1278(1.1236) | Error 0.0141(0.0136) Steps 440(440.00) | Grad Norm 0.3099(0.3531) | Total Time 10.00(10.00)\n",
      "Iter 3387 | Time 31.0230(31.4435) | Bit/dim 1.0995(1.1015) | Xent 0.0364(0.0439) | Loss 1.1177(1.1234) | Error 0.0120(0.0136) Steps 440(440.00) | Grad Norm 0.2399(0.3497) | Total Time 10.00(10.00)\n",
      "Iter 3388 | Time 32.1216(31.4639) | Bit/dim 1.1009(1.1015) | Xent 0.0411(0.0438) | Loss 1.1215(1.1234) | Error 0.0120(0.0135) Steps 440(440.00) | Grad Norm 0.3025(0.3483) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 17.7755, Epoch Time 252.2297(249.6720), Bit/dim 1.0958(best: 1.0959), Xent 0.0323, Loss 1.1120, Error 0.0103(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3389 | Time 30.8238(31.4447) | Bit/dim 1.1047(1.1016) | Xent 0.0482(0.0439) | Loss 1.1288(1.1235) | Error 0.0135(0.0135) Steps 440(440.00) | Grad Norm 0.3048(0.3470) | Total Time 10.00(10.00)\n",
      "Iter 3390 | Time 31.0247(31.4321) | Bit/dim 1.1037(1.1016) | Xent 0.0440(0.0439) | Loss 1.1257(1.1236) | Error 0.0138(0.0135) Steps 440(440.00) | Grad Norm 0.2306(0.3435) | Total Time 10.00(10.00)\n",
      "Iter 3391 | Time 31.0072(31.4193) | Bit/dim 1.0987(1.1015) | Xent 0.0481(0.0440) | Loss 1.1228(1.1236) | Error 0.0145(0.0136) Steps 440(440.00) | Grad Norm 0.3680(0.3442) | Total Time 10.00(10.00)\n",
      "Iter 3392 | Time 31.3565(31.4174) | Bit/dim 1.1061(1.1017) | Xent 0.0401(0.0439) | Loss 1.1262(1.1236) | Error 0.0131(0.0136) Steps 440(440.00) | Grad Norm 0.4130(0.3463) | Total Time 10.00(10.00)\n",
      "Iter 3393 | Time 31.2077(31.4112) | Bit/dim 1.0956(1.1015) | Xent 0.0456(0.0440) | Loss 1.1184(1.1235) | Error 0.0132(0.0135) Steps 440(440.00) | Grad Norm 0.2957(0.3448) | Total Time 10.00(10.00)\n",
      "Iter 3394 | Time 32.8459(31.4542) | Bit/dim 1.0994(1.1014) | Xent 0.0442(0.0440) | Loss 1.1215(1.1234) | Error 0.0136(0.0135) Steps 440(440.00) | Grad Norm 0.3265(0.3442) | Total Time 10.00(10.00)\n",
      "Iter 3395 | Time 31.3707(31.4517) | Bit/dim 1.0999(1.1014) | Xent 0.0420(0.0439) | Loss 1.1209(1.1233) | Error 0.0138(0.0135) Steps 440(440.00) | Grad Norm 0.3188(0.3435) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 17.8473, Epoch Time 250.2621(249.6897), Bit/dim 1.0957(best: 1.0958), Xent 0.0289, Loss 1.1101, Error 0.0094(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3396 | Time 31.3117(31.4475) | Bit/dim 1.0977(1.1013) | Xent 0.0469(0.0440) | Loss 1.1211(1.1233) | Error 0.0150(0.0136) Steps 440(440.00) | Grad Norm 0.3312(0.3431) | Total Time 10.00(10.00)\n",
      "Iter 3397 | Time 30.7535(31.4267) | Bit/dim 1.0992(1.1012) | Xent 0.0453(0.0440) | Loss 1.1219(1.1232) | Error 0.0135(0.0136) Steps 440(440.00) | Grad Norm 0.2587(0.3406) | Total Time 10.00(10.00)\n",
      "Iter 3398 | Time 30.8816(31.4103) | Bit/dim 1.1002(1.1012) | Xent 0.0517(0.0443) | Loss 1.1260(1.1233) | Error 0.0144(0.0136) Steps 440(440.00) | Grad Norm 0.2151(0.3368) | Total Time 10.00(10.00)\n",
      "Iter 3399 | Time 30.6399(31.3872) | Bit/dim 1.1071(1.1014) | Xent 0.0407(0.0442) | Loss 1.1275(1.1234) | Error 0.0129(0.0136) Steps 440(440.00) | Grad Norm 0.2349(0.3338) | Total Time 10.00(10.00)\n",
      "Iter 3400 | Time 31.4016(31.3876) | Bit/dim 1.1031(1.1014) | Xent 0.0462(0.0442) | Loss 1.1262(1.1235) | Error 0.0132(0.0136) Steps 440(440.00) | Grad Norm 0.1900(0.3294) | Total Time 10.00(10.00)\n",
      "Iter 3401 | Time 31.2488(31.3835) | Bit/dim 1.1012(1.1014) | Xent 0.0407(0.0441) | Loss 1.1215(1.1235) | Error 0.0129(0.0136) Steps 440(440.00) | Grad Norm 0.2849(0.3281) | Total Time 10.00(10.00)\n",
      "Iter 3402 | Time 31.0158(31.3724) | Bit/dim 1.0999(1.1014) | Xent 0.0413(0.0440) | Loss 1.1206(1.1234) | Error 0.0140(0.0136) Steps 440(440.00) | Grad Norm 0.3287(0.3281) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 17.8294, Epoch Time 247.7800(249.6324), Bit/dim 1.0957(best: 1.0957), Xent 0.0312, Loss 1.1113, Error 0.0087(best: 0.0089)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3403 | Time 30.5679(31.3483) | Bit/dim 1.1009(1.1013) | Xent 0.0488(0.0442) | Loss 1.1253(1.1234) | Error 0.0139(0.0136) Steps 440(440.00) | Grad Norm 0.3412(0.3285) | Total Time 10.00(10.00)\n",
      "Iter 3404 | Time 31.0632(31.3398) | Bit/dim 1.0966(1.1012) | Xent 0.0588(0.0446) | Loss 1.1260(1.1235) | Error 0.0162(0.0137) Steps 440(440.00) | Grad Norm 0.1958(0.3245) | Total Time 10.00(10.00)\n",
      "Iter 3405 | Time 31.1203(31.3332) | Bit/dim 1.1022(1.1012) | Xent 0.0410(0.0445) | Loss 1.1227(1.1235) | Error 0.0130(0.0136) Steps 440(440.00) | Grad Norm 0.4286(0.3277) | Total Time 10.00(10.00)\n",
      "Iter 3406 | Time 31.2624(31.3310) | Bit/dim 1.0991(1.1012) | Xent 0.0311(0.0441) | Loss 1.1146(1.1232) | Error 0.0096(0.0135) Steps 440(440.00) | Grad Norm 0.3242(0.3276) | Total Time 10.00(10.00)\n",
      "Iter 3407 | Time 30.8504(31.3166) | Bit/dim 1.1039(1.1013) | Xent 0.0389(0.0440) | Loss 1.1234(1.1232) | Error 0.0118(0.0135) Steps 440(440.00) | Grad Norm 0.2641(0.3256) | Total Time 10.00(10.00)\n",
      "Iter 3408 | Time 31.2319(31.3141) | Bit/dim 1.1025(1.1013) | Xent 0.0409(0.0439) | Loss 1.1230(1.1232) | Error 0.0134(0.0135) Steps 440(440.00) | Grad Norm 0.3430(0.3262) | Total Time 10.00(10.00)\n",
      "Iter 3409 | Time 31.2784(31.3130) | Bit/dim 1.1016(1.1013) | Xent 0.0440(0.0439) | Loss 1.1236(1.1232) | Error 0.0130(0.0135) Steps 440(440.00) | Grad Norm 0.1708(0.3215) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 17.6458, Epoch Time 247.7660(249.5764), Bit/dim 1.0960(best: 1.0957), Xent 0.0324, Loss 1.1123, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3410 | Time 30.7345(31.2957) | Bit/dim 1.1010(1.1013) | Xent 0.0417(0.0438) | Loss 1.1219(1.1232) | Error 0.0125(0.0134) Steps 440(440.00) | Grad Norm 0.3089(0.3211) | Total Time 10.00(10.00)\n",
      "Iter 3411 | Time 31.0310(31.2877) | Bit/dim 1.0972(1.1012) | Xent 0.0399(0.0437) | Loss 1.1172(1.1230) | Error 0.0102(0.0133) Steps 440(440.00) | Grad Norm 0.2326(0.3185) | Total Time 10.00(10.00)\n",
      "Iter 3412 | Time 31.0703(31.2812) | Bit/dim 1.0974(1.1011) | Xent 0.0432(0.0437) | Loss 1.1190(1.1229) | Error 0.0134(0.0133) Steps 440(440.00) | Grad Norm 0.2923(0.3177) | Total Time 10.00(10.00)\n",
      "Iter 3413 | Time 31.6321(31.2917) | Bit/dim 1.1067(1.1012) | Xent 0.0429(0.0436) | Loss 1.1281(1.1231) | Error 0.0125(0.0133) Steps 440(440.00) | Grad Norm 0.3378(0.3183) | Total Time 10.00(10.00)\n",
      "Iter 3414 | Time 30.9707(31.2821) | Bit/dim 1.1018(1.1012) | Xent 0.0408(0.0436) | Loss 1.1222(1.1230) | Error 0.0126(0.0133) Steps 440(440.00) | Grad Norm 0.2131(0.3151) | Total Time 10.00(10.00)\n",
      "Iter 3415 | Time 30.8541(31.2693) | Bit/dim 1.1029(1.1013) | Xent 0.0456(0.0436) | Loss 1.1256(1.1231) | Error 0.0135(0.0133) Steps 440(440.00) | Grad Norm 0.3426(0.3160) | Total Time 10.00(10.00)\n",
      "Iter 3416 | Time 31.1592(31.2660) | Bit/dim 1.0997(1.1012) | Xent 0.0433(0.0436) | Loss 1.1213(1.1231) | Error 0.0132(0.0133) Steps 440(440.00) | Grad Norm 0.2034(0.3126) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 17.5073, Epoch Time 247.6983(249.5200), Bit/dim 1.0957(best: 1.0957), Xent 0.0323, Loss 1.1119, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3417 | Time 31.2262(31.2648) | Bit/dim 1.1026(1.1013) | Xent 0.0451(0.0437) | Loss 1.1252(1.1231) | Error 0.0129(0.0133) Steps 440(440.00) | Grad Norm 0.2565(0.3109) | Total Time 10.00(10.00)\n",
      "Iter 3418 | Time 30.7727(31.2500) | Bit/dim 1.1011(1.1013) | Xent 0.0456(0.0437) | Loss 1.1239(1.1231) | Error 0.0135(0.0133) Steps 440(440.00) | Grad Norm 0.2654(0.3095) | Total Time 10.00(10.00)\n",
      "Iter 3419 | Time 32.6707(31.2926) | Bit/dim 1.1023(1.1013) | Xent 0.0404(0.0436) | Loss 1.1225(1.1231) | Error 0.0125(0.0133) Steps 440(440.00) | Grad Norm 0.1960(0.3061) | Total Time 10.00(10.00)\n",
      "Iter 3420 | Time 31.0105(31.2842) | Bit/dim 1.0998(1.1013) | Xent 0.0407(0.0435) | Loss 1.1201(1.1230) | Error 0.0130(0.0133) Steps 440(440.00) | Grad Norm 0.2707(0.3051) | Total Time 10.00(10.00)\n",
      "Iter 3421 | Time 32.4447(31.3190) | Bit/dim 1.0996(1.1012) | Xent 0.0437(0.0435) | Loss 1.1214(1.1230) | Error 0.0130(0.0132) Steps 440(440.00) | Grad Norm 0.2832(0.3044) | Total Time 10.00(10.00)\n",
      "Iter 3422 | Time 31.1855(31.3150) | Bit/dim 1.0993(1.1012) | Xent 0.0484(0.0437) | Loss 1.1235(1.1230) | Error 0.0146(0.0133) Steps 440(440.00) | Grad Norm 0.1998(0.3013) | Total Time 10.00(10.00)\n",
      "Iter 3423 | Time 30.9092(31.3028) | Bit/dim 1.1029(1.1012) | Xent 0.0446(0.0437) | Loss 1.1252(1.1231) | Error 0.0132(0.0133) Steps 440(440.00) | Grad Norm 0.2326(0.2992) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 17.6603, Epoch Time 250.6642(249.5544), Bit/dim 1.0964(best: 1.0957), Xent 0.0346, Loss 1.1137, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3424 | Time 31.3139(31.3031) | Bit/dim 1.1018(1.1012) | Xent 0.0436(0.0437) | Loss 1.1236(1.1231) | Error 0.0132(0.0133) Steps 440(440.00) | Grad Norm 0.2363(0.2973) | Total Time 10.00(10.00)\n",
      "Iter 3425 | Time 31.2896(31.3027) | Bit/dim 1.1013(1.1012) | Xent 0.0506(0.0439) | Loss 1.1266(1.1232) | Error 0.0145(0.0133) Steps 440(440.00) | Grad Norm 0.4183(0.3010) | Total Time 10.00(10.00)\n",
      "Iter 3426 | Time 32.6578(31.3434) | Bit/dim 1.1037(1.1013) | Xent 0.0397(0.0438) | Loss 1.1235(1.1232) | Error 0.0114(0.0133) Steps 440(440.00) | Grad Norm 0.1972(0.2978) | Total Time 10.00(10.00)\n",
      "Iter 3427 | Time 32.4065(31.3753) | Bit/dim 1.0964(1.1012) | Xent 0.0419(0.0437) | Loss 1.1173(1.1230) | Error 0.0131(0.0133) Steps 440(440.00) | Grad Norm 0.2396(0.2961) | Total Time 10.00(10.00)\n",
      "Iter 3428 | Time 31.6265(31.3828) | Bit/dim 1.1005(1.1011) | Xent 0.0388(0.0436) | Loss 1.1199(1.1229) | Error 0.0121(0.0132) Steps 440(440.00) | Grad Norm 0.3274(0.2970) | Total Time 10.00(10.00)\n",
      "Iter 3429 | Time 31.3749(31.3826) | Bit/dim 1.1031(1.1012) | Xent 0.0479(0.0437) | Loss 1.1270(1.1231) | Error 0.0140(0.0132) Steps 440(440.00) | Grad Norm 0.2431(0.2954) | Total Time 10.00(10.00)\n",
      "Iter 3430 | Time 31.3931(31.3829) | Bit/dim 1.0984(1.1011) | Xent 0.0444(0.0437) | Loss 1.1206(1.1230) | Error 0.0134(0.0133) Steps 440(440.00) | Grad Norm 0.3375(0.2967) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 17.8594, Epoch Time 252.3487(249.6382), Bit/dim 1.0961(best: 1.0957), Xent 0.0331, Loss 1.1127, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3431 | Time 31.5378(31.3875) | Bit/dim 1.1004(1.1011) | Xent 0.0465(0.0438) | Loss 1.1236(1.1230) | Error 0.0148(0.0133) Steps 440(440.00) | Grad Norm 0.2883(0.2964) | Total Time 10.00(10.00)\n",
      "Iter 3432 | Time 31.4586(31.3897) | Bit/dim 1.0999(1.1011) | Xent 0.0442(0.0438) | Loss 1.1220(1.1230) | Error 0.0128(0.0133) Steps 440(440.00) | Grad Norm 0.2207(0.2942) | Total Time 10.00(10.00)\n",
      "Iter 3433 | Time 31.7397(31.4002) | Bit/dim 1.1039(1.1011) | Xent 0.0383(0.0437) | Loss 1.1231(1.1230) | Error 0.0126(0.0133) Steps 440(440.00) | Grad Norm 0.5017(0.3004) | Total Time 10.00(10.00)\n",
      "Iter 3434 | Time 31.5430(31.4044) | Bit/dim 1.1022(1.1012) | Xent 0.0468(0.0438) | Loss 1.1256(1.1231) | Error 0.0136(0.0133) Steps 440(440.00) | Grad Norm 0.3169(0.3009) | Total Time 10.00(10.00)\n",
      "Iter 3435 | Time 31.8360(31.4174) | Bit/dim 1.1023(1.1012) | Xent 0.0394(0.0436) | Loss 1.1221(1.1230) | Error 0.0119(0.0132) Steps 440(440.00) | Grad Norm 0.2641(0.2998) | Total Time 10.00(10.00)\n",
      "Iter 3436 | Time 31.3443(31.4152) | Bit/dim 1.0962(1.1011) | Xent 0.0466(0.0437) | Loss 1.1195(1.1229) | Error 0.0150(0.0133) Steps 440(440.00) | Grad Norm 0.4282(0.3036) | Total Time 10.00(10.00)\n",
      "Iter 3437 | Time 31.0717(31.4049) | Bit/dim 1.1028(1.1011) | Xent 0.0437(0.0437) | Loss 1.1246(1.1230) | Error 0.0139(0.0133) Steps 440(440.00) | Grad Norm 0.2850(0.3031) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 17.6019, Epoch Time 250.8953(249.6759), Bit/dim 1.0953(best: 1.0957), Xent 0.0332, Loss 1.1119, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3438 | Time 30.3604(31.3736) | Bit/dim 1.1013(1.1011) | Xent 0.0414(0.0436) | Loss 1.1220(1.1229) | Error 0.0128(0.0133) Steps 440(440.00) | Grad Norm 0.2437(0.3013) | Total Time 10.00(10.00)\n",
      "Iter 3439 | Time 31.2369(31.3695) | Bit/dim 1.1023(1.1012) | Xent 0.0432(0.0436) | Loss 1.1239(1.1230) | Error 0.0140(0.0133) Steps 440(440.00) | Grad Norm 0.4393(0.3054) | Total Time 10.00(10.00)\n",
      "Iter 3440 | Time 30.9905(31.3581) | Bit/dim 1.0983(1.1011) | Xent 0.0460(0.0437) | Loss 1.1214(1.1229) | Error 0.0139(0.0133) Steps 440(440.00) | Grad Norm 0.2940(0.3051) | Total Time 10.00(10.00)\n",
      "Iter 3441 | Time 31.1592(31.3521) | Bit/dim 1.0994(1.1010) | Xent 0.0476(0.0438) | Loss 1.1232(1.1229) | Error 0.0160(0.0134) Steps 440(440.00) | Grad Norm 0.3926(0.3077) | Total Time 10.00(10.00)\n",
      "Iter 3442 | Time 30.8285(31.3364) | Bit/dim 1.1003(1.1010) | Xent 0.0351(0.0436) | Loss 1.1178(1.1228) | Error 0.0115(0.0133) Steps 440(440.00) | Grad Norm 0.7248(0.3202) | Total Time 10.00(10.00)\n",
      "Iter 3443 | Time 31.3654(31.3373) | Bit/dim 1.1050(1.1011) | Xent 0.0407(0.0435) | Loss 1.1253(1.1229) | Error 0.0145(0.0134) Steps 440(440.00) | Grad Norm 0.1934(0.3164) | Total Time 10.00(10.00)\n",
      "Iter 3444 | Time 30.8715(31.3233) | Bit/dim 1.1031(1.1012) | Xent 0.0437(0.0435) | Loss 1.1249(1.1229) | Error 0.0136(0.0134) Steps 440(440.00) | Grad Norm 0.7140(0.3283) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 17.6847, Epoch Time 247.3996(249.6076), Bit/dim 1.0953(best: 1.0953), Xent 0.0323, Loss 1.1115, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3445 | Time 31.8688(31.3397) | Bit/dim 1.0981(1.1011) | Xent 0.0393(0.0434) | Loss 1.1178(1.1228) | Error 0.0119(0.0133) Steps 440(440.00) | Grad Norm 0.6458(0.3379) | Total Time 10.00(10.00)\n",
      "Iter 3446 | Time 31.0772(31.3318) | Bit/dim 1.1052(1.1012) | Xent 0.0425(0.0433) | Loss 1.1265(1.1229) | Error 0.0126(0.0133) Steps 440(440.00) | Grad Norm 0.1926(0.3335) | Total Time 10.00(10.00)\n",
      "Iter 3447 | Time 31.6292(31.3407) | Bit/dim 1.0988(1.1011) | Xent 0.0395(0.0432) | Loss 1.1186(1.1227) | Error 0.0135(0.0133) Steps 440(440.00) | Grad Norm 0.4957(0.3384) | Total Time 10.00(10.00)\n",
      "Iter 3448 | Time 31.2748(31.3387) | Bit/dim 1.1014(1.1011) | Xent 0.0432(0.0432) | Loss 1.1230(1.1228) | Error 0.0130(0.0133) Steps 440(440.00) | Grad Norm 0.4715(0.3424) | Total Time 10.00(10.00)\n",
      "Iter 3449 | Time 31.3803(31.3400) | Bit/dim 1.1029(1.1012) | Xent 0.0458(0.0433) | Loss 1.1258(1.1228) | Error 0.0144(0.0133) Steps 440(440.00) | Grad Norm 0.3125(0.3415) | Total Time 10.00(10.00)\n",
      "Iter 3450 | Time 31.6937(31.3506) | Bit/dim 1.0991(1.1011) | Xent 0.0496(0.0435) | Loss 1.1239(1.1229) | Error 0.0149(0.0134) Steps 440(440.00) | Grad Norm 0.4254(0.3440) | Total Time 10.00(10.00)\n",
      "Iter 3451 | Time 31.4025(31.3522) | Bit/dim 1.1002(1.1011) | Xent 0.0427(0.0435) | Loss 1.1215(1.1228) | Error 0.0126(0.0134) Steps 440(440.00) | Grad Norm 0.4593(0.3474) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 17.6016, Epoch Time 250.8373(249.6445), Bit/dim 1.0964(best: 1.0953), Xent 0.0344, Loss 1.1136, Error 0.0095(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3452 | Time 30.9737(31.3408) | Bit/dim 1.0986(1.1010) | Xent 0.0408(0.0434) | Loss 1.1190(1.1227) | Error 0.0131(0.0134) Steps 440(440.00) | Grad Norm 0.2386(0.3442) | Total Time 10.00(10.00)\n",
      "Iter 3453 | Time 31.3925(31.3424) | Bit/dim 1.0998(1.1010) | Xent 0.0442(0.0434) | Loss 1.1219(1.1227) | Error 0.0145(0.0134) Steps 440(440.00) | Grad Norm 0.5540(0.3505) | Total Time 10.00(10.00)\n",
      "Iter 3454 | Time 31.3462(31.3425) | Bit/dim 1.1000(1.1010) | Xent 0.0412(0.0433) | Loss 1.1206(1.1226) | Error 0.0135(0.0134) Steps 440(440.00) | Grad Norm 0.2214(0.3466) | Total Time 10.00(10.00)\n",
      "Iter 3455 | Time 31.2697(31.3403) | Bit/dim 1.1016(1.1010) | Xent 0.0426(0.0433) | Loss 1.1229(1.1226) | Error 0.0126(0.0134) Steps 440(440.00) | Grad Norm 0.5159(0.3517) | Total Time 10.00(10.00)\n",
      "Iter 3456 | Time 31.2977(31.3390) | Bit/dim 1.0998(1.1009) | Xent 0.0434(0.0433) | Loss 1.1215(1.1226) | Error 0.0136(0.0134) Steps 440(440.00) | Grad Norm 0.1808(0.3466) | Total Time 10.00(10.00)\n",
      "Iter 3457 | Time 31.1204(31.3325) | Bit/dim 1.1022(1.1010) | Xent 0.0456(0.0434) | Loss 1.1251(1.1227) | Error 0.0131(0.0134) Steps 440(440.00) | Grad Norm 0.3496(0.3466) | Total Time 10.00(10.00)\n",
      "Iter 3458 | Time 31.8873(31.3491) | Bit/dim 1.1040(1.1011) | Xent 0.0494(0.0436) | Loss 1.1286(1.1229) | Error 0.0159(0.0135) Steps 440(440.00) | Grad Norm 0.2597(0.3440) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 18.2141, Epoch Time 250.1607(249.6600), Bit/dim 1.0957(best: 1.0953), Xent 0.0316, Loss 1.1114, Error 0.0094(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3459 | Time 31.0007(31.3386) | Bit/dim 1.1039(1.1012) | Xent 0.0448(0.0436) | Loss 1.1263(1.1230) | Error 0.0150(0.0135) Steps 440(440.00) | Grad Norm 0.2476(0.3411) | Total Time 10.00(10.00)\n",
      "Iter 3460 | Time 31.2230(31.3352) | Bit/dim 1.0988(1.1011) | Xent 0.0376(0.0434) | Loss 1.1176(1.1228) | Error 0.0105(0.0134) Steps 440(440.00) | Grad Norm 0.5106(0.3462) | Total Time 10.00(10.00)\n",
      "Iter 3461 | Time 30.9087(31.3224) | Bit/dim 1.1014(1.1011) | Xent 0.0454(0.0435) | Loss 1.1242(1.1228) | Error 0.0149(0.0135) Steps 440(440.00) | Grad Norm 0.2565(0.3435) | Total Time 10.00(10.00)\n",
      "Iter 3462 | Time 31.4917(31.3275) | Bit/dim 1.1032(1.1012) | Xent 0.0432(0.0435) | Loss 1.1248(1.1229) | Error 0.0121(0.0134) Steps 440(440.00) | Grad Norm 0.4816(0.3477) | Total Time 10.00(10.00)\n",
      "Iter 3463 | Time 31.2097(31.3239) | Bit/dim 1.0963(1.1010) | Xent 0.0485(0.0436) | Loss 1.1205(1.1228) | Error 0.0135(0.0134) Steps 440(440.00) | Grad Norm 0.3654(0.3482) | Total Time 10.00(10.00)\n",
      "Iter 3464 | Time 30.5958(31.3021) | Bit/dim 1.1047(1.1011) | Xent 0.0419(0.0436) | Loss 1.1256(1.1229) | Error 0.0152(0.0135) Steps 440(440.00) | Grad Norm 0.3098(0.3471) | Total Time 10.00(10.00)\n",
      "Iter 3465 | Time 31.5585(31.3098) | Bit/dim 1.0984(1.1010) | Xent 0.0448(0.0436) | Loss 1.1208(1.1229) | Error 0.0125(0.0134) Steps 440(440.00) | Grad Norm 0.2154(0.3431) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 17.4754, Epoch Time 248.3171(249.6197), Bit/dim 1.0955(best: 1.0953), Xent 0.0335, Loss 1.1122, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3466 | Time 31.3732(31.3117) | Bit/dim 1.1055(1.1012) | Xent 0.0480(0.0437) | Loss 1.1295(1.1230) | Error 0.0135(0.0134) Steps 440(440.00) | Grad Norm 0.3037(0.3419) | Total Time 10.00(10.00)\n",
      "Iter 3467 | Time 31.0895(31.3050) | Bit/dim 1.1009(1.1012) | Xent 0.0426(0.0437) | Loss 1.1222(1.1230) | Error 0.0128(0.0134) Steps 440(440.00) | Grad Norm 0.2589(0.3394) | Total Time 10.00(10.00)\n",
      "Iter 3468 | Time 31.2311(31.3028) | Bit/dim 1.1013(1.1012) | Xent 0.0488(0.0439) | Loss 1.1257(1.1231) | Error 0.0150(0.0135) Steps 440(440.00) | Grad Norm 0.3644(0.3402) | Total Time 10.00(10.00)\n",
      "Iter 3469 | Time 31.1328(31.2977) | Bit/dim 1.0980(1.1011) | Xent 0.0410(0.0438) | Loss 1.1185(1.1230) | Error 0.0129(0.0135) Steps 440(440.00) | Grad Norm 0.1869(0.3356) | Total Time 10.00(10.00)\n",
      "Iter 3470 | Time 31.2014(31.2948) | Bit/dim 1.1021(1.1011) | Xent 0.0444(0.0438) | Loss 1.1242(1.1230) | Error 0.0145(0.0135) Steps 440(440.00) | Grad Norm 0.1978(0.3315) | Total Time 10.00(10.00)\n",
      "Iter 3471 | Time 31.1815(31.2914) | Bit/dim 1.0986(1.1010) | Xent 0.0446(0.0438) | Loss 1.1209(1.1229) | Error 0.0140(0.0135) Steps 440(440.00) | Grad Norm 0.3076(0.3307) | Total Time 10.00(10.00)\n",
      "Iter 3472 | Time 31.8003(31.3067) | Bit/dim 1.0989(1.1010) | Xent 0.0460(0.0439) | Loss 1.1219(1.1229) | Error 0.0136(0.0135) Steps 440(440.00) | Grad Norm 0.2037(0.3269) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 17.6843, Epoch Time 249.5035(249.6162), Bit/dim 1.0960(best: 1.0953), Xent 0.0309, Loss 1.1115, Error 0.0092(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3473 | Time 31.0449(31.2988) | Bit/dim 1.0998(1.1009) | Xent 0.0467(0.0440) | Loss 1.1231(1.1229) | Error 0.0142(0.0135) Steps 440(440.00) | Grad Norm 0.2446(0.3245) | Total Time 10.00(10.00)\n",
      "Iter 3474 | Time 30.8625(31.2857) | Bit/dim 1.1026(1.1010) | Xent 0.0446(0.0440) | Loss 1.1249(1.1230) | Error 0.0135(0.0135) Steps 440(440.00) | Grad Norm 0.2534(0.3223) | Total Time 10.00(10.00)\n",
      "Iter 3475 | Time 31.8457(31.3025) | Bit/dim 1.0993(1.1009) | Xent 0.0487(0.0441) | Loss 1.1236(1.1230) | Error 0.0150(0.0136) Steps 440(440.00) | Grad Norm 0.2681(0.3207) | Total Time 10.00(10.00)\n",
      "Iter 3476 | Time 32.0237(31.3242) | Bit/dim 1.1027(1.1010) | Xent 0.0423(0.0441) | Loss 1.1239(1.1230) | Error 0.0128(0.0135) Steps 440(440.00) | Grad Norm 0.2936(0.3199) | Total Time 10.00(10.00)\n",
      "Iter 3477 | Time 31.4584(31.3282) | Bit/dim 1.1007(1.1010) | Xent 0.0419(0.0440) | Loss 1.1216(1.1230) | Error 0.0125(0.0135) Steps 440(440.00) | Grad Norm 0.3813(0.3217) | Total Time 10.00(10.00)\n",
      "Iter 3478 | Time 31.4420(31.3316) | Bit/dim 1.1024(1.1010) | Xent 0.0410(0.0439) | Loss 1.1229(1.1230) | Error 0.0140(0.0135) Steps 440(440.00) | Grad Norm 0.2818(0.3205) | Total Time 10.00(10.00)\n",
      "Iter 3479 | Time 31.9614(31.3505) | Bit/dim 1.0982(1.1009) | Xent 0.0465(0.0440) | Loss 1.1215(1.1229) | Error 0.0145(0.0136) Steps 440(440.00) | Grad Norm 0.3992(0.3229) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 17.7140, Epoch Time 251.2959(249.6666), Bit/dim 1.0958(best: 1.0953), Xent 0.0321, Loss 1.1118, Error 0.0111(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3480 | Time 31.3150(31.3494) | Bit/dim 1.1029(1.1010) | Xent 0.0441(0.0440) | Loss 1.1250(1.1230) | Error 0.0139(0.0136) Steps 440(440.00) | Grad Norm 0.2883(0.3218) | Total Time 10.00(10.00)\n",
      "Iter 3481 | Time 32.6538(31.3886) | Bit/dim 1.1012(1.1010) | Xent 0.0486(0.0441) | Loss 1.1255(1.1231) | Error 0.0146(0.0136) Steps 440(440.00) | Grad Norm 0.4545(0.3258) | Total Time 10.00(10.00)\n",
      "Iter 3482 | Time 31.1235(31.3806) | Bit/dim 1.1009(1.1010) | Xent 0.0426(0.0441) | Loss 1.1222(1.1230) | Error 0.0146(0.0136) Steps 440(440.00) | Grad Norm 0.3280(0.3259) | Total Time 10.00(10.00)\n",
      "Iter 3483 | Time 32.0828(31.4017) | Bit/dim 1.0985(1.1009) | Xent 0.0430(0.0441) | Loss 1.1200(1.1230) | Error 0.0135(0.0136) Steps 440(440.00) | Grad Norm 0.6361(0.3352) | Total Time 10.00(10.00)\n",
      "Iter 3484 | Time 32.2873(31.4282) | Bit/dim 1.1003(1.1009) | Xent 0.0438(0.0441) | Loss 1.1222(1.1229) | Error 0.0128(0.0136) Steps 440(440.00) | Grad Norm 0.4268(0.3379) | Total Time 10.00(10.00)\n",
      "Iter 3485 | Time 31.1257(31.4192) | Bit/dim 1.1032(1.1010) | Xent 0.0439(0.0440) | Loss 1.1252(1.1230) | Error 0.0142(0.0136) Steps 440(440.00) | Grad Norm 0.2079(0.3340) | Total Time 10.00(10.00)\n",
      "Iter 3486 | Time 30.8450(31.4019) | Bit/dim 1.1006(1.1010) | Xent 0.0457(0.0441) | Loss 1.1235(1.1230) | Error 0.0132(0.0136) Steps 440(440.00) | Grad Norm 0.7944(0.3479) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 17.6816, Epoch Time 251.8338(249.7316), Bit/dim 1.0951(best: 1.0953), Xent 0.0340, Loss 1.1121, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3487 | Time 31.0231(31.3906) | Bit/dim 1.1010(1.1010) | Xent 0.0414(0.0440) | Loss 1.1217(1.1230) | Error 0.0130(0.0136) Steps 440(440.00) | Grad Norm 0.4336(0.3504) | Total Time 10.00(10.00)\n",
      "Iter 3488 | Time 31.2295(31.3857) | Bit/dim 1.0984(1.1009) | Xent 0.0426(0.0440) | Loss 1.1197(1.1229) | Error 0.0138(0.0136) Steps 440(440.00) | Grad Norm 0.2122(0.3463) | Total Time 10.00(10.00)\n",
      "Iter 3489 | Time 31.2146(31.3806) | Bit/dim 1.0993(1.1008) | Xent 0.0501(0.0442) | Loss 1.1244(1.1229) | Error 0.0140(0.0136) Steps 440(440.00) | Grad Norm 0.2180(0.3424) | Total Time 10.00(10.00)\n",
      "Iter 3490 | Time 30.7370(31.3613) | Bit/dim 1.1057(1.1010) | Xent 0.0419(0.0441) | Loss 1.1266(1.1230) | Error 0.0125(0.0136) Steps 440(440.00) | Grad Norm 0.2830(0.3406) | Total Time 10.00(10.00)\n",
      "Iter 3491 | Time 31.9499(31.3790) | Bit/dim 1.1021(1.1010) | Xent 0.0430(0.0441) | Loss 1.1236(1.1230) | Error 0.0145(0.0136) Steps 440(440.00) | Grad Norm 0.3216(0.3401) | Total Time 10.00(10.00)\n",
      "Iter 3492 | Time 31.1431(31.3719) | Bit/dim 1.0981(1.1009) | Xent 0.0430(0.0440) | Loss 1.1195(1.1229) | Error 0.0128(0.0136) Steps 440(440.00) | Grad Norm 0.2757(0.3381) | Total Time 10.00(10.00)\n",
      "Iter 3493 | Time 31.6369(31.3798) | Bit/dim 1.1032(1.1010) | Xent 0.0357(0.0438) | Loss 1.1210(1.1229) | Error 0.0121(0.0135) Steps 440(440.00) | Grad Norm 0.2486(0.3355) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 17.7343, Epoch Time 249.5840(249.7272), Bit/dim 1.0948(best: 1.0951), Xent 0.0341, Loss 1.1119, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3494 | Time 31.1728(31.3736) | Bit/dim 1.1017(1.1010) | Xent 0.0395(0.0436) | Loss 1.1214(1.1228) | Error 0.0132(0.0135) Steps 440(440.00) | Grad Norm 0.2325(0.3324) | Total Time 10.00(10.00)\n",
      "Iter 3495 | Time 31.7544(31.3850) | Bit/dim 1.0996(1.1010) | Xent 0.0423(0.0436) | Loss 1.1207(1.1228) | Error 0.0136(0.0135) Steps 440(440.00) | Grad Norm 0.4746(0.3366) | Total Time 10.00(10.00)\n",
      "Iter 3496 | Time 32.3452(31.4139) | Bit/dim 1.1014(1.1010) | Xent 0.0447(0.0436) | Loss 1.1238(1.1228) | Error 0.0138(0.0135) Steps 440(440.00) | Grad Norm 0.2039(0.3327) | Total Time 10.00(10.00)\n",
      "Iter 3497 | Time 31.2293(31.4083) | Bit/dim 1.1001(1.1010) | Xent 0.0425(0.0436) | Loss 1.1214(1.1228) | Error 0.0144(0.0136) Steps 440(440.00) | Grad Norm 0.5930(0.3405) | Total Time 10.00(10.00)\n",
      "Iter 3498 | Time 31.8308(31.4210) | Bit/dim 1.0986(1.1009) | Xent 0.0442(0.0436) | Loss 1.1207(1.1227) | Error 0.0131(0.0135) Steps 440(440.00) | Grad Norm 0.5661(0.3472) | Total Time 10.00(10.00)\n",
      "Iter 3499 | Time 31.5830(31.4258) | Bit/dim 1.0999(1.1009) | Xent 0.0401(0.0435) | Loss 1.1200(1.1226) | Error 0.0132(0.0135) Steps 440(440.00) | Grad Norm 0.3664(0.3478) | Total Time 10.00(10.00)\n",
      "Iter 3500 | Time 31.1401(31.4173) | Bit/dim 1.1041(1.1010) | Xent 0.0445(0.0435) | Loss 1.1263(1.1227) | Error 0.0160(0.0136) Steps 440(440.00) | Grad Norm 0.4924(0.3521) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 17.7722, Epoch Time 251.3721(249.7765), Bit/dim 1.0952(best: 1.0948), Xent 0.0366, Loss 1.1135, Error 0.0110(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3501 | Time 30.9621(31.4036) | Bit/dim 1.1018(1.1010) | Xent 0.0508(0.0438) | Loss 1.1272(1.1229) | Error 0.0144(0.0136) Steps 440(440.00) | Grad Norm 0.5403(0.3578) | Total Time 10.00(10.00)\n",
      "Iter 3502 | Time 33.0239(31.4522) | Bit/dim 1.1041(1.1011) | Xent 0.0443(0.0438) | Loss 1.1263(1.1230) | Error 0.0145(0.0137) Steps 440(440.00) | Grad Norm 0.4209(0.3597) | Total Time 10.00(10.00)\n",
      "Iter 3503 | Time 31.3189(31.4482) | Bit/dim 1.1022(1.1011) | Xent 0.0399(0.0437) | Loss 1.1221(1.1229) | Error 0.0135(0.0137) Steps 440(440.00) | Grad Norm 0.5329(0.3649) | Total Time 10.00(10.00)\n",
      "Iter 3504 | Time 32.0667(31.4668) | Bit/dim 1.1044(1.1012) | Xent 0.0420(0.0436) | Loss 1.1254(1.1230) | Error 0.0144(0.0137) Steps 440(440.00) | Grad Norm 0.2845(0.3625) | Total Time 10.00(10.00)\n",
      "Iter 3505 | Time 31.0774(31.4551) | Bit/dim 1.1020(1.1012) | Xent 0.0426(0.0436) | Loss 1.1233(1.1230) | Error 0.0135(0.0137) Steps 440(440.00) | Grad Norm 0.2376(0.3587) | Total Time 10.00(10.00)\n",
      "Iter 3506 | Time 31.9929(31.4712) | Bit/dim 1.1001(1.1012) | Xent 0.0420(0.0435) | Loss 1.1212(1.1230) | Error 0.0129(0.0136) Steps 440(440.00) | Grad Norm 0.2335(0.3550) | Total Time 10.00(10.00)\n",
      "Iter 3507 | Time 32.0485(31.4886) | Bit/dim 1.0962(1.1011) | Xent 0.0451(0.0436) | Loss 1.1187(1.1228) | Error 0.0126(0.0136) Steps 440(440.00) | Grad Norm 0.3633(0.3552) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0501 | Time 17.6522, Epoch Time 252.8987(249.8702), Bit/dim 1.0957(best: 1.0948), Xent 0.0338, Loss 1.1126, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3508 | Time 31.1708(31.4790) | Bit/dim 1.1042(1.1011) | Xent 0.0382(0.0434) | Loss 1.1233(1.1229) | Error 0.0128(0.0136) Steps 440(440.00) | Grad Norm 0.2156(0.3510) | Total Time 10.00(10.00)\n",
      "Iter 3509 | Time 32.0905(31.4974) | Bit/dim 1.1015(1.1012) | Xent 0.0441(0.0434) | Loss 1.1235(1.1229) | Error 0.0135(0.0136) Steps 440(440.00) | Grad Norm 0.3392(0.3507) | Total Time 10.00(10.00)\n",
      "Iter 3510 | Time 30.4939(31.4673) | Bit/dim 1.0992(1.1011) | Xent 0.0389(0.0433) | Loss 1.1187(1.1227) | Error 0.0122(0.0135) Steps 440(440.00) | Grad Norm 0.3940(0.3520) | Total Time 10.00(10.00)\n",
      "Iter 3511 | Time 32.2070(31.4895) | Bit/dim 1.0972(1.1010) | Xent 0.0503(0.0435) | Loss 1.1224(1.1227) | Error 0.0154(0.0136) Steps 440(440.00) | Grad Norm 0.3863(0.3530) | Total Time 10.00(10.00)\n",
      "Iter 3512 | Time 31.9198(31.5024) | Bit/dim 1.1019(1.1010) | Xent 0.0527(0.0438) | Loss 1.1282(1.1229) | Error 0.0155(0.0137) Steps 440(440.00) | Grad Norm 0.4086(0.3547) | Total Time 10.00(10.00)\n",
      "Iter 3513 | Time 31.0200(31.4879) | Bit/dim 1.0955(1.1008) | Xent 0.0468(0.0439) | Loss 1.1189(1.1228) | Error 0.0146(0.0137) Steps 440(440.00) | Grad Norm 0.2761(0.3523) | Total Time 10.00(10.00)\n",
      "Iter 3514 | Time 31.6154(31.4917) | Bit/dim 1.1006(1.1008) | Xent 0.0458(0.0439) | Loss 1.1235(1.1228) | Error 0.0161(0.0138) Steps 440(440.00) | Grad Norm 0.2742(0.3500) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0502 | Time 17.6914, Epoch Time 250.6726(249.8943), Bit/dim 1.0950(best: 1.0948), Xent 0.0328, Loss 1.1114, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3515 | Time 31.0019(31.4770) | Bit/dim 1.1027(1.1009) | Xent 0.0461(0.0440) | Loss 1.1257(1.1229) | Error 0.0138(0.0138) Steps 440(440.00) | Grad Norm 0.5056(0.3546) | Total Time 10.00(10.00)\n",
      "Iter 3516 | Time 31.5069(31.4779) | Bit/dim 1.0997(1.1009) | Xent 0.0393(0.0439) | Loss 1.1193(1.1228) | Error 0.0129(0.0137) Steps 440(440.00) | Grad Norm 0.4540(0.3576) | Total Time 10.00(10.00)\n",
      "Iter 3517 | Time 30.7418(31.4558) | Bit/dim 1.1036(1.1009) | Xent 0.0376(0.0437) | Loss 1.1224(1.1228) | Error 0.0135(0.0137) Steps 440(440.00) | Grad Norm 0.3315(0.3568) | Total Time 10.00(10.00)\n",
      "Iter 3518 | Time 30.7733(31.4354) | Bit/dim 1.1049(1.1011) | Xent 0.0439(0.0437) | Loss 1.1269(1.1229) | Error 0.0126(0.0137) Steps 440(440.00) | Grad Norm 0.5580(0.3629) | Total Time 10.00(10.00)\n",
      "Iter 3519 | Time 31.6102(31.4406) | Bit/dim 1.1018(1.1011) | Xent 0.0428(0.0437) | Loss 1.1232(1.1229) | Error 0.0138(0.0137) Steps 440(440.00) | Grad Norm 0.2549(0.3596) | Total Time 10.00(10.00)\n",
      "Iter 3520 | Time 31.2694(31.4355) | Bit/dim 1.0967(1.1009) | Xent 0.0514(0.0439) | Loss 1.1224(1.1229) | Error 0.0145(0.0137) Steps 440(440.00) | Grad Norm 0.3397(0.3590) | Total Time 10.00(10.00)\n",
      "Iter 3521 | Time 32.5428(31.4687) | Bit/dim 1.1007(1.1009) | Xent 0.0478(0.0440) | Loss 1.1246(1.1229) | Error 0.0158(0.0138) Steps 440(440.00) | Grad Norm 0.3531(0.3589) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0503 | Time 17.7226, Epoch Time 249.9786(249.8968), Bit/dim 1.0950(best: 1.0948), Xent 0.0345, Loss 1.1123, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3522 | Time 32.9642(31.5135) | Bit/dim 1.1008(1.1009) | Xent 0.0447(0.0440) | Loss 1.1232(1.1229) | Error 0.0140(0.0138) Steps 440(440.00) | Grad Norm 0.2852(0.3566) | Total Time 10.00(10.00)\n",
      "Iter 3523 | Time 31.3199(31.5077) | Bit/dim 1.0984(1.1009) | Xent 0.0444(0.0440) | Loss 1.1206(1.1229) | Error 0.0122(0.0137) Steps 440(440.00) | Grad Norm 0.3149(0.3554) | Total Time 10.00(10.00)\n",
      "Iter 3524 | Time 31.2318(31.4995) | Bit/dim 1.1057(1.1010) | Xent 0.0503(0.0442) | Loss 1.1309(1.1231) | Error 0.0162(0.0138) Steps 440(440.00) | Grad Norm 0.2584(0.3525) | Total Time 10.00(10.00)\n",
      "Iter 3525 | Time 31.0602(31.4863) | Bit/dim 1.1023(1.1010) | Xent 0.0427(0.0442) | Loss 1.1237(1.1231) | Error 0.0126(0.0138) Steps 440(440.00) | Grad Norm 0.2862(0.3505) | Total Time 10.00(10.00)\n",
      "Iter 3526 | Time 31.0701(31.4738) | Bit/dim 1.0988(1.1010) | Xent 0.0376(0.0440) | Loss 1.1176(1.1230) | Error 0.0126(0.0137) Steps 440(440.00) | Grad Norm 0.4401(0.3532) | Total Time 10.00(10.00)\n",
      "Iter 3527 | Time 31.2906(31.4683) | Bit/dim 1.1006(1.1010) | Xent 0.0416(0.0439) | Loss 1.1214(1.1229) | Error 0.0128(0.0137) Steps 440(440.00) | Grad Norm 0.3533(0.3532) | Total Time 10.00(10.00)\n",
      "Iter 3528 | Time 30.8205(31.4489) | Bit/dim 1.0971(1.1008) | Xent 0.0398(0.0438) | Loss 1.1170(1.1227) | Error 0.0136(0.0137) Steps 440(440.00) | Grad Norm 0.2746(0.3508) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0504 | Time 17.5396, Epoch Time 249.9528(249.8985), Bit/dim 1.0952(best: 1.0948), Xent 0.0333, Loss 1.1118, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3529 | Time 31.3352(31.4455) | Bit/dim 1.1012(1.1009) | Xent 0.0426(0.0438) | Loss 1.1225(1.1227) | Error 0.0122(0.0137) Steps 440(440.00) | Grad Norm 0.3280(0.3501) | Total Time 10.00(10.00)\n",
      "Iter 3530 | Time 32.0403(31.4633) | Bit/dim 1.1011(1.1009) | Xent 0.0407(0.0437) | Loss 1.1215(1.1227) | Error 0.0130(0.0136) Steps 440(440.00) | Grad Norm 0.2203(0.3462) | Total Time 10.00(10.00)\n",
      "Iter 3531 | Time 31.8488(31.4749) | Bit/dim 1.1004(1.1009) | Xent 0.0328(0.0433) | Loss 1.1168(1.1225) | Error 0.0102(0.0135) Steps 440(440.00) | Grad Norm 0.6773(0.3562) | Total Time 10.00(10.00)\n",
      "Iter 3532 | Time 31.1314(31.4646) | Bit/dim 1.1033(1.1009) | Xent 0.0418(0.0433) | Loss 1.1242(1.1226) | Error 0.0135(0.0135) Steps 440(440.00) | Grad Norm 0.2896(0.3542) | Total Time 10.00(10.00)\n",
      "Iter 3533 | Time 32.0567(31.4823) | Bit/dim 1.0991(1.1009) | Xent 0.0470(0.0434) | Loss 1.1226(1.1226) | Error 0.0149(0.0136) Steps 440(440.00) | Grad Norm 0.6056(0.3617) | Total Time 10.00(10.00)\n",
      "Iter 3534 | Time 32.1457(31.5022) | Bit/dim 1.1003(1.1009) | Xent 0.0394(0.0433) | Loss 1.1200(1.1225) | Error 0.0125(0.0136) Steps 440(440.00) | Grad Norm 0.4136(0.3633) | Total Time 10.00(10.00)\n",
      "Iter 3535 | Time 32.3096(31.5264) | Bit/dim 1.1007(1.1008) | Xent 0.0347(0.0430) | Loss 1.1180(1.1224) | Error 0.0110(0.0135) Steps 440(440.00) | Grad Norm 0.3943(0.3642) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0505 | Time 17.8617, Epoch Time 253.4791(250.0059), Bit/dim 1.0958(best: 1.0948), Xent 0.0345, Loss 1.1130, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3536 | Time 30.8281(31.5055) | Bit/dim 1.1026(1.1009) | Xent 0.0447(0.0431) | Loss 1.1249(1.1224) | Error 0.0138(0.0135) Steps 440(440.00) | Grad Norm 0.2551(0.3609) | Total Time 10.00(10.00)\n",
      "Iter 3537 | Time 30.8801(31.4867) | Bit/dim 1.0988(1.1008) | Xent 0.0401(0.0430) | Loss 1.1188(1.1223) | Error 0.0131(0.0135) Steps 440(440.00) | Grad Norm 0.1942(0.3559) | Total Time 10.00(10.00)\n",
      "Iter 3538 | Time 31.2567(31.4798) | Bit/dim 1.1020(1.1009) | Xent 0.0414(0.0429) | Loss 1.1227(1.1223) | Error 0.0119(0.0134) Steps 440(440.00) | Grad Norm 0.2292(0.3521) | Total Time 10.00(10.00)\n",
      "Iter 3539 | Time 30.9132(31.4628) | Bit/dim 1.1033(1.1009) | Xent 0.0445(0.0430) | Loss 1.1256(1.1224) | Error 0.0139(0.0134) Steps 440(440.00) | Grad Norm 0.2560(0.3492) | Total Time 10.00(10.00)\n",
      "Iter 3540 | Time 30.9075(31.4462) | Bit/dim 1.1002(1.1009) | Xent 0.0377(0.0428) | Loss 1.1190(1.1223) | Error 0.0132(0.0134) Steps 440(440.00) | Grad Norm 0.3154(0.3482) | Total Time 10.00(10.00)\n",
      "Iter 3541 | Time 31.3679(31.4438) | Bit/dim 1.0952(1.1007) | Xent 0.0386(0.0427) | Loss 1.1145(1.1221) | Error 0.0122(0.0134) Steps 440(440.00) | Grad Norm 0.3200(0.3474) | Total Time 10.00(10.00)\n",
      "Iter 3542 | Time 32.2051(31.4667) | Bit/dim 1.1014(1.1008) | Xent 0.0451(0.0428) | Loss 1.1239(1.1222) | Error 0.0136(0.0134) Steps 440(440.00) | Grad Norm 0.3462(0.3473) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0506 | Time 17.6339, Epoch Time 248.6738(249.9659), Bit/dim 1.0955(best: 1.0948), Xent 0.0324, Loss 1.1117, Error 0.0098(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3543 | Time 32.4012(31.4947) | Bit/dim 1.0965(1.1006) | Xent 0.0426(0.0428) | Loss 1.1178(1.1220) | Error 0.0138(0.0134) Steps 440(440.00) | Grad Norm 0.2246(0.3437) | Total Time 10.00(10.00)\n",
      "Iter 3544 | Time 31.7041(31.5010) | Bit/dim 1.0986(1.1006) | Xent 0.0390(0.0427) | Loss 1.1181(1.1219) | Error 0.0121(0.0134) Steps 440(440.00) | Grad Norm 0.2693(0.3414) | Total Time 10.00(10.00)\n",
      "Iter 3545 | Time 31.3866(31.4975) | Bit/dim 1.0997(1.1006) | Xent 0.0396(0.0426) | Loss 1.1195(1.1218) | Error 0.0139(0.0134) Steps 440(440.00) | Grad Norm 0.3337(0.3412) | Total Time 10.00(10.00)\n",
      "Iter 3546 | Time 31.5668(31.4996) | Bit/dim 1.0996(1.1005) | Xent 0.0457(0.0427) | Loss 1.1225(1.1219) | Error 0.0156(0.0135) Steps 440(440.00) | Grad Norm 0.2846(0.3395) | Total Time 10.00(10.00)\n",
      "Iter 3547 | Time 31.1066(31.4878) | Bit/dim 1.1044(1.1006) | Xent 0.0428(0.0427) | Loss 1.1258(1.1220) | Error 0.0132(0.0135) Steps 440(440.00) | Grad Norm 0.3745(0.3406) | Total Time 10.00(10.00)\n",
      "Iter 3548 | Time 30.7749(31.4664) | Bit/dim 1.1037(1.1007) | Xent 0.0440(0.0427) | Loss 1.1257(1.1221) | Error 0.0126(0.0134) Steps 440(440.00) | Grad Norm 0.3142(0.3398) | Total Time 10.00(10.00)\n",
      "Iter 3549 | Time 30.8493(31.4479) | Bit/dim 1.1014(1.1008) | Xent 0.0502(0.0429) | Loss 1.1265(1.1222) | Error 0.0150(0.0135) Steps 440(440.00) | Grad Norm 0.2276(0.3364) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0507 | Time 17.7247, Epoch Time 249.9483(249.9654), Bit/dim 1.0950(best: 1.0948), Xent 0.0354, Loss 1.1127, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3550 | Time 30.9039(31.4316) | Bit/dim 1.1025(1.1008) | Xent 0.0454(0.0430) | Loss 1.1252(1.1223) | Error 0.0136(0.0135) Steps 440(440.00) | Grad Norm 0.3121(0.3357) | Total Time 10.00(10.00)\n",
      "Iter 3551 | Time 33.4543(31.4923) | Bit/dim 1.0976(1.1007) | Xent 0.0418(0.0430) | Loss 1.1185(1.1222) | Error 0.0125(0.0135) Steps 440(440.00) | Grad Norm 0.4570(0.3393) | Total Time 10.00(10.00)\n",
      "Iter 3552 | Time 31.0829(31.4800) | Bit/dim 1.0996(1.1007) | Xent 0.0454(0.0430) | Loss 1.1223(1.1222) | Error 0.0148(0.0135) Steps 440(440.00) | Grad Norm 0.2761(0.3374) | Total Time 10.00(10.00)\n",
      "Iter 3553 | Time 32.5823(31.5131) | Bit/dim 1.1036(1.1008) | Xent 0.0398(0.0429) | Loss 1.1235(1.1222) | Error 0.0112(0.0134) Steps 440(440.00) | Grad Norm 0.6017(0.3453) | Total Time 10.00(10.00)\n",
      "Iter 3554 | Time 31.5595(31.5145) | Bit/dim 1.1020(1.1008) | Xent 0.0452(0.0430) | Loss 1.1246(1.1223) | Error 0.0136(0.0134) Steps 440(440.00) | Grad Norm 0.3243(0.3447) | Total Time 10.00(10.00)\n",
      "Iter 3555 | Time 31.7438(31.5214) | Bit/dim 1.0988(1.1007) | Xent 0.0421(0.0430) | Loss 1.1198(1.1222) | Error 0.0134(0.0134) Steps 440(440.00) | Grad Norm 0.2432(0.3417) | Total Time 10.00(10.00)\n",
      "Iter 3556 | Time 31.4208(31.5183) | Bit/dim 1.0984(1.1007) | Xent 0.0482(0.0431) | Loss 1.1225(1.1222) | Error 0.0150(0.0135) Steps 440(440.00) | Grad Norm 0.4066(0.3436) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0508 | Time 17.7864, Epoch Time 253.5052(250.0716), Bit/dim 1.0954(best: 1.0948), Xent 0.0324, Loss 1.1116, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3557 | Time 32.1577(31.5375) | Bit/dim 1.0974(1.1006) | Xent 0.0504(0.0434) | Loss 1.1226(1.1222) | Error 0.0154(0.0135) Steps 440(440.00) | Grad Norm 0.2706(0.3414) | Total Time 10.00(10.00)\n",
      "Iter 3558 | Time 31.1635(31.5263) | Bit/dim 1.0973(1.1005) | Xent 0.0422(0.0433) | Loss 1.1184(1.1221) | Error 0.0122(0.0135) Steps 440(440.00) | Grad Norm 0.3282(0.3410) | Total Time 10.00(10.00)\n",
      "Iter 3559 | Time 31.0940(31.5133) | Bit/dim 1.1015(1.1005) | Xent 0.0422(0.0433) | Loss 1.1226(1.1221) | Error 0.0129(0.0135) Steps 440(440.00) | Grad Norm 0.2367(0.3379) | Total Time 10.00(10.00)\n",
      "Iter 3560 | Time 32.3000(31.5369) | Bit/dim 1.1026(1.1006) | Xent 0.0400(0.0432) | Loss 1.1226(1.1222) | Error 0.0130(0.0135) Steps 440(440.00) | Grad Norm 0.4190(0.3403) | Total Time 10.00(10.00)\n",
      "Iter 3561 | Time 31.2571(31.5285) | Bit/dim 1.1020(1.1006) | Xent 0.0408(0.0431) | Loss 1.1224(1.1222) | Error 0.0124(0.0134) Steps 440(440.00) | Grad Norm 0.3270(0.3399) | Total Time 10.00(10.00)\n",
      "Iter 3562 | Time 31.2319(31.5196) | Bit/dim 1.1032(1.1007) | Xent 0.0410(0.0430) | Loss 1.1236(1.1222) | Error 0.0129(0.0134) Steps 440(440.00) | Grad Norm 0.3191(0.3393) | Total Time 10.00(10.00)\n",
      "Iter 3563 | Time 31.1727(31.5092) | Bit/dim 1.1035(1.1008) | Xent 0.0483(0.0432) | Loss 1.1276(1.1224) | Error 0.0145(0.0134) Steps 440(440.00) | Grad Norm 0.4003(0.3411) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0509 | Time 17.7162, Epoch Time 250.5023(250.0845), Bit/dim 1.0952(best: 1.0948), Xent 0.0362, Loss 1.1133, Error 0.0111(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3564 | Time 31.4994(31.5089) | Bit/dim 1.0975(1.1007) | Xent 0.0465(0.0433) | Loss 1.1208(1.1223) | Error 0.0134(0.0134) Steps 440(440.00) | Grad Norm 0.4780(0.3452) | Total Time 10.00(10.00)\n",
      "Iter 3565 | Time 31.1289(31.4975) | Bit/dim 1.1045(1.1008) | Xent 0.0406(0.0432) | Loss 1.1248(1.1224) | Error 0.0126(0.0134) Steps 440(440.00) | Grad Norm 0.2290(0.3418) | Total Time 10.00(10.00)\n",
      "Iter 3566 | Time 31.5615(31.4995) | Bit/dim 1.1006(1.1008) | Xent 0.0508(0.0435) | Loss 1.1260(1.1225) | Error 0.0144(0.0134) Steps 440(440.00) | Grad Norm 0.2421(0.3388) | Total Time 10.00(10.00)\n",
      "Iter 3567 | Time 31.3759(31.4957) | Bit/dim 1.1010(1.1008) | Xent 0.0444(0.0435) | Loss 1.1232(1.1225) | Error 0.0131(0.0134) Steps 440(440.00) | Grad Norm 0.3767(0.3399) | Total Time 10.00(10.00)\n",
      "Iter 3568 | Time 31.2089(31.4871) | Bit/dim 1.1017(1.1008) | Xent 0.0373(0.0433) | Loss 1.1204(1.1225) | Error 0.0116(0.0134) Steps 440(440.00) | Grad Norm 0.3496(0.3402) | Total Time 10.00(10.00)\n",
      "Iter 3569 | Time 32.4461(31.5159) | Bit/dim 1.1015(1.1008) | Xent 0.0369(0.0431) | Loss 1.1199(1.1224) | Error 0.0111(0.0133) Steps 440(440.00) | Grad Norm 0.3078(0.3392) | Total Time 10.00(10.00)\n",
      "Iter 3570 | Time 33.3787(31.5718) | Bit/dim 1.0986(1.1008) | Xent 0.0442(0.0431) | Loss 1.1207(1.1223) | Error 0.0139(0.0133) Steps 440(440.00) | Grad Norm 0.3428(0.3393) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0510 | Time 17.6156, Epoch Time 253.0139(250.1724), Bit/dim 1.0953(best: 1.0948), Xent 0.0323, Loss 1.1115, Error 0.0095(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3571 | Time 31.0228(31.5553) | Bit/dim 1.0990(1.1007) | Xent 0.0473(0.0433) | Loss 1.1227(1.1223) | Error 0.0150(0.0134) Steps 440(440.00) | Grad Norm 0.2342(0.3362) | Total Time 10.00(10.00)\n",
      "Iter 3572 | Time 30.8464(31.5341) | Bit/dim 1.0980(1.1006) | Xent 0.0480(0.0434) | Loss 1.1220(1.1223) | Error 0.0155(0.0134) Steps 440(440.00) | Grad Norm 0.2676(0.3341) | Total Time 10.00(10.00)\n",
      "Iter 3573 | Time 31.0940(31.5208) | Bit/dim 1.0997(1.1006) | Xent 0.0479(0.0435) | Loss 1.1236(1.1224) | Error 0.0145(0.0135) Steps 440(440.00) | Grad Norm 0.4019(0.3361) | Total Time 10.00(10.00)\n",
      "Iter 3574 | Time 31.0049(31.5054) | Bit/dim 1.1003(1.1006) | Xent 0.0457(0.0436) | Loss 1.1231(1.1224) | Error 0.0148(0.0135) Steps 440(440.00) | Grad Norm 0.4779(0.3404) | Total Time 10.00(10.00)\n",
      "Iter 3575 | Time 30.8413(31.4855) | Bit/dim 1.1034(1.1007) | Xent 0.0418(0.0435) | Loss 1.1242(1.1225) | Error 0.0122(0.0135) Steps 440(440.00) | Grad Norm 0.3581(0.3409) | Total Time 10.00(10.00)\n",
      "Iter 3576 | Time 31.2490(31.4784) | Bit/dim 1.1003(1.1007) | Xent 0.0385(0.0434) | Loss 1.1196(1.1224) | Error 0.0120(0.0134) Steps 440(440.00) | Grad Norm 0.3086(0.3400) | Total Time 10.00(10.00)\n",
      "Iter 3577 | Time 31.1271(31.4678) | Bit/dim 1.1048(1.1008) | Xent 0.0442(0.0434) | Loss 1.1269(1.1225) | Error 0.0132(0.0134) Steps 440(440.00) | Grad Norm 0.3136(0.3392) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0511 | Time 17.5523, Epoch Time 247.2700(250.0853), Bit/dim 1.0950(best: 1.0948), Xent 0.0360, Loss 1.1130, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3578 | Time 31.0750(31.4560) | Bit/dim 1.0993(1.1007) | Xent 0.0355(0.0432) | Loss 1.1171(1.1223) | Error 0.0131(0.0134) Steps 440(440.00) | Grad Norm 0.3238(0.3387) | Total Time 10.00(10.00)\n",
      "Iter 3579 | Time 30.4980(31.4273) | Bit/dim 1.0968(1.1006) | Xent 0.0482(0.0433) | Loss 1.1209(1.1223) | Error 0.0142(0.0134) Steps 440(440.00) | Grad Norm 0.1955(0.3344) | Total Time 10.00(10.00)\n",
      "Iter 3580 | Time 32.6380(31.4636) | Bit/dim 1.1007(1.1006) | Xent 0.0486(0.0435) | Loss 1.1250(1.1224) | Error 0.0165(0.0135) Steps 440(440.00) | Grad Norm 0.2638(0.3323) | Total Time 10.00(10.00)\n",
      "Iter 3581 | Time 31.0917(31.4525) | Bit/dim 1.0973(1.1005) | Xent 0.0475(0.0436) | Loss 1.1210(1.1223) | Error 0.0148(0.0136) Steps 440(440.00) | Grad Norm 0.2474(0.3297) | Total Time 10.00(10.00)\n",
      "Iter 3582 | Time 31.2924(31.4477) | Bit/dim 1.1111(1.1008) | Xent 0.0474(0.0437) | Loss 1.1348(1.1227) | Error 0.0159(0.0136) Steps 440(440.00) | Grad Norm 0.2431(0.3271) | Total Time 10.00(10.00)\n",
      "Iter 3583 | Time 31.7901(31.4579) | Bit/dim 1.0972(1.1007) | Xent 0.0422(0.0437) | Loss 1.1183(1.1226) | Error 0.0131(0.0136) Steps 440(440.00) | Grad Norm 0.4075(0.3296) | Total Time 10.00(10.00)\n",
      "Iter 3584 | Time 32.3778(31.4855) | Bit/dim 1.1000(1.1007) | Xent 0.0428(0.0436) | Loss 1.1214(1.1225) | Error 0.0138(0.0136) Steps 440(440.00) | Grad Norm 0.2087(0.3259) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0512 | Time 17.6848, Epoch Time 251.1193(250.1164), Bit/dim 1.0949(best: 1.0948), Xent 0.0333, Loss 1.1115, Error 0.0094(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3585 | Time 31.4191(31.4835) | Bit/dim 1.1027(1.1008) | Xent 0.0479(0.0438) | Loss 1.1266(1.1227) | Error 0.0151(0.0137) Steps 440(440.00) | Grad Norm 0.1922(0.3219) | Total Time 10.00(10.00)\n",
      "Iter 3586 | Time 30.7563(31.4617) | Bit/dim 1.1031(1.1008) | Xent 0.0445(0.0438) | Loss 1.1253(1.1227) | Error 0.0141(0.0137) Steps 440(440.00) | Grad Norm 0.3953(0.3241) | Total Time 10.00(10.00)\n",
      "Iter 3587 | Time 31.5269(31.4637) | Bit/dim 1.0956(1.1007) | Xent 0.0421(0.0437) | Loss 1.1166(1.1226) | Error 0.0132(0.0137) Steps 440(440.00) | Grad Norm 0.3105(0.3237) | Total Time 10.00(10.00)\n",
      "Iter 3588 | Time 31.1493(31.4542) | Bit/dim 1.0975(1.1006) | Xent 0.0436(0.0437) | Loss 1.1194(1.1225) | Error 0.0141(0.0137) Steps 440(440.00) | Grad Norm 0.1926(0.3198) | Total Time 10.00(10.00)\n",
      "Iter 3589 | Time 32.2114(31.4769) | Bit/dim 1.0973(1.1005) | Xent 0.0373(0.0435) | Loss 1.1160(1.1223) | Error 0.0129(0.0137) Steps 440(440.00) | Grad Norm 0.4845(0.3247) | Total Time 10.00(10.00)\n",
      "Iter 3590 | Time 30.9638(31.4616) | Bit/dim 1.0996(1.1005) | Xent 0.0460(0.0436) | Loss 1.1225(1.1223) | Error 0.0146(0.0137) Steps 440(440.00) | Grad Norm 0.3282(0.3248) | Total Time 10.00(10.00)\n",
      "Iter 3591 | Time 31.4950(31.4626) | Bit/dim 1.1064(1.1006) | Xent 0.0467(0.0437) | Loss 1.1297(1.1225) | Error 0.0140(0.0137) Steps 440(440.00) | Grad Norm 0.3282(0.3249) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0513 | Time 17.7151, Epoch Time 249.9820(250.1123), Bit/dim 1.0947(best: 1.0948), Xent 0.0340, Loss 1.1117, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3592 | Time 31.1919(31.4544) | Bit/dim 1.1032(1.1007) | Xent 0.0410(0.0436) | Loss 1.1237(1.1225) | Error 0.0128(0.0137) Steps 440(440.00) | Grad Norm 0.4112(0.3275) | Total Time 10.00(10.00)\n",
      "Iter 3593 | Time 31.2944(31.4496) | Bit/dim 1.1001(1.1007) | Xent 0.0425(0.0436) | Loss 1.1214(1.1225) | Error 0.0141(0.0137) Steps 440(440.00) | Grad Norm 0.3071(0.3269) | Total Time 10.00(10.00)\n",
      "Iter 3594 | Time 31.1920(31.4419) | Bit/dim 1.0979(1.1006) | Xent 0.0449(0.0436) | Loss 1.1203(1.1224) | Error 0.0139(0.0137) Steps 440(440.00) | Grad Norm 0.6195(0.3357) | Total Time 10.00(10.00)\n",
      "Iter 3595 | Time 32.1628(31.4635) | Bit/dim 1.1031(1.1007) | Xent 0.0467(0.0437) | Loss 1.1264(1.1226) | Error 0.0140(0.0137) Steps 440(440.00) | Grad Norm 0.2508(0.3331) | Total Time 10.00(10.00)\n",
      "Iter 3596 | Time 31.1266(31.4534) | Bit/dim 1.0983(1.1006) | Xent 0.0424(0.0437) | Loss 1.1195(1.1225) | Error 0.0126(0.0137) Steps 440(440.00) | Grad Norm 0.2877(0.3318) | Total Time 10.00(10.00)\n",
      "Iter 3597 | Time 32.3384(31.4800) | Bit/dim 1.1013(1.1006) | Xent 0.0435(0.0437) | Loss 1.1230(1.1225) | Error 0.0138(0.0137) Steps 440(440.00) | Grad Norm 0.3691(0.3329) | Total Time 10.00(10.00)\n",
      "Iter 3598 | Time 30.8912(31.4623) | Bit/dim 1.0996(1.1006) | Xent 0.0479(0.0438) | Loss 1.1236(1.1225) | Error 0.0134(0.0137) Steps 440(440.00) | Grad Norm 0.2958(0.3318) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0514 | Time 17.6458, Epoch Time 250.4980(250.1239), Bit/dim 1.0957(best: 1.0947), Xent 0.0343, Loss 1.1128, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3599 | Time 31.5640(31.4654) | Bit/dim 1.0989(1.1006) | Xent 0.0381(0.0436) | Loss 1.1179(1.1224) | Error 0.0120(0.0136) Steps 440(440.00) | Grad Norm 0.4418(0.3351) | Total Time 10.00(10.00)\n",
      "Iter 3600 | Time 31.1248(31.4551) | Bit/dim 1.1017(1.1006) | Xent 0.0460(0.0437) | Loss 1.1247(1.1224) | Error 0.0131(0.0136) Steps 440(440.00) | Grad Norm 0.2092(0.3313) | Total Time 10.00(10.00)\n",
      "Iter 3601 | Time 31.4330(31.4545) | Bit/dim 1.1021(1.1006) | Xent 0.0358(0.0435) | Loss 1.1200(1.1224) | Error 0.0125(0.0136) Steps 440(440.00) | Grad Norm 0.2364(0.3285) | Total Time 10.00(10.00)\n",
      "Iter 3602 | Time 31.7210(31.4625) | Bit/dim 1.0958(1.1005) | Xent 0.0424(0.0434) | Loss 1.1170(1.1222) | Error 0.0126(0.0135) Steps 440(440.00) | Grad Norm 0.2774(0.3269) | Total Time 10.00(10.00)\n",
      "Iter 3603 | Time 31.9028(31.4757) | Bit/dim 1.0990(1.1004) | Xent 0.0485(0.0436) | Loss 1.1232(1.1222) | Error 0.0129(0.0135) Steps 440(440.00) | Grad Norm 0.4860(0.3317) | Total Time 10.00(10.00)\n",
      "Iter 3604 | Time 31.5814(31.4789) | Bit/dim 1.1047(1.1006) | Xent 0.0479(0.0437) | Loss 1.1286(1.1224) | Error 0.0146(0.0135) Steps 440(440.00) | Grad Norm 0.2940(0.3306) | Total Time 10.00(10.00)\n",
      "Iter 3605 | Time 32.2556(31.5022) | Bit/dim 1.0986(1.1005) | Xent 0.0406(0.0436) | Loss 1.1189(1.1223) | Error 0.0132(0.0135) Steps 440(440.00) | Grad Norm 0.1967(0.3266) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0515 | Time 17.7998, Epoch Time 252.1931(250.1860), Bit/dim 1.0950(best: 1.0947), Xent 0.0336, Loss 1.1118, Error 0.0094(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3606 | Time 31.2368(31.4942) | Bit/dim 1.1028(1.1006) | Xent 0.0379(0.0435) | Loss 1.1217(1.1223) | Error 0.0128(0.0135) Steps 440(440.00) | Grad Norm 0.4480(0.3302) | Total Time 10.00(10.00)\n",
      "Iter 3607 | Time 31.3543(31.4900) | Bit/dim 1.1013(1.1006) | Xent 0.0474(0.0436) | Loss 1.1250(1.1224) | Error 0.0144(0.0135) Steps 440(440.00) | Grad Norm 0.4135(0.3327) | Total Time 10.00(10.00)\n",
      "Iter 3608 | Time 32.1297(31.5092) | Bit/dim 1.0996(1.1006) | Xent 0.0483(0.0437) | Loss 1.1238(1.1224) | Error 0.0155(0.0136) Steps 440(440.00) | Grad Norm 0.4158(0.3352) | Total Time 10.00(10.00)\n",
      "Iter 3609 | Time 31.8169(31.5184) | Bit/dim 1.0980(1.1005) | Xent 0.0502(0.0439) | Loss 1.1231(1.1225) | Error 0.0164(0.0137) Steps 440(440.00) | Grad Norm 0.5485(0.3416) | Total Time 10.00(10.00)\n",
      "Iter 3610 | Time 31.0964(31.5058) | Bit/dim 1.1008(1.1005) | Xent 0.0468(0.0440) | Loss 1.1242(1.1225) | Error 0.0125(0.0136) Steps 440(440.00) | Grad Norm 0.4740(0.3456) | Total Time 10.00(10.00)\n",
      "Iter 3611 | Time 31.1813(31.4960) | Bit/dim 1.1033(1.1006) | Xent 0.0408(0.0439) | Loss 1.1236(1.1225) | Error 0.0122(0.0136) Steps 440(440.00) | Grad Norm 0.2526(0.3428) | Total Time 10.00(10.00)\n",
      "Iter 3612 | Time 31.1051(31.4843) | Bit/dim 1.0979(1.1005) | Xent 0.0446(0.0439) | Loss 1.1202(1.1225) | Error 0.0142(0.0136) Steps 440(440.00) | Grad Norm 0.3789(0.3439) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0516 | Time 17.9552, Epoch Time 250.8684(250.2064), Bit/dim 1.0947(best: 1.0947), Xent 0.0322, Loss 1.1108, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3613 | Time 31.8919(31.4965) | Bit/dim 1.0997(1.1005) | Xent 0.0435(0.0439) | Loss 1.1215(1.1224) | Error 0.0124(0.0136) Steps 440(440.00) | Grad Norm 0.2972(0.3425) | Total Time 10.00(10.00)\n",
      "Iter 3614 | Time 30.6972(31.4726) | Bit/dim 1.0987(1.1004) | Xent 0.0420(0.0439) | Loss 1.1197(1.1224) | Error 0.0124(0.0136) Steps 440(440.00) | Grad Norm 0.2027(0.3383) | Total Time 10.00(10.00)\n",
      "Iter 3615 | Time 32.0779(31.4907) | Bit/dim 1.0952(1.1003) | Xent 0.0459(0.0439) | Loss 1.1182(1.1222) | Error 0.0140(0.0136) Steps 440(440.00) | Grad Norm 0.6914(0.3489) | Total Time 10.00(10.00)\n",
      "Iter 3616 | Time 33.0718(31.5381) | Bit/dim 1.0999(1.1003) | Xent 0.0457(0.0440) | Loss 1.1228(1.1222) | Error 0.0134(0.0136) Steps 440(440.00) | Grad Norm 0.3064(0.3476) | Total Time 10.00(10.00)\n",
      "Iter 3617 | Time 31.0569(31.5237) | Bit/dim 1.1015(1.1003) | Xent 0.0426(0.0439) | Loss 1.1228(1.1223) | Error 0.0124(0.0135) Steps 440(440.00) | Grad Norm 0.2973(0.3461) | Total Time 10.00(10.00)\n",
      "Iter 3618 | Time 31.5558(31.5247) | Bit/dim 1.0979(1.1002) | Xent 0.0453(0.0440) | Loss 1.1205(1.1222) | Error 0.0140(0.0135) Steps 440(440.00) | Grad Norm 0.3363(0.3458) | Total Time 10.00(10.00)\n",
      "Iter 3619 | Time 32.1204(31.5425) | Bit/dim 1.1058(1.1004) | Xent 0.0447(0.0440) | Loss 1.1281(1.1224) | Error 0.0132(0.0135) Steps 440(440.00) | Grad Norm 0.3563(0.3461) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0517 | Time 17.7708, Epoch Time 252.8567(250.2860), Bit/dim 1.0947(best: 1.0947), Xent 0.0325, Loss 1.1109, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3620 | Time 31.0283(31.5271) | Bit/dim 1.0956(1.1003) | Xent 0.0422(0.0439) | Loss 1.1167(1.1222) | Error 0.0131(0.0135) Steps 440(440.00) | Grad Norm 0.2899(0.3444) | Total Time 10.00(10.00)\n",
      "Iter 3621 | Time 32.4701(31.5554) | Bit/dim 1.1046(1.1004) | Xent 0.0461(0.0440) | Loss 1.1276(1.1224) | Error 0.0148(0.0136) Steps 440(440.00) | Grad Norm 0.3497(0.3446) | Total Time 10.00(10.00)\n",
      "Iter 3622 | Time 31.1514(31.5433) | Bit/dim 1.1011(1.1004) | Xent 0.0413(0.0439) | Loss 1.1217(1.1224) | Error 0.0120(0.0135) Steps 440(440.00) | Grad Norm 0.2201(0.3408) | Total Time 10.00(10.00)\n",
      "Iter 3623 | Time 30.9826(31.5265) | Bit/dim 1.1003(1.1004) | Xent 0.0435(0.0439) | Loss 1.1220(1.1224) | Error 0.0138(0.0135) Steps 440(440.00) | Grad Norm 0.2332(0.3376) | Total Time 10.00(10.00)\n",
      "Iter 3624 | Time 31.0709(31.5128) | Bit/dim 1.1038(1.1005) | Xent 0.0448(0.0439) | Loss 1.1262(1.1225) | Error 0.0160(0.0136) Steps 440(440.00) | Grad Norm 0.2273(0.3343) | Total Time 10.00(10.00)\n",
      "Iter 3625 | Time 31.8819(31.5239) | Bit/dim 1.0973(1.1004) | Xent 0.0427(0.0439) | Loss 1.1187(1.1224) | Error 0.0125(0.0136) Steps 440(440.00) | Grad Norm 0.3767(0.3356) | Total Time 10.00(10.00)\n",
      "Iter 3626 | Time 31.0004(31.5082) | Bit/dim 1.0998(1.1004) | Xent 0.0499(0.0441) | Loss 1.1248(1.1224) | Error 0.0152(0.0136) Steps 440(440.00) | Grad Norm 0.3063(0.3347) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0518 | Time 17.8733, Epoch Time 250.2913(250.2861), Bit/dim 1.0941(best: 1.0947), Xent 0.0342, Loss 1.1112, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3627 | Time 31.4686(31.5070) | Bit/dim 1.1020(1.1004) | Xent 0.0402(0.0440) | Loss 1.1221(1.1224) | Error 0.0138(0.0136) Steps 440(440.00) | Grad Norm 0.2210(0.3313) | Total Time 10.00(10.00)\n",
      "Iter 3628 | Time 30.9383(31.4899) | Bit/dim 1.0992(1.1004) | Xent 0.0443(0.0440) | Loss 1.1214(1.1224) | Error 0.0136(0.0136) Steps 440(440.00) | Grad Norm 0.1738(0.3266) | Total Time 10.00(10.00)\n",
      "Iter 3629 | Time 31.4914(31.4900) | Bit/dim 1.1019(1.1004) | Xent 0.0371(0.0438) | Loss 1.1204(1.1223) | Error 0.0114(0.0135) Steps 440(440.00) | Grad Norm 0.5881(0.3344) | Total Time 10.00(10.00)\n",
      "Iter 3630 | Time 31.3233(31.4850) | Bit/dim 1.0994(1.1004) | Xent 0.0411(0.0437) | Loss 1.1200(1.1223) | Error 0.0118(0.0135) Steps 440(440.00) | Grad Norm 0.3186(0.3339) | Total Time 10.00(10.00)\n",
      "Iter 3631 | Time 31.9538(31.4990) | Bit/dim 1.1031(1.1005) | Xent 0.0431(0.0437) | Loss 1.1247(1.1223) | Error 0.0131(0.0135) Steps 440(440.00) | Grad Norm 0.3441(0.3342) | Total Time 10.00(10.00)\n",
      "Iter 3632 | Time 31.1685(31.4891) | Bit/dim 1.1011(1.1005) | Xent 0.0416(0.0436) | Loss 1.1219(1.1223) | Error 0.0138(0.0135) Steps 440(440.00) | Grad Norm 0.2916(0.3330) | Total Time 10.00(10.00)\n",
      "Iter 3633 | Time 33.2584(31.5422) | Bit/dim 1.0989(1.1005) | Xent 0.0354(0.0434) | Loss 1.1166(1.1221) | Error 0.0112(0.0134) Steps 440(440.00) | Grad Norm 0.4342(0.3360) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0519 | Time 17.6060, Epoch Time 251.7011(250.3286), Bit/dim 1.0950(best: 1.0941), Xent 0.0319, Loss 1.1110, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3634 | Time 31.4956(31.5408) | Bit/dim 1.0968(1.1004) | Xent 0.0449(0.0434) | Loss 1.1193(1.1221) | Error 0.0131(0.0134) Steps 440(440.00) | Grad Norm 0.2734(0.3341) | Total Time 10.00(10.00)\n",
      "Iter 3635 | Time 32.1081(31.5578) | Bit/dim 1.1038(1.1005) | Xent 0.0460(0.0435) | Loss 1.1268(1.1222) | Error 0.0148(0.0135) Steps 440(440.00) | Grad Norm 0.3068(0.3333) | Total Time 10.00(10.00)\n",
      "Iter 3636 | Time 31.5727(31.5583) | Bit/dim 1.0977(1.1004) | Xent 0.0480(0.0436) | Loss 1.1217(1.1222) | Error 0.0149(0.0135) Steps 440(440.00) | Grad Norm 0.2761(0.3316) | Total Time 10.00(10.00)\n",
      "Iter 3637 | Time 31.4574(31.5552) | Bit/dim 1.0966(1.1003) | Xent 0.0387(0.0435) | Loss 1.1159(1.1220) | Error 0.0112(0.0134) Steps 440(440.00) | Grad Norm 0.4264(0.3344) | Total Time 10.00(10.00)\n",
      "Iter 3638 | Time 31.0312(31.5395) | Bit/dim 1.1031(1.1003) | Xent 0.0436(0.0435) | Loss 1.1249(1.1221) | Error 0.0144(0.0135) Steps 440(440.00) | Grad Norm 0.4411(0.3376) | Total Time 10.00(10.00)\n",
      "Iter 3639 | Time 30.9779(31.5227) | Bit/dim 1.1011(1.1004) | Xent 0.0368(0.0433) | Loss 1.1195(1.1220) | Error 0.0106(0.0134) Steps 440(440.00) | Grad Norm 0.3624(0.3384) | Total Time 10.00(10.00)\n",
      "Iter 3640 | Time 32.0061(31.5372) | Bit/dim 1.0982(1.1003) | Xent 0.0464(0.0434) | Loss 1.1214(1.1220) | Error 0.0140(0.0134) Steps 440(440.00) | Grad Norm 0.3153(0.3377) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0520 | Time 17.6234, Epoch Time 251.4187(250.3613), Bit/dim 1.0942(best: 1.0941), Xent 0.0331, Loss 1.1107, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3641 | Time 30.8547(31.5167) | Bit/dim 1.1016(1.1003) | Xent 0.0414(0.0433) | Loss 1.1223(1.1220) | Error 0.0129(0.0134) Steps 440(440.00) | Grad Norm 0.2288(0.3344) | Total Time 10.00(10.00)\n",
      "Iter 3642 | Time 32.0614(31.5330) | Bit/dim 1.1032(1.1004) | Xent 0.0396(0.0432) | Loss 1.1230(1.1220) | Error 0.0130(0.0134) Steps 446(440.18) | Grad Norm 0.3126(0.3338) | Total Time 10.00(10.00)\n",
      "Iter 3643 | Time 31.8707(31.5432) | Bit/dim 1.1031(1.1005) | Xent 0.0439(0.0432) | Loss 1.1250(1.1221) | Error 0.0130(0.0134) Steps 446(440.35) | Grad Norm 0.3412(0.3340) | Total Time 10.00(10.00)\n",
      "Iter 3644 | Time 31.1224(31.5305) | Bit/dim 1.0929(1.1003) | Xent 0.0395(0.0431) | Loss 1.1126(1.1218) | Error 0.0129(0.0133) Steps 440(440.34) | Grad Norm 0.3672(0.3350) | Total Time 10.00(10.00)\n",
      "Iter 3645 | Time 31.8963(31.5415) | Bit/dim 1.0998(1.1003) | Xent 0.0427(0.0431) | Loss 1.1212(1.1218) | Error 0.0140(0.0134) Steps 440(440.33) | Grad Norm 0.2882(0.3336) | Total Time 10.00(10.00)\n",
      "Iter 3646 | Time 32.2853(31.5638) | Bit/dim 1.0977(1.1002) | Xent 0.0443(0.0431) | Loss 1.1199(1.1218) | Error 0.0145(0.0134) Steps 440(440.32) | Grad Norm 0.4198(0.3362) | Total Time 10.00(10.00)\n",
      "Iter 3647 | Time 30.7724(31.5401) | Bit/dim 1.1030(1.1003) | Xent 0.0420(0.0431) | Loss 1.1240(1.1218) | Error 0.0120(0.0134) Steps 440(440.31) | Grad Norm 0.2590(0.3338) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0521 | Time 17.7067, Epoch Time 251.2559(250.3881), Bit/dim 1.0944(best: 1.0941), Xent 0.0338, Loss 1.1114, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3648 | Time 31.1744(31.5291) | Bit/dim 1.1034(1.1004) | Xent 0.0469(0.0432) | Loss 1.1269(1.1220) | Error 0.0131(0.0133) Steps 440(440.30) | Grad Norm 0.6088(0.3421) | Total Time 10.00(10.00)\n",
      "Iter 3649 | Time 31.2111(31.5196) | Bit/dim 1.1015(1.1004) | Xent 0.0438(0.0432) | Loss 1.1234(1.1220) | Error 0.0130(0.0133) Steps 440(440.30) | Grad Norm 0.4657(0.3458) | Total Time 10.00(10.00)\n",
      "Iter 3650 | Time 30.8428(31.4993) | Bit/dim 1.0951(1.1002) | Xent 0.0464(0.0433) | Loss 1.1183(1.1219) | Error 0.0148(0.0134) Steps 440(440.29) | Grad Norm 0.3610(0.3463) | Total Time 10.00(10.00)\n",
      "Iter 3651 | Time 31.2183(31.4908) | Bit/dim 1.1019(1.1003) | Xent 0.0457(0.0434) | Loss 1.1247(1.1220) | Error 0.0124(0.0133) Steps 440(440.28) | Grad Norm 0.3381(0.3460) | Total Time 10.00(10.00)\n",
      "Iter 3652 | Time 32.0453(31.5075) | Bit/dim 1.1038(1.1004) | Xent 0.0408(0.0433) | Loss 1.1242(1.1221) | Error 0.0129(0.0133) Steps 440(440.27) | Grad Norm 0.4310(0.3486) | Total Time 10.00(10.00)\n",
      "Iter 3653 | Time 30.8111(31.4866) | Bit/dim 1.1047(1.1005) | Xent 0.0455(0.0434) | Loss 1.1275(1.1222) | Error 0.0150(0.0134) Steps 440(440.26) | Grad Norm 0.5054(0.3533) | Total Time 10.00(10.00)\n",
      "Iter 3654 | Time 31.1099(31.4753) | Bit/dim 1.0964(1.1004) | Xent 0.0386(0.0432) | Loss 1.1157(1.1220) | Error 0.0131(0.0134) Steps 440(440.25) | Grad Norm 0.3670(0.3537) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0522 | Time 17.7167, Epoch Time 248.9358(250.3445), Bit/dim 1.0951(best: 1.0941), Xent 0.0303, Loss 1.1102, Error 0.0093(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3655 | Time 31.1759(31.4663) | Bit/dim 1.0967(1.1003) | Xent 0.0437(0.0433) | Loss 1.1186(1.1219) | Error 0.0138(0.0134) Steps 440(440.25) | Grad Norm 0.3077(0.3523) | Total Time 10.00(10.00)\n",
      "Iter 3656 | Time 30.7356(31.4444) | Bit/dim 1.1012(1.1003) | Xent 0.0424(0.0432) | Loss 1.1224(1.1219) | Error 0.0120(0.0133) Steps 440(440.24) | Grad Norm 0.4107(0.3540) | Total Time 10.00(10.00)\n",
      "Iter 3657 | Time 31.2636(31.4390) | Bit/dim 1.1024(1.1004) | Xent 0.0510(0.0435) | Loss 1.1279(1.1221) | Error 0.0162(0.0134) Steps 440(440.23) | Grad Norm 0.2399(0.3506) | Total Time 10.00(10.00)\n",
      "Iter 3658 | Time 31.3080(31.4350) | Bit/dim 1.1013(1.1004) | Xent 0.0424(0.0434) | Loss 1.1225(1.1221) | Error 0.0122(0.0134) Steps 440(440.22) | Grad Norm 0.2610(0.3479) | Total Time 10.00(10.00)\n",
      "Iter 3659 | Time 32.4286(31.4648) | Bit/dim 1.1011(1.1004) | Xent 0.0423(0.0434) | Loss 1.1223(1.1221) | Error 0.0128(0.0134) Steps 440(440.22) | Grad Norm 0.2421(0.3448) | Total Time 10.00(10.00)\n",
      "Iter 3660 | Time 31.3893(31.4626) | Bit/dim 1.0973(1.1003) | Xent 0.0394(0.0433) | Loss 1.1170(1.1220) | Error 0.0129(0.0134) Steps 440(440.21) | Grad Norm 0.2973(0.3433) | Total Time 10.00(10.00)\n",
      "Iter 3661 | Time 31.4785(31.4631) | Bit/dim 1.0994(1.1003) | Xent 0.0360(0.0431) | Loss 1.1174(1.1218) | Error 0.0116(0.0133) Steps 440(440.20) | Grad Norm 0.2236(0.3397) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0523 | Time 17.8715, Epoch Time 250.2723(250.3424), Bit/dim 1.0946(best: 1.0941), Xent 0.0322, Loss 1.1107, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3662 | Time 31.8203(31.4738) | Bit/dim 1.0973(1.1002) | Xent 0.0437(0.0431) | Loss 1.1192(1.1218) | Error 0.0135(0.0133) Steps 440(440.20) | Grad Norm 0.1759(0.3348) | Total Time 10.00(10.00)\n",
      "Iter 3663 | Time 32.5871(31.5072) | Bit/dim 1.0987(1.1002) | Xent 0.0432(0.0431) | Loss 1.1203(1.1217) | Error 0.0134(0.0133) Steps 440(440.19) | Grad Norm 0.1985(0.3307) | Total Time 10.00(10.00)\n",
      "Iter 3664 | Time 31.0813(31.4944) | Bit/dim 1.0961(1.1001) | Xent 0.0496(0.0433) | Loss 1.1209(1.1217) | Error 0.0148(0.0134) Steps 440(440.19) | Grad Norm 0.2670(0.3288) | Total Time 10.00(10.00)\n",
      "Iter 3665 | Time 31.4513(31.4931) | Bit/dim 1.1018(1.1001) | Xent 0.0412(0.0432) | Loss 1.1224(1.1217) | Error 0.0131(0.0134) Steps 440(440.18) | Grad Norm 0.3635(0.3299) | Total Time 10.00(10.00)\n",
      "Iter 3666 | Time 31.5796(31.4957) | Bit/dim 1.1003(1.1001) | Xent 0.0418(0.0432) | Loss 1.1212(1.1217) | Error 0.0130(0.0133) Steps 440(440.18) | Grad Norm 0.2594(0.3278) | Total Time 10.00(10.00)\n",
      "Iter 3667 | Time 31.7129(31.5022) | Bit/dim 1.0998(1.1001) | Xent 0.0413(0.0431) | Loss 1.1204(1.1217) | Error 0.0139(0.0134) Steps 446(440.35) | Grad Norm 0.4555(0.3316) | Total Time 10.00(10.00)\n",
      "Iter 3668 | Time 30.5114(31.4725) | Bit/dim 1.1044(1.1002) | Xent 0.0358(0.0429) | Loss 1.1222(1.1217) | Error 0.0119(0.0133) Steps 440(440.34) | Grad Norm 0.2088(0.3279) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0524 | Time 17.7904, Epoch Time 251.4380(250.3752), Bit/dim 1.0947(best: 1.0941), Xent 0.0330, Loss 1.1112, Error 0.0091(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3669 | Time 32.4393(31.5015) | Bit/dim 1.0974(1.1001) | Xent 0.0427(0.0429) | Loss 1.1187(1.1216) | Error 0.0141(0.0133) Steps 440(440.33) | Grad Norm 0.3256(0.3278) | Total Time 10.00(10.00)\n",
      "Iter 3670 | Time 30.9819(31.4859) | Bit/dim 1.0995(1.1001) | Xent 0.0480(0.0430) | Loss 1.1235(1.1216) | Error 0.0138(0.0134) Steps 440(440.32) | Grad Norm 0.6167(0.3365) | Total Time 10.00(10.00)\n",
      "Iter 3671 | Time 32.4517(31.5149) | Bit/dim 1.1024(1.1002) | Xent 0.0422(0.0430) | Loss 1.1235(1.1217) | Error 0.0131(0.0133) Steps 440(440.31) | Grad Norm 0.2384(0.3336) | Total Time 10.00(10.00)\n",
      "Iter 3672 | Time 32.1704(31.5345) | Bit/dim 1.1000(1.1002) | Xent 0.0409(0.0430) | Loss 1.1205(1.1217) | Error 0.0122(0.0133) Steps 440(440.30) | Grad Norm 0.4557(0.3372) | Total Time 10.00(10.00)\n",
      "Iter 3673 | Time 32.5158(31.5640) | Bit/dim 1.0983(1.1001) | Xent 0.0502(0.0432) | Loss 1.1234(1.1217) | Error 0.0148(0.0134) Steps 440(440.29) | Grad Norm 0.5518(0.3437) | Total Time 10.00(10.00)\n",
      "Iter 3674 | Time 30.8516(31.5426) | Bit/dim 1.0996(1.1001) | Xent 0.0405(0.0431) | Loss 1.1198(1.1217) | Error 0.0115(0.0133) Steps 440(440.28) | Grad Norm 0.2720(0.3415) | Total Time 10.00(10.00)\n",
      "Iter 3675 | Time 32.3247(31.5661) | Bit/dim 1.1045(1.1002) | Xent 0.0445(0.0431) | Loss 1.1267(1.1218) | Error 0.0139(0.0133) Steps 440(440.27) | Grad Norm 0.3043(0.3404) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0525 | Time 17.7877, Epoch Time 254.2116(250.4903), Bit/dim 1.0947(best: 1.0941), Xent 0.0341, Loss 1.1118, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3676 | Time 30.9555(31.5478) | Bit/dim 1.1024(1.1003) | Xent 0.0437(0.0431) | Loss 1.1243(1.1219) | Error 0.0125(0.0133) Steps 440(440.27) | Grad Norm 0.3040(0.3393) | Total Time 10.00(10.00)\n",
      "Iter 3677 | Time 31.2379(31.5385) | Bit/dim 1.1006(1.1003) | Xent 0.0421(0.0431) | Loss 1.1217(1.1219) | Error 0.0141(0.0133) Steps 440(440.26) | Grad Norm 0.3403(0.3393) | Total Time 10.00(10.00)\n",
      "Iter 3678 | Time 31.3160(31.5318) | Bit/dim 1.1008(1.1003) | Xent 0.0527(0.0434) | Loss 1.1272(1.1220) | Error 0.0156(0.0134) Steps 440(440.25) | Grad Norm 0.2967(0.3380) | Total Time 10.00(10.00)\n",
      "Iter 3679 | Time 30.5067(31.5010) | Bit/dim 1.1001(1.1003) | Xent 0.0432(0.0434) | Loss 1.1217(1.1220) | Error 0.0126(0.0134) Steps 440(440.24) | Grad Norm 0.2227(0.3346) | Total Time 10.00(10.00)\n",
      "Iter 3680 | Time 32.5197(31.5316) | Bit/dim 1.0997(1.1003) | Xent 0.0444(0.0434) | Loss 1.1219(1.1220) | Error 0.0139(0.0134) Steps 440(440.24) | Grad Norm 0.1915(0.3303) | Total Time 10.00(10.00)\n",
      "Iter 3681 | Time 31.7990(31.5396) | Bit/dim 1.0969(1.1002) | Xent 0.0415(0.0434) | Loss 1.1177(1.1219) | Error 0.0128(0.0134) Steps 440(440.23) | Grad Norm 0.3905(0.3321) | Total Time 10.00(10.00)\n",
      "Iter 3682 | Time 32.0154(31.5539) | Bit/dim 1.1010(1.1002) | Xent 0.0422(0.0433) | Loss 1.1221(1.1219) | Error 0.0140(0.0134) Steps 440(440.22) | Grad Norm 0.3591(0.3329) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0526 | Time 17.7186, Epoch Time 250.8694(250.5017), Bit/dim 1.0950(best: 1.0941), Xent 0.0324, Loss 1.1112, Error 0.0093(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3683 | Time 32.1880(31.5729) | Bit/dim 1.1017(1.1003) | Xent 0.0490(0.0435) | Loss 1.1262(1.1220) | Error 0.0151(0.0134) Steps 440(440.22) | Grad Norm 0.2251(0.3297) | Total Time 10.00(10.00)\n",
      "Iter 3684 | Time 31.4027(31.5678) | Bit/dim 1.0977(1.1002) | Xent 0.0389(0.0434) | Loss 1.1171(1.1219) | Error 0.0124(0.0134) Steps 440(440.21) | Grad Norm 0.2161(0.3263) | Total Time 10.00(10.00)\n",
      "Iter 3685 | Time 30.7804(31.5442) | Bit/dim 1.1014(1.1002) | Xent 0.0401(0.0433) | Loss 1.1214(1.1219) | Error 0.0130(0.0134) Steps 440(440.20) | Grad Norm 0.3030(0.3256) | Total Time 10.00(10.00)\n",
      "Iter 3686 | Time 32.5151(31.5733) | Bit/dim 1.0997(1.1002) | Xent 0.0419(0.0432) | Loss 1.1207(1.1218) | Error 0.0138(0.0134) Steps 440(440.20) | Grad Norm 0.3361(0.3259) | Total Time 10.00(10.00)\n",
      "Iter 3687 | Time 31.2683(31.5642) | Bit/dim 1.1031(1.1003) | Xent 0.0503(0.0434) | Loss 1.1283(1.1220) | Error 0.0150(0.0134) Steps 440(440.19) | Grad Norm 0.4043(0.3282) | Total Time 10.00(10.00)\n",
      "Iter 3688 | Time 31.2668(31.5552) | Bit/dim 1.0994(1.1003) | Xent 0.0387(0.0433) | Loss 1.1187(1.1219) | Error 0.0115(0.0134) Steps 440(440.18) | Grad Norm 0.3094(0.3277) | Total Time 10.00(10.00)\n",
      "Iter 3689 | Time 32.2342(31.5756) | Bit/dim 1.1003(1.1003) | Xent 0.0395(0.0432) | Loss 1.1200(1.1219) | Error 0.0125(0.0134) Steps 440(440.18) | Grad Norm 0.3054(0.3270) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0527 | Time 17.7097, Epoch Time 252.3239(250.5564), Bit/dim 1.0947(best: 1.0941), Xent 0.0301, Loss 1.1097, Error 0.0093(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3690 | Time 32.5797(31.6057) | Bit/dim 1.0994(1.1003) | Xent 0.0432(0.0432) | Loss 1.1211(1.1218) | Error 0.0142(0.0134) Steps 440(440.17) | Grad Norm 0.5898(0.3349) | Total Time 10.00(10.00)\n",
      "Iter 3691 | Time 32.2632(31.6255) | Bit/dim 1.1027(1.1003) | Xent 0.0367(0.0430) | Loss 1.1210(1.1218) | Error 0.0106(0.0133) Steps 440(440.17) | Grad Norm 0.1848(0.3304) | Total Time 10.00(10.00)\n",
      "Iter 3692 | Time 32.0507(31.6382) | Bit/dim 1.1025(1.1004) | Xent 0.0485(0.0431) | Loss 1.1267(1.1220) | Error 0.0128(0.0133) Steps 440(440.16) | Grad Norm 0.2469(0.3279) | Total Time 10.00(10.00)\n",
      "Iter 3693 | Time 31.4610(31.6329) | Bit/dim 1.0950(1.1002) | Xent 0.0432(0.0432) | Loss 1.1166(1.1218) | Error 0.0128(0.0133) Steps 440(440.16) | Grad Norm 0.4880(0.3327) | Total Time 10.00(10.00)\n",
      "Iter 3694 | Time 31.2745(31.6222) | Bit/dim 1.1048(1.1004) | Xent 0.0422(0.0431) | Loss 1.1259(1.1219) | Error 0.0140(0.0133) Steps 440(440.15) | Grad Norm 0.3840(0.3342) | Total Time 10.00(10.00)\n",
      "Iter 3695 | Time 30.6848(31.5940) | Bit/dim 1.1006(1.1004) | Xent 0.0440(0.0431) | Loss 1.1226(1.1219) | Error 0.0140(0.0133) Steps 440(440.15) | Grad Norm 0.4423(0.3375) | Total Time 10.00(10.00)\n",
      "Iter 3696 | Time 31.4980(31.5912) | Bit/dim 1.0951(1.1002) | Xent 0.0416(0.0431) | Loss 1.1159(1.1218) | Error 0.0149(0.0134) Steps 440(440.14) | Grad Norm 0.3499(0.3378) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0528 | Time 17.8201, Epoch Time 252.3219(250.6093), Bit/dim 1.0946(best: 1.0941), Xent 0.0342, Loss 1.1117, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3697 | Time 31.4335(31.5864) | Bit/dim 1.1011(1.1002) | Xent 0.0394(0.0430) | Loss 1.1208(1.1217) | Error 0.0129(0.0133) Steps 440(440.14) | Grad Norm 0.3157(0.3372) | Total Time 10.00(10.00)\n",
      "Iter 3698 | Time 33.4726(31.6430) | Bit/dim 1.0951(1.1001) | Xent 0.0428(0.0430) | Loss 1.1165(1.1216) | Error 0.0140(0.0134) Steps 440(440.14) | Grad Norm 0.2294(0.3339) | Total Time 10.00(10.00)\n",
      "Iter 3699 | Time 31.5034(31.6388) | Bit/dim 1.1025(1.1002) | Xent 0.0459(0.0431) | Loss 1.1255(1.1217) | Error 0.0145(0.0134) Steps 440(440.13) | Grad Norm 0.3519(0.3345) | Total Time 10.00(10.00)\n",
      "Iter 3700 | Time 30.9484(31.6181) | Bit/dim 1.1062(1.1003) | Xent 0.0425(0.0431) | Loss 1.1275(1.1219) | Error 0.0136(0.0134) Steps 440(440.13) | Grad Norm 0.3117(0.3338) | Total Time 10.00(10.00)\n",
      "Iter 3701 | Time 30.7445(31.5919) | Bit/dim 1.1001(1.1003) | Xent 0.0417(0.0430) | Loss 1.1210(1.1218) | Error 0.0128(0.0134) Steps 440(440.12) | Grad Norm 0.2526(0.3314) | Total Time 10.00(10.00)\n",
      "Iter 3702 | Time 31.1685(31.5792) | Bit/dim 1.1033(1.1004) | Xent 0.0395(0.0429) | Loss 1.1231(1.1219) | Error 0.0125(0.0134) Steps 440(440.12) | Grad Norm 0.2887(0.3301) | Total Time 10.00(10.00)\n",
      "Iter 3703 | Time 31.5193(31.5774) | Bit/dim 1.0976(1.1003) | Xent 0.0443(0.0429) | Loss 1.1197(1.1218) | Error 0.0148(0.0134) Steps 446(440.30) | Grad Norm 0.2990(0.3292) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0529 | Time 17.7433, Epoch Time 251.2065(250.6272), Bit/dim 1.0945(best: 1.0941), Xent 0.0327, Loss 1.1109, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3704 | Time 32.2214(31.5967) | Bit/dim 1.0984(1.1003) | Xent 0.0389(0.0428) | Loss 1.1179(1.1217) | Error 0.0114(0.0133) Steps 446(440.47) | Grad Norm 0.2898(0.3280) | Total Time 10.00(10.00)\n",
      "Iter 3705 | Time 31.9119(31.6062) | Bit/dim 1.0985(1.1002) | Xent 0.0441(0.0429) | Loss 1.1206(1.1217) | Error 0.0129(0.0133) Steps 446(440.63) | Grad Norm 0.2817(0.3266) | Total Time 10.00(10.00)\n",
      "Iter 3706 | Time 31.6156(31.6065) | Bit/dim 1.1049(1.1004) | Xent 0.0498(0.0431) | Loss 1.1298(1.1219) | Error 0.0140(0.0133) Steps 440(440.62) | Grad Norm 0.4402(0.3300) | Total Time 10.00(10.00)\n",
      "Iter 3707 | Time 30.8373(31.5834) | Bit/dim 1.0964(1.1003) | Xent 0.0432(0.0431) | Loss 1.1180(1.1218) | Error 0.0134(0.0133) Steps 440(440.60) | Grad Norm 0.5560(0.3368) | Total Time 10.00(10.00)\n",
      "Iter 3708 | Time 31.2492(31.5734) | Bit/dim 1.1006(1.1003) | Xent 0.0486(0.0432) | Loss 1.1250(1.1219) | Error 0.0145(0.0134) Steps 440(440.58) | Grad Norm 0.2877(0.3353) | Total Time 10.00(10.00)\n",
      "Iter 3709 | Time 31.5202(31.5718) | Bit/dim 1.1002(1.1003) | Xent 0.0460(0.0433) | Loss 1.1232(1.1219) | Error 0.0126(0.0134) Steps 440(440.56) | Grad Norm 0.5827(0.3427) | Total Time 10.00(10.00)\n",
      "Iter 3710 | Time 32.1703(31.5897) | Bit/dim 1.0961(1.1001) | Xent 0.0408(0.0432) | Loss 1.1165(1.1218) | Error 0.0132(0.0134) Steps 440(440.54) | Grad Norm 0.2939(0.3413) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0530 | Time 17.6434, Epoch Time 251.7304(250.6603), Bit/dim 1.0941(best: 1.0941), Xent 0.0334, Loss 1.1108, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3711 | Time 31.3263(31.5818) | Bit/dim 1.1000(1.1001) | Xent 0.0415(0.0432) | Loss 1.1208(1.1217) | Error 0.0139(0.0134) Steps 440(440.53) | Grad Norm 0.6642(0.3509) | Total Time 10.00(10.00)\n",
      "Iter 3712 | Time 31.4023(31.5764) | Bit/dim 1.1013(1.1002) | Xent 0.0536(0.0435) | Loss 1.1281(1.1219) | Error 0.0164(0.0135) Steps 440(440.51) | Grad Norm 0.2417(0.3477) | Total Time 10.00(10.00)\n",
      "Iter 3713 | Time 31.9618(31.5880) | Bit/dim 1.1001(1.1002) | Xent 0.0456(0.0436) | Loss 1.1228(1.1220) | Error 0.0138(0.0135) Steps 440(440.50) | Grad Norm 0.3708(0.3484) | Total Time 10.00(10.00)\n",
      "Iter 3714 | Time 31.7137(31.5918) | Bit/dim 1.0973(1.1001) | Xent 0.0459(0.0436) | Loss 1.1203(1.1219) | Error 0.0138(0.0135) Steps 440(440.48) | Grad Norm 0.5981(0.3558) | Total Time 10.00(10.00)\n",
      "Iter 3715 | Time 32.4574(31.6177) | Bit/dim 1.0990(1.1001) | Xent 0.0427(0.0436) | Loss 1.1203(1.1219) | Error 0.0139(0.0135) Steps 440(440.47) | Grad Norm 0.3101(0.3545) | Total Time 10.00(10.00)\n",
      "Iter 3716 | Time 31.0985(31.6022) | Bit/dim 1.0960(1.0999) | Xent 0.0478(0.0437) | Loss 1.1199(1.1218) | Error 0.0141(0.0135) Steps 440(440.45) | Grad Norm 0.4852(0.3584) | Total Time 10.00(10.00)\n",
      "Iter 3717 | Time 31.1507(31.5886) | Bit/dim 1.1018(1.1000) | Xent 0.0474(0.0438) | Loss 1.1255(1.1219) | Error 0.0152(0.0136) Steps 440(440.44) | Grad Norm 0.3372(0.3578) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0531 | Time 17.6646, Epoch Time 251.4295(250.6834), Bit/dim 1.0941(best: 1.0941), Xent 0.0346, Loss 1.1114, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3718 | Time 32.7476(31.6234) | Bit/dim 1.0967(1.0999) | Xent 0.0399(0.0437) | Loss 1.1167(1.1218) | Error 0.0120(0.0135) Steps 440(440.43) | Grad Norm 0.5231(0.3627) | Total Time 10.00(10.00)\n",
      "Iter 3719 | Time 33.2822(31.6731) | Bit/dim 1.1038(1.1000) | Xent 0.0405(0.0436) | Loss 1.1240(1.1218) | Error 0.0132(0.0135) Steps 440(440.41) | Grad Norm 0.4788(0.3662) | Total Time 10.00(10.00)\n",
      "Iter 3720 | Time 30.9893(31.6526) | Bit/dim 1.0976(1.0999) | Xent 0.0435(0.0436) | Loss 1.1194(1.1217) | Error 0.0139(0.0135) Steps 440(440.40) | Grad Norm 0.3097(0.3645) | Total Time 10.00(10.00)\n",
      "Iter 3721 | Time 30.5769(31.6204) | Bit/dim 1.0969(1.0998) | Xent 0.0460(0.0437) | Loss 1.1199(1.1217) | Error 0.0149(0.0136) Steps 440(440.39) | Grad Norm 0.9791(0.3829) | Total Time 10.00(10.00)\n",
      "Iter 3722 | Time 32.1581(31.6365) | Bit/dim 1.1013(1.0999) | Xent 0.0387(0.0435) | Loss 1.1206(1.1217) | Error 0.0146(0.0136) Steps 440(440.38) | Grad Norm 0.3667(0.3825) | Total Time 10.00(10.00)\n",
      "Iter 3723 | Time 32.4138(31.6598) | Bit/dim 1.1007(1.0999) | Xent 0.0429(0.0435) | Loss 1.1222(1.1217) | Error 0.0141(0.0136) Steps 440(440.37) | Grad Norm 0.5637(0.3879) | Total Time 10.00(10.00)\n",
      "Iter 3724 | Time 31.7693(31.6631) | Bit/dim 1.1019(1.1000) | Xent 0.0464(0.0436) | Loss 1.1251(1.1218) | Error 0.0154(0.0137) Steps 440(440.36) | Grad Norm 0.6264(0.3950) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0532 | Time 17.6272, Epoch Time 254.1305(250.7868), Bit/dim 1.0948(best: 1.0941), Xent 0.0370, Loss 1.1133, Error 0.0114(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3725 | Time 30.9903(31.6429) | Bit/dim 1.1048(1.1001) | Xent 0.0459(0.0437) | Loss 1.1277(1.1220) | Error 0.0140(0.0137) Steps 440(440.34) | Grad Norm 0.2305(0.3901) | Total Time 10.00(10.00)\n",
      "Iter 3726 | Time 30.4570(31.6073) | Bit/dim 1.0962(1.1000) | Xent 0.0413(0.0436) | Loss 1.1168(1.1218) | Error 0.0132(0.0137) Steps 440(440.33) | Grad Norm 0.5052(0.3936) | Total Time 10.00(10.00)\n",
      "Iter 3727 | Time 31.3378(31.5992) | Bit/dim 1.0981(1.0999) | Xent 0.0500(0.0438) | Loss 1.1231(1.1218) | Error 0.0156(0.0137) Steps 440(440.32) | Grad Norm 0.5748(0.3990) | Total Time 10.00(10.00)\n",
      "Iter 3728 | Time 32.1607(31.6161) | Bit/dim 1.1023(1.1000) | Xent 0.0339(0.0435) | Loss 1.1193(1.1218) | Error 0.0104(0.0136) Steps 440(440.31) | Grad Norm 0.4782(0.4014) | Total Time 10.00(10.00)\n",
      "Iter 3729 | Time 31.5307(31.6135) | Bit/dim 1.0958(1.0999) | Xent 0.0441(0.0435) | Loss 1.1178(1.1216) | Error 0.0136(0.0136) Steps 440(440.31) | Grad Norm 0.3813(0.4008) | Total Time 10.00(10.00)\n",
      "Iter 3730 | Time 32.4197(31.6377) | Bit/dim 1.1031(1.1000) | Xent 0.0461(0.0436) | Loss 1.1261(1.1218) | Error 0.0146(0.0136) Steps 440(440.30) | Grad Norm 0.3281(0.3986) | Total Time 10.00(10.00)\n",
      "Iter 3731 | Time 30.9941(31.6184) | Bit/dim 1.1003(1.1000) | Xent 0.0479(0.0437) | Loss 1.1243(1.1219) | Error 0.0128(0.0136) Steps 440(440.29) | Grad Norm 0.3028(0.3957) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0533 | Time 17.7521, Epoch Time 250.4325(250.7762), Bit/dim 1.0942(best: 1.0941), Xent 0.0317, Loss 1.1101, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3732 | Time 31.3014(31.6089) | Bit/dim 1.0976(1.0999) | Xent 0.0497(0.0439) | Loss 1.1225(1.1219) | Error 0.0155(0.0137) Steps 440(440.28) | Grad Norm 0.6613(0.4037) | Total Time 10.00(10.00)\n",
      "Iter 3733 | Time 31.4238(31.6033) | Bit/dim 1.0941(1.0997) | Xent 0.0454(0.0440) | Loss 1.1168(1.1217) | Error 0.0136(0.0137) Steps 440(440.27) | Grad Norm 0.3519(0.4021) | Total Time 10.00(10.00)\n",
      "Iter 3734 | Time 31.5691(31.6023) | Bit/dim 1.1019(1.0998) | Xent 0.0394(0.0438) | Loss 1.1217(1.1217) | Error 0.0122(0.0136) Steps 440(440.26) | Grad Norm 0.3555(0.4007) | Total Time 10.00(10.00)\n",
      "Iter 3735 | Time 31.4604(31.5981) | Bit/dim 1.1011(1.0999) | Xent 0.0499(0.0440) | Loss 1.1260(1.1219) | Error 0.0154(0.0137) Steps 440(440.25) | Grad Norm 0.2206(0.3953) | Total Time 10.00(10.00)\n",
      "Iter 3736 | Time 31.7653(31.6031) | Bit/dim 1.1014(1.0999) | Xent 0.0396(0.0439) | Loss 1.1212(1.1218) | Error 0.0128(0.0137) Steps 440(440.25) | Grad Norm 0.2333(0.3905) | Total Time 10.00(10.00)\n",
      "Iter 3737 | Time 31.9644(31.6139) | Bit/dim 1.0979(1.0998) | Xent 0.0419(0.0438) | Loss 1.1188(1.1217) | Error 0.0139(0.0137) Steps 440(440.24) | Grad Norm 0.1937(0.3846) | Total Time 10.00(10.00)\n",
      "Iter 3738 | Time 32.0843(31.6280) | Bit/dim 1.1000(1.0998) | Xent 0.0393(0.0437) | Loss 1.1197(1.1217) | Error 0.0125(0.0136) Steps 440(440.23) | Grad Norm 0.5093(0.3883) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0534 | Time 17.7069, Epoch Time 252.1640(250.8178), Bit/dim 1.0945(best: 1.0941), Xent 0.0309, Loss 1.1100, Error 0.0084(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3739 | Time 30.5766(31.5965) | Bit/dim 1.0992(1.0998) | Xent 0.0495(0.0438) | Loss 1.1240(1.1217) | Error 0.0144(0.0137) Steps 440(440.23) | Grad Norm 0.4272(0.3895) | Total Time 10.00(10.00)\n",
      "Iter 3740 | Time 31.9918(31.6083) | Bit/dim 1.1064(1.1000) | Xent 0.0365(0.0436) | Loss 1.1247(1.1218) | Error 0.0121(0.0136) Steps 440(440.22) | Grad Norm 0.3412(0.3880) | Total Time 10.00(10.00)\n",
      "Iter 3741 | Time 32.4413(31.6333) | Bit/dim 1.1012(1.1001) | Xent 0.0394(0.0435) | Loss 1.1209(1.1218) | Error 0.0118(0.0135) Steps 440(440.21) | Grad Norm 0.2123(0.3828) | Total Time 10.00(10.00)\n",
      "Iter 3742 | Time 31.1005(31.6173) | Bit/dim 1.1007(1.1001) | Xent 0.0393(0.0434) | Loss 1.1204(1.1218) | Error 0.0105(0.0135) Steps 440(440.21) | Grad Norm 0.2422(0.3785) | Total Time 10.00(10.00)\n",
      "Iter 3743 | Time 32.1203(31.6324) | Bit/dim 1.0969(1.1000) | Xent 0.0378(0.0432) | Loss 1.1158(1.1216) | Error 0.0116(0.0134) Steps 440(440.20) | Grad Norm 0.2901(0.3759) | Total Time 10.00(10.00)\n",
      "Iter 3744 | Time 30.8848(31.6100) | Bit/dim 1.0952(1.0998) | Xent 0.0505(0.0434) | Loss 1.1205(1.1216) | Error 0.0150(0.0135) Steps 440(440.19) | Grad Norm 0.2906(0.3733) | Total Time 10.00(10.00)\n",
      "Iter 3745 | Time 32.5544(31.6383) | Bit/dim 1.0966(1.0997) | Xent 0.0473(0.0435) | Loss 1.1202(1.1215) | Error 0.0154(0.0135) Steps 440(440.19) | Grad Norm 0.3411(0.3724) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0535 | Time 17.7000, Epoch Time 252.0226(250.8540), Bit/dim 1.0945(best: 1.0941), Xent 0.0340, Loss 1.1115, Error 0.0094(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3746 | Time 31.0354(31.6202) | Bit/dim 1.1005(1.0998) | Xent 0.0476(0.0437) | Loss 1.1243(1.1216) | Error 0.0136(0.0135) Steps 440(440.18) | Grad Norm 0.3277(0.3710) | Total Time 10.00(10.00)\n",
      "Iter 3747 | Time 31.8737(31.6279) | Bit/dim 1.0948(1.0996) | Xent 0.0386(0.0435) | Loss 1.1141(1.1214) | Error 0.0124(0.0135) Steps 446(440.36) | Grad Norm 0.2201(0.3665) | Total Time 10.00(10.00)\n",
      "Iter 3748 | Time 32.8315(31.6640) | Bit/dim 1.0958(1.0995) | Xent 0.0449(0.0436) | Loss 1.1182(1.1213) | Error 0.0135(0.0135) Steps 440(440.35) | Grad Norm 0.2259(0.3623) | Total Time 10.00(10.00)\n",
      "Iter 3749 | Time 31.6669(31.6641) | Bit/dim 1.1020(1.0996) | Xent 0.0358(0.0433) | Loss 1.1199(1.1212) | Error 0.0119(0.0134) Steps 440(440.34) | Grad Norm 0.2685(0.3595) | Total Time 10.00(10.00)\n",
      "Iter 3750 | Time 31.2850(31.6527) | Bit/dim 1.0991(1.0996) | Xent 0.0415(0.0433) | Loss 1.1199(1.1212) | Error 0.0128(0.0134) Steps 440(440.33) | Grad Norm 0.2432(0.3560) | Total Time 10.00(10.00)\n",
      "Iter 3751 | Time 31.2442(31.6404) | Bit/dim 1.1025(1.0997) | Xent 0.0436(0.0433) | Loss 1.1243(1.1213) | Error 0.0119(0.0134) Steps 440(440.32) | Grad Norm 0.2382(0.3524) | Total Time 10.00(10.00)\n",
      "Iter 3752 | Time 33.6653(31.7012) | Bit/dim 1.1037(1.0998) | Xent 0.0415(0.0432) | Loss 1.1244(1.1214) | Error 0.0134(0.0134) Steps 446(440.49) | Grad Norm 0.4337(0.3549) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0536 | Time 17.9138, Epoch Time 254.1685(250.9534), Bit/dim 1.0940(best: 1.0941), Xent 0.0343, Loss 1.1111, Error 0.0113(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3753 | Time 30.6392(31.6693) | Bit/dim 1.0993(1.0998) | Xent 0.0444(0.0433) | Loss 1.1214(1.1214) | Error 0.0154(0.0134) Steps 440(440.47) | Grad Norm 0.3850(0.3558) | Total Time 10.00(10.00)\n",
      "Iter 3754 | Time 31.3056(31.6584) | Bit/dim 1.0993(1.0997) | Xent 0.0466(0.0434) | Loss 1.1226(1.1214) | Error 0.0139(0.0134) Steps 440(440.46) | Grad Norm 0.3444(0.3554) | Total Time 10.00(10.00)\n",
      "Iter 3755 | Time 31.8329(31.6636) | Bit/dim 1.0978(1.0997) | Xent 0.0458(0.0434) | Loss 1.1207(1.1214) | Error 0.0116(0.0134) Steps 440(440.44) | Grad Norm 0.4450(0.3581) | Total Time 10.00(10.00)\n",
      "Iter 3756 | Time 31.2897(31.6524) | Bit/dim 1.1015(1.0997) | Xent 0.0420(0.0434) | Loss 1.1225(1.1214) | Error 0.0142(0.0134) Steps 440(440.43) | Grad Norm 0.2974(0.3563) | Total Time 10.00(10.00)\n",
      "Iter 3757 | Time 31.1237(31.6366) | Bit/dim 1.1004(1.0998) | Xent 0.0458(0.0435) | Loss 1.1233(1.1215) | Error 0.0126(0.0134) Steps 440(440.42) | Grad Norm 0.2976(0.3545) | Total Time 10.00(10.00)\n",
      "Iter 3758 | Time 31.1517(31.6220) | Bit/dim 1.1012(1.0998) | Xent 0.0458(0.0435) | Loss 1.1241(1.1216) | Error 0.0124(0.0134) Steps 440(440.40) | Grad Norm 0.3633(0.3548) | Total Time 10.00(10.00)\n",
      "Iter 3759 | Time 30.9916(31.6031) | Bit/dim 1.0977(1.0997) | Xent 0.0451(0.0436) | Loss 1.1203(1.1215) | Error 0.0140(0.0134) Steps 440(440.39) | Grad Norm 0.3808(0.3556) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0537 | Time 17.7971, Epoch Time 249.1466(250.8992), Bit/dim 1.0948(best: 1.0940), Xent 0.0326, Loss 1.1111, Error 0.0090(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3760 | Time 33.0062(31.6452) | Bit/dim 1.0991(1.0997) | Xent 0.0422(0.0435) | Loss 1.1202(1.1215) | Error 0.0124(0.0133) Steps 446(440.56) | Grad Norm 0.2280(0.3518) | Total Time 10.00(10.00)\n",
      "Iter 3761 | Time 31.3849(31.6374) | Bit/dim 1.1033(1.0998) | Xent 0.0416(0.0435) | Loss 1.1241(1.1216) | Error 0.0135(0.0133) Steps 440(440.54) | Grad Norm 0.5145(0.3566) | Total Time 10.00(10.00)\n",
      "Iter 3762 | Time 31.4340(31.6313) | Bit/dim 1.0988(1.0998) | Xent 0.0435(0.0435) | Loss 1.1206(1.1215) | Error 0.0122(0.0133) Steps 440(440.53) | Grad Norm 0.2518(0.3535) | Total Time 10.00(10.00)\n",
      "Iter 3763 | Time 31.5274(31.6282) | Bit/dim 1.0969(1.0997) | Xent 0.0489(0.0436) | Loss 1.1214(1.1215) | Error 0.0139(0.0133) Steps 440(440.51) | Grad Norm 0.4672(0.3569) | Total Time 10.00(10.00)\n",
      "Iter 3764 | Time 31.0442(31.6106) | Bit/dim 1.0969(1.0996) | Xent 0.0384(0.0435) | Loss 1.1161(1.1214) | Error 0.0126(0.0133) Steps 440(440.50) | Grad Norm 0.4241(0.3589) | Total Time 10.00(10.00)\n",
      "Iter 3765 | Time 32.1586(31.6271) | Bit/dim 1.1052(1.0998) | Xent 0.0427(0.0435) | Loss 1.1266(1.1215) | Error 0.0142(0.0133) Steps 440(440.48) | Grad Norm 0.3682(0.3592) | Total Time 10.00(10.00)\n",
      "Iter 3766 | Time 32.0139(31.6387) | Bit/dim 1.0974(1.0997) | Xent 0.0428(0.0434) | Loss 1.1188(1.1214) | Error 0.0126(0.0133) Steps 440(440.47) | Grad Norm 0.4896(0.3631) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0538 | Time 17.6996, Epoch Time 253.3138(250.9716), Bit/dim 1.0945(best: 1.0940), Xent 0.0308, Loss 1.1099, Error 0.0098(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3767 | Time 32.5694(31.6666) | Bit/dim 1.1054(1.0999) | Xent 0.0366(0.0432) | Loss 1.1236(1.1215) | Error 0.0104(0.0132) Steps 446(440.63) | Grad Norm 0.2713(0.3604) | Total Time 10.00(10.00)\n",
      "Iter 3768 | Time 31.0549(31.6483) | Bit/dim 1.1005(1.0999) | Xent 0.0479(0.0434) | Loss 1.1244(1.1216) | Error 0.0142(0.0133) Steps 440(440.61) | Grad Norm 0.4656(0.3635) | Total Time 10.00(10.00)\n",
      "Iter 3769 | Time 33.0758(31.6911) | Bit/dim 1.0966(1.0998) | Xent 0.0393(0.0433) | Loss 1.1163(1.1214) | Error 0.0115(0.0132) Steps 446(440.78) | Grad Norm 0.2849(0.3612) | Total Time 10.00(10.00)\n",
      "Iter 3770 | Time 31.2405(31.6776) | Bit/dim 1.1025(1.0999) | Xent 0.0432(0.0432) | Loss 1.1241(1.1215) | Error 0.0136(0.0132) Steps 440(440.75) | Grad Norm 0.3452(0.3607) | Total Time 10.00(10.00)\n",
      "Iter 3771 | Time 31.5361(31.6733) | Bit/dim 1.0972(1.0998) | Xent 0.0431(0.0432) | Loss 1.1187(1.1214) | Error 0.0144(0.0133) Steps 440(440.73) | Grad Norm 0.2562(0.3575) | Total Time 10.00(10.00)\n",
      "Iter 3772 | Time 31.5151(31.6686) | Bit/dim 1.0956(1.0997) | Xent 0.0364(0.0430) | Loss 1.1138(1.1212) | Error 0.0110(0.0132) Steps 440(440.71) | Grad Norm 0.2791(0.3552) | Total Time 10.00(10.00)\n",
      "Iter 3773 | Time 32.1893(31.6842) | Bit/dim 1.1019(1.0997) | Xent 0.0432(0.0430) | Loss 1.1236(1.1213) | Error 0.0140(0.0132) Steps 446(440.87) | Grad Norm 0.2239(0.3513) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0539 | Time 17.8439, Epoch Time 253.7454(251.0549), Bit/dim 1.0940(best: 1.0940), Xent 0.0308, Loss 1.1094, Error 0.0091(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3774 | Time 31.2734(31.6719) | Bit/dim 1.0993(1.0997) | Xent 0.0443(0.0431) | Loss 1.1214(1.1213) | Error 0.0146(0.0133) Steps 440(440.84) | Grad Norm 0.2622(0.3486) | Total Time 10.00(10.00)\n",
      "Iter 3775 | Time 31.9501(31.6802) | Bit/dim 1.0998(1.0997) | Xent 0.0415(0.0430) | Loss 1.1206(1.1213) | Error 0.0130(0.0132) Steps 440(440.82) | Grad Norm 0.1934(0.3439) | Total Time 10.00(10.00)\n",
      "Iter 3776 | Time 31.0193(31.6604) | Bit/dim 1.1049(1.0999) | Xent 0.0452(0.0431) | Loss 1.1275(1.1214) | Error 0.0120(0.0132) Steps 440(440.79) | Grad Norm 0.3231(0.3433) | Total Time 10.00(10.00)\n",
      "Iter 3777 | Time 31.6180(31.6591) | Bit/dim 1.1005(1.0999) | Xent 0.0392(0.0430) | Loss 1.1201(1.1214) | Error 0.0136(0.0132) Steps 440(440.77) | Grad Norm 0.3676(0.3440) | Total Time 10.00(10.00)\n",
      "Iter 3778 | Time 32.4533(31.6829) | Bit/dim 1.0993(1.0999) | Xent 0.0436(0.0430) | Loss 1.1212(1.1214) | Error 0.0141(0.0132) Steps 440(440.74) | Grad Norm 0.3669(0.3447) | Total Time 10.00(10.00)\n",
      "Iter 3779 | Time 31.3682(31.6735) | Bit/dim 1.0990(1.0999) | Xent 0.0462(0.0431) | Loss 1.1221(1.1214) | Error 0.0151(0.0133) Steps 440(440.72) | Grad Norm 0.3748(0.3456) | Total Time 10.00(10.00)\n",
      "Iter 3780 | Time 30.9039(31.6504) | Bit/dim 1.0968(1.0998) | Xent 0.0479(0.0432) | Loss 1.1208(1.1214) | Error 0.0136(0.0133) Steps 440(440.70) | Grad Norm 0.3018(0.3443) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0540 | Time 17.7911, Epoch Time 251.2234(251.0599), Bit/dim 1.0941(best: 1.0940), Xent 0.0309, Loss 1.1095, Error 0.0103(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3781 | Time 31.0779(31.6332) | Bit/dim 1.1015(1.0998) | Xent 0.0457(0.0433) | Loss 1.1244(1.1215) | Error 0.0134(0.0133) Steps 440(440.68) | Grad Norm 0.4775(0.3483) | Total Time 10.00(10.00)\n",
      "Iter 3782 | Time 31.1946(31.6201) | Bit/dim 1.1022(1.0999) | Xent 0.0418(0.0433) | Loss 1.1232(1.1215) | Error 0.0136(0.0133) Steps 440(440.66) | Grad Norm 0.3376(0.3480) | Total Time 10.00(10.00)\n",
      "Iter 3783 | Time 32.0039(31.6316) | Bit/dim 1.0953(1.0998) | Xent 0.0435(0.0433) | Loss 1.1170(1.1214) | Error 0.0140(0.0133) Steps 446(440.82) | Grad Norm 0.3071(0.3468) | Total Time 10.00(10.00)\n",
      "Iter 3784 | Time 31.9287(31.6405) | Bit/dim 1.1000(1.0998) | Xent 0.0370(0.0431) | Loss 1.1184(1.1213) | Error 0.0108(0.0133) Steps 440(440.79) | Grad Norm 0.4276(0.3492) | Total Time 10.00(10.00)\n",
      "Iter 3785 | Time 31.9042(31.6484) | Bit/dim 1.0961(1.0997) | Xent 0.0399(0.0430) | Loss 1.1161(1.1212) | Error 0.0119(0.0132) Steps 440(440.77) | Grad Norm 0.2255(0.3455) | Total Time 10.00(10.00)\n",
      "Iter 3786 | Time 31.3483(31.6394) | Bit/dim 1.1018(1.0997) | Xent 0.0472(0.0431) | Loss 1.1254(1.1213) | Error 0.0130(0.0132) Steps 440(440.75) | Grad Norm 0.4361(0.3482) | Total Time 10.00(10.00)\n",
      "Iter 3787 | Time 32.1540(31.6549) | Bit/dim 1.0961(1.0996) | Xent 0.0455(0.0432) | Loss 1.1188(1.1212) | Error 0.0144(0.0133) Steps 446(440.91) | Grad Norm 0.2467(0.3451) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0541 | Time 17.6910, Epoch Time 252.3298(251.0980), Bit/dim 1.0942(best: 1.0940), Xent 0.0318, Loss 1.1101, Error 0.0090(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3788 | Time 31.0372(31.6363) | Bit/dim 1.1035(1.0997) | Xent 0.0375(0.0430) | Loss 1.1222(1.1212) | Error 0.0120(0.0132) Steps 440(440.88) | Grad Norm 0.3067(0.3440) | Total Time 10.00(10.00)\n",
      "Iter 3789 | Time 32.2199(31.6538) | Bit/dim 1.0944(1.0996) | Xent 0.0463(0.0431) | Loss 1.1175(1.1211) | Error 0.0141(0.0132) Steps 440(440.85) | Grad Norm 0.3045(0.3428) | Total Time 10.00(10.00)\n",
      "Iter 3790 | Time 32.0958(31.6671) | Bit/dim 1.0979(1.0995) | Xent 0.0370(0.0429) | Loss 1.1164(1.1210) | Error 0.0118(0.0132) Steps 440(440.83) | Grad Norm 0.2371(0.3396) | Total Time 10.00(10.00)\n",
      "Iter 3791 | Time 31.6963(31.6680) | Bit/dim 1.1017(1.0996) | Xent 0.0448(0.0430) | Loss 1.1241(1.1211) | Error 0.0142(0.0132) Steps 440(440.80) | Grad Norm 0.4726(0.3436) | Total Time 10.00(10.00)\n",
      "Iter 3792 | Time 31.1022(31.6510) | Bit/dim 1.1001(1.0996) | Xent 0.0442(0.0430) | Loss 1.1222(1.1211) | Error 0.0124(0.0132) Steps 440(440.78) | Grad Norm 0.3186(0.3429) | Total Time 10.00(10.00)\n",
      "Iter 3793 | Time 31.3357(31.6415) | Bit/dim 1.1002(1.0996) | Xent 0.0425(0.0430) | Loss 1.1215(1.1211) | Error 0.0124(0.0132) Steps 440(440.75) | Grad Norm 0.4690(0.3467) | Total Time 10.00(10.00)\n",
      "Iter 3794 | Time 31.1581(31.6270) | Bit/dim 1.0999(1.0996) | Xent 0.0442(0.0430) | Loss 1.1220(1.1212) | Error 0.0151(0.0132) Steps 440(440.73) | Grad Norm 0.2114(0.3426) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0542 | Time 17.9593, Epoch Time 251.1869(251.1007), Bit/dim 1.0940(best: 1.0940), Xent 0.0355, Loss 1.1117, Error 0.0114(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3795 | Time 31.2056(31.6144) | Bit/dim 1.0979(1.0996) | Xent 0.0509(0.0433) | Loss 1.1233(1.1212) | Error 0.0175(0.0134) Steps 440(440.71) | Grad Norm 0.2607(0.3401) | Total Time 10.00(10.00)\n",
      "Iter 3796 | Time 31.9541(31.6246) | Bit/dim 1.0964(1.0995) | Xent 0.0406(0.0432) | Loss 1.1167(1.1211) | Error 0.0129(0.0134) Steps 446(440.87) | Grad Norm 0.3241(0.3397) | Total Time 10.00(10.00)\n",
      "Iter 3797 | Time 33.0247(31.6666) | Bit/dim 1.0981(1.0994) | Xent 0.0364(0.0430) | Loss 1.1163(1.1209) | Error 0.0119(0.0133) Steps 440(440.84) | Grad Norm 0.2147(0.3359) | Total Time 10.00(10.00)\n",
      "Iter 3798 | Time 31.0873(31.6492) | Bit/dim 1.1047(1.0996) | Xent 0.0401(0.0429) | Loss 1.1247(1.1210) | Error 0.0108(0.0132) Steps 440(440.82) | Grad Norm 0.2103(0.3321) | Total Time 10.00(10.00)\n",
      "Iter 3799 | Time 32.5330(31.6757) | Bit/dim 1.1021(1.0997) | Xent 0.0433(0.0429) | Loss 1.1238(1.1211) | Error 0.0144(0.0133) Steps 440(440.79) | Grad Norm 0.2597(0.3300) | Total Time 10.00(10.00)\n",
      "Iter 3800 | Time 31.8522(31.6810) | Bit/dim 1.0982(1.0996) | Xent 0.0470(0.0430) | Loss 1.1217(1.1211) | Error 0.0131(0.0133) Steps 440(440.77) | Grad Norm 0.2401(0.3273) | Total Time 10.00(10.00)\n",
      "Iter 3801 | Time 32.4435(31.7039) | Bit/dim 1.1034(1.0997) | Xent 0.0426(0.0430) | Loss 1.1246(1.1213) | Error 0.0135(0.0133) Steps 440(440.75) | Grad Norm 0.2666(0.3255) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0543 | Time 17.5867, Epoch Time 254.6627(251.2075), Bit/dim 1.0942(best: 1.0940), Xent 0.0328, Loss 1.1106, Error 0.0093(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3802 | Time 32.6290(31.7316) | Bit/dim 1.0938(1.0996) | Xent 0.0357(0.0428) | Loss 1.1116(1.1210) | Error 0.0118(0.0132) Steps 440(440.72) | Grad Norm 0.2386(0.3228) | Total Time 10.00(10.00)\n",
      "Iter 3803 | Time 31.1409(31.7139) | Bit/dim 1.1005(1.0996) | Xent 0.0403(0.0427) | Loss 1.1206(1.1210) | Error 0.0120(0.0132) Steps 440(440.70) | Grad Norm 0.2625(0.3210) | Total Time 10.00(10.00)\n",
      "Iter 3804 | Time 31.9875(31.7221) | Bit/dim 1.1028(1.0997) | Xent 0.0483(0.0429) | Loss 1.1270(1.1211) | Error 0.0148(0.0132) Steps 440(440.68) | Grad Norm 0.2802(0.3198) | Total Time 10.00(10.00)\n",
      "Iter 3805 | Time 31.8512(31.7260) | Bit/dim 1.1007(1.0997) | Xent 0.0533(0.0432) | Loss 1.1273(1.1213) | Error 0.0168(0.0133) Steps 440(440.66) | Grad Norm 0.3692(0.3213) | Total Time 10.00(10.00)\n",
      "Iter 3806 | Time 32.6053(31.7524) | Bit/dim 1.0964(1.0996) | Xent 0.0345(0.0430) | Loss 1.1137(1.1211) | Error 0.0109(0.0133) Steps 440(440.64) | Grad Norm 0.3061(0.3208) | Total Time 10.00(10.00)\n",
      "Iter 3807 | Time 30.7575(31.7225) | Bit/dim 1.1047(1.0998) | Xent 0.0454(0.0430) | Loss 1.1274(1.1213) | Error 0.0126(0.0132) Steps 440(440.62) | Grad Norm 0.4442(0.3245) | Total Time 10.00(10.00)\n",
      "Iter 3808 | Time 31.0178(31.7014) | Bit/dim 1.0991(1.0997) | Xent 0.0481(0.0432) | Loss 1.1231(1.1213) | Error 0.0158(0.0133) Steps 440(440.60) | Grad Norm 0.4671(0.3288) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0544 | Time 17.8894, Epoch Time 252.7363(251.2534), Bit/dim 1.0941(best: 1.0940), Xent 0.0330, Loss 1.1106, Error 0.0104(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3809 | Time 31.9771(31.7097) | Bit/dim 1.0974(1.0997) | Xent 0.0425(0.0432) | Loss 1.1187(1.1213) | Error 0.0134(0.0133) Steps 440(440.58) | Grad Norm 0.3576(0.3297) | Total Time 10.00(10.00)\n",
      "Iter 3810 | Time 33.1924(31.7541) | Bit/dim 1.1033(1.0998) | Xent 0.0398(0.0431) | Loss 1.1232(1.1213) | Error 0.0122(0.0133) Steps 440(440.57) | Grad Norm 0.4368(0.3329) | Total Time 10.00(10.00)\n",
      "Iter 3811 | Time 32.1448(31.7659) | Bit/dim 1.1018(1.0998) | Xent 0.0394(0.0430) | Loss 1.1215(1.1213) | Error 0.0119(0.0132) Steps 440(440.55) | Grad Norm 0.3716(0.3341) | Total Time 10.00(10.00)\n",
      "Iter 3812 | Time 32.0425(31.7742) | Bit/dim 1.0969(1.0998) | Xent 0.0379(0.0428) | Loss 1.1158(1.1212) | Error 0.0116(0.0132) Steps 440(440.53) | Grad Norm 0.5766(0.3413) | Total Time 10.00(10.00)\n",
      "Iter 3813 | Time 32.1881(31.7866) | Bit/dim 1.0999(1.0998) | Xent 0.0438(0.0428) | Loss 1.1218(1.1212) | Error 0.0141(0.0132) Steps 440(440.52) | Grad Norm 0.2521(0.3387) | Total Time 10.00(10.00)\n",
      "Iter 3814 | Time 31.8407(31.7882) | Bit/dim 1.0965(1.0997) | Xent 0.0601(0.0433) | Loss 1.1265(1.1213) | Error 0.0170(0.0133) Steps 440(440.50) | Grad Norm 0.4070(0.3407) | Total Time 10.00(10.00)\n",
      "Iter 3815 | Time 30.8834(31.7611) | Bit/dim 1.1011(1.0997) | Xent 0.0433(0.0433) | Loss 1.1228(1.1214) | Error 0.0121(0.0133) Steps 440(440.49) | Grad Norm 0.4272(0.3433) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0545 | Time 17.9458, Epoch Time 254.6882(251.3564), Bit/dim 1.0946(best: 1.0940), Xent 0.0312, Loss 1.1102, Error 0.0097(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3816 | Time 31.3291(31.7481) | Bit/dim 1.0992(1.0997) | Xent 0.0501(0.0435) | Loss 1.1242(1.1215) | Error 0.0160(0.0134) Steps 440(440.47) | Grad Norm 0.3349(0.3430) | Total Time 10.00(10.00)\n",
      "Iter 3817 | Time 32.7290(31.7775) | Bit/dim 1.0993(1.0997) | Xent 0.0385(0.0434) | Loss 1.1185(1.1214) | Error 0.0125(0.0134) Steps 446(440.64) | Grad Norm 0.4224(0.3454) | Total Time 10.00(10.00)\n",
      "Iter 3818 | Time 32.2529(31.7918) | Bit/dim 1.0969(1.0996) | Xent 0.0403(0.0433) | Loss 1.1171(1.1212) | Error 0.0141(0.0134) Steps 440(440.62) | Grad Norm 0.2631(0.3430) | Total Time 10.00(10.00)\n",
      "Iter 3819 | Time 31.2170(31.7745) | Bit/dim 1.1022(1.0997) | Xent 0.0421(0.0433) | Loss 1.1232(1.1213) | Error 0.0122(0.0133) Steps 440(440.60) | Grad Norm 0.2049(0.3388) | Total Time 10.00(10.00)\n",
      "Iter 3820 | Time 33.4203(31.8239) | Bit/dim 1.0925(1.0995) | Xent 0.0436(0.0433) | Loss 1.1143(1.1211) | Error 0.0155(0.0134) Steps 440(440.58) | Grad Norm 0.4883(0.3433) | Total Time 10.00(10.00)\n",
      "Iter 3821 | Time 31.2928(31.8080) | Bit/dim 1.1002(1.0995) | Xent 0.0437(0.0433) | Loss 1.1220(1.1211) | Error 0.0141(0.0134) Steps 440(440.56) | Grad Norm 0.3783(0.3443) | Total Time 10.00(10.00)\n",
      "Iter 3822 | Time 32.2401(31.8209) | Bit/dim 1.1042(1.0996) | Xent 0.0361(0.0431) | Loss 1.1222(1.1212) | Error 0.0111(0.0134) Steps 440(440.55) | Grad Norm 0.3540(0.3446) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0546 | Time 17.7111, Epoch Time 254.8256(251.4605), Bit/dim 1.0939(best: 1.0940), Xent 0.0305, Loss 1.1091, Error 0.0096(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3823 | Time 32.6576(31.8460) | Bit/dim 1.1014(1.0997) | Xent 0.0420(0.0430) | Loss 1.1224(1.1212) | Error 0.0134(0.0134) Steps 440(440.53) | Grad Norm 0.3469(0.3447) | Total Time 10.00(10.00)\n",
      "Iter 3824 | Time 30.8677(31.8167) | Bit/dim 1.0989(1.0996) | Xent 0.0418(0.0430) | Loss 1.1198(1.1212) | Error 0.0139(0.0134) Steps 440(440.52) | Grad Norm 0.3114(0.3437) | Total Time 10.00(10.00)\n",
      "Iter 3825 | Time 32.2404(31.8294) | Bit/dim 1.0988(1.0996) | Xent 0.0470(0.0431) | Loss 1.1223(1.1212) | Error 0.0125(0.0134) Steps 446(440.68) | Grad Norm 0.3680(0.3444) | Total Time 10.00(10.00)\n",
      "Iter 3826 | Time 31.7942(31.8284) | Bit/dim 1.0919(1.0994) | Xent 0.0373(0.0429) | Loss 1.1105(1.1209) | Error 0.0112(0.0133) Steps 446(440.84) | Grad Norm 0.3288(0.3440) | Total Time 10.00(10.00)\n",
      "Iter 3827 | Time 32.4170(31.8460) | Bit/dim 1.0968(1.0993) | Xent 0.0435(0.0430) | Loss 1.1186(1.1208) | Error 0.0132(0.0133) Steps 446(440.99) | Grad Norm 0.2993(0.3426) | Total Time 10.00(10.00)\n",
      "Iter 3828 | Time 31.8255(31.8454) | Bit/dim 1.1025(1.0994) | Xent 0.0374(0.0428) | Loss 1.1212(1.1208) | Error 0.0111(0.0132) Steps 440(440.96) | Grad Norm 0.4707(0.3465) | Total Time 10.00(10.00)\n",
      "Iter 3829 | Time 31.8465(31.8454) | Bit/dim 1.0999(1.0994) | Xent 0.0513(0.0431) | Loss 1.1255(1.1210) | Error 0.0155(0.0133) Steps 440(440.94) | Grad Norm 0.5746(0.3533) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0547 | Time 17.6360, Epoch Time 254.0412(251.5379), Bit/dim 1.0933(best: 1.0939), Xent 0.0344, Loss 1.1105, Error 0.0112(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3830 | Time 32.4078(31.8623) | Bit/dim 1.0999(1.0994) | Xent 0.0420(0.0430) | Loss 1.1209(1.1209) | Error 0.0125(0.0133) Steps 440(440.91) | Grad Norm 0.5026(0.3578) | Total Time 10.00(10.00)\n",
      "Iter 3831 | Time 31.0485(31.8379) | Bit/dim 1.1019(1.0995) | Xent 0.0509(0.0433) | Loss 1.1273(1.1211) | Error 0.0155(0.0133) Steps 440(440.88) | Grad Norm 0.5465(0.3635) | Total Time 10.00(10.00)\n",
      "Iter 3832 | Time 30.8166(31.8072) | Bit/dim 1.1001(1.0995) | Xent 0.0409(0.0432) | Loss 1.1206(1.1211) | Error 0.0141(0.0134) Steps 440(440.85) | Grad Norm 0.4226(0.3652) | Total Time 10.00(10.00)\n",
      "Iter 3833 | Time 32.2612(31.8209) | Bit/dim 1.0928(1.0993) | Xent 0.0443(0.0432) | Loss 1.1150(1.1209) | Error 0.0136(0.0134) Steps 440(440.83) | Grad Norm 0.5865(0.3719) | Total Time 10.00(10.00)\n",
      "Iter 3834 | Time 31.2591(31.8040) | Bit/dim 1.1013(1.0994) | Xent 0.0500(0.0434) | Loss 1.1263(1.1211) | Error 0.0160(0.0134) Steps 440(440.80) | Grad Norm 0.3642(0.3716) | Total Time 10.00(10.00)\n",
      "Iter 3835 | Time 32.0318(31.8108) | Bit/dim 1.1003(1.0994) | Xent 0.0410(0.0434) | Loss 1.1208(1.1211) | Error 0.0135(0.0134) Steps 440(440.78) | Grad Norm 0.3349(0.3705) | Total Time 10.00(10.00)\n",
      "Iter 3836 | Time 32.3435(31.8268) | Bit/dim 1.0964(1.0993) | Xent 0.0474(0.0435) | Loss 1.1201(1.1211) | Error 0.0145(0.0135) Steps 440(440.76) | Grad Norm 0.4038(0.3715) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0548 | Time 17.8085, Epoch Time 252.5532(251.5684), Bit/dim 1.0939(best: 1.0933), Xent 0.0336, Loss 1.1108, Error 0.0101(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3837 | Time 32.2846(31.8406) | Bit/dim 1.0974(1.0993) | Xent 0.0371(0.0433) | Loss 1.1160(1.1209) | Error 0.0112(0.0134) Steps 446(440.91) | Grad Norm 0.5245(0.3761) | Total Time 10.00(10.00)\n",
      "Iter 3838 | Time 32.0343(31.8464) | Bit/dim 1.0986(1.0992) | Xent 0.0371(0.0431) | Loss 1.1172(1.1208) | Error 0.0124(0.0134) Steps 440(440.89) | Grad Norm 0.3201(0.3744) | Total Time 10.00(10.00)\n",
      "Iter 3839 | Time 31.0343(31.8220) | Bit/dim 1.1007(1.0993) | Xent 0.0429(0.0431) | Loss 1.1222(1.1208) | Error 0.0140(0.0134) Steps 440(440.86) | Grad Norm 0.8484(0.3887) | Total Time 10.00(10.00)\n",
      "Iter 3840 | Time 30.8958(31.7942) | Bit/dim 1.1041(1.0994) | Xent 0.0360(0.0429) | Loss 1.1221(1.1209) | Error 0.0108(0.0133) Steps 440(440.83) | Grad Norm 0.3053(0.3862) | Total Time 10.00(10.00)\n",
      "Iter 3841 | Time 31.1730(31.7756) | Bit/dim 1.1021(1.0995) | Xent 0.0445(0.0429) | Loss 1.1243(1.1210) | Error 0.0140(0.0133) Steps 440(440.81) | Grad Norm 0.5932(0.3924) | Total Time 10.00(10.00)\n",
      "Iter 3842 | Time 31.6604(31.7721) | Bit/dim 1.0974(1.0995) | Xent 0.0472(0.0431) | Loss 1.1210(1.1210) | Error 0.0152(0.0134) Steps 440(440.78) | Grad Norm 0.3790(0.3920) | Total Time 10.00(10.00)\n",
      "Iter 3843 | Time 31.3082(31.7582) | Bit/dim 1.0953(1.0993) | Xent 0.0414(0.0430) | Loss 1.1160(1.1208) | Error 0.0130(0.0134) Steps 440(440.76) | Grad Norm 0.3785(0.3916) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0549 | Time 17.5687, Epoch Time 250.5858(251.5389), Bit/dim 1.0927(best: 1.0933), Xent 0.0334, Loss 1.1094, Error 0.0102(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3844 | Time 31.2182(31.7420) | Bit/dim 1.1024(1.0994) | Xent 0.0434(0.0430) | Loss 1.1240(1.1209) | Error 0.0141(0.0134) Steps 440(440.74) | Grad Norm 0.5339(0.3958) | Total Time 10.00(10.00)\n",
      "Iter 3845 | Time 32.0217(31.7504) | Bit/dim 1.1007(1.0995) | Xent 0.0436(0.0430) | Loss 1.1225(1.1210) | Error 0.0126(0.0134) Steps 440(440.72) | Grad Norm 0.2116(0.3903) | Total Time 10.00(10.00)\n",
      "Iter 3846 | Time 32.1228(31.7616) | Bit/dim 1.1010(1.0995) | Xent 0.0457(0.0431) | Loss 1.1239(1.1211) | Error 0.0134(0.0134) Steps 440(440.69) | Grad Norm 0.6427(0.3979) | Total Time 10.00(10.00)\n",
      "Iter 3847 | Time 32.3313(31.7787) | Bit/dim 1.1001(1.0995) | Xent 0.0381(0.0430) | Loss 1.1191(1.1210) | Error 0.0134(0.0134) Steps 440(440.67) | Grad Norm 0.6703(0.4060) | Total Time 10.00(10.00)\n",
      "Iter 3848 | Time 31.8526(31.7809) | Bit/dim 1.0966(1.0994) | Xent 0.0432(0.0430) | Loss 1.1182(1.1209) | Error 0.0121(0.0133) Steps 440(440.65) | Grad Norm 0.4402(0.4071) | Total Time 10.00(10.00)\n",
      "Iter 3849 | Time 31.7951(31.7813) | Bit/dim 1.0965(1.0993) | Xent 0.0361(0.0428) | Loss 1.1145(1.1207) | Error 0.0111(0.0133) Steps 440(440.63) | Grad Norm 0.9807(0.4243) | Total Time 10.00(10.00)\n",
      "Iter 3850 | Time 31.7741(31.7811) | Bit/dim 1.0991(1.0993) | Xent 0.0475(0.0429) | Loss 1.1229(1.1208) | Error 0.0145(0.0133) Steps 440(440.61) | Grad Norm 0.4489(0.4250) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0550 | Time 17.6120, Epoch Time 253.0036(251.5829), Bit/dim 1.0938(best: 1.0927), Xent 0.0345, Loss 1.1111, Error 0.0107(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3851 | Time 31.0016(31.7577) | Bit/dim 1.0996(1.0993) | Xent 0.0392(0.0428) | Loss 1.1192(1.1207) | Error 0.0130(0.0133) Steps 440(440.60) | Grad Norm 0.8154(0.4367) | Total Time 10.00(10.00)\n",
      "Iter 3852 | Time 32.3712(31.7761) | Bit/dim 1.1006(1.0994) | Xent 0.0414(0.0428) | Loss 1.1213(1.1208) | Error 0.0136(0.0133) Steps 440(440.58) | Grad Norm 0.8060(0.4478) | Total Time 10.00(10.00)\n",
      "Iter 3853 | Time 32.4409(31.7961) | Bit/dim 1.0954(1.0993) | Xent 0.0415(0.0427) | Loss 1.1161(1.1206) | Error 0.0132(0.0133) Steps 440(440.56) | Grad Norm 0.5070(0.4496) | Total Time 10.00(10.00)\n",
      "Iter 3854 | Time 30.8971(31.7691) | Bit/dim 1.1015(1.0993) | Xent 0.0483(0.0429) | Loss 1.1257(1.1208) | Error 0.0148(0.0134) Steps 440(440.54) | Grad Norm 1.0000(0.4661) | Total Time 10.00(10.00)\n",
      "Iter 3855 | Time 30.7089(31.7373) | Bit/dim 1.1013(1.0994) | Xent 0.0466(0.0430) | Loss 1.1245(1.1209) | Error 0.0138(0.0134) Steps 440(440.53) | Grad Norm 0.3081(0.4614) | Total Time 10.00(10.00)\n",
      "Iter 3856 | Time 31.4060(31.7273) | Bit/dim 1.0980(1.0993) | Xent 0.0386(0.0429) | Loss 1.1173(1.1208) | Error 0.0112(0.0133) Steps 440(440.51) | Grad Norm 0.8968(0.4744) | Total Time 10.00(10.00)\n",
      "Iter 3857 | Time 32.5317(31.7515) | Bit/dim 1.0990(1.0993) | Xent 0.0456(0.0429) | Loss 1.1218(1.1208) | Error 0.0136(0.0133) Steps 440(440.50) | Grad Norm 0.3455(0.4706) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0551 | Time 17.8951, Epoch Time 252.2685(251.6034), Bit/dim 1.0933(best: 1.0927), Xent 0.0333, Loss 1.1099, Error 0.0101(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3858 | Time 31.9628(31.7578) | Bit/dim 1.1021(1.0994) | Xent 0.0456(0.0430) | Loss 1.1249(1.1209) | Error 0.0159(0.0134) Steps 440(440.48) | Grad Norm 0.6175(0.4750) | Total Time 10.00(10.00)\n",
      "Iter 3859 | Time 31.3902(31.7468) | Bit/dim 1.0944(1.0993) | Xent 0.0446(0.0431) | Loss 1.1167(1.1208) | Error 0.0139(0.0134) Steps 440(440.47) | Grad Norm 0.5930(0.4785) | Total Time 10.00(10.00)\n",
      "Iter 3860 | Time 32.0914(31.7571) | Bit/dim 1.0992(1.0993) | Xent 0.0409(0.0430) | Loss 1.1196(1.1208) | Error 0.0141(0.0134) Steps 446(440.63) | Grad Norm 0.4616(0.4780) | Total Time 10.00(10.00)\n",
      "Iter 3861 | Time 32.2152(31.7709) | Bit/dim 1.0973(1.0992) | Xent 0.0486(0.0432) | Loss 1.1216(1.1208) | Error 0.0142(0.0135) Steps 440(440.61) | Grad Norm 0.6135(0.4821) | Total Time 10.00(10.00)\n",
      "Iter 3862 | Time 31.8618(31.7736) | Bit/dim 1.1027(1.0993) | Xent 0.0442(0.0432) | Loss 1.1248(1.1209) | Error 0.0122(0.0134) Steps 440(440.60) | Grad Norm 0.3031(0.4767) | Total Time 10.00(10.00)\n",
      "Iter 3863 | Time 32.0696(31.7825) | Bit/dim 1.0969(1.0992) | Xent 0.0390(0.0431) | Loss 1.1164(1.1208) | Error 0.0111(0.0133) Steps 440(440.58) | Grad Norm 0.6575(0.4821) | Total Time 10.00(10.00)\n",
      "Iter 3864 | Time 32.2529(31.7966) | Bit/dim 1.1020(1.0993) | Xent 0.0397(0.0430) | Loss 1.1218(1.1208) | Error 0.0132(0.0133) Steps 440(440.56) | Grad Norm 0.5047(0.4828) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0552 | Time 17.6641, Epoch Time 254.0688(251.6774), Bit/dim 1.0934(best: 1.0927), Xent 0.0318, Loss 1.1093, Error 0.0091(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3865 | Time 31.7521(31.7953) | Bit/dim 1.0983(1.0993) | Xent 0.0431(0.0430) | Loss 1.1199(1.1208) | Error 0.0118(0.0133) Steps 440(440.54) | Grad Norm 0.3194(0.4779) | Total Time 10.00(10.00)\n",
      "Iter 3866 | Time 31.9642(31.8003) | Bit/dim 1.1000(1.0993) | Xent 0.0369(0.0428) | Loss 1.1185(1.1207) | Error 0.0124(0.0133) Steps 440(440.53) | Grad Norm 0.8983(0.4905) | Total Time 10.00(10.00)\n",
      "Iter 3867 | Time 31.3991(31.7883) | Bit/dim 1.0993(1.0993) | Xent 0.0473(0.0429) | Loss 1.1229(1.1208) | Error 0.0142(0.0133) Steps 440(440.51) | Grad Norm 0.2422(0.4830) | Total Time 10.00(10.00)\n",
      "Iter 3868 | Time 31.8513(31.7902) | Bit/dim 1.1015(1.0994) | Xent 0.0454(0.0430) | Loss 1.1242(1.1209) | Error 0.0139(0.0133) Steps 440(440.50) | Grad Norm 0.9889(0.4982) | Total Time 10.00(10.00)\n",
      "Iter 3869 | Time 32.4179(31.8090) | Bit/dim 1.1001(1.0994) | Xent 0.0449(0.0431) | Loss 1.1226(1.1209) | Error 0.0151(0.0134) Steps 440(440.48) | Grad Norm 0.5323(0.4992) | Total Time 10.00(10.00)\n",
      "Iter 3870 | Time 32.0853(31.8173) | Bit/dim 1.0995(1.0994) | Xent 0.0434(0.0431) | Loss 1.1212(1.1209) | Error 0.0130(0.0134) Steps 440(440.47) | Grad Norm 0.6414(0.5035) | Total Time 10.00(10.00)\n",
      "Iter 3871 | Time 32.1832(31.8283) | Bit/dim 1.0974(1.0993) | Xent 0.0477(0.0432) | Loss 1.1212(1.1209) | Error 0.0139(0.0134) Steps 440(440.45) | Grad Norm 0.8385(0.5136) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0553 | Time 17.7630, Epoch Time 254.0567(251.7488), Bit/dim 1.0939(best: 1.0927), Xent 0.0341, Loss 1.1110, Error 0.0102(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3872 | Time 30.7193(31.7950) | Bit/dim 1.0955(1.0992) | Xent 0.0463(0.0433) | Loss 1.1187(1.1209) | Error 0.0152(0.0134) Steps 440(440.44) | Grad Norm 0.4310(0.5111) | Total Time 10.00(10.00)\n",
      "Iter 3873 | Time 31.1257(31.7749) | Bit/dim 1.0991(1.0992) | Xent 0.0361(0.0431) | Loss 1.1171(1.1208) | Error 0.0114(0.0134) Steps 440(440.43) | Grad Norm 0.7643(0.5187) | Total Time 10.00(10.00)\n",
      "Iter 3874 | Time 31.6958(31.7726) | Bit/dim 1.0972(1.0992) | Xent 0.0424(0.0431) | Loss 1.1184(1.1207) | Error 0.0132(0.0134) Steps 440(440.41) | Grad Norm 0.6924(0.5239) | Total Time 10.00(10.00)\n",
      "Iter 3875 | Time 32.5201(31.7950) | Bit/dim 1.1034(1.0993) | Xent 0.0436(0.0431) | Loss 1.1252(1.1208) | Error 0.0136(0.0134) Steps 440(440.40) | Grad Norm 0.6173(0.5267) | Total Time 10.00(10.00)\n",
      "Iter 3876 | Time 31.8652(31.7971) | Bit/dim 1.0989(1.0993) | Xent 0.0470(0.0432) | Loss 1.1224(1.1209) | Error 0.0140(0.0134) Steps 440(440.39) | Grad Norm 1.0238(0.5416) | Total Time 10.00(10.00)\n",
      "Iter 3877 | Time 31.7247(31.7949) | Bit/dim 1.1053(1.0995) | Xent 0.0421(0.0432) | Loss 1.1264(1.1210) | Error 0.0134(0.0134) Steps 440(440.38) | Grad Norm 0.2897(0.5341) | Total Time 10.00(10.00)\n",
      "Iter 3878 | Time 31.8186(31.7956) | Bit/dim 1.0930(1.0993) | Xent 0.0468(0.0433) | Loss 1.1164(1.1209) | Error 0.0141(0.0134) Steps 440(440.37) | Grad Norm 0.5088(0.5333) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0554 | Time 17.5085, Epoch Time 251.7111(251.7476), Bit/dim 1.0933(best: 1.0927), Xent 0.0339, Loss 1.1102, Error 0.0103(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3879 | Time 31.7898(31.7955) | Bit/dim 1.1003(1.0993) | Xent 0.0406(0.0432) | Loss 1.1206(1.1209) | Error 0.0118(0.0134) Steps 440(440.36) | Grad Norm 0.2368(0.5244) | Total Time 10.00(10.00)\n",
      "Iter 3880 | Time 32.2472(31.8090) | Bit/dim 1.1000(1.0993) | Xent 0.0445(0.0432) | Loss 1.1223(1.1209) | Error 0.0138(0.0134) Steps 440(440.34) | Grad Norm 0.3970(0.5206) | Total Time 10.00(10.00)\n",
      "Iter 3881 | Time 31.8934(31.8115) | Bit/dim 1.0998(1.0993) | Xent 0.0489(0.0434) | Loss 1.1243(1.1210) | Error 0.0165(0.0135) Steps 440(440.33) | Grad Norm 0.3656(0.5159) | Total Time 10.00(10.00)\n",
      "Iter 3882 | Time 31.6830(31.8077) | Bit/dim 1.0982(1.0993) | Xent 0.0434(0.0434) | Loss 1.1199(1.1210) | Error 0.0138(0.0135) Steps 440(440.32) | Grad Norm 0.5735(0.5177) | Total Time 10.00(10.00)\n",
      "Iter 3883 | Time 32.1668(31.8185) | Bit/dim 1.0972(1.0992) | Xent 0.0450(0.0435) | Loss 1.1197(1.1210) | Error 0.0118(0.0134) Steps 440(440.31) | Grad Norm 0.3168(0.5116) | Total Time 10.00(10.00)\n",
      "Iter 3884 | Time 32.8163(31.8484) | Bit/dim 1.0985(1.0992) | Xent 0.0433(0.0435) | Loss 1.1201(1.1209) | Error 0.0138(0.0134) Steps 440(440.30) | Grad Norm 0.6477(0.5157) | Total Time 10.00(10.00)\n",
      "Iter 3885 | Time 32.7376(31.8751) | Bit/dim 1.0972(1.0992) | Xent 0.0404(0.0434) | Loss 1.1174(1.1208) | Error 0.0131(0.0134) Steps 440(440.30) | Grad Norm 0.2608(0.5081) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0555 | Time 17.7820, Epoch Time 256.1784(251.8806), Bit/dim 1.0935(best: 1.0927), Xent 0.0323, Loss 1.1097, Error 0.0100(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3886 | Time 31.1991(31.8548) | Bit/dim 1.1034(1.0993) | Xent 0.0434(0.0434) | Loss 1.1250(1.1210) | Error 0.0130(0.0134) Steps 440(440.29) | Grad Norm 0.3880(0.5045) | Total Time 10.00(10.00)\n",
      "Iter 3887 | Time 31.3843(31.8407) | Bit/dim 1.1008(1.0993) | Xent 0.0441(0.0434) | Loss 1.1229(1.1210) | Error 0.0135(0.0134) Steps 440(440.28) | Grad Norm 0.2324(0.4963) | Total Time 10.00(10.00)\n",
      "Iter 3888 | Time 31.1407(31.8197) | Bit/dim 1.0995(1.0993) | Xent 0.0461(0.0435) | Loss 1.1225(1.1211) | Error 0.0144(0.0134) Steps 440(440.27) | Grad Norm 0.3032(0.4905) | Total Time 10.00(10.00)\n",
      "Iter 3889 | Time 31.5881(31.8127) | Bit/dim 1.0988(1.0993) | Xent 0.0426(0.0434) | Loss 1.1201(1.1210) | Error 0.0134(0.0134) Steps 440(440.26) | Grad Norm 0.3407(0.4860) | Total Time 10.00(10.00)\n",
      "Iter 3890 | Time 32.0591(31.8201) | Bit/dim 1.0925(1.0991) | Xent 0.0396(0.0433) | Loss 1.1123(1.1208) | Error 0.0121(0.0134) Steps 440(440.25) | Grad Norm 0.2038(0.4775) | Total Time 10.00(10.00)\n",
      "Iter 3891 | Time 31.8999(31.8225) | Bit/dim 1.1022(1.0992) | Xent 0.0456(0.0434) | Loss 1.1250(1.1209) | Error 0.0130(0.0134) Steps 440(440.25) | Grad Norm 0.2546(0.4709) | Total Time 10.00(10.00)\n",
      "Iter 3892 | Time 31.2751(31.8061) | Bit/dim 1.0976(1.0992) | Xent 0.0478(0.0435) | Loss 1.1215(1.1209) | Error 0.0125(0.0134) Steps 440(440.24) | Grad Norm 0.3016(0.4658) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0556 | Time 17.8969, Epoch Time 251.0576(251.8559), Bit/dim 1.0935(best: 1.0927), Xent 0.0333, Loss 1.1102, Error 0.0101(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3893 | Time 31.5686(31.7990) | Bit/dim 1.0963(1.0991) | Xent 0.0422(0.0435) | Loss 1.1174(1.1208) | Error 0.0129(0.0133) Steps 440(440.23) | Grad Norm 0.3195(0.4614) | Total Time 10.00(10.00)\n",
      "Iter 3894 | Time 32.2279(31.8118) | Bit/dim 1.1000(1.0991) | Xent 0.0412(0.0434) | Loss 1.1206(1.1208) | Error 0.0125(0.0133) Steps 440(440.22) | Grad Norm 0.2785(0.4559) | Total Time 10.00(10.00)\n",
      "Iter 3895 | Time 31.3692(31.7986) | Bit/dim 1.1017(1.0992) | Xent 0.0424(0.0434) | Loss 1.1229(1.1209) | Error 0.0131(0.0133) Steps 440(440.22) | Grad Norm 0.3428(0.4525) | Total Time 10.00(10.00)\n",
      "Iter 3896 | Time 31.8135(31.7990) | Bit/dim 1.0998(1.0992) | Xent 0.0410(0.0433) | Loss 1.1203(1.1208) | Error 0.0126(0.0133) Steps 440(440.21) | Grad Norm 0.3274(0.4488) | Total Time 10.00(10.00)\n",
      "Iter 3897 | Time 31.7164(31.7965) | Bit/dim 1.0971(1.0991) | Xent 0.0441(0.0433) | Loss 1.1191(1.1208) | Error 0.0132(0.0133) Steps 446(440.39) | Grad Norm 0.4004(0.4473) | Total Time 10.00(10.00)\n",
      "Iter 3898 | Time 31.7549(31.7953) | Bit/dim 1.0971(1.0991) | Xent 0.0354(0.0431) | Loss 1.1148(1.1206) | Error 0.0120(0.0133) Steps 440(440.37) | Grad Norm 0.5891(0.4516) | Total Time 10.00(10.00)\n",
      "Iter 3899 | Time 33.2028(31.8375) | Bit/dim 1.1028(1.0992) | Xent 0.0493(0.0433) | Loss 1.1274(1.1208) | Error 0.0140(0.0133) Steps 446(440.54) | Grad Norm 0.4415(0.4513) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0557 | Time 17.9294, Epoch Time 254.4705(251.9343), Bit/dim 1.0937(best: 1.0927), Xent 0.0333, Loss 1.1103, Error 0.0107(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3900 | Time 31.4256(31.8251) | Bit/dim 1.0977(1.0991) | Xent 0.0412(0.0432) | Loss 1.1182(1.1207) | Error 0.0135(0.0133) Steps 440(440.53) | Grad Norm 0.4065(0.4499) | Total Time 10.00(10.00)\n",
      "Iter 3901 | Time 30.7508(31.7929) | Bit/dim 1.0984(1.0991) | Xent 0.0397(0.0431) | Loss 1.1182(1.1207) | Error 0.0129(0.0133) Steps 440(440.51) | Grad Norm 0.2650(0.4444) | Total Time 10.00(10.00)\n",
      "Iter 3902 | Time 31.9547(31.7978) | Bit/dim 1.0969(1.0990) | Xent 0.0440(0.0431) | Loss 1.1189(1.1206) | Error 0.0126(0.0133) Steps 440(440.50) | Grad Norm 0.4476(0.4445) | Total Time 10.00(10.00)\n",
      "Iter 3903 | Time 31.7403(31.7960) | Bit/dim 1.0999(1.0991) | Xent 0.0433(0.0431) | Loss 1.1216(1.1206) | Error 0.0125(0.0132) Steps 440(440.48) | Grad Norm 0.3105(0.4404) | Total Time 10.00(10.00)\n",
      "Iter 3904 | Time 33.7840(31.8557) | Bit/dim 1.0977(1.0990) | Xent 0.0401(0.0431) | Loss 1.1178(1.1206) | Error 0.0130(0.0132) Steps 440(440.47) | Grad Norm 0.3566(0.4379) | Total Time 10.00(10.00)\n",
      "Iter 3905 | Time 31.2054(31.8362) | Bit/dim 1.1046(1.0992) | Xent 0.0442(0.0431) | Loss 1.1266(1.1207) | Error 0.0140(0.0132) Steps 440(440.45) | Grad Norm 0.2453(0.4322) | Total Time 10.00(10.00)\n",
      "Iter 3906 | Time 32.0182(31.8416) | Bit/dim 1.1006(1.0992) | Xent 0.0444(0.0431) | Loss 1.1228(1.1208) | Error 0.0122(0.0132) Steps 440(440.44) | Grad Norm 0.2468(0.4266) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0558 | Time 17.7802, Epoch Time 253.0253(251.9670), Bit/dim 1.0935(best: 1.0927), Xent 0.0345, Loss 1.1108, Error 0.0097(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3907 | Time 31.6541(31.8360) | Bit/dim 1.1018(1.0993) | Xent 0.0429(0.0431) | Loss 1.1232(1.1209) | Error 0.0121(0.0132) Steps 440(440.43) | Grad Norm 0.2671(0.4218) | Total Time 10.00(10.00)\n",
      "Iter 3908 | Time 31.9660(31.8399) | Bit/dim 1.0976(1.0993) | Xent 0.0504(0.0433) | Loss 1.1229(1.1209) | Error 0.0149(0.0132) Steps 440(440.41) | Grad Norm 0.2205(0.4158) | Total Time 10.00(10.00)\n",
      "Iter 3909 | Time 32.2681(31.8528) | Bit/dim 1.0962(1.0992) | Xent 0.0443(0.0434) | Loss 1.1184(1.1209) | Error 0.0146(0.0133) Steps 440(440.40) | Grad Norm 0.2688(0.4114) | Total Time 10.00(10.00)\n",
      "Iter 3910 | Time 33.4367(31.9003) | Bit/dim 1.0945(1.0990) | Xent 0.0411(0.0433) | Loss 1.1150(1.1207) | Error 0.0119(0.0132) Steps 440(440.39) | Grad Norm 0.3592(0.4098) | Total Time 10.00(10.00)\n",
      "Iter 3911 | Time 32.2847(31.9118) | Bit/dim 1.0981(1.0990) | Xent 0.0467(0.0434) | Loss 1.1215(1.1207) | Error 0.0155(0.0133) Steps 440(440.38) | Grad Norm 0.3549(0.4081) | Total Time 10.00(10.00)\n",
      "Iter 3912 | Time 31.2413(31.8917) | Bit/dim 1.1009(1.0991) | Xent 0.0371(0.0432) | Loss 1.1194(1.1207) | Error 0.0116(0.0133) Steps 440(440.37) | Grad Norm 0.2680(0.4039) | Total Time 10.00(10.00)\n",
      "Iter 3913 | Time 30.7960(31.8588) | Bit/dim 1.0987(1.0991) | Xent 0.0396(0.0431) | Loss 1.1185(1.1206) | Error 0.0120(0.0132) Steps 440(440.35) | Grad Norm 0.4453(0.4052) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0559 | Time 17.5186, Epoch Time 253.5986(252.0160), Bit/dim 1.0934(best: 1.0927), Xent 0.0321, Loss 1.1094, Error 0.0094(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3914 | Time 31.8933(31.8599) | Bit/dim 1.1001(1.0991) | Xent 0.0440(0.0431) | Loss 1.1221(1.1206) | Error 0.0121(0.0132) Steps 440(440.34) | Grad Norm 0.4034(0.4051) | Total Time 10.00(10.00)\n",
      "Iter 3915 | Time 31.6541(31.8537) | Bit/dim 1.0924(1.0989) | Xent 0.0415(0.0431) | Loss 1.1132(1.1204) | Error 0.0120(0.0131) Steps 440(440.33) | Grad Norm 0.3923(0.4047) | Total Time 10.00(10.00)\n",
      "Iter 3916 | Time 31.5539(31.8447) | Bit/dim 1.1020(1.0990) | Xent 0.0480(0.0432) | Loss 1.1259(1.1206) | Error 0.0156(0.0132) Steps 440(440.32) | Grad Norm 0.6387(0.4118) | Total Time 10.00(10.00)\n",
      "Iter 3917 | Time 31.7410(31.8416) | Bit/dim 1.1003(1.0990) | Xent 0.0475(0.0434) | Loss 1.1241(1.1207) | Error 0.0145(0.0133) Steps 446(440.49) | Grad Norm 0.3690(0.4105) | Total Time 10.00(10.00)\n",
      "Iter 3918 | Time 32.3170(31.8558) | Bit/dim 1.0970(1.0990) | Xent 0.0374(0.0432) | Loss 1.1157(1.1205) | Error 0.0109(0.0132) Steps 440(440.48) | Grad Norm 0.9333(0.4262) | Total Time 10.00(10.00)\n",
      "Iter 3919 | Time 31.7162(31.8517) | Bit/dim 1.0968(1.0989) | Xent 0.0383(0.0430) | Loss 1.1160(1.1204) | Error 0.0115(0.0131) Steps 440(440.46) | Grad Norm 0.2281(0.4202) | Total Time 10.00(10.00)\n",
      "Iter 3920 | Time 32.4222(31.8688) | Bit/dim 1.1003(1.0989) | Xent 0.0470(0.0432) | Loss 1.1238(1.1205) | Error 0.0141(0.0132) Steps 440(440.45) | Grad Norm 0.8432(0.4329) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0560 | Time 17.6413, Epoch Time 253.5168(252.0610), Bit/dim 1.0931(best: 1.0927), Xent 0.0323, Loss 1.1092, Error 0.0097(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3921 | Time 31.6615(31.8626) | Bit/dim 1.1001(1.0990) | Xent 0.0481(0.0433) | Loss 1.1241(1.1206) | Error 0.0134(0.0132) Steps 440(440.44) | Grad Norm 0.3218(0.4296) | Total Time 10.00(10.00)\n",
      "Iter 3922 | Time 33.0946(31.8995) | Bit/dim 1.0993(1.0990) | Xent 0.0384(0.0432) | Loss 1.1186(1.1206) | Error 0.0121(0.0131) Steps 440(440.42) | Grad Norm 0.3311(0.4266) | Total Time 10.00(10.00)\n",
      "Iter 3923 | Time 31.4108(31.8849) | Bit/dim 1.1008(1.0990) | Xent 0.0376(0.0430) | Loss 1.1196(1.1205) | Error 0.0108(0.0131) Steps 446(440.59) | Grad Norm 0.4778(0.4282) | Total Time 10.00(10.00)\n",
      "Iter 3924 | Time 31.7138(31.8797) | Bit/dim 1.0974(1.0990) | Xent 0.0439(0.0430) | Loss 1.1194(1.1205) | Error 0.0131(0.0131) Steps 440(440.57) | Grad Norm 0.3149(0.4248) | Total Time 10.00(10.00)\n",
      "Iter 3925 | Time 32.1980(31.8893) | Bit/dim 1.1042(1.0991) | Xent 0.0428(0.0430) | Loss 1.1256(1.1206) | Error 0.0135(0.0131) Steps 440(440.56) | Grad Norm 0.5463(0.4284) | Total Time 10.00(10.00)\n",
      "Iter 3926 | Time 32.6044(31.9107) | Bit/dim 1.0942(1.0990) | Xent 0.0340(0.0427) | Loss 1.1112(1.1204) | Error 0.0114(0.0130) Steps 440(440.54) | Grad Norm 0.2579(0.4233) | Total Time 10.00(10.00)\n",
      "Iter 3927 | Time 31.4316(31.8964) | Bit/dim 1.0965(1.0989) | Xent 0.0442(0.0428) | Loss 1.1186(1.1203) | Error 0.0138(0.0131) Steps 440(440.52) | Grad Norm 0.2865(0.4192) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0561 | Time 17.6599, Epoch Time 254.5796(252.1366), Bit/dim 1.0934(best: 1.0927), Xent 0.0307, Loss 1.1088, Error 0.0099(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3928 | Time 31.4887(31.8841) | Bit/dim 1.0989(1.0989) | Xent 0.0428(0.0428) | Loss 1.1203(1.1203) | Error 0.0145(0.0131) Steps 440(440.51) | Grad Norm 0.3992(0.4186) | Total Time 10.00(10.00)\n",
      "Iter 3929 | Time 31.3174(31.8671) | Bit/dim 1.0971(1.0989) | Xent 0.0450(0.0429) | Loss 1.1196(1.1203) | Error 0.0146(0.0131) Steps 440(440.49) | Grad Norm 0.4988(0.4210) | Total Time 10.00(10.00)\n",
      "Iter 3930 | Time 30.9393(31.8393) | Bit/dim 1.0999(1.0989) | Xent 0.0414(0.0428) | Loss 1.1206(1.1203) | Error 0.0120(0.0131) Steps 440(440.48) | Grad Norm 0.2481(0.4158) | Total Time 10.00(10.00)\n",
      "Iter 3931 | Time 31.4214(31.8267) | Bit/dim 1.1025(1.0990) | Xent 0.0435(0.0428) | Loss 1.1242(1.1204) | Error 0.0126(0.0131) Steps 440(440.46) | Grad Norm 0.6286(0.4222) | Total Time 10.00(10.00)\n",
      "Iter 3932 | Time 31.7750(31.8252) | Bit/dim 1.0934(1.0988) | Xent 0.0405(0.0428) | Loss 1.1137(1.1202) | Error 0.0130(0.0131) Steps 440(440.45) | Grad Norm 0.4033(0.4216) | Total Time 10.00(10.00)\n",
      "Iter 3933 | Time 33.0066(31.8606) | Bit/dim 1.1026(1.0989) | Xent 0.0434(0.0428) | Loss 1.1243(1.1203) | Error 0.0128(0.0131) Steps 440(440.44) | Grad Norm 0.4008(0.4210) | Total Time 10.00(10.00)\n",
      "Iter 3934 | Time 31.9006(31.8618) | Bit/dim 1.0992(1.0990) | Xent 0.0450(0.0428) | Loss 1.1217(1.1204) | Error 0.0140(0.0131) Steps 446(440.60) | Grad Norm 0.2514(0.4159) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0562 | Time 17.7695, Epoch Time 252.2697(252.1406), Bit/dim 1.0935(best: 1.0927), Xent 0.0335, Loss 1.1103, Error 0.0105(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3935 | Time 31.8042(31.8601) | Bit/dim 1.0993(1.0990) | Xent 0.0484(0.0430) | Loss 1.1235(1.1205) | Error 0.0144(0.0131) Steps 440(440.58) | Grad Norm 0.6324(0.4224) | Total Time 10.00(10.00)\n",
      "Iter 3936 | Time 32.1291(31.8682) | Bit/dim 1.0977(1.0989) | Xent 0.0374(0.0428) | Loss 1.1164(1.1203) | Error 0.0124(0.0131) Steps 440(440.57) | Grad Norm 0.3662(0.4207) | Total Time 10.00(10.00)\n",
      "Iter 3937 | Time 32.3130(31.8815) | Bit/dim 1.1038(1.0991) | Xent 0.0437(0.0429) | Loss 1.1256(1.1205) | Error 0.0141(0.0132) Steps 440(440.55) | Grad Norm 0.3983(0.4201) | Total Time 10.00(10.00)\n",
      "Iter 3938 | Time 31.4241(31.8678) | Bit/dim 1.0972(1.0990) | Xent 0.0463(0.0430) | Loss 1.1204(1.1205) | Error 0.0139(0.0132) Steps 440(440.53) | Grad Norm 0.3176(0.4170) | Total Time 10.00(10.00)\n",
      "Iter 3939 | Time 31.3090(31.8510) | Bit/dim 1.0961(1.0989) | Xent 0.0389(0.0428) | Loss 1.1155(1.1204) | Error 0.0116(0.0131) Steps 440(440.52) | Grad Norm 0.5112(0.4198) | Total Time 10.00(10.00)\n",
      "Iter 3940 | Time 31.3765(31.8368) | Bit/dim 1.0975(1.0989) | Xent 0.0403(0.0428) | Loss 1.1177(1.1203) | Error 0.0132(0.0131) Steps 440(440.50) | Grad Norm 0.5795(0.4246) | Total Time 10.00(10.00)\n",
      "Iter 3941 | Time 31.3149(31.8211) | Bit/dim 1.0999(1.0989) | Xent 0.0403(0.0427) | Loss 1.1201(1.1203) | Error 0.0121(0.0131) Steps 440(440.49) | Grad Norm 0.5350(0.4279) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0563 | Time 17.7563, Epoch Time 252.4668(252.1504), Bit/dim 1.0936(best: 1.0927), Xent 0.0341, Loss 1.1107, Error 0.0093(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3942 | Time 31.2200(31.8031) | Bit/dim 1.0985(1.0989) | Xent 0.0420(0.0427) | Loss 1.1195(1.1202) | Error 0.0134(0.0131) Steps 440(440.47) | Grad Norm 0.3855(0.4266) | Total Time 10.00(10.00)\n",
      "Iter 3943 | Time 30.8262(31.7738) | Bit/dim 1.1004(1.0989) | Xent 0.0359(0.0425) | Loss 1.1183(1.1202) | Error 0.0104(0.0130) Steps 440(440.46) | Grad Norm 0.6241(0.4326) | Total Time 10.00(10.00)\n",
      "Iter 3944 | Time 31.3973(31.7625) | Bit/dim 1.1005(1.0990) | Xent 0.0491(0.0427) | Loss 1.1250(1.1203) | Error 0.0158(0.0131) Steps 440(440.44) | Grad Norm 0.2705(0.4277) | Total Time 10.00(10.00)\n",
      "Iter 3945 | Time 32.2462(31.7770) | Bit/dim 1.0996(1.0990) | Xent 0.0400(0.0426) | Loss 1.1196(1.1203) | Error 0.0129(0.0131) Steps 440(440.43) | Grad Norm 0.2546(0.4225) | Total Time 10.00(10.00)\n",
      "Iter 3946 | Time 31.3969(31.7656) | Bit/dim 1.1023(1.0991) | Xent 0.0421(0.0426) | Loss 1.1234(1.1204) | Error 0.0124(0.0131) Steps 440(440.42) | Grad Norm 0.2512(0.4174) | Total Time 10.00(10.00)\n",
      "Iter 3947 | Time 32.0006(31.7727) | Bit/dim 1.0969(1.0990) | Xent 0.0425(0.0426) | Loss 1.1182(1.1203) | Error 0.0130(0.0131) Steps 440(440.41) | Grad Norm 0.5028(0.4199) | Total Time 10.00(10.00)\n",
      "Iter 3948 | Time 31.3773(31.7608) | Bit/dim 1.0940(1.0989) | Xent 0.0424(0.0426) | Loss 1.1152(1.1202) | Error 0.0126(0.0131) Steps 440(440.39) | Grad Norm 0.3990(0.4193) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0564 | Time 17.9131, Epoch Time 250.7308(252.1078), Bit/dim 1.0927(best: 1.0927), Xent 0.0318, Loss 1.1086, Error 0.0090(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3949 | Time 33.1419(31.8022) | Bit/dim 1.0951(1.0988) | Xent 0.0474(0.0427) | Loss 1.1188(1.1201) | Error 0.0146(0.0131) Steps 440(440.38) | Grad Norm 0.5493(0.4232) | Total Time 10.00(10.00)\n",
      "Iter 3950 | Time 31.3697(31.7893) | Bit/dim 1.1033(1.0989) | Xent 0.0436(0.0427) | Loss 1.1251(1.1203) | Error 0.0122(0.0131) Steps 440(440.37) | Grad Norm 0.2710(0.4186) | Total Time 10.00(10.00)\n",
      "Iter 3951 | Time 31.6154(31.7840) | Bit/dim 1.0995(1.0989) | Xent 0.0447(0.0428) | Loss 1.1219(1.1203) | Error 0.0139(0.0131) Steps 440(440.36) | Grad Norm 1.0503(0.4376) | Total Time 10.00(10.00)\n",
      "Iter 3952 | Time 32.1107(31.7938) | Bit/dim 1.1033(1.0991) | Xent 0.0448(0.0429) | Loss 1.1257(1.1205) | Error 0.0132(0.0131) Steps 440(440.35) | Grad Norm 0.4843(0.4390) | Total Time 10.00(10.00)\n",
      "Iter 3953 | Time 32.0623(31.8019) | Bit/dim 1.0948(1.0989) | Xent 0.0423(0.0428) | Loss 1.1160(1.1204) | Error 0.0130(0.0131) Steps 440(440.34) | Grad Norm 0.6436(0.4451) | Total Time 10.00(10.00)\n",
      "Iter 3954 | Time 32.5784(31.8252) | Bit/dim 1.0993(1.0990) | Xent 0.0484(0.0430) | Loss 1.1235(1.1205) | Error 0.0141(0.0131) Steps 440(440.33) | Grad Norm 0.3541(0.4424) | Total Time 10.00(10.00)\n",
      "Iter 3955 | Time 31.9828(31.8299) | Bit/dim 1.0958(1.0989) | Xent 0.0428(0.0430) | Loss 1.1172(1.1204) | Error 0.0140(0.0132) Steps 440(440.32) | Grad Norm 0.5262(0.4449) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0565 | Time 17.5982, Epoch Time 254.8557(252.1902), Bit/dim 1.0930(best: 1.0927), Xent 0.0323, Loss 1.1092, Error 0.0107(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3956 | Time 31.0978(31.8080) | Bit/dim 1.0947(1.0987) | Xent 0.0361(0.0428) | Loss 1.1127(1.1201) | Error 0.0134(0.0132) Steps 440(440.31) | Grad Norm 0.4011(0.4436) | Total Time 10.00(10.00)\n",
      "Iter 3957 | Time 31.4757(31.7980) | Bit/dim 1.1005(1.0988) | Xent 0.0434(0.0428) | Loss 1.1222(1.1202) | Error 0.0138(0.0132) Steps 440(440.30) | Grad Norm 0.4840(0.4448) | Total Time 10.00(10.00)\n",
      "Iter 3958 | Time 32.4587(31.8178) | Bit/dim 1.1029(1.0989) | Xent 0.0413(0.0428) | Loss 1.1236(1.1203) | Error 0.0124(0.0132) Steps 440(440.29) | Grad Norm 0.4628(0.4453) | Total Time 10.00(10.00)\n",
      "Iter 3959 | Time 32.1007(31.8263) | Bit/dim 1.0990(1.0989) | Xent 0.0542(0.0431) | Loss 1.1261(1.1205) | Error 0.0151(0.0132) Steps 440(440.28) | Grad Norm 0.3034(0.4411) | Total Time 10.00(10.00)\n",
      "Iter 3960 | Time 31.9573(31.8302) | Bit/dim 1.0985(1.0989) | Xent 0.0403(0.0430) | Loss 1.1186(1.1204) | Error 0.0138(0.0132) Steps 440(440.27) | Grad Norm 0.2894(0.4365) | Total Time 10.00(10.00)\n",
      "Iter 3961 | Time 32.3644(31.8462) | Bit/dim 1.0979(1.0989) | Xent 0.0385(0.0429) | Loss 1.1171(1.1203) | Error 0.0118(0.0132) Steps 440(440.26) | Grad Norm 0.3230(0.4331) | Total Time 10.00(10.00)\n",
      "Iter 3962 | Time 30.9960(31.8207) | Bit/dim 1.0987(1.0989) | Xent 0.0403(0.0428) | Loss 1.1189(1.1203) | Error 0.0128(0.0132) Steps 440(440.26) | Grad Norm 0.3626(0.4310) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0566 | Time 17.8347, Epoch Time 252.7614(252.2073), Bit/dim 1.0935(best: 1.0927), Xent 0.0312, Loss 1.1091, Error 0.0086(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3963 | Time 30.8304(31.7910) | Bit/dim 1.1007(1.0989) | Xent 0.0412(0.0428) | Loss 1.1213(1.1203) | Error 0.0129(0.0132) Steps 440(440.25) | Grad Norm 0.1921(0.4238) | Total Time 10.00(10.00)\n",
      "Iter 3964 | Time 30.6696(31.7574) | Bit/dim 1.0978(1.0989) | Xent 0.0428(0.0428) | Loss 1.1192(1.1203) | Error 0.0135(0.0132) Steps 440(440.24) | Grad Norm 0.2226(0.4178) | Total Time 10.00(10.00)\n",
      "Iter 3965 | Time 31.2061(31.7408) | Bit/dim 1.0989(1.0989) | Xent 0.0465(0.0429) | Loss 1.1222(1.1203) | Error 0.0136(0.0132) Steps 440(440.23) | Grad Norm 0.2880(0.4139) | Total Time 10.00(10.00)\n",
      "Iter 3966 | Time 32.5654(31.7656) | Bit/dim 1.0962(1.0988) | Xent 0.0386(0.0428) | Loss 1.1155(1.1202) | Error 0.0124(0.0132) Steps 440(440.23) | Grad Norm 0.2996(0.4105) | Total Time 10.00(10.00)\n",
      "Iter 3967 | Time 32.4608(31.7864) | Bit/dim 1.1005(1.0989) | Xent 0.0433(0.0428) | Loss 1.1221(1.1202) | Error 0.0134(0.0132) Steps 440(440.22) | Grad Norm 0.2530(0.4058) | Total Time 10.00(10.00)\n",
      "Iter 3968 | Time 31.9293(31.7907) | Bit/dim 1.1007(1.0989) | Xent 0.0439(0.0428) | Loss 1.1226(1.1203) | Error 0.0132(0.0132) Steps 440(440.21) | Grad Norm 0.4628(0.4075) | Total Time 10.00(10.00)\n",
      "Iter 3969 | Time 31.0707(31.7691) | Bit/dim 1.0957(1.0988) | Xent 0.0417(0.0428) | Loss 1.1166(1.1202) | Error 0.0135(0.0132) Steps 440(440.21) | Grad Norm 0.3490(0.4057) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0567 | Time 17.5892, Epoch Time 251.1280(252.1750), Bit/dim 1.0937(best: 1.0927), Xent 0.0334, Loss 1.1104, Error 0.0104(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3970 | Time 32.1709(31.7812) | Bit/dim 1.1011(1.0989) | Xent 0.0410(0.0427) | Loss 1.1216(1.1202) | Error 0.0140(0.0132) Steps 446(440.38) | Grad Norm 0.3780(0.4049) | Total Time 10.00(10.00)\n",
      "Iter 3971 | Time 31.7926(31.7815) | Bit/dim 1.0952(1.0988) | Xent 0.0457(0.0428) | Loss 1.1181(1.1202) | Error 0.0135(0.0132) Steps 440(440.37) | Grad Norm 0.4689(0.4068) | Total Time 10.00(10.00)\n",
      "Iter 3972 | Time 31.4257(31.7708) | Bit/dim 1.0999(1.0988) | Xent 0.0440(0.0429) | Loss 1.1219(1.1202) | Error 0.0136(0.0132) Steps 440(440.36) | Grad Norm 0.6341(0.4136) | Total Time 10.00(10.00)\n",
      "Iter 3973 | Time 31.0823(31.7502) | Bit/dim 1.1023(1.0989) | Xent 0.0434(0.0429) | Loss 1.1240(1.1203) | Error 0.0134(0.0132) Steps 440(440.35) | Grad Norm 0.3136(0.4106) | Total Time 10.00(10.00)\n",
      "Iter 3974 | Time 31.6091(31.7460) | Bit/dim 1.1023(1.0990) | Xent 0.0424(0.0429) | Loss 1.1235(1.1204) | Error 0.0128(0.0132) Steps 440(440.34) | Grad Norm 0.5128(0.4137) | Total Time 10.00(10.00)\n",
      "Iter 3975 | Time 32.3508(31.7641) | Bit/dim 1.0931(1.0988) | Xent 0.0358(0.0426) | Loss 1.1110(1.1202) | Error 0.0112(0.0132) Steps 440(440.33) | Grad Norm 0.4227(0.4140) | Total Time 10.00(10.00)\n",
      "Iter 3976 | Time 32.2978(31.7801) | Bit/dim 1.0978(1.0988) | Xent 0.0437(0.0427) | Loss 1.1197(1.1201) | Error 0.0131(0.0132) Steps 440(440.32) | Grad Norm 0.3268(0.4113) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0568 | Time 17.9222, Epoch Time 253.3418(252.2100), Bit/dim 1.0930(best: 1.0927), Xent 0.0347, Loss 1.1103, Error 0.0112(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3977 | Time 30.9154(31.7542) | Bit/dim 1.0980(1.0988) | Xent 0.0401(0.0426) | Loss 1.1181(1.1201) | Error 0.0119(0.0131) Steps 440(440.31) | Grad Norm 0.7444(0.4213) | Total Time 10.00(10.00)\n",
      "Iter 3978 | Time 32.1855(31.7671) | Bit/dim 1.0972(1.0987) | Xent 0.0445(0.0427) | Loss 1.1194(1.1201) | Error 0.0135(0.0131) Steps 440(440.30) | Grad Norm 0.3186(0.4183) | Total Time 10.00(10.00)\n",
      "Iter 3979 | Time 32.5782(31.7914) | Bit/dim 1.0970(1.0987) | Xent 0.0410(0.0426) | Loss 1.1175(1.1200) | Error 0.0128(0.0131) Steps 440(440.29) | Grad Norm 0.8339(0.4307) | Total Time 10.00(10.00)\n",
      "Iter 3980 | Time 31.9094(31.7950) | Bit/dim 1.0964(1.0986) | Xent 0.0421(0.0426) | Loss 1.1175(1.1199) | Error 0.0129(0.0131) Steps 440(440.28) | Grad Norm 0.4221(0.4305) | Total Time 10.00(10.00)\n",
      "Iter 3981 | Time 31.1189(31.7747) | Bit/dim 1.0975(1.0986) | Xent 0.0436(0.0426) | Loss 1.1193(1.1199) | Error 0.0131(0.0131) Steps 440(440.27) | Grad Norm 0.4185(0.4301) | Total Time 10.00(10.00)\n",
      "Iter 3982 | Time 31.3229(31.7612) | Bit/dim 1.0967(1.0985) | Xent 0.0404(0.0426) | Loss 1.1168(1.1198) | Error 0.0118(0.0131) Steps 440(440.26) | Grad Norm 0.5699(0.4343) | Total Time 10.00(10.00)\n",
      "Iter 3983 | Time 31.5318(31.7543) | Bit/dim 1.1034(1.0987) | Xent 0.0420(0.0425) | Loss 1.1244(1.1199) | Error 0.0134(0.0131) Steps 440(440.26) | Grad Norm 0.3870(0.4329) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0569 | Time 17.7722, Epoch Time 251.9845(252.2032), Bit/dim 1.0941(best: 1.0927), Xent 0.0331, Loss 1.1106, Error 0.0100(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3984 | Time 30.8015(31.7257) | Bit/dim 1.0997(1.0987) | Xent 0.0380(0.0424) | Loss 1.1187(1.1199) | Error 0.0116(0.0130) Steps 440(440.25) | Grad Norm 1.0946(0.4527) | Total Time 10.00(10.00)\n",
      "Iter 3985 | Time 31.9067(31.7311) | Bit/dim 1.0987(1.0987) | Xent 0.0499(0.0426) | Loss 1.1237(1.1200) | Error 0.0148(0.0131) Steps 440(440.24) | Grad Norm 0.4347(0.4522) | Total Time 10.00(10.00)\n",
      "Iter 3986 | Time 31.5936(31.7270) | Bit/dim 1.0979(1.0987) | Xent 0.0380(0.0425) | Loss 1.1169(1.1199) | Error 0.0111(0.0130) Steps 440(440.23) | Grad Norm 0.4556(0.4523) | Total Time 10.00(10.00)\n",
      "Iter 3987 | Time 31.4818(31.7196) | Bit/dim 1.0947(1.0986) | Xent 0.0470(0.0426) | Loss 1.1182(1.1199) | Error 0.0131(0.0130) Steps 440(440.23) | Grad Norm 0.7062(0.4599) | Total Time 10.00(10.00)\n",
      "Iter 3988 | Time 31.6875(31.7187) | Bit/dim 1.0976(1.0985) | Xent 0.0457(0.0427) | Loss 1.1205(1.1199) | Error 0.0154(0.0131) Steps 440(440.22) | Grad Norm 0.4181(0.4587) | Total Time 10.00(10.00)\n",
      "Iter 3989 | Time 32.9042(31.7542) | Bit/dim 1.1003(1.0986) | Xent 0.0397(0.0426) | Loss 1.1201(1.1199) | Error 0.0128(0.0131) Steps 440(440.21) | Grad Norm 0.7945(0.4687) | Total Time 10.00(10.00)\n",
      "Iter 3990 | Time 32.0775(31.7639) | Bit/dim 1.0999(1.0986) | Xent 0.0477(0.0428) | Loss 1.1237(1.1200) | Error 0.0145(0.0131) Steps 440(440.21) | Grad Norm 0.5184(0.4702) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0570 | Time 17.4896, Epoch Time 252.6920(252.2179), Bit/dim 1.0937(best: 1.0927), Xent 0.0325, Loss 1.1099, Error 0.0100(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3991 | Time 32.6633(31.7909) | Bit/dim 1.0986(1.0986) | Xent 0.0439(0.0428) | Loss 1.1206(1.1200) | Error 0.0129(0.0131) Steps 446(440.38) | Grad Norm 0.5230(0.4718) | Total Time 10.00(10.00)\n",
      "Iter 3992 | Time 31.6348(31.7862) | Bit/dim 1.0966(1.0986) | Xent 0.0466(0.0429) | Loss 1.1199(1.1200) | Error 0.0132(0.0131) Steps 440(440.37) | Grad Norm 0.7642(0.4806) | Total Time 10.00(10.00)\n",
      "Iter 3993 | Time 32.4104(31.8050) | Bit/dim 1.0981(1.0985) | Xent 0.0366(0.0427) | Loss 1.1164(1.1199) | Error 0.0128(0.0131) Steps 440(440.36) | Grad Norm 0.4188(0.4787) | Total Time 10.00(10.00)\n",
      "Iter 3994 | Time 33.0493(31.8423) | Bit/dim 1.0978(1.0985) | Xent 0.0434(0.0427) | Loss 1.1195(1.1199) | Error 0.0132(0.0131) Steps 440(440.35) | Grad Norm 0.6244(0.4831) | Total Time 10.00(10.00)\n",
      "Iter 3995 | Time 32.6153(31.8655) | Bit/dim 1.0986(1.0985) | Xent 0.0411(0.0427) | Loss 1.1192(1.1199) | Error 0.0126(0.0131) Steps 452(440.70) | Grad Norm 0.2130(0.4750) | Total Time 10.00(10.00)\n",
      "Iter 3996 | Time 32.4106(31.8818) | Bit/dim 1.0963(1.0985) | Xent 0.0352(0.0425) | Loss 1.1139(1.1197) | Error 0.0106(0.0130) Steps 440(440.68) | Grad Norm 0.5850(0.4783) | Total Time 10.00(10.00)\n",
      "Iter 3997 | Time 31.2297(31.8623) | Bit/dim 1.1004(1.0985) | Xent 0.0462(0.0426) | Loss 1.1235(1.1198) | Error 0.0138(0.0131) Steps 440(440.66) | Grad Norm 0.4849(0.4785) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0571 | Time 17.8104, Epoch Time 256.4440(252.3446), Bit/dim 1.0927(best: 1.0927), Xent 0.0318, Loss 1.1086, Error 0.0093(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3998 | Time 32.2018(31.8725) | Bit/dim 1.0960(1.0984) | Xent 0.0451(0.0427) | Loss 1.1186(1.1198) | Error 0.0139(0.0131) Steps 440(440.64) | Grad Norm 0.5423(0.4804) | Total Time 10.00(10.00)\n",
      "Iter 3999 | Time 32.0858(31.8789) | Bit/dim 1.0934(1.0983) | Xent 0.0395(0.0426) | Loss 1.1131(1.1196) | Error 0.0128(0.0131) Steps 440(440.62) | Grad Norm 0.6426(0.4853) | Total Time 10.00(10.00)\n",
      "Iter 4000 | Time 32.1600(31.8873) | Bit/dim 1.0951(1.0982) | Xent 0.0415(0.0425) | Loss 1.1159(1.1195) | Error 0.0118(0.0130) Steps 440(440.60) | Grad Norm 0.4036(0.4828) | Total Time 10.00(10.00)\n",
      "Iter 4001 | Time 31.8168(31.8852) | Bit/dim 1.0988(1.0982) | Xent 0.0461(0.0426) | Loss 1.1219(1.1195) | Error 0.0158(0.0131) Steps 440(440.58) | Grad Norm 0.9164(0.4958) | Total Time 10.00(10.00)\n",
      "Iter 4002 | Time 32.0462(31.8900) | Bit/dim 1.0995(1.0983) | Xent 0.0379(0.0425) | Loss 1.1184(1.1195) | Error 0.0110(0.0131) Steps 446(440.74) | Grad Norm 0.6059(0.4991) | Total Time 10.00(10.00)\n",
      "Iter 4003 | Time 32.2334(31.9003) | Bit/dim 1.1010(1.0983) | Xent 0.0440(0.0425) | Loss 1.1229(1.1196) | Error 0.0132(0.0131) Steps 440(440.72) | Grad Norm 0.9131(0.5115) | Total Time 10.00(10.00)\n",
      "Iter 4004 | Time 30.9921(31.8731) | Bit/dim 1.1043(1.0985) | Xent 0.0343(0.0423) | Loss 1.1215(1.1197) | Error 0.0112(0.0130) Steps 446(440.88) | Grad Norm 0.4645(0.5101) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0572 | Time 17.7013, Epoch Time 254.2087(252.4006), Bit/dim 1.0930(best: 1.0927), Xent 0.0335, Loss 1.1097, Error 0.0099(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4005 | Time 31.4070(31.8591) | Bit/dim 1.0988(1.0985) | Xent 0.0404(0.0422) | Loss 1.1190(1.1196) | Error 0.0135(0.0130) Steps 440(440.85) | Grad Norm 0.7345(0.5169) | Total Time 10.00(10.00)\n",
      "Iter 4006 | Time 31.9663(31.8623) | Bit/dim 1.0989(1.0985) | Xent 0.0453(0.0423) | Loss 1.1215(1.1197) | Error 0.0122(0.0130) Steps 440(440.83) | Grad Norm 0.3299(0.5113) | Total Time 10.00(10.00)\n",
      "Iter 4007 | Time 32.0732(31.8686) | Bit/dim 1.0992(1.0986) | Xent 0.0408(0.0423) | Loss 1.1196(1.1197) | Error 0.0125(0.0130) Steps 440(440.80) | Grad Norm 0.7978(0.5199) | Total Time 10.00(10.00)\n",
      "Iter 4008 | Time 32.2810(31.8810) | Bit/dim 1.0987(1.0986) | Xent 0.0385(0.0422) | Loss 1.1179(1.1196) | Error 0.0111(0.0129) Steps 440(440.78) | Grad Norm 0.3353(0.5143) | Total Time 10.00(10.00)\n",
      "Iter 4009 | Time 31.0296(31.8554) | Bit/dim 1.1013(1.0986) | Xent 0.0395(0.0421) | Loss 1.1210(1.1197) | Error 0.0122(0.0129) Steps 440(440.76) | Grad Norm 0.2800(0.5073) | Total Time 10.00(10.00)\n",
      "Iter 4010 | Time 32.0495(31.8613) | Bit/dim 1.0991(1.0987) | Xent 0.0430(0.0421) | Loss 1.1206(1.1197) | Error 0.0141(0.0129) Steps 440(440.73) | Grad Norm 1.4783(0.5364) | Total Time 10.00(10.00)\n",
      "Iter 4011 | Time 32.6686(31.8855) | Bit/dim 1.0954(1.0986) | Xent 0.0420(0.0421) | Loss 1.1164(1.1196) | Error 0.0135(0.0130) Steps 440(440.71) | Grad Norm 0.5410(0.5366) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0573 | Time 17.7556, Epoch Time 253.6475(252.4380), Bit/dim 1.0936(best: 1.0927), Xent 0.0321, Loss 1.1097, Error 0.0098(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4012 | Time 32.1412(31.8932) | Bit/dim 1.0963(1.0985) | Xent 0.0442(0.0422) | Loss 1.1185(1.1196) | Error 0.0120(0.0129) Steps 440(440.69) | Grad Norm 1.1044(0.5536) | Total Time 10.00(10.00)\n",
      "Iter 4013 | Time 31.9131(31.8938) | Bit/dim 1.1000(1.0985) | Xent 0.0376(0.0420) | Loss 1.1188(1.1196) | Error 0.0120(0.0129) Steps 440(440.67) | Grad Norm 0.4331(0.5500) | Total Time 10.00(10.00)\n",
      "Iter 4014 | Time 31.8514(31.8925) | Bit/dim 1.0989(1.0985) | Xent 0.0464(0.0422) | Loss 1.1221(1.1196) | Error 0.0139(0.0129) Steps 440(440.65) | Grad Norm 0.8614(0.5593) | Total Time 10.00(10.00)\n",
      "Iter 4015 | Time 32.1100(31.8990) | Bit/dim 1.0936(1.0984) | Xent 0.0422(0.0422) | Loss 1.1147(1.1195) | Error 0.0139(0.0130) Steps 440(440.63) | Grad Norm 0.6831(0.5630) | Total Time 10.00(10.00)\n",
      "Iter 4016 | Time 31.9225(31.8997) | Bit/dim 1.0981(1.0984) | Xent 0.0428(0.0422) | Loss 1.1195(1.1195) | Error 0.0126(0.0129) Steps 440(440.61) | Grad Norm 0.3727(0.5573) | Total Time 10.00(10.00)\n",
      "Iter 4017 | Time 31.3046(31.8819) | Bit/dim 1.1028(1.0985) | Xent 0.0421(0.0422) | Loss 1.1238(1.1196) | Error 0.0129(0.0129) Steps 440(440.59) | Grad Norm 0.7077(0.5618) | Total Time 10.00(10.00)\n",
      "Iter 4018 | Time 32.0382(31.8866) | Bit/dim 1.1015(1.0986) | Xent 0.0410(0.0422) | Loss 1.1220(1.1197) | Error 0.0129(0.0129) Steps 440(440.57) | Grad Norm 0.2039(0.5511) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0574 | Time 17.6003, Epoch Time 254.0765(252.4871), Bit/dim 1.0931(best: 1.0927), Xent 0.0313, Loss 1.1087, Error 0.0099(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4019 | Time 31.2990(31.8689) | Bit/dim 1.0944(1.0985) | Xent 0.0446(0.0422) | Loss 1.1167(1.1196) | Error 0.0135(0.0130) Steps 440(440.56) | Grad Norm 0.5308(0.5505) | Total Time 10.00(10.00)\n",
      "Iter 4020 | Time 30.9552(31.8415) | Bit/dim 1.1019(1.0986) | Xent 0.0428(0.0422) | Loss 1.1233(1.1197) | Error 0.0132(0.0130) Steps 440(440.54) | Grad Norm 0.4527(0.5476) | Total Time 10.00(10.00)\n",
      "Iter 4021 | Time 32.5277(31.8621) | Bit/dim 1.0979(1.0986) | Xent 0.0349(0.0420) | Loss 1.1154(1.1196) | Error 0.0119(0.0129) Steps 440(440.52) | Grad Norm 0.2121(0.5375) | Total Time 10.00(10.00)\n",
      "Iter 4022 | Time 32.4058(31.8784) | Bit/dim 1.0979(1.0985) | Xent 0.0475(0.0422) | Loss 1.1217(1.1196) | Error 0.0148(0.0130) Steps 440(440.51) | Grad Norm 0.4277(0.5342) | Total Time 10.00(10.00)\n",
      "Iter 4023 | Time 32.0534(31.8837) | Bit/dim 1.0986(1.0985) | Xent 0.0409(0.0422) | Loss 1.1190(1.1196) | Error 0.0134(0.0130) Steps 440(440.49) | Grad Norm 0.1764(0.5235) | Total Time 10.00(10.00)\n",
      "Iter 4024 | Time 31.9228(31.8848) | Bit/dim 1.0967(1.0985) | Xent 0.0399(0.0421) | Loss 1.1166(1.1195) | Error 0.0122(0.0130) Steps 440(440.48) | Grad Norm 0.3276(0.5176) | Total Time 10.00(10.00)\n",
      "Iter 4025 | Time 31.7081(31.8795) | Bit/dim 1.1004(1.0985) | Xent 0.0369(0.0419) | Loss 1.1189(1.1195) | Error 0.0121(0.0130) Steps 440(440.46) | Grad Norm 0.4236(0.5148) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0575 | Time 17.7920, Epoch Time 253.7055(252.5237), Bit/dim 1.0927(best: 1.0927), Xent 0.0336, Loss 1.1095, Error 0.0098(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4026 | Time 31.9360(31.8812) | Bit/dim 1.0967(1.0985) | Xent 0.0408(0.0419) | Loss 1.1171(1.1194) | Error 0.0119(0.0129) Steps 440(440.45) | Grad Norm 0.2956(0.5082) | Total Time 10.00(10.00)\n",
      "Iter 4027 | Time 30.9271(31.8526) | Bit/dim 1.0999(1.0985) | Xent 0.0437(0.0420) | Loss 1.1217(1.1195) | Error 0.0131(0.0129) Steps 440(440.44) | Grad Norm 0.8193(0.5175) | Total Time 10.00(10.00)\n",
      "Iter 4028 | Time 31.5407(31.8432) | Bit/dim 1.1063(1.0988) | Xent 0.0423(0.0420) | Loss 1.1275(1.1197) | Error 0.0134(0.0129) Steps 440(440.42) | Grad Norm 0.2977(0.5109) | Total Time 10.00(10.00)\n",
      "Iter 4029 | Time 30.8519(31.8135) | Bit/dim 1.0961(1.0987) | Xent 0.0389(0.0419) | Loss 1.1156(1.1196) | Error 0.0121(0.0129) Steps 440(440.41) | Grad Norm 0.7023(0.5167) | Total Time 10.00(10.00)\n",
      "Iter 4030 | Time 33.4852(31.8637) | Bit/dim 1.0952(1.0986) | Xent 0.0423(0.0419) | Loss 1.1164(1.1195) | Error 0.0140(0.0129) Steps 440(440.40) | Grad Norm 0.2866(0.5098) | Total Time 10.00(10.00)\n",
      "Iter 4031 | Time 31.6877(31.8584) | Bit/dim 1.0989(1.0986) | Xent 0.0426(0.0419) | Loss 1.1202(1.1195) | Error 0.0132(0.0130) Steps 440(440.39) | Grad Norm 0.6514(0.5140) | Total Time 10.00(10.00)\n",
      "Iter 4032 | Time 32.3608(31.8734) | Bit/dim 1.0958(1.0985) | Xent 0.0425(0.0419) | Loss 1.1171(1.1195) | Error 0.0139(0.0130) Steps 446(440.55) | Grad Norm 0.3480(0.5090) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0576 | Time 17.4593, Epoch Time 253.1471(252.5424), Bit/dim 1.0931(best: 1.0927), Xent 0.0329, Loss 1.1096, Error 0.0107(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4033 | Time 30.8058(31.8414) | Bit/dim 1.1004(1.0986) | Xent 0.0382(0.0418) | Loss 1.1195(1.1195) | Error 0.0119(0.0130) Steps 440(440.54) | Grad Norm 0.5225(0.5094) | Total Time 10.00(10.00)\n",
      "Iter 4034 | Time 32.8651(31.8721) | Bit/dim 1.0941(1.0984) | Xent 0.0420(0.0418) | Loss 1.1151(1.1193) | Error 0.0138(0.0130) Steps 446(440.70) | Grad Norm 0.5194(0.5097) | Total Time 10.00(10.00)\n",
      "Iter 4035 | Time 31.9118(31.8733) | Bit/dim 1.0985(1.0984) | Xent 0.0403(0.0418) | Loss 1.1186(1.1193) | Error 0.0121(0.0130) Steps 440(440.68) | Grad Norm 0.2723(0.5026) | Total Time 10.00(10.00)\n",
      "Iter 4036 | Time 32.2885(31.8858) | Bit/dim 1.0998(1.0985) | Xent 0.0424(0.0418) | Loss 1.1210(1.1194) | Error 0.0126(0.0129) Steps 440(440.66) | Grad Norm 0.4441(0.5009) | Total Time 10.00(10.00)\n",
      "Iter 4037 | Time 32.1264(31.8930) | Bit/dim 1.0946(1.0984) | Xent 0.0442(0.0419) | Loss 1.1166(1.1193) | Error 0.0134(0.0130) Steps 440(440.64) | Grad Norm 0.4260(0.4986) | Total Time 10.00(10.00)\n",
      "Iter 4038 | Time 31.0695(31.8683) | Bit/dim 1.1004(1.0984) | Xent 0.0441(0.0419) | Loss 1.1224(1.1194) | Error 0.0132(0.0130) Steps 440(440.62) | Grad Norm 0.3608(0.4945) | Total Time 10.00(10.00)\n",
      "Iter 4039 | Time 31.7787(31.8656) | Bit/dim 1.1012(1.0985) | Xent 0.0399(0.0419) | Loss 1.1211(1.1194) | Error 0.0126(0.0130) Steps 440(440.60) | Grad Norm 0.3330(0.4896) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0577 | Time 17.6266, Epoch Time 253.5612(252.5730), Bit/dim 1.0926(best: 1.0927), Xent 0.0340, Loss 1.1096, Error 0.0097(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4040 | Time 30.9843(31.8392) | Bit/dim 1.0972(1.0985) | Xent 0.0470(0.0420) | Loss 1.1207(1.1195) | Error 0.0134(0.0130) Steps 440(440.58) | Grad Norm 0.2173(0.4815) | Total Time 10.00(10.00)\n",
      "Iter 4041 | Time 31.0837(31.8165) | Bit/dim 1.0982(1.0985) | Xent 0.0419(0.0420) | Loss 1.1192(1.1195) | Error 0.0120(0.0129) Steps 440(440.57) | Grad Norm 0.5122(0.4824) | Total Time 10.00(10.00)\n",
      "Iter 4042 | Time 31.8891(31.8187) | Bit/dim 1.0953(1.0984) | Xent 0.0475(0.0422) | Loss 1.1190(1.1195) | Error 0.0149(0.0130) Steps 440(440.55) | Grad Norm 0.4140(0.4803) | Total Time 10.00(10.00)\n",
      "Iter 4043 | Time 32.3773(31.8354) | Bit/dim 1.0958(1.0983) | Xent 0.0407(0.0421) | Loss 1.1161(1.1193) | Error 0.0128(0.0130) Steps 440(440.53) | Grad Norm 0.4893(0.4806) | Total Time 10.00(10.00)\n",
      "Iter 4044 | Time 33.0099(31.8707) | Bit/dim 1.1038(1.0984) | Xent 0.0354(0.0419) | Loss 1.1215(1.1194) | Error 0.0134(0.0130) Steps 440(440.52) | Grad Norm 0.3673(0.4772) | Total Time 10.00(10.00)\n",
      "Iter 4045 | Time 31.5666(31.8615) | Bit/dim 1.1004(1.0985) | Xent 0.0512(0.0422) | Loss 1.1260(1.1196) | Error 0.0151(0.0131) Steps 440(440.50) | Grad Norm 0.3874(0.4745) | Total Time 10.00(10.00)\n",
      "Iter 4046 | Time 32.0316(31.8667) | Bit/dim 1.0958(1.0984) | Xent 0.0413(0.0422) | Loss 1.1164(1.1195) | Error 0.0122(0.0130) Steps 440(440.49) | Grad Norm 0.3437(0.4706) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0578 | Time 17.7446, Epoch Time 253.0957(252.5886), Bit/dim 1.0921(best: 1.0926), Xent 0.0346, Loss 1.1094, Error 0.0110(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4047 | Time 31.8642(31.8666) | Bit/dim 1.0995(1.0985) | Xent 0.0371(0.0420) | Loss 1.1180(1.1195) | Error 0.0118(0.0130) Steps 440(440.47) | Grad Norm 0.5368(0.4726) | Total Time 10.00(10.00)\n",
      "Iter 4048 | Time 30.8018(31.8346) | Bit/dim 1.0964(1.0984) | Xent 0.0441(0.0421) | Loss 1.1184(1.1194) | Error 0.0138(0.0130) Steps 440(440.46) | Grad Norm 0.4200(0.4710) | Total Time 10.00(10.00)\n",
      "Iter 4049 | Time 31.8395(31.8348) | Bit/dim 1.1007(1.0985) | Xent 0.0401(0.0420) | Loss 1.1208(1.1195) | Error 0.0121(0.0130) Steps 440(440.44) | Grad Norm 0.3813(0.4683) | Total Time 10.00(10.00)\n",
      "Iter 4050 | Time 31.3765(31.8210) | Bit/dim 1.1009(1.0985) | Xent 0.0384(0.0419) | Loss 1.1201(1.1195) | Error 0.0104(0.0129) Steps 440(440.43) | Grad Norm 0.7393(0.4764) | Total Time 10.00(10.00)\n",
      "Iter 4051 | Time 30.9093(31.7937) | Bit/dim 1.0963(1.0985) | Xent 0.0437(0.0420) | Loss 1.1182(1.1195) | Error 0.0131(0.0129) Steps 440(440.42) | Grad Norm 0.5255(0.4779) | Total Time 10.00(10.00)\n",
      "Iter 4052 | Time 32.1783(31.8052) | Bit/dim 1.1000(1.0985) | Xent 0.0461(0.0421) | Loss 1.1231(1.1196) | Error 0.0155(0.0130) Steps 446(440.59) | Grad Norm 0.6596(0.4834) | Total Time 10.00(10.00)\n",
      "Iter 4053 | Time 33.0743(31.8433) | Bit/dim 1.0922(1.0983) | Xent 0.0444(0.0422) | Loss 1.1145(1.1194) | Error 0.0130(0.0130) Steps 434(440.39) | Grad Norm 0.3133(0.4783) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0579 | Time 17.8999, Epoch Time 252.4833(252.5855), Bit/dim 1.0925(best: 1.0921), Xent 0.0332, Loss 1.1091, Error 0.0099(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4054 | Time 32.2072(31.8542) | Bit/dim 1.1010(1.0984) | Xent 0.0364(0.0420) | Loss 1.1193(1.1194) | Error 0.0109(0.0129) Steps 440(440.38) | Grad Norm 0.8150(0.4884) | Total Time 10.00(10.00)\n",
      "Iter 4055 | Time 33.2498(31.8961) | Bit/dim 1.0999(1.0985) | Xent 0.0399(0.0419) | Loss 1.1198(1.1194) | Error 0.0131(0.0129) Steps 440(440.37) | Grad Norm 0.4015(0.4858) | Total Time 10.00(10.00)\n",
      "Iter 4056 | Time 32.2755(31.9075) | Bit/dim 1.0946(1.0983) | Xent 0.0408(0.0419) | Loss 1.1149(1.1193) | Error 0.0151(0.0130) Steps 446(440.53) | Grad Norm 0.5257(0.4870) | Total Time 10.00(10.00)\n",
      "Iter 4057 | Time 32.3357(31.9203) | Bit/dim 1.1007(1.0984) | Xent 0.0445(0.0420) | Loss 1.1230(1.1194) | Error 0.0148(0.0131) Steps 440(440.52) | Grad Norm 0.2746(0.4806) | Total Time 10.00(10.00)\n",
      "Iter 4058 | Time 33.3296(31.9626) | Bit/dim 1.0967(1.0984) | Xent 0.0464(0.0421) | Loss 1.1198(1.1194) | Error 0.0136(0.0131) Steps 446(440.68) | Grad Norm 0.3916(0.4779) | Total Time 10.00(10.00)\n",
      "Iter 4059 | Time 31.9143(31.9611) | Bit/dim 1.0949(1.0983) | Xent 0.0416(0.0421) | Loss 1.1157(1.1193) | Error 0.0126(0.0131) Steps 440(440.66) | Grad Norm 0.7552(0.4862) | Total Time 10.00(10.00)\n",
      "Iter 4060 | Time 31.7147(31.9537) | Bit/dim 1.0999(1.0983) | Xent 0.0385(0.0420) | Loss 1.1191(1.1193) | Error 0.0106(0.0130) Steps 446(440.82) | Grad Norm 0.3558(0.4823) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0580 | Time 17.8327, Epoch Time 257.9770(252.7472), Bit/dim 1.0926(best: 1.0921), Xent 0.0330, Loss 1.1091, Error 0.0101(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4061 | Time 32.7029(31.9762) | Bit/dim 1.1006(1.0984) | Xent 0.0473(0.0421) | Loss 1.1243(1.1194) | Error 0.0146(0.0130) Steps 440(440.80) | Grad Norm 0.8526(0.4934) | Total Time 10.00(10.00)\n",
      "Iter 4062 | Time 31.3668(31.9579) | Bit/dim 1.0988(1.0984) | Xent 0.0413(0.0421) | Loss 1.1194(1.1194) | Error 0.0139(0.0131) Steps 440(440.77) | Grad Norm 0.2289(0.4855) | Total Time 10.00(10.00)\n",
      "Iter 4063 | Time 31.9856(31.9588) | Bit/dim 1.0969(1.0983) | Xent 0.0362(0.0419) | Loss 1.1150(1.1193) | Error 0.0114(0.0130) Steps 440(440.75) | Grad Norm 0.7404(0.4931) | Total Time 10.00(10.00)\n",
      "Iter 4064 | Time 31.0894(31.9327) | Bit/dim 1.0948(1.0982) | Xent 0.0443(0.0420) | Loss 1.1170(1.1192) | Error 0.0141(0.0130) Steps 446(440.91) | Grad Norm 0.4421(0.4916) | Total Time 10.00(10.00)\n",
      "Iter 4065 | Time 31.4983(31.9197) | Bit/dim 1.0966(1.0982) | Xent 0.0438(0.0421) | Loss 1.1185(1.1192) | Error 0.0144(0.0131) Steps 446(441.06) | Grad Norm 1.0310(0.5078) | Total Time 10.00(10.00)\n",
      "Iter 4066 | Time 32.0372(31.9232) | Bit/dim 1.0995(1.0982) | Xent 0.0432(0.0421) | Loss 1.1212(1.1193) | Error 0.0129(0.0131) Steps 446(441.21) | Grad Norm 0.4468(0.5060) | Total Time 10.00(10.00)\n",
      "Iter 4067 | Time 32.1264(31.9293) | Bit/dim 1.1007(1.0983) | Xent 0.0413(0.0421) | Loss 1.1213(1.1193) | Error 0.0136(0.0131) Steps 440(441.17) | Grad Norm 0.6894(0.5115) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0581 | Time 17.7821, Epoch Time 253.0550(252.7565), Bit/dim 1.0931(best: 1.0921), Xent 0.0343, Loss 1.1103, Error 0.0104(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4068 | Time 32.0243(31.9321) | Bit/dim 1.1088(1.0986) | Xent 0.0457(0.0422) | Loss 1.1317(1.1197) | Error 0.0135(0.0131) Steps 440(441.14) | Grad Norm 0.8413(0.5214) | Total Time 10.00(10.00)\n",
      "Iter 4069 | Time 32.2544(31.9418) | Bit/dim 1.1017(1.0987) | Xent 0.0403(0.0421) | Loss 1.1218(1.1198) | Error 0.0128(0.0131) Steps 440(441.10) | Grad Norm 0.5791(0.5231) | Total Time 10.00(10.00)\n",
      "Iter 4070 | Time 32.2299(31.9504) | Bit/dim 1.0981(1.0987) | Xent 0.0386(0.0420) | Loss 1.1174(1.1197) | Error 0.0131(0.0131) Steps 446(441.25) | Grad Norm 1.0117(0.5378) | Total Time 10.00(10.00)\n",
      "Iter 4071 | Time 31.8762(31.9482) | Bit/dim 1.0920(1.0985) | Xent 0.0484(0.0422) | Loss 1.1162(1.1196) | Error 0.0149(0.0132) Steps 440(441.21) | Grad Norm 0.4500(0.5351) | Total Time 10.00(10.00)\n",
      "Iter 4072 | Time 31.7302(31.9417) | Bit/dim 1.0939(1.0984) | Xent 0.0456(0.0423) | Loss 1.1168(1.1195) | Error 0.0142(0.0132) Steps 440(441.18) | Grad Norm 0.9231(0.5468) | Total Time 10.00(10.00)\n",
      "Iter 4073 | Time 32.0730(31.9456) | Bit/dim 1.0981(1.0983) | Xent 0.0416(0.0423) | Loss 1.1189(1.1195) | Error 0.0124(0.0132) Steps 440(441.14) | Grad Norm 0.1992(0.5363) | Total Time 10.00(10.00)\n",
      "Iter 4074 | Time 31.8595(31.9430) | Bit/dim 1.0947(1.0982) | Xent 0.0366(0.0421) | Loss 1.1130(1.1193) | Error 0.0125(0.0131) Steps 440(441.11) | Grad Norm 1.0233(0.5509) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0582 | Time 17.7256, Epoch Time 254.5049(252.8089), Bit/dim 1.0924(best: 1.0921), Xent 0.0316, Loss 1.1082, Error 0.0088(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4075 | Time 30.8227(31.9094) | Bit/dim 1.0980(1.0982) | Xent 0.0459(0.0422) | Loss 1.1210(1.1193) | Error 0.0151(0.0132) Steps 440(441.07) | Grad Norm 0.3508(0.5449) | Total Time 10.00(10.00)\n",
      "Iter 4076 | Time 31.7697(31.9052) | Bit/dim 1.1007(1.0983) | Xent 0.0392(0.0421) | Loss 1.1203(1.1194) | Error 0.0121(0.0132) Steps 440(441.04) | Grad Norm 0.4889(0.5433) | Total Time 10.00(10.00)\n",
      "Iter 4077 | Time 31.7467(31.9005) | Bit/dim 1.1012(1.0984) | Xent 0.0451(0.0422) | Loss 1.1238(1.1195) | Error 0.0131(0.0132) Steps 440(441.01) | Grad Norm 0.8351(0.5520) | Total Time 10.00(10.00)\n",
      "Iter 4078 | Time 31.4981(31.8884) | Bit/dim 1.0944(1.0983) | Xent 0.0513(0.0425) | Loss 1.1201(1.1195) | Error 0.0148(0.0132) Steps 440(440.98) | Grad Norm 0.6332(0.5544) | Total Time 10.00(10.00)\n",
      "Iter 4079 | Time 31.0260(31.8625) | Bit/dim 1.0956(1.0982) | Xent 0.0375(0.0424) | Loss 1.1143(1.1194) | Error 0.0125(0.0132) Steps 440(440.95) | Grad Norm 0.5879(0.5554) | Total Time 10.00(10.00)\n",
      "Iter 4080 | Time 31.8027(31.8607) | Bit/dim 1.1003(1.0983) | Xent 0.0444(0.0424) | Loss 1.1225(1.1195) | Error 0.0120(0.0132) Steps 446(441.10) | Grad Norm 0.3554(0.5494) | Total Time 10.00(10.00)\n",
      "Iter 4081 | Time 33.0721(31.8971) | Bit/dim 1.0981(1.0982) | Xent 0.0428(0.0424) | Loss 1.1195(1.1195) | Error 0.0132(0.0132) Steps 440(441.07) | Grad Norm 0.4897(0.5477) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0583 | Time 17.6923, Epoch Time 252.1272(252.7885), Bit/dim 1.0931(best: 1.0921), Xent 0.0340, Loss 1.1101, Error 0.0106(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4082 | Time 32.0381(31.9013) | Bit/dim 1.1004(1.0983) | Xent 0.0424(0.0424) | Loss 1.1216(1.1195) | Error 0.0128(0.0131) Steps 440(441.04) | Grad Norm 0.2384(0.5384) | Total Time 10.00(10.00)\n",
      "Iter 4083 | Time 32.0890(31.9069) | Bit/dim 1.1002(1.0984) | Xent 0.0431(0.0424) | Loss 1.1217(1.1196) | Error 0.0149(0.0132) Steps 440(441.01) | Grad Norm 0.3171(0.5317) | Total Time 10.00(10.00)\n",
      "Iter 4084 | Time 32.2982(31.9187) | Bit/dim 1.0989(1.0984) | Xent 0.0389(0.0423) | Loss 1.1183(1.1196) | Error 0.0125(0.0132) Steps 440(440.98) | Grad Norm 0.2984(0.5247) | Total Time 10.00(10.00)\n",
      "Iter 4085 | Time 32.5498(31.9376) | Bit/dim 1.0965(1.0983) | Xent 0.0456(0.0424) | Loss 1.1193(1.1195) | Error 0.0148(0.0132) Steps 440(440.95) | Grad Norm 0.3412(0.5192) | Total Time 10.00(10.00)\n",
      "Iter 4086 | Time 31.1069(31.9127) | Bit/dim 1.0995(1.0984) | Xent 0.0444(0.0425) | Loss 1.1216(1.1196) | Error 0.0140(0.0132) Steps 440(440.92) | Grad Norm 0.1630(0.5085) | Total Time 10.00(10.00)\n",
      "Iter 4087 | Time 31.1629(31.8902) | Bit/dim 1.0939(1.0982) | Xent 0.0429(0.0425) | Loss 1.1154(1.1195) | Error 0.0131(0.0132) Steps 440(440.89) | Grad Norm 0.3551(0.5039) | Total Time 10.00(10.00)\n",
      "Iter 4088 | Time 33.5043(31.9386) | Bit/dim 1.0993(1.0983) | Xent 0.0450(0.0426) | Loss 1.1218(1.1196) | Error 0.0130(0.0132) Steps 440(440.86) | Grad Norm 0.5832(0.5063) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0584 | Time 17.4340, Epoch Time 254.4870(252.8394), Bit/dim 1.0929(best: 1.0921), Xent 0.0316, Loss 1.1087, Error 0.0091(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4089 | Time 30.8316(31.9054) | Bit/dim 1.0981(1.0983) | Xent 0.0433(0.0426) | Loss 1.1198(1.1196) | Error 0.0138(0.0133) Steps 440(440.84) | Grad Norm 0.3358(0.5012) | Total Time 10.00(10.00)\n",
      "Iter 4090 | Time 32.1741(31.9135) | Bit/dim 1.0944(1.0981) | Xent 0.0422(0.0426) | Loss 1.1155(1.1194) | Error 0.0130(0.0132) Steps 440(440.81) | Grad Norm 0.3475(0.4966) | Total Time 10.00(10.00)\n",
      "Iter 4091 | Time 31.9836(31.9156) | Bit/dim 1.0967(1.0981) | Xent 0.0388(0.0425) | Loss 1.1161(1.1193) | Error 0.0115(0.0132) Steps 440(440.79) | Grad Norm 0.3109(0.4910) | Total Time 10.00(10.00)\n",
      "Iter 4092 | Time 32.5326(31.9341) | Bit/dim 1.1043(1.0983) | Xent 0.0461(0.0426) | Loss 1.1273(1.1196) | Error 0.0129(0.0132) Steps 440(440.76) | Grad Norm 0.2597(0.4841) | Total Time 10.00(10.00)\n",
      "Iter 4093 | Time 31.8273(31.9309) | Bit/dim 1.0961(1.0982) | Xent 0.0476(0.0427) | Loss 1.1199(1.1196) | Error 0.0145(0.0132) Steps 446(440.92) | Grad Norm 0.2433(0.4769) | Total Time 10.00(10.00)\n",
      "Iter 4094 | Time 32.2160(31.9394) | Bit/dim 1.0978(1.0982) | Xent 0.0407(0.0427) | Loss 1.1181(1.1195) | Error 0.0119(0.0132) Steps 446(441.07) | Grad Norm 0.2456(0.4699) | Total Time 10.00(10.00)\n",
      "Iter 4095 | Time 31.0203(31.9119) | Bit/dim 1.0967(1.0982) | Xent 0.0459(0.0428) | Loss 1.1196(1.1195) | Error 0.0134(0.0132) Steps 440(441.04) | Grad Norm 0.3957(0.4677) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0585 | Time 17.8780, Epoch Time 253.1280(252.8481), Bit/dim 1.0921(best: 1.0921), Xent 0.0345, Loss 1.1093, Error 0.0110(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4096 | Time 32.0519(31.9161) | Bit/dim 1.0955(1.0981) | Xent 0.0469(0.0429) | Loss 1.1189(1.1195) | Error 0.0138(0.0132) Steps 446(441.19) | Grad Norm 0.3415(0.4639) | Total Time 10.00(10.00)\n",
      "Iter 4097 | Time 31.0686(31.8906) | Bit/dim 1.0987(1.0981) | Xent 0.0394(0.0428) | Loss 1.1184(1.1195) | Error 0.0135(0.0132) Steps 440(441.15) | Grad Norm 0.4884(0.4646) | Total Time 10.00(10.00)\n",
      "Iter 4098 | Time 31.9412(31.8921) | Bit/dim 1.0953(1.0980) | Xent 0.0388(0.0427) | Loss 1.1147(1.1193) | Error 0.0130(0.0132) Steps 446(441.30) | Grad Norm 0.3945(0.4625) | Total Time 10.00(10.00)\n",
      "Iter 4099 | Time 30.7755(31.8587) | Bit/dim 1.1019(1.0981) | Xent 0.0383(0.0425) | Loss 1.1210(1.1194) | Error 0.0120(0.0132) Steps 440(441.26) | Grad Norm 0.2452(0.4560) | Total Time 10.00(10.00)\n",
      "Iter 4100 | Time 32.4368(31.8760) | Bit/dim 1.1003(1.0982) | Xent 0.0385(0.0424) | Loss 1.1196(1.1194) | Error 0.0119(0.0131) Steps 440(441.22) | Grad Norm 0.3754(0.4536) | Total Time 10.00(10.00)\n",
      "Iter 4101 | Time 30.8970(31.8466) | Bit/dim 1.0961(1.0981) | Xent 0.0353(0.0422) | Loss 1.1137(1.1192) | Error 0.0128(0.0131) Steps 440(441.19) | Grad Norm 0.1761(0.4453) | Total Time 10.00(10.00)\n",
      "Iter 4102 | Time 31.0571(31.8229) | Bit/dim 1.0996(1.0982) | Xent 0.0441(0.0423) | Loss 1.1217(1.1193) | Error 0.0142(0.0132) Steps 440(441.15) | Grad Norm 0.4025(0.4440) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0586 | Time 17.7897, Epoch Time 250.5384(252.7788), Bit/dim 1.0928(best: 1.0921), Xent 0.0322, Loss 1.1088, Error 0.0093(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4103 | Time 32.1229(31.8319) | Bit/dim 1.0990(1.0982) | Xent 0.0431(0.0423) | Loss 1.1206(1.1193) | Error 0.0120(0.0131) Steps 440(441.12) | Grad Norm 0.2047(0.4368) | Total Time 10.00(10.00)\n",
      "Iter 4104 | Time 31.6373(31.8261) | Bit/dim 1.1001(1.0983) | Xent 0.0438(0.0423) | Loss 1.1219(1.1194) | Error 0.0142(0.0132) Steps 440(441.08) | Grad Norm 0.4295(0.4366) | Total Time 10.00(10.00)\n",
      "Iter 4105 | Time 31.3438(31.8116) | Bit/dim 1.1017(1.0984) | Xent 0.0457(0.0424) | Loss 1.1246(1.1196) | Error 0.0139(0.0132) Steps 440(441.05) | Grad Norm 0.2500(0.4310) | Total Time 10.00(10.00)\n",
      "Iter 4106 | Time 32.2618(31.8251) | Bit/dim 1.0964(1.0983) | Xent 0.0438(0.0425) | Loss 1.1183(1.1195) | Error 0.0125(0.0132) Steps 440(441.02) | Grad Norm 0.5747(0.4353) | Total Time 10.00(10.00)\n",
      "Iter 4107 | Time 31.8918(31.8271) | Bit/dim 1.0975(1.0983) | Xent 0.0432(0.0425) | Loss 1.1191(1.1195) | Error 0.0132(0.0132) Steps 440(440.99) | Grad Norm 0.3683(0.4333) | Total Time 10.00(10.00)\n",
      "Iter 4108 | Time 31.5604(31.8191) | Bit/dim 1.0951(1.0982) | Xent 0.0361(0.0423) | Loss 1.1132(1.1193) | Error 0.0120(0.0131) Steps 440(440.96) | Grad Norm 0.2677(0.4283) | Total Time 10.00(10.00)\n",
      "Iter 4109 | Time 31.6734(31.8148) | Bit/dim 1.0975(1.0982) | Xent 0.0411(0.0423) | Loss 1.1180(1.1193) | Error 0.0134(0.0131) Steps 440(440.93) | Grad Norm 0.7750(0.4387) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0587 | Time 17.6073, Epoch Time 253.0225(252.7861), Bit/dim 1.0922(best: 1.0921), Xent 0.0341, Loss 1.1092, Error 0.0103(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4110 | Time 31.6125(31.8087) | Bit/dim 1.0991(1.0982) | Xent 0.0433(0.0423) | Loss 1.1207(1.1193) | Error 0.0129(0.0131) Steps 440(440.90) | Grad Norm 0.2374(0.4327) | Total Time 10.00(10.00)\n",
      "Iter 4111 | Time 32.1273(31.8183) | Bit/dim 1.0974(1.0982) | Xent 0.0375(0.0422) | Loss 1.1162(1.1192) | Error 0.0124(0.0131) Steps 440(440.88) | Grad Norm 0.8216(0.4444) | Total Time 10.00(10.00)\n",
      "Iter 4112 | Time 32.8144(31.8481) | Bit/dim 1.1013(1.0983) | Xent 0.0393(0.0421) | Loss 1.1210(1.1193) | Error 0.0129(0.0131) Steps 440(440.85) | Grad Norm 0.2698(0.4391) | Total Time 10.00(10.00)\n",
      "Iter 4113 | Time 33.2622(31.8906) | Bit/dim 1.1008(1.0983) | Xent 0.0358(0.0419) | Loss 1.1187(1.1193) | Error 0.0121(0.0131) Steps 440(440.82) | Grad Norm 0.7742(0.4492) | Total Time 10.00(10.00)\n",
      "Iter 4114 | Time 31.1893(31.8695) | Bit/dim 1.0982(1.0983) | Xent 0.0447(0.0420) | Loss 1.1206(1.1193) | Error 0.0136(0.0131) Steps 440(440.80) | Grad Norm 0.6816(0.4561) | Total Time 10.00(10.00)\n",
      "Iter 4115 | Time 31.4656(31.8574) | Bit/dim 1.0978(1.0983) | Xent 0.0428(0.0420) | Loss 1.1192(1.1193) | Error 0.0141(0.0131) Steps 440(440.77) | Grad Norm 0.7245(0.4642) | Total Time 10.00(10.00)\n",
      "Iter 4116 | Time 32.3939(31.8735) | Bit/dim 1.0952(1.0982) | Xent 0.0480(0.0422) | Loss 1.1192(1.1193) | Error 0.0146(0.0132) Steps 440(440.75) | Grad Norm 0.5304(0.4662) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0588 | Time 17.4421, Epoch Time 255.4248(252.8653), Bit/dim 1.0919(best: 1.0921), Xent 0.0333, Loss 1.1085, Error 0.0101(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4117 | Time 31.2519(31.8549) | Bit/dim 1.1017(1.0983) | Xent 0.0415(0.0422) | Loss 1.1225(1.1194) | Error 0.0125(0.0131) Steps 440(440.73) | Grad Norm 0.3277(0.4620) | Total Time 10.00(10.00)\n",
      "Iter 4118 | Time 31.4287(31.8421) | Bit/dim 1.1006(1.0984) | Xent 0.0412(0.0421) | Loss 1.1212(1.1195) | Error 0.0138(0.0132) Steps 446(440.89) | Grad Norm 0.7584(0.4709) | Total Time 10.00(10.00)\n",
      "Iter 4119 | Time 31.8272(31.8416) | Bit/dim 1.0957(1.0983) | Xent 0.0458(0.0422) | Loss 1.1187(1.1194) | Error 0.0130(0.0132) Steps 440(440.86) | Grad Norm 0.4993(0.4718) | Total Time 10.00(10.00)\n",
      "Iter 4120 | Time 32.1144(31.8498) | Bit/dim 1.0935(1.0982) | Xent 0.0412(0.0422) | Loss 1.1140(1.1193) | Error 0.0120(0.0131) Steps 446(441.01) | Grad Norm 0.9476(0.4860) | Total Time 10.00(10.00)\n",
      "Iter 4121 | Time 33.0070(31.8845) | Bit/dim 1.0973(1.0981) | Xent 0.0421(0.0422) | Loss 1.1183(1.1192) | Error 0.0140(0.0131) Steps 440(440.98) | Grad Norm 0.7519(0.4940) | Total Time 10.00(10.00)\n",
      "Iter 4122 | Time 30.8391(31.8532) | Bit/dim 1.0974(1.0981) | Xent 0.0418(0.0422) | Loss 1.1183(1.1192) | Error 0.0128(0.0131) Steps 440(440.95) | Grad Norm 1.1601(0.5140) | Total Time 10.00(10.00)\n",
      "Iter 4123 | Time 31.1972(31.8335) | Bit/dim 1.0959(1.0981) | Xent 0.0408(0.0421) | Loss 1.1164(1.1191) | Error 0.0126(0.0131) Steps 446(441.11) | Grad Norm 0.6937(0.5194) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0589 | Time 17.5024, Epoch Time 251.9095(252.8366), Bit/dim 1.0929(best: 1.0919), Xent 0.0336, Loss 1.1098, Error 0.0101(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4124 | Time 31.7336(31.8305) | Bit/dim 1.1020(1.0982) | Xent 0.0449(0.0422) | Loss 1.1244(1.1193) | Error 0.0141(0.0131) Steps 440(441.07) | Grad Norm 0.4752(0.5181) | Total Time 10.00(10.00)\n",
      "Iter 4125 | Time 31.9597(31.8344) | Bit/dim 1.0993(1.0982) | Xent 0.0414(0.0422) | Loss 1.1200(1.1193) | Error 0.0140(0.0132) Steps 440(441.04) | Grad Norm 0.9200(0.5301) | Total Time 10.00(10.00)\n",
      "Iter 4126 | Time 32.4279(31.8522) | Bit/dim 1.0970(1.0982) | Xent 0.0483(0.0424) | Loss 1.1212(1.1194) | Error 0.0145(0.0132) Steps 440(441.01) | Grad Norm 0.4624(0.5281) | Total Time 10.00(10.00)\n",
      "Iter 4127 | Time 31.7978(31.8505) | Bit/dim 1.1003(1.0982) | Xent 0.0450(0.0425) | Loss 1.1228(1.1195) | Error 0.0141(0.0132) Steps 440(440.98) | Grad Norm 0.8444(0.5376) | Total Time 10.00(10.00)\n",
      "Iter 4128 | Time 31.4973(31.8399) | Bit/dim 1.1007(1.0983) | Xent 0.0398(0.0424) | Loss 1.1206(1.1195) | Error 0.0111(0.0132) Steps 440(440.95) | Grad Norm 0.4020(0.5335) | Total Time 10.00(10.00)\n",
      "Iter 4129 | Time 32.3782(31.8561) | Bit/dim 1.0945(1.0982) | Xent 0.0442(0.0424) | Loss 1.1167(1.1194) | Error 0.0130(0.0132) Steps 440(440.92) | Grad Norm 0.6633(0.5374) | Total Time 10.00(10.00)\n",
      "Iter 4130 | Time 31.1613(31.8352) | Bit/dim 1.0928(1.0980) | Xent 0.0370(0.0423) | Loss 1.1113(1.1192) | Error 0.0126(0.0132) Steps 440(440.89) | Grad Norm 0.3860(0.5329) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0590 | Time 17.7273, Epoch Time 253.1067(252.8447), Bit/dim 1.0922(best: 1.0919), Xent 0.0319, Loss 1.1081, Error 0.0094(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4131 | Time 31.0694(31.8123) | Bit/dim 1.0993(1.0981) | Xent 0.0424(0.0423) | Loss 1.1205(1.1192) | Error 0.0121(0.0131) Steps 440(440.87) | Grad Norm 0.5259(0.5327) | Total Time 10.00(10.00)\n",
      "Iter 4132 | Time 31.9280(31.8157) | Bit/dim 1.0998(1.0981) | Xent 0.0501(0.0425) | Loss 1.1249(1.1194) | Error 0.0145(0.0132) Steps 440(440.84) | Grad Norm 0.4269(0.5295) | Total Time 10.00(10.00)\n",
      "Iter 4133 | Time 31.9491(31.8197) | Bit/dim 1.1023(1.0982) | Xent 0.0416(0.0425) | Loss 1.1231(1.1195) | Error 0.0141(0.0132) Steps 440(440.82) | Grad Norm 0.2450(0.5210) | Total Time 10.00(10.00)\n",
      "Iter 4134 | Time 33.0309(31.8561) | Bit/dim 1.0932(1.0981) | Xent 0.0419(0.0425) | Loss 1.1142(1.1193) | Error 0.0130(0.0132) Steps 440(440.79) | Grad Norm 0.4132(0.5177) | Total Time 10.00(10.00)\n",
      "Iter 4135 | Time 32.0554(31.8621) | Bit/dim 1.1026(1.0982) | Xent 0.0483(0.0426) | Loss 1.1267(1.1196) | Error 0.0140(0.0132) Steps 440(440.77) | Grad Norm 0.5513(0.5187) | Total Time 10.00(10.00)\n",
      "Iter 4136 | Time 31.7715(31.8593) | Bit/dim 1.0996(1.0983) | Xent 0.0452(0.0427) | Loss 1.1223(1.1196) | Error 0.0138(0.0132) Steps 440(440.74) | Grad Norm 0.2902(0.5119) | Total Time 10.00(10.00)\n",
      "Iter 4137 | Time 31.9862(31.8631) | Bit/dim 1.0890(1.0980) | Xent 0.0416(0.0427) | Loss 1.1098(1.1193) | Error 0.0135(0.0132) Steps 440(440.72) | Grad Norm 0.2626(0.5044) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0591 | Time 17.7073, Epoch Time 254.2641(252.8873), Bit/dim 1.0916(best: 1.0919), Xent 0.0318, Loss 1.1075, Error 0.0093(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4138 | Time 32.7411(31.8895) | Bit/dim 1.0938(1.0979) | Xent 0.0357(0.0425) | Loss 1.1117(1.1191) | Error 0.0108(0.0132) Steps 440(440.70) | Grad Norm 0.4402(0.5025) | Total Time 10.00(10.00)\n",
      "Iter 4139 | Time 32.0080(31.8930) | Bit/dim 1.1008(1.0980) | Xent 0.0460(0.0426) | Loss 1.1238(1.1193) | Error 0.0142(0.0132) Steps 446(440.86) | Grad Norm 0.4539(0.5010) | Total Time 10.00(10.00)\n",
      "Iter 4140 | Time 30.8507(31.8618) | Bit/dim 1.0981(1.0980) | Xent 0.0442(0.0426) | Loss 1.1202(1.1193) | Error 0.0154(0.0133) Steps 440(440.83) | Grad Norm 0.4099(0.4983) | Total Time 10.00(10.00)\n",
      "Iter 4141 | Time 31.7104(31.8572) | Bit/dim 1.0940(1.0978) | Xent 0.0464(0.0427) | Loss 1.1172(1.1192) | Error 0.0132(0.0133) Steps 440(440.81) | Grad Norm 0.2943(0.4922) | Total Time 10.00(10.00)\n",
      "Iter 4142 | Time 31.4047(31.8436) | Bit/dim 1.1006(1.0979) | Xent 0.0415(0.0427) | Loss 1.1214(1.1193) | Error 0.0142(0.0133) Steps 440(440.78) | Grad Norm 0.3631(0.4883) | Total Time 10.00(10.00)\n",
      "Iter 4143 | Time 30.7545(31.8110) | Bit/dim 1.0967(1.0979) | Xent 0.0391(0.0426) | Loss 1.1163(1.1192) | Error 0.0124(0.0133) Steps 440(440.76) | Grad Norm 0.3422(0.4839) | Total Time 10.00(10.00)\n",
      "Iter 4144 | Time 32.1597(31.8214) | Bit/dim 1.0950(1.0978) | Xent 0.0450(0.0427) | Loss 1.1175(1.1191) | Error 0.0128(0.0132) Steps 440(440.74) | Grad Norm 0.3745(0.4806) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0592 | Time 17.7011, Epoch Time 252.0855(252.8632), Bit/dim 1.0924(best: 1.0916), Xent 0.0293, Loss 1.1070, Error 0.0092(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4145 | Time 31.8978(31.8237) | Bit/dim 1.0967(1.0978) | Xent 0.0416(0.0426) | Loss 1.1175(1.1191) | Error 0.0125(0.0132) Steps 440(440.72) | Grad Norm 0.4169(0.4787) | Total Time 10.00(10.00)\n",
      "Iter 4146 | Time 32.1758(31.8343) | Bit/dim 1.1008(1.0979) | Xent 0.0392(0.0425) | Loss 1.1204(1.1191) | Error 0.0122(0.0132) Steps 440(440.69) | Grad Norm 0.2963(0.4732) | Total Time 10.00(10.00)\n",
      "Iter 4147 | Time 32.0287(31.8401) | Bit/dim 1.0999(1.0979) | Xent 0.0426(0.0425) | Loss 1.1212(1.1192) | Error 0.0129(0.0132) Steps 440(440.67) | Grad Norm 0.3042(0.4682) | Total Time 10.00(10.00)\n",
      "Iter 4148 | Time 30.9079(31.8122) | Bit/dim 1.0985(1.0979) | Xent 0.0444(0.0426) | Loss 1.1207(1.1192) | Error 0.0156(0.0133) Steps 440(440.65) | Grad Norm 0.3930(0.4659) | Total Time 10.00(10.00)\n",
      "Iter 4149 | Time 31.4561(31.8015) | Bit/dim 1.0970(1.0979) | Xent 0.0400(0.0425) | Loss 1.1171(1.1192) | Error 0.0132(0.0133) Steps 446(440.81) | Grad Norm 0.5202(0.4675) | Total Time 10.00(10.00)\n",
      "Iter 4150 | Time 31.2894(31.7861) | Bit/dim 1.0951(1.0978) | Xent 0.0396(0.0424) | Loss 1.1150(1.1190) | Error 0.0132(0.0133) Steps 440(440.79) | Grad Norm 0.3924(0.4653) | Total Time 10.00(10.00)\n",
      "Iter 4151 | Time 32.1892(31.7982) | Bit/dim 1.1000(1.0979) | Xent 0.0505(0.0427) | Loss 1.1253(1.1192) | Error 0.0149(0.0133) Steps 440(440.77) | Grad Norm 0.6430(0.4706) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0593 | Time 17.7083, Epoch Time 252.1439(252.8416), Bit/dim 1.0925(best: 1.0916), Xent 0.0334, Loss 1.1092, Error 0.0102(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4152 | Time 32.0952(31.8071) | Bit/dim 1.0986(1.0979) | Xent 0.0399(0.0426) | Loss 1.1185(1.1192) | Error 0.0124(0.0133) Steps 440(440.74) | Grad Norm 0.2446(0.4638) | Total Time 10.00(10.00)\n",
      "Iter 4153 | Time 30.7424(31.7752) | Bit/dim 1.0969(1.0979) | Xent 0.0423(0.0426) | Loss 1.1180(1.1192) | Error 0.0134(0.0133) Steps 440(440.72) | Grad Norm 0.5719(0.4671) | Total Time 10.00(10.00)\n",
      "Iter 4154 | Time 31.8106(31.7762) | Bit/dim 1.0978(1.0979) | Xent 0.0426(0.0426) | Loss 1.1191(1.1192) | Error 0.0131(0.0133) Steps 440(440.70) | Grad Norm 0.3596(0.4639) | Total Time 10.00(10.00)\n",
      "Iter 4155 | Time 31.7567(31.7756) | Bit/dim 1.0954(1.0978) | Xent 0.0429(0.0426) | Loss 1.1168(1.1191) | Error 0.0128(0.0133) Steps 440(440.68) | Grad Norm 0.3993(0.4619) | Total Time 10.00(10.00)\n",
      "Iter 4156 | Time 31.9130(31.7798) | Bit/dim 1.1010(1.0979) | Xent 0.0405(0.0425) | Loss 1.1212(1.1192) | Error 0.0136(0.0133) Steps 446(440.84) | Grad Norm 0.3569(0.4588) | Total Time 10.00(10.00)\n",
      "Iter 4157 | Time 32.9136(31.8138) | Bit/dim 1.0977(1.0979) | Xent 0.0360(0.0423) | Loss 1.1157(1.1191) | Error 0.0102(0.0132) Steps 440(440.81) | Grad Norm 0.7642(0.4679) | Total Time 10.00(10.00)\n",
      "Iter 4158 | Time 31.6780(31.8097) | Bit/dim 1.0951(1.0978) | Xent 0.0403(0.0423) | Loss 1.1152(1.1189) | Error 0.0125(0.0132) Steps 446(440.97) | Grad Norm 0.2732(0.4621) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0594 | Time 17.6991, Epoch Time 253.3717(252.8575), Bit/dim 1.0921(best: 1.0916), Xent 0.0333, Loss 1.1087, Error 0.0105(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4159 | Time 30.8402(31.7806) | Bit/dim 1.0996(1.0979) | Xent 0.0425(0.0423) | Loss 1.1208(1.1190) | Error 0.0136(0.0132) Steps 440(440.94) | Grad Norm 0.3197(0.4578) | Total Time 10.00(10.00)\n",
      "Iter 4160 | Time 32.7584(31.8100) | Bit/dim 1.0968(1.0978) | Xent 0.0394(0.0422) | Loss 1.1165(1.1189) | Error 0.0131(0.0132) Steps 440(440.91) | Grad Norm 0.4624(0.4580) | Total Time 10.00(10.00)\n",
      "Iter 4161 | Time 31.2226(31.7923) | Bit/dim 1.0977(1.0978) | Xent 0.0402(0.0421) | Loss 1.1178(1.1189) | Error 0.0129(0.0132) Steps 440(440.88) | Grad Norm 0.3809(0.4556) | Total Time 10.00(10.00)\n",
      "Iter 4162 | Time 32.9650(31.8275) | Bit/dim 1.0967(1.0978) | Xent 0.0417(0.0421) | Loss 1.1175(1.1189) | Error 0.0135(0.0132) Steps 440(440.86) | Grad Norm 0.3131(0.4514) | Total Time 10.00(10.00)\n",
      "Iter 4163 | Time 32.1361(31.8368) | Bit/dim 1.0981(1.0978) | Xent 0.0480(0.0423) | Loss 1.1222(1.1190) | Error 0.0149(0.0132) Steps 434(440.65) | Grad Norm 0.4545(0.4515) | Total Time 10.00(10.00)\n",
      "Iter 4164 | Time 32.4029(31.8538) | Bit/dim 1.0941(1.0977) | Xent 0.0469(0.0424) | Loss 1.1176(1.1189) | Error 0.0146(0.0133) Steps 446(440.81) | Grad Norm 0.5103(0.4532) | Total Time 10.00(10.00)\n",
      "Iter 4165 | Time 31.1043(31.8313) | Bit/dim 1.1033(1.0979) | Xent 0.0446(0.0425) | Loss 1.1256(1.1191) | Error 0.0130(0.0133) Steps 440(440.79) | Grad Norm 0.2599(0.4474) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0595 | Time 17.6040, Epoch Time 253.7626(252.8847), Bit/dim 1.0924(best: 1.0916), Xent 0.0333, Loss 1.1091, Error 0.0107(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4166 | Time 32.9222(31.8640) | Bit/dim 1.0938(1.0977) | Xent 0.0410(0.0425) | Loss 1.1143(1.1190) | Error 0.0116(0.0132) Steps 440(440.76) | Grad Norm 0.3099(0.4433) | Total Time 10.00(10.00)\n",
      "Iter 4167 | Time 32.1961(31.8740) | Bit/dim 1.0987(1.0978) | Xent 0.0443(0.0425) | Loss 1.1208(1.1190) | Error 0.0139(0.0132) Steps 446(440.92) | Grad Norm 0.2326(0.4370) | Total Time 10.00(10.00)\n",
      "Iter 4168 | Time 31.3622(31.8586) | Bit/dim 1.0935(1.0976) | Xent 0.0446(0.0426) | Loss 1.1158(1.1189) | Error 0.0131(0.0132) Steps 440(440.89) | Grad Norm 0.4609(0.4377) | Total Time 10.00(10.00)\n",
      "Iter 4169 | Time 30.7421(31.8251) | Bit/dim 1.0963(1.0976) | Xent 0.0418(0.0425) | Loss 1.1172(1.1189) | Error 0.0125(0.0132) Steps 440(440.87) | Grad Norm 0.3732(0.4358) | Total Time 10.00(10.00)\n",
      "Iter 4170 | Time 30.8694(31.7965) | Bit/dim 1.0975(1.0976) | Xent 0.0398(0.0425) | Loss 1.1174(1.1188) | Error 0.0128(0.0132) Steps 440(440.84) | Grad Norm 0.3119(0.4320) | Total Time 10.00(10.00)\n",
      "Iter 4171 | Time 31.3142(31.7820) | Bit/dim 1.0983(1.0976) | Xent 0.0346(0.0422) | Loss 1.1156(1.1187) | Error 0.0110(0.0131) Steps 440(440.82) | Grad Norm 0.4027(0.4312) | Total Time 10.00(10.00)\n",
      "Iter 4172 | Time 31.9243(31.7863) | Bit/dim 1.1014(1.0977) | Xent 0.0411(0.0422) | Loss 1.1219(1.1188) | Error 0.0130(0.0131) Steps 440(440.79) | Grad Norm 0.8028(0.4423) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0596 | Time 17.9501, Epoch Time 252.1023(252.8612), Bit/dim 1.0926(best: 1.0916), Xent 0.0302, Loss 1.1077, Error 0.0086(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4173 | Time 30.7819(31.7561) | Bit/dim 1.0941(1.0976) | Xent 0.0326(0.0419) | Loss 1.1104(1.1186) | Error 0.0100(0.0130) Steps 440(440.77) | Grad Norm 0.4005(0.4411) | Total Time 10.00(10.00)\n",
      "Iter 4174 | Time 30.4748(31.7177) | Bit/dim 1.0996(1.0977) | Xent 0.0420(0.0419) | Loss 1.1206(1.1186) | Error 0.0131(0.0130) Steps 440(440.74) | Grad Norm 0.8538(0.4534) | Total Time 10.00(10.00)\n",
      "Iter 4175 | Time 32.4286(31.7390) | Bit/dim 1.0997(1.0977) | Xent 0.0481(0.0421) | Loss 1.1238(1.1188) | Error 0.0152(0.0131) Steps 440(440.72) | Grad Norm 0.3438(0.4501) | Total Time 10.00(10.00)\n",
      "Iter 4176 | Time 31.9907(31.7466) | Bit/dim 1.0974(1.0977) | Xent 0.0435(0.0421) | Loss 1.1191(1.1188) | Error 0.0134(0.0131) Steps 440(440.70) | Grad Norm 0.9854(0.4662) | Total Time 10.00(10.00)\n",
      "Iter 4177 | Time 32.4201(31.7668) | Bit/dim 1.0912(1.0975) | Xent 0.0371(0.0420) | Loss 1.1098(1.1185) | Error 0.0109(0.0130) Steps 440(440.68) | Grad Norm 0.3860(0.4638) | Total Time 10.00(10.00)\n",
      "Iter 4178 | Time 31.7953(31.7676) | Bit/dim 1.0996(1.0976) | Xent 0.0439(0.0420) | Loss 1.1216(1.1186) | Error 0.0141(0.0131) Steps 440(440.66) | Grad Norm 1.2269(0.4867) | Total Time 10.00(10.00)\n",
      "Iter 4179 | Time 31.2628(31.7525) | Bit/dim 1.1001(1.0977) | Xent 0.0441(0.0421) | Loss 1.1222(1.1187) | Error 0.0122(0.0130) Steps 446(440.82) | Grad Norm 0.2736(0.4803) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0597 | Time 18.0899, Epoch Time 251.8659(252.8314), Bit/dim 1.0929(best: 1.0916), Xent 0.0315, Loss 1.1086, Error 0.0085(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4180 | Time 32.6958(31.7808) | Bit/dim 1.0987(1.0977) | Xent 0.0404(0.0421) | Loss 1.1190(1.1187) | Error 0.0121(0.0130) Steps 440(440.79) | Grad Norm 0.7092(0.4872) | Total Time 10.00(10.00)\n",
      "Iter 4181 | Time 32.1653(31.7923) | Bit/dim 1.0935(1.0976) | Xent 0.0373(0.0419) | Loss 1.1121(1.1185) | Error 0.0125(0.0130) Steps 440(440.77) | Grad Norm 0.3418(0.4828) | Total Time 10.00(10.00)\n",
      "Iter 4182 | Time 33.4580(31.8423) | Bit/dim 1.0958(1.0975) | Xent 0.0485(0.0421) | Loss 1.1200(1.1186) | Error 0.0148(0.0131) Steps 440(440.75) | Grad Norm 0.7912(0.4921) | Total Time 10.00(10.00)\n",
      "Iter 4183 | Time 33.1683(31.8821) | Bit/dim 1.0936(1.0974) | Xent 0.0391(0.0420) | Loss 1.1131(1.1184) | Error 0.0096(0.0130) Steps 440(440.72) | Grad Norm 0.2972(0.4862) | Total Time 10.00(10.00)\n",
      "Iter 4184 | Time 31.4389(31.8688) | Bit/dim 1.0995(1.0975) | Xent 0.0413(0.0420) | Loss 1.1202(1.1185) | Error 0.0120(0.0129) Steps 440(440.70) | Grad Norm 0.3106(0.4809) | Total Time 10.00(10.00)\n",
      "Iter 4185 | Time 31.5929(31.8605) | Bit/dim 1.0999(1.0975) | Xent 0.0431(0.0420) | Loss 1.1214(1.1186) | Error 0.0129(0.0129) Steps 446(440.86) | Grad Norm 0.2755(0.4748) | Total Time 10.00(10.00)\n",
      "Iter 4186 | Time 31.2720(31.8428) | Bit/dim 1.1034(1.0977) | Xent 0.0444(0.0421) | Loss 1.1256(1.1188) | Error 0.0130(0.0129) Steps 446(441.02) | Grad Norm 0.2793(0.4689) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0598 | Time 17.7800, Epoch Time 256.2436(252.9337), Bit/dim 1.0919(best: 1.0916), Xent 0.0308, Loss 1.1073, Error 0.0095(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4187 | Time 31.9768(31.8469) | Bit/dim 1.0957(1.0977) | Xent 0.0448(0.0422) | Loss 1.1182(1.1188) | Error 0.0141(0.0130) Steps 440(440.99) | Grad Norm 0.3457(0.4652) | Total Time 10.00(10.00)\n",
      "Iter 4188 | Time 31.4450(31.8348) | Bit/dim 1.0957(1.0976) | Xent 0.0504(0.0424) | Loss 1.1208(1.1188) | Error 0.0141(0.0130) Steps 440(440.96) | Grad Norm 0.2854(0.4598) | Total Time 10.00(10.00)\n",
      "Iter 4189 | Time 32.3962(31.8516) | Bit/dim 1.0996(1.0977) | Xent 0.0351(0.0422) | Loss 1.1172(1.1188) | Error 0.0112(0.0129) Steps 440(440.93) | Grad Norm 0.4754(0.4603) | Total Time 10.00(10.00)\n",
      "Iter 4190 | Time 32.1923(31.8619) | Bit/dim 1.0950(1.0976) | Xent 0.0467(0.0423) | Loss 1.1184(1.1188) | Error 0.0152(0.0130) Steps 440(440.90) | Grad Norm 0.3761(0.4578) | Total Time 10.00(10.00)\n",
      "Iter 4191 | Time 31.0692(31.8381) | Bit/dim 1.0962(1.0975) | Xent 0.0434(0.0424) | Loss 1.1179(1.1187) | Error 0.0139(0.0130) Steps 440(440.87) | Grad Norm 0.7189(0.4656) | Total Time 10.00(10.00)\n",
      "Iter 4192 | Time 32.9805(31.8724) | Bit/dim 1.1002(1.0976) | Xent 0.0412(0.0423) | Loss 1.1208(1.1188) | Error 0.0105(0.0130) Steps 446(441.03) | Grad Norm 0.2793(0.4600) | Total Time 10.00(10.00)\n",
      "Iter 4193 | Time 32.3184(31.8857) | Bit/dim 1.1005(1.0977) | Xent 0.0444(0.0424) | Loss 1.1226(1.1189) | Error 0.0146(0.0130) Steps 440(441.00) | Grad Norm 0.6005(0.4642) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0599 | Time 17.6577, Epoch Time 254.7556(252.9884), Bit/dim 1.0919(best: 1.0916), Xent 0.0321, Loss 1.1080, Error 0.0097(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4194 | Time 31.7597(31.8820) | Bit/dim 1.0980(1.0977) | Xent 0.0393(0.0423) | Loss 1.1177(1.1189) | Error 0.0116(0.0130) Steps 440(440.97) | Grad Norm 0.3416(0.4605) | Total Time 10.00(10.00)\n",
      "Iter 4195 | Time 32.2374(31.8926) | Bit/dim 1.1025(1.0979) | Xent 0.0456(0.0424) | Loss 1.1253(1.1191) | Error 0.0148(0.0130) Steps 446(441.12) | Grad Norm 0.9689(0.4758) | Total Time 10.00(10.00)\n",
      "Iter 4196 | Time 32.4316(31.9088) | Bit/dim 1.0977(1.0979) | Xent 0.0436(0.0424) | Loss 1.1194(1.1191) | Error 0.0144(0.0131) Steps 446(441.26) | Grad Norm 0.3250(0.4713) | Total Time 10.00(10.00)\n",
      "Iter 4197 | Time 32.4211(31.9242) | Bit/dim 1.0969(1.0978) | Xent 0.0417(0.0424) | Loss 1.1177(1.1190) | Error 0.0135(0.0131) Steps 446(441.41) | Grad Norm 0.8431(0.4824) | Total Time 10.00(10.00)\n",
      "Iter 4198 | Time 31.9716(31.9256) | Bit/dim 1.0991(1.0979) | Xent 0.0398(0.0423) | Loss 1.1190(1.1190) | Error 0.0124(0.0131) Steps 440(441.36) | Grad Norm 0.2345(0.4750) | Total Time 10.00(10.00)\n",
      "Iter 4199 | Time 31.1382(31.9020) | Bit/dim 1.0932(1.0977) | Xent 0.0427(0.0424) | Loss 1.1145(1.1189) | Error 0.0126(0.0130) Steps 440(441.32) | Grad Norm 0.6397(0.4799) | Total Time 10.00(10.00)\n",
      "Iter 4200 | Time 31.2317(31.8819) | Bit/dim 1.0953(1.0976) | Xent 0.0478(0.0425) | Loss 1.1191(1.1189) | Error 0.0150(0.0131) Steps 440(441.28) | Grad Norm 0.4580(0.4793) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0600 | Time 17.5927, Epoch Time 253.3189(252.9983), Bit/dim 1.0925(best: 1.0916), Xent 0.0310, Loss 1.1080, Error 0.0104(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4201 | Time 31.2813(31.8638) | Bit/dim 1.0945(1.0976) | Xent 0.0415(0.0425) | Loss 1.1153(1.1188) | Error 0.0124(0.0131) Steps 440(441.24) | Grad Norm 0.6263(0.4837) | Total Time 10.00(10.00)\n",
      "Iter 4202 | Time 30.9764(31.8372) | Bit/dim 1.0983(1.0976) | Xent 0.0365(0.0423) | Loss 1.1166(1.1187) | Error 0.0122(0.0131) Steps 440(441.21) | Grad Norm 0.2405(0.4764) | Total Time 10.00(10.00)\n",
      "Iter 4203 | Time 32.0107(31.8424) | Bit/dim 1.0946(1.0975) | Xent 0.0441(0.0424) | Loss 1.1166(1.1187) | Error 0.0129(0.0131) Steps 440(441.17) | Grad Norm 0.4953(0.4770) | Total Time 10.00(10.00)\n",
      "Iter 4204 | Time 31.8822(31.8436) | Bit/dim 1.0981(1.0975) | Xent 0.0476(0.0425) | Loss 1.1219(1.1188) | Error 0.0142(0.0131) Steps 440(441.14) | Grad Norm 0.3482(0.4731) | Total Time 10.00(10.00)\n",
      "Iter 4205 | Time 31.8768(31.8446) | Bit/dim 1.0930(1.0974) | Xent 0.0471(0.0427) | Loss 1.1166(1.1187) | Error 0.0150(0.0131) Steps 440(441.10) | Grad Norm 0.4525(0.4725) | Total Time 10.00(10.00)\n",
      "Iter 4206 | Time 31.6068(31.8375) | Bit/dim 1.0973(1.0974) | Xent 0.0463(0.0428) | Loss 1.1205(1.1187) | Error 0.0124(0.0131) Steps 440(441.07) | Grad Norm 0.4386(0.4715) | Total Time 10.00(10.00)\n",
      "Iter 4207 | Time 32.0104(31.8427) | Bit/dim 1.1033(1.0975) | Xent 0.0473(0.0429) | Loss 1.1270(1.1190) | Error 0.0155(0.0132) Steps 440(441.04) | Grad Norm 1.0680(0.4894) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0601 | Time 17.9758, Epoch Time 252.2149(252.9748), Bit/dim 1.0924(best: 1.0916), Xent 0.0342, Loss 1.1095, Error 0.0101(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4208 | Time 32.6191(31.8660) | Bit/dim 1.0965(1.0975) | Xent 0.0370(0.0427) | Loss 1.1150(1.1189) | Error 0.0115(0.0131) Steps 446(441.19) | Grad Norm 0.4342(0.4877) | Total Time 10.00(10.00)\n",
      "Iter 4209 | Time 32.1513(31.8745) | Bit/dim 1.1001(1.0976) | Xent 0.0403(0.0427) | Loss 1.1202(1.1189) | Error 0.0114(0.0131) Steps 440(441.15) | Grad Norm 1.3231(0.5128) | Total Time 10.00(10.00)\n",
      "Iter 4210 | Time 30.8941(31.8451) | Bit/dim 1.0994(1.0976) | Xent 0.0384(0.0425) | Loss 1.1186(1.1189) | Error 0.0132(0.0131) Steps 440(441.12) | Grad Norm 0.8437(0.5227) | Total Time 10.00(10.00)\n",
      "Iter 4211 | Time 33.0562(31.8814) | Bit/dim 1.0962(1.0976) | Xent 0.0398(0.0424) | Loss 1.1161(1.1188) | Error 0.0130(0.0131) Steps 440(441.08) | Grad Norm 1.1000(0.5400) | Total Time 10.00(10.00)\n",
      "Iter 4212 | Time 32.0789(31.8874) | Bit/dim 1.0985(1.0976) | Xent 0.0426(0.0424) | Loss 1.1198(1.1189) | Error 0.0130(0.0131) Steps 440(441.05) | Grad Norm 0.3830(0.5353) | Total Time 10.00(10.00)\n",
      "Iter 4213 | Time 31.8983(31.8877) | Bit/dim 1.0974(1.0976) | Xent 0.0380(0.0423) | Loss 1.1165(1.1188) | Error 0.0115(0.0130) Steps 440(441.02) | Grad Norm 1.1766(0.5545) | Total Time 10.00(10.00)\n",
      "Iter 4214 | Time 32.3602(31.9019) | Bit/dim 1.0939(1.0975) | Xent 0.0445(0.0424) | Loss 1.1162(1.1187) | Error 0.0139(0.0131) Steps 440(440.99) | Grad Norm 0.3956(0.5498) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0602 | Time 17.6864, Epoch Time 255.9678(253.0646), Bit/dim 1.0911(best: 1.0916), Xent 0.0308, Loss 1.1065, Error 0.0104(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4215 | Time 32.8757(31.9311) | Bit/dim 1.0980(1.0975) | Xent 0.0398(0.0423) | Loss 1.1179(1.1187) | Error 0.0118(0.0130) Steps 440(440.96) | Grad Norm 0.9273(0.5611) | Total Time 10.00(10.00)\n",
      "Iter 4216 | Time 31.6880(31.9238) | Bit/dim 1.0990(1.0976) | Xent 0.0404(0.0422) | Loss 1.1192(1.1187) | Error 0.0122(0.0130) Steps 440(440.93) | Grad Norm 0.4826(0.5587) | Total Time 10.00(10.00)\n",
      "Iter 4217 | Time 31.6681(31.9161) | Bit/dim 1.0979(1.0976) | Xent 0.0387(0.0421) | Loss 1.1173(1.1187) | Error 0.0119(0.0130) Steps 440(440.90) | Grad Norm 0.4638(0.5559) | Total Time 10.00(10.00)\n",
      "Iter 4218 | Time 31.7155(31.9101) | Bit/dim 1.0982(1.0976) | Xent 0.0490(0.0423) | Loss 1.1227(1.1188) | Error 0.0150(0.0130) Steps 446(441.05) | Grad Norm 0.2686(0.5473) | Total Time 10.00(10.00)\n",
      "Iter 4219 | Time 31.1552(31.8874) | Bit/dim 1.0974(1.0976) | Xent 0.0387(0.0422) | Loss 1.1167(1.1187) | Error 0.0140(0.0131) Steps 440(441.02) | Grad Norm 0.6100(0.5492) | Total Time 10.00(10.00)\n",
      "Iter 4220 | Time 31.8417(31.8861) | Bit/dim 1.0941(1.0975) | Xent 0.0422(0.0422) | Loss 1.1152(1.1186) | Error 0.0131(0.0131) Steps 446(441.17) | Grad Norm 0.3397(0.5429) | Total Time 10.00(10.00)\n",
      "Iter 4221 | Time 32.5184(31.9050) | Bit/dim 1.0988(1.0975) | Xent 0.0422(0.0422) | Loss 1.1200(1.1186) | Error 0.0142(0.0131) Steps 440(441.14) | Grad Norm 0.3714(0.5377) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0603 | Time 17.8023, Epoch Time 253.8882(253.0893), Bit/dim 1.0921(best: 1.0911), Xent 0.0336, Loss 1.1089, Error 0.0099(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4222 | Time 31.1064(31.8811) | Bit/dim 1.0978(1.0975) | Xent 0.0455(0.0423) | Loss 1.1206(1.1187) | Error 0.0138(0.0131) Steps 440(441.10) | Grad Norm 0.4550(0.5352) | Total Time 10.00(10.00)\n",
      "Iter 4223 | Time 31.4696(31.8687) | Bit/dim 1.0988(1.0976) | Xent 0.0467(0.0425) | Loss 1.1221(1.1188) | Error 0.0150(0.0132) Steps 440(441.07) | Grad Norm 0.3586(0.5299) | Total Time 10.00(10.00)\n",
      "Iter 4224 | Time 30.9087(31.8399) | Bit/dim 1.0944(1.0975) | Xent 0.0419(0.0424) | Loss 1.1153(1.1187) | Error 0.0129(0.0132) Steps 440(441.04) | Grad Norm 0.2850(0.5226) | Total Time 10.00(10.00)\n",
      "Iter 4225 | Time 32.0162(31.8452) | Bit/dim 1.1041(1.0977) | Xent 0.0464(0.0426) | Loss 1.1273(1.1190) | Error 0.0136(0.0132) Steps 440(441.01) | Grad Norm 0.2276(0.5137) | Total Time 10.00(10.00)\n",
      "Iter 4226 | Time 31.5759(31.8371) | Bit/dim 1.0908(1.0975) | Xent 0.0411(0.0425) | Loss 1.1113(1.1187) | Error 0.0126(0.0132) Steps 440(440.98) | Grad Norm 0.2886(0.5070) | Total Time 10.00(10.00)\n",
      "Iter 4227 | Time 31.2111(31.8184) | Bit/dim 1.0978(1.0975) | Xent 0.0353(0.0423) | Loss 1.1155(1.1186) | Error 0.0111(0.0131) Steps 440(440.95) | Grad Norm 0.3864(0.5034) | Total Time 10.00(10.00)\n",
      "Iter 4228 | Time 30.9321(31.7918) | Bit/dim 1.0990(1.0975) | Xent 0.0465(0.0424) | Loss 1.1223(1.1187) | Error 0.0134(0.0131) Steps 440(440.92) | Grad Norm 0.3000(0.4973) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0604 | Time 17.8042, Epoch Time 249.6657(252.9866), Bit/dim 1.0921(best: 1.0911), Xent 0.0305, Loss 1.1073, Error 0.0100(best: 0.0084)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4229 | Time 32.7528(31.8206) | Bit/dim 1.1020(1.0977) | Xent 0.0410(0.0424) | Loss 1.1225(1.1189) | Error 0.0128(0.0131) Steps 440(440.89) | Grad Norm 0.3047(0.4915) | Total Time 10.00(10.00)\n",
      "Iter 4230 | Time 32.3032(31.8351) | Bit/dim 1.0984(1.0977) | Xent 0.0400(0.0423) | Loss 1.1184(1.1188) | Error 0.0118(0.0131) Steps 440(440.86) | Grad Norm 0.4298(0.4897) | Total Time 10.00(10.00)\n",
      "Iter 4231 | Time 31.0011(31.8101) | Bit/dim 1.0983(1.0977) | Xent 0.0429(0.0423) | Loss 1.1198(1.1189) | Error 0.0121(0.0130) Steps 440(440.84) | Grad Norm 0.2181(0.4815) | Total Time 10.00(10.00)\n",
      "Iter 4232 | Time 30.8387(31.7809) | Bit/dim 1.1000(1.0978) | Xent 0.0363(0.0421) | Loss 1.1181(1.1188) | Error 0.0106(0.0130) Steps 440(440.81) | Grad Norm 0.2519(0.4746) | Total Time 10.00(10.00)\n",
      "Iter 4233 | Time 30.8714(31.7536) | Bit/dim 1.0939(1.0977) | Xent 0.0363(0.0420) | Loss 1.1121(1.1186) | Error 0.0115(0.0129) Steps 440(440.79) | Grad Norm 0.2063(0.4666) | Total Time 10.00(10.00)\n",
      "Iter 4234 | Time 31.4108(31.7434) | Bit/dim 1.0926(1.0975) | Xent 0.0416(0.0420) | Loss 1.1134(1.1185) | Error 0.0144(0.0130) Steps 440(440.76) | Grad Norm 0.3912(0.4643) | Total Time 10.00(10.00)\n",
      "Iter 4235 | Time 30.9489(31.7195) | Bit/dim 1.0950(1.0974) | Xent 0.0453(0.0421) | Loss 1.1177(1.1185) | Error 0.0135(0.0130) Steps 440(440.74) | Grad Norm 0.4185(0.4629) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0605 | Time 17.9869, Epoch Time 250.6366(252.9161), Bit/dim 1.0918(best: 1.0911), Xent 0.0332, Loss 1.1084, Error 0.0102(best: 0.0084)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tancode/repos/tan-ffjord/train_cnf_disentangle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mfig_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"figs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{:04d}.jpg\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0mgenerated_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generated_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         1336891420 function calls (1323391111 primitive calls) in 62445.220 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "     1680 33950.409   20.209 33950.409   20.209 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
       "   163430 24461.153    0.150 24461.153    0.150 {method 'acquire' of '_thread.lock' objects}\n",
       " 15840000  543.630    0.000  770.215    0.000 train_cnf_disentangle.py:130(add_noise)\n",
       " 15840000  323.036    0.000 1361.767    0.000 functional.py:32(to_tensor)\n",
       " 15840000  260.012    0.000  260.012    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
       " 15840000  232.277    0.000 3414.559    0.000 mnist.py:59(__getitem__)\n",
       " 15840084  141.210    0.000  141.210    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
       " 15840000  125.964    0.000  125.964    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
       " 15840478  125.339    0.000  727.250    0.000 Image.py:2457(fromarray)\n",
       " 15840000  111.518    0.000  357.896    0.000 Image.py:711(tobytes)\n",
       "   158928  101.663    0.001  101.663    0.001 {method '_write_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
       " 31680000   99.325    0.000   99.325    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
       "187957046/187952587   96.269    0.000   96.396    0.000 {built-in method builtins.isinstance}\n",
       " 15840478   86.615    0.000  319.177    0.000 Image.py:2322(new)\n",
       " 15840478   84.915    0.000  582.078    0.000 Image.py:2396(frombuffer)\n",
       " 15844559   84.654    0.000   84.654    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
       " 15840000   84.411    0.000 2368.627    0.000 transforms.py:47(__call__)\n",
       " 31680717   77.878    0.000  126.581    0.000 Image.py:553(_new)\n",
       " 15840478   69.114    0.000  109.190    0.000 Image.py:451(_getencoder)\n",
       "47567827/47567813   58.361    0.000   58.378    0.000 {built-in method builtins.hasattr}\n",
       "     4320   55.170    0.013   55.170    0.013 {built-in method stack}\n",
       " 47521195   53.942    0.000   53.942    0.000 Image.py:529(__init__)\n",
       " 15840000   53.751    0.000   98.403    0.000 functional.py:172(resize)\n",
       " 31681434   53.033    0.000   82.175    0.000 Image.py:2304(_check_size)\n",
       " 47521195   52.965    0.000  111.245    0.000 Image.py:601(__del__)\n",
       "112216994/112214279   50.439    0.000   50.449    0.000 {built-in method builtins.len}\n",
       " 15840478   48.998    0.000   48.998    0.000 {built-in method PIL._imaging.fill}\n",
       " 15840239   47.570    0.000   47.570    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
       " 15840000   44.633    0.000   44.633    0.000 {method 'resize_as_' of 'torch._C._TensorBase' objects}\n",
       " 12011535   44.048    0.000   67.839    0.000 module.py:537(__setattr__)\n",
       "    25441   43.444    0.002   43.444    0.002 {method 'clone' of 'torch._C._TensorBase' objects}\n",
       " 15840000   42.456    0.000   42.456    0.000 {built-in method PIL._imaging.map_buffer}\n",
       " 15840433   40.750    0.000   40.750    0.000 {method 'new' of 'torch._C._TensorBase' objects}\n",
       " 15873358   35.587    0.000   35.587    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
       " 15840000   33.337    0.000   33.337    0.000 {built-in method from_buffer}\n",
       " 31680000   31.340    0.000   44.677    0.000 functional.py:17(_is_pil_image)\n",
       "     2160   29.341    0.014 3443.900    1.594 dataloader.py:615(<listcomp>)\n",
       " 15840000   28.648    0.000 1390.415    0.000 transforms.py:68(__call__)\n",
       " 63362151   28.139    0.000   28.139    0.000 Image.py:549(size)\n",
       " 15840000   25.183    0.000  123.587    0.000 transforms.py:167(__call__)\n",
       " 15841195   23.410    0.000   34.060    0.000 Image.py:809(load)\n",
       " 51899282   23.117    0.000   23.117    0.000 {method 'get' of 'dict' objects}\n",
       "     2400   20.292    0.008  126.373    0.053 replicate.py:5(replicate)\n",
       " 34656719   18.670    0.000   18.670    0.000 {method 'copy' of 'dict' objects}\n",
       " 15840000   17.611    0.000   17.611    0.000 {built-in method PIL._imaging.raw_encoder}\n",
       " 15866108   16.820    0.000   16.820    0.000 {built-in method builtins.max}\n",
       "     4560   16.810    0.004   16.810    0.004 {built-in method torch._C._scatter}\n",
       "     2640   16.485    0.006   30.111    0.011 sampler.py:158(__iter__)\n",
       " 35691401   15.501    0.000   15.501    0.000 {method 'append' of 'list' objects}\n",
       " 16021776   15.455    0.000   15.455    0.000 {built-in method builtins.getattr}\n",
       " 15840717   15.192    0.000   22.511    0.000 _util.py:7(isStringType)\n",
       "     2640   14.752    0.006 3564.415    1.350 dataloader.py:612(__next__)\n",
       "    23280   14.143    0.001   14.143    0.001 {method 'sort' of 'numpy.ndarray' objects}\n",
       "14159277/1425108   13.326    0.000   14.958    0.000 module.py:938(named_modules)\n",
       " 15840478   11.839    0.000   11.839    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
       "     3360   11.800    0.004   11.800    0.004 {method 'pin_memory' of 'torch._C._TensorBase' objects}\n",
       "     4800   11.525    0.002   11.525    0.002 {built-in method torch._C._broadcast_coalesced}\n",
       "    23280   10.736    0.000   40.823    0.002 summary.py:150(make_histogram)\n",
       " 15841195   10.650    0.000   10.650    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
       " 15840000    8.520    0.000    8.520    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
       "        1    8.475    8.475 62445.168 62445.168 train_cnf_disentangle.py:1(<module>)\n",
       "6480/2160    7.592    0.001   63.740    0.030 dataloader.py:196(default_collate)\n",
       " 15840718    7.573    0.000    7.573    0.000 {method 'join' of 'bytes' objects}\n",
       "    11385    7.439    0.001    7.457    0.001 {method 'to' of 'torch._C._TensorBase' objects}\n",
       "    31198    6.951    0.000    6.951    0.000 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
       "   162960    6.800    0.000    6.800    0.000 {built-in method norm}\n",
       "  4320168    6.758    0.000   12.270    0.000 serialization.py:234(persistent_id)\n",
       "   171927    5.988    0.000    5.988    0.000 {built-in method numpy.core.multiarray.array}\n",
       "   325920    5.402    0.000    5.402    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
       "  8928007    5.307    0.000    5.307    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
       "      968    5.226    0.005    5.227    0.005 {built-in method io.open}\n",
       "   325920    4.792    0.000    4.792    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
       "   188640    4.276    0.000    4.276    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
       "     2405    3.513    0.001    3.513    0.001 {method 'flush' of '_io.TextIOWrapper' objects}\n",
       "      528    3.510    0.007   17.112    0.032 {method 'dump' of '_pickle.Pickler' objects}\n",
       "    11041    3.368    0.000 24611.364    2.229 module.py:483(__call__)\n",
       "     1680    3.112    0.002   20.309    0.012 adam.py:49(step)\n",
       "   162960    2.342    0.000    2.342    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
       "  4320168    2.309    0.000    2.309    0.000 __init__.py:128(is_storage)\n",
       "   162960    2.163    0.000    2.163    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
       "   450054    2.120    0.000   16.687    0.000 module.py:771(_named_members)\n",
       "    23280    2.049    0.000   43.689    0.002 summary.py:126(histogram)\n",
       "   162960    2.034    0.000    2.034    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
       "    98162    2.008    0.000    2.008    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "  2509965    1.811    0.000    2.332    0.000 {method 'add' of 'set' objects}\n",
       "  4502686    1.710    0.000    1.710    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
       "554564/3361    1.698    0.000    6.813    0.002 module.py:203(apply)\n",
       "  1264016    1.639    0.000    2.146    0.000 module.py:891(named_children)\n",
       "     6134    1.609    0.000    1.609    0.000 {built-in method posix.stat}\n",
       "     4559    1.579    0.000    1.579    0.000 {built-in method torch._C._gather}\n",
       "    46560    1.572    0.000    1.572    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
       "    11519    1.525    0.000   31.421    0.003 {built-in method apply}\n",
       "    12030    1.516    0.000    1.516    0.000 socket.py:334(send)\n",
       "    23281    1.494    0.000    1.494    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
       "  2978152    1.310    0.000    1.310    0.000 {built-in method __new__ of type object at 0x5653174dad60}\n",
       "      239    1.296    0.005    1.296    0.005 {method 'encode_to_file' of 'ImagingEncoder' objects}\n",
       "  1563416    1.287    0.000    1.932    0.000 tensor.py:416(__hash__)\n",
       "  1264016    1.281    0.000    3.427    0.000 module.py:882(children)\n",
       "     1680    1.133    0.001   17.410    0.010 clip_grad.py:6(clip_grad_norm_)\n",
       "    19223    1.133    0.000    1.133    0.000 {built-in method _thread.start_new_thread}\n",
       "      239    1.116    0.005    4.208    0.018 summary.py:184(image)\n",
       "    42480    1.079    0.000    4.798    0.000 writer.py:82(add_summary)\n",
       "   277200    1.014    0.000    1.193    0.000 train_misc.py:81(__call__)\n",
       "     2161    0.971    0.000    2.052    0.001 odenvp_conditional_tol.py:124(_prior)\n",
       "     2161    0.962    0.000    0.962    0.000 {method 'scatter_' of 'torch._C._TensorBase' objects}\n",
       "   162867    0.936    0.000    0.936    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
       "     2160    0.914    0.000   56.122    0.026 dataloader.py:232(<listcomp>)\n",
       "    23320    0.893    0.000    0.893    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "   159456    0.785    0.000    1.331    0.000 tensor.py:33(__reduce_ex__)\n",
       "   671985    0.781    0.000    1.040    0.000 module.py:829(<lambda>)\n",
       "     2160    0.746    0.000 22467.322   10.402 train_cnf_disentangle.py:276(compute_bits_per_dim_conditional)\n",
       "    23519    0.728    0.000    0.728    0.000 {built-in method numpy.core.multiarray.zeros}\n",
       "  1668451    0.690    0.000    0.690    0.000 {built-in method builtins.id}\n",
       "    25919    0.684    0.000    0.684    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "    23280    0.683    0.000    7.484    0.000 histograms.py:297(_get_bin_edges)\n",
       "97152/528    0.682    0.000    0.852    0.002 module.py:602(state_dict)\n",
       "    23280    0.623    0.000   26.482    0.001 histograms.py:597(histogram)\n",
       "        1    0.604    0.604    0.604    0.604 {built-in method caffe2.python.caffe2_pybind11_state_gpu.num_cuda_devices}\n",
       "     4321    0.586    0.000    0.586    0.000 {built-in method addmm}\n",
       "      239    0.550    0.002    0.550    0.002 {method 'tobytes' of 'numpy.ndarray' objects}\n",
       "      240    0.533    0.002    0.533    0.002 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
       "    79468    0.532    0.000    0.532    0.000 {method 'release' of '_thread.lock' objects}\n",
       "   159459    0.524    0.000    0.524    0.000 serialization.py:149(_is_compressed_file)\n",
       "     2160    0.501    0.000    0.501    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
       "      302    0.472    0.002    0.472    0.002 {method '_set_from_file' of 'torch._C.FloatStorageBase' objects}\n",
       "     2160    0.442    0.000    0.484    0.000 modules.py:268(likelihood)\n",
       "      528    0.437    0.001  120.830    0.229 serialization.py:221(_save)\n",
       "    42480    0.419    0.000    3.220    0.000 queue.py:115(put)\n",
       "   423654    0.398    0.000   12.542    0.000 module.py:808(named_parameters)\n",
       "   162960    0.389    0.000    7.274    0.000 functional.py:607(norm)\n",
       "   372000    0.374    0.000    0.510    0.000 module.py:877(<lambda>)\n",
       "   159459    0.360    0.000    1.036    0.000 serialization.py:157(_should_read_directly)\n",
       "   400134    0.352    0.000   11.854    0.000 module.py:784(parameters)\n",
       "     1680    0.349    0.000    1.402    0.001 optimizer.py:157(zero_grad)\n",
       "    16800    0.347    0.000    2.009    0.000 summary.py:105(scalar)\n",
       "    23280    0.343    0.000    0.417    0.000 function_base.py:1079(diff)\n",
       "     4321    0.335    0.000    1.160    0.000 modules.py:105(forward)\n",
       "    46560    0.316    0.000    0.316    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "    16800    0.309    0.000    5.442    0.000 writer.py:344(add_scalars)\n",
       "    23280    0.301    0.000   47.748    0.002 writer.py:390(add_histogram)\n",
       "   374400    0.298    0.000    3.770    0.000 module.py:911(modules)\n",
       "   159456    0.290    0.000    0.717    0.000 serialization.py:102(location_tag)\n",
       "    21830    0.284    0.000   18.682    0.001 threading.py:263(wait)\n",
       "      528    0.270    0.001    0.270    0.001 {method '_write_file' of 'torch._C.FloatStorageBase' objects}\n",
       "79200/480    0.270    0.000    1.240    0.003 module.py:976(train)\n",
       "      240    0.269    0.001    0.269    0.001 {built-in method randperm}\n",
       "   277200    0.267    0.000    0.942    0.000 train_misc.py:61(__call__)\n",
       "    42480    0.264    0.000    3.648    0.000 writer.py:137(_add_event)\n",
       "    42480    0.259    0.000    0.894    0.000 threading.py:334(notify)\n",
       "   162960    0.259    0.000    7.533    0.000 tensor.py:250(norm)\n",
       "    24007    0.258    0.000    0.258    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}\n",
       "      551    0.257    0.000    0.257    0.000 {method 'flush' of '_io.BufferedWriter' objects}\n",
       "    13680    0.251    0.000    0.251    0.000 utils.py:74(update)\n",
       "   158928    0.234    0.000    0.316    0.000 serialization.py:57(_cuda_tag)\n",
       "    46560    0.223    0.000    4.246    0.000 fromnumeric.py:2651(ndim)\n",
       "    16800    0.211    0.000    1.917    0.000 writer.py:303(__append_to_scalar_dict)\n",
       "    57119    0.210    0.000    3.238    0.000 x2num.py:10(make_np)\n",
       "     4324    0.207    0.000    0.207    0.000 {built-in method zeros}\n",
       "     2161    0.202    0.000    0.217    0.000 summary.py:380(text)\n",
       "      126    0.194    0.002    0.194    0.002 {method 'read' of '_io.BufferedReader' objects}\n",
       "   124108    0.193    0.000    0.198    0.000 module.py:521(__getattr__)\n",
       "   212608    0.191    0.000    0.191    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
       "     2400    0.187    0.000 24460.417   10.192 parallel_apply.py:21(parallel_apply)\n",
       "    23280    0.184    0.000    0.184    0.000 {built-in method numpy.core.multiarray.concatenate}\n",
       "    27/24    0.180    0.007    0.186    0.008 {built-in method _imp.create_dynamic}\n",
       "    21630    0.168    0.000   17.459    0.001 threading.py:533(wait)\n",
       "   159456    0.165    0.000    0.244    0.000 serialization.py:121(normalize_storage_type)\n",
       "328037/326819    0.165    0.000    0.177    0.000 {built-in method builtins.issubclass}\n",
       "    25922    0.164    0.000    0.771    0.000 fromnumeric.py:64(_wrapreduction)\n",
       "    98874    0.164    0.000    0.256    0.000 _utils.py:5(_get_device_index)\n",
       "   162960    0.162    0.000    0.162    0.000 clip_grad.py:24(<lambda>)\n",
       "    40647    0.159    0.000    0.159    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
       "      528    0.156    0.000  120.986    0.229 serialization.py:218(<lambda>)\n",
       "     2400    0.154    0.000    0.404    0.000 replicate.py:12(<dictcomp>)\n",
       "   159456    0.152    0.000    0.152    0.000 {method 'fileno' of '_io.BufferedWriter' objects}\n",
       "     6482    0.147    0.000    0.147    0.000 {built-in method exp}\n",
       "    19223    0.145    0.000   16.441    0.001 threading.py:828(start)\n",
       "   159650    0.144    0.000    0.144    0.000 {method 'storage' of 'torch._C._TensorBase' objects}\n",
       "    23280    0.139    0.000    1.895    0.000 histograms.py:391(_search_sorted_inclusive)\n",
       "    19223    0.138    0.000    0.383    0.000 threading.py:757(__init__)\n",
       "5066/5062    0.137    0.000    0.224    0.000 {built-in method builtins.__build_class__}\n",
       "    40319    0.129    0.000    0.336    0.000 summary.py:64(_clean_tag)\n",
       "    93120    0.129    0.000    5.967    0.000 numeric.py:433(asarray)\n",
       "    47800    0.128    0.000    0.128    0.000 {method 'narrow' of 'torch._C._TensorBase' objects}\n",
       "     4321    0.126    0.000    0.126    0.000 {built-in method sum}\n",
       "    42480    0.125    0.000    3.346    0.000 event_file_writer.py:131(add_event)\n",
       "      239    0.125    0.001    0.537    0.002 utils.py:6(make_grid)\n",
       "    64110    0.125    0.000    0.185    0.000 threading.py:239(__enter__)\n",
       "    33630    0.124    0.000 24443.112    0.727 threading.py:1062(_wait_for_tstate_lock)\n",
       "      239    0.123    0.001    0.205    0.001 utils.py:70(make_grid)\n",
       "    11735    0.122    0.000    0.272    0.000 {built-in method builtins.all}\n",
       "     4559    0.117    0.000    1.932    0.000 _functions.py:52(forward)\n",
       "   235200    0.117    0.000    0.117    0.000 _functions.py:13(<genexpr>)\n",
       "   162863    0.117    0.000    0.117    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}\n",
       "    64310    0.115    0.000    0.196    0.000 threading.py:254(_is_owned)\n",
       "    19193    0.115    0.000 24443.263    1.274 threading.py:1024(join)\n",
       "   159456    0.110    0.000    0.110    0.000 serialization.py:52(_cpu_tag)\n",
       "    23280    0.110    0.000    0.110    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "     2405    0.109    0.000    0.223    0.000 __init__.py:251(__init__)\n",
       "     4320    0.107    0.000    0.107    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
       "    23280    0.105    0.000   15.196    0.001 fromnumeric.py:760(sort)\n",
       "   163170    0.104    0.000    0.104    0.000 {built-in method math.sqrt}\n",
       "     2160    0.104    0.000    0.250    0.000 train_misc.py:10(standard_normal_logprob)\n",
       "   159650    0.102    0.000    0.102    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
       "    23280    0.102    0.000    0.203    0.000 histograms.py:220(_ravel_and_check_weights)\n",
       "    64110    0.100    0.000    0.140    0.000 threading.py:242(__exit__)\n",
       "      695    0.100    0.000    0.122    0.000 <frozen importlib._bootstrap_external>:830(get_data)\n",
       "    21699    0.100    0.000    0.100    0.000 threading.py:215(__init__)\n",
       "   179357    0.099    0.000    0.099    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
       "     2160    0.093    0.000    0.093    0.000 {built-in method torch._C._nn.nll_loss}\n",
       "     2400    0.090    0.000   10.924    0.005 _functions.py:11(forward)\n",
       "     2400    0.090    0.000 24460.555   10.192 data_parallel.py:152(parallel_apply)\n",
       "    40319    0.089    0.000    0.145    0.000 writer.py:314(_check_caffe2)\n",
       "    12030    0.088    0.000    1.718    0.000 iostream.py:195(schedule)\n",
       "   159650    0.087    0.000    0.087    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
       "     2400    0.087    0.000    0.087    0.000 _functions.py:28(<listcomp>)\n",
       "   159456    0.084    0.000    0.084    0.000 hooks.py:51(warn_if_has_hooks)\n",
       "   158928    0.082    0.000    0.082    0.000 {method 'get_device' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "   158928    0.082    0.000    0.082    0.000 {method 'size' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "     6748    0.080    0.000    0.684    0.000 {method 'format' of 'str' objects}\n",
       "    40821    0.079    0.000    0.107    0.000 threading.py:1230(current_thread)\n",
       "     2160    0.077    0.000    0.077    0.000 {built-in method rsub}\n",
       "    23280    0.075    0.000    0.669    0.000 fromnumeric.py:1933(any)\n",
       "    12245    0.073    0.000    0.120    0.000 abc.py:180(__instancecheck__)\n",
       "    16800    0.072    0.000    0.532    0.000 cnf.py:88(num_evals)\n",
       "     2160    0.071    0.000    0.071    0.000 {built-in method dropout}\n",
       "     4560    0.070    0.000   17.040    0.004 _functions.py:80(forward)\n",
       "    33839    0.070    0.000    0.151    0.000 numeric.py:1927(isscalar)\n",
       "    49491    0.070    0.000    0.070    0.000 {built-in method time.time}\n",
       "    48619    0.069    0.000    0.069    0.000 {built-in method _thread.allocate_lock}\n",
       "     2160    0.069    0.000    0.069    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}\n",
       "      480    0.067    0.000    0.067    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
       "    42717    0.065    0.000    0.096    0.000 queue.py:202(_qsize)\n",
       "    42480    0.064    0.000    0.095    0.000 queue.py:206(_put)\n",
       "      528    0.064    0.000    0.064    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
       "    48960    0.063    0.000    0.119    0.000 numeric.py:504(asanyarray)\n",
       "    23280    0.063    0.000    0.905    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "7920/2640    0.063    0.000   17.206    0.007 scatter_gather.py:11(scatter_map)\n",
       "    21630    0.061    0.000    0.177    0.000 threading.py:498(__init__)\n",
       "    64110    0.061    0.000    0.061    0.000 {method '__enter__' of '_thread.lock' objects}\n",
       "      528    0.060    0.000    0.104    0.000 optimizer.py:88(<dictcomp>)\n",
       "   119582    0.060    0.000    0.060    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
       "     2400    0.059    0.000 24606.431   10.253 data_parallel.py:136(forward)\n",
       "6719/2399    0.057    0.000    2.103    0.001 scatter_gather.py:51(gather_map)\n",
       "    76340    0.056    0.000    0.056    0.000 {method 'append' of 'collections.deque' objects}\n",
       "     4810    0.056    0.000    1.589    0.000 iostream.py:382(write)\n",
       "     4079    0.056    0.000    2.730    0.001 x2num.py:27(prepare_pytorch)\n",
       "     2400    0.055    0.000    0.143    0.000 _methods.py:58(_mean)\n",
       "    20976    0.055    0.000    0.078    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "     4810    0.053    0.000    7.993    0.002 __init__.py:982(emit)\n",
       "      695    0.053    0.000    0.053    0.000 {built-in method marshal.loads}\n",
       "     2160    0.052    0.000    0.052    0.000 {method 'pow' of 'torch._C._TensorBase' objects}\n",
       "    14437    0.050    0.000    0.100    0.000 threading.py:1104(is_alive)\n",
       "    40797    0.048    0.000    0.048    0.000 {method 'lstrip' of 'str' objects}\n",
       "    19192    0.047    0.000    0.059    0.000 threading.py:966(_stop)\n",
       "    23280    0.046    0.000    0.842    0.000 _methods.py:30(_amin)\n",
       "     2715    0.044    0.000    0.096    0.000 {built-in method builtins.sorted}\n",
       "    16800    0.044    0.000    0.089    0.000 cnf_regularization.py:30(_num_evals)\n",
       "     4810    0.044    0.000    6.216    0.001 __init__.py:971(flush)\n",
       "     2400    0.044    0.000    0.426    0.000 parallel_apply.py:67(<listcomp>)\n",
       "     4321    0.043    0.000    0.043    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
       "    21206    0.043    0.000    0.043    0.000 _weakrefset.py:70(__contains__)\n",
       "    36480    0.043    0.000    0.136    0.000 _functions.py:82(<lambda>)\n",
       "    21830    0.042    0.000    0.068    0.000 threading.py:251(_acquire_restore)\n",
       "     4321    0.042    0.000    0.678    0.000 functional.py:1335(linear)\n",
       "     2161    0.042    0.000    0.046    0.000 thops.py:47(split_feature)\n",
       "    23280    0.041    0.000    0.363    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "     2405    0.041    0.000    0.081    0.000 __init__.py:1376(findCaller)\n",
       "22361/20572    0.041    0.000    1.511    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
       "    52876    0.041    0.000    0.041    0.000 threading.py:506(is_set)\n",
       "    23280    0.041    0.000    0.372    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "    64110    0.040    0.000    0.040    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "5040/1680    0.039    0.000   11.899    0.007 dataloader.py:237(pin_memory_batch)\n",
       "    36472    0.038    0.000    0.062    0.000 _functions.py:58(<lambda>)\n",
       "    36472    0.037    0.000    0.068    0.000 _functions.py:67(<lambda>)\n",
       "     2400    0.036    0.000  126.409    0.053 data_parallel.py:146(replicate)\n",
       "    11041    0.035    0.000    0.035    0.000 {built-in method torch._C._get_tracing_state}\n",
       "      239    0.035    0.000    0.035    0.000 {method 'close' of '_io.BufferedRandom' objects}\n",
       "        2    0.035    0.018    0.035    0.018 {method '_set_from_file' of 'torch._C.ByteStorageBase' objects}\n",
       "     2407    0.035    0.000    2.628    0.001 iostream.py:334(flush)\n",
       "      478    0.035    0.000    0.035    0.000 {method 'decode' of 'ImagingDecoder' objects}\n",
       "    19192    0.034    0.000    0.047    0.000 _weakrefset.py:38(_remove)\n",
       "    23280    0.033    0.000    0.322    0.000 _methods.py:34(_sum)\n",
       "    16801    0.033    0.000    0.045    0.000 writer.py:204(get_logdir)\n",
       "     4810    0.033    0.000    8.078    0.002 __init__.py:852(handle)\n",
       "     2322    0.033    0.000    0.185    0.000 module.py:62(__init__)\n",
       "    45592    0.033    0.000    0.033    0.000 {method 'get_device' of 'torch._C._TensorBase' objects}\n",
       "     2161    0.033    0.000    1.151    0.001 thops.py:4(onehot)\n",
       "     1681    0.033    0.000    0.033    0.000 {built-in method ones_like}\n",
       "    44795    0.033    0.000    0.033    0.000 {method 'items' of 'dict' objects}\n",
       "     4810    0.032    0.000    0.111    0.000 __init__.py:564(format)\n",
       "     2400    0.032    0.000   17.267    0.007 scatter_gather.py:33(scatter_kwargs)\n",
       "     2161    0.032    0.000    0.393    0.000 writer.py:523(add_text)\n",
       "    47198    0.032    0.000    0.032    0.000 {built-in method _thread.get_ident}\n",
       "    23280    0.032    0.000    0.332    0.000 _methods.py:26(_amax)\n",
       "     2405    0.031    0.000    8.110    0.003 __init__.py:1500(callHandlers)\n",
       "    19741    0.031    0.000    0.043    0.000 _weakrefset.py:81(add)\n",
       "     1680    0.031    0.000    0.039    0.000 train_cnf_disentangle.py:141(update_lr)\n",
       "     2160    0.031    0.000    0.631    0.000 modules.py:277(logp)\n",
       "      480    0.030    0.000    0.147    0.000 dataloader.py:518(__init__)\n",
       "    26400    0.030    0.000    4.601    0.000 module.py:834(buffers)\n",
       "      528    0.029    0.000    0.051    0.000 optimizer.py:84(<listcomp>)\n",
       "    21830    0.028    0.000    0.041    0.000 threading.py:248(_release_save)\n",
       "    26400    0.028    0.000    4.571    0.000 module.py:856(named_buffers)\n",
       "     2112    0.027    0.000    0.027    0.000 {built-in method _pickle.dump}\n",
       "     1680    0.027    0.000 33950.511   20.209 tensor.py:74(backward)\n",
       "      798    0.027    0.000    0.027    0.000 {built-in method torch._C._cuda_isDriverSufficient}\n",
       "    26044    0.026    0.000    0.026    0.000 {method 'rpartition' of 'str' objects}\n",
       "        3    0.026    0.009    0.076    0.025 utils.py:70(parse_header)\n",
       "     4321    0.026    0.000    0.713    0.000 linear.py:65(forward)\n",
       "     2160    0.026    0.000    0.567    0.000 odenvp_conditional_tol.py:155(loss_class)\n",
       "    38446    0.025    0.000    0.025    0.000 {method 'remove' of 'collections.deque' objects}\n",
       "     2161    0.025    0.000    0.025    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}\n",
       "     2405    0.025    0.000    8.474    0.004 __init__.py:1421(_log)\n",
       "    19223    0.024    0.000    0.024    0.000 threading.py:727(_newname)\n",
       "     2400    0.024    0.000    0.031    0.000 replicate.py:15(<listcomp>)\n",
       "    23280    0.024    0.000    0.024    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "     2160    0.023    0.000    0.108    0.000 thops.py:15(sum)\n",
       "    36472    0.023    0.000    0.023    0.000 _functions.py:54(<lambda>)\n",
       "     2160    0.023    0.000    0.125    0.000 functional.py:1734(nll_loss)\n",
       "     2405    0.022    0.000    8.516    0.004 __init__.py:1298(info)\n",
       "     9620    0.022    0.000    0.034    0.000 __init__.py:809(acquire)\n",
       "  742/127    0.022    0.000    0.078    0.001 sre_parse.py:470(_parse)\n",
       "      695    0.022    0.000    0.022    0.000 {method 'read' of '_io.FileIO' objects}\n",
       "    23280    0.022    0.000    0.022    0.000 {built-in method numpy.core.multiarray.normalize_axis_index}\n",
       "     2160    0.022    0.000    0.101    0.000 functional.py:728(dropout)\n",
       "    34164    0.021    0.000    0.021    0.000 {method 'keys' of 'dict' objects}\n",
       "      412    0.021    0.000    0.021    0.000 {built-in method posix.listdir}\n",
       "     3360    0.021    0.000    0.605    0.000 tensor.py:362(__format__)\n",
       "    19200    0.020    0.000    0.067    0.000 parallel_apply.py:45(<lambda>)\n",
       "    19200    0.020    0.000    0.065    0.000 replicate.py:8(<lambda>)\n",
       "    43381    0.019    0.000    0.019    0.000 {method 'startswith' of 'str' objects}\n",
       "     4560    0.019    0.000   16.829    0.004 comm.py:131(scatter)\n",
       "     2400    0.019    0.000    0.162    0.000 fromnumeric.py:2817(mean)\n",
       "     2400    0.019    0.000    0.047    0.000 replicate.py:19(<dictcomp>)\n",
       "    19200    0.019    0.000    0.066    0.000 _functions.py:15(<lambda>)\n",
       "     1264    0.019    0.000    0.209    0.000 <frozen importlib._bootstrap_external>:1233(find_spec)\n",
       "      240    0.019    0.000    0.019    0.000 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
       "    12030    0.019    0.000    0.019    0.000 iostream.py:93(_event_pipe)\n",
       "     3519    0.019    0.000    0.043    0.000 posixpath.py:121(splitext)\n",
       "      240    0.019    0.000    0.019    0.000 {built-in method cat}\n",
       "     2726    0.018    0.000    0.034    0.000 posixpath.py:144(basename)\n",
       "     2160    0.018    0.000    0.018    0.000 {method 'squeeze_' of 'torch._C._TensorBase' objects}\n",
       "     4321    0.018    0.000    0.018    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
       "     9620    0.018    0.000    0.024    0.000 __init__.py:816(release)\n",
       "        1    0.018    0.018    0.018    0.018 {built-in method torch._C._cuda_init}\n",
       "    16800    0.018    0.000    0.018    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
       "     1680    0.017    0.000 33950.484   20.209 __init__.py:38(backward)\n",
       "     2400    0.017    0.000    0.018    0.000 _methods.py:48(_count_reduce_items)\n",
       "     1680    0.017    0.000    0.056    0.000 __init__.py:20(_make_grads)\n",
       "     4810    0.016    0.000    0.127    0.000 __init__.py:829(format)\n",
       "     2405    0.016    0.000    0.239    0.000 __init__.py:1406(makeRecord)\n",
       " 1482/120    0.016    0.000    0.069    0.001 sre_compile.py:64(_compile)\n",
       "     4810    0.015    0.000    0.038    0.000 __init__.py:542(usesTime)\n",
       "     2405    0.015    0.000    8.130    0.003 __init__.py:1446(handle)\n",
       "      239    0.015    0.000    2.718    0.011 summary.py:248(make_image)\n",
       "     1680    0.015    0.000    3.235    0.002 train_misc.py:54(count_nfe)\n",
       "     4559    0.015    0.000    1.594    0.000 comm.py:151(gather)\n",
       "     4800    0.015    0.000   11.540    0.002 comm.py:24(broadcast_coalesced)\n",
       "     2356    0.014    0.000    0.014    0.000 {method 'type' of 'torch._C._TensorBase' objects}\n",
       "     2355    0.014    0.000    3.213    0.001 train_cnf_disentangle.py:397(<lambda>)\n",
       "     2162    0.014    0.000    0.178    0.000 fromnumeric.py:2478(prod)\n",
       "     8743    0.014    0.000    0.041    0.000 <frozen importlib._bootstrap_external>:57(_path_join)\n",
       "    14811    0.014    0.000    0.024    0.000 sre_parse.py:253(get)\n",
       "     2405    0.014    0.000    0.020    0.000 __init__.py:1544(isEnabledFor)\n",
       "     4810    0.014    0.000    0.022    0.000 __init__.py:387(usesTime)\n",
       "     2850    0.014    0.000   30.139    0.011 {built-in method builtins.next}\n",
       "     3519    0.014    0.000    0.020    0.000 genericpath.py:117(_splitext)\n",
       "     4810    0.014    0.000    0.019    0.000 iostream.py:307(_is_master_process)\n",
       "     1680    0.014    0.000    3.724    0.002 train_misc.py:74(count_total_time)\n",
       "     2160    0.014    0.000    0.219    0.000 functional.py:1923(cross_entropy)\n",
       "    10514    0.014    0.000    0.014    0.000 {method 'rfind' of 'str' objects}\n",
       "     4810    0.014    0.000    0.141    0.000 iostream.py:320(_schedule_flush)\n",
       "     4810    0.013    0.000    0.013    0.000 __init__.py:390(format)\n",
       "     2428    0.013    0.000    0.021    0.000 posixpath.py:52(normcase)\n",
       "     8743    0.013    0.000    0.022    0.000 <frozen importlib._bootstrap_external>:59(<listcomp>)\n",
       "     2160    0.013    0.000    0.248    0.000 loss.py:22(__init__)\n",
       "     2405    0.013    0.000    3.677    0.002 __init__.py:1063(emit)\n",
       "    19192    0.013    0.000    0.013    0.000 {method 'discard' of 'set' objects}\n",
       "    19223    0.013    0.000    0.013    0.000 threading.py:1120(daemon)\n",
       "     7215    0.013    0.000    0.013    0.000 __init__.py:705(filter)\n",
       "     2160    0.013    0.000    0.234    0.000 loss.py:901(forward)\n",
       "     1528    0.012    0.000    0.030    0.000 version.py:198(__init__)\n",
       "      239    0.012    0.000    3.768    0.016 utils.py:90(save_image)\n",
       "     1626    0.012    0.000    0.021    0.000 posixpath.py:75(join)\n",
       "    26619    0.012    0.000    0.012    0.000 {method 'rstrip' of 'str' objects}\n",
       "      478    0.012    0.000    5.159    0.011 Image.py:1892(save)\n",
       "     9118    0.012    0.000    0.014    0.000 _functions.py:59(<genexpr>)\n",
       "      478    0.012    0.000    3.366    0.007 ImageFile.py:463(_save)\n",
       "     2399    0.012    0.000    2.123    0.001 data_parallel.py:155(gather)\n",
       "    13266    0.012    0.000    0.012    0.000 {built-in method posix.fspath}\n",
       "       14    0.011    0.001    0.011    0.001 {built-in method _pickle.load}\n",
       "     2160    0.011    0.000    0.272    0.000 loss.py:896(__init__)\n",
       "    19192    0.011    0.000    0.011    0.000 {method 'locked' of '_thread.lock' objects}\n",
       "     2405    0.011    0.000    0.016    0.000 __init__.py:157(<lambda>)\n",
       "     9641    0.011    0.000    0.011    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "     2160    0.011    0.000    0.112    0.000 dropout.py:56(forward)\n",
       "    16531    0.011    0.000    0.011    0.000 sre_parse.py:232(__next)\n",
       "    16801    0.011    0.000    0.011    0.000 event_file_writer.py:118(get_logdir)\n",
       "     4810    0.011    0.000    0.018    0.000 __init__.py:329(getMessage)\n",
       "     2160    0.011    0.000    0.199    0.000 loss.py:13(__init__)\n",
       "     2170    0.011    0.000    0.036    0.000 module.py:87(register_buffer)\n",
       "     1434    0.011    0.000    0.011    0.000 {built-in method zlib.crc32}\n",
       "     4167    0.011    0.000    0.028    0.000 enum.py:803(__and__)\n",
       "      184    0.010    0.000    0.022    0.000 module.py:647(_load_from_state_dict)\n",
       "     9613    0.010    0.000    0.018    0.000 enum.py:267(__call__)\n",
       "     1680    0.010    0.000   11.833    0.007 dataloader.py:245(<listcomp>)\n",
       "      239    0.010    0.000    0.010    0.000 {method 'copy' of 'ImagingCore' objects}\n",
       "     2400    0.010    0.000   17.277    0.007 data_parallel.py:149(scatter)\n",
       "     2640    0.010    0.000   17.216    0.007 scatter_gather.py:5(scatter)\n",
       "     2160    0.010    0.000    0.080    0.000 functional.py:1271(log_softmax)\n",
       "     2160    0.010    0.000    0.087    0.000 tensor.py:348(__rsub__)\n",
       "     3360    0.010    0.000    0.010    0.000 {method '__format__' of 'float' objects}\n",
       "     4810    0.010    0.000    0.023    0.000 __init__.py:548(formatMessage)\n",
       "     2160    0.010    0.000    0.010    0.000 scatter_gather.py:40(<listcomp>)\n",
       "    719/1    0.010    0.000 62445.221 62445.221 {built-in method builtins.exec}\n",
       "      239    0.009    0.000    0.009    0.000 {method 'mul' of 'torch._C._TensorBase' objects}\n",
       "     2399    0.009    0.000    2.112    0.001 scatter_gather.py:46(gather)\n",
       "     5127    0.009    0.000    0.013    0.000 posixpath.py:41(_get_sep)\n",
       "     4810    0.009    0.000    0.009    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
       "     5827    0.009    0.000    0.009    0.000 {method 'find' of 'str' objects}\n",
       "     2160    0.009    0.000    0.521    0.000 fromnumeric.py:976(argmax)\n",
       "     2184    0.008    0.000    0.008    0.000 {method 'SerializeToString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "      239    0.008    0.000    1.328    0.006 JpegImagePlugin.py:617(_save)\n",
       "      239    0.008    0.000    2.076    0.009 PngImagePlugin.py:689(_save)\n",
       "     7220    0.008    0.000    0.008    0.000 {built-in method posix.getpid}\n",
       "     2160    0.008    0.000    0.512    0.000 fromnumeric.py:49(_wrapfunc)\n",
       "11933/11861    0.008    0.000    0.010    0.000 {method 'join' of 'str' objects}\n",
       "     9612    0.007    0.000    0.008    0.000 enum.py:517(__new__)\n",
       "      239    0.007    0.000    0.007    0.000 {method 'byte' of 'torch._C._TensorBase' objects}\n",
       "     2160    0.007    0.000    0.007    0.000 {method 'long' of 'torch._C._TensorBase' objects}\n",
       " 1066/326    0.007    0.000    2.011    0.006 <frozen importlib._bootstrap>:966(_find_and_load)\n",
       "      749    0.007    0.000    0.211    0.000 <frozen importlib._bootstrap>:870(_find_spec)\n",
       "     1986    0.007    0.000    0.013    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "     1390    0.007    0.000    0.021    0.000 <frozen importlib._bootstrap_external>:263(cache_from_source)\n",
       "     2160    0.007    0.000    0.007    0.000 {built-in method math.log}\n",
       "     2441    0.007    0.000    0.007    0.000 {method 'encode' of 'str' objects}\n",
       "      695    0.007    0.000    0.010    0.000 <frozen importlib._bootstrap_external>:430(_validate_bytecode_header)\n",
       "     4079    0.007    0.000    0.009    0.000 variable.py:6(__instancecheck__)\n",
       "     2405    0.007    0.000    0.010    0.000 __init__.py:120(getLevelName)\n",
       "      614    0.007    0.000    0.012    0.000 sre_compile.py:250(_optimize_charset)\n",
       "     9641    0.007    0.000    0.007    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "      695    0.007    0.000    0.242    0.000 <frozen importlib._bootstrap_external>:743(get_code)\n",
       "      717    0.007    0.000    0.030    0.000 PngImagePlugin.py:667(putchunk)\n",
       "     6232    0.006    0.000    0.010    0.000 sre_parse.py:163(__getitem__)\n",
       "     2405    0.006    0.000    0.006    0.000 threading.py:1076(name)\n",
       "     2390    0.006    0.000    0.006    0.000 {method 'write' of '_io.BytesIO' objects}\n",
       "      239    0.006    0.000    0.006    0.000 {method 'clamp' of 'torch._C._TensorBase' objects}\n",
       "    10563    0.006    0.000    0.006    0.000 {method 'split' of 'str' objects}\n",
       "      724    0.006    0.000    0.027    0.000 <frozen importlib._bootstrap>:504(_init_module_attrs)\n",
       "      239    0.006    0.000    0.215    0.001 utils.py:95(convert_to_HWC)\n",
       "       28    0.006    0.000    0.006    0.000 {method 'readlines' of '_io._IOBase' objects}\n",
       "     2405    0.006    0.000    0.006    0.000 __init__.py:1530(getEffectiveLevel)\n",
       "      797    0.006    0.000    0.035    0.000 __init__.py:45(is_available)\n",
       "     2161    0.005    0.000    0.009    0.000 _VF.py:11(__getattr__)\n",
       "     2400    0.005    0.000    0.005    0.000 replicate.py:23(<listcomp>)\n",
       " 2304/962    0.005    0.000    0.007    0.000 sre_parse.py:173(getwidth)\n",
       "      760    0.005    0.000    0.016    0.000 version.py:131(_legacy_cmpkey)\n",
       "     2160    0.005    0.000    0.005    0.000 {method 'nelement' of 'torch._C._TensorBase' objects}\n",
       "      528    0.005    0.000  124.526    0.236 serialization.py:131(_with_file_like)\n",
       "      239    0.005    0.000    4.238    0.018 writer.py:429(add_images)\n",
       "      240    0.005    0.000    3.135    0.013 train_cnf_disentangle.py:148(get_train_loader)\n",
       "       97    0.005    0.000    0.012    0.000 <frozen importlib._bootstrap_external>:1067(_path_hooks)\n",
       "     3312    0.005    0.000    0.008    0.000 version.py:114(_parse_version_parts)\n",
       "      528    0.005    0.000    0.168    0.000 optimizer.py:72(state_dict)\n",
       "     4833    0.005    0.000    0.168    0.000 <frozen importlib._bootstrap_external>:75(_path_stat)\n",
       "   738/21    0.005    0.000    1.971    0.094 <frozen importlib._bootstrap>:651(_load_unlocked)\n",
       "        1    0.005    0.005    0.005    0.005 {built-in method builtins.compile}\n",
       "      239    0.005    0.000    0.005    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
       "      241    0.005    0.000    0.016    0.000 dataloader.py:768(__init__)\n",
       "    12309    0.005    0.000    0.005    0.000 {method 'strip' of 'str' objects}\n",
       "     1986    0.005    0.000    0.006    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "  483/175    0.005    0.000    0.013    0.000 abc.py:196(__subclasscheck__)\n",
       "     5680    0.005    0.000    0.005    0.000 {built-in method builtins.min}\n",
       "     3918    0.005    0.000    0.005    0.000 {built-in method torch._C.is_grad_enabled}\n",
       "     1954    0.005    0.000    0.005    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
       "     2400    0.005    0.000    0.005    0.000 function.py:45(mark_non_differentiable)\n",
       "     3814    0.005    0.000    0.007    0.000 utils.py:51(add_argument)\n",
       "     2400    0.005    0.000    0.005    0.000 replicate.py:69(<listcomp>)\n",
       "     3740    0.005    0.000    0.007    0.000 version.py:65(_compare)\n",
       "      725    0.005    0.000    0.008    0.000 posixpath.py:154(dirname)\n",
       "     7541    0.005    0.000    0.005    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "      107    0.004    0.000    0.004    0.000 {method 'cuda' of 'torch._C._TensorBase' objects}\n",
       "     2786    0.004    0.000    0.004    0.000 {built-in method sys._getframe}\n",
       "     6481    0.004    0.000    0.004    0.000 __init__.py:1408(_unwrap_optional)\n",
       "   760/20    0.004    0.000    1.998    0.100 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)\n",
       "      500    0.004    0.000    0.004    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
       "      445    0.004    0.000    0.006    0.000 PyColorize.py:284(_inner_call_)\n",
       "     1986    0.004    0.000    0.005    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "     3488    0.004    0.000    0.007    0.000 utils.py:79(<lambda>)\n",
       "     3488    0.004    0.000    0.007    0.000 utils.py:81(<lambda>)\n",
       "      528    0.004    0.000  124.530    0.236 serialization.py:191(save)\n",
       "     1200    0.004    0.000    0.005    0.000 tensor.py:395(__len__)\n",
       "      768    0.004    0.000    0.005    0.000 version.py:343(_cmpkey)\n",
       "     2651    0.004    0.000    0.004    0.000 dataloader.py:811(__setattr__)\n",
       "  750/749    0.004    0.000    0.194    0.000 <frozen importlib._bootstrap_external>:1117(_get_spec)\n",
       "      478    0.004    0.000    0.046    0.000 Image.py:779(frombytes)\n",
       "      528    0.004    0.000    0.057    0.000 optimizer.py:82(pack_group)\n",
       "     8043    0.004    0.000    0.004    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
       "     2874    0.004    0.000    0.065    0.000 <frozen importlib._bootstrap_external>:85(_path_is_mode_type)\n",
       "      352    0.004    0.000    0.013    0.000 inspect.py:2100(_signature_from_function)\n",
       "     2406    0.004    0.000    0.004    0.000 process.py:35(current_process)\n",
       "     2778    0.004    0.000    0.004    0.000 {method 'extend' of 'list' objects}\n",
       "     1680    0.004    0.000    0.004    0.000 train_misc.py:56(AccNumEvals)\n",
       "      759    0.003    0.000    0.008    0.000 grad_mode.py:35(__exit__)\n",
       "      478    0.003    0.000    0.006    0.000 Image.py:430(_getdecoder)\n",
       "     4135    0.003    0.000    0.004    0.000 {built-in method builtins.setattr}\n",
       "      478    0.003    0.000    0.098    0.000 Image.py:2353(frombytes)\n",
       "     1531    0.003    0.000    0.003    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n",
       "      529    0.003    0.000    1.414    0.003 utils.py:8(makedirs)\n",
       "       10    0.003    0.000    0.003    0.000 {built-in method sqrt}\n",
       "     1680    0.003    0.000    0.003    0.000 train_misc.py:76(Accumulator)\n",
       "     4226    0.003    0.000    0.005    0.000 utils.py:92(<lambda>)\n",
       "     2160    0.003    0.000    0.003    0.000 _reduction.py:8(get_enum)\n",
       "      873    0.003    0.000    1.443    0.002 genericpath.py:16(exists)\n",
       "  498/120    0.003    0.000    0.079    0.001 sre_parse.py:407(_parse_sub)\n",
       "     1361    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "     2579    0.003    0.000    0.005    0.000 {built-in method builtins.any}\n",
       "      584    0.003    0.000    0.006    0.000 tokenize.py:492(_tokenize)\n",
       "     2405    0.003    0.000    0.003    0.000 process.py:146(name)\n",
       "        3    0.003    0.001    0.027    0.009 {method 'load' of '_pickle.Unpickler' objects}\n",
       "     1200    0.003    0.000    0.011    0.000 mnist.py:84(__len__)\n",
       "        1    0.003    0.003    0.003    0.003 {built-in method posix.read}\n",
       "      695    0.003    0.000    0.057    0.000 <frozen importlib._bootstrap_external>:485(_compile_bytecode)\n",
       "        1    0.003    0.003    0.014    0.014 {built-in method torch._C._initExtension}\n",
       "      240    0.003    0.000    0.809    0.003 sampler.py:69(__iter__)\n",
       "      759    0.003    0.000    0.004    0.000 grad_mode.py:122(__init__)\n",
       "      480    0.003    0.000    0.017    0.000 fromnumeric.py:1821(sum)\n",
       "      480    0.003    0.000    0.149    0.000 dataloader.py:818(__iter__)\n",
       "     3830    0.003    0.000    0.004    0.000 utils.py:75(<lambda>)\n",
       "     1912    0.003    0.000    0.005    0.000 _binary.py:93(o32be)\n",
       "      320    0.003    0.000    0.048    0.000 __init__.py:2481(from_location)\n",
       "     1361    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "      724    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:524(spec_from_file_location)\n",
       "     4189    0.003    0.000    0.004    0.000 sre_parse.py:248(match)\n",
       "        1    0.003    0.003    0.004    0.004 packages.py:1(<module>)\n",
       "     1762    0.003    0.000    0.004    0.000 __init__.py:1972(dist_factory)\n",
       "     1434    0.003    0.000    0.013    0.000 PngImagePlugin.py:90(_crc32)\n",
       "     5821    0.003    0.000    0.003    0.000 {built-in method _imp.release_lock}\n",
       "     5821    0.003    0.000    0.003    0.000 {built-in method _imp.acquire_lock}\n",
       "      512    0.003    0.000    0.008    0.000 copy.py:66(copy)\n",
       "  724/718    0.003    0.000    0.217    0.000 <frozen importlib._bootstrap>:564(module_from_spec)\n",
       "     1680    0.003    0.000    0.003    0.000 train_misc.py:78(__init__)\n",
       "     3488    0.003    0.000    0.004    0.000 utils.py:83(<lambda>)\n",
       "   695/19    0.003    0.000    1.970    0.104 <frozen importlib._bootstrap_external>:672(exec_module)\n",
       "      614    0.003    0.000    0.017    0.000 sre_compile.py:223(_compile_charset)\n",
       "     2488    0.003    0.000    0.059    0.000 <frozen importlib._bootstrap_external>:94(_path_isfile)\n",
       "      724    0.003    0.000    0.006    0.000 <frozen importlib._bootstrap>:318(__exit__)\n",
       "      628    0.002    0.000    0.063    0.000 __init__.py:2027(distributions_from_metadata)\n",
       "    893/1    0.002    0.000    0.014    0.014 copy.py:132(deepcopy)\n",
       "     1680    0.002    0.000    0.002    0.000 train_misc.py:58(__init__)\n",
       "     2160    0.002    0.000    0.002    0.000 modules.py:280(<listcomp>)\n",
       "     2407    0.002    0.000    0.002    0.000 {built-in method _imp.lock_held}\n",
       "     3488    0.002    0.000    0.004    0.000 utils.py:77(<lambda>)\n",
       "     1390    0.002    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:63(_path_split)\n",
       "        1    0.002    0.002    0.002    0.002 {built-in method _posixsubprocess.fork_exec}\n",
       "     1023    0.002    0.000    0.163    0.000 re.py:286(_compile)\n",
       "      352    0.002    0.000    0.006    0.000 inspect.py:2832(_hash_basis)\n",
       "      239    0.002    0.000    0.017    0.000 Image.py:1738(resize)\n",
       "      352    0.002    0.000    0.018    0.000 inspect.py:2181(_signature_from_callable)\n",
       "     3814    0.002    0.000    0.002    0.000 utils.py:61(__init__)\n",
       "     1981    0.002    0.000    0.002    0.000 {built-in method _struct.pack}\n",
       "      744    0.002    0.000    0.004    0.000 inspect.py:2450(__init__)\n",
       "      759    0.002    0.000    0.003    0.000 grad_mode.py:31(__enter__)\n",
       "     4479    0.002    0.000    0.002    0.000 {method 'lower' of 'str' objects}\n",
       "     2307    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:847(__exit__)\n",
       "     2103    0.002    0.000    0.003    0.000 sre_parse.py:171(append)\n",
       "     1066    0.002    0.000    0.015    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "     2992    0.002    0.000    0.002    0.000 version.py:207(<genexpr>)\n",
       "     1076    0.002    0.000    0.032    0.000 version.py:24(parse)\n",
       "      490    0.002    0.000    0.002    0.000 {method 'sort' of 'list' objects}\n",
       "      306    0.002    0.000    0.004    0.000 serialization.py:513(persistent_load)\n",
       "      920    0.002    0.000    0.010    0.000 <frozen importlib._bootstrap>:194(_lock_unlock_module)\n",
       "     2307    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:843(__enter__)\n",
       "     2281    0.002    0.000    0.003    0.000 sre_parse.py:159(__len__)\n",
       "      306    0.002    0.000    0.020    0.000 _utils.py:127(_rebuild_tensor)\n",
       "    368/2    0.002    0.000    0.006    0.003 module.py:1024(__repr__)\n",
       "      724    0.002    0.000    0.007    0.000 <frozen importlib._bootstrap_external>:1228(_get_spec)\n",
       "      239    0.002    0.000    0.002    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
       "     2949    0.002    0.000    0.002    0.000 {method 'endswith' of 'str' objects}\n",
       "      320    0.002    0.000    0.005    0.000 __init__.py:683(add)\n",
       "      478    0.002    0.000    0.002    0.000 {method 'flush' of '_io.BufferedRandom' objects}\n",
       "     1866    0.002    0.000    0.003    0.000 sre_parse.py:285(tell)\n",
       "      722    0.002    0.000    0.014    0.000 <frozen importlib._bootstrap_external>:361(_get_cached)\n",
       "        1    0.002    0.002    0.031    0.031 binding.py:81(build_conditional_library)\n",
       "      326    0.002    0.000    0.043    0.000 __init__.py:2094(_handle_ns)\n",
       "      352    0.002    0.000    0.003    0.000 inspect.py:2730(__init__)\n",
       "      891    0.002    0.000    0.002    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
       "     1117    0.002    0.000    0.002    0.000 {built-in method builtins.iter}\n",
       "     3828    0.002    0.000    0.002    0.000 {method 'partition' of 'str' objects}\n",
       "      691    0.002    0.000    0.018    0.000 __init__.py:2647(_get_metadata)\n",
       "     1417    0.002    0.000    0.015    0.000 <frozen importlib._bootstrap>:403(cached)\n",
       "      138    0.002    0.000    0.002    0.000 {method 'splitlines' of 'str' objects}\n",
       "      194    0.002    0.000    0.008    0.000 tensor.py:16(__deepcopy__)\n",
       "      150    0.002    0.000    0.029    0.000 utils.py:89(verify_interface)\n",
       "      478    0.002    0.000    0.002    0.000 {built-in method PIL._imaging.raw_decoder}\n",
       "     1390    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:52(_r_long)\n",
       "     1136    0.002    0.000    0.004    0.000 _weakrefset.py:58(__iter__)\n",
       "     1870    0.002    0.000    0.005    0.000 version.py:47(__lt__)\n",
       "     1870    0.002    0.000    0.005    0.000 version.py:53(__eq__)\n",
       "      528    0.002    0.000    0.002    0.000 optimizer.py:83(<dictcomp>)\n",
       "      452    0.002    0.000    0.023    0.000 __init__.py:1323(safe_version)\n",
       "      240    0.002    0.000    0.006    0.000 sampler.py:50(__init__)\n",
       "     4226    0.002    0.000    0.002    0.000 utils.py:94(<lambda>)\n",
       "      239    0.002    0.000    0.002    0.000 {built-in method PIL._imaging.jpeg_encoder}\n",
       "     2896    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:321(<genexpr>)\n",
       "       93    0.001    0.000    0.002    0.000 function.py:89(__init__)\n",
       "      239    0.001    0.000    0.002    0.000 summary.py:59(_calc_scale_factor)\n",
       "      194    0.001    0.000    0.001    0.000 {method 'copy_' of 'torch._C.FloatStorageBase' objects}\n",
       "      241    0.001    0.000    0.002    0.000 sampler.py:142(__init__)\n",
       "      471    0.001    0.000    0.003    0.000 copy.py:268(_reconstruct)\n",
       "       16    0.001    0.000    0.001    0.000 {method 'AddSerializedFile' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "      240    0.001    0.000    0.006    0.000 sampler.py:33(__iter__)\n",
       "      452    0.001    0.000    0.004    0.000 version.py:236(__str__)\n",
       "     1066    0.001    0.000    0.005    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "      956    0.001    0.000    0.002    0.000 __init__.py:2540(key)\n",
       "      342    0.001    0.000    0.131    0.000 __init__.py:1940(find_on_path)\n",
       "       68    0.001    0.000    0.001    0.000 {built-in method posix.lstat}\n",
       "      478    0.001    0.000    0.001    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "      528    0.001    0.000    0.059    0.000 optimizer.py:86(<listcomp>)\n",
       "      507    0.001    0.000    0.001    0.000 _weakrefset.py:36(__init__)\n",
       "      775    0.001    0.000    0.001    0.000 {method 'split' of '_sre.SRE_Pattern' objects}\n",
       "      330    0.001    0.000    0.005    0.000 __init__.py:1958(<genexpr>)\n",
       "      133    0.001    0.000    0.003    0.000 pyparsing.py:3260(__init__)\n",
       "     1054    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "    165/1    0.001    0.000    0.007    0.007 module.py:185(_apply)\n",
       "     1482    0.001    0.000    0.001    0.000 sre_parse.py:111(__init__)\n",
       "      695    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:393(_check_name_wrapper)\n",
       "      695    0.001    0.000    0.034    0.000 <frozen importlib._bootstrap_external>:840(path_stats)\n",
       "      748    0.001    0.000    0.002    0.000 __init__.py:2688(__getattr__)\n",
       "      982    0.001    0.000    0.013    0.000 <frozen importlib._bootstrap_external>:1080(_path_importer_cache)\n",
       "       52    0.001    0.000    1.378    0.027 __init__.py:1(<module>)\n",
       "     1680    0.001    0.000    0.001    0.000 {method 'upper' of 'str' objects}\n",
       "       34    0.001    0.000    0.001    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
       "      239    0.001    0.000    0.002    0.000 JpegImagePlugin.py:626(<listcomp>)\n",
       "      239    0.001    0.000    0.014    0.000 Image.py:1083(copy)\n",
       "       84    0.001    0.000    0.002    0.000 init.py:178(_calculate_fan_in_and_fan_out)\n",
       "      630    0.001    0.000    0.002    0.000 sre_compile.py:388(_simple)\n",
       "      445    0.001    0.000    0.007    0.000 PyColorize.py:328(__call__)\n",
       "      749    0.001    0.000    0.195    0.000 <frozen importlib._bootstrap_external>:1149(find_spec)\n",
       "      239    0.001    0.000    0.002    0.000 utils.py:102(<listcomp>)\n",
       "   963/20    0.001    0.000    1.956    0.098 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "   530/46    0.001    0.000    1.555    0.034 {built-in method builtins.__import__}\n",
       "      760    0.001    0.000    0.017    0.000 version.py:74(__init__)\n",
       "       29    0.001    0.000    0.014    0.000 traceback.py:319(extract)\n",
       "      194    0.001    0.000    0.004    0.000 storage.py:40(clone)\n",
       "     1390    0.001    0.000    0.001    0.000 {built-in method from_bytes}\n",
       "     1096    0.001    0.000    0.001    0.000 inspect.py:2779(<genexpr>)\n",
       "       31    0.001    0.000    0.002    0.000 auto.py:107(_make_function_class)\n",
       "       35    0.001    0.000    0.013    0.000 PyColorize.py:207(format2)\n",
       "      537    0.001    0.000    0.003    0.000 __init__.py:2281(yield_lines)\n",
       "     1096    0.001    0.000    0.001    0.000 inspect.py:2833(<genexpr>)\n",
       "     1758    0.001    0.000    0.001    0.000 version.py:244(<genexpr>)\n",
       "       86    0.001    0.000    0.005    0.000 abc.py:132(__new__)\n",
       "      282    0.001    0.000    0.003    0.000 function_base.py:3895(add_newdoc)\n",
       "      697    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
       "      335    0.001    0.000    0.001    0.000 pyparsing.py:1144(__init__)\n",
       "      120    0.001    0.000    0.005    0.000 sre_compile.py:482(_compile_info)\n",
       "      352    0.001    0.000    0.002    0.000 inspect.py:485(unwrap)\n",
       "     2304    0.001    0.000    0.001    0.000 version.py:298(_parse_letter_version)\n",
       "       23    0.001    0.000    0.001    0.000 {built-in method builtins.dir}\n",
       "       32    0.001    0.000    0.001    0.000 {method 'readline' of '_io.BufferedReader' objects}\n",
       "      314    0.001    0.000    0.033    0.000 __init__.py:1935(<listcomp>)\n",
       "      478    0.001    0.000    0.001    0.000 {built-in method builtins.round}\n",
       "     2552    0.001    0.000    0.001    0.000 {built-in method builtins.ord}\n",
       "     1806    0.001    0.000    0.001    0.000 {method 'find' of 'bytearray' objects}\n",
       "      695    0.001    0.000    0.001    0.000 {built-in method _imp._fix_co_filename}\n",
       "      120    0.001    0.000    0.158    0.001 sre_compile.py:557(compile)\n",
       "     1015    0.001    0.000    0.002    0.000 sre_compile.py:102(fixup)\n",
       "       40    0.001    0.000    0.015    0.000 conv.py:17(__init__)\n",
       "      159    0.001    0.000    0.002    0.000 __init__.py:2772(<listcomp>)\n",
       "      285    0.001    0.000    0.001    0.000 {built-in method _warnings.warn}\n",
       "     1518    0.001    0.000    0.001    0.000 {built-in method torch._C.set_grad_enabled}\n",
       "      121    0.001    0.000    0.003    0.000 __init__.py:1521(_get)\n",
       "   388/97    0.001    0.000    0.002    0.000 optimizer.py:122(cast)\n",
       "      323    0.001    0.000    0.037    0.000 <frozen importlib._bootstrap_external>:413(_find_module_shim)\n",
       "      478    0.001    0.000    0.002    0.000 _util.py:10(isPath)\n",
       "      366    0.001    0.000    0.002    0.000 module.py:11(_addindent)\n",
       "      314    0.001    0.000    0.037    0.000 __init__.py:1929(_by_version)\n",
       "      823    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
       "      336    0.001    0.000    0.002    0.000 warnings.py:159(_add_filter)\n",
       "     1066    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "      320    0.001    0.000    0.019    0.000 __init__.py:2468(__init__)\n",
       "      388    0.001    0.000    0.004    0.000 __init__.py:1468(_fn)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:48(<lambda>)\n",
       "      749    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:780(find_spec)\n",
       "     1940    0.001    0.000    0.004    0.000 __init__.py:2248(_normalize_cached)\n",
       "      240    0.001    0.000    0.575    0.002 module.py:992(eval)\n",
       "      176    0.001    0.000    0.007    0.000 inspect.py:2846(__eq__)\n",
       "     1499    0.001    0.000    0.001    0.000 {built-in method _sre.getlower}\n",
       "       14    0.001    0.000    0.001    0.000 traitlets.py:596(_cross_validate)\n",
       "        3    0.001    0.000    0.341    0.114 __init__.py:9(<module>)\n",
       "        1    0.001    0.001    0.001    0.001 descriptor_pb2.py:4(<module>)\n",
       "      120    0.001    0.000    0.082    0.001 sre_parse.py:844(parse)\n",
       "        2    0.001    0.000    0.002    0.001 __init__.py:1420(register_all)\n",
       "        3    0.001    0.000    0.738    0.246 serialization.py:385(_load)\n",
       "      471    0.001    0.000    0.008    0.000 pyparsing.py:1167(copy)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:54(<lambda>)\n",
       "      267    0.001    0.000    0.002    0.000 enum.py:797(__or__)\n",
       "      724    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:311(__enter__)\n",
       "      722    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C.FloatStorageBase' objects}\n",
       "       15    0.001    0.000    0.003    0.000 enum.py:124(__new__)\n",
       "    184/1    0.001    0.000    0.023    0.023 module.py:746(load)\n",
       "       20    0.001    0.000    0.001    0.000 {method 'read' of '_io.TextIOWrapper' objects}\n",
       "      800    0.001    0.000    0.001    0.000 inspect.py:159(isfunction)\n",
       "      352    0.001    0.000    0.001    0.000 inspect.py:2836(<dictcomp>)\n",
       "      159    0.001    0.000    0.004    0.000 __init__.py:2746(insert_on)\n",
       "      239    0.001    0.000    0.001    0.000 {built-in method PIL._imaging.zip_encoder}\n",
       "       95    0.001    0.000    0.001    0.000 functools.py:44(update_wrapper)\n",
       "        1    0.001    0.001    0.668    0.668 writer.py:246(__init__)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method torch._C._c10d_init}\n",
       "       98    0.001    0.000    0.011    0.000 <frozen importlib._bootstrap_external>:1281(_fill_cache)\n",
       "     1402    0.001    0.000    0.001    0.000 {method 'isidentifier' of 'str' objects}\n",
       "      749    0.001    0.000    0.001    0.000 {built-in method _imp.is_frozen}\n",
       "      530    0.001    0.000    0.001    0.000 __init__.py:119(is_tensor)\n",
       "      161    0.001    0.000    0.009    0.000 abc.py:151(register)\n",
       "      715    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
       "     1526    0.001    0.000    0.001    0.000 _structures.py:33(__neg__)\n",
       "       90    0.001    0.000    0.001    0.000 sre_compile.py:376(_mk_bitmap)\n",
       "    100/1    0.001    0.000    0.014    0.014 copy.py:236(_deepcopy_dict)\n",
       "      724    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:307(__init__)\n",
       "       24    0.001    0.000    0.138    0.006 __init__.py:609(add_entry)\n",
       "      324    0.001    0.000    0.001    0.000 warnings.py:449(__enter__)\n",
       "      355    0.001    0.000    0.001    0.000 _weakrefset.py:26(__exit__)\n",
       "      374    0.001    0.000    0.001    0.000 sre_parse.py:342(_escape)\n",
       "     1488    0.001    0.000    0.001    0.000 inspect.py:2512(kind)\n",
       "      214    0.001    0.000    0.001    0.000 module.py:17(<listcomp>)\n",
       "      316    0.001    0.000    0.003    0.000 genericpath.py:39(isdir)\n",
       "       18    0.001    0.000    0.010    0.001 __init__.py:357(namedtuple)\n",
       "      478    0.001    0.000    0.001    0.000 {method 'setimage' of 'ImagingDecoder' objects}\n",
       "      324    0.001    0.000    0.002    0.000 re.py:184(sub)\n",
       "     1264    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:41(_relax_case)\n",
       "      227    0.001    0.000    0.001    0.000 sre_parse.py:294(_class_escape)\n",
       "        3    0.001    0.000    0.002    0.001 six.py:1(<module>)\n",
       "        1    0.001    0.001    0.003    0.003 caffe2_pb2.py:4(<module>)\n",
       "        1    0.001    0.001    0.001    0.001 case.py:341(TestCase)\n",
       "       98    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:1196(__init__)\n",
       "      159    0.001    0.000    0.038    0.000 __init__.py:2193(fixup_namespace_packages)\n",
       "      267    0.001    0.000    0.005    0.000 __init__.py:1404(has_metadata)\n",
       "      471    0.001    0.000    0.001    0.000 {method '__reduce_ex__' of 'object' objects}\n",
       "        1    0.001    0.001    0.001    0.001 encoder.py:65(<module>)\n",
       "      480    0.001    0.000    0.001    0.000 dataloader.py:715(__del__)\n",
       "      330    0.001    0.000    0.002    0.000 warnings.py:143(simplefilter)\n",
       "      612    0.001    0.000    0.001    0.000 serialization.py:502(maybe_decode_ascii)\n",
       "      306    0.001    0.000    0.014    0.000 __init__.py:108(import_module)\n",
       "       86    0.001    0.000    0.001    0.000 _oid.py:11(__init__)\n",
       "      697    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:800(__init__)\n",
       "      239    0.001    0.000    0.020    0.000 PngImagePlugin.py:685(write)\n",
       "      159    0.001    0.000    0.052    0.000 __init__.py:2652(activate)\n",
       "      656    0.001    0.000    0.001    0.000 sre_parse.py:81(groups)\n",
       "      668    0.001    0.000    0.162    0.000 re.py:231(compile)\n",
       "      239    0.001    0.000    0.001    0.000 {built-in method math.ceil}\n",
       "      202    0.001    0.000    0.001    0.000 sre_parse.py:84(opengroup)\n",
       "       23    0.001    0.000    0.068    0.003 event_file_writer.py:35(__init__)\n",
       "       42    0.001    0.000    0.014    0.000 linecache.py:82(updatecache)\n",
       "      917    0.001    0.000    0.001    0.000 {method 'setdefault' of 'dict' objects}\n",
       "      480    0.001    0.000    0.001    0.000 scatter_gather.py:20(<listcomp>)\n",
       "      132    0.001    0.000    0.022    0.000 __init__.py:2451(_version_from_file)\n",
       "      396    0.001    0.000    0.001    0.000 __init__.py:2456(is_version_line)\n",
       "  472/114    0.001    0.000    0.006    0.000 {built-in method builtins.repr}\n",
       "       86    0.001    0.000    0.001    0.000 abc.py:135(<setcomp>)\n",
       "      782    0.001    0.000    0.001    0.000 {method 'pop' of 'dict' objects}\n",
       "      356    0.001    0.000    0.001    0.000 {method 'remove' of 'list' objects}\n",
       "      240    0.001    0.000    0.003    0.000 sampler.py:168(__len__)\n",
       "      336    0.001    0.000    0.001    0.000 loader.py:150(_is_section_key)\n",
       "        4    0.001    0.000    0.001    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
       "       56    0.001    0.000    0.003    0.000 argparse.py:1307(add_argument)\n",
       "    102/2    0.000    0.000    0.002    0.001 pyparsing.py:1370(_parseNoCache)\n",
       "      372    0.000    0.000    0.001    0.000 inspect.py:2559(__eq__)\n",
       "      336    0.000    0.000    0.002    0.000 loader.py:231(_has_section)\n",
       "      281    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
       "      306    0.000    0.000    0.013    0.000 <frozen importlib._bootstrap>:982(_gcd_import)\n",
       "     35/7    0.000    0.000    0.003    0.000 configurable.py:106(_find_my_config)\n",
       "      542    0.000    0.000    0.001    0.000 <string>:12(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method randn}\n",
       "      306    0.000    0.000    0.021    0.000 _utils.py:134(_rebuild_tensor_v2)\n",
       "      384    0.000    0.000    0.009    0.000 traceback.py:283(line)\n",
       "      478    0.000    0.000    0.015    0.000 Image.py:370(preinit)\n",
       "     1024    0.000    0.000    0.000    0.000 version.py:352(<lambda>)\n",
       "      355    0.000    0.000    0.001    0.000 _weakrefset.py:20(__enter__)\n",
       "      352    0.000    0.000    0.019    0.000 inspect.py:3055(signature)\n",
       "      324    0.000    0.000    0.001    0.000 warnings.py:468(__exit__)\n",
       "      118    0.000    0.000    0.001    0.000 enum.py:70(__setitem__)\n",
       "      352    0.000    0.000    0.019    0.000 inspect.py:2803(from_callable)\n",
       "      296    0.000    0.000    0.001    0.000 copy.py:252(_keep_alive)\n",
       "      564    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "      471    0.000    0.000    0.001    0.000 copyreg.py:87(__newobj__)\n",
       "      374    0.000    0.000    0.001    0.000 descriptor.py:524(__new__)\n",
       "      323    0.000    0.000    0.034    0.000 <frozen importlib._bootstrap_external>:1216(find_loader)\n",
       "        7    0.000    0.000    0.025    0.004 ultratb.py:833(format_record)\n",
       "        7    0.000    0.000    0.001    0.000 traitlets.py:224(getmembers)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method normal}\n",
       "       70    0.000    0.000    0.001    0.000 configurable.py:102(<listcomp>)\n",
       "       82    0.000    0.000    0.001    0.000 pyparsing.py:3719(__init__)\n",
       "      121    0.000    0.000    0.005    0.000 __init__.py:1407(get_metadata)\n",
       "      840    0.000    0.000    0.000    0.000 {built-in method builtins.chr}\n",
       "       90    0.000    0.000    0.000    0.000 sre_compile.py:378(<listcomp>)\n",
       "        7    0.000    0.000    0.002    0.000 traitlets.py:961(setup_instance)\n",
       "     1134    0.000    0.000    0.000    0.000 __init__.py:1997(__bool__)\n",
       "      386    0.000    0.000    0.009    0.000 <frozen importlib._bootstrap_external>:99(_path_isdir)\n",
       "      320    0.000    0.000    0.002    0.000 __init__.py:1315(safe_name)\n",
       "     1113    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
       "      239    0.000    0.000    0.000    0.000 PngImagePlugin.py:681(__init__)\n",
       "      749    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:707(find_spec)\n",
       "      120    0.000    0.000    0.075    0.001 sre_compile.py:542(_code)\n",
       "       40    0.000    0.000    0.009    0.000 conv.py:45(reset_parameters)\n",
       "      478    0.000    0.000    0.000    0.000 ImageFile.py:65(_tilesort)\n",
       "      407    0.000    0.000    0.001    0.000 tokenize.py:152(_compile)\n",
       "      478    0.000    0.000    0.000    0.000 {method 'cleanup' of 'ImagingEncoder' objects}\n",
       "      194    0.000    0.000    0.004    0.000 storage.py:24(__deepcopy__)\n",
       "        1    0.000    0.000 62445.175 62445.175 py3compat.py:184(execfile)\n",
       "       27    0.000    0.000    0.000    0.000 {built-in method _imp.exec_dynamic}\n",
       "      286    0.000    0.000    0.001    0.000 _tensor_docs.py:8(add_docstr_all)\n",
       "      704    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
       "       10    0.000    0.000    0.025    0.003 odefunc.py:99(__init__)\n",
       "       15    0.000    0.000    0.001    0.000 enum.py:160(<setcomp>)\n",
       "      960    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
       "      132    0.000    0.000    0.023    0.000 __init__.py:2858(_reload_version)\n",
       "      784    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1202(<genexpr>)\n",
       "        2    0.000    0.000    0.001    0.000 traceback.py:386(format)\n",
       "   219/58    0.000    0.000    0.005    0.000 typing.py:1145(__subclasscheck__)\n",
       "        1    0.000    0.000    0.608    0.608 _import_c_extension.py:3(<module>)\n",
       "      186    0.000    0.000    0.008    0.000 linecache.py:15(getline)\n",
       "       56    0.000    0.000    0.001    0.000 argparse.py:157(__init__)\n",
       "      343    0.000    0.000    0.000    0.000 loader.py:218(__contains__)\n",
       "      193    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
       "      352    0.000    0.000    0.001    0.000 inspect.py:505(_is_wrapper)\n",
       "      302    0.000    0.000    0.000    0.000 serialization.py:401(restore_location)\n",
       "      768    0.000    0.000    0.000    0.000 version.py:332(_parse_local_version)\n",
       "      149    0.000    0.000    0.035    0.000 utils.py:38(register_decorator)\n",
       "      240    0.000    0.000    0.004    0.000 dataloader.py:821(__len__)\n",
       "       21    0.000    0.000    0.000    0.000 {built-in method tensor}\n",
       "      984    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
       "      267    0.000    0.000    0.002    0.000 __init__.py:1509(_has)\n",
       "      724    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:424(has_location)\n",
       "      120    0.000    0.000    0.001    0.000 sre_parse.py:223(__init__)\n",
       "      695    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:825(get_filename)\n",
       "        9    0.000    0.000    0.001    0.000 auto.py:14(_make_function_class_criterion)\n",
       "       46    0.000    0.000    0.000    0.000 crc32c.py:77(crc_update)\n",
       "       60    0.000    0.000    0.003    0.000 six.py:837(wrapper)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_library_init}\n",
       "       23    0.000    0.000    0.097    0.004 event_file_writer.py:90(__init__)\n",
       "       98    0.000    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:1322(path_hook_for_FileFinder)\n",
       "      306    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:917(_sanity_check)\n",
       "      239    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedRandom' objects}\n",
       "       42    0.000    0.000    0.007    0.000 init.py:261(kaiming_uniform_)\n",
       "        2    0.000    0.000    0.000    0.000 {method '_set_from_file' of 'torch._C.LongStorageBase' objects}\n",
       "      178    0.000    0.000    0.001    0.000 _jit_internal.py:34(createResolutionCallback)\n",
       "      240    0.000    0.000    0.002    0.000 sampler.py:75(__len__)\n",
       "      704    0.000    0.000    0.000    0.000 inspect.py:2809(parameters)\n",
       "      588    0.000    0.000    0.000    0.000 ipstruct.py:125(__getattr__)\n",
       "      630    0.000    0.000    0.000    0.000 sre_parse.py:167(__setitem__)\n",
       "      193    0.000    0.000    0.001    0.000 codecs.py:318(decode)\n",
       "      160    0.000    0.000    0.052    0.000 __init__.py:3153(<genexpr>)\n",
       "      204    0.000    0.000    0.015    0.000 linecache.py:37(getlines)\n",
       "       80    0.000    0.000    0.001    0.000 conv.py:53(extra_repr)\n",
       "      196    0.000    0.000    0.007    0.000 train_misc.py:71(<genexpr>)\n",
       "       28    0.000    0.000    0.007    0.000 tokenize.py:448(open)\n",
       "      120    0.000    0.000    0.001    0.000 sre_parse.py:828(fix_flags)\n",
       "      200    0.000    0.000    0.004    0.000 utils.py:6(parse)\n",
       "      374    0.000    0.000    0.000    0.000 {method 'FindFieldByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       84    0.000    0.000    0.002    0.000 pyparsing.py:3390(__init__)\n",
       "       36    0.000    0.000    0.000    0.000 posixpath.py:331(normpath)\n",
       "        1    0.000    0.000    0.038    0.038 pyparsing.py:75(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 utils.py:13(get_logger)\n",
       "      324    0.000    0.000    0.000    0.000 warnings.py:428(__init__)\n",
       "        7    0.000    0.000    0.014    0.002 ultratb.py:379(_format_traceback_lines)\n",
       "      744    0.000    0.000    0.000    0.000 inspect.py:2500(name)\n",
       "   131/65    0.000    0.000    0.005    0.000 pyparsing.py:3365(<listcomp>)\n",
       "        1    0.000    0.000    0.002    0.002 numerictypes.py:81(<module>)\n",
       "      120    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
       "        1    0.000    0.000    0.026    0.026 auto.py:268(_generate_function_classes)\n",
       "      240    0.000    0.000    0.000    0.000 sre_compile.py:539(isstring)\n",
       "      202    0.000    0.000    0.005    0.000 sre_parse.py:96(closegroup)\n",
       "       98    0.000    0.000    0.001    0.000 module.py:122(register_parameter)\n",
       "      695    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:669(create_module)\n",
       "      136    0.000    0.000    0.000    0.000 enum.py:353(__setattr__)\n",
       "      350    0.000    0.000    0.001    0.000 pkgutil.py:402(get_importer)\n",
       "      304    0.000    0.000    0.000    0.000 __init__.py:1837(__init__)\n",
       "      495    0.000    0.000    0.000    0.000 {built-in method torch._C._add_docstr}\n",
       "   131/65    0.000    0.000    0.007    0.000 pyparsing.py:3363(copy)\n",
       "      754    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "       40    0.000    0.000    0.022    0.001 basic.py:152(__init__)\n",
       "      296    0.000    0.000    0.000    0.000 weakref.py:406(__setitem__)\n",
       "        1    0.000    0.000    0.004    0.004 summary_pb2.py:4(<module>)\n",
       "    61/11    0.000    0.000    0.007    0.001 pyparsing.py:3288(leaveWhitespace)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1444(_get_optional_kwargs)\n",
       "       57    0.000    0.000    0.000    0.000 sre_parse.py:266(getuntil)\n",
       "      104    0.000    0.000    0.001    0.000 os.py:664(__getitem__)\n",
       "      164    0.000    0.000    0.001    0.000 train_misc.py:17(_set)\n",
       "       39    0.000    0.000    0.001    0.000 _inspect.py:142(formatargspec)\n",
       "      355    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)\n",
       "      445    0.000    0.000    0.000    0.000 {method 'read' of '_io.StringIO' objects}\n",
       "       69    0.000    0.000    0.000    0.000 pyparsing.py:2412(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:104(_init)\n",
       "        1    0.000    0.000    0.001    0.001 attr_value_pb2.py:4(<module>)\n",
       "      266    0.000    0.000    0.000    0.000 pyparsing.py:3270(<genexpr>)\n",
       "        1    0.000    0.000 62445.221 62445.221 interactiveshell.py:2637(safe_execfile)\n",
       "        1    0.000    0.000    0.001    0.001 step_stats_pb2.py:4(<module>)\n",
       "      179    0.000    0.000    0.000    0.000 linecache.py:147(lazycache)\n",
       "      352    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
       "      331    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "       83    0.000    0.000    0.002    0.000 pyparsing.py:1821(__add__)\n",
       "    98/50    0.000    0.000    0.000    0.000 typing.py:1164(__setattr__)\n",
       "      178    0.000    0.000    0.000    0.000 inspect.py:1493(currentframe)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_load_error_strings}\n",
       "      239    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
       "      586    0.000    0.000    0.000    0.000 {built-in method _CheckCalledFromGeneratedFile}\n",
       "        1    0.000    0.000    0.003    0.003 core.py:21(<module>)\n",
       "      355    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
       "       86    0.000    0.000    0.004    0.000 compilerop.py:137(check_linecache_ipython)\n",
       "       91    0.000    0.000    0.001    0.000 _jit_internal.py:105(weak_script_method)\n",
       "      194    0.000    0.000    0.001    0.000 __init__.py:219(__init__)\n",
       "      184    0.000    0.000    0.000    0.000 module.py:684(<dictcomp>)\n",
       "   117/99    0.000    0.000    0.000    0.000 sre_compile.py:414(_get_literal_prefix)\n",
       "      409    0.000    0.000    0.000    0.000 utils.py:47(__init__)\n",
       "      198    0.000    0.000    0.000    0.000 traceback.py:290(walk_stack)\n",
       "       40    0.000    0.000    0.019    0.000 conv.py:307(__init__)\n",
       "      596    0.000    0.000    0.000    0.000 copy.py:190(_deepcopy_atomic)\n",
       "        1    0.000    0.000    0.000    0.000 token.py:3(<module>)\n",
       "        1    0.000    0.000    0.355    0.355 event_pb2.py:4(<module>)\n",
       "      148    0.000    0.000    0.001    0.000 _oid.py:58(__hash__)\n",
       "        6    0.000    0.000    0.001    0.000 getlimits.py:65(__init__)\n",
       "       86    0.000    0.000    0.003    0.000 linecache.py:53(checkcache)\n",
       "    82/80    0.000    0.000    0.000    0.000 pyparsing.py:372(__init__)\n",
       "        9    0.000    0.000    0.010    0.001 ultratb.py:157(findsource)\n",
       "       97    0.000    0.000    0.002    0.000 optimizer.py:132(<dictcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:2916(extend_all)\n",
       "      385    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}\n",
       "      160    0.000    0.000    0.000    0.000 __init__.py:666(__iter__)\n",
       "    32/31    0.000    0.000    0.001    0.000 typing.py:875(__extrahook__)\n",
       "       14    0.000    0.000    0.006    0.000 traitlets.py:1142(notify_change)\n",
       "      239    0.000    0.000    0.000    0.000 JpegImagePlugin.py:665(validate_qtables)\n",
       "        1    0.000    0.000    0.016    0.016 optimizer.py:95(load_state_dict)\n",
       "       10    0.000    0.000    0.005    0.001 cnf.py:12(__init__)\n",
       "      121    0.000    0.000    0.005    0.000 __init__.py:1413(get_metadata_lines)\n",
       "       23    0.000    0.000    0.009    0.000 record_writer.py:114(write)\n",
       "      166    0.000    0.000    0.000    0.000 six.py:141(__init__)\n",
       "        3    0.000    0.000    0.745    0.248 serialization.py:300(load)\n",
       "      239    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BytesIO' objects}\n",
       "        7    0.000    0.000    0.000    0.000 traitlets.py:1421(<listcomp>)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:393(_joinrealpath)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd_init}\n",
       "      352    0.000    0.000    0.000    0.000 inspect.py:2813(return_annotation)\n",
       "      445    0.000    0.000    0.000    0.000 {method 'seek' of '_io.StringIO' objects}\n",
       "       12    0.000    0.000    0.006    0.000 pyparsing.py:2653(__init__)\n",
       "       48    0.000    0.000    0.002    0.000 pyparsing.py:3540(__init__)\n",
       "       26    0.000    0.000    0.043    0.002 pyparsing.py:2779(__init__)\n",
       "      407    0.000    0.000    0.000    0.000 {method 'span' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.001    0.001 getlimits.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 _tensor_docs.py:1(<module>)\n",
       "       86    0.000    0.000    0.001    0.000 module.py:161(add_module)\n",
       "        1    0.000    0.000    0.044    0.044 add_newdocs.py:10(<module>)\n",
       "        1    0.000    0.000    0.038    0.038 extensions.py:5(<module>)\n",
       "     19/4    0.000    0.000    0.001    0.000 pyparsing.py:3319(streamline)\n",
       "        1    0.000    0.000    0.003    0.003 kl.py:1(<module>)\n",
       "        3    0.000    0.000    0.192    0.064 tarfile.py:1411(__init__)\n",
       "       27    0.000    0.000    0.004    0.000 pyparsing.py:1039(_trim_arity)\n",
       "        3    0.000    0.000    0.122    0.041 functional.py:1(<module>)\n",
       "        1    0.000    0.000    0.329    0.329 __init__.py:16(<module>)\n",
       "       42    0.000    0.000    0.000    0.000 init.py:8(calculate_gain)\n",
       "      248    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "       24    0.000    0.000    0.001    0.000 container.py:187(extend)\n",
       "       28    0.000    0.000    0.012    0.000 traceback.py:200(extract_stack)\n",
       "      362    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
       "      107    0.000    0.000    0.005    0.000 module.py:260(<lambda>)\n",
       "        1    0.000    0.000    0.656    0.656 workspace.py:3(<module>)\n",
       "       23    0.000    0.000    0.001    0.000 queue.py:27(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 layout_pb2.py:4(<module>)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:2826(__str__)\n",
       "       23    0.000    0.000    0.023    0.001 record_writer.py:35(directory_check)\n",
       "        1    0.000    0.000    0.006    0.006 __init__.py:57(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:118(__repr__)\n",
       "      282    0.000    0.000    0.000    0.000 {method 'zfill' of 'str' objects}\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1796(get_metadata)\n",
       "       28    0.000    0.000    0.001    0.000 tokenize.py:355(detect_encoding)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1364(_add_action)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(<listcomp>)\n",
       "      368    0.000    0.000    0.000    0.000 module.py:1012(_get_name)\n",
       "       86    0.000    0.000    0.000    0.000 six.py:105(__init__)\n",
       "      244    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
       "       21    0.000    0.000    0.000    0.000 traitlets.py:486(_dynamic_default_callable)\n",
       "        1    0.000    0.000    0.018    0.018 pyparsing.py:5399(pyparsing_common)\n",
       "      120    0.000    0.000    0.001    0.000 pyparsing.py:2368(__init__)\n",
       "      110    0.000    0.000    0.000    0.000 os.py:742(encode)\n",
       "        1    0.000    0.000    0.074    0.074 __init__.py:106(<module>)\n",
       "      120    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
       "      148    0.000    0.000    0.000    0.000 utils.py:34(<lambda>)\n",
       "      315    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
       "      138    0.000    0.000    0.000    0.000 argparse.py:1282(_registry_get)\n",
       "       53    0.000    0.000    0.000    0.000 core.py:893(__init__)\n",
       "      164    0.000    0.000    0.000    0.000 abc.py:9(abstractmethod)\n",
       "       46    0.000    0.000    0.001    0.000 record_writer.py:127(masked_crc32c)\n",
       "       38    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "        1    0.000    0.000    0.004    0.004 tensor_pb2.py:4(<module>)\n",
       "        2    0.000    0.000    0.005    0.003 ec.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1775(_parse_known_args)\n",
       "        1    0.000    0.000    0.001    0.001 _torch_docs.py:1(<module>)\n",
       "       23    0.000    0.000    0.058    0.003 record_writer.py:105(__init__)\n",
       "       15    0.000    0.000    0.000    0.000 {built-in method builtins.eval}\n",
       "       82    0.000    0.000    0.000    0.000 pyparsing.py:363(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:317(getmembers)\n",
       "       11    0.000    0.000    0.107    0.010 __init__.py:5(<module>)\n",
       "       87    0.000    0.000    0.001    0.000 _jit_internal.py:83(weak_script)\n",
       "      118    0.000    0.000    0.000    0.000 enum.py:28(_is_dunder)\n",
       "        1    0.000    0.000    0.016    0.016 __init__.py:184(<module>)\n",
       "        2    0.000    0.000    0.234    0.117 __init__.py:41(<module>)\n",
       "      127    0.000    0.000    0.000    0.000 typing.py:1019(_abc_negative_cache)\n",
       "       42    0.000    0.000    0.001    0.000 init.py:50(uniform_)\n",
       "       98    0.000    0.000    0.000    0.000 parameter.py:23(__new__)\n",
       "       25    0.000    0.000    0.004    0.000 pyparsing.py:1250(setParseAction)\n",
       "       82    0.000    0.000    0.000    0.000 descriptor.py:281(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:349(_populate)\n",
       "      183    0.000    0.000    0.000    0.000 module.py:538(remove_from)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:358(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 _methods.py:5(<module>)\n",
       "       26    0.000    0.000    0.004    0.000 pyparsing.py:1047(extract_stack)\n",
       "        1    0.000    0.000    0.190    0.190 __init__.py:3126(_initialize_master_working_set)\n",
       "       42    0.000    0.000    0.001    0.000 init.py:251(_calculate_correct_fan)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}\n",
       "        1    0.000    0.000    0.003    0.003 markers.py:4(<module>)\n",
       "       18    0.000    0.000    0.004    0.000 inspect.py:680(getsourcefile)\n",
       "      343    0.000    0.000    0.000    0.000 {function Config.__contains__ at 0x7f3fc5a54620}\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:464(_find_new_)\n",
       "        1    0.000    0.000    0.078    0.078 requirements.py:4(<module>)\n",
       "      108    0.000    0.000    0.000    0.000 utils.py:33(read_only_property)\n",
       "      111    0.000    0.000    0.000    0.000 _jit_internal.py:98(weak_module)\n",
       "       88    0.000    0.000    0.000    0.000 typing.py:1033(_abc_negative_cache_version)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1555(_add_action)\n",
       "      179    0.000    0.000    0.000    0.000 traceback.py:243(__init__)\n",
       "      170    0.000    0.000    0.000    0.000 pyparsing.py:2061(setWhitespaceChars)\n",
       "        1    0.000    0.000    0.003    0.003 numeric.py:1(<module>)\n",
       "       32    0.000    0.000    0.000    0.000 tokenize.py:385(find_cookie)\n",
       "        1    0.000    0.000    0.006    0.006 subprocess.py:1208(_execute_child)\n",
       "       68    0.000    0.000    0.001    0.000 posixpath.py:168(islink)\n",
       "      130    0.000    0.000    0.000    0.000 traitlets.py:545(__get__)\n",
       "       28    0.000    0.000    0.000    0.000 traitlets.py:1067(hold_trait_notifications)\n",
       "      149    0.000    0.000    0.000    0.000 utils.py:37(register_interface)\n",
       "       73    0.000    0.000    0.000    0.000 sre_compile.py:441(_get_charset_prefix)\n",
       "       60    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:861(_find_spec_legacy)\n",
       "       98    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
       "        1    0.000    0.000    0.050    0.050 backend.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method from_numpy}\n",
       "       61    0.000    0.000    0.005    0.000 pyparsing.py:3292(<listcomp>)\n",
       "       23    0.000    0.000    0.097    0.004 writer.py:162(__init__)\n",
       "        1    0.000    0.000    0.016    0.016 __init__.py:72(<module>)\n",
       "      302    0.000    0.000    0.000    0.000 train_cnf_disentangle.py:433(<lambda>)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:68(RegisterMessage)\n",
       "      159    0.000    0.000    0.000    0.000 __init__.py:919(_added_new)\n",
       "       21    0.000    0.000    0.001    0.000 traitlets.py:516(instance_init)\n",
       "      194    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
       "        7    0.000    0.000    0.002    0.000 traitlets.py:1407(traits)\n",
       "       27    0.000    0.000    0.000    0.000 inspect.py:64(ismodule)\n",
       "       18    0.000    0.000    0.000    0.000 inspect.py:643(getfile)\n",
       "      109    0.000    0.000    0.000    0.000 __init__.py:420(<genexpr>)\n",
       "      239    0.000    0.000    0.000    0.000 {method 'close' of '_io.BytesIO' objects}\n",
       "       23    0.000    0.000    0.058    0.003 record_writer.py:46(open_file)\n",
       "       68    0.000    0.000    0.000    0.000 status_codes.py:111(doc)\n",
       "        2    0.000    0.000    0.007    0.004 rsa.py:5(<module>)\n",
       "      220    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1161(getLogger)\n",
       "       60    0.000    0.000    0.000    0.000 enum.py:20(_is_descriptor)\n",
       "      252    0.000    0.000    0.000    0.000 six.py:88(__init__)\n",
       "        1    0.000    0.000    0.007    0.007 TiffImagePlugin.py:42(<module>)\n",
       "       48    0.000    0.000    0.002    0.000 pyparsing.py:1948(__or__)\n",
       "       96    0.000    0.000    0.000    0.000 pyparsing.py:2153(__str__)\n",
       "       30    0.000    0.000    0.001    0.000 contextlib.py:129(contextmanager)\n",
       "      195    0.000    0.000    0.000    0.000 pyparsing.py:3392(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:174(add_param_group)\n",
       "      277    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.add_docstring}\n",
       "     14/1    0.000    0.000    0.001    0.001 jsonutil.py:109(json_clean)\n",
       "       72    0.000    0.000    0.000    0.000 functools.py:74(wraps)\n",
       "      168    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
       "        9    0.000    0.000    0.013    0.001 inspect.py:1430(getframeinfo)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:237(SummaryWriter)\n",
       "       23    0.000    0.000    0.009    0.000 event_file_writer.py:54(write_event)\n",
       "    27/24    0.000    0.000    0.186    0.008 <frozen importlib._bootstrap_external>:919(create_module)\n",
       "       23    0.000    0.000    0.001    0.000 event_file_writer.py:159(__init__)\n",
       "      103    0.000    0.000    0.000    0.000 TiffTags.py:26(__new__)\n",
       "        1    0.000    0.000    0.146    0.146 pyopenssl.py:43(<module>)\n",
       "      194    0.000    0.000    0.000    0.000 __init__.py:231(__exit__)\n",
       "      189    0.000    0.000    0.000    0.000 status_codes.py:112(<genexpr>)\n",
       "        1    0.000    0.000    0.003    0.003 oid.py:5(<module>)\n",
       "       67    0.000    0.000    0.000    0.000 auto.py:95(_find_buffers)\n",
       "       46    0.000    0.000    0.000    0.000 crc32c.py:114(crc32c)\n",
       "        2    0.000    0.000    0.007    0.004 {built-in method builtins.sum}\n",
       "      129    0.000    0.000    0.000    0.000 {method 'mro' of 'type' objects}\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:580(_format_args)\n",
       "       49    0.000    0.000    0.000    0.000 codecs.py:308(__init__)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:98(getargspec)\n",
       "      118    0.000    0.000    0.000    0.000 enum.py:36(_is_sunder)\n",
       "        1    0.000    0.000    0.003    0.003 lapack.py:461(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stringprep.py:6(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:296(get_device_properties)\n",
       "       31    0.000    0.000    0.000    0.000 enum.py:419(_get_mixins_)\n",
       "      109    0.000    0.000    0.000    0.000 __init__.py:422(<genexpr>)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:67(getargs)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:835(__init__)\n",
       "       97    0.000    0.000    0.000    0.000 pyparsing.py:4781(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:50(__init__)\n",
       "        2    0.000    0.000    0.009    0.004 ocsp.py:5(<module>)\n",
       "        1    0.000    0.000    0.089    0.089 crypto.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:37(<listcomp>)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3037(_find_adapter)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2710(MaskedArray)\n",
       "       92    0.000    0.000    0.000    0.000 {method 'write' of '_io.BufferedWriter' objects}\n",
       "        1    0.000    0.000    0.009    0.009 Image.py:30(<module>)\n",
       "        2    0.000    0.000    0.053    0.027 base.py:5(<module>)\n",
       "        2    0.000    0.000    0.062    0.031 mnist.py:39(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3581(<genexpr>)\n",
       "      128    0.000    0.000    0.000    0.000 typing.py:1089(__eq__)\n",
       "       70    0.000    0.000    0.001    0.000 configurable.py:99(section_names)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1480(_pop_action_class)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:4875(_makeTags)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method torch.cuda._get_device_properties}\n",
       "    36/11    0.000    0.000    0.008    0.001 pyparsing.py:3743(leaveWhitespace)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:272(<setcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:120(<listcomp>)\n",
       "    14/13    0.000    0.000    0.045    0.003 <frozen importlib._bootstrap>:622(_load_backward_compatible)\n",
       "       23    0.000    0.000    0.000    0.000 pyparsing.py:2742(__str__)\n",
       "       20    0.000    0.000    0.000    0.000 pyparsing.py:2813(parseImpl)\n",
       "        1    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:4(<module>)\n",
       "       78    0.000    0.000    0.000    0.000 pyparsing.py:2052(leaveWhitespace)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:38(register_kl)\n",
       "       90    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
       "        1    0.000    0.000    0.002    0.002 core.py:47(<module>)\n",
       "       37    0.000    0.000    0.000    0.000 contextlib.py:59(__init__)\n",
       "      2/1    0.000    0.000    0.001    0.001 copy.py:210(_deepcopy_list)\n",
       "       43    0.000    0.000    0.000    0.000 posixpath.py:64(isabs)\n",
       "      183    0.000    0.000    0.000    0.000 {method '__subclasshook__' of 'object' objects}\n",
       "       38    0.000    0.000    0.000    0.000 constraint_registry.py:86(register)\n",
       "       51    0.000    0.000    0.000    0.000 _internal.py:715(_ufunc_doc_signature_formatter)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:90(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 modules.py:283(sample)\n",
       "       26    0.000    0.000    0.000    0.000 sre_compile.py:393(_generate_overlap_table)\n",
       "       82    0.000    0.000    0.000    0.000 types.py:135(__get__)\n",
       "       10    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "      194    0.000    0.000    0.000    0.000 __init__.py:223(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:151(ConcatConv2d)\n",
       "        1    0.000    0.000    0.001    0.001 node_def_pb2.py:4(<module>)\n",
       "      113    0.000    0.000    0.000    0.000 descriptor.py:690(__new__)\n",
       "     10/2    0.000    0.000    0.002    0.001 pyparsing.py:3397(parseImpl)\n",
       "        3    0.000    0.000    0.099    0.033 __init__.py:6(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:2234(_get_values)\n",
       "        1    0.000    0.000    0.007    0.007 text_format.py:41(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:8(<module>)\n",
       "        1    0.000    0.000    0.019    0.019 keys.py:15(<module>)\n",
       "       56    0.000    0.000    0.001    0.000 argparse.py:2352(_get_formatter)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:85(RegisterMessageDescriptor)\n",
       "      188    0.000    0.000    0.000    0.000 __init__.py:2498(_reload_version)\n",
       "        1    0.000    0.000    0.003    0.003 modes.py:5(<module>)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:573(format)\n",
       "       22    0.000    0.000    0.001    0.000 posixpath.py:369(abspath)\n",
       "        8    0.000    0.000    0.001    0.000 utils.py:1(<module>)\n",
       "        1    0.000    0.000    0.034    0.034 odenvp_conditional_tol.py:21(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 zipfile.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:1(<module>)\n",
       "        1    0.000    0.000    0.021    0.021 tokenize.py:26(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 pyparsing.py:3576(__str__)\n",
       "       10    0.000    0.000    0.001    0.000 odefunc.py:257(__init__)\n",
       "       88    0.000    0.000    0.000    0.000 traitlets.py:526(get)\n",
       "        2    0.000    0.000    0.004    0.002 dsa.py:5(<module>)\n",
       "     20/8    0.000    0.000    0.001    0.000 pyparsing.py:3547(parseImpl)\n",
       "      188    0.000    0.000    0.000    0.000 pyparsing.py:2656(<genexpr>)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1212(_fixupParents)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:204(iterencode)\n",
       "        1    0.000    0.000    0.000    0.000 types_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 resource_handle_pb2.py:4(<module>)\n",
       "       60    0.000    0.000    0.000    0.000 pyparsing.py:1351(preParse)\n",
       "      138    0.000    0.000    0.000    0.000 record_writer.py:132(u32)\n",
       "        1    0.000    0.000    0.015    0.015 ultratb.py:343(_fixed_getinnerframes)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:1822(take_action)\n",
       "        2    0.000    0.000    0.000    0.000 traceback.py:367(from_list)\n",
       "      139    0.000    0.000    0.000    0.000 pyparsing.py:3543(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:5(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 backend.py:13(register_function)\n",
       "       44    0.000    0.000    0.001    0.000 core.py:149(get_object_signature)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1740(parse_known_args)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:114(__prepare__)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:299(_add_aliases)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:793(__init__)\n",
       "       27    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:927(exec_module)\n",
       "       23    0.000    0.000    0.009    0.000 event_file_writer.py:63(_write_serialized_event)\n",
       "        1    0.000    0.000    0.000    0.000 dual.py:12(<module>)\n",
       "        3    0.000    0.000    0.003    0.001 distributed.py:1(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 general_name.py:5(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:930(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:48(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.Cryptography_add_osrandom_engine}\n",
       "      222    0.000    0.000    0.000    0.000 module.py:1015(extra_repr)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:26(_fr1)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:70(<lambda>)\n",
       "        1    0.000    0.000    0.009    0.009 util.py:150(_get_soname)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:564(_metavar_formatter)\n",
       "       84    0.000    0.000    0.000    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
       "        1    0.000    0.000    0.003    0.003 adapters.py:9(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 _big_num_ctypes.py:20(<module>)\n",
       "        1    0.000    0.000    0.012    0.012 connectionpool.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:1(<module>)\n",
       "       24    0.000    0.000    0.002    0.000 container.py:119(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 function_base.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 algorithms.py:5(<module>)\n",
       "        3    0.000    0.000    0.001    0.000 utils.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:1(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:365(__getitem__)\n",
       "       22    0.000    0.000    0.001    0.000 argparse.py:1843(consume_optional)\n",
       "       69    0.000    0.000    0.000    0.000 __init__.py:1265(<lambda>)\n",
       "      101    0.000    0.000    0.000    0.000 _inspect.py:133(strseq)\n",
       "        7    0.000    0.000    0.007    0.001 configurable.py:38(__init__)\n",
       "       45    0.000    0.000    0.000    0.000 pyparsing.py:1190(setName)\n",
       "      100    0.000    0.000    0.000    0.000 six.py:177(_add_module)\n",
       "        1    0.000    0.000    0.035    0.035 utils.py:9(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 numerictypes.py:229(bitname)\n",
       "        1    0.000    0.000    0.004    0.004 zmqshell.py:538(_showtraceback)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1713(_add_action)\n",
       "       72    0.000    0.000    0.000    0.000 inspect.py:690(<genexpr>)\n",
       "        3    0.000    0.000    0.033    0.011 odenvp_conditional_tol.py:181(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _ctypes.dlopen}\n",
       "       28    0.000    0.000    0.000    0.000 pyparsing.py:3997(__init__)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1813(get_metadata_lines)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:261(AuthorityInformationAccess)\n",
       "       18    0.000    0.000    0.000    0.000 copyreg.py:96(_slotnames)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:94(_check_capability)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:409(_init)\n",
       "      8/6    0.000    0.000    0.006    0.001 __init__.py:2159(declare_namespace)\n",
       "        3    0.000    0.000    0.006    0.002 __init__.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:225(_register_default_ciphers)\n",
       "       35    0.000    0.000    0.000    0.000 loader.py:161(__init__)\n",
       "       14    0.000    0.000    0.007    0.000 traitlets.py:558(set)\n",
       "       24    0.000    0.000    0.001    0.000 __init__.py:1870(find_distributions)\n",
       "        3    0.000    0.000    0.017    0.006 __init__.py:3(<module>)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6573(getdoc)\n",
       "       69    0.000    0.000    0.000    0.000 status_codes.py:117(<genexpr>)\n",
       "        2    0.000    0.000    0.007    0.003 connection.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:47(CosineSimilarity)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:2050(_match_argument)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:857(<listcomp>)\n",
       "       37    0.000    0.000    0.000    0.000 contextlib.py:85(__exit__)\n",
       "        1    0.000    0.000    0.002    0.002 graph_pb2.py:4(<module>)\n",
       "       38    0.000    0.000    0.001    0.000 pyparsing.py:4230(__init__)\n",
       "       15    0.000    0.000    0.000    0.000 pyparsing.py:4565(_escapeRegexRangeChars)\n",
       "        1    0.000    0.000    0.003    0.003 models.py:8(<module>)\n",
       "        1    0.000    0.000    0.018    0.018 cookiejar.py:26(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 ocsp.py:25(_requires_successful_response)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:69(decorator)\n",
       "       60    0.000    0.000    0.000    0.000 activation.py:617(extra_repr)\n",
       "       62    0.000    0.000    0.000    0.000 numerictypes.py:127(english_lower)\n",
       "        1    0.000    0.000    0.048    0.048 odeint.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:466(find)\n",
       "        2    0.000    0.000    0.000    0.000 weakref.py:102(__init__)\n",
       "        1    0.000    0.000    0.022    0.022 grammar.py:13(<module>)\n",
       "       14    0.000    0.000    0.003    0.000 __init__.py:2232(normalize_path)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method zeros_like}\n",
       "       25    0.000    0.000    0.000    0.000 typing.py:1025(_abc_negative_cache)\n",
       "        2    0.000    0.000    0.007    0.003 transforms.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:621(decorator)\n",
       "       16    0.000    0.000    0.001    0.000 pyparsing.py:1204(setResultsName)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:170(<dictcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 extras.py:10(<module>)\n",
       "        1    0.000    0.000    0.039    0.039 odefunc.py:1(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1268(__init__)\n",
       "       30    0.000    0.000    0.000    0.000 sre_parse.py:257(getwhile)\n",
       "       37    0.000    0.000    0.000    0.000 contextlib.py:157(helper)\n",
       "        1    0.000    0.000    0.000    0.000 versions_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:83(<listcomp>)\n",
       "        1    0.000    0.000    0.002    0.002 utils.py:4(<module>)\n",
       "       62    0.000    0.000    0.000    0.000 _inspect.py:146(<lambda>)\n",
       "       36    0.000    0.000    0.000    0.000 inspect.py:229(istraceback)\n",
       "        1    0.000    0.000    0.002    0.002 summary.py:30(<module>)\n",
       "       10    0.000    0.000    0.026    0.003 odenvp_conditional_tol.py:196(_make_odefunc)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:84(<listcomp>)\n",
       "        1    0.000    0.000    0.007    0.007 cookies.py:127(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:863(DefaultCookiePolicy)\n",
       "        2    0.000    0.000    0.002    0.001 hashes.py:5(<module>)\n",
       "        1    0.000    0.000    0.035    0.035 binding.py:5(<module>)\n",
       "        1    0.000    0.000    0.025    0.025 ultratb.py:820(format_records)\n",
       "       10    0.000    0.000    0.000    0.000 sre_compile.py:381(_bytes_to_codes)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:5(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 traitlets.py:988(__init__)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:202(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:433(spec_from_loader)\n",
       "       60    0.000    0.000    0.000    0.000 {method 'copy' of 'mappingproxy' objects}\n",
       "       42    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "       82    0.000    0.000    0.000    0.000 {method 'FindMessageTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        6    0.000    0.000    0.044    0.007 __init__.py:35(load_module)\n",
       "        1    0.000    0.000    0.000    0.000 idnadata.py:3(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 distributed_c10d.py:1(<module>)\n",
       "        3    0.000    0.000    0.191    0.064 tarfile.py:2276(next)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:74(__call__)\n",
       "        4    0.000    0.000    0.005    0.001 mnist.py:90(_check_exists)\n",
       "       23    0.000    0.000    0.000    0.000 {built-in method _socket.gethostname}\n",
       "       54    0.000    0.000    0.000    0.000 inspect.py:687(<genexpr>)\n",
       "       35    0.000    0.000    0.000    0.000 enum.py:822(_high_bit)\n",
       "       23    0.000    0.000    0.000    0.000 writer.py:53(__init__)\n",
       "        1    0.000    0.000    0.367    0.367 writer.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 encode_asn1.py:5(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 optimizer.py:32(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:61(__new__)\n",
       "        2    0.000    0.000    0.008    0.004 __init__.py:45(<module>)\n",
       "       43    0.000    0.000    0.000    0.000 py3compat.py:28(cast_unicode)\n",
       "       45    0.000    0.000    0.000    0.000 inspect.py:239(isframe)\n",
       "        1    0.000    0.000    0.002    0.002 decoder.py:79(<module>)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3439(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:11(<module>)\n",
       "       21    0.000    0.000    0.001    0.000 traitlets.py:587(_validate)\n",
       "        6    0.000    0.000    0.002    0.000 warnings.py:119(filterwarnings)\n",
       "       24    0.000    0.000    0.000    0.000 genericpath.py:27(isfile)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:52(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 plistlib.py:47(<module>)\n",
       "        4    0.000    0.000    0.373    0.093 __init__.py:2(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 blas.py:202(<module>)\n",
       "        1    0.000    0.000    0.088    0.088 thnn.py:21(_initialize_backend)\n",
       "       32    0.000    0.000    0.000    0.000 typing.py:889(__extrahook__)\n",
       "       14    0.000    0.000    0.003    0.000 posixpath.py:384(realpath)\n",
       "       95    0.000    0.000    0.000    0.000 pyparsing.py:203(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:55(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 constraint_registry.py:66(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 pooling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:58(InstanceNorm1d)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:71(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:285(_add_types)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2923(<listcomp>)\n",
       "       11    0.000    0.000    0.001    0.000 six.py:91(__get__)\n",
       "       12    0.000    0.000    0.000    0.000 {built-in method builtins.delattr}\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:1793(has_metadata)\n",
       "        1    0.000    0.000    0.001    0.001 loss.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 serialization.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 getlimits.py:376(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:2286(_get_value)\n",
       "        7    0.000    0.000    0.006    0.001 configurable.py:170(_config_changed)\n",
       "       14    0.000    0.000    0.006    0.000 traitlets.py:1133(_notify_trait)\n",
       "       59    0.000    0.000    0.000    0.000 enum.py:594(name)\n",
       "        3    0.000    0.000    0.002    0.001 __init__.py:10(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 response.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 normalization.py:1(<module>)\n",
       "      102    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3781(__str__)\n",
       "        2    0.000    0.000    0.004    0.002 dh.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 activation.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:86(<listcomp>)\n",
       "       78    0.000    0.000    0.000    0.000 _internal.py:726(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 ImageFilter.py:18(<module>)\n",
       "       50    0.000    0.000    0.000    0.000 six.py:184(find_module)\n",
       "        1    0.000    0.000    0.003    0.003 _tqdm.py:9(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:15(ismethod)\n",
       "       25    0.000    0.000    0.000    0.000 typing.py:1039(_abc_negative_cache_version)\n",
       "       60    0.000    0.000    0.000    0.000 six.py:835(add_metaclass)\n",
       "       43    0.000    0.000    0.000    0.000 caffe2_pb2.py:5(<lambda>)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:109(has_argument)\n",
       "        1    0.000    0.000    0.044    0.044 interactiveshell.py:1981(showtraceback)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1226(__init__)\n",
       "       50    0.000    0.000    0.000    0.000 inspect.py:81(ismethod)\n",
       "        6    0.000    0.000    0.000    0.000 inspect.py:1251(formatargvalues)\n",
       "       42    0.000    0.000    0.000    0.000 tokenize.py:739(generate_tokens)\n",
       "      102    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
       "        3    0.000    0.000    0.000    0.000 _utils.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 x25519.py:5(<module>)\n",
       "       66    0.000    0.000    0.000    0.000 {method 'readline' of '_io.StringIO' objects}\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:4(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:1069(wrapper)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2707(parseImpl)\n",
       "        3    0.000    0.000    0.037    0.012 _util.py:1(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 sessions.py:9(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 serialization.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:11(ExtensionOID)\n",
       "        7    0.000    0.000    0.004    0.001 configurable.py:131(_load_config)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1838(getLogger)\n",
       "        1    0.000    0.000    0.002    0.002 type_checkers.py:44(<module>)\n",
       "       16    0.000    0.000    0.055    0.003 __init__.py:1914(_by_version_descending)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:331(device_count)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:766(_construct_lookups)\n",
       "        1    0.000    0.000    0.062    0.062 train_cnf_disentangle.py:162(get_dataset)\n",
       "       41    0.000    0.000    0.000    0.000 enum.py:874(_power_of_two)\n",
       "        3    0.000    0.000    0.004    0.001 misc.py:1(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 {method 'AddDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       61    0.000    0.000    0.000    0.000 pyparsing.py:2159(streamline)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:30(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 index_tricks.py:1(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 traitlets.py:1690(instance_init)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:4757(<lambda>)\n",
       "        1    0.000    0.000    0.013    0.013 inspect.py:1481(getinnerframes)\n",
       "       17    0.000    0.000    0.000    0.000 __init__.py:685(__init__)\n",
       "       32    0.000    0.000    0.001    0.000 tokenize.py:379(read_or_stop)\n",
       "       22    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "       12    0.000    0.000    0.009    0.001 pyparsing.py:4251(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:663(__iadd__)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2263(_is_unpacked_egg)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:10(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:174(nti)\n",
       "       27    0.000    0.000    0.000    0.000 core.py:920(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 util.py:301(_findLib_prefix)\n",
       "       37    0.000    0.000    0.000    0.000 contextlib.py:79(__enter__)\n",
       "       49    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 TiffTags.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:49(<listcomp>)\n",
       "     15/4    0.000    0.000    0.001    0.000 pyparsing.py:3762(streamline)\n",
       "        1    0.000    0.000    0.005    0.005 train_misc.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:308(init_reductions)\n",
       "       23    0.000    0.000    0.000    0.000 threading.py:1136(daemon)\n",
       "        1    0.000    0.000    0.003    0.003 algos.py:19(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 utils.py:112(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 linear.py:47(__init__)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:118(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:126(EventHandle)\n",
       "        1    0.000    0.000    0.005    0.005 _internal.py:6(<module>)\n",
       "        1    0.000    0.000    0.040    0.040 ultratb.py:1056(format_exception_as_a_whole)\n",
       "        6    0.000    0.000    0.000    0.000 gettext.py:205(_expand_lang)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:746(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:1(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 x509.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 interfaces.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:28(<module>)\n",
       "        3    0.000    0.000    0.006    0.002 container.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:3(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 npyio.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 case.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:146(rng)\n",
       "       34    0.000    0.000    0.000    0.000 argparse.py:1278(register)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1493(_check_conflict)\n",
       "        7    0.000    0.000    0.000    0.000 inspect.py:1026(_getfullargs)\n",
       "        1    0.000    0.000    0.000    0.000 shutil.py:1093(which)\n",
       "        2    0.000    0.000    0.363    0.182 __init__.py:33(<module>)\n",
       "        1    0.000    0.000    0.033    0.033 odenvp_conditional_tol.py:65(_build_net)\n",
       "       24    0.000    0.000    0.000    0.000 pyparsing.py:411(__getitem__)\n",
       "        1    0.000    0.000    0.001    0.001 data_parallel.py:113(__init__)\n",
       "        2    0.000    0.000    0.003    0.002 rnn.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 shape_base.py:1(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:28(isfunction)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
       "       35    0.000    0.000    0.000    0.000 bunch.py:11(__getattr__)\n",
       "       24    0.000    0.000    0.000    0.000 re.py:169(match)\n",
       "       35    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:411(ImageFileDirectory_v2)\n",
       "        1    0.000    0.000    0.009    0.009 JpegImagePlugin.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:409(_VarintBytes)\n",
       "       34    0.000    0.000    0.000    0.000 descriptor_pb2.py:5(<lambda>)\n",
       "    13/12    0.000    0.000    0.000    0.000 pyparsing.py:3434(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 special_matrices.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 sbcsgroupprober.py:29(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 constraint_registry.py:105(<lambda>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:128(<lambda>)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6568(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:88(<module>)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:43(iscode)\n",
       "        7    0.000    0.000    0.007    0.001 PyColorize.py:180(__init__)\n",
       "       21    0.000    0.000    0.000    0.000 traitlets.py:215(__init__)\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:219(_acquireLock)\n",
       "       26    0.000    0.000    0.000    0.000 traceback.py:273(__getitem__)\n",
       "       15    0.000    0.000    0.000    0.000 _collections_abc.py:664(__contains__)\n",
       "       94    0.000    0.000    0.000    0.000 pyparsing.py:4890(<genexpr>)\n",
       "       32    0.000    0.000    0.000    0.000 pyparsing.py:209(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 constant_time.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 linalg.py:10(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 numerictypes.py:216(_evalname)\n",
       "        7    0.000    0.000    0.000    0.000 inspect.py:1180(getargvalues)\n",
       "        2    0.000    0.000    0.000    0.000 shutil.py:1048(get_terminal_size)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:976(_get_parent_path)\n",
       "       10    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:980(_recalculate)\n",
       "        1    0.000    0.000    0.001    0.001 PngImagePlugin.py:34(<module>)\n",
       "       16    0.000    0.000    0.001    0.000 descriptor.py:869(__new__)\n",
       "        1    0.000    0.000    0.010    0.010 descriptor.py:33(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 specifiers.py:266(_require_version_compare)\n",
       "        1    0.000    0.000    0.001    0.001 poolmanager.py:1(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 mbcsgroupprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 exceptions.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:267(get_device_name)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:73(CFUNCTYPE)\n",
       "        2    0.000    0.000    0.001    0.000 modules.py:96(__init__)\n",
       "        2    0.000    0.000    0.005    0.002 mnist.py:94(download)\n",
       "       23    0.000    0.000    0.000    0.000 queue.py:199(_init)\n",
       "       15    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
       "        1    0.000    0.000    0.004    0.004 pytorch_graph.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:2863(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 socks.py:23(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:147(deprecated)\n",
       "        1    0.000    0.000    0.003    0.003 chardistribution.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:11(_check_balance)\n",
       "        1    0.000    0.000    0.086    0.086 auto.py:1(<module>)\n",
       "       40    0.000    0.000    0.000    0.000 numerictypes.py:154(english_upper)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:2190(_get_nargs_pattern)\n",
       "        7    0.000    0.000    0.000    0.000 traitlets.py:1178(_add_notifiers)\n",
       "       28    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:190(_checkLevel)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:752(_addHandlerRef)\n",
       "        4    0.000    0.000    0.000    0.000 decoder.py:263(_StructPackDecoder)\n",
       "        1    0.000    0.000    0.001    0.001 text_encoding.py:31(<module>)\n",
       "     12/2    0.000    0.000    0.000    0.000 pyparsing.py:1926(makeOptionalList)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:3120(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 matfuncs.py:5(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 basic.py:7(<module>)\n",
       "        1    0.000    0.000    0.028    0.028 compat.py:9(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 name.py:5(<module>)\n",
       "       21    0.000    0.000    0.000    0.000 utils.py:126(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:5(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:242(getdoc)\n",
       "       36    0.000    0.000    0.000    0.000 getlimits.py:69(<lambda>)\n",
       "        1    0.000    0.000    0.011    0.011 __init__.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1020(prepare_header)\n",
       "        1    0.000    0.000    0.040    0.040 ultratb.py:1373(structured_traceback)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1414(wait)\n",
       "       27    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:908(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.putenv}\n",
       "       37    0.000    0.000    0.000    0.000 {method 'expandtabs' of 'str' objects}\n",
       "       73    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:3851(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:214(_CertificateRevocationList)\n",
       "        1    0.000    0.000    0.000    0.000 ssl_.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:29(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 sparse.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:2(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:1024(frombuf)\n",
       "        1    0.000    0.000    0.001    0.001 fromnumeric.py:3(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 __init__.py:206(_sanity_check)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:771(__init__)\n",
       "        1    0.000    0.000    0.006    0.006 subprocess.py:588(__init__)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:65(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
       "        1    0.000    0.000    0.004    0.004 fractions.py:4(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 fixer_util.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 six.py:195(load_module)\n",
       "        1    0.000    0.000    0.000    0.000 decomp.py:15(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 util.py:15(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 request.py:1(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 container.py:153(__len__)\n",
       "       24    0.000    0.000    0.001    0.000 container.py:159(__iadd__)\n",
       "        2    0.000    0.000    0.000    0.000 profiler.py:1(<module>)\n",
       "        3    0.000    0.000    0.192    0.064 tarfile.py:1522(open)\n",
       "        1    0.000    0.000    0.001    0.001 polynomial.py:56(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.empty}\n",
       "        1    0.000    0.000    0.034    0.034 train_cnf_disentangle.py:312(create_model)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:55(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:321(fix_frame_records_filenames)\n",
       "        7    0.000    0.000    0.002    0.000 traitlets.py:950(__new__)\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:228(_releaseLock)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
       "       12    0.000    0.000    0.000    0.000 six.py:126(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.unsetenv}\n",
       "       10    0.000    0.000    0.000    0.000 {method 'tolist' of 'memoryview' objects}\n",
       "        2    0.000    0.000    0.001    0.000 grammar.py:105(load)\n",
       "        1    0.000    0.000    0.031    0.031 specifiers.py:4(<module>)\n",
       "        1    0.000    0.000    0.014    0.014 _elliptic_curve.py:47(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcssm.py:28(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 linear.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 tensor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:59(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:59(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 dopri5.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:1(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:1950(<listcomp>)\n",
       "       34    0.000    0.000    0.000    0.000 inspect.py:253(iscode)\n",
       "        7    0.000    0.000    0.000    0.000 TiffImagePlugin.py:635(_register_basic)\n",
       "        1    0.000    0.000    0.001    0.001 well_known_types.py:39(<module>)\n",
       "       14    0.000    0.000    0.001    0.000 pyparsing.py:2026(__call__)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2256(_is_egg_path)\n",
       "        1    0.000    0.000    0.355    0.355 event_file_writer.py:15(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1414(_get_builtin_table)\n",
       "        7    0.000    0.000    0.000    0.000 _jit_internal.py:113(boolean_dispatch)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:88(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:4(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:118(deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:17(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:251(_get_machar)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:332(__init__)\n",
       "        1    0.000    0.000    0.016    0.016 tsit5.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:1(<module>)\n",
       "       35    0.000    0.000    0.000    0.000 traitlets.py:911(__get__)\n",
       "        7    0.000    0.000    0.002    0.000 traitlets.py:982(setup_instance)\n",
       "        7    0.000    0.000    0.000    0.000 inspect.py:1016(getargs)\n",
       "       15    0.000    0.000    0.000    0.000 inspect.py:1262(convert)\n",
       "        3    0.000    0.000    0.001    0.000 re.py:179(search)\n",
       "        5    0.000    0.000    0.000    0.000 re.py:249(escape)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:135(<dictcomp>)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:312(__getattr__)\n",
       "       20    0.000    0.000    0.000    0.000 enum.py:581(__hash__)\n",
       "       20    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}\n",
       "        1    0.000    0.000    0.008    0.008 utils.py:3(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 pygram.py:22(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 parse.py:11(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 api_implementation.py:32(<module>)\n",
       "     16/2    0.000    0.000    0.001    0.001 pyparsing.py:3737(parseImpl)\n",
       "        1    0.000    0.000    0.000    0.000 _solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:1529(Connection)\n",
       "        1    0.000    0.000    0.001    0.001 core.py:1(<module>)\n",
       "        1    0.000    0.000    0.014    0.014 _int.py:32(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 scatter_gather.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2931(__array_finalize__)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:332(<dictcomp>)\n",
       "       18    0.000    0.000    0.000    0.000 core.py:996(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:83(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:63(NDArrayOperatorsMixin)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Mismatch)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:440(_set_array_types)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:657(send)\n",
       "        1    0.000    0.000    0.009    0.009 util.py:310(find_library)\n",
       "        1    0.000    0.000    0.030    0.030 modules.py:1(<module>)\n",
       "       10    0.000    0.000    0.001    0.000 cnf_regularization.py:6(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 loader.py:182(merge)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:1059(system)\n",
       "       23    0.000    0.000    0.000    0.000 enum.py:599(value)\n",
       "       10    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:993(__iter__)\n",
       "       46    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
       "       67    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.urandom}\n",
       "        1    0.000    0.000    0.000    0.000 ImageChops.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:48(<module>)\n",
       "        1    0.000    0.000    0.027    0.027 refactor.py:9(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 descriptor.py:919(_ParseOptions)\n",
       "       46    0.000    0.000    0.000    0.000 pyparsing.py:1366(postParse)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3164(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1805(_warn_on_replacement)\n",
       "       16    0.000    0.000    0.005    0.000 __init__.py:2006(safe_listdir)\n",
       "       10    0.000    0.000    0.000    0.000 __init__.py:23(find_module)\n",
       "        1    0.000    0.000    0.002    0.002 record_writer.py:4(<module>)\n",
       "        1    0.000    0.000    0.368    0.368 torchvis.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_schur.py:1(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 Image.py:2810(register_extension)\n",
       "        2    0.000    0.000    0.006    0.003 resnet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:171(RequestsCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1063(ZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:684(Context)\n",
       "        1    0.000    0.000    0.013    0.013 universaldetector.py:36(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 constraints.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:328(ExprBuilder)\n",
       "        2    0.000    0.000    0.000    0.000 random.py:1(<module>)\n",
       "        1    0.000    0.000    0.018    0.018 __init__.py:147(_lazy_init)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:19(ABCPolyBase)\n",
       "       30    0.000    0.000    0.000    0.000 numerictypes.py:432(_add_array_type)\n",
       "        4    0.000    0.000    0.000    0.000 textwrap.py:414(dedent)\n",
       "       18    0.000    0.000    0.000    0.000 argparse.py:568(<listcomp>)\n",
       "       42    0.000    0.000    0.000    0.000 traitlets.py:1047(cross_validation_lock)\n",
       "       13    0.000    0.000    0.000    0.000 _collections_abc.py:72(_check_methods)\n",
       "        1    0.000    0.000    0.001    0.001 GifImagePlugin.py:27(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 BmpImagePlugin.py:27(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 noniterators.py:18(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:116(RegisterFileDescriptor)\n",
       "       46    0.000    0.000    0.000    0.000 crc32c.py:100(crc_finalize)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:89(_OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:81(Backend)\n",
       "        5    0.000    0.000    0.031    0.006 binding.py:122(_ensure_ffi_initialized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 crypto.py:625(_cmp)\n",
       "        1    0.000    0.000    0.001    0.001 retry.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:9(parse_kwargs)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:271(<dictcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2905(_update_from)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:126(doc_note)\n",
       "        1    0.000    0.000    0.001    0.001 fftpack.py:32(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:1(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:18(_fr0)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:340(_add_integer_aliases)\n",
       "        1    0.000    0.000    0.005    0.005 cnf_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1604(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:839(_decompose)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:294(IFDRational)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:30(<module>)\n",
       "        2    0.000    0.000    0.010    0.005 odenvp_conditional_tol.py:208(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:31(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:4681(originalTextFor)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3458(__init__)\n",
       "        6    0.000    0.000    0.001    0.000 __init__.py:2707(from_filename)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:1(<module>)\n",
       "        1    0.000    0.000    0.089    0.089 module.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:51(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:25(register_func)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:48(_numeric_methods)\n",
       "        2    0.000    0.000    0.000    0.000 __config__.py:3(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 train_cnf_disentangle.py:163(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 jsonapi.py:31(dumps)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:65(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 ultratb.py:968(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:586(iteritems)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:183(dumps)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(Iterator)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4781(<lambda>)\n",
       "        1    0.000    0.000    0.011    0.011 version.py:4(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 api.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:52(NameOID)\n",
       "        1    0.000    0.000    0.002    0.002 _iri.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:79(Certificate)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PoolKey)\n",
       "        1    0.000    0.000    0.004    0.004 sjisprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:59(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scimath.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:418(_construct_char_code_lookup)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2491(seterr)\n",
       "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7f3fc5a46a60}\n",
       "       35    0.000    0.000    0.000    0.000 loader.py:165(_ensure_subconfig)\n",
       "       43    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
       "       34    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:323(_DoubleDecoder)\n",
       "        1    0.000    0.000    0.001    0.001 pygram.py:4(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:4017(__str__)\n",
       "        2    0.000    0.000    0.003    0.001 pyparsing.py:4763(srange)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3027(_always_object)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_svd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:119(IDEA)\n",
       "        1    0.000    0.000    0.001    0.001 scrypt.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 data_parallel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:502(AvgPool2d)\n",
       "        2    0.000    0.000    0.000    0.000 linear.py:58(reset_parameters)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:15(Tensor)\n",
       "        3    0.000    0.000    0.000    0.000 serialization.py:173(_check_seekable)\n",
       "        3    0.000    0.000    0.192    0.064 serialization.py:448(legacy_load)\n",
       "        1    0.000    0.000    0.003    0.003 random.py:22(manual_seed)\n",
       "        1    0.000    0.000    0.001    0.001 loader.py:1(<module>)\n",
       "        1    0.000    0.000    0.028    0.028 type_check.py:3(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 util.py:136(register_after_fork)\n",
       "       49    0.000    0.000    0.000    0.000 reduction.py:43(register)\n",
       "        7    0.000    0.000    0.000    0.000 data.py:23(<listcomp>)\n",
       "       44    0.000    0.000    0.000    0.000 argparse.py:2087(_parse_optional)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:255(choice)\n",
       "        6    0.000    0.000    0.000    0.000 locale.py:379(normalize)\n",
       "       14    0.000    0.000    0.007    0.000 traitlets.py:576(__set__)\n",
       "        7    0.000    0.000    0.006    0.001 traitlets.py:805(compatible_observer)\n",
       "        7    0.000    0.000    0.000    0.000 traitlets.py:1237(observe)\n",
       "       18    0.000    0.000    0.000    0.000 os.py:746(decode)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scope.py:3(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 onnx_graph.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3841(__str__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:420(__setitem__)\n",
       "        1    0.000    0.000    0.027    0.027 specifiers.py:275(Specifier)\n",
       "       13    0.000    0.000    0.000    0.000 six.py:80(_import_module)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:514(Image)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:78(contains)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:23(<dictcomp>)\n",
       "        1    0.000    0.000    0.238    0.238 model_zoo.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:11(<module>)\n",
       "       27    0.000    0.000    0.000    0.000 auto.py:339(make_default_double_backwards_fn)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:40(_inplace_binary_method)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:151(AdamsBashforthMoulton)\n",
       "        7    0.000    0.000    0.000    0.000 traitlets.py:188(parse_notifier_name)\n",
       "       28    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
       "        6    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:966(_find_parent_path_names)\n",
       "       28    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
       "       35    0.000    0.000    0.000    0.000 {method '__getitem__' of 'dict' objects}\n",
       "        1    0.000    0.000    0.003    0.003 text_format.py:1006(Tokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 visdom_writer.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 pyparsing.py:3859(parseImpl)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1103(ParserElement)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:164(_SixMetaPathImporter)\n",
       "       12    0.000    0.000    0.000    0.000 dual.py:52(register_func)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:18(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 name.py:28(<genexpr>)\n",
       "        1    0.000    0.000    0.002    0.002 idna.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:253(DERSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:378(DeltaCRLIndicator)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1078(X509)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:9(Exponential)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:279(get_device_capability)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:484(cast)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:265(GaussianDiag)\n",
       "        1    0.000    0.000    0.001    0.001 adams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
       "        1    0.000    0.000    0.040    0.040 ultratb.py:1128(structured_traceback)\n",
       "        6    0.000    0.000    0.000    0.000 weakref.py:354(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:794(fsencode)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:1(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'FindEnumTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4214(copy)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:3032(__str__)\n",
       "        1    0.000    0.000    0.073    0.073 __init__.py:554(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 _main.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:112(tqdm)\n",
       "        2    0.000    0.000    0.000    0.000 backend.py:128(_get_osurandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:491(PrivateKeyInfo)\n",
       "        6    0.000    0.000    0.000    0.000 _elliptic_curve.py:97(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:154(cached_property)\n",
       "        1    0.000    0.000    0.000    0.000 filepost.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:3(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:20(warn_imbalance)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 twodim_base.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:1933(_get_exc_info)\n",
       "       14    0.000    0.000    0.000    0.000 traitlets.py:1673(validate)\n",
       "       14    0.000    0.000    0.000    0.000 traitlets.py:1694(_resolve_classes)\n",
       "       27    0.000    0.000    0.000    0.000 inspect.py:479(getmro)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'isoformat' of 'datetime.datetime' objects}\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1348(_handle_exitstatus)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:2(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
       "        1    0.000    0.000    0.000    0.000 fractions.py:60(Fraction)\n",
       "        1    0.000    0.000    0.000    0.000 workspace.py:494(_BlobDict)\n",
       "       11    0.000    0.000    0.000    0.000 attr_value_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 proto_graph.py:1(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 descriptor.py:635(__new__)\n",
       "       13    0.000    0.000    0.000    0.000 symbol_database.py:93(RegisterEnumDescriptor)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2431(parseImpl)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2751(charsAsStr)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:1(<module>)\n",
       "       36    0.000    0.000    0.000    0.000 backend.py:218(register_cipher_adapter)\n",
       "        1    0.000    0.000    0.007    0.007 ciphers.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:185(CertificateRevocationList)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:714(X509Extension)\n",
       "        1    0.000    0.000    0.000    0.000 escsm.py:28(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.239    0.239 alexnet.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:57(_load_cudart)\n",
       "        3    0.000    0.000    0.191    0.064 tarfile.py:1087(fromtarfile)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8061(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 mixins.py:20(_binary_method)\n",
       "        5    0.000    0.000    0.000    0.000 getlimits.py:507(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 numerictypes.py:181(english_capitalize)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:369(_set_up_aliases)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2592(geterr)\n",
       "        1    0.000    0.000    0.000    0.000 ImageOps.py:20(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 context.py:69(RLock)\n",
       "        7    0.000    0.000    0.000    0.000 path.py:86(compress_user)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:366(_create_)\n",
       "        1    0.000    0.000    0.000    0.000 ImageColor.py:20(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:40(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:115(copy)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4450(delimitedList)\n",
       "        3    0.000    0.000    0.001    0.000 pyparsing.py:1877(__mul__)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2045(suppress)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2464(Distribution)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_ldl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_qz.py:1(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2761(register_open)\n",
       "        1    0.000    0.000    0.015    0.015 lsun.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 hmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:26(_Certificate)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:148(activate_osrandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.X509_new}\n",
       "        1    0.000    0.000    0.014    0.014 __init__.py:19(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 utf8prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:104(_has_ipv6)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 gumbel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 beta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:1(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 init.py:403(_make_deprecate)\n",
       "        4    0.000    0.000    0.000    0.000 linear.py:69(extra_repr)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8066(getdoc)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'seed' of 'mtrand.RandomState' objects}\n",
       "        1    0.000    0.000    0.001    0.001 main.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 runner.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:583(sign)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 container.py:8(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 rk_common.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:1(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:864(__call__)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:223(_randbelow)\n",
       "        2    0.000    0.000    0.010    0.005 traceback.py:193(format_stack)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:767(_create_pseudo_member_)\n",
       "        1    0.000    0.000    0.000    0.000 sysconfig.py:612(get_platform)\n",
       "        2    0.000    0.000    0.000    0.000 spectral_norm.py:3(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'findall' of '_sre.SRE_Pattern' objects}\n",
       "       21    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._multiprocessing_init}\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:11(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 driver.py:117(load_grammar)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:1841(__radd__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2991(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 six.py:114(_resolve)\n",
       "        8    0.000    0.000    0.000    0.000 six.py:209(is_package)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:135(_declare_state)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2932(_apply_env_variables)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:21(FFI)\n",
       "        1    0.000    0.000    0.001    0.001 cookiejar.py:1224(CookieJar)\n",
       "        1    0.000    0.000    0.001    0.001 cmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:15(_ASN1Type)\n",
       "        1    0.000    0.000    0.000    0.000 parser.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:459(CudnnModule)\n",
       "        2    0.000    0.000    0.000    0.000 function.py:183(once_differentiable)\n",
       "        2    0.000    0.000    0.010    0.005 __init__.py:120(_lazy_call)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _six.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2775(__new__)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:2551(_arraymethod)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:493(StringConverter)\n",
       "        1    0.000    0.000    0.000    0.000 nanfunctions.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:156(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:1(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 data.py:13(uniq_stable)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1533(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:826(__new__)\n",
       "        7    0.000    0.000    0.000    0.000 traitlets.py:923(instance_init)\n",
       "       46    0.000    0.000    0.000    0.000 inspect.py:358(<lambda>)\n",
       "       21    0.000    0.000    0.000    0.000 traitlets.py:216(__call__)\n",
       "        6    0.000    0.000    0.000    0.000 tokenize.py:344(_get_normal_name)\n",
       "       25    0.000    0.000    0.000    0.000 enum.py:332(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:71(search_function)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._init_names}\n",
       "       20    0.000    0.000    0.000    0.000 tokenize.py:48(group)\n",
       "        1    0.000    0.000    0.000    0.000 visdom_writer.py:23(VisdomWriter)\n",
       "       13    0.000    0.000    0.000    0.000 summary_pb2.py:5(<lambda>)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'AddFileDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:3935(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4825(tokenMap)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:338(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:389(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:135(create_regularization_fns)\n",
       "        1    0.000    0.000    0.000    0.000 _sketches.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 _ccallback.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:259(Morsel)\n",
       "        7    0.000    0.000    0.000    0.000 ocsp.py:43(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:302(OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_init}\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 certificate_transparency.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1082(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:8(NegativeBinomial)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:10(Normal)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:7(Distribution)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:8(Binomial)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:118(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 rendezvous.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _reduction.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 module.py:23(Module)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:727(TarInfo)\n",
       "        4    0.000    0.000    0.000    0.000 serialization.py:111(default_restore_location)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:166(nts)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:238(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _numpy_fft.py:54(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:45(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:9(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 _version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:934(poly1d)\n",
       "        1    0.000    0.000    0.000    0.000 histograms.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 einsumfunc.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:598(serialize)\n",
       "        1    0.000    0.000    0.089    0.089 cnf.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:409(_real_close)\n",
       "        2    0.000    0.000    0.000    0.000 terminal.py:109(get_terminal_size)\n",
       "        1    0.000    0.000    0.015    0.015 ultratb.py:307(wrapped)\n",
       "        8    0.000    0.000    0.000    0.000 shutil.py:1106(_access_check)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:182(encode)\n",
       "        1    0.000    0.000    0.000    0.000 latin_1.py:41(getregentry)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_manualSeedAll}\n",
       "       28    0.000    0.000    0.000    0.000 TiffImagePlugin.py:368(_delegate)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:16(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 extension_loader.py:16(DlopenGuard)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:6(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:4(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 symbol_database.py:58(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:47(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:40(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 enum_type_wrapper.py:46(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:324(ParseResults)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:1608(parseString)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:3098(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:21(BaseSpecifier)\n",
       "       16    0.000    0.000    0.000    0.000 six.py:189(__get_module)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_lu.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_cholesky.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:294(socksocket)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:102(__init__)\n",
       "       35    0.000    0.000    0.000    0.000 backend.py:2100(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:81(SignatureAlgorithmOID)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:116(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:514(X509Name)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 escprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:22(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 lowrank_multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gradcheck.py:1(<module>)\n",
       "        3    0.000    0.000    0.192    0.064 tarfile.py:1613(taropen)\n",
       "        4    0.000    0.000    0.000    0.000 _utils_internal.py:16(get_file_path)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6266(__new__)\n",
       "        2    0.000    0.000    0.001    0.000 _distributor_init.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:35(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.002    0.002 defmatrix.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ufunclike.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 py3k.py:4(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 numerictypes.py:565(obj2sctype)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:1(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 __init__.py:1109(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 traceback.py:27(format_list)\n",
       "        1    0.000    0.000    0.000    0.000 getipython.py:17(get_ipython)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1401(_try_wait)\n",
       "       10    0.000    0.000    0.000    0.000 {method 'cast' of 'memoryview' objects}\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_TagInfo)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 extension_loader.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:3(<module>)\n",
       "        1    0.000    0.000    0.022    0.022 driver.py:12(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 descriptor_pool.py:56(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3829(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:317(__getitem__)\n",
       "       18    0.000    0.000    0.000    0.000 pyparsing.py:458(__bool__)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_Version)\n",
       "       16    0.000    0.000    0.000    0.000 six.py:75(_add_doc)\n",
       "        1    0.000    0.000    0.001    0.001 expat.py:1(<module>)\n",
       "        2    0.000    0.000    0.007    0.004 train_misc.py:70(count_parameters)\n",
       "        1    0.000    0.000    0.000    0.000 _expm_frechet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 flinalg.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:387(_CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:264(OCSPRequest)\n",
       "        5    0.000    0.000    0.000    0.000 SSL.py:701(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:183(EllipticCurveBackend)\n",
       "        1    0.000    0.000    0.001    0.001 exceptions.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:292(CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:115(inject_into_urllib3)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:383(PyOpenSSLContext)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:124(HTTPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 url.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:225(StmtBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 comm.py:1(<module>)\n",
       "        1    0.000    0.000    0.088    0.088 thnn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1385(TarFile)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:1145(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 util.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 session.py:102(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:62(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_RungeKuttaState)\n",
       "        1    0.000    0.000    0.002    0.002 ImageEnhance.py:21(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'bind' of '_socket.socket' objects}\n",
       "        7    0.000    0.000    0.000    0.000 ultratb.py:917(linereader)\n",
       "       10    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:193(total_ordering)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(normalize_encoding)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
       "       14    0.000    0.000    0.000    0.000 {method 'end' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:18(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 ImagePalette.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Int8Tensor)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:24(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:5(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:138(_newer)\n",
       "        2    0.000    0.000    0.001    0.000 driver.py:147(load_packaged_grammar)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 reflection.py:46(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:4292(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:668(<listcomp>)\n",
       "        4    0.000    0.000    0.001    0.000 pyparsing.py:3353(setResultsName)\n",
       "        1    0.000    0.000    0.009    0.009 version.py:191(Version)\n",
       "        1    0.000    0.000    0.073    0.073 __init__.py:567(_build_master)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1790(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 __init__.py:15(search_path)\n",
       "        1    0.000    0.000    0.000    0.000 _binary.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:103(EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:137(_validate_dependencies_met)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 charsetgroupprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(RequestHistory)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Url)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:8(TransformedDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lowrank_multivariate_normal.py:57(LowRankMultivariateNormal)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:17(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:18(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 vision.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:1(<module>)\n",
       "        1    0.000    0.000    0.023    0.023 module.py:723(load_state_dict)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:20(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defmatrix.py:70(matrix)\n",
       "       13    0.000    0.000    0.000    0.000 mixins.py:30(_reflected_binary_method)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:69(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 pytesttester.py:72(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 result.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jsonutil.py:177(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:169(utcnow)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:561(msg_header)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:87(date_default)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_ButcherTableau)\n",
       "        1    0.000    0.000    0.008    0.008 fakedata.py:1(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:2312(_check_value)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:506(translation)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1456(addHandler)\n",
       "        9    0.000    0.000    0.000    0.000 traceback.py:276(__iter__)\n",
       "       10    0.000    0.000    0.000    0.000 traceback.py:303(walk_tb)\n",
       "        4    0.000    0.000    0.000    0.000 re.py:204(split)\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:960(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'count' of 'bytes' objects}\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup}\n",
       "       16    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 JpegPresets.py:67(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 fractions.py:294(_operator_fallbacks)\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:17(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 decoder.py:190(_SimpleDecoder)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:110(_generate_pickle_name)\n",
       "        7    0.000    0.000    0.000    0.000 node_def_pb2.py:5(<lambda>)\n",
       "        9    0.000    0.000    0.000    0.000 step_stats_pb2.py:5(<lambda>)\n",
       "        6    0.000    0.000    0.000    0.000 layout_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:392(FieldDescriptor)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2376(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:2963(__str__)\n",
       "       10    0.000    0.000    0.000    0.000 six.py:181(_get_module)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:469(Module_six_moves_urllib)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1123(ResourceManager)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1603(ZipProvider)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:2237(_cygwin_patch)\n",
       "       10    0.000    0.000    0.000    0.000 event_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:385(get_build_platform)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ArgSpec)\n",
       "        5    0.000    0.000    0.000    0.000 Image.py:2776(register_mime)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:264(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:499(_SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:34(OCSPResponseStatus)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:76(Blowfish)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:126(_EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:109(_register_osrandom_engine)\n",
       "        2    0.000    0.000    0.031    0.016 binding.py:136(init_static_locks)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_OpenSSLErrorWithText)\n",
       "        3    0.000    0.000    0.000    0.000 extensions.py:915(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:949(KeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:275(X509Backend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:334(DHBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:142(AuthorityKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:581(ReasonFlags)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:10(_Reasons)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2665(_PassphraseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:217(PKey)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 universaldetector.py:51(UniversalDetector)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:10(Multinomial)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:18(add_docstr_all)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:49(check_compatibility)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:10(Geometric)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:7(Independent)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:58(MultivariateNormal)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 bernoulli.py:10(Bernoulli)\n",
       "        1    0.000    0.000    0.003    0.003 adam.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:451(__set__)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:239(manager_path)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:54(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 financial.py:12(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.geterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:7(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 session.py:132(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:95(copy)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interp.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:160(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:157(__next__)\n",
       "        7    0.000    0.000    0.000    0.000 debugger.py:53(make_arrow)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:96(seed)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:678(__delitem__)\n",
       "       12    0.000    0.000    0.000    0.000 {method 'groupdict' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.open}\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:110(GzipFile)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:375(EncodeVarint)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:32(Base)\n",
       "        1    0.000    0.000    0.000    0.000 x2num.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:102(DescriptorPool)\n",
       "       11    0.000    0.000    0.000    0.000 tensor_pb2.py:5(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 descriptor.py:729(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3962(Optional)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:2020(__invert__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3061(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 py31compat.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 specifiers.py:214(LegacySpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:4(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 six.py:159(_resolve)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:551(WorkingSet)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2310(EntryPoint)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_qr.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_polar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 linalg_version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:114(_make_name)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:25(MockRequest)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:586(Response)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:120(ExtendedKeyUsageOID)\n",
       "        3    0.000    0.000    0.000    0.000 binding.py:106(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3848(SequenceOf)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:180(RSASSAPSSParams)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:764(Void)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:388(extended_datetime)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:69(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:268(RSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2111(CRL)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:22(SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(Version)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:872(X509Req)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:28(Retry)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:9(Poisson)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:10(LogitRelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:11(StudentT)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 beta.py:10(Beta)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:8(Categorical)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 clip_grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:41(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 auto_double_backwards.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 random.py:77(manual_seed_all)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:323(_get_typecodes)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.seterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.arange}\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:74(_determine_error_states)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:450(decorating_function)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:1669(chararray)\n",
       "        3    0.000    0.000    0.000    0.000 result.py:12(failfast)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:24(TestResult)\n",
       "        1    0.000    0.000    0.000    0.000 _inspect.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:942(_register_types)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2891(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:121(new_id)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:214(GatedLinear)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:12(PhotoTour)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:142(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1042(format_exception)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:572(dgettext)\n",
       "        7    0.000    0.000    0.000    0.000 loader.py:252(__getitem__)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:921(uname)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:1014(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 traceback.py:59(extract_tb)\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:219(_deepcopy_tuple)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:331(__iter__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:672(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:806(fsdecode)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method sys.setdlopenflags}\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_cudnn_benchmark}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._tracer_warn_use_python}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:947(TiffImageFile)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:115(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:504(_StructPackEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 compatibility.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 grammar.py:77(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:37(<listcomp>)\n",
       "        1    0.000    0.000    0.033    0.033 __init__.py:85(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:93(StrictVersion)\n",
       "       14    0.000    0.000    0.000    0.000 visdom_writer.py:13(_check_connection)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:105(calc_output_size)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:187(Default)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'AddEnumDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       25    0.000    0.000    0.000    0.000 {method 'append' of 'DescriptorSequence' objects}\n",
       "        1    0.000    0.000    0.000    0.000 message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(manifest_mod)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4003(parseImpl)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1288(addParseAction)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1567(resetCache)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3015(parseImpl)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:248(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:78(_IndividualSpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:957(Environment)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1381(NullProvider)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:2205(file_ns_handler)\n",
       "        3    0.000    0.000    0.000    0.000 Image.py:2821(register_extensions)\n",
       "        4    0.000    0.000    0.000    0.000 _utils.py:8(<genexpr>)\n",
       "        1    0.000    0.000    0.004    0.004 api.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:95(SessionRedirectMixin)\n",
       "        1    0.000    0.000    0.028    0.028 _internal_utils.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_MemoryBIO)\n",
       "        4    0.000    0.000    0.000    0.000 ocsp.py:63(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:14(X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:325(_OCSPRequest)\n",
       "        7    0.000    0.000    0.000    0.000 decode_asn1.py:187(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 aead.py:5(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 SSL.py:646(_requires_decorator)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.OpenSSL_add_all_algorithms}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ASN1_STRING_set_default_mask_asc}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:172(Encoding)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3050(Sequence)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:50(_ForceNullParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:613(EncryptionAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(Concat)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:964(PublicKeyInfo)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:170(__mul__)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:96(RSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:131(DSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:300(AccessDescription)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:488(DistributionPoint)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:313(EllipticCurvePublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:375(_EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:70(HTTPConnection)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:7(OneHotCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:10(Weibull)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:9(Uniform)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ScriptMethodStub)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:38(_parse_env)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:17(Optimizer)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:44(__setstate__)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 parallel_apply.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 replicate.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:31(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:79(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:169(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:13(_BatchNorm)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:341(FormattedTimesMixin)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:7(Stream)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:7(cudaOutputMode)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:7(_StorageBase)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6256(MaskedConstant)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:1764(Laguerre)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:845(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:1606(Polynomial)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:2109(Chebyshev)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:1794(Legendre)\n",
       "        1    0.000    0.000    0.000    0.000 arraypad.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 arraysetops.py:27(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 ufunclike.py:14(_deprecate_out_named_y)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_LoggingWatcher)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:1506(set_string_function)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:96(_str_xmin)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:388(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 case.py:420(addTypeEqualityFunc)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:845(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:564(msg)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:99(CFunctionType)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:342(_FuncPtr)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:66(reset)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 odefunc.py:75(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:133(_get_kwargs)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1354(add_argument_group)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1484(_get_handler)\n",
       "        7    0.000    0.000    0.000    0.000 traitlets.py:2045(validate)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:1115(append)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1236(_fixupChildren)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:104(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:773(_get_devnull)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1154(_get_handles)\n",
       "       14    0.000    0.000    0.000    0.000 weakref.py:428(get)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:339(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:334(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:760(getenv)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.access}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.get_terminal_size}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:854(ImageFileDirectory_v1)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:1552(AppendingTiffWriter)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 GifImagePlugin.py:46(GifImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:33(olddict)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:593(_Parser)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:318(Leaf)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:27(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:171(RefactoringTool)\n",
       "        1    0.000    0.000    0.003    0.003 odenvp_conditional_tol.py:212(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 resource_handle_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:788(ListValue)\n",
       "        3    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:5(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 graph_pb2.py:5(<lambda>)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'ParseFromString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'FindOneofByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:35(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:4783(<genexpr>)\n",
       "        8    0.000    0.000    0.000    0.000 version.py:261(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1583(MemoizedZipManifests)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2876(DistInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3114(_initialize)\n",
       "        1    0.000    0.000    0.002    0.002 train_misc.py:15(set_cnf_options)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:56(S3RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 torchvis.py:19(TorchVis)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(VersionConflict)\n",
       "        1    0.000    0.000    0.000    0.000 _procrustes.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:148(ChaCha20)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:29(OCSPResponderEncoding)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:329(_RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:418(_RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:12(MACContext)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:185(DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_get_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:33(HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:22(_OpenSSLError)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:183(PublicFormat)\n",
       "        1    0.000    0.000    0.000    0.000 _types.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:168(Asn1Value)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1126(Extension)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:60(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:92(PrimePoint)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:336(BasicConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:150(DSAParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:227(DSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:48(EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:21(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:32(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:128(HebrewProber)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:247(WrappedSocket)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1573(X509Store)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:102(HTTPHeaderDict)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:95(HTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:736(HTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:9(Pareto)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:10(ExpRelaxedCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:74(_check_cryptography)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:8(Laplace)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:38(Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:11(Cauchy)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:13(Gamma)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:26(Transform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:164(_InverseTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:209(ComposeTransform)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:11(FisherSnedecor)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:5(ExponentialFamily)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:63(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:1279(_make_fail)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:113(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ASMoutput)\n",
       "        1    0.000    0.000    0.000    0.000 nccl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:658(LSTMCell)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:321(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 auto_symbolic.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nvtx.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:2363(_check)\n",
       "        2    0.000    0.000    0.000    0.000 serialization.py:46(register_package)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3080(view)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6348(__setattr__)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:1811(HermiteE)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:1814(Hermite)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:17(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.copyto}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:246(_ctypes)\n",
       "        4    0.000    0.000    0.000    0.000 mixins.py:55(_unary_method)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1923(suppress_warnings)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:532(max)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:455(iinfo)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:44(_Outcome)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2887(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2896(__exit__)\n",
       "        9    0.000    0.000    0.000    0.000 _globals.py:73(__repr__)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:63(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:260(send_multipart)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:425(LoadLibrary)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:11(CNF_augment)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:8(MultiscaleParallelCNF)\n",
       "        2    0.000    0.000    0.000    0.000 squeeze.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:6(AdaptiveStepsizeODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:36(FixedGridODESolver)\n",
       "        1    0.000    0.000    0.040    0.040 ultratb.py:1276(structured_traceback)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'copy' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1920(consume_positionals)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:960(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1280(setLevel)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'datetime.datetime' objects}\n",
       "       10    0.000    0.000    0.000    0.000 copy.py:111(_copy_immutable)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:758(__del__)\n",
       "        3    0.000    0.000    0.000    0.000 threading.py:74(RLock)\n",
       "        2    0.000    0.000    0.000    0.000 weakref.py:288(update)\n",
       "        4    0.000    0.000    0.000    0.000 genericpath.py:53(getmtime)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:252(__subclasshook__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:349(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.TextIOWrapper' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.uname}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:561(PyDecoder)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:49(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:77(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:22(RParen)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:208(Node)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:327(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 version.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:10(ODENVP)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:107(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:241(Duration)\n",
       "        2    0.000    0.000    0.000    0.000 types_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:44(Message)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4026(SkipTo)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4163(__lshift__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:315(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:506(haskeys)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:644(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1298(addCondition)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1972(__xor__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2765(Regex)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:39(NegativeInfinity)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:589(SpecifierSet)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1525(_register)\n",
       "        2    0.000    0.000    0.190    0.095 __init__.py:3109(_call_aside)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:127(Plist)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:312(_PlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:764(_BinaryPlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 thops.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:11(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:32(EventsWriter)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:26(LowLevelCallable)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:156(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2787(register_save)\n",
       "        2    0.000    0.000    0.000    0.000 Image.py:2798(register_save_all)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lock.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:102(PrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:300(_DataLoaderIter)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:46(SemLock)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_pandas.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:185(InceptionC)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:340(Session)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:84(HTTPAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:91(set_self_blocking)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:13(where)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:91(CAST5)\n",
       "        1    0.000    0.000    0.000    0.000 makefile.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:57(OCSPCertStatus)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:31(X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:26(AES)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:13(_HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:176(_RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 cmac.py:16(_CMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:18(DHPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:49(DHPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:118(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:142(DHPrivateKey)\n",
       "        5    0.000    0.000    0.000    0.000 backend.py:114(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:117(activate_builtin_random)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:96(Binding)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:40(NameAttribute)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:135(CertificatePoliciesOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:18(HashAlgorithm)\n",
       "        6    0.000    0.000    0.000    0.000 binding.py:54(_openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:279(IPAddress)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2198(OctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2737(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 _ordereddict.py:23(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:220(SignedDigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(Any)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:971(Choice)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:862(TLSFeature)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:904(TLSFeatureType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:918(InhibitAnyPolicy)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1044(NameConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:54(OtherPrimeInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:329(NamedCurve)\n",
       "        1    0.000    0.000    0.000    0.000 _errors.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:12(CipherBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:694(PolicyInformation)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:189(DSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:15(EllipticCurveOID)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:88(EllipticCurvePrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1696(X509StoreContext)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:13(LogEntryType)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:598(CertificateRevocationListBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:693(RevokedCertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 langhebrewmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:93(MultiDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 compat.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 utf8prober.py:35(UTF8Prober)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:18(is_local_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:18(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 url.py:14(Url)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:8(LogNormal)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:19(cuFFTPlanCache)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:32(_OpNamespace)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:8(LogisticNormal)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(PowerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:550(ignore_lib_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1262(_get_methods)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:154(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:6(Rprop)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:110(Unfold)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:35(DataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:19(DistributedDataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:29(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:10(Embedding)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:10(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 convert_parameters.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:96(ModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:202(ModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:415(ParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:9(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:81(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:608(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:621(Softshrink)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:658(MultiLabelMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:13(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:11(Linear)\n",
       "        4    0.000    0.000    0.000    0.000 profiler.py:337(attr_formatter)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:39(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 function.py:273(_iter_filter)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:331(NestedIOFunction)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:612(_FileInFile)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6449(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:866(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:20(Arrayterator)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:184(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 helper.py:245(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:138(_FileOpeners)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:270(NameValidator)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:34(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:52(_set_function_name)\n",
       "        3    0.000    0.000    0.000    0.000 index_tricks.py:241(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:66(TestLoader)\n",
       "        1    0.000    0.000    0.000    0.000 main.py:49(TestProgram)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:29(TextTestResult)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:62(MachArLike)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:156(ones)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:156(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:739(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:108(_current)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:127(hexdigest)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:70(set)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:110(Conv2d)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:62(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:32(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:43(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:29(Stat)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:24(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:341(StructOrUnion)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:48(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:55(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:46(__exit__)\n",
       "        1    0.000    0.000    0.015    0.015 ultratb.py:1090(get_records)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1115(get_chained_exception)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1726(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:611(gettext)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1148(_sys_version)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:800(createLock)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:760(_missing_)\n",
       "        4    0.000    0.000    0.000    0.000 sre_parse.py:161(__delitem__)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:196(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:93(__new__)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.charmap_build}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isalnum' of 'str' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:620(_register_loader)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:629(_register_writer)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:97(ChunkStream)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:286(PngStream)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:56(BmpImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:74(ImageFile)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:134(_SignedVarintDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:418(TagBytes)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:542(_FloatingPointEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:37(oldstr)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:100(TextWriter)\n",
       "        1    0.000    0.000    0.000    0.000 literals.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:82(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:10(ParserGenerator)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:252(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 versions_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:31(Version)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:267(LooseVersion)\n",
       "        3    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:191(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 message_factory.py:50(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:541(_FieldMaskTree)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:230(RepeatedScalarFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:343(RepeatedCompositeFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:185(BaseContainer)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:222(Descriptor)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:434(ScalarMap)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:524(MessageMap)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3523(MatchFirst)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3914(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2439(Keyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2527(CaselessKeyword)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3064(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3368(And)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:407(AppDirs)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:72(LegacyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:7(Infinity)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:28(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:103(MovedModule)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:124(_LazyModule)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:173(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:523(IResourceProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1484(EggProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2973(Requirement)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:10(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 crc32c.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:40(SummaryToEventTransformer)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:144(FileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 embedding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:79(EventFileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:175(get_supported_platform)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:288(ContextualVersionConflict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:301(DistributionNotFound)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:342(register_loader_type)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:12(qualify)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:97(BasePrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:155(_Transition)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:126(BatchSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:46(ConcatDataset)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:371(Barrier)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:16(ResNeXtBottleneckC)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:93(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:485(BaseCookie)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:13(CaseInsensitiveDict)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:272(PreparedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:760(ZipExtFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:989(_ZipWriteFile)\n",
       "        1    0.000    0.000    0.002    0.002 certs.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1961(MozillaCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:106(ARC4)\n",
       "        1    0.000    0.000    0.000    0.000 scrypt.py:23(Scrypt)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:740(_Tellable)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:42(Camellia)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:57(TripleDES)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:108(_DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:197(_DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:52(Prehashed)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:228(_EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:15(_HMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:96(Cipher)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:14(Mode)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:100(XTS)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:197(GCM)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:106(_DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:80(DHParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:170(DHPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 ciphers.py:13(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:297(_VerifyHelper)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:46(CRLEntryExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:130(AuthorityInformationAccessOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:146(BLAKE2b)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:178(PrivateFormat)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:50(RFC822Name)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:115(DNSName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:160(UniformResourceIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:253(RegisteredID)\n",
       "        1    0.000    0.000    0.000    0.000 intranges.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2501(ParsableOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2706(Null)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2964(Enumerated)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:272(SignedDigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:475(RSAESOAEPParams)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:561(EncryptionAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1210(SubjectAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1373(PrecertificateSignedCertificateTimestamps)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1421(OCSPNonce)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:74(RSAPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:264(CharacteristicTwo)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:202(extended_date)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:114(CRLNumber)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:447(FreshestCRL)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:594(PolicyConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:744(UserNotice)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:781(NoticeReference)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:384(EllipticCurvePrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:10(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:338(RSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1941(Revoked)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2387(PKCS12)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2568(NetscapeSPKI)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:18(Version)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:46(register_decorator)\n",
       "        2    0.000    0.000    0.000    0.000 utils.py:123(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:122(_ModuleWithDeprecations)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(AsymmetricSignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:65(DSAPrivateKeyWithSerialization)\n",
       "        4    0.000    0.000    0.000    0.000 pyopenssl.py:102(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1550(X509StoreFlags)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:36(EUCJPProber)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:34(EUCKRProber)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:33(SingleByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 langcyrillicmodel.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:34(MultiByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:113(EUCTWDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:35(CharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 escprober.py:35(EscCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:96(Latin1Prober)\n",
       "        1    0.000    0.000    0.000    0.000 sjisprober.py:36(SJISProber)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 alexnet.py:13(AlexNet)\n",
       "        1    0.000    0.000    0.000    0.000 gumbel.py:13(Gumbel)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:11(HalfCauchy)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:11(HalfNormal)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:24(_Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:6(Chi2)\n",
       "        2    0.000    0.000    0.000    0.000 constraint_registry.py:83(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:211(_Interval)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:39(SharedCache)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:784(OrderedDictWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:27(DistributedDataParallel)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:111(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:161(MultiStepLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:254(ReduceLROnPlateau)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:4(is_available)\n",
       "        3    0.000    0.000    0.000    0.000 rendezvous.py:13(register_rendezvous_handler)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:10(_ConstantPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:21(RNNBase)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:9(Upsample)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:7(PairwiseDistance)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:723(LPPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:6(_InstanceNorm)\n",
       "        2    0.000    0.000    0.000    0.000 dropout.py:17(extra_repr)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:10(Threshold)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:335(CELU)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:27(L1Loss)\n",
       "        4    0.000    0.000    0.000    0.000 utils.py:5(_ntuple)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(FilterDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:75(Bilinear)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:129(profile)\n",
       "        1    0.000    0.000    0.007    0.007 module.py:246(cuda)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(Function)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:131(Event)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:86(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:237(device_of)\n",
       "        4    0.000    0.000    0.000    0.000 serialization.py:62(_cpu_deserialize)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:312(_LowLevelFile)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1489(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:3350(dtype)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6060(mvoid)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6440(_extrema_operation)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:28(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'tobytes' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:216(_getintp_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:231(AxisConcatenator)\n",
       "       10    0.000    0.000    0.000    0.000 case.py:1316(_deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:76(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:17(MachAr)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:88(_str_eps)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:759(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:83(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:206(utcoffset)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:250(_isdst)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:236(msg_header)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:242(extract_header)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:509(msg_id)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:34(_ensure_tzinfo)\n",
       "        4    0.000    0.000    0.000    0.000 hmac.py:90(update)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(MovingBatchNormNd)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:6(BruteForceLayer)\n",
       "        3    0.000    0.000    0.000    0.000 _testutils.py:26(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:114(_compare)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:5(RegularizedODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:94(ODEnet)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:82(CocoDetection)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:16(CIFAR10)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:12(STL10)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:10(SVHN)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:44(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:436(find_recursion)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1114(get_parts_of_chained_exception)\n",
       "       19    0.000    0.000    0.000    0.000 ultratb.py:1466(nullrepr)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1733(parse_args)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:87(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1011(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:1056(_open)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method binascii.b2a_hex}\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:220(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:12(pickle)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:537(_generate_next_value_)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:868(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 _collections_abc.py:271(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rfind' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'title' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:630(decorator)\n",
       "        1    0.000    0.000    0.000    0.000 JpegImagePlugin.py:300(JpegImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:137(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:540(PngImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImagePalette.py:23(ImagePalette)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:69(_PaddedFile)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:377(_GzipReader)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:98(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:288(_FloatDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:822(_FieldSkipper)\n",
       "        3    0.000    0.000    0.000    0.000 encoder.py:184(_FixedSizer)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:429(_SimpleEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:1022(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:17(BMNode)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:26(BottomMatcher)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:16(MinNode)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:19(LParen)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:415(BasePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:606(WildcardPattern)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(RTs)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:241(Py2Fixer)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:692(MultiprocessRefactoringTool)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:23(Grammar)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:49(any)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:96(_calc_n_scale)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:68(Any)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:98(Timestamp)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:398(FieldMask)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:735(Struct)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:803(MethodDescriptor)\n",
       "        2    0.000    0.000    0.000    0.000 api_implementation.py:136(Type)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:607(EnumDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:748(ServiceDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:94(DescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:165(_NestedDescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:41(EnumTypeWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3715(ParseElementEnhance)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4141(Forward)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4296(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4335(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:4383(postParse)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:4904(makeHTMLTags)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:75(Requirement)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:205(ParseBaseException)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:460(__iter__)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3066(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3151(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3184(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3195(StringEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3256(ParseExpression)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:20(with_metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:86(_LazyDescr)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:139(MovedAttribute)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:320(Module_six_moves_urllib_parse)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:380(Module_six_moves_urllib_request)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:430(Module_six_moves_urllib_response)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:905(subscribe)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1506(DefaultProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1536(EmptyProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1556(ZipManifests)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1778(FileMetadata)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1860(register_finder)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1907(find_nothing)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1989(NoDists)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:2076(register_namespace_handler)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:79(_InternalDict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:454(_PlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:595(_BinaryPlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:4(VendorImporter)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:126(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:156(_EventLoggerThread)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:500(IMetadataProvider)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:25(BaseTypeByIdentity)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:88(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:14(LSUNClass)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:59(LSUN)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:7(DistributedSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:720(DataLoader)\n",
       "        1    0.000    0.000    0.000    0.000 _utils.py:123(Comparable)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:210(Condition)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:332(Event)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:96(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:24(VGG)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:17(Fire)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:130(InceptionA)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:162(InceptionB)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:292(InceptionAux)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:317(BasicConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:127(_DenseLayer)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:141(SOCKSProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:267(_BaseSocket)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:86(TqdmDefaultWriteLock)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:87(LookupDict)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:60(RequestEncodingMixin)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:13(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:108(HTTPDigestAuth)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1819(PyZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:732(Cookie)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:830(CookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1755(FileCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:133(SEED)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(KeyDerivationFunction)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:318(ZipInfo)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:595(LZMACompressor)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:175(OCSPResponseBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:17(AsymmetricPadding)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:84(_DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:92(_ECDSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:108(_ECDSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:20(CipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:76(AEADDecryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:86(AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:164(_AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:228(_AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:30(ModeWithInitializationVector)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:85(CBC)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:131(OFB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:146(CFB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:161(CFB8)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:176(CTR)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:36(_DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:217(_DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_by_id}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_set_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 name.py:102(RelativeDistinguishedName)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:142(Name)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:42(OCSPExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:60(Hash)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:167(BLAKE2s)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:57(make_assert)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'new_allocator' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:189(ParameterFormat)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:41(GeneralName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:227(DirectoryName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:317(OtherName)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1776(Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1910(BitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2286(IntegerBitString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:64(register)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:372(Pbkdf2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:510(DSASignature)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1695(AbstractString)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1165(GeneralNames)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1245(IssuerAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1280(CertificateIssuer)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1315(CRLReason)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1343(InvalidityDate)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1449(UnrecognizedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:86(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:136(_ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:252(Pentanomial)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:284(FieldID)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:301(Curve)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:454(PrivateKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:54(PrimeCurve)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:146(Codec)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:63(ExtensionType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:232(SubjectKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:655(CertificatePolicies)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:80(DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:24(EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:39(EllipticCurveSignatureAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:288(ECDSA)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2336(PKCS7)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:369(RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:390(CertificateSigningRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:431(CertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:14(DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langturkishmodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:204(_X509NameInvalidator)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:33(GB2312Prober)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:34(CP949Prober)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:34(Big5Prober)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:33(EUCTWProber)\n",
       "        1    0.000    0.000    0.000    0.000 langgreekmodel.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langthaimodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langbulgarianmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:40(CharDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312freq.py:42(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:116(JapaneseContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:183(SJISContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:50(RequestField)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:122(PoolManager)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:362(ProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 charsetgroupprober.py:32(CharSetGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:17(LanguageFilter)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:33(CodingStateMachine)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:8(is_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:29(is_prod_appengine_mvms)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:28(RecentlyUsedContainer)\n",
       "        1    0.000    0.000    0.000    0.000 request.py:10(RequestMethods)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:55(ConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:117(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:92(RelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:87(RelaxedOneHotCategorical)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:6(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:217(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:290(ExpTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:379(AffineTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:514(LowerCholeskyTransform)\n",
       "        2    0.000    0.000    0.000    0.000 constraints.py:143(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:42(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:61(_ResourceSharer)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:8(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:549(TracerWarning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:960(ScriptModule)\n",
       "        2    0.000    0.000    0.000    0.000 annotations.py:15(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:10(DistributedDataParallelCPU)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:119(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:5(Adagrad)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:6(SparseAdam)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:5(SGD)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:5(RMSprop)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:6(LBFGS)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:10(_LRScheduler)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:6(Fold)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:35(ReduceAddCoalesced)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:61(Dropout2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:166(_ReflectionPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:8(WeightNorm)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:9(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:6(PixelShuffle)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:143(UpsamplingNearest2d)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:22(Sequential)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:318(ParameterList)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:9(_MaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:151(MaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:568(AvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:647(FractionalMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:936(_AdaptiveAvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:1005(AdaptiveAvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:134(InstanceNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:210(InstanceNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:11(LocalResponseNorm)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:75(LayerNorm)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:165(GroupNorm)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:617(ConvTranspose2d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:760(ConvTranspose3d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:89(RReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:146(Hardtanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:269(Tanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:295(ELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:380(SELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:425(GLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:459(Hardshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:501(LeakyReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:576(Softplus)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:663(PReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:728(Softsign)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:897(LogSoftmax)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:223(PoissonNLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:289(KLDivLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:507(BCEWithLogitsLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:713(SmoothL1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:773(SoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1001(MarginRankingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1049(MultiMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1112(TripletMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1188(CTCLoss)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:460(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:464(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:6(VFModule)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:5(Parameter)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:24(EventList)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:377(FunctionEvent)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:108(Function)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:23(THNNBackendBase)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:10(_ContextMethodMixin)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:73(_check_driver)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:211(device)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:336(_Stream)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1443(MAxisConcatenator)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:59(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2596(MaskedIterator)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:3366(shape)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:86(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:177(_ndptr)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:805(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:882(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1315(_replace_dtype_fields)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:1362(getmask)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2378(_MaskedPrintOption)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:18(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:224(_FFTCache)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:51(BagObj)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:115(NpzFile)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:265(DataSource)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:621(Repository)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:170(LineSplitter)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_string_function}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:204(dummy_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1858(clear_and_catch_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:997(SafeEval)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:115(NoseTester)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:446(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1338(FunctionTestCase)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:16(BaseTestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:92(TestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:270(_ErrorHolder)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:23(_FailedTest)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:13(_WritelnDecorator)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:120(TextTestRunner)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:810(FloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1234(TimedeltaFormat)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:85(format_parser)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:217(record)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:304(recarray)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:20(memmap)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:92(_str_epsneg)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:305(finfo)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:184(_AssertRaisesContext)\n",
       "        5    0.000    0.000    0.000    0.000 _inspect.py:145(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2902(_setdef)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:55(_NoValueType)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:9(PackageLoader)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:7(CouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:7(PlanarFlow)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:6(FeedforwardGateI)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:4(SequentialFlow_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:115(ParallelSumModules)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:9(_ActNorm)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:194(InvertibleConv1x1)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:17(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:61(VariableCoefficientAdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:7(OdeintAdjointMethod)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:176(AutoencoderDiffEqNet)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:7(DiffEqWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:29(ReshapeDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:13(HyperLinear)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:6(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:9(Omniglot)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:8(ZeroMeanTransform)\n",
       "        1    0.000    0.000    0.000    0.000 cnf.py:11(CNF)\n",
       "        1    0.000    0.000    0.000    0.000 tsit5.py:66(Tsit5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 dopri5.py:58(Dopri5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:5(Euler)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:221(Pad)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:360(RandomCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:481(RandomResizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:567(FiveCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:695(ColorJitter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:306(Color3DLUT)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:17(SEMEION)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:278(ConstPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:297(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:47(DatasetFolder)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:150(ImageFolder)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:174(CIFAR100)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:12(MNIST)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:179(EMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 fakedata.py:6(FakeData)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:39(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:413(close)\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:1138(_get_call_pdb)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1725(_get_positional_actions)\n",
       "        1    0.000    0.000    0.000    0.000 configurable.py:381(instance)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:136(_get_args)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1255(python_implementation)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:188(iteritems)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:829(__prepare__)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:824(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:819(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:19(encode)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1982(createLock)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method utcnow}\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:287(seek)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:203(_cleanup)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:22(constructor)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:98(checkgroup)\n",
       "        4    0.000    0.000    0.000    0.000 _collections_abc.py:367(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 _collections_abc.py:406(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rstrip' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method sys.getdlopenflags}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rjust' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method '__prepare__' of 'type' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getCompiledVersion}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._jit_init}\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:23(TagInfo)\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:48(PpmImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:678(_idat)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:188(iTXt)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:209(PngInfo)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:249(DibImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:62(GradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:103(GimpGradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:22(PaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:24(GimpPaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:294(StubImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:324(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:549(PyCodecState)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:92(TypeChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:125(IntValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:146(EnumValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:166(UnicodeValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:194(Int32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:202(Uint32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:208(Int64ValueChecker)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:107(_VarintDecoder)\n",
       "        3    0.000    0.000    0.000    0.000 decoder.py:249(_ModifiedDecoder)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:126(_SimpleSizer)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:372(_VarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:387(_SignedVarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:80(PackTag)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:24(BaseBaseString)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:33(basestring)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:28(BaseOldDict)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:14(BaseOldStr)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:272(DebugMode)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:73(Error)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:253(_Printer)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:38(PatternCompiler)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:337(NFAState)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:347(DFAState)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:50(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:501(LeafPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:545(NodePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:794(NegatedPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pygram.py:20(Symbols)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:477(suspend_hooks)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:16(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:43(_EveryNode)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:167(FixerError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:688(MultiprocessingUnsupported)\n",
       "        1    0.000    0.000    0.000    0.000 driver.py:30(Driver)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:164(TokenError)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:197(Untokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:7(PgenGrammar)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:180(StackedCNFLayers)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:19(Node_base)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:38(Node_py)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:63(Node_py_IO)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:72(Node_py_OP)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:79(Graph_py)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:50(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 symbol_database.py:65(SymbolDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:38(Error)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:46(DescriptorDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:47(MessageFactory)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:60(Error)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:64(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:843(FileDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:672(EnumValueDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:712(OneofDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:55(TypeTransformationError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:64(DescriptorMetaclass)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:76(_Lock)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:39(Error)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:42(GeneratedProtocolMessageType)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:272(Marker)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:31(UndefinedComparison)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:44(Node)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:59(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:71(Op)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3591(Each)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3818(NotAny)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3888(OneOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3923(ZeroOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3954(_NullToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4222(_ForwardNoRecurse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4226(TokenConverter)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4234(Combine)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4278(Group)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4299(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4364(Suppress)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:183(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:195(_Constants)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:261(ParseException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:282(ParseFatalException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:287(ParseSyntaxException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:306(RecursiveGrammarException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:314(_ParseResultsWithOffset)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1478(_FifoCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2383(NoMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2398(Literal)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2545(CloseMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2606(Word)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2838(QuotedString)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2975(CharsNotIn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3046(White)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3097(_PositionToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3104(GoToColumn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3130(LineStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3160(LineEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3199(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3213(WordStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3233(WordEnd)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:3461(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3444(Or)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:36(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:42(_BaseVersion)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:27(metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:229(_MovedItems)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:360(Module_six_moves_urllib_error)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:451(Module_six_moves_urllib_robotparser)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:937(_ReqExtras)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1107(ExtractionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1127(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1549(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1817(PathMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1842(EggMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2857(EggInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2946(RequirementParseError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3165(PkgResourcesDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:109(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:204(Data)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:416(_DumbXMLWriter)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:587(InvalidFileException)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:64(install)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:29(register_writer_factory)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:89(S3RecordWriterFactory)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:104(RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(PEP440Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:249(ResolutionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:328(UnknownExtra)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1044(LstsqLapackError)\n",
       "        4    0.000    0.000    0.000    0.000 six.py:67(_add_doc)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:9(CData)\n",
       "        1    0.000    0.000    0.000    0.000 misc.py:11(LinAlgWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:138(DeprecatedImport)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2282(ImagePointHandler)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:25(deferred_error)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:20(ModeDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(FFIError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:5(CDefError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:20(VerificationMissing)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:72(BaseType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:85(VoidType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:178(UnknownIntegerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:192(UnknownFloatType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:204(BaseFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:224(RawFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:147(_DenseBlock)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:165(DenseNet)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:5(Sampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:23(SequentialSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:40(RandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:79(SubsetRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:96(WeightedRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:8(Dataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:26(TensorDataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:90(Subset)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:39(ExceptionWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:86(ManagerWatchdog)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:40(DecompressionBombWarning)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:44(DecompressionBombError)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:48(_imaging_not_installed)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:479(_E)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:8(TqdmSynchronisationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:14(TMonitor)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:123(Semaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:142(BoundedSemaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:159(Lock)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:186(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:26(tqdm_gui)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:25(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:57(Bottleneck)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:58(ResNeXt)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:40(SqueezeNet)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:33(Inception3)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:224(InceptionD)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:250(InceptionE)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:55(BaseAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:59(SOCKSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:133(SOCKSHTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:110(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:127(ProxyConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:135(SOCKS5Error)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:143(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:36(TqdmTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:40(TqdmKeyError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:44(TqdmWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:95(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:625(SimpleCookie)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:97(MockResponse)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:165(CookieConflictError)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:174(RequestHooksMixin)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:198(Request)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:79(HTTPBasicAuth)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:100(HTTPProxyAuth)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1841(LWPCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:150(CookieError)\n",
       "        1    0.000    0.000    0.000    0.000 __version__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:43(BadZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:47(LargeZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:534(_ZipDecrypter)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:618(LZMADecompressor)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:714(_SharedFile)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:76(OCSPRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:113(_SingleResponse)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:272(_RSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:299(_RSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(PKCS1v15)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:31(PSS)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:49(OAEP)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:62(MGF1)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:13(_X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:32(_X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:47(_DSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:68(_DSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:35(BlockCipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:67(AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:141(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:39(ModeWithTweak)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:48(ModeWithNonce)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:57(ModeWithAuthenticationTag)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:124(ECB)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:23(_Integers)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:186(_X509ExtensionParser)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2099(GetCipherByName)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:118(_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:239(Error)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:249(WantReadError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:257(WantX509LookupError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:261(ZeroReturnError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:269(_CallbackExceptionHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:377(_NpnSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:426(_ALPNSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:549(_OCSPClientCallbackHelper)\n",
       "        3    0.000    0.000    0.000    0.000 SSL.py:636(_make_requires)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_finish}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_free}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ERR_clear_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.RAND_cleanup}\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:154(_verify_openssl_version)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:46(cryptography_has_ssl3_method)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:151(cryptography_has_locking_callbacks)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:104(SHA1)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:118(SHA256)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:139(MD5)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:62(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'gc' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:198(BestAvailableEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:207(NoEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:35(UnsupportedGeneralNameType)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:16(IDNAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:21(IDNABidiError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:26(InvalidCodepoint)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1829(Integer)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2370(OctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2448(IntegerOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2948(InstanceOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3032(UTF8String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4298(Set)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4484(SetOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4517(EmbeddedPdv)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4543(TeletexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4569(AbstractTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4615(UTCTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4671(GeneralizedTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4754(VisibleString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4763(GeneralString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4773(UniversalString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4792(BMPString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:14(TeletexCodec)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:23(TeletexIncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:43(AlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:107(HmacAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:120(HmacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:127(DigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:141(DigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:149(DigestInfo)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:156(MaskGenAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:162(MaskGenAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:174(TrailerField)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:365(Pbkdf2Salt)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:381(KdfAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:387(KdfAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:398(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:411(KeyExchangeAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:417(KeyExchangeAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:435(Rc5ParamVersion)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:441(Rc5Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:450(Pbes1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:457(PSourceAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:463(PSourceAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1091(Pbmac1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1098(Pkcs5MacId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1104(Pkcs5MacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1119(AnyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1129(AnyAlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:622(ValueMap)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:649(Castable)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:693(Constructable)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1572(Primitive)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:817(ExtendedKeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:857(PrecertPoison)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:105(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:116(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:206(ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:216(SpecifiedECDomainVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:313(SpecifiedECDomain)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:384(ECDomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:396(ECPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:407(ECPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:435(Attribute)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:473(PrivateKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:910(DomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:924(PublicKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:944(PublicKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:218(IncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:253(IncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:292(StreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:33(HashBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:48(HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:64(CMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:79(PBKDF2HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:231(PEMSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:389(ScryptBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:72(Extensions)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:406(CRLDistributionPoints)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:145(SECT571R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:151(SECT409R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:157(SECT283R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:169(SECT163R2)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:175(SECT571K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:187(SECT283K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:193(SECT233K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:199(SECT163K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:223(SECP256K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:229(SECP224R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:235(SECP192R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:247(BrainpoolP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:420(ECDH)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:54(RSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:24(UnsupportedAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:30(AlreadyFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:34(AlreadyUpdated)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(InternalError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:56(InvalidKey)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:73(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(register_interface_if)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(AsymmetricVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:23(DSAParametersWithNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:12(RequestException)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:28(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:32(ConnectionError)\n",
       "        2    0.000    0.000    0.000    0.000 exceptions.py:40(SSLError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:60(ReadTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:68(TooManyRedirects)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:96(ContentDecodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:104(RetryError)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:54(UnsupportedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:76(Error)\n",
       "        2    0.000    0.000    0.000    0.000 crypto.py:205(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1682(X509StoreContextError)\n",
       "        1    0.000    0.000    0.000    0.000 sbcsgroupprober.py:43(SBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 euctwfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:132(EUCKRDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:151(GB2312DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:170(Big5DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:192(SJISDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:217(EUCJPDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 euckrfreq.py:41(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 big5freq.py:43(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jisfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:22(DeflateDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:55(GzipDecoderState)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:62(GzipDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:10(LifoQueue)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:8(InputState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:32(ProbingState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:41(MachineState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:50(SequenceLikelihood)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:65(CharacterCategory)\n",
       "        1    0.000    0.000    0.000    0.000 mbcsgroupprober.py:41(MBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:65(DummyConnection)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:223(HTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:263(VerifiedHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:13(NoWayToWaitForSocketError)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:14(is_appengine_sandbox)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:23(is_prod_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:13(HTTPWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:18(PoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:45(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:55(ProtocolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:66(MaxRetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:99(TimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:125(EmptyPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:130(ClosedPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:140(LocationParseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:181(SNIMissingWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:186(DependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:207(IncompleteRead)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:228(ProxySchemeUnknown)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:237(HeaderParsingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:244(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:5(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:28(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(CUDAModule)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:68(_Ops)\n",
       "        1    0.000    0.000    0.000    0.000 kl.py:77(_Match)\n",
       "        1    0.000    0.000    0.000    0.000 constraint_registry.py:79(ConstraintRegistry)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:77(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:340(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:362(AbsTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:446(SoftmaxTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:472(StickBreakingTransform)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:49(Constraint)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:67(_Dependent)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:106(_IntegerInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:123(_IntegerLessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:167(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:183(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:179(_GreaterThanEq)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:195(_LessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:215(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:228(_HalfOpenInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:245(_Simplex)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:105(lazy_property)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:20(StorageWeakRef)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:45(DupFd)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:40(SpawnContext)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:7(Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:13(ExportTypes)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:234(LegacyTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:408(TracingCheckError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:649(CompilationUnit)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:817(OrderedModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:847(OrderedParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:868(OrderedBufferDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:926(ScriptMeta)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1164(WeakScriptModuleProxy)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1292(TracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1354(_ConstModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1384(_ConstSequential)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1450(_register_builtin)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1465(_disable_tracing)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:90(FrontendError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:102(NotSupportedError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:106(UnsupportedNodeError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:152(SourceContext)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:158(Builder)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:14(Module)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:142(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:149(group)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:153(_DistributedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:6(Adadelta)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:9(_RequiredParameter)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:58(__setstate__)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:112(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:150(update_group)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:6(Adam)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:5(Adamax)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:6(ASGD)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:56(LambdaLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:126(StepLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:198(ExponentialLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:217(CosineAnnealingLR)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:15(AdaptiveLogSoftmaxWithLoss)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:9(Broadcast)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:50(Gather)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:78(Scatter)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:71(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:93(group)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:97(GroupMember)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:22(Dropout)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:105(Dropout3d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:149(AlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(ConstantPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:75(ConstantPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:130(ConstantPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:220(ReflectionPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:321(ReplicationPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:232(RNN)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:333(LSTM)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:441(GRU)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:537(RNNCellBase)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:585(RNNCell)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:736(GRUCell)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:147(SpectralNormLoadStateDictPreHook)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:177(SpectralNormStateDictHook)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:188(UpsamplingBilinear2d)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:11(Container)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:29(MaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:222(_MaxUnpoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:231(MaxUnpool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:297(MaxUnpool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:371(MaxUnpool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:434(_AvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:444(AvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:707(_LPPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:766(LPPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:822(_AdaptiveMaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:863(AdaptiveMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:899(AdaptiveMaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:948(AdaptiveAvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:172(BatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:58(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:6(_DropoutNd)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:12(_ConvNd)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:69(Conv1d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:190(Conv2d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:323(Conv3d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:451(_ConvTransposeMixin)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:509(ConvTranspose1d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:59(ReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:210(ReLU6)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:242(Sigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:754(Tanhshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:818(Softmax)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:868(Softmax2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:12(_Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:96(NLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:213(NLLLoss2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:370(MSELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:438(BCELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:598(HingeEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:815(CrossEntropyLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:907(MultiLabelSoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:954(CosineEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:196(BroadcastingListCls)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:160(flags_frozen)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:187(CuDNNHandle)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:197(CuDNNError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:204(TensorDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:226(TensorDescriptorArray)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:277(DropoutDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:321(RNNDescriptor)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:444(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:443(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:12(range)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:225(emit_nvtx)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:360(Interval)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:407(FunctionEventAvg)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:431(StringTable)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:7(Type)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:25(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:5(no_grad)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:47(enable_grad)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:91(set_grad_enabled)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:4(detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:75(set_detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:61(_HookMixin)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:72(BackwardCFunction)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:79(FunctionMeta)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:242(InplaceFunction)\n",
       "        1    0.000    0.000    0.000    0.000 thnn.py:4(THNNFunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:4(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(FunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:6(Backends)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:18(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(THNNCudaBackendStateMixin)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(Argument)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:5(VariableMeta)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:130(DeferredCudaCallError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:195(cudaStatus)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:499(_CudaBase)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:514(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:522(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:538(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:8(__PrinterOptions)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:68(_Formatter)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:7(RemovableHandle)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:278(ExtractError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:281(ReadError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:284(CompressionError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:290(HeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:302(InvalidHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:582(_StreamProxy)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:716(ExFileObject)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1473(mr_class)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:194(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:202(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:214(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:222(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:28(prepare_multiprocessing_environment)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:32(SourceChangeWarning)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:6260(__has_singleton)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6284(__array_finalize__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6557(_frommethod)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:8048(_convert2ma)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:218(_fromnxfunction)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:291(_fromnxfunction_seq)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:304(_fromnxfunction_args)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:329(_fromnxfunction_allargs)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:166(MAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:206(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:208(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:796(_DomainCheckInterval)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:829(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(_DomainTan)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:839(_DomainSafeDivide)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:876(_DomainGreaterEqual)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:902(_MaskedUnaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:976(_MaskedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1124(_DomainedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(_replace_dtype_fields_recursive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1329(make_mask_descr)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2384(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:58(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:62(PolyError)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:66(PolyDomainError)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:79(PolyBase)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:14(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:13(RTLD_for_MKL)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:464(ConverterError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:480(ConversionWarning)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_typeDict}\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:44(LinAlgError)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:15(DummyArray)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1816(IgnoreException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:57(_Deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:47(PytestTester)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:98(nd_grid)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:351(RClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:476(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:481(ndenumerate)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:531(ndindex)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:653(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:609(IndexExpression)\n",
       "        1    0.000    0.000    0.000    0.000 function_base.py:1760(vectorize)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1396(_SubTest)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:317(_DebugResult)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:9(_InterruptHandler)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:440(_recursive_guard)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:953(FloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:960(LongFloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1109(IntegerFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1122(BoolFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1132(ComplexFloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1176(_TimelikeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1202(DatetimeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1239(SubArrayFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1249(StructuredVoidFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1286(StructureFormat)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:104(_str_resolution)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:25(SkipTest)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:38(_UnexpectedSuccess)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:128(_BaseTestCaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:137(_AssertRaisesBaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:221(_AssertWarnsContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:278(_CapturingHandler)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:297(_AssertLogsContext)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:683(TooHardError)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:686(AxisError)\n",
       "        7    0.000    0.000    0.000    0.000 _inspect.py:144(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:750(_typedict)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2817(_unspecified)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2824(errstate)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:339(PackageLoaderDebug)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:33(ModuleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:207(send_multipart)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:128(MovingBatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:134(MovingBatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:51(MaskedCouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate.py:20(CNF_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:47(FeedforwardGateII)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:40(AverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(RunningAverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:126(ParallelCNFLayers)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:83(ActNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:95(LinearZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:152(Conv2dZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:170(Permute2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:291(Split2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:347(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:16(FPUModeChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:78(_compare_version)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:136(__lt__)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:63(Swish)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:73(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:255(ODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:316(AutoencoderODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:7(SequentialDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:21(MixtureODELayer)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:9(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:38(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:36(IgnoreLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:45(ConcatLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:56(ConcatLinear_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:66(SquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:76(ConcatSquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:88(HyperConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:124(IgnoreConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:137(SquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:166(ConcatConv2d_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:180(ConcatSquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:226(GatedConv)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:242(GatedConvTranspose)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:260(BlendLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:272(BlendConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:25(LogitTransform)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:43(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:4(SequentialFlow)\n",
       "        1    0.000    0.000    0.000    0.000 rk_common.py:8(_RungeKuttaState)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:15(Midpoint)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:26(RK4)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:208(AdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:18(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:271(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:289(RandomTransforms)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(RandomApply)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:341(RandomOrder)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:352(RandomChoice)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:429(RandomHorizontalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:455(RandomVerticalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:557(RandomSizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:606(TenCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:649(LinearTransformation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:767(RandomRotation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:834(RandomAffine)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:954(Grayscale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:984(RandomGrayscale)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:24(_Enhance)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:40(Color)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:74(Brightness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:28(Filter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:32(MultibandFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:36(BuiltinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:71(RankFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:94(MedianFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:108(MinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:122(MaxFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:136(ModeFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:153(GaussianBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:167(BoxBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:187(UnsharpMask)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:212(BLUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:223(CONTOUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:232(DETAIL)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:241(EDGE_ENHANCE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:277(SHARPEN)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:286(SMOOTH)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:261(PointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:284(NamedPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:293(ArrayType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:324(StructOrUnionOrEnum)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:475(StructType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:483(EnumType)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:7(CocoCaptions)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:155(FashionMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:31(Compose)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:61(ToTensor)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:82(ToPILImage)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:120(Normalize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:149(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:182(Scale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:192(CenterCrop)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:124(synchronize_with_editor)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:45(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:196(get_start_method)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:422(is_recursion_error)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:2071(_match_arguments_partial)\n",
       "        1    0.000    0.000    0.000    0.000 configurable.py:426(initialized)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:595(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1211(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'pack' of 'Struct' objects}\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:60(safe_unicode)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:1253(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:1254(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:823(setLevel)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:743(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:337(__members__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:101(checklookbehindgroup)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:213(setstate)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:113(TypeCheckerWithDefault)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:214(Uint64ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:155(_ModifiedSizer)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:470(_ModifiedEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:24(PatternSyntaxError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(hooks)\n",
       "        2    0.000    0.000    0.000    0.000 tokenize.py:50(maybe)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:166(StopTokenizing)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:1056(Default)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:42(DescriptorDatabaseConflictingDefinitionError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:51(Error)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:40(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:41(EncodeError)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:25(InvalidMarker)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:37(UndefinedEnvironmentName)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:65(Value)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3792(FollowedBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3850(_MultipleMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4390(OnlyOnce)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:666(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1455(_UnboundedCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2364(Token)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2372(Empty)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2504(CaselessLiteral)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3180(StringStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3384(_ErrorStop)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:15(InvalidSpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:18(InvalidRequirement)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:22(SqrtmError)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2287(ImageTransformHandler)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:16(VerificationError)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:239(FunctionPtrType)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:184(RLock)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:129(SOCKSHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:137(SOCKSHTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:123(GeneralProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:131(SOCKS5AuthError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:139(SOCKS4Error)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:57(TqdmExperimentalWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:62(TqdmDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:67(TqdmMonitorWarning)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:72(AuthBase)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1222(Absent)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1753(LoadError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:253(WantWriteError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:265(SysCallError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:336(_NpnAdvertiseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:477(_OCSPServerCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:673(Session)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:135(cryptography_has_ssl_st)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:111(SHA224)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:125(SHA384)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:132(SHA512)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:193(KeySerializationEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 package_data.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:31(InvalidCodepointContext)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2665(ParsableOctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2940(ObjectDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2956(Real)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3041(RelativeOid)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4525(NumericString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4534(PrintableString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4552(VideotexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4560(IA5String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4744(GraphicString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4782(CharacterString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:29(TeletexIncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:35(TeletexStreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:40(TeletexStreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:30(LibraryNotFoundError)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:39(FFIEngineError)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:428(Rc2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1084(Pbes2Params)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:852(OCSPNoCheck)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:66(OtherPrimeInfos)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:211(ECPointBitString)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:227(FieldType)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:239(CharacteristicTwoBasis)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:420(DSAParams)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:446(Attributes)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:886(EncryptedPrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:899(ValidationParms)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:295(StreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:51(DuplicateExtension)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:57(ExtensionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:163(SECT233R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:181(SECT409K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:205(SECP521R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:211(SECP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:217(SECP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:241(BrainpoolP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:253(BrainpoolP512R1)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:38(NotYetFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:42(InvalidTag)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:46(InvalidSignature)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:16(CryptographyDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:79(InterfaceNotImplemented)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:115(_DeprecatedValue)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:36(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:44(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:53(ConnectTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:64(URLRequired)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:72(MissingSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:76(InvalidSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:80(InvalidURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:84(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:88(InvalidProxyURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:92(ChunkedEncodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:100(StreamConsumedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:114(RequestsWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:119(FileModeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:124(RequestsDependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:212(EUCJPContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:29(RequestError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:85(HostChangedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:94(TimeoutStateError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(ReadTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:115(ConnectTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:120(NewConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:135(LocationValueError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:150(ResponseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:156(SecurityWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:161(SubjectAltNameWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:166(InsecureRequestWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:171(SystemTimeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:176(InsecurePlatformWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:194(ResponseNotChunked)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:199(BodyNotHttplibCompatible)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:223(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:80(_DependentProperty)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:98(_Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:139(_IntegerGreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:155(_Real)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:163(_GreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:254(_LowerTriangular)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:263(_LowerCholesky)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:277(_PositiveDefinite)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:291(_RealVector)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1349(TopLevelTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:119(FrontendTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(dist_backend)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:120(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:193(FeatureAlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:178(ReflectionPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:270(_ReplicationPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:282(ReplicationPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:370(ReplicationPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:406(ZeroPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:84(MaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:838(AdaptiveMaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:971(AdaptiveAvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:98(BatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:246(BatchNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:551(LogSigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:780(Softmin)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:21(_WeightedLoss)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:369(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:497(EnforceUnique)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:249(_nested_map)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:10(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:200(CudaError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:510(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:518(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:526(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:530(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:534(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:275(TarError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:287(StreamError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:293(EmptyHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:296(TruncatedHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:299(EOFHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:305(SubsequentHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:198(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:206(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:218(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:273(_fromnxfunction_single)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:95(MaskedArrayFutureWarning)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:174(MaskError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:860(_DomainGreater)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:892(_MaskedUFunc)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:22(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:472(ConverterLockError)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:239(_missing_ctypes)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:99(skipif)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:451(CClass)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(KnownFailureException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1212(_Dummy)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1161(ComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1168(LongComplexFormat)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:100(_str_xmax)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:33(_ShouldStop)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:83(ComplexWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:45(VisibleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:21(PytestTester)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:196(ConcatCoordConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:58(Contrast)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:89(Sharpness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:250(EDGE_ENHANCE_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:259(EMBOSS)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:268(FIND_EDGES)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:295(SMOOTH_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:479(UnionType)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1366(_internal_poll)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle.py --data mnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_conditional_disentangle_bs8K_sratio_0_25_drop_0_5_run3 --resume ../experiments_published/cnf_conditional_disentangle_bs8K_sratio_0_25_drop_0_5_run3/epoch_365_checkpt.pth --seed 3 --conditional True --controlled_tol True --train_mode semisup --lr 0.0001 --warmup_iters 113 --atol 1e-4  --rtol 1e-4 --weight_y 0.5 --condition_ratio 0.25 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
