{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_drop_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z = model.module.dropout(z)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_cifar10_bs900_drop_0_5_run1/current_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_conditional_cifar10_bs900_drop_0_5_run1', seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=6144, bias=True)\n",
      "  (project_class): LinearZeros(in_features=3072, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1469494\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 0670 | Time 17.5730(17.7142) | Bit/dim 4.6595(4.7348) | Xent 1.6956(1.7752) | Loss 5.5073(5.6224) | Error 0.5967(0.6237) Steps 712(696.72) | Grad Norm 11.1101(10.8527) | Total Time 14.00(14.00)\n",
      "Iter 0680 | Time 18.0191(17.7834) | Bit/dim 4.6464(4.7122) | Xent 1.6882(1.7518) | Loss 5.4905(5.5881) | Error 0.5900(0.6147) Steps 718(703.65) | Grad Norm 5.9446(9.9248) | Total Time 14.00(14.00)\n",
      "Iter 0690 | Time 17.8199(17.7920) | Bit/dim 4.7794(4.7074) | Xent 1.8687(1.7524) | Loss 5.7138(5.5836) | Error 0.6889(0.6179) Steps 736(709.49) | Grad Norm 19.3590(11.8172) | Total Time 14.00(14.00)\n",
      "Iter 0700 | Time 17.4546(17.9183) | Bit/dim 4.7051(4.7017) | Xent 1.7686(1.7702) | Loss 5.5894(5.5868) | Error 0.6156(0.6235) Steps 718(716.86) | Grad Norm 16.4879(12.4702) | Total Time 14.00(14.00)\n",
      "Iter 0710 | Time 17.7961(17.8694) | Bit/dim 4.6370(4.6875) | Xent 1.7720(1.7766) | Loss 5.5230(5.5758) | Error 0.6044(0.6247) Steps 724(716.02) | Grad Norm 5.2225(12.0809) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 92.2955, Epoch Time 1111.7568(858.7808), Bit/dim 4.6025(best: inf), Xent 1.6540, Loss 5.4295, Error 0.5824(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 17.7911(17.8587) | Bit/dim 4.6267(4.6680) | Xent 1.6422(1.7622) | Loss 5.4478(5.5491) | Error 0.5733(0.6202) Steps 712(715.46) | Grad Norm 4.6590(10.5328) | Total Time 14.00(14.00)\n",
      "Iter 0730 | Time 17.7654(17.8783) | Bit/dim 4.6036(4.6481) | Xent 1.6409(1.7343) | Loss 5.4241(5.5152) | Error 0.5833(0.6097) Steps 718(717.14) | Grad Norm 9.0247(9.4006) | Total Time 14.00(14.00)\n",
      "Iter 0740 | Time 18.0722(17.9850) | Bit/dim 4.5272(4.6277) | Xent 1.6768(1.7125) | Loss 5.3656(5.4840) | Error 0.5889(0.6029) Steps 742(723.59) | Grad Norm 19.2496(10.0848) | Total Time 14.00(14.00)\n",
      "Iter 0750 | Time 18.4002(18.1707) | Bit/dim 4.5971(4.6135) | Xent 1.6405(1.7068) | Loss 5.4174(5.4669) | Error 0.5922(0.6024) Steps 778(733.25) | Grad Norm 9.2194(10.5608) | Total Time 14.00(14.00)\n",
      "Iter 0760 | Time 18.3154(18.2365) | Bit/dim 4.5356(4.6010) | Xent 1.6037(1.6870) | Loss 5.3375(5.4445) | Error 0.5600(0.5970) Steps 742(739.32) | Grad Norm 5.7428(9.7298) | Total Time 14.00(14.00)\n",
      "Iter 0770 | Time 18.1724(18.2730) | Bit/dim 4.5828(4.5868) | Xent 1.6607(1.6769) | Loss 5.4132(5.4252) | Error 0.5944(0.5942) Steps 736(741.41) | Grad Norm 3.3699(9.3889) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 95.6478, Epoch Time 1120.8610(866.6432), Bit/dim 4.5345(best: 4.6025), Xent 1.5823, Loss 5.3256, Error 0.5601(best: 0.5824)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 18.2286(18.3063) | Bit/dim 4.5529(4.5720) | Xent 1.6794(1.6661) | Loss 5.3925(5.4050) | Error 0.6033(0.5908) Steps 766(745.18) | Grad Norm 23.7528(10.8919) | Total Time 14.00(14.00)\n",
      "Iter 0790 | Time 18.1849(18.3392) | Bit/dim 4.5358(4.5600) | Xent 1.6288(1.6534) | Loss 5.3502(5.3867) | Error 0.5822(0.5884) Steps 742(748.06) | Grad Norm 9.4759(10.6376) | Total Time 14.00(14.00)\n",
      "Iter 0800 | Time 19.0006(18.3663) | Bit/dim 4.5032(4.5464) | Xent 1.6238(1.6419) | Loss 5.3152(5.3674) | Error 0.5700(0.5833) Steps 766(750.30) | Grad Norm 4.3707(9.9103) | Total Time 14.00(14.00)\n",
      "Iter 0810 | Time 18.9733(18.4308) | Bit/dim 4.4660(4.5340) | Xent 1.5691(1.6366) | Loss 5.2506(5.3523) | Error 0.5744(0.5821) Steps 766(753.55) | Grad Norm 6.9490(9.7056) | Total Time 14.00(14.00)\n",
      "Iter 0820 | Time 18.9009(18.5833) | Bit/dim 4.4956(4.5264) | Xent 1.5650(1.6290) | Loss 5.2781(5.3409) | Error 0.5767(0.5804) Steps 796(757.88) | Grad Norm 6.8492(10.1937) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 98.0194, Epoch Time 1140.8660(874.8699), Bit/dim 4.4838(best: 4.5345), Xent 1.5439, Loss 5.2557, Error 0.5562(best: 0.5601)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 19.1036(18.6837) | Bit/dim 4.4664(4.5149) | Xent 1.5487(1.6261) | Loss 5.2407(5.3280) | Error 0.5533(0.5799) Steps 778(762.39) | Grad Norm 6.5945(9.6996) | Total Time 14.00(14.00)\n",
      "Iter 0840 | Time 19.0889(18.7400) | Bit/dim 4.4935(4.5035) | Xent 1.5871(1.6079) | Loss 5.2870(5.3075) | Error 0.6056(0.5740) Steps 772(764.17) | Grad Norm 9.1425(9.0207) | Total Time 14.00(14.00)\n",
      "Iter 0850 | Time 18.6057(18.8641) | Bit/dim 4.4491(4.4880) | Xent 1.5001(1.5956) | Loss 5.1992(5.2858) | Error 0.5344(0.5690) Steps 784(768.77) | Grad Norm 11.3883(8.6384) | Total Time 14.00(14.00)\n",
      "Iter 0860 | Time 19.5568(18.9999) | Bit/dim 4.4466(4.4806) | Xent 1.5346(1.5828) | Loss 5.2139(5.2720) | Error 0.5467(0.5657) Steps 802(775.24) | Grad Norm 3.5083(8.5042) | Total Time 14.00(14.00)\n",
      "Iter 0870 | Time 19.9869(19.2133) | Bit/dim 4.4280(4.4706) | Xent 1.4870(1.5671) | Loss 5.1715(5.2541) | Error 0.5467(0.5608) Steps 766(781.16) | Grad Norm 7.0098(8.1928) | Total Time 14.00(14.00)\n",
      "Iter 0880 | Time 20.3251(19.3792) | Bit/dim 4.4161(4.4603) | Xent 1.6680(1.5677) | Loss 5.2500(5.2442) | Error 0.5989(0.5598) Steps 802(787.47) | Grad Norm 17.0156(8.6301) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 101.1680, Epoch Time 1184.7986(884.1677), Bit/dim 4.4622(best: 4.4838), Xent 1.5454, Loss 5.2349, Error 0.5514(best: 0.5562)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 20.0471(19.4884) | Bit/dim 4.4671(4.4551) | Xent 1.5109(1.5605) | Loss 5.2225(5.2354) | Error 0.5467(0.5571) Steps 802(793.60) | Grad Norm 11.4986(9.1944) | Total Time 14.00(14.00)\n",
      "Iter 0900 | Time 18.9885(19.5511) | Bit/dim 4.3949(4.4462) | Xent 1.5194(1.5476) | Loss 5.1545(5.2200) | Error 0.5200(0.5544) Steps 784(793.73) | Grad Norm 6.1610(9.1409) | Total Time 14.00(14.00)\n",
      "Iter 0910 | Time 19.9419(19.6945) | Bit/dim 4.4093(4.4368) | Xent 1.5588(1.5367) | Loss 5.1886(5.2052) | Error 0.5567(0.5505) Steps 844(800.83) | Grad Norm 14.9496(9.2659) | Total Time 14.00(14.00)\n",
      "Iter 0920 | Time 20.0702(19.7860) | Bit/dim 4.4151(4.4271) | Xent 1.5571(1.5387) | Loss 5.1937(5.1965) | Error 0.5700(0.5517) Steps 808(804.18) | Grad Norm 5.7554(8.9828) | Total Time 14.00(14.00)\n",
      "Iter 0930 | Time 20.5472(19.8944) | Bit/dim 4.3568(4.4141) | Xent 1.5414(1.5331) | Loss 5.1276(5.1806) | Error 0.5644(0.5506) Steps 838(808.54) | Grad Norm 8.0108(8.6829) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 101.0541, Epoch Time 1219.2838(894.2212), Bit/dim 4.3767(best: 4.4622), Xent 1.4286, Loss 5.0910, Error 0.5152(best: 0.5514)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 20.1411(19.9214) | Bit/dim 4.4058(4.4050) | Xent 1.4731(1.5146) | Loss 5.1423(5.1623) | Error 0.5244(0.5448) Steps 826(810.19) | Grad Norm 10.6255(8.2703) | Total Time 14.00(14.00)\n",
      "Iter 0950 | Time 20.6915(20.0464) | Bit/dim 4.3241(4.3951) | Xent 1.3620(1.5002) | Loss 5.0051(5.1452) | Error 0.4756(0.5382) Steps 814(814.51) | Grad Norm 5.1311(8.3030) | Total Time 14.00(14.00)\n",
      "Iter 0960 | Time 19.7642(20.0476) | Bit/dim 4.3508(4.3845) | Xent 1.5547(1.4877) | Loss 5.1282(5.1283) | Error 0.5600(0.5348) Steps 820(811.75) | Grad Norm 17.1470(7.9608) | Total Time 14.00(14.00)\n",
      "Iter 0970 | Time 21.0184(20.1987) | Bit/dim 4.3430(4.3791) | Xent 1.6337(1.4953) | Loss 5.1598(5.1268) | Error 0.5989(0.5375) Steps 826(814.79) | Grad Norm 11.7319(9.0609) | Total Time 14.00(14.00)\n",
      "Iter 0980 | Time 20.1634(20.1774) | Bit/dim 4.3300(4.3703) | Xent 1.5970(1.5045) | Loss 5.1285(5.1226) | Error 0.5722(0.5415) Steps 826(818.73) | Grad Norm 6.5746(8.8289) | Total Time 14.00(14.00)\n",
      "Iter 0990 | Time 19.6648(20.2128) | Bit/dim 4.3420(4.3627) | Xent 1.5424(1.5106) | Loss 5.1132(5.1180) | Error 0.5278(0.5425) Steps 820(820.43) | Grad Norm 10.5947(8.6764) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 102.0387, Epoch Time 1234.2339(904.4216), Bit/dim 4.3319(best: 4.3767), Xent 1.4375, Loss 5.0507, Error 0.5211(best: 0.5152)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 20.7945(20.2920) | Bit/dim 4.3392(4.3541) | Xent 1.4596(1.4939) | Loss 5.0689(5.1011) | Error 0.5256(0.5366) Steps 784(819.48) | Grad Norm 12.2488(8.7991) | Total Time 14.00(14.00)\n",
      "Iter 1010 | Time 20.3005(20.2127) | Bit/dim 4.3059(4.3429) | Xent 1.5069(1.4821) | Loss 5.0594(5.0840) | Error 0.5422(0.5311) Steps 832(818.94) | Grad Norm 9.5510(8.5473) | Total Time 14.00(14.00)\n",
      "Iter 1020 | Time 20.4856(20.2620) | Bit/dim 4.3354(4.3377) | Xent 1.4963(1.4899) | Loss 5.0836(5.0826) | Error 0.5567(0.5352) Steps 814(819.79) | Grad Norm 11.3843(9.6393) | Total Time 14.00(14.00)\n",
      "Iter 1030 | Time 20.0436(20.2613) | Bit/dim 4.3173(4.3301) | Xent 1.3910(1.4747) | Loss 5.0128(5.0675) | Error 0.4944(0.5310) Steps 868(823.17) | Grad Norm 4.2307(8.5031) | Total Time 14.00(14.00)\n",
      "Iter 1040 | Time 21.0809(20.3046) | Bit/dim 4.2675(4.3180) | Xent 1.4111(1.4579) | Loss 4.9731(5.0470) | Error 0.5033(0.5231) Steps 820(821.41) | Grad Norm 9.6238(7.7685) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 103.3871, Epoch Time 1239.0597(914.4607), Bit/dim 4.2690(best: 4.3319), Xent 1.3627, Loss 4.9504, Error 0.4919(best: 0.5152)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 20.8750(20.3361) | Bit/dim 4.2505(4.3069) | Xent 1.4082(1.4491) | Loss 4.9546(5.0314) | Error 0.5089(0.5195) Steps 832(824.70) | Grad Norm 13.1927(7.9864) | Total Time 14.00(14.00)\n",
      "Iter 1060 | Time 20.2720(20.2795) | Bit/dim 4.2574(4.2963) | Xent 1.3794(1.4325) | Loss 4.9471(5.0126) | Error 0.5167(0.5140) Steps 802(820.44) | Grad Norm 9.0271(7.7725) | Total Time 14.00(14.00)\n",
      "Iter 1070 | Time 20.6970(20.3016) | Bit/dim 4.2326(4.2838) | Xent 1.4192(1.4200) | Loss 4.9422(4.9937) | Error 0.4956(0.5091) Steps 844(821.62) | Grad Norm 2.9523(6.8858) | Total Time 14.00(14.00)\n",
      "Iter 1080 | Time 19.7254(20.4463) | Bit/dim 4.8294(4.3047) | Xent 2.5339(1.4768) | Loss 6.0964(5.0431) | Error 0.7667(0.5214) Steps 844(829.02) | Grad Norm 34.7666(9.6305) | Total Time 14.00(14.00)\n",
      "Iter 1090 | Time 23.0487(20.8186) | Bit/dim 4.5842(4.3966) | Xent 1.9598(1.6336) | Loss 5.5641(5.2135) | Error 0.6633(0.5660) Steps 958(855.59) | Grad Norm 7.5125(11.7706) | Total Time 14.00(14.00)\n",
      "Iter 1100 | Time 21.5427(21.1360) | Bit/dim 4.4100(4.4190) | Xent 1.7120(1.6756) | Loss 5.2660(5.2568) | Error 0.6211(0.5866) Steps 886(875.18) | Grad Norm 6.5378(10.2528) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 108.3243, Epoch Time 1279.9334(925.4249), Bit/dim 4.4071(best: 4.2690), Xent 1.6193, Loss 5.2168, Error 0.5847(best: 0.4919)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 21.2694(21.1485) | Bit/dim 4.3440(4.4045) | Xent 1.6126(1.6630) | Loss 5.1503(5.2360) | Error 0.5933(0.5849) Steps 844(876.35) | Grad Norm 3.2191(8.6854) | Total Time 14.00(14.00)\n",
      "Iter 1120 | Time 20.1208(20.8734) | Bit/dim 4.2631(4.3789) | Xent 1.5434(1.6367) | Loss 5.0348(5.1972) | Error 0.5478(0.5802) Steps 844(866.72) | Grad Norm 3.7417(7.4888) | Total Time 14.00(14.00)\n",
      "Iter 1130 | Time 19.5810(20.6954) | Bit/dim 4.2876(4.3509) | Xent 1.5017(1.6034) | Loss 5.0385(5.1526) | Error 0.5689(0.5730) Steps 832(857.72) | Grad Norm 2.2998(6.4733) | Total Time 14.00(14.00)\n",
      "Iter 1140 | Time 20.3964(20.5818) | Bit/dim 4.2446(4.3230) | Xent 1.4444(1.5718) | Loss 4.9668(5.1089) | Error 0.5278(0.5638) Steps 838(851.59) | Grad Norm 2.2071(5.7074) | Total Time 14.00(14.00)\n",
      "Iter 1150 | Time 20.5532(20.5623) | Bit/dim 4.2090(4.2996) | Xent 1.4347(1.5490) | Loss 4.9264(5.0740) | Error 0.5000(0.5558) Steps 832(849.88) | Grad Norm 9.0790(5.7733) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 105.9385, Epoch Time 1248.6409(935.1214), Bit/dim 4.2227(best: 4.2690), Xent 1.4376, Loss 4.9415, Error 0.5212(best: 0.4919)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 20.1811(20.6418) | Bit/dim 4.2110(4.2799) | Xent 1.4206(1.5227) | Loss 4.9213(5.0413) | Error 0.5289(0.5465) Steps 856(850.91) | Grad Norm 4.9626(5.6286) | Total Time 14.00(14.00)\n",
      "Iter 1170 | Time 21.4337(20.7746) | Bit/dim 4.1953(4.2599) | Xent 1.4433(1.4977) | Loss 4.9169(5.0087) | Error 0.5211(0.5377) Steps 856(850.99) | Grad Norm 10.1840(5.8876) | Total Time 14.00(14.00)\n",
      "Iter 1180 | Time 21.2023(20.8689) | Bit/dim 4.1943(4.2458) | Xent 1.3958(1.4735) | Loss 4.8922(4.9825) | Error 0.4978(0.5303) Steps 856(850.57) | Grad Norm 3.7337(5.5016) | Total Time 14.00(14.00)\n",
      "Iter 1190 | Time 20.6973(20.9284) | Bit/dim 4.1755(4.2283) | Xent 1.4267(1.4534) | Loss 4.8888(4.9550) | Error 0.4967(0.5232) Steps 826(848.56) | Grad Norm 5.2172(5.2188) | Total Time 14.00(14.00)\n",
      "Iter 1200 | Time 20.5656(20.9011) | Bit/dim 4.1427(4.2162) | Xent 1.4093(1.4514) | Loss 4.8474(4.9418) | Error 0.5300(0.5227) Steps 862(848.99) | Grad Norm 4.4105(6.4905) | Total Time 14.00(14.00)\n",
      "Iter 1210 | Time 20.3425(20.7519) | Bit/dim 4.1766(4.2082) | Xent 1.3391(1.4338) | Loss 4.8462(4.9251) | Error 0.4856(0.5168) Steps 826(843.71) | Grad Norm 7.4729(6.4831) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 103.5223, Epoch Time 1273.1325(945.2617), Bit/dim 4.1724(best: 4.2227), Xent 1.3493, Loss 4.8470, Error 0.4926(best: 0.4919)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 21.7438(20.7725) | Bit/dim 4.1663(4.1979) | Xent 1.3516(1.4091) | Loss 4.8421(4.9024) | Error 0.4967(0.5079) Steps 856(841.69) | Grad Norm 4.2292(5.9646) | Total Time 14.00(14.00)\n",
      "Iter 1230 | Time 20.6532(20.7782) | Bit/dim 4.1835(4.1898) | Xent 1.3540(1.3963) | Loss 4.8605(4.8880) | Error 0.4889(0.5015) Steps 826(842.31) | Grad Norm 3.6422(5.8399) | Total Time 14.00(14.00)\n",
      "Iter 1240 | Time 21.4210(20.8609) | Bit/dim 4.1565(4.1810) | Xent 1.2894(1.3740) | Loss 4.8012(4.8680) | Error 0.4556(0.4941) Steps 850(843.21) | Grad Norm 4.3226(5.3944) | Total Time 14.00(14.00)\n",
      "Iter 1250 | Time 21.2165(20.9451) | Bit/dim 4.1081(4.1683) | Xent 1.3409(1.3652) | Loss 4.7785(4.8509) | Error 0.4844(0.4915) Steps 838(847.11) | Grad Norm 11.6646(5.7047) | Total Time 14.00(14.00)\n",
      "Iter 1260 | Time 21.2724(20.9719) | Bit/dim 4.1218(4.1646) | Xent 1.2639(1.3582) | Loss 4.7538(4.8436) | Error 0.4600(0.4896) Steps 850(846.98) | Grad Norm 5.0436(5.8045) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 102.3978, Epoch Time 1274.9946(955.1537), Bit/dim 4.1373(best: 4.1724), Xent 1.3021, Loss 4.7883, Error 0.4733(best: 0.4919)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 20.6814(20.9654) | Bit/dim 4.1210(4.1600) | Xent 1.3945(1.3516) | Loss 4.8182(4.8358) | Error 0.5100(0.4866) Steps 844(846.16) | Grad Norm 8.8262(5.7791) | Total Time 14.00(14.00)\n",
      "Iter 1280 | Time 20.5202(20.8991) | Bit/dim 4.1125(4.1521) | Xent 1.2927(1.3351) | Loss 4.7589(4.8196) | Error 0.4400(0.4790) Steps 844(842.67) | Grad Norm 7.3829(5.8293) | Total Time 14.00(14.00)\n",
      "Iter 1290 | Time 20.6763(20.8837) | Bit/dim 4.1301(4.1458) | Xent 1.2450(1.3191) | Loss 4.7526(4.8053) | Error 0.4500(0.4730) Steps 844(841.94) | Grad Norm 3.9114(5.6916) | Total Time 14.00(14.00)\n",
      "Iter 1300 | Time 21.7677(20.9322) | Bit/dim 4.1435(4.1381) | Xent 1.2791(1.3141) | Loss 4.7830(4.7952) | Error 0.4400(0.4714) Steps 868(841.98) | Grad Norm 6.0920(5.7159) | Total Time 14.00(14.00)\n",
      "Iter 1310 | Time 20.5985(20.9783) | Bit/dim 4.0996(4.1306) | Xent 1.3050(1.3137) | Loss 4.7521(4.7874) | Error 0.4678(0.4705) Steps 832(846.01) | Grad Norm 4.7374(5.6503) | Total Time 14.00(14.00)\n",
      "Iter 1320 | Time 20.9079(21.0185) | Bit/dim 4.1457(4.1272) | Xent 1.3489(1.3150) | Loss 4.8201(4.7847) | Error 0.4711(0.4721) Steps 832(845.99) | Grad Norm 4.5858(6.3563) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 102.0363, Epoch Time 1272.8232(964.6838), Bit/dim 4.1422(best: 4.1373), Xent 1.3223, Loss 4.8034, Error 0.4741(best: 0.4733)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 21.2011(20.9618) | Bit/dim 4.1188(4.1258) | Xent 1.2639(1.3122) | Loss 4.7507(4.7819) | Error 0.4367(0.4707) Steps 820(843.52) | Grad Norm 13.7435(6.9869) | Total Time 14.00(14.00)\n",
      "Iter 1340 | Time 21.2793(20.9773) | Bit/dim 4.0977(4.1193) | Xent 1.1999(1.2923) | Loss 4.6977(4.7655) | Error 0.4289(0.4623) Steps 838(842.90) | Grad Norm 4.5655(6.4837) | Total Time 14.00(14.00)\n",
      "Iter 1350 | Time 20.5289(21.0013) | Bit/dim 4.1432(4.1155) | Xent 1.2617(1.2830) | Loss 4.7741(4.7570) | Error 0.4511(0.4583) Steps 838(843.50) | Grad Norm 10.6681(6.0948) | Total Time 14.00(14.00)\n",
      "Iter 1360 | Time 21.2828(21.0610) | Bit/dim 4.0909(4.1055) | Xent 1.2199(1.2739) | Loss 4.7009(4.7425) | Error 0.4333(0.4547) Steps 832(844.15) | Grad Norm 5.3697(6.0647) | Total Time 14.00(14.00)\n",
      "Iter 1370 | Time 20.2016(21.0497) | Bit/dim 4.0848(4.1009) | Xent 1.2442(1.2714) | Loss 4.7069(4.7366) | Error 0.4444(0.4546) Steps 820(844.51) | Grad Norm 7.3296(6.7566) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 101.8618, Epoch Time 1275.5727(974.0105), Bit/dim 4.0856(best: 4.1373), Xent 1.2315, Loss 4.7013, Error 0.4424(best: 0.4733)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 20.5514(21.0106) | Bit/dim 4.0693(4.0954) | Xent 1.1360(1.2550) | Loss 4.6373(4.7229) | Error 0.4122(0.4495) Steps 826(844.36) | Grad Norm 4.5492(6.3359) | Total Time 14.00(14.00)\n",
      "Iter 1390 | Time 21.2064(21.0018) | Bit/dim 4.1134(4.0944) | Xent 1.2389(1.2507) | Loss 4.7329(4.7198) | Error 0.4500(0.4472) Steps 844(841.76) | Grad Norm 3.3775(6.3316) | Total Time 14.00(14.00)\n",
      "Iter 1400 | Time 22.5801(21.0991) | Bit/dim 4.0330(4.0873) | Xent 1.2394(1.2409) | Loss 4.6526(4.7078) | Error 0.4400(0.4419) Steps 850(841.63) | Grad Norm 8.1993(6.2365) | Total Time 14.00(14.00)\n",
      "Iter 1410 | Time 21.4158(21.1576) | Bit/dim 4.0282(4.0831) | Xent 1.2170(1.2448) | Loss 4.6367(4.7055) | Error 0.4511(0.4432) Steps 838(843.91) | Grad Norm 4.2351(6.5381) | Total Time 14.00(14.00)\n",
      "Iter 1420 | Time 20.8547(21.1443) | Bit/dim 4.0784(4.0792) | Xent 1.1992(1.2425) | Loss 4.6780(4.7004) | Error 0.4378(0.4427) Steps 802(840.96) | Grad Norm 4.9503(6.0910) | Total Time 14.00(14.00)\n",
      "Iter 1430 | Time 21.0193(21.1814) | Bit/dim 4.0784(4.0753) | Xent 1.2249(1.2380) | Loss 4.6908(4.6943) | Error 0.4222(0.4405) Steps 844(843.56) | Grad Norm 4.9612(6.3152) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 101.6174, Epoch Time 1285.1172(983.3437), Bit/dim 4.0569(best: 4.0856), Xent 1.1818, Loss 4.6478, Error 0.4271(best: 0.4424)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 21.7612(21.1771) | Bit/dim 4.0529(4.0679) | Xent 1.1824(1.2126) | Loss 4.6441(4.6742) | Error 0.4367(0.4313) Steps 808(839.83) | Grad Norm 4.4442(5.9671) | Total Time 14.00(14.00)\n",
      "Iter 1450 | Time 21.3405(21.1932) | Bit/dim 4.0497(4.0635) | Xent 1.2367(1.2025) | Loss 4.6681(4.6647) | Error 0.4300(0.4303) Steps 868(839.82) | Grad Norm 8.2743(6.2087) | Total Time 14.00(14.00)\n",
      "Iter 1460 | Time 21.2883(21.1800) | Bit/dim 4.0227(4.0567) | Xent 1.3230(1.2150) | Loss 4.6842(4.6642) | Error 0.4544(0.4328) Steps 820(839.14) | Grad Norm 13.9358(6.9526) | Total Time 14.00(14.00)\n",
      "Iter 1470 | Time 20.8004(21.0324) | Bit/dim 4.0850(4.0608) | Xent 1.1822(1.2217) | Loss 4.6761(4.6717) | Error 0.4033(0.4334) Steps 778(834.15) | Grad Norm 5.4969(6.8828) | Total Time 14.00(14.00)\n",
      "Iter 1480 | Time 20.3695(20.8423) | Bit/dim 4.0589(4.0598) | Xent 1.1949(1.2166) | Loss 4.6564(4.6681) | Error 0.4344(0.4320) Steps 826(828.30) | Grad Norm 8.5909(6.7368) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 100.8513, Epoch Time 1267.3323(991.8633), Bit/dim 4.0487(best: 4.0569), Xent 1.1868, Loss 4.6420, Error 0.4288(best: 0.4271)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 21.5327(20.8651) | Bit/dim 4.0326(4.0559) | Xent 1.1742(1.2036) | Loss 4.6197(4.6576) | Error 0.4167(0.4272) Steps 838(830.59) | Grad Norm 6.8568(6.6003) | Total Time 14.00(14.00)\n",
      "Iter 1500 | Time 20.9701(20.8810) | Bit/dim 4.0365(4.0519) | Xent 1.1442(1.1818) | Loss 4.6086(4.6428) | Error 0.4144(0.4206) Steps 850(834.22) | Grad Norm 6.8559(6.9704) | Total Time 14.00(14.00)\n",
      "Iter 1510 | Time 20.5558(20.9608) | Bit/dim 4.0276(4.0478) | Xent 1.1969(1.1775) | Loss 4.6260(4.6365) | Error 0.4167(0.4186) Steps 856(837.56) | Grad Norm 4.3815(7.1233) | Total Time 14.00(14.00)\n",
      "Iter 1520 | Time 20.5623(20.8746) | Bit/dim 4.0572(4.0438) | Xent 1.0912(1.1702) | Loss 4.6028(4.6289) | Error 0.4056(0.4162) Steps 844(835.71) | Grad Norm 4.6492(6.6258) | Total Time 14.00(14.00)\n",
      "Iter 1530 | Time 21.8695(20.8446) | Bit/dim 4.0087(4.0380) | Xent 1.1458(1.1630) | Loss 4.5816(4.6195) | Error 0.4178(0.4139) Steps 850(834.84) | Grad Norm 3.0773(6.3018) | Total Time 14.00(14.00)\n",
      "Iter 1540 | Time 20.4558(20.8641) | Bit/dim 4.0121(4.0322) | Xent 1.1687(1.1568) | Loss 4.5965(4.6106) | Error 0.4144(0.4122) Steps 832(835.74) | Grad Norm 6.9220(6.4642) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 99.5566, Epoch Time 1267.3524(1000.1280), Bit/dim 4.0158(best: 4.0487), Xent 1.1320, Loss 4.5818, Error 0.4065(best: 0.4271)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 20.9744(20.9019) | Bit/dim 4.0101(4.0252) | Xent 1.0776(1.1464) | Loss 4.5489(4.5983) | Error 0.3900(0.4091) Steps 802(833.20) | Grad Norm 7.6724(6.4857) | Total Time 14.00(14.00)\n",
      "Iter 1560 | Time 21.2390(20.8533) | Bit/dim 4.0173(4.0271) | Xent 1.0873(1.1449) | Loss 4.5610(4.5996) | Error 0.3856(0.4075) Steps 850(833.93) | Grad Norm 4.9752(7.1970) | Total Time 14.00(14.00)\n",
      "Iter 1570 | Time 21.2684(20.8854) | Bit/dim 4.0076(4.0261) | Xent 1.1416(1.1487) | Loss 4.5784(4.6004) | Error 0.4044(0.4082) Steps 850(835.87) | Grad Norm 5.1789(7.1802) | Total Time 14.00(14.00)\n",
      "Iter 1580 | Time 21.6004(20.9365) | Bit/dim 3.9972(4.0221) | Xent 1.0819(1.1402) | Loss 4.5382(4.5922) | Error 0.3733(0.4059) Steps 832(837.30) | Grad Norm 3.8061(6.9115) | Total Time 14.00(14.00)\n",
      "Iter 1590 | Time 21.5674(20.9810) | Bit/dim 3.9954(4.0149) | Xent 1.1010(1.1249) | Loss 4.5459(4.5774) | Error 0.3933(0.4001) Steps 850(840.33) | Grad Norm 4.0852(6.3613) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 99.2143, Epoch Time 1270.7028(1008.2452), Bit/dim 3.9964(best: 4.0158), Xent 1.1565, Loss 4.5747, Error 0.4173(best: 0.4065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 21.1629(21.0269) | Bit/dim 4.0678(4.0141) | Xent 1.0219(1.1160) | Loss 4.5787(4.5721) | Error 0.3811(0.3979) Steps 814(837.70) | Grad Norm 6.5419(6.7139) | Total Time 14.00(14.00)\n",
      "Iter 1610 | Time 20.8782(21.0472) | Bit/dim 3.9859(4.0115) | Xent 1.0637(1.1025) | Loss 4.5177(4.5627) | Error 0.3900(0.3937) Steps 844(839.29) | Grad Norm 4.6022(6.5458) | Total Time 14.00(14.00)\n",
      "Iter 1620 | Time 21.2560(21.0709) | Bit/dim 4.0087(4.0082) | Xent 1.0877(1.0851) | Loss 4.5526(4.5508) | Error 0.3756(0.3879) Steps 832(841.98) | Grad Norm 6.5613(6.1161) | Total Time 14.00(14.00)\n",
      "Iter 1630 | Time 21.2079(21.0746) | Bit/dim 3.9748(4.0003) | Xent 1.1021(1.0851) | Loss 4.5259(4.5429) | Error 0.4022(0.3871) Steps 838(842.54) | Grad Norm 8.2880(6.4083) | Total Time 14.00(14.00)\n",
      "Iter 1640 | Time 21.3460(21.0586) | Bit/dim 4.0006(3.9951) | Xent 1.0547(1.0887) | Loss 4.5279(4.5395) | Error 0.3833(0.3866) Steps 832(842.86) | Grad Norm 3.8769(6.3963) | Total Time 14.00(14.00)\n",
      "Iter 1650 | Time 21.3646(21.1216) | Bit/dim 3.9806(3.9920) | Xent 1.0716(1.0869) | Loss 4.5165(4.5354) | Error 0.3744(0.3842) Steps 844(841.97) | Grad Norm 5.3110(6.4227) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 98.9961, Epoch Time 1279.9615(1016.3967), Bit/dim 3.9893(best: 3.9964), Xent 1.1054, Loss 4.5420, Error 0.3989(best: 0.4065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 21.9068(21.2001) | Bit/dim 3.9849(3.9885) | Xent 1.0040(1.0641) | Loss 4.4869(4.5205) | Error 0.3389(0.3756) Steps 826(839.59) | Grad Norm 5.4704(5.9241) | Total Time 14.00(14.00)\n",
      "Iter 1670 | Time 20.4715(21.1421) | Bit/dim 3.9673(3.9852) | Xent 1.0601(1.0531) | Loss 4.4974(4.5117) | Error 0.3800(0.3720) Steps 826(838.70) | Grad Norm 10.7425(5.7850) | Total Time 14.00(14.00)\n",
      "Iter 1680 | Time 20.4280(21.1616) | Bit/dim 3.9650(3.9808) | Xent 1.0195(1.0425) | Loss 4.4748(4.5021) | Error 0.3633(0.3672) Steps 838(837.37) | Grad Norm 6.3371(5.7978) | Total Time 14.00(14.00)\n",
      "Iter 1690 | Time 21.4700(21.2268) | Bit/dim 3.9540(3.9756) | Xent 1.0654(1.0375) | Loss 4.4867(4.4944) | Error 0.3700(0.3664) Steps 874(836.30) | Grad Norm 4.0256(5.3756) | Total Time 14.00(14.00)\n",
      "Iter 1700 | Time 20.9452(21.2563) | Bit/dim 3.9499(3.9727) | Xent 1.0540(1.0380) | Loss 4.4769(4.4917) | Error 0.3711(0.3656) Steps 850(839.16) | Grad Norm 12.7424(6.1125) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 99.5059, Epoch Time 1288.4295(1024.5577), Bit/dim 3.9686(best: 3.9893), Xent 1.0929, Loss 4.5151, Error 0.3869(best: 0.3989)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 20.8504(21.2513) | Bit/dim 3.9203(3.9695) | Xent 0.9959(1.0398) | Loss 4.4182(4.4894) | Error 0.3511(0.3655) Steps 820(836.67) | Grad Norm 9.7117(6.4669) | Total Time 14.00(14.00)\n",
      "Iter 1720 | Time 20.8922(21.0772) | Bit/dim 3.9825(3.9701) | Xent 0.9736(1.0329) | Loss 4.4693(4.4866) | Error 0.3378(0.3625) Steps 832(833.77) | Grad Norm 9.7336(6.8433) | Total Time 14.00(14.00)\n",
      "Iter 1730 | Time 20.9149(21.1138) | Bit/dim 3.9572(3.9680) | Xent 0.9706(1.0212) | Loss 4.4425(4.4786) | Error 0.3311(0.3594) Steps 808(833.81) | Grad Norm 4.1980(6.5323) | Total Time 14.00(14.00)\n",
      "Iter 1740 | Time 21.3808(21.2439) | Bit/dim 3.9779(3.9667) | Xent 0.9548(1.0112) | Loss 4.4553(4.4723) | Error 0.3467(0.3565) Steps 844(837.64) | Grad Norm 2.7906(5.9535) | Total Time 14.00(14.00)\n",
      "Iter 1750 | Time 21.5481(21.2687) | Bit/dim 3.9510(3.9631) | Xent 0.9317(1.0048) | Loss 4.4168(4.4655) | Error 0.3222(0.3552) Steps 844(842.10) | Grad Norm 4.7599(5.8202) | Total Time 14.00(14.00)\n",
      "Iter 1760 | Time 21.4763(21.2844) | Bit/dim 3.9479(3.9581) | Xent 0.9928(1.0005) | Loss 4.4443(4.4583) | Error 0.3433(0.3539) Steps 850(844.08) | Grad Norm 4.1740(5.4518) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 99.7712, Epoch Time 1283.9276(1032.3388), Bit/dim 3.9449(best: 3.9686), Xent 1.0788, Loss 4.4843, Error 0.3875(best: 0.3869)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 21.3590(21.3034) | Bit/dim 3.9215(3.9553) | Xent 1.0237(0.9958) | Loss 4.4333(4.4532) | Error 0.3667(0.3518) Steps 862(848.28) | Grad Norm 7.6190(5.6184) | Total Time 14.00(14.00)\n",
      "Iter 1780 | Time 20.7283(21.3246) | Bit/dim 3.9065(3.9508) | Xent 0.9895(0.9914) | Loss 4.4012(4.4465) | Error 0.3456(0.3504) Steps 838(851.57) | Grad Norm 8.2232(6.0043) | Total Time 14.00(14.00)\n",
      "Iter 1790 | Time 20.8068(21.3055) | Bit/dim 3.9121(3.9493) | Xent 0.9609(0.9853) | Loss 4.3925(4.4419) | Error 0.3411(0.3484) Steps 856(851.83) | Grad Norm 10.5616(6.4608) | Total Time 14.00(14.00)\n",
      "Iter 1800 | Time 21.2825(21.3192) | Bit/dim 3.9541(3.9501) | Xent 0.9893(0.9816) | Loss 4.4487(4.4409) | Error 0.3456(0.3477) Steps 850(848.75) | Grad Norm 4.0594(6.2131) | Total Time 14.00(14.00)\n",
      "Iter 1810 | Time 21.6823(21.3604) | Bit/dim 3.9311(3.9475) | Xent 0.9673(0.9777) | Loss 4.4147(4.4364) | Error 0.3300(0.3466) Steps 814(846.34) | Grad Norm 3.5251(5.7984) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 99.9792, Epoch Time 1290.7832(1040.0921), Bit/dim 3.9311(best: 3.9449), Xent 1.0580, Loss 4.4601, Error 0.3781(best: 0.3869)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 21.0265(21.2845) | Bit/dim 3.9307(3.9450) | Xent 1.0156(0.9703) | Loss 4.4385(4.4302) | Error 0.3667(0.3440) Steps 820(844.26) | Grad Norm 7.4586(5.6575) | Total Time 14.00(14.00)\n",
      "Iter 1830 | Time 20.8739(21.2748) | Bit/dim 3.9423(3.9416) | Xent 0.9971(0.9616) | Loss 4.4408(4.4224) | Error 0.3656(0.3409) Steps 844(843.17) | Grad Norm 13.4041(6.0626) | Total Time 14.00(14.00)\n",
      "Iter 1840 | Time 20.7021(21.3119) | Bit/dim 3.9398(3.9389) | Xent 0.9737(0.9617) | Loss 4.4266(4.4197) | Error 0.3511(0.3418) Steps 814(840.27) | Grad Norm 3.2759(6.1003) | Total Time 14.00(14.00)\n",
      "Iter 1850 | Time 21.4431(21.3409) | Bit/dim 3.8987(3.9322) | Xent 0.8617(0.9510) | Loss 4.3296(4.4077) | Error 0.3122(0.3374) Steps 844(843.24) | Grad Norm 3.3908(5.8067) | Total Time 14.00(14.00)\n",
      "Iter 1860 | Time 20.9871(21.3651) | Bit/dim 3.9113(3.9297) | Xent 0.9947(0.9437) | Loss 4.4086(4.4016) | Error 0.3500(0.3356) Steps 856(839.72) | Grad Norm 7.1139(5.7445) | Total Time 14.00(14.00)\n",
      "Iter 1870 | Time 21.1825(21.3192) | Bit/dim 3.9086(3.9289) | Xent 0.9769(0.9400) | Loss 4.3970(4.3989) | Error 0.3478(0.3342) Steps 838(838.28) | Grad Norm 4.8849(5.8201) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 98.0992, Epoch Time 1289.3630(1047.5703), Bit/dim 3.9215(best: 3.9311), Xent 1.0142, Loss 4.4286, Error 0.3594(best: 0.3781)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 20.6507(21.2809) | Bit/dim 3.9202(3.9269) | Xent 0.9287(0.9200) | Loss 4.3846(4.3869) | Error 0.3378(0.3281) Steps 856(835.21) | Grad Norm 4.7098(5.7552) | Total Time 14.00(14.00)\n",
      "Iter 1890 | Time 21.3381(21.3656) | Bit/dim 3.9020(3.9253) | Xent 0.9420(0.9226) | Loss 4.3730(4.3866) | Error 0.3289(0.3285) Steps 832(837.89) | Grad Norm 4.5259(5.9005) | Total Time 14.00(14.00)\n",
      "Iter 1900 | Time 21.4689(21.2860) | Bit/dim 3.9539(3.9249) | Xent 0.8312(0.9173) | Loss 4.3695(4.3836) | Error 0.3056(0.3249) Steps 796(833.75) | Grad Norm 3.9411(5.7462) | Total Time 14.00(14.00)\n",
      "Iter 1910 | Time 20.7162(21.2872) | Bit/dim 3.9476(3.9198) | Xent 0.9216(0.9102) | Loss 4.4084(4.3749) | Error 0.3100(0.3215) Steps 808(833.32) | Grad Norm 10.3823(6.1010) | Total Time 14.00(14.00)\n",
      "Iter 1920 | Time 21.0544(21.2264) | Bit/dim 3.9317(3.9184) | Xent 0.9349(0.9180) | Loss 4.3992(4.3774) | Error 0.3333(0.3245) Steps 814(831.48) | Grad Norm 7.7192(6.7130) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 97.7705, Epoch Time 1281.6162(1054.5916), Bit/dim 3.9142(best: 3.9215), Xent 1.0206, Loss 4.4245, Error 0.3609(best: 0.3594)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 21.7265(21.1298) | Bit/dim 3.9661(3.9171) | Xent 0.8455(0.9110) | Loss 4.3889(4.3726) | Error 0.2989(0.3222) Steps 850(830.70) | Grad Norm 6.5765(6.6269) | Total Time 14.00(14.00)\n",
      "Iter 1940 | Time 20.9642(21.2666) | Bit/dim 3.9103(3.9135) | Xent 0.8611(0.9027) | Loss 4.3408(4.3648) | Error 0.3189(0.3191) Steps 850(834.34) | Grad Norm 3.9679(6.5651) | Total Time 14.00(14.00)\n",
      "Iter 1950 | Time 21.0935(21.1844) | Bit/dim 3.8879(3.9091) | Xent 0.8700(0.8950) | Loss 4.3229(4.3566) | Error 0.3056(0.3162) Steps 844(833.32) | Grad Norm 5.4450(6.2097) | Total Time 14.00(14.00)\n",
      "Iter 1960 | Time 21.3314(21.3169) | Bit/dim 3.9319(3.9096) | Xent 0.8272(0.8821) | Loss 4.3455(4.3506) | Error 0.2967(0.3107) Steps 838(834.05) | Grad Norm 6.1829(5.9125) | Total Time 14.00(14.00)\n",
      "Iter 1970 | Time 21.1472(21.3049) | Bit/dim 3.9184(3.9050) | Xent 0.8598(0.8839) | Loss 4.3483(4.3469) | Error 0.2978(0.3123) Steps 832(836.41) | Grad Norm 8.4225(6.3439) | Total Time 14.00(14.00)\n",
      "Iter 1980 | Time 21.5550(21.3459) | Bit/dim 3.9320(3.9060) | Xent 0.8940(0.8802) | Loss 4.3790(4.3461) | Error 0.3122(0.3113) Steps 850(837.74) | Grad Norm 3.9585(6.3673) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 97.3045, Epoch Time 1290.4024(1061.6660), Bit/dim 3.9042(best: 3.9142), Xent 1.0145, Loss 4.4115, Error 0.3590(best: 0.3594)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 20.9334(21.2637) | Bit/dim 3.8898(3.9032) | Xent 0.8642(0.8708) | Loss 4.3219(4.3386) | Error 0.2989(0.3086) Steps 838(835.83) | Grad Norm 5.6886(6.0827) | Total Time 14.00(14.00)\n",
      "Iter 2000 | Time 21.2604(21.2546) | Bit/dim 3.9103(3.9018) | Xent 0.9229(0.8644) | Loss 4.3717(4.3340) | Error 0.3378(0.3067) Steps 850(836.23) | Grad Norm 5.8772(6.1159) | Total Time 14.00(14.00)\n",
      "Iter 2010 | Time 21.2738(21.3266) | Bit/dim 3.8923(3.9000) | Xent 0.7985(0.8597) | Loss 4.2916(4.3298) | Error 0.2944(0.3044) Steps 850(838.06) | Grad Norm 4.8810(5.6461) | Total Time 14.00(14.00)\n",
      "Iter 2020 | Time 21.6523(21.3717) | Bit/dim 3.8771(3.8959) | Xent 0.8858(0.8519) | Loss 4.3200(4.3219) | Error 0.3200(0.3022) Steps 850(836.14) | Grad Norm 8.8310(5.6263) | Total Time 14.00(14.00)\n",
      "Iter 2030 | Time 21.8061(21.2922) | Bit/dim 3.9181(3.8959) | Xent 0.8100(0.8538) | Loss 4.3231(4.3228) | Error 0.2889(0.3031) Steps 802(832.46) | Grad Norm 6.4085(5.8891) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 96.7395, Epoch Time 1283.0624(1068.3079), Bit/dim 3.8862(best: 3.9042), Xent 1.0001, Loss 4.3862, Error 0.3449(best: 0.3590)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 20.3920(21.2376) | Bit/dim 3.9065(3.8954) | Xent 0.8018(0.8412) | Loss 4.3074(4.3160) | Error 0.2833(0.2988) Steps 832(831.49) | Grad Norm 3.7173(5.8111) | Total Time 14.00(14.00)\n",
      "Iter 2050 | Time 21.2438(21.1878) | Bit/dim 3.8727(3.8927) | Xent 0.8306(0.8309) | Loss 4.2880(4.3082) | Error 0.2956(0.2943) Steps 844(831.84) | Grad Norm 7.4818(5.9359) | Total Time 14.00(14.00)\n",
      "Iter 2060 | Time 20.8769(21.1919) | Bit/dim 3.8779(3.8886) | Xent 0.8593(0.8287) | Loss 4.3076(4.3029) | Error 0.3078(0.2944) Steps 820(832.96) | Grad Norm 8.1899(6.0053) | Total Time 14.00(14.00)\n",
      "Iter 2070 | Time 22.2344(21.2393) | Bit/dim 3.8825(3.8925) | Xent 0.8521(0.8256) | Loss 4.3086(4.3053) | Error 0.2711(0.2935) Steps 850(833.37) | Grad Norm 7.4963(5.8124) | Total Time 14.00(14.00)\n",
      "Iter 2080 | Time 20.9579(21.2025) | Bit/dim 3.8758(3.8879) | Xent 0.8186(0.8244) | Loss 4.2851(4.3001) | Error 0.2922(0.2926) Steps 832(834.88) | Grad Norm 6.2784(5.7837) | Total Time 14.00(14.00)\n",
      "Iter 2090 | Time 21.0988(21.3380) | Bit/dim 3.9077(3.8869) | Xent 0.7976(0.8241) | Loss 4.3065(4.2990) | Error 0.2833(0.2928) Steps 862(836.89) | Grad Norm 4.4667(5.9678) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 98.0981, Epoch Time 1287.0922(1074.8714), Bit/dim 3.8830(best: 3.8862), Xent 1.0084, Loss 4.3872, Error 0.3473(best: 0.3449)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 20.8904(21.2626) | Bit/dim 3.9020(3.8867) | Xent 0.7435(0.8081) | Loss 4.2738(4.2908) | Error 0.2711(0.2855) Steps 844(836.23) | Grad Norm 4.8268(5.7778) | Total Time 14.00(14.00)\n",
      "Iter 2110 | Time 21.8049(21.2796) | Bit/dim 3.8547(3.8826) | Xent 0.8247(0.8049) | Loss 4.2670(4.2851) | Error 0.2811(0.2844) Steps 874(837.32) | Grad Norm 7.9763(5.6894) | Total Time 14.00(14.00)\n",
      "Iter 2120 | Time 20.7065(21.2803) | Bit/dim 3.8843(3.8818) | Xent 0.7549(0.8015) | Loss 4.2617(4.2826) | Error 0.2733(0.2834) Steps 832(837.27) | Grad Norm 3.6138(5.8032) | Total Time 14.00(14.00)\n",
      "Iter 2130 | Time 21.4219(21.2272) | Bit/dim 3.8568(3.8777) | Xent 0.7737(0.8033) | Loss 4.2437(4.2793) | Error 0.2711(0.2812) Steps 844(839.20) | Grad Norm 7.3429(6.4463) | Total Time 14.00(14.00)\n",
      "Iter 2140 | Time 21.1479(21.1968) | Bit/dim 3.8884(3.8787) | Xent 0.8009(0.8082) | Loss 4.2888(4.2828) | Error 0.3000(0.2846) Steps 826(837.83) | Grad Norm 4.5982(6.4448) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 96.6548, Epoch Time 1278.7130(1080.9866), Bit/dim 3.8714(best: 3.8830), Xent 1.0000, Loss 4.3714, Error 0.3424(best: 0.3449)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 21.1579(21.1598) | Bit/dim 3.8668(3.8785) | Xent 0.7694(0.7982) | Loss 4.2515(4.2776) | Error 0.2756(0.2825) Steps 820(835.25) | Grad Norm 7.9386(6.4480) | Total Time 14.00(14.00)\n",
      "Iter 2160 | Time 21.0386(21.2021) | Bit/dim 3.8868(3.8770) | Xent 0.7375(0.7774) | Loss 4.2556(4.2657) | Error 0.2567(0.2766) Steps 826(835.70) | Grad Norm 8.1044(6.3451) | Total Time 14.00(14.00)\n",
      "Iter 2170 | Time 20.8088(21.1496) | Bit/dim 3.8744(3.8738) | Xent 0.7749(0.7740) | Loss 4.2618(4.2608) | Error 0.2778(0.2751) Steps 838(834.09) | Grad Norm 6.8350(6.2973) | Total Time 14.00(14.00)\n",
      "Iter 2180 | Time 20.9921(21.1277) | Bit/dim 3.8901(3.8731) | Xent 0.7104(0.7637) | Loss 4.2453(4.2550) | Error 0.2622(0.2716) Steps 838(831.50) | Grad Norm 4.5308(5.9047) | Total Time 14.00(14.00)\n",
      "Iter 2190 | Time 21.2709(21.1393) | Bit/dim 3.8472(3.8679) | Xent 0.8143(0.7653) | Loss 4.2543(4.2505) | Error 0.2944(0.2716) Steps 826(831.78) | Grad Norm 4.4885(5.6845) | Total Time 14.00(14.00)\n",
      "Iter 2200 | Time 20.7653(21.0961) | Bit/dim 3.8503(3.8667) | Xent 0.7729(0.7649) | Loss 4.2368(4.2492) | Error 0.2689(0.2721) Steps 826(831.48) | Grad Norm 8.1424(5.9706) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 97.5510, Epoch Time 1276.0509(1086.8386), Bit/dim 3.8808(best: 3.8714), Xent 1.0539, Loss 4.4078, Error 0.3502(best: 0.3424)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 21.6891(21.1109) | Bit/dim 3.8714(3.8665) | Xent 0.7268(0.7497) | Loss 4.2348(4.2413) | Error 0.2622(0.2670) Steps 826(828.29) | Grad Norm 7.7932(6.0792) | Total Time 14.00(14.00)\n",
      "Iter 2220 | Time 21.4397(21.1828) | Bit/dim 3.8852(3.8659) | Xent 0.8080(0.7467) | Loss 4.2892(4.2392) | Error 0.2656(0.2653) Steps 844(828.30) | Grad Norm 9.8897(6.1821) | Total Time 14.00(14.00)\n",
      "Iter 2230 | Time 22.1965(21.2980) | Bit/dim 3.8406(3.8640) | Xent 0.6918(0.7517) | Loss 4.1865(4.2399) | Error 0.2522(0.2670) Steps 838(830.27) | Grad Norm 4.8867(6.3429) | Total Time 14.00(14.00)\n",
      "Iter 2240 | Time 21.6589(21.2931) | Bit/dim 3.8106(3.8620) | Xent 0.7438(0.7441) | Loss 4.1825(4.2340) | Error 0.2767(0.2646) Steps 832(831.80) | Grad Norm 4.4214(6.4271) | Total Time 14.00(14.00)\n",
      "Iter 2250 | Time 20.5898(21.2836) | Bit/dim 3.8804(3.8623) | Xent 0.7444(0.7471) | Loss 4.2527(4.2358) | Error 0.2478(0.2641) Steps 844(832.74) | Grad Norm 4.4969(6.5598) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 98.3512, Epoch Time 1289.3089(1092.9127), Bit/dim 3.8644(best: 3.8714), Xent 1.0097, Loss 4.3693, Error 0.3419(best: 0.3424)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 21.8566(21.2754) | Bit/dim 3.8669(3.8607) | Xent 0.6692(0.7340) | Loss 4.2015(4.2277) | Error 0.2400(0.2599) Steps 832(835.71) | Grad Norm 4.0633(6.1804) | Total Time 14.00(14.00)\n",
      "Iter 2270 | Time 21.2310(21.2207) | Bit/dim 3.8561(3.8593) | Xent 0.6492(0.7120) | Loss 4.1807(4.2153) | Error 0.2344(0.2517) Steps 850(835.06) | Grad Norm 4.2285(5.7858) | Total Time 14.00(14.00)\n",
      "Iter 2280 | Time 20.6529(21.2038) | Bit/dim 3.8619(3.8571) | Xent 0.7068(0.7190) | Loss 4.2153(4.2166) | Error 0.2544(0.2552) Steps 814(833.72) | Grad Norm 6.8658(5.8007) | Total Time 14.00(14.00)\n",
      "Iter 2290 | Time 20.5979(21.2253) | Bit/dim 3.8406(3.8569) | Xent 0.7759(0.7188) | Loss 4.2286(4.2163) | Error 0.2622(0.2543) Steps 832(834.20) | Grad Norm 5.4095(5.7833) | Total Time 14.00(14.00)\n",
      "Iter 2300 | Time 21.7743(21.2260) | Bit/dim 3.8250(3.8540) | Xent 0.6664(0.7122) | Loss 4.1582(4.2101) | Error 0.2400(0.2518) Steps 820(833.43) | Grad Norm 3.9474(5.4183) | Total Time 14.00(14.00)\n",
      "Iter 2310 | Time 21.0717(21.2141) | Bit/dim 3.8249(3.8521) | Xent 0.7058(0.7078) | Loss 4.1778(4.2060) | Error 0.2489(0.2507) Steps 820(834.32) | Grad Norm 4.4339(5.2802) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 97.9581, Epoch Time 1281.5509(1098.5718), Bit/dim 3.8457(best: 3.8644), Xent 1.0115, Loss 4.3515, Error 0.3401(best: 0.3419)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 20.9672(21.1945) | Bit/dim 3.8501(3.8482) | Xent 0.6009(0.6867) | Loss 4.1505(4.1916) | Error 0.2100(0.2436) Steps 832(835.20) | Grad Norm 4.2660(5.0735) | Total Time 14.00(14.00)\n",
      "Iter 2330 | Time 20.9565(21.2289) | Bit/dim 3.8274(3.8473) | Xent 0.6106(0.6743) | Loss 4.1327(4.1845) | Error 0.2089(0.2391) Steps 832(835.73) | Grad Norm 4.4845(5.1732) | Total Time 14.00(14.00)\n",
      "Iter 2340 | Time 20.5100(21.1767) | Bit/dim 3.8346(3.8454) | Xent 0.6846(0.6711) | Loss 4.1769(4.1809) | Error 0.2456(0.2387) Steps 826(833.14) | Grad Norm 4.3335(4.9415) | Total Time 14.00(14.00)\n",
      "Iter 2350 | Time 20.5383(21.0872) | Bit/dim 3.8365(3.8450) | Xent 0.6028(0.6663) | Loss 4.1379(4.1781) | Error 0.2256(0.2387) Steps 844(832.90) | Grad Norm 5.7219(5.1339) | Total Time 14.00(14.00)\n",
      "Iter 2360 | Time 21.2408(21.0415) | Bit/dim 3.8316(3.8442) | Xent 0.7580(0.6789) | Loss 4.2106(4.1836) | Error 0.2811(0.2427) Steps 850(833.58) | Grad Norm 6.3945(5.3502) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 97.5334, Epoch Time 1273.8117(1103.8290), Bit/dim 3.8465(best: 3.8457), Xent 1.0527, Loss 4.3729, Error 0.3472(best: 0.3401)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 21.2536(21.0476) | Bit/dim 3.8416(3.8413) | Xent 0.5344(0.6746) | Loss 4.1088(4.1787) | Error 0.1989(0.2419) Steps 802(831.76) | Grad Norm 3.8716(5.3365) | Total Time 14.00(14.00)\n",
      "Iter 2380 | Time 21.3585(21.0062) | Bit/dim 3.8426(3.8413) | Xent 0.6663(0.6570) | Loss 4.1757(4.1698) | Error 0.2344(0.2347) Steps 838(831.14) | Grad Norm 5.7494(5.4699) | Total Time 14.00(14.00)\n",
      "Iter 2390 | Time 20.7618(21.0602) | Bit/dim 3.8218(3.8372) | Xent 0.7494(0.6616) | Loss 4.1966(4.1680) | Error 0.2500(0.2363) Steps 826(831.86) | Grad Norm 5.7543(5.5744) | Total Time 14.00(14.00)\n",
      "Iter 2400 | Time 21.1791(21.0718) | Bit/dim 3.8612(3.8398) | Xent 0.6511(0.6600) | Loss 4.1868(4.1698) | Error 0.2311(0.2354) Steps 826(831.43) | Grad Norm 5.9509(5.8275) | Total Time 14.00(14.00)\n",
      "Iter 2410 | Time 21.0170(20.9796) | Bit/dim 3.8215(3.8375) | Xent 0.6013(0.6565) | Loss 4.1222(4.1657) | Error 0.2200(0.2344) Steps 814(826.44) | Grad Norm 4.6306(5.5736) | Total Time 14.00(14.00)\n",
      "Iter 2420 | Time 20.8016(20.9794) | Bit/dim 3.8567(3.8385) | Xent 0.7489(0.6616) | Loss 4.2312(4.1693) | Error 0.2778(0.2369) Steps 844(825.65) | Grad Norm 7.2892(5.7163) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 98.9179, Epoch Time 1271.2605(1108.8520), Bit/dim 3.8527(best: 3.8457), Xent 1.0199, Loss 4.3626, Error 0.3354(best: 0.3401)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 21.1355(21.0192) | Bit/dim 3.8301(3.8407) | Xent 0.5902(0.6508) | Loss 4.1252(4.1661) | Error 0.2178(0.2327) Steps 838(828.37) | Grad Norm 10.1771(6.0370) | Total Time 14.00(14.00)\n",
      "Iter 2440 | Time 21.4629(21.0868) | Bit/dim 3.8260(3.8403) | Xent 0.6322(0.6369) | Loss 4.1421(4.1587) | Error 0.2189(0.2278) Steps 832(828.49) | Grad Norm 5.8680(6.0942) | Total Time 14.00(14.00)\n",
      "Iter 2450 | Time 20.6758(21.1755) | Bit/dim 3.8374(3.8413) | Xent 0.5910(0.6411) | Loss 4.1329(4.1619) | Error 0.2111(0.2290) Steps 826(829.71) | Grad Norm 7.9502(6.8277) | Total Time 14.00(14.00)\n",
      "Iter 2460 | Time 21.0921(21.0991) | Bit/dim 3.8231(3.8396) | Xent 0.6159(0.6464) | Loss 4.1311(4.1628) | Error 0.2144(0.2303) Steps 832(826.00) | Grad Norm 4.3899(6.5489) | Total Time 14.00(14.00)\n",
      "Iter 2470 | Time 20.9874(21.0539) | Bit/dim 3.8159(3.8369) | Xent 0.5773(0.6364) | Loss 4.1045(4.1550) | Error 0.1978(0.2271) Steps 814(824.77) | Grad Norm 3.5201(5.8709) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 98.0707, Epoch Time 1277.3833(1113.9079), Bit/dim 3.8280(best: 3.8457), Xent 1.0474, Loss 4.3518, Error 0.3407(best: 0.3354)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 21.4461(21.0375) | Bit/dim 3.8272(3.8326) | Xent 0.4853(0.6298) | Loss 4.0699(4.1475) | Error 0.1722(0.2245) Steps 832(823.38) | Grad Norm 3.4474(5.7574) | Total Time 14.00(14.00)\n",
      "Iter 2490 | Time 21.1488(21.0730) | Bit/dim 3.8241(3.8332) | Xent 0.5429(0.6148) | Loss 4.0955(4.1406) | Error 0.1844(0.2181) Steps 832(825.30) | Grad Norm 6.7572(5.7513) | Total Time 14.00(14.00)\n",
      "Iter 2500 | Time 21.1160(21.0489) | Bit/dim 3.8260(3.8291) | Xent 0.5505(0.6033) | Loss 4.1013(4.1307) | Error 0.2067(0.2150) Steps 832(826.86) | Grad Norm 5.3949(5.6912) | Total Time 14.00(14.00)\n",
      "Iter 2510 | Time 21.1579(21.0048) | Bit/dim 3.8213(3.8289) | Xent 0.6026(0.6019) | Loss 4.1226(4.1298) | Error 0.2156(0.2142) Steps 808(826.52) | Grad Norm 6.4481(5.8802) | Total Time 14.00(14.00)\n",
      "Iter 2520 | Time 20.5760(20.9430) | Bit/dim 3.8071(3.8254) | Xent 0.6003(0.6072) | Loss 4.1073(4.1290) | Error 0.2211(0.2155) Steps 814(825.39) | Grad Norm 7.2358(6.1278) | Total Time 14.00(14.00)\n",
      "Iter 2530 | Time 21.1844(20.9575) | Bit/dim 3.8522(3.8274) | Xent 0.5972(0.6102) | Loss 4.1508(4.1325) | Error 0.2200(0.2177) Steps 844(825.99) | Grad Norm 5.7898(6.3013) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 98.3927, Epoch Time 1269.6166(1118.5792), Bit/dim 3.8370(best: 3.8280), Xent 1.0697, Loss 4.3719, Error 0.3389(best: 0.3354)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 20.9545(20.9883) | Bit/dim 3.8446(3.8283) | Xent 0.5338(0.5901) | Loss 4.1115(4.1234) | Error 0.1800(0.2105) Steps 832(827.18) | Grad Norm 3.2557(5.9988) | Total Time 14.00(14.00)\n",
      "Iter 2550 | Time 21.0904(21.0328) | Bit/dim 3.7917(3.8270) | Xent 0.6207(0.5826) | Loss 4.1020(4.1183) | Error 0.2111(0.2074) Steps 832(827.66) | Grad Norm 4.8260(5.8125) | Total Time 14.00(14.00)\n",
      "Iter 2560 | Time 20.9948(20.9225) | Bit/dim 3.7883(3.8218) | Xent 0.4995(0.5718) | Loss 4.0380(4.1076) | Error 0.1800(0.2040) Steps 814(823.26) | Grad Norm 5.6616(5.5006) | Total Time 14.00(14.00)\n",
      "Iter 2570 | Time 21.1428(20.8380) | Bit/dim 3.8336(3.8216) | Xent 0.5788(0.5848) | Loss 4.1230(4.1140) | Error 0.2044(0.2101) Steps 826(822.98) | Grad Norm 4.7909(5.9933) | Total Time 14.00(14.00)\n",
      "Iter 2580 | Time 20.8151(20.8436) | Bit/dim 3.8087(3.8204) | Xent 0.6049(0.5836) | Loss 4.1112(4.1122) | Error 0.2122(0.2089) Steps 808(821.79) | Grad Norm 6.5026(5.7692) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 98.2700, Epoch Time 1263.7061(1122.9330), Bit/dim 3.8230(best: 3.8280), Xent 1.1205, Loss 4.3833, Error 0.3395(best: 0.3354)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 19.8227(20.7867) | Bit/dim 3.8151(3.8181) | Xent 0.5571(0.5862) | Loss 4.0937(4.1112) | Error 0.2044(0.2093) Steps 820(821.93) | Grad Norm 4.4984(6.2091) | Total Time 14.00(14.00)\n",
      "Iter 2600 | Time 21.2382(20.9037) | Bit/dim 3.8153(3.8207) | Xent 0.4771(0.5750) | Loss 4.0538(4.1082) | Error 0.1656(0.2049) Steps 820(824.08) | Grad Norm 3.7814(6.1362) | Total Time 14.00(14.00)\n",
      "Iter 2610 | Time 20.7884(20.9545) | Bit/dim 3.8242(3.8196) | Xent 0.4810(0.5610) | Loss 4.0648(4.1001) | Error 0.1711(0.1996) Steps 826(823.86) | Grad Norm 6.9728(5.8822) | Total Time 14.00(14.00)\n",
      "Iter 2620 | Time 21.0130(20.9134) | Bit/dim 3.8177(3.8188) | Xent 0.5334(0.5573) | Loss 4.0844(4.0975) | Error 0.1878(0.1971) Steps 826(823.00) | Grad Norm 4.2629(5.6987) | Total Time 14.00(14.00)\n",
      "Iter 2630 | Time 21.3418(20.9428) | Bit/dim 3.8181(3.8156) | Xent 0.5093(0.5519) | Loss 4.0728(4.0916) | Error 0.1756(0.1950) Steps 850(823.11) | Grad Norm 7.0872(6.0035) | Total Time 14.00(14.00)\n",
      "Iter 2640 | Time 20.4561(20.8651) | Bit/dim 3.8245(3.8151) | Xent 0.5343(0.5507) | Loss 4.0916(4.0905) | Error 0.2011(0.1952) Steps 820(822.27) | Grad Norm 4.1481(6.1755) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 97.8139, Epoch Time 1266.1140(1127.2284), Bit/dim 3.8154(best: 3.8230), Xent 1.0888, Loss 4.3598, Error 0.3385(best: 0.3354)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 20.8985(20.8939) | Bit/dim 3.8285(3.8133) | Xent 0.4857(0.5376) | Loss 4.0714(4.0820) | Error 0.1678(0.1899) Steps 820(821.45) | Grad Norm 7.6494(6.0330) | Total Time 14.00(14.00)\n",
      "Iter 2660 | Time 20.6692(20.8207) | Bit/dim 3.8593(3.8121) | Xent 0.5027(0.5246) | Loss 4.1107(4.0744) | Error 0.1633(0.1860) Steps 826(823.61) | Grad Norm 4.2063(5.4803) | Total Time 14.00(14.00)\n",
      "Iter 2670 | Time 20.5840(20.8686) | Bit/dim 3.7992(3.8128) | Xent 0.5982(0.5367) | Loss 4.0983(4.0812) | Error 0.1933(0.1901) Steps 838(824.09) | Grad Norm 5.8998(6.0361) | Total Time 14.00(14.00)\n",
      "Iter 2680 | Time 21.1400(20.9037) | Bit/dim 3.8207(3.8165) | Xent 0.5070(0.5372) | Loss 4.0742(4.0851) | Error 0.1778(0.1910) Steps 850(826.38) | Grad Norm 4.0400(6.0722) | Total Time 14.00(14.00)\n",
      "Iter 2690 | Time 20.0952(20.8423) | Bit/dim 3.7670(3.8133) | Xent 0.4823(0.5295) | Loss 4.0082(4.0780) | Error 0.1689(0.1873) Steps 826(825.11) | Grad Norm 4.3996(5.8182) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 98.4474, Epoch Time 1263.3391(1131.3117), Bit/dim 3.8186(best: 3.8154), Xent 1.1430, Loss 4.3901, Error 0.3389(best: 0.3354)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 20.9288(20.8170) | Bit/dim 3.7891(3.8141) | Xent 0.4859(0.5280) | Loss 4.0321(4.0781) | Error 0.1656(0.1859) Steps 808(824.91) | Grad Norm 6.7635(5.9953) | Total Time 14.00(14.00)\n",
      "Iter 2710 | Time 20.1395(20.8440) | Bit/dim 3.7691(3.8143) | Xent 0.4874(0.5207) | Loss 4.0128(4.0747) | Error 0.1756(0.1837) Steps 814(825.21) | Grad Norm 5.8484(5.9982) | Total Time 14.00(14.00)\n",
      "Iter 2720 | Time 21.4632(20.8903) | Bit/dim 3.7787(3.8124) | Xent 0.4967(0.5149) | Loss 4.0270(4.0699) | Error 0.1722(0.1827) Steps 850(826.37) | Grad Norm 3.4629(5.6850) | Total Time 14.00(14.00)\n",
      "Iter 2730 | Time 20.9330(20.9374) | Bit/dim 3.8329(3.8105) | Xent 0.4851(0.5064) | Loss 4.0754(4.0638) | Error 0.1633(0.1793) Steps 826(826.81) | Grad Norm 4.9743(5.5295) | Total Time 14.00(14.00)\n",
      "Iter 2740 | Time 21.0133(20.9591) | Bit/dim 3.8120(3.8080) | Xent 0.5045(0.5027) | Loss 4.0642(4.0594) | Error 0.1678(0.1779) Steps 832(828.18) | Grad Norm 5.1027(5.2870) | Total Time 14.00(14.00)\n",
      "Iter 2750 | Time 21.7392(20.9981) | Bit/dim 3.7869(3.8065) | Xent 0.5141(0.5032) | Loss 4.0439(4.0581) | Error 0.1767(0.1788) Steps 856(833.16) | Grad Norm 4.7367(5.3595) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 98.6741, Epoch Time 1271.3951(1135.5142), Bit/dim 3.8041(best: 3.8154), Xent 1.1219, Loss 4.3651, Error 0.3418(best: 0.3354)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 20.2127(20.9276) | Bit/dim 3.8247(3.8048) | Xent 0.5347(0.4937) | Loss 4.0921(4.0516) | Error 0.2122(0.1755) Steps 814(830.93) | Grad Norm 11.7306(5.9561) | Total Time 14.00(14.00)\n",
      "Iter 2770 | Time 21.4259(20.8808) | Bit/dim 3.8628(3.8059) | Xent 0.5700(0.4987) | Loss 4.1478(4.0552) | Error 0.1900(0.1770) Steps 832(829.62) | Grad Norm 7.8822(6.3458) | Total Time 14.00(14.00)\n",
      "Iter 2780 | Time 21.1354(20.8898) | Bit/dim 3.7979(3.8036) | Xent 0.5198(0.4924) | Loss 4.0578(4.0498) | Error 0.1844(0.1740) Steps 862(830.69) | Grad Norm 6.7093(6.1264) | Total Time 14.00(14.00)\n",
      "Iter 2790 | Time 20.7714(20.9266) | Bit/dim 3.8656(3.8025) | Xent 0.4556(0.4915) | Loss 4.0934(4.0483) | Error 0.1589(0.1739) Steps 838(828.43) | Grad Norm 4.6555(6.0440) | Total Time 14.00(14.00)\n",
      "Iter 2800 | Time 21.6051(20.9342) | Bit/dim 3.7824(3.8028) | Xent 0.5324(0.4942) | Loss 4.0486(4.0499) | Error 0.1933(0.1753) Steps 820(828.50) | Grad Norm 4.6219(6.0162) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 99.1041, Epoch Time 1265.7696(1139.4219), Bit/dim 3.8029(best: 3.8041), Xent 1.1099, Loss 4.3579, Error 0.3325(best: 0.3354)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 20.7471(20.9035) | Bit/dim 3.7880(3.8026) | Xent 0.3978(0.4821) | Loss 3.9869(4.0436) | Error 0.1356(0.1705) Steps 820(828.64) | Grad Norm 3.9889(5.6128) | Total Time 14.00(14.00)\n",
      "Iter 2820 | Time 20.8420(20.8579) | Bit/dim 3.7641(3.7992) | Xent 0.4261(0.4653) | Loss 3.9772(4.0319) | Error 0.1500(0.1643) Steps 826(826.53) | Grad Norm 4.9477(5.6784) | Total Time 14.00(14.00)\n",
      "Iter 2830 | Time 20.8270(20.7956) | Bit/dim 3.7974(3.7978) | Xent 0.4328(0.4600) | Loss 4.0138(4.0278) | Error 0.1578(0.1621) Steps 844(826.85) | Grad Norm 6.4011(5.6150) | Total Time 14.00(14.00)\n",
      "Iter 2840 | Time 20.9166(20.8163) | Bit/dim 3.7957(3.7958) | Xent 0.5202(0.4596) | Loss 4.0559(4.0257) | Error 0.1878(0.1633) Steps 814(826.69) | Grad Norm 10.2017(5.8083) | Total Time 14.00(14.00)\n",
      "Iter 2850 | Time 20.7737(20.8804) | Bit/dim 3.7747(3.7977) | Xent 0.4235(0.4628) | Loss 3.9865(4.0291) | Error 0.1444(0.1645) Steps 838(829.13) | Grad Norm 4.4184(5.9216) | Total Time 14.00(14.00)\n",
      "Iter 2860 | Time 20.7287(20.8897) | Bit/dim 3.7990(3.7965) | Xent 0.4798(0.4701) | Loss 4.0389(4.0315) | Error 0.1767(0.1673) Steps 838(831.79) | Grad Norm 4.6393(5.8852) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 99.6928, Epoch Time 1262.8027(1143.1233), Bit/dim 3.8000(best: 3.8029), Xent 1.2028, Loss 4.4015, Error 0.3433(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 20.7745(20.8936) | Bit/dim 3.7996(3.7965) | Xent 0.4694(0.4653) | Loss 4.0342(4.0291) | Error 0.1644(0.1654) Steps 838(832.72) | Grad Norm 4.5127(5.9081) | Total Time 14.00(14.00)\n",
      "Iter 2880 | Time 20.9299(20.9269) | Bit/dim 3.8092(3.7956) | Xent 0.4507(0.4607) | Loss 4.0346(4.0260) | Error 0.1478(0.1647) Steps 826(833.67) | Grad Norm 4.1842(5.7255) | Total Time 14.00(14.00)\n",
      "Iter 2890 | Time 20.9110(20.9467) | Bit/dim 3.7735(3.7970) | Xent 0.3906(0.4490) | Loss 3.9687(4.0215) | Error 0.1467(0.1607) Steps 844(833.27) | Grad Norm 7.1086(5.6972) | Total Time 14.00(14.00)\n",
      "Iter 2900 | Time 21.5225(20.9205) | Bit/dim 3.7833(3.7944) | Xent 0.4626(0.4441) | Loss 4.0146(4.0164) | Error 0.1722(0.1596) Steps 850(834.47) | Grad Norm 7.0234(5.4739) | Total Time 14.00(14.00)\n",
      "Iter 2910 | Time 20.3348(20.9020) | Bit/dim 3.7918(3.7935) | Xent 0.4388(0.4453) | Loss 4.0112(4.0162) | Error 0.1444(0.1584) Steps 844(836.04) | Grad Norm 5.3111(5.5370) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 99.3515, Epoch Time 1269.3734(1146.9108), Bit/dim 3.7952(best: 3.8000), Xent 1.2290, Loss 4.4097, Error 0.3430(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 21.1584(20.9592) | Bit/dim 3.7878(3.7904) | Xent 0.3802(0.4392) | Loss 3.9779(4.0100) | Error 0.1322(0.1571) Steps 838(837.66) | Grad Norm 6.5759(5.4831) | Total Time 14.00(14.00)\n",
      "Iter 2930 | Time 21.1363(20.9471) | Bit/dim 3.7585(3.7883) | Xent 0.4557(0.4300) | Loss 3.9864(4.0033) | Error 0.1733(0.1536) Steps 832(833.59) | Grad Norm 10.6096(5.6358) | Total Time 14.00(14.00)\n",
      "Iter 2940 | Time 20.9318(20.9521) | Bit/dim 3.7941(3.7903) | Xent 0.4286(0.4328) | Loss 4.0084(4.0067) | Error 0.1533(0.1545) Steps 814(831.52) | Grad Norm 4.1639(6.0195) | Total Time 14.00(14.00)\n",
      "Iter 2950 | Time 20.9196(20.9837) | Bit/dim 3.8124(3.7934) | Xent 0.4230(0.4424) | Loss 4.0239(4.0146) | Error 0.1378(0.1574) Steps 820(832.88) | Grad Norm 3.2455(6.4693) | Total Time 14.00(14.00)\n",
      "Iter 2960 | Time 20.0156(21.0030) | Bit/dim 3.8019(3.7940) | Xent 0.4752(0.4499) | Loss 4.0395(4.0189) | Error 0.1656(0.1597) Steps 832(832.63) | Grad Norm 4.8903(6.5039) | Total Time 14.00(14.00)\n",
      "Iter 2970 | Time 20.7346(20.9899) | Bit/dim 3.7998(3.7916) | Xent 0.4110(0.4497) | Loss 4.0053(4.0165) | Error 0.1500(0.1590) Steps 820(833.54) | Grad Norm 3.8087(6.3496) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 98.0814, Epoch Time 1270.9854(1150.6331), Bit/dim 3.7995(best: 3.7952), Xent 1.1947, Loss 4.3968, Error 0.3384(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 21.4392(21.0125) | Bit/dim 3.8164(3.7916) | Xent 0.3745(0.4322) | Loss 4.0036(4.0077) | Error 0.1311(0.1534) Steps 826(834.65) | Grad Norm 6.1680(5.9203) | Total Time 14.00(14.00)\n",
      "Iter 2990 | Time 21.0503(21.0491) | Bit/dim 3.7542(3.7898) | Xent 0.3614(0.4223) | Loss 3.9349(4.0009) | Error 0.1333(0.1496) Steps 838(836.42) | Grad Norm 8.9673(5.9869) | Total Time 14.00(14.00)\n",
      "Iter 3000 | Time 21.2923(21.0332) | Bit/dim 3.7719(3.7882) | Xent 0.4480(0.4202) | Loss 3.9959(3.9983) | Error 0.1556(0.1482) Steps 844(836.15) | Grad Norm 9.1385(5.9365) | Total Time 14.00(14.00)\n",
      "Iter 3010 | Time 20.3257(21.0102) | Bit/dim 3.7732(3.7901) | Xent 0.4803(0.4269) | Loss 4.0133(4.0036) | Error 0.1644(0.1508) Steps 820(837.22) | Grad Norm 5.8179(6.4159) | Total Time 14.00(14.00)\n",
      "Iter 3020 | Time 20.3912(20.9562) | Bit/dim 3.7681(3.7894) | Xent 0.4096(0.4252) | Loss 3.9729(4.0019) | Error 0.1522(0.1506) Steps 808(836.21) | Grad Norm 5.2550(6.0699) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 98.6211, Epoch Time 1272.4938(1154.2889), Bit/dim 3.7925(best: 3.7952), Xent 1.2693, Loss 4.4271, Error 0.3459(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 20.8427(20.9781) | Bit/dim 3.7282(3.7876) | Xent 0.3398(0.4153) | Loss 3.8980(3.9953) | Error 0.1244(0.1473) Steps 856(837.01) | Grad Norm 5.4360(5.9524) | Total Time 14.00(14.00)\n",
      "Iter 3040 | Time 20.7569(20.9588) | Bit/dim 3.7832(3.7892) | Xent 0.3698(0.4098) | Loss 3.9681(3.9941) | Error 0.1367(0.1451) Steps 814(835.23) | Grad Norm 3.5061(5.6712) | Total Time 14.00(14.00)\n",
      "Iter 3050 | Time 21.2815(20.9640) | Bit/dim 3.7756(3.7834) | Xent 0.3678(0.4042) | Loss 3.9595(3.9855) | Error 0.1200(0.1434) Steps 832(834.50) | Grad Norm 3.2815(5.5607) | Total Time 14.00(14.00)\n",
      "Iter 3060 | Time 20.5114(20.9790) | Bit/dim 3.7815(3.7843) | Xent 0.4051(0.3948) | Loss 3.9840(3.9817) | Error 0.1489(0.1402) Steps 826(834.34) | Grad Norm 4.7686(5.9756) | Total Time 14.00(14.00)\n",
      "Iter 3070 | Time 20.7120(20.9812) | Bit/dim 3.7628(3.7848) | Xent 0.3937(0.3948) | Loss 3.9597(3.9822) | Error 0.1433(0.1394) Steps 838(835.08) | Grad Norm 4.6044(5.6312) | Total Time 14.00(14.00)\n",
      "Iter 3080 | Time 21.2951(21.0330) | Bit/dim 3.7744(3.7831) | Xent 0.4220(0.3961) | Loss 3.9854(3.9812) | Error 0.1589(0.1389) Steps 826(836.64) | Grad Norm 4.9499(5.8066) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 99.1411, Epoch Time 1272.0426(1157.8215), Bit/dim 3.7979(best: 3.7925), Xent 1.2546, Loss 4.4252, Error 0.3490(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 21.3109(21.0540) | Bit/dim 3.7451(3.7810) | Xent 0.3491(0.3901) | Loss 3.9197(3.9760) | Error 0.1300(0.1379) Steps 850(838.09) | Grad Norm 6.4965(6.0030) | Total Time 14.00(14.00)\n",
      "Iter 3100 | Time 20.4399(21.0184) | Bit/dim 3.7987(3.7831) | Xent 0.3487(0.3743) | Loss 3.9730(3.9702) | Error 0.1289(0.1325) Steps 838(837.28) | Grad Norm 7.1220(5.7716) | Total Time 14.00(14.00)\n",
      "Iter 3110 | Time 20.9455(20.9430) | Bit/dim 3.7514(3.7810) | Xent 0.4672(0.3854) | Loss 3.9850(3.9736) | Error 0.1622(0.1355) Steps 832(837.42) | Grad Norm 6.3202(6.5462) | Total Time 14.00(14.00)\n",
      "Iter 3120 | Time 21.0848(20.9683) | Bit/dim 3.7856(3.7830) | Xent 0.4008(0.3898) | Loss 3.9860(3.9779) | Error 0.1378(0.1376) Steps 826(835.95) | Grad Norm 4.9038(6.2265) | Total Time 14.00(14.00)\n",
      "Iter 3130 | Time 20.4158(20.9609) | Bit/dim 3.7799(3.7828) | Xent 0.3825(0.3912) | Loss 3.9712(3.9784) | Error 0.1300(0.1378) Steps 838(836.76) | Grad Norm 6.0292(5.9659) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 98.4922, Epoch Time 1268.5586(1161.1436), Bit/dim 3.7819(best: 3.7925), Xent 1.3166, Loss 4.4402, Error 0.3577(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 21.4000(20.9211) | Bit/dim 3.8101(3.7804) | Xent 0.3546(0.3853) | Loss 3.9874(3.9730) | Error 0.1200(0.1360) Steps 850(839.31) | Grad Norm 6.5094(6.0332) | Total Time 14.00(14.00)\n",
      "Iter 3150 | Time 20.3009(20.9205) | Bit/dim 3.7675(3.7779) | Xent 0.2972(0.3706) | Loss 3.9161(3.9632) | Error 0.0956(0.1306) Steps 832(838.13) | Grad Norm 3.2301(5.7484) | Total Time 14.00(14.00)\n",
      "Iter 3160 | Time 21.2435(20.9962) | Bit/dim 3.7541(3.7775) | Xent 0.3729(0.3648) | Loss 3.9405(3.9599) | Error 0.1322(0.1267) Steps 826(837.41) | Grad Norm 6.0008(5.3460) | Total Time 14.00(14.00)\n",
      "Iter 3170 | Time 21.0210(20.9998) | Bit/dim 3.7626(3.7755) | Xent 0.3335(0.3611) | Loss 3.9293(3.9560) | Error 0.1111(0.1259) Steps 826(835.45) | Grad Norm 4.6850(5.4407) | Total Time 14.00(14.00)\n",
      "Iter 3180 | Time 20.9629(21.0095) | Bit/dim 3.7586(3.7751) | Xent 0.2837(0.3546) | Loss 3.9004(3.9524) | Error 0.1056(0.1248) Steps 820(833.10) | Grad Norm 4.4430(5.4255) | Total Time 14.00(14.00)\n",
      "Iter 3190 | Time 20.5644(20.9500) | Bit/dim 3.7578(3.7737) | Xent 0.2910(0.3493) | Loss 3.9033(3.9484) | Error 0.1067(0.1241) Steps 838(831.66) | Grad Norm 3.2989(5.4195) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 99.4804, Epoch Time 1271.2986(1164.4482), Bit/dim 3.7759(best: 3.7819), Xent 1.2523, Loss 4.4020, Error 0.3406(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 21.2302(21.0175) | Bit/dim 3.7472(3.7706) | Xent 0.3294(0.3399) | Loss 3.9119(3.9405) | Error 0.1189(0.1213) Steps 832(832.16) | Grad Norm 6.2464(5.3375) | Total Time 14.00(14.00)\n",
      "Iter 3210 | Time 20.8842(21.0051) | Bit/dim 3.7884(3.7712) | Xent 0.2851(0.3298) | Loss 3.9310(3.9361) | Error 0.1022(0.1174) Steps 844(832.31) | Grad Norm 4.5033(5.0436) | Total Time 14.00(14.00)\n",
      "Iter 3220 | Time 20.1353(20.9888) | Bit/dim 3.7666(3.7713) | Xent 0.3127(0.3286) | Loss 3.9229(3.9356) | Error 0.1200(0.1165) Steps 826(832.14) | Grad Norm 4.7668(5.1004) | Total Time 14.00(14.00)\n",
      "Iter 3230 | Time 22.2964(21.0905) | Bit/dim 3.7838(3.7728) | Xent 0.3473(0.3299) | Loss 3.9575(3.9378) | Error 0.1156(0.1167) Steps 880(833.89) | Grad Norm 6.9366(5.0543) | Total Time 14.00(14.00)\n",
      "Iter 3240 | Time 21.1294(21.0400) | Bit/dim 3.7973(3.7720) | Xent 0.3115(0.3319) | Loss 3.9531(3.9379) | Error 0.1089(0.1172) Steps 832(833.42) | Grad Norm 6.1947(5.1469) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 99.0135, Epoch Time 1274.6443(1167.7541), Bit/dim 3.7763(best: 3.7759), Xent 1.3348, Loss 4.4437, Error 0.3509(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 20.5314(21.0020) | Bit/dim 3.7684(3.7700) | Xent 0.2922(0.3277) | Loss 3.9145(3.9339) | Error 0.1011(0.1151) Steps 826(835.73) | Grad Norm 4.3831(5.0099) | Total Time 14.00(14.00)\n",
      "Iter 3260 | Time 21.0601(21.0486) | Bit/dim 3.7754(3.7686) | Xent 0.3312(0.3338) | Loss 3.9410(3.9355) | Error 0.1144(0.1181) Steps 850(837.75) | Grad Norm 6.8179(5.6544) | Total Time 14.00(14.00)\n",
      "Iter 3270 | Time 21.0954(21.0442) | Bit/dim 3.7524(3.7686) | Xent 0.3261(0.3283) | Loss 3.9154(3.9327) | Error 0.1200(0.1164) Steps 850(837.79) | Grad Norm 6.5113(5.5008) | Total Time 14.00(14.00)\n",
      "Iter 3280 | Time 21.5947(21.0028) | Bit/dim 3.7434(3.7670) | Xent 0.3856(0.3249) | Loss 3.9362(3.9294) | Error 0.1356(0.1147) Steps 838(837.22) | Grad Norm 6.1128(5.4074) | Total Time 14.00(14.00)\n",
      "Iter 3290 | Time 21.1359(21.0424) | Bit/dim 3.8128(3.7692) | Xent 0.3157(0.3249) | Loss 3.9706(3.9316) | Error 0.1122(0.1154) Steps 832(838.43) | Grad Norm 6.9158(5.6443) | Total Time 14.00(14.00)\n",
      "Iter 3300 | Time 20.4536(21.0059) | Bit/dim 3.7523(3.7690) | Xent 0.3341(0.3276) | Loss 3.9194(3.9328) | Error 0.1122(0.1155) Steps 838(841.86) | Grad Norm 3.7633(5.8156) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 99.3235, Epoch Time 1273.9331(1170.9395), Bit/dim 3.7726(best: 3.7759), Xent 1.2918, Loss 4.4185, Error 0.3374(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 21.1827(20.9447) | Bit/dim 3.7780(3.7690) | Xent 0.3614(0.3155) | Loss 3.9587(3.9267) | Error 0.1233(0.1106) Steps 832(839.95) | Grad Norm 6.9828(5.4581) | Total Time 14.00(14.00)\n",
      "Iter 3320 | Time 21.3838(20.9182) | Bit/dim 3.7751(3.7667) | Xent 0.3004(0.3132) | Loss 3.9253(3.9233) | Error 0.1111(0.1099) Steps 832(837.16) | Grad Norm 5.7247(5.7250) | Total Time 14.00(14.00)\n",
      "Iter 3330 | Time 20.8600(20.9710) | Bit/dim 3.7383(3.7651) | Xent 0.2522(0.3076) | Loss 3.8644(3.9189) | Error 0.0978(0.1092) Steps 850(838.46) | Grad Norm 5.9577(5.8035) | Total Time 14.00(14.00)\n",
      "Iter 3340 | Time 21.4496(20.9841) | Bit/dim 3.7550(3.7635) | Xent 0.3093(0.3075) | Loss 3.9096(3.9172) | Error 0.1022(0.1092) Steps 844(838.51) | Grad Norm 3.9356(5.6674) | Total Time 14.00(14.00)\n",
      "Iter 3350 | Time 21.0415(21.0125) | Bit/dim 3.7474(3.7629) | Xent 0.2699(0.3071) | Loss 3.8823(3.9165) | Error 0.1011(0.1094) Steps 862(838.72) | Grad Norm 5.9043(5.8762) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 99.1019, Epoch Time 1269.4780(1173.8957), Bit/dim 3.7714(best: 3.7726), Xent 1.3916, Loss 4.4672, Error 0.3420(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 21.2462(21.0278) | Bit/dim 3.7804(3.7632) | Xent 0.2556(0.3079) | Loss 3.9082(3.9172) | Error 0.0933(0.1096) Steps 862(841.70) | Grad Norm 4.2416(5.8160) | Total Time 14.00(14.00)\n",
      "Iter 3370 | Time 20.8098(21.0394) | Bit/dim 3.7885(3.7642) | Xent 0.2314(0.3060) | Loss 3.9042(3.9172) | Error 0.0867(0.1081) Steps 844(843.06) | Grad Norm 4.8111(5.8025) | Total Time 14.00(14.00)\n",
      "Iter 3380 | Time 20.9708(21.0000) | Bit/dim 3.7981(3.7622) | Xent 0.2875(0.3002) | Loss 3.9419(3.9123) | Error 0.0967(0.1056) Steps 856(842.53) | Grad Norm 4.2125(5.5964) | Total Time 14.00(14.00)\n",
      "Iter 3390 | Time 21.1775(20.9441) | Bit/dim 3.7557(3.7592) | Xent 0.3160(0.2998) | Loss 3.9137(3.9091) | Error 0.1056(0.1059) Steps 844(840.89) | Grad Norm 8.2774(5.5914) | Total Time 14.00(14.00)\n",
      "Iter 3400 | Time 20.2791(20.8690) | Bit/dim 3.7783(3.7599) | Xent 0.3686(0.3022) | Loss 3.9626(3.9110) | Error 0.1211(0.1068) Steps 838(840.49) | Grad Norm 6.1799(5.6020) | Total Time 14.00(14.00)\n",
      "Iter 3410 | Time 20.6516(20.9474) | Bit/dim 3.7410(3.7608) | Xent 0.3014(0.3017) | Loss 3.8917(3.9117) | Error 0.0967(0.1067) Steps 850(841.02) | Grad Norm 2.6976(5.6791) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 102.3095, Epoch Time 1272.5227(1176.8545), Bit/dim 3.7701(best: 3.7714), Xent 1.3346, Loss 4.4374, Error 0.3360(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 20.6961(20.9499) | Bit/dim 3.7657(3.7611) | Xent 0.2316(0.2907) | Loss 3.8815(3.9065) | Error 0.0878(0.1026) Steps 850(841.42) | Grad Norm 3.3368(5.5451) | Total Time 14.00(14.00)\n",
      "Iter 3430 | Time 20.9354(21.0272) | Bit/dim 3.7591(3.7611) | Xent 0.2630(0.2891) | Loss 3.8906(3.9056) | Error 0.0878(0.1019) Steps 820(841.39) | Grad Norm 3.8174(5.8781) | Total Time 14.00(14.00)\n",
      "Iter 3440 | Time 20.4333(20.9261) | Bit/dim 3.7703(3.7620) | Xent 0.3212(0.2902) | Loss 3.9309(3.9071) | Error 0.1000(0.1015) Steps 826(839.21) | Grad Norm 9.4785(5.9128) | Total Time 14.00(14.00)\n",
      "Iter 3450 | Time 20.9758(20.9113) | Bit/dim 3.7922(3.7621) | Xent 0.2790(0.2957) | Loss 3.9317(3.9100) | Error 0.0922(0.1037) Steps 844(838.27) | Grad Norm 5.1665(6.0372) | Total Time 14.00(14.00)\n",
      "Iter 3460 | Time 20.9827(20.9190) | Bit/dim 3.7504(3.7598) | Xent 0.2691(0.2928) | Loss 3.8850(3.9063) | Error 0.0956(0.1025) Steps 850(836.97) | Grad Norm 6.3513(5.7752) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 99.1479, Epoch Time 1268.4011(1179.6009), Bit/dim 3.7669(best: 3.7701), Xent 1.4269, Loss 4.4804, Error 0.3500(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 20.1573(20.9415) | Bit/dim 3.7854(3.7576) | Xent 0.2288(0.2861) | Loss 3.8998(3.9007) | Error 0.0878(0.1002) Steps 826(837.72) | Grad Norm 5.2167(5.5720) | Total Time 14.00(14.00)\n",
      "Iter 3480 | Time 21.7858(21.0499) | Bit/dim 3.7328(3.7583) | Xent 0.2721(0.2836) | Loss 3.8689(3.9001) | Error 0.0889(0.0996) Steps 856(838.06) | Grad Norm 5.4828(5.7547) | Total Time 14.00(14.00)\n",
      "Iter 3490 | Time 20.5643(21.0461) | Bit/dim 3.7727(3.7581) | Xent 0.2084(0.2725) | Loss 3.8768(3.8944) | Error 0.0800(0.0966) Steps 820(837.83) | Grad Norm 4.1302(5.3804) | Total Time 14.00(14.00)\n",
      "Iter 3500 | Time 20.9845(21.0326) | Bit/dim 3.7785(3.7574) | Xent 0.2518(0.2738) | Loss 3.9044(3.8943) | Error 0.0922(0.0975) Steps 850(838.19) | Grad Norm 4.7677(5.5564) | Total Time 14.00(14.00)\n",
      "Iter 3510 | Time 21.3609(21.0488) | Bit/dim 3.7326(3.7559) | Xent 0.2804(0.2810) | Loss 3.8727(3.8964) | Error 0.0956(0.0993) Steps 838(836.72) | Grad Norm 3.7648(5.4564) | Total Time 14.00(14.00)\n",
      "Iter 3520 | Time 21.4995(21.0658) | Bit/dim 3.7407(3.7542) | Xent 0.3789(0.2811) | Loss 3.9302(3.8947) | Error 0.1278(0.0991) Steps 844(834.97) | Grad Norm 6.9096(5.5117) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 97.8821, Epoch Time 1277.2063(1182.5290), Bit/dim 3.7596(best: 3.7669), Xent 1.4027, Loss 4.4609, Error 0.3436(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 21.2444(21.0125) | Bit/dim 3.7641(3.7513) | Xent 0.2538(0.2732) | Loss 3.8910(3.8879) | Error 0.0811(0.0966) Steps 814(834.40) | Grad Norm 5.1449(5.3896) | Total Time 14.00(14.00)\n",
      "Iter 3540 | Time 20.3564(20.9632) | Bit/dim 3.7542(3.7514) | Xent 0.2559(0.2707) | Loss 3.8821(3.8867) | Error 0.0956(0.0963) Steps 820(833.26) | Grad Norm 3.6920(5.5135) | Total Time 14.00(14.00)\n",
      "Iter 3550 | Time 20.7209(20.9586) | Bit/dim 3.7297(3.7525) | Xent 0.2839(0.2689) | Loss 3.8716(3.8869) | Error 0.0933(0.0951) Steps 820(832.74) | Grad Norm 5.6109(5.7495) | Total Time 14.00(14.00)\n",
      "Iter 3560 | Time 20.0278(20.9385) | Bit/dim 3.7855(3.7538) | Xent 0.2967(0.2653) | Loss 3.9339(3.8865) | Error 0.1033(0.0940) Steps 826(834.41) | Grad Norm 5.6061(5.7261) | Total Time 14.00(14.00)\n",
      "Iter 3570 | Time 21.3608(20.9308) | Bit/dim 3.7353(3.7535) | Xent 0.3097(0.2640) | Loss 3.8901(3.8855) | Error 0.1067(0.0935) Steps 826(834.48) | Grad Norm 6.3695(5.3805) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 100.3371, Epoch Time 1268.0588(1185.0949), Bit/dim 3.7583(best: 3.7596), Xent 1.4893, Loss 4.5030, Error 0.3555(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 21.2836(20.9803) | Bit/dim 3.7466(3.7515) | Xent 0.3071(0.2665) | Loss 3.9001(3.8848) | Error 0.1133(0.0944) Steps 880(834.91) | Grad Norm 4.4546(5.4498) | Total Time 14.00(14.00)\n",
      "Iter 3590 | Time 20.4932(20.9231) | Bit/dim 3.7665(3.7530) | Xent 0.3133(0.2617) | Loss 3.9232(3.8838) | Error 0.1189(0.0933) Steps 844(834.05) | Grad Norm 6.8383(5.4749) | Total Time 14.00(14.00)\n",
      "Iter 3600 | Time 21.0917(21.0502) | Bit/dim 3.7546(3.7502) | Xent 0.2632(0.2600) | Loss 3.8862(3.8802) | Error 0.0956(0.0926) Steps 820(837.66) | Grad Norm 5.3387(5.4313) | Total Time 14.00(14.00)\n",
      "Iter 3610 | Time 21.1750(21.0366) | Bit/dim 3.7859(3.7489) | Xent 0.2838(0.2662) | Loss 3.9278(3.8820) | Error 0.1089(0.0949) Steps 832(839.69) | Grad Norm 7.1359(5.8984) | Total Time 14.00(14.00)\n",
      "Iter 3620 | Time 20.6298(21.0531) | Bit/dim 3.7742(3.7481) | Xent 0.2603(0.2635) | Loss 3.9044(3.8798) | Error 0.0933(0.0940) Steps 838(840.60) | Grad Norm 5.3888(5.7812) | Total Time 14.00(14.00)\n",
      "Iter 3630 | Time 20.9187(21.0962) | Bit/dim 3.7857(3.7513) | Xent 0.3514(0.2605) | Loss 3.9614(3.8816) | Error 0.1189(0.0928) Steps 838(840.23) | Grad Norm 10.6067(5.6782) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 99.1589, Epoch Time 1277.8864(1187.8787), Bit/dim 3.7667(best: 3.7583), Xent 1.5756, Loss 4.5545, Error 0.3499(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 21.0539(21.0192) | Bit/dim 3.7197(3.7529) | Xent 0.2865(0.2566) | Loss 3.8630(3.8813) | Error 0.1000(0.0909) Steps 826(837.47) | Grad Norm 4.1547(5.5387) | Total Time 14.00(14.00)\n",
      "Iter 3650 | Time 20.9012(20.9739) | Bit/dim 3.7580(3.7498) | Xent 0.2422(0.2486) | Loss 3.8791(3.8741) | Error 0.0767(0.0879) Steps 826(835.48) | Grad Norm 3.9713(5.2364) | Total Time 14.00(14.00)\n",
      "Iter 3660 | Time 21.3525(21.0057) | Bit/dim 3.7484(3.7489) | Xent 0.2420(0.2485) | Loss 3.8694(3.8732) | Error 0.0856(0.0875) Steps 838(836.56) | Grad Norm 4.2779(5.4204) | Total Time 14.00(14.00)\n",
      "Iter 3670 | Time 22.1064(21.1208) | Bit/dim 3.7564(3.7489) | Xent 0.2611(0.2575) | Loss 3.8869(3.8777) | Error 0.0956(0.0901) Steps 850(838.95) | Grad Norm 5.9652(5.5652) | Total Time 14.00(14.00)\n",
      "Iter 3680 | Time 20.8642(21.1020) | Bit/dim 3.7277(3.7481) | Xent 0.2765(0.2536) | Loss 3.8660(3.8749) | Error 0.1078(0.0897) Steps 844(840.11) | Grad Norm 2.9678(5.1925) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 99.6581, Epoch Time 1275.6628(1190.5122), Bit/dim 3.7544(best: 3.7583), Xent 1.5223, Loss 4.5155, Error 0.3474(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 21.0025(21.1170) | Bit/dim 3.7370(3.7463) | Xent 0.2523(0.2501) | Loss 3.8632(3.8714) | Error 0.0933(0.0887) Steps 832(841.53) | Grad Norm 8.2968(5.3548) | Total Time 14.00(14.00)\n",
      "Iter 3700 | Time 20.8291(21.1048) | Bit/dim 3.7672(3.7450) | Xent 0.2147(0.2521) | Loss 3.8745(3.8710) | Error 0.0778(0.0886) Steps 838(841.69) | Grad Norm 4.8929(5.7033) | Total Time 14.00(14.00)\n",
      "Iter 3710 | Time 21.9176(21.1400) | Bit/dim 3.7663(3.7460) | Xent 0.3082(0.2475) | Loss 3.9204(3.8697) | Error 0.1011(0.0871) Steps 844(841.33) | Grad Norm 6.9209(5.4355) | Total Time 14.00(14.00)\n",
      "Iter 3720 | Time 20.8546(21.1641) | Bit/dim 3.7455(3.7426) | Xent 0.2034(0.2409) | Loss 3.8472(3.8631) | Error 0.0722(0.0845) Steps 844(842.27) | Grad Norm 4.2003(5.1600) | Total Time 14.00(14.00)\n",
      "Iter 3730 | Time 20.6112(21.1474) | Bit/dim 3.7328(3.7426) | Xent 0.2366(0.2339) | Loss 3.8511(3.8595) | Error 0.0789(0.0817) Steps 832(842.31) | Grad Norm 3.4439(4.9657) | Total Time 14.00(14.00)\n",
      "Iter 3740 | Time 21.6240(21.1035) | Bit/dim 3.7414(3.7449) | Xent 0.2800(0.2332) | Loss 3.8814(3.8615) | Error 0.1033(0.0818) Steps 850(838.99) | Grad Norm 7.7139(5.1996) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 100.7824, Epoch Time 1280.8089(1193.2211), Bit/dim 3.7503(best: 3.7544), Xent 1.4606, Loss 4.4805, Error 0.3430(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 21.9876(21.0242) | Bit/dim 3.7357(3.7429) | Xent 0.1728(0.2231) | Loss 3.8221(3.8545) | Error 0.0578(0.0778) Steps 850(838.18) | Grad Norm 4.4786(5.2422) | Total Time 14.00(14.00)\n",
      "Iter 3760 | Time 20.2398(21.0683) | Bit/dim 3.7639(3.7444) | Xent 0.2315(0.2235) | Loss 3.8797(3.8561) | Error 0.0811(0.0779) Steps 832(838.65) | Grad Norm 3.6363(5.3231) | Total Time 14.00(14.00)\n",
      "Iter 3770 | Time 20.3369(20.9643) | Bit/dim 3.7128(3.7411) | Xent 0.2209(0.2208) | Loss 3.8233(3.8515) | Error 0.0756(0.0768) Steps 814(836.81) | Grad Norm 3.5748(5.0304) | Total Time 14.00(14.00)\n",
      "Iter 3780 | Time 20.5861(20.9476) | Bit/dim 3.7245(3.7393) | Xent 0.2294(0.2214) | Loss 3.8392(3.8500) | Error 0.0711(0.0775) Steps 838(838.25) | Grad Norm 4.3356(5.1468) | Total Time 14.00(14.00)\n",
      "Iter 3790 | Time 21.8136(21.0351) | Bit/dim 3.7612(3.7403) | Xent 0.2042(0.2174) | Loss 3.8633(3.8490) | Error 0.0722(0.0761) Steps 832(838.98) | Grad Norm 5.3607(4.8186) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 100.6081, Epoch Time 1271.1102(1195.5578), Bit/dim 3.7453(best: 3.7503), Xent 1.6186, Loss 4.5546, Error 0.3459(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 20.7010(20.9795) | Bit/dim 3.7227(3.7381) | Xent 0.1436(0.2108) | Loss 3.7945(3.8435) | Error 0.0478(0.0733) Steps 820(838.37) | Grad Norm 3.9056(4.7779) | Total Time 14.00(14.00)\n",
      "Iter 3810 | Time 21.3833(20.9394) | Bit/dim 3.7641(3.7371) | Xent 0.1739(0.2088) | Loss 3.8510(3.8416) | Error 0.0633(0.0725) Steps 832(836.34) | Grad Norm 5.0065(4.8742) | Total Time 14.00(14.00)\n",
      "Iter 3820 | Time 21.0495(20.9281) | Bit/dim 3.7483(3.7393) | Xent 0.1749(0.2054) | Loss 3.8357(3.8420) | Error 0.0622(0.0714) Steps 838(835.36) | Grad Norm 4.1447(4.7664) | Total Time 14.00(14.00)\n",
      "Iter 3830 | Time 21.4639(20.8577) | Bit/dim 3.7450(3.7401) | Xent 0.2177(0.2071) | Loss 3.8539(3.8436) | Error 0.0822(0.0729) Steps 820(832.96) | Grad Norm 6.2443(4.8254) | Total Time 14.00(14.00)\n",
      "Iter 3840 | Time 20.4865(20.8144) | Bit/dim 3.7741(3.7421) | Xent 0.1902(0.2050) | Loss 3.8692(3.8446) | Error 0.0700(0.0717) Steps 838(833.69) | Grad Norm 3.1042(4.6253) | Total Time 14.00(14.00)\n",
      "Iter 3850 | Time 20.7568(20.8829) | Bit/dim 3.7303(3.7380) | Xent 0.2005(0.2075) | Loss 3.8306(3.8418) | Error 0.0633(0.0721) Steps 838(834.49) | Grad Norm 3.5210(4.5981) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 99.5884, Epoch Time 1263.0986(1197.5840), Bit/dim 3.7456(best: 3.7453), Xent 1.5578, Loss 4.5245, Error 0.3429(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 20.8160(20.8429) | Bit/dim 3.7516(3.7350) | Xent 0.1823(0.2039) | Loss 3.8427(3.8369) | Error 0.0578(0.0704) Steps 844(832.41) | Grad Norm 2.9694(4.4743) | Total Time 14.00(14.00)\n",
      "Iter 3870 | Time 20.9064(20.8211) | Bit/dim 3.7496(3.7367) | Xent 0.2410(0.2039) | Loss 3.8702(3.8386) | Error 0.0733(0.0692) Steps 838(832.06) | Grad Norm 5.5751(4.6092) | Total Time 14.00(14.00)\n",
      "Iter 3880 | Time 20.8223(20.7769) | Bit/dim 3.7302(3.7355) | Xent 0.1933(0.2045) | Loss 3.8269(3.8377) | Error 0.0722(0.0698) Steps 832(834.77) | Grad Norm 3.9536(4.8379) | Total Time 14.00(14.00)\n",
      "Iter 3890 | Time 21.2659(20.8092) | Bit/dim 3.7023(3.7343) | Xent 0.2331(0.2039) | Loss 3.8188(3.8363) | Error 0.0767(0.0693) Steps 850(836.78) | Grad Norm 4.0977(4.8356) | Total Time 14.00(14.00)\n",
      "Iter 3900 | Time 20.9834(20.8925) | Bit/dim 3.7157(3.7351) | Xent 0.1379(0.1971) | Loss 3.7846(3.8336) | Error 0.0511(0.0677) Steps 850(837.12) | Grad Norm 3.2861(4.7175) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 100.8101, Epoch Time 1265.7199(1199.6281), Bit/dim 3.7412(best: 3.7453), Xent 1.6040, Loss 4.5432, Error 0.3484(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 20.9264(20.9109) | Bit/dim 3.7318(3.7318) | Xent 0.1471(0.1940) | Loss 3.8054(3.8287) | Error 0.0533(0.0666) Steps 814(838.48) | Grad Norm 3.7590(4.8764) | Total Time 14.00(14.00)\n",
      "Iter 3920 | Time 20.5517(20.8839) | Bit/dim 3.7547(3.7314) | Xent 0.1910(0.1926) | Loss 3.8502(3.8277) | Error 0.0700(0.0671) Steps 844(838.31) | Grad Norm 8.7899(4.8316) | Total Time 14.00(14.00)\n",
      "Iter 3930 | Time 21.4364(20.9381) | Bit/dim 3.7538(3.7339) | Xent 0.2238(0.1950) | Loss 3.8657(3.8314) | Error 0.0678(0.0673) Steps 850(839.48) | Grad Norm 6.6649(5.2012) | Total Time 14.00(14.00)\n",
      "Iter 3940 | Time 21.2185(20.9300) | Bit/dim 3.7355(3.7362) | Xent 0.1784(0.1956) | Loss 3.8247(3.8340) | Error 0.0533(0.0669) Steps 832(840.26) | Grad Norm 5.5261(5.2624) | Total Time 14.00(14.00)\n",
      "Iter 3950 | Time 20.8756(21.0128) | Bit/dim 3.7126(3.7345) | Xent 0.1912(0.1986) | Loss 3.8082(3.8338) | Error 0.0622(0.0685) Steps 850(843.09) | Grad Norm 5.8647(5.3135) | Total Time 14.00(14.00)\n",
      "Iter 3960 | Time 20.4062(20.9770) | Bit/dim 3.7067(3.7336) | Xent 0.1970(0.2011) | Loss 3.8052(3.8342) | Error 0.0700(0.0694) Steps 856(843.78) | Grad Norm 4.6295(5.2770) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 100.3997, Epoch Time 1271.9450(1201.7976), Bit/dim 3.7424(best: 3.7412), Xent 1.5279, Loss 4.5064, Error 0.3408(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 20.9226(20.9739) | Bit/dim 3.7452(3.7340) | Xent 0.1506(0.1964) | Loss 3.8205(3.8322) | Error 0.0578(0.0680) Steps 820(841.84) | Grad Norm 3.8413(5.0897) | Total Time 14.00(14.00)\n",
      "Iter 3980 | Time 21.5289(20.9875) | Bit/dim 3.7185(3.7315) | Xent 0.2082(0.1936) | Loss 3.8227(3.8283) | Error 0.0656(0.0680) Steps 838(839.08) | Grad Norm 4.6591(5.1020) | Total Time 14.00(14.00)\n",
      "Iter 3990 | Time 21.0189(20.9737) | Bit/dim 3.7259(3.7344) | Xent 0.2821(0.1986) | Loss 3.8670(3.8337) | Error 0.0911(0.0687) Steps 850(839.25) | Grad Norm 9.6829(5.5506) | Total Time 14.00(14.00)\n",
      "Iter 4000 | Time 20.4284(21.0413) | Bit/dim 3.7272(3.7341) | Xent 0.1789(0.1993) | Loss 3.8167(3.8338) | Error 0.0667(0.0691) Steps 820(839.71) | Grad Norm 5.1205(5.5074) | Total Time 14.00(14.00)\n",
      "Iter 4010 | Time 20.7683(21.0113) | Bit/dim 3.7072(3.7330) | Xent 0.2374(0.2061) | Loss 3.8259(3.8361) | Error 0.0756(0.0711) Steps 844(842.12) | Grad Norm 6.9412(5.6821) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 101.3442, Epoch Time 1277.1344(1204.0577), Bit/dim 3.7392(best: 3.7412), Xent 1.5549, Loss 4.5167, Error 0.3457(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 21.0454(21.0380) | Bit/dim 3.7339(3.7332) | Xent 0.1955(0.2047) | Loss 3.8316(3.8356) | Error 0.0622(0.0708) Steps 850(846.70) | Grad Norm 6.3827(5.5877) | Total Time 14.00(14.00)\n",
      "Iter 4030 | Time 21.2134(21.0630) | Bit/dim 3.7312(3.7323) | Xent 0.2120(0.1998) | Loss 3.8373(3.8322) | Error 0.0656(0.0681) Steps 844(845.90) | Grad Norm 4.7906(5.3942) | Total Time 14.00(14.00)\n",
      "Iter 4040 | Time 20.8398(21.0711) | Bit/dim 3.7307(3.7311) | Xent 0.1816(0.1977) | Loss 3.8215(3.8299) | Error 0.0567(0.0671) Steps 826(844.09) | Grad Norm 4.4243(5.2999) | Total Time 14.00(14.00)\n",
      "Iter 4050 | Time 20.8639(21.0358) | Bit/dim 3.7371(3.7331) | Xent 0.2157(0.1998) | Loss 3.8450(3.8330) | Error 0.0778(0.0688) Steps 832(843.55) | Grad Norm 5.6218(5.3946) | Total Time 14.00(14.00)\n",
      "Iter 4060 | Time 20.3036(21.0108) | Bit/dim 3.7137(3.7322) | Xent 0.1929(0.2038) | Loss 3.8101(3.8342) | Error 0.0611(0.0703) Steps 820(841.92) | Grad Norm 6.7891(5.7683) | Total Time 14.00(14.00)\n",
      "Iter 4070 | Time 20.9977(20.9862) | Bit/dim 3.7250(3.7311) | Xent 0.1531(0.2029) | Loss 3.8015(3.8325) | Error 0.0567(0.0701) Steps 844(841.30) | Grad Norm 3.3418(5.2592) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 101.4608, Epoch Time 1274.3145(1206.1654), Bit/dim 3.7378(best: 3.7392), Xent 1.5188, Loss 4.4972, Error 0.3366(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 20.8919(20.9722) | Bit/dim 3.7123(3.7274) | Xent 0.1658(0.1924) | Loss 3.7951(3.8236) | Error 0.0567(0.0668) Steps 826(840.11) | Grad Norm 6.2539(5.0715) | Total Time 14.00(14.00)\n",
      "Iter 4090 | Time 21.9219(20.9741) | Bit/dim 3.6993(3.7287) | Xent 0.1809(0.1842) | Loss 3.7897(3.8209) | Error 0.0678(0.0638) Steps 850(837.87) | Grad Norm 6.9057(5.2661) | Total Time 14.00(14.00)\n",
      "Iter 4100 | Time 21.1856(21.0700) | Bit/dim 3.7268(3.7270) | Xent 0.1534(0.1801) | Loss 3.8035(3.8170) | Error 0.0511(0.0617) Steps 850(840.34) | Grad Norm 3.7901(5.0863) | Total Time 14.00(14.00)\n",
      "Iter 4110 | Time 21.3848(21.0936) | Bit/dim 3.7435(3.7275) | Xent 0.1610(0.1845) | Loss 3.8240(3.8197) | Error 0.0611(0.0636) Steps 838(841.56) | Grad Norm 6.4966(5.0220) | Total Time 14.00(14.00)\n",
      "Iter 4120 | Time 20.6761(21.0007) | Bit/dim 3.7284(3.7272) | Xent 0.2506(0.1917) | Loss 3.8537(3.8230) | Error 0.0856(0.0668) Steps 826(838.95) | Grad Norm 8.0399(5.4515) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 100.6694, Epoch Time 1273.2341(1208.1774), Bit/dim 3.7545(best: 3.7378), Xent 1.6855, Loss 4.5973, Error 0.3455(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 21.8331(20.9954) | Bit/dim 3.7267(3.7300) | Xent 0.1611(0.1880) | Loss 3.8072(3.8241) | Error 0.0522(0.0650) Steps 856(840.98) | Grad Norm 5.1798(5.2686) | Total Time 14.00(14.00)\n",
      "Iter 4140 | Time 20.6136(21.0146) | Bit/dim 3.7415(3.7316) | Xent 0.1557(0.1883) | Loss 3.8193(3.8258) | Error 0.0600(0.0638) Steps 832(844.13) | Grad Norm 3.3756(5.4653) | Total Time 14.00(14.00)\n",
      "Iter 4150 | Time 20.7461(20.9609) | Bit/dim 3.7196(3.7299) | Xent 0.1601(0.1837) | Loss 3.7996(3.8218) | Error 0.0578(0.0624) Steps 838(843.56) | Grad Norm 4.9678(5.2409) | Total Time 14.00(14.00)\n",
      "Iter 4160 | Time 21.8704(21.0177) | Bit/dim 3.7560(3.7279) | Xent 0.1532(0.1775) | Loss 3.8326(3.8166) | Error 0.0589(0.0605) Steps 826(845.07) | Grad Norm 2.9363(4.7659) | Total Time 14.00(14.00)\n",
      "Iter 4170 | Time 21.4237(21.0542) | Bit/dim 3.7202(3.7267) | Xent 0.1797(0.1740) | Loss 3.8100(3.8137) | Error 0.0733(0.0600) Steps 844(843.40) | Grad Norm 6.2038(4.6557) | Total Time 14.00(14.00)\n",
      "Iter 4180 | Time 20.7313(21.0012) | Bit/dim 3.7029(3.7246) | Xent 0.1547(0.1739) | Loss 3.7803(3.8116) | Error 0.0522(0.0604) Steps 832(841.11) | Grad Norm 3.2980(4.5910) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 101.7600, Epoch Time 1275.9348(1210.2102), Bit/dim 3.7315(best: 3.7378), Xent 1.6804, Loss 4.5717, Error 0.3488(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 20.9113(20.9831) | Bit/dim 3.7592(3.7241) | Xent 0.1210(0.1656) | Loss 3.8197(3.8069) | Error 0.0400(0.0575) Steps 838(841.23) | Grad Norm 4.6966(4.3434) | Total Time 14.00(14.00)\n",
      "Iter 4200 | Time 21.4089(21.0706) | Bit/dim 3.6972(3.7193) | Xent 0.1408(0.1617) | Loss 3.7676(3.8001) | Error 0.0456(0.0556) Steps 838(841.99) | Grad Norm 3.8272(4.2863) | Total Time 14.00(14.00)\n",
      "Iter 4210 | Time 21.1335(21.0862) | Bit/dim 3.7320(3.7174) | Xent 0.1516(0.1583) | Loss 3.8078(3.7965) | Error 0.0511(0.0544) Steps 820(840.55) | Grad Norm 5.0847(4.1498) | Total Time 14.00(14.00)\n",
      "Iter 4220 | Time 21.1832(21.1241) | Bit/dim 3.6997(3.7168) | Xent 0.2148(0.1612) | Loss 3.8071(3.7974) | Error 0.0744(0.0556) Steps 856(841.49) | Grad Norm 5.9395(4.4744) | Total Time 14.00(14.00)\n",
      "Iter 4230 | Time 20.9093(21.0929) | Bit/dim 3.7163(3.7183) | Xent 0.1540(0.1624) | Loss 3.7933(3.7995) | Error 0.0500(0.0554) Steps 856(841.46) | Grad Norm 5.2703(4.7921) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 102.1896, Epoch Time 1282.1684(1212.3689), Bit/dim 3.7313(best: 3.7315), Xent 1.6803, Loss 4.5715, Error 0.3462(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 20.8521(21.0556) | Bit/dim 3.6918(3.7178) | Xent 0.1248(0.1557) | Loss 3.7542(3.7956) | Error 0.0422(0.0539) Steps 826(841.87) | Grad Norm 4.1354(4.4350) | Total Time 14.00(14.00)\n",
      "Iter 4250 | Time 21.6242(21.0679) | Bit/dim 3.7252(3.7208) | Xent 0.1455(0.1504) | Loss 3.7979(3.7960) | Error 0.0489(0.0515) Steps 808(840.22) | Grad Norm 4.0376(4.2744) | Total Time 14.00(14.00)\n",
      "Iter 4260 | Time 20.8660(20.9581) | Bit/dim 3.7052(3.7198) | Xent 0.1406(0.1487) | Loss 3.7755(3.7941) | Error 0.0533(0.0508) Steps 844(838.33) | Grad Norm 3.0632(4.1828) | Total Time 14.00(14.00)\n",
      "Iter 4270 | Time 21.3251(21.0002) | Bit/dim 3.7075(3.7162) | Xent 0.1522(0.1508) | Loss 3.7835(3.7916) | Error 0.0478(0.0518) Steps 862(839.89) | Grad Norm 3.7431(4.2578) | Total Time 14.00(14.00)\n",
      "Iter 4280 | Time 20.6569(20.9700) | Bit/dim 3.7176(3.7142) | Xent 0.2205(0.1607) | Loss 3.8279(3.7945) | Error 0.0678(0.0544) Steps 856(841.87) | Grad Norm 5.8961(4.4963) | Total Time 14.00(14.00)\n",
      "Iter 4290 | Time 20.6118(21.0013) | Bit/dim 3.7237(3.7163) | Xent 0.2133(0.1721) | Loss 3.8303(3.8023) | Error 0.0733(0.0585) Steps 844(841.95) | Grad Norm 3.1609(4.7253) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 102.6720, Epoch Time 1272.9211(1214.1855), Bit/dim 3.7296(best: 3.7313), Xent 1.5702, Loss 4.5147, Error 0.3460(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 21.4961(21.0595) | Bit/dim 3.6926(3.7161) | Xent 0.1403(0.1643) | Loss 3.7628(3.7982) | Error 0.0533(0.0558) Steps 832(842.68) | Grad Norm 5.8354(4.5958) | Total Time 14.00(14.00)\n",
      "Iter 4310 | Time 21.1246(21.0898) | Bit/dim 3.7123(3.7134) | Xent 0.1469(0.1585) | Loss 3.7858(3.7927) | Error 0.0456(0.0535) Steps 832(840.81) | Grad Norm 4.8240(4.3421) | Total Time 14.00(14.00)\n",
      "Iter 4320 | Time 21.0335(21.0789) | Bit/dim 3.7107(3.7142) | Xent 0.1319(0.1564) | Loss 3.7766(3.7924) | Error 0.0511(0.0527) Steps 838(840.51) | Grad Norm 3.9668(4.4754) | Total Time 14.00(14.00)\n",
      "Iter 4330 | Time 21.3898(21.0217) | Bit/dim 3.7494(3.7135) | Xent 0.0965(0.1515) | Loss 3.7977(3.7892) | Error 0.0356(0.0511) Steps 838(839.07) | Grad Norm 2.4185(4.3216) | Total Time 14.00(14.00)\n",
      "Iter 4340 | Time 20.8193(20.9714) | Bit/dim 3.7295(3.7163) | Xent 0.1617(0.1486) | Loss 3.8104(3.7906) | Error 0.0578(0.0504) Steps 820(836.45) | Grad Norm 3.5309(4.2649) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 100.0594, Epoch Time 1273.6507(1215.9694), Bit/dim 3.7274(best: 3.7296), Xent 1.6350, Loss 4.5449, Error 0.3393(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 20.8022(20.9450) | Bit/dim 3.7521(3.7162) | Xent 0.1205(0.1477) | Loss 3.8124(3.7901) | Error 0.0367(0.0499) Steps 832(835.55) | Grad Norm 3.3306(4.1516) | Total Time 14.00(14.00)\n",
      "Iter 4360 | Time 21.1815(20.9754) | Bit/dim 3.6969(3.7156) | Xent 0.1752(0.1489) | Loss 3.7845(3.7901) | Error 0.0644(0.0515) Steps 832(832.17) | Grad Norm 6.2101(4.6215) | Total Time 14.00(14.00)\n",
      "Iter 4370 | Time 21.8407(21.0049) | Bit/dim 3.7318(3.7142) | Xent 0.1170(0.1484) | Loss 3.7903(3.7884) | Error 0.0367(0.0508) Steps 820(833.45) | Grad Norm 4.2529(4.7108) | Total Time 14.00(14.00)\n",
      "Iter 4380 | Time 20.7884(20.9659) | Bit/dim 3.7134(3.7173) | Xent 0.1460(0.1558) | Loss 3.7864(3.7951) | Error 0.0489(0.0530) Steps 814(833.97) | Grad Norm 4.1303(5.1401) | Total Time 14.00(14.00)\n",
      "Iter 4390 | Time 21.6198(21.0382) | Bit/dim 3.7077(3.7183) | Xent 0.1958(0.1647) | Loss 3.8056(3.8006) | Error 0.0678(0.0559) Steps 844(834.14) | Grad Norm 4.9456(5.2805) | Total Time 14.00(14.00)\n",
      "Iter 4400 | Time 21.2849(21.1263) | Bit/dim 3.7141(3.7170) | Xent 0.1529(0.1605) | Loss 3.7906(3.7972) | Error 0.0522(0.0545) Steps 832(837.55) | Grad Norm 3.1465(4.9685) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 103.1733, Epoch Time 1282.0631(1217.9522), Bit/dim 3.7291(best: 3.7274), Xent 1.8337, Loss 4.6460, Error 0.3504(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 20.8208(21.2337) | Bit/dim 3.7044(3.7143) | Xent 0.1524(0.1597) | Loss 3.7806(3.7941) | Error 0.0600(0.0540) Steps 844(839.62) | Grad Norm 3.8178(5.1979) | Total Time 14.00(14.00)\n",
      "Iter 4420 | Time 20.9739(21.2056) | Bit/dim 3.7097(3.7154) | Xent 0.1161(0.1567) | Loss 3.7677(3.7937) | Error 0.0467(0.0534) Steps 856(841.53) | Grad Norm 2.9486(4.9161) | Total Time 14.00(14.00)\n",
      "Iter 4430 | Time 21.3138(21.1889) | Bit/dim 3.7184(3.7138) | Xent 0.1438(0.1570) | Loss 3.7903(3.7923) | Error 0.0500(0.0530) Steps 850(841.14) | Grad Norm 5.1640(4.9763) | Total Time 14.00(14.00)\n",
      "Iter 4440 | Time 21.6661(21.2225) | Bit/dim 3.6873(3.7128) | Xent 0.1537(0.1551) | Loss 3.7642(3.7903) | Error 0.0589(0.0526) Steps 874(840.58) | Grad Norm 9.7263(5.1269) | Total Time 14.00(14.00)\n",
      "Iter 4450 | Time 21.8729(21.2477) | Bit/dim 3.7095(3.7151) | Xent 0.1460(0.1534) | Loss 3.7825(3.7918) | Error 0.0489(0.0518) Steps 844(842.80) | Grad Norm 5.0421(5.0242) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 101.5896, Epoch Time 1292.0914(1220.1764), Bit/dim 3.7344(best: 3.7274), Xent 1.7077, Loss 4.5882, Error 0.3481(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 20.7691(21.2496) | Bit/dim 3.7338(3.7138) | Xent 0.1217(0.1517) | Loss 3.7946(3.7897) | Error 0.0422(0.0513) Steps 838(842.33) | Grad Norm 4.3605(4.8683) | Total Time 14.00(14.00)\n",
      "Iter 4470 | Time 21.9495(21.2163) | Bit/dim 3.7079(3.7132) | Xent 0.1120(0.1430) | Loss 3.7639(3.7847) | Error 0.0367(0.0482) Steps 850(840.67) | Grad Norm 2.7535(4.5172) | Total Time 14.00(14.00)\n",
      "Iter 4480 | Time 20.6754(21.2315) | Bit/dim 3.7029(3.7106) | Xent 0.1309(0.1392) | Loss 3.7683(3.7802) | Error 0.0444(0.0473) Steps 838(841.02) | Grad Norm 4.6985(4.4794) | Total Time 14.00(14.00)\n",
      "Iter 4490 | Time 21.7058(21.2961) | Bit/dim 3.7334(3.7095) | Xent 0.1797(0.1430) | Loss 3.8233(3.7810) | Error 0.0589(0.0487) Steps 838(842.47) | Grad Norm 5.5222(4.6413) | Total Time 14.00(14.00)\n",
      "Iter 4500 | Time 21.4693(21.3005) | Bit/dim 3.6862(3.7102) | Xent 0.1680(0.1474) | Loss 3.7702(3.7839) | Error 0.0533(0.0497) Steps 832(842.44) | Grad Norm 5.6719(4.9227) | Total Time 14.00(14.00)\n",
      "Iter 4510 | Time 21.0560(21.2370) | Bit/dim 3.7068(3.7103) | Xent 0.1712(0.1515) | Loss 3.7924(3.7861) | Error 0.0544(0.0515) Steps 844(841.83) | Grad Norm 3.9557(4.8625) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 102.2190, Epoch Time 1287.6510(1222.2007), Bit/dim 3.7255(best: 3.7274), Xent 1.6958, Loss 4.5734, Error 0.3502(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 21.2309(21.2629) | Bit/dim 3.6989(3.7063) | Xent 0.1041(0.1451) | Loss 3.7510(3.7789) | Error 0.0356(0.0488) Steps 838(842.37) | Grad Norm 3.2286(4.4686) | Total Time 14.00(14.00)\n",
      "Iter 4530 | Time 21.0543(21.2377) | Bit/dim 3.7254(3.7068) | Xent 0.1024(0.1403) | Loss 3.7765(3.7770) | Error 0.0411(0.0477) Steps 814(841.01) | Grad Norm 2.9219(4.1335) | Total Time 14.00(14.00)\n",
      "Iter 4540 | Time 20.5181(21.1935) | Bit/dim 3.7104(3.7070) | Xent 0.1325(0.1380) | Loss 3.7767(3.7760) | Error 0.0444(0.0468) Steps 814(839.83) | Grad Norm 3.8045(4.0491) | Total Time 14.00(14.00)\n",
      "Iter 4550 | Time 21.3054(21.1607) | Bit/dim 3.7488(3.7096) | Xent 0.1692(0.1411) | Loss 3.8334(3.7802) | Error 0.0533(0.0477) Steps 868(839.37) | Grad Norm 4.7032(4.0805) | Total Time 14.00(14.00)\n",
      "Iter 4560 | Time 21.7155(21.2557) | Bit/dim 3.7207(3.7115) | Xent 0.1152(0.1453) | Loss 3.7783(3.7841) | Error 0.0456(0.0489) Steps 826(839.44) | Grad Norm 2.7388(4.1663) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 99.9419, Epoch Time 1286.1272(1224.1185), Bit/dim 3.7221(best: 3.7255), Xent 1.7332, Loss 4.5887, Error 0.3430(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 20.6064(21.2538) | Bit/dim 3.7370(3.7104) | Xent 0.1483(0.1419) | Loss 3.8111(3.7814) | Error 0.0456(0.0469) Steps 832(838.96) | Grad Norm 6.6018(4.4197) | Total Time 14.00(14.00)\n",
      "Iter 4580 | Time 21.1171(21.1895) | Bit/dim 3.6957(3.7092) | Xent 0.1673(0.1423) | Loss 3.7794(3.7803) | Error 0.0578(0.0475) Steps 838(838.09) | Grad Norm 8.9561(4.9286) | Total Time 14.00(14.00)\n",
      "Iter 4590 | Time 20.6072(21.1506) | Bit/dim 3.6903(3.7086) | Xent 0.1745(0.1491) | Loss 3.7775(3.7831) | Error 0.0544(0.0506) Steps 826(838.32) | Grad Norm 5.4837(5.0716) | Total Time 14.00(14.00)\n",
      "Iter 4600 | Time 21.5035(21.1606) | Bit/dim 3.7184(3.7091) | Xent 0.1259(0.1428) | Loss 3.7813(3.7805) | Error 0.0422(0.0486) Steps 850(839.12) | Grad Norm 2.9245(4.6327) | Total Time 14.00(14.00)\n",
      "Iter 4610 | Time 21.7159(21.2669) | Bit/dim 3.7133(3.7067) | Xent 0.1163(0.1360) | Loss 3.7714(3.7747) | Error 0.0389(0.0464) Steps 832(843.19) | Grad Norm 3.6789(4.3466) | Total Time 14.00(14.00)\n",
      "Iter 4620 | Time 21.3279(21.2915) | Bit/dim 3.6982(3.7066) | Xent 0.1448(0.1384) | Loss 3.7706(3.7758) | Error 0.0489(0.0473) Steps 838(844.59) | Grad Norm 3.6846(4.3878) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 101.6237, Epoch Time 1287.6755(1226.0252), Bit/dim 3.7179(best: 3.7221), Xent 1.7209, Loss 4.5784, Error 0.3496(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 20.9082(21.3045) | Bit/dim 3.6984(3.7073) | Xent 0.1564(0.1353) | Loss 3.7766(3.7750) | Error 0.0511(0.0459) Steps 844(844.81) | Grad Norm 4.0060(4.1441) | Total Time 14.00(14.00)\n",
      "Iter 4640 | Time 21.7400(21.3208) | Bit/dim 3.7111(3.7061) | Xent 0.1186(0.1293) | Loss 3.7705(3.7707) | Error 0.0400(0.0440) Steps 826(845.05) | Grad Norm 2.6499(3.8022) | Total Time 14.00(14.00)\n",
      "Iter 4650 | Time 20.7935(21.3916) | Bit/dim 3.7144(3.7007) | Xent 0.1147(0.1286) | Loss 3.7718(3.7650) | Error 0.0456(0.0437) Steps 844(847.73) | Grad Norm 5.5128(4.0212) | Total Time 14.00(14.00)\n",
      "Iter 4660 | Time 22.0639(21.4230) | Bit/dim 3.6920(3.6994) | Xent 0.1453(0.1251) | Loss 3.7647(3.7620) | Error 0.0500(0.0426) Steps 838(848.98) | Grad Norm 3.9744(4.1192) | Total Time 14.00(14.00)\n",
      "Iter 4670 | Time 21.3220(21.4195) | Bit/dim 3.6998(3.7006) | Xent 0.1626(0.1314) | Loss 3.7811(3.7663) | Error 0.0533(0.0446) Steps 844(848.12) | Grad Norm 4.9322(4.1150) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 101.3835, Epoch Time 1296.9583(1228.1532), Bit/dim 3.7265(best: 3.7179), Xent 1.7565, Loss 4.6047, Error 0.3405(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 21.9084(21.3828) | Bit/dim 3.6786(3.7049) | Xent 0.1165(0.1335) | Loss 3.7369(3.7717) | Error 0.0378(0.0453) Steps 880(850.20) | Grad Norm 3.4138(4.1720) | Total Time 14.00(14.00)\n",
      "Iter 4690 | Time 21.3075(21.3969) | Bit/dim 3.7138(3.7040) | Xent 0.0927(0.1289) | Loss 3.7601(3.7685) | Error 0.0289(0.0439) Steps 874(851.05) | Grad Norm 4.9027(4.2615) | Total Time 14.00(14.00)\n",
      "Iter 4700 | Time 21.9326(21.3826) | Bit/dim 3.6947(3.7048) | Xent 0.1688(0.1331) | Loss 3.7791(3.7714) | Error 0.0600(0.0459) Steps 868(852.22) | Grad Norm 8.6470(4.8721) | Total Time 14.00(14.00)\n",
      "Iter 4710 | Time 22.3386(21.5010) | Bit/dim 3.6906(3.7059) | Xent 0.1240(0.1366) | Loss 3.7527(3.7742) | Error 0.0433(0.0467) Steps 880(853.94) | Grad Norm 5.3232(5.1647) | Total Time 14.00(14.00)\n",
      "Iter 4720 | Time 21.8561(21.5276) | Bit/dim 3.7061(3.7084) | Xent 0.1384(0.1381) | Loss 3.7753(3.7775) | Error 0.0389(0.0469) Steps 856(853.65) | Grad Norm 4.4541(4.9285) | Total Time 14.00(14.00)\n",
      "Iter 4730 | Time 21.4904(21.5681) | Bit/dim 3.7158(3.7075) | Xent 0.1649(0.1409) | Loss 3.7983(3.7779) | Error 0.0578(0.0481) Steps 850(853.43) | Grad Norm 5.0859(4.8802) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 101.7713, Epoch Time 1305.0876(1230.4612), Bit/dim 3.7146(best: 3.7179), Xent 1.6766, Loss 4.5529, Error 0.3368(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 21.6093(21.5187) | Bit/dim 3.7027(3.7069) | Xent 0.1095(0.1374) | Loss 3.7575(3.7756) | Error 0.0367(0.0470) Steps 856(851.40) | Grad Norm 3.1517(4.6169) | Total Time 14.00(14.00)\n",
      "Iter 4750 | Time 21.5272(21.4801) | Bit/dim 3.6908(3.7059) | Xent 0.0935(0.1309) | Loss 3.7375(3.7713) | Error 0.0256(0.0449) Steps 850(852.21) | Grad Norm 2.7498(4.3865) | Total Time 14.00(14.00)\n",
      "Iter 4760 | Time 20.4288(21.3476) | Bit/dim 3.7305(3.7064) | Xent 0.1156(0.1256) | Loss 3.7882(3.7692) | Error 0.0411(0.0434) Steps 844(848.80) | Grad Norm 3.3041(4.0937) | Total Time 14.00(14.00)\n",
      "Iter 4770 | Time 21.7464(21.2916) | Bit/dim 3.7115(3.7051) | Xent 0.1413(0.1274) | Loss 3.7821(3.7688) | Error 0.0422(0.0431) Steps 850(847.17) | Grad Norm 4.6791(4.2544) | Total Time 14.00(14.00)\n",
      "Iter 4780 | Time 21.9233(21.4199) | Bit/dim 3.7077(3.7034) | Xent 0.1666(0.1316) | Loss 3.7911(3.7692) | Error 0.0533(0.0445) Steps 832(849.21) | Grad Norm 4.1713(4.5326) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 102.7720, Epoch Time 1291.7311(1232.2993), Bit/dim 3.7137(best: 3.7146), Xent 1.6567, Loss 4.5420, Error 0.3382(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 21.2007(21.3443) | Bit/dim 3.6874(3.6999) | Xent 0.1155(0.1327) | Loss 3.7451(3.7663) | Error 0.0378(0.0450) Steps 844(849.35) | Grad Norm 3.1815(4.4471) | Total Time 14.00(14.00)\n",
      "Iter 4800 | Time 21.6892(21.2508) | Bit/dim 3.7011(3.6996) | Xent 0.1049(0.1282) | Loss 3.7536(3.7637) | Error 0.0367(0.0435) Steps 850(847.64) | Grad Norm 2.6921(4.3826) | Total Time 14.00(14.00)\n",
      "Iter 4810 | Time 21.4941(21.2112) | Bit/dim 3.7180(3.6985) | Xent 0.1602(0.1263) | Loss 3.7981(3.7617) | Error 0.0478(0.0427) Steps 850(846.05) | Grad Norm 6.2472(4.3876) | Total Time 14.00(14.00)\n",
      "Iter 4820 | Time 21.7919(21.1962) | Bit/dim 3.7096(3.6950) | Xent 0.1115(0.1263) | Loss 3.7653(3.7581) | Error 0.0400(0.0425) Steps 832(845.66) | Grad Norm 2.6690(4.5296) | Total Time 14.00(14.00)\n",
      "Iter 4830 | Time 20.6383(21.1433) | Bit/dim 3.6906(3.6985) | Xent 0.1185(0.1255) | Loss 3.7499(3.7612) | Error 0.0456(0.0424) Steps 862(847.09) | Grad Norm 4.5734(4.5283) | Total Time 14.00(14.00)\n",
      "Iter 4840 | Time 21.1939(21.1927) | Bit/dim 3.7041(3.6997) | Xent 0.1189(0.1269) | Loss 3.7635(3.7631) | Error 0.0311(0.0424) Steps 838(846.73) | Grad Norm 4.0408(4.3901) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 101.6045, Epoch Time 1281.9673(1233.7893), Bit/dim 3.7114(best: 3.7137), Xent 1.7344, Loss 4.5786, Error 0.3499(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 21.6919(21.2572) | Bit/dim 3.6724(3.6967) | Xent 0.0970(0.1250) | Loss 3.7209(3.7592) | Error 0.0300(0.0419) Steps 874(845.90) | Grad Norm 3.4927(4.1551) | Total Time 14.00(14.00)\n",
      "Iter 4860 | Time 21.0571(21.2393) | Bit/dim 3.7482(3.7002) | Xent 0.1343(0.1269) | Loss 3.8154(3.7637) | Error 0.0467(0.0425) Steps 838(845.83) | Grad Norm 2.9188(4.3578) | Total Time 14.00(14.00)\n",
      "Iter 4870 | Time 20.6704(21.1666) | Bit/dim 3.7055(3.6974) | Xent 0.1119(0.1265) | Loss 3.7614(3.7607) | Error 0.0433(0.0429) Steps 874(846.69) | Grad Norm 2.7215(4.2574) | Total Time 14.00(14.00)\n",
      "Iter 4880 | Time 21.3082(21.1549) | Bit/dim 3.6915(3.6992) | Xent 0.1173(0.1223) | Loss 3.7502(3.7604) | Error 0.0422(0.0412) Steps 868(847.46) | Grad Norm 4.1884(3.9790) | Total Time 14.00(14.00)\n",
      "Iter 4890 | Time 21.4363(21.1367) | Bit/dim 3.6592(3.6978) | Xent 0.1445(0.1222) | Loss 3.7314(3.7588) | Error 0.0456(0.0409) Steps 868(846.19) | Grad Norm 3.2180(3.9764) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 101.4423, Epoch Time 1285.5395(1235.3418), Bit/dim 3.7083(best: 3.7114), Xent 1.7962, Loss 4.6064, Error 0.3459(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 21.2981(21.2335) | Bit/dim 3.6828(3.6942) | Xent 0.0932(0.1192) | Loss 3.7294(3.7538) | Error 0.0344(0.0393) Steps 844(847.26) | Grad Norm 3.9586(3.9706) | Total Time 14.00(14.00)\n",
      "Iter 4910 | Time 21.7832(21.2855) | Bit/dim 3.6672(3.6922) | Xent 0.1146(0.1173) | Loss 3.7244(3.7509) | Error 0.0378(0.0388) Steps 844(847.63) | Grad Norm 3.8125(3.9407) | Total Time 14.00(14.00)\n",
      "Iter 4920 | Time 21.2398(21.2972) | Bit/dim 3.7260(3.6941) | Xent 0.0996(0.1149) | Loss 3.7758(3.7515) | Error 0.0322(0.0385) Steps 838(846.82) | Grad Norm 4.4551(3.9372) | Total Time 14.00(14.00)\n",
      "Iter 4930 | Time 21.5938(21.3159) | Bit/dim 3.6804(3.6914) | Xent 0.1283(0.1149) | Loss 3.7446(3.7488) | Error 0.0478(0.0390) Steps 868(846.46) | Grad Norm 6.6180(3.9256) | Total Time 14.00(14.00)\n",
      "Iter 4940 | Time 21.7290(21.2870) | Bit/dim 3.6881(3.6918) | Xent 0.1236(0.1179) | Loss 3.7499(3.7507) | Error 0.0456(0.0391) Steps 850(846.70) | Grad Norm 4.2272(4.3058) | Total Time 14.00(14.00)\n",
      "Iter 4950 | Time 21.2755(21.2573) | Bit/dim 3.7338(3.6972) | Xent 0.1621(0.1223) | Loss 3.8149(3.7583) | Error 0.0544(0.0404) Steps 838(846.26) | Grad Norm 5.4835(4.5225) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 101.3854, Epoch Time 1291.7692(1237.0347), Bit/dim 3.7059(best: 3.7083), Xent 1.7257, Loss 4.5688, Error 0.3457(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 22.0724(21.2693) | Bit/dim 3.7045(3.6963) | Xent 0.1707(0.1208) | Loss 3.7898(3.7567) | Error 0.0567(0.0398) Steps 838(847.66) | Grad Norm 4.5499(4.5541) | Total Time 14.00(14.00)\n",
      "Iter 4970 | Time 21.0023(21.2740) | Bit/dim 3.6778(3.6934) | Xent 0.1359(0.1231) | Loss 3.7457(3.7550) | Error 0.0444(0.0410) Steps 856(849.35) | Grad Norm 4.1142(4.7887) | Total Time 14.00(14.00)\n",
      "Iter 4980 | Time 20.9351(21.2628) | Bit/dim 3.6826(3.6922) | Xent 0.1121(0.1227) | Loss 3.7386(3.7535) | Error 0.0389(0.0407) Steps 826(847.97) | Grad Norm 3.2149(4.6781) | Total Time 14.00(14.00)\n",
      "Iter 4990 | Time 21.1334(21.2432) | Bit/dim 3.6652(3.6915) | Xent 0.0701(0.1179) | Loss 3.7003(3.7504) | Error 0.0278(0.0389) Steps 856(847.87) | Grad Norm 4.0349(4.3636) | Total Time 14.00(14.00)\n",
      "Iter 5000 | Time 21.4916(21.2903) | Bit/dim 3.6846(3.6908) | Xent 0.1153(0.1150) | Loss 3.7422(3.7483) | Error 0.0422(0.0385) Steps 838(847.14) | Grad Norm 4.5549(4.3322) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 102.4833, Epoch Time 1289.9326(1238.6216), Bit/dim 3.7145(best: 3.7059), Xent 1.8948, Loss 4.6619, Error 0.3518(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 21.5663(21.2246) | Bit/dim 3.6721(3.6925) | Xent 0.1049(0.1179) | Loss 3.7246(3.7515) | Error 0.0278(0.0388) Steps 832(846.57) | Grad Norm 3.2827(4.4894) | Total Time 14.00(14.00)\n",
      "Iter 5020 | Time 21.1374(21.2973) | Bit/dim 3.6845(3.6915) | Xent 0.1096(0.1200) | Loss 3.7393(3.7515) | Error 0.0367(0.0395) Steps 856(847.91) | Grad Norm 3.8610(4.3908) | Total Time 14.00(14.00)\n",
      "Iter 5030 | Time 21.4227(21.3088) | Bit/dim 3.6787(3.6909) | Xent 0.0961(0.1193) | Loss 3.7267(3.7506) | Error 0.0422(0.0400) Steps 856(846.80) | Grad Norm 3.2633(4.2534) | Total Time 14.00(14.00)\n",
      "Iter 5040 | Time 21.2882(21.3878) | Bit/dim 3.7020(3.6929) | Xent 0.1097(0.1177) | Loss 3.7569(3.7518) | Error 0.0422(0.0395) Steps 856(848.19) | Grad Norm 3.5905(4.0719) | Total Time 14.00(14.00)\n",
      "Iter 5050 | Time 22.2608(21.3856) | Bit/dim 3.6729(3.6905) | Xent 0.1463(0.1171) | Loss 3.7460(3.7491) | Error 0.0511(0.0393) Steps 862(849.29) | Grad Norm 3.7352(4.0466) | Total Time 14.00(14.00)\n",
      "Iter 5060 | Time 21.6912(21.4427) | Bit/dim 3.6826(3.6878) | Xent 0.1140(0.1127) | Loss 3.7396(3.7442) | Error 0.0422(0.0379) Steps 868(850.50) | Grad Norm 3.2444(3.7000) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 100.3281, Epoch Time 1298.2820(1240.4114), Bit/dim 3.6978(best: 3.7059), Xent 1.8480, Loss 4.6218, Error 0.3376(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 20.4765(21.3826) | Bit/dim 3.6476(3.6861) | Xent 0.1039(0.1122) | Loss 3.6995(3.7422) | Error 0.0311(0.0374) Steps 832(848.99) | Grad Norm 4.5580(3.6923) | Total Time 14.00(14.00)\n",
      "Iter 5080 | Time 20.8539(21.3911) | Bit/dim 3.7211(3.6856) | Xent 0.0961(0.1099) | Loss 3.7692(3.7406) | Error 0.0300(0.0364) Steps 844(847.80) | Grad Norm 3.5059(3.6807) | Total Time 14.00(14.00)\n",
      "Iter 5090 | Time 21.0368(21.4339) | Bit/dim 3.6916(3.6877) | Xent 0.0862(0.1059) | Loss 3.7347(3.7406) | Error 0.0311(0.0356) Steps 844(849.03) | Grad Norm 2.8789(3.6300) | Total Time 14.00(14.00)\n",
      "Iter 5100 | Time 21.3808(21.3484) | Bit/dim 3.6871(3.6853) | Xent 0.1191(0.1048) | Loss 3.7467(3.7377) | Error 0.0389(0.0351) Steps 850(848.99) | Grad Norm 3.7860(3.5505) | Total Time 14.00(14.00)\n",
      "Iter 5110 | Time 20.9512(21.3780) | Bit/dim 3.6756(3.6841) | Xent 0.1163(0.1081) | Loss 3.7338(3.7382) | Error 0.0433(0.0367) Steps 844(849.55) | Grad Norm 3.0420(3.5276) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 100.3589, Epoch Time 1294.4802(1242.0335), Bit/dim 3.6983(best: 3.6978), Xent 1.8412, Loss 4.6189, Error 0.3435(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 20.8066(21.3832) | Bit/dim 3.6892(3.6862) | Xent 0.1314(0.1111) | Loss 3.7549(3.7418) | Error 0.0400(0.0373) Steps 850(849.40) | Grad Norm 4.5280(3.4598) | Total Time 14.00(14.00)\n",
      "Iter 5130 | Time 21.1619(21.3367) | Bit/dim 3.6681(3.6843) | Xent 0.0749(0.1080) | Loss 3.7055(3.7383) | Error 0.0267(0.0361) Steps 850(848.18) | Grad Norm 2.6371(3.5052) | Total Time 14.00(14.00)\n",
      "Iter 5140 | Time 22.3489(21.4275) | Bit/dim 3.6989(3.6856) | Xent 0.1535(0.1111) | Loss 3.7757(3.7411) | Error 0.0456(0.0370) Steps 862(850.04) | Grad Norm 6.9274(3.9298) | Total Time 14.00(14.00)\n",
      "Iter 5150 | Time 22.1234(21.3860) | Bit/dim 3.6837(3.6864) | Xent 0.1080(0.1087) | Loss 3.7377(3.7408) | Error 0.0411(0.0362) Steps 892(853.78) | Grad Norm 3.9468(3.7876) | Total Time 14.00(14.00)\n",
      "Iter 5160 | Time 21.5416(21.4094) | Bit/dim 3.6757(3.6864) | Xent 0.0778(0.1061) | Loss 3.7147(3.7395) | Error 0.0256(0.0357) Steps 838(851.48) | Grad Norm 2.7541(3.6196) | Total Time 14.00(14.00)\n",
      "Iter 5170 | Time 21.9032(21.4008) | Bit/dim 3.6832(3.6823) | Xent 0.1040(0.1083) | Loss 3.7352(3.7364) | Error 0.0378(0.0361) Steps 862(849.60) | Grad Norm 2.8249(3.4308) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 102.8116, Epoch Time 1296.8664(1243.6785), Bit/dim 3.6977(best: 3.6978), Xent 1.7063, Loss 4.5509, Error 0.3353(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 21.6675(21.3610) | Bit/dim 3.6887(3.6833) | Xent 0.1212(0.1098) | Loss 3.7493(3.7382) | Error 0.0411(0.0369) Steps 880(851.03) | Grad Norm 7.3142(3.9027) | Total Time 14.00(14.00)\n",
      "Iter 5190 | Time 21.1799(21.3466) | Bit/dim 3.6563(3.6814) | Xent 0.0980(0.1072) | Loss 3.7053(3.7350) | Error 0.0378(0.0358) Steps 862(851.65) | Grad Norm 4.5019(3.9052) | Total Time 14.00(14.00)\n",
      "Iter 5200 | Time 20.6485(21.3179) | Bit/dim 3.6751(3.6830) | Xent 0.0668(0.1053) | Loss 3.7084(3.7357) | Error 0.0244(0.0351) Steps 844(851.56) | Grad Norm 4.4885(4.0445) | Total Time 14.00(14.00)\n",
      "Iter 5210 | Time 21.3457(21.2870) | Bit/dim 3.6836(3.6859) | Xent 0.1418(0.1164) | Loss 3.7545(3.7441) | Error 0.0489(0.0389) Steps 844(850.38) | Grad Norm 4.8870(4.6175) | Total Time 14.00(14.00)\n",
      "Iter 5220 | Time 20.3891(21.2165) | Bit/dim 3.6822(3.6853) | Xent 0.1225(0.1222) | Loss 3.7434(3.7464) | Error 0.0378(0.0404) Steps 832(847.42) | Grad Norm 4.7689(4.6175) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 103.0660, Epoch Time 1288.2653(1245.0161), Bit/dim 3.7084(best: 3.6977), Xent 1.7550, Loss 4.5859, Error 0.3482(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 21.1279(21.2415) | Bit/dim 3.6566(3.6866) | Xent 0.1160(0.1215) | Loss 3.7147(3.7474) | Error 0.0356(0.0400) Steps 850(848.79) | Grad Norm 3.8672(4.4720) | Total Time 14.00(14.00)\n",
      "Iter 5240 | Time 21.7444(21.3313) | Bit/dim 3.6868(3.6898) | Xent 0.1276(0.1194) | Loss 3.7506(3.7494) | Error 0.0456(0.0398) Steps 856(851.23) | Grad Norm 5.6678(4.3671) | Total Time 14.00(14.00)\n",
      "Iter 5250 | Time 21.2580(21.3689) | Bit/dim 3.6769(3.6922) | Xent 0.2004(0.1415) | Loss 3.7771(3.7629) | Error 0.0656(0.0469) Steps 850(850.87) | Grad Norm 6.4136(5.2519) | Total Time 14.00(14.00)\n",
      "Iter 5260 | Time 21.4737(21.4149) | Bit/dim 3.7038(3.6991) | Xent 0.2036(0.1670) | Loss 3.8056(3.7826) | Error 0.0700(0.0558) Steps 844(850.76) | Grad Norm 4.9917(5.4134) | Total Time 14.00(14.00)\n",
      "Iter 5270 | Time 21.0051(21.5284) | Bit/dim 3.6720(3.6979) | Xent 0.1934(0.1665) | Loss 3.7687(3.7811) | Error 0.0678(0.0553) Steps 844(852.47) | Grad Norm 5.6169(5.1933) | Total Time 14.00(14.00)\n",
      "Iter 5280 | Time 21.1446(21.5078) | Bit/dim 3.7200(3.6962) | Xent 0.1325(0.1600) | Loss 3.7863(3.7762) | Error 0.0489(0.0531) Steps 844(852.26) | Grad Norm 3.1005(4.7775) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 101.8237, Epoch Time 1305.7197(1246.8372), Bit/dim 3.7036(best: 3.6977), Xent 1.6717, Loss 4.5395, Error 0.3483(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 21.3434(21.4659) | Bit/dim 3.7094(3.6955) | Xent 0.1040(0.1464) | Loss 3.7614(3.7687) | Error 0.0367(0.0484) Steps 868(851.55) | Grad Norm 3.6855(4.4407) | Total Time 14.00(14.00)\n",
      "Iter 5300 | Time 21.1418(21.5509) | Bit/dim 3.6511(3.6883) | Xent 0.1304(0.1369) | Loss 3.7163(3.7568) | Error 0.0444(0.0453) Steps 850(852.95) | Grad Norm 5.7510(4.3352) | Total Time 14.00(14.00)\n",
      "Iter 5310 | Time 20.9732(21.5430) | Bit/dim 3.7122(3.6898) | Xent 0.1135(0.1261) | Loss 3.7689(3.7528) | Error 0.0411(0.0423) Steps 832(851.21) | Grad Norm 5.1819(4.2287) | Total Time 14.00(14.00)\n",
      "Iter 5320 | Time 21.2214(21.4734) | Bit/dim 3.6726(3.6880) | Xent 0.1086(0.1212) | Loss 3.7269(3.7486) | Error 0.0356(0.0404) Steps 874(851.14) | Grad Norm 3.5225(4.1648) | Total Time 14.00(14.00)\n",
      "Iter 5330 | Time 21.3946(21.5300) | Bit/dim 3.6725(3.6838) | Xent 0.0903(0.1137) | Loss 3.7177(3.7407) | Error 0.0300(0.0378) Steps 880(852.03) | Grad Norm 3.7382(3.8894) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 101.6752, Epoch Time 1300.4093(1248.4443), Bit/dim 3.6940(best: 3.6977), Xent 1.8870, Loss 4.6375, Error 0.3451(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 21.7269(21.4449) | Bit/dim 3.6697(3.6809) | Xent 0.1282(0.1120) | Loss 3.7338(3.7369) | Error 0.0422(0.0370) Steps 850(851.01) | Grad Norm 5.8897(4.0861) | Total Time 14.00(14.00)\n",
      "Iter 5350 | Time 21.8064(21.4881) | Bit/dim 3.6693(3.6803) | Xent 0.0876(0.1102) | Loss 3.7131(3.7353) | Error 0.0311(0.0361) Steps 844(854.36) | Grad Norm 2.7618(4.0134) | Total Time 14.00(14.00)\n",
      "Iter 5360 | Time 21.9082(21.4890) | Bit/dim 3.6577(3.6802) | Xent 0.1071(0.1082) | Loss 3.7112(3.7343) | Error 0.0411(0.0355) Steps 844(851.39) | Grad Norm 5.3948(4.1625) | Total Time 14.00(14.00)\n",
      "Iter 5370 | Time 21.9803(21.4900) | Bit/dim 3.6866(3.6783) | Xent 0.0732(0.1036) | Loss 3.7232(3.7301) | Error 0.0222(0.0339) Steps 856(854.05) | Grad Norm 2.3379(3.8163) | Total Time 14.00(14.00)\n",
      "Iter 5380 | Time 21.9676(21.5667) | Bit/dim 3.7436(3.6809) | Xent 0.1217(0.0994) | Loss 3.8044(3.7306) | Error 0.0333(0.0322) Steps 862(855.96) | Grad Norm 3.2607(3.5585) | Total Time 14.00(14.00)\n",
      "Iter 5390 | Time 21.3638(21.5066) | Bit/dim 3.6770(3.6772) | Xent 0.1050(0.0981) | Loss 3.7295(3.7262) | Error 0.0278(0.0320) Steps 862(855.17) | Grad Norm 4.6946(3.4598) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 101.3719, Epoch Time 1304.0533(1250.1126), Bit/dim 3.6888(best: 3.6940), Xent 1.8736, Loss 4.6256, Error 0.3461(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 21.7525(21.5003) | Bit/dim 3.6823(3.6784) | Xent 0.0720(0.0932) | Loss 3.7183(3.7250) | Error 0.0244(0.0304) Steps 868(854.63) | Grad Norm 1.9617(3.4028) | Total Time 14.00(14.00)\n",
      "Iter 5410 | Time 21.7190(21.5931) | Bit/dim 3.6363(3.6767) | Xent 0.0732(0.0900) | Loss 3.6728(3.7217) | Error 0.0256(0.0293) Steps 880(856.90) | Grad Norm 2.3410(3.2114) | Total Time 14.00(14.00)\n",
      "Iter 5420 | Time 20.6065(21.4774) | Bit/dim 3.7095(3.6777) | Xent 0.0851(0.0912) | Loss 3.7521(3.7233) | Error 0.0300(0.0296) Steps 844(854.01) | Grad Norm 3.8660(3.4662) | Total Time 14.00(14.00)\n",
      "Iter 5430 | Time 21.5502(21.4911) | Bit/dim 3.6595(3.6741) | Xent 0.1144(0.0969) | Loss 3.7167(3.7225) | Error 0.0400(0.0313) Steps 844(853.07) | Grad Norm 3.9264(3.5830) | Total Time 14.00(14.00)\n",
      "Iter 5440 | Time 21.4307(21.4816) | Bit/dim 3.6833(3.6746) | Xent 0.1027(0.0977) | Loss 3.7346(3.7234) | Error 0.0322(0.0314) Steps 838(853.10) | Grad Norm 2.7230(3.5161) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 102.2234, Epoch Time 1303.7664(1251.7222), Bit/dim 3.6895(best: 3.6888), Xent 1.7683, Loss 4.5736, Error 0.3421(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 21.3835(21.5453) | Bit/dim 3.6827(3.6751) | Xent 0.0709(0.0975) | Loss 3.7181(3.7239) | Error 0.0200(0.0317) Steps 868(855.32) | Grad Norm 3.8706(3.6354) | Total Time 14.00(14.00)\n",
      "Iter 5460 | Time 21.1910(21.5762) | Bit/dim 3.6704(3.6728) | Xent 0.0965(0.0977) | Loss 3.7187(3.7216) | Error 0.0322(0.0319) Steps 850(855.30) | Grad Norm 3.6159(3.7532) | Total Time 14.00(14.00)\n",
      "Iter 5470 | Time 22.0912(21.5425) | Bit/dim 3.6769(3.6709) | Xent 0.0845(0.0951) | Loss 3.7191(3.7184) | Error 0.0289(0.0311) Steps 814(852.67) | Grad Norm 3.2001(3.8954) | Total Time 14.00(14.00)\n",
      "Iter 5480 | Time 21.1232(21.4968) | Bit/dim 3.6888(3.6756) | Xent 0.1549(0.0990) | Loss 3.7662(3.7251) | Error 0.0411(0.0323) Steps 832(852.32) | Grad Norm 6.5939(4.0295) | Total Time 14.00(14.00)\n",
      "Iter 5490 | Time 22.6605(21.5847) | Bit/dim 3.7040(3.6776) | Xent 0.1086(0.1041) | Loss 3.7582(3.7296) | Error 0.0344(0.0339) Steps 856(849.82) | Grad Norm 3.1084(4.0239) | Total Time 14.00(14.00)\n",
      "Iter 5500 | Time 21.8496(21.5876) | Bit/dim 3.6601(3.6774) | Xent 0.0881(0.0989) | Loss 3.7042(3.7268) | Error 0.0267(0.0318) Steps 874(851.78) | Grad Norm 3.1449(3.7731) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 100.7173, Epoch Time 1305.9974(1253.3505), Bit/dim 3.6854(best: 3.6888), Xent 1.8165, Loss 4.5937, Error 0.3405(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 21.2616(21.6148) | Bit/dim 3.6838(3.6741) | Xent 0.0638(0.0956) | Loss 3.7157(3.7219) | Error 0.0200(0.0309) Steps 856(850.15) | Grad Norm 4.7401(3.8590) | Total Time 14.00(14.00)\n",
      "Iter 5520 | Time 21.9232(21.6210) | Bit/dim 3.6476(3.6729) | Xent 0.1227(0.0963) | Loss 3.7090(3.7210) | Error 0.0378(0.0311) Steps 844(850.39) | Grad Norm 5.2693(3.9555) | Total Time 14.00(14.00)\n",
      "Iter 5530 | Time 21.8247(21.6652) | Bit/dim 3.6364(3.6723) | Xent 0.0840(0.0939) | Loss 3.6784(3.7192) | Error 0.0289(0.0300) Steps 844(851.14) | Grad Norm 3.3984(3.8642) | Total Time 14.00(14.00)\n",
      "Iter 5540 | Time 22.0623(21.6342) | Bit/dim 3.6722(3.6731) | Xent 0.1066(0.0952) | Loss 3.7255(3.7207) | Error 0.0356(0.0310) Steps 868(854.03) | Grad Norm 2.9063(4.1215) | Total Time 14.00(14.00)\n",
      "Iter 5550 | Time 21.8949(21.6201) | Bit/dim 3.7331(3.6750) | Xent 0.0874(0.0994) | Loss 3.7768(3.7247) | Error 0.0367(0.0327) Steps 862(854.74) | Grad Norm 4.0543(4.2531) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 102.2925, Epoch Time 1311.2054(1255.0861), Bit/dim 3.6932(best: 3.6854), Xent 1.8710, Loss 4.6287, Error 0.3486(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 21.8287(21.6169) | Bit/dim 3.7079(3.6797) | Xent 0.1121(0.1029) | Loss 3.7639(3.7311) | Error 0.0378(0.0337) Steps 820(854.09) | Grad Norm 3.8169(4.2758) | Total Time 14.00(14.00)\n",
      "Iter 5570 | Time 21.4425(21.5754) | Bit/dim 3.6784(3.6789) | Xent 0.1108(0.1024) | Loss 3.7338(3.7300) | Error 0.0367(0.0338) Steps 850(852.43) | Grad Norm 3.2550(4.1624) | Total Time 14.00(14.00)\n",
      "Iter 5580 | Time 22.2210(21.6720) | Bit/dim 3.6645(3.6771) | Xent 0.0835(0.1045) | Loss 3.7063(3.7293) | Error 0.0300(0.0342) Steps 862(853.92) | Grad Norm 4.1898(4.3848) | Total Time 14.00(14.00)\n",
      "Iter 5590 | Time 21.3748(21.6035) | Bit/dim 3.6426(3.6737) | Xent 0.0867(0.1073) | Loss 3.6860(3.7273) | Error 0.0311(0.0353) Steps 850(850.68) | Grad Norm 4.2336(4.4269) | Total Time 14.00(14.00)\n",
      "Iter 5600 | Time 21.8742(21.5621) | Bit/dim 3.6550(3.6758) | Xent 0.1135(0.1144) | Loss 3.7118(3.7330) | Error 0.0300(0.0369) Steps 844(851.28) | Grad Norm 2.4717(4.7264) | Total Time 14.00(14.00)\n",
      "Iter 5610 | Time 21.4440(21.5566) | Bit/dim 3.6734(3.6785) | Xent 0.1010(0.1146) | Loss 3.7239(3.7358) | Error 0.0356(0.0373) Steps 832(849.54) | Grad Norm 4.8468(4.7464) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 102.3936, Epoch Time 1306.4271(1256.6263), Bit/dim 3.6958(best: 3.6854), Xent 1.8316, Loss 4.6116, Error 0.3458(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 21.4028(21.6194) | Bit/dim 3.6441(3.6764) | Xent 0.0987(0.1104) | Loss 3.6935(3.7316) | Error 0.0244(0.0355) Steps 844(854.04) | Grad Norm 3.8673(4.4810) | Total Time 14.00(14.00)\n",
      "Iter 5630 | Time 20.7598(21.5724) | Bit/dim 3.6803(3.6775) | Xent 0.0893(0.1054) | Loss 3.7249(3.7302) | Error 0.0311(0.0342) Steps 862(854.08) | Grad Norm 4.8976(4.2286) | Total Time 14.00(14.00)\n",
      "Iter 5640 | Time 21.5378(21.5503) | Bit/dim 3.6390(3.6743) | Xent 0.0718(0.0974) | Loss 3.6749(3.7230) | Error 0.0267(0.0318) Steps 844(853.33) | Grad Norm 2.6155(3.8998) | Total Time 14.00(14.00)\n",
      "Iter 5650 | Time 21.1750(21.5472) | Bit/dim 3.6710(3.6719) | Xent 0.0731(0.0909) | Loss 3.7075(3.7174) | Error 0.0200(0.0298) Steps 850(854.10) | Grad Norm 3.0881(3.5836) | Total Time 14.00(14.00)\n",
      "Iter 5660 | Time 21.7254(21.5414) | Bit/dim 3.6912(3.6704) | Xent 0.0911(0.0917) | Loss 3.7368(3.7163) | Error 0.0256(0.0296) Steps 826(853.70) | Grad Norm 3.2084(3.4873) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 103.0404, Epoch Time 1306.9802(1258.1370), Bit/dim 3.6831(best: 3.6854), Xent 1.8449, Loss 4.6056, Error 0.3422(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 21.9263(21.5582) | Bit/dim 3.7164(3.6733) | Xent 0.1915(0.0954) | Loss 3.8121(3.7210) | Error 0.0567(0.0313) Steps 874(856.29) | Grad Norm 9.9706(4.0629) | Total Time 14.00(14.00)\n",
      "Iter 5680 | Time 22.3190(21.7246) | Bit/dim 3.6641(3.6742) | Xent 0.1441(0.1052) | Loss 3.7361(3.7268) | Error 0.0456(0.0342) Steps 868(859.52) | Grad Norm 6.4351(4.6058) | Total Time 14.00(14.00)\n",
      "Iter 5690 | Time 21.8734(21.7106) | Bit/dim 3.6698(3.6743) | Xent 0.0985(0.1056) | Loss 3.7190(3.7271) | Error 0.0322(0.0346) Steps 832(858.67) | Grad Norm 4.5115(4.5225) | Total Time 14.00(14.00)\n",
      "Iter 5700 | Time 21.2264(21.6686) | Bit/dim 3.6665(3.6734) | Xent 0.0638(0.1004) | Loss 3.6984(3.7236) | Error 0.0178(0.0327) Steps 874(860.90) | Grad Norm 2.1440(4.1908) | Total Time 14.00(14.00)\n",
      "Iter 5710 | Time 22.1691(21.7151) | Bit/dim 3.6881(3.6699) | Xent 0.1104(0.0970) | Loss 3.7433(3.7184) | Error 0.0356(0.0317) Steps 874(861.34) | Grad Norm 3.2365(3.9252) | Total Time 14.00(14.00)\n",
      "Iter 5720 | Time 22.0925(21.7241) | Bit/dim 3.6693(3.6713) | Xent 0.0866(0.0914) | Loss 3.7126(3.7170) | Error 0.0278(0.0300) Steps 844(859.80) | Grad Norm 3.6118(3.7130) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 102.3269, Epoch Time 1318.5274(1259.9487), Bit/dim 3.6793(best: 3.6831), Xent 1.8404, Loss 4.5995, Error 0.3449(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 21.7966(21.8300) | Bit/dim 3.6694(3.6695) | Xent 0.1103(0.0886) | Loss 3.7245(3.7138) | Error 0.0344(0.0287) Steps 862(861.21) | Grad Norm 2.9475(3.5472) | Total Time 14.00(14.00)\n",
      "Iter 5740 | Time 21.1120(21.8586) | Bit/dim 3.6678(3.6670) | Xent 0.0473(0.0871) | Loss 3.6914(3.7105) | Error 0.0133(0.0280) Steps 856(861.88) | Grad Norm 2.5748(3.5273) | Total Time 14.00(14.00)\n",
      "Iter 5750 | Time 21.7565(21.8073) | Bit/dim 3.6906(3.6661) | Xent 0.1076(0.0867) | Loss 3.7444(3.7095) | Error 0.0344(0.0281) Steps 856(862.90) | Grad Norm 3.0032(3.3491) | Total Time 14.00(14.00)\n",
      "Iter 5760 | Time 21.8591(21.7502) | Bit/dim 3.6666(3.6661) | Xent 0.0954(0.0892) | Loss 3.7143(3.7107) | Error 0.0322(0.0292) Steps 850(861.79) | Grad Norm 2.7228(3.3103) | Total Time 14.00(14.00)\n",
      "Iter 5770 | Time 21.6046(21.7604) | Bit/dim 3.6595(3.6678) | Xent 0.1035(0.0908) | Loss 3.7113(3.7132) | Error 0.0311(0.0297) Steps 880(863.14) | Grad Norm 3.0936(3.3575) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 102.9548, Epoch Time 1320.7164(1261.7717), Bit/dim 3.6860(best: 3.6793), Xent 1.8562, Loss 4.6141, Error 0.3448(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 21.9426(21.7409) | Bit/dim 3.6555(3.6676) | Xent 0.0975(0.0883) | Loss 3.7043(3.7118) | Error 0.0289(0.0291) Steps 856(862.40) | Grad Norm 4.5915(3.2778) | Total Time 14.00(14.00)\n",
      "Iter 5790 | Time 21.9499(21.7494) | Bit/dim 3.6815(3.6678) | Xent 0.1293(0.0892) | Loss 3.7461(3.7124) | Error 0.0444(0.0289) Steps 880(863.55) | Grad Norm 9.6389(3.6423) | Total Time 14.00(14.00)\n",
      "Iter 5800 | Time 22.3611(21.7787) | Bit/dim 3.6903(3.6683) | Xent 0.0722(0.0874) | Loss 3.7264(3.7120) | Error 0.0256(0.0288) Steps 856(863.20) | Grad Norm 2.3347(3.6644) | Total Time 14.00(14.00)\n",
      "Iter 5810 | Time 21.6798(21.7889) | Bit/dim 3.6582(3.6660) | Xent 0.0502(0.0862) | Loss 3.6833(3.7091) | Error 0.0156(0.0285) Steps 874(861.85) | Grad Norm 2.5481(3.5061) | Total Time 14.00(14.00)\n",
      "Iter 5820 | Time 22.1162(21.8714) | Bit/dim 3.6420(3.6644) | Xent 0.1014(0.0856) | Loss 3.6927(3.7072) | Error 0.0344(0.0281) Steps 862(861.84) | Grad Norm 3.2817(3.4073) | Total Time 14.00(14.00)\n",
      "Iter 5830 | Time 21.6351(21.8879) | Bit/dim 3.6767(3.6647) | Xent 0.0657(0.0886) | Loss 3.7095(3.7090) | Error 0.0200(0.0289) Steps 856(862.37) | Grad Norm 2.6467(3.5272) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 102.2151, Epoch Time 1324.2115(1263.6449), Bit/dim 3.6798(best: 3.6793), Xent 1.8305, Loss 4.5951, Error 0.3512(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 21.5115(21.8089) | Bit/dim 3.6730(3.6645) | Xent 0.1132(0.0868) | Loss 3.7296(3.7079) | Error 0.0367(0.0285) Steps 856(861.09) | Grad Norm 3.2927(3.3418) | Total Time 14.00(14.00)\n",
      "Iter 5850 | Time 21.8578(21.7700) | Bit/dim 3.6356(3.6639) | Xent 0.0844(0.0829) | Loss 3.6778(3.7054) | Error 0.0278(0.0269) Steps 856(862.70) | Grad Norm 2.0988(3.1795) | Total Time 14.00(14.00)\n",
      "Iter 5860 | Time 21.8341(21.8263) | Bit/dim 3.6831(3.6641) | Xent 0.0996(0.0793) | Loss 3.7329(3.7037) | Error 0.0322(0.0258) Steps 874(863.42) | Grad Norm 2.1918(3.0049) | Total Time 14.00(14.00)\n",
      "Iter 5870 | Time 21.7459(21.8855) | Bit/dim 3.6641(3.6597) | Xent 0.1056(0.0810) | Loss 3.7169(3.7002) | Error 0.0367(0.0263) Steps 874(866.21) | Grad Norm 5.9871(3.1664) | Total Time 14.00(14.00)\n",
      "Iter 5880 | Time 22.1307(21.9686) | Bit/dim 3.6801(3.6604) | Xent 0.1070(0.0849) | Loss 3.7336(3.7028) | Error 0.0322(0.0274) Steps 886(868.83) | Grad Norm 2.9303(3.2587) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 101.5691, Epoch Time 1322.8346(1265.4206), Bit/dim 3.6846(best: 3.6793), Xent 1.7649, Loss 4.5671, Error 0.3405(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 22.0092(21.9261) | Bit/dim 3.6679(3.6592) | Xent 0.0915(0.0866) | Loss 3.7137(3.7025) | Error 0.0289(0.0279) Steps 850(866.96) | Grad Norm 4.4544(3.3086) | Total Time 14.00(14.00)\n",
      "Iter 5900 | Time 22.0249(21.9723) | Bit/dim 3.6750(3.6632) | Xent 0.0635(0.0835) | Loss 3.7068(3.7050) | Error 0.0189(0.0266) Steps 874(867.68) | Grad Norm 3.1399(3.4070) | Total Time 14.00(14.00)\n",
      "Iter 5910 | Time 22.2536(21.9879) | Bit/dim 3.6704(3.6623) | Xent 0.1211(0.0848) | Loss 3.7310(3.7047) | Error 0.0422(0.0272) Steps 880(868.43) | Grad Norm 3.5715(3.4004) | Total Time 14.00(14.00)\n",
      "Iter 5920 | Time 21.6781(21.9696) | Bit/dim 3.6287(3.6590) | Xent 0.0763(0.0831) | Loss 3.6669(3.7006) | Error 0.0267(0.0270) Steps 862(865.90) | Grad Norm 2.8298(3.3581) | Total Time 14.00(14.00)\n",
      "Iter 5930 | Time 22.4684(21.9181) | Bit/dim 3.6550(3.6584) | Xent 0.0853(0.0825) | Loss 3.6976(3.6996) | Error 0.0244(0.0268) Steps 880(865.51) | Grad Norm 3.5437(3.4084) | Total Time 14.00(14.00)\n",
      "Iter 5940 | Time 21.7028(21.9667) | Bit/dim 3.6385(3.6588) | Xent 0.0720(0.0804) | Loss 3.6745(3.6990) | Error 0.0222(0.0263) Steps 832(862.51) | Grad Norm 3.9854(3.3238) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 101.0352, Epoch Time 1328.0882(1267.3006), Bit/dim 3.6714(best: 3.6793), Xent 1.9240, Loss 4.6334, Error 0.3515(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 21.3023(21.8848) | Bit/dim 3.6934(3.6581) | Xent 0.0868(0.0796) | Loss 3.7368(3.6979) | Error 0.0267(0.0261) Steps 886(862.94) | Grad Norm 3.1725(3.2070) | Total Time 14.00(14.00)\n",
      "Iter 5960 | Time 22.3669(21.8945) | Bit/dim 3.6880(3.6589) | Xent 0.0694(0.0830) | Loss 3.7227(3.7004) | Error 0.0311(0.0276) Steps 862(862.64) | Grad Norm 4.3888(3.5775) | Total Time 14.00(14.00)\n",
      "Iter 5970 | Time 21.8910(21.8333) | Bit/dim 3.6866(3.6593) | Xent 0.0840(0.0849) | Loss 3.7286(3.7017) | Error 0.0311(0.0280) Steps 856(861.48) | Grad Norm 3.0771(3.5987) | Total Time 14.00(14.00)\n",
      "Iter 5980 | Time 20.6034(21.7239) | Bit/dim 3.6546(3.6581) | Xent 0.0759(0.0845) | Loss 3.6925(3.7004) | Error 0.0200(0.0273) Steps 850(858.60) | Grad Norm 2.6510(3.4819) | Total Time 14.00(14.00)\n",
      "Iter 5990 | Time 22.2367(21.7789) | Bit/dim 3.6543(3.6575) | Xent 0.0748(0.0815) | Loss 3.6917(3.6982) | Error 0.0211(0.0265) Steps 844(859.16) | Grad Norm 2.9843(3.2640) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 100.6686, Epoch Time 1313.8375(1268.6967), Bit/dim 3.6739(best: 3.6714), Xent 1.9183, Loss 4.6330, Error 0.3419(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 22.3402(21.8036) | Bit/dim 3.7046(3.6606) | Xent 0.1083(0.0805) | Loss 3.7587(3.7009) | Error 0.0367(0.0264) Steps 886(860.27) | Grad Norm 3.8794(3.2020) | Total Time 14.00(14.00)\n",
      "Iter 6010 | Time 21.5868(21.8223) | Bit/dim 3.6698(3.6631) | Xent 0.1785(0.0877) | Loss 3.7591(3.7070) | Error 0.0533(0.0283) Steps 892(863.30) | Grad Norm 6.4964(3.8201) | Total Time 14.00(14.00)\n",
      "Iter 6020 | Time 20.8812(21.8161) | Bit/dim 3.6277(3.6614) | Xent 0.0860(0.0899) | Loss 3.6707(3.7064) | Error 0.0278(0.0291) Steps 844(862.90) | Grad Norm 3.7423(3.9097) | Total Time 14.00(14.00)\n",
      "Iter 6030 | Time 21.3571(21.7310) | Bit/dim 3.6785(3.6603) | Xent 0.1215(0.0916) | Loss 3.7392(3.7061) | Error 0.0444(0.0295) Steps 838(858.86) | Grad Norm 4.1672(3.8651) | Total Time 14.00(14.00)\n",
      "Iter 6040 | Time 20.8926(21.6570) | Bit/dim 3.6626(3.6600) | Xent 0.0969(0.0872) | Loss 3.7111(3.7036) | Error 0.0322(0.0278) Steps 850(856.06) | Grad Norm 2.5599(3.5085) | Total Time 14.00(14.00)\n",
      "Iter 6050 | Time 21.2545(21.6499) | Bit/dim 3.6527(3.6590) | Xent 0.0722(0.0877) | Loss 3.6889(3.7029) | Error 0.0233(0.0285) Steps 838(853.25) | Grad Norm 2.6691(3.4649) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 101.3217, Epoch Time 1312.2536(1270.0034), Bit/dim 3.6707(best: 3.6714), Xent 1.8862, Loss 4.6138, Error 0.3493(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 21.3745(21.6878) | Bit/dim 3.6409(3.6569) | Xent 0.0505(0.0850) | Loss 3.6662(3.6994) | Error 0.0122(0.0275) Steps 868(855.33) | Grad Norm 2.5890(3.4188) | Total Time 14.00(14.00)\n",
      "Iter 6070 | Time 22.2410(21.8021) | Bit/dim 3.6768(3.6600) | Xent 0.1195(0.0873) | Loss 3.7366(3.7036) | Error 0.0333(0.0279) Steps 862(858.38) | Grad Norm 2.7042(3.6025) | Total Time 14.00(14.00)\n",
      "Iter 6080 | Time 22.0267(21.7737) | Bit/dim 3.6673(3.6591) | Xent 0.0852(0.0872) | Loss 3.7099(3.7027) | Error 0.0244(0.0282) Steps 850(858.78) | Grad Norm 2.8531(3.7334) | Total Time 14.00(14.00)\n",
      "Iter 6090 | Time 21.1988(21.7278) | Bit/dim 3.6518(3.6583) | Xent 0.0853(0.0884) | Loss 3.6945(3.7025) | Error 0.0278(0.0287) Steps 868(857.87) | Grad Norm 3.1539(3.6363) | Total Time 14.00(14.00)\n",
      "Iter 6100 | Time 21.1607(21.6805) | Bit/dim 3.6328(3.6591) | Xent 0.1622(0.0955) | Loss 3.7139(3.7069) | Error 0.0456(0.0309) Steps 886(857.99) | Grad Norm 4.6405(3.7335) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 102.3221, Epoch Time 1316.2529(1271.3909), Bit/dim 3.6808(best: 3.6707), Xent 1.8007, Loss 4.5811, Error 0.3563(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 21.4519(21.6974) | Bit/dim 3.6514(3.6610) | Xent 0.0974(0.0948) | Loss 3.7001(3.7083) | Error 0.0367(0.0312) Steps 850(858.01) | Grad Norm 5.8348(3.8520) | Total Time 14.00(14.00)\n",
      "Iter 6120 | Time 21.5501(21.7133) | Bit/dim 3.6879(3.6612) | Xent 0.0833(0.0921) | Loss 3.7296(3.7072) | Error 0.0233(0.0302) Steps 850(858.89) | Grad Norm 3.5608(3.6716) | Total Time 14.00(14.00)\n",
      "Iter 6130 | Time 21.9601(21.7698) | Bit/dim 3.6281(3.6573) | Xent 0.0719(0.0882) | Loss 3.6641(3.7013) | Error 0.0222(0.0285) Steps 850(858.31) | Grad Norm 2.6992(3.5166) | Total Time 14.00(14.00)\n",
      "Iter 6140 | Time 22.1285(21.8189) | Bit/dim 3.6312(3.6578) | Xent 0.0755(0.0878) | Loss 3.6690(3.7018) | Error 0.0233(0.0283) Steps 850(861.04) | Grad Norm 2.4936(3.4831) | Total Time 14.00(14.00)\n",
      "Iter 6150 | Time 21.7202(21.8642) | Bit/dim 3.6762(3.6556) | Xent 0.1366(0.0883) | Loss 3.7445(3.6997) | Error 0.0422(0.0279) Steps 856(861.92) | Grad Norm 6.4697(3.5255) | Total Time 14.00(14.00)\n",
      "Iter 6160 | Time 22.5849(21.8806) | Bit/dim 3.6569(3.6579) | Xent 0.0739(0.0890) | Loss 3.6939(3.7024) | Error 0.0200(0.0279) Steps 862(863.02) | Grad Norm 3.0880(3.7362) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 103.7566, Epoch Time 1326.4983(1273.0441), Bit/dim 3.6858(best: 3.6707), Xent 1.9760, Loss 4.6738, Error 0.3584(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 21.2983(21.8856) | Bit/dim 3.6596(3.6593) | Xent 0.0727(0.0925) | Loss 3.6960(3.7056) | Error 0.0211(0.0292) Steps 856(863.35) | Grad Norm 2.0615(4.0279) | Total Time 14.00(14.00)\n",
      "Iter 6180 | Time 21.6470(21.8804) | Bit/dim 3.6622(3.6575) | Xent 0.1197(0.0954) | Loss 3.7221(3.7052) | Error 0.0400(0.0307) Steps 856(863.90) | Grad Norm 3.2861(3.9663) | Total Time 14.00(14.00)\n",
      "Iter 6190 | Time 21.4553(21.7519) | Bit/dim 3.6770(3.6610) | Xent 0.0917(0.0962) | Loss 3.7228(3.7091) | Error 0.0289(0.0313) Steps 844(857.59) | Grad Norm 3.8901(4.0532) | Total Time 14.00(14.00)\n",
      "Iter 6200 | Time 21.8966(21.7485) | Bit/dim 3.6636(3.6612) | Xent 0.1047(0.0942) | Loss 3.7159(3.7083) | Error 0.0311(0.0307) Steps 868(856.60) | Grad Norm 5.8021(4.0898) | Total Time 14.00(14.00)\n",
      "Iter 6210 | Time 21.7159(21.7917) | Bit/dim 3.6710(3.6600) | Xent 0.1073(0.0961) | Loss 3.7247(3.7081) | Error 0.0333(0.0308) Steps 856(858.22) | Grad Norm 2.9990(3.9839) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 104.0607, Epoch Time 1321.1455(1274.4872), Bit/dim 3.6710(best: 3.6707), Xent 1.8546, Loss 4.5983, Error 0.3418(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 21.6463(21.8331) | Bit/dim 3.6572(3.6625) | Xent 0.0694(0.0914) | Loss 3.6919(3.7082) | Error 0.0211(0.0296) Steps 874(860.44) | Grad Norm 2.7029(3.6610) | Total Time 14.00(14.00)\n",
      "Iter 6230 | Time 22.0226(21.8214) | Bit/dim 3.6808(3.6597) | Xent 0.0798(0.0882) | Loss 3.7207(3.7038) | Error 0.0278(0.0289) Steps 856(861.86) | Grad Norm 3.1471(3.5118) | Total Time 14.00(14.00)\n",
      "Iter 6240 | Time 21.2170(21.8762) | Bit/dim 3.6636(3.6563) | Xent 0.0732(0.0876) | Loss 3.7002(3.7001) | Error 0.0278(0.0287) Steps 850(864.90) | Grad Norm 3.1936(3.4556) | Total Time 14.00(14.00)\n",
      "Iter 6250 | Time 21.8714(21.8377) | Bit/dim 3.6569(3.6580) | Xent 0.0988(0.0863) | Loss 3.7063(3.7012) | Error 0.0322(0.0281) Steps 856(861.72) | Grad Norm 2.6100(3.4771) | Total Time 14.00(14.00)\n",
      "Iter 6260 | Time 22.2411(21.8873) | Bit/dim 3.6438(3.6562) | Xent 0.0929(0.0870) | Loss 3.6902(3.6997) | Error 0.0300(0.0286) Steps 886(861.92) | Grad Norm 4.3120(3.4883) | Total Time 14.00(14.00)\n",
      "Iter 6270 | Time 22.0625(21.8125) | Bit/dim 3.6703(3.6568) | Xent 0.1400(0.0869) | Loss 3.7403(3.7002) | Error 0.0467(0.0285) Steps 862(861.96) | Grad Norm 3.7760(3.3710) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 102.8021, Epoch Time 1321.8448(1275.9079), Bit/dim 3.6754(best: 3.6707), Xent 1.9038, Loss 4.6273, Error 0.3514(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 22.1160(21.8012) | Bit/dim 3.6897(3.6584) | Xent 0.1203(0.0879) | Loss 3.7498(3.7024) | Error 0.0322(0.0288) Steps 850(860.48) | Grad Norm 4.0954(3.5676) | Total Time 14.00(14.00)\n",
      "Iter 6290 | Time 22.4279(21.7220) | Bit/dim 3.6876(3.6579) | Xent 0.1625(0.0970) | Loss 3.7689(3.7064) | Error 0.0444(0.0310) Steps 868(859.41) | Grad Norm 8.8166(4.1592) | Total Time 14.00(14.00)\n",
      "Iter 6300 | Time 22.4164(21.7730) | Bit/dim 3.6652(3.6600) | Xent 0.0726(0.0975) | Loss 3.7015(3.7087) | Error 0.0267(0.0315) Steps 862(859.58) | Grad Norm 3.7180(4.0661) | Total Time 14.00(14.00)\n",
      "Iter 6310 | Time 21.8563(21.7799) | Bit/dim 3.6257(3.6576) | Xent 0.1078(0.0960) | Loss 3.6796(3.7057) | Error 0.0378(0.0313) Steps 862(858.95) | Grad Norm 2.7421(3.9813) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 103.0885, Epoch Time 1316.3584(1277.1214), Bit/dim 3.6705(best: 3.6707), Xent 1.8831, Loss 4.6121, Error 0.3465(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 22.4265(21.7703) | Bit/dim 3.6764(3.6546) | Xent 0.0969(0.0881) | Loss 3.7249(3.6986) | Error 0.0333(0.0287) Steps 850(860.43) | Grad Norm 4.2156(3.6448) | Total Time 14.00(14.00)\n",
      "Iter 6340 | Time 22.1740(21.8862) | Bit/dim 3.6481(3.6541) | Xent 0.0628(0.0869) | Loss 3.6795(3.6975) | Error 0.0200(0.0282) Steps 910(866.77) | Grad Norm 2.9305(3.7372) | Total Time 14.00(14.00)\n",
      "Iter 6350 | Time 21.4379(21.8755) | Bit/dim 3.6772(3.6539) | Xent 0.0977(0.0837) | Loss 3.7260(3.6957) | Error 0.0322(0.0275) Steps 880(872.22) | Grad Norm 3.3828(3.6361) | Total Time 14.00(14.00)\n",
      "Iter 6360 | Time 22.9211(22.0165) | Bit/dim 3.6744(3.6547) | Xent 0.0531(0.0826) | Loss 3.7009(3.6960) | Error 0.0211(0.0271) Steps 892(876.63) | Grad Norm 2.6071(3.5159) | Total Time 14.00(14.00)\n",
      "Iter 6370 | Time 21.6967(22.0239) | Bit/dim 3.6326(3.6516) | Xent 0.0994(0.0822) | Loss 3.6823(3.6927) | Error 0.0322(0.0270) Steps 886(877.79) | Grad Norm 3.8308(3.3160) | Total Time 14.00(14.00)\n",
      "Iter 6380 | Time 21.8536(21.9452) | Bit/dim 3.6858(3.6520) | Xent 0.0585(0.0822) | Loss 3.7151(3.6931) | Error 0.0178(0.0266) Steps 892(876.80) | Grad Norm 3.0597(3.4092) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 102.5406, Epoch Time 1333.1491(1278.8023), Bit/dim 3.6719(best: 3.6705), Xent 1.8875, Loss 4.6156, Error 0.3516(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 21.6138(21.9130) | Bit/dim 3.6499(3.6534) | Xent 0.1611(0.0855) | Loss 3.7304(3.6961) | Error 0.0467(0.0272) Steps 844(875.02) | Grad Norm 6.9897(3.5698) | Total Time 14.00(14.00)\n",
      "Iter 6400 | Time 22.3736(21.8776) | Bit/dim 3.6943(3.6570) | Xent 0.1240(0.0932) | Loss 3.7563(3.7036) | Error 0.0311(0.0294) Steps 868(870.06) | Grad Norm 3.0455(3.6748) | Total Time 14.00(14.00)\n",
      "Iter 6410 | Time 20.8235(21.8216) | Bit/dim 3.6810(3.6576) | Xent 0.0846(0.0941) | Loss 3.7233(3.7046) | Error 0.0322(0.0301) Steps 850(869.71) | Grad Norm 3.2725(3.6765) | Total Time 14.00(14.00)\n",
      "Iter 6420 | Time 21.1792(21.8315) | Bit/dim 3.6609(3.6555) | Xent 0.0942(0.0923) | Loss 3.7080(3.7017) | Error 0.0333(0.0298) Steps 880(868.90) | Grad Norm 4.0478(3.6069) | Total Time 14.00(14.00)\n",
      "Iter 6430 | Time 22.0588(21.8451) | Bit/dim 3.6328(3.6529) | Xent 0.0621(0.0927) | Loss 3.6638(3.6992) | Error 0.0178(0.0301) Steps 868(868.68) | Grad Norm 2.7893(3.6342) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 102.7243, Epoch Time 1320.0527(1280.0398), Bit/dim 3.6790(best: 3.6705), Xent 1.7761, Loss 4.5670, Error 0.3421(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 21.2507(21.7725) | Bit/dim 3.6576(3.6532) | Xent 0.0735(0.0936) | Loss 3.6944(3.7000) | Error 0.0278(0.0306) Steps 868(867.97) | Grad Norm 2.6145(3.6381) | Total Time 14.00(14.00)\n",
      "Iter 6450 | Time 21.7424(21.8590) | Bit/dim 3.6648(3.6544) | Xent 0.0715(0.0895) | Loss 3.7005(3.6992) | Error 0.0222(0.0291) Steps 880(868.10) | Grad Norm 2.6598(3.5094) | Total Time 14.00(14.00)\n",
      "Iter 6460 | Time 22.0271(21.8377) | Bit/dim 3.6597(3.6527) | Xent 0.1283(0.0890) | Loss 3.7239(3.6972) | Error 0.0378(0.0284) Steps 868(869.12) | Grad Norm 4.8986(3.2958) | Total Time 14.00(14.00)\n",
      "Iter 6470 | Time 21.8717(21.8309) | Bit/dim 3.6502(3.6533) | Xent 0.0818(0.0867) | Loss 3.6911(3.6967) | Error 0.0256(0.0279) Steps 868(869.21) | Grad Norm 3.0440(3.2235) | Total Time 14.00(14.00)\n",
      "Iter 6480 | Time 21.9378(21.7999) | Bit/dim 3.6184(3.6506) | Xent 0.0866(0.0830) | Loss 3.6617(3.6921) | Error 0.0244(0.0264) Steps 892(868.69) | Grad Norm 2.2498(3.1013) | Total Time 14.00(14.00)\n",
      "Iter 6490 | Time 22.6139(21.8717) | Bit/dim 3.6458(3.6481) | Xent 0.0787(0.0845) | Loss 3.6851(3.6903) | Error 0.0256(0.0268) Steps 880(871.54) | Grad Norm 2.3499(3.1953) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 102.5303, Epoch Time 1322.7703(1281.3217), Bit/dim 3.6665(best: 3.6705), Xent 1.9002, Loss 4.6166, Error 0.3539(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 22.5722(21.9612) | Bit/dim 3.6709(3.6503) | Xent 0.0703(0.0821) | Loss 3.7061(3.6914) | Error 0.0256(0.0265) Steps 862(872.17) | Grad Norm 2.9645(3.3144) | Total Time 14.00(14.00)\n",
      "Iter 6510 | Time 23.1887(22.0239) | Bit/dim 3.6391(3.6499) | Xent 0.0664(0.0789) | Loss 3.6723(3.6894) | Error 0.0233(0.0256) Steps 862(874.19) | Grad Norm 2.3704(3.3668) | Total Time 14.00(14.00)\n",
      "Iter 6520 | Time 21.7277(21.9984) | Bit/dim 3.6719(3.6508) | Xent 0.1022(0.0804) | Loss 3.7230(3.6910) | Error 0.0389(0.0260) Steps 856(874.03) | Grad Norm 4.9021(3.5815) | Total Time 14.00(14.00)\n",
      "Iter 6530 | Time 21.3073(21.9984) | Bit/dim 3.6319(3.6524) | Xent 0.0790(0.0827) | Loss 3.6714(3.6937) | Error 0.0256(0.0268) Steps 868(874.49) | Grad Norm 3.6913(3.6332) | Total Time 14.00(14.00)\n",
      "Iter 6540 | Time 21.9346(21.9402) | Bit/dim 3.6243(3.6512) | Xent 0.1138(0.0854) | Loss 3.6812(3.6939) | Error 0.0311(0.0271) Steps 868(869.35) | Grad Norm 5.6790(3.5874) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 100.7872, Epoch Time 1328.8866(1282.7486), Bit/dim 3.6599(best: 3.6665), Xent 1.9138, Loss 4.6168, Error 0.3464(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 22.0694(21.8455) | Bit/dim 3.6451(3.6506) | Xent 0.0585(0.0815) | Loss 3.6743(3.6913) | Error 0.0200(0.0259) Steps 856(867.44) | Grad Norm 2.3705(3.3342) | Total Time 14.00(14.00)\n",
      "Iter 6560 | Time 21.4594(21.8203) | Bit/dim 3.6359(3.6460) | Xent 0.0783(0.0789) | Loss 3.6750(3.6854) | Error 0.0311(0.0252) Steps 862(867.52) | Grad Norm 2.8808(3.1413) | Total Time 14.00(14.00)\n",
      "Iter 6570 | Time 22.8377(21.8713) | Bit/dim 3.6541(3.6414) | Xent 0.0600(0.0776) | Loss 3.6841(3.6802) | Error 0.0222(0.0250) Steps 898(869.14) | Grad Norm 3.1234(3.0311) | Total Time 14.00(14.00)\n",
      "Iter 6580 | Time 22.6054(21.9404) | Bit/dim 3.6387(3.6423) | Xent 0.0634(0.0760) | Loss 3.6704(3.6803) | Error 0.0200(0.0244) Steps 892(871.04) | Grad Norm 2.0405(3.0389) | Total Time 14.00(14.00)\n",
      "Iter 6590 | Time 21.8680(21.9533) | Bit/dim 3.6695(3.6453) | Xent 0.1063(0.0791) | Loss 3.7227(3.6849) | Error 0.0333(0.0252) Steps 856(873.50) | Grad Norm 4.9941(3.3255) | Total Time 14.00(14.00)\n",
      "Iter 6600 | Time 21.8676(21.8984) | Bit/dim 3.6810(3.6500) | Xent 0.1076(0.0937) | Loss 3.7349(3.6969) | Error 0.0400(0.0293) Steps 910(874.52) | Grad Norm 2.9005(3.8113) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 103.6044, Epoch Time 1325.0055(1284.0163), Bit/dim 3.6730(best: 3.6599), Xent 1.8136, Loss 4.5798, Error 0.3569(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 21.9335(21.9277) | Bit/dim 3.6313(3.6479) | Xent 0.0784(0.0954) | Loss 3.6706(3.6956) | Error 0.0311(0.0303) Steps 892(874.24) | Grad Norm 2.1102(3.6397) | Total Time 14.00(14.00)\n",
      "Iter 6620 | Time 21.4032(21.9180) | Bit/dim 3.6540(3.6488) | Xent 0.0552(0.0894) | Loss 3.6816(3.6934) | Error 0.0178(0.0281) Steps 886(872.42) | Grad Norm 2.7512(3.3606) | Total Time 14.00(14.00)\n",
      "Iter 6630 | Time 21.4572(21.9267) | Bit/dim 3.6517(3.6488) | Xent 0.0705(0.0838) | Loss 3.6869(3.6907) | Error 0.0244(0.0268) Steps 892(874.70) | Grad Norm 3.6885(3.2686) | Total Time 14.00(14.00)\n",
      "Iter 6640 | Time 21.7673(21.9080) | Bit/dim 3.6371(3.6452) | Xent 0.0884(0.0807) | Loss 3.6814(3.6855) | Error 0.0333(0.0263) Steps 880(875.06) | Grad Norm 4.5835(3.3002) | Total Time 14.00(14.00)\n",
      "Iter 6650 | Time 21.8418(21.9118) | Bit/dim 3.6446(3.6445) | Xent 0.0995(0.0811) | Loss 3.6943(3.6851) | Error 0.0311(0.0267) Steps 874(875.53) | Grad Norm 3.9506(3.4789) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 106.2391, Epoch Time 1332.4264(1285.4686), Bit/dim 3.6599(best: 3.6599), Xent 1.8688, Loss 4.5943, Error 0.3411(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 22.2631(22.0597) | Bit/dim 3.6386(3.6435) | Xent 0.0722(0.0813) | Loss 3.6747(3.6842) | Error 0.0278(0.0268) Steps 868(880.00) | Grad Norm 2.4498(3.3890) | Total Time 14.00(14.00)\n",
      "Iter 6670 | Time 21.7254(22.1013) | Bit/dim 3.6152(3.6431) | Xent 0.0540(0.0779) | Loss 3.6422(3.6820) | Error 0.0189(0.0257) Steps 874(878.55) | Grad Norm 2.2375(3.2241) | Total Time 14.00(14.00)\n",
      "Iter 6680 | Time 22.4026(22.1450) | Bit/dim 3.6181(3.6430) | Xent 0.0577(0.0770) | Loss 3.6469(3.6815) | Error 0.0200(0.0250) Steps 868(877.96) | Grad Norm 2.5444(3.1234) | Total Time 14.00(14.00)\n",
      "Iter 6690 | Time 22.9227(22.1815) | Bit/dim 3.6311(3.6416) | Xent 0.0774(0.0755) | Loss 3.6697(3.6794) | Error 0.0233(0.0246) Steps 874(878.43) | Grad Norm 2.4752(2.9894) | Total Time 14.00(14.00)\n",
      "Iter 6700 | Time 22.3928(22.3651) | Bit/dim 3.6502(3.6410) | Xent 0.0665(0.0764) | Loss 3.6835(3.6792) | Error 0.0200(0.0247) Steps 904(882.36) | Grad Norm 3.5663(3.2098) | Total Time 14.00(14.00)\n",
      "Iter 6710 | Time 22.7856(22.4087) | Bit/dim 3.6434(3.6424) | Xent 0.0687(0.0753) | Loss 3.6777(3.6800) | Error 0.0178(0.0239) Steps 892(888.01) | Grad Norm 2.3253(3.0651) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 105.1762, Epoch Time 1358.5510(1287.6611), Bit/dim 3.6581(best: 3.6599), Xent 1.9808, Loss 4.6486, Error 0.3503(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 22.0770(22.3172) | Bit/dim 3.6384(3.6390) | Xent 0.0514(0.0734) | Loss 3.6641(3.6757) | Error 0.0200(0.0234) Steps 886(889.22) | Grad Norm 1.8036(3.0439) | Total Time 14.00(14.00)\n",
      "Iter 6730 | Time 21.8171(22.1789) | Bit/dim 3.6069(3.6414) | Xent 0.0865(0.0721) | Loss 3.6501(3.6774) | Error 0.0311(0.0235) Steps 874(885.98) | Grad Norm 3.1339(2.9837) | Total Time 14.00(14.00)\n",
      "Iter 6740 | Time 22.2269(22.1200) | Bit/dim 3.6626(3.6442) | Xent 0.0716(0.0754) | Loss 3.6984(3.6819) | Error 0.0244(0.0245) Steps 856(882.99) | Grad Norm 3.1786(3.1515) | Total Time 14.00(14.00)\n",
      "Iter 6750 | Time 23.0203(22.1395) | Bit/dim 3.6361(3.6435) | Xent 0.0951(0.0785) | Loss 3.6836(3.6828) | Error 0.0289(0.0252) Steps 910(884.41) | Grad Norm 2.9179(3.1119) | Total Time 14.00(14.00)\n",
      "Iter 6760 | Time 22.5741(22.2216) | Bit/dim 3.6314(3.6421) | Xent 0.0722(0.0781) | Loss 3.6675(3.6811) | Error 0.0189(0.0251) Steps 898(889.33) | Grad Norm 2.9826(3.1203) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 105.6501, Epoch Time 1338.8148(1289.1957), Bit/dim 3.6596(best: 3.6581), Xent 1.9275, Loss 4.6233, Error 0.3450(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 21.8076(22.2305) | Bit/dim 3.6673(3.6423) | Xent 0.1046(0.0822) | Loss 3.7196(3.6834) | Error 0.0344(0.0265) Steps 868(891.48) | Grad Norm 5.1225(3.3530) | Total Time 14.00(14.00)\n",
      "Iter 6780 | Time 22.2098(22.2230) | Bit/dim 3.6760(3.6459) | Xent 0.1110(0.0836) | Loss 3.7315(3.6877) | Error 0.0356(0.0272) Steps 922(894.37) | Grad Norm 4.0283(3.3648) | Total Time 14.00(14.00)\n",
      "Iter 6790 | Time 21.7786(22.1842) | Bit/dim 3.6550(3.6475) | Xent 0.0755(0.0787) | Loss 3.6928(3.6868) | Error 0.0211(0.0255) Steps 910(894.16) | Grad Norm 2.9453(3.1744) | Total Time 14.00(14.00)\n",
      "Iter 6800 | Time 22.2912(22.2026) | Bit/dim 3.6296(3.6432) | Xent 0.0645(0.0753) | Loss 3.6618(3.6808) | Error 0.0211(0.0242) Steps 910(895.55) | Grad Norm 4.4067(3.0709) | Total Time 14.00(14.00)\n",
      "Iter 6810 | Time 21.0821(22.1388) | Bit/dim 3.6440(3.6413) | Xent 0.1034(0.0789) | Loss 3.6957(3.6807) | Error 0.0278(0.0248) Steps 874(892.97) | Grad Norm 2.3553(3.1488) | Total Time 14.00(14.00)\n",
      "Iter 6820 | Time 21.7896(22.0858) | Bit/dim 3.6634(3.6440) | Xent 0.0624(0.0808) | Loss 3.6946(3.6844) | Error 0.0178(0.0252) Steps 892(891.47) | Grad Norm 2.8916(3.4145) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 102.9629, Epoch Time 1337.8803(1290.6563), Bit/dim 3.6660(best: 3.6581), Xent 1.8609, Loss 4.5965, Error 0.3426(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 22.0949(22.1158) | Bit/dim 3.6527(3.6411) | Xent 0.0694(0.0774) | Loss 3.6874(3.6797) | Error 0.0267(0.0246) Steps 886(888.70) | Grad Norm 2.6684(3.3270) | Total Time 14.00(14.00)\n",
      "Iter 6840 | Time 23.0138(22.1090) | Bit/dim 3.6408(3.6416) | Xent 0.0672(0.0755) | Loss 3.6744(3.6793) | Error 0.0244(0.0242) Steps 868(884.94) | Grad Norm 3.8389(3.2508) | Total Time 14.00(14.00)\n",
      "Iter 6850 | Time 21.9352(22.0993) | Bit/dim 3.6707(3.6412) | Xent 0.1559(0.0782) | Loss 3.7487(3.6803) | Error 0.0444(0.0249) Steps 886(887.31) | Grad Norm 6.7456(3.5133) | Total Time 14.00(14.00)\n",
      "Iter 6860 | Time 22.9497(22.1269) | Bit/dim 3.6278(3.6392) | Xent 0.0657(0.0775) | Loss 3.6606(3.6780) | Error 0.0244(0.0247) Steps 946(889.79) | Grad Norm 2.5240(3.3676) | Total Time 14.00(14.00)\n",
      "Iter 6870 | Time 22.7269(22.1575) | Bit/dim 3.6498(3.6410) | Xent 0.0434(0.0733) | Loss 3.6715(3.6777) | Error 0.0133(0.0235) Steps 886(891.90) | Grad Norm 2.4532(3.1207) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 105.5040, Epoch Time 1343.3345(1292.2366), Bit/dim 3.6537(best: 3.6581), Xent 1.9260, Loss 4.6167, Error 0.3472(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 21.7051(22.1934) | Bit/dim 3.6232(3.6407) | Xent 0.1043(0.0746) | Loss 3.6753(3.6780) | Error 0.0344(0.0237) Steps 874(889.99) | Grad Norm 3.5571(3.0583) | Total Time 14.00(14.00)\n",
      "Iter 6890 | Time 22.0077(22.2028) | Bit/dim 3.6302(3.6392) | Xent 0.0655(0.0737) | Loss 3.6629(3.6761) | Error 0.0178(0.0237) Steps 880(890.65) | Grad Norm 2.9027(3.2220) | Total Time 14.00(14.00)\n",
      "Iter 6900 | Time 21.8093(22.1721) | Bit/dim 3.6556(3.6409) | Xent 0.0845(0.0741) | Loss 3.6978(3.6780) | Error 0.0222(0.0236) Steps 868(891.90) | Grad Norm 3.0161(3.2736) | Total Time 14.00(14.00)\n",
      "Iter 6910 | Time 22.0122(22.1363) | Bit/dim 3.6226(3.6425) | Xent 0.1097(0.0762) | Loss 3.6775(3.6806) | Error 0.0333(0.0243) Steps 886(889.66) | Grad Norm 2.9748(3.3905) | Total Time 14.00(14.00)\n",
      "Iter 6920 | Time 22.6989(22.2004) | Bit/dim 3.6664(3.6434) | Xent 0.0811(0.0797) | Loss 3.7070(3.6832) | Error 0.0256(0.0250) Steps 904(892.51) | Grad Norm 3.5793(3.5450) | Total Time 14.00(14.00)\n",
      "Iter 6930 | Time 21.9596(22.2179) | Bit/dim 3.6551(3.6434) | Xent 0.1129(0.0846) | Loss 3.7116(3.6857) | Error 0.0311(0.0266) Steps 892(894.64) | Grad Norm 5.7330(3.5739) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 106.0608, Epoch Time 1345.3557(1293.8302), Bit/dim 3.6580(best: 3.6537), Xent 1.8860, Loss 4.6010, Error 0.3526(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 21.8935(22.2226) | Bit/dim 3.6591(3.6451) | Xent 0.1030(0.0859) | Loss 3.7106(3.6881) | Error 0.0289(0.0269) Steps 874(893.03) | Grad Norm 4.7580(3.7838) | Total Time 14.00(14.00)\n",
      "Iter 6950 | Time 22.4855(22.3037) | Bit/dim 3.6299(3.6436) | Xent 0.0357(0.0822) | Loss 3.6478(3.6847) | Error 0.0111(0.0256) Steps 892(893.81) | Grad Norm 1.7672(3.4359) | Total Time 14.00(14.00)\n",
      "Iter 6960 | Time 21.2994(22.2312) | Bit/dim 3.6351(3.6427) | Xent 0.0634(0.0790) | Loss 3.6668(3.6822) | Error 0.0133(0.0243) Steps 886(891.09) | Grad Norm 1.9656(3.1935) | Total Time 14.00(14.00)\n",
      "Iter 6970 | Time 22.4697(22.2006) | Bit/dim 3.6064(3.6383) | Xent 0.0787(0.0762) | Loss 3.6458(3.6764) | Error 0.0278(0.0237) Steps 880(887.34) | Grad Norm 2.5469(2.9851) | Total Time 14.00(14.00)\n",
      "Iter 6980 | Time 22.1904(22.1675) | Bit/dim 3.6588(3.6382) | Xent 0.0517(0.0721) | Loss 3.6846(3.6743) | Error 0.0189(0.0231) Steps 868(883.68) | Grad Norm 2.6656(2.8808) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 106.0761, Epoch Time 1346.1794(1295.4007), Bit/dim 3.6521(best: 3.6537), Xent 1.9938, Loss 4.6490, Error 0.3508(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 22.2680(22.1927) | Bit/dim 3.6454(3.6332) | Xent 0.0820(0.0708) | Loss 3.6864(3.6686) | Error 0.0267(0.0225) Steps 874(884.27) | Grad Norm 3.0567(2.8877) | Total Time 14.00(14.00)\n",
      "Iter 7000 | Time 22.2765(22.2018) | Bit/dim 3.6215(3.6359) | Xent 0.0717(0.0718) | Loss 3.6573(3.6718) | Error 0.0278(0.0227) Steps 886(888.36) | Grad Norm 2.8876(3.0011) | Total Time 14.00(14.00)\n",
      "Iter 7010 | Time 21.5880(22.0865) | Bit/dim 3.6225(3.6378) | Xent 0.0760(0.0749) | Loss 3.6604(3.6753) | Error 0.0256(0.0237) Steps 880(887.12) | Grad Norm 3.4155(3.2899) | Total Time 14.00(14.00)\n",
      "Iter 7020 | Time 22.0094(22.0394) | Bit/dim 3.6649(3.6369) | Xent 0.0841(0.0762) | Loss 3.7069(3.6750) | Error 0.0200(0.0244) Steps 862(886.12) | Grad Norm 2.4814(3.2684) | Total Time 14.00(14.00)\n",
      "Iter 7030 | Time 21.7622(22.0185) | Bit/dim 3.6302(3.6376) | Xent 0.0874(0.0765) | Loss 3.6739(3.6759) | Error 0.0322(0.0246) Steps 886(886.88) | Grad Norm 3.1164(3.1755) | Total Time 14.00(14.00)\n",
      "Iter 7040 | Time 21.6566(21.9527) | Bit/dim 3.6301(3.6367) | Xent 0.0930(0.0757) | Loss 3.6766(3.6745) | Error 0.0256(0.0247) Steps 916(887.93) | Grad Norm 2.9363(3.0456) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 106.5483, Epoch Time 1331.6664(1296.4886), Bit/dim 3.6546(best: 3.6521), Xent 1.9458, Loss 4.6276, Error 0.3380(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 22.1688(22.0442) | Bit/dim 3.6920(3.6379) | Xent 0.1567(0.0769) | Loss 3.7704(3.6764) | Error 0.0422(0.0244) Steps 904(890.13) | Grad Norm 6.0316(3.1781) | Total Time 14.00(14.00)\n",
      "Iter 7060 | Time 23.0697(22.1486) | Bit/dim 3.6266(3.6387) | Xent 0.0683(0.0769) | Loss 3.6607(3.6771) | Error 0.0222(0.0248) Steps 928(892.75) | Grad Norm 2.3082(3.1036) | Total Time 14.00(14.00)\n",
      "Iter 7070 | Time 21.6380(22.1647) | Bit/dim 3.6284(3.6364) | Xent 0.0566(0.0734) | Loss 3.6567(3.6731) | Error 0.0167(0.0236) Steps 874(890.21) | Grad Norm 2.5242(2.9877) | Total Time 14.00(14.00)\n",
      "Iter 7080 | Time 21.2902(22.1580) | Bit/dim 3.6160(3.6329) | Xent 0.1103(0.0753) | Loss 3.6712(3.6706) | Error 0.0356(0.0242) Steps 880(889.26) | Grad Norm 2.5085(2.9960) | Total Time 14.00(14.00)\n",
      "Iter 7090 | Time 21.7420(22.0711) | Bit/dim 3.6602(3.6341) | Xent 0.0913(0.0764) | Loss 3.7058(3.6723) | Error 0.0278(0.0244) Steps 862(887.65) | Grad Norm 2.6104(2.9020) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 104.4665, Epoch Time 1340.6942(1297.8148), Bit/dim 3.6514(best: 3.6521), Xent 1.9300, Loss 4.6165, Error 0.3474(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 21.9025(21.9961) | Bit/dim 3.6590(3.6333) | Xent 0.0736(0.0764) | Loss 3.6957(3.6715) | Error 0.0244(0.0243) Steps 892(886.35) | Grad Norm 2.1232(2.9563) | Total Time 14.00(14.00)\n",
      "Iter 7110 | Time 22.5082(22.0488) | Bit/dim 3.6187(3.6315) | Xent 0.0681(0.0758) | Loss 3.6528(3.6694) | Error 0.0233(0.0244) Steps 898(887.11) | Grad Norm 3.8848(3.0016) | Total Time 14.00(14.00)\n",
      "Iter 7120 | Time 22.2523(22.2052) | Bit/dim 3.6189(3.6316) | Xent 0.0859(0.0761) | Loss 3.6619(3.6697) | Error 0.0256(0.0243) Steps 886(891.69) | Grad Norm 3.8847(3.1047) | Total Time 14.00(14.00)\n",
      "Iter 7130 | Time 22.7786(22.2592) | Bit/dim 3.6495(3.6347) | Xent 0.0927(0.0758) | Loss 3.6959(3.6726) | Error 0.0278(0.0241) Steps 922(894.92) | Grad Norm 5.6326(3.1490) | Total Time 14.00(14.00)\n",
      "Iter 7140 | Time 21.8226(22.2467) | Bit/dim 3.6444(3.6373) | Xent 0.0598(0.0761) | Loss 3.6742(3.6754) | Error 0.0222(0.0246) Steps 886(895.17) | Grad Norm 2.2567(3.1060) | Total Time 14.00(14.00)\n",
      "Iter 7150 | Time 22.4220(22.2701) | Bit/dim 3.6337(3.6349) | Xent 0.0772(0.0749) | Loss 3.6723(3.6723) | Error 0.0278(0.0245) Steps 898(895.01) | Grad Norm 2.3003(2.9700) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 106.9507, Epoch Time 1351.9569(1299.4391), Bit/dim 3.6478(best: 3.6514), Xent 1.8644, Loss 4.5800, Error 0.3401(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 21.9296(22.1883) | Bit/dim 3.6236(3.6338) | Xent 0.0600(0.0724) | Loss 3.6536(3.6700) | Error 0.0189(0.0232) Steps 886(893.39) | Grad Norm 2.0364(2.8569) | Total Time 14.00(14.00)\n",
      "Iter 7170 | Time 21.4148(22.1618) | Bit/dim 3.6401(3.6341) | Xent 0.0817(0.0732) | Loss 3.6810(3.6706) | Error 0.0267(0.0236) Steps 862(890.72) | Grad Norm 3.4200(3.0194) | Total Time 14.00(14.00)\n",
      "Iter 7180 | Time 22.1778(22.2561) | Bit/dim 3.6317(3.6345) | Xent 0.1120(0.0773) | Loss 3.6877(3.6731) | Error 0.0300(0.0245) Steps 880(890.59) | Grad Norm 5.3516(3.1209) | Total Time 14.00(14.00)\n",
      "Iter 7190 | Time 21.7350(22.1376) | Bit/dim 3.6278(3.6312) | Xent 0.0512(0.0758) | Loss 3.6534(3.6691) | Error 0.0189(0.0243) Steps 880(888.15) | Grad Norm 3.2288(3.2250) | Total Time 14.00(14.00)\n",
      "Iter 7200 | Time 22.2731(22.1568) | Bit/dim 3.6268(3.6298) | Xent 0.0684(0.0746) | Loss 3.6611(3.6671) | Error 0.0222(0.0240) Steps 904(889.25) | Grad Norm 2.8169(3.1015) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 105.2643, Epoch Time 1341.3471(1300.6963), Bit/dim 3.6490(best: 3.6478), Xent 1.8626, Loss 4.5803, Error 0.3451(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 21.3194(22.1405) | Bit/dim 3.6407(3.6295) | Xent 0.0903(0.0733) | Loss 3.6859(3.6661) | Error 0.0311(0.0237) Steps 862(887.70) | Grad Norm 2.5907(3.0122) | Total Time 14.00(14.00)\n",
      "Iter 7220 | Time 21.7793(22.0065) | Bit/dim 3.6262(3.6293) | Xent 0.0829(0.0739) | Loss 3.6676(3.6663) | Error 0.0278(0.0239) Steps 856(884.51) | Grad Norm 2.9258(3.0748) | Total Time 14.00(14.00)\n",
      "Iter 7230 | Time 22.4229(22.0444) | Bit/dim 3.6607(3.6282) | Xent 0.0707(0.0709) | Loss 3.6961(3.6636) | Error 0.0211(0.0230) Steps 898(889.07) | Grad Norm 4.4008(3.1029) | Total Time 14.00(14.00)\n",
      "Iter 7240 | Time 21.9760(22.0653) | Bit/dim 3.6688(3.6298) | Xent 0.0485(0.0675) | Loss 3.6931(3.6636) | Error 0.0144(0.0218) Steps 910(893.51) | Grad Norm 2.7945(2.9028) | Total Time 14.00(14.00)\n",
      "Iter 7250 | Time 21.7446(22.0171) | Bit/dim 3.6199(3.6280) | Xent 0.0744(0.0677) | Loss 3.6571(3.6619) | Error 0.0244(0.0219) Steps 886(891.09) | Grad Norm 3.6302(2.9182) | Total Time 14.00(14.00)\n",
      "Iter 7260 | Time 21.1918(21.9339) | Bit/dim 3.6300(3.6305) | Xent 0.0498(0.0679) | Loss 3.6549(3.6644) | Error 0.0178(0.0221) Steps 868(889.08) | Grad Norm 2.0143(2.8801) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 105.4052, Epoch Time 1328.2638(1301.5233), Bit/dim 3.6538(best: 3.6478), Xent 1.9904, Loss 4.6490, Error 0.3560(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7270 | Time 21.8478(21.8561) | Bit/dim 3.6540(3.6298) | Xent 0.0551(0.0664) | Loss 3.6816(3.6630) | Error 0.0189(0.0216) Steps 880(884.95) | Grad Norm 4.2565(2.8407) | Total Time 14.00(14.00)\n",
      "Iter 7280 | Time 22.2176(21.9291) | Bit/dim 3.6141(3.6276) | Xent 0.0913(0.0693) | Loss 3.6597(3.6623) | Error 0.0289(0.0221) Steps 874(883.55) | Grad Norm 3.2338(2.9640) | Total Time 14.00(14.00)\n",
      "Iter 7290 | Time 21.7239(21.8914) | Bit/dim 3.6438(3.6316) | Xent 0.0936(0.0775) | Loss 3.6905(3.6704) | Error 0.0356(0.0249) Steps 868(882.37) | Grad Norm 4.6332(3.3626) | Total Time 14.00(14.00)\n",
      "Iter 7300 | Time 21.9349(21.9215) | Bit/dim 3.6114(3.6336) | Xent 0.0780(0.0801) | Loss 3.6504(3.6736) | Error 0.0300(0.0257) Steps 892(881.75) | Grad Norm 2.3125(3.3394) | Total Time 14.00(14.00)\n",
      "Iter 7310 | Time 22.6331(21.8938) | Bit/dim 3.6493(3.6346) | Xent 0.0680(0.0785) | Loss 3.6833(3.6739) | Error 0.0200(0.0252) Steps 898(884.17) | Grad Norm 3.4147(3.4093) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 106.0469, Epoch Time 1325.6198(1302.2462), Bit/dim 3.6531(best: 3.6478), Xent 1.8640, Loss 4.5851, Error 0.3478(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7320 | Time 22.3557(21.8519) | Bit/dim 3.6358(3.6339) | Xent 0.0840(0.0764) | Loss 3.6778(3.6721) | Error 0.0289(0.0245) Steps 874(884.55) | Grad Norm 3.1514(3.2991) | Total Time 14.00(14.00)\n",
      "Iter 7330 | Time 22.0506(21.8261) | Bit/dim 3.6167(3.6330) | Xent 0.0824(0.0763) | Loss 3.6579(3.6711) | Error 0.0267(0.0238) Steps 904(885.63) | Grad Norm 2.3975(3.1648) | Total Time 14.00(14.00)\n",
      "Iter 7340 | Time 23.0443(21.9181) | Bit/dim 3.6236(3.6332) | Xent 0.0485(0.0730) | Loss 3.6478(3.6696) | Error 0.0144(0.0226) Steps 898(885.71) | Grad Norm 2.5887(2.9999) | Total Time 14.00(14.00)\n",
      "Iter 7350 | Time 22.4536(21.9905) | Bit/dim 3.6159(3.6324) | Xent 0.0618(0.0716) | Loss 3.6468(3.6682) | Error 0.0178(0.0223) Steps 904(889.13) | Grad Norm 2.3094(2.7997) | Total Time 14.00(14.00)\n",
      "Iter 7360 | Time 22.4992(22.0264) | Bit/dim 3.6144(3.6285) | Xent 0.0665(0.0698) | Loss 3.6476(3.6634) | Error 0.0244(0.0221) Steps 886(888.86) | Grad Norm 2.2921(2.7237) | Total Time 14.00(14.00)\n",
      "Iter 7370 | Time 21.3110(22.0601) | Bit/dim 3.6206(3.6266) | Xent 0.0567(0.0687) | Loss 3.6490(3.6609) | Error 0.0211(0.0218) Steps 892(889.96) | Grad Norm 2.8875(2.6903) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 107.4411, Epoch Time 1339.0594(1303.3506), Bit/dim 3.6430(best: 3.6478), Xent 1.9519, Loss 4.6189, Error 0.3459(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7380 | Time 21.5793(21.9377) | Bit/dim 3.6537(3.6275) | Xent 0.0712(0.0673) | Loss 3.6893(3.6612) | Error 0.0267(0.0216) Steps 868(887.75) | Grad Norm 2.2050(2.6298) | Total Time 14.00(14.00)\n",
      "Iter 7390 | Time 22.0942(21.8383) | Bit/dim 3.6457(3.6260) | Xent 0.0741(0.0652) | Loss 3.6828(3.6586) | Error 0.0233(0.0211) Steps 856(882.56) | Grad Norm 4.5840(2.7421) | Total Time 14.00(14.00)\n",
      "Iter 7400 | Time 21.5966(21.8199) | Bit/dim 3.6245(3.6247) | Xent 0.0709(0.0648) | Loss 3.6600(3.6571) | Error 0.0211(0.0203) Steps 886(879.61) | Grad Norm 3.4120(2.8354) | Total Time 14.00(14.00)\n",
      "Iter 7410 | Time 21.5359(21.8456) | Bit/dim 3.6525(3.6238) | Xent 0.0705(0.0642) | Loss 3.6877(3.6559) | Error 0.0178(0.0202) Steps 886(883.52) | Grad Norm 2.2450(2.7098) | Total Time 14.00(14.00)\n",
      "Iter 7420 | Time 22.4173(21.9341) | Bit/dim 3.6352(3.6251) | Xent 0.0459(0.0624) | Loss 3.6582(3.6563) | Error 0.0133(0.0196) Steps 910(886.37) | Grad Norm 1.8001(2.6048) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 106.7624, Epoch Time 1327.6861(1304.0807), Bit/dim 3.6361(best: 3.6430), Xent 1.9907, Loss 4.6314, Error 0.3425(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7430 | Time 22.4934(22.0689) | Bit/dim 3.6193(3.6229) | Xent 0.0603(0.0589) | Loss 3.6494(3.6524) | Error 0.0167(0.0183) Steps 880(890.24) | Grad Norm 2.6046(2.5615) | Total Time 14.00(14.00)\n",
      "Iter 7440 | Time 22.3052(22.1552) | Bit/dim 3.5830(3.6210) | Xent 0.0563(0.0577) | Loss 3.6112(3.6498) | Error 0.0211(0.0183) Steps 880(893.99) | Grad Norm 2.1019(2.5420) | Total Time 14.00(14.00)\n",
      "Iter 7450 | Time 22.7820(22.1747) | Bit/dim 3.6537(3.6210) | Xent 0.1074(0.0645) | Loss 3.7074(3.6533) | Error 0.0289(0.0204) Steps 934(896.98) | Grad Norm 4.8899(2.8409) | Total Time 14.00(14.00)\n",
      "Iter 7460 | Time 22.4129(22.2929) | Bit/dim 3.6502(3.6230) | Xent 0.0656(0.0689) | Loss 3.6830(3.6574) | Error 0.0233(0.0221) Steps 940(899.36) | Grad Norm 2.1933(3.0506) | Total Time 14.00(14.00)\n",
      "Iter 7470 | Time 22.0490(22.3948) | Bit/dim 3.6167(3.6270) | Xent 0.0632(0.0724) | Loss 3.6483(3.6632) | Error 0.0233(0.0232) Steps 880(901.63) | Grad Norm 2.2528(3.1586) | Total Time 14.00(14.00)\n",
      "Iter 7480 | Time 22.4594(22.2969) | Bit/dim 3.6266(3.6292) | Xent 0.1345(0.0780) | Loss 3.6939(3.6682) | Error 0.0522(0.0252) Steps 898(899.00) | Grad Norm 5.4373(3.2511) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 106.5462, Epoch Time 1356.0259(1305.6390), Bit/dim 3.6506(best: 3.6361), Xent 2.0062, Loss 4.6537, Error 0.3550(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7490 | Time 22.3226(22.2911) | Bit/dim 3.5901(3.6311) | Xent 0.1056(0.0869) | Loss 3.6429(3.6745) | Error 0.0322(0.0276) Steps 916(898.22) | Grad Norm 3.3397(3.6234) | Total Time 14.00(14.00)\n",
      "Iter 7500 | Time 21.9012(22.2995) | Bit/dim 3.6263(3.6323) | Xent 0.0526(0.0825) | Loss 3.6526(3.6735) | Error 0.0200(0.0265) Steps 916(897.10) | Grad Norm 3.6156(3.4816) | Total Time 14.00(14.00)\n",
      "Iter 7510 | Time 21.8088(22.2689) | Bit/dim 3.6411(3.6336) | Xent 0.0937(0.0812) | Loss 3.6879(3.6742) | Error 0.0244(0.0257) Steps 880(894.10) | Grad Norm 3.4869(3.3187) | Total Time 14.00(14.00)\n",
      "Iter 7520 | Time 21.4018(22.1357) | Bit/dim 3.6363(3.6334) | Xent 0.0713(0.0804) | Loss 3.6719(3.6736) | Error 0.0244(0.0256) Steps 880(891.60) | Grad Norm 2.7127(3.2092) | Total Time 14.00(14.00)\n",
      "Iter 7530 | Time 22.2108(22.0763) | Bit/dim 3.5950(3.6285) | Xent 0.0827(0.0769) | Loss 3.6364(3.6670) | Error 0.0244(0.0245) Steps 892(890.97) | Grad Norm 2.2977(3.0265) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 104.4224, Epoch Time 1337.1982(1306.5858), Bit/dim 3.6530(best: 3.6361), Xent 2.0794, Loss 4.6926, Error 0.3531(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7540 | Time 21.4935(22.1107) | Bit/dim 3.6371(3.6324) | Xent 0.0874(0.0818) | Loss 3.6808(3.6733) | Error 0.0244(0.0258) Steps 892(891.03) | Grad Norm 2.9786(3.3312) | Total Time 14.00(14.00)\n",
      "Iter 7550 | Time 22.5858(22.1430) | Bit/dim 3.6596(3.6315) | Xent 0.0615(0.0798) | Loss 3.6903(3.6714) | Error 0.0189(0.0252) Steps 880(892.13) | Grad Norm 4.1963(3.2151) | Total Time 14.00(14.00)\n",
      "Iter 7560 | Time 22.3640(22.1760) | Bit/dim 3.6512(3.6316) | Xent 0.0656(0.0754) | Loss 3.6840(3.6693) | Error 0.0178(0.0240) Steps 898(893.51) | Grad Norm 2.6768(3.2171) | Total Time 14.00(14.00)\n",
      "Iter 7570 | Time 22.0207(22.1256) | Bit/dim 3.6203(3.6277) | Xent 0.0484(0.0726) | Loss 3.6445(3.6640) | Error 0.0211(0.0233) Steps 880(894.19) | Grad Norm 2.9306(3.0875) | Total Time 14.00(14.00)\n",
      "Iter 7580 | Time 22.4529(22.1073) | Bit/dim 3.6152(3.6262) | Xent 0.0848(0.0730) | Loss 3.6576(3.6627) | Error 0.0256(0.0236) Steps 904(895.93) | Grad Norm 4.0910(3.2952) | Total Time 14.00(14.00)\n",
      "Iter 7590 | Time 21.6182(22.0857) | Bit/dim 3.6255(3.6254) | Xent 0.0688(0.0738) | Loss 3.6599(3.6623) | Error 0.0200(0.0237) Steps 886(896.92) | Grad Norm 2.7108(3.2303) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 106.3993, Epoch Time 1342.0359(1307.6493), Bit/dim 3.6430(best: 3.6361), Xent 1.8930, Loss 4.5895, Error 0.3357(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7600 | Time 21.9596(22.1273) | Bit/dim 3.6107(3.6220) | Xent 0.0501(0.0705) | Loss 3.6358(3.6573) | Error 0.0178(0.0227) Steps 892(898.56) | Grad Norm 2.3220(3.0235) | Total Time 14.00(14.00)\n",
      "Iter 7610 | Time 21.9600(22.1597) | Bit/dim 3.6280(3.6226) | Xent 0.0669(0.0652) | Loss 3.6614(3.6552) | Error 0.0211(0.0211) Steps 898(897.61) | Grad Norm 3.2942(2.8264) | Total Time 14.00(14.00)\n",
      "Iter 7620 | Time 21.9762(22.1310) | Bit/dim 3.6262(3.6231) | Xent 0.0610(0.0608) | Loss 3.6566(3.6535) | Error 0.0211(0.0197) Steps 898(899.38) | Grad Norm 3.1198(2.8021) | Total Time 14.00(14.00)\n",
      "Iter 7630 | Time 21.4072(22.1549) | Bit/dim 3.6005(3.6203) | Xent 0.0517(0.0624) | Loss 3.6264(3.6515) | Error 0.0156(0.0203) Steps 898(897.48) | Grad Norm 2.8159(2.9229) | Total Time 14.00(14.00)\n",
      "Iter 7640 | Time 22.1664(22.1243) | Bit/dim 3.6010(3.6213) | Xent 0.0679(0.0635) | Loss 3.6350(3.6530) | Error 0.0244(0.0202) Steps 904(896.27) | Grad Norm 3.2891(3.0578) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 105.7412, Epoch Time 1345.0847(1308.7724), Bit/dim 3.6445(best: 3.6361), Xent 2.0128, Loss 4.6509, Error 0.3481(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7650 | Time 21.9519(22.1530) | Bit/dim 3.6229(3.6203) | Xent 0.0540(0.0674) | Loss 3.6499(3.6540) | Error 0.0144(0.0214) Steps 886(896.42) | Grad Norm 2.2823(3.1317) | Total Time 14.00(14.00)\n",
      "Iter 7660 | Time 22.4298(22.1315) | Bit/dim 3.6710(3.6219) | Xent 0.0618(0.0703) | Loss 3.7019(3.6570) | Error 0.0189(0.0222) Steps 886(894.91) | Grad Norm 2.4646(3.1208) | Total Time 14.00(14.00)\n",
      "Iter 7670 | Time 22.5277(22.1031) | Bit/dim 3.6638(3.6225) | Xent 0.0716(0.0713) | Loss 3.6996(3.6581) | Error 0.0256(0.0226) Steps 880(894.64) | Grad Norm 4.1133(3.1315) | Total Time 14.00(14.00)\n",
      "Iter 7680 | Time 22.2795(22.1371) | Bit/dim 3.6132(3.6248) | Xent 0.0505(0.0684) | Loss 3.6385(3.6590) | Error 0.0156(0.0220) Steps 916(894.17) | Grad Norm 2.1077(3.0799) | Total Time 14.00(14.00)\n",
      "Iter 7690 | Time 22.7992(22.1758) | Bit/dim 3.6131(3.6233) | Xent 0.0637(0.0676) | Loss 3.6450(3.6571) | Error 0.0233(0.0216) Steps 910(900.05) | Grad Norm 2.8535(2.9197) | Total Time 14.00(14.00)\n",
      "Iter 7700 | Time 21.7884(22.2051) | Bit/dim 3.6506(3.6219) | Xent 0.0562(0.0658) | Loss 3.6787(3.6548) | Error 0.0222(0.0210) Steps 910(900.71) | Grad Norm 2.9148(2.8081) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 106.1279, Epoch Time 1343.3727(1309.8104), Bit/dim 3.6367(best: 3.6361), Xent 1.9555, Loss 4.6144, Error 0.3370(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7710 | Time 22.5691(22.1463) | Bit/dim 3.6247(3.6187) | Xent 0.0375(0.0632) | Loss 3.6434(3.6503) | Error 0.0122(0.0203) Steps 898(897.57) | Grad Norm 2.0327(2.6457) | Total Time 14.00(14.00)\n",
      "Iter 7720 | Time 22.3049(22.0067) | Bit/dim 3.5846(3.6175) | Xent 0.0552(0.0603) | Loss 3.6122(3.6477) | Error 0.0189(0.0195) Steps 886(894.06) | Grad Norm 2.6717(2.5694) | Total Time 14.00(14.00)\n",
      "Iter 7730 | Time 22.0633(22.0420) | Bit/dim 3.6080(3.6160) | Xent 0.0576(0.0608) | Loss 3.6368(3.6464) | Error 0.0156(0.0194) Steps 892(893.92) | Grad Norm 2.3863(2.5260) | Total Time 14.00(14.00)\n",
      "Iter 7740 | Time 23.0138(22.1695) | Bit/dim 3.6084(3.6160) | Xent 0.0684(0.0662) | Loss 3.6426(3.6491) | Error 0.0222(0.0207) Steps 916(896.06) | Grad Norm 2.5052(2.7115) | Total Time 14.00(14.00)\n",
      "Iter 7750 | Time 23.0400(22.3248) | Bit/dim 3.5987(3.6205) | Xent 0.0672(0.0673) | Loss 3.6323(3.6541) | Error 0.0189(0.0208) Steps 892(900.57) | Grad Norm 2.7597(2.7540) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 107.1536, Epoch Time 1346.8963(1310.9230), Bit/dim 3.6416(best: 3.6361), Xent 1.9434, Loss 4.6133, Error 0.3418(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7760 | Time 22.6036(22.2988) | Bit/dim 3.6584(3.6241) | Xent 0.0574(0.0660) | Loss 3.6871(3.6571) | Error 0.0200(0.0207) Steps 910(899.82) | Grad Norm 2.4770(2.7627) | Total Time 14.00(14.00)\n",
      "Iter 7770 | Time 22.6305(22.3660) | Bit/dim 3.6421(3.6240) | Xent 0.0689(0.0623) | Loss 3.6766(3.6551) | Error 0.0222(0.0198) Steps 880(899.16) | Grad Norm 2.9178(2.6943) | Total Time 14.00(14.00)\n",
      "Iter 7780 | Time 22.3746(22.3746) | Bit/dim 3.5979(3.6216) | Xent 0.0629(0.0625) | Loss 3.6294(3.6529) | Error 0.0189(0.0193) Steps 910(900.04) | Grad Norm 3.3000(2.7041) | Total Time 14.00(14.00)\n",
      "Iter 7790 | Time 21.5749(22.3554) | Bit/dim 3.5975(3.6167) | Xent 0.0500(0.0641) | Loss 3.6225(3.6487) | Error 0.0133(0.0195) Steps 886(899.28) | Grad Norm 1.6435(2.5930) | Total Time 14.00(14.00)\n",
      "Iter 7800 | Time 22.3070(22.2244) | Bit/dim 3.6478(3.6182) | Xent 0.0803(0.0637) | Loss 3.6880(3.6501) | Error 0.0244(0.0196) Steps 910(898.74) | Grad Norm 3.2692(2.5890) | Total Time 14.00(14.00)\n",
      "Iter 7810 | Time 22.8944(22.2512) | Bit/dim 3.6549(3.6178) | Xent 0.1342(0.0704) | Loss 3.7220(3.6530) | Error 0.0444(0.0216) Steps 898(900.79) | Grad Norm 8.3685(3.0196) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 106.8302, Epoch Time 1350.2825(1312.1037), Bit/dim 3.6517(best: 3.6361), Xent 1.8506, Loss 4.5770, Error 0.3376(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7820 | Time 22.7880(22.2793) | Bit/dim 3.6008(3.6207) | Xent 0.0590(0.0695) | Loss 3.6303(3.6554) | Error 0.0211(0.0219) Steps 904(901.61) | Grad Norm 3.7872(3.0765) | Total Time 14.00(14.00)\n",
      "Iter 7830 | Time 22.2588(22.2674) | Bit/dim 3.6315(3.6228) | Xent 0.0827(0.0701) | Loss 3.6729(3.6578) | Error 0.0211(0.0217) Steps 892(900.37) | Grad Norm 4.6299(3.0816) | Total Time 14.00(14.00)\n",
      "Iter 7840 | Time 22.4456(22.2750) | Bit/dim 3.5961(3.6198) | Xent 0.0501(0.0713) | Loss 3.6211(3.6555) | Error 0.0144(0.0219) Steps 904(900.82) | Grad Norm 2.2810(2.9907) | Total Time 14.00(14.00)\n",
      "Iter 7850 | Time 22.4706(22.2896) | Bit/dim 3.6159(3.6195) | Xent 0.0572(0.0694) | Loss 3.6445(3.6542) | Error 0.0167(0.0216) Steps 910(902.56) | Grad Norm 2.1451(2.8484) | Total Time 14.00(14.00)\n",
      "Iter 7860 | Time 22.0330(22.2955) | Bit/dim 3.6058(3.6174) | Xent 0.0832(0.0679) | Loss 3.6474(3.6514) | Error 0.0267(0.0214) Steps 916(900.47) | Grad Norm 2.2706(2.6983) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 106.3499, Epoch Time 1349.3380(1313.2208), Bit/dim 3.6302(best: 3.6361), Xent 1.9257, Loss 4.5930, Error 0.3402(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7870 | Time 21.8097(22.2231) | Bit/dim 3.5887(3.6134) | Xent 0.0901(0.0644) | Loss 3.6337(3.6456) | Error 0.0244(0.0199) Steps 886(899.15) | Grad Norm 2.2670(2.5151) | Total Time 14.00(14.00)\n",
      "Iter 7880 | Time 22.4913(22.2261) | Bit/dim 3.6309(3.6126) | Xent 0.0456(0.0630) | Loss 3.6537(3.6441) | Error 0.0156(0.0198) Steps 874(896.86) | Grad Norm 1.9163(2.5423) | Total Time 14.00(14.00)\n",
      "Iter 7890 | Time 23.2009(22.2605) | Bit/dim 3.5978(3.6125) | Xent 0.0605(0.0654) | Loss 3.6280(3.6452) | Error 0.0211(0.0209) Steps 916(898.44) | Grad Norm 1.8933(2.6115) | Total Time 14.00(14.00)\n",
      "Iter 7900 | Time 22.7999(22.3908) | Bit/dim 3.6234(3.6133) | Xent 0.0775(0.0658) | Loss 3.6621(3.6461) | Error 0.0256(0.0210) Steps 934(905.98) | Grad Norm 2.5315(2.5836) | Total Time 14.00(14.00)\n",
      "Iter 7910 | Time 22.6638(22.3923) | Bit/dim 3.6218(3.6166) | Xent 0.0470(0.0641) | Loss 3.6453(3.6487) | Error 0.0200(0.0213) Steps 892(907.81) | Grad Norm 2.4439(2.6543) | Total Time 14.00(14.00)\n",
      "Iter 7920 | Time 22.3425(22.4093) | Bit/dim 3.6099(3.6141) | Xent 0.0819(0.0661) | Loss 3.6508(3.6472) | Error 0.0256(0.0213) Steps 880(907.89) | Grad Norm 2.3865(2.5398) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 104.7282, Epoch Time 1355.2481(1314.4816), Bit/dim 3.6304(best: 3.6302), Xent 1.9062, Loss 4.5835, Error 0.3533(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7930 | Time 22.2074(22.3583) | Bit/dim 3.6191(3.6141) | Xent 0.0398(0.0652) | Loss 3.6390(3.6467) | Error 0.0156(0.0208) Steps 886(904.09) | Grad Norm 2.9683(2.5636) | Total Time 14.00(14.00)\n",
      "Iter 7940 | Time 22.4932(22.3545) | Bit/dim 3.5961(3.6138) | Xent 0.0829(0.0677) | Loss 3.6375(3.6477) | Error 0.0278(0.0218) Steps 874(901.22) | Grad Norm 2.6651(2.6912) | Total Time 14.00(14.00)\n",
      "Iter 7950 | Time 22.0076(22.2616) | Bit/dim 3.6565(3.6151) | Xent 0.0745(0.0703) | Loss 3.6938(3.6503) | Error 0.0244(0.0228) Steps 886(895.28) | Grad Norm 2.4019(2.6903) | Total Time 14.00(14.00)\n",
      "Iter 7960 | Time 21.3674(22.2569) | Bit/dim 3.5974(3.6173) | Xent 0.0648(0.0694) | Loss 3.6298(3.6521) | Error 0.0189(0.0222) Steps 874(895.78) | Grad Norm 3.0358(2.7522) | Total Time 14.00(14.00)\n",
      "Iter 7970 | Time 21.7860(22.2392) | Bit/dim 3.6264(3.6177) | Xent 0.0800(0.0686) | Loss 3.6664(3.6520) | Error 0.0256(0.0220) Steps 886(894.39) | Grad Norm 2.8258(2.7400) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 106.6517, Epoch Time 1346.3791(1315.4385), Bit/dim 3.6399(best: 3.6302), Xent 1.9867, Loss 4.6332, Error 0.3537(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7980 | Time 21.9364(22.2611) | Bit/dim 3.6071(3.6184) | Xent 0.0773(0.0714) | Loss 3.6457(3.6541) | Error 0.0256(0.0228) Steps 916(897.42) | Grad Norm 2.7791(2.9066) | Total Time 14.00(14.00)\n",
      "Iter 7990 | Time 22.5818(22.2621) | Bit/dim 3.6174(3.6183) | Xent 0.0791(0.0738) | Loss 3.6570(3.6552) | Error 0.0233(0.0232) Steps 934(898.68) | Grad Norm 3.0295(2.9373) | Total Time 14.00(14.00)\n",
      "Iter 8000 | Time 21.9038(22.2782) | Bit/dim 3.6350(3.6207) | Xent 0.0711(0.0760) | Loss 3.6705(3.6587) | Error 0.0200(0.0240) Steps 874(897.11) | Grad Norm 4.7647(3.0671) | Total Time 14.00(14.00)\n",
      "Iter 8010 | Time 22.5240(22.2839) | Bit/dim 3.5964(3.6213) | Xent 0.0639(0.0759) | Loss 3.6284(3.6592) | Error 0.0300(0.0243) Steps 886(893.37) | Grad Norm 1.9831(2.9655) | Total Time 14.00(14.00)\n",
      "Iter 8020 | Time 22.2832(22.2896) | Bit/dim 3.6132(3.6214) | Xent 0.0680(0.0714) | Loss 3.6472(3.6571) | Error 0.0233(0.0227) Steps 874(892.94) | Grad Norm 2.4383(2.6882) | Total Time 14.00(14.00)\n",
      "Iter 8030 | Time 22.3203(22.2205) | Bit/dim 3.6217(3.6156) | Xent 0.0468(0.0687) | Loss 3.6451(3.6499) | Error 0.0167(0.0217) Steps 904(892.14) | Grad Norm 2.5985(2.6318) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 105.7777, Epoch Time 1348.0079(1316.4156), Bit/dim 3.6263(best: 3.6302), Xent 1.9140, Loss 4.5833, Error 0.3445(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8040 | Time 22.1561(22.2197) | Bit/dim 3.6177(3.6147) | Xent 0.0417(0.0643) | Loss 3.6386(3.6469) | Error 0.0122(0.0201) Steps 862(891.05) | Grad Norm 2.1446(2.6514) | Total Time 14.00(14.00)\n",
      "Iter 8050 | Time 22.1125(22.2667) | Bit/dim 3.6171(3.6158) | Xent 0.0363(0.0628) | Loss 3.6353(3.6472) | Error 0.0078(0.0196) Steps 910(895.31) | Grad Norm 2.6842(2.6848) | Total Time 14.00(14.00)\n",
      "Iter 8060 | Time 22.1211(22.2826) | Bit/dim 3.6212(3.6141) | Xent 0.0955(0.0644) | Loss 3.6690(3.6463) | Error 0.0267(0.0202) Steps 910(898.03) | Grad Norm 4.7039(2.8049) | Total Time 14.00(14.00)\n",
      "Iter 8070 | Time 22.4523(22.3699) | Bit/dim 3.6672(3.6214) | Xent 0.1116(0.0901) | Loss 3.7231(3.6665) | Error 0.0356(0.0276) Steps 886(899.29) | Grad Norm 3.0144(3.7949) | Total Time 14.00(14.00)\n",
      "Iter 8080 | Time 23.1062(22.4332) | Bit/dim 3.6466(3.6283) | Xent 0.0914(0.1011) | Loss 3.6923(3.6788) | Error 0.0278(0.0315) Steps 910(900.85) | Grad Norm 2.5197(3.8216) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0147 | Time 108.1821, Epoch Time 1361.5757(1317.7704), Bit/dim 3.6468(best: 3.6263), Xent 1.8670, Loss 4.5803, Error 0.3500(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8090 | Time 22.8281(22.4611) | Bit/dim 3.6301(3.6283) | Xent 0.0556(0.0946) | Loss 3.6579(3.6756) | Error 0.0189(0.0297) Steps 928(904.27) | Grad Norm 2.3296(3.4885) | Total Time 14.00(14.00)\n",
      "Iter 8100 | Time 22.3718(22.4936) | Bit/dim 3.5926(3.6253) | Xent 0.0444(0.0835) | Loss 3.6148(3.6670) | Error 0.0167(0.0266) Steps 928(907.31) | Grad Norm 1.8648(3.1194) | Total Time 14.00(14.00)\n",
      "Iter 8110 | Time 22.2913(22.4264) | Bit/dim 3.6188(3.6253) | Xent 0.0464(0.0764) | Loss 3.6420(3.6635) | Error 0.0144(0.0243) Steps 904(908.98) | Grad Norm 2.3143(2.9143) | Total Time 14.00(14.00)\n",
      "Iter 8120 | Time 22.4505(22.3580) | Bit/dim 3.5966(3.6218) | Xent 0.0722(0.0702) | Loss 3.6327(3.6569) | Error 0.0289(0.0222) Steps 910(908.04) | Grad Norm 2.1073(2.7045) | Total Time 14.00(14.00)\n",
      "Iter 8130 | Time 22.0054(22.2987) | Bit/dim 3.6221(3.6194) | Xent 0.0810(0.0689) | Loss 3.6626(3.6538) | Error 0.0267(0.0214) Steps 910(905.59) | Grad Norm 3.2455(2.5855) | Total Time 14.00(14.00)\n",
      "Iter 8140 | Time 21.7665(22.2733) | Bit/dim 3.6051(3.6157) | Xent 0.0607(0.0667) | Loss 3.6355(3.6490) | Error 0.0211(0.0208) Steps 880(904.99) | Grad Norm 4.2121(2.6170) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 108.1410, Epoch Time 1352.4202(1318.8099), Bit/dim 3.6346(best: 3.6263), Xent 1.9953, Loss 4.6323, Error 0.3406(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8150 | Time 22.1831(22.3628) | Bit/dim 3.6066(3.6157) | Xent 0.0677(0.0635) | Loss 3.6404(3.6474) | Error 0.0222(0.0200) Steps 892(904.92) | Grad Norm 2.8887(2.6463) | Total Time 14.00(14.00)\n",
      "Iter 8160 | Time 22.8661(22.4284) | Bit/dim 3.6450(3.6199) | Xent 0.0540(0.0677) | Loss 3.6720(3.6537) | Error 0.0133(0.0210) Steps 922(904.97) | Grad Norm 2.6057(2.7109) | Total Time 14.00(14.00)\n",
      "Iter 8170 | Time 22.3888(22.4645) | Bit/dim 3.6077(3.6173) | Xent 0.0631(0.0698) | Loss 3.6393(3.6522) | Error 0.0178(0.0214) Steps 904(908.02) | Grad Norm 2.0832(2.7342) | Total Time 14.00(14.00)\n",
      "Iter 8180 | Time 22.4339(22.5056) | Bit/dim 3.6205(3.6154) | Xent 0.0692(0.0679) | Loss 3.6551(3.6493) | Error 0.0178(0.0206) Steps 910(909.37) | Grad Norm 3.0626(2.6729) | Total Time 14.00(14.00)\n",
      "Iter 8190 | Time 22.2672(22.4808) | Bit/dim 3.5882(3.6111) | Xent 0.0926(0.0664) | Loss 3.6345(3.6443) | Error 0.0256(0.0199) Steps 904(909.50) | Grad Norm 2.3041(2.5853) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 106.6063, Epoch Time 1364.4384(1320.1788), Bit/dim 3.6296(best: 3.6263), Xent 1.9653, Loss 4.6123, Error 0.3459(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8200 | Time 22.9359(22.4506) | Bit/dim 3.6388(3.6101) | Xent 0.0714(0.0654) | Loss 3.6745(3.6429) | Error 0.0211(0.0196) Steps 910(907.97) | Grad Norm 3.0287(2.5376) | Total Time 14.00(14.00)\n",
      "Iter 8210 | Time 22.6007(22.4265) | Bit/dim 3.5894(3.6074) | Xent 0.0556(0.0611) | Loss 3.6172(3.6379) | Error 0.0156(0.0184) Steps 910(905.27) | Grad Norm 2.6877(2.4127) | Total Time 14.00(14.00)\n",
      "Iter 8220 | Time 21.6698(22.3723) | Bit/dim 3.6189(3.6048) | Xent 0.0511(0.0560) | Loss 3.6444(3.6328) | Error 0.0189(0.0170) Steps 892(905.85) | Grad Norm 1.8353(2.2755) | Total Time 14.00(14.00)\n",
      "Iter 8230 | Time 23.4362(22.3732) | Bit/dim 3.6244(3.6063) | Xent 0.0497(0.0556) | Loss 3.6492(3.6341) | Error 0.0167(0.0172) Steps 898(904.34) | Grad Norm 1.8816(2.2838) | Total Time 14.00(14.00)\n",
      "Iter 8240 | Time 22.1225(22.3613) | Bit/dim 3.6427(3.6098) | Xent 0.0832(0.0608) | Loss 3.6843(3.6402) | Error 0.0233(0.0183) Steps 886(904.20) | Grad Norm 2.3673(2.4956) | Total Time 14.00(14.00)\n",
      "Iter 8250 | Time 22.9551(22.3918) | Bit/dim 3.6192(3.6095) | Xent 0.1224(0.0647) | Loss 3.6804(3.6418) | Error 0.0333(0.0199) Steps 940(905.58) | Grad Norm 4.0129(2.5197) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 108.0939, Epoch Time 1356.4178(1321.2659), Bit/dim 3.6324(best: 3.6263), Xent 1.8941, Loss 4.5795, Error 0.3426(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8260 | Time 22.0870(22.4746) | Bit/dim 3.6239(3.6092) | Xent 0.1101(0.0700) | Loss 3.6790(3.6442) | Error 0.0311(0.0211) Steps 910(910.10) | Grad Norm 4.9349(2.7557) | Total Time 14.00(14.00)\n",
      "Iter 8270 | Time 21.7972(22.4304) | Bit/dim 3.6385(3.6120) | Xent 0.0504(0.0713) | Loss 3.6637(3.6476) | Error 0.0222(0.0219) Steps 916(909.17) | Grad Norm 3.2894(2.8542) | Total Time 14.00(14.00)\n",
      "Iter 8280 | Time 22.5001(22.5189) | Bit/dim 3.5953(3.6119) | Xent 0.0302(0.0671) | Loss 3.6104(3.6454) | Error 0.0078(0.0209) Steps 922(909.61) | Grad Norm 1.6520(2.6829) | Total Time 14.00(14.00)\n",
      "Iter 8290 | Time 22.2194(22.4689) | Bit/dim 3.6054(3.6137) | Xent 0.0600(0.0651) | Loss 3.6354(3.6463) | Error 0.0211(0.0205) Steps 886(905.97) | Grad Norm 2.9255(2.6457) | Total Time 14.00(14.00)\n",
      "Iter 8300 | Time 22.7642(22.4647) | Bit/dim 3.5970(3.6122) | Xent 0.0761(0.0638) | Loss 3.6350(3.6441) | Error 0.0211(0.0201) Steps 928(905.46) | Grad Norm 2.2054(2.5519) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0151 | Time 108.7354, Epoch Time 1365.9216(1322.6056), Bit/dim 3.6358(best: 3.6263), Xent 1.9504, Loss 4.6110, Error 0.3505(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8310 | Time 22.3963(22.4634) | Bit/dim 3.5940(3.6128) | Xent 0.0364(0.0650) | Loss 3.6122(3.6453) | Error 0.0122(0.0205) Steps 892(908.39) | Grad Norm 1.7687(2.6022) | Total Time 14.00(14.00)\n",
      "Iter 8320 | Time 22.4149(22.4356) | Bit/dim 3.6511(3.6139) | Xent 0.0716(0.0645) | Loss 3.6869(3.6461) | Error 0.0200(0.0200) Steps 886(908.37) | Grad Norm 2.0820(2.5451) | Total Time 14.00(14.00)\n",
      "Iter 8330 | Time 22.1640(22.3496) | Bit/dim 3.6169(3.6097) | Xent 0.0421(0.0614) | Loss 3.6379(3.6404) | Error 0.0089(0.0191) Steps 874(903.32) | Grad Norm 1.7571(2.4262) | Total Time 14.00(14.00)\n",
      "Iter 8340 | Time 22.6708(22.3808) | Bit/dim 3.5941(3.6079) | Xent 0.0795(0.0588) | Loss 3.6338(3.6373) | Error 0.0244(0.0184) Steps 910(903.07) | Grad Norm 3.7210(2.3916) | Total Time 14.00(14.00)\n",
      "Iter 8350 | Time 22.7491(22.4357) | Bit/dim 3.5866(3.6109) | Xent 0.0930(0.0621) | Loss 3.6331(3.6420) | Error 0.0300(0.0195) Steps 910(907.44) | Grad Norm 3.4592(2.4587) | Total Time 14.00(14.00)\n",
      "Iter 8360 | Time 22.3191(22.3773) | Bit/dim 3.6135(3.6110) | Xent 0.0540(0.0630) | Loss 3.6404(3.6425) | Error 0.0189(0.0197) Steps 898(904.23) | Grad Norm 3.0239(2.5796) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0152 | Time 106.5839, Epoch Time 1353.6871(1323.5380), Bit/dim 3.6278(best: 3.6263), Xent 1.8913, Loss 4.5735, Error 0.3389(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8370 | Time 21.8152(22.2812) | Bit/dim 3.6193(3.6133) | Xent 0.0683(0.0664) | Loss 3.6535(3.6465) | Error 0.0233(0.0212) Steps 886(903.12) | Grad Norm 1.8287(2.8868) | Total Time 14.00(14.00)\n",
      "Iter 8380 | Time 21.6768(22.2719) | Bit/dim 3.6079(3.6126) | Xent 0.0711(0.0685) | Loss 3.6434(3.6469) | Error 0.0233(0.0217) Steps 880(902.54) | Grad Norm 2.9729(2.9479) | Total Time 14.00(14.00)\n",
      "Iter 8390 | Time 22.2642(22.3004) | Bit/dim 3.6052(3.6123) | Xent 0.0828(0.0705) | Loss 3.6466(3.6476) | Error 0.0311(0.0226) Steps 904(901.88) | Grad Norm 2.7267(3.0002) | Total Time 14.00(14.00)\n",
      "Iter 8400 | Time 22.0975(22.2431) | Bit/dim 3.6220(3.6111) | Xent 0.0821(0.0703) | Loss 3.6631(3.6462) | Error 0.0278(0.0221) Steps 874(898.16) | Grad Norm 4.2338(2.9571) | Total Time 14.00(14.00)\n",
      "Iter 8410 | Time 22.4914(22.2344) | Bit/dim 3.6004(3.6133) | Xent 0.0680(0.0699) | Loss 3.6343(3.6483) | Error 0.0144(0.0219) Steps 886(896.25) | Grad Norm 1.7928(2.8219) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0153 | Time 105.6561, Epoch Time 1345.8031(1324.2060), Bit/dim 3.6263(best: 3.6263), Xent 1.8642, Loss 4.5584, Error 0.3419(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8420 | Time 22.9710(22.3441) | Bit/dim 3.6485(3.6165) | Xent 0.0582(0.0669) | Loss 3.6775(3.6499) | Error 0.0222(0.0213) Steps 916(903.88) | Grad Norm 2.6052(2.7777) | Total Time 14.00(14.00)\n",
      "Iter 8430 | Time 22.5470(22.3208) | Bit/dim 3.6179(3.6150) | Xent 0.0673(0.0671) | Loss 3.6516(3.6486) | Error 0.0222(0.0212) Steps 910(906.32) | Grad Norm 3.4248(2.8146) | Total Time 14.00(14.00)\n",
      "Iter 8440 | Time 22.1919(22.3570) | Bit/dim 3.6360(3.6173) | Xent 0.1112(0.0765) | Loss 3.6916(3.6555) | Error 0.0378(0.0241) Steps 904(908.43) | Grad Norm 4.2473(3.1240) | Total Time 14.00(14.00)\n",
      "Iter 8450 | Time 22.6011(22.4238) | Bit/dim 3.6395(3.6177) | Xent 0.0700(0.0751) | Loss 3.6745(3.6552) | Error 0.0178(0.0236) Steps 934(909.71) | Grad Norm 2.0447(2.9794) | Total Time 14.00(14.00)\n",
      "Iter 8460 | Time 22.5824(22.4462) | Bit/dim 3.5765(3.6135) | Xent 0.0623(0.0744) | Loss 3.6076(3.6507) | Error 0.0244(0.0236) Steps 934(911.13) | Grad Norm 2.4970(2.8212) | Total Time 14.00(14.00)\n",
      "Iter 8470 | Time 22.9673(22.4952) | Bit/dim 3.6564(3.6109) | Xent 0.0640(0.0728) | Loss 3.6884(3.6473) | Error 0.0211(0.0230) Steps 916(912.46) | Grad Norm 2.7050(2.7586) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0154 | Time 105.9025, Epoch Time 1362.0234(1325.3405), Bit/dim 3.6343(best: 3.6263), Xent 1.9553, Loss 4.6120, Error 0.3555(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8480 | Time 22.6373(22.4929) | Bit/dim 3.6221(3.6107) | Xent 0.0485(0.0696) | Loss 3.6463(3.6455) | Error 0.0178(0.0220) Steps 922(911.76) | Grad Norm 2.1689(2.6990) | Total Time 14.00(14.00)\n",
      "Iter 8490 | Time 22.9125(22.5409) | Bit/dim 3.6173(3.6096) | Xent 0.0510(0.0642) | Loss 3.6428(3.6417) | Error 0.0200(0.0202) Steps 928(915.07) | Grad Norm 4.1699(2.7233) | Total Time 14.00(14.00)\n",
      "Iter 8500 | Time 22.0478(22.5971) | Bit/dim 3.5969(3.6101) | Xent 0.0792(0.0640) | Loss 3.6365(3.6421) | Error 0.0256(0.0204) Steps 916(916.47) | Grad Norm 3.6607(2.8734) | Total Time 14.00(14.00)\n",
      "Iter 8510 | Time 22.9963(22.7125) | Bit/dim 3.5929(3.6085) | Xent 0.0753(0.0665) | Loss 3.6305(3.6417) | Error 0.0211(0.0209) Steps 922(917.04) | Grad Norm 2.8935(2.8505) | Total Time 14.00(14.00)\n",
      "Iter 8520 | Time 22.7585(22.6830) | Bit/dim 3.6064(3.6110) | Xent 0.0867(0.0697) | Loss 3.6498(3.6459) | Error 0.0289(0.0218) Steps 922(918.81) | Grad Norm 2.1729(2.8381) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0155 | Time 108.5788, Epoch Time 1375.2814(1326.8387), Bit/dim 3.6297(best: 3.6263), Xent 1.8803, Loss 4.5699, Error 0.3352(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8530 | Time 23.5399(22.6896) | Bit/dim 3.6221(3.6120) | Xent 0.0698(0.0693) | Loss 3.6570(3.6467) | Error 0.0178(0.0214) Steps 952(923.03) | Grad Norm 2.6365(2.6970) | Total Time 14.00(14.00)\n",
      "Iter 8540 | Time 22.5331(22.6789) | Bit/dim 3.6041(3.6093) | Xent 0.0882(0.0688) | Loss 3.6482(3.6437) | Error 0.0256(0.0211) Steps 916(921.08) | Grad Norm 2.5021(2.6709) | Total Time 14.00(14.00)\n",
      "Iter 8550 | Time 23.5476(22.7904) | Bit/dim 3.6184(3.6091) | Xent 0.0426(0.0664) | Loss 3.6397(3.6423) | Error 0.0156(0.0202) Steps 904(922.80) | Grad Norm 1.6001(2.5687) | Total Time 14.00(14.00)\n",
      "Iter 8560 | Time 23.5506(22.8861) | Bit/dim 3.5960(3.6085) | Xent 0.0475(0.0633) | Loss 3.6198(3.6402) | Error 0.0156(0.0189) Steps 934(926.52) | Grad Norm 1.4822(2.4305) | Total Time 14.00(14.00)\n",
      "Iter 8570 | Time 23.0224(22.9186) | Bit/dim 3.5948(3.6063) | Xent 0.0439(0.0614) | Loss 3.6167(3.6370) | Error 0.0122(0.0185) Steps 892(925.49) | Grad Norm 2.0323(2.3970) | Total Time 14.00(14.00)\n",
      "Iter 8580 | Time 22.3806(22.8668) | Bit/dim 3.5973(3.6043) | Xent 0.0630(0.0595) | Loss 3.6288(3.6340) | Error 0.0278(0.0182) Steps 910(923.70) | Grad Norm 2.4393(2.4387) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0156 | Time 105.8894, Epoch Time 1384.5715(1328.5707), Bit/dim 3.6230(best: 3.6263), Xent 1.9678, Loss 4.6069, Error 0.3464(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8590 | Time 22.6193(22.8809) | Bit/dim 3.5812(3.6039) | Xent 0.0554(0.0563) | Loss 3.6090(3.6320) | Error 0.0178(0.0172) Steps 940(926.79) | Grad Norm 2.9226(2.3619) | Total Time 14.00(14.00)\n",
      "Iter 8600 | Time 22.9105(22.8896) | Bit/dim 3.6369(3.6043) | Xent 0.0440(0.0537) | Loss 3.6589(3.6312) | Error 0.0133(0.0163) Steps 910(926.43) | Grad Norm 1.9857(2.2701) | Total Time 14.00(14.00)\n",
      "Iter 8610 | Time 23.8090(22.9234) | Bit/dim 3.6038(3.6021) | Xent 0.0383(0.0513) | Loss 3.6229(3.6277) | Error 0.0144(0.0154) Steps 946(926.30) | Grad Norm 2.0444(2.1914) | Total Time 14.00(14.00)\n",
      "Iter 8620 | Time 22.7348(22.8932) | Bit/dim 3.5969(3.6011) | Xent 0.0638(0.0560) | Loss 3.6288(3.6291) | Error 0.0233(0.0171) Steps 910(924.60) | Grad Norm 3.1422(2.4712) | Total Time 14.00(14.00)\n",
      "Iter 8630 | Time 22.1933(22.7691) | Bit/dim 3.6001(3.6020) | Xent 0.1240(0.0633) | Loss 3.6621(3.6336) | Error 0.0333(0.0194) Steps 898(918.67) | Grad Norm 3.7244(2.6064) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0157 | Time 107.8662, Epoch Time 1384.6014(1330.2516), Bit/dim 3.6307(best: 3.6230), Xent 1.8604, Loss 4.5609, Error 0.3457(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8640 | Time 22.7676(22.8709) | Bit/dim 3.6073(3.6040) | Xent 0.0759(0.0691) | Loss 3.6453(3.6386) | Error 0.0267(0.0215) Steps 952(921.11) | Grad Norm 3.1023(2.8073) | Total Time 14.00(14.00)\n",
      "Iter 8650 | Time 22.3142(22.7557) | Bit/dim 3.6218(3.6069) | Xent 0.0528(0.0699) | Loss 3.6482(3.6418) | Error 0.0133(0.0216) Steps 910(920.07) | Grad Norm 1.8352(2.6946) | Total Time 14.00(14.00)\n",
      "Iter 8660 | Time 22.3231(22.6603) | Bit/dim 3.6057(3.6086) | Xent 0.0753(0.0697) | Loss 3.6433(3.6434) | Error 0.0233(0.0212) Steps 916(920.56) | Grad Norm 3.0827(2.7848) | Total Time 14.00(14.00)\n",
      "Iter 8670 | Time 22.0629(22.7082) | Bit/dim 3.6022(3.6059) | Xent 0.0397(0.0697) | Loss 3.6221(3.6407) | Error 0.0100(0.0214) Steps 928(922.86) | Grad Norm 2.8963(2.7181) | Total Time 14.00(14.00)\n",
      "Iter 8680 | Time 22.1304(22.6028) | Bit/dim 3.5841(3.6074) | Xent 0.0555(0.0687) | Loss 3.6118(3.6418) | Error 0.0211(0.0213) Steps 928(920.07) | Grad Norm 3.5151(2.7000) | Total Time 14.00(14.00)\n",
      "Iter 8690 | Time 23.5108(22.6945) | Bit/dim 3.6056(3.6070) | Xent 0.0514(0.0659) | Loss 3.6313(3.6400) | Error 0.0178(0.0207) Steps 946(920.89) | Grad Norm 2.9187(2.7060) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0158 | Time 107.4379, Epoch Time 1368.7914(1331.4078), Bit/dim 3.6213(best: 3.6230), Xent 1.9442, Loss 4.5934, Error 0.3425(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8700 | Time 22.8024(22.6096) | Bit/dim 3.5976(3.6027) | Xent 0.0443(0.0634) | Loss 3.6198(3.6344) | Error 0.0133(0.0201) Steps 898(916.03) | Grad Norm 2.7660(2.6334) | Total Time 14.00(14.00)\n",
      "Iter 8710 | Time 22.3135(22.5883) | Bit/dim 3.6041(3.6034) | Xent 0.0374(0.0620) | Loss 3.6228(3.6344) | Error 0.0167(0.0200) Steps 928(915.41) | Grad Norm 2.5609(2.5304) | Total Time 14.00(14.00)\n",
      "Iter 8720 | Time 22.0685(22.5259) | Bit/dim 3.6079(3.6066) | Xent 0.1192(0.0681) | Loss 3.6675(3.6406) | Error 0.0344(0.0220) Steps 904(912.87) | Grad Norm 6.3274(2.9405) | Total Time 14.00(14.00)\n",
      "Iter 8730 | Time 22.4494(22.6300) | Bit/dim 3.6193(3.6093) | Xent 0.0716(0.0711) | Loss 3.6551(3.6448) | Error 0.0200(0.0225) Steps 952(918.35) | Grad Norm 2.9385(3.1090) | Total Time 14.00(14.00)\n",
      "Iter 8740 | Time 23.3584(22.7109) | Bit/dim 3.6188(3.6105) | Xent 0.0424(0.0658) | Loss 3.6400(3.6434) | Error 0.0122(0.0208) Steps 910(918.63) | Grad Norm 1.3227(2.8657) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0159 | Time 106.2398, Epoch Time 1367.9919(1332.5054), Bit/dim 3.6202(best: 3.6213), Xent 1.9880, Loss 4.6142, Error 0.3406(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8750 | Time 22.3275(22.7047) | Bit/dim 3.5625(3.6069) | Xent 0.0321(0.0597) | Loss 3.5785(3.6367) | Error 0.0111(0.0187) Steps 910(918.38) | Grad Norm 1.8957(2.6183) | Total Time 14.00(14.00)\n",
      "Iter 8760 | Time 22.8599(22.7727) | Bit/dim 3.5968(3.6040) | Xent 0.0425(0.0571) | Loss 3.6181(3.6326) | Error 0.0144(0.0179) Steps 916(920.02) | Grad Norm 2.0503(2.4427) | Total Time 14.00(14.00)\n",
      "Iter 8770 | Time 22.3674(22.8449) | Bit/dim 3.5686(3.6007) | Xent 0.0718(0.0567) | Loss 3.6045(3.6290) | Error 0.0222(0.0176) Steps 934(921.92) | Grad Norm 1.8972(2.3283) | Total Time 14.00(14.00)\n",
      "Iter 8780 | Time 23.2857(22.8118) | Bit/dim 3.6256(3.6043) | Xent 0.1186(0.0621) | Loss 3.6849(3.6354) | Error 0.0267(0.0192) Steps 916(922.46) | Grad Norm 4.6952(2.5318) | Total Time 14.00(14.00)\n",
      "Iter 8790 | Time 22.8655(22.8239) | Bit/dim 3.6006(3.6043) | Xent 0.0630(0.0626) | Loss 3.6321(3.6356) | Error 0.0200(0.0193) Steps 910(921.79) | Grad Norm 2.4904(2.4856) | Total Time 14.00(14.00)\n",
      "Iter 8800 | Time 23.3693(22.9011) | Bit/dim 3.5895(3.6046) | Xent 0.0491(0.0616) | Loss 3.6141(3.6354) | Error 0.0144(0.0192) Steps 958(926.71) | Grad Norm 1.6843(2.3622) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0160 | Time 108.5694, Epoch Time 1388.1769(1334.1755), Bit/dim 3.6186(best: 3.6202), Xent 1.9867, Loss 4.6119, Error 0.3398(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8810 | Time 23.3733(23.0603) | Bit/dim 3.5916(3.6024) | Xent 0.0506(0.0572) | Loss 3.6169(3.6310) | Error 0.0167(0.0179) Steps 934(932.15) | Grad Norm 2.6436(2.2429) | Total Time 14.00(14.00)\n",
      "Iter 8820 | Time 23.2386(23.0950) | Bit/dim 3.5949(3.6029) | Xent 0.0498(0.0580) | Loss 3.6198(3.6319) | Error 0.0133(0.0179) Steps 940(931.16) | Grad Norm 1.7544(2.3147) | Total Time 14.00(14.00)\n",
      "Iter 8830 | Time 23.1578(23.1126) | Bit/dim 3.6016(3.6004) | Xent 0.0469(0.0597) | Loss 3.6250(3.6303) | Error 0.0133(0.0180) Steps 940(933.32) | Grad Norm 2.6666(2.3338) | Total Time 14.00(14.00)\n",
      "Iter 8840 | Time 22.7621(23.1521) | Bit/dim 3.6217(3.6009) | Xent 0.0549(0.0563) | Loss 3.6491(3.6290) | Error 0.0133(0.0172) Steps 952(937.10) | Grad Norm 2.0856(2.2257) | Total Time 14.00(14.00)\n",
      "Iter 8850 | Time 23.6066(23.1989) | Bit/dim 3.6175(3.6006) | Xent 0.0703(0.0559) | Loss 3.6526(3.6286) | Error 0.0222(0.0169) Steps 958(936.00) | Grad Norm 2.9318(2.2704) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0161 | Time 106.9834, Epoch Time 1404.1592(1336.2750), Bit/dim 3.6283(best: 3.6186), Xent 1.9470, Loss 4.6018, Error 0.3484(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8860 | Time 23.3276(23.0934) | Bit/dim 3.5965(3.6017) | Xent 0.0714(0.0587) | Loss 3.6322(3.6310) | Error 0.0211(0.0176) Steps 952(933.37) | Grad Norm 3.5638(2.4887) | Total Time 14.00(14.00)\n",
      "Iter 8870 | Time 22.7897(23.1297) | Bit/dim 3.5864(3.6046) | Xent 0.0598(0.0665) | Loss 3.6163(3.6378) | Error 0.0189(0.0196) Steps 922(935.37) | Grad Norm 2.6777(2.7637) | Total Time 14.00(14.00)\n",
      "Iter 8880 | Time 23.3012(23.1106) | Bit/dim 3.6577(3.6099) | Xent 0.0808(0.0758) | Loss 3.6981(3.6478) | Error 0.0278(0.0223) Steps 958(938.09) | Grad Norm 2.5968(2.9367) | Total Time 14.00(14.00)\n",
      "Iter 8890 | Time 23.6729(23.2195) | Bit/dim 3.6039(3.6079) | Xent 0.0708(0.0751) | Loss 3.6393(3.6454) | Error 0.0256(0.0228) Steps 952(939.55) | Grad Norm 2.7790(2.9080) | Total Time 14.00(14.00)\n",
      "Iter 8900 | Time 23.3815(23.2770) | Bit/dim 3.6166(3.6058) | Xent 0.0567(0.0740) | Loss 3.6450(3.6428) | Error 0.0233(0.0229) Steps 940(942.03) | Grad Norm 2.1436(2.8065) | Total Time 14.00(14.00)\n",
      "Iter 8910 | Time 22.8904(23.2508) | Bit/dim 3.5837(3.6056) | Xent 0.0713(0.0710) | Loss 3.6193(3.6411) | Error 0.0189(0.0219) Steps 940(944.45) | Grad Norm 3.0079(2.6881) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0162 | Time 107.1642, Epoch Time 1403.1769(1338.2821), Bit/dim 3.6150(best: 3.6186), Xent 1.9548, Loss 4.5924, Error 0.3462(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8920 | Time 23.2042(23.2585) | Bit/dim 3.5795(3.6018) | Xent 0.0692(0.0665) | Loss 3.6141(3.6350) | Error 0.0200(0.0204) Steps 958(947.33) | Grad Norm 2.0232(2.4759) | Total Time 14.00(14.00)\n",
      "Iter 8930 | Time 23.4100(23.2910) | Bit/dim 3.5786(3.5996) | Xent 0.0583(0.0634) | Loss 3.6077(3.6313) | Error 0.0156(0.0192) Steps 958(946.92) | Grad Norm 1.9879(2.3566) | Total Time 14.00(14.00)\n",
      "Iter 8940 | Time 22.7666(23.2395) | Bit/dim 3.6092(3.6007) | Xent 0.0730(0.0621) | Loss 3.6457(3.6317) | Error 0.0278(0.0190) Steps 934(942.86) | Grad Norm 3.4928(2.3753) | Total Time 14.00(14.00)\n",
      "Iter 8950 | Time 22.4706(23.1158) | Bit/dim 3.6208(3.6023) | Xent 0.0818(0.0629) | Loss 3.6617(3.6338) | Error 0.0289(0.0195) Steps 904(933.98) | Grad Norm 2.7627(2.3673) | Total Time 14.00(14.00)\n",
      "Iter 8960 | Time 23.1795(23.1134) | Bit/dim 3.6164(3.6020) | Xent 0.0868(0.0643) | Loss 3.6598(3.6341) | Error 0.0278(0.0198) Steps 958(935.83) | Grad Norm 2.3975(2.3411) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0163 | Time 108.0679, Epoch Time 1399.1909(1340.1093), Bit/dim 3.6173(best: 3.6150), Xent 1.8822, Loss 4.5584, Error 0.3412(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8970 | Time 23.4661(23.1438) | Bit/dim 3.5994(3.6023) | Xent 0.0726(0.0646) | Loss 3.6357(3.6346) | Error 0.0233(0.0200) Steps 934(936.41) | Grad Norm 3.8149(2.4470) | Total Time 14.00(14.00)\n",
      "Iter 8980 | Time 22.9375(22.9774) | Bit/dim 3.6034(3.6008) | Xent 0.0694(0.0648) | Loss 3.6381(3.6332) | Error 0.0211(0.0201) Steps 952(934.97) | Grad Norm 2.5684(2.4350) | Total Time 14.00(14.00)\n",
      "Iter 8990 | Time 22.6140(22.8834) | Bit/dim 3.6164(3.5991) | Xent 0.0389(0.0629) | Loss 3.6358(3.6306) | Error 0.0122(0.0196) Steps 922(930.51) | Grad Norm 1.6484(2.3972) | Total Time 14.00(14.00)\n",
      "Iter 9000 | Time 23.3786(22.8767) | Bit/dim 3.5968(3.5969) | Xent 0.0403(0.0606) | Loss 3.6169(3.6272) | Error 0.0122(0.0188) Steps 910(928.00) | Grad Norm 1.7755(2.2996) | Total Time 14.00(14.00)\n",
      "Iter 9010 | Time 22.9567(22.9433) | Bit/dim 3.5914(3.5954) | Xent 0.0516(0.0580) | Loss 3.6172(3.6244) | Error 0.0189(0.0184) Steps 952(929.20) | Grad Norm 1.4782(2.3054) | Total Time 14.00(14.00)\n",
      "Iter 9020 | Time 22.5628(22.8975) | Bit/dim 3.6057(3.5991) | Xent 0.0673(0.0630) | Loss 3.6394(3.6307) | Error 0.0244(0.0199) Steps 898(923.86) | Grad Norm 3.6028(2.5034) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0164 | Time 106.7521, Epoch Time 1379.4562(1341.2897), Bit/dim 3.6260(best: 3.6150), Xent 1.9269, Loss 4.5895, Error 0.3485(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9030 | Time 22.8724(22.8953) | Bit/dim 3.6052(3.6009) | Xent 0.0563(0.0620) | Loss 3.6333(3.6319) | Error 0.0200(0.0197) Steps 928(922.96) | Grad Norm 2.4604(2.5339) | Total Time 14.00(14.00)\n",
      "Iter 9040 | Time 23.6275(22.9284) | Bit/dim 3.5784(3.5991) | Xent 0.1010(0.0636) | Loss 3.6289(3.6310) | Error 0.0300(0.0202) Steps 940(925.48) | Grad Norm 3.3580(2.7088) | Total Time 14.00(14.00)\n",
      "Iter 9050 | Time 22.6260(22.9628) | Bit/dim 3.5798(3.5996) | Xent 0.0573(0.0628) | Loss 3.6085(3.6310) | Error 0.0167(0.0194) Steps 934(926.78) | Grad Norm 3.1177(2.6710) | Total Time 14.00(14.00)\n",
      "Iter 9060 | Time 23.4846(22.9944) | Bit/dim 3.6059(3.5992) | Xent 0.0474(0.0607) | Loss 3.6296(3.6296) | Error 0.0133(0.0186) Steps 934(925.95) | Grad Norm 2.2431(2.5963) | Total Time 14.00(14.00)\n",
      "Iter 9070 | Time 23.4998(23.0711) | Bit/dim 3.5850(3.6004) | Xent 0.0593(0.0616) | Loss 3.6147(3.6312) | Error 0.0222(0.0190) Steps 970(929.91) | Grad Norm 3.0455(2.5519) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0165 | Time 106.2089, Epoch Time 1392.8048(1342.8352), Bit/dim 3.6109(best: 3.6150), Xent 1.9692, Loss 4.5955, Error 0.3543(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9080 | Time 22.3258(22.9757) | Bit/dim 3.6052(3.6001) | Xent 0.0391(0.0598) | Loss 3.6247(3.6300) | Error 0.0100(0.0184) Steps 946(930.39) | Grad Norm 1.8645(2.4338) | Total Time 14.00(14.00)\n",
      "Iter 9090 | Time 22.7816(22.8777) | Bit/dim 3.6334(3.5988) | Xent 0.0746(0.0582) | Loss 3.6707(3.6280) | Error 0.0200(0.0179) Steps 928(928.19) | Grad Norm 3.0864(2.3815) | Total Time 14.00(14.00)\n",
      "Iter 9100 | Time 23.4366(22.9254) | Bit/dim 3.5725(3.5983) | Xent 0.0776(0.0577) | Loss 3.6113(3.6271) | Error 0.0211(0.0180) Steps 940(930.32) | Grad Norm 2.1024(2.3472) | Total Time 14.00(14.00)\n",
      "Iter 9110 | Time 22.8618(23.0327) | Bit/dim 3.5976(3.5964) | Xent 0.0427(0.0551) | Loss 3.6190(3.6239) | Error 0.0133(0.0175) Steps 946(931.96) | Grad Norm 2.1787(2.2954) | Total Time 14.00(14.00)\n",
      "Iter 9120 | Time 23.0161(23.0697) | Bit/dim 3.6032(3.5954) | Xent 0.0558(0.0556) | Loss 3.6311(3.6231) | Error 0.0167(0.0170) Steps 922(930.97) | Grad Norm 2.1114(2.2902) | Total Time 14.00(14.00)\n",
      "Iter 9130 | Time 22.9245(23.1591) | Bit/dim 3.5967(3.5958) | Xent 0.0519(0.0526) | Loss 3.6226(3.6221) | Error 0.0211(0.0161) Steps 952(933.66) | Grad Norm 1.9682(2.2158) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0166 | Time 107.8984, Epoch Time 1394.3075(1344.3794), Bit/dim 3.6125(best: 3.6109), Xent 1.9647, Loss 4.5949, Error 0.3399(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9140 | Time 22.6585(23.1361) | Bit/dim 3.5580(3.5910) | Xent 0.0520(0.0520) | Loss 3.5840(3.6169) | Error 0.0122(0.0157) Steps 952(936.41) | Grad Norm 2.0839(2.1750) | Total Time 14.00(14.00)\n",
      "Iter 9150 | Time 23.9697(23.2304) | Bit/dim 3.5915(3.5921) | Xent 0.0481(0.0508) | Loss 3.6156(3.6175) | Error 0.0189(0.0152) Steps 934(936.92) | Grad Norm 3.1896(2.1974) | Total Time 14.00(14.00)\n",
      "Iter 9160 | Time 23.1788(23.1631) | Bit/dim 3.6056(3.5949) | Xent 0.0733(0.0522) | Loss 3.6422(3.6210) | Error 0.0200(0.0155) Steps 952(937.41) | Grad Norm 2.7531(2.3008) | Total Time 14.00(14.00)\n",
      "Iter 9170 | Time 23.6228(23.2463) | Bit/dim 3.5848(3.5952) | Xent 0.0241(0.0498) | Loss 3.5969(3.6201) | Error 0.0078(0.0149) Steps 928(939.46) | Grad Norm 1.8221(2.2631) | Total Time 14.00(14.00)\n",
      "Iter 9180 | Time 23.5081(23.1544) | Bit/dim 3.6069(3.5949) | Xent 0.0442(0.0483) | Loss 3.6290(3.6191) | Error 0.0167(0.0147) Steps 922(936.86) | Grad Norm 2.1122(2.2338) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0167 | Time 110.4696, Epoch Time 1402.8965(1346.1349), Bit/dim 3.6120(best: 3.6109), Xent 1.9078, Loss 4.5659, Error 0.3438(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9190 | Time 23.8303(23.1519) | Bit/dim 3.6099(3.5945) | Xent 0.0928(0.0511) | Loss 3.6563(3.6200) | Error 0.0233(0.0155) Steps 940(935.94) | Grad Norm 3.2216(2.2790) | Total Time 14.00(14.00)\n",
      "Iter 9200 | Time 23.5941(23.2410) | Bit/dim 3.5772(3.5918) | Xent 0.0401(0.0514) | Loss 3.5973(3.6175) | Error 0.0100(0.0159) Steps 940(938.72) | Grad Norm 2.6487(2.2551) | Total Time 14.00(14.00)\n",
      "Iter 9210 | Time 23.1268(23.3125) | Bit/dim 3.6248(3.5941) | Xent 0.0594(0.0518) | Loss 3.6545(3.6200) | Error 0.0222(0.0162) Steps 970(943.52) | Grad Norm 1.7457(2.1712) | Total Time 14.00(14.00)\n",
      "Iter 9220 | Time 22.9797(23.2595) | Bit/dim 3.6067(3.5981) | Xent 0.0606(0.0514) | Loss 3.6370(3.6237) | Error 0.0167(0.0161) Steps 946(943.34) | Grad Norm 2.2811(2.2333) | Total Time 14.00(14.00)\n",
      "Iter 9230 | Time 23.0906(23.1895) | Bit/dim 3.5825(3.5944) | Xent 0.0512(0.0538) | Loss 3.6082(3.6214) | Error 0.0122(0.0165) Steps 958(940.77) | Grad Norm 3.5300(2.4476) | Total Time 14.00(14.00)\n",
      "Iter 9240 | Time 22.7919(23.1245) | Bit/dim 3.6182(3.5984) | Xent 0.1287(0.0649) | Loss 3.6825(3.6308) | Error 0.0389(0.0198) Steps 958(939.52) | Grad Norm 6.4467(2.9960) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0168 | Time 107.4765, Epoch Time 1402.9720(1347.8400), Bit/dim 3.6294(best: 3.6109), Xent 1.8961, Loss 4.5775, Error 0.3419(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9250 | Time 23.3771(23.0982) | Bit/dim 3.5802(3.6008) | Xent 0.0499(0.0634) | Loss 3.6051(3.6325) | Error 0.0167(0.0192) Steps 964(938.38) | Grad Norm 1.9121(2.9777) | Total Time 14.00(14.00)\n",
      "Iter 9260 | Time 23.1754(23.0881) | Bit/dim 3.5747(3.6000) | Xent 0.0685(0.0612) | Loss 3.6090(3.6307) | Error 0.0244(0.0188) Steps 946(934.41) | Grad Norm 2.7151(2.8373) | Total Time 14.00(14.00)\n",
      "Iter 9270 | Time 22.9754(23.1169) | Bit/dim 3.5986(3.5981) | Xent 0.0560(0.0604) | Loss 3.6266(3.6283) | Error 0.0189(0.0184) Steps 934(936.57) | Grad Norm 2.0120(2.7310) | Total Time 14.00(14.00)\n",
      "Iter 9280 | Time 22.5359(23.1089) | Bit/dim 3.6064(3.5997) | Xent 0.1403(0.0643) | Loss 3.6765(3.6318) | Error 0.0411(0.0199) Steps 922(937.46) | Grad Norm 5.6282(2.7787) | Total Time 14.00(14.00)\n",
      "Iter 9290 | Time 23.4729(23.1656) | Bit/dim 3.6457(3.6020) | Xent 0.1071(0.0687) | Loss 3.6993(3.6364) | Error 0.0322(0.0215) Steps 928(937.62) | Grad Norm 3.5405(3.0158) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0169 | Time 107.3352, Epoch Time 1398.6641(1349.3647), Bit/dim 3.6230(best: 3.6109), Xent 1.8808, Loss 4.5634, Error 0.3570(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9300 | Time 23.0751(23.1707) | Bit/dim 3.5887(3.5998) | Xent 0.1306(0.0748) | Loss 3.6540(3.6372) | Error 0.0367(0.0233) Steps 946(937.25) | Grad Norm 3.1927(3.1484) | Total Time 14.00(14.00)\n",
      "Iter 9310 | Time 23.2832(23.1629) | Bit/dim 3.6262(3.6022) | Xent 0.0648(0.0738) | Loss 3.6586(3.6391) | Error 0.0211(0.0230) Steps 946(938.05) | Grad Norm 2.9609(3.1018) | Total Time 14.00(14.00)\n",
      "Iter 9320 | Time 23.7166(23.2371) | Bit/dim 3.5787(3.6024) | Xent 0.0296(0.0678) | Loss 3.5935(3.6363) | Error 0.0100(0.0212) Steps 970(940.48) | Grad Norm 1.7142(2.8867) | Total Time 14.00(14.00)\n",
      "Iter 9330 | Time 22.8863(23.2571) | Bit/dim 3.6062(3.6016) | Xent 0.0539(0.0638) | Loss 3.6332(3.6335) | Error 0.0122(0.0196) Steps 946(938.20) | Grad Norm 1.7412(2.7178) | Total Time 14.00(14.00)\n",
      "Iter 9340 | Time 23.2979(23.1907) | Bit/dim 3.5785(3.5966) | Xent 0.0486(0.0618) | Loss 3.6028(3.6275) | Error 0.0189(0.0194) Steps 946(935.72) | Grad Norm 1.9967(2.5596) | Total Time 14.00(14.00)\n",
      "Iter 9350 | Time 23.1591(23.1979) | Bit/dim 3.6230(3.5977) | Xent 0.0444(0.0603) | Loss 3.6452(3.6279) | Error 0.0144(0.0187) Steps 946(935.12) | Grad Norm 3.4019(2.4999) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0170 | Time 107.0608, Epoch Time 1402.5044(1350.9589), Bit/dim 3.6147(best: 3.6109), Xent 1.9550, Loss 4.5922, Error 0.3464(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9360 | Time 22.9355(23.1857) | Bit/dim 3.5879(3.5978) | Xent 0.0399(0.0595) | Loss 3.6079(3.6275) | Error 0.0100(0.0182) Steps 934(934.57) | Grad Norm 2.2606(2.4897) | Total Time 14.00(14.00)\n",
      "Iter 9370 | Time 22.9842(23.1898) | Bit/dim 3.5831(3.5935) | Xent 0.0624(0.0560) | Loss 3.6143(3.6215) | Error 0.0244(0.0174) Steps 928(935.51) | Grad Norm 2.2623(2.4020) | Total Time 14.00(14.00)\n",
      "Iter 9380 | Time 22.2224(23.1280) | Bit/dim 3.6190(3.5956) | Xent 0.0375(0.0529) | Loss 3.6377(3.6221) | Error 0.0144(0.0167) Steps 940(935.15) | Grad Norm 1.4828(2.3743) | Total Time 14.00(14.00)\n",
      "Iter 9390 | Time 22.8278(23.0842) | Bit/dim 3.5893(3.5939) | Xent 0.0329(0.0506) | Loss 3.6058(3.6192) | Error 0.0100(0.0156) Steps 934(933.76) | Grad Norm 1.2281(2.1893) | Total Time 14.00(14.00)\n",
      "Iter 9400 | Time 23.4502(23.1179) | Bit/dim 3.6102(3.5925) | Xent 0.0609(0.0500) | Loss 3.6406(3.6175) | Error 0.0156(0.0154) Steps 934(933.05) | Grad Norm 2.0822(2.0942) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0171 | Time 108.8708, Epoch Time 1396.1306(1352.3141), Bit/dim 3.6073(best: 3.6109), Xent 1.9920, Loss 4.6032, Error 0.3384(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9410 | Time 22.6478(23.0822) | Bit/dim 3.6018(3.5895) | Xent 0.0923(0.0511) | Loss 3.6479(3.6151) | Error 0.0267(0.0158) Steps 940(934.52) | Grad Norm 4.2408(2.1617) | Total Time 14.00(14.00)\n",
      "Iter 9420 | Time 23.3182(23.1610) | Bit/dim 3.5682(3.5884) | Xent 0.0517(0.0525) | Loss 3.5940(3.6146) | Error 0.0144(0.0161) Steps 940(938.90) | Grad Norm 2.1116(2.2418) | Total Time 14.00(14.00)\n",
      "Iter 9430 | Time 23.2442(23.2030) | Bit/dim 3.6150(3.5890) | Xent 0.0456(0.0544) | Loss 3.6378(3.6163) | Error 0.0178(0.0167) Steps 916(938.29) | Grad Norm 1.6103(2.2505) | Total Time 14.00(14.00)\n",
      "Iter 9440 | Time 23.4990(23.1569) | Bit/dim 3.6308(3.5890) | Xent 0.0624(0.0529) | Loss 3.6620(3.6154) | Error 0.0211(0.0168) Steps 934(935.65) | Grad Norm 1.8030(2.1940) | Total Time 14.00(14.00)\n",
      "Iter 9450 | Time 22.6653(23.1799) | Bit/dim 3.6128(3.5905) | Xent 0.0255(0.0531) | Loss 3.6256(3.6170) | Error 0.0056(0.0165) Steps 922(935.98) | Grad Norm 1.7430(2.1713) | Total Time 14.00(14.00)\n",
      "Iter 9460 | Time 22.4962(23.0483) | Bit/dim 3.6000(3.5931) | Xent 0.0637(0.0540) | Loss 3.6318(3.6201) | Error 0.0178(0.0167) Steps 928(935.93) | Grad Norm 2.6552(2.1938) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0172 | Time 110.2225, Epoch Time 1400.4408(1353.7579), Bit/dim 3.6114(best: 3.6073), Xent 1.9941, Loss 4.6084, Error 0.3456(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9470 | Time 23.6577(23.1428) | Bit/dim 3.5922(3.5915) | Xent 0.0410(0.0540) | Loss 3.6127(3.6185) | Error 0.0111(0.0163) Steps 922(935.68) | Grad Norm 1.5132(2.3011) | Total Time 14.00(14.00)\n",
      "Iter 9480 | Time 23.1326(23.1974) | Bit/dim 3.6104(3.5909) | Xent 0.0504(0.0531) | Loss 3.6356(3.6174) | Error 0.0189(0.0165) Steps 946(937.78) | Grad Norm 2.5234(2.3393) | Total Time 14.00(14.00)\n",
      "Iter 9490 | Time 23.1671(23.2133) | Bit/dim 3.6055(3.5938) | Xent 0.0490(0.0514) | Loss 3.6301(3.6195) | Error 0.0122(0.0158) Steps 940(939.00) | Grad Norm 2.6289(2.3872) | Total Time 14.00(14.00)\n",
      "Iter 9500 | Time 23.2686(23.1857) | Bit/dim 3.6045(3.5927) | Xent 0.0606(0.0518) | Loss 3.6348(3.6186) | Error 0.0156(0.0159) Steps 916(936.44) | Grad Norm 1.6845(2.3126) | Total Time 14.00(14.00)\n",
      "Iter 9510 | Time 23.5177(23.1940) | Bit/dim 3.5910(3.5919) | Xent 0.0545(0.0533) | Loss 3.6183(3.6185) | Error 0.0122(0.0161) Steps 910(934.53) | Grad Norm 1.5137(2.2524) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0173 | Time 110.5613, Epoch Time 1407.0567(1355.3568), Bit/dim 3.6107(best: 3.6073), Xent 1.9551, Loss 4.5883, Error 0.3459(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9520 | Time 23.5844(23.2126) | Bit/dim 3.5890(3.5935) | Xent 0.0499(0.0524) | Loss 3.6139(3.6197) | Error 0.0144(0.0160) Steps 940(936.30) | Grad Norm 2.0324(2.2306) | Total Time 14.00(14.00)\n",
      "Iter 9530 | Time 23.6205(23.2535) | Bit/dim 3.5697(3.5899) | Xent 0.0266(0.0512) | Loss 3.5830(3.6155) | Error 0.0067(0.0157) Steps 928(938.12) | Grad Norm 1.5763(2.1912) | Total Time 14.00(14.00)\n",
      "Iter 9540 | Time 23.4250(23.2480) | Bit/dim 3.5823(3.5909) | Xent 0.0631(0.0504) | Loss 3.6138(3.6161) | Error 0.0178(0.0158) Steps 964(939.96) | Grad Norm 2.0190(2.1173) | Total Time 14.00(14.00)\n",
      "Iter 9550 | Time 23.1745(23.2848) | Bit/dim 3.6204(3.5882) | Xent 0.0659(0.0519) | Loss 3.6533(3.6142) | Error 0.0211(0.0162) Steps 958(939.66) | Grad Norm 2.3222(2.1829) | Total Time 14.00(14.00)\n",
      "Iter 9560 | Time 23.4713(23.3474) | Bit/dim 3.5662(3.5894) | Xent 0.0352(0.0526) | Loss 3.5838(3.6157) | Error 0.0133(0.0164) Steps 934(942.25) | Grad Norm 1.6156(2.2311) | Total Time 14.00(14.00)\n",
      "Iter 9570 | Time 23.2834(23.3301) | Bit/dim 3.5979(3.5898) | Xent 0.0606(0.0539) | Loss 3.6282(3.6167) | Error 0.0211(0.0167) Steps 934(939.96) | Grad Norm 3.6628(2.3236) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0174 | Time 106.6928, Epoch Time 1409.8188(1356.9907), Bit/dim 3.6104(best: 3.6073), Xent 1.8879, Loss 4.5543, Error 0.3375(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9580 | Time 22.8941(23.3373) | Bit/dim 3.5706(3.5892) | Xent 0.0510(0.0510) | Loss 3.5961(3.6147) | Error 0.0178(0.0161) Steps 922(941.61) | Grad Norm 2.3677(2.2641) | Total Time 14.00(14.00)\n",
      "Iter 9590 | Time 23.4924(23.2512) | Bit/dim 3.5586(3.5874) | Xent 0.0330(0.0479) | Loss 3.5751(3.6113) | Error 0.0100(0.0145) Steps 940(938.46) | Grad Norm 1.5425(2.1001) | Total Time 14.00(14.00)\n",
      "Iter 9600 | Time 23.1050(23.2441) | Bit/dim 3.6055(3.5860) | Xent 0.0768(0.0489) | Loss 3.6439(3.6104) | Error 0.0222(0.0151) Steps 940(937.07) | Grad Norm 2.8711(2.1282) | Total Time 14.00(14.00)\n",
      "Iter 9610 | Time 23.3185(23.2855) | Bit/dim 3.6163(3.5891) | Xent 0.0635(0.0530) | Loss 3.6480(3.6156) | Error 0.0200(0.0165) Steps 964(940.06) | Grad Norm 1.8617(2.2300) | Total Time 14.00(14.00)\n",
      "Iter 9620 | Time 23.5760(23.3014) | Bit/dim 3.5902(3.5886) | Xent 0.0636(0.0533) | Loss 3.6220(3.6152) | Error 0.0144(0.0164) Steps 940(938.42) | Grad Norm 1.8053(2.2344) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0175 | Time 109.9507, Epoch Time 1406.7789(1358.4843), Bit/dim 3.6095(best: 3.6073), Xent 1.9669, Loss 4.5930, Error 0.3412(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9630 | Time 22.3251(23.2146) | Bit/dim 3.5620(3.5870) | Xent 0.0404(0.0537) | Loss 3.5822(3.6139) | Error 0.0133(0.0168) Steps 928(937.65) | Grad Norm 1.9846(2.2288) | Total Time 14.00(14.00)\n",
      "Iter 9640 | Time 23.0597(23.1353) | Bit/dim 3.5774(3.5885) | Xent 0.0765(0.0544) | Loss 3.6157(3.6157) | Error 0.0256(0.0169) Steps 916(936.03) | Grad Norm 3.5116(2.3638) | Total Time 14.00(14.00)\n",
      "Iter 9650 | Time 22.9494(23.0797) | Bit/dim 3.5973(3.5912) | Xent 0.0463(0.0549) | Loss 3.6204(3.6186) | Error 0.0133(0.0173) Steps 952(937.65) | Grad Norm 2.4697(2.3747) | Total Time 14.00(14.00)\n",
      "Iter 9660 | Time 23.5333(23.0511) | Bit/dim 3.6064(3.5900) | Xent 0.0647(0.0528) | Loss 3.6388(3.6164) | Error 0.0200(0.0165) Steps 922(936.49) | Grad Norm 1.5719(2.2619) | Total Time 14.00(14.00)\n",
      "Iter 9670 | Time 22.8960(23.0678) | Bit/dim 3.5888(3.5882) | Xent 0.0249(0.0512) | Loss 3.6013(3.6138) | Error 0.0100(0.0161) Steps 958(937.93) | Grad Norm 2.3127(2.1810) | Total Time 14.00(14.00)\n",
      "Iter 9680 | Time 24.0115(23.1125) | Bit/dim 3.6009(3.5858) | Xent 0.0880(0.0525) | Loss 3.6449(3.6120) | Error 0.0244(0.0164) Steps 946(938.99) | Grad Norm 3.2588(2.2196) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0176 | Time 111.0255, Epoch Time 1395.2762(1359.5881), Bit/dim 3.6091(best: 3.6073), Xent 1.9329, Loss 4.5755, Error 0.3447(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9700 | Time 23.1244(23.3263) | Bit/dim 3.6004(3.5870) | Xent 0.0655(0.0530) | Loss 3.6332(3.6135) | Error 0.0189(0.0163) Steps 910(942.09) | Grad Norm 3.4394(2.3360) | Total Time 14.00(14.00)\n",
      "Iter 9710 | Time 22.8162(23.2213) | Bit/dim 3.5699(3.5881) | Xent 0.1231(0.0624) | Loss 3.6314(3.6192) | Error 0.0333(0.0190) Steps 934(937.31) | Grad Norm 6.2011(2.6703) | Total Time 14.00(14.00)\n",
      "Iter 9720 | Time 22.8956(23.2874) | Bit/dim 3.6147(3.5945) | Xent 0.0751(0.0687) | Loss 3.6523(3.6288) | Error 0.0233(0.0211) Steps 946(941.35) | Grad Norm 2.2389(2.7504) | Total Time 14.00(14.00)\n",
      "Iter 9730 | Time 23.1952(23.3211) | Bit/dim 3.5436(3.5918) | Xent 0.0829(0.0680) | Loss 3.5851(3.6258) | Error 0.0211(0.0209) Steps 958(946.83) | Grad Norm 2.2184(2.6375) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0177 | Time 111.4187, Epoch Time 1416.8131(1361.3048), Bit/dim 3.6178(best: 3.6073), Xent 1.9643, Loss 4.6000, Error 0.3485(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9740 | Time 23.4774(23.3621) | Bit/dim 3.5957(3.5922) | Xent 0.0989(0.0713) | Loss 3.6451(3.6278) | Error 0.0267(0.0215) Steps 952(947.50) | Grad Norm 3.0115(2.7166) | Total Time 14.00(14.00)\n",
      "Iter 9750 | Time 23.8239(23.3371) | Bit/dim 3.5852(3.5961) | Xent 0.1152(0.0748) | Loss 3.6428(3.6335) | Error 0.0356(0.0227) Steps 946(948.96) | Grad Norm 4.8152(2.9631) | Total Time 14.00(14.00)\n",
      "Iter 9760 | Time 23.4197(23.3688) | Bit/dim 3.5892(3.5958) | Xent 0.0930(0.0754) | Loss 3.6357(3.6335) | Error 0.0256(0.0227) Steps 958(952.32) | Grad Norm 2.4816(2.8579) | Total Time 14.00(14.00)\n",
      "Iter 9770 | Time 23.2022(23.3974) | Bit/dim 3.5932(3.5963) | Xent 0.0966(0.0767) | Loss 3.6415(3.6347) | Error 0.0244(0.0235) Steps 952(952.73) | Grad Norm 2.6946(2.8220) | Total Time 14.00(14.00)\n",
      "Iter 9780 | Time 23.8640(23.4246) | Bit/dim 3.5757(3.5964) | Xent 0.0606(0.0760) | Loss 3.6060(3.6344) | Error 0.0156(0.0232) Steps 958(952.98) | Grad Norm 2.0805(2.7150) | Total Time 14.00(14.00)\n",
      "Iter 9790 | Time 23.3389(23.3298) | Bit/dim 3.5955(3.5967) | Xent 0.0937(0.0771) | Loss 3.6424(3.6353) | Error 0.0311(0.0233) Steps 958(953.76) | Grad Norm 5.2292(2.8823) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0178 | Time 108.2378, Epoch Time 1411.6983(1362.8166), Bit/dim 3.6167(best: 3.6073), Xent 1.9132, Loss 4.5733, Error 0.3409(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9800 | Time 23.9483(23.4048) | Bit/dim 3.6309(3.5996) | Xent 0.0783(0.0751) | Loss 3.6701(3.6371) | Error 0.0256(0.0231) Steps 982(954.62) | Grad Norm 2.7117(2.8867) | Total Time 14.00(14.00)\n",
      "Iter 9810 | Time 23.8347(23.4183) | Bit/dim 3.5870(3.6020) | Xent 0.0521(0.0701) | Loss 3.6131(3.6371) | Error 0.0167(0.0214) Steps 946(954.72) | Grad Norm 1.9096(2.7826) | Total Time 14.00(14.00)\n",
      "Iter 9820 | Time 23.3237(23.3855) | Bit/dim 3.5711(3.5982) | Xent 0.0541(0.0680) | Loss 3.5982(3.6322) | Error 0.0189(0.0209) Steps 946(953.45) | Grad Norm 1.8706(2.7222) | Total Time 14.00(14.00)\n",
      "Iter 9830 | Time 23.8297(23.4585) | Bit/dim 3.5721(3.5941) | Xent 0.0536(0.0652) | Loss 3.5989(3.6267) | Error 0.0178(0.0203) Steps 964(954.37) | Grad Norm 2.5341(2.7442) | Total Time 14.00(14.00)\n",
      "Iter 9840 | Time 23.8765(23.5105) | Bit/dim 3.6083(3.5945) | Xent 0.0539(0.0645) | Loss 3.6353(3.6267) | Error 0.0144(0.0201) Steps 952(956.21) | Grad Norm 1.6625(2.7328) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0179 | Time 109.5111, Epoch Time 1425.5471(1364.6986), Bit/dim 3.6084(best: 3.6073), Xent 1.9632, Loss 4.5900, Error 0.3484(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9850 | Time 24.0346(23.6342) | Bit/dim 3.5876(3.5952) | Xent 0.0447(0.0646) | Loss 3.6099(3.6275) | Error 0.0189(0.0203) Steps 946(957.21) | Grad Norm 1.7222(2.6818) | Total Time 14.00(14.00)\n",
      "Iter 9860 | Time 23.7310(23.5865) | Bit/dim 3.5597(3.5911) | Xent 0.0500(0.0599) | Loss 3.5847(3.6210) | Error 0.0189(0.0187) Steps 970(958.15) | Grad Norm 2.0454(2.4540) | Total Time 14.00(14.00)\n",
      "Iter 9870 | Time 23.5499(23.6178) | Bit/dim 3.5972(3.5904) | Xent 0.0546(0.0584) | Loss 3.6245(3.6196) | Error 0.0189(0.0180) Steps 958(956.76) | Grad Norm 1.9666(2.3886) | Total Time 14.00(14.00)\n",
      "Iter 9880 | Time 23.4032(23.5821) | Bit/dim 3.5727(3.5866) | Xent 0.0456(0.0548) | Loss 3.5955(3.6140) | Error 0.0111(0.0167) Steps 940(955.83) | Grad Norm 1.5549(2.2707) | Total Time 14.00(14.00)\n",
      "Iter 9890 | Time 23.2209(23.5370) | Bit/dim 3.5547(3.5872) | Xent 0.0713(0.0528) | Loss 3.5903(3.6136) | Error 0.0211(0.0163) Steps 946(954.06) | Grad Norm 2.9474(2.1782) | Total Time 14.00(14.00)\n",
      "Iter 9900 | Time 23.2718(23.4646) | Bit/dim 3.5744(3.5865) | Xent 0.1151(0.0546) | Loss 3.6320(3.6139) | Error 0.0322(0.0167) Steps 958(951.91) | Grad Norm 3.6585(2.2058) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0180 | Time 109.6181, Epoch Time 1420.2780(1366.3659), Bit/dim 3.6065(best: 3.6073), Xent 1.9605, Loss 4.5868, Error 0.3336(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9910 | Time 23.2335(23.3815) | Bit/dim 3.5892(3.5887) | Xent 0.0390(0.0553) | Loss 3.6087(3.6163) | Error 0.0156(0.0167) Steps 952(949.66) | Grad Norm 2.3042(2.2360) | Total Time 14.00(14.00)\n",
      "Iter 9920 | Time 23.8745(23.4831) | Bit/dim 3.5750(3.5854) | Xent 0.0276(0.0524) | Loss 3.5888(3.6116) | Error 0.0089(0.0159) Steps 952(949.60) | Grad Norm 1.2806(2.1484) | Total Time 14.00(14.00)\n",
      "Iter 9930 | Time 23.6390(23.4533) | Bit/dim 3.6193(3.5855) | Xent 0.0485(0.0530) | Loss 3.6436(3.6120) | Error 0.0144(0.0162) Steps 958(947.61) | Grad Norm 1.8431(2.1790) | Total Time 14.00(14.00)\n",
      "Iter 9940 | Time 22.8049(23.4396) | Bit/dim 3.6009(3.5849) | Xent 0.0597(0.0549) | Loss 3.6307(3.6123) | Error 0.0144(0.0167) Steps 964(949.12) | Grad Norm 2.0152(2.1943) | Total Time 14.00(14.00)\n",
      "Iter 9950 | Time 22.6960(23.4449) | Bit/dim 3.6023(3.5866) | Xent 0.0649(0.0572) | Loss 3.6348(3.6152) | Error 0.0144(0.0172) Steps 946(948.64) | Grad Norm 1.9103(2.1794) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Iter 9960 | Time 23.1658(23.4197) | Bit/dim 3.5657(3.5857) | Xent 0.0555(0.0544) | Loss 3.5934(3.6129) | Error 0.0189(0.0168) Steps 946(947.76) | Grad Norm 2.0751(2.1405) | Total Time 14.00(14.00)\n",
      "Iter 9970 | Time 22.9485(23.2758) | Bit/dim 3.5826(3.5862) | Xent 0.0563(0.0515) | Loss 3.6108(3.6119) | Error 0.0200(0.0158) Steps 946(945.20) | Grad Norm 2.4189(2.1897) | Total Time 14.00(14.00)\n",
      "Iter 9980 | Time 23.1042(23.1994) | Bit/dim 3.6160(3.5859) | Xent 0.0465(0.0521) | Loss 3.6392(3.6120) | Error 0.0144(0.0158) Steps 916(942.48) | Grad Norm 1.7878(2.2124) | Total Time 14.00(14.00)\n",
      "Iter 9990 | Time 22.8583(23.1355) | Bit/dim 3.5723(3.5830) | Xent 0.0903(0.0527) | Loss 3.6174(3.6093) | Error 0.0267(0.0158) Steps 940(940.37) | Grad Norm 3.2549(2.2276) | Total Time 14.00(14.00)\n",
      "Iter 10000 | Time 23.2782(23.1216) | Bit/dim 3.6138(3.5848) | Xent 0.0712(0.0556) | Loss 3.6494(3.6126) | Error 0.0178(0.0165) Steps 934(937.61) | Grad Norm 2.2396(2.2296) | Total Time 14.00(14.00)\n",
      "Iter 10010 | Time 23.1769(23.1177) | Bit/dim 3.5504(3.5854) | Xent 0.0461(0.0573) | Loss 3.5735(3.6140) | Error 0.0200(0.0179) Steps 934(940.87) | Grad Norm 1.5685(2.2483) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0182 | Time 109.5121, Epoch Time 1393.0080(1368.6271), Bit/dim 3.6083(best: 3.6056), Xent 2.1186, Loss 4.6676, Error 0.3649(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10020 | Time 23.4860(23.2305) | Bit/dim 3.5852(3.5884) | Xent 0.0308(0.0616) | Loss 3.6006(3.6192) | Error 0.0089(0.0194) Steps 934(944.60) | Grad Norm 1.3771(2.4346) | Total Time 14.00(14.00)\n",
      "Iter 10030 | Time 23.7720(23.3829) | Bit/dim 3.6208(3.5883) | Xent 0.0587(0.0624) | Loss 3.6501(3.6195) | Error 0.0244(0.0198) Steps 976(948.05) | Grad Norm 2.5291(2.3609) | Total Time 14.00(14.00)\n",
      "Iter 10040 | Time 23.4492(23.4574) | Bit/dim 3.5968(3.5886) | Xent 0.0562(0.0588) | Loss 3.6249(3.6180) | Error 0.0178(0.0192) Steps 946(950.92) | Grad Norm 2.1801(2.3116) | Total Time 14.00(14.00)\n",
      "Iter 10050 | Time 24.0227(23.5093) | Bit/dim 3.5628(3.5863) | Xent 0.0615(0.0566) | Loss 3.5936(3.6146) | Error 0.0189(0.0180) Steps 958(949.84) | Grad Norm 2.3242(2.2576) | Total Time 14.00(14.00)\n",
      "Iter 10060 | Time 23.1810(23.4167) | Bit/dim 3.5875(3.5845) | Xent 0.0229(0.0530) | Loss 3.5990(3.6110) | Error 0.0067(0.0169) Steps 934(948.89) | Grad Norm 1.2603(2.1628) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0183 | Time 112.3459, Epoch Time 1427.9974(1370.4082), Bit/dim 3.5976(best: 3.6056), Xent 2.0323, Loss 4.6137, Error 0.3468(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10070 | Time 23.9025(23.5219) | Bit/dim 3.5986(3.5840) | Xent 0.0560(0.0509) | Loss 3.6266(3.6094) | Error 0.0178(0.0162) Steps 952(952.58) | Grad Norm 2.0977(2.0406) | Total Time 14.00(14.00)\n",
      "Iter 10080 | Time 22.5435(23.4554) | Bit/dim 3.5835(3.5855) | Xent 0.0792(0.0511) | Loss 3.6231(3.6110) | Error 0.0178(0.0160) Steps 946(955.35) | Grad Norm 2.0775(1.9574) | Total Time 14.00(14.00)\n",
      "Iter 10090 | Time 23.5401(23.4137) | Bit/dim 3.5740(3.5848) | Xent 0.0641(0.0527) | Loss 3.6060(3.6111) | Error 0.0200(0.0165) Steps 964(954.55) | Grad Norm 1.8024(2.0148) | Total Time 14.00(14.00)\n",
      "Iter 10100 | Time 23.3551(23.4566) | Bit/dim 3.5727(3.5842) | Xent 0.0424(0.0512) | Loss 3.5939(3.6098) | Error 0.0089(0.0160) Steps 952(954.56) | Grad Norm 2.1944(2.0167) | Total Time 14.00(14.00)\n",
      "Iter 10110 | Time 23.0863(23.4241) | Bit/dim 3.5962(3.5848) | Xent 0.0308(0.0552) | Loss 3.6116(3.6124) | Error 0.0089(0.0176) Steps 964(953.98) | Grad Norm 2.2670(2.2241) | Total Time 14.00(14.00)\n",
      "Iter 10120 | Time 23.2931(23.4712) | Bit/dim 3.5972(3.5847) | Xent 0.0847(0.0583) | Loss 3.6396(3.6138) | Error 0.0289(0.0181) Steps 952(955.30) | Grad Norm 2.2791(2.2660) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0184 | Time 112.5029, Epoch Time 1420.6743(1371.9162), Bit/dim 3.6087(best: 3.5976), Xent 1.8720, Loss 4.5447, Error 0.3400(best: 0.3325)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10130 | Time 23.3592(23.5587) | Bit/dim 3.5765(3.5836) | Xent 0.0401(0.0542) | Loss 3.5965(3.6108) | Error 0.0144(0.0168) Steps 964(956.10) | Grad Norm 2.2665(2.1688) | Total Time 14.00(14.00)\n",
      "Iter 10140 | Time 23.2278(23.5653) | Bit/dim 3.5630(3.5834) | Xent 0.0443(0.0524) | Loss 3.5852(3.6096) | Error 0.0144(0.0164) Steps 958(955.08) | Grad Norm 2.0534(2.1505) | Total Time 14.00(14.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_drop_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_cifar10_bs900_drop_0_5_run1 --resume ../experiments_published/cnf_conditional_cifar10_bs900_drop_0_5_run1/current_checkpt.pth --seed 1 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
