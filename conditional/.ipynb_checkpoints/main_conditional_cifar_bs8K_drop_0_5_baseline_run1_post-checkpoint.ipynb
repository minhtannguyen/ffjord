{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_drop_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z = model.module.dropout(z)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_cifar10_8K_drop_0_5_baseline_run1/epoch_250_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_conditional_cifar10_8K_drop_0_5_baseline_run1', seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=6144, bias=True)\n",
      "  (project_class): LinearZeros(in_features=3072, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1469494\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 1501 | Time 127.5391(78.3046) | Bit/dim 4.0424(4.0337) | Xent 1.1731(0.8495) | Loss 4.6289(4.4584) | Error 0.4106(0.3035) Steps 820(822.61) | Grad Norm 30.9822(7.4288) | Total Time 14.00(14.00)\n",
      "Iter 1502 | Time 77.3683(78.2765) | Bit/dim 4.0245(4.0334) | Xent 1.0255(0.8548) | Loss 4.5373(4.4608) | Error 0.3646(0.3053) Steps 838(823.07) | Grad Norm 23.6008(7.9140) | Total Time 14.00(14.00)\n",
      "Iter 1503 | Time 78.8022(78.2923) | Bit/dim 4.0067(4.0326) | Xent 0.8441(0.8544) | Loss 4.4288(4.4598) | Error 0.3043(0.3053) Steps 808(822.62) | Grad Norm 8.8993(7.9435) | Total Time 14.00(14.00)\n",
      "Iter 1504 | Time 74.0701(78.1656) | Bit/dim 4.0098(4.0319) | Xent 0.7986(0.8528) | Loss 4.4091(4.4583) | Error 0.2890(0.3048) Steps 814(822.36) | Grad Norm 6.0821(7.8877) | Total Time 14.00(14.00)\n",
      "Iter 1505 | Time 76.5556(78.1173) | Bit/dim 4.0120(4.0313) | Xent 0.8454(0.8525) | Loss 4.4347(4.4576) | Error 0.3043(0.3048) Steps 820(822.29) | Grad Norm 12.8670(8.0371) | Total Time 14.00(14.00)\n",
      "Iter 1506 | Time 74.8553(78.0195) | Bit/dim 4.0291(4.0313) | Xent 0.8620(0.8528) | Loss 4.4601(4.4577) | Error 0.3133(0.3050) Steps 814(822.04) | Grad Norm 13.6270(8.2048) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 41.2157, Epoch Time 566.6514(503.7925), Bit/dim 4.0283(best: inf), Xent 1.3144, Loss 4.6855, Error 0.4418(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1507 | Time 84.1211(78.2025) | Bit/dim 4.0235(4.0310) | Xent 0.8570(0.8530) | Loss 4.4520(4.4575) | Error 0.3066(0.3051) Steps 826(822.16) | Grad Norm 12.3092(8.3279) | Total Time 14.00(14.00)\n",
      "Iter 1508 | Time 76.9728(78.1656) | Bit/dim 4.0225(4.0308) | Xent 0.8631(0.8533) | Loss 4.4540(4.4574) | Error 0.3169(0.3054) Steps 832(822.46) | Grad Norm 10.4824(8.3925) | Total Time 14.00(14.00)\n",
      "Iter 1509 | Time 74.8913(78.0674) | Bit/dim 4.0215(4.0305) | Xent 0.8164(0.8522) | Loss 4.4297(4.4566) | Error 0.2950(0.3051) Steps 814(822.20) | Grad Norm 7.8267(8.3756) | Total Time 14.00(14.00)\n",
      "Iter 1510 | Time 75.2105(77.9817) | Bit/dim 4.0157(4.0301) | Xent 0.8248(0.8513) | Loss 4.4281(4.4557) | Error 0.2965(0.3048) Steps 820(822.14) | Grad Norm 5.2380(8.2814) | Total Time 14.00(14.00)\n",
      "Iter 1511 | Time 75.5355(77.9083) | Bit/dim 4.0035(4.0293) | Xent 0.7952(0.8496) | Loss 4.4011(4.4541) | Error 0.2887(0.3044) Steps 826(822.25) | Grad Norm 4.1527(8.1576) | Total Time 14.00(14.00)\n",
      "Iter 1512 | Time 79.2767(77.9494) | Bit/dim 4.0067(4.0286) | Xent 0.7756(0.8474) | Loss 4.3945(4.4523) | Error 0.2785(0.3036) Steps 826(822.37) | Grad Norm 5.0117(8.0632) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 29.6691, Epoch Time 511.5409(504.0250), Bit/dim 4.0139(best: 4.0283), Xent 1.2517, Loss 4.6398, Error 0.4204(best: 0.4418)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1513 | Time 76.1889(77.8965) | Bit/dim 4.0043(4.0279) | Xent 0.7595(0.8448) | Loss 4.3841(4.4502) | Error 0.2755(0.3027) Steps 826(822.48) | Grad Norm 6.6607(8.0211) | Total Time 14.00(14.00)\n",
      "Iter 1514 | Time 75.7697(77.8327) | Bit/dim 4.0036(4.0271) | Xent 0.7785(0.8428) | Loss 4.3929(4.4485) | Error 0.2789(0.3020) Steps 826(822.58) | Grad Norm 6.8431(7.9858) | Total Time 14.00(14.00)\n",
      "Iter 1515 | Time 78.5052(77.8529) | Bit/dim 4.0185(4.0269) | Xent 0.7570(0.8402) | Loss 4.3970(4.4470) | Error 0.2731(0.3012) Steps 832(822.86) | Grad Norm 5.8761(7.9225) | Total Time 14.00(14.00)\n",
      "Iter 1516 | Time 79.2735(77.8955) | Bit/dim 4.0079(4.0263) | Xent 0.7706(0.8381) | Loss 4.3932(4.4454) | Error 0.2782(0.3005) Steps 814(822.60) | Grad Norm 5.0670(7.8368) | Total Time 14.00(14.00)\n",
      "Iter 1517 | Time 76.5466(77.8551) | Bit/dim 4.0167(4.0260) | Xent 0.7506(0.8355) | Loss 4.3920(4.4438) | Error 0.2721(0.2996) Steps 832(822.88) | Grad Norm 4.1551(7.7264) | Total Time 14.00(14.00)\n",
      "Iter 1518 | Time 76.9104(77.8267) | Bit/dim 4.0247(4.0260) | Xent 0.7234(0.8321) | Loss 4.3865(4.4420) | Error 0.2536(0.2982) Steps 826(822.97) | Grad Norm 3.0488(7.5860) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 29.7815, Epoch Time 508.6339(504.1633), Bit/dim 4.0151(best: 4.0139), Xent 1.2806, Loss 4.6554, Error 0.4147(best: 0.4204)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1519 | Time 74.3210(77.7215) | Bit/dim 4.0182(4.0257) | Xent 0.7278(0.8290) | Loss 4.3821(4.4402) | Error 0.2608(0.2971) Steps 832(823.24) | Grad Norm 2.6318(7.4374) | Total Time 14.00(14.00)\n",
      "Iter 1520 | Time 80.0485(77.7914) | Bit/dim 3.9920(4.0247) | Xent 0.7336(0.8262) | Loss 4.3588(4.4378) | Error 0.2611(0.2960) Steps 832(823.51) | Grad Norm 3.2260(7.3111) | Total Time 14.00(14.00)\n",
      "Iter 1521 | Time 76.8753(77.7639) | Bit/dim 4.0014(4.0240) | Xent 0.7178(0.8229) | Loss 4.3603(4.4355) | Error 0.2544(0.2948) Steps 838(823.94) | Grad Norm 3.9879(7.2114) | Total Time 14.00(14.00)\n",
      "Iter 1522 | Time 79.8312(77.8259) | Bit/dim 4.0171(4.0238) | Xent 0.7224(0.8199) | Loss 4.3783(4.4338) | Error 0.2605(0.2938) Steps 826(824.00) | Grad Norm 3.9478(7.1135) | Total Time 14.00(14.00)\n",
      "Iter 1523 | Time 75.3912(77.7528) | Bit/dim 4.0094(4.0234) | Xent 0.7401(0.8175) | Loss 4.3795(4.4321) | Error 0.2620(0.2928) Steps 832(824.24) | Grad Norm 3.1986(6.9960) | Total Time 14.00(14.00)\n",
      "Iter 1524 | Time 73.0797(77.6127) | Bit/dim 4.0185(4.0232) | Xent 0.7383(0.8151) | Loss 4.3877(4.4308) | Error 0.2652(0.2920) Steps 814(823.94) | Grad Norm 2.9064(6.8733) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 29.2887, Epoch Time 504.5529(504.1749), Bit/dim 4.0108(best: 4.0139), Xent 1.2690, Loss 4.6454, Error 0.4180(best: 0.4147)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1525 | Time 77.1245(77.5980) | Bit/dim 4.0007(4.0226) | Xent 0.7109(0.8120) | Loss 4.3562(4.4286) | Error 0.2608(0.2910) Steps 820(823.82) | Grad Norm 2.4608(6.7410) | Total Time 14.00(14.00)\n",
      "Iter 1526 | Time 74.1323(77.4940) | Bit/dim 4.0140(4.0223) | Xent 0.7293(0.8095) | Loss 4.3787(4.4271) | Error 0.2606(0.2901) Steps 826(823.88) | Grad Norm 2.3840(6.6103) | Total Time 14.00(14.00)\n",
      "Iter 1527 | Time 76.9434(77.4775) | Bit/dim 4.0126(4.0220) | Xent 0.7133(0.8066) | Loss 4.3692(4.4253) | Error 0.2600(0.2892) Steps 832(824.13) | Grad Norm 2.1993(6.4779) | Total Time 14.00(14.00)\n",
      "Iter 1528 | Time 78.7131(77.5146) | Bit/dim 4.0112(4.0217) | Xent 0.7244(0.8042) | Loss 4.3734(4.4238) | Error 0.2602(0.2884) Steps 826(824.18) | Grad Norm 2.1457(6.3480) | Total Time 14.00(14.00)\n",
      "Iter 1529 | Time 76.4458(77.4825) | Bit/dim 3.9959(4.0209) | Xent 0.7059(0.8012) | Loss 4.3488(4.4215) | Error 0.2480(0.2871) Steps 832(824.42) | Grad Norm 2.6589(6.2373) | Total Time 14.00(14.00)\n",
      "Iter 1530 | Time 77.8122(77.4924) | Bit/dim 3.9998(4.0203) | Xent 0.7178(0.7987) | Loss 4.3587(4.4196) | Error 0.2604(0.2863) Steps 826(824.47) | Grad Norm 2.8545(6.1358) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 29.5687, Epoch Time 506.3997(504.2417), Bit/dim 4.0111(best: 4.0108), Xent 1.2647, Loss 4.6435, Error 0.4123(best: 0.4147)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1531 | Time 74.8187(77.4122) | Bit/dim 4.0167(4.0202) | Xent 0.6941(0.7956) | Loss 4.3638(4.4180) | Error 0.2511(0.2853) Steps 820(824.33) | Grad Norm 1.9606(6.0105) | Total Time 14.00(14.00)\n",
      "Iter 1532 | Time 76.8829(77.3963) | Bit/dim 4.0178(4.0201) | Xent 0.6932(0.7925) | Loss 4.3644(4.4164) | Error 0.2452(0.2841) Steps 814(824.02) | Grad Norm 1.8892(5.8869) | Total Time 14.00(14.00)\n",
      "Iter 1533 | Time 75.2090(77.3307) | Bit/dim 4.0065(4.0197) | Xent 0.6951(0.7896) | Loss 4.3541(4.4145) | Error 0.2510(0.2831) Steps 826(824.08) | Grad Norm 1.4445(5.7536) | Total Time 14.00(14.00)\n",
      "Iter 1534 | Time 76.8105(77.3151) | Bit/dim 4.0009(4.0191) | Xent 0.6854(0.7865) | Loss 4.3436(4.4124) | Error 0.2435(0.2819) Steps 820(823.96) | Grad Norm 1.8272(5.6358) | Total Time 14.00(14.00)\n",
      "Iter 1535 | Time 74.5297(77.2315) | Bit/dim 3.9990(4.0185) | Xent 0.7182(0.7844) | Loss 4.3581(4.4107) | Error 0.2588(0.2812) Steps 814(823.66) | Grad Norm 1.7916(5.5205) | Total Time 14.00(14.00)\n",
      "Iter 1536 | Time 75.9973(77.1945) | Bit/dim 3.9973(4.0179) | Xent 0.6934(0.7817) | Loss 4.3440(4.4087) | Error 0.2508(0.2803) Steps 814(823.37) | Grad Norm 2.1019(5.4180) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 29.4057, Epoch Time 499.2488(504.0919), Bit/dim 4.0104(best: 4.0108), Xent 1.2689, Loss 4.6448, Error 0.4102(best: 0.4123)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1537 | Time 78.3455(77.2290) | Bit/dim 4.0155(4.0178) | Xent 0.7008(0.7793) | Loss 4.3659(4.4074) | Error 0.2506(0.2794) Steps 814(823.09) | Grad Norm 2.1288(5.3193) | Total Time 14.00(14.00)\n",
      "Iter 1538 | Time 75.6575(77.1819) | Bit/dim 4.0053(4.0174) | Xent 0.6733(0.7761) | Loss 4.3420(4.4055) | Error 0.2415(0.2783) Steps 820(823.00) | Grad Norm 2.1000(5.2227) | Total Time 14.00(14.00)\n",
      "Iter 1539 | Time 76.4045(77.1586) | Bit/dim 4.0069(4.0171) | Xent 0.6879(0.7734) | Loss 4.3508(4.4038) | Error 0.2489(0.2774) Steps 820(822.91) | Grad Norm 1.8202(5.1206) | Total Time 14.00(14.00)\n",
      "Iter 1540 | Time 74.6244(77.0825) | Bit/dim 4.0046(4.0167) | Xent 0.6942(0.7711) | Loss 4.3517(4.4023) | Error 0.2548(0.2767) Steps 814(822.64) | Grad Norm 1.5334(5.0130) | Total Time 14.00(14.00)\n",
      "Iter 1541 | Time 73.7431(76.9824) | Bit/dim 3.9982(4.0162) | Xent 0.6946(0.7688) | Loss 4.3455(4.4006) | Error 0.2466(0.2758) Steps 820(822.56) | Grad Norm 1.4406(4.9058) | Total Time 14.00(14.00)\n",
      "Iter 1542 | Time 72.8817(76.8593) | Bit/dim 4.0073(4.0159) | Xent 0.6834(0.7662) | Loss 4.3490(4.3990) | Error 0.2445(0.2749) Steps 826(822.66) | Grad Norm 1.1267(4.7925) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 29.5728, Epoch Time 496.9667(503.8781), Bit/dim 4.0101(best: 4.0104), Xent 1.2806, Loss 4.6504, Error 0.4106(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1543 | Time 73.5122(76.7589) | Bit/dim 4.0071(4.0157) | Xent 0.6873(0.7638) | Loss 4.3508(4.3976) | Error 0.2418(0.2739) Steps 814(822.40) | Grad Norm 1.3952(4.6906) | Total Time 14.00(14.00)\n",
      "Iter 1544 | Time 76.4826(76.7506) | Bit/dim 4.0022(4.0153) | Xent 0.6691(0.7610) | Loss 4.3368(4.3958) | Error 0.2350(0.2727) Steps 814(822.15) | Grad Norm 1.4803(4.5942) | Total Time 14.00(14.00)\n",
      "Iter 1545 | Time 72.0021(76.6082) | Bit/dim 4.0038(4.0149) | Xent 0.6819(0.7586) | Loss 4.3447(4.3942) | Error 0.2379(0.2717) Steps 826(822.27) | Grad Norm 1.6765(4.5067) | Total Time 14.00(14.00)\n",
      "Iter 1546 | Time 74.6976(76.5509) | Bit/dim 4.0077(4.0147) | Xent 0.6823(0.7563) | Loss 4.3489(4.3929) | Error 0.2470(0.2709) Steps 814(822.02) | Grad Norm 2.1764(4.4368) | Total Time 14.00(14.00)\n",
      "Iter 1547 | Time 72.3490(76.4248) | Bit/dim 4.0062(4.0144) | Xent 0.7035(0.7547) | Loss 4.3580(4.3918) | Error 0.2564(0.2705) Steps 820(821.96) | Grad Norm 1.4798(4.3481) | Total Time 14.00(14.00)\n",
      "Iter 1548 | Time 74.6480(76.3715) | Bit/dim 4.0053(4.0142) | Xent 0.6720(0.7523) | Loss 4.3413(4.3903) | Error 0.2408(0.2696) Steps 820(821.90) | Grad Norm 0.8338(4.2427) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 29.6577, Epoch Time 489.0881(503.4344), Bit/dim 4.0088(best: 4.0101), Xent 1.2750, Loss 4.6463, Error 0.4113(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1549 | Time 78.2409(76.4276) | Bit/dim 3.9982(4.0137) | Xent 0.6766(0.7500) | Loss 4.3365(4.3887) | Error 0.2434(0.2688) Steps 820(821.84) | Grad Norm 1.2055(4.1515) | Total Time 14.00(14.00)\n",
      "Iter 1550 | Time 74.2049(76.3609) | Bit/dim 4.0037(4.0134) | Xent 0.6928(0.7483) | Loss 4.3501(4.3875) | Error 0.2478(0.2682) Steps 820(821.79) | Grad Norm 1.6962(4.0779) | Total Time 14.00(14.00)\n",
      "Iter 1551 | Time 72.5030(76.2452) | Bit/dim 4.0054(4.0132) | Xent 0.6719(0.7460) | Loss 4.3414(4.3861) | Error 0.2394(0.2673) Steps 814(821.55) | Grad Norm 1.4806(4.0000) | Total Time 14.00(14.00)\n",
      "Iter 1552 | Time 73.2376(76.1549) | Bit/dim 4.0045(4.0129) | Xent 0.6832(0.7441) | Loss 4.3461(4.3849) | Error 0.2466(0.2667) Steps 832(821.87) | Grad Norm 1.5577(3.9267) | Total Time 14.00(14.00)\n",
      "Iter 1553 | Time 77.5291(76.1962) | Bit/dim 4.0050(4.0127) | Xent 0.6956(0.7426) | Loss 4.3528(4.3840) | Error 0.2482(0.2661) Steps 820(821.81) | Grad Norm 1.2255(3.8457) | Total Time 14.00(14.00)\n",
      "Iter 1554 | Time 74.4607(76.1441) | Bit/dim 4.0098(4.0126) | Xent 0.6712(0.7405) | Loss 4.3453(4.3828) | Error 0.2424(0.2654) Steps 814(821.58) | Grad Norm 0.7983(3.7542) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 29.3975, Epoch Time 495.1728(503.1866), Bit/dim 4.0094(best: 4.0088), Xent 1.2892, Loss 4.6540, Error 0.4102(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1555 | Time 74.3511(76.0903) | Bit/dim 4.0050(4.0123) | Xent 0.6840(0.7388) | Loss 4.3470(4.3817) | Error 0.2462(0.2649) Steps 808(821.17) | Grad Norm 1.2917(3.6804) | Total Time 14.00(14.00)\n",
      "Iter 1556 | Time 75.7454(76.0800) | Bit/dim 4.0010(4.0120) | Xent 0.6990(0.7376) | Loss 4.3505(4.3808) | Error 0.2492(0.2644) Steps 820(821.13) | Grad Norm 1.1114(3.6033) | Total Time 14.00(14.00)\n",
      "Iter 1557 | Time 76.6154(76.0960) | Bit/dim 4.0012(4.0117) | Xent 0.6754(0.7357) | Loss 4.3389(4.3796) | Error 0.2434(0.2638) Steps 820(821.10) | Grad Norm 1.3419(3.5355) | Total Time 14.00(14.00)\n",
      "Iter 1558 | Time 76.6204(76.1118) | Bit/dim 4.0082(4.0116) | Xent 0.6619(0.7335) | Loss 4.3392(4.3783) | Error 0.2410(0.2631) Steps 808(820.71) | Grad Norm 1.1023(3.4625) | Total Time 14.00(14.00)\n",
      "Iter 1559 | Time 75.4900(76.0931) | Bit/dim 4.0090(4.0115) | Xent 0.6747(0.7318) | Loss 4.3463(4.3774) | Error 0.2415(0.2624) Steps 820(820.69) | Grad Norm 0.9700(3.3877) | Total Time 14.00(14.00)\n",
      "Iter 1560 | Time 77.0236(76.1210) | Bit/dim 3.9944(4.0110) | Xent 0.6864(0.7304) | Loss 4.3376(4.3762) | Error 0.2451(0.2619) Steps 808(820.31) | Grad Norm 0.8388(3.3112) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 29.2789, Epoch Time 500.8806(503.1174), Bit/dim 4.0083(best: 4.0088), Xent 1.2837, Loss 4.6502, Error 0.4110(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1561 | Time 74.0221(76.0581) | Bit/dim 4.0055(4.0108) | Xent 0.6932(0.7293) | Loss 4.3521(4.3755) | Error 0.2530(0.2616) Steps 820(820.30) | Grad Norm 1.2881(3.2505) | Total Time 14.00(14.00)\n",
      "Iter 1562 | Time 74.4446(76.0097) | Bit/dim 4.0046(4.0106) | Xent 0.6966(0.7283) | Loss 4.3529(4.3748) | Error 0.2522(0.2614) Steps 826(820.47) | Grad Norm 0.9331(3.1810) | Total Time 14.00(14.00)\n",
      "Iter 1563 | Time 73.5010(75.9344) | Bit/dim 4.0055(4.0105) | Xent 0.6720(0.7266) | Loss 4.3415(4.3738) | Error 0.2444(0.2608) Steps 820(820.45) | Grad Norm 0.7798(3.1090) | Total Time 14.00(14.00)\n",
      "Iter 1564 | Time 73.3931(75.8582) | Bit/dim 4.0092(4.0104) | Xent 0.6672(0.7248) | Loss 4.3427(4.3729) | Error 0.2405(0.2602) Steps 814(820.26) | Grad Norm 1.1216(3.0493) | Total Time 14.00(14.00)\n",
      "Iter 1565 | Time 72.5611(75.7592) | Bit/dim 3.9943(4.0100) | Xent 0.6886(0.7237) | Loss 4.3386(4.3718) | Error 0.2480(0.2599) Steps 814(820.07) | Grad Norm 0.8251(2.9826) | Total Time 14.00(14.00)\n",
      "Iter 1566 | Time 75.7968(75.7604) | Bit/dim 4.0026(4.0097) | Xent 0.6587(0.7218) | Loss 4.3320(4.3706) | Error 0.2359(0.2591) Steps 814(819.89) | Grad Norm 1.1172(2.9267) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 29.3590, Epoch Time 488.5856(502.6815), Bit/dim 4.0081(best: 4.0083), Xent 1.2876, Loss 4.6519, Error 0.4140(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1567 | Time 75.8529(75.7631) | Bit/dim 4.0045(4.0096) | Xent 0.6755(0.7204) | Loss 4.3423(4.3698) | Error 0.2452(0.2587) Steps 814(819.71) | Grad Norm 1.0251(2.8696) | Total Time 14.00(14.00)\n",
      "Iter 1568 | Time 72.2743(75.6585) | Bit/dim 4.0010(4.0093) | Xent 0.6628(0.7187) | Loss 4.3325(4.3687) | Error 0.2434(0.2583) Steps 826(819.90) | Grad Norm 0.6974(2.8044) | Total Time 14.00(14.00)\n",
      "Iter 1569 | Time 75.0174(75.6392) | Bit/dim 4.0139(4.0095) | Xent 0.6670(0.7171) | Loss 4.3474(4.3680) | Error 0.2399(0.2577) Steps 820(819.90) | Grad Norm 1.1510(2.7548) | Total Time 14.00(14.00)\n",
      "Iter 1570 | Time 76.8778(75.6764) | Bit/dim 3.9948(4.0090) | Xent 0.6781(0.7160) | Loss 4.3339(4.3670) | Error 0.2472(0.2574) Steps 820(819.91) | Grad Norm 0.8796(2.6986) | Total Time 14.00(14.00)\n",
      "Iter 1571 | Time 73.9010(75.6231) | Bit/dim 4.0112(4.0091) | Xent 0.6803(0.7149) | Loss 4.3514(4.3665) | Error 0.2475(0.2571) Steps 826(820.09) | Grad Norm 0.9489(2.6461) | Total Time 14.00(14.00)\n",
      "Iter 1572 | Time 74.8490(75.5999) | Bit/dim 3.9886(4.0085) | Xent 0.6665(0.7134) | Loss 4.3219(4.3652) | Error 0.2386(0.2566) Steps 814(819.91) | Grad Norm 0.7818(2.5902) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 29.1736, Epoch Time 493.7798(502.4144), Bit/dim 4.0083(best: 4.0081), Xent 1.3018, Loss 4.6592, Error 0.4119(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1573 | Time 73.6270(75.5407) | Bit/dim 4.0014(4.0083) | Xent 0.6682(0.7121) | Loss 4.3355(4.3643) | Error 0.2392(0.2560) Steps 820(819.91) | Grad Norm 0.8864(2.5390) | Total Time 14.00(14.00)\n",
      "Iter 1574 | Time 72.7147(75.4559) | Bit/dim 4.0139(4.0084) | Xent 0.6616(0.7106) | Loss 4.3447(4.3637) | Error 0.2356(0.2554) Steps 808(819.55) | Grad Norm 1.0452(2.4942) | Total Time 14.00(14.00)\n",
      "Iter 1575 | Time 76.6558(75.4919) | Bit/dim 4.0002(4.0082) | Xent 0.6503(0.7088) | Loss 4.3254(4.3626) | Error 0.2371(0.2549) Steps 820(819.57) | Grad Norm 0.6963(2.4403) | Total Time 14.00(14.00)\n",
      "Iter 1576 | Time 74.6068(75.4654) | Bit/dim 3.9995(4.0079) | Xent 0.6678(0.7075) | Loss 4.3334(4.3617) | Error 0.2401(0.2544) Steps 814(819.40) | Grad Norm 0.7975(2.3910) | Total Time 14.00(14.00)\n",
      "Iter 1577 | Time 77.2654(75.5194) | Bit/dim 4.0050(4.0078) | Xent 0.6681(0.7063) | Loss 4.3391(4.3610) | Error 0.2414(0.2540) Steps 820(819.42) | Grad Norm 0.9069(2.3465) | Total Time 14.00(14.00)\n",
      "Iter 1578 | Time 77.5708(75.5809) | Bit/dim 4.0025(4.0077) | Xent 0.6761(0.7054) | Loss 4.3406(4.3604) | Error 0.2442(0.2537) Steps 820(819.43) | Grad Norm 0.7729(2.2993) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 29.2024, Epoch Time 497.2923(502.2607), Bit/dim 4.0078(best: 4.0081), Xent 1.2970, Loss 4.6563, Error 0.4131(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1579 | Time 75.6596(75.5833) | Bit/dim 4.0124(4.0078) | Xent 0.6484(0.7037) | Loss 4.3366(4.3597) | Error 0.2310(0.2531) Steps 808(819.09) | Grad Norm 1.0340(2.2613) | Total Time 14.00(14.00)\n",
      "Iter 1580 | Time 74.8267(75.5606) | Bit/dim 3.9902(4.0073) | Xent 0.6610(0.7024) | Loss 4.3207(4.3585) | Error 0.2339(0.2525) Steps 814(818.94) | Grad Norm 0.9173(2.2210) | Total Time 14.00(14.00)\n",
      "Iter 1581 | Time 73.7012(75.5048) | Bit/dim 4.0052(4.0072) | Xent 0.6582(0.7011) | Loss 4.3343(4.3578) | Error 0.2368(0.2520) Steps 820(818.97) | Grad Norm 0.7898(2.1781) | Total Time 14.00(14.00)\n",
      "Iter 1582 | Time 76.3072(75.5289) | Bit/dim 4.0052(4.0072) | Xent 0.6839(0.7006) | Loss 4.3472(4.3575) | Error 0.2478(0.2519) Steps 814(818.82) | Grad Norm 1.2159(2.1492) | Total Time 14.00(14.00)\n",
      "Iter 1583 | Time 76.0966(75.5459) | Bit/dim 4.0091(4.0072) | Xent 0.6677(0.6996) | Loss 4.3429(4.3570) | Error 0.2389(0.2515) Steps 814(818.68) | Grad Norm 1.0025(2.1148) | Total Time 14.00(14.00)\n",
      "Iter 1584 | Time 76.3515(75.5701) | Bit/dim 3.9921(4.0068) | Xent 0.6739(0.6988) | Loss 4.3290(4.3562) | Error 0.2400(0.2512) Steps 814(818.54) | Grad Norm 0.8690(2.0774) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 29.5189, Epoch Time 497.9837(502.1324), Bit/dim 4.0077(best: 4.0078), Xent 1.2981, Loss 4.6567, Error 0.4137(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1585 | Time 77.6381(75.6321) | Bit/dim 3.9984(4.0065) | Xent 0.6690(0.6979) | Loss 4.3329(4.3555) | Error 0.2408(0.2508) Steps 808(818.22) | Grad Norm 1.0755(2.0474) | Total Time 14.00(14.00)\n",
      "Iter 1586 | Time 77.3581(75.6839) | Bit/dim 3.9993(4.0063) | Xent 0.6668(0.6970) | Loss 4.3327(4.3548) | Error 0.2364(0.2504) Steps 814(818.09) | Grad Norm 0.7112(2.0073) | Total Time 14.00(14.00)\n",
      "Iter 1587 | Time 76.0572(75.6951) | Bit/dim 4.0020(4.0062) | Xent 0.6820(0.6966) | Loss 4.3430(4.3545) | Error 0.2441(0.2502) Steps 814(817.97) | Grad Norm 0.7412(1.9693) | Total Time 14.00(14.00)\n",
      "Iter 1588 | Time 74.3680(75.6553) | Bit/dim 4.0045(4.0061) | Xent 0.6485(0.6951) | Loss 4.3288(4.3537) | Error 0.2355(0.2498) Steps 820(818.03) | Grad Norm 0.7805(1.9336) | Total Time 14.00(14.00)\n",
      "Iter 1589 | Time 75.5257(75.6514) | Bit/dim 4.0124(4.0063) | Xent 0.6594(0.6940) | Loss 4.3421(4.3533) | Error 0.2376(0.2494) Steps 814(817.91) | Grad Norm 0.9269(1.9034) | Total Time 14.00(14.00)\n",
      "Iter 1590 | Time 75.0210(75.6325) | Bit/dim 3.9982(4.0061) | Xent 0.6631(0.6931) | Loss 4.3298(4.3526) | Error 0.2386(0.2491) Steps 814(817.79) | Grad Norm 0.8318(1.8713) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 29.9287, Epoch Time 501.8717(502.1246), Bit/dim 4.0067(best: 4.0077), Xent 1.2912, Loss 4.6523, Error 0.4102(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1591 | Time 74.1828(75.5890) | Bit/dim 4.0050(4.0060) | Xent 0.6527(0.6919) | Loss 4.3314(4.3520) | Error 0.2325(0.2486) Steps 826(818.04) | Grad Norm 0.7727(1.8383) | Total Time 14.00(14.00)\n",
      "Iter 1592 | Time 74.4352(75.5544) | Bit/dim 3.9967(4.0058) | Xent 0.6715(0.6913) | Loss 4.3325(4.3514) | Error 0.2381(0.2483) Steps 814(817.92) | Grad Norm 0.8964(1.8101) | Total Time 14.00(14.00)\n",
      "Iter 1593 | Time 75.7742(75.5610) | Bit/dim 4.0008(4.0056) | Xent 0.6585(0.6903) | Loss 4.3300(4.3508) | Error 0.2356(0.2479) Steps 826(818.16) | Grad Norm 0.9357(1.7838) | Total Time 14.00(14.00)\n",
      "Iter 1594 | Time 76.9606(75.6030) | Bit/dim 4.0034(4.0055) | Xent 0.6533(0.6892) | Loss 4.3300(4.3501) | Error 0.2339(0.2475) Steps 808(817.86) | Grad Norm 0.8969(1.7572) | Total Time 14.00(14.00)\n",
      "Iter 1595 | Time 76.9779(75.6442) | Bit/dim 4.0094(4.0057) | Xent 0.6694(0.6886) | Loss 4.3441(4.3500) | Error 0.2444(0.2474) Steps 820(817.92) | Grad Norm 0.8996(1.7315) | Total Time 14.00(14.00)\n",
      "Iter 1596 | Time 75.9064(75.6521) | Bit/dim 3.9958(4.0054) | Xent 0.6633(0.6878) | Loss 4.3274(4.3493) | Error 0.2318(0.2469) Steps 820(817.98) | Grad Norm 1.0454(1.7109) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 29.3083, Epoch Time 499.5429(502.0472), Bit/dim 4.0073(best: 4.0067), Xent 1.3000, Loss 4.6573, Error 0.4101(best: 0.4102)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1597 | Time 74.6878(75.6232) | Bit/dim 3.9950(4.0051) | Xent 0.6749(0.6875) | Loss 4.3325(4.3488) | Error 0.2400(0.2467) Steps 820(818.04) | Grad Norm 1.1222(1.6933) | Total Time 14.00(14.00)\n",
      "Iter 1598 | Time 73.7419(75.5667) | Bit/dim 4.0065(4.0051) | Xent 0.6488(0.6863) | Loss 4.3309(4.3482) | Error 0.2350(0.2464) Steps 820(818.10) | Grad Norm 0.7456(1.6648) | Total Time 14.00(14.00)\n",
      "Iter 1599 | Time 74.1881(75.5254) | Bit/dim 4.0109(4.0053) | Xent 0.6703(0.6858) | Loss 4.3460(4.3482) | Error 0.2349(0.2460) Steps 814(817.98) | Grad Norm 1.2504(1.6524) | Total Time 14.00(14.00)\n",
      "Iter 1600 | Time 76.2357(75.5467) | Bit/dim 4.0034(4.0052) | Xent 0.6411(0.6845) | Loss 4.3239(4.3474) | Error 0.2321(0.2456) Steps 820(818.04) | Grad Norm 1.0539(1.6344) | Total Time 14.00(14.00)\n",
      "Iter 1601 | Time 75.8391(75.5554) | Bit/dim 3.9962(4.0049) | Xent 0.6577(0.6837) | Loss 4.3251(4.3468) | Error 0.2356(0.2453) Steps 826(818.28) | Grad Norm 0.8052(1.6096) | Total Time 14.00(14.00)\n",
      "Iter 1602 | Time 74.6477(75.5282) | Bit/dim 4.0036(4.0049) | Xent 0.6707(0.6833) | Loss 4.3390(4.3465) | Error 0.2394(0.2451) Steps 814(818.15) | Grad Norm 1.0876(1.5939) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 29.5733, Epoch Time 494.7058(501.8269), Bit/dim 4.0065(best: 4.0067), Xent 1.3068, Loss 4.6599, Error 0.4135(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1603 | Time 74.3498(75.4929) | Bit/dim 3.9952(4.0046) | Xent 0.6651(0.6827) | Loss 4.3277(4.3460) | Error 0.2338(0.2448) Steps 814(818.03) | Grad Norm 1.3709(1.5872) | Total Time 14.00(14.00)\n",
      "Iter 1604 | Time 79.6134(75.6165) | Bit/dim 4.0093(4.0048) | Xent 0.6592(0.6820) | Loss 4.3389(4.3458) | Error 0.2349(0.2445) Steps 808(817.72) | Grad Norm 1.4352(1.5827) | Total Time 14.00(14.00)\n",
      "Iter 1605 | Time 73.4916(75.5527) | Bit/dim 4.0024(4.0047) | Xent 0.6572(0.6813) | Loss 4.3310(4.3453) | Error 0.2400(0.2443) Steps 826(817.97) | Grad Norm 1.9576(1.5939) | Total Time 14.00(14.00)\n",
      "Iter 1606 | Time 75.5921(75.5539) | Bit/dim 4.0016(4.0046) | Xent 0.6823(0.6813) | Loss 4.3427(4.3452) | Error 0.2435(0.2443) Steps 814(817.85) | Grad Norm 0.8734(1.5723) | Total Time 14.00(14.00)\n",
      "Iter 1607 | Time 72.9464(75.4757) | Bit/dim 3.9951(4.0043) | Xent 0.6759(0.6812) | Loss 4.3330(4.3449) | Error 0.2435(0.2443) Steps 802(817.38) | Grad Norm 1.1668(1.5601) | Total Time 14.00(14.00)\n",
      "Iter 1608 | Time 75.5305(75.4773) | Bit/dim 4.0015(4.0042) | Xent 0.6335(0.6797) | Loss 4.3182(4.3441) | Error 0.2306(0.2439) Steps 808(817.10) | Grad Norm 1.2658(1.5513) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 29.9735, Epoch Time 497.2120(501.6885), Bit/dim 4.0056(best: 4.0065), Xent 1.3008, Loss 4.6560, Error 0.4126(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1609 | Time 75.9805(75.4924) | Bit/dim 4.0115(4.0044) | Xent 0.6495(0.6788) | Loss 4.3362(4.3438) | Error 0.2395(0.2438) Steps 814(817.00) | Grad Norm 0.8420(1.5300) | Total Time 14.00(14.00)\n",
      "Iter 1610 | Time 74.5598(75.4644) | Bit/dim 3.9909(4.0040) | Xent 0.6611(0.6783) | Loss 4.3215(4.3432) | Error 0.2404(0.2437) Steps 832(817.45) | Grad Norm 1.3070(1.5233) | Total Time 14.00(14.00)\n",
      "Iter 1611 | Time 78.7086(75.5618) | Bit/dim 4.0035(4.0040) | Xent 0.6753(0.6782) | Loss 4.3411(4.3431) | Error 0.2411(0.2436) Steps 820(817.53) | Grad Norm 1.1086(1.5109) | Total Time 14.00(14.00)\n",
      "Iter 1612 | Time 75.3538(75.5555) | Bit/dim 4.0033(4.0040) | Xent 0.6567(0.6776) | Loss 4.3316(4.3428) | Error 0.2389(0.2434) Steps 826(817.78) | Grad Norm 1.2292(1.5024) | Total Time 14.00(14.00)\n",
      "Iter 1613 | Time 75.5651(75.5558) | Bit/dim 4.0023(4.0039) | Xent 0.6626(0.6771) | Loss 4.3336(4.3425) | Error 0.2392(0.2433) Steps 814(817.67) | Grad Norm 1.0568(1.4891) | Total Time 14.00(14.00)\n",
      "Iter 1614 | Time 72.2448(75.4565) | Bit/dim 4.0003(4.0038) | Xent 0.6616(0.6766) | Loss 4.3311(4.3421) | Error 0.2351(0.2431) Steps 808(817.38) | Grad Norm 0.9663(1.4734) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 29.5844, Epoch Time 497.6332(501.5668), Bit/dim 4.0058(best: 4.0056), Xent 1.3059, Loss 4.6587, Error 0.4102(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1615 | Time 75.9679(75.4718) | Bit/dim 4.0046(4.0039) | Xent 0.6563(0.6760) | Loss 4.3328(4.3419) | Error 0.2361(0.2429) Steps 814(817.28) | Grad Norm 0.8870(1.4558) | Total Time 14.00(14.00)\n",
      "Iter 1616 | Time 76.2642(75.4956) | Bit/dim 3.9972(4.0037) | Xent 0.6582(0.6755) | Loss 4.3263(4.3414) | Error 0.2360(0.2427) Steps 814(817.18) | Grad Norm 1.0957(1.4450) | Total Time 14.00(14.00)\n",
      "Iter 1617 | Time 74.5659(75.4677) | Bit/dim 3.9973(4.0035) | Xent 0.6559(0.6749) | Loss 4.3252(4.3409) | Error 0.2304(0.2423) Steps 814(817.09) | Grad Norm 0.7449(1.4240) | Total Time 14.00(14.00)\n",
      "Iter 1618 | Time 72.6585(75.3834) | Bit/dim 4.0024(4.0034) | Xent 0.6466(0.6741) | Loss 4.3257(4.3405) | Error 0.2338(0.2420) Steps 814(816.99) | Grad Norm 0.9790(1.4106) | Total Time 14.00(14.00)\n",
      "Iter 1619 | Time 76.1167(75.4054) | Bit/dim 4.0090(4.0036) | Xent 0.6437(0.6731) | Loss 4.3309(4.3402) | Error 0.2278(0.2416) Steps 820(817.08) | Grad Norm 0.6894(1.3890) | Total Time 14.00(14.00)\n",
      "Iter 1620 | Time 75.2807(75.4017) | Bit/dim 3.9976(4.0034) | Xent 0.6577(0.6727) | Loss 4.3265(4.3398) | Error 0.2374(0.2415) Steps 808(816.81) | Grad Norm 1.1376(1.3815) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 29.4131, Epoch Time 496.0852(501.4024), Bit/dim 4.0063(best: 4.0056), Xent 1.3102, Loss 4.6614, Error 0.4126(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1621 | Time 74.5345(75.3757) | Bit/dim 4.0090(4.0036) | Xent 0.6678(0.6725) | Loss 4.3429(4.3399) | Error 0.2381(0.2414) Steps 820(816.91) | Grad Norm 0.8965(1.3669) | Total Time 14.00(14.00)\n",
      "Iter 1622 | Time 75.7573(75.3871) | Bit/dim 3.9965(4.0034) | Xent 0.6544(0.6720) | Loss 4.3237(4.3394) | Error 0.2368(0.2412) Steps 820(817.00) | Grad Norm 0.9580(1.3546) | Total Time 14.00(14.00)\n",
      "Iter 1623 | Time 75.0803(75.3779) | Bit/dim 3.9998(4.0033) | Xent 0.6564(0.6715) | Loss 4.3280(4.3390) | Error 0.2331(0.2410) Steps 814(816.91) | Grad Norm 0.8702(1.3401) | Total Time 14.00(14.00)\n",
      "Iter 1624 | Time 74.3384(75.3467) | Bit/dim 4.0031(4.0033) | Xent 0.6542(0.6710) | Loss 4.3302(4.3388) | Error 0.2351(0.2408) Steps 814(816.82) | Grad Norm 0.9665(1.3289) | Total Time 14.00(14.00)\n",
      "Iter 1625 | Time 74.5626(75.3232) | Bit/dim 3.9973(4.0031) | Xent 0.6675(0.6709) | Loss 4.3311(4.3385) | Error 0.2320(0.2405) Steps 826(817.10) | Grad Norm 1.0005(1.3191) | Total Time 14.00(14.00)\n",
      "Iter 1626 | Time 74.2854(75.2921) | Bit/dim 3.9969(4.0029) | Xent 0.6502(0.6703) | Loss 4.3220(4.3380) | Error 0.2292(0.2402) Steps 820(817.18) | Grad Norm 0.8762(1.3058) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 29.6331, Epoch Time 494.1006(501.1833), Bit/dim 4.0059(best: 4.0056), Xent 1.3110, Loss 4.6614, Error 0.4143(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1627 | Time 75.2443(75.2906) | Bit/dim 4.0033(4.0029) | Xent 0.6497(0.6697) | Loss 4.3281(4.3377) | Error 0.2272(0.2398) Steps 820(817.27) | Grad Norm 0.8732(1.2928) | Total Time 14.00(14.00)\n",
      "Iter 1628 | Time 77.8478(75.3674) | Bit/dim 4.0063(4.0030) | Xent 0.6632(0.6695) | Loss 4.3379(4.3377) | Error 0.2389(0.2398) Steps 814(817.17) | Grad Norm 1.2985(1.2930) | Total Time 14.00(14.00)\n",
      "Iter 1629 | Time 74.6407(75.3456) | Bit/dim 3.9949(4.0028) | Xent 0.6483(0.6688) | Loss 4.3190(4.3372) | Error 0.2354(0.2397) Steps 826(817.44) | Grad Norm 0.8875(1.2808) | Total Time 14.00(14.00)\n",
      "Iter 1630 | Time 73.4862(75.2898) | Bit/dim 3.9993(4.0027) | Xent 0.6585(0.6685) | Loss 4.3286(4.3369) | Error 0.2358(0.2395) Steps 814(817.33) | Grad Norm 1.0270(1.2732) | Total Time 14.00(14.00)\n",
      "Iter 1631 | Time 77.2178(75.3476) | Bit/dim 4.0016(4.0026) | Xent 0.6384(0.6676) | Loss 4.3208(4.3364) | Error 0.2322(0.2393) Steps 826(817.59) | Grad Norm 0.9537(1.2636) | Total Time 14.00(14.00)\n",
      "Iter 1632 | Time 74.4442(75.3205) | Bit/dim 4.0005(4.0026) | Xent 0.6408(0.6668) | Loss 4.3209(4.3360) | Error 0.2299(0.2390) Steps 814(817.48) | Grad Norm 0.9978(1.2556) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 29.2060, Epoch Time 497.8679(501.0839), Bit/dim 4.0060(best: 4.0056), Xent 1.3198, Loss 4.6659, Error 0.4103(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1633 | Time 73.8897(75.2776) | Bit/dim 3.9999(4.0025) | Xent 0.6499(0.6663) | Loss 4.3249(4.3356) | Error 0.2321(0.2388) Steps 814(817.38) | Grad Norm 0.7876(1.2416) | Total Time 14.00(14.00)\n",
      "Iter 1634 | Time 74.3035(75.2484) | Bit/dim 3.9948(4.0023) | Xent 0.6460(0.6657) | Loss 4.3178(4.3351) | Error 0.2332(0.2387) Steps 820(817.46) | Grad Norm 0.9633(1.2332) | Total Time 14.00(14.00)\n",
      "Iter 1635 | Time 75.3666(75.2519) | Bit/dim 3.9989(4.0022) | Xent 0.6473(0.6651) | Loss 4.3225(4.3347) | Error 0.2358(0.2386) Steps 808(817.18) | Grad Norm 0.9520(1.2248) | Total Time 14.00(14.00)\n",
      "Iter 1636 | Time 75.1404(75.2486) | Bit/dim 3.9979(4.0020) | Xent 0.6491(0.6647) | Loss 4.3224(4.3344) | Error 0.2354(0.2385) Steps 820(817.26) | Grad Norm 1.0600(1.2199) | Total Time 14.00(14.00)\n",
      "Iter 1637 | Time 75.0953(75.2440) | Bit/dim 4.0084(4.0022) | Xent 0.6526(0.6643) | Loss 4.3347(4.3344) | Error 0.2381(0.2385) Steps 820(817.34) | Grad Norm 1.5058(1.2284) | Total Time 14.00(14.00)\n",
      "Iter 1638 | Time 74.4670(75.2207) | Bit/dim 4.0005(4.0022) | Xent 0.6413(0.6636) | Loss 4.3211(4.3340) | Error 0.2252(0.2381) Steps 820(817.42) | Grad Norm 0.8440(1.2169) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 28.9838, Epoch Time 492.7571(500.8341), Bit/dim 4.0051(best: 4.0056), Xent 1.3102, Loss 4.6602, Error 0.4114(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1639 | Time 72.1420(75.1283) | Bit/dim 4.0007(4.0021) | Xent 0.6682(0.6637) | Loss 4.3348(4.3340) | Error 0.2365(0.2380) Steps 826(817.68) | Grad Norm 0.8227(1.2051) | Total Time 14.00(14.00)\n",
      "Iter 1640 | Time 72.8431(75.0597) | Bit/dim 4.0031(4.0022) | Xent 0.6380(0.6630) | Loss 4.3221(4.3336) | Error 0.2279(0.2377) Steps 814(817.57) | Grad Norm 1.0313(1.1999) | Total Time 14.00(14.00)\n",
      "Iter 1641 | Time 73.7835(75.0215) | Bit/dim 3.9999(4.0021) | Xent 0.6511(0.6626) | Loss 4.3254(4.3334) | Error 0.2318(0.2375) Steps 826(817.82) | Grad Norm 1.5351(1.2099) | Total Time 14.00(14.00)\n",
      "Iter 1642 | Time 76.9889(75.0805) | Bit/dim 3.9997(4.0020) | Xent 0.6412(0.6620) | Loss 4.3203(4.3330) | Error 0.2292(0.2373) Steps 832(818.25) | Grad Norm 1.1626(1.2085) | Total Time 14.00(14.00)\n",
      "Iter 1643 | Time 77.6245(75.1568) | Bit/dim 3.9917(4.0017) | Xent 0.6561(0.6618) | Loss 4.3197(4.3326) | Error 0.2380(0.2373) Steps 814(818.12) | Grad Norm 0.8972(1.1992) | Total Time 14.00(14.00)\n",
      "Iter 1644 | Time 75.9520(75.1807) | Bit/dim 4.0003(4.0017) | Xent 0.6383(0.6611) | Loss 4.3195(4.3322) | Error 0.2296(0.2371) Steps 826(818.36) | Grad Norm 1.0017(1.1932) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 29.5408, Epoch Time 494.4005(500.6411), Bit/dim 4.0059(best: 4.0051), Xent 1.3134, Loss 4.6626, Error 0.4133(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1645 | Time 73.8477(75.1407) | Bit/dim 3.9945(4.0014) | Xent 0.6516(0.6608) | Loss 4.3203(4.3319) | Error 0.2294(0.2369) Steps 820(818.41) | Grad Norm 0.9297(1.1853) | Total Time 14.00(14.00)\n",
      "Iter 1646 | Time 75.2906(75.1452) | Bit/dim 3.9988(4.0014) | Xent 0.6613(0.6608) | Loss 4.3294(4.3318) | Error 0.2409(0.2370) Steps 820(818.45) | Grad Norm 1.0359(1.1808) | Total Time 14.00(14.00)\n",
      "Iter 1647 | Time 73.0918(75.0836) | Bit/dim 4.0060(4.0015) | Xent 0.6417(0.6602) | Loss 4.3268(4.3316) | Error 0.2284(0.2367) Steps 814(818.32) | Grad Norm 0.9051(1.1726) | Total Time 14.00(14.00)\n",
      "Iter 1648 | Time 74.7590(75.0738) | Bit/dim 3.9866(4.0011) | Xent 0.6555(0.6601) | Loss 4.3143(4.3311) | Error 0.2324(0.2366) Steps 814(818.19) | Grad Norm 1.1213(1.1710) | Total Time 14.00(14.00)\n",
      "Iter 1649 | Time 76.5040(75.1167) | Bit/dim 4.0061(4.0012) | Xent 0.6554(0.6600) | Loss 4.3338(4.3312) | Error 0.2362(0.2366) Steps 814(818.06) | Grad Norm 1.4984(1.1809) | Total Time 14.00(14.00)\n",
      "Iter 1650 | Time 73.6449(75.0726) | Bit/dim 4.0058(4.0013) | Xent 0.6432(0.6595) | Loss 4.3274(4.3311) | Error 0.2280(0.2363) Steps 820(818.12) | Grad Norm 1.1430(1.1797) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 29.6840, Epoch Time 492.7161(500.4033), Bit/dim 4.0058(best: 4.0051), Xent 1.3174, Loss 4.6645, Error 0.4131(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1651 | Time 74.0257(75.0412) | Bit/dim 4.0053(4.0015) | Xent 0.6494(0.6592) | Loss 4.3300(4.3310) | Error 0.2340(0.2362) Steps 820(818.18) | Grad Norm 1.1397(1.1785) | Total Time 14.00(14.00)\n",
      "Iter 1652 | Time 74.3845(75.0215) | Bit/dim 4.0016(4.0015) | Xent 0.6361(0.6585) | Loss 4.3196(4.3307) | Error 0.2255(0.2359) Steps 814(818.05) | Grad Norm 1.5422(1.1894) | Total Time 14.00(14.00)\n",
      "Iter 1653 | Time 73.2942(74.9697) | Bit/dim 4.0024(4.0015) | Xent 0.6421(0.6580) | Loss 4.3234(4.3305) | Error 0.2350(0.2359) Steps 832(818.47) | Grad Norm 1.2737(1.1920) | Total Time 14.00(14.00)\n",
      "Iter 1654 | Time 74.9070(74.9678) | Bit/dim 3.9875(4.0011) | Xent 0.6504(0.6577) | Loss 4.3127(4.3300) | Error 0.2324(0.2358) Steps 814(818.34) | Grad Norm 0.8856(1.1828) | Total Time 14.00(14.00)\n",
      "Iter 1655 | Time 76.0915(75.0015) | Bit/dim 4.0036(4.0012) | Xent 0.6497(0.6575) | Loss 4.3285(4.3299) | Error 0.2295(0.2356) Steps 814(818.21) | Grad Norm 1.0028(1.1774) | Total Time 14.00(14.00)\n",
      "Iter 1656 | Time 71.7657(74.9044) | Bit/dim 4.0031(4.0012) | Xent 0.6462(0.6572) | Loss 4.3262(4.3298) | Error 0.2336(0.2355) Steps 814(818.08) | Grad Norm 1.2791(1.1804) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 29.5792, Epoch Time 489.7088(500.0825), Bit/dim 4.0042(best: 4.0051), Xent 1.3171, Loss 4.6628, Error 0.4097(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1657 | Time 73.8537(74.8729) | Bit/dim 3.9901(4.0009) | Xent 0.6475(0.6569) | Loss 4.3138(4.3293) | Error 0.2331(0.2355) Steps 814(817.96) | Grad Norm 1.4248(1.1877) | Total Time 14.00(14.00)\n",
      "Iter 1658 | Time 72.1708(74.7918) | Bit/dim 4.0063(4.0010) | Xent 0.6454(0.6565) | Loss 4.3290(4.3293) | Error 0.2321(0.2354) Steps 820(818.02) | Grad Norm 0.9811(1.1815) | Total Time 14.00(14.00)\n",
      "Iter 1659 | Time 77.0296(74.8590) | Bit/dim 4.0038(4.0011) | Xent 0.6356(0.6559) | Loss 4.3216(4.3291) | Error 0.2275(0.2351) Steps 826(818.26) | Grad Norm 0.9523(1.1747) | Total Time 14.00(14.00)\n",
      "Iter 1660 | Time 74.9669(74.8622) | Bit/dim 4.0043(4.0012) | Xent 0.6496(0.6557) | Loss 4.3291(4.3291) | Error 0.2312(0.2350) Steps 802(817.77) | Grad Norm 0.9226(1.1671) | Total Time 14.00(14.00)\n",
      "Iter 1661 | Time 74.6868(74.8569) | Bit/dim 3.9827(4.0007) | Xent 0.6555(0.6557) | Loss 4.3104(4.3285) | Error 0.2381(0.2351) Steps 814(817.66) | Grad Norm 1.2112(1.1684) | Total Time 14.00(14.00)\n",
      "Iter 1662 | Time 77.0705(74.9233) | Bit/dim 4.0053(4.0008) | Xent 0.6617(0.6559) | Loss 4.3362(4.3287) | Error 0.2348(0.2351) Steps 814(817.55) | Grad Norm 1.1916(1.1691) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 29.2463, Epoch Time 494.7394(499.9222), Bit/dim 4.0036(best: 4.0042), Xent 1.3118, Loss 4.6595, Error 0.4109(best: 0.4097)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1663 | Time 73.7370(74.8878) | Bit/dim 4.0043(4.0009) | Xent 0.6465(0.6556) | Loss 4.3275(4.3287) | Error 0.2252(0.2348) Steps 802(817.08) | Grad Norm 0.9222(1.1617) | Total Time 14.00(14.00)\n",
      "Iter 1664 | Time 75.1913(74.8969) | Bit/dim 4.0000(4.0009) | Xent 0.6395(0.6551) | Loss 4.3198(4.3284) | Error 0.2282(0.2346) Steps 820(817.17) | Grad Norm 1.1484(1.1613) | Total Time 14.00(14.00)\n",
      "Iter 1665 | Time 74.8385(74.8951) | Bit/dim 3.9918(4.0006) | Xent 0.6525(0.6550) | Loss 4.3181(4.3281) | Error 0.2381(0.2347) Steps 820(817.25) | Grad Norm 0.8818(1.1529) | Total Time 14.00(14.00)\n",
      "Iter 1666 | Time 74.6388(74.8874) | Bit/dim 4.0002(4.0006) | Xent 0.6426(0.6547) | Loss 4.3214(4.3279) | Error 0.2309(0.2346) Steps 820(817.34) | Grad Norm 1.4190(1.1609) | Total Time 14.00(14.00)\n",
      "Iter 1667 | Time 77.1456(74.9552) | Bit/dim 3.9947(4.0004) | Xent 0.6478(0.6545) | Loss 4.3186(4.3277) | Error 0.2381(0.2347) Steps 838(817.96) | Grad Norm 1.1041(1.1592) | Total Time 14.00(14.00)\n",
      "Iter 1668 | Time 74.7814(74.9500) | Bit/dim 4.0025(4.0005) | Xent 0.6446(0.6542) | Loss 4.3248(4.3276) | Error 0.2325(0.2346) Steps 814(817.84) | Grad Norm 1.3574(1.1652) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 29.3456, Epoch Time 495.7464(499.7969), Bit/dim 4.0040(best: 4.0036), Xent 1.3265, Loss 4.6673, Error 0.4103(best: 0.4097)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1669 | Time 74.9342(74.9495) | Bit/dim 3.9991(4.0004) | Xent 0.6427(0.6538) | Loss 4.3204(4.3273) | Error 0.2281(0.2344) Steps 820(817.90) | Grad Norm 0.9718(1.1594) | Total Time 14.00(14.00)\n",
      "Iter 1670 | Time 74.3181(74.9305) | Bit/dim 3.9983(4.0004) | Xent 0.6554(0.6539) | Loss 4.3260(4.3273) | Error 0.2312(0.2343) Steps 820(817.97) | Grad Norm 1.0939(1.1574) | Total Time 14.00(14.00)\n",
      "Iter 1671 | Time 73.3699(74.8837) | Bit/dim 3.9971(4.0003) | Xent 0.6455(0.6536) | Loss 4.3199(4.3271) | Error 0.2292(0.2342) Steps 808(817.67) | Grad Norm 0.9796(1.1521) | Total Time 14.00(14.00)\n",
      "Iter 1672 | Time 72.0034(74.7973) | Bit/dim 4.0024(4.0003) | Xent 0.6281(0.6529) | Loss 4.3164(4.3268) | Error 0.2315(0.2341) Steps 814(817.56) | Grad Norm 1.1297(1.1514) | Total Time 14.00(14.00)\n",
      "Iter 1673 | Time 72.7610(74.7362) | Bit/dim 3.9914(4.0001) | Xent 0.6210(0.6519) | Loss 4.3018(4.3260) | Error 0.2202(0.2337) Steps 820(817.63) | Grad Norm 0.9891(1.1465) | Total Time 14.00(14.00)\n",
      "Iter 1674 | Time 75.8721(74.7703) | Bit/dim 4.0004(4.0001) | Xent 0.6360(0.6514) | Loss 4.3184(4.3258) | Error 0.2311(0.2336) Steps 820(817.70) | Grad Norm 1.1199(1.1457) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 29.3542, Epoch Time 488.3166(499.4525), Bit/dim 4.0034(best: 4.0036), Xent 1.3161, Loss 4.6614, Error 0.4125(best: 0.4097)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1675 | Time 77.0004(74.8372) | Bit/dim 4.0045(4.0002) | Xent 0.6311(0.6508) | Loss 4.3200(4.3256) | Error 0.2329(0.2336) Steps 808(817.41) | Grad Norm 0.7458(1.1337) | Total Time 14.00(14.00)\n",
      "Iter 1676 | Time 75.9608(74.8709) | Bit/dim 3.9861(3.9998) | Xent 0.6242(0.6500) | Loss 4.2982(4.3248) | Error 0.2264(0.2334) Steps 820(817.49) | Grad Norm 0.9697(1.1288) | Total Time 14.00(14.00)\n",
      "Iter 1677 | Time 73.4989(74.8297) | Bit/dim 4.0099(4.0001) | Xent 0.6485(0.6500) | Loss 4.3342(4.3251) | Error 0.2329(0.2334) Steps 814(817.38) | Grad Norm 1.0806(1.1274) | Total Time 14.00(14.00)\n",
      "Iter 1678 | Time 75.0542(74.8365) | Bit/dim 3.9996(4.0001) | Xent 0.6437(0.6498) | Loss 4.3214(4.3250) | Error 0.2314(0.2333) Steps 814(817.28) | Grad Norm 1.0467(1.1249) | Total Time 14.00(14.00)\n",
      "Iter 1679 | Time 74.6577(74.8311) | Bit/dim 3.9947(3.9999) | Xent 0.6639(0.6502) | Loss 4.3266(4.3250) | Error 0.2384(0.2335) Steps 814(817.18) | Grad Norm 0.9332(1.1192) | Total Time 14.00(14.00)\n",
      "Iter 1680 | Time 76.6912(74.8869) | Bit/dim 3.9925(3.9997) | Xent 0.6487(0.6502) | Loss 4.3169(4.3248) | Error 0.2322(0.2334) Steps 826(817.45) | Grad Norm 1.0166(1.1161) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 29.2236, Epoch Time 497.5195(499.3945), Bit/dim 4.0032(best: 4.0034), Xent 1.3298, Loss 4.6681, Error 0.4138(best: 0.4097)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1681 | Time 76.3555(74.9310) | Bit/dim 3.9962(3.9996) | Xent 0.6581(0.6504) | Loss 4.3253(4.3248) | Error 0.2350(0.2335) Steps 820(817.52) | Grad Norm 1.0835(1.1151) | Total Time 14.00(14.00)\n",
      "Iter 1682 | Time 75.0429(74.9343) | Bit/dim 3.9876(3.9992) | Xent 0.6298(0.6498) | Loss 4.3025(4.3241) | Error 0.2288(0.2333) Steps 814(817.42) | Grad Norm 1.2900(1.1204) | Total Time 14.00(14.00)\n",
      "Iter 1683 | Time 75.7037(74.9574) | Bit/dim 4.0082(3.9995) | Xent 0.6431(0.6496) | Loss 4.3298(4.3243) | Error 0.2279(0.2332) Steps 814(817.32) | Grad Norm 0.9625(1.1156) | Total Time 14.00(14.00)\n",
      "Iter 1684 | Time 75.3117(74.9680) | Bit/dim 3.9925(3.9993) | Xent 0.6364(0.6492) | Loss 4.3107(4.3239) | Error 0.2229(0.2329) Steps 820(817.40) | Grad Norm 0.8027(1.1063) | Total Time 14.00(14.00)\n",
      "Iter 1685 | Time 76.5828(75.0165) | Bit/dim 3.9956(3.9992) | Xent 0.6322(0.6487) | Loss 4.3117(4.3235) | Error 0.2309(0.2328) Steps 826(817.65) | Grad Norm 1.0902(1.1058) | Total Time 14.00(14.00)\n",
      "Iter 1686 | Time 75.8137(75.0404) | Bit/dim 4.0057(3.9994) | Xent 0.6326(0.6482) | Loss 4.3221(4.3235) | Error 0.2304(0.2327) Steps 820(817.73) | Grad Norm 0.9303(1.1005) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 29.2067, Epoch Time 499.8167(499.4072), Bit/dim 4.0026(best: 4.0032), Xent 1.3268, Loss 4.6660, Error 0.4134(best: 0.4097)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1687 | Time 76.7758(75.0925) | Bit/dim 3.9931(3.9992) | Xent 0.6444(0.6481) | Loss 4.3153(4.3232) | Error 0.2349(0.2328) Steps 826(817.97) | Grad Norm 0.8577(1.0932) | Total Time 14.00(14.00)\n",
      "Iter 1688 | Time 74.9727(75.0889) | Bit/dim 3.9944(3.9990) | Xent 0.6343(0.6477) | Loss 4.3116(4.3229) | Error 0.2301(0.2327) Steps 808(817.67) | Grad Norm 0.9144(1.0879) | Total Time 14.00(14.00)\n",
      "Iter 1689 | Time 77.4332(75.1592) | Bit/dim 4.0047(3.9992) | Xent 0.6382(0.6474) | Loss 4.3238(4.3229) | Error 0.2245(0.2325) Steps 814(817.56) | Grad Norm 0.8523(1.0808) | Total Time 14.00(14.00)\n",
      "Iter 1690 | Time 76.9506(75.2129) | Bit/dim 4.0059(3.9994) | Xent 0.6423(0.6472) | Loss 4.3270(4.3230) | Error 0.2290(0.2324) Steps 820(817.64) | Grad Norm 0.8799(1.0748) | Total Time 14.00(14.00)\n",
      "Iter 1691 | Time 76.2065(75.2427) | Bit/dim 3.9997(3.9994) | Xent 0.6308(0.6467) | Loss 4.3151(4.3228) | Error 0.2230(0.2321) Steps 808(817.35) | Grad Norm 0.9685(1.0716) | Total Time 14.00(14.00)\n",
      "Iter 1692 | Time 75.5601(75.2523) | Bit/dim 3.9878(3.9991) | Xent 0.6531(0.6469) | Loss 4.3143(4.3225) | Error 0.2344(0.2321) Steps 814(817.25) | Grad Norm 0.8417(1.0647) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 29.2439, Epoch Time 503.2304(499.5219), Bit/dim 4.0027(best: 4.0026), Xent 1.3254, Loss 4.6654, Error 0.4123(best: 0.4097)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1693 | Time 77.7506(75.3272) | Bit/dim 4.0090(3.9994) | Xent 0.6231(0.6462) | Loss 4.3206(4.3225) | Error 0.2211(0.2318) Steps 832(817.69) | Grad Norm 0.7414(1.0550) | Total Time 14.00(14.00)\n",
      "Iter 1694 | Time 75.0526(75.3190) | Bit/dim 3.9904(3.9991) | Xent 0.6526(0.6464) | Loss 4.3168(4.3223) | Error 0.2319(0.2318) Steps 820(817.76) | Grad Norm 0.8834(1.0498) | Total Time 14.00(14.00)\n",
      "Iter 1695 | Time 78.3311(75.4093) | Bit/dim 3.9915(3.9989) | Xent 0.6403(0.6462) | Loss 4.3117(4.3220) | Error 0.2299(0.2318) Steps 820(817.83) | Grad Norm 0.9793(1.0477) | Total Time 14.00(14.00)\n",
      "Iter 1696 | Time 73.5125(75.3524) | Bit/dim 4.0025(3.9990) | Xent 0.6342(0.6459) | Loss 4.3196(4.3219) | Error 0.2252(0.2316) Steps 820(817.89) | Grad Norm 0.8715(1.0424) | Total Time 14.00(14.00)\n",
      "Iter 1697 | Time 73.6819(75.3023) | Bit/dim 3.9968(3.9989) | Xent 0.6297(0.6454) | Loss 4.3117(4.3216) | Error 0.2294(0.2315) Steps 820(817.96) | Grad Norm 1.0530(1.0427) | Total Time 14.00(14.00)\n",
      "Iter 1698 | Time 72.7755(75.2265) | Bit/dim 3.9952(3.9988) | Xent 0.6268(0.6448) | Loss 4.3086(4.3212) | Error 0.2271(0.2314) Steps 826(818.20) | Grad Norm 1.6515(1.0610) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 29.5728, Epoch Time 496.2019(499.4223), Bit/dim 4.0030(best: 4.0026), Xent 1.3392, Loss 4.6726, Error 0.4122(best: 0.4097)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1699 | Time 75.3623(75.2306) | Bit/dim 4.0020(3.9989) | Xent 0.6447(0.6448) | Loss 4.3243(4.3213) | Error 0.2302(0.2313) Steps 820(818.25) | Grad Norm 1.0960(1.0621) | Total Time 14.00(14.00)\n",
      "Iter 1700 | Time 74.2331(75.2007) | Bit/dim 3.9956(3.9988) | Xent 0.6418(0.6447) | Loss 4.3165(4.3212) | Error 0.2276(0.2312) Steps 808(817.94) | Grad Norm 1.1180(1.0637) | Total Time 14.00(14.00)\n",
      "Iter 1701 | Time 75.7566(75.2173) | Bit/dim 4.0054(3.9990) | Xent 0.6130(0.6438) | Loss 4.3119(4.3209) | Error 0.2252(0.2310) Steps 820(818.00) | Grad Norm 0.8694(1.0579) | Total Time 14.00(14.00)\n",
      "Iter 1702 | Time 77.6193(75.2894) | Bit/dim 3.9872(3.9986) | Xent 0.6538(0.6441) | Loss 4.3142(4.3207) | Error 0.2372(0.2312) Steps 808(817.70) | Grad Norm 1.0856(1.0587) | Total Time 14.00(14.00)\n",
      "Iter 1703 | Time 75.0252(75.2815) | Bit/dim 3.9958(3.9986) | Xent 0.6313(0.6437) | Loss 4.3114(4.3204) | Error 0.2284(0.2311) Steps 814(817.59) | Grad Norm 0.7405(1.0492) | Total Time 14.00(14.00)\n",
      "Iter 1704 | Time 74.8058(75.2672) | Bit/dim 3.9977(3.9985) | Xent 0.6161(0.6429) | Loss 4.3057(4.3200) | Error 0.2185(0.2308) Steps 814(817.49) | Grad Norm 1.2336(1.0547) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 29.8064, Epoch Time 498.4282(499.3924), Bit/dim 4.0025(best: 4.0026), Xent 1.3274, Loss 4.6662, Error 0.4093(best: 0.4097)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1705 | Time 73.9978(75.2291) | Bit/dim 4.0002(3.9986) | Xent 0.6317(0.6425) | Loss 4.3161(4.3199) | Error 0.2271(0.2307) Steps 820(817.56) | Grad Norm 0.8031(1.0472) | Total Time 14.00(14.00)\n",
      "Iter 1706 | Time 74.7461(75.2146) | Bit/dim 4.0096(3.9989) | Xent 0.6294(0.6421) | Loss 4.3243(4.3200) | Error 0.2272(0.2306) Steps 820(817.63) | Grad Norm 0.8929(1.0425) | Total Time 14.00(14.00)\n",
      "Iter 1707 | Time 74.2270(75.1850) | Bit/dim 3.9903(3.9987) | Xent 0.6279(0.6417) | Loss 4.3042(4.3195) | Error 0.2261(0.2304) Steps 820(817.71) | Grad Norm 0.9562(1.0400) | Total Time 14.00(14.00)\n",
      "Iter 1708 | Time 74.4215(75.1621) | Bit/dim 3.9905(3.9984) | Xent 0.6399(0.6417) | Loss 4.3104(4.3192) | Error 0.2210(0.2301) Steps 808(817.41) | Grad Norm 1.2294(1.0456) | Total Time 14.00(14.00)\n",
      "Iter 1709 | Time 74.7955(75.1511) | Bit/dim 3.9958(3.9983) | Xent 0.6121(0.6408) | Loss 4.3018(4.3187) | Error 0.2226(0.2299) Steps 826(817.67) | Grad Norm 1.0995(1.0473) | Total Time 14.00(14.00)\n",
      "Iter 1710 | Time 76.4397(75.1898) | Bit/dim 3.9932(3.9982) | Xent 0.6355(0.6406) | Loss 4.3109(4.3185) | Error 0.2339(0.2300) Steps 826(817.92) | Grad Norm 1.0343(1.0469) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 29.5789, Epoch Time 493.6871(499.2213), Bit/dim 4.0018(best: 4.0025), Xent 1.3445, Loss 4.6740, Error 0.4170(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1711 | Time 75.1329(75.1881) | Bit/dim 3.9975(3.9982) | Xent 0.6252(0.6401) | Loss 4.3101(4.3182) | Error 0.2246(0.2299) Steps 814(817.80) | Grad Norm 1.0484(1.0469) | Total Time 14.00(14.00)\n",
      "Iter 1712 | Time 73.4117(75.1348) | Bit/dim 3.9891(3.9979) | Xent 0.6207(0.6396) | Loss 4.2995(4.3177) | Error 0.2299(0.2299) Steps 826(818.05) | Grad Norm 1.2702(1.0536) | Total Time 14.00(14.00)\n",
      "Iter 1713 | Time 75.9400(75.1589) | Bit/dim 4.0015(3.9980) | Xent 0.6394(0.6396) | Loss 4.3212(4.3178) | Error 0.2286(0.2298) Steps 820(818.11) | Grad Norm 2.0133(1.0824) | Total Time 14.00(14.00)\n",
      "Iter 1714 | Time 72.8942(75.0910) | Bit/dim 3.9888(3.9977) | Xent 0.6498(0.6399) | Loss 4.3137(4.3176) | Error 0.2348(0.2300) Steps 820(818.16) | Grad Norm 1.0164(1.0804) | Total Time 14.00(14.00)\n",
      "Iter 1715 | Time 73.9512(75.0568) | Bit/dim 4.0009(3.9978) | Xent 0.6284(0.6395) | Loss 4.3151(4.3176) | Error 0.2280(0.2299) Steps 820(818.22) | Grad Norm 1.0204(1.0786) | Total Time 14.00(14.00)\n",
      "Iter 1716 | Time 74.9128(75.0525) | Bit/dim 3.9988(3.9978) | Xent 0.6259(0.6391) | Loss 4.3118(4.3174) | Error 0.2278(0.2299) Steps 814(818.09) | Grad Norm 1.0384(1.0774) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 29.5708, Epoch Time 491.5722(498.9918), Bit/dim 4.0025(best: 4.0018), Xent 1.3303, Loss 4.6676, Error 0.4138(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1717 | Time 72.6003(74.9789) | Bit/dim 3.9949(3.9978) | Xent 0.6333(0.6389) | Loss 4.3115(4.3172) | Error 0.2259(0.2297) Steps 826(818.33) | Grad Norm 1.2913(1.0838) | Total Time 14.00(14.00)\n",
      "Iter 1718 | Time 74.4165(74.9620) | Bit/dim 3.9907(3.9975) | Xent 0.6529(0.6394) | Loss 4.3172(4.3172) | Error 0.2350(0.2299) Steps 820(818.38) | Grad Norm 1.1841(1.0868) | Total Time 14.00(14.00)\n",
      "Iter 1719 | Time 76.5640(75.0101) | Bit/dim 3.9945(3.9975) | Xent 0.6632(0.6401) | Loss 4.3261(4.3175) | Error 0.2379(0.2301) Steps 820(818.43) | Grad Norm 0.9213(1.0819) | Total Time 14.00(14.00)\n",
      "Iter 1720 | Time 75.7016(75.0308) | Bit/dim 3.9934(3.9973) | Xent 0.6209(0.6395) | Loss 4.3039(4.3171) | Error 0.2270(0.2300) Steps 820(818.48) | Grad Norm 1.2956(1.0883) | Total Time 14.00(14.00)\n",
      "Iter 1721 | Time 73.9829(74.9994) | Bit/dim 4.0028(3.9975) | Xent 0.6110(0.6386) | Loss 4.3083(4.3168) | Error 0.2175(0.2297) Steps 814(818.34) | Grad Norm 1.1188(1.0892) | Total Time 14.00(14.00)\n",
      "Iter 1722 | Time 74.7978(74.9933) | Bit/dim 3.9978(3.9975) | Xent 0.6195(0.6381) | Loss 4.3076(4.3165) | Error 0.2238(0.2295) Steps 808(818.03) | Grad Norm 0.8250(1.0813) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 29.0233, Epoch Time 492.7478(498.8045), Bit/dim 4.0015(best: 4.0018), Xent 1.3340, Loss 4.6685, Error 0.4136(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1723 | Time 77.2684(75.0616) | Bit/dim 3.9985(3.9975) | Xent 0.6108(0.6372) | Loss 4.3039(4.3162) | Error 0.2134(0.2290) Steps 808(817.73) | Grad Norm 0.7183(1.0704) | Total Time 14.00(14.00)\n",
      "Iter 1724 | Time 75.7038(75.0809) | Bit/dim 4.0021(3.9977) | Xent 0.6349(0.6372) | Loss 4.3196(4.3163) | Error 0.2329(0.2291) Steps 832(818.16) | Grad Norm 1.2238(1.0750) | Total Time 14.00(14.00)\n",
      "Iter 1725 | Time 76.7265(75.1302) | Bit/dim 3.9996(3.9977) | Xent 0.6145(0.6365) | Loss 4.3069(4.3160) | Error 0.2252(0.2290) Steps 814(818.03) | Grad Norm 1.0066(1.0729) | Total Time 14.00(14.00)\n",
      "Iter 1726 | Time 73.4533(75.0799) | Bit/dim 3.9966(3.9977) | Xent 0.6355(0.6365) | Loss 4.3143(4.3159) | Error 0.2274(0.2290) Steps 802(817.55) | Grad Norm 1.0128(1.0711) | Total Time 14.00(14.00)\n",
      "Iter 1727 | Time 74.3726(75.0587) | Bit/dim 3.9904(3.9975) | Xent 0.6200(0.6360) | Loss 4.3004(4.3155) | Error 0.2261(0.2289) Steps 832(817.99) | Grad Norm 1.1346(1.0730) | Total Time 14.00(14.00)\n",
      "Iter 1728 | Time 73.2134(75.0033) | Bit/dim 3.9930(3.9973) | Xent 0.6320(0.6358) | Loss 4.3090(4.3153) | Error 0.2216(0.2287) Steps 820(818.05) | Grad Norm 1.2720(1.0790) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 29.3480, Epoch Time 495.4946(498.7052), Bit/dim 4.0018(best: 4.0015), Xent 1.3410, Loss 4.6723, Error 0.4111(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1729 | Time 76.5585(75.0500) | Bit/dim 3.9996(3.9974) | Xent 0.6262(0.6356) | Loss 4.3127(4.3152) | Error 0.2272(0.2286) Steps 814(817.93) | Grad Norm 1.2440(1.0840) | Total Time 14.00(14.00)\n",
      "Iter 1730 | Time 75.6753(75.0688) | Bit/dim 4.0008(3.9975) | Xent 0.6108(0.6348) | Loss 4.3062(4.3149) | Error 0.2204(0.2284) Steps 820(817.99) | Grad Norm 0.8204(1.0761) | Total Time 14.00(14.00)\n",
      "Iter 1731 | Time 77.7460(75.1491) | Bit/dim 3.9985(3.9975) | Xent 0.6227(0.6345) | Loss 4.3099(4.3148) | Error 0.2234(0.2282) Steps 826(818.23) | Grad Norm 1.5024(1.0888) | Total Time 14.00(14.00)\n",
      "Iter 1732 | Time 76.0798(75.1770) | Bit/dim 3.9881(3.9973) | Xent 0.6264(0.6342) | Loss 4.3013(4.3144) | Error 0.2234(0.2281) Steps 832(818.64) | Grad Norm 1.5452(1.1025) | Total Time 14.00(14.00)\n",
      "Iter 1733 | Time 74.3848(75.1532) | Bit/dim 3.9942(3.9972) | Xent 0.6162(0.6337) | Loss 4.3024(4.3140) | Error 0.2201(0.2278) Steps 814(818.50) | Grad Norm 1.4297(1.1123) | Total Time 14.00(14.00)\n",
      "Iter 1734 | Time 72.1991(75.0646) | Bit/dim 3.9977(3.9972) | Xent 0.6518(0.6342) | Loss 4.3236(4.3143) | Error 0.2354(0.2281) Steps 814(818.37) | Grad Norm 0.9035(1.1061) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 29.2878, Epoch Time 497.3873(498.6657), Bit/dim 4.0016(best: 4.0015), Xent 1.3381, Loss 4.6707, Error 0.4136(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1735 | Time 72.3673(74.9837) | Bit/dim 3.9918(3.9970) | Xent 0.6371(0.6343) | Loss 4.3104(4.3142) | Error 0.2272(0.2280) Steps 820(818.42) | Grad Norm 1.3202(1.1125) | Total Time 14.00(14.00)\n",
      "Iter 1736 | Time 75.7858(75.0077) | Bit/dim 3.9994(3.9971) | Xent 0.6273(0.6341) | Loss 4.3130(4.3141) | Error 0.2250(0.2279) Steps 808(818.10) | Grad Norm 1.9177(1.1367) | Total Time 14.00(14.00)\n",
      "Iter 1737 | Time 75.5177(75.0230) | Bit/dim 3.9965(3.9971) | Xent 0.6169(0.6336) | Loss 4.3050(4.3139) | Error 0.2271(0.2279) Steps 820(818.16) | Grad Norm 1.4710(1.1467) | Total Time 14.00(14.00)\n",
      "Iter 1738 | Time 73.7116(74.9837) | Bit/dim 3.9942(3.9970) | Xent 0.6320(0.6335) | Loss 4.3102(4.3138) | Error 0.2309(0.2280) Steps 814(818.04) | Grad Norm 1.2406(1.1495) | Total Time 14.00(14.00)\n",
      "Iter 1739 | Time 73.6648(74.9441) | Bit/dim 3.9932(3.9969) | Xent 0.6350(0.6336) | Loss 4.3108(4.3137) | Error 0.2256(0.2279) Steps 802(817.55) | Grad Norm 1.1705(1.1501) | Total Time 14.00(14.00)\n",
      "Iter 1740 | Time 75.1990(74.9518) | Bit/dim 3.9999(3.9970) | Xent 0.6242(0.6333) | Loss 4.3120(4.3136) | Error 0.2259(0.2279) Steps 820(817.63) | Grad Norm 1.1467(1.1500) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 29.7678, Epoch Time 491.7592(498.4585), Bit/dim 4.0010(best: 4.0015), Xent 1.3436, Loss 4.6728, Error 0.4129(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1741 | Time 75.6655(74.9732) | Bit/dim 3.9949(3.9969) | Xent 0.6232(0.6330) | Loss 4.3065(4.3134) | Error 0.2226(0.2277) Steps 814(817.52) | Grad Norm 1.2048(1.1517) | Total Time 14.00(14.00)\n",
      "Iter 1742 | Time 74.9621(74.9729) | Bit/dim 4.0004(3.9970) | Xent 0.6188(0.6326) | Loss 4.3098(4.3133) | Error 0.2186(0.2274) Steps 814(817.41) | Grad Norm 1.0122(1.1475) | Total Time 14.00(14.00)\n",
      "Iter 1743 | Time 75.0320(74.9746) | Bit/dim 3.9959(3.9970) | Xent 0.6177(0.6321) | Loss 4.3047(4.3130) | Error 0.2228(0.2273) Steps 826(817.67) | Grad Norm 0.9162(1.1406) | Total Time 14.00(14.00)\n",
      "Iter 1744 | Time 74.9095(74.9727) | Bit/dim 3.9957(3.9969) | Xent 0.6160(0.6316) | Loss 4.3037(4.3128) | Error 0.2174(0.2270) Steps 832(818.10) | Grad Norm 0.9636(1.1352) | Total Time 14.00(14.00)\n",
      "Iter 1745 | Time 76.9622(75.0324) | Bit/dim 3.9938(3.9968) | Xent 0.6393(0.6319) | Loss 4.3134(4.3128) | Error 0.2312(0.2271) Steps 826(818.34) | Grad Norm 1.2123(1.1376) | Total Time 14.00(14.00)\n",
      "Iter 1746 | Time 74.5079(75.0166) | Bit/dim 3.9915(3.9967) | Xent 0.6404(0.6321) | Loss 4.3116(4.3127) | Error 0.2270(0.2271) Steps 814(818.21) | Grad Norm 0.8034(1.1275) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 29.2202, Epoch Time 496.7078(498.4059), Bit/dim 4.0010(best: 4.0010), Xent 1.3525, Loss 4.6772, Error 0.4134(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1747 | Time 74.7525(75.0087) | Bit/dim 4.0004(3.9968) | Xent 0.6235(0.6319) | Loss 4.3121(4.3127) | Error 0.2232(0.2270) Steps 814(818.08) | Grad Norm 1.0609(1.1255) | Total Time 14.00(14.00)\n",
      "Iter 1748 | Time 73.8787(74.9748) | Bit/dim 3.9952(3.9967) | Xent 0.6214(0.6315) | Loss 4.3059(4.3125) | Error 0.2251(0.2270) Steps 814(817.96) | Grad Norm 0.9171(1.1193) | Total Time 14.00(14.00)\n",
      "Iter 1749 | Time 77.1449(75.0399) | Bit/dim 3.9882(3.9965) | Xent 0.6233(0.6313) | Loss 4.2999(4.3121) | Error 0.2205(0.2268) Steps 814(817.84) | Grad Norm 0.8760(1.1120) | Total Time 14.00(14.00)\n",
      "Iter 1750 | Time 73.7594(75.0015) | Bit/dim 4.0067(3.9968) | Xent 0.6354(0.6314) | Loss 4.3244(4.3125) | Error 0.2315(0.2269) Steps 826(818.09) | Grad Norm 1.0988(1.1116) | Total Time 14.00(14.00)\n",
      "Iter 1751 | Time 76.0909(75.0342) | Bit/dim 3.9856(3.9965) | Xent 0.6127(0.6309) | Loss 4.2920(4.3119) | Error 0.2192(0.2267) Steps 820(818.14) | Grad Norm 1.5436(1.1246) | Total Time 14.00(14.00)\n",
      "Iter 1752 | Time 74.5445(75.0195) | Bit/dim 3.9931(3.9964) | Xent 0.6351(0.6310) | Loss 4.3106(4.3119) | Error 0.2252(0.2266) Steps 814(818.02) | Grad Norm 1.3160(1.1303) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 29.7535, Epoch Time 495.6058(498.3219), Bit/dim 4.0011(best: 4.0010), Xent 1.3501, Loss 4.6761, Error 0.4144(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1753 | Time 74.8376(75.0140) | Bit/dim 3.9975(3.9964) | Xent 0.6214(0.6307) | Loss 4.3082(4.3117) | Error 0.2220(0.2265) Steps 808(817.72) | Grad Norm 0.9352(1.1244) | Total Time 14.00(14.00)\n",
      "Iter 1754 | Time 76.4761(75.0579) | Bit/dim 3.9961(3.9964) | Xent 0.6431(0.6311) | Loss 4.3177(4.3119) | Error 0.2332(0.2267) Steps 820(817.79) | Grad Norm 0.8697(1.1168) | Total Time 14.00(14.00)\n",
      "Iter 1755 | Time 73.9638(75.0251) | Bit/dim 3.9996(3.9965) | Xent 0.6287(0.6310) | Loss 4.3139(4.3120) | Error 0.2240(0.2266) Steps 820(817.85) | Grad Norm 1.3513(1.1238) | Total Time 14.00(14.00)\n",
      "Iter 1756 | Time 74.3830(75.0058) | Bit/dim 3.9985(3.9965) | Xent 0.6100(0.6304) | Loss 4.3035(4.3117) | Error 0.2139(0.2262) Steps 808(817.56) | Grad Norm 1.2100(1.1264) | Total Time 14.00(14.00)\n",
      "Iter 1757 | Time 72.8022(74.9397) | Bit/dim 3.9900(3.9963) | Xent 0.6306(0.6304) | Loss 4.3053(4.3115) | Error 0.2266(0.2262) Steps 820(817.63) | Grad Norm 1.0493(1.1241) | Total Time 14.00(14.00)\n",
      "Iter 1758 | Time 76.1381(74.9756) | Bit/dim 3.9844(3.9960) | Xent 0.6143(0.6299) | Loss 4.2916(4.3109) | Error 0.2214(0.2261) Steps 826(817.88) | Grad Norm 1.3973(1.1323) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 29.7709, Epoch Time 493.8458(498.1877), Bit/dim 4.0001(best: 4.0010), Xent 1.3497, Loss 4.6749, Error 0.4125(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1759 | Time 72.2105(74.8927) | Bit/dim 4.0083(3.9964) | Xent 0.6191(0.6296) | Loss 4.3179(4.3111) | Error 0.2260(0.2261) Steps 814(817.76) | Grad Norm 0.8348(1.1234) | Total Time 14.00(14.00)\n",
      "Iter 1760 | Time 74.7116(74.8873) | Bit/dim 3.9891(3.9961) | Xent 0.6290(0.6296) | Loss 4.3036(4.3109) | Error 0.2206(0.2259) Steps 808(817.47) | Grad Norm 1.4597(1.1335) | Total Time 14.00(14.00)\n",
      "Iter 1761 | Time 74.8709(74.8868) | Bit/dim 3.9974(3.9962) | Xent 0.6081(0.6289) | Loss 4.3014(4.3106) | Error 0.2156(0.2256) Steps 820(817.55) | Grad Norm 1.0966(1.1324) | Total Time 14.00(14.00)\n",
      "Iter 1762 | Time 73.8487(74.8556) | Bit/dim 3.9875(3.9959) | Xent 0.6268(0.6288) | Loss 4.3009(4.3103) | Error 0.2214(0.2255) Steps 808(817.26) | Grad Norm 1.3104(1.1377) | Total Time 14.00(14.00)\n",
      "Iter 1763 | Time 76.5466(74.9064) | Bit/dim 3.9924(3.9958) | Xent 0.6174(0.6285) | Loss 4.3011(4.3101) | Error 0.2177(0.2253) Steps 820(817.34) | Grad Norm 1.1539(1.1382) | Total Time 14.00(14.00)\n",
      "Iter 1764 | Time 74.3167(74.8887) | Bit/dim 3.9964(3.9958) | Xent 0.6255(0.6284) | Loss 4.3092(4.3100) | Error 0.2269(0.2253) Steps 820(817.42) | Grad Norm 1.1935(1.1398) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 29.4699, Epoch Time 491.3811(497.9835), Bit/dim 3.9999(best: 4.0001), Xent 1.3550, Loss 4.6774, Error 0.4143(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1765 | Time 76.2697(74.9301) | Bit/dim 3.9917(3.9957) | Xent 0.6170(0.6281) | Loss 4.3002(4.3097) | Error 0.2231(0.2252) Steps 808(817.14) | Grad Norm 1.6298(1.1545) | Total Time 14.00(14.00)\n",
      "Iter 1766 | Time 77.2458(74.9996) | Bit/dim 3.9791(3.9952) | Xent 0.6031(0.6273) | Loss 4.2807(4.3089) | Error 0.2208(0.2251) Steps 820(817.23) | Grad Norm 0.9763(1.1492) | Total Time 14.00(14.00)\n",
      "Iter 1767 | Time 73.2370(74.9467) | Bit/dim 3.9986(3.9953) | Xent 0.6268(0.6273) | Loss 4.3120(4.3090) | Error 0.2240(0.2251) Steps 820(817.31) | Grad Norm 1.0791(1.1471) | Total Time 14.00(14.00)\n",
      "Iter 1768 | Time 75.2343(74.9553) | Bit/dim 4.0029(3.9955) | Xent 0.6307(0.6274) | Loss 4.3182(4.3092) | Error 0.2282(0.2252) Steps 808(817.03) | Grad Norm 1.1245(1.1464) | Total Time 14.00(14.00)\n",
      "Iter 1769 | Time 74.8441(74.9520) | Bit/dim 4.0013(3.9957) | Xent 0.6111(0.6269) | Loss 4.3068(4.3092) | Error 0.2202(0.2250) Steps 826(817.30) | Grad Norm 1.0942(1.1449) | Total Time 14.00(14.00)\n",
      "Iter 1770 | Time 75.5079(74.9687) | Bit/dim 3.9921(3.9956) | Xent 0.6194(0.6267) | Loss 4.3018(4.3089) | Error 0.2206(0.2249) Steps 814(817.20) | Grad Norm 0.9276(1.1383) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 29.5805, Epoch Time 498.0200(497.9846), Bit/dim 3.9999(best: 3.9999), Xent 1.3456, Loss 4.6727, Error 0.4120(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1771 | Time 73.7865(74.9332) | Bit/dim 3.9997(3.9957) | Xent 0.6276(0.6267) | Loss 4.3135(4.3091) | Error 0.2250(0.2249) Steps 820(817.28) | Grad Norm 1.2769(1.1425) | Total Time 14.00(14.00)\n",
      "Iter 1772 | Time 74.6743(74.9254) | Bit/dim 3.9815(3.9953) | Xent 0.6279(0.6268) | Loss 4.2954(4.3087) | Error 0.2260(0.2249) Steps 820(817.37) | Grad Norm 1.1671(1.1432) | Total Time 14.00(14.00)\n",
      "Iter 1773 | Time 76.7587(74.9804) | Bit/dim 3.9917(3.9952) | Xent 0.6060(0.6261) | Loss 4.2946(4.3083) | Error 0.2196(0.2248) Steps 826(817.62) | Grad Norm 0.9798(1.1383) | Total Time 14.00(14.00)\n",
      "Iter 1774 | Time 77.3539(75.0516) | Bit/dim 3.9948(3.9952) | Xent 0.6110(0.6257) | Loss 4.3003(4.3080) | Error 0.2150(0.2245) Steps 838(818.24) | Grad Norm 1.2539(1.1418) | Total Time 14.00(14.00)\n",
      "Iter 1775 | Time 73.8698(75.0162) | Bit/dim 3.9973(3.9952) | Xent 0.6200(0.6255) | Loss 4.3073(4.3080) | Error 0.2229(0.2244) Steps 826(818.47) | Grad Norm 1.6101(1.1558) | Total Time 14.00(14.00)\n",
      "Iter 1776 | Time 76.5505(75.0622) | Bit/dim 3.9938(3.9952) | Xent 0.6061(0.6249) | Loss 4.2968(4.3077) | Error 0.2135(0.2241) Steps 820(818.51) | Grad Norm 1.9494(1.1796) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 29.7413, Epoch Time 498.2247(497.9918), Bit/dim 3.9994(best: 3.9999), Xent 1.3530, Loss 4.6759, Error 0.4127(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1777 | Time 77.2885(75.1290) | Bit/dim 3.9899(3.9950) | Xent 0.6079(0.6244) | Loss 4.2938(4.3072) | Error 0.2173(0.2239) Steps 814(818.38) | Grad Norm 0.8916(1.1710) | Total Time 14.00(14.00)\n",
      "Iter 1778 | Time 75.5580(75.1419) | Bit/dim 4.0015(3.9952) | Xent 0.6152(0.6241) | Loss 4.3091(4.3073) | Error 0.2224(0.2238) Steps 820(818.43) | Grad Norm 1.2964(1.1748) | Total Time 14.00(14.00)\n",
      "Iter 1779 | Time 75.3712(75.1487) | Bit/dim 3.9971(3.9953) | Xent 0.6353(0.6245) | Loss 4.3147(4.3075) | Error 0.2279(0.2240) Steps 820(818.48) | Grad Norm 1.7936(1.1933) | Total Time 14.00(14.00)\n",
      "Iter 1780 | Time 71.9937(75.0541) | Bit/dim 3.9900(3.9951) | Xent 0.6240(0.6245) | Loss 4.3020(4.3074) | Error 0.2242(0.2240) Steps 820(818.52) | Grad Norm 1.5649(1.2045) | Total Time 14.00(14.00)\n",
      "Iter 1781 | Time 75.5087(75.0677) | Bit/dim 3.9897(3.9950) | Xent 0.6212(0.6244) | Loss 4.3003(4.3071) | Error 0.2281(0.2241) Steps 826(818.75) | Grad Norm 1.3050(1.2075) | Total Time 14.00(14.00)\n",
      "Iter 1782 | Time 75.8914(75.0924) | Bit/dim 3.9952(3.9950) | Xent 0.6031(0.6237) | Loss 4.2968(4.3068) | Error 0.2175(0.2239) Steps 814(818.60) | Grad Norm 1.7393(1.2234) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 29.3973, Epoch Time 496.6082(497.9502), Bit/dim 3.9994(best: 3.9994), Xent 1.3593, Loss 4.6791, Error 0.4144(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1783 | Time 74.2567(75.0674) | Bit/dim 3.9884(3.9948) | Xent 0.6109(0.6233) | Loss 4.2939(4.3064) | Error 0.2196(0.2238) Steps 826(818.82) | Grad Norm 1.7957(1.2406) | Total Time 14.00(14.00)\n",
      "Iter 1784 | Time 76.1692(75.1004) | Bit/dim 3.9943(3.9948) | Xent 0.6321(0.6236) | Loss 4.3103(4.3066) | Error 0.2289(0.2239) Steps 826(819.04) | Grad Norm 1.2442(1.2407) | Total Time 14.00(14.00)\n",
      "Iter 1785 | Time 75.6345(75.1165) | Bit/dim 3.9900(3.9946) | Xent 0.6122(0.6233) | Loss 4.2961(4.3062) | Error 0.2192(0.2238) Steps 808(818.71) | Grad Norm 1.0022(1.2336) | Total Time 14.00(14.00)\n",
      "Iter 1786 | Time 76.5717(75.1601) | Bit/dim 3.9963(3.9947) | Xent 0.6114(0.6229) | Loss 4.3020(4.3061) | Error 0.2224(0.2237) Steps 814(818.57) | Grad Norm 1.4039(1.2387) | Total Time 14.00(14.00)\n",
      "Iter 1787 | Time 75.8647(75.1812) | Bit/dim 4.0009(3.9949) | Xent 0.6292(0.6231) | Loss 4.3155(4.3064) | Error 0.2245(0.2238) Steps 808(818.25) | Grad Norm 1.7472(1.2539) | Total Time 14.00(14.00)\n",
      "Iter 1788 | Time 74.2462(75.1532) | Bit/dim 3.9906(3.9947) | Xent 0.6126(0.6228) | Loss 4.2969(4.3061) | Error 0.2174(0.2236) Steps 820(818.30) | Grad Norm 1.3856(1.2579) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 29.5947, Epoch Time 498.0730(497.9539), Bit/dim 3.9983(best: 3.9994), Xent 1.3613, Loss 4.6790, Error 0.4119(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1789 | Time 75.8847(75.1751) | Bit/dim 3.9892(3.9946) | Xent 0.6167(0.6226) | Loss 4.2975(4.3059) | Error 0.2196(0.2235) Steps 814(818.17) | Grad Norm 1.0676(1.2522) | Total Time 14.00(14.00)\n",
      "Iter 1790 | Time 75.2077(75.1761) | Bit/dim 3.9987(3.9947) | Xent 0.6254(0.6227) | Loss 4.3114(4.3060) | Error 0.2251(0.2235) Steps 808(817.87) | Grad Norm 1.4162(1.2571) | Total Time 14.00(14.00)\n",
      "Iter 1791 | Time 74.9546(75.1695) | Bit/dim 3.9944(3.9947) | Xent 0.6030(0.6221) | Loss 4.2959(4.3057) | Error 0.2151(0.2233) Steps 820(817.93) | Grad Norm 1.4107(1.2617) | Total Time 14.00(14.00)\n",
      "Iter 1792 | Time 72.9910(75.1041) | Bit/dim 3.9907(3.9946) | Xent 0.5964(0.6213) | Loss 4.2890(4.3052) | Error 0.2125(0.2229) Steps 814(817.81) | Grad Norm 1.2425(1.2611) | Total Time 14.00(14.00)\n",
      "Iter 1793 | Time 77.1748(75.1662) | Bit/dim 3.9807(3.9941) | Xent 0.6228(0.6214) | Loss 4.2921(4.3048) | Error 0.2216(0.2229) Steps 802(817.34) | Grad Norm 1.0375(1.2544) | Total Time 14.00(14.00)\n",
      "Iter 1794 | Time 75.6547(75.1809) | Bit/dim 4.0009(3.9943) | Xent 0.6074(0.6209) | Loss 4.3046(4.3048) | Error 0.2143(0.2226) Steps 808(817.06) | Grad Norm 1.2996(1.2558) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 29.4586, Epoch Time 497.0040(497.9254), Bit/dim 3.9989(best: 3.9983), Xent 1.3562, Loss 4.6770, Error 0.4100(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1795 | Time 73.4223(75.1281) | Bit/dim 3.9931(3.9943) | Xent 0.6197(0.6209) | Loss 4.3030(4.3048) | Error 0.2211(0.2226) Steps 820(817.15) | Grad Norm 1.5383(1.2643) | Total Time 14.00(14.00)\n",
      "Iter 1796 | Time 74.3269(75.1041) | Bit/dim 3.9873(3.9941) | Xent 0.6092(0.6206) | Loss 4.2919(4.3044) | Error 0.2218(0.2226) Steps 808(816.87) | Grad Norm 0.8587(1.2521) | Total Time 14.00(14.00)\n",
      "Iter 1797 | Time 77.3120(75.1703) | Bit/dim 3.9928(3.9941) | Xent 0.6181(0.6205) | Loss 4.3018(4.3043) | Error 0.2249(0.2226) Steps 826(817.15) | Grad Norm 0.7268(1.2363) | Total Time 14.00(14.00)\n",
      "Iter 1798 | Time 73.2086(75.1115) | Bit/dim 4.0018(3.9943) | Xent 0.6202(0.6205) | Loss 4.3120(4.3045) | Error 0.2312(0.2229) Steps 826(817.41) | Grad Norm 1.0808(1.2317) | Total Time 14.00(14.00)\n",
      "Iter 1799 | Time 75.2188(75.1147) | Bit/dim 3.9908(3.9942) | Xent 0.6121(0.6202) | Loss 4.2968(4.3043) | Error 0.2240(0.2229) Steps 814(817.31) | Grad Norm 1.2577(1.2324) | Total Time 14.00(14.00)\n",
      "Iter 1800 | Time 74.0281(75.0821) | Bit/dim 3.9945(3.9942) | Xent 0.6152(0.6201) | Loss 4.3021(4.3042) | Error 0.2224(0.2229) Steps 820(817.39) | Grad Norm 1.1820(1.2309) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 29.4061, Epoch Time 492.5593(497.7645), Bit/dim 3.9985(best: 3.9983), Xent 1.3595, Loss 4.6783, Error 0.4127(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1801 | Time 73.9256(75.0474) | Bit/dim 3.9963(3.9943) | Xent 0.6068(0.6197) | Loss 4.2997(4.3041) | Error 0.2180(0.2228) Steps 814(817.29) | Grad Norm 0.8383(1.2191) | Total Time 14.00(14.00)\n",
      "Iter 1802 | Time 74.1426(75.0203) | Bit/dim 3.9882(3.9941) | Xent 0.6195(0.6197) | Loss 4.2979(4.3039) | Error 0.2212(0.2227) Steps 826(817.55) | Grad Norm 1.1925(1.2183) | Total Time 14.00(14.00)\n",
      "Iter 1803 | Time 75.7449(75.0420) | Bit/dim 3.9893(3.9939) | Xent 0.6259(0.6199) | Loss 4.3023(4.3039) | Error 0.2221(0.2227) Steps 820(817.62) | Grad Norm 1.2900(1.2205) | Total Time 14.00(14.00)\n",
      "Iter 1804 | Time 78.0034(75.1308) | Bit/dim 3.9971(3.9940) | Xent 0.6044(0.6194) | Loss 4.2993(4.3037) | Error 0.2188(0.2226) Steps 826(817.88) | Grad Norm 0.9663(1.2129) | Total Time 14.00(14.00)\n",
      "Iter 1805 | Time 77.3303(75.1968) | Bit/dim 4.0056(3.9944) | Xent 0.6041(0.6189) | Loss 4.3077(4.3038) | Error 0.2166(0.2224) Steps 802(817.40) | Grad Norm 1.9280(1.2343) | Total Time 14.00(14.00)\n",
      "Iter 1806 | Time 74.6769(75.1812) | Bit/dim 3.9755(3.9938) | Xent 0.6004(0.6184) | Loss 4.2757(4.3030) | Error 0.2184(0.2223) Steps 814(817.30) | Grad Norm 1.0614(1.2291) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 29.4927, Epoch Time 498.8220(497.7962), Bit/dim 3.9977(best: 3.9983), Xent 1.3549, Loss 4.6751, Error 0.4148(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1807 | Time 73.7105(75.1371) | Bit/dim 3.9974(3.9939) | Xent 0.5950(0.6177) | Loss 4.2949(4.3028) | Error 0.2115(0.2220) Steps 820(817.38) | Grad Norm 1.6854(1.2428) | Total Time 14.00(14.00)\n",
      "Iter 1808 | Time 75.3682(75.1440) | Bit/dim 3.9915(3.9938) | Xent 0.6048(0.6173) | Loss 4.2939(4.3025) | Error 0.2201(0.2219) Steps 814(817.28) | Grad Norm 1.5632(1.2524) | Total Time 14.00(14.00)\n",
      "Iter 1809 | Time 74.7201(75.1313) | Bit/dim 3.9908(3.9938) | Xent 0.6120(0.6171) | Loss 4.2968(4.3023) | Error 0.2208(0.2219) Steps 808(817.00) | Grad Norm 1.0213(1.2455) | Total Time 14.00(14.00)\n",
      "Iter 1810 | Time 77.8719(75.2135) | Bit/dim 3.9943(3.9938) | Xent 0.6016(0.6167) | Loss 4.2951(4.3021) | Error 0.2169(0.2217) Steps 826(817.27) | Grad Norm 0.8962(1.2350) | Total Time 14.00(14.00)\n",
      "Iter 1811 | Time 73.5445(75.1635) | Bit/dim 3.9847(3.9935) | Xent 0.6133(0.6166) | Loss 4.2914(4.3018) | Error 0.2199(0.2217) Steps 814(817.17) | Grad Norm 1.5690(1.2450) | Total Time 14.00(14.00)\n",
      "Iter 1812 | Time 75.8471(75.1840) | Bit/dim 3.9916(3.9934) | Xent 0.6085(0.6163) | Loss 4.2958(4.3016) | Error 0.2184(0.2216) Steps 838(817.80) | Grad Norm 0.7794(1.2311) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 29.9270, Epoch Time 496.4372(497.7554), Bit/dim 3.9977(best: 3.9977), Xent 1.3715, Loss 4.6835, Error 0.4131(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1813 | Time 73.2539(75.1261) | Bit/dim 3.9980(3.9936) | Xent 0.6119(0.6162) | Loss 4.3039(4.3017) | Error 0.2191(0.2215) Steps 808(817.50) | Grad Norm 1.2050(1.2303) | Total Time 14.00(14.00)\n",
      "Iter 1814 | Time 75.6461(75.1417) | Bit/dim 3.9968(3.9937) | Xent 0.5933(0.6155) | Loss 4.2935(4.3014) | Error 0.2140(0.2213) Steps 826(817.76) | Grad Norm 1.2452(1.2307) | Total Time 14.00(14.00)\n",
      "Iter 1815 | Time 76.6738(75.1876) | Bit/dim 3.9940(3.9937) | Xent 0.6095(0.6153) | Loss 4.2988(4.3013) | Error 0.2146(0.2211) Steps 820(817.82) | Grad Norm 1.0725(1.2260) | Total Time 14.00(14.00)\n",
      "Iter 1816 | Time 73.3378(75.1321) | Bit/dim 3.9913(3.9936) | Xent 0.5936(0.6147) | Loss 4.2881(4.3009) | Error 0.2147(0.2209) Steps 814(817.71) | Grad Norm 0.8392(1.2144) | Total Time 14.00(14.00)\n",
      "Iter 1817 | Time 72.0281(75.0390) | Bit/dim 3.9917(3.9936) | Xent 0.6158(0.6147) | Loss 4.2996(4.3009) | Error 0.2254(0.2210) Steps 820(817.78) | Grad Norm 0.9851(1.2075) | Total Time 14.00(14.00)\n",
      "Iter 1818 | Time 75.3009(75.0469) | Bit/dim 3.9879(3.9934) | Xent 0.6210(0.6149) | Loss 4.2984(4.3008) | Error 0.2238(0.2211) Steps 814(817.66) | Grad Norm 1.2437(1.2086) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 29.6962, Epoch Time 491.4978(497.5677), Bit/dim 3.9982(best: 3.9977), Xent 1.3756, Loss 4.6860, Error 0.4136(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1819 | Time 74.8237(75.0402) | Bit/dim 3.9908(3.9933) | Xent 0.6110(0.6148) | Loss 4.2963(4.3007) | Error 0.2188(0.2210) Steps 808(817.37) | Grad Norm 1.3996(1.2143) | Total Time 14.00(14.00)\n",
      "Iter 1820 | Time 77.0200(75.0996) | Bit/dim 4.0058(3.9937) | Xent 0.6071(0.6145) | Loss 4.3094(4.3010) | Error 0.2185(0.2209) Steps 814(817.27) | Grad Norm 0.9348(1.2059) | Total Time 14.00(14.00)\n",
      "Iter 1821 | Time 74.5383(75.0827) | Bit/dim 3.9868(3.9935) | Xent 0.6149(0.6146) | Loss 4.2942(4.3008) | Error 0.2153(0.2208) Steps 808(817.00) | Grad Norm 2.0534(1.2314) | Total Time 14.00(14.00)\n",
      "Iter 1822 | Time 75.0524(75.0818) | Bit/dim 3.9909(3.9934) | Xent 0.5971(0.6140) | Loss 4.2894(4.3004) | Error 0.2131(0.2205) Steps 820(817.09) | Grad Norm 1.4791(1.2388) | Total Time 14.00(14.00)\n",
      "Iter 1823 | Time 75.8000(75.1034) | Bit/dim 3.9951(3.9935) | Xent 0.6089(0.6139) | Loss 4.2996(4.3004) | Error 0.2199(0.2205) Steps 808(816.81) | Grad Norm 0.8849(1.2282) | Total Time 14.00(14.00)\n",
      "Iter 1824 | Time 77.6114(75.1786) | Bit/dim 3.9896(3.9933) | Xent 0.6062(0.6136) | Loss 4.2927(4.3002) | Error 0.2215(0.2206) Steps 826(817.09) | Grad Norm 2.0494(1.2528) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 29.7149, Epoch Time 500.4640(497.6546), Bit/dim 3.9981(best: 3.9977), Xent 1.3662, Loss 4.6812, Error 0.4121(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1825 | Time 74.8146(75.1677) | Bit/dim 3.9937(3.9933) | Xent 0.6041(0.6134) | Loss 4.2958(4.3000) | Error 0.2159(0.2204) Steps 808(816.82) | Grad Norm 1.7391(1.2674) | Total Time 14.00(14.00)\n",
      "Iter 1826 | Time 72.5952(75.0905) | Bit/dim 3.9909(3.9933) | Xent 0.6048(0.6131) | Loss 4.2933(4.2998) | Error 0.2175(0.2203) Steps 820(816.91) | Grad Norm 1.1270(1.2632) | Total Time 14.00(14.00)\n",
      "Iter 1827 | Time 72.1821(75.0033) | Bit/dim 3.9881(3.9931) | Xent 0.6024(0.6128) | Loss 4.2893(4.2995) | Error 0.2160(0.2202) Steps 832(817.36) | Grad Norm 1.7877(1.2789) | Total Time 14.00(14.00)\n",
      "Iter 1828 | Time 75.4065(75.0154) | Bit/dim 3.9920(3.9931) | Xent 0.6104(0.6127) | Loss 4.2972(4.2994) | Error 0.2174(0.2201) Steps 808(817.08) | Grad Norm 2.4177(1.3131) | Total Time 14.00(14.00)\n",
      "Iter 1829 | Time 75.7190(75.0365) | Bit/dim 3.9964(3.9932) | Xent 0.6159(0.6128) | Loss 4.3043(4.2996) | Error 0.2262(0.2203) Steps 814(816.99) | Grad Norm 1.5209(1.3193) | Total Time 14.00(14.00)\n",
      "Iter 1830 | Time 76.3940(75.0772) | Bit/dim 3.9853(3.9929) | Xent 0.6072(0.6126) | Loss 4.2889(4.2993) | Error 0.2204(0.2203) Steps 820(817.08) | Grad Norm 1.1236(1.3135) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 29.8230, Epoch Time 492.6880(497.5056), Bit/dim 3.9976(best: 3.9977), Xent 1.3793, Loss 4.6873, Error 0.4124(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1831 | Time 77.0882(75.1375) | Bit/dim 3.9820(3.9926) | Xent 0.6037(0.6124) | Loss 4.2839(4.2988) | Error 0.2230(0.2204) Steps 814(816.99) | Grad Norm 2.7469(1.3565) | Total Time 14.00(14.00)\n",
      "Iter 1832 | Time 74.4818(75.1179) | Bit/dim 3.9999(3.9928) | Xent 0.6062(0.6122) | Loss 4.3030(4.2989) | Error 0.2215(0.2204) Steps 808(816.72) | Grad Norm 2.9001(1.4028) | Total Time 14.00(14.00)\n",
      "Iter 1833 | Time 74.8201(75.1089) | Bit/dim 3.9946(3.9929) | Xent 0.5949(0.6117) | Loss 4.2921(4.2987) | Error 0.2150(0.2203) Steps 826(817.00) | Grad Norm 1.1896(1.3964) | Total Time 14.00(14.00)\n",
      "Iter 1834 | Time 74.8524(75.1012) | Bit/dim 3.9931(3.9929) | Xent 0.5893(0.6110) | Loss 4.2877(4.2984) | Error 0.2085(0.2199) Steps 826(817.27) | Grad Norm 1.9502(1.4130) | Total Time 14.00(14.00)\n",
      "Iter 1835 | Time 75.3865(75.1098) | Bit/dim 3.9889(3.9928) | Xent 0.6006(0.6107) | Loss 4.2892(4.2981) | Error 0.2175(0.2198) Steps 826(817.53) | Grad Norm 2.2942(1.4394) | Total Time 14.00(14.00)\n",
      "Iter 1836 | Time 74.3580(75.0872) | Bit/dim 3.9865(3.9926) | Xent 0.6123(0.6107) | Loss 4.2926(4.2980) | Error 0.2186(0.2198) Steps 826(817.78) | Grad Norm 1.9111(1.4536) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 29.5122, Epoch Time 496.1919(497.4662), Bit/dim 3.9975(best: 3.9976), Xent 1.3743, Loss 4.6847, Error 0.4136(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1837 | Time 73.6811(75.0451) | Bit/dim 3.9882(3.9925) | Xent 0.6059(0.6106) | Loss 4.2912(4.2978) | Error 0.2156(0.2197) Steps 826(818.03) | Grad Norm 1.0283(1.4408) | Total Time 14.00(14.00)\n",
      "Iter 1838 | Time 73.9368(75.0118) | Bit/dim 3.9910(3.9924) | Xent 0.5925(0.6100) | Loss 4.2872(4.2974) | Error 0.2125(0.2195) Steps 820(818.09) | Grad Norm 1.3664(1.4386) | Total Time 14.00(14.00)\n",
      "Iter 1839 | Time 75.3317(75.0214) | Bit/dim 3.9918(3.9924) | Xent 0.6060(0.6099) | Loss 4.2948(4.2974) | Error 0.2198(0.2195) Steps 814(817.97) | Grad Norm 1.8194(1.4500) | Total Time 14.00(14.00)\n",
      "Iter 1840 | Time 74.6557(75.0104) | Bit/dim 4.0030(3.9927) | Xent 0.6030(0.6097) | Loss 4.3045(4.2976) | Error 0.2126(0.2193) Steps 820(818.03) | Grad Norm 1.6678(1.4565) | Total Time 14.00(14.00)\n",
      "Iter 1841 | Time 74.6632(75.0000) | Bit/dim 3.9907(3.9927) | Xent 0.5900(0.6091) | Loss 4.2857(4.2972) | Error 0.2156(0.2191) Steps 826(818.27) | Grad Norm 0.8909(1.4396) | Total Time 14.00(14.00)\n",
      "Iter 1842 | Time 75.4223(75.0127) | Bit/dim 3.9760(3.9922) | Xent 0.6054(0.6090) | Loss 4.2787(4.2967) | Error 0.2163(0.2191) Steps 814(818.14) | Grad Norm 1.2639(1.4343) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 29.7907, Epoch Time 492.8993(497.3292), Bit/dim 3.9968(best: 3.9975), Xent 1.3801, Loss 4.6869, Error 0.4126(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1843 | Time 74.9876(75.0119) | Bit/dim 3.9907(3.9921) | Xent 0.6087(0.6090) | Loss 4.2950(4.2966) | Error 0.2153(0.2189) Steps 814(818.01) | Grad Norm 2.0654(1.4532) | Total Time 14.00(14.00)\n",
      "Iter 1844 | Time 74.2535(74.9892) | Bit/dim 3.9883(3.9920) | Xent 0.5936(0.6085) | Loss 4.2851(4.2963) | Error 0.2155(0.2188) Steps 820(818.07) | Grad Norm 1.4638(1.4536) | Total Time 14.00(14.00)\n",
      "Iter 1845 | Time 74.0295(74.9604) | Bit/dim 3.9811(3.9917) | Xent 0.5938(0.6081) | Loss 4.2780(4.2957) | Error 0.2145(0.2187) Steps 820(818.13) | Grad Norm 1.1846(1.4455) | Total Time 14.00(14.00)\n",
      "Iter 1846 | Time 73.7024(74.9226) | Bit/dim 3.9972(3.9918) | Xent 0.6086(0.6081) | Loss 4.3015(4.2959) | Error 0.2175(0.2187) Steps 832(818.55) | Grad Norm 2.1588(1.4669) | Total Time 14.00(14.00)\n",
      "Iter 1847 | Time 71.5501(74.8215) | Bit/dim 3.9960(3.9920) | Xent 0.5997(0.6079) | Loss 4.2958(4.2959) | Error 0.2163(0.2186) Steps 820(818.59) | Grad Norm 1.2331(1.4599) | Total Time 14.00(14.00)\n",
      "Iter 1848 | Time 76.7540(74.8795) | Bit/dim 3.9892(3.9919) | Xent 0.6000(0.6076) | Loss 4.2892(4.2957) | Error 0.2140(0.2185) Steps 808(818.27) | Grad Norm 1.0710(1.4482) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 29.5243, Epoch Time 490.5262(497.1251), Bit/dim 3.9971(best: 3.9968), Xent 1.3806, Loss 4.6874, Error 0.4137(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1849 | Time 75.7088(74.9043) | Bit/dim 3.9831(3.9916) | Xent 0.6192(0.6080) | Loss 4.2927(4.2956) | Error 0.2240(0.2186) Steps 820(818.33) | Grad Norm 1.3869(1.4464) | Total Time 14.00(14.00)\n",
      "Iter 1850 | Time 74.2355(74.8843) | Bit/dim 3.9887(3.9915) | Xent 0.5863(0.6073) | Loss 4.2819(4.2952) | Error 0.2073(0.2183) Steps 826(818.56) | Grad Norm 0.9508(1.4315) | Total Time 14.00(14.00)\n",
      "Iter 1851 | Time 72.2487(74.8052) | Bit/dim 3.9918(3.9915) | Xent 0.6002(0.6071) | Loss 4.2918(4.2951) | Error 0.2219(0.2184) Steps 820(818.60) | Grad Norm 0.9909(1.4183) | Total Time 14.00(14.00)\n",
      "Iter 1852 | Time 77.1400(74.8752) | Bit/dim 3.9858(3.9914) | Xent 0.5977(0.6068) | Loss 4.2846(4.2948) | Error 0.2143(0.2183) Steps 832(819.00) | Grad Norm 0.9777(1.4051) | Total Time 14.00(14.00)\n",
      "Iter 1853 | Time 74.4571(74.8627) | Bit/dim 4.0005(3.9916) | Xent 0.6100(0.6069) | Loss 4.3055(4.2951) | Error 0.2179(0.2183) Steps 814(818.85) | Grad Norm 0.9388(1.3911) | Total Time 14.00(14.00)\n",
      "Iter 1854 | Time 74.6390(74.8560) | Bit/dim 3.9909(3.9916) | Xent 0.5961(0.6066) | Loss 4.2889(4.2949) | Error 0.2175(0.2182) Steps 814(818.71) | Grad Norm 1.0618(1.3812) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 29.7312, Epoch Time 493.8813(497.0278), Bit/dim 3.9966(best: 3.9968), Xent 1.3753, Loss 4.6842, Error 0.4153(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1855 | Time 75.4548(74.8740) | Bit/dim 3.9881(3.9915) | Xent 0.6022(0.6065) | Loss 4.2892(4.2947) | Error 0.2166(0.2182) Steps 808(818.38) | Grad Norm 0.8609(1.3656) | Total Time 14.00(14.00)\n",
      "Iter 1856 | Time 72.5875(74.8054) | Bit/dim 3.9863(3.9913) | Xent 0.5990(0.6062) | Loss 4.2858(4.2945) | Error 0.2123(0.2180) Steps 814(818.25) | Grad Norm 0.9191(1.3522) | Total Time 14.00(14.00)\n",
      "Iter 1857 | Time 76.7236(74.8629) | Bit/dim 3.9902(3.9913) | Xent 0.6002(0.6061) | Loss 4.2903(4.2943) | Error 0.2133(0.2179) Steps 820(818.31) | Grad Norm 1.0869(1.3442) | Total Time 14.00(14.00)\n",
      "Iter 1858 | Time 74.6323(74.8560) | Bit/dim 4.0004(3.9916) | Xent 0.5929(0.6057) | Loss 4.2968(4.2944) | Error 0.2175(0.2179) Steps 814(818.18) | Grad Norm 1.0555(1.3356) | Total Time 14.00(14.00)\n",
      "Iter 1859 | Time 77.8013(74.9443) | Bit/dim 3.9922(3.9916) | Xent 0.5946(0.6053) | Loss 4.2895(4.2943) | Error 0.2155(0.2178) Steps 808(817.87) | Grad Norm 1.1165(1.3290) | Total Time 14.00(14.00)\n",
      "Iter 1860 | Time 77.9181(75.0336) | Bit/dim 3.9857(3.9914) | Xent 0.5839(0.6047) | Loss 4.2777(4.2938) | Error 0.2085(0.2175) Steps 814(817.75) | Grad Norm 1.6758(1.3394) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 29.7662, Epoch Time 500.4316(497.1299), Bit/dim 3.9961(best: 3.9966), Xent 1.3794, Loss 4.6858, Error 0.4131(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1861 | Time 76.8166(75.0870) | Bit/dim 3.9878(3.9913) | Xent 0.6021(0.6046) | Loss 4.2889(4.2936) | Error 0.2139(0.2174) Steps 820(817.82) | Grad Norm 1.2240(1.3359) | Total Time 14.00(14.00)\n",
      "Iter 1862 | Time 75.4276(75.0973) | Bit/dim 3.9914(3.9913) | Xent 0.6045(0.6046) | Loss 4.2937(4.2936) | Error 0.2221(0.2175) Steps 814(817.71) | Grad Norm 1.0863(1.3285) | Total Time 14.00(14.00)\n",
      "Iter 1863 | Time 76.4350(75.1374) | Bit/dim 3.9892(3.9913) | Xent 0.6062(0.6047) | Loss 4.2922(4.2936) | Error 0.2176(0.2175) Steps 838(818.32) | Grad Norm 0.9088(1.3159) | Total Time 14.00(14.00)\n",
      "Iter 1864 | Time 74.3487(75.1137) | Bit/dim 3.9928(3.9913) | Xent 0.6046(0.6047) | Loss 4.2951(4.2936) | Error 0.2145(0.2175) Steps 808(818.01) | Grad Norm 1.8078(1.3306) | Total Time 14.00(14.00)\n",
      "Iter 1865 | Time 73.4556(75.0640) | Bit/dim 3.9916(3.9913) | Xent 0.5830(0.6040) | Loss 4.2831(4.2933) | Error 0.2119(0.2173) Steps 808(817.71) | Grad Norm 1.2042(1.3268) | Total Time 14.00(14.00)\n",
      "Iter 1866 | Time 76.0333(75.0931) | Bit/dim 3.9913(3.9913) | Xent 0.6027(0.6040) | Loss 4.2927(4.2933) | Error 0.2126(0.2171) Steps 808(817.42) | Grad Norm 1.6371(1.3361) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 29.7960, Epoch Time 498.0001(497.1560), Bit/dim 3.9948(best: 3.9961), Xent 1.3857, Loss 4.6877, Error 0.4154(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1867 | Time 72.4348(75.0133) | Bit/dim 3.9960(3.9915) | Xent 0.5961(0.6037) | Loss 4.2940(4.2933) | Error 0.2151(0.2171) Steps 808(817.13) | Grad Norm 1.1758(1.3313) | Total Time 14.00(14.00)\n",
      "Iter 1868 | Time 76.3446(75.0533) | Bit/dim 3.9864(3.9913) | Xent 0.5891(0.6033) | Loss 4.2809(4.2929) | Error 0.2123(0.2169) Steps 820(817.22) | Grad Norm 1.4070(1.3336) | Total Time 14.00(14.00)\n",
      "Iter 1869 | Time 73.6156(75.0101) | Bit/dim 3.9865(3.9912) | Xent 0.5944(0.6030) | Loss 4.2837(4.2927) | Error 0.2115(0.2168) Steps 832(817.66) | Grad Norm 1.0288(1.3245) | Total Time 14.00(14.00)\n",
      "Iter 1870 | Time 73.7621(74.9727) | Bit/dim 3.9856(3.9910) | Xent 0.5881(0.6026) | Loss 4.2797(4.2923) | Error 0.2084(0.2165) Steps 814(817.55) | Grad Norm 0.8769(1.3110) | Total Time 14.00(14.00)\n",
      "Iter 1871 | Time 72.9620(74.9124) | Bit/dim 3.9858(3.9908) | Xent 0.5988(0.6025) | Loss 4.2852(4.2921) | Error 0.2114(0.2164) Steps 820(817.63) | Grad Norm 0.8634(1.2976) | Total Time 14.00(14.00)\n",
      "Iter 1872 | Time 74.7825(74.9085) | Bit/dim 3.9951(3.9910) | Xent 0.5893(0.6021) | Loss 4.2897(4.2920) | Error 0.2101(0.2162) Steps 814(817.52) | Grad Norm 0.9181(1.2862) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 29.7511, Epoch Time 489.4168(496.9238), Bit/dim 3.9956(best: 3.9948), Xent 1.3889, Loss 4.6900, Error 0.4135(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1873 | Time 73.2195(74.8578) | Bit/dim 3.9879(3.9909) | Xent 0.5990(0.6020) | Loss 4.2873(4.2919) | Error 0.2184(0.2162) Steps 814(817.41) | Grad Norm 0.7714(1.2708) | Total Time 14.00(14.00)\n",
      "Iter 1874 | Time 74.8129(74.8565) | Bit/dim 3.9803(3.9906) | Xent 0.5963(0.6018) | Loss 4.2785(4.2915) | Error 0.2170(0.2163) Steps 814(817.31) | Grad Norm 1.0076(1.2629) | Total Time 14.00(14.00)\n",
      "Iter 1875 | Time 73.8188(74.8253) | Bit/dim 3.9916(3.9906) | Xent 0.6057(0.6019) | Loss 4.2944(4.2915) | Error 0.2208(0.2164) Steps 808(817.03) | Grad Norm 0.9215(1.2526) | Total Time 14.00(14.00)\n",
      "Iter 1876 | Time 75.6533(74.8502) | Bit/dim 3.9985(3.9908) | Xent 0.5832(0.6014) | Loss 4.2901(4.2915) | Error 0.2055(0.2161) Steps 808(816.76) | Grad Norm 1.3416(1.2553) | Total Time 14.00(14.00)\n",
      "Iter 1877 | Time 74.2380(74.8318) | Bit/dim 3.9939(3.9909) | Xent 0.5909(0.6010) | Loss 4.2893(4.2914) | Error 0.2159(0.2161) Steps 802(816.32) | Grad Norm 1.0526(1.2492) | Total Time 14.00(14.00)\n",
      "Iter 1878 | Time 77.6655(74.9168) | Bit/dim 3.9859(3.9908) | Xent 0.5908(0.6007) | Loss 4.2813(4.2911) | Error 0.2130(0.2160) Steps 808(816.07) | Grad Norm 1.3416(1.2520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 29.1605, Epoch Time 494.2207(496.8427), Bit/dim 3.9944(best: 3.9948), Xent 1.3876, Loss 4.6882, Error 0.4176(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1879 | Time 72.5850(74.8469) | Bit/dim 3.9857(3.9906) | Xent 0.6030(0.6008) | Loss 4.2872(4.2910) | Error 0.2195(0.2161) Steps 826(816.36) | Grad Norm 2.0105(1.2747) | Total Time 14.00(14.00)\n",
      "Iter 1880 | Time 74.0095(74.8217) | Bit/dim 3.9919(3.9906) | Xent 0.5772(0.6001) | Loss 4.2805(4.2907) | Error 0.2086(0.2159) Steps 820(816.47) | Grad Norm 1.4199(1.2791) | Total Time 14.00(14.00)\n",
      "Iter 1881 | Time 76.2448(74.8644) | Bit/dim 3.9894(3.9906) | Xent 0.5890(0.5998) | Loss 4.2839(4.2905) | Error 0.2136(0.2158) Steps 832(816.94) | Grad Norm 1.1010(1.2738) | Total Time 14.00(14.00)\n",
      "Iter 1882 | Time 77.5033(74.9436) | Bit/dim 3.9853(3.9905) | Xent 0.5892(0.5994) | Loss 4.2800(4.2902) | Error 0.2137(0.2157) Steps 808(816.67) | Grad Norm 1.4176(1.2781) | Total Time 14.00(14.00)\n",
      "Iter 1883 | Time 74.3384(74.9254) | Bit/dim 3.9932(3.9905) | Xent 0.5898(0.5992) | Loss 4.2881(4.2901) | Error 0.2119(0.2156) Steps 814(816.59) | Grad Norm 1.6029(1.2878) | Total Time 14.00(14.00)\n",
      "Iter 1884 | Time 76.0840(74.9602) | Bit/dim 3.9889(3.9905) | Xent 0.6027(0.5993) | Loss 4.2902(4.2901) | Error 0.2173(0.2157) Steps 814(816.51) | Grad Norm 0.9984(1.2791) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 29.7299, Epoch Time 496.0720(496.8196), Bit/dim 3.9950(best: 3.9944), Xent 1.3906, Loss 4.6902, Error 0.4149(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1885 | Time 72.7908(74.8951) | Bit/dim 3.9845(3.9903) | Xent 0.5806(0.5987) | Loss 4.2749(4.2897) | Error 0.2130(0.2156) Steps 820(816.62) | Grad Norm 0.9535(1.2694) | Total Time 14.00(14.00)\n",
      "Iter 1886 | Time 74.5351(74.8843) | Bit/dim 3.9947(3.9904) | Xent 0.5983(0.5987) | Loss 4.2939(4.2898) | Error 0.2134(0.2155) Steps 814(816.54) | Grad Norm 1.7087(1.2825) | Total Time 14.00(14.00)\n",
      "Iter 1887 | Time 74.3870(74.8694) | Bit/dim 3.9949(3.9906) | Xent 0.6028(0.5988) | Loss 4.2963(4.2900) | Error 0.2202(0.2157) Steps 820(816.64) | Grad Norm 1.1842(1.2796) | Total Time 14.00(14.00)\n",
      "Iter 1888 | Time 72.9463(74.8117) | Bit/dim 3.9898(3.9905) | Xent 0.5856(0.5984) | Loss 4.2826(4.2898) | Error 0.2086(0.2155) Steps 814(816.56) | Grad Norm 1.0796(1.2736) | Total Time 14.00(14.00)\n",
      "Iter 1889 | Time 73.5885(74.7750) | Bit/dim 3.9889(3.9905) | Xent 0.5821(0.5979) | Loss 4.2799(4.2895) | Error 0.2159(0.2155) Steps 832(817.03) | Grad Norm 1.4771(1.2797) | Total Time 14.00(14.00)\n",
      "Iter 1890 | Time 75.3936(74.7936) | Bit/dim 3.9822(3.9903) | Xent 0.5942(0.5978) | Loss 4.2794(4.2892) | Error 0.2140(0.2154) Steps 808(816.76) | Grad Norm 1.0677(1.2733) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 29.4338, Epoch Time 488.4473(496.5684), Bit/dim 3.9949(best: 3.9944), Xent 1.3940, Loss 4.6919, Error 0.4150(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1891 | Time 72.7439(74.7321) | Bit/dim 3.9880(3.9902) | Xent 0.5734(0.5971) | Loss 4.2747(4.2887) | Error 0.2065(0.2152) Steps 832(817.21) | Grad Norm 1.2083(1.2714) | Total Time 14.00(14.00)\n",
      "Iter 1892 | Time 73.8631(74.7060) | Bit/dim 3.9852(3.9900) | Xent 0.5630(0.5961) | Loss 4.2667(4.2881) | Error 0.2020(0.2148) Steps 826(817.48) | Grad Norm 1.6563(1.2829) | Total Time 14.00(14.00)\n",
      "Iter 1893 | Time 75.3845(74.7264) | Bit/dim 3.9884(3.9900) | Xent 0.5894(0.5959) | Loss 4.2831(4.2879) | Error 0.2143(0.2147) Steps 814(817.37) | Grad Norm 1.3201(1.2841) | Total Time 14.00(14.00)\n",
      "Iter 1894 | Time 76.3454(74.7749) | Bit/dim 3.9927(3.9901) | Xent 0.5915(0.5957) | Loss 4.2885(4.2879) | Error 0.2121(0.2147) Steps 820(817.45) | Grad Norm 0.8790(1.2719) | Total Time 14.00(14.00)\n",
      "Iter 1895 | Time 77.4399(74.8549) | Bit/dim 3.9885(3.9900) | Xent 0.5922(0.5956) | Loss 4.2846(4.2878) | Error 0.2124(0.2146) Steps 808(817.17) | Grad Norm 1.5681(1.2808) | Total Time 14.00(14.00)\n",
      "Iter 1896 | Time 72.5045(74.7844) | Bit/dim 3.9860(3.9899) | Xent 0.6047(0.5959) | Loss 4.2884(4.2878) | Error 0.2190(0.2147) Steps 820(817.25) | Grad Norm 1.3342(1.2824) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 29.9224, Epoch Time 493.7780(496.4847), Bit/dim 3.9950(best: 3.9944), Xent 1.4056, Loss 4.6978, Error 0.4177(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1897 | Time 77.9491(74.8793) | Bit/dim 3.9927(3.9900) | Xent 0.5902(0.5957) | Loss 4.2878(4.2878) | Error 0.2144(0.2147) Steps 820(817.34) | Grad Norm 1.5888(1.2916) | Total Time 14.00(14.00)\n",
      "Iter 1898 | Time 76.7342(74.9350) | Bit/dim 3.9835(3.9898) | Xent 0.5908(0.5956) | Loss 4.2789(4.2876) | Error 0.2125(0.2147) Steps 826(817.60) | Grad Norm 2.6331(1.3318) | Total Time 14.00(14.00)\n",
      "Iter 1899 | Time 76.6682(74.9870) | Bit/dim 3.9831(3.9896) | Xent 0.5776(0.5950) | Loss 4.2719(4.2871) | Error 0.2069(0.2144) Steps 814(817.49) | Grad Norm 1.3043(1.3310) | Total Time 14.00(14.00)\n",
      "Iter 1900 | Time 73.3841(74.9389) | Bit/dim 3.9887(3.9896) | Xent 0.5996(0.5952) | Loss 4.2885(4.2871) | Error 0.2180(0.2145) Steps 802(817.02) | Grad Norm 1.6785(1.3414) | Total Time 14.00(14.00)\n",
      "Iter 1901 | Time 73.5163(74.8962) | Bit/dim 3.9873(3.9895) | Xent 0.5887(0.5950) | Loss 4.2816(4.2870) | Error 0.2115(0.2144) Steps 808(816.75) | Grad Norm 1.7680(1.3542) | Total Time 14.00(14.00)\n",
      "Iter 1902 | Time 77.6858(74.9799) | Bit/dim 3.9957(3.9897) | Xent 0.5920(0.5949) | Loss 4.2917(4.2871) | Error 0.2114(0.2143) Steps 802(816.31) | Grad Norm 1.6704(1.3637) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 29.0510, Epoch Time 500.2577(496.5979), Bit/dim 3.9940(best: 3.9944), Xent 1.3973, Loss 4.6927, Error 0.4163(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1903 | Time 75.8107(75.0048) | Bit/dim 3.9879(3.9896) | Xent 0.5851(0.5946) | Loss 4.2804(4.2869) | Error 0.2121(0.2143) Steps 802(815.88) | Grad Norm 1.5936(1.3706) | Total Time 14.00(14.00)\n",
      "Iter 1904 | Time 74.0611(74.9765) | Bit/dim 4.0023(3.9900) | Xent 0.5966(0.5947) | Loss 4.3005(4.2873) | Error 0.2085(0.2141) Steps 808(815.64) | Grad Norm 1.9752(1.3887) | Total Time 14.00(14.00)\n",
      "Iter 1905 | Time 73.3290(74.9271) | Bit/dim 3.9880(3.9899) | Xent 0.5827(0.5943) | Loss 4.2794(4.2871) | Error 0.2089(0.2139) Steps 802(815.23) | Grad Norm 1.8555(1.4027) | Total Time 14.00(14.00)\n",
      "Iter 1906 | Time 72.5712(74.8564) | Bit/dim 3.9902(3.9900) | Xent 0.5690(0.5935) | Loss 4.2747(4.2867) | Error 0.2039(0.2136) Steps 814(815.20) | Grad Norm 1.4778(1.4050) | Total Time 14.00(14.00)\n",
      "Iter 1907 | Time 75.4851(74.8753) | Bit/dim 3.9816(3.9897) | Xent 0.5829(0.5932) | Loss 4.2730(4.2863) | Error 0.2126(0.2136) Steps 808(814.98) | Grad Norm 1.7006(1.4139) | Total Time 14.00(14.00)\n",
      "Iter 1908 | Time 75.3679(74.8900) | Bit/dim 3.9810(3.9894) | Xent 0.6009(0.5934) | Loss 4.2815(4.2862) | Error 0.2129(0.2136) Steps 808(814.77) | Grad Norm 2.2489(1.4389) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 29.5120, Epoch Time 492.0079(496.4602), Bit/dim 3.9948(best: 3.9940), Xent 1.4039, Loss 4.6967, Error 0.4137(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1909 | Time 74.2925(74.8721) | Bit/dim 3.9863(3.9893) | Xent 0.5809(0.5931) | Loss 4.2767(4.2859) | Error 0.2096(0.2135) Steps 832(815.29) | Grad Norm 1.6547(1.4454) | Total Time 14.00(14.00)\n",
      "Iter 1910 | Time 77.4190(74.9485) | Bit/dim 3.9925(3.9894) | Xent 0.5810(0.5927) | Loss 4.2829(4.2858) | Error 0.2063(0.2133) Steps 814(815.25) | Grad Norm 1.2405(1.4392) | Total Time 14.00(14.00)\n",
      "Iter 1911 | Time 78.3706(75.0512) | Bit/dim 3.9828(3.9892) | Xent 0.5852(0.5925) | Loss 4.2754(4.2855) | Error 0.2084(0.2131) Steps 814(815.21) | Grad Norm 2.1527(1.4606) | Total Time 14.00(14.00)\n",
      "Iter 1912 | Time 75.1919(75.0554) | Bit/dim 3.9908(3.9893) | Xent 0.5767(0.5920) | Loss 4.2791(4.2853) | Error 0.2031(0.2128) Steps 814(815.18) | Grad Norm 1.1179(1.4504) | Total Time 14.00(14.00)\n",
      "Iter 1913 | Time 77.4233(75.1264) | Bit/dim 3.9855(3.9892) | Xent 0.5895(0.5919) | Loss 4.2803(4.2851) | Error 0.2134(0.2128) Steps 826(815.50) | Grad Norm 1.2413(1.4441) | Total Time 14.00(14.00)\n",
      "Iter 1914 | Time 74.9021(75.1197) | Bit/dim 3.9902(3.9892) | Xent 0.5830(0.5917) | Loss 4.2817(4.2850) | Error 0.2059(0.2126) Steps 802(815.10) | Grad Norm 1.0052(1.4309) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 29.6452, Epoch Time 502.8093(496.6507), Bit/dim 3.9934(best: 3.9940), Xent 1.3974, Loss 4.6921, Error 0.4110(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1915 | Time 73.9238(75.0838) | Bit/dim 3.9801(3.9889) | Xent 0.5869(0.5915) | Loss 4.2735(4.2847) | Error 0.2149(0.2127) Steps 820(815.24) | Grad Norm 1.0500(1.4195) | Total Time 14.00(14.00)\n",
      "Iter 1916 | Time 74.8270(75.0761) | Bit/dim 3.9892(3.9889) | Xent 0.5861(0.5914) | Loss 4.2823(4.2846) | Error 0.2116(0.2127) Steps 808(815.03) | Grad Norm 1.2178(1.4135) | Total Time 14.00(14.00)\n",
      "Iter 1917 | Time 75.4719(75.0880) | Bit/dim 3.9955(3.9891) | Xent 0.5929(0.5914) | Loss 4.2920(4.2848) | Error 0.2146(0.2127) Steps 814(815.00) | Grad Norm 1.2761(1.4093) | Total Time 14.00(14.00)\n",
      "Iter 1918 | Time 76.1153(75.1188) | Bit/dim 3.9852(3.9890) | Xent 0.5901(0.5914) | Loss 4.2803(4.2847) | Error 0.2130(0.2127) Steps 808(814.79) | Grad Norm 0.8485(1.3925) | Total Time 14.00(14.00)\n",
      "Iter 1919 | Time 75.8669(75.1413) | Bit/dim 3.9931(3.9891) | Xent 0.5667(0.5906) | Loss 4.2764(4.2845) | Error 0.2066(0.2125) Steps 814(814.76) | Grad Norm 1.4258(1.3935) | Total Time 14.00(14.00)\n",
      "Iter 1920 | Time 72.5262(75.0628) | Bit/dim 3.9814(3.9889) | Xent 0.5781(0.5902) | Loss 4.2704(4.2840) | Error 0.2111(0.2125) Steps 808(814.56) | Grad Norm 1.1164(1.3852) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 29.6639, Epoch Time 494.0342(496.5722), Bit/dim 3.9938(best: 3.9934), Xent 1.3989, Loss 4.6933, Error 0.4135(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1921 | Time 74.0251(75.0317) | Bit/dim 3.9898(3.9889) | Xent 0.5926(0.5903) | Loss 4.2861(4.2841) | Error 0.2107(0.2124) Steps 820(814.72) | Grad Norm 2.2813(1.4121) | Total Time 14.00(14.00)\n",
      "Iter 1922 | Time 76.1248(75.0645) | Bit/dim 3.9924(3.9890) | Xent 0.5723(0.5898) | Loss 4.2785(4.2839) | Error 0.2077(0.2123) Steps 814(814.70) | Grad Norm 1.5372(1.4158) | Total Time 14.00(14.00)\n",
      "Iter 1923 | Time 73.7051(75.0237) | Bit/dim 3.9924(3.9891) | Xent 0.5837(0.5896) | Loss 4.2843(4.2839) | Error 0.2147(0.2124) Steps 814(814.68) | Grad Norm 1.1278(1.4072) | Total Time 14.00(14.00)\n",
      "Iter 1924 | Time 75.0680(75.0250) | Bit/dim 3.9818(3.9889) | Xent 0.5689(0.5890) | Loss 4.2662(4.2834) | Error 0.2055(0.2122) Steps 826(815.02) | Grad Norm 1.0031(1.3951) | Total Time 14.00(14.00)\n",
      "Iter 1925 | Time 74.2322(75.0012) | Bit/dim 3.9807(3.9887) | Xent 0.5883(0.5890) | Loss 4.2749(4.2832) | Error 0.2135(0.2122) Steps 808(814.81) | Grad Norm 1.9223(1.4109) | Total Time 14.00(14.00)\n",
      "Iter 1926 | Time 74.5986(74.9892) | Bit/dim 3.9833(3.9885) | Xent 0.5945(0.5891) | Loss 4.2806(4.2831) | Error 0.2124(0.2122) Steps 820(814.96) | Grad Norm 1.4560(1.4122) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 29.6380, Epoch Time 492.9499(496.4635), Bit/dim 3.9931(best: 3.9934), Xent 1.3970, Loss 4.6916, Error 0.4119(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1927 | Time 77.3820(75.0609) | Bit/dim 3.9940(3.9887) | Xent 0.5707(0.5886) | Loss 4.2793(4.2830) | Error 0.2079(0.2121) Steps 820(815.12) | Grad Norm 1.0548(1.4015) | Total Time 14.00(14.00)\n",
      "Iter 1928 | Time 74.1287(75.0330) | Bit/dim 3.9888(3.9887) | Xent 0.5897(0.5886) | Loss 4.2836(4.2830) | Error 0.2077(0.2120) Steps 808(814.90) | Grad Norm 0.9385(1.3876) | Total Time 14.00(14.00)\n",
      "Iter 1929 | Time 75.9393(75.0602) | Bit/dim 3.9917(3.9888) | Xent 0.5789(0.5883) | Loss 4.2811(4.2829) | Error 0.2031(0.2117) Steps 814(814.87) | Grad Norm 0.9742(1.3752) | Total Time 14.00(14.00)\n",
      "Iter 1930 | Time 72.7970(74.9923) | Bit/dim 3.9756(3.9884) | Xent 0.5762(0.5880) | Loss 4.2637(4.2824) | Error 0.2023(0.2114) Steps 820(815.03) | Grad Norm 1.3296(1.3739) | Total Time 14.00(14.00)\n",
      "Iter 1931 | Time 75.5148(75.0079) | Bit/dim 3.9812(3.9882) | Xent 0.5789(0.5877) | Loss 4.2707(4.2820) | Error 0.2095(0.2113) Steps 814(815.00) | Grad Norm 0.9312(1.3606) | Total Time 14.00(14.00)\n",
      "Iter 1932 | Time 75.3079(75.0169) | Bit/dim 3.9918(3.9883) | Xent 0.5669(0.5871) | Loss 4.2753(4.2818) | Error 0.2003(0.2110) Steps 808(814.79) | Grad Norm 1.7482(1.3722) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 29.7462, Epoch Time 496.4084(496.4619), Bit/dim 3.9930(best: 3.9931), Xent 1.4131, Loss 4.6996, Error 0.4205(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1933 | Time 73.1198(74.9600) | Bit/dim 3.9961(3.9885) | Xent 0.5853(0.5870) | Loss 4.2888(4.2820) | Error 0.2167(0.2112) Steps 814(814.76) | Grad Norm 1.1853(1.3666) | Total Time 14.00(14.00)\n",
      "Iter 1934 | Time 75.3485(74.9717) | Bit/dim 3.9914(3.9886) | Xent 0.5802(0.5868) | Loss 4.2815(4.2820) | Error 0.2050(0.2110) Steps 802(814.38) | Grad Norm 1.1573(1.3603) | Total Time 14.00(14.00)\n",
      "Iter 1935 | Time 74.1064(74.9457) | Bit/dim 3.9774(3.9883) | Xent 0.5696(0.5863) | Loss 4.2622(4.2814) | Error 0.2064(0.2109) Steps 826(814.73) | Grad Norm 1.5021(1.3646) | Total Time 14.00(14.00)\n",
      "Iter 1936 | Time 75.9765(74.9766) | Bit/dim 3.9813(3.9880) | Xent 0.5898(0.5864) | Loss 4.2762(4.2812) | Error 0.2110(0.2109) Steps 820(814.89) | Grad Norm 1.2513(1.3612) | Total Time 14.00(14.00)\n",
      "Iter 1937 | Time 75.4175(74.9899) | Bit/dim 3.9865(3.9880) | Xent 0.5661(0.5858) | Loss 4.2696(4.2809) | Error 0.2063(0.2107) Steps 802(814.50) | Grad Norm 1.5433(1.3666) | Total Time 14.00(14.00)\n",
      "Iter 1938 | Time 74.8573(74.9859) | Bit/dim 3.9854(3.9879) | Xent 0.5914(0.5860) | Loss 4.2811(4.2809) | Error 0.2126(0.2108) Steps 820(814.67) | Grad Norm 1.2537(1.3632) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 29.3867, Epoch Time 493.7220(496.3797), Bit/dim 3.9934(best: 3.9930), Xent 1.4103, Loss 4.6985, Error 0.4143(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1939 | Time 72.2056(74.9025) | Bit/dim 3.9971(3.9882) | Xent 0.5784(0.5857) | Loss 4.2863(4.2811) | Error 0.2116(0.2108) Steps 814(814.65) | Grad Norm 1.2406(1.3596) | Total Time 14.00(14.00)\n",
      "Iter 1940 | Time 73.7649(74.8684) | Bit/dim 3.9863(3.9881) | Xent 0.5850(0.5857) | Loss 4.2788(4.2810) | Error 0.2129(0.2109) Steps 808(814.45) | Grad Norm 2.1786(1.3841) | Total Time 14.00(14.00)\n",
      "Iter 1941 | Time 76.4352(74.9154) | Bit/dim 3.9875(3.9881) | Xent 0.5650(0.5851) | Loss 4.2700(4.2807) | Error 0.2033(0.2106) Steps 808(814.25) | Grad Norm 1.9876(1.4022) | Total Time 14.00(14.00)\n",
      "Iter 1942 | Time 75.2233(74.9246) | Bit/dim 3.9771(3.9878) | Xent 0.5726(0.5847) | Loss 4.2634(4.2801) | Error 0.2023(0.2104) Steps 808(814.07) | Grad Norm 1.1496(1.3947) | Total Time 14.00(14.00)\n",
      "Iter 1943 | Time 73.3900(74.8786) | Bit/dim 3.9848(3.9877) | Xent 0.5796(0.5846) | Loss 4.2746(4.2800) | Error 0.2106(0.2104) Steps 814(814.06) | Grad Norm 2.0108(1.4132) | Total Time 14.00(14.00)\n",
      "Iter 1944 | Time 73.9143(74.8496) | Bit/dim 3.9879(3.9877) | Xent 0.5696(0.5841) | Loss 4.2727(4.2798) | Error 0.2053(0.2102) Steps 814(814.06) | Grad Norm 1.8752(1.4270) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 29.5185, Epoch Time 490.1062(496.1915), Bit/dim 3.9913(best: 3.9930), Xent 1.4140, Loss 4.6983, Error 0.4170(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1945 | Time 77.0662(74.9161) | Bit/dim 3.9883(3.9877) | Xent 0.5673(0.5836) | Loss 4.2720(4.2795) | Error 0.2005(0.2100) Steps 820(814.24) | Grad Norm 1.3881(1.4258) | Total Time 14.00(14.00)\n",
      "Iter 1946 | Time 73.5340(74.8747) | Bit/dim 3.9828(3.9876) | Xent 0.5842(0.5836) | Loss 4.2749(4.2794) | Error 0.2054(0.2098) Steps 826(814.59) | Grad Norm 1.3905(1.4248) | Total Time 14.00(14.00)\n",
      "Iter 1947 | Time 74.2237(74.8551) | Bit/dim 3.9816(3.9874) | Xent 0.5702(0.5832) | Loss 4.2667(4.2790) | Error 0.2081(0.2098) Steps 820(814.76) | Grad Norm 1.5844(1.4296) | Total Time 14.00(14.00)\n",
      "Iter 1948 | Time 74.9716(74.8586) | Bit/dim 3.9865(3.9874) | Xent 0.5669(0.5827) | Loss 4.2699(4.2787) | Error 0.2066(0.2097) Steps 832(815.27) | Grad Norm 1.4586(1.4304) | Total Time 14.00(14.00)\n",
      "Iter 1949 | Time 75.6108(74.8812) | Bit/dim 3.9930(3.9875) | Xent 0.5971(0.5832) | Loss 4.2915(4.2791) | Error 0.2143(0.2098) Steps 820(815.41) | Grad Norm 1.3640(1.4285) | Total Time 14.00(14.00)\n",
      "Iter 1950 | Time 77.2780(74.9531) | Bit/dim 3.9814(3.9874) | Xent 0.5678(0.5827) | Loss 4.2653(4.2787) | Error 0.2049(0.2097) Steps 814(815.37) | Grad Norm 1.6332(1.4346) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 30.0936, Epoch Time 498.3237(496.2554), Bit/dim 3.9919(best: 3.9913), Xent 1.4144, Loss 4.6990, Error 0.4159(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1951 | Time 71.6396(74.8537) | Bit/dim 3.9827(3.9872) | Xent 0.5886(0.5829) | Loss 4.2769(4.2787) | Error 0.2099(0.2097) Steps 808(815.15) | Grad Norm 1.2459(1.4289) | Total Time 14.00(14.00)\n",
      "Iter 1952 | Time 75.0802(74.8605) | Bit/dim 3.9877(3.9872) | Xent 0.5684(0.5824) | Loss 4.2719(4.2784) | Error 0.2033(0.2095) Steps 826(815.48) | Grad Norm 1.7483(1.4385) | Total Time 14.00(14.00)\n",
      "Iter 1953 | Time 76.0349(74.8957) | Bit/dim 3.9804(3.9870) | Xent 0.5574(0.5817) | Loss 4.2591(4.2779) | Error 0.1999(0.2092) Steps 820(815.61) | Grad Norm 1.1500(1.4299) | Total Time 14.00(14.00)\n",
      "Iter 1954 | Time 74.1808(74.8743) | Bit/dim 3.9863(3.9870) | Xent 0.5830(0.5817) | Loss 4.2778(4.2779) | Error 0.2083(0.2092) Steps 808(815.38) | Grad Norm 1.2729(1.4252) | Total Time 14.00(14.00)\n",
      "Iter 1955 | Time 76.2120(74.9144) | Bit/dim 3.9886(3.9871) | Xent 0.5619(0.5811) | Loss 4.2695(4.2776) | Error 0.2016(0.2089) Steps 814(815.34) | Grad Norm 2.6580(1.4621) | Total Time 14.00(14.00)\n",
      "Iter 1956 | Time 76.5330(74.9630) | Bit/dim 3.9917(3.9872) | Xent 0.5801(0.5811) | Loss 4.2817(4.2777) | Error 0.2085(0.2089) Steps 808(815.12) | Grad Norm 1.0816(1.4507) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 29.9595, Epoch Time 495.1676(496.2228), Bit/dim 3.9921(best: 3.9913), Xent 1.4249, Loss 4.7045, Error 0.4151(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1957 | Time 77.1866(75.0297) | Bit/dim 3.9834(3.9871) | Xent 0.5657(0.5806) | Loss 4.2662(4.2774) | Error 0.2063(0.2088) Steps 802(814.73) | Grad Norm 1.3136(1.4466) | Total Time 14.00(14.00)\n",
      "Iter 1958 | Time 76.5881(75.0764) | Bit/dim 3.9919(3.9872) | Xent 0.5536(0.5798) | Loss 4.2687(4.2771) | Error 0.2029(0.2087) Steps 808(814.53) | Grad Norm 1.1920(1.4390) | Total Time 14.00(14.00)\n",
      "Iter 1959 | Time 73.9465(75.0425) | Bit/dim 3.9826(3.9871) | Xent 0.5683(0.5795) | Loss 4.2667(4.2768) | Error 0.1983(0.2083) Steps 832(815.05) | Grad Norm 1.7554(1.4485) | Total Time 14.00(14.00)\n",
      "Iter 1960 | Time 75.2444(75.0486) | Bit/dim 3.9788(3.9868) | Xent 0.5629(0.5790) | Loss 4.2603(4.2763) | Error 0.2053(0.2083) Steps 820(815.20) | Grad Norm 1.0730(1.4372) | Total Time 14.00(14.00)\n",
      "Iter 1961 | Time 75.9659(75.0761) | Bit/dim 3.9871(3.9868) | Xent 0.5882(0.5793) | Loss 4.2812(4.2765) | Error 0.2151(0.2085) Steps 808(814.98) | Grad Norm 1.7584(1.4468) | Total Time 14.00(14.00)\n",
      "Iter 1962 | Time 74.2445(75.0512) | Bit/dim 3.9861(3.9868) | Xent 0.5686(0.5789) | Loss 4.2704(4.2763) | Error 0.2039(0.2083) Steps 826(815.31) | Grad Norm 0.8692(1.4295) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 29.9149, Epoch Time 498.6171(496.2946), Bit/dim 3.9914(best: 3.9913), Xent 1.4291, Loss 4.7060, Error 0.4156(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1963 | Time 75.4773(75.0639) | Bit/dim 3.9935(3.9870) | Xent 0.5646(0.5785) | Loss 4.2758(4.2763) | Error 0.2054(0.2082) Steps 814(815.27) | Grad Norm 1.0482(1.4181) | Total Time 14.00(14.00)\n",
      "Iter 1964 | Time 75.9933(75.0918) | Bit/dim 3.9906(3.9871) | Xent 0.5632(0.5781) | Loss 4.2722(4.2762) | Error 0.2026(0.2081) Steps 802(814.88) | Grad Norm 0.8854(1.4021) | Total Time 14.00(14.00)\n",
      "Iter 1965 | Time 77.1992(75.1550) | Bit/dim 3.9853(3.9871) | Xent 0.5611(0.5775) | Loss 4.2659(4.2758) | Error 0.2004(0.2078) Steps 814(814.85) | Grad Norm 0.9872(1.3896) | Total Time 14.00(14.00)\n",
      "Iter 1966 | Time 74.7275(75.1422) | Bit/dim 3.9784(3.9868) | Xent 0.5606(0.5770) | Loss 4.2587(4.2753) | Error 0.1990(0.2076) Steps 814(814.82) | Grad Norm 1.5693(1.3950) | Total Time 14.00(14.00)\n",
      "Iter 1967 | Time 74.3845(75.1195) | Bit/dim 3.9920(3.9870) | Xent 0.5664(0.5767) | Loss 4.2752(4.2753) | Error 0.2070(0.2076) Steps 808(814.62) | Grad Norm 1.4575(1.3969) | Total Time 14.00(14.00)\n",
      "Iter 1968 | Time 74.2267(75.0927) | Bit/dim 3.9705(3.9865) | Xent 0.5821(0.5769) | Loss 4.2616(4.2749) | Error 0.2027(0.2074) Steps 814(814.60) | Grad Norm 1.2585(1.3927) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 30.2512, Epoch Time 497.8384(496.3409), Bit/dim 3.9914(best: 3.9913), Xent 1.4335, Loss 4.7082, Error 0.4128(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1969 | Time 72.6666(75.0199) | Bit/dim 3.9883(3.9865) | Xent 0.5740(0.5768) | Loss 4.2753(4.2749) | Error 0.2083(0.2074) Steps 814(814.58) | Grad Norm 1.0607(1.3828) | Total Time 14.00(14.00)\n",
      "Iter 1970 | Time 74.8862(75.0159) | Bit/dim 3.9782(3.9863) | Xent 0.5746(0.5767) | Loss 4.2655(4.2746) | Error 0.2105(0.2075) Steps 820(814.75) | Grad Norm 1.1110(1.3746) | Total Time 14.00(14.00)\n",
      "Iter 1971 | Time 72.1779(74.9308) | Bit/dim 3.9870(3.9863) | Xent 0.5719(0.5766) | Loss 4.2729(4.2746) | Error 0.2034(0.2074) Steps 820(814.90) | Grad Norm 0.9736(1.3626) | Total Time 14.00(14.00)\n",
      "Iter 1972 | Time 72.1944(74.8487) | Bit/dim 3.9857(3.9863) | Xent 0.5750(0.5765) | Loss 4.2732(4.2745) | Error 0.2051(0.2073) Steps 820(815.06) | Grad Norm 1.2663(1.3597) | Total Time 14.00(14.00)\n",
      "Iter 1973 | Time 76.1491(74.8877) | Bit/dim 3.9848(3.9862) | Xent 0.5530(0.5758) | Loss 4.2613(4.2742) | Error 0.2024(0.2072) Steps 814(815.02) | Grad Norm 1.6397(1.3681) | Total Time 14.00(14.00)\n",
      "Iter 1974 | Time 74.2696(74.8691) | Bit/dim 3.9879(3.9863) | Xent 0.5712(0.5757) | Loss 4.2735(4.2741) | Error 0.2069(0.2072) Steps 814(814.99) | Grad Norm 1.3074(1.3663) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 29.6088, Epoch Time 487.5145(496.0761), Bit/dim 3.9908(best: 3.9913), Xent 1.4294, Loss 4.7055, Error 0.4167(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1975 | Time 76.1418(74.9073) | Bit/dim 3.9833(3.9862) | Xent 0.5538(0.5750) | Loss 4.2602(4.2737) | Error 0.1961(0.2068) Steps 820(815.14) | Grad Norm 1.6714(1.3754) | Total Time 14.00(14.00)\n",
      "Iter 1976 | Time 74.8490(74.9056) | Bit/dim 3.9926(3.9864) | Xent 0.5510(0.5743) | Loss 4.2681(4.2735) | Error 0.1965(0.2065) Steps 808(814.93) | Grad Norm 1.4534(1.3778) | Total Time 14.00(14.00)\n",
      "Iter 1977 | Time 73.2371(74.8555) | Bit/dim 3.9875(3.9864) | Xent 0.5554(0.5737) | Loss 4.2652(4.2733) | Error 0.2046(0.2065) Steps 820(815.08) | Grad Norm 1.3797(1.3778) | Total Time 14.00(14.00)\n",
      "Iter 1978 | Time 74.7658(74.8528) | Bit/dim 3.9811(3.9863) | Xent 0.5779(0.5739) | Loss 4.2700(4.2732) | Error 0.2105(0.2066) Steps 826(815.41) | Grad Norm 1.4002(1.3785) | Total Time 14.00(14.00)\n",
      "Iter 1979 | Time 76.8599(74.9130) | Bit/dim 3.9829(3.9862) | Xent 0.5602(0.5735) | Loss 4.2630(4.2729) | Error 0.1999(0.2064) Steps 814(815.37) | Grad Norm 1.3880(1.3788) | Total Time 14.00(14.00)\n",
      "Iter 1980 | Time 77.7125(74.9970) | Bit/dim 3.9808(3.9860) | Xent 0.5798(0.5737) | Loss 4.2707(4.2728) | Error 0.2090(0.2065) Steps 814(815.33) | Grad Norm 2.2825(1.4059) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 30.0316, Epoch Time 499.2339(496.1709), Bit/dim 3.9916(best: 3.9908), Xent 1.4331, Loss 4.7082, Error 0.4151(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1981 | Time 74.3090(74.9764) | Bit/dim 3.9856(3.9860) | Xent 0.5576(0.5732) | Loss 4.2644(4.2726) | Error 0.2009(0.2063) Steps 820(815.47) | Grad Norm 1.7500(1.4162) | Total Time 14.00(14.00)\n",
      "Iter 1982 | Time 74.0680(74.9491) | Bit/dim 3.9843(3.9859) | Xent 0.5666(0.5730) | Loss 4.2676(4.2724) | Error 0.2095(0.2064) Steps 820(815.60) | Grad Norm 1.1187(1.4073) | Total Time 14.00(14.00)\n",
      "Iter 1983 | Time 73.5709(74.9078) | Bit/dim 3.9794(3.9857) | Xent 0.5703(0.5729) | Loss 4.2645(4.2722) | Error 0.2086(0.2065) Steps 808(815.37) | Grad Norm 1.4527(1.4087) | Total Time 14.00(14.00)\n",
      "Iter 1984 | Time 75.3573(74.9213) | Bit/dim 3.9891(3.9858) | Xent 0.5755(0.5730) | Loss 4.2768(4.2723) | Error 0.2051(0.2064) Steps 808(815.15) | Grad Norm 1.9068(1.4236) | Total Time 14.00(14.00)\n",
      "Iter 1985 | Time 74.3147(74.9031) | Bit/dim 3.9766(3.9856) | Xent 0.5505(0.5723) | Loss 4.2519(4.2717) | Error 0.2006(0.2063) Steps 808(814.94) | Grad Norm 1.1296(1.4148) | Total Time 14.00(14.00)\n",
      "Iter 1986 | Time 76.3528(74.9466) | Bit/dim 3.9904(3.9857) | Xent 0.5736(0.5723) | Loss 4.2772(4.2719) | Error 0.2084(0.2063) Steps 832(815.45) | Grad Norm 1.1305(1.4063) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 29.9529, Epoch Time 493.6743(496.0960), Bit/dim 3.9923(best: 3.9908), Xent 1.4395, Loss 4.7121, Error 0.4134(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1987 | Time 73.6861(74.9088) | Bit/dim 3.9932(3.9859) | Xent 0.5774(0.5725) | Loss 4.2819(4.2722) | Error 0.2043(0.2063) Steps 814(815.41) | Grad Norm 0.9769(1.3934) | Total Time 14.00(14.00)\n",
      "Iter 1988 | Time 73.9165(74.8790) | Bit/dim 3.9877(3.9860) | Xent 0.5518(0.5719) | Loss 4.2636(4.2719) | Error 0.2009(0.2061) Steps 802(815.00) | Grad Norm 1.5156(1.3970) | Total Time 14.00(14.00)\n",
      "Iter 1989 | Time 74.1283(74.8565) | Bit/dim 3.9907(3.9861) | Xent 0.5612(0.5715) | Loss 4.2712(4.2719) | Error 0.2009(0.2059) Steps 826(815.33) | Grad Norm 1.2300(1.3920) | Total Time 14.00(14.00)\n",
      "Iter 1990 | Time 72.4002(74.7828) | Bit/dim 3.9767(3.9858) | Xent 0.5774(0.5717) | Loss 4.2654(4.2717) | Error 0.2133(0.2062) Steps 814(815.29) | Grad Norm 1.0281(1.3811) | Total Time 14.00(14.00)\n",
      "Iter 1991 | Time 72.4951(74.7141) | Bit/dim 3.9833(3.9858) | Xent 0.5538(0.5712) | Loss 4.2601(4.2714) | Error 0.1996(0.2060) Steps 820(815.44) | Grad Norm 1.2299(1.3766) | Total Time 14.00(14.00)\n",
      "Iter 1992 | Time 73.9131(74.6901) | Bit/dim 3.9767(3.9855) | Xent 0.5668(0.5710) | Loss 4.2601(4.2710) | Error 0.2079(0.2060) Steps 820(815.57) | Grad Norm 1.8042(1.3894) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 29.5678, Epoch Time 485.7016(495.7841), Bit/dim 3.9908(best: 3.9908), Xent 1.4284, Loss 4.7050, Error 0.4156(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1993 | Time 75.0107(74.6997) | Bit/dim 3.9741(3.9851) | Xent 0.5682(0.5710) | Loss 4.2582(4.2706) | Error 0.2086(0.2061) Steps 808(815.35) | Grad Norm 1.6890(1.3984) | Total Time 14.00(14.00)\n",
      "Iter 1994 | Time 73.7376(74.6709) | Bit/dim 3.9907(3.9853) | Xent 0.5457(0.5702) | Loss 4.2636(4.2704) | Error 0.1945(0.2057) Steps 820(815.48) | Grad Norm 0.9828(1.3859) | Total Time 14.00(14.00)\n",
      "Iter 1995 | Time 75.2974(74.6897) | Bit/dim 3.9927(3.9855) | Xent 0.5599(0.5699) | Loss 4.2727(4.2705) | Error 0.2053(0.2057) Steps 814(815.44) | Grad Norm 1.3066(1.3835) | Total Time 14.00(14.00)\n",
      "Iter 1996 | Time 76.1068(74.7322) | Bit/dim 3.9849(3.9855) | Xent 0.5633(0.5697) | Loss 4.2666(4.2704) | Error 0.2061(0.2057) Steps 820(815.58) | Grad Norm 1.1243(1.3758) | Total Time 14.00(14.00)\n",
      "Iter 1997 | Time 74.4260(74.7230) | Bit/dim 3.9872(3.9856) | Xent 0.5759(0.5699) | Loss 4.2752(4.2705) | Error 0.2106(0.2059) Steps 814(815.53) | Grad Norm 1.8424(1.3898) | Total Time 14.00(14.00)\n",
      "Iter 1998 | Time 76.6936(74.7821) | Bit/dim 3.9773(3.9853) | Xent 0.5683(0.5698) | Loss 4.2615(4.2702) | Error 0.2047(0.2059) Steps 826(815.84) | Grad Norm 1.3721(1.3892) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 29.8991, Epoch Time 496.6941(495.8114), Bit/dim 3.9916(best: 3.9908), Xent 1.4394, Loss 4.7112, Error 0.4174(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1999 | Time 75.9071(74.8159) | Bit/dim 3.9832(3.9853) | Xent 0.5548(0.5694) | Loss 4.2606(4.2700) | Error 0.1996(0.2057) Steps 808(815.61) | Grad Norm 1.6878(1.3982) | Total Time 14.00(14.00)\n",
      "Iter 2000 | Time 75.8981(74.8483) | Bit/dim 3.9827(3.9852) | Xent 0.5624(0.5692) | Loss 4.2639(4.2698) | Error 0.2044(0.2056) Steps 814(815.56) | Grad Norm 1.0745(1.3885) | Total Time 14.00(14.00)\n",
      "Iter 2001 | Time 72.5324(74.7788) | Bit/dim 3.9792(3.9850) | Xent 0.5580(0.5688) | Loss 4.2581(4.2694) | Error 0.2006(0.2055) Steps 814(815.51) | Grad Norm 1.3691(1.3879) | Total Time 14.00(14.00)\n",
      "Iter 2002 | Time 76.2884(74.8241) | Bit/dim 3.9863(3.9850) | Xent 0.5691(0.5688) | Loss 4.2709(4.2695) | Error 0.2047(0.2055) Steps 820(815.65) | Grad Norm 1.4448(1.3896) | Total Time 14.00(14.00)\n",
      "Iter 2003 | Time 74.3166(74.8089) | Bit/dim 3.9879(3.9851) | Xent 0.5654(0.5687) | Loss 4.2706(4.2695) | Error 0.2011(0.2053) Steps 808(815.42) | Grad Norm 1.4378(1.3911) | Total Time 14.00(14.00)\n",
      "Iter 2004 | Time 74.4883(74.7993) | Bit/dim 3.9792(3.9849) | Xent 0.5599(0.5685) | Loss 4.2592(4.2692) | Error 0.1996(0.2052) Steps 808(815.20) | Grad Norm 1.0152(1.3798) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 29.7657, Epoch Time 494.7788(495.7805), Bit/dim 3.9902(best: 3.9908), Xent 1.4333, Loss 4.7068, Error 0.4143(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2005 | Time 73.7376(74.7674) | Bit/dim 3.9823(3.9849) | Xent 0.5590(0.5682) | Loss 4.2618(4.2690) | Error 0.2045(0.2051) Steps 814(815.16) | Grad Norm 1.3940(1.3802) | Total Time 14.00(14.00)\n",
      "Iter 2006 | Time 71.3221(74.6641) | Bit/dim 3.9829(3.9848) | Xent 0.5582(0.5679) | Loss 4.2621(4.2688) | Error 0.2027(0.2051) Steps 808(814.95) | Grad Norm 1.4356(1.3819) | Total Time 14.00(14.00)\n",
      "Iter 2007 | Time 75.4242(74.6869) | Bit/dim 3.9862(3.9849) | Xent 0.5429(0.5671) | Loss 4.2577(4.2684) | Error 0.1921(0.2047) Steps 820(815.10) | Grad Norm 2.2272(1.4072) | Total Time 14.00(14.00)\n",
      "Iter 2008 | Time 74.4090(74.6785) | Bit/dim 3.9804(3.9847) | Xent 0.5494(0.5666) | Loss 4.2551(4.2680) | Error 0.1981(0.2045) Steps 820(815.24) | Grad Norm 1.2863(1.4036) | Total Time 14.00(14.00)\n",
      "Iter 2009 | Time 72.5243(74.6139) | Bit/dim 3.9896(3.9849) | Xent 0.5747(0.5669) | Loss 4.2770(4.2683) | Error 0.2039(0.2045) Steps 808(815.03) | Grad Norm 1.6571(1.4112) | Total Time 14.00(14.00)\n",
      "Iter 2010 | Time 75.9539(74.6541) | Bit/dim 3.9776(3.9847) | Xent 0.5531(0.5664) | Loss 4.2541(4.2679) | Error 0.1984(0.2043) Steps 814(815.00) | Grad Norm 2.1715(1.4340) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 29.7439, Epoch Time 488.7787(495.5704), Bit/dim 3.9900(best: 3.9902), Xent 1.4468, Loss 4.7134, Error 0.4161(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2011 | Time 72.1633(74.5794) | Bit/dim 3.9865(3.9847) | Xent 0.5505(0.5660) | Loss 4.2618(4.2677) | Error 0.2027(0.2042) Steps 826(815.33) | Grad Norm 2.0981(1.4539) | Total Time 14.00(14.00)\n",
      "Iter 2012 | Time 75.6755(74.6123) | Bit/dim 3.9798(3.9846) | Xent 0.5699(0.5661) | Loss 4.2648(4.2676) | Error 0.2047(0.2043) Steps 808(815.11) | Grad Norm 1.1314(1.4443) | Total Time 14.00(14.00)\n",
      "Iter 2013 | Time 74.4111(74.6062) | Bit/dim 3.9796(3.9844) | Xent 0.5540(0.5657) | Loss 4.2566(4.2673) | Error 0.2013(0.2042) Steps 820(815.25) | Grad Norm 1.7497(1.4534) | Total Time 14.00(14.00)\n",
      "Iter 2014 | Time 73.4897(74.5727) | Bit/dim 3.9744(3.9841) | Xent 0.5539(0.5654) | Loss 4.2514(4.2668) | Error 0.2013(0.2041) Steps 826(815.58) | Grad Norm 1.8092(1.4641) | Total Time 14.00(14.00)\n",
      "Iter 2015 | Time 73.6879(74.5462) | Bit/dim 3.9842(3.9841) | Xent 0.5620(0.5653) | Loss 4.2652(4.2667) | Error 0.2029(0.2040) Steps 826(815.89) | Grad Norm 1.6345(1.4692) | Total Time 14.00(14.00)\n",
      "Iter 2016 | Time 75.8243(74.5845) | Bit/dim 3.9935(3.9844) | Xent 0.5669(0.5653) | Loss 4.2769(4.2671) | Error 0.2060(0.2041) Steps 820(816.01) | Grad Norm 1.5167(1.4706) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 29.9327, Epoch Time 490.8599(495.4291), Bit/dim 3.9894(best: 3.9900), Xent 1.4470, Loss 4.7130, Error 0.4182(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2017 | Time 73.9318(74.5650) | Bit/dim 3.9818(3.9843) | Xent 0.5663(0.5653) | Loss 4.2649(4.2670) | Error 0.2033(0.2041) Steps 820(816.13) | Grad Norm 1.2464(1.4639) | Total Time 14.00(14.00)\n",
      "Iter 2018 | Time 75.9573(74.6067) | Bit/dim 3.9891(3.9845) | Xent 0.5476(0.5648) | Loss 4.2629(4.2669) | Error 0.1930(0.2037) Steps 808(815.89) | Grad Norm 1.4665(1.4640) | Total Time 14.00(14.00)\n",
      "Iter 2019 | Time 74.9156(74.6160) | Bit/dim 3.9868(3.9845) | Xent 0.5528(0.5644) | Loss 4.2632(4.2668) | Error 0.1980(0.2036) Steps 820(816.01) | Grad Norm 1.8620(1.4759) | Total Time 14.00(14.00)\n",
      "Iter 2020 | Time 74.1660(74.6025) | Bit/dim 3.9654(3.9840) | Xent 0.5672(0.5645) | Loss 4.2489(4.2662) | Error 0.2059(0.2036) Steps 820(816.13) | Grad Norm 1.8999(1.4887) | Total Time 14.00(14.00)\n",
      "Iter 2021 | Time 76.8759(74.6707) | Bit/dim 3.9929(3.9842) | Xent 0.5553(0.5643) | Loss 4.2705(4.2663) | Error 0.2001(0.2035) Steps 820(816.25) | Grad Norm 1.1557(1.4787) | Total Time 14.00(14.00)\n",
      "Iter 2022 | Time 74.6513(74.6701) | Bit/dim 3.9846(3.9842) | Xent 0.5556(0.5640) | Loss 4.2623(4.2662) | Error 0.2060(0.2036) Steps 820(816.36) | Grad Norm 1.3385(1.4745) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 29.5708, Epoch Time 495.4254(495.4290), Bit/dim 3.9899(best: 3.9894), Xent 1.4522, Loss 4.7160, Error 0.4148(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2023 | Time 73.7306(74.6419) | Bit/dim 3.9925(3.9845) | Xent 0.5587(0.5638) | Loss 4.2719(4.2664) | Error 0.1981(0.2034) Steps 832(816.83) | Grad Norm 1.3882(1.4719) | Total Time 14.00(14.00)\n",
      "Iter 2024 | Time 73.3896(74.6044) | Bit/dim 3.9714(3.9841) | Xent 0.5459(0.5633) | Loss 4.2443(4.2657) | Error 0.1991(0.2033) Steps 820(816.92) | Grad Norm 1.1998(1.4637) | Total Time 14.00(14.00)\n",
      "Iter 2025 | Time 78.0472(74.7077) | Bit/dim 3.9797(3.9840) | Xent 0.5390(0.5626) | Loss 4.2492(4.2652) | Error 0.1996(0.2032) Steps 820(817.02) | Grad Norm 1.1521(1.4544) | Total Time 14.00(14.00)\n",
      "Iter 2026 | Time 71.0729(74.5986) | Bit/dim 3.9861(3.9840) | Xent 0.5561(0.5624) | Loss 4.2642(4.2652) | Error 0.1965(0.2030) Steps 808(816.75) | Grad Norm 1.5050(1.4559) | Total Time 14.00(14.00)\n",
      "Iter 2027 | Time 74.1975(74.5866) | Bit/dim 3.9827(3.9840) | Xent 0.5475(0.5619) | Loss 4.2565(4.2649) | Error 0.1983(0.2029) Steps 820(816.84) | Grad Norm 1.2423(1.4495) | Total Time 14.00(14.00)\n",
      "Iter 2028 | Time 71.8094(74.5033) | Bit/dim 3.9872(3.9841) | Xent 0.5669(0.5621) | Loss 4.2707(4.2651) | Error 0.2023(0.2028) Steps 814(816.76) | Grad Norm 0.9404(1.4342) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 29.9675, Epoch Time 487.7050(495.1973), Bit/dim 3.9887(best: 3.9894), Xent 1.4473, Loss 4.7123, Error 0.4164(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2029 | Time 77.1346(74.5822) | Bit/dim 3.9781(3.9839) | Xent 0.5407(0.5614) | Loss 4.2484(4.2646) | Error 0.1931(0.2025) Steps 814(816.67) | Grad Norm 0.9786(1.4205) | Total Time 14.00(14.00)\n",
      "Iter 2030 | Time 71.9943(74.5046) | Bit/dim 3.9850(3.9839) | Xent 0.5484(0.5610) | Loss 4.2592(4.2645) | Error 0.1989(0.2024) Steps 826(816.95) | Grad Norm 1.7728(1.4311) | Total Time 14.00(14.00)\n",
      "Iter 2031 | Time 74.3831(74.5009) | Bit/dim 3.9923(3.9842) | Xent 0.5433(0.5605) | Loss 4.2640(4.2644) | Error 0.1956(0.2022) Steps 814(816.87) | Grad Norm 1.3904(1.4299) | Total Time 14.00(14.00)\n",
      "Iter 2032 | Time 72.2070(74.4321) | Bit/dim 3.9794(3.9840) | Xent 0.5554(0.5604) | Loss 4.2571(4.2642) | Error 0.1969(0.2021) Steps 820(816.96) | Grad Norm 2.0029(1.4471) | Total Time 14.00(14.00)\n",
      "Iter 2033 | Time 75.6413(74.4684) | Bit/dim 3.9840(3.9840) | Xent 0.5616(0.5604) | Loss 4.2648(4.2642) | Error 0.2025(0.2021) Steps 808(816.69) | Grad Norm 1.1285(1.4375) | Total Time 14.00(14.00)\n",
      "Iter 2034 | Time 76.6094(74.5326) | Bit/dim 3.9801(3.9839) | Xent 0.5673(0.5606) | Loss 4.2638(4.2642) | Error 0.2034(0.2021) Steps 832(817.15) | Grad Norm 1.9868(1.4540) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 29.6687, Epoch Time 493.6689(495.1514), Bit/dim 3.9896(best: 3.9887), Xent 1.4632, Loss 4.7212, Error 0.4176(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2035 | Time 74.6811(74.5371) | Bit/dim 3.9782(3.9837) | Xent 0.5481(0.5602) | Loss 4.2523(4.2639) | Error 0.1973(0.2020) Steps 820(817.24) | Grad Norm 1.4356(1.4534) | Total Time 14.00(14.00)\n",
      "Iter 2036 | Time 74.9404(74.5492) | Bit/dim 3.9785(3.9836) | Xent 0.5421(0.5597) | Loss 4.2496(4.2634) | Error 0.1951(0.2018) Steps 808(816.96) | Grad Norm 1.3719(1.4510) | Total Time 14.00(14.00)\n",
      "Iter 2037 | Time 77.4647(74.6366) | Bit/dim 3.9841(3.9836) | Xent 0.5477(0.5593) | Loss 4.2579(4.2633) | Error 0.1954(0.2016) Steps 826(817.23) | Grad Norm 1.9757(1.4667) | Total Time 14.00(14.00)\n",
      "Iter 2038 | Time 73.6028(74.6056) | Bit/dim 3.9766(3.9834) | Xent 0.5471(0.5590) | Loss 4.2502(4.2629) | Error 0.2039(0.2016) Steps 814(817.13) | Grad Norm 1.6758(1.4730) | Total Time 14.00(14.00)\n",
      "Iter 2039 | Time 74.3555(74.5981) | Bit/dim 3.9849(3.9834) | Xent 0.5460(0.5586) | Loss 4.2579(4.2627) | Error 0.1961(0.2015) Steps 820(817.22) | Grad Norm 1.8365(1.4839) | Total Time 14.00(14.00)\n",
      "Iter 2040 | Time 74.4545(74.5938) | Bit/dim 3.9904(3.9837) | Xent 0.5518(0.5584) | Loss 4.2663(4.2628) | Error 0.2004(0.2014) Steps 820(817.30) | Grad Norm 2.8840(1.5259) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 30.0278, Epoch Time 495.1835(495.1524), Bit/dim 3.9891(best: 3.9887), Xent 1.4541, Loss 4.7161, Error 0.4152(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2041 | Time 74.8074(74.6002) | Bit/dim 3.9879(3.9838) | Xent 0.5511(0.5581) | Loss 4.2634(4.2629) | Error 0.1961(0.2013) Steps 826(817.56) | Grad Norm 2.0967(1.5430) | Total Time 14.00(14.00)\n",
      "Iter 2042 | Time 73.9903(74.5819) | Bit/dim 3.9779(3.9836) | Xent 0.5407(0.5576) | Loss 4.2483(4.2624) | Error 0.1974(0.2012) Steps 826(817.82) | Grad Norm 1.0508(1.5283) | Total Time 14.00(14.00)\n",
      "Iter 2043 | Time 77.1161(74.6579) | Bit/dim 3.9807(3.9835) | Xent 0.5551(0.5576) | Loss 4.2582(4.2623) | Error 0.1959(0.2010) Steps 820(817.88) | Grad Norm 2.1548(1.5471) | Total Time 14.00(14.00)\n",
      "Iter 2044 | Time 71.7266(74.5700) | Bit/dim 3.9896(3.9837) | Xent 0.5478(0.5573) | Loss 4.2635(4.2623) | Error 0.2021(0.2010) Steps 814(817.77) | Grad Norm 2.9498(1.5891) | Total Time 14.00(14.00)\n",
      "Iter 2045 | Time 76.4498(74.6264) | Bit/dim 3.9737(3.9834) | Xent 0.5593(0.5573) | Loss 4.2534(4.2621) | Error 0.2044(0.2011) Steps 820(817.83) | Grad Norm 1.0498(1.5730) | Total Time 14.00(14.00)\n",
      "Iter 2046 | Time 74.3489(74.6181) | Bit/dim 3.9779(3.9832) | Xent 0.5600(0.5574) | Loss 4.2579(4.2619) | Error 0.2039(0.2012) Steps 808(817.54) | Grad Norm 1.7673(1.5788) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 29.8455, Epoch Time 494.0790(495.1202), Bit/dim 3.9898(best: 3.9887), Xent 1.4617, Loss 4.7206, Error 0.4182(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2047 | Time 76.3636(74.6704) | Bit/dim 3.9801(3.9831) | Xent 0.5531(0.5573) | Loss 4.2567(4.2618) | Error 0.1961(0.2011) Steps 808(817.25) | Grad Norm 1.5317(1.5774) | Total Time 14.00(14.00)\n",
      "Iter 2048 | Time 78.0990(74.7733) | Bit/dim 3.9792(3.9830) | Xent 0.5439(0.5569) | Loss 4.2512(4.2615) | Error 0.1931(0.2008) Steps 814(817.15) | Grad Norm 1.3882(1.5717) | Total Time 14.00(14.00)\n",
      "Iter 2049 | Time 73.9966(74.7500) | Bit/dim 3.9759(3.9828) | Xent 0.5601(0.5570) | Loss 4.2559(4.2613) | Error 0.2029(0.2009) Steps 820(817.24) | Grad Norm 1.3467(1.5650) | Total Time 14.00(14.00)\n",
      "Iter 2050 | Time 74.6824(74.7480) | Bit/dim 3.9832(3.9828) | Xent 0.5422(0.5565) | Loss 4.2542(4.2611) | Error 0.1984(0.2008) Steps 808(816.96) | Grad Norm 1.5738(1.5652) | Total Time 14.00(14.00)\n",
      "Iter 2051 | Time 77.4988(74.8305) | Bit/dim 3.9813(3.9828) | Xent 0.5714(0.5570) | Loss 4.2671(4.2613) | Error 0.2029(0.2009) Steps 814(816.87) | Grad Norm 2.5919(1.5960) | Total Time 14.00(14.00)\n",
      "Iter 2052 | Time 74.8504(74.8311) | Bit/dim 3.9872(3.9829) | Xent 0.5443(0.5566) | Loss 4.2594(4.2612) | Error 0.1946(0.2007) Steps 814(816.79) | Grad Norm 1.4378(1.5913) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 29.8233, Epoch Time 501.2223(495.3032), Bit/dim 3.9878(best: 3.9887), Xent 1.4521, Loss 4.7139, Error 0.4181(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2053 | Time 75.8756(74.8624) | Bit/dim 3.9868(3.9830) | Xent 0.5691(0.5570) | Loss 4.2713(4.2615) | Error 0.2067(0.2009) Steps 814(816.70) | Grad Norm 2.1805(1.6090) | Total Time 14.00(14.00)\n",
      "Iter 2054 | Time 72.0890(74.7792) | Bit/dim 3.9838(3.9830) | Xent 0.5587(0.5570) | Loss 4.2631(4.2616) | Error 0.2007(0.2009) Steps 808(816.44) | Grad Norm 2.4140(1.6331) | Total Time 14.00(14.00)\n",
      "Iter 2055 | Time 71.4415(74.6791) | Bit/dim 3.9830(3.9830) | Xent 0.5355(0.5564) | Loss 4.2507(4.2612) | Error 0.1917(0.2006) Steps 826(816.73) | Grad Norm 3.3270(1.6839) | Total Time 14.00(14.00)\n",
      "Iter 2056 | Time 72.0698(74.6008) | Bit/dim 3.9759(3.9828) | Xent 0.5493(0.5562) | Loss 4.2505(4.2609) | Error 0.1969(0.2005) Steps 814(816.65) | Grad Norm 2.2045(1.6995) | Total Time 14.00(14.00)\n",
      "Iter 2057 | Time 73.1506(74.5573) | Bit/dim 3.9863(3.9829) | Xent 0.5475(0.5559) | Loss 4.2601(4.2609) | Error 0.1996(0.2005) Steps 802(816.21) | Grad Norm 3.7637(1.7615) | Total Time 14.00(14.00)\n",
      "Iter 2058 | Time 75.8842(74.5971) | Bit/dim 3.9802(3.9829) | Xent 0.5595(0.5560) | Loss 4.2599(4.2609) | Error 0.2057(0.2006) Steps 814(816.14) | Grad Norm 2.5512(1.7852) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 29.8201, Epoch Time 485.9882(495.0238), Bit/dim 3.9878(best: 3.9878), Xent 1.4637, Loss 4.7197, Error 0.4168(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2059 | Time 73.9618(74.5781) | Bit/dim 3.9768(3.9827) | Xent 0.5436(0.5556) | Loss 4.2486(4.2605) | Error 0.1997(0.2006) Steps 826(816.44) | Grad Norm 1.4277(1.7744) | Total Time 14.00(14.00)\n",
      "Iter 2060 | Time 74.0548(74.5624) | Bit/dim 3.9800(3.9826) | Xent 0.5362(0.5551) | Loss 4.2481(4.2601) | Error 0.1903(0.2003) Steps 820(816.54) | Grad Norm 2.5086(1.7965) | Total Time 14.00(14.00)\n",
      "Iter 2061 | Time 72.8342(74.5105) | Bit/dim 3.9766(3.9824) | Xent 0.5490(0.5549) | Loss 4.2510(4.2598) | Error 0.1980(0.2002) Steps 796(815.93) | Grad Norm 2.9683(1.8316) | Total Time 14.00(14.00)\n",
      "Iter 2062 | Time 75.8694(74.5513) | Bit/dim 3.9849(3.9825) | Xent 0.5485(0.5547) | Loss 4.2591(4.2598) | Error 0.2020(0.2003) Steps 808(815.69) | Grad Norm 1.2178(1.8132) | Total Time 14.00(14.00)\n",
      "Iter 2063 | Time 74.3130(74.5441) | Bit/dim 3.9907(3.9827) | Xent 0.5310(0.5540) | Loss 4.2562(4.2597) | Error 0.1910(0.2000) Steps 808(815.46) | Grad Norm 2.5078(1.8340) | Total Time 14.00(14.00)\n",
      "Iter 2064 | Time 72.9378(74.4959) | Bit/dim 3.9738(3.9825) | Xent 0.5548(0.5540) | Loss 4.2512(4.2595) | Error 0.1956(0.1999) Steps 814(815.42) | Grad Norm 1.6979(1.8299) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 29.7782, Epoch Time 489.2926(494.8518), Bit/dim 3.9875(best: 3.9878), Xent 1.4719, Loss 4.7234, Error 0.4183(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2065 | Time 76.4784(74.5554) | Bit/dim 3.9724(3.9822) | Xent 0.5468(0.5538) | Loss 4.2458(4.2590) | Error 0.2044(0.2000) Steps 820(815.55) | Grad Norm 1.3494(1.8155) | Total Time 14.00(14.00)\n",
      "Iter 2066 | Time 75.4045(74.5809) | Bit/dim 3.9827(3.9822) | Xent 0.5455(0.5535) | Loss 4.2554(4.2589) | Error 0.1936(0.1998) Steps 820(815.69) | Grad Norm 1.1714(1.7962) | Total Time 14.00(14.00)\n",
      "Iter 2067 | Time 72.3461(74.5138) | Bit/dim 3.9843(3.9822) | Xent 0.5450(0.5533) | Loss 4.2568(4.2589) | Error 0.1990(0.1998) Steps 814(815.64) | Grad Norm 1.3470(1.7827) | Total Time 14.00(14.00)\n",
      "Iter 2068 | Time 72.5347(74.4545) | Bit/dim 3.9826(3.9822) | Xent 0.5438(0.5530) | Loss 4.2545(4.2587) | Error 0.1930(0.1996) Steps 820(815.77) | Grad Norm 0.9840(1.7588) | Total Time 14.00(14.00)\n",
      "Iter 2069 | Time 72.9426(74.4091) | Bit/dim 3.9809(3.9822) | Xent 0.5642(0.5533) | Loss 4.2630(4.2589) | Error 0.2049(0.1997) Steps 814(815.71) | Grad Norm 1.3012(1.7450) | Total Time 14.00(14.00)\n",
      "Iter 2070 | Time 74.0230(74.3975) | Bit/dim 3.9831(3.9822) | Xent 0.5375(0.5529) | Loss 4.2519(4.2587) | Error 0.1959(0.1996) Steps 826(816.02) | Grad Norm 1.2117(1.7290) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 29.5316, Epoch Time 488.7893(494.6700), Bit/dim 3.9873(best: 3.9875), Xent 1.4758, Loss 4.7252, Error 0.4171(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2071 | Time 74.6629(74.4055) | Bit/dim 3.9854(3.9823) | Xent 0.5531(0.5529) | Loss 4.2619(4.2588) | Error 0.2007(0.1997) Steps 814(815.96) | Grad Norm 1.1690(1.7122) | Total Time 14.00(14.00)\n",
      "Iter 2072 | Time 74.3044(74.4025) | Bit/dim 3.9817(3.9823) | Xent 0.5404(0.5525) | Loss 4.2519(4.2585) | Error 0.2020(0.1997) Steps 820(816.08) | Grad Norm 1.3423(1.7011) | Total Time 14.00(14.00)\n",
      "Iter 2073 | Time 76.9926(74.4802) | Bit/dim 3.9756(3.9821) | Xent 0.5409(0.5521) | Loss 4.2460(4.2582) | Error 0.1949(0.1996) Steps 814(816.02) | Grad Norm 0.9244(1.6778) | Total Time 14.00(14.00)\n",
      "Iter 2074 | Time 72.5721(74.4229) | Bit/dim 3.9793(3.9820) | Xent 0.5160(0.5511) | Loss 4.2373(4.2575) | Error 0.1844(0.1991) Steps 820(816.14) | Grad Norm 1.1620(1.6624) | Total Time 14.00(14.00)\n",
      "Iter 2075 | Time 76.7648(74.4932) | Bit/dim 3.9852(3.9821) | Xent 0.5502(0.5510) | Loss 4.2603(4.2576) | Error 0.1965(0.1990) Steps 820(816.26) | Grad Norm 1.4003(1.6545) | Total Time 14.00(14.00)\n",
      "Iter 2076 | Time 77.3474(74.5788) | Bit/dim 3.9802(3.9821) | Xent 0.5580(0.5512) | Loss 4.2592(4.2577) | Error 0.2024(0.1991) Steps 820(816.37) | Grad Norm 1.3489(1.6453) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 29.8950, Epoch Time 498.1098(494.7732), Bit/dim 3.9876(best: 3.9873), Xent 1.4746, Loss 4.7249, Error 0.4146(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2077 | Time 74.5948(74.5793) | Bit/dim 3.9943(3.9824) | Xent 0.5400(0.5509) | Loss 4.2643(4.2579) | Error 0.1911(0.1989) Steps 814(816.30) | Grad Norm 1.2851(1.6345) | Total Time 14.00(14.00)\n",
      "Iter 2078 | Time 75.2125(74.5983) | Bit/dim 3.9760(3.9822) | Xent 0.5250(0.5501) | Loss 4.2384(4.2573) | Error 0.1891(0.1986) Steps 826(816.59) | Grad Norm 1.8337(1.6405) | Total Time 14.00(14.00)\n",
      "Iter 2079 | Time 75.7272(74.6321) | Bit/dim 3.9644(3.9817) | Xent 0.5645(0.5505) | Loss 4.2467(4.2570) | Error 0.1991(0.1986) Steps 826(816.87) | Grad Norm 1.0158(1.6218) | Total Time 14.00(14.00)\n",
      "Iter 2080 | Time 74.2653(74.6211) | Bit/dim 3.9850(3.9818) | Xent 0.5211(0.5497) | Loss 4.2455(4.2566) | Error 0.1853(0.1982) Steps 802(816.42) | Grad Norm 0.9479(1.6015) | Total Time 14.00(14.00)\n",
      "Iter 2081 | Time 76.6112(74.6808) | Bit/dim 3.9814(3.9818) | Xent 0.5534(0.5498) | Loss 4.2581(4.2567) | Error 0.2006(0.1983) Steps 814(816.35) | Grad Norm 1.3337(1.5935) | Total Time 14.00(14.00)\n",
      "Iter 2082 | Time 72.7615(74.6233) | Bit/dim 3.9851(3.9819) | Xent 0.5271(0.5491) | Loss 4.2486(4.2564) | Error 0.1870(0.1980) Steps 814(816.28) | Grad Norm 1.6357(1.5948) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 29.7515, Epoch Time 494.4817(494.7644), Bit/dim 3.9875(best: 3.9873), Xent 1.4873, Loss 4.7312, Error 0.4218(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2083 | Time 72.5505(74.5611) | Bit/dim 3.9822(3.9819) | Xent 0.5543(0.5493) | Loss 4.2594(4.2565) | Error 0.2014(0.1981) Steps 814(816.21) | Grad Norm 1.0322(1.5779) | Total Time 14.00(14.00)\n",
      "Iter 2084 | Time 74.2220(74.5509) | Bit/dim 3.9723(3.9816) | Xent 0.5492(0.5493) | Loss 4.2469(4.2562) | Error 0.1984(0.1981) Steps 814(816.15) | Grad Norm 1.1912(1.5663) | Total Time 14.00(14.00)\n",
      "Iter 2085 | Time 74.5176(74.5499) | Bit/dim 3.9785(3.9815) | Xent 0.5287(0.5486) | Loss 4.2428(4.2558) | Error 0.1896(0.1978) Steps 820(816.26) | Grad Norm 1.2788(1.5577) | Total Time 14.00(14.00)\n",
      "Iter 2086 | Time 74.6096(74.5517) | Bit/dim 3.9857(3.9816) | Xent 0.5264(0.5480) | Loss 4.2489(4.2556) | Error 0.1953(0.1977) Steps 808(816.01) | Grad Norm 2.8589(1.5967) | Total Time 14.00(14.00)\n",
      "Iter 2087 | Time 73.5233(74.5208) | Bit/dim 3.9663(3.9812) | Xent 0.5386(0.5477) | Loss 4.2356(4.2550) | Error 0.1957(0.1977) Steps 820(816.13) | Grad Norm 1.3501(1.5893) | Total Time 14.00(14.00)\n",
      "Iter 2088 | Time 76.0242(74.5659) | Bit/dim 3.9824(3.9812) | Xent 0.5407(0.5475) | Loss 4.2527(4.2549) | Error 0.1986(0.1977) Steps 808(815.89) | Grad Norm 1.6409(1.5909) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 29.7970, Epoch Time 490.8263(494.6463), Bit/dim 3.9864(best: 3.9873), Xent 1.4725, Loss 4.7227, Error 0.4205(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2089 | Time 76.5590(74.6257) | Bit/dim 3.9846(3.9813) | Xent 0.5268(0.5469) | Loss 4.2480(4.2547) | Error 0.1955(0.1976) Steps 826(816.19) | Grad Norm 1.8123(1.5975) | Total Time 14.00(14.00)\n",
      "Iter 2090 | Time 75.4701(74.6511) | Bit/dim 3.9746(3.9811) | Xent 0.5171(0.5460) | Loss 4.2332(4.2541) | Error 0.1849(0.1973) Steps 802(815.77) | Grad Norm 1.0967(1.5825) | Total Time 14.00(14.00)\n",
      "Iter 2091 | Time 71.1206(74.5452) | Bit/dim 3.9799(3.9811) | Xent 0.5303(0.5455) | Loss 4.2450(4.2538) | Error 0.1964(0.1972) Steps 826(816.07) | Grad Norm 1.4800(1.5794) | Total Time 14.00(14.00)\n",
      "Iter 2092 | Time 76.2085(74.5951) | Bit/dim 3.9894(3.9813) | Xent 0.5492(0.5456) | Loss 4.2640(4.2541) | Error 0.1951(0.1972) Steps 820(816.19) | Grad Norm 1.6541(1.5816) | Total Time 14.00(14.00)\n",
      "Iter 2093 | Time 71.9418(74.5155) | Bit/dim 3.9787(3.9812) | Xent 0.5470(0.5456) | Loss 4.2522(4.2541) | Error 0.1927(0.1970) Steps 808(815.95) | Grad Norm 1.3825(1.5757) | Total Time 14.00(14.00)\n",
      "Iter 2094 | Time 75.6002(74.5480) | Bit/dim 3.9704(3.9809) | Xent 0.5377(0.5454) | Loss 4.2392(4.2536) | Error 0.1955(0.1970) Steps 820(816.07) | Grad Norm 0.9822(1.5579) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 29.9066, Epoch Time 492.3209(494.5765), Bit/dim 3.9868(best: 3.9864), Xent 1.4860, Loss 4.7298, Error 0.4191(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2095 | Time 75.4945(74.5764) | Bit/dim 3.9724(3.9807) | Xent 0.5461(0.5454) | Loss 4.2454(4.2534) | Error 0.1986(0.1970) Steps 820(816.19) | Grad Norm 1.8984(1.5681) | Total Time 14.00(14.00)\n",
      "Iter 2096 | Time 74.7867(74.5827) | Bit/dim 3.9776(3.9806) | Xent 0.5169(0.5446) | Loss 4.2360(4.2529) | Error 0.1865(0.1967) Steps 814(816.12) | Grad Norm 1.5656(1.5680) | Total Time 14.00(14.00)\n",
      "Iter 2097 | Time 71.4133(74.4876) | Bit/dim 3.9746(3.9804) | Xent 0.5233(0.5439) | Loss 4.2362(4.2524) | Error 0.1887(0.1965) Steps 814(816.06) | Grad Norm 1.6627(1.5709) | Total Time 14.00(14.00)\n",
      "Iter 2098 | Time 75.2330(74.5100) | Bit/dim 3.9793(3.9804) | Xent 0.5530(0.5442) | Loss 4.2559(4.2525) | Error 0.1981(0.1965) Steps 826(816.35) | Grad Norm 1.7413(1.5760) | Total Time 14.00(14.00)\n",
      "Iter 2099 | Time 71.7938(74.4285) | Bit/dim 3.9781(3.9803) | Xent 0.5488(0.5443) | Loss 4.2526(4.2525) | Error 0.2017(0.1967) Steps 826(816.64) | Grad Norm 2.0725(1.5909) | Total Time 14.00(14.00)\n",
      "Iter 2100 | Time 75.0643(74.4476) | Bit/dim 3.9903(3.9806) | Xent 0.5570(0.5447) | Loss 4.2688(4.2530) | Error 0.2007(0.1968) Steps 826(816.92) | Grad Norm 1.4387(1.5863) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 30.0452, Epoch Time 489.3368(494.4193), Bit/dim 3.9869(best: 3.9864), Xent 1.4860, Loss 4.7299, Error 0.4177(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2101 | Time 76.2081(74.5004) | Bit/dim 3.9751(3.9804) | Xent 0.5356(0.5444) | Loss 4.2429(4.2527) | Error 0.1917(0.1967) Steps 820(817.02) | Grad Norm 1.3284(1.5786) | Total Time 14.00(14.00)\n",
      "Iter 2102 | Time 75.7421(74.5376) | Bit/dim 3.9782(3.9804) | Xent 0.5318(0.5441) | Loss 4.2441(4.2524) | Error 0.1904(0.1965) Steps 808(816.75) | Grad Norm 1.6068(1.5794) | Total Time 14.00(14.00)\n",
      "Iter 2103 | Time 74.1675(74.5265) | Bit/dim 3.9867(3.9806) | Xent 0.5264(0.5435) | Loss 4.2499(4.2523) | Error 0.1893(0.1963) Steps 826(817.02) | Grad Norm 1.7078(1.5833) | Total Time 14.00(14.00)\n",
      "Iter 2104 | Time 77.4455(74.6141) | Bit/dim 3.9764(3.9804) | Xent 0.5360(0.5433) | Loss 4.2444(4.2521) | Error 0.1909(0.1961) Steps 814(816.93) | Grad Norm 1.4061(1.5779) | Total Time 14.00(14.00)\n",
      "Iter 2105 | Time 72.5306(74.5516) | Bit/dim 3.9731(3.9802) | Xent 0.5376(0.5431) | Loss 4.2419(4.2518) | Error 0.1985(0.1962) Steps 814(816.85) | Grad Norm 1.7588(1.5834) | Total Time 14.00(14.00)\n",
      "Iter 2106 | Time 76.9896(74.6247) | Bit/dim 3.9777(3.9801) | Xent 0.5374(0.5430) | Loss 4.2464(4.2516) | Error 0.1946(0.1961) Steps 808(816.58) | Grad Norm 2.6971(1.6168) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 29.9653, Epoch Time 498.7603(494.5496), Bit/dim 3.9860(best: 3.9864), Xent 1.4870, Loss 4.7295, Error 0.4180(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2107 | Time 77.9892(74.7257) | Bit/dim 3.9716(3.9799) | Xent 0.5227(0.5424) | Loss 4.2329(4.2511) | Error 0.1886(0.1959) Steps 808(816.32) | Grad Norm 1.2943(1.6071) | Total Time 14.00(14.00)\n",
      "Iter 2108 | Time 75.1641(74.7388) | Bit/dim 3.9802(3.9799) | Xent 0.5462(0.5425) | Loss 4.2533(4.2511) | Error 0.2015(0.1961) Steps 820(816.43) | Grad Norm 2.4285(1.6317) | Total Time 14.00(14.00)\n",
      "Iter 2109 | Time 73.2806(74.6951) | Bit/dim 3.9803(3.9799) | Xent 0.5256(0.5420) | Loss 4.2431(4.2509) | Error 0.1895(0.1959) Steps 820(816.54) | Grad Norm 2.0669(1.6448) | Total Time 14.00(14.00)\n",
      "Iter 2110 | Time 73.7793(74.6676) | Bit/dim 3.9885(3.9802) | Xent 0.5129(0.5411) | Loss 4.2450(4.2507) | Error 0.1875(0.1956) Steps 814(816.46) | Grad Norm 1.8204(1.6501) | Total Time 14.00(14.00)\n",
      "Iter 2111 | Time 73.4280(74.6304) | Bit/dim 3.9748(3.9800) | Xent 0.5390(0.5410) | Loss 4.2443(4.2505) | Error 0.1946(0.1956) Steps 820(816.57) | Grad Norm 2.1407(1.6648) | Total Time 14.00(14.00)\n",
      "Iter 2112 | Time 74.7735(74.6347) | Bit/dim 3.9717(3.9797) | Xent 0.5396(0.5410) | Loss 4.2415(4.2502) | Error 0.1915(0.1955) Steps 814(816.49) | Grad Norm 1.5617(1.6617) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 30.2731, Epoch Time 494.3186(494.5426), Bit/dim 3.9861(best: 3.9860), Xent 1.4925, Loss 4.7323, Error 0.4143(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2113 | Time 73.9993(74.6156) | Bit/dim 3.9788(3.9797) | Xent 0.5365(0.5409) | Loss 4.2470(4.2501) | Error 0.1917(0.1954) Steps 802(816.06) | Grad Norm 1.6777(1.6622) | Total Time 14.00(14.00)\n",
      "Iter 2114 | Time 74.0767(74.5995) | Bit/dim 3.9753(3.9796) | Xent 0.5297(0.5405) | Loss 4.2401(4.2498) | Error 0.1927(0.1953) Steps 826(816.36) | Grad Norm 2.2677(1.6803) | Total Time 14.00(14.00)\n",
      "Iter 2115 | Time 73.7561(74.5742) | Bit/dim 3.9741(3.9794) | Xent 0.5514(0.5408) | Loss 4.2498(4.2498) | Error 0.2006(0.1954) Steps 820(816.47) | Grad Norm 1.8650(1.6859) | Total Time 14.00(14.00)\n",
      "Iter 2116 | Time 74.0941(74.5598) | Bit/dim 3.9773(3.9794) | Xent 0.5249(0.5404) | Loss 4.2397(4.2495) | Error 0.1913(0.1953) Steps 826(816.75) | Grad Norm 1.1690(1.6704) | Total Time 14.00(14.00)\n",
      "Iter 2117 | Time 74.0451(74.5443) | Bit/dim 3.9796(3.9794) | Xent 0.5204(0.5398) | Loss 4.2398(4.2493) | Error 0.1839(0.1950) Steps 820(816.85) | Grad Norm 2.5664(1.6973) | Total Time 14.00(14.00)\n",
      "Iter 2118 | Time 75.2516(74.5656) | Bit/dim 3.9827(3.9795) | Xent 0.5419(0.5398) | Loss 4.2537(4.2494) | Error 0.1927(0.1949) Steps 814(816.76) | Grad Norm 1.7133(1.6977) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 29.5174, Epoch Time 490.2698(494.4144), Bit/dim 3.9847(best: 3.9860), Xent 1.5003, Loss 4.7348, Error 0.4167(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2119 | Time 75.2923(74.5874) | Bit/dim 3.9681(3.9791) | Xent 0.5401(0.5398) | Loss 4.2381(4.2490) | Error 0.1946(0.1949) Steps 808(816.50) | Grad Norm 1.4253(1.6896) | Total Time 14.00(14.00)\n",
      "Iter 2120 | Time 72.5231(74.5254) | Bit/dim 3.9821(3.9792) | Xent 0.5245(0.5394) | Loss 4.2443(4.2489) | Error 0.1887(0.1947) Steps 808(816.25) | Grad Norm 1.9130(1.6963) | Total Time 14.00(14.00)\n",
      "Iter 2121 | Time 74.3259(74.5194) | Bit/dim 3.9783(3.9792) | Xent 0.5158(0.5387) | Loss 4.2362(4.2485) | Error 0.1883(0.1945) Steps 808(816.00) | Grad Norm 1.6952(1.6962) | Total Time 14.00(14.00)\n",
      "Iter 2122 | Time 73.9778(74.5032) | Bit/dim 3.9695(3.9789) | Xent 0.5389(0.5387) | Loss 4.2390(4.2482) | Error 0.1953(0.1945) Steps 814(815.94) | Grad Norm 1.5215(1.6910) | Total Time 14.00(14.00)\n",
      "Iter 2123 | Time 72.4436(74.4414) | Bit/dim 3.9767(3.9788) | Xent 0.5395(0.5387) | Loss 4.2464(4.2482) | Error 0.1947(0.1945) Steps 826(816.24) | Grad Norm 1.0193(1.6708) | Total Time 14.00(14.00)\n",
      "Iter 2124 | Time 71.2383(74.3453) | Bit/dim 3.9917(3.9792) | Xent 0.5188(0.5381) | Loss 4.2511(4.2483) | Error 0.1861(0.1943) Steps 808(815.99) | Grad Norm 1.5302(1.6666) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 29.7976, Epoch Time 485.0865(494.1346), Bit/dim 3.9853(best: 3.9847), Xent 1.4862, Loss 4.7284, Error 0.4181(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2125 | Time 76.0232(74.3956) | Bit/dim 3.9817(3.9793) | Xent 0.5188(0.5375) | Loss 4.2411(4.2481) | Error 0.1850(0.1940) Steps 814(815.93) | Grad Norm 1.2765(1.6549) | Total Time 14.00(14.00)\n",
      "Iter 2126 | Time 76.6379(74.4629) | Bit/dim 3.9689(3.9790) | Xent 0.5169(0.5369) | Loss 4.2273(4.2474) | Error 0.1900(0.1939) Steps 826(816.24) | Grad Norm 1.5190(1.6508) | Total Time 14.00(14.00)\n",
      "Iter 2127 | Time 74.4089(74.4613) | Bit/dim 3.9735(3.9788) | Xent 0.5274(0.5366) | Loss 4.2372(4.2471) | Error 0.1926(0.1939) Steps 820(816.35) | Grad Norm 1.5314(1.6473) | Total Time 14.00(14.00)\n",
      "Iter 2128 | Time 76.6450(74.5268) | Bit/dim 3.9810(3.9789) | Xent 0.5251(0.5363) | Loss 4.2436(4.2470) | Error 0.1873(0.1937) Steps 808(816.10) | Grad Norm 1.2356(1.6349) | Total Time 14.00(14.00)\n",
      "Iter 2129 | Time 74.9074(74.5382) | Bit/dim 3.9822(3.9790) | Xent 0.5397(0.5364) | Loss 4.2520(4.2472) | Error 0.1903(0.1936) Steps 820(816.21) | Grad Norm 1.5258(1.6316) | Total Time 14.00(14.00)\n",
      "Iter 2130 | Time 75.3922(74.5638) | Bit/dim 3.9775(3.9789) | Xent 0.5284(0.5361) | Loss 4.2417(4.2470) | Error 0.1894(0.1934) Steps 808(815.97) | Grad Norm 1.3584(1.6234) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 29.6198, Epoch Time 499.1883(494.2862), Bit/dim 3.9856(best: 3.9847), Xent 1.4987, Loss 4.7349, Error 0.4168(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2131 | Time 71.7763(74.4802) | Bit/dim 3.9891(3.9792) | Xent 0.5246(0.5358) | Loss 4.2514(4.2471) | Error 0.1890(0.1933) Steps 820(816.09) | Grad Norm 1.2554(1.6124) | Total Time 14.00(14.00)\n",
      "Iter 2132 | Time 74.1850(74.4714) | Bit/dim 3.9761(3.9791) | Xent 0.5271(0.5355) | Loss 4.2397(4.2469) | Error 0.1920(0.1933) Steps 814(816.03) | Grad Norm 1.3662(1.6050) | Total Time 14.00(14.00)\n",
      "Iter 2133 | Time 75.3421(74.4975) | Bit/dim 3.9729(3.9790) | Xent 0.5291(0.5353) | Loss 4.2375(4.2466) | Error 0.1921(0.1932) Steps 820(816.15) | Grad Norm 1.5219(1.6025) | Total Time 14.00(14.00)\n",
      "Iter 2134 | Time 75.9590(74.5413) | Bit/dim 3.9763(3.9789) | Xent 0.5279(0.5351) | Loss 4.2403(4.2464) | Error 0.1911(0.1932) Steps 814(816.08) | Grad Norm 0.9055(1.5816) | Total Time 14.00(14.00)\n",
      "Iter 2135 | Time 74.7978(74.5490) | Bit/dim 3.9761(3.9788) | Xent 0.5384(0.5352) | Loss 4.2453(4.2464) | Error 0.1961(0.1932) Steps 808(815.84) | Grad Norm 1.9222(1.5918) | Total Time 14.00(14.00)\n",
      "Iter 2136 | Time 74.1660(74.5375) | Bit/dim 3.9753(3.9787) | Xent 0.5337(0.5352) | Loss 4.2422(4.2463) | Error 0.1923(0.1932) Steps 820(815.96) | Grad Norm 2.2142(1.6105) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 29.5842, Epoch Time 491.2782(494.1960), Bit/dim 3.9842(best: 3.9847), Xent 1.5063, Loss 4.7374, Error 0.4219(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2137 | Time 76.1797(74.5868) | Bit/dim 3.9811(3.9788) | Xent 0.5112(0.5345) | Loss 4.2367(4.2460) | Error 0.1857(0.1930) Steps 814(815.90) | Grad Norm 1.1307(1.5961) | Total Time 14.00(14.00)\n",
      "Iter 2138 | Time 72.8657(74.5352) | Bit/dim 3.9791(3.9788) | Xent 0.5389(0.5346) | Loss 4.2485(4.2461) | Error 0.1873(0.1928) Steps 814(815.85) | Grad Norm 2.1371(1.6123) | Total Time 14.00(14.00)\n",
      "Iter 2139 | Time 79.2906(74.6778) | Bit/dim 3.9770(3.9787) | Xent 0.5313(0.5345) | Loss 4.2426(4.2460) | Error 0.1880(0.1927) Steps 814(815.79) | Grad Norm 1.2292(1.6008) | Total Time 14.00(14.00)\n",
      "Iter 2140 | Time 76.1309(74.7214) | Bit/dim 3.9726(3.9785) | Xent 0.5384(0.5346) | Loss 4.2418(4.2458) | Error 0.1970(0.1928) Steps 814(815.74) | Grad Norm 2.1186(1.6164) | Total Time 14.00(14.00)\n",
      "Iter 2141 | Time 73.9931(74.6996) | Bit/dim 3.9657(3.9781) | Xent 0.5297(0.5345) | Loss 4.2305(4.2454) | Error 0.1929(0.1928) Steps 814(815.69) | Grad Norm 1.4338(1.6109) | Total Time 14.00(14.00)\n",
      "Iter 2142 | Time 76.2744(74.7468) | Bit/dim 3.9856(3.9784) | Xent 0.5171(0.5339) | Loss 4.2441(4.2453) | Error 0.1803(0.1924) Steps 814(815.64) | Grad Norm 2.0063(1.6228) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 29.8646, Epoch Time 500.3245(494.3798), Bit/dim 3.9852(best: 3.9842), Xent 1.5089, Loss 4.7397, Error 0.4188(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2143 | Time 74.8869(74.7510) | Bit/dim 3.9751(3.9783) | Xent 0.5340(0.5339) | Loss 4.2421(4.2452) | Error 0.1936(0.1925) Steps 814(815.59) | Grad Norm 1.3680(1.6151) | Total Time 14.00(14.00)\n",
      "Iter 2144 | Time 74.9836(74.7580) | Bit/dim 3.9774(3.9782) | Xent 0.5276(0.5338) | Loss 4.2412(4.2451) | Error 0.1910(0.1924) Steps 814(815.54) | Grad Norm 1.0685(1.5987) | Total Time 14.00(14.00)\n",
      "Iter 2145 | Time 72.8358(74.7003) | Bit/dim 3.9782(3.9782) | Xent 0.5274(0.5336) | Loss 4.2419(4.2450) | Error 0.1933(0.1924) Steps 826(815.85) | Grad Norm 2.1577(1.6155) | Total Time 14.00(14.00)\n",
      "Iter 2146 | Time 74.7503(74.7018) | Bit/dim 3.9824(3.9784) | Xent 0.5091(0.5328) | Loss 4.2369(4.2448) | Error 0.1796(0.1921) Steps 814(815.80) | Grad Norm 1.4375(1.6101) | Total Time 14.00(14.00)\n",
      "Iter 2147 | Time 73.6006(74.6688) | Bit/dim 3.9703(3.9781) | Xent 0.5294(0.5327) | Loss 4.2350(4.2445) | Error 0.1879(0.1919) Steps 820(815.92) | Grad Norm 1.8144(1.6163) | Total Time 14.00(14.00)\n",
      "Iter 2148 | Time 74.3210(74.6584) | Bit/dim 3.9812(3.9782) | Xent 0.5300(0.5326) | Loss 4.2462(4.2445) | Error 0.1940(0.1920) Steps 820(816.05) | Grad Norm 1.4204(1.6104) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 29.8243, Epoch Time 490.8534(494.2740), Bit/dim 3.9847(best: 3.9842), Xent 1.5153, Loss 4.7424, Error 0.4164(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2149 | Time 73.3190(74.6182) | Bit/dim 3.9861(3.9785) | Xent 0.5427(0.5329) | Loss 4.2575(4.2449) | Error 0.1937(0.1921) Steps 808(815.80) | Grad Norm 1.3521(1.6026) | Total Time 14.00(14.00)\n",
      "Iter 2150 | Time 74.7282(74.6215) | Bit/dim 3.9739(3.9783) | Xent 0.5290(0.5328) | Loss 4.2383(4.2447) | Error 0.1909(0.1920) Steps 802(815.39) | Grad Norm 1.6887(1.6052) | Total Time 14.00(14.00)\n",
      "Iter 2151 | Time 75.9700(74.6619) | Bit/dim 3.9817(3.9784) | Xent 0.5147(0.5323) | Loss 4.2391(4.2446) | Error 0.1894(0.1919) Steps 820(815.53) | Grad Norm 1.2724(1.5952) | Total Time 14.00(14.00)\n",
      "Iter 2152 | Time 78.4958(74.7769) | Bit/dim 3.9733(3.9783) | Xent 0.5253(0.5321) | Loss 4.2359(4.2443) | Error 0.1889(0.1918) Steps 820(815.66) | Grad Norm 2.4753(1.6216) | Total Time 14.00(14.00)\n",
      "Iter 2153 | Time 72.5011(74.7087) | Bit/dim 3.9629(3.9778) | Xent 0.5331(0.5321) | Loss 4.2295(4.2439) | Error 0.1970(0.1920) Steps 820(815.79) | Grad Norm 1.3803(1.6144) | Total Time 14.00(14.00)\n",
      "Iter 2154 | Time 74.8639(74.7133) | Bit/dim 3.9839(3.9780) | Xent 0.5094(0.5314) | Loss 4.2386(4.2437) | Error 0.1847(0.1918) Steps 826(816.10) | Grad Norm 1.5517(1.6125) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 29.5442, Epoch Time 495.2553(494.3035), Bit/dim 3.9842(best: 3.9842), Xent 1.5160, Loss 4.7422, Error 0.4195(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2155 | Time 74.0225(74.6926) | Bit/dim 3.9768(3.9780) | Xent 0.5241(0.5312) | Loss 4.2389(4.2436) | Error 0.1843(0.1916) Steps 826(816.40) | Grad Norm 1.7577(1.6169) | Total Time 14.00(14.00)\n",
      "Iter 2156 | Time 73.8046(74.6660) | Bit/dim 3.9805(3.9780) | Xent 0.5227(0.5310) | Loss 4.2419(4.2435) | Error 0.1910(0.1915) Steps 814(816.32) | Grad Norm 1.7902(1.6221) | Total Time 14.00(14.00)\n",
      "Iter 2157 | Time 74.3773(74.6573) | Bit/dim 3.9789(3.9781) | Xent 0.5164(0.5305) | Loss 4.2371(4.2433) | Error 0.1909(0.1915) Steps 814(816.25) | Grad Norm 3.0183(1.6640) | Total Time 14.00(14.00)\n",
      "Iter 2158 | Time 74.5688(74.6546) | Bit/dim 3.9744(3.9779) | Xent 0.5376(0.5307) | Loss 4.2432(4.2433) | Error 0.1951(0.1916) Steps 814(816.19) | Grad Norm 2.5711(1.6912) | Total Time 14.00(14.00)\n",
      "Iter 2159 | Time 75.0117(74.6654) | Bit/dim 3.9671(3.9776) | Xent 0.5179(0.5303) | Loss 4.2260(4.2428) | Error 0.1873(0.1915) Steps 814(816.12) | Grad Norm 2.8891(1.7271) | Total Time 14.00(14.00)\n",
      "Iter 2160 | Time 75.5630(74.6923) | Bit/dim 3.9783(3.9776) | Xent 0.5138(0.5298) | Loss 4.2352(4.2426) | Error 0.1826(0.1912) Steps 820(816.24) | Grad Norm 2.4802(1.7497) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 29.9568, Epoch Time 492.9753(494.2636), Bit/dim 3.9834(best: 3.9842), Xent 1.5181, Loss 4.7424, Error 0.4218(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2161 | Time 72.0164(74.6120) | Bit/dim 3.9846(3.9778) | Xent 0.5088(0.5292) | Loss 4.2390(4.2425) | Error 0.1810(0.1909) Steps 802(815.81) | Grad Norm 1.6469(1.7466) | Total Time 14.00(14.00)\n",
      "Iter 2162 | Time 74.2303(74.6006) | Bit/dim 3.9748(3.9778) | Xent 0.5164(0.5288) | Loss 4.2330(4.2422) | Error 0.1899(0.1909) Steps 814(815.76) | Grad Norm 4.1422(1.8185) | Total Time 14.00(14.00)\n",
      "Iter 2163 | Time 76.4945(74.6574) | Bit/dim 3.9736(3.9776) | Xent 0.5166(0.5285) | Loss 4.2319(4.2419) | Error 0.1833(0.1907) Steps 808(815.52) | Grad Norm 1.5556(1.8106) | Total Time 14.00(14.00)\n",
      "Iter 2164 | Time 75.5269(74.6835) | Bit/dim 3.9670(3.9773) | Xent 0.5124(0.5280) | Loss 4.2232(4.2413) | Error 0.1867(0.1905) Steps 820(815.66) | Grad Norm 2.4398(1.8295) | Total Time 14.00(14.00)\n",
      "Iter 2165 | Time 73.3767(74.6443) | Bit/dim 3.9751(3.9772) | Xent 0.5287(0.5280) | Loss 4.2395(4.2413) | Error 0.1935(0.1906) Steps 808(815.43) | Grad Norm 4.0506(1.8961) | Total Time 14.00(14.00)\n",
      "Iter 2166 | Time 74.5364(74.6410) | Bit/dim 3.9765(3.9772) | Xent 0.5155(0.5276) | Loss 4.2342(4.2410) | Error 0.1861(0.1905) Steps 820(815.57) | Grad Norm 1.2760(1.8775) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 29.8744, Epoch Time 492.0482(494.1972), Bit/dim 3.9838(best: 3.9834), Xent 1.5204, Loss 4.7440, Error 0.4186(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2167 | Time 74.9910(74.6515) | Bit/dim 3.9748(3.9772) | Xent 0.5374(0.5279) | Loss 4.2435(4.2411) | Error 0.1987(0.1907) Steps 814(815.52) | Grad Norm 3.5859(1.9288) | Total Time 14.00(14.00)\n",
      "Iter 2168 | Time 74.1644(74.6369) | Bit/dim 3.9909(3.9776) | Xent 0.5125(0.5275) | Loss 4.2472(4.2413) | Error 0.1859(0.1906) Steps 820(815.65) | Grad Norm 3.3038(1.9700) | Total Time 14.00(14.00)\n",
      "Iter 2169 | Time 75.2838(74.6563) | Bit/dim 3.9758(3.9775) | Xent 0.5240(0.5274) | Loss 4.2378(4.2412) | Error 0.1894(0.1906) Steps 826(815.96) | Grad Norm 2.5585(1.9877) | Total Time 14.00(14.00)\n",
      "Iter 2170 | Time 73.7187(74.6282) | Bit/dim 3.9808(3.9776) | Xent 0.5230(0.5272) | Loss 4.2423(4.2412) | Error 0.1874(0.1905) Steps 814(815.90) | Grad Norm 2.9155(2.0155) | Total Time 14.00(14.00)\n",
      "Iter 2171 | Time 75.1896(74.6450) | Bit/dim 3.9601(3.9771) | Xent 0.5173(0.5269) | Loss 4.2188(4.2406) | Error 0.1866(0.1904) Steps 820(816.03) | Grad Norm 1.6862(2.0056) | Total Time 14.00(14.00)\n",
      "Iter 2172 | Time 75.0922(74.6584) | Bit/dim 3.9736(3.9770) | Xent 0.5052(0.5263) | Loss 4.2262(4.2401) | Error 0.1813(0.1901) Steps 814(815.97) | Grad Norm 2.1329(2.0094) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 29.7594, Epoch Time 493.7429(494.1835), Bit/dim 3.9843(best: 3.9834), Xent 1.5334, Loss 4.7510, Error 0.4212(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2173 | Time 74.6212(74.6573) | Bit/dim 3.9828(3.9772) | Xent 0.5343(0.5265) | Loss 4.2499(4.2404) | Error 0.1860(0.1900) Steps 796(815.37) | Grad Norm 1.6181(1.9977) | Total Time 14.00(14.00)\n",
      "Iter 2174 | Time 74.3258(74.6474) | Bit/dim 3.9725(3.9770) | Xent 0.5192(0.5263) | Loss 4.2320(4.2402) | Error 0.1847(0.1898) Steps 820(815.51) | Grad Norm 1.7263(1.9896) | Total Time 14.00(14.00)\n",
      "Iter 2175 | Time 74.8563(74.6536) | Bit/dim 3.9648(3.9766) | Xent 0.5135(0.5259) | Loss 4.2215(4.2396) | Error 0.1877(0.1897) Steps 814(815.46) | Grad Norm 3.1078(2.0231) | Total Time 14.00(14.00)\n",
      "Iter 2176 | Time 76.2367(74.7011) | Bit/dim 3.9792(3.9767) | Xent 0.5019(0.5252) | Loss 4.2301(4.2393) | Error 0.1785(0.1894) Steps 820(815.60) | Grad Norm 1.0998(1.9954) | Total Time 14.00(14.00)\n",
      "Iter 2177 | Time 72.3707(74.6312) | Bit/dim 3.9804(3.9768) | Xent 0.5149(0.5249) | Loss 4.2378(4.2393) | Error 0.1897(0.1894) Steps 820(815.73) | Grad Norm 1.9362(1.9936) | Total Time 14.00(14.00)\n",
      "Iter 2178 | Time 74.8941(74.6391) | Bit/dim 3.9759(3.9768) | Xent 0.5159(0.5246) | Loss 4.2338(4.2391) | Error 0.1904(0.1894) Steps 808(815.50) | Grad Norm 2.5934(2.0116) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 29.5691, Epoch Time 492.3883(494.1297), Bit/dim 3.9822(best: 3.9834), Xent 1.5062, Loss 4.7353, Error 0.4195(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2179 | Time 73.9462(74.6183) | Bit/dim 3.9761(3.9768) | Xent 0.5256(0.5246) | Loss 4.2389(4.2391) | Error 0.1903(0.1895) Steps 796(814.91) | Grad Norm 2.0398(2.0125) | Total Time 14.00(14.00)\n",
      "Iter 2180 | Time 76.6909(74.6805) | Bit/dim 3.9829(3.9770) | Xent 0.5167(0.5244) | Loss 4.2412(4.2392) | Error 0.1854(0.1893) Steps 826(815.25) | Grad Norm 3.3790(2.0535) | Total Time 14.00(14.00)\n",
      "Iter 2181 | Time 77.4247(74.7628) | Bit/dim 3.9670(3.9767) | Xent 0.4989(0.5236) | Loss 4.2165(4.2385) | Error 0.1781(0.1890) Steps 814(815.21) | Grad Norm 1.2816(2.0303) | Total Time 14.00(14.00)\n",
      "Iter 2182 | Time 75.7616(74.7928) | Bit/dim 3.9751(3.9766) | Xent 0.5211(0.5236) | Loss 4.2357(4.2384) | Error 0.1867(0.1889) Steps 802(814.81) | Grad Norm 3.1608(2.0642) | Total Time 14.00(14.00)\n",
      "Iter 2183 | Time 76.2494(74.8365) | Bit/dim 3.9708(3.9764) | Xent 0.5129(0.5232) | Loss 4.2273(4.2381) | Error 0.1871(0.1889) Steps 814(814.79) | Grad Norm 2.3000(2.0713) | Total Time 14.00(14.00)\n",
      "Iter 2184 | Time 74.6643(74.8313) | Bit/dim 3.9779(3.9765) | Xent 0.5263(0.5233) | Loss 4.2411(4.2382) | Error 0.1927(0.1890) Steps 820(814.94) | Grad Norm 1.8909(2.0659) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 29.4620, Epoch Time 499.8685(494.3018), Bit/dim 3.9815(best: 3.9822), Xent 1.5210, Loss 4.7420, Error 0.4195(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2185 | Time 72.0934(74.7492) | Bit/dim 3.9590(3.9760) | Xent 0.5287(0.5235) | Loss 4.2234(4.2377) | Error 0.1926(0.1891) Steps 820(815.10) | Grad Norm 3.0529(2.0955) | Total Time 14.00(14.00)\n",
      "Iter 2186 | Time 74.5033(74.7418) | Bit/dim 3.9801(3.9761) | Xent 0.5062(0.5230) | Loss 4.2332(4.2376) | Error 0.1843(0.1890) Steps 814(815.06) | Grad Norm 1.1345(2.0667) | Total Time 14.00(14.00)\n",
      "Iter 2187 | Time 72.5515(74.6761) | Bit/dim 3.9681(3.9759) | Xent 0.5124(0.5227) | Loss 4.2243(4.2372) | Error 0.1841(0.1888) Steps 808(814.85) | Grad Norm 1.8901(2.0614) | Total Time 14.00(14.00)\n",
      "Iter 2188 | Time 74.0597(74.6576) | Bit/dim 3.9837(3.9761) | Xent 0.5035(0.5221) | Loss 4.2354(4.2371) | Error 0.1805(0.1886) Steps 814(814.83) | Grad Norm 1.7912(2.0533) | Total Time 14.00(14.00)\n",
      "Iter 2189 | Time 75.8898(74.6946) | Bit/dim 3.9785(3.9762) | Xent 0.5123(0.5218) | Loss 4.2347(4.2371) | Error 0.1839(0.1884) Steps 820(814.98) | Grad Norm 1.4763(2.0359) | Total Time 14.00(14.00)\n",
      "Iter 2190 | Time 76.0986(74.7367) | Bit/dim 3.9805(3.9763) | Xent 0.5068(0.5213) | Loss 4.2339(4.2370) | Error 0.1833(0.1883) Steps 802(814.59) | Grad Norm 1.8421(2.0301) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 29.8837, Epoch Time 490.7169(494.1943), Bit/dim 3.9829(best: 3.9815), Xent 1.5418, Loss 4.7538, Error 0.4172(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2191 | Time 77.1695(74.8097) | Bit/dim 3.9785(3.9764) | Xent 0.5088(0.5210) | Loss 4.2329(4.2368) | Error 0.1801(0.1880) Steps 802(814.21) | Grad Norm 1.5889(2.0169) | Total Time 14.00(14.00)\n",
      "Iter 2192 | Time 73.4652(74.7693) | Bit/dim 3.9748(3.9763) | Xent 0.4979(0.5203) | Loss 4.2237(4.2364) | Error 0.1847(0.1879) Steps 820(814.39) | Grad Norm 1.8633(2.0123) | Total Time 14.00(14.00)\n",
      "Iter 2193 | Time 76.0793(74.8086) | Bit/dim 3.9766(3.9763) | Xent 0.5269(0.5205) | Loss 4.2401(4.2366) | Error 0.1897(0.1880) Steps 808(814.20) | Grad Norm 1.8812(2.0084) | Total Time 14.00(14.00)\n",
      "Iter 2194 | Time 76.6724(74.8646) | Bit/dim 3.9702(3.9761) | Xent 0.5325(0.5208) | Loss 4.2364(4.2365) | Error 0.1973(0.1883) Steps 826(814.55) | Grad Norm 2.5107(2.0234) | Total Time 14.00(14.00)\n",
      "Iter 2195 | Time 76.4281(74.9115) | Bit/dim 3.9752(3.9761) | Xent 0.5116(0.5206) | Loss 4.2310(4.2364) | Error 0.1883(0.1883) Steps 790(813.81) | Grad Norm 1.8695(2.0188) | Total Time 14.00(14.00)\n",
      "Iter 2196 | Time 75.3195(74.9237) | Bit/dim 3.9732(3.9760) | Xent 0.5011(0.5200) | Loss 4.2237(4.2360) | Error 0.1790(0.1880) Steps 796(813.28) | Grad Norm 2.0948(2.0211) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 29.7414, Epoch Time 500.5351(494.3845), Bit/dim 3.9825(best: 3.9815), Xent 1.5350, Loss 4.7500, Error 0.4220(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2197 | Time 76.3853(74.9676) | Bit/dim 3.9716(3.9759) | Xent 0.5166(0.5199) | Loss 4.2299(4.2358) | Error 0.1877(0.1880) Steps 814(813.30) | Grad Norm 2.3123(2.0298) | Total Time 14.00(14.00)\n",
      "Iter 2198 | Time 74.6346(74.9576) | Bit/dim 3.9698(3.9757) | Xent 0.5095(0.5196) | Loss 4.2245(4.2355) | Error 0.1831(0.1878) Steps 814(813.32) | Grad Norm 1.4622(2.0128) | Total Time 14.00(14.00)\n",
      "Iter 2199 | Time 76.8671(75.0148) | Bit/dim 3.9731(3.9756) | Xent 0.5089(0.5192) | Loss 4.2276(4.2352) | Error 0.1813(0.1876) Steps 796(812.80) | Grad Norm 3.1226(2.0461) | Total Time 14.00(14.00)\n",
      "Iter 2200 | Time 75.9303(75.0423) | Bit/dim 3.9756(3.9756) | Xent 0.5134(0.5191) | Loss 4.2323(4.2352) | Error 0.1873(0.1876) Steps 814(812.84) | Grad Norm 1.3122(2.0241) | Total Time 14.00(14.00)\n",
      "Iter 2201 | Time 73.4239(74.9938) | Bit/dim 3.9812(3.9758) | Xent 0.5064(0.5187) | Loss 4.2344(4.2351) | Error 0.1794(0.1874) Steps 820(813.05) | Grad Norm 2.2080(2.0296) | Total Time 14.00(14.00)\n",
      "Iter 2202 | Time 72.5075(74.9192) | Bit/dim 3.9716(3.9757) | Xent 0.5104(0.5184) | Loss 4.2268(4.2349) | Error 0.1827(0.1872) Steps 814(813.08) | Grad Norm 3.5898(2.0764) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 29.9977, Epoch Time 495.4813(494.4174), Bit/dim 3.9819(best: 3.9815), Xent 1.5437, Loss 4.7537, Error 0.4233(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2203 | Time 72.0168(74.8321) | Bit/dim 3.9781(3.9757) | Xent 0.5173(0.5184) | Loss 4.2368(4.2349) | Error 0.1865(0.1872) Steps 820(813.29) | Grad Norm 1.3050(2.0533) | Total Time 14.00(14.00)\n",
      "Iter 2204 | Time 77.7768(74.9204) | Bit/dim 3.9711(3.9756) | Xent 0.5180(0.5184) | Loss 4.2301(4.2348) | Error 0.1861(0.1872) Steps 814(813.31) | Grad Norm 2.8823(2.0781) | Total Time 14.00(14.00)\n",
      "Iter 2205 | Time 75.7473(74.9452) | Bit/dim 3.9734(3.9755) | Xent 0.4942(0.5177) | Loss 4.2205(4.2344) | Error 0.1763(0.1869) Steps 826(813.69) | Grad Norm 2.4372(2.0889) | Total Time 14.00(14.00)\n",
      "Iter 2206 | Time 75.9202(74.9745) | Bit/dim 3.9701(3.9754) | Xent 0.5007(0.5172) | Loss 4.2205(4.2340) | Error 0.1834(0.1867) Steps 820(813.88) | Grad Norm 1.2560(2.0639) | Total Time 14.00(14.00)\n",
      "Iter 2207 | Time 74.3432(74.9556) | Bit/dim 3.9768(3.9754) | Xent 0.5090(0.5169) | Loss 4.2313(4.2339) | Error 0.1824(0.1866) Steps 820(814.06) | Grad Norm 1.6716(2.0521) | Total Time 14.00(14.00)\n",
      "Iter 2208 | Time 75.9649(74.9858) | Bit/dim 3.9813(3.9756) | Xent 0.5226(0.5171) | Loss 4.2426(4.2341) | Error 0.1869(0.1866) Steps 814(814.06) | Grad Norm 2.0320(2.0515) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 29.7873, Epoch Time 497.5888(494.5126), Bit/dim 3.9817(best: 3.9815), Xent 1.5290, Loss 4.7462, Error 0.4170(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2209 | Time 74.3617(74.9671) | Bit/dim 3.9759(3.9756) | Xent 0.4999(0.5166) | Loss 4.2258(4.2339) | Error 0.1789(0.1864) Steps 796(813.52) | Grad Norm 1.4583(2.0337) | Total Time 14.00(14.00)\n",
      "Iter 2210 | Time 74.3572(74.9488) | Bit/dim 3.9784(3.9757) | Xent 0.5214(0.5167) | Loss 4.2391(4.2340) | Error 0.1855(0.1864) Steps 814(813.53) | Grad Norm 3.2560(2.0704) | Total Time 14.00(14.00)\n",
      "Iter 2211 | Time 74.3654(74.9313) | Bit/dim 3.9712(3.9755) | Xent 0.5255(0.5170) | Loss 4.2339(4.2340) | Error 0.1890(0.1864) Steps 814(813.55) | Grad Norm 1.7234(2.0600) | Total Time 14.00(14.00)\n",
      "Iter 2212 | Time 74.3962(74.9153) | Bit/dim 3.9722(3.9754) | Xent 0.5089(0.5167) | Loss 4.2266(4.2338) | Error 0.1879(0.1865) Steps 820(813.74) | Grad Norm 1.9950(2.0581) | Total Time 14.00(14.00)\n",
      "Iter 2213 | Time 75.1796(74.9232) | Bit/dim 3.9763(3.9755) | Xent 0.5017(0.5163) | Loss 4.2272(4.2336) | Error 0.1827(0.1864) Steps 814(813.75) | Grad Norm 1.9931(2.0561) | Total Time 14.00(14.00)\n",
      "Iter 2214 | Time 74.9736(74.9247) | Bit/dim 3.9729(3.9754) | Xent 0.4982(0.5157) | Loss 4.2220(4.2333) | Error 0.1767(0.1861) Steps 814(813.76) | Grad Norm 2.0600(2.0562) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 29.8154, Epoch Time 493.0422(494.4685), Bit/dim 3.9807(best: 3.9815), Xent 1.5375, Loss 4.7495, Error 0.4207(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2215 | Time 73.8977(74.8939) | Bit/dim 3.9787(3.9755) | Xent 0.5093(0.5155) | Loss 4.2333(4.2333) | Error 0.1803(0.1859) Steps 802(813.40) | Grad Norm 2.2543(2.0622) | Total Time 14.00(14.00)\n",
      "Iter 2216 | Time 75.4739(74.9113) | Bit/dim 3.9666(3.9752) | Xent 0.5014(0.5151) | Loss 4.2173(4.2328) | Error 0.1789(0.1857) Steps 826(813.78) | Grad Norm 1.2656(2.0383) | Total Time 14.00(14.00)\n",
      "Iter 2217 | Time 75.1044(74.9171) | Bit/dim 3.9759(3.9753) | Xent 0.5119(0.5150) | Loss 4.2319(4.2328) | Error 0.1827(0.1856) Steps 814(813.79) | Grad Norm 1.8702(2.0332) | Total Time 14.00(14.00)\n",
      "Iter 2218 | Time 75.5519(74.9361) | Bit/dim 3.9763(3.9753) | Xent 0.5044(0.5147) | Loss 4.2285(4.2326) | Error 0.1859(0.1856) Steps 814(813.79) | Grad Norm 1.7533(2.0248) | Total Time 14.00(14.00)\n",
      "Iter 2219 | Time 77.0807(75.0005) | Bit/dim 3.9723(3.9752) | Xent 0.5071(0.5145) | Loss 4.2258(4.2324) | Error 0.1816(0.1855) Steps 814(813.80) | Grad Norm 1.9491(2.0226) | Total Time 14.00(14.00)\n",
      "Iter 2220 | Time 72.2725(74.9186) | Bit/dim 3.9766(3.9752) | Xent 0.4978(0.5140) | Loss 4.2255(4.2322) | Error 0.1810(0.1854) Steps 802(813.45) | Grad Norm 2.4679(2.0359) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 29.9550, Epoch Time 495.0248(494.4851), Bit/dim 3.9811(best: 3.9807), Xent 1.5427, Loss 4.7525, Error 0.4182(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2221 | Time 74.3945(74.9029) | Bit/dim 3.9749(3.9752) | Xent 0.5018(0.5136) | Loss 4.2258(4.2320) | Error 0.1745(0.1850) Steps 808(813.28) | Grad Norm 1.8498(2.0303) | Total Time 14.00(14.00)\n",
      "Iter 2222 | Time 74.8879(74.9025) | Bit/dim 3.9786(3.9753) | Xent 0.5170(0.5137) | Loss 4.2371(4.2322) | Error 0.1936(0.1853) Steps 802(812.95) | Grad Norm 1.6817(2.0199) | Total Time 14.00(14.00)\n",
      "Iter 2223 | Time 72.2983(74.8243) | Bit/dim 3.9716(3.9752) | Xent 0.4881(0.5129) | Loss 4.2156(4.2317) | Error 0.1756(0.1850) Steps 820(813.16) | Grad Norm 2.1602(2.0241) | Total Time 14.00(14.00)\n",
      "Iter 2224 | Time 74.7799(74.8230) | Bit/dim 3.9677(3.9750) | Xent 0.5205(0.5132) | Loss 4.2280(4.2316) | Error 0.1877(0.1851) Steps 814(813.18) | Grad Norm 2.2453(2.0307) | Total Time 14.00(14.00)\n",
      "Iter 2225 | Time 74.2432(74.8056) | Bit/dim 3.9725(3.9749) | Xent 0.4857(0.5123) | Loss 4.2154(4.2311) | Error 0.1787(0.1849) Steps 832(813.75) | Grad Norm 1.9034(2.0269) | Total Time 14.00(14.00)\n",
      "Iter 2226 | Time 74.2657(74.7894) | Bit/dim 3.9767(3.9750) | Xent 0.5139(0.5124) | Loss 4.2337(4.2312) | Error 0.1855(0.1849) Steps 820(813.93) | Grad Norm 1.9171(2.0236) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 30.0859, Epoch Time 490.5726(494.3678), Bit/dim 3.9809(best: 3.9807), Xent 1.5499, Loss 4.7559, Error 0.4219(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2227 | Time 73.8232(74.7604) | Bit/dim 3.9785(3.9751) | Xent 0.5043(0.5122) | Loss 4.2306(4.2312) | Error 0.1791(0.1847) Steps 802(813.58) | Grad Norm 1.3464(2.0033) | Total Time 14.00(14.00)\n",
      "Iter 2228 | Time 74.2828(74.7461) | Bit/dim 3.9737(3.9750) | Xent 0.4903(0.5115) | Loss 4.2189(4.2308) | Error 0.1787(0.1846) Steps 808(813.41) | Grad Norm 1.2481(1.9806) | Total Time 14.00(14.00)\n",
      "Iter 2229 | Time 75.7033(74.7748) | Bit/dim 3.9724(3.9750) | Xent 0.5133(0.5115) | Loss 4.2290(4.2307) | Error 0.1795(0.1844) Steps 808(813.25) | Grad Norm 1.9516(1.9798) | Total Time 14.00(14.00)\n",
      "Iter 2230 | Time 74.8599(74.7774) | Bit/dim 3.9689(3.9748) | Xent 0.4990(0.5112) | Loss 4.2184(4.2304) | Error 0.1836(0.1844) Steps 808(813.09) | Grad Norm 1.2599(1.9582) | Total Time 14.00(14.00)\n",
      "Iter 2231 | Time 73.8886(74.7507) | Bit/dim 3.9711(3.9747) | Xent 0.5080(0.5111) | Loss 4.2251(4.2302) | Error 0.1850(0.1844) Steps 820(813.30) | Grad Norm 1.0675(1.9314) | Total Time 14.00(14.00)\n",
      "Iter 2232 | Time 74.2534(74.7358) | Bit/dim 3.9691(3.9745) | Xent 0.4885(0.5104) | Loss 4.2134(4.2297) | Error 0.1825(0.1843) Steps 820(813.50) | Grad Norm 2.2992(1.9425) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 29.9163, Epoch Time 492.3320(494.3067), Bit/dim 3.9798(best: 3.9807), Xent 1.5547, Loss 4.7571, Error 0.4210(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2233 | Time 72.1063(74.6569) | Bit/dim 3.9722(3.9744) | Xent 0.5099(0.5104) | Loss 4.2271(4.2296) | Error 0.1853(0.1844) Steps 808(813.33) | Grad Norm 1.5012(1.9292) | Total Time 14.00(14.00)\n",
      "Iter 2234 | Time 73.7585(74.6299) | Bit/dim 3.9805(3.9746) | Xent 0.4794(0.5095) | Loss 4.2202(4.2293) | Error 0.1764(0.1841) Steps 808(813.17) | Grad Norm 1.2627(1.9092) | Total Time 14.00(14.00)\n",
      "Iter 2235 | Time 72.1317(74.5550) | Bit/dim 3.9611(3.9742) | Xent 0.5136(0.5096) | Loss 4.2179(4.2290) | Error 0.1911(0.1843) Steps 820(813.38) | Grad Norm 1.0245(1.8827) | Total Time 14.00(14.00)\n",
      "Iter 2236 | Time 74.4239(74.5511) | Bit/dim 3.9742(3.9742) | Xent 0.4967(0.5092) | Loss 4.2226(4.2288) | Error 0.1805(0.1842) Steps 802(813.04) | Grad Norm 1.3320(1.8662) | Total Time 14.00(14.00)\n",
      "Iter 2237 | Time 75.0090(74.5648) | Bit/dim 3.9644(3.9739) | Xent 0.4971(0.5088) | Loss 4.2129(4.2283) | Error 0.1813(0.1841) Steps 820(813.25) | Grad Norm 1.4634(1.8541) | Total Time 14.00(14.00)\n",
      "Iter 2238 | Time 73.1970(74.5238) | Bit/dim 3.9815(3.9741) | Xent 0.4871(0.5082) | Loss 4.2251(4.2282) | Error 0.1754(0.1839) Steps 808(813.09) | Grad Norm 1.6980(1.8494) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 29.8303, Epoch Time 485.9913(494.0572), Bit/dim 3.9822(best: 3.9798), Xent 1.5722, Loss 4.7683, Error 0.4241(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2239 | Time 72.4084(74.4603) | Bit/dim 3.9678(3.9740) | Xent 0.4983(0.5079) | Loss 4.2169(4.2279) | Error 0.1774(0.1837) Steps 814(813.12) | Grad Norm 2.4509(1.8675) | Total Time 14.00(14.00)\n",
      "Iter 2240 | Time 74.9863(74.4761) | Bit/dim 3.9745(3.9740) | Xent 0.4941(0.5075) | Loss 4.2216(4.2277) | Error 0.1787(0.1835) Steps 802(812.78) | Grad Norm 1.5325(1.8574) | Total Time 14.00(14.00)\n",
      "Iter 2241 | Time 74.9109(74.4891) | Bit/dim 3.9711(3.9739) | Xent 0.4869(0.5068) | Loss 4.2145(4.2273) | Error 0.1810(0.1835) Steps 802(812.46) | Grad Norm 2.4290(1.8746) | Total Time 14.00(14.00)\n",
      "Iter 2242 | Time 75.3379(74.5146) | Bit/dim 3.9779(3.9740) | Xent 0.4987(0.5066) | Loss 4.2272(4.2273) | Error 0.1819(0.1834) Steps 808(812.32) | Grad Norm 1.1437(1.8526) | Total Time 14.00(14.00)\n",
      "Iter 2243 | Time 72.2325(74.4461) | Bit/dim 3.9754(3.9740) | Xent 0.5045(0.5065) | Loss 4.2276(4.2273) | Error 0.1834(0.1834) Steps 802(812.01) | Grad Norm 1.7109(1.8484) | Total Time 14.00(14.00)\n",
      "Iter 2244 | Time 74.1175(74.4363) | Bit/dim 3.9691(3.9739) | Xent 0.4945(0.5062) | Loss 4.2164(4.2270) | Error 0.1737(0.1831) Steps 808(811.89) | Grad Norm 1.2757(1.8312) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 29.8892, Epoch Time 489.2606(493.9133), Bit/dim 3.9804(best: 3.9798), Xent 1.5682, Loss 4.7646, Error 0.4195(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2245 | Time 73.7740(74.4164) | Bit/dim 3.9734(3.9739) | Xent 0.4974(0.5059) | Loss 4.2221(4.2268) | Error 0.1784(0.1830) Steps 808(811.78) | Grad Norm 1.7585(1.8290) | Total Time 14.00(14.00)\n",
      "Iter 2246 | Time 73.7632(74.3968) | Bit/dim 3.9654(3.9736) | Xent 0.4960(0.5056) | Loss 4.2134(4.2264) | Error 0.1776(0.1828) Steps 814(811.84) | Grad Norm 1.4056(1.8163) | Total Time 14.00(14.00)\n",
      "Iter 2247 | Time 73.0496(74.3564) | Bit/dim 3.9693(3.9735) | Xent 0.5073(0.5057) | Loss 4.2230(4.2263) | Error 0.1843(0.1829) Steps 802(811.55) | Grad Norm 2.8896(1.8485) | Total Time 14.00(14.00)\n",
      "Iter 2248 | Time 73.6830(74.3362) | Bit/dim 3.9739(3.9735) | Xent 0.4972(0.5054) | Loss 4.2225(4.2262) | Error 0.1767(0.1827) Steps 814(811.62) | Grad Norm 1.9885(1.8527) | Total Time 14.00(14.00)\n",
      "Iter 2249 | Time 75.7475(74.3785) | Bit/dim 3.9768(3.9736) | Xent 0.4972(0.5052) | Loss 4.2255(4.2262) | Error 0.1799(0.1826) Steps 814(811.69) | Grad Norm 2.4334(1.8701) | Total Time 14.00(14.00)\n",
      "Iter 2250 | Time 74.4386(74.3803) | Bit/dim 3.9697(3.9735) | Xent 0.4940(0.5048) | Loss 4.2167(4.2259) | Error 0.1765(0.1824) Steps 796(811.22) | Grad Norm 1.1367(1.8481) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 29.6455, Epoch Time 489.6828(493.7864), Bit/dim 3.9794(best: 3.9798), Xent 1.5605, Loss 4.7597, Error 0.4231(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2251 | Time 75.8379(74.4241) | Bit/dim 3.9814(3.9737) | Xent 0.4850(0.5042) | Loss 4.2239(4.2259) | Error 0.1817(0.1824) Steps 802(810.95) | Grad Norm 2.0329(1.8537) | Total Time 14.00(14.00)\n",
      "Iter 2252 | Time 76.1938(74.4772) | Bit/dim 3.9651(3.9735) | Xent 0.5059(0.5043) | Loss 4.2180(4.2256) | Error 0.1834(0.1824) Steps 802(810.68) | Grad Norm 1.8152(1.8525) | Total Time 14.00(14.00)\n",
      "Iter 2253 | Time 73.8014(74.4569) | Bit/dim 3.9659(3.9732) | Xent 0.5149(0.5046) | Loss 4.2234(4.2255) | Error 0.1865(0.1825) Steps 814(810.78) | Grad Norm 2.9631(1.8858) | Total Time 14.00(14.00)\n",
      "Iter 2254 | Time 74.6987(74.4641) | Bit/dim 3.9719(3.9732) | Xent 0.4963(0.5044) | Loss 4.2201(4.2254) | Error 0.1829(0.1826) Steps 814(810.87) | Grad Norm 2.4318(1.9022) | Total Time 14.00(14.00)\n",
      "Iter 2255 | Time 75.1590(74.4850) | Bit/dim 3.9846(3.9735) | Xent 0.4788(0.5036) | Loss 4.2240(4.2253) | Error 0.1715(0.1822) Steps 808(810.79) | Grad Norm 2.0680(1.9072) | Total Time 14.00(14.00)\n",
      "Iter 2256 | Time 75.1147(74.5039) | Bit/dim 3.9607(3.9732) | Xent 0.5136(0.5039) | Loss 4.2175(4.2251) | Error 0.1836(0.1823) Steps 814(810.88) | Grad Norm 2.7759(1.9333) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 29.6923, Epoch Time 496.1131(493.8562), Bit/dim 3.9797(best: 3.9794), Xent 1.5632, Loss 4.7613, Error 0.4224(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2257 | Time 73.5234(74.4745) | Bit/dim 3.9684(3.9730) | Xent 0.4920(0.5035) | Loss 4.2144(4.2248) | Error 0.1817(0.1822) Steps 796(810.44) | Grad Norm 1.8241(1.9300) | Total Time 14.00(14.00)\n",
      "Iter 2258 | Time 74.6965(74.4811) | Bit/dim 3.9716(3.9730) | Xent 0.4784(0.5028) | Loss 4.2108(4.2244) | Error 0.1704(0.1819) Steps 802(810.18) | Grad Norm 1.5445(1.9184) | Total Time 14.00(14.00)\n",
      "Iter 2259 | Time 74.8567(74.4924) | Bit/dim 3.9802(3.9732) | Xent 0.5022(0.5028) | Loss 4.2313(4.2246) | Error 0.1809(0.1819) Steps 808(810.12) | Grad Norm 2.2823(1.9293) | Total Time 14.00(14.00)\n",
      "Iter 2260 | Time 72.1450(74.4220) | Bit/dim 3.9656(3.9730) | Xent 0.4946(0.5025) | Loss 4.2129(4.2242) | Error 0.1791(0.1818) Steps 808(810.06) | Grad Norm 2.2643(1.9394) | Total Time 14.00(14.00)\n",
      "Iter 2261 | Time 77.3599(74.5101) | Bit/dim 3.9706(3.9729) | Xent 0.4973(0.5024) | Loss 4.2192(4.2241) | Error 0.1756(0.1816) Steps 808(809.99) | Grad Norm 0.9651(1.9101) | Total Time 14.00(14.00)\n",
      "Iter 2262 | Time 76.2673(74.5628) | Bit/dim 3.9736(3.9729) | Xent 0.4956(0.5022) | Loss 4.2214(4.2240) | Error 0.1800(0.1815) Steps 796(809.57) | Grad Norm 1.3247(1.8926) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 29.7792, Epoch Time 494.2416(493.8678), Bit/dim 3.9794(best: 3.9794), Xent 1.5745, Loss 4.7667, Error 0.4243(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2263 | Time 75.6790(74.5963) | Bit/dim 3.9681(3.9728) | Xent 0.5119(0.5025) | Loss 4.2240(4.2240) | Error 0.1853(0.1817) Steps 808(809.53) | Grad Norm 2.1134(1.8992) | Total Time 14.00(14.00)\n",
      "Iter 2264 | Time 74.2087(74.5847) | Bit/dim 3.9659(3.9726) | Xent 0.4936(0.5022) | Loss 4.2127(4.2237) | Error 0.1800(0.1816) Steps 802(809.30) | Grad Norm 1.5658(1.8892) | Total Time 14.00(14.00)\n",
      "Iter 2265 | Time 73.0490(74.5386) | Bit/dim 3.9757(3.9727) | Xent 0.4981(0.5021) | Loss 4.2247(4.2237) | Error 0.1764(0.1815) Steps 808(809.26) | Grad Norm 2.2549(1.9002) | Total Time 14.00(14.00)\n",
      "Iter 2266 | Time 71.8207(74.4571) | Bit/dim 3.9644(3.9724) | Xent 0.4927(0.5018) | Loss 4.2107(4.2233) | Error 0.1783(0.1814) Steps 802(809.04) | Grad Norm 1.3904(1.8849) | Total Time 14.00(14.00)\n",
      "Iter 2267 | Time 72.9467(74.4118) | Bit/dim 3.9798(3.9726) | Xent 0.4816(0.5012) | Loss 4.2206(4.2232) | Error 0.1763(0.1812) Steps 808(809.01) | Grad Norm 1.2839(1.8669) | Total Time 14.00(14.00)\n",
      "Iter 2268 | Time 74.7002(74.4204) | Bit/dim 3.9714(3.9726) | Xent 0.5106(0.5015) | Loss 4.2267(4.2233) | Error 0.1865(0.1814) Steps 796(808.62) | Grad Norm 1.8115(1.8652) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 29.7742, Epoch Time 487.7517(493.6843), Bit/dim 3.9795(best: 3.9794), Xent 1.5905, Loss 4.7747, Error 0.4249(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2269 | Time 75.4757(74.4521) | Bit/dim 3.9739(3.9726) | Xent 0.5029(0.5015) | Loss 4.2254(4.2234) | Error 0.1807(0.1813) Steps 808(808.60) | Grad Norm 1.4527(1.8528) | Total Time 14.00(14.00)\n",
      "Iter 2270 | Time 72.9976(74.4084) | Bit/dim 3.9654(3.9724) | Xent 0.4870(0.5011) | Loss 4.2090(4.2230) | Error 0.1729(0.1811) Steps 814(808.77) | Grad Norm 2.1444(1.8616) | Total Time 14.00(14.00)\n",
      "Iter 2271 | Time 76.4234(74.4689) | Bit/dim 3.9723(3.9724) | Xent 0.4843(0.5006) | Loss 4.2144(4.2227) | Error 0.1760(0.1809) Steps 802(808.56) | Grad Norm 1.4036(1.8478) | Total Time 14.00(14.00)\n",
      "Iter 2272 | Time 74.6687(74.4749) | Bit/dim 3.9722(3.9724) | Xent 0.5035(0.5007) | Loss 4.2240(4.2227) | Error 0.1825(0.1810) Steps 814(808.73) | Grad Norm 2.1140(1.8558) | Total Time 14.00(14.00)\n",
      "Iter 2273 | Time 73.7664(74.4536) | Bit/dim 3.9637(3.9721) | Xent 0.4811(0.5001) | Loss 4.2042(4.2222) | Error 0.1783(0.1809) Steps 808(808.70) | Grad Norm 2.2729(1.8683) | Total Time 14.00(14.00)\n",
      "Iter 2274 | Time 74.0073(74.4402) | Bit/dim 3.9790(3.9724) | Xent 0.4896(0.4998) | Loss 4.2238(4.2222) | Error 0.1710(0.1806) Steps 820(809.04) | Grad Norm 2.9069(1.8995) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 29.8975, Epoch Time 492.9223(493.6614), Bit/dim 3.9785(best: 3.9794), Xent 1.5726, Loss 4.7648, Error 0.4235(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2275 | Time 76.5111(74.5024) | Bit/dim 3.9648(3.9721) | Xent 0.4896(0.4995) | Loss 4.2096(4.2219) | Error 0.1751(0.1804) Steps 814(809.19) | Grad Norm 2.4638(1.9164) | Total Time 14.00(14.00)\n",
      "Iter 2276 | Time 77.5868(74.5949) | Bit/dim 3.9665(3.9720) | Xent 0.5036(0.4996) | Loss 4.2183(4.2217) | Error 0.1843(0.1806) Steps 802(808.98) | Grad Norm 1.9858(1.9185) | Total Time 14.00(14.00)\n",
      "Iter 2277 | Time 72.9644(74.5460) | Bit/dim 3.9794(3.9722) | Xent 0.5025(0.4997) | Loss 4.2306(4.2220) | Error 0.1830(0.1806) Steps 808(808.95) | Grad Norm 3.1710(1.9561) | Total Time 14.00(14.00)\n",
      "Iter 2278 | Time 75.5581(74.5763) | Bit/dim 3.9717(3.9722) | Xent 0.4753(0.4989) | Loss 4.2094(4.2216) | Error 0.1690(0.1803) Steps 820(809.28) | Grad Norm 1.1067(1.9306) | Total Time 14.00(14.00)\n",
      "Iter 2279 | Time 73.1963(74.5349) | Bit/dim 3.9721(3.9722) | Xent 0.4957(0.4988) | Loss 4.2200(4.2216) | Error 0.1811(0.1803) Steps 802(809.06) | Grad Norm 3.2092(1.9689) | Total Time 14.00(14.00)\n",
      "Iter 2280 | Time 74.6038(74.5370) | Bit/dim 3.9711(3.9721) | Xent 0.4854(0.4984) | Loss 4.2138(4.2214) | Error 0.1783(0.1802) Steps 826(809.57) | Grad Norm 1.3288(1.9497) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 29.7935, Epoch Time 495.9468(493.7300), Bit/dim 3.9781(best: 3.9785), Xent 1.5793, Loss 4.7677, Error 0.4237(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2281 | Time 76.0516(74.5825) | Bit/dim 3.9679(3.9720) | Xent 0.4988(0.4984) | Loss 4.2173(4.2212) | Error 0.1806(0.1803) Steps 814(809.70) | Grad Norm 1.3882(1.9329) | Total Time 14.00(14.00)\n",
      "Iter 2282 | Time 73.7148(74.5564) | Bit/dim 3.9802(3.9723) | Xent 0.4645(0.4974) | Loss 4.2125(4.2210) | Error 0.1691(0.1799) Steps 820(810.01) | Grad Norm 1.7995(1.9289) | Total Time 14.00(14.00)\n",
      "Iter 2283 | Time 73.8413(74.5350) | Bit/dim 3.9657(3.9721) | Xent 0.4603(0.4963) | Loss 4.1958(4.2202) | Error 0.1675(0.1795) Steps 814(810.13) | Grad Norm 1.0664(1.9030) | Total Time 14.00(14.00)\n",
      "Iter 2284 | Time 77.0509(74.6104) | Bit/dim 3.9692(3.9720) | Xent 0.4854(0.4960) | Loss 4.2119(4.2200) | Error 0.1771(0.1795) Steps 808(810.07) | Grad Norm 2.3863(1.9175) | Total Time 14.00(14.00)\n",
      "Iter 2285 | Time 74.0171(74.5926) | Bit/dim 3.9606(3.9716) | Xent 0.5070(0.4963) | Loss 4.2141(4.2198) | Error 0.1830(0.1796) Steps 814(810.18) | Grad Norm 1.8024(1.9141) | Total Time 14.00(14.00)\n",
      "Iter 2286 | Time 74.2403(74.5821) | Bit/dim 3.9738(3.9717) | Xent 0.5047(0.4966) | Loss 4.2261(4.2200) | Error 0.1819(0.1796) Steps 802(809.94) | Grad Norm 2.7982(1.9406) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 29.7711, Epoch Time 494.1296(493.7420), Bit/dim 3.9786(best: 3.9781), Xent 1.6006, Loss 4.7788, Error 0.4208(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2287 | Time 71.2851(74.4832) | Bit/dim 3.9730(3.9717) | Xent 0.4788(0.4960) | Loss 4.2124(4.2197) | Error 0.1729(0.1794) Steps 808(809.88) | Grad Norm 3.9166(1.9999) | Total Time 14.00(14.00)\n",
      "Iter 2288 | Time 73.8597(74.4645) | Bit/dim 3.9588(3.9713) | Xent 0.4891(0.4958) | Loss 4.2034(4.2193) | Error 0.1809(0.1795) Steps 820(810.18) | Grad Norm 2.7067(2.0211) | Total Time 14.00(14.00)\n",
      "Iter 2289 | Time 74.8886(74.4772) | Bit/dim 3.9831(3.9717) | Xent 0.4897(0.4956) | Loss 4.2279(4.2195) | Error 0.1731(0.1793) Steps 796(809.76) | Grad Norm 4.3150(2.0899) | Total Time 14.00(14.00)\n",
      "Iter 2290 | Time 75.9743(74.5221) | Bit/dim 3.9721(3.9717) | Xent 0.4923(0.4955) | Loss 4.2182(4.2195) | Error 0.1775(0.1792) Steps 814(809.89) | Grad Norm 2.1851(2.0927) | Total Time 14.00(14.00)\n",
      "Iter 2291 | Time 73.2085(74.4827) | Bit/dim 3.9711(3.9717) | Xent 0.4962(0.4956) | Loss 4.2192(4.2195) | Error 0.1819(0.1793) Steps 802(809.65) | Grad Norm 4.7403(2.1722) | Total Time 14.00(14.00)\n",
      "Iter 2292 | Time 77.1472(74.5626) | Bit/dim 3.9643(3.9715) | Xent 0.4912(0.4954) | Loss 4.2099(4.2192) | Error 0.1755(0.1792) Steps 820(809.96) | Grad Norm 3.4477(2.2104) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 29.8886, Epoch Time 491.9227(493.6874), Bit/dim 3.9778(best: 3.9781), Xent 1.5698, Loss 4.7627, Error 0.4244(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2293 | Time 72.4501(74.4993) | Bit/dim 3.9779(3.9717) | Xent 0.4868(0.4952) | Loss 4.2213(4.2192) | Error 0.1774(0.1792) Steps 808(809.90) | Grad Norm 2.5508(2.2206) | Total Time 14.00(14.00)\n",
      "Iter 2294 | Time 73.8955(74.4811) | Bit/dim 3.9728(3.9717) | Xent 0.4813(0.4948) | Loss 4.2135(4.2191) | Error 0.1747(0.1790) Steps 814(810.02) | Grad Norm 5.1702(2.3091) | Total Time 14.00(14.00)\n",
      "Iter 2295 | Time 77.7218(74.5784) | Bit/dim 3.9648(3.9715) | Xent 0.4914(0.4947) | Loss 4.2106(4.2188) | Error 0.1713(0.1788) Steps 814(810.14) | Grad Norm 1.9883(2.2995) | Total Time 14.00(14.00)\n",
      "Iter 2296 | Time 73.2093(74.5373) | Bit/dim 3.9641(3.9713) | Xent 0.4967(0.4947) | Loss 4.2124(4.2186) | Error 0.1805(0.1788) Steps 808(810.08) | Grad Norm 4.4202(2.3631) | Total Time 14.00(14.00)\n",
      "Iter 2297 | Time 74.3821(74.5326) | Bit/dim 3.9666(3.9711) | Xent 0.4850(0.4944) | Loss 4.2091(4.2183) | Error 0.1761(0.1788) Steps 808(810.02) | Grad Norm 2.7743(2.3755) | Total Time 14.00(14.00)\n",
      "Iter 2298 | Time 74.8871(74.5433) | Bit/dim 3.9717(3.9711) | Xent 0.4932(0.4944) | Loss 4.2183(4.2183) | Error 0.1766(0.1787) Steps 820(810.32) | Grad Norm 4.2860(2.4328) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 29.7327, Epoch Time 491.8713(493.6329), Bit/dim 3.9779(best: 3.9778), Xent 1.5977, Loss 4.7768, Error 0.4249(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2299 | Time 73.6168(74.5155) | Bit/dim 3.9606(3.9708) | Xent 0.4915(0.4943) | Loss 4.2063(4.2180) | Error 0.1761(0.1786) Steps 808(810.25) | Grad Norm 3.9431(2.4781) | Total Time 14.00(14.00)\n",
      "Iter 2300 | Time 74.7630(74.5229) | Bit/dim 3.9703(3.9708) | Xent 0.4893(0.4942) | Loss 4.2150(4.2179) | Error 0.1787(0.1786) Steps 814(810.36) | Grad Norm 2.9580(2.4925) | Total Time 14.00(14.00)\n",
      "Iter 2301 | Time 71.3269(74.4270) | Bit/dim 3.9786(3.9710) | Xent 0.4870(0.4939) | Loss 4.2221(4.2180) | Error 0.1734(0.1785) Steps 814(810.47) | Grad Norm 4.1781(2.5431) | Total Time 14.00(14.00)\n",
      "Iter 2302 | Time 73.0352(74.3853) | Bit/dim 3.9625(3.9708) | Xent 0.4816(0.4936) | Loss 4.2033(4.2176) | Error 0.1743(0.1783) Steps 814(810.57) | Grad Norm 1.2387(2.5039) | Total Time 14.00(14.00)\n",
      "Iter 2303 | Time 76.9953(74.4636) | Bit/dim 3.9778(3.9710) | Xent 0.4784(0.4931) | Loss 4.2169(4.2176) | Error 0.1743(0.1782) Steps 796(810.14) | Grad Norm 3.5437(2.5351) | Total Time 14.00(14.00)\n",
      "Iter 2304 | Time 75.5630(74.4965) | Bit/dim 3.9687(3.9709) | Xent 0.4705(0.4924) | Loss 4.2040(4.2171) | Error 0.1684(0.1779) Steps 814(810.25) | Grad Norm 2.4116(2.5314) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 29.8720, Epoch Time 491.0961(493.5568), Bit/dim 3.9784(best: 3.9778), Xent 1.5896, Loss 4.7732, Error 0.4236(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2305 | Time 73.5054(74.4668) | Bit/dim 3.9701(3.9709) | Xent 0.4777(0.4920) | Loss 4.2090(4.2169) | Error 0.1717(0.1777) Steps 820(810.55) | Grad Norm 2.5180(2.5310) | Total Time 14.00(14.00)\n",
      "Iter 2306 | Time 75.2652(74.4908) | Bit/dim 3.9753(3.9710) | Xent 0.4741(0.4915) | Loss 4.2123(4.2168) | Error 0.1760(0.1777) Steps 814(810.65) | Grad Norm 2.4520(2.5286) | Total Time 14.00(14.00)\n",
      "Iter 2307 | Time 73.9636(74.4750) | Bit/dim 3.9622(3.9708) | Xent 0.4774(0.4910) | Loss 4.2009(4.2163) | Error 0.1725(0.1775) Steps 802(810.39) | Grad Norm 2.6439(2.5321) | Total Time 14.00(14.00)\n",
      "Iter 2308 | Time 75.4422(74.5040) | Bit/dim 3.9658(3.9706) | Xent 0.4915(0.4910) | Loss 4.2116(4.2161) | Error 0.1806(0.1776) Steps 790(809.78) | Grad Norm 2.6055(2.5343) | Total Time 14.00(14.00)\n",
      "Iter 2309 | Time 74.9153(74.5163) | Bit/dim 3.9711(3.9706) | Xent 0.4857(0.4909) | Loss 4.2139(4.2161) | Error 0.1757(0.1776) Steps 814(809.90) | Grad Norm 1.9141(2.5157) | Total Time 14.00(14.00)\n",
      "Iter 2310 | Time 73.2673(74.4788) | Bit/dim 3.9649(3.9705) | Xent 0.4742(0.4904) | Loss 4.2020(4.2157) | Error 0.1761(0.1775) Steps 814(810.03) | Grad Norm 2.7290(2.5221) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 29.6532, Epoch Time 491.2901(493.4888), Bit/dim 3.9780(best: 3.9778), Xent 1.6093, Loss 4.7827, Error 0.4211(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2311 | Time 75.2797(74.5029) | Bit/dim 3.9690(3.9704) | Xent 0.4714(0.4898) | Loss 4.2048(4.2153) | Error 0.1691(0.1773) Steps 814(810.15) | Grad Norm 2.1866(2.5120) | Total Time 14.00(14.00)\n",
      "Iter 2312 | Time 74.4417(74.5010) | Bit/dim 3.9646(3.9702) | Xent 0.4738(0.4893) | Loss 4.2015(4.2149) | Error 0.1723(0.1771) Steps 814(810.26) | Grad Norm 3.5355(2.5427) | Total Time 14.00(14.00)\n",
      "Iter 2313 | Time 75.6877(74.5366) | Bit/dim 3.9739(3.9704) | Xent 0.4805(0.4891) | Loss 4.2142(4.2149) | Error 0.1730(0.1770) Steps 814(810.37) | Grad Norm 1.4763(2.5107) | Total Time 14.00(14.00)\n",
      "Iter 2314 | Time 76.7154(74.6020) | Bit/dim 3.9722(3.9704) | Xent 0.4714(0.4885) | Loss 4.2079(4.2147) | Error 0.1676(0.1767) Steps 814(810.48) | Grad Norm 3.2013(2.5315) | Total Time 14.00(14.00)\n",
      "Iter 2315 | Time 71.7603(74.5167) | Bit/dim 3.9693(3.9704) | Xent 0.4873(0.4885) | Loss 4.2130(4.2146) | Error 0.1777(0.1767) Steps 814(810.59) | Grad Norm 2.0146(2.5160) | Total Time 14.00(14.00)\n",
      "Iter 2316 | Time 75.5790(74.5486) | Bit/dim 3.9697(3.9704) | Xent 0.4730(0.4880) | Loss 4.2061(4.2144) | Error 0.1750(0.1767) Steps 808(810.51) | Grad Norm 2.8334(2.5255) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 29.9864, Epoch Time 494.9440(493.5325), Bit/dim 3.9773(best: 3.9778), Xent 1.6055, Loss 4.7800, Error 0.4212(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2317 | Time 74.8242(74.5569) | Bit/dim 3.9680(3.9703) | Xent 0.4638(0.4873) | Loss 4.1999(4.2139) | Error 0.1693(0.1765) Steps 808(810.44) | Grad Norm 1.1359(2.4838) | Total Time 14.00(14.00)\n",
      "Iter 2318 | Time 74.6625(74.5600) | Bit/dim 3.9686(3.9702) | Xent 0.4869(0.4873) | Loss 4.2121(4.2139) | Error 0.1803(0.1766) Steps 802(810.18) | Grad Norm 1.1197(2.4429) | Total Time 14.00(14.00)\n",
      "Iter 2319 | Time 75.6326(74.5922) | Bit/dim 3.9696(3.9702) | Xent 0.4746(0.4869) | Loss 4.2069(4.2137) | Error 0.1715(0.1764) Steps 808(810.12) | Grad Norm 1.7545(2.4222) | Total Time 14.00(14.00)\n",
      "Iter 2320 | Time 75.9426(74.6327) | Bit/dim 3.9739(3.9703) | Xent 0.4700(0.4864) | Loss 4.2089(4.2135) | Error 0.1699(0.1762) Steps 814(810.23) | Grad Norm 1.3644(2.3905) | Total Time 14.00(14.00)\n",
      "Iter 2321 | Time 73.0909(74.5865) | Bit/dim 3.9691(3.9703) | Xent 0.4675(0.4858) | Loss 4.2029(4.2132) | Error 0.1677(0.1760) Steps 802(809.99) | Grad Norm 1.0201(2.3494) | Total Time 14.00(14.00)\n",
      "Iter 2322 | Time 75.1030(74.6020) | Bit/dim 3.9634(3.9701) | Xent 0.4716(0.4854) | Loss 4.1991(4.2128) | Error 0.1701(0.1758) Steps 808(809.93) | Grad Norm 1.6652(2.3288) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 29.7757, Epoch Time 494.6475(493.5659), Bit/dim 3.9774(best: 3.9773), Xent 1.6324, Loss 4.7935, Error 0.4203(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2323 | Time 73.1935(74.5597) | Bit/dim 3.9833(3.9705) | Xent 0.4775(0.4852) | Loss 4.2220(4.2131) | Error 0.1706(0.1756) Steps 808(809.87) | Grad Norm 1.0919(2.2917) | Total Time 14.00(14.00)\n",
      "Iter 2324 | Time 73.6515(74.5325) | Bit/dim 3.9726(3.9705) | Xent 0.4798(0.4850) | Loss 4.2125(4.2131) | Error 0.1721(0.1755) Steps 802(809.63) | Grad Norm 1.6121(2.2714) | Total Time 14.00(14.00)\n",
      "Iter 2325 | Time 71.5254(74.4423) | Bit/dim 3.9792(3.9708) | Xent 0.4763(0.4848) | Loss 4.2174(4.2132) | Error 0.1693(0.1754) Steps 808(809.58) | Grad Norm 0.9540(2.2318) | Total Time 14.00(14.00)\n",
      "Iter 2326 | Time 77.3146(74.5284) | Bit/dim 3.9565(3.9704) | Xent 0.4697(0.4843) | Loss 4.1913(4.2125) | Error 0.1639(0.1750) Steps 826(810.08) | Grad Norm 1.9936(2.2247) | Total Time 14.00(14.00)\n",
      "Iter 2327 | Time 74.3888(74.5242) | Bit/dim 3.9638(3.9702) | Xent 0.4819(0.4842) | Loss 4.2048(4.2123) | Error 0.1763(0.1750) Steps 790(809.47) | Grad Norm 1.1899(2.1936) | Total Time 14.00(14.00)\n",
      "Iter 2328 | Time 75.5742(74.5557) | Bit/dim 3.9562(3.9698) | Xent 0.4673(0.4837) | Loss 4.1898(4.2116) | Error 0.1690(0.1749) Steps 814(809.61) | Grad Norm 1.3886(2.1695) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 29.6540, Epoch Time 491.1596(493.4937), Bit/dim 3.9760(best: 3.9773), Xent 1.6020, Loss 4.7770, Error 0.4202(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2329 | Time 75.3655(74.5800) | Bit/dim 3.9614(3.9695) | Xent 0.4759(0.4835) | Loss 4.1994(4.2113) | Error 0.1765(0.1749) Steps 820(809.92) | Grad Norm 2.2549(2.1721) | Total Time 14.00(14.00)\n",
      "Iter 2330 | Time 76.0448(74.6240) | Bit/dim 3.9702(3.9695) | Xent 0.4929(0.4838) | Loss 4.2166(4.2114) | Error 0.1803(0.1751) Steps 802(809.68) | Grad Norm 1.7888(2.1606) | Total Time 14.00(14.00)\n",
      "Iter 2331 | Time 76.1537(74.6699) | Bit/dim 3.9654(3.9694) | Xent 0.4734(0.4835) | Loss 4.2021(4.2111) | Error 0.1701(0.1749) Steps 802(809.45) | Grad Norm 3.2531(2.1933) | Total Time 14.00(14.00)\n",
      "Iter 2332 | Time 75.7084(74.7010) | Bit/dim 3.9677(3.9694) | Xent 0.4736(0.4832) | Loss 4.2045(4.2109) | Error 0.1689(0.1747) Steps 802(809.23) | Grad Norm 2.0378(2.1887) | Total Time 14.00(14.00)\n",
      "Iter 2333 | Time 74.9652(74.7090) | Bit/dim 3.9571(3.9690) | Xent 0.4640(0.4826) | Loss 4.1891(4.2103) | Error 0.1707(0.1746) Steps 808(809.19) | Grad Norm 1.8843(2.1795) | Total Time 14.00(14.00)\n",
      "Iter 2334 | Time 73.2853(74.6662) | Bit/dim 3.9803(3.9693) | Xent 0.4518(0.4817) | Loss 4.2062(4.2102) | Error 0.1637(0.1743) Steps 808(809.16) | Grad Norm 1.9549(2.1728) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 29.2827, Epoch Time 496.6377(493.5881), Bit/dim 3.9760(best: 3.9760), Xent 1.6051, Loss 4.7785, Error 0.4221(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2335 | Time 75.0969(74.6792) | Bit/dim 3.9683(3.9693) | Xent 0.4651(0.4812) | Loss 4.2009(4.2099) | Error 0.1707(0.1742) Steps 814(809.30) | Grad Norm 2.1460(2.1720) | Total Time 14.00(14.00)\n",
      "Iter 2336 | Time 73.7169(74.6503) | Bit/dim 3.9651(3.9692) | Xent 0.4729(0.4809) | Loss 4.2016(4.2096) | Error 0.1747(0.1742) Steps 790(808.72) | Grad Norm 1.5757(2.1541) | Total Time 14.00(14.00)\n",
      "Iter 2337 | Time 73.9313(74.6287) | Bit/dim 3.9658(3.9691) | Xent 0.4624(0.4804) | Loss 4.1970(4.2093) | Error 0.1665(0.1740) Steps 814(808.88) | Grad Norm 1.3531(2.1301) | Total Time 14.00(14.00)\n",
      "Iter 2338 | Time 75.8497(74.6654) | Bit/dim 3.9629(3.9689) | Xent 0.4677(0.4800) | Loss 4.1968(4.2089) | Error 0.1700(0.1739) Steps 802(808.68) | Grad Norm 2.3715(2.1373) | Total Time 14.00(14.00)\n",
      "Iter 2339 | Time 71.0110(74.5557) | Bit/dim 3.9670(3.9688) | Xent 0.4792(0.4800) | Loss 4.2066(4.2088) | Error 0.1749(0.1739) Steps 802(808.47) | Grad Norm 1.9292(2.1311) | Total Time 14.00(14.00)\n",
      "Iter 2340 | Time 75.6845(74.5896) | Bit/dim 3.9808(3.9692) | Xent 0.4710(0.4797) | Loss 4.2163(4.2090) | Error 0.1676(0.1737) Steps 802(808.28) | Grad Norm 1.2620(2.1050) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 29.7563, Epoch Time 490.7568(493.5031), Bit/dim 3.9754(best: 3.9760), Xent 1.6202, Loss 4.7855, Error 0.4234(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2341 | Time 70.8452(74.4773) | Bit/dim 3.9725(3.9693) | Xent 0.4688(0.4794) | Loss 4.2069(4.2090) | Error 0.1733(0.1737) Steps 802(808.09) | Grad Norm 3.0354(2.1329) | Total Time 14.00(14.00)\n",
      "Iter 2342 | Time 73.6650(74.4529) | Bit/dim 3.9660(3.9692) | Xent 0.4819(0.4794) | Loss 4.2070(4.2089) | Error 0.1710(0.1736) Steps 808(808.09) | Grad Norm 1.8914(2.1257) | Total Time 14.00(14.00)\n",
      "Iter 2343 | Time 73.0642(74.4112) | Bit/dim 3.9641(3.9690) | Xent 0.4488(0.4785) | Loss 4.1885(4.2083) | Error 0.1635(0.1733) Steps 802(807.91) | Grad Norm 1.2863(2.1005) | Total Time 14.00(14.00)\n",
      "Iter 2344 | Time 75.9590(74.4577) | Bit/dim 3.9713(3.9691) | Xent 0.4788(0.4785) | Loss 4.2107(4.2084) | Error 0.1731(0.1733) Steps 808(807.91) | Grad Norm 1.7060(2.0887) | Total Time 14.00(14.00)\n",
      "Iter 2345 | Time 75.0405(74.4751) | Bit/dim 3.9723(3.9692) | Xent 0.4522(0.4777) | Loss 4.1985(4.2081) | Error 0.1620(0.1730) Steps 790(807.37) | Grad Norm 1.4398(2.0692) | Total Time 14.00(14.00)\n",
      "Iter 2346 | Time 73.0798(74.4333) | Bit/dim 3.9647(3.9691) | Xent 0.4811(0.4778) | Loss 4.2052(4.2080) | Error 0.1749(0.1730) Steps 802(807.21) | Grad Norm 1.8562(2.0628) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 29.8480, Epoch Time 487.1972(493.3139), Bit/dim 3.9761(best: 3.9754), Xent 1.6403, Loss 4.7962, Error 0.4243(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2347 | Time 72.1094(74.3636) | Bit/dim 3.9788(3.9694) | Xent 0.4634(0.4774) | Loss 4.2105(4.2081) | Error 0.1625(0.1727) Steps 802(807.05) | Grad Norm 1.2234(2.0376) | Total Time 14.00(14.00)\n",
      "Iter 2348 | Time 73.3890(74.3343) | Bit/dim 3.9579(3.9690) | Xent 0.4785(0.4774) | Loss 4.1971(4.2077) | Error 0.1741(0.1727) Steps 796(806.72) | Grad Norm 2.1058(2.0397) | Total Time 14.00(14.00)\n",
      "Iter 2349 | Time 74.9702(74.3534) | Bit/dim 3.9719(3.9691) | Xent 0.4635(0.4770) | Loss 4.2036(4.2076) | Error 0.1729(0.1727) Steps 796(806.40) | Grad Norm 1.2789(2.0168) | Total Time 14.00(14.00)\n",
      "Iter 2350 | Time 72.7938(74.3066) | Bit/dim 3.9611(3.9689) | Xent 0.4723(0.4769) | Loss 4.1973(4.2073) | Error 0.1731(0.1728) Steps 814(806.63) | Grad Norm 1.3670(1.9973) | Total Time 14.00(14.00)\n",
      "Iter 2351 | Time 76.3651(74.3684) | Bit/dim 3.9714(3.9689) | Xent 0.4660(0.4766) | Loss 4.2045(4.2072) | Error 0.1691(0.1726) Steps 802(806.49) | Grad Norm 1.3311(1.9774) | Total Time 14.00(14.00)\n",
      "Iter 2352 | Time 74.0031(74.3574) | Bit/dim 3.9721(3.9690) | Xent 0.4588(0.4760) | Loss 4.2015(4.2070) | Error 0.1639(0.1724) Steps 814(806.72) | Grad Norm 1.1072(1.9513) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 29.8315, Epoch Time 489.0907(493.1872), Bit/dim 3.9755(best: 3.9754), Xent 1.6303, Loss 4.7906, Error 0.4231(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2353 | Time 75.0524(74.3783) | Bit/dim 3.9713(3.9691) | Xent 0.4769(0.4760) | Loss 4.2097(4.2071) | Error 0.1735(0.1724) Steps 808(806.75) | Grad Norm 2.8440(1.9780) | Total Time 14.00(14.00)\n",
      "Iter 2354 | Time 74.7277(74.3887) | Bit/dim 3.9665(3.9690) | Xent 0.4718(0.4759) | Loss 4.2024(4.2070) | Error 0.1706(0.1724) Steps 796(806.43) | Grad Norm 1.7993(1.9727) | Total Time 14.00(14.00)\n",
      "Iter 2355 | Time 71.5415(74.3033) | Bit/dim 3.9509(3.9685) | Xent 0.4586(0.4754) | Loss 4.1802(4.2062) | Error 0.1643(0.1721) Steps 802(806.30) | Grad Norm 2.6474(1.9929) | Total Time 14.00(14.00)\n",
      "Iter 2356 | Time 73.2388(74.2714) | Bit/dim 3.9658(3.9684) | Xent 0.4645(0.4751) | Loss 4.1980(4.2059) | Error 0.1671(0.1720) Steps 796(805.99) | Grad Norm 1.6280(1.9820) | Total Time 14.00(14.00)\n",
      "Iter 2357 | Time 73.8294(74.2581) | Bit/dim 3.9772(3.9687) | Xent 0.4708(0.4749) | Loss 4.2126(4.2061) | Error 0.1711(0.1719) Steps 802(805.87) | Grad Norm 1.5032(1.9676) | Total Time 14.00(14.00)\n",
      "Iter 2358 | Time 74.1143(74.2538) | Bit/dim 3.9687(3.9687) | Xent 0.4552(0.4744) | Loss 4.1963(4.2058) | Error 0.1630(0.1717) Steps 808(805.93) | Grad Norm 1.7612(1.9614) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 29.7576, Epoch Time 488.0855(493.0342), Bit/dim 3.9758(best: 3.9754), Xent 1.6328, Loss 4.7922, Error 0.4184(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2359 | Time 73.2015(74.2223) | Bit/dim 3.9748(3.9688) | Xent 0.4710(0.4743) | Loss 4.2103(4.2060) | Error 0.1659(0.1715) Steps 790(805.46) | Grad Norm 2.2671(1.9706) | Total Time 14.00(14.00)\n",
      "Iter 2360 | Time 74.8052(74.2397) | Bit/dim 3.9656(3.9687) | Xent 0.4596(0.4738) | Loss 4.1954(4.2057) | Error 0.1653(0.1713) Steps 802(805.35) | Grad Norm 1.3134(1.9509) | Total Time 14.00(14.00)\n",
      "Iter 2361 | Time 72.3576(74.1833) | Bit/dim 3.9766(3.9690) | Xent 0.4509(0.4731) | Loss 4.2020(4.2055) | Error 0.1639(0.1711) Steps 802(805.25) | Grad Norm 1.4569(1.9360) | Total Time 14.00(14.00)\n",
      "Iter 2362 | Time 74.2312(74.1847) | Bit/dim 3.9675(3.9689) | Xent 0.4647(0.4729) | Loss 4.1998(4.2054) | Error 0.1701(0.1711) Steps 796(804.97) | Grad Norm 1.8713(1.9341) | Total Time 14.00(14.00)\n",
      "Iter 2363 | Time 73.2428(74.1565) | Bit/dim 3.9529(3.9685) | Xent 0.4726(0.4729) | Loss 4.1892(4.2049) | Error 0.1726(0.1711) Steps 802(804.88) | Grad Norm 2.7067(1.9573) | Total Time 14.00(14.00)\n",
      "Iter 2364 | Time 73.4583(74.1355) | Bit/dim 3.9656(3.9684) | Xent 0.4704(0.4728) | Loss 4.2008(4.2048) | Error 0.1707(0.1711) Steps 808(804.98) | Grad Norm 2.1652(1.9635) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 29.6331, Epoch Time 486.5910(492.8409), Bit/dim 3.9752(best: 3.9754), Xent 1.6331, Loss 4.7918, Error 0.4200(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2365 | Time 74.5889(74.1491) | Bit/dim 3.9624(3.9682) | Xent 0.4621(0.4725) | Loss 4.1934(4.2044) | Error 0.1667(0.1710) Steps 802(804.89) | Grad Norm 3.0065(1.9948) | Total Time 14.00(14.00)\n",
      "Iter 2366 | Time 74.4890(74.1593) | Bit/dim 3.9517(3.9677) | Xent 0.4668(0.4723) | Loss 4.1852(4.2038) | Error 0.1640(0.1708) Steps 796(804.62) | Grad Norm 1.7379(1.9871) | Total Time 14.00(14.00)\n",
      "Iter 2367 | Time 72.7896(74.1182) | Bit/dim 3.9716(3.9678) | Xent 0.4552(0.4718) | Loss 4.1992(4.2037) | Error 0.1680(0.1707) Steps 802(804.54) | Grad Norm 2.1917(1.9932) | Total Time 14.00(14.00)\n",
      "Iter 2368 | Time 73.8582(74.1104) | Bit/dim 3.9797(3.9682) | Xent 0.4652(0.4716) | Loss 4.2123(4.2040) | Error 0.1724(0.1707) Steps 796(804.29) | Grad Norm 1.8525(1.9890) | Total Time 14.00(14.00)\n",
      "Iter 2369 | Time 76.6884(74.1878) | Bit/dim 3.9641(3.9680) | Xent 0.4724(0.4716) | Loss 4.2002(4.2039) | Error 0.1693(0.1707) Steps 796(804.04) | Grad Norm 1.5934(1.9771) | Total Time 14.00(14.00)\n",
      "Iter 2370 | Time 73.0690(74.1542) | Bit/dim 3.9687(3.9681) | Xent 0.4639(0.4714) | Loss 4.2006(4.2038) | Error 0.1657(0.1705) Steps 796(803.80) | Grad Norm 2.0826(1.9803) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 30.0565, Epoch Time 491.2751(492.7939), Bit/dim 3.9744(best: 3.9752), Xent 1.6389, Loss 4.7939, Error 0.4248(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2371 | Time 73.0631(74.1215) | Bit/dim 3.9613(3.9679) | Xent 0.4736(0.4714) | Loss 4.1981(4.2036) | Error 0.1707(0.1705) Steps 796(803.56) | Grad Norm 1.1719(1.9561) | Total Time 14.00(14.00)\n",
      "Iter 2372 | Time 75.6501(74.1673) | Bit/dim 3.9649(3.9678) | Xent 0.4599(0.4711) | Loss 4.1948(4.2033) | Error 0.1659(0.1704) Steps 802(803.52) | Grad Norm 2.0110(1.9577) | Total Time 14.00(14.00)\n",
      "Iter 2373 | Time 75.0213(74.1929) | Bit/dim 3.9664(3.9677) | Xent 0.4555(0.4706) | Loss 4.1941(4.2030) | Error 0.1664(0.1703) Steps 808(803.65) | Grad Norm 1.3490(1.9394) | Total Time 14.00(14.00)\n",
      "Iter 2374 | Time 73.5613(74.1740) | Bit/dim 3.9687(3.9678) | Xent 0.4633(0.4704) | Loss 4.2004(4.2030) | Error 0.1693(0.1703) Steps 808(803.78) | Grad Norm 2.4945(1.9561) | Total Time 14.00(14.00)\n",
      "Iter 2375 | Time 72.7892(74.1324) | Bit/dim 3.9724(3.9679) | Xent 0.4618(0.4702) | Loss 4.2033(4.2030) | Error 0.1679(0.1702) Steps 802(803.73) | Grad Norm 1.7370(1.9495) | Total Time 14.00(14.00)\n",
      "Iter 2376 | Time 72.4159(74.0809) | Bit/dim 3.9619(3.9677) | Xent 0.4736(0.4703) | Loss 4.1987(4.2028) | Error 0.1729(0.1703) Steps 802(803.68) | Grad Norm 2.9158(1.9785) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 30.0125, Epoch Time 488.0979(492.6530), Bit/dim 3.9739(best: 3.9744), Xent 1.6352, Loss 4.7915, Error 0.4226(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2377 | Time 74.4192(74.0911) | Bit/dim 3.9563(3.9674) | Xent 0.4709(0.4703) | Loss 4.1918(4.2025) | Error 0.1694(0.1702) Steps 808(803.81) | Grad Norm 1.9545(1.9778) | Total Time 14.00(14.00)\n",
      "Iter 2378 | Time 73.7315(74.0803) | Bit/dim 3.9685(3.9674) | Xent 0.4609(0.4700) | Loss 4.1989(4.2024) | Error 0.1645(0.1701) Steps 808(803.93) | Grad Norm 2.4702(1.9926) | Total Time 14.00(14.00)\n",
      "Iter 2379 | Time 74.2698(74.0860) | Bit/dim 3.9642(3.9673) | Xent 0.4373(0.4690) | Loss 4.1829(4.2018) | Error 0.1595(0.1697) Steps 802(803.87) | Grad Norm 1.3270(1.9726) | Total Time 14.00(14.00)\n",
      "Iter 2380 | Time 75.8076(74.1376) | Bit/dim 3.9716(3.9674) | Xent 0.4488(0.4684) | Loss 4.1960(4.2016) | Error 0.1633(0.1696) Steps 796(803.64) | Grad Norm 1.6680(1.9635) | Total Time 14.00(14.00)\n",
      "Iter 2381 | Time 73.5791(74.1209) | Bit/dim 3.9663(3.9674) | Xent 0.4693(0.4684) | Loss 4.2010(4.2016) | Error 0.1699(0.1696) Steps 796(803.41) | Grad Norm 2.6905(1.9853) | Total Time 14.00(14.00)\n",
      "Iter 2382 | Time 74.1503(74.1218) | Bit/dim 3.9665(3.9674) | Xent 0.4649(0.4683) | Loss 4.1990(4.2015) | Error 0.1711(0.1696) Steps 808(803.55) | Grad Norm 2.3273(1.9955) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 29.5085, Epoch Time 490.8949(492.6003), Bit/dim 3.9740(best: 3.9739), Xent 1.6448, Loss 4.7963, Error 0.4231(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2383 | Time 75.9402(74.1763) | Bit/dim 3.9686(3.9674) | Xent 0.4520(0.4678) | Loss 4.1946(4.2013) | Error 0.1646(0.1695) Steps 802(803.50) | Grad Norm 1.5994(1.9836) | Total Time 14.00(14.00)\n",
      "Iter 2384 | Time 75.0186(74.2016) | Bit/dim 3.9737(3.9676) | Xent 0.4516(0.4674) | Loss 4.1995(4.2013) | Error 0.1617(0.1692) Steps 808(803.64) | Grad Norm 2.2142(1.9906) | Total Time 14.00(14.00)\n",
      "Iter 2385 | Time 73.3537(74.1762) | Bit/dim 3.9673(3.9676) | Xent 0.4583(0.4671) | Loss 4.1964(4.2011) | Error 0.1631(0.1690) Steps 796(803.41) | Grad Norm 1.0832(1.9633) | Total Time 14.00(14.00)\n",
      "Iter 2386 | Time 72.5203(74.1265) | Bit/dim 3.9669(3.9676) | Xent 0.4545(0.4667) | Loss 4.1942(4.2009) | Error 0.1671(0.1690) Steps 808(803.54) | Grad Norm 3.6335(2.0134) | Total Time 14.00(14.00)\n",
      "Iter 2387 | Time 74.4508(74.1362) | Bit/dim 3.9574(3.9673) | Xent 0.4708(0.4668) | Loss 4.1928(4.2007) | Error 0.1689(0.1690) Steps 802(803.50) | Grad Norm 2.0005(2.0131) | Total Time 14.00(14.00)\n",
      "Iter 2388 | Time 73.5350(74.1182) | Bit/dim 3.9608(3.9671) | Xent 0.4691(0.4669) | Loss 4.1953(4.2005) | Error 0.1734(0.1691) Steps 790(803.09) | Grad Norm 1.1993(1.9886) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 29.7225, Epoch Time 496.9910(492.7320), Bit/dim 3.9745(best: 3.9739), Xent 1.6538, Loss 4.8014, Error 0.4241(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2389 | Time 72.1955(74.0605) | Bit/dim 3.9671(3.9671) | Xent 0.4601(0.4667) | Loss 4.1972(4.2004) | Error 0.1624(0.1689) Steps 796(802.88) | Grad Norm 2.1644(1.9939) | Total Time 14.00(14.00)\n",
      "Iter 2390 | Time 72.2244(74.0054) | Bit/dim 3.9645(3.9670) | Xent 0.4609(0.4665) | Loss 4.1950(4.2003) | Error 0.1665(0.1688) Steps 802(802.85) | Grad Norm 1.5481(1.9805) | Total Time 14.00(14.00)\n",
      "Iter 2391 | Time 73.6187(73.9938) | Bit/dim 3.9659(3.9670) | Xent 0.4588(0.4663) | Loss 4.1953(4.2001) | Error 0.1630(0.1687) Steps 796(802.65) | Grad Norm 1.2836(1.9596) | Total Time 14.00(14.00)\n",
      "Iter 2392 | Time 76.8699(74.0801) | Bit/dim 3.9639(3.9669) | Xent 0.4415(0.4655) | Loss 4.1846(4.1996) | Error 0.1587(0.1684) Steps 808(802.81) | Grad Norm 1.7550(1.9535) | Total Time 14.00(14.00)\n",
      "Iter 2393 | Time 73.4100(74.0600) | Bit/dim 3.9607(3.9667) | Xent 0.4544(0.4652) | Loss 4.1879(4.1993) | Error 0.1675(0.1683) Steps 796(802.60) | Grad Norm 1.3274(1.9347) | Total Time 14.00(14.00)\n",
      "Iter 2394 | Time 72.4227(74.0109) | Bit/dim 3.9669(3.9667) | Xent 0.4662(0.4652) | Loss 4.2000(4.1993) | Error 0.1667(0.1683) Steps 802(802.59) | Grad Norm 1.4479(1.9201) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 29.6207, Epoch Time 485.8256(492.5248), Bit/dim 3.9738(best: 3.9739), Xent 1.6620, Loss 4.8048, Error 0.4265(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2395 | Time 75.5340(74.0566) | Bit/dim 3.9672(3.9667) | Xent 0.4607(0.4651) | Loss 4.1976(4.1993) | Error 0.1709(0.1684) Steps 796(802.39) | Grad Norm 1.4498(1.9060) | Total Time 14.00(14.00)\n",
      "Iter 2396 | Time 73.5136(74.0403) | Bit/dim 3.9748(3.9670) | Xent 0.4417(0.4644) | Loss 4.1957(4.1992) | Error 0.1558(0.1680) Steps 796(802.20) | Grad Norm 1.3736(1.8900) | Total Time 14.00(14.00)\n",
      "Iter 2397 | Time 73.6673(74.0291) | Bit/dim 3.9600(3.9667) | Xent 0.4686(0.4645) | Loss 4.1943(4.1990) | Error 0.1701(0.1681) Steps 802(802.19) | Grad Norm 1.6049(1.8815) | Total Time 14.00(14.00)\n",
      "Iter 2398 | Time 74.5024(74.0433) | Bit/dim 3.9596(3.9665) | Xent 0.4435(0.4639) | Loss 4.1814(4.1985) | Error 0.1626(0.1679) Steps 790(801.83) | Grad Norm 1.4608(1.8689) | Total Time 14.00(14.00)\n",
      "Iter 2399 | Time 71.5559(73.9687) | Bit/dim 3.9666(3.9665) | Xent 0.4546(0.4636) | Loss 4.1939(4.1983) | Error 0.1640(0.1678) Steps 796(801.65) | Grad Norm 1.4730(1.8570) | Total Time 14.00(14.00)\n",
      "Iter 2400 | Time 72.8751(73.9359) | Bit/dim 3.9634(3.9664) | Xent 0.4681(0.4638) | Loss 4.1974(4.1983) | Error 0.1735(0.1679) Steps 814(802.02) | Grad Norm 1.9517(1.8598) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 29.7802, Epoch Time 486.9771(492.3584), Bit/dim 3.9736(best: 3.9738), Xent 1.6629, Loss 4.8050, Error 0.4244(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2401 | Time 73.1759(73.9131) | Bit/dim 3.9587(3.9662) | Xent 0.4642(0.4638) | Loss 4.1908(4.1981) | Error 0.1697(0.1680) Steps 808(802.20) | Grad Norm 1.1695(1.8391) | Total Time 14.00(14.00)\n",
      "Iter 2402 | Time 73.9253(73.9134) | Bit/dim 3.9701(3.9663) | Xent 0.4572(0.4636) | Loss 4.1987(4.1981) | Error 0.1666(0.1680) Steps 802(802.19) | Grad Norm 1.4552(1.8276) | Total Time 14.00(14.00)\n",
      "Iter 2403 | Time 73.0780(73.8884) | Bit/dim 3.9635(3.9662) | Xent 0.4484(0.4631) | Loss 4.1878(4.1978) | Error 0.1655(0.1679) Steps 790(801.83) | Grad Norm 3.3020(1.8718) | Total Time 14.00(14.00)\n",
      "Iter 2404 | Time 75.7755(73.9450) | Bit/dim 3.9640(3.9662) | Xent 0.4709(0.4634) | Loss 4.1995(4.1978) | Error 0.1651(0.1678) Steps 808(802.01) | Grad Norm 1.3493(1.8562) | Total Time 14.00(14.00)\n",
      "Iter 2405 | Time 75.1239(73.9803) | Bit/dim 3.9571(3.9659) | Xent 0.4511(0.4630) | Loss 4.1827(4.1974) | Error 0.1611(0.1676) Steps 796(801.83) | Grad Norm 2.5174(1.8760) | Total Time 14.00(14.00)\n",
      "Iter 2406 | Time 75.2190(74.0175) | Bit/dim 3.9678(3.9660) | Xent 0.4514(0.4626) | Loss 4.1935(4.1973) | Error 0.1633(0.1675) Steps 790(801.48) | Grad Norm 1.8043(1.8738) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 29.7885, Epoch Time 491.4964(492.3325), Bit/dim 3.9730(best: 3.9736), Xent 1.6697, Loss 4.8079, Error 0.4234(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2407 | Time 74.0707(74.0191) | Bit/dim 3.9538(3.9656) | Xent 0.4509(0.4623) | Loss 4.1793(4.1967) | Error 0.1625(0.1673) Steps 790(801.13) | Grad Norm 1.3466(1.8580) | Total Time 14.00(14.00)\n",
      "Iter 2408 | Time 73.3506(73.9990) | Bit/dim 3.9677(3.9657) | Xent 0.4543(0.4620) | Loss 4.1949(4.1967) | Error 0.1660(0.1673) Steps 790(800.80) | Grad Norm 3.0587(1.8940) | Total Time 14.00(14.00)\n",
      "Iter 2409 | Time 72.7406(73.9613) | Bit/dim 3.9651(3.9656) | Xent 0.4501(0.4617) | Loss 4.1901(4.1965) | Error 0.1627(0.1671) Steps 802(800.84) | Grad Norm 2.2850(1.9058) | Total Time 14.00(14.00)\n",
      "Iter 2410 | Time 72.3734(73.9137) | Bit/dim 3.9580(3.9654) | Xent 0.4496(0.4613) | Loss 4.1828(4.1961) | Error 0.1623(0.1670) Steps 814(801.23) | Grad Norm 1.6930(1.8994) | Total Time 14.00(14.00)\n",
      "Iter 2411 | Time 74.8826(73.9427) | Bit/dim 3.9775(3.9658) | Xent 0.4545(0.4611) | Loss 4.2048(4.1963) | Error 0.1670(0.1670) Steps 802(801.25) | Grad Norm 1.9490(1.9009) | Total Time 14.00(14.00)\n",
      "Iter 2412 | Time 74.3654(73.9554) | Bit/dim 3.9657(3.9658) | Xent 0.4691(0.4614) | Loss 4.2003(4.1964) | Error 0.1715(0.1671) Steps 796(801.10) | Grad Norm 1.8872(1.9005) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 29.5153, Epoch Time 488.4834(492.2171), Bit/dim 3.9720(best: 3.9730), Xent 1.6623, Loss 4.8032, Error 0.4229(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2413 | Time 73.6702(73.9468) | Bit/dim 3.9617(3.9656) | Xent 0.4578(0.4613) | Loss 4.1906(4.1963) | Error 0.1704(0.1672) Steps 808(801.30) | Grad Norm 1.9425(1.9017) | Total Time 14.00(14.00)\n",
      "Iter 2414 | Time 71.3598(73.8692) | Bit/dim 3.9666(3.9657) | Xent 0.4325(0.4604) | Loss 4.1828(4.1959) | Error 0.1549(0.1669) Steps 808(801.50) | Grad Norm 1.9634(1.9036) | Total Time 14.00(14.00)\n",
      "Iter 2415 | Time 74.6578(73.8929) | Bit/dim 3.9720(3.9659) | Xent 0.4524(0.4601) | Loss 4.1982(4.1959) | Error 0.1639(0.1668) Steps 784(800.98) | Grad Norm 2.0685(1.9085) | Total Time 14.00(14.00)\n",
      "Iter 2416 | Time 76.2432(73.9634) | Bit/dim 3.9578(3.9656) | Xent 0.4483(0.4598) | Loss 4.1820(4.1955) | Error 0.1631(0.1667) Steps 802(801.01) | Grad Norm 1.7644(1.9042) | Total Time 14.00(14.00)\n",
      "Iter 2417 | Time 72.1811(73.9099) | Bit/dim 3.9561(3.9653) | Xent 0.4536(0.4596) | Loss 4.1829(4.1951) | Error 0.1629(0.1665) Steps 802(801.04) | Grad Norm 3.8010(1.9611) | Total Time 14.00(14.00)\n",
      "Iter 2418 | Time 76.4244(73.9854) | Bit/dim 3.9607(3.9652) | Xent 0.4495(0.4593) | Loss 4.1854(4.1949) | Error 0.1646(0.1665) Steps 796(800.89) | Grad Norm 2.2759(1.9705) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 29.6174, Epoch Time 489.7629(492.1434), Bit/dim 3.9738(best: 3.9720), Xent 1.6829, Loss 4.8153, Error 0.4253(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2419 | Time 74.6076(74.0040) | Bit/dim 3.9557(3.9649) | Xent 0.4510(0.4591) | Loss 4.1812(4.1944) | Error 0.1656(0.1665) Steps 796(800.74) | Grad Norm 3.5150(2.0169) | Total Time 14.00(14.00)\n",
      "Iter 2420 | Time 73.8521(73.9995) | Bit/dim 3.9730(3.9652) | Xent 0.4381(0.4584) | Loss 4.1921(4.1944) | Error 0.1585(0.1662) Steps 814(801.14) | Grad Norm 1.8481(2.0118) | Total Time 14.00(14.00)\n",
      "Iter 2421 | Time 75.1167(74.0330) | Bit/dim 3.9693(3.9653) | Xent 0.4694(0.4588) | Loss 4.2040(4.1947) | Error 0.1625(0.1661) Steps 790(800.81) | Grad Norm 3.3771(2.0528) | Total Time 14.00(14.00)\n",
      "Iter 2422 | Time 75.2286(74.0689) | Bit/dim 3.9540(3.9649) | Xent 0.4468(0.4584) | Loss 4.1774(4.1941) | Error 0.1639(0.1660) Steps 790(800.48) | Grad Norm 3.3977(2.0931) | Total Time 14.00(14.00)\n",
      "Iter 2423 | Time 72.1962(74.0127) | Bit/dim 3.9704(3.9651) | Xent 0.4463(0.4580) | Loss 4.1935(4.1941) | Error 0.1607(0.1659) Steps 802(800.53) | Grad Norm 1.8886(2.0870) | Total Time 14.00(14.00)\n",
      "Iter 2424 | Time 71.9522(73.9509) | Bit/dim 3.9580(3.9649) | Xent 0.4469(0.4577) | Loss 4.1814(4.1937) | Error 0.1615(0.1658) Steps 802(800.57) | Grad Norm 1.6255(2.0731) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 29.8647, Epoch Time 488.2967(492.0280), Bit/dim 3.9739(best: 3.9720), Xent 1.6790, Loss 4.8134, Error 0.4218(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2425 | Time 72.3768(73.9036) | Bit/dim 3.9722(3.9651) | Xent 0.4471(0.4574) | Loss 4.1958(4.1938) | Error 0.1625(0.1657) Steps 796(800.43) | Grad Norm 3.2989(2.1099) | Total Time 14.00(14.00)\n",
      "Iter 2426 | Time 75.7238(73.9582) | Bit/dim 3.9640(3.9651) | Xent 0.4436(0.4570) | Loss 4.1858(4.1936) | Error 0.1587(0.1655) Steps 790(800.12) | Grad Norm 2.4586(2.1204) | Total Time 14.00(14.00)\n",
      "Iter 2427 | Time 73.1812(73.9349) | Bit/dim 3.9681(3.9652) | Xent 0.4458(0.4566) | Loss 4.1910(4.1935) | Error 0.1634(0.1654) Steps 796(800.00) | Grad Norm 1.3149(2.0962) | Total Time 14.00(14.00)\n",
      "Iter 2428 | Time 72.8788(73.9033) | Bit/dim 3.9582(3.9650) | Xent 0.4541(0.4566) | Loss 4.1852(4.1932) | Error 0.1666(0.1654) Steps 802(800.06) | Grad Norm 3.1180(2.1269) | Total Time 14.00(14.00)\n",
      "Iter 2429 | Time 75.1138(73.9396) | Bit/dim 3.9621(3.9649) | Xent 0.4389(0.4560) | Loss 4.1816(4.1929) | Error 0.1581(0.1652) Steps 808(800.30) | Grad Norm 1.8119(2.1174) | Total Time 14.00(14.00)\n",
      "Iter 2430 | Time 72.7358(73.9035) | Bit/dim 3.9616(3.9648) | Xent 0.4468(0.4557) | Loss 4.1850(4.1927) | Error 0.1615(0.1651) Steps 808(800.53) | Grad Norm 2.6343(2.1329) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 29.8908, Epoch Time 487.4796(491.8916), Bit/dim 3.9718(best: 3.9720), Xent 1.6913, Loss 4.8175, Error 0.4246(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2431 | Time 74.9519(73.9349) | Bit/dim 3.9588(3.9646) | Xent 0.4407(0.4553) | Loss 4.1792(4.1922) | Error 0.1594(0.1649) Steps 796(800.39) | Grad Norm 1.5280(2.1148) | Total Time 14.00(14.00)\n",
      "Iter 2432 | Time 76.6021(74.0149) | Bit/dim 3.9626(3.9645) | Xent 0.4601(0.4554) | Loss 4.1926(4.1923) | Error 0.1649(0.1649) Steps 802(800.44) | Grad Norm 2.7557(2.1340) | Total Time 14.00(14.00)\n",
      "Iter 2433 | Time 74.6792(74.0349) | Bit/dim 3.9613(3.9644) | Xent 0.4582(0.4555) | Loss 4.1904(4.1922) | Error 0.1653(0.1649) Steps 814(800.85) | Grad Norm 1.9895(2.1297) | Total Time 14.00(14.00)\n",
      "Iter 2434 | Time 72.6645(73.9937) | Bit/dim 3.9697(3.9646) | Xent 0.4366(0.4550) | Loss 4.1881(4.1921) | Error 0.1555(0.1647) Steps 790(800.52) | Grad Norm 2.7970(2.1497) | Total Time 14.00(14.00)\n",
      "Iter 2435 | Time 76.0518(74.0555) | Bit/dim 3.9607(3.9645) | Xent 0.4477(0.4547) | Loss 4.1846(4.1919) | Error 0.1617(0.1646) Steps 796(800.38) | Grad Norm 1.6727(2.1354) | Total Time 14.00(14.00)\n",
      "Iter 2436 | Time 72.3586(74.0046) | Bit/dim 3.9550(3.9642) | Xent 0.4404(0.4543) | Loss 4.1752(4.1914) | Error 0.1624(0.1645) Steps 802(800.43) | Grad Norm 1.9066(2.1285) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 29.9147, Epoch Time 492.7245(491.9166), Bit/dim 3.9721(best: 3.9718), Xent 1.6703, Loss 4.8072, Error 0.4204(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2437 | Time 74.8765(74.0307) | Bit/dim 3.9659(3.9642) | Xent 0.4353(0.4537) | Loss 4.1835(4.1911) | Error 0.1565(0.1643) Steps 796(800.30) | Grad Norm 2.0197(2.1253) | Total Time 14.00(14.00)\n",
      "Iter 2438 | Time 73.2357(74.0069) | Bit/dim 3.9518(3.9639) | Xent 0.4254(0.4529) | Loss 4.1645(4.1903) | Error 0.1539(0.1639) Steps 796(800.17) | Grad Norm 2.7730(2.1447) | Total Time 14.00(14.00)\n",
      "Iter 2439 | Time 76.5314(74.0826) | Bit/dim 3.9675(3.9640) | Xent 0.4412(0.4525) | Loss 4.1881(4.1903) | Error 0.1562(0.1637) Steps 790(799.87) | Grad Norm 1.4917(2.1251) | Total Time 14.00(14.00)\n",
      "Iter 2440 | Time 76.0557(74.1418) | Bit/dim 3.9662(3.9641) | Xent 0.4456(0.4523) | Loss 4.1890(4.1902) | Error 0.1631(0.1637) Steps 796(799.75) | Grad Norm 2.7487(2.1438) | Total Time 14.00(14.00)\n",
      "Iter 2441 | Time 73.5340(74.1236) | Bit/dim 3.9718(3.9643) | Xent 0.4415(0.4520) | Loss 4.1925(4.1903) | Error 0.1564(0.1635) Steps 802(799.82) | Grad Norm 2.8143(2.1639) | Total Time 14.00(14.00)\n",
      "Iter 2442 | Time 73.5595(74.1067) | Bit/dim 3.9568(3.9641) | Xent 0.4596(0.4522) | Loss 4.1866(4.1902) | Error 0.1663(0.1636) Steps 796(799.70) | Grad Norm 1.1433(2.1333) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 29.6224, Epoch Time 493.0049(491.9492), Bit/dim 3.9723(best: 3.9718), Xent 1.7162, Loss 4.8304, Error 0.4255(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2443 | Time 73.6599(74.0932) | Bit/dim 3.9645(3.9641) | Xent 0.4411(0.4519) | Loss 4.1850(4.1900) | Error 0.1580(0.1634) Steps 808(799.95) | Grad Norm 2.7943(2.1531) | Total Time 14.00(14.00)\n",
      "Iter 2444 | Time 75.7139(74.1419) | Bit/dim 3.9602(3.9640) | Xent 0.4368(0.4514) | Loss 4.1786(4.1897) | Error 0.1603(0.1633) Steps 784(799.47) | Grad Norm 2.8242(2.1733) | Total Time 14.00(14.00)\n",
      "Iter 2445 | Time 75.5942(74.1854) | Bit/dim 3.9572(3.9638) | Xent 0.4506(0.4514) | Loss 4.1824(4.1895) | Error 0.1627(0.1633) Steps 802(799.55) | Grad Norm 1.7757(2.1613) | Total Time 14.00(14.00)\n",
      "Iter 2446 | Time 73.9897(74.1796) | Bit/dim 3.9642(3.9638) | Xent 0.4444(0.4512) | Loss 4.1864(4.1894) | Error 0.1586(0.1631) Steps 784(799.08) | Grad Norm 3.3381(2.1966) | Total Time 14.00(14.00)\n",
      "Iter 2447 | Time 75.4861(74.2188) | Bit/dim 3.9676(3.9639) | Xent 0.4494(0.4512) | Loss 4.1923(4.1895) | Error 0.1641(0.1632) Steps 790(798.81) | Grad Norm 2.5212(2.2064) | Total Time 14.00(14.00)\n",
      "Iter 2448 | Time 74.3257(74.2220) | Bit/dim 3.9619(3.9638) | Xent 0.4382(0.4508) | Loss 4.1810(4.1892) | Error 0.1607(0.1631) Steps 790(798.55) | Grad Norm 2.3758(2.2114) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 29.6872, Epoch Time 494.1126(492.0141), Bit/dim 3.9724(best: 3.9718), Xent 1.6934, Loss 4.8191, Error 0.4263(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2449 | Time 72.9393(74.1835) | Bit/dim 3.9490(3.9634) | Xent 0.4489(0.4507) | Loss 4.1735(4.1887) | Error 0.1621(0.1631) Steps 802(798.65) | Grad Norm 2.9579(2.2338) | Total Time 14.00(14.00)\n",
      "Iter 2450 | Time 71.5665(74.1050) | Bit/dim 3.9682(3.9635) | Xent 0.4519(0.4507) | Loss 4.1941(4.1889) | Error 0.1617(0.1630) Steps 796(798.57) | Grad Norm 2.9905(2.2565) | Total Time 14.00(14.00)\n",
      "Iter 2451 | Time 73.7555(74.0945) | Bit/dim 3.9676(3.9636) | Xent 0.4530(0.4508) | Loss 4.1941(4.1890) | Error 0.1606(0.1630) Steps 802(798.67) | Grad Norm 3.7093(2.3001) | Total Time 14.00(14.00)\n",
      "Iter 2452 | Time 71.9106(74.0290) | Bit/dim 3.9664(3.9637) | Xent 0.4373(0.4504) | Loss 4.1851(4.1889) | Error 0.1590(0.1628) Steps 790(798.41) | Grad Norm 2.2128(2.2975) | Total Time 14.00(14.00)\n",
      "Iter 2453 | Time 72.8416(73.9934) | Bit/dim 3.9692(3.9639) | Xent 0.4530(0.4505) | Loss 4.1957(4.1891) | Error 0.1664(0.1629) Steps 790(798.16) | Grad Norm 2.4645(2.3025) | Total Time 14.00(14.00)\n",
      "Iter 2454 | Time 75.1339(74.0276) | Bit/dim 3.9526(3.9636) | Xent 0.4353(0.4500) | Loss 4.1702(4.1886) | Error 0.1604(0.1629) Steps 796(798.10) | Grad Norm 4.0072(2.3537) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 29.7119, Epoch Time 483.3073(491.7529), Bit/dim 3.9716(best: 3.9718), Xent 1.7034, Loss 4.8233, Error 0.4240(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2455 | Time 74.9608(74.0556) | Bit/dim 3.9658(3.9636) | Xent 0.4453(0.4499) | Loss 4.1885(4.1886) | Error 0.1593(0.1628) Steps 790(797.85) | Grad Norm 2.4884(2.3577) | Total Time 14.00(14.00)\n",
      "Iter 2456 | Time 74.4852(74.0685) | Bit/dim 3.9618(3.9636) | Xent 0.4440(0.4497) | Loss 4.1838(4.1884) | Error 0.1595(0.1627) Steps 802(797.98) | Grad Norm 4.9016(2.4340) | Total Time 14.00(14.00)\n",
      "Iter 2457 | Time 72.6967(74.0273) | Bit/dim 3.9641(3.9636) | Xent 0.4306(0.4491) | Loss 4.1794(4.1881) | Error 0.1551(0.1624) Steps 796(797.92) | Grad Norm 3.8755(2.4773) | Total Time 14.00(14.00)\n",
      "Iter 2458 | Time 72.1208(73.9701) | Bit/dim 3.9589(3.9634) | Xent 0.4325(0.4486) | Loss 4.1752(4.1878) | Error 0.1570(0.1623) Steps 790(797.68) | Grad Norm 3.0479(2.4944) | Total Time 14.00(14.00)\n",
      "Iter 2459 | Time 75.3961(74.0129) | Bit/dim 3.9659(3.9635) | Xent 0.4340(0.4482) | Loss 4.1830(4.1876) | Error 0.1577(0.1621) Steps 808(797.99) | Grad Norm 3.9236(2.5373) | Total Time 14.00(14.00)\n",
      "Iter 2460 | Time 73.6663(74.0025) | Bit/dim 3.9556(3.9633) | Xent 0.4500(0.4483) | Loss 4.1806(4.1874) | Error 0.1633(0.1622) Steps 802(798.11) | Grad Norm 2.4968(2.5360) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 29.4128, Epoch Time 495.1471(491.8547), Bit/dim 3.9708(best: 3.9716), Xent 1.6904, Loss 4.8160, Error 0.4217(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2461 | Time 74.7993(74.0264) | Bit/dim 3.9635(3.9633) | Xent 0.4445(0.4481) | Loss 4.1857(4.1874) | Error 0.1595(0.1621) Steps 802(798.23) | Grad Norm 3.0502(2.5515) | Total Time 14.00(14.00)\n",
      "Iter 2462 | Time 74.2281(74.0324) | Bit/dim 3.9557(3.9631) | Xent 0.4388(0.4479) | Loss 4.1751(4.1870) | Error 0.1589(0.1620) Steps 784(797.80) | Grad Norm 2.7521(2.5575) | Total Time 14.00(14.00)\n",
      "Iter 2463 | Time 73.1885(74.0071) | Bit/dim 3.9572(3.9629) | Xent 0.4352(0.4475) | Loss 4.1748(4.1866) | Error 0.1631(0.1620) Steps 790(797.57) | Grad Norm 1.7874(2.5344) | Total Time 14.00(14.00)\n",
      "Iter 2464 | Time 74.0047(74.0071) | Bit/dim 3.9683(3.9630) | Xent 0.4436(0.4474) | Loss 4.1901(4.1867) | Error 0.1575(0.1619) Steps 796(797.52) | Grad Norm 1.7344(2.5104) | Total Time 14.00(14.00)\n",
      "Iter 2465 | Time 74.0305(74.0078) | Bit/dim 3.9673(3.9632) | Xent 0.4493(0.4474) | Loss 4.1919(4.1869) | Error 0.1657(0.1620) Steps 796(797.47) | Grad Norm 2.7947(2.5189) | Total Time 14.00(14.00)\n",
      "Iter 2466 | Time 72.0012(73.9476) | Bit/dim 3.9608(3.9631) | Xent 0.4440(0.4473) | Loss 4.1828(4.1868) | Error 0.1630(0.1620) Steps 802(797.61) | Grad Norm 1.4908(2.4881) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 29.7356, Epoch Time 488.1799(491.7445), Bit/dim 3.9706(best: 3.9708), Xent 1.7152, Loss 4.8282, Error 0.4248(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2467 | Time 74.1013(73.9522) | Bit/dim 3.9674(3.9632) | Xent 0.4590(0.4477) | Loss 4.1969(4.1871) | Error 0.1624(0.1620) Steps 796(797.56) | Grad Norm 2.9482(2.5019) | Total Time 14.00(14.00)\n",
      "Iter 2468 | Time 74.7787(73.9770) | Bit/dim 3.9538(3.9629) | Xent 0.4359(0.4473) | Loss 4.1718(4.1866) | Error 0.1575(0.1619) Steps 790(797.33) | Grad Norm 3.0844(2.5193) | Total Time 14.00(14.00)\n",
      "Iter 2469 | Time 73.6163(73.9662) | Bit/dim 3.9607(3.9629) | Xent 0.4369(0.4470) | Loss 4.1792(4.1864) | Error 0.1570(0.1618) Steps 796(797.29) | Grad Norm 2.8218(2.5284) | Total Time 14.00(14.00)\n",
      "Iter 2470 | Time 74.3083(73.9764) | Bit/dim 3.9652(3.9629) | Xent 0.4403(0.4468) | Loss 4.1854(4.1864) | Error 0.1614(0.1618) Steps 796(797.26) | Grad Norm 4.5516(2.5891) | Total Time 14.00(14.00)\n",
      "Iter 2471 | Time 75.4415(74.0204) | Bit/dim 3.9593(3.9628) | Xent 0.4346(0.4464) | Loss 4.1766(4.1861) | Error 0.1569(0.1616) Steps 808(797.58) | Grad Norm 2.9526(2.6000) | Total Time 14.00(14.00)\n",
      "Iter 2472 | Time 72.9329(73.9877) | Bit/dim 3.9592(3.9627) | Xent 0.4348(0.4461) | Loss 4.1766(4.1858) | Error 0.1601(0.1616) Steps 802(797.71) | Grad Norm 3.1191(2.6156) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 29.4581, Epoch Time 493.4983(491.7971), Bit/dim 3.9699(best: 3.9706), Xent 1.7122, Loss 4.8260, Error 0.4260(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2473 | Time 71.6387(73.9173) | Bit/dim 3.9595(3.9626) | Xent 0.4269(0.4455) | Loss 4.1730(4.1854) | Error 0.1541(0.1613) Steps 796(797.66) | Grad Norm 3.0737(2.6293) | Total Time 14.00(14.00)\n",
      "Iter 2474 | Time 72.1496(73.8642) | Bit/dim 3.9618(3.9626) | Xent 0.4469(0.4456) | Loss 4.1852(4.1854) | Error 0.1665(0.1615) Steps 802(797.79) | Grad Norm 1.7809(2.6039) | Total Time 14.00(14.00)\n",
      "Iter 2475 | Time 76.5771(73.9456) | Bit/dim 3.9642(3.9627) | Xent 0.4430(0.4455) | Loss 4.1857(4.1854) | Error 0.1641(0.1616) Steps 802(797.92) | Grad Norm 2.3146(2.5952) | Total Time 14.00(14.00)\n",
      "Iter 2476 | Time 74.5276(73.9631) | Bit/dim 3.9500(3.9623) | Xent 0.4558(0.4458) | Loss 4.1779(4.1852) | Error 0.1633(0.1616) Steps 796(797.86) | Grad Norm 1.6100(2.5657) | Total Time 14.00(14.00)\n",
      "Iter 2477 | Time 73.4149(73.9466) | Bit/dim 3.9566(3.9621) | Xent 0.4260(0.4452) | Loss 4.1696(4.1847) | Error 0.1599(0.1616) Steps 796(797.80) | Grad Norm 2.2007(2.5547) | Total Time 14.00(14.00)\n",
      "Iter 2478 | Time 72.1754(73.8935) | Bit/dim 3.9666(3.9622) | Xent 0.4338(0.4449) | Loss 4.1835(4.1847) | Error 0.1560(0.1614) Steps 796(797.75) | Grad Norm 2.1308(2.5420) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 29.0950, Epoch Time 486.1896(491.6289), Bit/dim 3.9700(best: 3.9699), Xent 1.7000, Loss 4.8199, Error 0.4250(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2479 | Time 76.4546(73.9703) | Bit/dim 3.9618(3.9622) | Xent 0.4162(0.4440) | Loss 4.1700(4.1842) | Error 0.1496(0.1611) Steps 802(797.88) | Grad Norm 1.8768(2.5220) | Total Time 14.00(14.00)\n",
      "Iter 2480 | Time 74.6375(73.9903) | Bit/dim 3.9644(3.9623) | Xent 0.4370(0.4438) | Loss 4.1830(4.1842) | Error 0.1561(0.1609) Steps 790(797.64) | Grad Norm 1.7556(2.4990) | Total Time 14.00(14.00)\n",
      "Iter 2481 | Time 76.5381(74.0668) | Bit/dim 3.9622(3.9623) | Xent 0.4460(0.4439) | Loss 4.1852(4.1842) | Error 0.1576(0.1608) Steps 802(797.77) | Grad Norm 2.1266(2.4879) | Total Time 14.00(14.00)\n",
      "Iter 2482 | Time 72.1360(74.0089) | Bit/dim 3.9555(3.9621) | Xent 0.4339(0.4436) | Loss 4.1724(4.1839) | Error 0.1583(0.1607) Steps 778(797.18) | Grad Norm 2.1804(2.4786) | Total Time 14.00(14.00)\n",
      "Iter 2483 | Time 73.7430(74.0009) | Bit/dim 3.9579(3.9620) | Xent 0.4260(0.4430) | Loss 4.1709(4.1835) | Error 0.1470(0.1603) Steps 802(797.32) | Grad Norm 1.7274(2.4561) | Total Time 14.00(14.00)\n",
      "Iter 2484 | Time 75.6422(74.0501) | Bit/dim 3.9630(3.9620) | Xent 0.4065(0.4419) | Loss 4.1663(4.1830) | Error 0.1454(0.1599) Steps 796(797.28) | Grad Norm 3.5682(2.4895) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 29.3117, Epoch Time 494.0195(491.7006), Bit/dim 3.9707(best: 3.9699), Xent 1.7248, Loss 4.8332, Error 0.4245(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2485 | Time 74.1082(74.0519) | Bit/dim 3.9656(3.9621) | Xent 0.4228(0.4414) | Loss 4.1771(4.1828) | Error 0.1509(0.1596) Steps 796(797.24) | Grad Norm 2.7638(2.4977) | Total Time 14.00(14.00)\n",
      "Iter 2486 | Time 73.9920(74.0501) | Bit/dim 3.9615(3.9621) | Xent 0.4481(0.4416) | Loss 4.1856(4.1829) | Error 0.1637(0.1597) Steps 784(796.85) | Grad Norm 2.1453(2.4871) | Total Time 14.00(14.00)\n",
      "Iter 2487 | Time 74.6682(74.0686) | Bit/dim 3.9590(3.9620) | Xent 0.4246(0.4411) | Loss 4.1713(4.1825) | Error 0.1516(0.1595) Steps 796(796.82) | Grad Norm 2.4575(2.4862) | Total Time 14.00(14.00)\n",
      "Iter 2488 | Time 73.9727(74.0657) | Bit/dim 3.9532(3.9617) | Xent 0.4293(0.4407) | Loss 4.1679(4.1821) | Error 0.1549(0.1593) Steps 802(796.98) | Grad Norm 1.4144(2.4541) | Total Time 14.00(14.00)\n",
      "Iter 2489 | Time 73.4440(74.0471) | Bit/dim 3.9581(3.9616) | Xent 0.4327(0.4405) | Loss 4.1745(4.1819) | Error 0.1586(0.1593) Steps 790(796.77) | Grad Norm 3.6206(2.4891) | Total Time 14.00(14.00)\n",
      "Iter 2490 | Time 72.5799(74.0031) | Bit/dim 3.9650(3.9617) | Xent 0.4120(0.4396) | Loss 4.1710(4.1815) | Error 0.1534(0.1591) Steps 814(797.28) | Grad Norm 1.8989(2.4714) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 29.2775, Epoch Time 487.4375(491.5727), Bit/dim 3.9693(best: 3.9699), Xent 1.7202, Loss 4.8294, Error 0.4227(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2491 | Time 75.2044(74.0391) | Bit/dim 3.9619(3.9617) | Xent 0.4277(0.4393) | Loss 4.1758(4.1814) | Error 0.1521(0.1589) Steps 784(796.89) | Grad Norm 1.9822(2.4567) | Total Time 14.00(14.00)\n",
      "Iter 2492 | Time 76.2575(74.1057) | Bit/dim 3.9611(3.9617) | Xent 0.4199(0.4387) | Loss 4.1710(4.1810) | Error 0.1484(0.1586) Steps 790(796.68) | Grad Norm 2.7391(2.4652) | Total Time 14.00(14.00)\n",
      "Iter 2493 | Time 73.7127(74.0939) | Bit/dim 3.9606(3.9617) | Xent 0.4360(0.4386) | Loss 4.1786(4.1810) | Error 0.1585(0.1586) Steps 802(796.84) | Grad Norm 2.4089(2.4635) | Total Time 14.00(14.00)\n",
      "Iter 2494 | Time 76.7372(74.1732) | Bit/dim 3.9663(3.9618) | Xent 0.4242(0.4382) | Loss 4.1784(4.1809) | Error 0.1562(0.1585) Steps 790(796.63) | Grad Norm 1.8154(2.4440) | Total Time 14.00(14.00)\n",
      "Iter 2495 | Time 72.3819(74.1194) | Bit/dim 3.9539(3.9616) | Xent 0.4206(0.4376) | Loss 4.1642(4.1804) | Error 0.1519(0.1583) Steps 796(796.61) | Grad Norm 1.5006(2.4157) | Total Time 14.00(14.00)\n",
      "Iter 2496 | Time 74.1973(74.1218) | Bit/dim 3.9611(3.9616) | Xent 0.4242(0.4372) | Loss 4.1732(4.1802) | Error 0.1559(0.1583) Steps 790(796.42) | Grad Norm 2.0522(2.4048) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 29.5504, Epoch Time 495.6227(491.6942), Bit/dim 3.9675(best: 3.9693), Xent 1.7251, Loss 4.8301, Error 0.4275(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2497 | Time 73.6791(74.1085) | Bit/dim 3.9588(3.9615) | Xent 0.4190(0.4367) | Loss 4.1683(4.1798) | Error 0.1511(0.1581) Steps 790(796.22) | Grad Norm 1.7193(2.3843) | Total Time 14.00(14.00)\n",
      "Iter 2498 | Time 75.2542(74.1429) | Bit/dim 3.9587(3.9614) | Xent 0.4400(0.4368) | Loss 4.1787(4.1798) | Error 0.1546(0.1579) Steps 784(795.86) | Grad Norm 1.9325(2.3707) | Total Time 14.00(14.00)\n",
      "Iter 2499 | Time 71.2974(74.0575) | Bit/dim 3.9592(3.9613) | Xent 0.4149(0.4361) | Loss 4.1666(4.1794) | Error 0.1528(0.1578) Steps 790(795.68) | Grad Norm 1.7488(2.3520) | Total Time 14.00(14.00)\n",
      "Iter 2500 | Time 73.9022(74.0528) | Bit/dim 3.9592(3.9613) | Xent 0.4150(0.4355) | Loss 4.1667(4.1790) | Error 0.1499(0.1576) Steps 802(795.87) | Grad Norm 1.7290(2.3334) | Total Time 14.00(14.00)\n",
      "Iter 2501 | Time 74.9633(74.0801) | Bit/dim 3.9592(3.9612) | Xent 0.4445(0.4358) | Loss 4.1814(4.1791) | Error 0.1594(0.1576) Steps 796(795.87) | Grad Norm 3.0530(2.3549) | Total Time 14.00(14.00)\n",
      "Iter 2502 | Time 72.4859(74.0323) | Bit/dim 3.9574(3.9611) | Xent 0.4220(0.4354) | Loss 4.1683(4.1788) | Error 0.1544(0.1575) Steps 790(795.70) | Grad Norm 1.2086(2.3206) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 29.7935, Epoch Time 487.1678(491.5584), Bit/dim 3.9685(best: 3.9675), Xent 1.7254, Loss 4.8312, Error 0.4252(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2503 | Time 74.3394(74.0415) | Bit/dim 3.9555(3.9609) | Xent 0.4293(0.4352) | Loss 4.1701(4.1785) | Error 0.1522(0.1574) Steps 796(795.71) | Grad Norm 2.9105(2.3383) | Total Time 14.00(14.00)\n",
      "Iter 2504 | Time 73.4343(74.0233) | Bit/dim 3.9641(3.9610) | Xent 0.4334(0.4351) | Loss 4.1809(4.1786) | Error 0.1565(0.1573) Steps 790(795.54) | Grad Norm 1.9857(2.3277) | Total Time 14.00(14.00)\n",
      "Iter 2505 | Time 72.9596(73.9914) | Bit/dim 3.9632(3.9611) | Xent 0.4154(0.4345) | Loss 4.1709(4.1783) | Error 0.1515(0.1572) Steps 778(795.01) | Grad Norm 1.7265(2.3096) | Total Time 14.00(14.00)\n",
      "Iter 2506 | Time 75.7946(74.0455) | Bit/dim 3.9579(3.9610) | Xent 0.4093(0.4338) | Loss 4.1626(4.1779) | Error 0.1502(0.1569) Steps 790(794.86) | Grad Norm 2.2306(2.3073) | Total Time 14.00(14.00)\n",
      "Iter 2507 | Time 74.1935(74.0499) | Bit/dim 3.9538(3.9608) | Xent 0.4286(0.4336) | Loss 4.1681(4.1776) | Error 0.1550(0.1569) Steps 790(794.71) | Grad Norm 2.6655(2.3180) | Total Time 14.00(14.00)\n",
      "Iter 2508 | Time 75.7719(74.1016) | Bit/dim 3.9587(3.9607) | Xent 0.4427(0.4339) | Loss 4.1800(4.1777) | Error 0.1586(0.1569) Steps 796(794.75) | Grad Norm 2.3211(2.3181) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 29.7482, Epoch Time 491.6653(491.5616), Bit/dim 3.9678(best: 3.9675), Xent 1.7188, Loss 4.8272, Error 0.4258(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2509 | Time 74.9217(74.1262) | Bit/dim 3.9584(3.9606) | Xent 0.4246(0.4336) | Loss 4.1707(4.1774) | Error 0.1476(0.1567) Steps 796(794.79) | Grad Norm 2.6497(2.3281) | Total Time 14.00(14.00)\n",
      "Iter 2510 | Time 72.8400(74.0876) | Bit/dim 3.9623(3.9607) | Xent 0.4109(0.4329) | Loss 4.1678(4.1772) | Error 0.1490(0.1564) Steps 790(794.65) | Grad Norm 1.4523(2.3018) | Total Time 14.00(14.00)\n",
      "Iter 2511 | Time 73.8003(74.0790) | Bit/dim 3.9622(3.9607) | Xent 0.4216(0.4326) | Loss 4.1730(4.1770) | Error 0.1558(0.1564) Steps 790(794.51) | Grad Norm 1.7921(2.2865) | Total Time 14.00(14.00)\n",
      "Iter 2512 | Time 72.6897(74.0373) | Bit/dim 3.9672(3.9609) | Xent 0.4156(0.4321) | Loss 4.1750(4.1770) | Error 0.1474(0.1561) Steps 778(794.01) | Grad Norm 1.5126(2.2633) | Total Time 14.00(14.00)\n",
      "Iter 2513 | Time 72.7022(73.9973) | Bit/dim 3.9572(3.9608) | Xent 0.4216(0.4318) | Loss 4.1680(4.1767) | Error 0.1489(0.1559) Steps 790(793.89) | Grad Norm 1.7201(2.2470) | Total Time 14.00(14.00)\n",
      "Iter 2514 | Time 75.9698(74.0564) | Bit/dim 3.9459(3.9604) | Xent 0.4295(0.4317) | Loss 4.1606(4.1762) | Error 0.1520(0.1558) Steps 790(793.77) | Grad Norm 1.2654(2.2175) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 29.9225, Epoch Time 488.6024(491.4728), Bit/dim 3.9681(best: 3.9675), Xent 1.7431, Loss 4.8396, Error 0.4291(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2515 | Time 73.4179(74.0373) | Bit/dim 3.9622(3.9604) | Xent 0.4275(0.4316) | Loss 4.1760(4.1762) | Error 0.1516(0.1557) Steps 784(793.48) | Grad Norm 1.5530(2.1976) | Total Time 14.00(14.00)\n",
      "Iter 2516 | Time 71.8334(73.9712) | Bit/dim 3.9571(3.9603) | Xent 0.4388(0.4318) | Loss 4.1764(4.1762) | Error 0.1595(0.1558) Steps 796(793.56) | Grad Norm 2.4341(2.2047) | Total Time 14.00(14.00)\n",
      "Iter 2517 | Time 72.0620(73.9139) | Bit/dim 3.9599(3.9603) | Xent 0.4201(0.4314) | Loss 4.1699(4.1760) | Error 0.1530(0.1557) Steps 796(793.63) | Grad Norm 2.4542(2.2122) | Total Time 14.00(14.00)\n",
      "Iter 2518 | Time 70.5855(73.8140) | Bit/dim 3.9677(3.9605) | Xent 0.4110(0.4308) | Loss 4.1732(4.1759) | Error 0.1515(0.1556) Steps 808(794.06) | Grad Norm 2.0634(2.2077) | Total Time 14.00(14.00)\n",
      "Iter 2519 | Time 72.5401(73.7758) | Bit/dim 3.9567(3.9604) | Xent 0.4121(0.4303) | Loss 4.1627(4.1755) | Error 0.1532(0.1555) Steps 790(793.94) | Grad Norm 2.9212(2.2291) | Total Time 14.00(14.00)\n",
      "Iter 2520 | Time 72.0095(73.7228) | Bit/dim 3.9531(3.9602) | Xent 0.4337(0.4304) | Loss 4.1700(4.1754) | Error 0.1556(0.1555) Steps 808(794.36) | Grad Norm 2.5593(2.2390) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 29.5090, Epoch Time 477.9024(491.0657), Bit/dim 3.9686(best: 3.9675), Xent 1.7717, Loss 4.8545, Error 0.4260(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2521 | Time 74.0162(73.7316) | Bit/dim 3.9601(3.9602) | Xent 0.4346(0.4305) | Loss 4.1774(4.1754) | Error 0.1580(0.1556) Steps 784(794.05) | Grad Norm 2.3347(2.2419) | Total Time 14.00(14.00)\n",
      "Iter 2522 | Time 73.0721(73.7119) | Bit/dim 3.9627(3.9603) | Xent 0.4219(0.4302) | Loss 4.1737(4.1754) | Error 0.1499(0.1554) Steps 790(793.93) | Grad Norm 1.7505(2.2271) | Total Time 14.00(14.00)\n",
      "Iter 2523 | Time 73.0534(73.6921) | Bit/dim 3.9574(3.9602) | Xent 0.4169(0.4298) | Loss 4.1659(4.1751) | Error 0.1486(0.1552) Steps 790(793.81) | Grad Norm 2.6795(2.2407) | Total Time 14.00(14.00)\n",
      "Iter 2524 | Time 72.3955(73.6532) | Bit/dim 3.9547(3.9600) | Xent 0.4172(0.4294) | Loss 4.1632(4.1747) | Error 0.1524(0.1551) Steps 808(794.24) | Grad Norm 2.1001(2.2365) | Total Time 14.00(14.00)\n",
      "Iter 2525 | Time 73.3410(73.6438) | Bit/dim 3.9559(3.9599) | Xent 0.4045(0.4287) | Loss 4.1581(4.1742) | Error 0.1440(0.1548) Steps 814(794.83) | Grad Norm 2.0116(2.2298) | Total Time 14.00(14.00)\n",
      "Iter 2526 | Time 72.6960(73.6154) | Bit/dim 3.9629(3.9600) | Xent 0.4248(0.4286) | Loss 4.1753(4.1743) | Error 0.1535(0.1548) Steps 784(794.50) | Grad Norm 1.6465(2.2123) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 29.4991, Epoch Time 485.1245(490.8875), Bit/dim 3.9678(best: 3.9675), Xent 1.7445, Loss 4.8400, Error 0.4255(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2527 | Time 74.7152(73.6484) | Bit/dim 3.9555(3.9598) | Xent 0.4127(0.4281) | Loss 4.1619(4.1739) | Error 0.1511(0.1546) Steps 790(794.37) | Grad Norm 2.7755(2.2292) | Total Time 14.00(14.00)\n",
      "Iter 2528 | Time 73.4383(73.6421) | Bit/dim 3.9550(3.9597) | Xent 0.4086(0.4275) | Loss 4.1593(4.1735) | Error 0.1444(0.1543) Steps 790(794.24) | Grad Norm 1.7920(2.2160) | Total Time 14.00(14.00)\n",
      "Iter 2529 | Time 73.5623(73.6397) | Bit/dim 3.9555(3.9596) | Xent 0.4132(0.4271) | Loss 4.1621(4.1731) | Error 0.1474(0.1541) Steps 796(794.29) | Grad Norm 3.6758(2.2598) | Total Time 14.00(14.00)\n",
      "Iter 2530 | Time 75.4432(73.6938) | Bit/dim 3.9477(3.9592) | Xent 0.4418(0.4275) | Loss 4.1686(4.1730) | Error 0.1569(0.1542) Steps 784(793.98) | Grad Norm 1.9831(2.2515) | Total Time 14.00(14.00)\n",
      "Iter 2531 | Time 76.0459(73.7644) | Bit/dim 3.9686(3.9595) | Xent 0.4144(0.4271) | Loss 4.1758(4.1731) | Error 0.1478(0.1540) Steps 808(794.40) | Grad Norm 1.7457(2.2364) | Total Time 14.00(14.00)\n",
      "Iter 2532 | Time 75.1185(73.8050) | Bit/dim 3.9611(3.9596) | Xent 0.4240(0.4270) | Loss 4.1731(4.1731) | Error 0.1556(0.1541) Steps 784(794.09) | Grad Norm 2.3561(2.2399) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 29.6865, Epoch Time 494.6981(491.0018), Bit/dim 3.9682(best: 3.9675), Xent 1.7724, Loss 4.8544, Error 0.4277(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2533 | Time 72.0352(73.7519) | Bit/dim 3.9629(3.9597) | Xent 0.4236(0.4269) | Loss 4.1747(4.1731) | Error 0.1552(0.1541) Steps 790(793.97) | Grad Norm 2.3687(2.2438) | Total Time 14.00(14.00)\n",
      "Iter 2534 | Time 74.0520(73.7609) | Bit/dim 3.9615(3.9597) | Xent 0.4345(0.4272) | Loss 4.1788(4.1733) | Error 0.1585(0.1542) Steps 784(793.67) | Grad Norm 2.1320(2.2405) | Total Time 14.00(14.00)\n",
      "Iter 2535 | Time 71.7054(73.6992) | Bit/dim 3.9534(3.9595) | Xent 0.4065(0.4266) | Loss 4.1566(4.1728) | Error 0.1450(0.1540) Steps 802(793.92) | Grad Norm 1.7424(2.2255) | Total Time 14.00(14.00)\n",
      "Iter 2536 | Time 70.7801(73.6117) | Bit/dim 3.9594(3.9595) | Xent 0.4175(0.4263) | Loss 4.1681(4.1727) | Error 0.1532(0.1539) Steps 790(793.80) | Grad Norm 1.5840(2.2063) | Total Time 14.00(14.00)\n",
      "Iter 2537 | Time 71.4125(73.5457) | Bit/dim 3.9643(3.9597) | Xent 0.4076(0.4257) | Loss 4.1681(4.1725) | Error 0.1482(0.1538) Steps 790(793.69) | Grad Norm 2.2417(2.2073) | Total Time 14.00(14.00)\n",
      "Iter 2538 | Time 73.1811(73.5347) | Bit/dim 3.9486(3.9593) | Xent 0.4197(0.4255) | Loss 4.1585(4.1721) | Error 0.1496(0.1536) Steps 802(793.94) | Grad Norm 2.1258(2.2049) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 29.5509, Epoch Time 480.5444(490.6881), Bit/dim 3.9668(best: 3.9675), Xent 1.7608, Loss 4.8473, Error 0.4242(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2539 | Time 72.2173(73.4952) | Bit/dim 3.9590(3.9593) | Xent 0.4290(0.4256) | Loss 4.1736(4.1721) | Error 0.1562(0.1537) Steps 796(794.00) | Grad Norm 3.0960(2.2316) | Total Time 14.00(14.00)\n",
      "Iter 2540 | Time 74.9615(73.5392) | Bit/dim 3.9656(3.9595) | Xent 0.4207(0.4255) | Loss 4.1759(4.1723) | Error 0.1585(0.1539) Steps 790(793.88) | Grad Norm 2.0849(2.2272) | Total Time 14.00(14.00)\n",
      "Iter 2541 | Time 71.6955(73.4839) | Bit/dim 3.9576(3.9594) | Xent 0.4266(0.4255) | Loss 4.1709(4.1722) | Error 0.1516(0.1538) Steps 790(793.76) | Grad Norm 3.0409(2.2516) | Total Time 14.00(14.00)\n",
      "Iter 2542 | Time 73.2490(73.4769) | Bit/dim 3.9494(3.9591) | Xent 0.4204(0.4254) | Loss 4.1596(4.1718) | Error 0.1519(0.1537) Steps 790(793.65) | Grad Norm 1.8264(2.2389) | Total Time 14.00(14.00)\n",
      "Iter 2543 | Time 74.8234(73.5172) | Bit/dim 3.9497(3.9589) | Xent 0.4362(0.4257) | Loss 4.1678(4.1717) | Error 0.1574(0.1538) Steps 826(794.62) | Grad Norm 5.0308(2.3226) | Total Time 14.00(14.00)\n",
      "Iter 2544 | Time 75.3354(73.5718) | Bit/dim 3.9567(3.9588) | Xent 0.4006(0.4249) | Loss 4.1570(4.1713) | Error 0.1484(0.1537) Steps 796(794.66) | Grad Norm 1.6875(2.3036) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 29.8496, Epoch Time 487.6935(490.5983), Bit/dim 3.9670(best: 3.9668), Xent 1.7749, Loss 4.8545, Error 0.4310(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2545 | Time 72.1062(73.5278) | Bit/dim 3.9483(3.9585) | Xent 0.4140(0.4246) | Loss 4.1553(4.1708) | Error 0.1511(0.1536) Steps 796(794.70) | Grad Norm 3.9855(2.3540) | Total Time 14.00(14.00)\n",
      "Iter 2546 | Time 71.1356(73.4561) | Bit/dim 3.9605(3.9585) | Xent 0.4249(0.4246) | Loss 4.1730(4.1709) | Error 0.1531(0.1536) Steps 784(794.38) | Grad Norm 2.3400(2.3536) | Total Time 14.00(14.00)\n",
      "Iter 2547 | Time 74.1814(73.4778) | Bit/dim 3.9561(3.9585) | Xent 0.4194(0.4245) | Loss 4.1658(4.1707) | Error 0.1522(0.1536) Steps 802(794.61) | Grad Norm 2.6637(2.3629) | Total Time 14.00(14.00)\n",
      "Iter 2548 | Time 72.5976(73.4514) | Bit/dim 3.9568(3.9584) | Xent 0.4120(0.4241) | Loss 4.1628(4.1705) | Error 0.1472(0.1534) Steps 796(794.65) | Grad Norm 3.3375(2.3921) | Total Time 14.00(14.00)\n",
      "Iter 2549 | Time 73.0207(73.4385) | Bit/dim 3.9534(3.9583) | Xent 0.4211(0.4240) | Loss 4.1639(4.1703) | Error 0.1484(0.1532) Steps 790(794.51) | Grad Norm 4.0217(2.4410) | Total Time 14.00(14.00)\n",
      "Iter 2550 | Time 73.4074(73.4376) | Bit/dim 3.9589(3.9583) | Xent 0.4291(0.4242) | Loss 4.1734(4.1704) | Error 0.1545(0.1533) Steps 796(794.56) | Grad Norm 3.6905(2.4785) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 29.7640, Epoch Time 481.8724(490.3365), Bit/dim 3.9676(best: 3.9668), Xent 1.7775, Loss 4.8564, Error 0.4267(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2551 | Time 74.0296(73.4553) | Bit/dim 3.9614(3.9584) | Xent 0.4025(0.4235) | Loss 4.1626(4.1701) | Error 0.1462(0.1530) Steps 814(795.14) | Grad Norm 4.1541(2.5288) | Total Time 14.00(14.00)\n",
      "Iter 2552 | Time 72.8355(73.4367) | Bit/dim 3.9590(3.9584) | Xent 0.4239(0.4235) | Loss 4.1710(4.1702) | Error 0.1559(0.1531) Steps 802(795.35) | Grad Norm 3.2736(2.5511) | Total Time 14.00(14.00)\n",
      "Iter 2553 | Time 72.9878(73.4233) | Bit/dim 3.9499(3.9581) | Xent 0.4091(0.4231) | Loss 4.1545(4.1697) | Error 0.1471(0.1529) Steps 790(795.18) | Grad Norm 3.3476(2.5750) | Total Time 14.00(14.00)\n",
      "Iter 2554 | Time 73.3796(73.4219) | Bit/dim 3.9576(3.9581) | Xent 0.4103(0.4227) | Loss 4.1627(4.1695) | Error 0.1479(0.1528) Steps 790(795.03) | Grad Norm 3.0004(2.5878) | Total Time 14.00(14.00)\n",
      "Iter 2555 | Time 75.3531(73.4799) | Bit/dim 3.9448(3.9577) | Xent 0.4202(0.4226) | Loss 4.1549(4.1690) | Error 0.1546(0.1529) Steps 784(794.70) | Grad Norm 3.0044(2.6003) | Total Time 14.00(14.00)\n",
      "Iter 2556 | Time 75.0810(73.5279) | Bit/dim 3.9660(3.9580) | Xent 0.4134(0.4224) | Loss 4.1727(4.1692) | Error 0.1521(0.1528) Steps 802(794.92) | Grad Norm 2.4763(2.5966) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 29.7636, Epoch Time 489.0388(490.2975), Bit/dim 3.9674(best: 3.9668), Xent 1.7670, Loss 4.8509, Error 0.4228(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2557 | Time 73.7486(73.5345) | Bit/dim 3.9498(3.9577) | Xent 0.4065(0.4219) | Loss 4.1531(4.1687) | Error 0.1462(0.1526) Steps 784(794.59) | Grad Norm 2.4700(2.5928) | Total Time 14.00(14.00)\n",
      "Iter 2558 | Time 72.8905(73.5152) | Bit/dim 3.9638(3.9579) | Xent 0.4128(0.4216) | Loss 4.1702(4.1687) | Error 0.1540(0.1527) Steps 796(794.63) | Grad Norm 3.1013(2.6080) | Total Time 14.00(14.00)\n",
      "Iter 2559 | Time 74.3483(73.5402) | Bit/dim 3.9492(3.9577) | Xent 0.4023(0.4210) | Loss 4.1503(4.1682) | Error 0.1468(0.1525) Steps 802(794.85) | Grad Norm 1.5724(2.5770) | Total Time 14.00(14.00)\n",
      "Iter 2560 | Time 74.5849(73.5716) | Bit/dim 3.9591(3.9577) | Xent 0.4071(0.4206) | Loss 4.1626(4.1680) | Error 0.1484(0.1524) Steps 802(795.07) | Grad Norm 2.6506(2.5792) | Total Time 14.00(14.00)\n",
      "Iter 2561 | Time 74.1448(73.5887) | Bit/dim 3.9548(3.9576) | Xent 0.4251(0.4207) | Loss 4.1673(4.1680) | Error 0.1564(0.1525) Steps 790(794.92) | Grad Norm 3.1116(2.5951) | Total Time 14.00(14.00)\n",
      "Iter 2562 | Time 73.4387(73.5842) | Bit/dim 3.9653(3.9578) | Xent 0.4009(0.4201) | Loss 4.1658(4.1679) | Error 0.1461(0.1523) Steps 808(795.31) | Grad Norm 2.1750(2.5825) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 29.7265, Epoch Time 488.4783(490.2430), Bit/dim 3.9676(best: 3.9668), Xent 1.8202, Loss 4.8777, Error 0.4333(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2563 | Time 75.4965(73.6416) | Bit/dim 3.9616(3.9579) | Xent 0.4113(0.4199) | Loss 4.1672(4.1679) | Error 0.1491(0.1522) Steps 802(795.51) | Grad Norm 6.1429(2.6893) | Total Time 14.00(14.00)\n",
      "Iter 2564 | Time 77.4636(73.7563) | Bit/dim 3.9592(3.9580) | Xent 0.4135(0.4197) | Loss 4.1660(4.1678) | Error 0.1438(0.1520) Steps 796(795.52) | Grad Norm 1.9058(2.6658) | Total Time 14.00(14.00)\n",
      "Iter 2565 | Time 72.7038(73.7247) | Bit/dim 3.9587(3.9580) | Xent 0.4070(0.4193) | Loss 4.1621(4.1677) | Error 0.1485(0.1518) Steps 796(795.54) | Grad Norm 5.2853(2.7444) | Total Time 14.00(14.00)\n",
      "Iter 2566 | Time 72.7157(73.6944) | Bit/dim 3.9566(3.9580) | Xent 0.4156(0.4192) | Loss 4.1644(4.1676) | Error 0.1518(0.1518) Steps 778(795.01) | Grad Norm 2.3673(2.7331) | Total Time 14.00(14.00)\n",
      "Iter 2567 | Time 73.8947(73.7004) | Bit/dim 3.9519(3.9578) | Xent 0.4081(0.4189) | Loss 4.1559(4.1672) | Error 0.1452(0.1516) Steps 790(794.86) | Grad Norm 2.0797(2.7135) | Total Time 14.00(14.00)\n",
      "Iter 2568 | Time 73.9455(73.7078) | Bit/dim 3.9489(3.9575) | Xent 0.4155(0.4188) | Loss 4.1566(4.1669) | Error 0.1522(0.1517) Steps 790(794.72) | Grad Norm 2.3610(2.7029) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 29.7541, Epoch Time 491.4649(490.2796), Bit/dim 3.9657(best: 3.9668), Xent 1.7712, Loss 4.8514, Error 0.4264(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2569 | Time 75.9143(73.7740) | Bit/dim 3.9574(3.9575) | Xent 0.3995(0.4182) | Loss 4.1572(4.1666) | Error 0.1429(0.1514) Steps 784(794.39) | Grad Norm 2.2785(2.6902) | Total Time 14.00(14.00)\n",
      "Iter 2570 | Time 74.6097(73.7991) | Bit/dim 3.9642(3.9577) | Xent 0.4046(0.4178) | Loss 4.1665(4.1666) | Error 0.1444(0.1512) Steps 784(794.08) | Grad Norm 2.4882(2.6841) | Total Time 14.00(14.00)\n",
      "Iter 2571 | Time 76.3832(73.8766) | Bit/dim 3.9506(3.9575) | Xent 0.4025(0.4173) | Loss 4.1518(4.1662) | Error 0.1466(0.1511) Steps 790(793.96) | Grad Norm 1.6883(2.6543) | Total Time 14.00(14.00)\n",
      "Iter 2572 | Time 70.9212(73.7879) | Bit/dim 3.9474(3.9572) | Xent 0.4140(0.4172) | Loss 4.1544(4.1658) | Error 0.1502(0.1510) Steps 790(793.84) | Grad Norm 3.2515(2.6722) | Total Time 14.00(14.00)\n",
      "Iter 2573 | Time 74.1119(73.7976) | Bit/dim 3.9553(3.9571) | Xent 0.4024(0.4168) | Loss 4.1565(4.1655) | Error 0.1451(0.1509) Steps 790(793.73) | Grad Norm 3.0791(2.6844) | Total Time 14.00(14.00)\n",
      "Iter 2574 | Time 72.3032(73.7528) | Bit/dim 3.9596(3.9572) | Xent 0.4093(0.4166) | Loss 4.1643(4.1655) | Error 0.1454(0.1507) Steps 802(793.97) | Grad Norm 2.0534(2.6655) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 29.9082, Epoch Time 489.8590(490.2670), Bit/dim 3.9666(best: 3.9657), Xent 1.8226, Loss 4.8779, Error 0.4289(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2575 | Time 72.1527(73.7048) | Bit/dim 3.9630(3.9574) | Xent 0.4096(0.4163) | Loss 4.1679(4.1656) | Error 0.1492(0.1506) Steps 790(793.85) | Grad Norm 2.6912(2.6662) | Total Time 14.00(14.00)\n",
      "Iter 2576 | Time 72.0395(73.6548) | Bit/dim 3.9415(3.9569) | Xent 0.4129(0.4162) | Loss 4.1479(4.1650) | Error 0.1510(0.1507) Steps 790(793.74) | Grad Norm 3.2618(2.6841) | Total Time 14.00(14.00)\n",
      "Iter 2577 | Time 72.6104(73.6235) | Bit/dim 3.9621(3.9571) | Xent 0.3978(0.4157) | Loss 4.1610(4.1649) | Error 0.1426(0.1504) Steps 802(793.99) | Grad Norm 3.1799(2.6990) | Total Time 14.00(14.00)\n",
      "Iter 2578 | Time 73.7399(73.6270) | Bit/dim 3.9482(3.9568) | Xent 0.4118(0.4156) | Loss 4.1541(4.1646) | Error 0.1501(0.1504) Steps 790(793.87) | Grad Norm 3.3960(2.7199) | Total Time 14.00(14.00)\n",
      "Iter 2579 | Time 75.1135(73.6716) | Bit/dim 3.9514(3.9566) | Xent 0.4059(0.4153) | Loss 4.1544(4.1643) | Error 0.1461(0.1503) Steps 790(793.75) | Grad Norm 1.9764(2.6976) | Total Time 14.00(14.00)\n",
      "Iter 2580 | Time 70.6367(73.5806) | Bit/dim 3.9659(3.9569) | Xent 0.4101(0.4151) | Loss 4.1710(4.1645) | Error 0.1478(0.1502) Steps 790(793.64) | Grad Norm 3.5035(2.7218) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 29.8188, Epoch Time 481.9196(490.0166), Bit/dim 3.9656(best: 3.9657), Xent 1.7940, Loss 4.8626, Error 0.4275(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2581 | Time 70.4687(73.4872) | Bit/dim 3.9559(3.9569) | Xent 0.4110(0.4150) | Loss 4.1614(4.1644) | Error 0.1478(0.1501) Steps 796(793.71) | Grad Norm 4.0208(2.7607) | Total Time 14.00(14.00)\n",
      "Iter 2582 | Time 73.3714(73.4837) | Bit/dim 3.9533(3.9568) | Xent 0.4000(0.4146) | Loss 4.1533(4.1641) | Error 0.1449(0.1500) Steps 796(793.78) | Grad Norm 2.2291(2.7448) | Total Time 14.00(14.00)\n",
      "Iter 2583 | Time 73.2725(73.4774) | Bit/dim 3.9529(3.9567) | Xent 0.4062(0.4143) | Loss 4.1560(4.1638) | Error 0.1468(0.1499) Steps 784(793.49) | Grad Norm 5.1338(2.8164) | Total Time 14.00(14.00)\n",
      "Iter 2584 | Time 73.0765(73.4654) | Bit/dim 3.9550(3.9566) | Xent 0.4097(0.4142) | Loss 4.1599(4.1637) | Error 0.1485(0.1498) Steps 784(793.20) | Grad Norm 2.8100(2.8163) | Total Time 14.00(14.00)\n",
      "Iter 2585 | Time 75.7853(73.5350) | Bit/dim 3.9580(3.9567) | Xent 0.4101(0.4140) | Loss 4.1631(4.1637) | Error 0.1481(0.1498) Steps 802(793.46) | Grad Norm 3.9749(2.8510) | Total Time 14.00(14.00)\n",
      "Iter 2586 | Time 73.1164(73.5224) | Bit/dim 3.9537(3.9566) | Xent 0.4023(0.4137) | Loss 4.1549(4.1634) | Error 0.1415(0.1495) Steps 790(793.36) | Grad Norm 2.2583(2.8332) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 29.7934, Epoch Time 484.7200(489.8577), Bit/dim 3.9653(best: 3.9656), Xent 1.7819, Loss 4.8563, Error 0.4262(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2587 | Time 75.3983(73.5787) | Bit/dim 3.9548(3.9565) | Xent 0.4182(0.4138) | Loss 4.1639(4.1634) | Error 0.1500(0.1495) Steps 784(793.08) | Grad Norm 2.6822(2.8287) | Total Time 14.00(14.00)\n",
      "Iter 2588 | Time 75.9512(73.6499) | Bit/dim 3.9536(3.9564) | Xent 0.4106(0.4137) | Loss 4.1589(4.1633) | Error 0.1459(0.1494) Steps 790(792.99) | Grad Norm 2.0155(2.8043) | Total Time 14.00(14.00)\n",
      "Iter 2589 | Time 71.5818(73.5878) | Bit/dim 3.9542(3.9564) | Xent 0.3816(0.4128) | Loss 4.1450(4.1627) | Error 0.1384(0.1491) Steps 790(792.90) | Grad Norm 1.5360(2.7663) | Total Time 14.00(14.00)\n",
      "Iter 2590 | Time 74.5128(73.6156) | Bit/dim 3.9623(3.9565) | Xent 0.4047(0.4125) | Loss 4.1646(4.1628) | Error 0.1484(0.1491) Steps 796(792.99) | Grad Norm 2.9964(2.7732) | Total Time 14.00(14.00)\n",
      "Iter 2591 | Time 71.8365(73.5622) | Bit/dim 3.9527(3.9564) | Xent 0.4026(0.4122) | Loss 4.1540(4.1625) | Error 0.1448(0.1490) Steps 802(793.26) | Grad Norm 1.9499(2.7485) | Total Time 14.00(14.00)\n",
      "Iter 2592 | Time 75.9136(73.6327) | Bit/dim 3.9520(3.9563) | Xent 0.4020(0.4119) | Loss 4.1530(4.1623) | Error 0.1446(0.1488) Steps 790(793.16) | Grad Norm 2.5416(2.7423) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 29.5788, Epoch Time 490.6506(489.8815), Bit/dim 3.9651(best: 3.9653), Xent 1.8010, Loss 4.8656, Error 0.4272(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2593 | Time 74.0683(73.6458) | Bit/dim 3.9558(3.9563) | Xent 0.3813(0.4110) | Loss 4.1465(4.1618) | Error 0.1385(0.1485) Steps 790(793.07) | Grad Norm 2.6922(2.7408) | Total Time 14.00(14.00)\n",
      "Iter 2594 | Time 72.8790(73.6228) | Bit/dim 3.9438(3.9559) | Xent 0.4231(0.4114) | Loss 4.1553(4.1616) | Error 0.1506(0.1486) Steps 796(793.16) | Grad Norm 3.0205(2.7491) | Total Time 14.00(14.00)\n",
      "Iter 2595 | Time 72.8980(73.6010) | Bit/dim 3.9476(3.9557) | Xent 0.4010(0.4111) | Loss 4.1480(4.1612) | Error 0.1476(0.1485) Steps 790(793.06) | Grad Norm 2.0027(2.7267) | Total Time 14.00(14.00)\n",
      "Iter 2596 | Time 74.3505(73.6235) | Bit/dim 3.9641(3.9559) | Xent 0.3971(0.4106) | Loss 4.1627(4.1612) | Error 0.1422(0.1484) Steps 796(793.15) | Grad Norm 3.4631(2.7488) | Total Time 14.00(14.00)\n",
      "Iter 2597 | Time 73.9341(73.6328) | Bit/dim 3.9545(3.9559) | Xent 0.4097(0.4106) | Loss 4.1593(4.1612) | Error 0.1500(0.1484) Steps 796(793.24) | Grad Norm 4.3918(2.7981) | Total Time 14.00(14.00)\n",
      "Iter 2598 | Time 72.5580(73.6006) | Bit/dim 3.9569(3.9559) | Xent 0.3990(0.4103) | Loss 4.1564(4.1610) | Error 0.1440(0.1483) Steps 796(793.32) | Grad Norm 1.4115(2.7565) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 29.6597, Epoch Time 486.1048(489.7682), Bit/dim 3.9654(best: 3.9651), Xent 1.7945, Loss 4.8627, Error 0.4274(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2599 | Time 71.2924(73.5314) | Bit/dim 3.9659(3.9562) | Xent 0.4043(0.4101) | Loss 4.1681(4.1612) | Error 0.1451(0.1482) Steps 796(793.40) | Grad Norm 5.5452(2.8402) | Total Time 14.00(14.00)\n",
      "Iter 2600 | Time 76.1990(73.6114) | Bit/dim 3.9519(3.9561) | Xent 0.4040(0.4099) | Loss 4.1539(4.1610) | Error 0.1445(0.1481) Steps 796(793.48) | Grad Norm 1.3441(2.7953) | Total Time 14.00(14.00)\n",
      "Iter 2601 | Time 74.6475(73.6425) | Bit/dim 3.9491(3.9559) | Xent 0.3995(0.4096) | Loss 4.1488(4.1606) | Error 0.1462(0.1480) Steps 790(793.37) | Grad Norm 4.1022(2.8345) | Total Time 14.00(14.00)\n",
      "Iter 2602 | Time 72.6009(73.6112) | Bit/dim 3.9440(3.9555) | Xent 0.4118(0.4097) | Loss 4.1499(4.1603) | Error 0.1456(0.1479) Steps 790(793.27) | Grad Norm 1.6218(2.7981) | Total Time 14.00(14.00)\n",
      "Iter 2603 | Time 73.8501(73.6184) | Bit/dim 3.9513(3.9554) | Xent 0.3940(0.4092) | Loss 4.1483(4.1600) | Error 0.1452(0.1479) Steps 784(792.99) | Grad Norm 3.0618(2.8060) | Total Time 14.00(14.00)\n",
      "Iter 2604 | Time 72.9204(73.5974) | Bit/dim 3.9568(3.9554) | Xent 0.4029(0.4090) | Loss 4.1582(4.1599) | Error 0.1441(0.1478) Steps 802(793.26) | Grad Norm 2.3303(2.7918) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 29.2749, Epoch Time 491.2251(489.8119), Bit/dim 3.9644(best: 3.9651), Xent 1.8125, Loss 4.8707, Error 0.4287(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2605 | Time 73.5333(73.5955) | Bit/dim 3.9545(3.9554) | Xent 0.4068(0.4089) | Loss 4.1580(4.1599) | Error 0.1432(0.1476) Steps 790(793.17) | Grad Norm 1.6008(2.7560) | Total Time 14.00(14.00)\n",
      "Iter 2606 | Time 75.2757(73.6459) | Bit/dim 3.9551(3.9554) | Xent 0.3904(0.4084) | Loss 4.1503(4.1596) | Error 0.1405(0.1474) Steps 790(793.07) | Grad Norm 1.3773(2.7147) | Total Time 14.00(14.00)\n",
      "Iter 2607 | Time 73.6533(73.6461) | Bit/dim 3.9542(3.9553) | Xent 0.4030(0.4082) | Loss 4.1557(4.1595) | Error 0.1470(0.1474) Steps 790(792.98) | Grad Norm 1.3309(2.6732) | Total Time 14.00(14.00)\n",
      "Iter 2608 | Time 73.1528(73.6313) | Bit/dim 3.9572(3.9554) | Xent 0.4021(0.4080) | Loss 4.1583(4.1594) | Error 0.1484(0.1474) Steps 796(793.07) | Grad Norm 2.2024(2.6590) | Total Time 14.00(14.00)\n",
      "Iter 2609 | Time 73.1114(73.6157) | Bit/dim 3.9549(3.9554) | Xent 0.3760(0.4071) | Loss 4.1429(4.1589) | Error 0.1354(0.1471) Steps 790(792.98) | Grad Norm 2.1155(2.6427) | Total Time 14.00(14.00)\n",
      "Iter 2610 | Time 75.1401(73.6615) | Bit/dim 3.9447(3.9551) | Xent 0.4127(0.4072) | Loss 4.1510(4.1587) | Error 0.1504(0.1472) Steps 790(792.89) | Grad Norm 3.2358(2.6605) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 29.7301, Epoch Time 489.1556(489.7922), Bit/dim 3.9634(best: 3.9644), Xent 1.8079, Loss 4.8674, Error 0.4292(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2611 | Time 76.0122(73.7320) | Bit/dim 3.9549(3.9551) | Xent 0.3979(0.4070) | Loss 4.1539(4.1585) | Error 0.1435(0.1470) Steps 790(792.80) | Grad Norm 2.0431(2.6420) | Total Time 14.00(14.00)\n",
      "Iter 2612 | Time 75.6932(73.7908) | Bit/dim 3.9447(3.9547) | Xent 0.3827(0.4062) | Loss 4.1360(4.1579) | Error 0.1381(0.1468) Steps 796(792.90) | Grad Norm 2.5796(2.6401) | Total Time 14.00(14.00)\n",
      "Iter 2613 | Time 73.2608(73.7749) | Bit/dim 3.9522(3.9547) | Xent 0.3940(0.4059) | Loss 4.1492(4.1576) | Error 0.1391(0.1466) Steps 784(792.63) | Grad Norm 2.1920(2.6267) | Total Time 14.00(14.00)\n",
      "Iter 2614 | Time 72.7267(73.7435) | Bit/dim 3.9574(3.9548) | Xent 0.3896(0.4054) | Loss 4.1522(4.1574) | Error 0.1384(0.1463) Steps 796(792.73) | Grad Norm 2.2309(2.6148) | Total Time 14.00(14.00)\n",
      "Iter 2615 | Time 73.1703(73.7263) | Bit/dim 3.9518(3.9547) | Xent 0.3950(0.4051) | Loss 4.1493(4.1572) | Error 0.1418(0.1462) Steps 802(793.01) | Grad Norm 2.2472(2.6038) | Total Time 14.00(14.00)\n",
      "Iter 2616 | Time 74.5487(73.7510) | Bit/dim 3.9557(3.9547) | Xent 0.4026(0.4050) | Loss 4.1570(4.1572) | Error 0.1446(0.1461) Steps 796(793.10) | Grad Norm 2.2693(2.5938) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 29.6813, Epoch Time 490.7532(489.8210), Bit/dim 3.9635(best: 3.9634), Xent 1.8259, Loss 4.8764, Error 0.4263(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2617 | Time 73.6080(73.7467) | Bit/dim 3.9440(3.9544) | Xent 0.3893(0.4045) | Loss 4.1387(4.1566) | Error 0.1424(0.1460) Steps 790(793.01) | Grad Norm 2.2394(2.5831) | Total Time 14.00(14.00)\n",
      "Iter 2618 | Time 73.0318(73.7252) | Bit/dim 3.9588(3.9545) | Xent 0.3930(0.4042) | Loss 4.1553(4.1566) | Error 0.1419(0.1459) Steps 802(793.28) | Grad Norm 1.4176(2.5482) | Total Time 14.00(14.00)\n",
      "Iter 2619 | Time 72.5416(73.6897) | Bit/dim 3.9541(3.9545) | Xent 0.4060(0.4042) | Loss 4.1571(4.1566) | Error 0.1482(0.1460) Steps 784(793.00) | Grad Norm 3.9276(2.5895) | Total Time 14.00(14.00)\n",
      "Iter 2620 | Time 71.7754(73.6323) | Bit/dim 3.9561(3.9545) | Xent 0.3863(0.4037) | Loss 4.1493(4.1564) | Error 0.1382(0.1457) Steps 790(792.91) | Grad Norm 2.0540(2.5735) | Total Time 14.00(14.00)\n",
      "Iter 2621 | Time 74.8203(73.6679) | Bit/dim 3.9518(3.9545) | Xent 0.4038(0.4037) | Loss 4.1537(4.1563) | Error 0.1459(0.1457) Steps 790(792.82) | Grad Norm 2.1765(2.5616) | Total Time 14.00(14.00)\n",
      "Iter 2622 | Time 73.5715(73.6650) | Bit/dim 3.9554(3.9545) | Xent 0.3898(0.4033) | Loss 4.1503(4.1561) | Error 0.1386(0.1455) Steps 796(792.92) | Grad Norm 2.9491(2.5732) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 29.5756, Epoch Time 487.6500(489.7559), Bit/dim 3.9638(best: 3.9634), Xent 1.8306, Loss 4.8791, Error 0.4300(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2623 | Time 73.1465(73.6495) | Bit/dim 3.9465(3.9543) | Xent 0.3920(0.4029) | Loss 4.1425(4.1557) | Error 0.1411(0.1454) Steps 784(792.65) | Grad Norm 2.0549(2.5576) | Total Time 14.00(14.00)\n",
      "Iter 2624 | Time 71.5210(73.5856) | Bit/dim 3.9449(3.9540) | Xent 0.3839(0.4024) | Loss 4.1368(4.1552) | Error 0.1388(0.1452) Steps 796(792.75) | Grad Norm 2.0499(2.5424) | Total Time 14.00(14.00)\n",
      "Iter 2625 | Time 75.2156(73.6345) | Bit/dim 3.9532(3.9540) | Xent 0.4026(0.4024) | Loss 4.1545(4.1551) | Error 0.1456(0.1452) Steps 790(792.67) | Grad Norm 1.6021(2.5142) | Total Time 14.00(14.00)\n",
      "Iter 2626 | Time 73.7605(73.6383) | Bit/dim 3.9600(3.9541) | Xent 0.3886(0.4020) | Loss 4.1543(4.1551) | Error 0.1346(0.1449) Steps 802(792.95) | Grad Norm 2.5733(2.5160) | Total Time 14.00(14.00)\n",
      "Iter 2627 | Time 73.2912(73.6279) | Bit/dim 3.9522(3.9541) | Xent 0.3919(0.4017) | Loss 4.1481(4.1549) | Error 0.1419(0.1448) Steps 790(792.86) | Grad Norm 2.2434(2.5078) | Total Time 14.00(14.00)\n",
      "Iter 2628 | Time 73.6499(73.6285) | Bit/dim 3.9574(3.9542) | Xent 0.3842(0.4011) | Loss 4.1495(4.1547) | Error 0.1384(0.1446) Steps 778(792.41) | Grad Norm 1.8103(2.4869) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 29.9936, Epoch Time 486.0690(489.6453), Bit/dim 3.9630(best: 3.9634), Xent 1.8262, Loss 4.8761, Error 0.4249(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2629 | Time 73.2047(73.6158) | Bit/dim 3.9459(3.9539) | Xent 0.3898(0.4008) | Loss 4.1408(4.1543) | Error 0.1426(0.1445) Steps 790(792.34) | Grad Norm 2.7204(2.4939) | Total Time 14.00(14.00)\n",
      "Iter 2630 | Time 73.0708(73.5995) | Bit/dim 3.9553(3.9540) | Xent 0.3778(0.4001) | Loss 4.1442(4.1540) | Error 0.1369(0.1443) Steps 784(792.09) | Grad Norm 2.1150(2.4825) | Total Time 14.00(14.00)\n",
      "Iter 2631 | Time 72.5539(73.5681) | Bit/dim 3.9537(3.9540) | Xent 0.3920(0.3999) | Loss 4.1497(4.1539) | Error 0.1395(0.1442) Steps 784(791.85) | Grad Norm 2.1988(2.4740) | Total Time 14.00(14.00)\n",
      "Iter 2632 | Time 72.1937(73.5269) | Bit/dim 3.9563(3.9540) | Xent 0.3995(0.3998) | Loss 4.1560(4.1540) | Error 0.1415(0.1441) Steps 796(791.97) | Grad Norm 3.0674(2.4918) | Total Time 14.00(14.00)\n",
      "Iter 2633 | Time 76.1485(73.6055) | Bit/dim 3.9391(3.9536) | Xent 0.3888(0.3995) | Loss 4.1335(4.1533) | Error 0.1378(0.1439) Steps 802(792.27) | Grad Norm 1.6338(2.4661) | Total Time 14.00(14.00)\n",
      "Iter 2634 | Time 72.8282(73.5822) | Bit/dim 3.9686(3.9540) | Xent 0.3971(0.3994) | Loss 4.1672(4.1538) | Error 0.1439(0.1439) Steps 790(792.20) | Grad Norm 2.7477(2.4745) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 29.9090, Epoch Time 485.5078(489.5212), Bit/dim 3.9629(best: 3.9630), Xent 1.8343, Loss 4.8801, Error 0.4269(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2635 | Time 76.2793(73.6631) | Bit/dim 3.9497(3.9539) | Xent 0.3856(0.3990) | Loss 4.1425(4.1534) | Error 0.1362(0.1437) Steps 802(792.50) | Grad Norm 2.8273(2.4851) | Total Time 14.00(14.00)\n",
      "Iter 2636 | Time 73.6820(73.6637) | Bit/dim 3.9434(3.9536) | Xent 0.4037(0.3992) | Loss 4.1452(4.1532) | Error 0.1436(0.1437) Steps 796(792.60) | Grad Norm 2.5150(2.4860) | Total Time 14.00(14.00)\n",
      "Iter 2637 | Time 74.9118(73.7011) | Bit/dim 3.9539(3.9536) | Xent 0.3877(0.3988) | Loss 4.1478(4.1530) | Error 0.1402(0.1436) Steps 796(792.71) | Grad Norm 1.9262(2.4692) | Total Time 14.00(14.00)\n",
      "Iter 2638 | Time 75.9360(73.7682) | Bit/dim 3.9655(3.9540) | Xent 0.3928(0.3986) | Loss 4.1619(4.1533) | Error 0.1428(0.1435) Steps 790(792.62) | Grad Norm 2.3478(2.4656) | Total Time 14.00(14.00)\n",
      "Iter 2639 | Time 70.8738(73.6813) | Bit/dim 3.9527(3.9539) | Xent 0.3902(0.3984) | Loss 4.1478(4.1531) | Error 0.1421(0.1435) Steps 790(792.55) | Grad Norm 3.1530(2.4862) | Total Time 14.00(14.00)\n",
      "Iter 2640 | Time 74.8364(73.7160) | Bit/dim 3.9487(3.9538) | Xent 0.3866(0.3980) | Loss 4.1421(4.1528) | Error 0.1421(0.1435) Steps 808(793.01) | Grad Norm 2.7025(2.4927) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 29.4627, Epoch Time 491.8263(489.5903), Bit/dim 3.9633(best: 3.9629), Xent 1.8416, Loss 4.8841, Error 0.4314(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2641 | Time 72.4532(73.6781) | Bit/dim 3.9615(3.9540) | Xent 0.3987(0.3981) | Loss 4.1608(4.1530) | Error 0.1444(0.1435) Steps 790(792.92) | Grad Norm 3.4161(2.5204) | Total Time 14.00(14.00)\n",
      "Iter 2642 | Time 75.5465(73.7342) | Bit/dim 3.9481(3.9538) | Xent 0.3782(0.3975) | Loss 4.1372(4.1525) | Error 0.1376(0.1433) Steps 796(793.01) | Grad Norm 1.2676(2.4828) | Total Time 14.00(14.00)\n",
      "Iter 2643 | Time 71.8622(73.6780) | Bit/dim 3.9409(3.9534) | Xent 0.3958(0.3974) | Loss 4.1388(4.1521) | Error 0.1409(0.1432) Steps 790(792.92) | Grad Norm 3.2650(2.5063) | Total Time 14.00(14.00)\n",
      "Iter 2644 | Time 73.1097(73.6610) | Bit/dim 3.9536(3.9534) | Xent 0.3864(0.3971) | Loss 4.1468(4.1520) | Error 0.1421(0.1432) Steps 796(793.01) | Grad Norm 1.8533(2.4867) | Total Time 14.00(14.00)\n",
      "Iter 2645 | Time 75.2558(73.7088) | Bit/dim 3.9582(3.9536) | Xent 0.3646(0.3961) | Loss 4.1405(4.1516) | Error 0.1339(0.1429) Steps 802(793.28) | Grad Norm 2.3137(2.4815) | Total Time 14.00(14.00)\n",
      "Iter 2646 | Time 74.2103(73.7238) | Bit/dim 3.9460(3.9533) | Xent 0.3912(0.3960) | Loss 4.1416(4.1513) | Error 0.1474(0.1431) Steps 784(793.00) | Grad Norm 1.5889(2.4547) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 29.8442, Epoch Time 487.7999(489.5366), Bit/dim 3.9617(best: 3.9629), Xent 1.8597, Loss 4.8915, Error 0.4306(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2647 | Time 75.0546(73.7638) | Bit/dim 3.9541(3.9534) | Xent 0.3959(0.3960) | Loss 4.1520(4.1513) | Error 0.1399(0.1430) Steps 784(792.73) | Grad Norm 1.8577(2.4368) | Total Time 14.00(14.00)\n",
      "Iter 2648 | Time 75.5921(73.8186) | Bit/dim 3.9549(3.9534) | Xent 0.3797(0.3955) | Loss 4.1447(4.1512) | Error 0.1384(0.1428) Steps 802(793.01) | Grad Norm 2.3982(2.4356) | Total Time 14.00(14.00)\n",
      "Iter 2649 | Time 72.6796(73.7844) | Bit/dim 3.9510(3.9533) | Xent 0.3916(0.3954) | Loss 4.1468(4.1510) | Error 0.1406(0.1428) Steps 790(792.92) | Grad Norm 1.9798(2.4220) | Total Time 14.00(14.00)\n",
      "Iter 2650 | Time 71.1435(73.7052) | Bit/dim 3.9615(3.9536) | Xent 0.3901(0.3952) | Loss 4.1566(4.1512) | Error 0.1361(0.1426) Steps 790(792.83) | Grad Norm 4.2668(2.4773) | Total Time 14.00(14.00)\n",
      "Iter 2651 | Time 73.0236(73.6848) | Bit/dim 3.9337(3.9530) | Xent 0.3852(0.3949) | Loss 4.1263(4.1504) | Error 0.1405(0.1425) Steps 790(792.75) | Grad Norm 1.7245(2.4547) | Total Time 14.00(14.00)\n",
      "Iter 2652 | Time 72.9243(73.6620) | Bit/dim 3.9556(3.9531) | Xent 0.3907(0.3948) | Loss 4.1509(4.1505) | Error 0.1398(0.1424) Steps 796(792.85) | Grad Norm 2.2794(2.4495) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 29.5555, Epoch Time 485.5974(489.4184), Bit/dim 3.9618(best: 3.9617), Xent 1.8365, Loss 4.8800, Error 0.4256(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2653 | Time 74.0410(73.6733) | Bit/dim 3.9466(3.9529) | Xent 0.3959(0.3948) | Loss 4.1445(4.1503) | Error 0.1439(0.1425) Steps 784(792.58) | Grad Norm 2.3743(2.4472) | Total Time 14.00(14.00)\n",
      "Iter 2654 | Time 72.5332(73.6391) | Bit/dim 3.9527(3.9529) | Xent 0.4018(0.3950) | Loss 4.1536(4.1504) | Error 0.1462(0.1426) Steps 790(792.50) | Grad Norm 2.6569(2.4535) | Total Time 14.00(14.00)\n",
      "Iter 2655 | Time 75.6171(73.6985) | Bit/dim 3.9511(3.9528) | Xent 0.3920(0.3949) | Loss 4.1471(4.1503) | Error 0.1421(0.1426) Steps 796(792.61) | Grad Norm 5.3709(2.5410) | Total Time 14.00(14.00)\n",
      "Iter 2656 | Time 73.1730(73.6827) | Bit/dim 3.9420(3.9525) | Xent 0.3884(0.3947) | Loss 4.1362(4.1499) | Error 0.1425(0.1426) Steps 796(792.71) | Grad Norm 2.3777(2.5361) | Total Time 14.00(14.00)\n",
      "Iter 2657 | Time 76.5550(73.7689) | Bit/dim 3.9602(3.9527) | Xent 0.3751(0.3941) | Loss 4.1477(4.1498) | Error 0.1374(0.1424) Steps 784(792.45) | Grad Norm 5.1280(2.6139) | Total Time 14.00(14.00)\n",
      "Iter 2658 | Time 71.5247(73.7015) | Bit/dim 3.9548(3.9528) | Xent 0.4030(0.3944) | Loss 4.1563(4.1500) | Error 0.1474(0.1425) Steps 784(792.20) | Grad Norm 2.6812(2.6159) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 29.9000, Epoch Time 488.9812(489.4053), Bit/dim 3.9613(best: 3.9617), Xent 1.8420, Loss 4.8823, Error 0.4304(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2659 | Time 73.1045(73.6836) | Bit/dim 3.9461(3.9526) | Xent 0.3910(0.3943) | Loss 4.1416(4.1497) | Error 0.1406(0.1425) Steps 802(792.49) | Grad Norm 3.0651(2.6294) | Total Time 14.00(14.00)\n",
      "Iter 2660 | Time 73.6952(73.6840) | Bit/dim 3.9553(3.9527) | Xent 0.3901(0.3942) | Loss 4.1504(4.1498) | Error 0.1414(0.1425) Steps 790(792.42) | Grad Norm 4.4311(2.6834) | Total Time 14.00(14.00)\n",
      "Iter 2661 | Time 74.5773(73.7108) | Bit/dim 3.9444(3.9524) | Xent 0.3988(0.3943) | Loss 4.1439(4.1496) | Error 0.1429(0.1425) Steps 796(792.52) | Grad Norm 3.3637(2.7038) | Total Time 14.00(14.00)\n",
      "Iter 2662 | Time 76.9511(73.8080) | Bit/dim 3.9651(3.9528) | Xent 0.3943(0.3943) | Loss 4.1623(4.1500) | Error 0.1428(0.1425) Steps 802(792.81) | Grad Norm 2.1427(2.6870) | Total Time 14.00(14.00)\n",
      "Iter 2663 | Time 75.2603(73.8516) | Bit/dim 3.9448(3.9526) | Xent 0.3916(0.3942) | Loss 4.1406(4.1497) | Error 0.1412(0.1424) Steps 796(792.90) | Grad Norm 5.0573(2.7581) | Total Time 14.00(14.00)\n",
      "Iter 2664 | Time 72.5762(73.8133) | Bit/dim 3.9498(3.9525) | Xent 0.3907(0.3941) | Loss 4.1452(4.1495) | Error 0.1386(0.1423) Steps 784(792.64) | Grad Norm 4.8046(2.8195) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 29.6183, Epoch Time 491.4268(489.4660), Bit/dim 3.9614(best: 3.9613), Xent 1.8358, Loss 4.8793, Error 0.4278(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2665 | Time 72.8372(73.7840) | Bit/dim 3.9607(3.9527) | Xent 0.3722(0.3935) | Loss 4.1469(4.1495) | Error 0.1326(0.1420) Steps 796(792.74) | Grad Norm 1.5249(2.7807) | Total Time 14.00(14.00)\n",
      "Iter 2666 | Time 73.0170(73.7610) | Bit/dim 3.9535(3.9527) | Xent 0.3832(0.3932) | Loss 4.1451(4.1493) | Error 0.1405(0.1420) Steps 790(792.65) | Grad Norm 4.9760(2.8465) | Total Time 14.00(14.00)\n",
      "Iter 2667 | Time 73.2608(73.7460) | Bit/dim 3.9544(3.9528) | Xent 0.3871(0.3930) | Loss 4.1479(4.1493) | Error 0.1414(0.1420) Steps 796(792.75) | Grad Norm 4.0042(2.8813) | Total Time 14.00(14.00)\n",
      "Iter 2668 | Time 74.9173(73.7811) | Bit/dim 3.9523(3.9528) | Xent 0.3930(0.3930) | Loss 4.1488(4.1493) | Error 0.1429(0.1420) Steps 796(792.85) | Grad Norm 5.6925(2.9656) | Total Time 14.00(14.00)\n",
      "Iter 2669 | Time 72.9204(73.7553) | Bit/dim 3.9476(3.9526) | Xent 0.3726(0.3924) | Loss 4.1339(4.1488) | Error 0.1315(0.1417) Steps 784(792.59) | Grad Norm 1.9757(2.9359) | Total Time 14.00(14.00)\n",
      "Iter 2670 | Time 74.2482(73.7701) | Bit/dim 3.9399(3.9522) | Xent 0.3965(0.3925) | Loss 4.1382(4.1485) | Error 0.1415(0.1417) Steps 802(792.87) | Grad Norm 5.6591(3.0176) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 29.6122, Epoch Time 486.6028(489.3801), Bit/dim 3.9617(best: 3.9613), Xent 1.8501, Loss 4.8868, Error 0.4298(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2671 | Time 72.0013(73.7170) | Bit/dim 3.9520(3.9522) | Xent 0.3894(0.3924) | Loss 4.1467(4.1484) | Error 0.1420(0.1417) Steps 790(792.78) | Grad Norm 2.9391(3.0152) | Total Time 14.00(14.00)\n",
      "Iter 2672 | Time 74.5897(73.7432) | Bit/dim 3.9534(3.9523) | Xent 0.3833(0.3921) | Loss 4.1451(4.1483) | Error 0.1374(0.1416) Steps 790(792.70) | Grad Norm 4.3857(3.0564) | Total Time 14.00(14.00)\n",
      "Iter 2673 | Time 71.8596(73.6867) | Bit/dim 3.9560(3.9524) | Xent 0.3826(0.3918) | Loss 4.1473(4.1483) | Error 0.1375(0.1414) Steps 790(792.62) | Grad Norm 3.4881(3.0693) | Total Time 14.00(14.00)\n",
      "Iter 2674 | Time 71.9023(73.6332) | Bit/dim 3.9457(3.9522) | Xent 0.3668(0.3911) | Loss 4.1291(4.1477) | Error 0.1316(0.1411) Steps 790(792.54) | Grad Norm 1.7299(3.0291) | Total Time 14.00(14.00)\n",
      "Iter 2675 | Time 73.4100(73.6265) | Bit/dim 3.9600(3.9524) | Xent 0.3801(0.3908) | Loss 4.1500(4.1478) | Error 0.1395(0.1411) Steps 796(792.64) | Grad Norm 4.0466(3.0596) | Total Time 14.00(14.00)\n",
      "Iter 2676 | Time 73.5292(73.6236) | Bit/dim 3.9400(3.9520) | Xent 0.3897(0.3907) | Loss 4.1349(4.1474) | Error 0.1381(0.1410) Steps 790(792.56) | Grad Norm 2.5544(3.0445) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 29.3462, Epoch Time 482.5175(489.1742), Bit/dim 3.9615(best: 3.9613), Xent 1.8646, Loss 4.8938, Error 0.4356(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2677 | Time 75.1986(73.6708) | Bit/dim 3.9536(3.9521) | Xent 0.3853(0.3906) | Loss 4.1463(4.1474) | Error 0.1395(0.1410) Steps 796(792.67) | Grad Norm 3.6166(3.0617) | Total Time 14.00(14.00)\n",
      "Iter 2678 | Time 75.1212(73.7143) | Bit/dim 3.9422(3.9518) | Xent 0.3871(0.3905) | Loss 4.1358(4.1470) | Error 0.1432(0.1410) Steps 790(792.59) | Grad Norm 5.0653(3.1218) | Total Time 14.00(14.00)\n",
      "Iter 2679 | Time 73.7367(73.7150) | Bit/dim 3.9574(3.9520) | Xent 0.3813(0.3902) | Loss 4.1480(4.1471) | Error 0.1340(0.1408) Steps 784(792.33) | Grad Norm 2.6234(3.1068) | Total Time 14.00(14.00)\n",
      "Iter 2680 | Time 71.1297(73.6374) | Bit/dim 3.9482(3.9519) | Xent 0.3845(0.3900) | Loss 4.1405(4.1469) | Error 0.1380(0.1407) Steps 784(792.08) | Grad Norm 3.9736(3.1328) | Total Time 14.00(14.00)\n",
      "Iter 2681 | Time 75.6327(73.6973) | Bit/dim 3.9469(3.9517) | Xent 0.3929(0.3901) | Loss 4.1434(4.1468) | Error 0.1396(0.1407) Steps 778(791.66) | Grad Norm 2.3573(3.1096) | Total Time 14.00(14.00)\n",
      "Iter 2682 | Time 74.7354(73.7284) | Bit/dim 3.9557(3.9518) | Xent 0.3702(0.3895) | Loss 4.1408(4.1466) | Error 0.1330(0.1405) Steps 784(791.43) | Grad Norm 4.0170(3.1368) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 29.4096, Epoch Time 490.3393(489.2091), Bit/dim 3.9605(best: 3.9613), Xent 1.8495, Loss 4.8852, Error 0.4258(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2683 | Time 74.6353(73.7556) | Bit/dim 3.9517(3.9518) | Xent 0.3789(0.3892) | Loss 4.1412(4.1464) | Error 0.1344(0.1403) Steps 790(791.38) | Grad Norm 2.8725(3.1288) | Total Time 14.00(14.00)\n",
      "Iter 2684 | Time 73.6475(73.7524) | Bit/dim 3.9399(3.9515) | Xent 0.3678(0.3885) | Loss 4.1238(4.1457) | Error 0.1364(0.1402) Steps 802(791.70) | Grad Norm 3.7774(3.1483) | Total Time 14.00(14.00)\n",
      "Iter 2685 | Time 75.1007(73.7929) | Bit/dim 3.9479(3.9514) | Xent 0.3784(0.3882) | Loss 4.1371(4.1455) | Error 0.1376(0.1401) Steps 796(791.83) | Grad Norm 3.0200(3.1445) | Total Time 14.00(14.00)\n",
      "Iter 2686 | Time 70.9679(73.7081) | Bit/dim 3.9546(3.9515) | Xent 0.3813(0.3880) | Loss 4.1453(4.1455) | Error 0.1359(0.1400) Steps 790(791.78) | Grad Norm 2.2804(3.1185) | Total Time 14.00(14.00)\n",
      "Iter 2687 | Time 74.9365(73.7450) | Bit/dim 3.9559(3.9516) | Xent 0.3939(0.3882) | Loss 4.1529(4.1457) | Error 0.1440(0.1401) Steps 790(791.72) | Grad Norm 2.4034(3.0971) | Total Time 14.00(14.00)\n",
      "Iter 2688 | Time 75.1564(73.7873) | Bit/dim 3.9480(3.9515) | Xent 0.3853(0.3881) | Loss 4.1407(4.1455) | Error 0.1392(0.1401) Steps 778(791.31) | Grad Norm 1.5912(3.0519) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 29.7485, Epoch Time 492.9460(489.3212), Bit/dim 3.9598(best: 3.9605), Xent 1.8644, Loss 4.8920, Error 0.4286(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2689 | Time 72.9199(73.7613) | Bit/dim 3.9619(3.9518) | Xent 0.3788(0.3878) | Loss 4.1512(4.1457) | Error 0.1312(0.1398) Steps 784(791.09) | Grad Norm 2.1842(3.0259) | Total Time 14.00(14.00)\n",
      "Iter 2690 | Time 73.1895(73.7441) | Bit/dim 3.9433(3.9515) | Xent 0.3666(0.3872) | Loss 4.1266(4.1451) | Error 0.1331(0.1396) Steps 796(791.24) | Grad Norm 1.8001(2.9891) | Total Time 14.00(14.00)\n",
      "Iter 2691 | Time 71.2893(73.6705) | Bit/dim 3.9534(3.9516) | Xent 0.3854(0.3872) | Loss 4.1461(4.1452) | Error 0.1409(0.1396) Steps 790(791.20) | Grad Norm 2.9201(2.9870) | Total Time 14.00(14.00)\n",
      "Iter 2692 | Time 73.7871(73.6740) | Bit/dim 3.9520(3.9516) | Xent 0.3829(0.3870) | Loss 4.1434(4.1451) | Error 0.1412(0.1397) Steps 790(791.17) | Grad Norm 3.8836(3.0139) | Total Time 14.00(14.00)\n",
      "Iter 2693 | Time 72.3143(73.6332) | Bit/dim 3.9459(3.9514) | Xent 0.3720(0.3866) | Loss 4.1319(4.1447) | Error 0.1359(0.1396) Steps 796(791.31) | Grad Norm 1.9872(2.9831) | Total Time 14.00(14.00)\n",
      "Iter 2694 | Time 74.3803(73.6556) | Bit/dim 3.9461(3.9513) | Xent 0.3878(0.3866) | Loss 4.1400(4.1446) | Error 0.1402(0.1396) Steps 790(791.27) | Grad Norm 1.7565(2.9463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 29.8473, Epoch Time 483.3721(489.1428), Bit/dim 3.9591(best: 3.9598), Xent 1.8489, Loss 4.8836, Error 0.4263(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2695 | Time 74.7010(73.6870) | Bit/dim 3.9483(3.9512) | Xent 0.3694(0.3861) | Loss 4.1330(4.1442) | Error 0.1330(0.1394) Steps 790(791.23) | Grad Norm 3.5284(2.9638) | Total Time 14.00(14.00)\n",
      "Iter 2696 | Time 76.1304(73.7603) | Bit/dim 3.9422(3.9509) | Xent 0.3894(0.3862) | Loss 4.1369(4.1440) | Error 0.1428(0.1395) Steps 796(791.38) | Grad Norm 2.8170(2.9594) | Total Time 14.00(14.00)\n",
      "Iter 2697 | Time 72.9881(73.7371) | Bit/dim 3.9475(3.9508) | Xent 0.3729(0.3858) | Loss 4.1339(4.1437) | Error 0.1322(0.1393) Steps 790(791.34) | Grad Norm 3.5763(2.9779) | Total Time 14.00(14.00)\n",
      "Iter 2698 | Time 73.0236(73.7157) | Bit/dim 3.9530(3.9509) | Xent 0.3889(0.3859) | Loss 4.1475(4.1438) | Error 0.1420(0.1394) Steps 784(791.12) | Grad Norm 2.6174(2.9671) | Total Time 14.00(14.00)\n",
      "Iter 2699 | Time 79.1724(73.8794) | Bit/dim 3.9551(3.9510) | Xent 0.3651(0.3853) | Loss 4.1376(4.1436) | Error 0.1306(0.1391) Steps 796(791.26) | Grad Norm 2.9454(2.9664) | Total Time 14.00(14.00)\n",
      "Iter 2700 | Time 74.7826(73.9065) | Bit/dim 3.9439(3.9508) | Xent 0.3934(0.3855) | Loss 4.1406(4.1435) | Error 0.1379(0.1391) Steps 784(791.04) | Grad Norm 1.7520(2.9300) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 29.5479, Epoch Time 497.6306(489.3974), Bit/dim 3.9591(best: 3.9591), Xent 1.8780, Loss 4.8981, Error 0.4305(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2701 | Time 77.3374(74.0094) | Bit/dim 3.9486(3.9507) | Xent 0.3750(0.3852) | Loss 4.1361(4.1433) | Error 0.1375(0.1390) Steps 796(791.19) | Grad Norm 2.7533(2.9247) | Total Time 14.00(14.00)\n",
      "Iter 2702 | Time 72.5603(73.9659) | Bit/dim 3.9425(3.9505) | Xent 0.3755(0.3849) | Loss 4.1302(4.1429) | Error 0.1351(0.1389) Steps 790(791.16) | Grad Norm 1.6219(2.8856) | Total Time 14.00(14.00)\n",
      "Iter 2703 | Time 72.3508(73.9175) | Bit/dim 3.9523(3.9505) | Xent 0.3612(0.3842) | Loss 4.1329(4.1426) | Error 0.1302(0.1386) Steps 790(791.12) | Grad Norm 2.0140(2.8595) | Total Time 14.00(14.00)\n",
      "Iter 2704 | Time 74.1532(73.9246) | Bit/dim 3.9558(3.9507) | Xent 0.3589(0.3834) | Loss 4.1352(4.1424) | Error 0.1316(0.1384) Steps 790(791.09) | Grad Norm 2.0411(2.8349) | Total Time 14.00(14.00)\n",
      "Iter 2705 | Time 73.0362(73.8979) | Bit/dim 3.9460(3.9505) | Xent 0.3734(0.3831) | Loss 4.1327(4.1421) | Error 0.1394(0.1385) Steps 790(791.06) | Grad Norm 2.7787(2.8332) | Total Time 14.00(14.00)\n",
      "Iter 2706 | Time 73.4006(73.8830) | Bit/dim 3.9397(3.9502) | Xent 0.3721(0.3828) | Loss 4.1258(4.1416) | Error 0.1352(0.1384) Steps 790(791.02) | Grad Norm 2.5056(2.8234) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 29.8278, Epoch Time 496.4695(489.6096), Bit/dim 3.9600(best: 3.9591), Xent 1.8699, Loss 4.8949, Error 0.4275(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2707 | Time 74.6893(73.9072) | Bit/dim 3.9532(3.9503) | Xent 0.3674(0.3823) | Loss 4.1369(4.1415) | Error 0.1319(0.1382) Steps 802(791.35) | Grad Norm 3.2749(2.8369) | Total Time 14.00(14.00)\n",
      "Iter 2708 | Time 71.5282(73.8358) | Bit/dim 3.9462(3.9502) | Xent 0.3843(0.3824) | Loss 4.1383(4.1414) | Error 0.1382(0.1382) Steps 784(791.13) | Grad Norm 3.0641(2.8438) | Total Time 14.00(14.00)\n",
      "Iter 2709 | Time 72.5937(73.7985) | Bit/dim 3.9479(3.9501) | Xent 0.3719(0.3821) | Loss 4.1339(4.1412) | Error 0.1320(0.1380) Steps 790(791.10) | Grad Norm 1.7489(2.8109) | Total Time 14.00(14.00)\n",
      "Iter 2710 | Time 71.0705(73.7167) | Bit/dim 3.9401(3.9498) | Xent 0.3827(0.3821) | Loss 4.1315(4.1409) | Error 0.1369(0.1379) Steps 796(791.25) | Grad Norm 2.5116(2.8019) | Total Time 14.00(14.00)\n",
      "Iter 2711 | Time 73.6501(73.7147) | Bit/dim 3.9500(3.9498) | Xent 0.3574(0.3814) | Loss 4.1287(4.1405) | Error 0.1310(0.1377) Steps 790(791.21) | Grad Norm 2.0204(2.7785) | Total Time 14.00(14.00)\n",
      "Iter 2712 | Time 74.9629(73.7522) | Bit/dim 3.9562(3.9500) | Xent 0.3684(0.3810) | Loss 4.1404(4.1405) | Error 0.1342(0.1376) Steps 790(791.17) | Grad Norm 2.8220(2.7798) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 29.7531, Epoch Time 487.1163(489.5348), Bit/dim 3.9591(best: 3.9591), Xent 1.8928, Loss 4.9055, Error 0.4279(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2713 | Time 72.9249(73.7273) | Bit/dim 3.9478(3.9499) | Xent 0.3787(0.3809) | Loss 4.1372(4.1404) | Error 0.1342(0.1375) Steps 784(790.96) | Grad Norm 2.0607(2.7582) | Total Time 14.00(14.00)\n",
      "Iter 2714 | Time 73.4020(73.7176) | Bit/dim 3.9509(3.9500) | Xent 0.3734(0.3807) | Loss 4.1376(4.1403) | Error 0.1336(0.1374) Steps 796(791.11) | Grad Norm 2.9297(2.7634) | Total Time 14.00(14.00)\n",
      "Iter 2715 | Time 73.4416(73.7093) | Bit/dim 3.9449(3.9498) | Xent 0.3755(0.3805) | Loss 4.1326(4.1401) | Error 0.1389(0.1375) Steps 790(791.08) | Grad Norm 4.4487(2.8139) | Total Time 14.00(14.00)\n",
      "Iter 2716 | Time 73.1008(73.6910) | Bit/dim 3.9455(3.9497) | Xent 0.3755(0.3804) | Loss 4.1332(4.1399) | Error 0.1338(0.1373) Steps 790(791.04) | Grad Norm 4.4165(2.8620) | Total Time 14.00(14.00)\n",
      "Iter 2717 | Time 71.7080(73.6315) | Bit/dim 3.9492(3.9497) | Xent 0.3624(0.3798) | Loss 4.1304(4.1396) | Error 0.1336(0.1372) Steps 796(791.19) | Grad Norm 1.5723(2.8233) | Total Time 14.00(14.00)\n",
      "Iter 2718 | Time 75.6222(73.6913) | Bit/dim 3.9470(3.9496) | Xent 0.3713(0.3796) | Loss 4.1327(4.1394) | Error 0.1385(0.1373) Steps 790(791.16) | Grad Norm 5.4041(2.9007) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 29.3340, Epoch Time 490.0968(489.5516), Bit/dim 3.9582(best: 3.9591), Xent 1.9049, Loss 4.9107, Error 0.4336(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2719 | Time 75.6202(73.7491) | Bit/dim 3.9409(3.9493) | Xent 0.3755(0.3795) | Loss 4.1287(4.1391) | Error 0.1355(0.1372) Steps 790(791.12) | Grad Norm 3.1223(2.9074) | Total Time 14.00(14.00)\n",
      "Iter 2720 | Time 73.7412(73.7489) | Bit/dim 3.9543(3.9495) | Xent 0.3695(0.3792) | Loss 4.1390(4.1391) | Error 0.1311(0.1370) Steps 784(790.91) | Grad Norm 2.5513(2.8967) | Total Time 14.00(14.00)\n",
      "Iter 2721 | Time 73.4431(73.7397) | Bit/dim 3.9457(3.9494) | Xent 0.3679(0.3788) | Loss 4.1296(4.1388) | Error 0.1344(0.1370) Steps 790(790.88) | Grad Norm 4.0578(2.9315) | Total Time 14.00(14.00)\n",
      "Iter 2722 | Time 72.2379(73.6947) | Bit/dim 3.9560(3.9496) | Xent 0.3713(0.3786) | Loss 4.1417(4.1389) | Error 0.1310(0.1368) Steps 790(790.85) | Grad Norm 4.0086(2.9638) | Total Time 14.00(14.00)\n",
      "Iter 2723 | Time 73.6029(73.6919) | Bit/dim 3.9452(3.9494) | Xent 0.3705(0.3783) | Loss 4.1304(4.1386) | Error 0.1321(0.1366) Steps 790(790.83) | Grad Norm 2.2347(2.9420) | Total Time 14.00(14.00)\n",
      "Iter 2724 | Time 72.3978(73.6531) | Bit/dim 3.9475(3.9494) | Xent 0.3654(0.3780) | Loss 4.1302(4.1384) | Error 0.1295(0.1364) Steps 790(790.80) | Grad Norm 5.1485(3.0082) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 29.6718, Epoch Time 486.2557(489.4528), Bit/dim 3.9592(best: 3.9582), Xent 1.9038, Loss 4.9111, Error 0.4277(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2725 | Time 74.0780(73.6658) | Bit/dim 3.9530(3.9495) | Xent 0.3780(0.3780) | Loss 4.1420(4.1385) | Error 0.1340(0.1364) Steps 790(790.78) | Grad Norm 3.4750(3.0222) | Total Time 14.00(14.00)\n",
      "Iter 2726 | Time 73.8057(73.6700) | Bit/dim 3.9476(3.9494) | Xent 0.3750(0.3779) | Loss 4.1351(4.1384) | Error 0.1341(0.1363) Steps 790(790.76) | Grad Norm 4.1346(3.0555) | Total Time 14.00(14.00)\n",
      "Iter 2727 | Time 74.5253(73.6957) | Bit/dim 3.9455(3.9493) | Xent 0.3692(0.3776) | Loss 4.1301(4.1381) | Error 0.1339(0.1362) Steps 790(790.73) | Grad Norm 3.8506(3.0794) | Total Time 14.00(14.00)\n",
      "Iter 2728 | Time 73.6782(73.6952) | Bit/dim 3.9484(3.9493) | Xent 0.3593(0.3771) | Loss 4.1281(4.1378) | Error 0.1290(0.1360) Steps 796(790.89) | Grad Norm 3.8254(3.1018) | Total Time 14.00(14.00)\n",
      "Iter 2729 | Time 74.2864(73.7129) | Bit/dim 3.9482(3.9493) | Xent 0.3665(0.3767) | Loss 4.1315(4.1376) | Error 0.1305(0.1358) Steps 796(791.04) | Grad Norm 2.3545(3.0794) | Total Time 14.00(14.00)\n",
      "Iter 2730 | Time 73.3913(73.7033) | Bit/dim 3.9360(3.9489) | Xent 0.3868(0.3770) | Loss 4.1294(4.1374) | Error 0.1401(0.1360) Steps 790(791.01) | Grad Norm 3.9893(3.1067) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 29.4238, Epoch Time 493.2535(489.5668), Bit/dim 3.9581(best: 3.9582), Xent 1.9070, Loss 4.9116, Error 0.4292(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2731 | Time 72.2126(73.6585) | Bit/dim 3.9568(3.9491) | Xent 0.3455(0.3761) | Loss 4.1295(4.1371) | Error 0.1192(0.1355) Steps 790(790.98) | Grad Norm 3.5449(3.1198) | Total Time 14.00(14.00)\n",
      "Iter 2732 | Time 74.1340(73.6728) | Bit/dim 3.9515(3.9492) | Xent 0.3730(0.3760) | Loss 4.1380(4.1372) | Error 0.1308(0.1353) Steps 790(790.95) | Grad Norm 1.8910(3.0829) | Total Time 14.00(14.00)\n",
      "Iter 2733 | Time 73.6574(73.6723) | Bit/dim 3.9510(3.9492) | Xent 0.3671(0.3757) | Loss 4.1346(4.1371) | Error 0.1319(0.1352) Steps 790(790.92) | Grad Norm 3.9094(3.1077) | Total Time 14.00(14.00)\n",
      "Iter 2734 | Time 73.4683(73.6662) | Bit/dim 3.9405(3.9490) | Xent 0.3702(0.3756) | Loss 4.1256(4.1367) | Error 0.1335(0.1352) Steps 790(790.90) | Grad Norm 2.7895(3.0982) | Total Time 14.00(14.00)\n",
      "Iter 2735 | Time 74.7809(73.6997) | Bit/dim 3.9356(3.9486) | Xent 0.3777(0.3756) | Loss 4.1244(4.1364) | Error 0.1352(0.1352) Steps 802(791.23) | Grad Norm 3.7233(3.1169) | Total Time 14.00(14.00)\n",
      "Iter 2736 | Time 70.7194(73.6103) | Bit/dim 3.9470(3.9485) | Xent 0.3706(0.3755) | Loss 4.1323(4.1363) | Error 0.1412(0.1353) Steps 796(791.37) | Grad Norm 4.5795(3.1608) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 29.7957, Epoch Time 484.4526(489.4134), Bit/dim 3.9590(best: 3.9581), Xent 1.9094, Loss 4.9137, Error 0.4259(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2737 | Time 76.3639(73.6929) | Bit/dim 3.9454(3.9484) | Xent 0.3660(0.3752) | Loss 4.1284(4.1360) | Error 0.1342(0.1353) Steps 802(791.69) | Grad Norm 6.0585(3.2477) | Total Time 14.00(14.00)\n",
      "Iter 2738 | Time 74.6099(73.7204) | Bit/dim 3.9390(3.9481) | Xent 0.3666(0.3749) | Loss 4.1223(4.1356) | Error 0.1326(0.1352) Steps 784(791.46) | Grad Norm 3.6108(3.2586) | Total Time 14.00(14.00)\n",
      "Iter 2739 | Time 74.2300(73.7357) | Bit/dim 3.9484(3.9481) | Xent 0.3543(0.3743) | Loss 4.1255(4.1353) | Error 0.1259(0.1350) Steps 790(791.42) | Grad Norm 3.6539(3.2705) | Total Time 14.00(14.00)\n",
      "Iter 2740 | Time 73.9376(73.7417) | Bit/dim 3.9402(3.9479) | Xent 0.3711(0.3742) | Loss 4.1258(4.1350) | Error 0.1382(0.1351) Steps 796(791.56) | Grad Norm 4.3015(3.3014) | Total Time 14.00(14.00)\n",
      "Iter 2741 | Time 77.0562(73.8412) | Bit/dim 3.9519(3.9480) | Xent 0.3660(0.3740) | Loss 4.1348(4.1350) | Error 0.1296(0.1349) Steps 790(791.51) | Grad Norm 1.5803(3.2498) | Total Time 14.00(14.00)\n",
      "Iter 2742 | Time 72.8153(73.8104) | Bit/dim 3.9499(3.9481) | Xent 0.3785(0.3741) | Loss 4.1392(4.1351) | Error 0.1380(0.1350) Steps 796(791.64) | Grad Norm 3.9197(3.2699) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 29.5266, Epoch Time 494.1197(489.5545), Bit/dim 3.9569(best: 3.9581), Xent 1.8571, Loss 4.8855, Error 0.4273(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2743 | Time 73.4284(73.7989) | Bit/dim 3.9417(3.9479) | Xent 0.3783(0.3742) | Loss 4.1308(4.1350) | Error 0.1388(0.1351) Steps 796(791.77) | Grad Norm 2.7643(3.2547) | Total Time 14.00(14.00)\n",
      "Iter 2744 | Time 72.7369(73.7671) | Bit/dim 3.9479(3.9479) | Xent 0.3584(0.3738) | Loss 4.1271(4.1348) | Error 0.1325(0.1350) Steps 790(791.72) | Grad Norm 3.8759(3.2734) | Total Time 14.00(14.00)\n",
      "Iter 2745 | Time 72.6396(73.7332) | Bit/dim 3.9429(3.9477) | Xent 0.3623(0.3734) | Loss 4.1241(4.1345) | Error 0.1285(0.1348) Steps 796(791.85) | Grad Norm 2.6915(3.2559) | Total Time 14.00(14.00)\n",
      "Iter 2746 | Time 73.4145(73.7237) | Bit/dim 3.9501(3.9478) | Xent 0.3681(0.3733) | Loss 4.1341(4.1344) | Error 0.1345(0.1348) Steps 790(791.79) | Grad Norm 2.9038(3.2453) | Total Time 14.00(14.00)\n",
      "Iter 2747 | Time 73.0865(73.7046) | Bit/dim 3.9503(3.9479) | Xent 0.3545(0.3727) | Loss 4.1275(4.1342) | Error 0.1261(0.1346) Steps 790(791.74) | Grad Norm 4.1690(3.2730) | Total Time 14.00(14.00)\n",
      "Iter 2748 | Time 73.7662(73.7064) | Bit/dim 3.9477(3.9479) | Xent 0.3584(0.3723) | Loss 4.1269(4.1340) | Error 0.1289(0.1344) Steps 796(791.87) | Grad Norm 3.4205(3.2775) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 29.7560, Epoch Time 484.3161(489.3974), Bit/dim 3.9587(best: 3.9569), Xent 1.9487, Loss 4.9331, Error 0.4341(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2749 | Time 74.8398(73.7404) | Bit/dim 3.9431(3.9477) | Xent 0.3687(0.3722) | Loss 4.1274(4.1338) | Error 0.1281(0.1342) Steps 784(791.63) | Grad Norm 6.0019(3.3592) | Total Time 14.00(14.00)\n",
      "Iter 2750 | Time 70.7692(73.6513) | Bit/dim 3.9539(3.9479) | Xent 0.3458(0.3714) | Loss 4.1268(4.1336) | Error 0.1209(0.1338) Steps 796(791.76) | Grad Norm 4.5896(3.3961) | Total Time 14.00(14.00)\n",
      "Iter 2751 | Time 73.8097(73.6560) | Bit/dim 3.9437(3.9478) | Xent 0.3701(0.3713) | Loss 4.1288(4.1335) | Error 0.1334(0.1338) Steps 796(791.89) | Grad Norm 4.5427(3.4305) | Total Time 14.00(14.00)\n",
      "Iter 2752 | Time 73.3332(73.6463) | Bit/dim 3.9552(3.9480) | Xent 0.3751(0.3715) | Loss 4.1428(4.1337) | Error 0.1372(0.1339) Steps 790(791.83) | Grad Norm 5.6320(3.4966) | Total Time 14.00(14.00)\n",
      "Iter 2753 | Time 72.5955(73.6148) | Bit/dim 3.9429(3.9479) | Xent 0.3629(0.3712) | Loss 4.1243(4.1335) | Error 0.1272(0.1337) Steps 790(791.78) | Grad Norm 2.8883(3.4783) | Total Time 14.00(14.00)\n",
      "Iter 2754 | Time 74.2391(73.6335) | Bit/dim 3.9446(3.9478) | Xent 0.3728(0.3712) | Loss 4.1310(4.1334) | Error 0.1381(0.1338) Steps 790(791.72) | Grad Norm 6.0836(3.5565) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 29.3741, Epoch Time 484.8117(489.2598), Bit/dim 3.9565(best: 3.9569), Xent 1.8699, Loss 4.8915, Error 0.4271(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2755 | Time 72.4623(73.5984) | Bit/dim 3.9459(3.9477) | Xent 0.3602(0.3709) | Loss 4.1260(4.1332) | Error 0.1275(0.1336) Steps 784(791.49) | Grad Norm 2.2266(3.5166) | Total Time 14.00(14.00)\n",
      "Iter 2756 | Time 71.1279(73.5243) | Bit/dim 3.9439(3.9476) | Xent 0.3615(0.3706) | Loss 4.1247(4.1329) | Error 0.1278(0.1335) Steps 790(791.45) | Grad Norm 5.4159(3.5736) | Total Time 14.00(14.00)\n",
      "Iter 2757 | Time 75.4376(73.5817) | Bit/dim 3.9407(3.9474) | Xent 0.3597(0.3703) | Loss 4.1206(4.1325) | Error 0.1298(0.1333) Steps 790(791.40) | Grad Norm 5.9757(3.6456) | Total Time 14.00(14.00)\n",
      "Iter 2758 | Time 73.6014(73.5823) | Bit/dim 3.9425(3.9472) | Xent 0.3625(0.3701) | Loss 4.1237(4.1323) | Error 0.1311(0.1333) Steps 778(791.00) | Grad Norm 2.1261(3.6000) | Total Time 14.00(14.00)\n",
      "Iter 2759 | Time 72.9209(73.5624) | Bit/dim 3.9459(3.9472) | Xent 0.3660(0.3699) | Loss 4.1289(4.1322) | Error 0.1336(0.1333) Steps 784(790.79) | Grad Norm 5.0425(3.6433) | Total Time 14.00(14.00)\n",
      "Iter 2760 | Time 74.4781(73.5899) | Bit/dim 3.9520(3.9473) | Xent 0.3541(0.3695) | Loss 4.1291(4.1321) | Error 0.1285(0.1331) Steps 790(790.77) | Grad Norm 4.8310(3.6789) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 29.3735, Epoch Time 484.8332(489.1270), Bit/dim 3.9569(best: 3.9565), Xent 1.9191, Loss 4.9164, Error 0.4311(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2761 | Time 73.0783(73.5746) | Bit/dim 3.9409(3.9472) | Xent 0.3531(0.3690) | Loss 4.1175(4.1316) | Error 0.1288(0.1330) Steps 790(790.75) | Grad Norm 2.5591(3.6453) | Total Time 14.00(14.00)\n",
      "Iter 2762 | Time 70.9566(73.4960) | Bit/dim 3.9415(3.9470) | Xent 0.3451(0.3683) | Loss 4.1141(4.1311) | Error 0.1215(0.1327) Steps 790(790.72) | Grad Norm 4.8882(3.6826) | Total Time 14.00(14.00)\n",
      "Iter 2763 | Time 73.3404(73.4914) | Bit/dim 3.9474(3.9470) | Xent 0.3541(0.3678) | Loss 4.1244(4.1309) | Error 0.1284(0.1325) Steps 784(790.52) | Grad Norm 2.6777(3.6525) | Total Time 14.00(14.00)\n",
      "Iter 2764 | Time 73.2991(73.4856) | Bit/dim 3.9447(3.9469) | Xent 0.3604(0.3676) | Loss 4.1249(4.1307) | Error 0.1314(0.1325) Steps 790(790.51) | Grad Norm 6.9756(3.7522) | Total Time 14.00(14.00)\n",
      "Iter 2765 | Time 72.3926(73.4528) | Bit/dim 3.9557(3.9472) | Xent 0.3460(0.3670) | Loss 4.1287(4.1307) | Error 0.1244(0.1323) Steps 784(790.31) | Grad Norm 5.8225(3.8143) | Total Time 14.00(14.00)\n",
      "Iter 2766 | Time 73.1350(73.4433) | Bit/dim 3.9389(3.9469) | Xent 0.3685(0.3670) | Loss 4.1232(4.1305) | Error 0.1316(0.1322) Steps 802(790.66) | Grad Norm 4.4326(3.8328) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 29.9737, Epoch Time 481.7133(488.9046), Bit/dim 3.9571(best: 3.9565), Xent 1.9127, Loss 4.9134, Error 0.4283(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2767 | Time 75.1466(73.4944) | Bit/dim 3.9436(3.9468) | Xent 0.3639(0.3669) | Loss 4.1256(4.1303) | Error 0.1264(0.1321) Steps 796(790.82) | Grad Norm 6.3250(3.9076) | Total Time 14.00(14.00)\n",
      "Iter 2768 | Time 72.9630(73.4784) | Bit/dim 3.9534(3.9470) | Xent 0.3468(0.3663) | Loss 4.1268(4.1302) | Error 0.1225(0.1318) Steps 784(790.62) | Grad Norm 1.4641(3.8343) | Total Time 14.00(14.00)\n",
      "Iter 2769 | Time 73.3833(73.4756) | Bit/dim 3.9375(3.9468) | Xent 0.3643(0.3663) | Loss 4.1197(4.1299) | Error 0.1335(0.1318) Steps 784(790.42) | Grad Norm 6.0213(3.8999) | Total Time 14.00(14.00)\n",
      "Iter 2770 | Time 73.7902(73.4850) | Bit/dim 3.9461(3.9467) | Xent 0.3546(0.3659) | Loss 4.1234(4.1297) | Error 0.1234(0.1316) Steps 796(790.59) | Grad Norm 2.6598(3.8627) | Total Time 14.00(14.00)\n",
      "Iter 2771 | Time 72.3511(73.4510) | Bit/dim 3.9372(3.9465) | Xent 0.3818(0.3664) | Loss 4.1281(4.1296) | Error 0.1340(0.1316) Steps 790(790.57) | Grad Norm 4.1206(3.8704) | Total Time 14.00(14.00)\n",
      "Iter 2772 | Time 75.7275(73.5193) | Bit/dim 3.9488(3.9465) | Xent 0.3589(0.3662) | Loss 4.1283(4.1296) | Error 0.1239(0.1314) Steps 778(790.19) | Grad Norm 3.7940(3.8681) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 29.9482, Epoch Time 489.0565(488.9092), Bit/dim 3.9564(best: 3.9565), Xent 1.9326, Loss 4.9227, Error 0.4349(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2773 | Time 71.7742(73.4669) | Bit/dim 3.9393(3.9463) | Xent 0.3519(0.3657) | Loss 4.1153(4.1292) | Error 0.1240(0.1312) Steps 796(790.37) | Grad Norm 2.8098(3.8364) | Total Time 14.00(14.00)\n",
      "Iter 2774 | Time 73.0102(73.4532) | Bit/dim 3.9453(3.9463) | Xent 0.3678(0.3658) | Loss 4.1292(4.1292) | Error 0.1318(0.1312) Steps 796(790.53) | Grad Norm 3.7103(3.8326) | Total Time 14.00(14.00)\n",
      "Iter 2775 | Time 73.2908(73.4484) | Bit/dim 3.9415(3.9461) | Xent 0.3626(0.3657) | Loss 4.1228(4.1290) | Error 0.1256(0.1310) Steps 784(790.34) | Grad Norm 5.4572(3.8813) | Total Time 14.00(14.00)\n",
      "Iter 2776 | Time 73.3185(73.4445) | Bit/dim 3.9426(3.9460) | Xent 0.3475(0.3652) | Loss 4.1163(4.1286) | Error 0.1270(0.1309) Steps 784(790.15) | Grad Norm 4.2999(3.8939) | Total Time 14.00(14.00)\n",
      "Iter 2777 | Time 74.9952(73.4910) | Bit/dim 3.9537(3.9463) | Xent 0.3650(0.3651) | Loss 4.1362(4.1288) | Error 0.1311(0.1309) Steps 790(790.14) | Grad Norm 7.4866(4.0017) | Total Time 14.00(14.00)\n",
      "Iter 2778 | Time 73.2673(73.4843) | Bit/dim 3.9480(3.9463) | Xent 0.3609(0.3650) | Loss 4.1284(4.1288) | Error 0.1342(0.1310) Steps 796(790.32) | Grad Norm 5.2024(4.0377) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 29.4229, Epoch Time 484.8042(488.7860), Bit/dim 3.9562(best: 3.9564), Xent 1.9378, Loss 4.9251, Error 0.4335(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2779 | Time 75.8310(73.5547) | Bit/dim 3.9522(3.9465) | Xent 0.3636(0.3650) | Loss 4.1340(4.1290) | Error 0.1308(0.1310) Steps 778(789.95) | Grad Norm 7.7968(4.1505) | Total Time 14.00(14.00)\n",
      "Iter 2780 | Time 74.0766(73.5703) | Bit/dim 3.9393(3.9463) | Xent 0.3420(0.3643) | Loss 4.1103(4.1284) | Error 0.1211(0.1307) Steps 790(789.95) | Grad Norm 3.9763(4.1453) | Total Time 14.00(14.00)\n",
      "Iter 2781 | Time 73.6632(73.5731) | Bit/dim 3.9446(3.9462) | Xent 0.3591(0.3641) | Loss 4.1241(4.1283) | Error 0.1286(0.1307) Steps 796(790.13) | Grad Norm 6.4769(4.2152) | Total Time 14.00(14.00)\n",
      "Iter 2782 | Time 75.2605(73.6237) | Bit/dim 3.9417(3.9461) | Xent 0.3530(0.3638) | Loss 4.1182(4.1280) | Error 0.1282(0.1306) Steps 796(790.31) | Grad Norm 4.9394(4.2369) | Total Time 14.00(14.00)\n",
      "Iter 2783 | Time 76.4043(73.7072) | Bit/dim 3.9524(3.9463) | Xent 0.3689(0.3640) | Loss 4.1369(4.1282) | Error 0.1335(0.1307) Steps 784(790.12) | Grad Norm 4.8727(4.2560) | Total Time 14.00(14.00)\n",
      "Iter 2784 | Time 75.0101(73.7462) | Bit/dim 3.9480(3.9463) | Xent 0.3536(0.3636) | Loss 4.1248(4.1281) | Error 0.1278(0.1306) Steps 796(790.30) | Grad Norm 5.5022(4.2934) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 29.6065, Epoch Time 495.5219(488.9881), Bit/dim 3.9558(best: 3.9562), Xent 1.9249, Loss 4.9182, Error 0.4306(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2785 | Time 73.8456(73.7492) | Bit/dim 3.9456(3.9463) | Xent 0.3326(0.3627) | Loss 4.1119(4.1277) | Error 0.1185(0.1302) Steps 790(790.29) | Grad Norm 1.9169(4.2221) | Total Time 14.00(14.00)\n",
      "Iter 2786 | Time 74.2690(73.7648) | Bit/dim 3.9351(3.9460) | Xent 0.3614(0.3627) | Loss 4.1159(4.1273) | Error 0.1324(0.1303) Steps 796(790.46) | Grad Norm 4.4302(4.2283) | Total Time 14.00(14.00)\n",
      "Iter 2787 | Time 71.8753(73.7081) | Bit/dim 3.9460(3.9460) | Xent 0.3562(0.3625) | Loss 4.1241(4.1272) | Error 0.1296(0.1303) Steps 784(790.26) | Grad Norm 1.8497(4.1570) | Total Time 14.00(14.00)\n",
      "Iter 2788 | Time 74.8376(73.7420) | Bit/dim 3.9467(3.9460) | Xent 0.3592(0.3624) | Loss 4.1263(4.1272) | Error 0.1290(0.1302) Steps 790(790.26) | Grad Norm 5.0808(4.1847) | Total Time 14.00(14.00)\n",
      "Iter 2789 | Time 73.1709(73.7249) | Bit/dim 3.9508(3.9461) | Xent 0.3656(0.3625) | Loss 4.1336(4.1274) | Error 0.1319(0.1303) Steps 790(790.25) | Grad Norm 5.1231(4.2128) | Total Time 14.00(14.00)\n",
      "Iter 2790 | Time 73.5109(73.7185) | Bit/dim 3.9416(3.9460) | Xent 0.3574(0.3623) | Loss 4.1202(4.1272) | Error 0.1310(0.1303) Steps 796(790.42) | Grad Norm 2.9751(4.1757) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 29.9182, Epoch Time 487.1963(488.9343), Bit/dim 3.9561(best: 3.9558), Xent 1.9558, Loss 4.9340, Error 0.4304(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2791 | Time 72.6366(73.6860) | Bit/dim 3.9415(3.9459) | Xent 0.3710(0.3626) | Loss 4.1270(4.1272) | Error 0.1346(0.1304) Steps 790(790.41) | Grad Norm 4.3657(4.1814) | Total Time 14.00(14.00)\n",
      "Iter 2792 | Time 74.3852(73.7070) | Bit/dim 3.9507(3.9460) | Xent 0.3454(0.3621) | Loss 4.1234(4.1270) | Error 0.1229(0.1302) Steps 790(790.40) | Grad Norm 3.1388(4.1501) | Total Time 14.00(14.00)\n",
      "Iter 2793 | Time 76.7008(73.7968) | Bit/dim 3.9477(3.9461) | Xent 0.3497(0.3617) | Loss 4.1225(4.1269) | Error 0.1296(0.1302) Steps 790(790.38) | Grad Norm 5.2549(4.1833) | Total Time 14.00(14.00)\n",
      "Iter 2794 | Time 74.7618(73.8258) | Bit/dim 3.9404(3.9459) | Xent 0.3518(0.3614) | Loss 4.1163(4.1266) | Error 0.1288(0.1301) Steps 790(790.37) | Grad Norm 2.8832(4.1443) | Total Time 14.00(14.00)\n",
      "Iter 2795 | Time 74.1194(73.8346) | Bit/dim 3.9424(3.9458) | Xent 0.3386(0.3607) | Loss 4.1117(4.1261) | Error 0.1266(0.1300) Steps 784(790.18) | Grad Norm 1.8112(4.0743) | Total Time 14.00(14.00)\n",
      "Iter 2796 | Time 73.9362(73.8376) | Bit/dim 3.9400(3.9456) | Xent 0.3499(0.3604) | Loss 4.1150(4.1258) | Error 0.1284(0.1300) Steps 790(790.18) | Grad Norm 2.7829(4.0355) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 29.7204, Epoch Time 496.0899(489.1490), Bit/dim 3.9550(best: 3.9558), Xent 1.9355, Loss 4.9228, Error 0.4304(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2797 | Time 73.1947(73.8183) | Bit/dim 3.9447(3.9456) | Xent 0.3493(0.3601) | Loss 4.1194(4.1256) | Error 0.1256(0.1299) Steps 796(790.35) | Grad Norm 2.7747(3.9977) | Total Time 14.00(14.00)\n",
      "Iter 2798 | Time 73.2669(73.8018) | Bit/dim 3.9396(3.9454) | Xent 0.3596(0.3600) | Loss 4.1194(4.1254) | Error 0.1301(0.1299) Steps 790(790.34) | Grad Norm 5.0379(4.0289) | Total Time 14.00(14.00)\n",
      "Iter 2799 | Time 72.2617(73.7556) | Bit/dim 3.9369(3.9451) | Xent 0.3717(0.3604) | Loss 4.1227(4.1253) | Error 0.1319(0.1299) Steps 796(790.51) | Grad Norm 4.6675(4.0481) | Total Time 14.00(14.00)\n",
      "Iter 2800 | Time 73.8611(73.7587) | Bit/dim 3.9525(3.9454) | Xent 0.3466(0.3600) | Loss 4.1259(4.1254) | Error 0.1228(0.1297) Steps 784(790.32) | Grad Norm 3.8879(4.0433) | Total Time 14.00(14.00)\n",
      "Iter 2801 | Time 73.6133(73.7544) | Bit/dim 3.9436(3.9453) | Xent 0.3544(0.3598) | Loss 4.1208(4.1252) | Error 0.1314(0.1298) Steps 796(790.49) | Grad Norm 5.2565(4.0797) | Total Time 14.00(14.00)\n",
      "Iter 2802 | Time 74.5888(73.7794) | Bit/dim 3.9481(3.9454) | Xent 0.3380(0.3592) | Loss 4.1171(4.1250) | Error 0.1205(0.1295) Steps 790(790.47) | Grad Norm 2.6711(4.0374) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 29.1159, Epoch Time 485.5407(489.0408), Bit/dim 3.9550(best: 3.9550), Xent 1.9486, Loss 4.9293, Error 0.4325(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2803 | Time 73.0761(73.7583) | Bit/dim 3.9413(3.9453) | Xent 0.3581(0.3591) | Loss 4.1204(4.1248) | Error 0.1269(0.1294) Steps 784(790.28) | Grad Norm 6.0703(4.0984) | Total Time 14.00(14.00)\n",
      "Iter 2804 | Time 72.7483(73.7280) | Bit/dim 3.9424(3.9452) | Xent 0.3553(0.3590) | Loss 4.1201(4.1247) | Error 0.1309(0.1294) Steps 778(789.91) | Grad Norm 2.3719(4.0466) | Total Time 14.00(14.00)\n",
      "Iter 2805 | Time 77.4264(73.8390) | Bit/dim 3.9498(3.9453) | Xent 0.3435(0.3585) | Loss 4.1215(4.1246) | Error 0.1248(0.1293) Steps 796(790.09) | Grad Norm 5.6873(4.0958) | Total Time 14.00(14.00)\n",
      "Iter 2806 | Time 72.4939(73.7986) | Bit/dim 3.9515(3.9455) | Xent 0.3581(0.3585) | Loss 4.1306(4.1248) | Error 0.1296(0.1293) Steps 790(790.09) | Grad Norm 5.4568(4.1366) | Total Time 14.00(14.00)\n",
      "Iter 2807 | Time 77.8019(73.9187) | Bit/dim 3.9382(3.9453) | Xent 0.3436(0.3581) | Loss 4.1100(4.1243) | Error 0.1238(0.1291) Steps 796(790.27) | Grad Norm 5.7557(4.1852) | Total Time 14.00(14.00)\n",
      "Iter 2808 | Time 73.7041(73.9123) | Bit/dim 3.9392(3.9451) | Xent 0.3448(0.3577) | Loss 4.1116(4.1240) | Error 0.1239(0.1290) Steps 790(790.26) | Grad Norm 3.8046(4.1738) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 29.7143, Epoch Time 492.5358(489.1456), Bit/dim 3.9548(best: 3.9550), Xent 1.9403, Loss 4.9250, Error 0.4317(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2809 | Time 72.4401(73.8681) | Bit/dim 3.9374(3.9449) | Xent 0.3503(0.3575) | Loss 4.1125(4.1236) | Error 0.1260(0.1289) Steps 802(790.61) | Grad Norm 3.6397(4.1578) | Total Time 14.00(14.00)\n",
      "Iter 2810 | Time 73.4508(73.8556) | Bit/dim 3.9494(3.9450) | Xent 0.3442(0.3571) | Loss 4.1215(4.1236) | Error 0.1254(0.1288) Steps 802(790.95) | Grad Norm 4.5347(4.1691) | Total Time 14.00(14.00)\n",
      "Iter 2811 | Time 72.7621(73.8228) | Bit/dim 3.9503(3.9452) | Xent 0.3449(0.3567) | Loss 4.1227(4.1235) | Error 0.1258(0.1287) Steps 790(790.92) | Grad Norm 3.3106(4.1433) | Total Time 14.00(14.00)\n",
      "Iter 2812 | Time 71.8772(73.7644) | Bit/dim 3.9438(3.9451) | Xent 0.3538(0.3566) | Loss 4.1207(4.1234) | Error 0.1285(0.1287) Steps 790(790.90) | Grad Norm 3.1588(4.1138) | Total Time 14.00(14.00)\n",
      "Iter 2813 | Time 73.9480(73.7699) | Bit/dim 3.9310(3.9447) | Xent 0.3620(0.3568) | Loss 4.1120(4.1231) | Error 0.1260(0.1286) Steps 790(790.87) | Grad Norm 2.3142(4.0598) | Total Time 14.00(14.00)\n",
      "Iter 2814 | Time 74.8651(73.8028) | Bit/dim 3.9424(3.9446) | Xent 0.3516(0.3566) | Loss 4.1182(4.1230) | Error 0.1286(0.1286) Steps 790(790.84) | Grad Norm 4.1149(4.0615) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 29.5913, Epoch Time 484.5129(489.0066), Bit/dim 3.9541(best: 3.9548), Xent 1.9647, Loss 4.9365, Error 0.4307(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2815 | Time 72.9081(73.7759) | Bit/dim 3.9509(3.9448) | Xent 0.3411(0.3562) | Loss 4.1215(4.1229) | Error 0.1230(0.1284) Steps 802(791.18) | Grad Norm 2.2858(4.0082) | Total Time 14.00(14.00)\n",
      "Iter 2816 | Time 73.2696(73.7607) | Bit/dim 3.9463(3.9449) | Xent 0.3449(0.3558) | Loss 4.1187(4.1228) | Error 0.1225(0.1283) Steps 796(791.32) | Grad Norm 3.7768(4.0013) | Total Time 14.00(14.00)\n",
      "Iter 2817 | Time 75.0675(73.7999) | Bit/dim 3.9418(3.9448) | Xent 0.3407(0.3554) | Loss 4.1122(4.1225) | Error 0.1252(0.1282) Steps 796(791.46) | Grad Norm 3.0455(3.9726) | Total Time 14.00(14.00)\n",
      "Iter 2818 | Time 74.0656(73.8079) | Bit/dim 3.9453(3.9448) | Xent 0.3540(0.3553) | Loss 4.1223(4.1225) | Error 0.1240(0.1281) Steps 796(791.60) | Grad Norm 1.5656(3.9004) | Total Time 14.00(14.00)\n",
      "Iter 2819 | Time 75.8589(73.8694) | Bit/dim 3.9341(3.9445) | Xent 0.3505(0.3552) | Loss 4.1094(4.1221) | Error 0.1265(0.1280) Steps 790(791.55) | Grad Norm 3.4027(3.8854) | Total Time 14.00(14.00)\n",
      "Iter 2820 | Time 71.6889(73.8040) | Bit/dim 3.9409(3.9444) | Xent 0.3482(0.3550) | Loss 4.1150(4.1219) | Error 0.1251(0.1279) Steps 790(791.50) | Grad Norm 3.0873(3.8615) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 29.5787, Epoch Time 487.9127(488.9738), Bit/dim 3.9546(best: 3.9541), Xent 1.9821, Loss 4.9457, Error 0.4320(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2821 | Time 72.6627(73.7698) | Bit/dim 3.9426(3.9443) | Xent 0.3626(0.3552) | Loss 4.1239(4.1219) | Error 0.1295(0.1280) Steps 790(791.46) | Grad Norm 5.4552(3.9093) | Total Time 14.00(14.00)\n",
      "Iter 2822 | Time 74.4735(73.7909) | Bit/dim 3.9464(3.9444) | Xent 0.3400(0.3547) | Loss 4.1164(4.1218) | Error 0.1239(0.1278) Steps 784(791.24) | Grad Norm 2.3964(3.8639) | Total Time 14.00(14.00)\n",
      "Iter 2823 | Time 74.4770(73.8115) | Bit/dim 3.9410(3.9443) | Xent 0.3491(0.3546) | Loss 4.1155(4.1216) | Error 0.1250(0.1278) Steps 802(791.56) | Grad Norm 7.6562(3.9777) | Total Time 14.00(14.00)\n",
      "Iter 2824 | Time 74.2973(73.8261) | Bit/dim 3.9470(3.9444) | Xent 0.3435(0.3542) | Loss 4.1187(4.1215) | Error 0.1259(0.1277) Steps 790(791.51) | Grad Norm 3.2456(3.9557) | Total Time 14.00(14.00)\n",
      "Iter 2825 | Time 74.5304(73.8472) | Bit/dim 3.9407(3.9442) | Xent 0.3535(0.3542) | Loss 4.1175(4.1214) | Error 0.1246(0.1276) Steps 784(791.29) | Grad Norm 9.0821(4.1095) | Total Time 14.00(14.00)\n",
      "Iter 2826 | Time 73.3697(73.8329) | Bit/dim 3.9427(3.9442) | Xent 0.3448(0.3539) | Loss 4.1151(4.1212) | Error 0.1262(0.1276) Steps 802(791.61) | Grad Norm 4.3256(4.1160) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 29.7617, Epoch Time 489.2510(488.9821), Bit/dim 3.9548(best: 3.9541), Xent 1.9698, Loss 4.9397, Error 0.4313(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2827 | Time 75.7684(73.8909) | Bit/dim 3.9477(3.9443) | Xent 0.3465(0.3537) | Loss 4.1209(4.1212) | Error 0.1251(0.1275) Steps 790(791.56) | Grad Norm 4.0750(4.1148) | Total Time 14.00(14.00)\n",
      "Iter 2828 | Time 75.3360(73.9343) | Bit/dim 3.9367(3.9441) | Xent 0.3419(0.3534) | Loss 4.1077(4.1208) | Error 0.1219(0.1273) Steps 790(791.51) | Grad Norm 5.9359(4.1694) | Total Time 14.00(14.00)\n",
      "Iter 2829 | Time 72.2281(73.8831) | Bit/dim 3.9440(3.9441) | Xent 0.3497(0.3533) | Loss 4.1189(4.1207) | Error 0.1244(0.1272) Steps 796(791.65) | Grad Norm 2.6697(4.1244) | Total Time 14.00(14.00)\n",
      "Iter 2830 | Time 73.2516(73.8642) | Bit/dim 3.9444(3.9441) | Xent 0.3287(0.3525) | Loss 4.1087(4.1203) | Error 0.1204(0.1270) Steps 790(791.60) | Grad Norm 4.7933(4.1445) | Total Time 14.00(14.00)\n",
      "Iter 2831 | Time 76.9122(73.9556) | Bit/dim 3.9336(3.9438) | Xent 0.3458(0.3523) | Loss 4.1064(4.1199) | Error 0.1239(0.1269) Steps 778(791.19) | Grad Norm 2.0991(4.0831) | Total Time 14.00(14.00)\n",
      "Iter 2832 | Time 74.2348(73.9640) | Bit/dim 3.9444(3.9438) | Xent 0.3572(0.3525) | Loss 4.1230(4.1200) | Error 0.1269(0.1269) Steps 790(791.15) | Grad Norm 3.4236(4.0633) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 29.4194, Epoch Time 492.6926(489.0934), Bit/dim 3.9529(best: 3.9541), Xent 1.9761, Loss 4.9409, Error 0.4300(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2833 | Time 75.2132(74.0014) | Bit/dim 3.9523(3.9440) | Xent 0.3354(0.3519) | Loss 4.1200(4.1200) | Error 0.1211(0.1268) Steps 802(791.48) | Grad Norm 2.3323(4.0114) | Total Time 14.00(14.00)\n",
      "Iter 2834 | Time 73.3271(73.9812) | Bit/dim 3.9343(3.9437) | Xent 0.3463(0.3518) | Loss 4.1074(4.1196) | Error 0.1255(0.1267) Steps 790(791.44) | Grad Norm 3.8778(4.0074) | Total Time 14.00(14.00)\n",
      "Iter 2835 | Time 73.9892(73.9815) | Bit/dim 3.9407(3.9437) | Xent 0.3364(0.3513) | Loss 4.1089(4.1193) | Error 0.1212(0.1266) Steps 784(791.21) | Grad Norm 2.0211(3.9478) | Total Time 14.00(14.00)\n",
      "Iter 2836 | Time 75.6603(74.0318) | Bit/dim 3.9407(3.9436) | Xent 0.3318(0.3507) | Loss 4.1065(4.1189) | Error 0.1169(0.1263) Steps 802(791.54) | Grad Norm 1.5925(3.8771) | Total Time 14.00(14.00)\n",
      "Iter 2837 | Time 71.4526(73.9544) | Bit/dim 3.9418(3.9435) | Xent 0.3366(0.3503) | Loss 4.1101(4.1187) | Error 0.1246(0.1262) Steps 790(791.49) | Grad Norm 2.5791(3.8382) | Total Time 14.00(14.00)\n",
      "Iter 2838 | Time 76.5270(74.0316) | Bit/dim 3.9413(3.9434) | Xent 0.3376(0.3499) | Loss 4.1101(4.1184) | Error 0.1218(0.1261) Steps 796(791.62) | Grad Norm 2.0450(3.7844) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 29.5065, Epoch Time 491.2602(489.1584), Bit/dim 3.9527(best: 3.9529), Xent 1.9542, Loss 4.9298, Error 0.4283(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2839 | Time 76.8815(74.1171) | Bit/dim 3.9466(3.9435) | Xent 0.3354(0.3495) | Loss 4.1144(4.1183) | Error 0.1176(0.1258) Steps 790(791.58) | Grad Norm 3.4671(3.7749) | Total Time 14.00(14.00)\n",
      "Iter 2840 | Time 72.0922(74.0564) | Bit/dim 3.9390(3.9434) | Xent 0.3491(0.3495) | Loss 4.1135(4.1181) | Error 0.1256(0.1258) Steps 796(791.71) | Grad Norm 3.8422(3.7769) | Total Time 14.00(14.00)\n",
      "Iter 2841 | Time 73.8387(74.0498) | Bit/dim 3.9407(3.9433) | Xent 0.3333(0.3490) | Loss 4.1074(4.1178) | Error 0.1241(0.1258) Steps 784(791.48) | Grad Norm 2.2194(3.7302) | Total Time 14.00(14.00)\n",
      "Iter 2842 | Time 73.2431(74.0256) | Bit/dim 3.9461(3.9434) | Xent 0.3280(0.3484) | Loss 4.1101(4.1176) | Error 0.1236(0.1257) Steps 790(791.43) | Grad Norm 2.9566(3.7070) | Total Time 14.00(14.00)\n",
      "Iter 2843 | Time 74.1391(74.0290) | Bit/dim 3.9318(3.9431) | Xent 0.3413(0.3482) | Loss 4.1025(4.1171) | Error 0.1234(0.1256) Steps 790(791.39) | Grad Norm 2.2620(3.6636) | Total Time 14.00(14.00)\n",
      "Iter 2844 | Time 72.9263(73.9960) | Bit/dim 3.9360(3.9428) | Xent 0.3418(0.3480) | Loss 4.1069(4.1168) | Error 0.1220(0.1255) Steps 808(791.89) | Grad Norm 2.1716(3.6189) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 29.5816, Epoch Time 493.0979(489.2766), Bit/dim 3.9526(best: 3.9527), Xent 1.9674, Loss 4.9363, Error 0.4338(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2845 | Time 73.3853(73.9776) | Bit/dim 3.9349(3.9426) | Xent 0.3365(0.3476) | Loss 4.1032(4.1164) | Error 0.1200(0.1254) Steps 790(791.83) | Grad Norm 4.1092(3.6336) | Total Time 14.00(14.00)\n",
      "Iter 2846 | Time 71.3972(73.9002) | Bit/dim 3.9448(3.9427) | Xent 0.3461(0.3476) | Loss 4.1178(4.1165) | Error 0.1278(0.1254) Steps 796(791.96) | Grad Norm 3.7387(3.6367) | Total Time 14.00(14.00)\n",
      "Iter 2847 | Time 72.8497(73.8687) | Bit/dim 3.9485(3.9428) | Xent 0.3349(0.3472) | Loss 4.1159(4.1164) | Error 0.1229(0.1254) Steps 796(792.08) | Grad Norm 3.1098(3.6209) | Total Time 14.00(14.00)\n",
      "Iter 2848 | Time 73.8049(73.8668) | Bit/dim 3.9334(3.9426) | Xent 0.3542(0.3474) | Loss 4.1105(4.1163) | Error 0.1269(0.1254) Steps 802(792.38) | Grad Norm 4.3330(3.6423) | Total Time 14.00(14.00)\n",
      "Iter 2849 | Time 73.4060(73.8530) | Bit/dim 3.9391(3.9425) | Xent 0.3331(0.3470) | Loss 4.1056(4.1159) | Error 0.1242(0.1254) Steps 796(792.48) | Grad Norm 3.9425(3.6513) | Total Time 14.00(14.00)\n",
      "Iter 2850 | Time 77.2686(73.9554) | Bit/dim 3.9438(3.9425) | Xent 0.3365(0.3467) | Loss 4.1121(4.1158) | Error 0.1209(0.1252) Steps 790(792.41) | Grad Norm 2.1392(3.6059) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 29.5179, Epoch Time 487.1515(489.2129), Bit/dim 3.9520(best: 3.9526), Xent 1.9811, Loss 4.9426, Error 0.4311(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2851 | Time 74.1813(73.9622) | Bit/dim 3.9423(3.9425) | Xent 0.3564(0.3470) | Loss 4.1205(4.1160) | Error 0.1266(0.1253) Steps 796(792.52) | Grad Norm 2.5794(3.5751) | Total Time 14.00(14.00)\n",
      "Iter 2852 | Time 74.0654(73.9653) | Bit/dim 3.9388(3.9424) | Xent 0.3489(0.3470) | Loss 4.1132(4.1159) | Error 0.1261(0.1253) Steps 802(792.80) | Grad Norm 5.4964(3.6328) | Total Time 14.00(14.00)\n",
      "Iter 2853 | Time 71.2767(73.8847) | Bit/dim 3.9509(3.9426) | Xent 0.3486(0.3471) | Loss 4.1252(4.1162) | Error 0.1251(0.1253) Steps 790(792.72) | Grad Norm 5.9425(3.7021) | Total Time 14.00(14.00)\n",
      "Iter 2854 | Time 73.7735(73.8813) | Bit/dim 3.9344(3.9424) | Xent 0.3361(0.3467) | Loss 4.1024(4.1158) | Error 0.1228(0.1252) Steps 790(792.64) | Grad Norm 2.5616(3.6679) | Total Time 14.00(14.00)\n",
      "Iter 2855 | Time 71.7130(73.8163) | Bit/dim 3.9378(3.9423) | Xent 0.3449(0.3467) | Loss 4.1103(4.1156) | Error 0.1258(0.1252) Steps 796(792.74) | Grad Norm 4.5016(3.6929) | Total Time 14.00(14.00)\n",
      "Iter 2856 | Time 73.6295(73.8107) | Bit/dim 3.9403(3.9422) | Xent 0.3433(0.3466) | Loss 4.1120(4.1155) | Error 0.1231(0.1252) Steps 784(792.48) | Grad Norm 3.6131(3.6905) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 29.5922, Epoch Time 483.7725(489.0497), Bit/dim 3.9515(best: 3.9520), Xent 1.9755, Loss 4.9393, Error 0.4320(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2857 | Time 71.4055(73.7385) | Bit/dim 3.9397(3.9421) | Xent 0.3439(0.3465) | Loss 4.1117(4.1154) | Error 0.1248(0.1252) Steps 802(792.76) | Grad Norm 2.3629(3.6506) | Total Time 14.00(14.00)\n",
      "Iter 2858 | Time 73.3081(73.7256) | Bit/dim 3.9380(3.9420) | Xent 0.3390(0.3463) | Loss 4.1076(4.1151) | Error 0.1231(0.1251) Steps 790(792.68) | Grad Norm 4.3317(3.6711) | Total Time 14.00(14.00)\n",
      "Iter 2859 | Time 73.5594(73.7206) | Bit/dim 3.9413(3.9420) | Xent 0.3336(0.3459) | Loss 4.1081(4.1149) | Error 0.1202(0.1250) Steps 790(792.60) | Grad Norm 2.9887(3.6506) | Total Time 14.00(14.00)\n",
      "Iter 2860 | Time 74.8809(73.7554) | Bit/dim 3.9518(3.9423) | Xent 0.3363(0.3456) | Loss 4.1200(4.1151) | Error 0.1262(0.1250) Steps 790(792.52) | Grad Norm 3.1442(3.6354) | Total Time 14.00(14.00)\n",
      "Iter 2861 | Time 73.4770(73.7471) | Bit/dim 3.9388(3.9422) | Xent 0.3229(0.3449) | Loss 4.1003(4.1146) | Error 0.1148(0.1247) Steps 796(792.62) | Grad Norm 1.5425(3.5726) | Total Time 14.00(14.00)\n",
      "Iter 2862 | Time 73.8504(73.7502) | Bit/dim 3.9321(3.9419) | Xent 0.3412(0.3448) | Loss 4.1027(4.1143) | Error 0.1214(0.1246) Steps 796(792.73) | Grad Norm 3.2575(3.5632) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 28.9852, Epoch Time 485.4401(488.9414), Bit/dim 3.9519(best: 3.9515), Xent 1.9905, Loss 4.9472, Error 0.4317(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2863 | Time 74.3669(73.7687) | Bit/dim 3.9277(3.9414) | Xent 0.3290(0.3443) | Loss 4.0922(4.1136) | Error 0.1192(0.1244) Steps 796(792.82) | Grad Norm 2.0949(3.5191) | Total Time 14.00(14.00)\n",
      "Iter 2864 | Time 73.5684(73.7627) | Bit/dim 3.9436(3.9415) | Xent 0.3233(0.3437) | Loss 4.1052(4.1134) | Error 0.1159(0.1242) Steps 790(792.74) | Grad Norm 4.0268(3.5344) | Total Time 14.00(14.00)\n",
      "Iter 2865 | Time 75.0651(73.8017) | Bit/dim 3.9487(3.9417) | Xent 0.3475(0.3438) | Loss 4.1224(4.1136) | Error 0.1215(0.1241) Steps 790(792.66) | Grad Norm 1.6938(3.4791) | Total Time 14.00(14.00)\n",
      "Iter 2866 | Time 70.9712(73.7168) | Bit/dim 3.9444(3.9418) | Xent 0.3300(0.3434) | Loss 4.1094(4.1135) | Error 0.1184(0.1239) Steps 784(792.40) | Grad Norm 4.3207(3.5044) | Total Time 14.00(14.00)\n",
      "Iter 2867 | Time 73.9269(73.7231) | Bit/dim 3.9437(3.9419) | Xent 0.3042(0.3422) | Loss 4.0958(4.1130) | Error 0.1091(0.1235) Steps 790(792.33) | Grad Norm 1.9462(3.4576) | Total Time 14.00(14.00)\n",
      "Iter 2868 | Time 75.3635(73.7723) | Bit/dim 3.9332(3.9416) | Xent 0.3342(0.3420) | Loss 4.1003(4.1126) | Error 0.1216(0.1234) Steps 790(792.26) | Grad Norm 3.4423(3.4572) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 29.5044, Epoch Time 488.6059(488.9313), Bit/dim 3.9511(best: 3.9515), Xent 1.9980, Loss 4.9501, Error 0.4335(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2869 | Time 72.4585(73.7329) | Bit/dim 3.9404(3.9416) | Xent 0.3234(0.3414) | Loss 4.1021(4.1123) | Error 0.1176(0.1232) Steps 796(792.37) | Grad Norm 2.9090(3.4407) | Total Time 14.00(14.00)\n",
      "Iter 2870 | Time 70.9500(73.6494) | Bit/dim 3.9447(3.9417) | Xent 0.3321(0.3412) | Loss 4.1107(4.1122) | Error 0.1222(0.1232) Steps 796(792.48) | Grad Norm 3.5474(3.4439) | Total Time 14.00(14.00)\n",
      "Iter 2871 | Time 73.2140(73.6364) | Bit/dim 3.9365(3.9415) | Xent 0.3245(0.3407) | Loss 4.0987(4.1118) | Error 0.1190(0.1231) Steps 796(792.58) | Grad Norm 2.2859(3.4092) | Total Time 14.00(14.00)\n",
      "Iter 2872 | Time 75.4186(73.6898) | Bit/dim 3.9367(3.9414) | Xent 0.3200(0.3400) | Loss 4.0967(4.1114) | Error 0.1136(0.1228) Steps 778(792.15) | Grad Norm 2.3256(3.3767) | Total Time 14.00(14.00)\n",
      "Iter 2873 | Time 74.6286(73.7180) | Bit/dim 3.9381(3.9413) | Xent 0.3232(0.3395) | Loss 4.0997(4.1110) | Error 0.1186(0.1227) Steps 790(792.08) | Grad Norm 3.7907(3.3891) | Total Time 14.00(14.00)\n",
      "Iter 2874 | Time 75.2493(73.7639) | Bit/dim 3.9388(3.9412) | Xent 0.3425(0.3396) | Loss 4.1100(4.1110) | Error 0.1265(0.1228) Steps 790(792.02) | Grad Norm 5.0840(3.4399) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 29.1076, Epoch Time 486.7117(488.8647), Bit/dim 3.9520(best: 3.9511), Xent 2.0233, Loss 4.9636, Error 0.4299(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2875 | Time 71.5017(73.6961) | Bit/dim 3.9425(3.9412) | Xent 0.3421(0.3397) | Loss 4.1135(4.1111) | Error 0.1220(0.1228) Steps 790(791.96) | Grad Norm 4.6238(3.4755) | Total Time 14.00(14.00)\n",
      "Iter 2876 | Time 74.9330(73.7332) | Bit/dim 3.9450(3.9413) | Xent 0.3456(0.3399) | Loss 4.1178(4.1113) | Error 0.1216(0.1227) Steps 784(791.72) | Grad Norm 2.8720(3.4574) | Total Time 14.00(14.00)\n",
      "Iter 2877 | Time 74.7217(73.7628) | Bit/dim 3.9459(3.9415) | Xent 0.3274(0.3395) | Loss 4.1096(4.1112) | Error 0.1208(0.1227) Steps 796(791.85) | Grad Norm 3.2321(3.4506) | Total Time 14.00(14.00)\n",
      "Iter 2878 | Time 72.4765(73.7242) | Bit/dim 3.9345(3.9413) | Xent 0.3152(0.3388) | Loss 4.0921(4.1106) | Error 0.1164(0.1225) Steps 796(791.97) | Grad Norm 2.2928(3.4159) | Total Time 14.00(14.00)\n",
      "Iter 2879 | Time 73.8648(73.7285) | Bit/dim 3.9264(3.9408) | Xent 0.3376(0.3387) | Loss 4.0952(4.1102) | Error 0.1200(0.1224) Steps 790(791.91) | Grad Norm 2.9767(3.4027) | Total Time 14.00(14.00)\n",
      "Iter 2880 | Time 71.2842(73.6551) | Bit/dim 3.9386(3.9408) | Xent 0.3310(0.3385) | Loss 4.1041(4.1100) | Error 0.1230(0.1224) Steps 790(791.86) | Grad Norm 1.3928(3.3424) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 29.7015, Epoch Time 491.7862(488.9524), Bit/dim 3.9520(best: 3.9511), Xent 2.0026, Loss 4.9533, Error 0.4296(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2881 | Time 72.0513(73.6070) | Bit/dim 3.9473(3.9409) | Xent 0.3258(0.3381) | Loss 4.1102(4.1100) | Error 0.1171(0.1223) Steps 790(791.80) | Grad Norm 3.0654(3.3341) | Total Time 14.00(14.00)\n",
      "Iter 2882 | Time 72.8782(73.5851) | Bit/dim 3.9411(3.9410) | Xent 0.3338(0.3380) | Loss 4.1081(4.1099) | Error 0.1191(0.1222) Steps 790(791.75) | Grad Norm 3.1275(3.3279) | Total Time 14.00(14.00)\n",
      "Iter 2883 | Time 74.6683(73.6176) | Bit/dim 3.9396(3.9409) | Xent 0.3335(0.3379) | Loss 4.1064(4.1098) | Error 0.1238(0.1222) Steps 790(791.69) | Grad Norm 2.3326(3.2980) | Total Time 14.00(14.00)\n",
      "Iter 2884 | Time 75.8488(73.6846) | Bit/dim 3.9339(3.9407) | Xent 0.3350(0.3378) | Loss 4.1014(4.1096) | Error 0.1198(0.1222) Steps 790(791.64) | Grad Norm 2.5769(3.2764) | Total Time 14.00(14.00)\n",
      "Iter 2885 | Time 71.5998(73.6220) | Bit/dim 3.9343(3.9405) | Xent 0.3232(0.3373) | Loss 4.0959(4.1092) | Error 0.1170(0.1220) Steps 790(791.59) | Grad Norm 2.9242(3.2658) | Total Time 14.00(14.00)\n",
      "Iter 2886 | Time 75.0944(73.6662) | Bit/dim 3.9345(3.9403) | Xent 0.3286(0.3371) | Loss 4.0988(4.1089) | Error 0.1200(0.1219) Steps 802(791.91) | Grad Norm 2.6793(3.2482) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 29.3827, Epoch Time 487.4991(488.9088), Bit/dim 3.9510(best: 3.9511), Xent 2.0277, Loss 4.9649, Error 0.4283(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2887 | Time 72.7303(73.6381) | Bit/dim 3.9382(3.9403) | Xent 0.3315(0.3369) | Loss 4.1039(4.1087) | Error 0.1204(0.1219) Steps 790(791.85) | Grad Norm 3.1075(3.2440) | Total Time 14.00(14.00)\n",
      "Iter 2888 | Time 73.3899(73.6307) | Bit/dim 3.9497(3.9405) | Xent 0.3282(0.3366) | Loss 4.1138(4.1089) | Error 0.1180(0.1218) Steps 796(791.97) | Grad Norm 2.3950(3.2185) | Total Time 14.00(14.00)\n",
      "Iter 2889 | Time 73.9668(73.6408) | Bit/dim 3.9366(3.9404) | Xent 0.3319(0.3365) | Loss 4.1025(4.1087) | Error 0.1195(0.1217) Steps 790(791.91) | Grad Norm 4.2205(3.2486) | Total Time 14.00(14.00)\n",
      "Iter 2890 | Time 76.1142(73.7150) | Bit/dim 3.9425(3.9405) | Xent 0.3080(0.3356) | Loss 4.0965(4.1083) | Error 0.1108(0.1214) Steps 802(792.22) | Grad Norm 2.6207(3.2298) | Total Time 14.00(14.00)\n",
      "Iter 2891 | Time 72.8356(73.6886) | Bit/dim 3.9310(3.9402) | Xent 0.3215(0.3352) | Loss 4.0918(4.1078) | Error 0.1144(0.1212) Steps 790(792.15) | Grad Norm 4.2058(3.2590) | Total Time 14.00(14.00)\n",
      "Iter 2892 | Time 73.8771(73.6942) | Bit/dim 3.9356(3.9401) | Xent 0.3356(0.3352) | Loss 4.1034(4.1077) | Error 0.1238(0.1212) Steps 790(792.09) | Grad Norm 1.8892(3.2180) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 29.3547, Epoch Time 487.7554(488.8742), Bit/dim 3.9513(best: 3.9510), Xent 2.0316, Loss 4.9671, Error 0.4326(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2893 | Time 73.5574(73.6901) | Bit/dim 3.9280(3.9397) | Xent 0.3256(0.3349) | Loss 4.0908(4.1072) | Error 0.1171(0.1211) Steps 784(791.84) | Grad Norm 4.5013(3.2565) | Total Time 14.00(14.00)\n",
      "Iter 2894 | Time 75.0753(73.7317) | Bit/dim 3.9336(3.9395) | Xent 0.3337(0.3349) | Loss 4.1004(4.1070) | Error 0.1191(0.1211) Steps 790(791.79) | Grad Norm 3.0407(3.2500) | Total Time 14.00(14.00)\n",
      "Iter 2895 | Time 72.8219(73.7044) | Bit/dim 3.9412(3.9396) | Xent 0.3195(0.3344) | Loss 4.1009(4.1068) | Error 0.1182(0.1210) Steps 790(791.73) | Grad Norm 1.8927(3.2093) | Total Time 14.00(14.00)\n",
      "Iter 2896 | Time 73.0267(73.6841) | Bit/dim 3.9456(3.9398) | Xent 0.3246(0.3341) | Loss 4.1079(4.1068) | Error 0.1185(0.1209) Steps 790(791.68) | Grad Norm 3.6389(3.2222) | Total Time 14.00(14.00)\n",
      "Iter 2897 | Time 76.0628(73.7554) | Bit/dim 3.9469(3.9400) | Xent 0.3099(0.3334) | Loss 4.1018(4.1067) | Error 0.1114(0.1206) Steps 796(791.81) | Grad Norm 2.9683(3.2145) | Total Time 14.00(14.00)\n",
      "Iter 2898 | Time 71.5080(73.6880) | Bit/dim 3.9337(3.9398) | Xent 0.3282(0.3333) | Loss 4.0978(4.1064) | Error 0.1194(0.1206) Steps 790(791.76) | Grad Norm 2.6616(3.1979) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 29.3910, Epoch Time 487.1459(488.8223), Bit/dim 3.9508(best: 3.9510), Xent 2.0696, Loss 4.9856, Error 0.4338(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2899 | Time 74.7914(73.7211) | Bit/dim 3.9307(3.9395) | Xent 0.3295(0.3331) | Loss 4.0954(4.1061) | Error 0.1241(0.1207) Steps 784(791.52) | Grad Norm 5.4772(3.2663) | Total Time 14.00(14.00)\n",
      "Iter 2900 | Time 76.1079(73.7927) | Bit/dim 3.9402(3.9395) | Xent 0.3270(0.3330) | Loss 4.1038(4.1060) | Error 0.1164(0.1206) Steps 796(791.66) | Grad Norm 6.9689(3.3774) | Total Time 14.00(14.00)\n",
      "Iter 2901 | Time 74.5331(73.8149) | Bit/dim 3.9336(3.9394) | Xent 0.3192(0.3326) | Loss 4.0932(4.1056) | Error 0.1175(0.1205) Steps 796(791.79) | Grad Norm 4.7625(3.4190) | Total Time 14.00(14.00)\n",
      "Iter 2902 | Time 75.9905(73.8802) | Bit/dim 3.9454(3.9395) | Xent 0.3355(0.3326) | Loss 4.1132(4.1059) | Error 0.1219(0.1205) Steps 790(791.74) | Grad Norm 6.0107(3.4967) | Total Time 14.00(14.00)\n",
      "Iter 2903 | Time 74.0870(73.8864) | Bit/dim 3.9389(3.9395) | Xent 0.3389(0.3328) | Loss 4.1084(4.1059) | Error 0.1204(0.1205) Steps 796(791.86) | Grad Norm 7.0384(3.6030) | Total Time 14.00(14.00)\n",
      "Iter 2904 | Time 72.4266(73.8426) | Bit/dim 3.9429(3.9396) | Xent 0.3221(0.3325) | Loss 4.1040(4.1059) | Error 0.1144(0.1203) Steps 790(791.81) | Grad Norm 3.2083(3.5911) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 29.3847, Epoch Time 493.0351(488.9487), Bit/dim 3.9509(best: 3.9508), Xent 2.0441, Loss 4.9730, Error 0.4347(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2905 | Time 71.8051(73.7815) | Bit/dim 3.9407(3.9397) | Xent 0.3218(0.3322) | Loss 4.1016(4.1057) | Error 0.1120(0.1201) Steps 790(791.75) | Grad Norm 5.8789(3.6597) | Total Time 14.00(14.00)\n",
      "Iter 2906 | Time 72.2658(73.7360) | Bit/dim 3.9373(3.9396) | Xent 0.3304(0.3321) | Loss 4.1025(4.1056) | Error 0.1209(0.1201) Steps 796(791.88) | Grad Norm 3.7071(3.6612) | Total Time 14.00(14.00)\n",
      "Iter 2907 | Time 73.4626(73.7278) | Bit/dim 3.9429(3.9397) | Xent 0.3178(0.3317) | Loss 4.1018(4.1055) | Error 0.1142(0.1199) Steps 802(792.18) | Grad Norm 2.3457(3.6217) | Total Time 14.00(14.00)\n",
      "Iter 2908 | Time 73.4858(73.7205) | Bit/dim 3.9316(3.9394) | Xent 0.3394(0.3319) | Loss 4.1013(4.1054) | Error 0.1250(0.1201) Steps 790(792.12) | Grad Norm 3.3662(3.6140) | Total Time 14.00(14.00)\n",
      "Iter 2909 | Time 73.2795(73.7073) | Bit/dim 3.9424(3.9395) | Xent 0.3265(0.3318) | Loss 4.1056(4.1054) | Error 0.1189(0.1200) Steps 784(791.87) | Grad Norm 4.4077(3.6378) | Total Time 14.00(14.00)\n",
      "Iter 2910 | Time 73.3783(73.6974) | Bit/dim 3.9297(3.9392) | Xent 0.3389(0.3320) | Loss 4.0991(4.1052) | Error 0.1229(0.1201) Steps 784(791.64) | Grad Norm 2.0215(3.5894) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 29.3408, Epoch Time 482.6580(488.7600), Bit/dim 3.9503(best: 3.9508), Xent 2.0363, Loss 4.9685, Error 0.4344(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2911 | Time 73.0267(73.6773) | Bit/dim 3.9303(3.9390) | Xent 0.3295(0.3319) | Loss 4.0951(4.1049) | Error 0.1196(0.1201) Steps 784(791.41) | Grad Norm 5.4060(3.6439) | Total Time 14.00(14.00)\n",
      "Iter 2912 | Time 74.5075(73.7022) | Bit/dim 3.9345(3.9388) | Xent 0.3148(0.3314) | Loss 4.0919(4.1045) | Error 0.1162(0.1200) Steps 790(791.37) | Grad Norm 1.8409(3.5898) | Total Time 14.00(14.00)\n",
      "Iter 2913 | Time 72.1272(73.6550) | Bit/dim 3.9404(3.9389) | Xent 0.3300(0.3314) | Loss 4.1054(4.1046) | Error 0.1195(0.1200) Steps 796(791.51) | Grad Norm 6.7699(3.6852) | Total Time 14.00(14.00)\n",
      "Iter 2914 | Time 77.1822(73.7608) | Bit/dim 3.9443(3.9390) | Xent 0.3108(0.3307) | Loss 4.0997(4.1044) | Error 0.1169(0.1199) Steps 802(791.82) | Grad Norm 2.8521(3.6602) | Total Time 14.00(14.00)\n",
      "Iter 2915 | Time 74.0684(73.7700) | Bit/dim 3.9293(3.9387) | Xent 0.3302(0.3307) | Loss 4.0944(4.1041) | Error 0.1206(0.1199) Steps 784(791.59) | Grad Norm 6.8404(3.7556) | Total Time 14.00(14.00)\n",
      "Iter 2916 | Time 75.2268(73.8137) | Bit/dim 3.9390(3.9388) | Xent 0.3213(0.3304) | Loss 4.0997(4.1040) | Error 0.1179(0.1198) Steps 802(791.90) | Grad Norm 5.1187(3.7965) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 29.4331, Epoch Time 491.3045(488.8363), Bit/dim 3.9500(best: 3.9503), Xent 2.0625, Loss 4.9812, Error 0.4315(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2917 | Time 73.0763(73.7916) | Bit/dim 3.9376(3.9387) | Xent 0.3216(0.3302) | Loss 4.0984(4.1038) | Error 0.1180(0.1198) Steps 790(791.84) | Grad Norm 3.7968(3.7965) | Total Time 14.00(14.00)\n",
      "Iter 2918 | Time 71.2767(73.7162) | Bit/dim 3.9289(3.9384) | Xent 0.3116(0.3296) | Loss 4.0848(4.1032) | Error 0.1118(0.1195) Steps 784(791.61) | Grad Norm 2.9750(3.7718) | Total Time 14.00(14.00)\n",
      "Iter 2919 | Time 75.6718(73.7748) | Bit/dim 3.9542(3.9389) | Xent 0.3153(0.3292) | Loss 4.1118(4.1035) | Error 0.1148(0.1194) Steps 790(791.56) | Grad Norm 4.4552(3.7923) | Total Time 14.00(14.00)\n",
      "Iter 2920 | Time 73.3600(73.7624) | Bit/dim 3.9362(3.9388) | Xent 0.3024(0.3284) | Loss 4.0874(4.1030) | Error 0.1108(0.1191) Steps 796(791.69) | Grad Norm 3.1308(3.7725) | Total Time 14.00(14.00)\n",
      "Iter 2921 | Time 72.6583(73.7293) | Bit/dim 3.9339(3.9387) | Xent 0.3123(0.3279) | Loss 4.0900(4.1026) | Error 0.1111(0.1189) Steps 790(791.64) | Grad Norm 2.6156(3.7378) | Total Time 14.00(14.00)\n",
      "Iter 2922 | Time 72.8512(73.7029) | Bit/dim 3.9381(3.9387) | Xent 0.3208(0.3277) | Loss 4.0985(4.1025) | Error 0.1154(0.1188) Steps 802(791.95) | Grad Norm 3.9649(3.7446) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 29.6373, Epoch Time 483.9599(488.6900), Bit/dim 3.9500(best: 3.9500), Xent 2.0782, Loss 4.9891, Error 0.4356(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2923 | Time 73.6509(73.7014) | Bit/dim 3.9423(3.9388) | Xent 0.3216(0.3275) | Loss 4.1031(4.1025) | Error 0.1140(0.1187) Steps 790(791.89) | Grad Norm 3.6828(3.7428) | Total Time 14.00(14.00)\n",
      "Iter 2924 | Time 73.4997(73.6953) | Bit/dim 3.9375(3.9387) | Xent 0.3232(0.3274) | Loss 4.0991(4.1024) | Error 0.1185(0.1186) Steps 790(791.84) | Grad Norm 8.6088(3.8887) | Total Time 14.00(14.00)\n",
      "Iter 2925 | Time 71.2480(73.6219) | Bit/dim 3.9293(3.9384) | Xent 0.3185(0.3271) | Loss 4.0886(4.1020) | Error 0.1142(0.1185) Steps 796(791.96) | Grad Norm 3.3848(3.8736) | Total Time 14.00(14.00)\n",
      "Iter 2926 | Time 74.2109(73.6396) | Bit/dim 3.9413(3.9385) | Xent 0.3231(0.3270) | Loss 4.1029(4.1020) | Error 0.1142(0.1184) Steps 808(792.44) | Grad Norm 4.9481(3.9058) | Total Time 14.00(14.00)\n",
      "Iter 2927 | Time 71.5490(73.5768) | Bit/dim 3.9329(3.9384) | Xent 0.3367(0.3273) | Loss 4.1012(4.1020) | Error 0.1201(0.1184) Steps 796(792.55) | Grad Norm 4.1042(3.9118) | Total Time 14.00(14.00)\n",
      "Iter 2928 | Time 74.3763(73.6008) | Bit/dim 3.9415(3.9385) | Xent 0.3298(0.3274) | Loss 4.1064(4.1021) | Error 0.1168(0.1184) Steps 796(792.65) | Grad Norm 3.3646(3.8954) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 29.4689, Epoch Time 483.8205(488.5439), Bit/dim 3.9497(best: 3.9500), Xent 2.0372, Loss 4.9683, Error 0.4315(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2929 | Time 75.0263(73.6436) | Bit/dim 3.9386(3.9385) | Xent 0.3162(0.3270) | Loss 4.0967(4.1020) | Error 0.1131(0.1182) Steps 802(792.93) | Grad Norm 4.7361(3.9206) | Total Time 14.00(14.00)\n",
      "Iter 2930 | Time 74.3155(73.6637) | Bit/dim 3.9323(3.9383) | Xent 0.3068(0.3264) | Loss 4.0858(4.1015) | Error 0.1086(0.1179) Steps 784(792.67) | Grad Norm 5.2652(3.9609) | Total Time 14.00(14.00)\n",
      "Iter 2931 | Time 74.3390(73.6840) | Bit/dim 3.9424(3.9384) | Xent 0.3311(0.3266) | Loss 4.1080(4.1017) | Error 0.1194(0.1180) Steps 790(792.59) | Grad Norm 3.5151(3.9476) | Total Time 14.00(14.00)\n",
      "Iter 2932 | Time 73.8458(73.6889) | Bit/dim 3.9448(3.9386) | Xent 0.3171(0.3263) | Loss 4.1033(4.1017) | Error 0.1165(0.1179) Steps 802(792.87) | Grad Norm 9.3676(4.1102) | Total Time 14.00(14.00)\n",
      "Iter 2933 | Time 75.4091(73.7405) | Bit/dim 3.9361(3.9385) | Xent 0.3248(0.3262) | Loss 4.0985(4.1016) | Error 0.1158(0.1179) Steps 784(792.60) | Grad Norm 6.6406(4.1861) | Total Time 14.00(14.00)\n",
      "Iter 2934 | Time 76.5050(73.8234) | Bit/dim 3.9275(3.9382) | Xent 0.3267(0.3262) | Loss 4.0909(4.1013) | Error 0.1165(0.1178) Steps 784(792.34) | Grad Norm 3.2487(4.1580) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 29.3977, Epoch Time 494.3269(488.7174), Bit/dim 3.9485(best: 3.9497), Xent 2.0464, Loss 4.9717, Error 0.4347(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2935 | Time 72.7923(73.7925) | Bit/dim 3.9381(3.9382) | Xent 0.3211(0.3261) | Loss 4.0986(4.1012) | Error 0.1118(0.1177) Steps 796(792.45) | Grad Norm 6.4136(4.2256) | Total Time 14.00(14.00)\n",
      "Iter 2936 | Time 73.4681(73.7827) | Bit/dim 3.9401(3.9382) | Xent 0.3091(0.3256) | Loss 4.0947(4.1010) | Error 0.1146(0.1176) Steps 790(792.38) | Grad Norm 3.2062(4.1950) | Total Time 14.00(14.00)\n",
      "Iter 2937 | Time 73.0594(73.7610) | Bit/dim 3.9304(3.9380) | Xent 0.3268(0.3256) | Loss 4.0938(4.1008) | Error 0.1209(0.1177) Steps 796(792.49) | Grad Norm 6.6705(4.2693) | Total Time 14.00(14.00)\n",
      "Iter 2938 | Time 74.2326(73.7752) | Bit/dim 3.9304(3.9378) | Xent 0.3287(0.3257) | Loss 4.0948(4.1006) | Error 0.1174(0.1177) Steps 790(792.41) | Grad Norm 6.7238(4.3429) | Total Time 14.00(14.00)\n",
      "Iter 2939 | Time 76.8262(73.8667) | Bit/dim 3.9428(3.9379) | Xent 0.3108(0.3253) | Loss 4.0982(4.1006) | Error 0.1085(0.1174) Steps 778(791.98) | Grad Norm 2.2144(4.2791) | Total Time 14.00(14.00)\n",
      "Iter 2940 | Time 71.0146(73.7811) | Bit/dim 3.9360(3.9379) | Xent 0.3186(0.3251) | Loss 4.0953(4.1004) | Error 0.1139(0.1173) Steps 784(791.74) | Grad Norm 5.7761(4.3240) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 29.4593, Epoch Time 486.4379(488.6490), Bit/dim 3.9484(best: 3.9485), Xent 2.0501, Loss 4.9734, Error 0.4334(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2941 | Time 73.0689(73.7598) | Bit/dim 3.9449(3.9381) | Xent 0.3072(0.3245) | Loss 4.0985(4.1004) | Error 0.1124(0.1171) Steps 790(791.69) | Grad Norm 5.9622(4.3731) | Total Time 14.00(14.00)\n",
      "Iter 2942 | Time 70.9645(73.6759) | Bit/dim 3.9328(3.9379) | Xent 0.3140(0.3242) | Loss 4.0899(4.1000) | Error 0.1139(0.1170) Steps 796(791.82) | Grad Norm 3.7069(4.3532) | Total Time 14.00(14.00)\n",
      "Iter 2943 | Time 73.9966(73.6855) | Bit/dim 3.9425(3.9381) | Xent 0.3120(0.3238) | Loss 4.0985(4.1000) | Error 0.1111(0.1169) Steps 784(791.58) | Grad Norm 7.9515(4.4611) | Total Time 14.00(14.00)\n",
      "Iter 2944 | Time 76.3913(73.7667) | Bit/dim 3.9301(3.9378) | Xent 0.3294(0.3240) | Loss 4.0948(4.0998) | Error 0.1160(0.1168) Steps 790(791.54) | Grad Norm 2.6295(4.4062) | Total Time 14.00(14.00)\n",
      "Iter 2945 | Time 73.4844(73.7582) | Bit/dim 3.9371(3.9378) | Xent 0.3318(0.3242) | Loss 4.1030(4.0999) | Error 0.1199(0.1169) Steps 796(791.67) | Grad Norm 5.8616(4.4498) | Total Time 14.00(14.00)\n",
      "Iter 2946 | Time 76.2136(73.8319) | Bit/dim 3.9322(3.9376) | Xent 0.3112(0.3239) | Loss 4.0878(4.0996) | Error 0.1068(0.1166) Steps 796(791.80) | Grad Norm 2.8287(4.4012) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 29.4328, Epoch Time 489.3392(488.6698), Bit/dim 3.9487(best: 3.9484), Xent 2.0758, Loss 4.9866, Error 0.4366(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2947 | Time 75.9691(73.8960) | Bit/dim 3.9347(3.9376) | Xent 0.2969(0.3230) | Loss 4.0831(4.0991) | Error 0.1046(0.1163) Steps 784(791.57) | Grad Norm 2.1454(4.3335) | Total Time 14.00(14.00)\n",
      "Iter 2948 | Time 74.3925(73.9109) | Bit/dim 3.9347(3.9375) | Xent 0.3177(0.3229) | Loss 4.0936(4.0989) | Error 0.1132(0.1162) Steps 790(791.52) | Grad Norm 3.2309(4.3004) | Total Time 14.00(14.00)\n",
      "Iter 2949 | Time 74.1686(73.9186) | Bit/dim 3.9368(3.9374) | Xent 0.3206(0.3228) | Loss 4.0971(4.0989) | Error 0.1180(0.1162) Steps 790(791.47) | Grad Norm 3.6164(4.2799) | Total Time 14.00(14.00)\n",
      "Iter 2950 | Time 74.7340(73.9431) | Bit/dim 3.9359(3.9374) | Xent 0.3093(0.3224) | Loss 4.0905(4.0986) | Error 0.1115(0.1161) Steps 802(791.79) | Grad Norm 2.2331(4.2185) | Total Time 14.00(14.00)\n",
      "Iter 2951 | Time 75.5069(73.9900) | Bit/dim 3.9274(3.9371) | Xent 0.3161(0.3222) | Loss 4.0854(4.0982) | Error 0.1160(0.1161) Steps 790(791.74) | Grad Norm 3.7218(4.2036) | Total Time 14.00(14.00)\n",
      "Iter 2952 | Time 71.6080(73.9186) | Bit/dim 3.9435(3.9373) | Xent 0.3108(0.3219) | Loss 4.0989(4.0982) | Error 0.1136(0.1160) Steps 790(791.68) | Grad Norm 4.1184(4.2011) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 29.3983, Epoch Time 491.4662(488.7536), Bit/dim 3.9480(best: 3.9484), Xent 2.0595, Loss 4.9777, Error 0.4328(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2953 | Time 73.1690(73.8961) | Bit/dim 3.9339(3.9372) | Xent 0.3037(0.3213) | Loss 4.0857(4.0979) | Error 0.1129(0.1159) Steps 790(791.63) | Grad Norm 3.1433(4.1693) | Total Time 14.00(14.00)\n",
      "Iter 2954 | Time 72.9678(73.8682) | Bit/dim 3.9435(3.9374) | Xent 0.3171(0.3212) | Loss 4.1020(4.0980) | Error 0.1149(0.1159) Steps 790(791.58) | Grad Norm 3.3001(4.1432) | Total Time 14.00(14.00)\n",
      "Iter 2955 | Time 73.6532(73.8618) | Bit/dim 3.9342(3.9373) | Xent 0.3149(0.3210) | Loss 4.0916(4.0978) | Error 0.1104(0.1157) Steps 790(791.54) | Grad Norm 4.2784(4.1473) | Total Time 14.00(14.00)\n",
      "Iter 2956 | Time 73.7517(73.8585) | Bit/dim 3.9314(3.9371) | Xent 0.3156(0.3209) | Loss 4.0892(4.0975) | Error 0.1095(0.1155) Steps 796(791.67) | Grad Norm 2.2252(4.0896) | Total Time 14.00(14.00)\n",
      "Iter 2957 | Time 74.2727(73.8709) | Bit/dim 3.9393(3.9372) | Xent 0.3105(0.3205) | Loss 4.0946(4.0974) | Error 0.1124(0.1154) Steps 784(791.44) | Grad Norm 2.8327(4.0519) | Total Time 14.00(14.00)\n",
      "Iter 2958 | Time 75.3941(73.9166) | Bit/dim 3.9344(3.9371) | Xent 0.3175(0.3205) | Loss 4.0932(4.0973) | Error 0.1116(0.1153) Steps 790(791.40) | Grad Norm 3.8127(4.0447) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 29.5814, Epoch Time 488.4694(488.7451), Bit/dim 3.9475(best: 3.9480), Xent 2.0684, Loss 4.9816, Error 0.4372(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2959 | Time 74.6679(73.9391) | Bit/dim 3.9197(3.9366) | Xent 0.3247(0.3206) | Loss 4.0820(4.0969) | Error 0.1129(0.1152) Steps 802(791.72) | Grad Norm 4.3627(4.0543) | Total Time 14.00(14.00)\n",
      "Iter 2960 | Time 72.3215(73.8906) | Bit/dim 3.9329(3.9365) | Xent 0.3097(0.3203) | Loss 4.0877(4.0966) | Error 0.1111(0.1151) Steps 784(791.48) | Grad Norm 5.1343(4.0867) | Total Time 14.00(14.00)\n",
      "Iter 2961 | Time 74.8593(73.9197) | Bit/dim 3.9475(3.9368) | Xent 0.3085(0.3199) | Loss 4.1017(4.0967) | Error 0.1149(0.1151) Steps 784(791.26) | Grad Norm 9.3543(4.2447) | Total Time 14.00(14.00)\n",
      "Iter 2962 | Time 75.8924(73.9788) | Bit/dim 3.9368(3.9368) | Xent 0.3220(0.3200) | Loss 4.0978(4.0968) | Error 0.1189(0.1152) Steps 796(791.40) | Grad Norm 2.8759(4.2036) | Total Time 14.00(14.00)\n",
      "Iter 2963 | Time 73.7951(73.9733) | Bit/dim 3.9438(3.9370) | Xent 0.3384(0.3205) | Loss 4.1130(4.0973) | Error 0.1251(0.1155) Steps 790(791.36) | Grad Norm 11.4278(4.4204) | Total Time 14.00(14.00)\n",
      "Iter 2964 | Time 76.6949(74.0550) | Bit/dim 3.9287(3.9367) | Xent 0.3176(0.3204) | Loss 4.0875(4.0970) | Error 0.1125(0.1154) Steps 802(791.68) | Grad Norm 8.2069(4.5340) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 29.2761, Epoch Time 493.1156(488.8762), Bit/dim 3.9469(best: 3.9475), Xent 2.0647, Loss 4.9793, Error 0.4332(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2965 | Time 75.1125(74.0867) | Bit/dim 3.9422(3.9369) | Xent 0.3041(0.3199) | Loss 4.0943(4.0969) | Error 0.1084(0.1152) Steps 784(791.45) | Grad Norm 3.5198(4.5035) | Total Time 14.00(14.00)\n",
      "Iter 2966 | Time 74.4957(74.0990) | Bit/dim 3.9338(3.9368) | Xent 0.3366(0.3204) | Loss 4.1021(4.0970) | Error 0.1155(0.1152) Steps 796(791.59) | Grad Norm 8.1096(4.6117) | Total Time 14.00(14.00)\n",
      "Iter 2967 | Time 72.9919(74.0658) | Bit/dim 3.9231(3.9364) | Xent 0.3152(0.3203) | Loss 4.0807(4.0965) | Error 0.1144(0.1152) Steps 796(791.72) | Grad Norm 5.7990(4.6473) | Total Time 14.00(14.00)\n",
      "Iter 2968 | Time 72.3026(74.0129) | Bit/dim 3.9417(3.9366) | Xent 0.3225(0.3203) | Loss 4.1029(4.0967) | Error 0.1171(0.1153) Steps 790(791.67) | Grad Norm 4.5560(4.6446) | Total Time 14.00(14.00)\n",
      "Iter 2969 | Time 74.4924(74.0272) | Bit/dim 3.9344(3.9365) | Xent 0.3298(0.3206) | Loss 4.0993(4.0968) | Error 0.1191(0.1154) Steps 790(791.62) | Grad Norm 6.8836(4.7118) | Total Time 14.00(14.00)\n",
      "Iter 2970 | Time 74.7508(74.0490) | Bit/dim 3.9348(3.9365) | Xent 0.3136(0.3204) | Loss 4.0916(4.0967) | Error 0.1139(0.1153) Steps 796(791.75) | Grad Norm 5.5003(4.7354) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 29.5210, Epoch Time 489.3040(488.8891), Bit/dim 3.9466(best: 3.9469), Xent 2.0773, Loss 4.9853, Error 0.4329(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2971 | Time 71.3151(73.9669) | Bit/dim 3.9195(3.9359) | Xent 0.3202(0.3204) | Loss 4.0796(4.0961) | Error 0.1102(0.1152) Steps 796(791.88) | Grad Norm 3.8155(4.7078) | Total Time 14.00(14.00)\n",
      "Iter 2972 | Time 75.6587(74.0177) | Bit/dim 3.9402(3.9361) | Xent 0.3125(0.3202) | Loss 4.0965(4.0962) | Error 0.1110(0.1151) Steps 796(792.00) | Grad Norm 6.3555(4.7573) | Total Time 14.00(14.00)\n",
      "Iter 2973 | Time 74.2006(74.0232) | Bit/dim 3.9344(3.9360) | Xent 0.3141(0.3200) | Loss 4.0914(4.0960) | Error 0.1104(0.1149) Steps 796(792.12) | Grad Norm 3.3271(4.7144) | Total Time 14.00(14.00)\n",
      "Iter 2974 | Time 75.9203(74.0801) | Bit/dim 3.9371(3.9361) | Xent 0.3064(0.3196) | Loss 4.0903(4.0958) | Error 0.1088(0.1147) Steps 784(791.88) | Grad Norm 7.2012(4.7890) | Total Time 14.00(14.00)\n",
      "Iter 2975 | Time 74.1818(74.0831) | Bit/dim 3.9341(3.9360) | Xent 0.3021(0.3191) | Loss 4.0851(4.0955) | Error 0.1061(0.1145) Steps 778(791.46) | Grad Norm 2.4577(4.7190) | Total Time 14.00(14.00)\n",
      "Iter 2976 | Time 73.7327(74.0726) | Bit/dim 3.9381(3.9361) | Xent 0.3202(0.3191) | Loss 4.0982(4.0956) | Error 0.1126(0.1144) Steps 790(791.42) | Grad Norm 4.7152(4.7189) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 29.5904, Epoch Time 490.3002(488.9314), Bit/dim 3.9477(best: 3.9466), Xent 2.0935, Loss 4.9944, Error 0.4326(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2977 | Time 72.5329(74.0264) | Bit/dim 3.9330(3.9360) | Xent 0.3136(0.3189) | Loss 4.0898(4.0954) | Error 0.1108(0.1143) Steps 790(791.37) | Grad Norm 4.8623(4.7232) | Total Time 14.00(14.00)\n",
      "Iter 2978 | Time 71.7263(73.9574) | Bit/dim 3.9428(3.9362) | Xent 0.3097(0.3187) | Loss 4.0977(4.0955) | Error 0.1152(0.1143) Steps 784(791.15) | Grad Norm 2.3074(4.6507) | Total Time 14.00(14.00)\n",
      "Iter 2979 | Time 72.2849(73.9073) | Bit/dim 3.9224(3.9358) | Xent 0.3167(0.3186) | Loss 4.0808(4.0951) | Error 0.1131(0.1143) Steps 796(791.30) | Grad Norm 3.5623(4.6181) | Total Time 14.00(14.00)\n",
      "Iter 2980 | Time 75.8480(73.9655) | Bit/dim 3.9444(3.9360) | Xent 0.3104(0.3184) | Loss 4.0996(4.0952) | Error 0.1130(0.1143) Steps 790(791.26) | Grad Norm 3.7305(4.5915) | Total Time 14.00(14.00)\n",
      "Iter 2981 | Time 74.1487(73.9710) | Bit/dim 3.9410(3.9362) | Xent 0.2952(0.3177) | Loss 4.0886(4.0950) | Error 0.1115(0.1142) Steps 790(791.22) | Grad Norm 2.1510(4.5182) | Total Time 14.00(14.00)\n",
      "Iter 2982 | Time 74.4294(73.9847) | Bit/dim 3.9237(3.9358) | Xent 0.3202(0.3177) | Loss 4.0838(4.0947) | Error 0.1152(0.1142) Steps 790(791.18) | Grad Norm 2.3515(4.4532) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 29.5234, Epoch Time 486.4202(488.8561), Bit/dim 3.9476(best: 3.9466), Xent 2.1014, Loss 4.9983, Error 0.4292(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2983 | Time 73.9025(73.9823) | Bit/dim 3.9252(3.9355) | Xent 0.3094(0.3175) | Loss 4.0799(4.0942) | Error 0.1114(0.1141) Steps 796(791.33) | Grad Norm 3.2008(4.4157) | Total Time 14.00(14.00)\n",
      "Iter 2984 | Time 75.9458(74.0412) | Bit/dim 3.9464(3.9358) | Xent 0.2989(0.3169) | Loss 4.0958(4.0943) | Error 0.1086(0.1140) Steps 790(791.29) | Grad Norm 1.9591(4.3420) | Total Time 14.00(14.00)\n",
      "Iter 2985 | Time 73.4224(74.0226) | Bit/dim 3.9275(3.9356) | Xent 0.3119(0.3168) | Loss 4.0835(4.0939) | Error 0.1116(0.1139) Steps 790(791.25) | Grad Norm 3.1222(4.3054) | Total Time 14.00(14.00)\n",
      "Iter 2986 | Time 74.2361(74.0290) | Bit/dim 3.9404(3.9357) | Xent 0.3024(0.3163) | Loss 4.0916(4.0939) | Error 0.1095(0.1138) Steps 790(791.21) | Grad Norm 3.0510(4.2677) | Total Time 14.00(14.00)\n",
      "Iter 2987 | Time 73.5838(74.0157) | Bit/dim 3.9413(3.9359) | Xent 0.2890(0.3155) | Loss 4.0858(4.0936) | Error 0.1028(0.1134) Steps 784(791.00) | Grad Norm 2.8796(4.2261) | Total Time 14.00(14.00)\n",
      "Iter 2988 | Time 73.5164(74.0007) | Bit/dim 3.9233(3.9355) | Xent 0.3036(0.3152) | Loss 4.0750(4.0931) | Error 0.1116(0.1134) Steps 790(790.97) | Grad Norm 5.5733(4.2665) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 29.4510, Epoch Time 489.7057(488.8816), Bit/dim 3.9459(best: 3.9466), Xent 2.0874, Loss 4.9896, Error 0.4322(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2989 | Time 71.9901(73.9404) | Bit/dim 3.9277(3.9353) | Xent 0.3041(0.3148) | Loss 4.0797(4.0927) | Error 0.1082(0.1132) Steps 796(791.12) | Grad Norm 2.7253(4.2203) | Total Time 14.00(14.00)\n",
      "Iter 2990 | Time 74.3197(73.9517) | Bit/dim 3.9296(3.9351) | Xent 0.3032(0.3145) | Loss 4.0812(4.0923) | Error 0.1104(0.1131) Steps 796(791.26) | Grad Norm 5.2285(4.2505) | Total Time 14.00(14.00)\n",
      "Iter 2991 | Time 73.8929(73.9500) | Bit/dim 3.9322(3.9350) | Xent 0.3030(0.3141) | Loss 4.0837(4.0921) | Error 0.1070(0.1129) Steps 784(791.05) | Grad Norm 4.8485(4.2685) | Total Time 14.00(14.00)\n",
      "Iter 2992 | Time 75.4028(73.9936) | Bit/dim 3.9275(3.9348) | Xent 0.3143(0.3141) | Loss 4.0846(4.0918) | Error 0.1135(0.1130) Steps 796(791.19) | Grad Norm 1.9736(4.1996) | Total Time 14.00(14.00)\n",
      "Iter 2993 | Time 73.9757(73.9930) | Bit/dim 3.9441(3.9351) | Xent 0.2839(0.3132) | Loss 4.0861(4.0917) | Error 0.1051(0.1127) Steps 796(791.34) | Grad Norm 4.0137(4.1940) | Total Time 14.00(14.00)\n",
      "Iter 2994 | Time 72.9863(73.9628) | Bit/dim 3.9408(3.9352) | Xent 0.3014(0.3129) | Loss 4.0915(4.0917) | Error 0.1060(0.1125) Steps 784(791.12) | Grad Norm 4.0435(4.1895) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 29.1983, Epoch Time 487.4284(488.8380), Bit/dim 3.9470(best: 3.9459), Xent 2.1199, Loss 5.0069, Error 0.4355(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2995 | Time 76.0676(74.0260) | Bit/dim 3.9302(3.9351) | Xent 0.2962(0.3124) | Loss 4.0783(4.0913) | Error 0.1072(0.1124) Steps 796(791.26) | Grad Norm 2.7653(4.1468) | Total Time 14.00(14.00)\n",
      "Iter 2996 | Time 73.4578(74.0089) | Bit/dim 3.9348(3.9351) | Xent 0.3089(0.3123) | Loss 4.0893(4.0912) | Error 0.1098(0.1123) Steps 796(791.41) | Grad Norm 3.2704(4.1205) | Total Time 14.00(14.00)\n",
      "Iter 2997 | Time 76.3264(74.0784) | Bit/dim 3.9295(3.9349) | Xent 0.3059(0.3121) | Loss 4.0824(4.0909) | Error 0.1120(0.1123) Steps 796(791.54) | Grad Norm 4.9493(4.1454) | Total Time 14.00(14.00)\n",
      "Iter 2998 | Time 74.4765(74.0904) | Bit/dim 3.9402(3.9351) | Xent 0.3039(0.3118) | Loss 4.0921(4.0910) | Error 0.1088(0.1122) Steps 796(791.68) | Grad Norm 2.1720(4.0862) | Total Time 14.00(14.00)\n",
      "Iter 2999 | Time 77.3534(74.1883) | Bit/dim 3.9357(3.9351) | Xent 0.3077(0.3117) | Loss 4.0896(4.0909) | Error 0.1074(0.1120) Steps 802(791.99) | Grad Norm 5.5675(4.1306) | Total Time 14.00(14.00)\n",
      "Iter 3000 | Time 74.5233(74.1983) | Bit/dim 3.9280(3.9349) | Xent 0.2956(0.3112) | Loss 4.0758(4.0905) | Error 0.1061(0.1119) Steps 802(792.29) | Grad Norm 3.3385(4.1069) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 29.3136, Epoch Time 497.1251(489.0866), Bit/dim 3.9456(best: 3.9459), Xent 2.0907, Loss 4.9909, Error 0.4318(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3001 | Time 72.9415(74.1606) | Bit/dim 3.9214(3.9345) | Xent 0.3158(0.3114) | Loss 4.0794(4.0901) | Error 0.1134(0.1119) Steps 784(792.04) | Grad Norm 3.5686(4.0907) | Total Time 14.00(14.00)\n",
      "Iter 3002 | Time 73.4649(74.1397) | Bit/dim 3.9340(3.9344) | Xent 0.2961(0.3109) | Loss 4.0821(4.0899) | Error 0.1062(0.1117) Steps 790(791.98) | Grad Norm 3.6353(4.0770) | Total Time 14.00(14.00)\n",
      "Iter 3003 | Time 73.6646(74.1255) | Bit/dim 3.9429(3.9347) | Xent 0.3059(0.3108) | Loss 4.0959(4.0901) | Error 0.1085(0.1116) Steps 784(791.74) | Grad Norm 2.1927(4.0205) | Total Time 14.00(14.00)\n",
      "Iter 3004 | Time 72.9850(74.0913) | Bit/dim 3.9424(3.9349) | Xent 0.3106(0.3108) | Loss 4.0977(4.0903) | Error 0.1124(0.1117) Steps 790(791.69) | Grad Norm 4.4065(4.0321) | Total Time 14.00(14.00)\n",
      "Iter 3005 | Time 75.6262(74.1373) | Bit/dim 3.9328(3.9349) | Xent 0.2938(0.3102) | Loss 4.0797(4.0900) | Error 0.1076(0.1115) Steps 790(791.64) | Grad Norm 2.2031(3.9772) | Total Time 14.00(14.00)\n",
      "Iter 3006 | Time 73.9641(74.1321) | Bit/dim 3.9226(3.9345) | Xent 0.3114(0.3103) | Loss 4.0783(4.0896) | Error 0.1111(0.1115) Steps 796(791.77) | Grad Norm 6.8993(4.0649) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0501 | Time 29.3209, Epoch Time 487.6345(489.0430), Bit/dim 3.9460(best: 3.9456), Xent 2.1140, Loss 5.0030, Error 0.4350(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3007 | Time 72.3498(74.0787) | Bit/dim 3.9318(3.9344) | Xent 0.3136(0.3104) | Loss 4.0886(4.0896) | Error 0.1111(0.1115) Steps 790(791.71) | Grad Norm 5.2645(4.1009) | Total Time 14.00(14.00)\n",
      "Iter 3008 | Time 72.6771(74.0366) | Bit/dim 3.9298(3.9343) | Xent 0.3045(0.3102) | Loss 4.0821(4.0894) | Error 0.1089(0.1114) Steps 790(791.66) | Grad Norm 4.4619(4.1117) | Total Time 14.00(14.00)\n",
      "Iter 3009 | Time 72.6042(73.9936) | Bit/dim 3.9364(3.9343) | Xent 0.3044(0.3100) | Loss 4.0886(4.0894) | Error 0.1066(0.1113) Steps 784(791.43) | Grad Norm 5.3981(4.1503) | Total Time 14.00(14.00)\n",
      "Iter 3010 | Time 74.5145(74.0093) | Bit/dim 3.9275(3.9341) | Xent 0.3111(0.3101) | Loss 4.0830(4.0892) | Error 0.1130(0.1113) Steps 796(791.57) | Grad Norm 7.7481(4.2582) | Total Time 14.00(14.00)\n",
      "Iter 3011 | Time 75.2180(74.0455) | Bit/dim 3.9342(3.9341) | Xent 0.2990(0.3097) | Loss 4.0837(4.0890) | Error 0.1050(0.1111) Steps 796(791.70) | Grad Norm 1.4910(4.1752) | Total Time 14.00(14.00)\n",
      "Iter 3012 | Time 74.6173(74.0627) | Bit/dim 3.9404(3.9343) | Xent 0.3128(0.3098) | Loss 4.0969(4.0892) | Error 0.1121(0.1112) Steps 778(791.29) | Grad Norm 7.3835(4.2715) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0502 | Time 29.8584, Epoch Time 487.3188(488.9913), Bit/dim 3.9454(best: 3.9456), Xent 2.1480, Loss 5.0194, Error 0.4338(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3013 | Time 71.6208(73.9894) | Bit/dim 3.9372(3.9344) | Xent 0.2969(0.3094) | Loss 4.0857(4.0891) | Error 0.1074(0.1111) Steps 802(791.61) | Grad Norm 5.3813(4.3048) | Total Time 14.00(14.00)\n",
      "Iter 3014 | Time 76.7242(74.0715) | Bit/dim 3.9423(3.9347) | Xent 0.3035(0.3093) | Loss 4.0941(4.0893) | Error 0.1059(0.1109) Steps 796(791.74) | Grad Norm 3.0659(4.2676) | Total Time 14.00(14.00)\n",
      "Iter 3015 | Time 73.6103(74.0576) | Bit/dim 3.9255(3.9344) | Xent 0.3029(0.3091) | Loss 4.0770(4.0889) | Error 0.1082(0.1108) Steps 790(791.69) | Grad Norm 5.0607(4.2914) | Total Time 14.00(14.00)\n",
      "Iter 3016 | Time 75.1032(74.0890) | Bit/dim 3.9365(3.9344) | Xent 0.3023(0.3089) | Loss 4.0877(4.0889) | Error 0.1116(0.1109) Steps 790(791.64) | Grad Norm 3.9197(4.2802) | Total Time 14.00(14.00)\n",
      "Iter 3017 | Time 71.3648(74.0073) | Bit/dim 3.9407(3.9346) | Xent 0.2908(0.3083) | Loss 4.0861(4.0888) | Error 0.1044(0.1107) Steps 790(791.59) | Grad Norm 3.5802(4.2592) | Total Time 14.00(14.00)\n",
      "Iter 3018 | Time 71.7535(73.9397) | Bit/dim 3.9089(3.9339) | Xent 0.3175(0.3086) | Loss 4.0677(4.0882) | Error 0.1141(0.1108) Steps 796(791.72) | Grad Norm 5.4624(4.2953) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0503 | Time 29.3045, Epoch Time 484.9597(488.8703), Bit/dim 3.9443(best: 3.9454), Xent 2.1148, Loss 5.0017, Error 0.4318(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3019 | Time 74.5488(73.9579) | Bit/dim 3.9171(3.9334) | Xent 0.2913(0.3081) | Loss 4.0628(4.0874) | Error 0.1042(0.1106) Steps 790(791.67) | Grad Norm 1.7192(4.2180) | Total Time 14.00(14.00)\n",
      "Iter 3020 | Time 72.9517(73.9277) | Bit/dim 3.9266(3.9332) | Xent 0.3157(0.3083) | Loss 4.0844(4.0873) | Error 0.1111(0.1106) Steps 790(791.62) | Grad Norm 4.5049(4.2266) | Total Time 14.00(14.00)\n",
      "Iter 3021 | Time 72.9516(73.8985) | Bit/dim 3.9356(3.9332) | Xent 0.2910(0.3078) | Loss 4.0811(4.0871) | Error 0.1050(0.1104) Steps 796(791.75) | Grad Norm 2.3384(4.1700) | Total Time 14.00(14.00)\n",
      "Iter 3022 | Time 73.3239(73.8812) | Bit/dim 3.9497(3.9337) | Xent 0.3051(0.3077) | Loss 4.1022(4.0876) | Error 0.1105(0.1104) Steps 790(791.70) | Grad Norm 3.4744(4.1491) | Total Time 14.00(14.00)\n",
      "Iter 3023 | Time 75.1477(73.9192) | Bit/dim 3.9245(3.9334) | Xent 0.3071(0.3077) | Loss 4.0780(4.0873) | Error 0.1100(0.1104) Steps 796(791.83) | Grad Norm 3.3863(4.1262) | Total Time 14.00(14.00)\n",
      "Iter 3024 | Time 73.9663(73.9206) | Bit/dim 3.9340(3.9335) | Xent 0.2880(0.3071) | Loss 4.0781(4.0870) | Error 0.0992(0.1101) Steps 796(791.96) | Grad Norm 3.4272(4.1053) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0504 | Time 29.3079, Epoch Time 487.7149(488.8357), Bit/dim 3.9446(best: 3.9443), Xent 2.0942, Loss 4.9917, Error 0.4335(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3025 | Time 73.6738(73.9132) | Bit/dim 3.9319(3.9334) | Xent 0.2964(0.3068) | Loss 4.0801(4.0868) | Error 0.1040(0.1099) Steps 796(792.08) | Grad Norm 4.7961(4.1260) | Total Time 14.00(14.00)\n",
      "Iter 3026 | Time 75.3652(73.9568) | Bit/dim 3.9240(3.9331) | Xent 0.2939(0.3064) | Loss 4.0709(4.0863) | Error 0.1028(0.1097) Steps 796(792.19) | Grad Norm 2.2898(4.0709) | Total Time 14.00(14.00)\n",
      "Iter 3027 | Time 75.0257(73.9889) | Bit/dim 3.9352(3.9332) | Xent 0.3086(0.3065) | Loss 4.0895(4.0864) | Error 0.1088(0.1096) Steps 796(792.31) | Grad Norm 3.4828(4.0533) | Total Time 14.00(14.00)\n",
      "Iter 3028 | Time 76.1796(74.0546) | Bit/dim 3.9254(3.9330) | Xent 0.2847(0.3058) | Loss 4.0678(4.0859) | Error 0.1011(0.1094) Steps 790(792.24) | Grad Norm 2.5109(4.0070) | Total Time 14.00(14.00)\n",
      "Iter 3029 | Time 74.1437(74.0572) | Bit/dim 3.9277(3.9328) | Xent 0.3005(0.3056) | Loss 4.0779(4.0856) | Error 0.1101(0.1094) Steps 796(792.35) | Grad Norm 4.0015(4.0068) | Total Time 14.00(14.00)\n",
      "Iter 3030 | Time 73.3781(74.0369) | Bit/dim 3.9441(3.9331) | Xent 0.3129(0.3059) | Loss 4.1006(4.0861) | Error 0.1162(0.1096) Steps 796(792.46) | Grad Norm 5.4175(4.0492) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0505 | Time 29.3612, Epoch Time 492.9088(488.9579), Bit/dim 3.9439(best: 3.9443), Xent 2.1236, Loss 5.0057, Error 0.4334(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3031 | Time 71.8926(73.9725) | Bit/dim 3.9227(3.9328) | Xent 0.2947(0.3055) | Loss 4.0700(4.0856) | Error 0.1096(0.1096) Steps 790(792.39) | Grad Norm 3.4978(4.0326) | Total Time 14.00(14.00)\n",
      "Iter 3032 | Time 73.9504(73.9719) | Bit/dim 3.9228(3.9325) | Xent 0.2980(0.3053) | Loss 4.0718(4.0852) | Error 0.1071(0.1095) Steps 790(792.32) | Grad Norm 2.5668(3.9886) | Total Time 14.00(14.00)\n",
      "Iter 3033 | Time 74.0138(73.9731) | Bit/dim 3.9261(3.9323) | Xent 0.2877(0.3048) | Loss 4.0699(4.0847) | Error 0.1044(0.1094) Steps 796(792.43) | Grad Norm 4.1469(3.9934) | Total Time 14.00(14.00)\n",
      "Iter 3034 | Time 73.8325(73.9689) | Bit/dim 3.9471(3.9328) | Xent 0.2934(0.3044) | Loss 4.0938(4.0850) | Error 0.1068(0.1093) Steps 796(792.53) | Grad Norm 3.6567(3.9833) | Total Time 14.00(14.00)\n",
      "Iter 3035 | Time 74.5992(73.9878) | Bit/dim 3.9467(3.9332) | Xent 0.3005(0.3043) | Loss 4.0970(4.0854) | Error 0.1065(0.1092) Steps 802(792.82) | Grad Norm 3.9324(3.9818) | Total Time 14.00(14.00)\n",
      "Iter 3036 | Time 74.6857(74.0088) | Bit/dim 3.9257(3.9330) | Xent 0.3047(0.3043) | Loss 4.0781(4.0851) | Error 0.1108(0.1093) Steps 796(792.91) | Grad Norm 3.1589(3.9571) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0506 | Time 28.9100, Epoch Time 487.3780(488.9105), Bit/dim 3.9440(best: 3.9439), Xent 2.0959, Loss 4.9919, Error 0.4377(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3037 | Time 74.9873(74.0381) | Bit/dim 3.9351(3.9330) | Xent 0.3027(0.3043) | Loss 4.0864(4.0852) | Error 0.1068(0.1092) Steps 796(793.01) | Grad Norm 3.7062(3.9495) | Total Time 14.00(14.00)\n",
      "Iter 3038 | Time 75.8476(74.0924) | Bit/dim 3.9256(3.9328) | Xent 0.3028(0.3042) | Loss 4.0770(4.0849) | Error 0.1088(0.1092) Steps 796(793.10) | Grad Norm 2.4080(3.9033) | Total Time 14.00(14.00)\n",
      "Iter 3039 | Time 75.7496(74.1421) | Bit/dim 3.9251(3.9326) | Xent 0.3172(0.3046) | Loss 4.0837(4.0849) | Error 0.1115(0.1093) Steps 802(793.36) | Grad Norm 3.7331(3.8982) | Total Time 14.00(14.00)\n",
      "Iter 3040 | Time 73.8938(74.1347) | Bit/dim 3.9349(3.9326) | Xent 0.2861(0.3041) | Loss 4.0779(4.0847) | Error 0.1044(0.1091) Steps 784(793.08) | Grad Norm 5.2453(3.9386) | Total Time 14.00(14.00)\n",
      "Iter 3041 | Time 76.7813(74.2141) | Bit/dim 3.9297(3.9326) | Xent 0.2966(0.3038) | Loss 4.0780(4.0845) | Error 0.1042(0.1090) Steps 790(792.99) | Grad Norm 3.6853(3.9310) | Total Time 14.00(14.00)\n",
      "Iter 3042 | Time 76.7572(74.2904) | Bit/dim 3.9371(3.9327) | Xent 0.3100(0.3040) | Loss 4.0921(4.0847) | Error 0.1086(0.1089) Steps 790(792.90) | Grad Norm 2.7334(3.8951) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0507 | Time 28.9344, Epoch Time 498.4878(489.1978), Bit/dim 3.9441(best: 3.9439), Xent 2.1544, Loss 5.0213, Error 0.4326(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3043 | Time 72.9137(74.2491) | Bit/dim 3.9240(3.9324) | Xent 0.2947(0.3037) | Loss 4.0714(4.0843) | Error 0.1084(0.1089) Steps 790(792.81) | Grad Norm 4.6739(3.9184) | Total Time 14.00(14.00)\n",
      "Iter 3044 | Time 73.8028(74.2357) | Bit/dim 3.9342(3.9325) | Xent 0.3048(0.3038) | Loss 4.0866(4.0844) | Error 0.1085(0.1089) Steps 808(793.27) | Grad Norm 4.3632(3.9318) | Total Time 14.00(14.00)\n",
      "Iter 3045 | Time 73.9412(74.2268) | Bit/dim 3.9326(3.9325) | Xent 0.2827(0.3031) | Loss 4.0739(4.0841) | Error 0.1011(0.1087) Steps 790(793.17) | Grad Norm 3.2426(3.9111) | Total Time 14.00(14.00)\n",
      "Iter 3046 | Time 74.2955(74.2289) | Bit/dim 3.9338(3.9325) | Xent 0.3115(0.3034) | Loss 4.0895(4.0842) | Error 0.1151(0.1089) Steps 790(793.08) | Grad Norm 5.5479(3.9602) | Total Time 14.00(14.00)\n",
      "Iter 3047 | Time 75.0633(74.2539) | Bit/dim 3.9287(3.9324) | Xent 0.2957(0.3032) | Loss 4.0766(4.0840) | Error 0.1078(0.1088) Steps 790(792.98) | Grad Norm 3.8653(3.9574) | Total Time 14.00(14.00)\n",
      "Iter 3048 | Time 76.6372(74.3254) | Bit/dim 3.9283(3.9323) | Xent 0.2951(0.3029) | Loss 4.0758(4.0838) | Error 0.1040(0.1087) Steps 802(793.25) | Grad Norm 3.9312(3.9566) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0508 | Time 29.5834, Epoch Time 492.0286(489.2827), Bit/dim 3.9439(best: 3.9439), Xent 2.1473, Loss 5.0175, Error 0.4315(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3049 | Time 73.4866(74.3003) | Bit/dim 3.9326(3.9323) | Xent 0.2877(0.3025) | Loss 4.0765(4.0835) | Error 0.1026(0.1085) Steps 808(793.70) | Grad Norm 4.8568(3.9836) | Total Time 14.00(14.00)\n",
      "Iter 3050 | Time 72.9741(74.2605) | Bit/dim 3.9273(3.9322) | Xent 0.2980(0.3023) | Loss 4.0763(4.0833) | Error 0.1059(0.1084) Steps 796(793.76) | Grad Norm 3.8123(3.9785) | Total Time 14.00(14.00)\n",
      "Iter 3051 | Time 74.0376(74.2538) | Bit/dim 3.9238(3.9319) | Xent 0.2957(0.3021) | Loss 4.0717(4.0830) | Error 0.1050(0.1083) Steps 790(793.65) | Grad Norm 5.1442(4.0134) | Total Time 14.00(14.00)\n",
      "Iter 3052 | Time 74.8668(74.2722) | Bit/dim 3.9341(3.9320) | Xent 0.3070(0.3023) | Loss 4.0876(4.0831) | Error 0.1100(0.1084) Steps 796(793.72) | Grad Norm 5.8438(4.0683) | Total Time 14.00(14.00)\n",
      "Iter 3053 | Time 75.2160(74.3005) | Bit/dim 3.9287(3.9319) | Xent 0.2914(0.3020) | Loss 4.0744(4.0828) | Error 0.1012(0.1082) Steps 784(793.43) | Grad Norm 3.4097(4.0486) | Total Time 14.00(14.00)\n",
      "Iter 3054 | Time 72.6742(74.2517) | Bit/dim 3.9397(3.9321) | Xent 0.2967(0.3018) | Loss 4.0880(4.0830) | Error 0.1039(0.1080) Steps 790(793.33) | Grad Norm 4.9377(4.0752) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0509 | Time 29.3572, Epoch Time 488.2836(489.2527), Bit/dim 3.9434(best: 3.9439), Xent 2.1686, Loss 5.0277, Error 0.4350(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3055 | Time 72.5147(74.1996) | Bit/dim 3.9287(3.9320) | Xent 0.2873(0.3014) | Loss 4.0723(4.0827) | Error 0.1001(0.1078) Steps 796(793.41) | Grad Norm 6.3763(4.1443) | Total Time 14.00(14.00)\n",
      "Iter 3056 | Time 71.1981(74.1096) | Bit/dim 3.9252(3.9318) | Xent 0.2973(0.3012) | Loss 4.0738(4.0824) | Error 0.1069(0.1078) Steps 796(793.49) | Grad Norm 3.7188(4.1315) | Total Time 14.00(14.00)\n",
      "Iter 3057 | Time 73.5009(74.0913) | Bit/dim 3.9232(3.9315) | Xent 0.2870(0.3008) | Loss 4.0667(4.0819) | Error 0.1038(0.1077) Steps 784(793.20) | Grad Norm 5.1096(4.1609) | Total Time 14.00(14.00)\n",
      "Iter 3058 | Time 77.9843(74.2081) | Bit/dim 3.9410(3.9318) | Xent 0.2917(0.3005) | Loss 4.0869(4.0821) | Error 0.1085(0.1077) Steps 790(793.11) | Grad Norm 4.1439(4.1603) | Total Time 14.00(14.00)\n",
      "Iter 3059 | Time 75.6578(74.2516) | Bit/dim 3.9379(3.9320) | Xent 0.2891(0.3002) | Loss 4.0824(4.0821) | Error 0.1040(0.1076) Steps 790(793.01) | Grad Norm 1.8769(4.0918) | Total Time 14.00(14.00)\n",
      "Iter 3060 | Time 73.7350(74.2361) | Bit/dim 3.9239(3.9318) | Xent 0.2984(0.3001) | Loss 4.0731(4.0818) | Error 0.1050(0.1075) Steps 796(793.10) | Grad Norm 4.9352(4.1171) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0510 | Time 29.1277, Epoch Time 489.2024(489.2512), Bit/dim 3.9435(best: 3.9434), Xent 2.1774, Loss 5.0323, Error 0.4361(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3061 | Time 76.0645(74.2909) | Bit/dim 3.9286(3.9317) | Xent 0.2917(0.2999) | Loss 4.0745(4.0816) | Error 0.1082(0.1075) Steps 790(793.01) | Grad Norm 3.6323(4.1026) | Total Time 14.00(14.00)\n",
      "Iter 3062 | Time 74.7136(74.3036) | Bit/dim 3.9225(3.9314) | Xent 0.3058(0.3001) | Loss 4.0754(4.0814) | Error 0.1071(0.1075) Steps 796(793.10) | Grad Norm 4.2806(4.1079) | Total Time 14.00(14.00)\n",
      "Iter 3063 | Time 74.2293(74.3014) | Bit/dim 3.9358(3.9315) | Xent 0.2932(0.2999) | Loss 4.0824(4.0815) | Error 0.1028(0.1074) Steps 790(793.01) | Grad Norm 7.3226(4.2044) | Total Time 14.00(14.00)\n",
      "Iter 3064 | Time 73.7018(74.2834) | Bit/dim 3.9300(3.9315) | Xent 0.3022(0.2999) | Loss 4.0811(4.0814) | Error 0.1072(0.1074) Steps 802(793.28) | Grad Norm 6.0098(4.2585) | Total Time 14.00(14.00)\n",
      "Iter 3065 | Time 76.4800(74.3493) | Bit/dim 3.9365(3.9316) | Xent 0.2984(0.2999) | Loss 4.0857(4.0816) | Error 0.1044(0.1073) Steps 802(793.54) | Grad Norm 4.3515(4.2613) | Total Time 14.00(14.00)\n",
      "Iter 3066 | Time 73.7958(74.3327) | Bit/dim 3.9294(3.9316) | Xent 0.3133(0.3003) | Loss 4.0860(4.0817) | Error 0.1162(0.1075) Steps 784(793.25) | Grad Norm 9.3590(4.4143) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0511 | Time 29.3399, Epoch Time 493.8104(489.3880), Bit/dim 3.9425(best: 3.9434), Xent 2.1728, Loss 5.0289, Error 0.4320(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3067 | Time 74.2313(74.3297) | Bit/dim 3.9277(3.9314) | Xent 0.2837(0.2998) | Loss 4.0695(4.0813) | Error 0.0966(0.1072) Steps 784(792.97) | Grad Norm 5.3693(4.4429) | Total Time 14.00(14.00)\n",
      "Iter 3068 | Time 75.2915(74.3585) | Bit/dim 3.9307(3.9314) | Xent 0.2929(0.2996) | Loss 4.0772(4.0812) | Error 0.1045(0.1071) Steps 790(792.88) | Grad Norm 5.2104(4.4659) | Total Time 14.00(14.00)\n",
      "Iter 3069 | Time 74.9629(74.3766) | Bit/dim 3.9239(3.9312) | Xent 0.3057(0.2998) | Loss 4.0768(4.0811) | Error 0.1091(0.1072) Steps 790(792.80) | Grad Norm 7.2688(4.5500) | Total Time 14.00(14.00)\n",
      "Iter 3070 | Time 75.7798(74.4187) | Bit/dim 3.9324(3.9312) | Xent 0.2818(0.2992) | Loss 4.0733(4.0808) | Error 0.0972(0.1069) Steps 784(792.53) | Grad Norm 2.9681(4.5026) | Total Time 14.00(14.00)\n",
      "Iter 3071 | Time 74.8534(74.4318) | Bit/dim 3.9263(3.9311) | Xent 0.3086(0.2995) | Loss 4.0806(4.0808) | Error 0.1102(0.1070) Steps 796(792.64) | Grad Norm 7.1819(4.5829) | Total Time 14.00(14.00)\n",
      "Iter 3072 | Time 75.6065(74.4670) | Bit/dim 3.9316(3.9311) | Xent 0.3021(0.2996) | Loss 4.0827(4.0809) | Error 0.1075(0.1070) Steps 802(792.92) | Grad Norm 8.6464(4.7048) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0512 | Time 29.4540, Epoch Time 495.7099(489.5777), Bit/dim 3.9425(best: 3.9425), Xent 2.1741, Loss 5.0295, Error 0.4333(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3073 | Time 72.6148(74.4114) | Bit/dim 3.9295(3.9311) | Xent 0.3012(0.2996) | Loss 4.0800(4.0809) | Error 0.1071(0.1070) Steps 796(793.01) | Grad Norm 5.2061(4.7199) | Total Time 14.00(14.00)\n",
      "Iter 3074 | Time 73.2941(74.3779) | Bit/dim 3.9309(3.9310) | Xent 0.2873(0.2993) | Loss 4.0746(4.0807) | Error 0.1045(0.1069) Steps 796(793.10) | Grad Norm 3.1184(4.6718) | Total Time 14.00(14.00)\n",
      "Iter 3075 | Time 72.8923(74.3334) | Bit/dim 3.9285(3.9310) | Xent 0.2921(0.2990) | Loss 4.0745(4.0805) | Error 0.1048(0.1069) Steps 796(793.19) | Grad Norm 7.0112(4.7420) | Total Time 14.00(14.00)\n",
      "Iter 3076 | Time 71.3089(74.2426) | Bit/dim 3.9298(3.9309) | Xent 0.2830(0.2986) | Loss 4.0713(4.0802) | Error 0.0999(0.1067) Steps 796(793.27) | Grad Norm 4.4532(4.7334) | Total Time 14.00(14.00)\n",
      "Iter 3077 | Time 72.2366(74.1824) | Bit/dim 3.9344(3.9310) | Xent 0.2829(0.2981) | Loss 4.0758(4.0801) | Error 0.1020(0.1065) Steps 802(793.53) | Grad Norm 4.3074(4.7206) | Total Time 14.00(14.00)\n",
      "Iter 3078 | Time 72.9140(74.1444) | Bit/dim 3.9258(3.9309) | Xent 0.2932(0.2980) | Loss 4.0724(4.0799) | Error 0.1039(0.1064) Steps 796(793.61) | Grad Norm 6.4545(4.7726) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0513 | Time 29.4402, Epoch Time 480.1819(489.2958), Bit/dim 3.9422(best: 3.9425), Xent 2.1814, Loss 5.0329, Error 0.4332(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3079 | Time 73.7443(74.1324) | Bit/dim 3.9273(3.9308) | Xent 0.2897(0.2977) | Loss 4.0721(4.0796) | Error 0.1061(0.1064) Steps 784(793.32) | Grad Norm 3.8878(4.7461) | Total Time 14.00(14.00)\n",
      "Iter 3080 | Time 74.3606(74.1392) | Bit/dim 3.9346(3.9309) | Xent 0.2939(0.2976) | Loss 4.0815(4.0797) | Error 0.1049(0.1064) Steps 790(793.22) | Grad Norm 5.2778(4.7620) | Total Time 14.00(14.00)\n",
      "Iter 3081 | Time 73.0842(74.1076) | Bit/dim 3.9322(3.9309) | Xent 0.2936(0.2975) | Loss 4.0790(4.0797) | Error 0.1022(0.1063) Steps 790(793.12) | Grad Norm 6.1426(4.8034) | Total Time 14.00(14.00)\n",
      "Iter 3082 | Time 74.4667(74.1184) | Bit/dim 3.9197(3.9306) | Xent 0.2814(0.2970) | Loss 4.0605(4.0791) | Error 0.1035(0.1062) Steps 802(793.39) | Grad Norm 3.0231(4.7500) | Total Time 14.00(14.00)\n",
      "Iter 3083 | Time 74.7041(74.1359) | Bit/dim 3.9337(3.9307) | Xent 0.2946(0.2969) | Loss 4.0810(4.0791) | Error 0.1050(0.1061) Steps 814(794.01) | Grad Norm 8.6887(4.8682) | Total Time 14.00(14.00)\n",
      "Iter 3084 | Time 73.6011(74.1199) | Bit/dim 3.9293(3.9306) | Xent 0.3034(0.2971) | Loss 4.0810(4.0792) | Error 0.1090(0.1062) Steps 802(794.25) | Grad Norm 3.2161(4.8186) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0514 | Time 29.1582, Epoch Time 488.7505(489.2794), Bit/dim 3.9424(best: 3.9422), Xent 2.1961, Loss 5.0405, Error 0.4412(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3085 | Time 74.4903(74.1310) | Bit/dim 3.9223(3.9304) | Xent 0.2986(0.2972) | Loss 4.0716(4.0790) | Error 0.1066(0.1062) Steps 796(794.30) | Grad Norm 4.1840(4.7996) | Total Time 14.00(14.00)\n",
      "Iter 3086 | Time 74.4323(74.1400) | Bit/dim 3.9300(3.9304) | Xent 0.2870(0.2969) | Loss 4.0735(4.0788) | Error 0.1025(0.1061) Steps 790(794.17) | Grad Norm 2.2625(4.7235) | Total Time 14.00(14.00)\n",
      "Iter 3087 | Time 74.7154(74.1573) | Bit/dim 3.9306(3.9304) | Xent 0.2709(0.2961) | Loss 4.0660(4.0784) | Error 0.0933(0.1057) Steps 796(794.23) | Grad Norm 2.3203(4.6514) | Total Time 14.00(14.00)\n",
      "Iter 3088 | Time 74.8311(74.1775) | Bit/dim 3.9215(3.9301) | Xent 0.2837(0.2957) | Loss 4.0634(4.0780) | Error 0.1012(0.1056) Steps 790(794.10) | Grad Norm 1.2481(4.5493) | Total Time 14.00(14.00)\n",
      "Iter 3089 | Time 73.1546(74.1468) | Bit/dim 3.9364(3.9303) | Xent 0.2945(0.2957) | Loss 4.0837(4.0781) | Error 0.1080(0.1057) Steps 802(794.34) | Grad Norm 2.3843(4.4843) | Total Time 14.00(14.00)\n",
      "Iter 3090 | Time 74.5144(74.1578) | Bit/dim 3.9295(3.9303) | Xent 0.2768(0.2951) | Loss 4.0679(4.0778) | Error 0.0964(0.1054) Steps 790(794.21) | Grad Norm 1.7579(4.4025) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0515 | Time 29.5158, Epoch Time 491.3478(489.3415), Bit/dim 3.9434(best: 3.9422), Xent 2.2028, Loss 5.0448, Error 0.4362(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3091 | Time 74.6577(74.1728) | Bit/dim 3.9252(3.9301) | Xent 0.2920(0.2950) | Loss 4.0712(4.0776) | Error 0.1055(0.1054) Steps 796(794.26) | Grad Norm 2.1404(4.3347) | Total Time 14.00(14.00)\n",
      "Iter 3092 | Time 76.5251(74.2434) | Bit/dim 3.9254(3.9300) | Xent 0.3034(0.2953) | Loss 4.0771(4.0776) | Error 0.1075(0.1055) Steps 796(794.31) | Grad Norm 2.9584(4.2934) | Total Time 14.00(14.00)\n",
      "Iter 3093 | Time 74.3602(74.2469) | Bit/dim 3.9348(3.9301) | Xent 0.2839(0.2949) | Loss 4.0768(4.0776) | Error 0.1020(0.1054) Steps 796(794.36) | Grad Norm 2.0027(4.2247) | Total Time 14.00(14.00)\n",
      "Iter 3094 | Time 73.9156(74.2370) | Bit/dim 3.9262(3.9300) | Xent 0.2860(0.2947) | Loss 4.0693(4.0773) | Error 0.1040(0.1053) Steps 796(794.41) | Grad Norm 2.6101(4.1762) | Total Time 14.00(14.00)\n",
      "Iter 3095 | Time 76.9598(74.3187) | Bit/dim 3.9288(3.9300) | Xent 0.2950(0.2947) | Loss 4.0763(4.0773) | Error 0.1048(0.1053) Steps 796(794.46) | Grad Norm 4.2526(4.1785) | Total Time 14.00(14.00)\n",
      "Iter 3096 | Time 73.4266(74.2919) | Bit/dim 3.9311(3.9300) | Xent 0.2872(0.2944) | Loss 4.0747(4.0772) | Error 0.1039(0.1053) Steps 802(794.69) | Grad Norm 5.9221(4.2308) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0516 | Time 29.4422, Epoch Time 494.8528(489.5068), Bit/dim 3.9419(best: 3.9422), Xent 2.1870, Loss 5.0354, Error 0.4332(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3097 | Time 77.5427(74.3894) | Bit/dim 3.9244(3.9298) | Xent 0.2974(0.2945) | Loss 4.0731(4.0771) | Error 0.1051(0.1053) Steps 802(794.91) | Grad Norm 4.2957(4.2328) | Total Time 14.00(14.00)\n",
      "Iter 3098 | Time 74.3240(74.3875) | Bit/dim 3.9303(3.9299) | Xent 0.2717(0.2938) | Loss 4.0662(4.0768) | Error 0.0951(0.1050) Steps 796(794.94) | Grad Norm 1.8828(4.1623) | Total Time 14.00(14.00)\n",
      "Iter 3099 | Time 74.2075(74.3821) | Bit/dim 3.9301(3.9299) | Xent 0.2665(0.2930) | Loss 4.0634(4.0764) | Error 0.0951(0.1047) Steps 802(795.15) | Grad Norm 2.9458(4.1258) | Total Time 14.00(14.00)\n",
      "Iter 3100 | Time 72.7958(74.3345) | Bit/dim 3.9309(3.9299) | Xent 0.2736(0.2924) | Loss 4.0677(4.0761) | Error 0.0972(0.1044) Steps 802(795.36) | Grad Norm 3.7103(4.1133) | Total Time 14.00(14.00)\n",
      "Iter 3101 | Time 75.7477(74.3769) | Bit/dim 3.9375(3.9301) | Xent 0.2856(0.2922) | Loss 4.0802(4.0762) | Error 0.0969(0.1042) Steps 808(795.73) | Grad Norm 2.0674(4.0519) | Total Time 14.00(14.00)\n",
      "Iter 3102 | Time 72.6686(74.3256) | Bit/dim 3.9171(3.9297) | Xent 0.2909(0.2922) | Loss 4.0626(4.0758) | Error 0.1072(0.1043) Steps 796(795.74) | Grad Norm 6.3457(4.1207) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0517 | Time 29.0286, Epoch Time 491.9793(489.5810), Bit/dim 3.9417(best: 3.9419), Xent 2.1575, Loss 5.0205, Error 0.4322(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3103 | Time 75.0804(74.3483) | Bit/dim 3.9260(3.9296) | Xent 0.2846(0.2920) | Loss 4.0684(4.0756) | Error 0.1011(0.1042) Steps 802(795.93) | Grad Norm 6.4769(4.1914) | Total Time 14.00(14.00)\n",
      "Iter 3104 | Time 73.6684(74.3279) | Bit/dim 3.9305(3.9297) | Xent 0.2802(0.2916) | Loss 4.0706(4.0755) | Error 0.0976(0.1040) Steps 796(795.93) | Grad Norm 3.6624(4.1756) | Total Time 14.00(14.00)\n",
      "Iter 3105 | Time 74.6942(74.3389) | Bit/dim 3.9265(3.9296) | Xent 0.2935(0.2917) | Loss 4.0732(4.0754) | Error 0.1038(0.1040) Steps 796(795.93) | Grad Norm 7.1909(4.2660) | Total Time 14.00(14.00)\n",
      "Iter 3106 | Time 72.2533(74.2763) | Bit/dim 3.9301(3.9296) | Xent 0.2779(0.2913) | Loss 4.0690(4.0752) | Error 0.0972(0.1038) Steps 802(796.12) | Grad Norm 2.6069(4.2162) | Total Time 14.00(14.00)\n",
      "Iter 3107 | Time 73.6257(74.2568) | Bit/dim 3.9285(3.9295) | Xent 0.2687(0.2906) | Loss 4.0628(4.0748) | Error 0.0964(0.1036) Steps 796(796.11) | Grad Norm 5.0595(4.2415) | Total Time 14.00(14.00)\n",
      "Iter 3108 | Time 75.4513(74.2926) | Bit/dim 3.9284(3.9295) | Xent 0.2954(0.2907) | Loss 4.0761(4.0749) | Error 0.1080(0.1037) Steps 796(796.11) | Grad Norm 4.1015(4.2373) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0518 | Time 29.3093, Epoch Time 489.4974(489.5785), Bit/dim 3.9412(best: 3.9417), Xent 2.2215, Loss 5.0519, Error 0.4393(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3109 | Time 74.7539(74.3065) | Bit/dim 3.9336(3.9296) | Xent 0.2824(0.2905) | Loss 4.0748(4.0749) | Error 0.0995(0.1036) Steps 808(796.47) | Grad Norm 3.6276(4.2190) | Total Time 14.00(14.00)\n",
      "Iter 3110 | Time 75.8263(74.3520) | Bit/dim 3.9347(3.9298) | Xent 0.2707(0.2899) | Loss 4.0701(4.0747) | Error 0.0954(0.1033) Steps 796(796.45) | Grad Norm 1.3420(4.1327) | Total Time 14.00(14.00)\n",
      "Iter 3111 | Time 74.9785(74.3708) | Bit/dim 3.9186(3.9294) | Xent 0.2854(0.2897) | Loss 4.0613(4.0743) | Error 0.1025(0.1033) Steps 808(796.80) | Grad Norm 5.3335(4.1688) | Total Time 14.00(14.00)\n",
      "Iter 3112 | Time 71.2249(74.2765) | Bit/dim 3.9204(3.9292) | Xent 0.2797(0.2894) | Loss 4.0603(4.0739) | Error 0.0974(0.1031) Steps 802(796.95) | Grad Norm 5.3466(4.2041) | Total Time 14.00(14.00)\n",
      "Iter 3113 | Time 74.6863(74.2888) | Bit/dim 3.9257(3.9291) | Xent 0.2737(0.2890) | Loss 4.0626(4.0736) | Error 0.0971(0.1030) Steps 802(797.11) | Grad Norm 1.8439(4.1333) | Total Time 14.00(14.00)\n",
      "Iter 3114 | Time 74.7096(74.3014) | Bit/dim 3.9306(3.9291) | Xent 0.2761(0.2886) | Loss 4.0687(4.0734) | Error 0.0995(0.1028) Steps 802(797.25) | Grad Norm 5.8283(4.1841) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0519 | Time 29.4772, Epoch Time 491.2599(489.6289), Bit/dim 3.9409(best: 3.9412), Xent 2.1977, Loss 5.0397, Error 0.4338(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3115 | Time 74.3789(74.3037) | Bit/dim 3.9316(3.9292) | Xent 0.2741(0.2882) | Loss 4.0686(4.0733) | Error 0.0970(0.1027) Steps 802(797.40) | Grad Norm 5.8456(4.2340) | Total Time 14.00(14.00)\n",
      "Iter 3116 | Time 76.3266(74.3644) | Bit/dim 3.9225(3.9290) | Xent 0.2919(0.2883) | Loss 4.0684(4.0731) | Error 0.1039(0.1027) Steps 802(797.53) | Grad Norm 5.3914(4.2687) | Total Time 14.00(14.00)\n",
      "Iter 3117 | Time 73.7636(74.3464) | Bit/dim 3.9255(3.9289) | Xent 0.2764(0.2879) | Loss 4.0637(4.0728) | Error 0.1020(0.1027) Steps 796(797.49) | Grad Norm 1.8789(4.1970) | Total Time 14.00(14.00)\n",
      "Iter 3118 | Time 74.1277(74.3398) | Bit/dim 3.9212(3.9287) | Xent 0.2888(0.2879) | Loss 4.0656(4.0726) | Error 0.1030(0.1027) Steps 802(797.62) | Grad Norm 4.2487(4.1986) | Total Time 14.00(14.00)\n",
      "Iter 3119 | Time 71.2337(74.2466) | Bit/dim 3.9321(3.9288) | Xent 0.2728(0.2875) | Loss 4.0685(4.0725) | Error 0.0921(0.1024) Steps 790(797.39) | Grad Norm 2.1524(4.1372) | Total Time 14.00(14.00)\n",
      "Iter 3120 | Time 74.3900(74.2509) | Bit/dim 3.9269(3.9287) | Xent 0.2775(0.2872) | Loss 4.0657(4.0723) | Error 0.0986(0.1023) Steps 802(797.53) | Grad Norm 4.3059(4.1422) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0520 | Time 29.5917, Epoch Time 489.2391(489.6172), Bit/dim 3.9396(best: 3.9409), Xent 2.1968, Loss 5.0380, Error 0.4347(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3121 | Time 73.1839(74.2189) | Bit/dim 3.9381(3.9290) | Xent 0.2810(0.2870) | Loss 4.0787(4.0725) | Error 0.1009(0.1022) Steps 796(797.49) | Grad Norm 3.0765(4.1103) | Total Time 14.00(14.00)\n",
      "Iter 3122 | Time 73.1600(74.1872) | Bit/dim 3.9160(3.9286) | Xent 0.2805(0.2868) | Loss 4.0562(4.0720) | Error 0.0970(0.1021) Steps 790(797.26) | Grad Norm 4.3211(4.1166) | Total Time 14.00(14.00)\n",
      "Iter 3123 | Time 75.3897(74.2232) | Bit/dim 3.9238(3.9285) | Xent 0.2904(0.2869) | Loss 4.0690(4.0719) | Error 0.1016(0.1021) Steps 796(797.22) | Grad Norm 5.6736(4.1633) | Total Time 14.00(14.00)\n",
      "Iter 3124 | Time 73.5040(74.2017) | Bit/dim 3.9274(3.9284) | Xent 0.2908(0.2870) | Loss 4.0728(4.0719) | Error 0.1012(0.1020) Steps 796(797.19) | Grad Norm 6.1530(4.2230) | Total Time 14.00(14.00)\n",
      "Iter 3125 | Time 73.8660(74.1916) | Bit/dim 3.9276(3.9284) | Xent 0.2855(0.2870) | Loss 4.0703(4.0719) | Error 0.0994(0.1020) Steps 802(797.33) | Grad Norm 3.6930(4.2071) | Total Time 14.00(14.00)\n",
      "Iter 3126 | Time 73.3247(74.1656) | Bit/dim 3.9236(3.9283) | Xent 0.2822(0.2868) | Loss 4.0647(4.0717) | Error 0.1019(0.1019) Steps 802(797.47) | Grad Norm 3.6275(4.1897) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0521 | Time 29.3851, Epoch Time 487.8500(489.5642), Bit/dim 3.9404(best: 3.9396), Xent 2.1975, Loss 5.0391, Error 0.4312(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3127 | Time 74.1395(74.1648) | Bit/dim 3.9244(3.9281) | Xent 0.2637(0.2861) | Loss 4.0563(4.0712) | Error 0.0965(0.1018) Steps 802(797.61) | Grad Norm 2.3313(4.1340) | Total Time 14.00(14.00)\n",
      "Iter 3128 | Time 72.1427(74.1041) | Bit/dim 3.9282(3.9281) | Xent 0.2674(0.2856) | Loss 4.0619(4.0709) | Error 0.0984(0.1017) Steps 802(797.74) | Grad Norm 2.7072(4.0912) | Total Time 14.00(14.00)\n",
      "Iter 3129 | Time 75.1563(74.1357) | Bit/dim 3.9248(3.9280) | Xent 0.2758(0.2853) | Loss 4.0628(4.0707) | Error 0.0994(0.1016) Steps 802(797.87) | Grad Norm 2.0597(4.0302) | Total Time 14.00(14.00)\n",
      "Iter 3130 | Time 73.1415(74.1059) | Bit/dim 3.9363(3.9283) | Xent 0.2729(0.2849) | Loss 4.0728(4.0708) | Error 0.1000(0.1016) Steps 796(797.81) | Grad Norm 2.8551(3.9950) | Total Time 14.00(14.00)\n",
      "Iter 3131 | Time 73.4571(74.0864) | Bit/dim 3.9211(3.9281) | Xent 0.2638(0.2843) | Loss 4.0530(4.0702) | Error 0.0959(0.1014) Steps 796(797.76) | Grad Norm 2.9368(3.9632) | Total Time 14.00(14.00)\n",
      "Iter 3132 | Time 74.2166(74.0903) | Bit/dim 3.9232(3.9279) | Xent 0.2834(0.2843) | Loss 4.0649(4.0701) | Error 0.1016(0.1014) Steps 802(797.88) | Grad Norm 3.2074(3.9405) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0522 | Time 29.4114, Epoch Time 487.3701(489.4984), Bit/dim 3.9402(best: 3.9396), Xent 2.2326, Loss 5.0565, Error 0.4329(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3133 | Time 74.3728(74.0988) | Bit/dim 3.9359(3.9282) | Xent 0.2648(0.2837) | Loss 4.0683(4.0700) | Error 0.0959(0.1012) Steps 796(797.83) | Grad Norm 2.8501(3.9078) | Total Time 14.00(14.00)\n",
      "Iter 3134 | Time 74.0701(74.0979) | Bit/dim 3.9220(3.9280) | Xent 0.2577(0.2829) | Loss 4.0508(4.0694) | Error 0.0945(0.1010) Steps 796(797.77) | Grad Norm 1.7289(3.8425) | Total Time 14.00(14.00)\n",
      "Iter 3135 | Time 72.8724(74.0612) | Bit/dim 3.9323(3.9281) | Xent 0.2609(0.2822) | Loss 4.0627(4.0692) | Error 0.0909(0.1007) Steps 784(797.36) | Grad Norm 2.0942(3.7900) | Total Time 14.00(14.00)\n",
      "Iter 3136 | Time 77.7940(74.1731) | Bit/dim 3.9301(3.9282) | Xent 0.2797(0.2822) | Loss 4.0699(4.0693) | Error 0.0990(0.1007) Steps 796(797.32) | Grad Norm 2.9125(3.7637) | Total Time 14.00(14.00)\n",
      "Iter 3137 | Time 73.5458(74.1543) | Bit/dim 3.9163(3.9278) | Xent 0.2861(0.2823) | Loss 4.0593(4.0690) | Error 0.1051(0.1008) Steps 802(797.46) | Grad Norm 4.5780(3.7881) | Total Time 14.00(14.00)\n",
      "Iter 3138 | Time 74.6319(74.1686) | Bit/dim 3.9205(3.9276) | Xent 0.2844(0.2823) | Loss 4.0627(4.0688) | Error 0.1042(0.1009) Steps 802(797.60) | Grad Norm 3.0635(3.7664) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0523 | Time 29.5483, Epoch Time 492.4321(489.5864), Bit/dim 3.9406(best: 3.9396), Xent 2.2510, Loss 5.0661, Error 0.4373(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3139 | Time 75.3741(74.2048) | Bit/dim 3.9301(3.9277) | Xent 0.2639(0.2818) | Loss 4.0620(4.0686) | Error 0.0958(0.1008) Steps 790(797.37) | Grad Norm 4.1797(3.7788) | Total Time 14.00(14.00)\n",
      "Iter 3140 | Time 76.9869(74.2883) | Bit/dim 3.9236(3.9275) | Xent 0.2646(0.2813) | Loss 4.0559(4.0682) | Error 0.0990(0.1007) Steps 808(797.69) | Grad Norm 3.1523(3.7600) | Total Time 14.00(14.00)\n",
      "Iter 3141 | Time 73.2763(74.2579) | Bit/dim 3.9377(3.9279) | Xent 0.2737(0.2810) | Loss 4.0746(4.0684) | Error 0.0939(0.1005) Steps 796(797.64) | Grad Norm 4.2389(3.7743) | Total Time 14.00(14.00)\n",
      "Iter 3142 | Time 73.6008(74.2382) | Bit/dim 3.9198(3.9276) | Xent 0.2882(0.2813) | Loss 4.0639(4.0682) | Error 0.1026(0.1006) Steps 796(797.59) | Grad Norm 2.9476(3.7495) | Total Time 14.00(14.00)\n",
      "Iter 3143 | Time 74.9658(74.2600) | Bit/dim 3.9206(3.9274) | Xent 0.2888(0.2815) | Loss 4.0650(4.0681) | Error 0.1030(0.1006) Steps 790(797.36) | Grad Norm 3.8169(3.7516) | Total Time 14.00(14.00)\n",
      "Iter 3144 | Time 75.2386(74.2894) | Bit/dim 3.9243(3.9273) | Xent 0.2660(0.2810) | Loss 4.0572(4.0678) | Error 0.0968(0.1005) Steps 802(797.50) | Grad Norm 3.7109(3.7503) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0524 | Time 29.4061, Epoch Time 494.5596(489.7356), Bit/dim 3.9393(best: 3.9396), Xent 2.2486, Loss 5.0636, Error 0.4366(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3145 | Time 73.6953(74.2716) | Bit/dim 3.9300(3.9274) | Xent 0.2676(0.2806) | Loss 4.0638(4.0677) | Error 0.0945(0.1003) Steps 790(797.27) | Grad Norm 4.5977(3.7758) | Total Time 14.00(14.00)\n",
      "Iter 3146 | Time 75.3038(74.3025) | Bit/dim 3.9270(3.9274) | Xent 0.2699(0.2803) | Loss 4.0620(4.0675) | Error 0.0969(0.1002) Steps 796(797.24) | Grad Norm 3.0370(3.7536) | Total Time 14.00(14.00)\n",
      "Iter 3147 | Time 77.1394(74.3876) | Bit/dim 3.9200(3.9272) | Xent 0.2733(0.2801) | Loss 4.0567(4.0672) | Error 0.0978(0.1002) Steps 802(797.38) | Grad Norm 2.7833(3.7245) | Total Time 14.00(14.00)\n",
      "Iter 3148 | Time 71.4360(74.2991) | Bit/dim 3.9206(3.9270) | Xent 0.2785(0.2800) | Loss 4.0599(4.0670) | Error 0.0999(0.1002) Steps 796(797.34) | Grad Norm 2.7813(3.6962) | Total Time 14.00(14.00)\n",
      "Iter 3149 | Time 73.3740(74.2713) | Bit/dim 3.9211(3.9268) | Xent 0.2737(0.2798) | Loss 4.0579(4.0667) | Error 0.0982(0.1001) Steps 802(797.48) | Grad Norm 2.1703(3.6504) | Total Time 14.00(14.00)\n",
      "Iter 3150 | Time 74.5589(74.2800) | Bit/dim 3.9368(3.9271) | Xent 0.2681(0.2795) | Loss 4.0709(4.0668) | Error 0.0952(0.1000) Steps 796(797.43) | Grad Norm 3.3579(3.6416) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0525 | Time 29.3723, Epoch Time 490.6165(489.7620), Bit/dim 3.9394(best: 3.9393), Xent 2.2379, Loss 5.0584, Error 0.4347(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3151 | Time 74.2031(74.2777) | Bit/dim 3.9275(3.9271) | Xent 0.2696(0.2792) | Loss 4.0623(4.0667) | Error 0.0968(0.0999) Steps 802(797.57) | Grad Norm 3.8454(3.6478) | Total Time 14.00(14.00)\n",
      "Iter 3152 | Time 75.9775(74.3287) | Bit/dim 3.9194(3.9269) | Xent 0.2776(0.2792) | Loss 4.0582(4.0664) | Error 0.0992(0.0998) Steps 796(797.52) | Grad Norm 2.8157(3.6228) | Total Time 14.00(14.00)\n",
      "Iter 3153 | Time 73.5094(74.3041) | Bit/dim 3.9209(3.9267) | Xent 0.2652(0.2787) | Loss 4.0535(4.0661) | Error 0.0996(0.0998) Steps 802(797.66) | Grad Norm 3.1007(3.6071) | Total Time 14.00(14.00)\n",
      "Iter 3154 | Time 75.1396(74.3291) | Bit/dim 3.9226(3.9266) | Xent 0.2613(0.2782) | Loss 4.0532(4.0657) | Error 0.0960(0.0997) Steps 802(797.79) | Grad Norm 4.7953(3.6428) | Total Time 14.00(14.00)\n",
      "Iter 3155 | Time 72.9360(74.2873) | Bit/dim 3.9372(3.9269) | Xent 0.2664(0.2779) | Loss 4.0704(4.0658) | Error 0.0970(0.0996) Steps 802(797.91) | Grad Norm 3.6950(3.6443) | Total Time 14.00(14.00)\n",
      "Iter 3156 | Time 74.3665(74.2897) | Bit/dim 3.9255(3.9268) | Xent 0.2864(0.2781) | Loss 4.0687(4.0659) | Error 0.1011(0.0997) Steps 802(798.04) | Grad Norm 3.6714(3.6452) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0526 | Time 29.5643, Epoch Time 491.3040(489.8083), Bit/dim 3.9397(best: 3.9393), Xent 2.2937, Loss 5.0865, Error 0.4389(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3157 | Time 72.4180(74.2336) | Bit/dim 3.9181(3.9266) | Xent 0.2816(0.2782) | Loss 4.0589(4.0657) | Error 0.1045(0.0998) Steps 802(798.15) | Grad Norm 7.4755(3.7601) | Total Time 14.00(14.00)\n",
      "Iter 3158 | Time 73.0802(74.1990) | Bit/dim 3.9323(3.9267) | Xent 0.2647(0.2778) | Loss 4.0646(4.0657) | Error 0.0954(0.0997) Steps 796(798.09) | Grad Norm 8.9650(3.9162) | Total Time 14.00(14.00)\n",
      "Iter 3159 | Time 73.2425(74.1703) | Bit/dim 3.9272(3.9268) | Xent 0.2654(0.2774) | Loss 4.0599(4.0655) | Error 0.0964(0.0996) Steps 796(798.03) | Grad Norm 5.5432(3.9650) | Total Time 14.00(14.00)\n",
      "Iter 3160 | Time 72.8364(74.1303) | Bit/dim 3.9221(3.9266) | Xent 0.2803(0.2775) | Loss 4.0623(4.0654) | Error 0.1006(0.0996) Steps 790(797.79) | Grad Norm 3.1213(3.9397) | Total Time 14.00(14.00)\n",
      "Iter 3161 | Time 77.0472(74.2178) | Bit/dim 3.9244(3.9266) | Xent 0.2649(0.2771) | Loss 4.0569(4.0651) | Error 0.0948(0.0995) Steps 796(797.73) | Grad Norm 3.8785(3.9379) | Total Time 14.00(14.00)\n",
      "Iter 3162 | Time 73.5040(74.1964) | Bit/dim 3.9265(3.9266) | Xent 0.2836(0.2773) | Loss 4.0683(4.0652) | Error 0.1012(0.0995) Steps 796(797.68) | Grad Norm 2.8521(3.9053) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0527 | Time 29.0436, Epoch Time 486.6334(489.7130), Bit/dim 3.9387(best: 3.9393), Xent 2.2488, Loss 5.0631, Error 0.4347(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3163 | Time 73.1915(74.1662) | Bit/dim 3.9159(3.9262) | Xent 0.2698(0.2771) | Loss 4.0508(4.0648) | Error 0.0954(0.0994) Steps 796(797.63) | Grad Norm 3.3412(3.8884) | Total Time 14.00(14.00)\n",
      "Iter 3164 | Time 74.7453(74.1836) | Bit/dim 3.9297(3.9263) | Xent 0.2655(0.2768) | Loss 4.0624(4.0647) | Error 0.0951(0.0993) Steps 796(797.58) | Grad Norm 4.4052(3.9039) | Total Time 14.00(14.00)\n",
      "Iter 3165 | Time 72.1250(74.1218) | Bit/dim 3.9243(3.9263) | Xent 0.2497(0.2760) | Loss 4.0492(4.0643) | Error 0.0920(0.0991) Steps 802(797.71) | Grad Norm 2.8394(3.8719) | Total Time 14.00(14.00)\n",
      "Iter 3166 | Time 73.2432(74.0955) | Bit/dim 3.9418(3.9267) | Xent 0.2684(0.2757) | Loss 4.0760(4.0646) | Error 0.0976(0.0990) Steps 796(797.66) | Grad Norm 3.4470(3.8592) | Total Time 14.00(14.00)\n",
      "Iter 3167 | Time 75.5155(74.1381) | Bit/dim 3.9204(3.9266) | Xent 0.2672(0.2755) | Loss 4.0540(4.0643) | Error 0.0985(0.0990) Steps 796(797.61) | Grad Norm 3.0999(3.8364) | Total Time 14.00(14.00)\n",
      "Iter 3168 | Time 72.9836(74.1034) | Bit/dim 3.9146(3.9262) | Xent 0.2768(0.2755) | Loss 4.0530(4.0640) | Error 0.0995(0.0990) Steps 802(797.74) | Grad Norm 2.0996(3.7843) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0528 | Time 29.4683, Epoch Time 486.9792(489.6310), Bit/dim 3.9373(best: 3.9387), Xent 2.2239, Loss 5.0492, Error 0.4336(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3169 | Time 75.0788(74.1327) | Bit/dim 3.9213(3.9260) | Xent 0.2671(0.2753) | Loss 4.0549(4.0637) | Error 0.0949(0.0989) Steps 808(798.05) | Grad Norm 2.1048(3.7339) | Total Time 14.00(14.00)\n",
      "Iter 3170 | Time 74.4107(74.1410) | Bit/dim 3.9242(3.9260) | Xent 0.2724(0.2752) | Loss 4.0605(4.0636) | Error 0.0942(0.0988) Steps 796(797.99) | Grad Norm 2.8390(3.7071) | Total Time 14.00(14.00)\n",
      "Iter 3171 | Time 73.2930(74.1156) | Bit/dim 3.9237(3.9259) | Xent 0.2707(0.2750) | Loss 4.0591(4.0634) | Error 0.0966(0.0987) Steps 802(798.11) | Grad Norm 2.9616(3.6847) | Total Time 14.00(14.00)\n",
      "Iter 3172 | Time 75.2625(74.1500) | Bit/dim 3.9236(3.9259) | Xent 0.2702(0.2749) | Loss 4.0587(4.0633) | Error 0.0972(0.0986) Steps 802(798.23) | Grad Norm 3.4461(3.6776) | Total Time 14.00(14.00)\n",
      "Iter 3173 | Time 74.7519(74.1681) | Bit/dim 3.9241(3.9258) | Xent 0.2743(0.2749) | Loss 4.0613(4.0632) | Error 0.0984(0.0986) Steps 796(798.16) | Grad Norm 4.0429(3.6885) | Total Time 14.00(14.00)\n",
      "Iter 3174 | Time 73.0083(74.1333) | Bit/dim 3.9257(3.9258) | Xent 0.2756(0.2749) | Loss 4.0635(4.0633) | Error 0.0992(0.0987) Steps 808(798.46) | Grad Norm 7.4360(3.8010) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0529 | Time 29.7322, Epoch Time 491.0465(489.6735), Bit/dim 3.9395(best: 3.9373), Xent 2.2841, Loss 5.0816, Error 0.4411(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3175 | Time 73.6210(74.1179) | Bit/dim 3.9161(3.9255) | Xent 0.2663(0.2746) | Loss 4.0492(4.0628) | Error 0.0938(0.0985) Steps 796(798.38) | Grad Norm 3.1794(3.7823) | Total Time 14.00(14.00)\n",
      "Iter 3176 | Time 71.7456(74.0467) | Bit/dim 3.9367(3.9258) | Xent 0.2567(0.2741) | Loss 4.0650(4.0629) | Error 0.0961(0.0984) Steps 796(798.31) | Grad Norm 5.6259(3.8376) | Total Time 14.00(14.00)\n",
      "Iter 3177 | Time 73.3929(74.0271) | Bit/dim 3.9246(3.9258) | Xent 0.2689(0.2739) | Loss 4.0591(4.0628) | Error 0.0996(0.0985) Steps 802(798.42) | Grad Norm 4.7098(3.8638) | Total Time 14.00(14.00)\n",
      "Iter 3178 | Time 75.9113(74.0836) | Bit/dim 3.9297(3.9259) | Xent 0.2798(0.2741) | Loss 4.0697(4.0630) | Error 0.0996(0.0985) Steps 802(798.53) | Grad Norm 5.3292(3.9077) | Total Time 14.00(14.00)\n",
      "Iter 3179 | Time 72.7838(74.0446) | Bit/dim 3.9237(3.9259) | Xent 0.2591(0.2737) | Loss 4.0533(4.0627) | Error 0.0884(0.0982) Steps 784(798.09) | Grad Norm 2.6324(3.8695) | Total Time 14.00(14.00)\n",
      "Iter 3180 | Time 71.7512(73.9758) | Bit/dim 3.9175(3.9256) | Xent 0.2669(0.2735) | Loss 4.0510(4.0623) | Error 0.0935(0.0981) Steps 796(798.03) | Grad Norm 6.0750(3.9356) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0530 | Time 29.6219, Epoch Time 484.4465(489.5167), Bit/dim 3.9389(best: 3.9373), Xent 2.2974, Loss 5.0876, Error 0.4413(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3181 | Time 75.0324(74.0075) | Bit/dim 3.9247(3.9256) | Xent 0.2652(0.2732) | Loss 4.0573(4.0622) | Error 0.0955(0.0980) Steps 808(798.33) | Grad Norm 8.5619(4.0744) | Total Time 14.00(14.00)\n",
      "Iter 3182 | Time 75.3644(74.0482) | Bit/dim 3.9255(3.9256) | Xent 0.2716(0.2732) | Loss 4.0613(4.0622) | Error 0.0981(0.0980) Steps 802(798.44) | Grad Norm 5.9612(4.1310) | Total Time 14.00(14.00)\n",
      "Iter 3183 | Time 74.3319(74.0568) | Bit/dim 3.9283(3.9257) | Xent 0.2600(0.2728) | Loss 4.0584(4.0621) | Error 0.0949(0.0979) Steps 790(798.19) | Grad Norm 4.9856(4.1567) | Total Time 14.00(14.00)\n",
      "Iter 3184 | Time 71.4432(73.9783) | Bit/dim 3.9097(3.9252) | Xent 0.2668(0.2726) | Loss 4.0431(4.0615) | Error 0.0923(0.0977) Steps 796(798.12) | Grad Norm 5.4914(4.1967) | Total Time 14.00(14.00)\n",
      "Iter 3185 | Time 73.8821(73.9755) | Bit/dim 3.9296(3.9253) | Xent 0.2653(0.2724) | Loss 4.0623(4.0615) | Error 0.0955(0.0977) Steps 796(798.06) | Grad Norm 3.8217(4.1855) | Total Time 14.00(14.00)\n",
      "Iter 3186 | Time 74.8098(74.0005) | Bit/dim 3.9245(3.9253) | Xent 0.2837(0.2727) | Loss 4.0663(4.0617) | Error 0.0980(0.0977) Steps 778(797.46) | Grad Norm 7.2646(4.2778) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0531 | Time 29.5095, Epoch Time 489.8191(489.5258), Bit/dim 3.9370(best: 3.9373), Xent 2.2604, Loss 5.0672, Error 0.4352(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3187 | Time 72.8212(73.9651) | Bit/dim 3.9301(3.9254) | Xent 0.2677(0.2726) | Loss 4.0640(4.0617) | Error 0.1006(0.0978) Steps 796(797.41) | Grad Norm 4.5177(4.2850) | Total Time 14.00(14.00)\n",
      "Iter 3188 | Time 72.9324(73.9341) | Bit/dim 3.9216(3.9253) | Xent 0.2574(0.2721) | Loss 4.0503(4.0614) | Error 0.0923(0.0976) Steps 802(797.55) | Grad Norm 3.2311(4.2534) | Total Time 14.00(14.00)\n",
      "Iter 3189 | Time 72.2430(73.8834) | Bit/dim 3.9210(3.9252) | Xent 0.2598(0.2717) | Loss 4.0509(4.0611) | Error 0.0945(0.0975) Steps 790(797.32) | Grad Norm 8.9644(4.3947) | Total Time 14.00(14.00)\n",
      "Iter 3190 | Time 72.0759(73.8292) | Bit/dim 3.9143(3.9249) | Xent 0.2782(0.2719) | Loss 4.0534(4.0608) | Error 0.1034(0.0977) Steps 796(797.28) | Grad Norm 7.4683(4.4870) | Total Time 14.00(14.00)\n",
      "Iter 3191 | Time 74.7663(73.8573) | Bit/dim 3.9286(3.9250) | Xent 0.2550(0.2714) | Loss 4.0561(4.0607) | Error 0.0885(0.0974) Steps 790(797.06) | Grad Norm 2.1837(4.4179) | Total Time 14.00(14.00)\n",
      "Iter 3192 | Time 76.1025(73.9246) | Bit/dim 3.9231(3.9249) | Xent 0.2533(0.2709) | Loss 4.0498(4.0604) | Error 0.0899(0.0972) Steps 796(797.03) | Grad Norm 4.5739(4.4225) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0532 | Time 29.2219, Epoch Time 485.6474(489.4094), Bit/dim 3.9373(best: 3.9370), Xent 2.2201, Loss 5.0474, Error 0.4347(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3193 | Time 71.6565(73.8566) | Bit/dim 3.9271(3.9250) | Xent 0.2624(0.2706) | Loss 4.0583(4.0603) | Error 0.0929(0.0970) Steps 796(797.00) | Grad Norm 4.2279(4.4167) | Total Time 14.00(14.00)\n",
      "Iter 3194 | Time 72.2377(73.8080) | Bit/dim 3.9155(3.9247) | Xent 0.2519(0.2701) | Loss 4.0414(4.0597) | Error 0.0913(0.0969) Steps 808(797.33) | Grad Norm 1.5035(4.3293) | Total Time 14.00(14.00)\n",
      "Iter 3195 | Time 73.3700(73.7949) | Bit/dim 3.9300(3.9249) | Xent 0.2659(0.2699) | Loss 4.0629(4.0598) | Error 0.0931(0.0968) Steps 796(797.29) | Grad Norm 4.5140(4.3348) | Total Time 14.00(14.00)\n",
      "Iter 3196 | Time 73.5207(73.7867) | Bit/dim 3.9214(3.9248) | Xent 0.2712(0.2700) | Loss 4.0571(4.0598) | Error 0.0964(0.0967) Steps 796(797.25) | Grad Norm 5.1660(4.3598) | Total Time 14.00(14.00)\n",
      "Iter 3197 | Time 71.7414(73.7253) | Bit/dim 3.9177(3.9245) | Xent 0.2579(0.2696) | Loss 4.0466(4.0594) | Error 0.0889(0.0965) Steps 796(797.22) | Grad Norm 3.7196(4.3406) | Total Time 14.00(14.00)\n",
      "Iter 3198 | Time 75.4214(73.7762) | Bit/dim 3.9220(3.9245) | Xent 0.2570(0.2692) | Loss 4.0505(4.0591) | Error 0.0917(0.0964) Steps 796(797.18) | Grad Norm 3.6703(4.3205) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0533 | Time 29.4904, Epoch Time 483.0326(489.2181), Bit/dim 3.9388(best: 3.9370), Xent 2.3136, Loss 5.0956, Error 0.4366(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3199 | Time 75.2122(73.8193) | Bit/dim 3.9346(3.9248) | Xent 0.2725(0.2693) | Loss 4.0708(4.0594) | Error 0.0975(0.0964) Steps 796(797.14) | Grad Norm 7.4379(4.4140) | Total Time 14.00(14.00)\n",
      "Iter 3200 | Time 75.9478(73.8831) | Bit/dim 3.9246(3.9248) | Xent 0.2600(0.2691) | Loss 4.0546(4.0593) | Error 0.0960(0.0964) Steps 790(796.93) | Grad Norm 4.8712(4.4277) | Total Time 14.00(14.00)\n",
      "Iter 3201 | Time 75.5304(73.9325) | Bit/dim 3.9197(3.9246) | Xent 0.2759(0.2693) | Loss 4.0577(4.0593) | Error 0.0980(0.0964) Steps 802(797.08) | Grad Norm 3.5134(4.4003) | Total Time 14.00(14.00)\n",
      "Iter 3202 | Time 73.6067(73.9228) | Bit/dim 3.9247(3.9246) | Xent 0.2487(0.2687) | Loss 4.0490(4.0589) | Error 0.0906(0.0963) Steps 802(797.23) | Grad Norm 6.4602(4.4621) | Total Time 14.00(14.00)\n",
      "Iter 3203 | Time 72.4205(73.8777) | Bit/dim 3.9179(3.9244) | Xent 0.2565(0.2683) | Loss 4.0462(4.0586) | Error 0.0929(0.0962) Steps 796(797.19) | Grad Norm 4.5254(4.4640) | Total Time 14.00(14.00)\n",
      "Iter 3204 | Time 75.2628(73.9193) | Bit/dim 3.9172(3.9242) | Xent 0.2597(0.2680) | Loss 4.0470(4.0582) | Error 0.0895(0.0960) Steps 802(797.34) | Grad Norm 5.5505(4.4966) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0534 | Time 29.1249, Epoch Time 492.5957(489.3194), Bit/dim 3.9366(best: 3.9370), Xent 2.2750, Loss 5.0741, Error 0.4390(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3205 | Time 72.6719(73.8818) | Bit/dim 3.9263(3.9243) | Xent 0.2745(0.2682) | Loss 4.0635(4.0584) | Error 0.0962(0.0960) Steps 796(797.30) | Grad Norm 10.6638(4.6816) | Total Time 14.00(14.00)\n",
      "Iter 3206 | Time 76.0137(73.9458) | Bit/dim 3.9208(3.9242) | Xent 0.2624(0.2680) | Loss 4.0520(4.0582) | Error 0.0920(0.0959) Steps 802(797.44) | Grad Norm 5.6225(4.7098) | Total Time 14.00(14.00)\n",
      "Iter 3207 | Time 74.4342(73.9604) | Bit/dim 3.9146(3.9239) | Xent 0.2544(0.2676) | Loss 4.0418(4.0577) | Error 0.0924(0.0957) Steps 796(797.39) | Grad Norm 3.6642(4.6784) | Total Time 14.00(14.00)\n",
      "Iter 3208 | Time 76.4101(74.0339) | Bit/dim 3.9256(3.9239) | Xent 0.2621(0.2675) | Loss 4.0567(4.0577) | Error 0.0920(0.0956) Steps 802(797.53) | Grad Norm 4.7727(4.6813) | Total Time 14.00(14.00)\n",
      "Iter 3209 | Time 72.9861(74.0025) | Bit/dim 3.9260(3.9240) | Xent 0.2811(0.2679) | Loss 4.0665(4.0579) | Error 0.1041(0.0959) Steps 784(797.13) | Grad Norm 7.4875(4.7655) | Total Time 14.00(14.00)\n",
      "Iter 3210 | Time 75.8818(74.0589) | Bit/dim 3.9157(3.9237) | Xent 0.2707(0.2680) | Loss 4.0510(4.0577) | Error 0.0951(0.0959) Steps 796(797.09) | Grad Norm 6.3716(4.8136) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0535 | Time 29.3762, Epoch Time 493.4004(489.4419), Bit/dim 3.9360(best: 3.9366), Xent 2.2638, Loss 5.0679, Error 0.4379(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3211 | Time 72.5230(74.0128) | Bit/dim 3.9249(3.9238) | Xent 0.2759(0.2682) | Loss 4.0629(4.0579) | Error 0.1009(0.0960) Steps 802(797.24) | Grad Norm 4.4573(4.8029) | Total Time 14.00(14.00)\n",
      "Iter 3212 | Time 73.9731(74.0116) | Bit/dim 3.9233(3.9238) | Xent 0.2681(0.2682) | Loss 4.0573(4.0579) | Error 0.0988(0.0961) Steps 790(797.02) | Grad Norm 6.0006(4.8389) | Total Time 14.00(14.00)\n",
      "Iter 3213 | Time 74.3661(74.0222) | Bit/dim 3.9180(3.9236) | Xent 0.2730(0.2683) | Loss 4.0545(4.0578) | Error 0.0970(0.0961) Steps 802(797.17) | Grad Norm 6.2315(4.8807) | Total Time 14.00(14.00)\n",
      "Iter 3214 | Time 78.2148(74.1480) | Bit/dim 3.9281(3.9237) | Xent 0.2496(0.2678) | Loss 4.0529(4.0576) | Error 0.0927(0.0960) Steps 802(797.32) | Grad Norm 2.0701(4.7963) | Total Time 14.00(14.00)\n",
      "Iter 3215 | Time 72.8972(74.1105) | Bit/dim 3.9167(3.9235) | Xent 0.2528(0.2673) | Loss 4.0431(4.0572) | Error 0.0914(0.0959) Steps 796(797.28) | Grad Norm 4.8827(4.7989) | Total Time 14.00(14.00)\n",
      "Iter 3216 | Time 73.1706(74.0823) | Bit/dim 3.9235(3.9235) | Xent 0.2614(0.2672) | Loss 4.0542(4.0571) | Error 0.0909(0.0957) Steps 808(797.60) | Grad Norm 2.3444(4.7253) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0536 | Time 29.2118, Epoch Time 489.9285(489.4565), Bit/dim 3.9362(best: 3.9360), Xent 2.2634, Loss 5.0679, Error 0.4343(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3217 | Time 75.7465(74.1322) | Bit/dim 3.9246(3.9235) | Xent 0.2758(0.2674) | Loss 4.0625(4.0572) | Error 0.0956(0.0957) Steps 790(797.37) | Grad Norm 4.0132(4.7039) | Total Time 14.00(14.00)\n",
      "Iter 3218 | Time 73.6597(74.1180) | Bit/dim 3.9104(3.9231) | Xent 0.2610(0.2672) | Loss 4.0409(4.0568) | Error 0.0950(0.0957) Steps 796(797.33) | Grad Norm 3.1492(4.6573) | Total Time 14.00(14.00)\n",
      "Iter 3219 | Time 72.5559(74.0712) | Bit/dim 3.9261(3.9232) | Xent 0.2646(0.2671) | Loss 4.0584(4.0568) | Error 0.0930(0.0956) Steps 802(797.47) | Grad Norm 2.1949(4.5834) | Total Time 14.00(14.00)\n",
      "Iter 3220 | Time 74.4277(74.0819) | Bit/dim 3.9222(3.9232) | Xent 0.2657(0.2671) | Loss 4.0550(4.0568) | Error 0.0923(0.0955) Steps 796(797.43) | Grad Norm 3.8063(4.5601) | Total Time 14.00(14.00)\n",
      "Iter 3221 | Time 76.1141(74.1428) | Bit/dim 3.9248(3.9233) | Xent 0.2514(0.2666) | Loss 4.0505(4.0566) | Error 0.0867(0.0953) Steps 796(797.38) | Grad Norm 4.1499(4.5478) | Total Time 14.00(14.00)\n",
      "Iter 3222 | Time 73.3102(74.1179) | Bit/dim 3.9203(3.9232) | Xent 0.2582(0.2664) | Loss 4.0494(4.0564) | Error 0.0952(0.0953) Steps 802(797.52) | Grad Norm 4.3682(4.5424) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0537 | Time 29.6420, Epoch Time 490.9632(489.5017), Bit/dim 3.9362(best: 3.9360), Xent 2.3192, Loss 5.0958, Error 0.4407(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3223 | Time 72.5625(74.0712) | Bit/dim 3.9263(3.9233) | Xent 0.2582(0.2661) | Loss 4.0554(4.0563) | Error 0.0911(0.0951) Steps 796(797.48) | Grad Norm 5.0714(4.5583) | Total Time 14.00(14.00)\n",
      "Iter 3224 | Time 75.6708(74.1192) | Bit/dim 3.9218(3.9232) | Xent 0.2672(0.2662) | Loss 4.0554(4.0563) | Error 0.0988(0.0952) Steps 790(797.25) | Grad Norm 6.5307(4.6175) | Total Time 14.00(14.00)\n",
      "Iter 3225 | Time 76.9127(74.2030) | Bit/dim 3.9235(3.9232) | Xent 0.2563(0.2659) | Loss 4.0517(4.0562) | Error 0.0941(0.0952) Steps 802(797.39) | Grad Norm 2.3152(4.5484) | Total Time 14.00(14.00)\n",
      "Iter 3226 | Time 73.1714(74.1721) | Bit/dim 3.9237(3.9232) | Xent 0.2449(0.2652) | Loss 4.0461(4.0559) | Error 0.0875(0.0950) Steps 814(797.89) | Grad Norm 7.8353(4.6470) | Total Time 14.00(14.00)\n",
      "Iter 3227 | Time 76.0822(74.2294) | Bit/dim 3.9171(3.9230) | Xent 0.2642(0.2652) | Loss 4.0491(4.0557) | Error 0.0960(0.0950) Steps 796(797.84) | Grad Norm 6.5221(4.7033) | Total Time 14.00(14.00)\n",
      "Iter 3228 | Time 74.6201(74.2411) | Bit/dim 3.9179(3.9229) | Xent 0.2604(0.2651) | Loss 4.0481(4.0554) | Error 0.0929(0.0949) Steps 802(797.96) | Grad Norm 3.5465(4.6685) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0538 | Time 29.0530, Epoch Time 494.0025(489.6367), Bit/dim 3.9359(best: 3.9360), Xent 2.2837, Loss 5.0777, Error 0.4334(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3229 | Time 76.7049(74.3150) | Bit/dim 3.9316(3.9232) | Xent 0.2643(0.2650) | Loss 4.0638(4.0557) | Error 0.0921(0.0949) Steps 796(797.90) | Grad Norm 3.5139(4.6339) | Total Time 14.00(14.00)\n",
      "Iter 3230 | Time 74.7003(74.3266) | Bit/dim 3.9215(3.9231) | Xent 0.2526(0.2647) | Loss 4.0478(4.0554) | Error 0.0933(0.0948) Steps 796(797.84) | Grad Norm 2.9407(4.5831) | Total Time 14.00(14.00)\n",
      "Iter 3231 | Time 75.4535(74.3604) | Bit/dim 3.9198(3.9230) | Xent 0.2311(0.2637) | Loss 4.0353(4.0548) | Error 0.0827(0.0945) Steps 802(797.97) | Grad Norm 2.0207(4.5062) | Total Time 14.00(14.00)\n",
      "Iter 3232 | Time 74.8196(74.3741) | Bit/dim 3.9135(3.9227) | Xent 0.2555(0.2634) | Loss 4.0413(4.0544) | Error 0.0901(0.0943) Steps 808(798.27) | Grad Norm 2.8923(4.4578) | Total Time 14.00(14.00)\n",
      "Iter 3233 | Time 75.8225(74.4176) | Bit/dim 3.9151(3.9225) | Xent 0.2636(0.2634) | Loss 4.0469(4.0542) | Error 0.0959(0.0944) Steps 802(798.38) | Grad Norm 3.6028(4.4322) | Total Time 14.00(14.00)\n",
      "Iter 3234 | Time 75.7311(74.4570) | Bit/dim 3.9315(3.9228) | Xent 0.2544(0.2632) | Loss 4.0587(4.0543) | Error 0.0901(0.0942) Steps 802(798.49) | Grad Norm 3.2115(4.3956) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0539 | Time 29.6083, Epoch Time 498.7324(489.9096), Bit/dim 3.9356(best: 3.9359), Xent 2.2996, Loss 5.0854, Error 0.4408(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3235 | Time 75.1339(74.4773) | Bit/dim 3.9244(3.9228) | Xent 0.2591(0.2630) | Loss 4.0539(4.0543) | Error 0.0921(0.0942) Steps 784(798.06) | Grad Norm 5.3413(4.4239) | Total Time 14.00(14.00)\n",
      "Iter 3236 | Time 79.0856(74.6156) | Bit/dim 3.9174(3.9227) | Xent 0.2536(0.2627) | Loss 4.0442(4.0540) | Error 0.0909(0.0941) Steps 796(797.99) | Grad Norm 4.0804(4.4136) | Total Time 14.00(14.00)\n",
      "Iter 3237 | Time 74.1598(74.6019) | Bit/dim 3.9227(3.9227) | Xent 0.2547(0.2625) | Loss 4.0500(4.0539) | Error 0.0927(0.0940) Steps 796(797.93) | Grad Norm 3.4457(4.3846) | Total Time 14.00(14.00)\n",
      "Iter 3238 | Time 75.5436(74.6301) | Bit/dim 3.9206(3.9226) | Xent 0.2613(0.2625) | Loss 4.0513(4.0538) | Error 0.0899(0.0939) Steps 796(797.88) | Grad Norm 6.0961(4.4359) | Total Time 14.00(14.00)\n",
      "Iter 3239 | Time 74.0189(74.6118) | Bit/dim 3.9190(3.9225) | Xent 0.2503(0.2621) | Loss 4.0441(4.0535) | Error 0.0871(0.0937) Steps 802(798.00) | Grad Norm 1.9292(4.3607) | Total Time 14.00(14.00)\n",
      "Iter 3240 | Time 72.2988(74.5424) | Bit/dim 3.9208(3.9224) | Xent 0.2547(0.2619) | Loss 4.0481(4.0534) | Error 0.0885(0.0936) Steps 802(798.12) | Grad Norm 4.7329(4.3719) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0540 | Time 29.6956, Epoch Time 495.5634(490.0792), Bit/dim 3.9344(best: 3.9356), Xent 2.3083, Loss 5.0886, Error 0.4396(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3241 | Time 75.3394(74.5663) | Bit/dim 3.9129(3.9221) | Xent 0.2566(0.2617) | Loss 4.0412(4.0530) | Error 0.0906(0.0935) Steps 796(798.06) | Grad Norm 4.3051(4.3699) | Total Time 14.00(14.00)\n",
      "Iter 3242 | Time 73.2773(74.5276) | Bit/dim 3.9241(3.9222) | Xent 0.2646(0.2618) | Loss 4.0564(4.0531) | Error 0.0981(0.0936) Steps 796(797.99) | Grad Norm 2.2244(4.3055) | Total Time 14.00(14.00)\n",
      "Iter 3243 | Time 74.4697(74.5259) | Bit/dim 3.9163(3.9220) | Xent 0.2615(0.2618) | Loss 4.0471(4.0529) | Error 0.0914(0.0935) Steps 802(798.11) | Grad Norm 2.6739(4.2566) | Total Time 14.00(14.00)\n",
      "Iter 3244 | Time 75.1072(74.5433) | Bit/dim 3.9146(3.9218) | Xent 0.2574(0.2617) | Loss 4.0433(4.0526) | Error 0.0894(0.0934) Steps 802(798.23) | Grad Norm 3.1832(4.2244) | Total Time 14.00(14.00)\n",
      "Iter 3245 | Time 75.9073(74.5843) | Bit/dim 3.9268(3.9220) | Xent 0.2482(0.2613) | Loss 4.0509(4.0526) | Error 0.0909(0.0933) Steps 802(798.34) | Grad Norm 1.7803(4.1511) | Total Time 14.00(14.00)\n",
      "Iter 3246 | Time 73.7643(74.5597) | Bit/dim 3.9297(3.9222) | Xent 0.2660(0.2614) | Loss 4.0627(4.0529) | Error 0.0965(0.0934) Steps 802(798.45) | Grad Norm 5.6207(4.1951) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0541 | Time 29.3395, Epoch Time 492.9526(490.1654), Bit/dim 3.9354(best: 3.9344), Xent 2.3131, Loss 5.0919, Error 0.4321(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3247 | Time 74.4846(74.5574) | Bit/dim 3.9219(3.9222) | Xent 0.2464(0.2610) | Loss 4.0451(4.0527) | Error 0.0901(0.0933) Steps 796(798.38) | Grad Norm 5.5598(4.2361) | Total Time 14.00(14.00)\n",
      "Iter 3248 | Time 74.9280(74.5685) | Bit/dim 3.9228(3.9222) | Xent 0.2538(0.2607) | Loss 4.0497(4.0526) | Error 0.0906(0.0933) Steps 802(798.49) | Grad Norm 2.1691(4.1741) | Total Time 14.00(14.00)\n",
      "Iter 3249 | Time 76.7513(74.6340) | Bit/dim 3.9212(3.9222) | Xent 0.2570(0.2606) | Loss 4.0497(4.0525) | Error 0.0884(0.0931) Steps 802(798.59) | Grad Norm 6.0592(4.2306) | Total Time 14.00(14.00)\n",
      "Iter 3250 | Time 73.1570(74.5897) | Bit/dim 3.9203(3.9221) | Xent 0.2417(0.2601) | Loss 4.0412(4.0521) | Error 0.0830(0.0928) Steps 796(798.52) | Grad Norm 4.0130(4.2241) | Total Time 14.00(14.00)\n",
      "Iter 3251 | Time 73.6067(74.5602) | Bit/dim 3.9133(3.9218) | Xent 0.2668(0.2603) | Loss 4.0467(4.0520) | Error 0.0961(0.0929) Steps 802(798.62) | Grad Norm 3.2454(4.1947) | Total Time 14.00(14.00)\n",
      "Iter 3252 | Time 74.4433(74.5567) | Bit/dim 3.9245(3.9219) | Xent 0.2499(0.2600) | Loss 4.0495(4.0519) | Error 0.0897(0.0928) Steps 802(798.72) | Grad Norm 3.1240(4.1626) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0542 | Time 29.9309, Epoch Time 492.8823(490.2469), Bit/dim 3.9350(best: 3.9344), Xent 2.3705, Loss 5.1203, Error 0.4371(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3253 | Time 71.3274(74.4598) | Bit/dim 3.9234(3.9220) | Xent 0.2415(0.2594) | Loss 4.0442(4.0517) | Error 0.0880(0.0927) Steps 802(798.82) | Grad Norm 2.7254(4.1195) | Total Time 14.00(14.00)\n",
      "Iter 3254 | Time 76.4160(74.5185) | Bit/dim 3.9159(3.9218) | Xent 0.2497(0.2591) | Loss 4.0407(4.0513) | Error 0.0936(0.0927) Steps 796(798.74) | Grad Norm 3.0013(4.0860) | Total Time 14.00(14.00)\n",
      "Iter 3255 | Time 75.4423(74.5462) | Bit/dim 3.9188(3.9217) | Xent 0.2476(0.2588) | Loss 4.0425(4.0511) | Error 0.0840(0.0924) Steps 802(798.83) | Grad Norm 3.7195(4.0750) | Total Time 14.00(14.00)\n",
      "Iter 3256 | Time 73.4855(74.5144) | Bit/dim 3.9230(3.9217) | Xent 0.2609(0.2588) | Loss 4.0535(4.0512) | Error 0.0899(0.0924) Steps 808(799.11) | Grad Norm 2.5241(4.0284) | Total Time 14.00(14.00)\n",
      "Iter 3257 | Time 74.8555(74.5246) | Bit/dim 3.9165(3.9216) | Xent 0.2543(0.2587) | Loss 4.0436(4.0509) | Error 0.0896(0.0923) Steps 802(799.20) | Grad Norm 2.9974(3.9975) | Total Time 14.00(14.00)\n",
      "Iter 3258 | Time 74.4102(74.5212) | Bit/dim 3.9208(3.9216) | Xent 0.2504(0.2584) | Loss 4.0460(4.0508) | Error 0.0899(0.0922) Steps 796(799.10) | Grad Norm 4.3078(4.0068) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0543 | Time 29.5649, Epoch Time 491.0631(490.2714), Bit/dim 3.9356(best: 3.9344), Xent 2.3595, Loss 5.1154, Error 0.4429(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3259 | Time 74.1286(74.5094) | Bit/dim 3.9189(3.9215) | Xent 0.2526(0.2583) | Loss 4.0452(4.0506) | Error 0.0924(0.0922) Steps 802(799.19) | Grad Norm 9.4996(4.1716) | Total Time 14.00(14.00)\n",
      "Iter 3260 | Time 74.1504(74.4986) | Bit/dim 3.9183(3.9214) | Xent 0.2515(0.2581) | Loss 4.0441(4.0504) | Error 0.0907(0.0922) Steps 802(799.27) | Grad Norm 6.1148(4.2299) | Total Time 14.00(14.00)\n",
      "Iter 3261 | Time 74.9725(74.5129) | Bit/dim 3.9130(3.9211) | Xent 0.2524(0.2579) | Loss 4.0392(4.0501) | Error 0.0914(0.0921) Steps 802(799.35) | Grad Norm 4.7571(4.2457) | Total Time 14.00(14.00)\n",
      "Iter 3262 | Time 74.2401(74.5047) | Bit/dim 3.9159(3.9210) | Xent 0.2607(0.2580) | Loss 4.0462(4.0500) | Error 0.0920(0.0921) Steps 796(799.25) | Grad Norm 4.7487(4.2608) | Total Time 14.00(14.00)\n",
      "Iter 3263 | Time 74.4736(74.5037) | Bit/dim 3.9194(3.9209) | Xent 0.2482(0.2577) | Loss 4.0435(4.0498) | Error 0.0879(0.0920) Steps 790(798.98) | Grad Norm 4.6314(4.2719) | Total Time 14.00(14.00)\n",
      "Iter 3264 | Time 74.7387(74.5108) | Bit/dim 3.9371(3.9214) | Xent 0.2555(0.2576) | Loss 4.0649(4.0502) | Error 0.0909(0.0920) Steps 808(799.25) | Grad Norm 2.9644(4.2327) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0544 | Time 29.5122, Epoch Time 491.7090(490.3145), Bit/dim 3.9343(best: 3.9344), Xent 2.3452, Loss 5.1069, Error 0.4407(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3265 | Time 73.9677(74.4945) | Bit/dim 3.9181(3.9213) | Xent 0.2806(0.2583) | Loss 4.0585(4.0505) | Error 0.1001(0.0922) Steps 802(799.33) | Grad Norm 8.5125(4.3611) | Total Time 14.00(14.00)\n",
      "Iter 3266 | Time 75.1930(74.5155) | Bit/dim 3.9171(3.9212) | Xent 0.2519(0.2581) | Loss 4.0431(4.0502) | Error 0.0910(0.0922) Steps 802(799.41) | Grad Norm 11.4805(4.5747) | Total Time 14.00(14.00)\n",
      "Iter 3267 | Time 74.0616(74.5018) | Bit/dim 3.9237(3.9213) | Xent 0.2772(0.2587) | Loss 4.0623(4.0506) | Error 0.1022(0.0925) Steps 802(799.49) | Grad Norm 8.5308(4.6934) | Total Time 14.00(14.00)\n",
      "Iter 3268 | Time 74.5783(74.5041) | Bit/dim 3.9163(3.9211) | Xent 0.2461(0.2583) | Loss 4.0394(4.0503) | Error 0.0886(0.0924) Steps 796(799.38) | Grad Norm 3.9533(4.6711) | Total Time 14.00(14.00)\n",
      "Iter 3269 | Time 71.6033(74.4171) | Bit/dim 3.9199(3.9211) | Xent 0.2577(0.2583) | Loss 4.0488(4.0502) | Error 0.0949(0.0924) Steps 790(799.10) | Grad Norm 5.1324(4.6850) | Total Time 14.00(14.00)\n",
      "Iter 3270 | Time 72.7903(74.3683) | Bit/dim 3.9253(3.9212) | Xent 0.2577(0.2583) | Loss 4.0541(4.0503) | Error 0.0914(0.0924) Steps 802(799.19) | Grad Norm 5.3437(4.7047) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0545 | Time 29.7998, Epoch Time 487.6854(490.2356), Bit/dim 3.9334(best: 3.9343), Xent 2.3145, Loss 5.0906, Error 0.4400(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3271 | Time 74.8152(74.3817) | Bit/dim 3.9184(3.9211) | Xent 0.2519(0.2581) | Loss 4.0444(4.0502) | Error 0.0917(0.0924) Steps 790(798.91) | Grad Norm 5.0900(4.7163) | Total Time 14.00(14.00)\n",
      "Iter 3272 | Time 73.3125(74.3496) | Bit/dim 3.9106(3.9208) | Xent 0.2712(0.2585) | Loss 4.0463(4.0500) | Error 0.0969(0.0925) Steps 784(798.46) | Grad Norm 8.3561(4.8255) | Total Time 14.00(14.00)\n",
      "Iter 3273 | Time 73.7004(74.3302) | Bit/dim 3.9356(3.9213) | Xent 0.2725(0.2589) | Loss 4.0719(4.0507) | Error 0.0968(0.0927) Steps 796(798.39) | Grad Norm 6.8478(4.8862) | Total Time 14.00(14.00)\n",
      "Iter 3274 | Time 72.1936(74.2661) | Bit/dim 3.9165(3.9211) | Xent 0.2574(0.2589) | Loss 4.0452(4.0505) | Error 0.0920(0.0926) Steps 790(798.14) | Grad Norm 8.2398(4.9868) | Total Time 14.00(14.00)\n",
      "Iter 3275 | Time 75.9467(74.3165) | Bit/dim 3.9132(3.9209) | Xent 0.2454(0.2585) | Loss 4.0359(4.0501) | Error 0.0881(0.0925) Steps 790(797.89) | Grad Norm 4.6918(4.9779) | Total Time 14.00(14.00)\n",
      "Iter 3276 | Time 74.1314(74.3109) | Bit/dim 3.9218(3.9209) | Xent 0.2422(0.2580) | Loss 4.0429(4.0499) | Error 0.0883(0.0924) Steps 802(798.02) | Grad Norm 8.4772(5.0829) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0546 | Time 29.5754, Epoch Time 489.1630(490.2034), Bit/dim 3.9343(best: 3.9334), Xent 2.3429, Loss 5.1057, Error 0.4397(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3277 | Time 74.2751(74.3099) | Bit/dim 3.9292(3.9211) | Xent 0.2556(0.2579) | Loss 4.0570(4.0501) | Error 0.0897(0.0923) Steps 808(798.32) | Grad Norm 6.5559(5.1271) | Total Time 14.00(14.00)\n",
      "Iter 3278 | Time 72.4105(74.2529) | Bit/dim 3.9101(3.9208) | Xent 0.2523(0.2577) | Loss 4.0363(4.0497) | Error 0.0855(0.0921) Steps 802(798.43) | Grad Norm 6.6251(5.1720) | Total Time 14.00(14.00)\n",
      "Iter 3279 | Time 73.4510(74.2288) | Bit/dim 3.9197(3.9208) | Xent 0.2643(0.2579) | Loss 4.0519(4.0497) | Error 0.0949(0.0922) Steps 802(798.53) | Grad Norm 7.6437(5.2462) | Total Time 14.00(14.00)\n",
      "Iter 3280 | Time 74.7447(74.2443) | Bit/dim 3.9108(3.9205) | Xent 0.2463(0.2576) | Loss 4.0340(4.0493) | Error 0.0864(0.0920) Steps 796(798.46) | Grad Norm 4.7621(5.2317) | Total Time 14.00(14.00)\n",
      "Iter 3281 | Time 73.8965(74.2339) | Bit/dim 3.9209(3.9205) | Xent 0.2547(0.2575) | Loss 4.0482(4.0492) | Error 0.0891(0.0919) Steps 796(798.38) | Grad Norm 10.3759(5.3860) | Total Time 14.00(14.00)\n",
      "Iter 3282 | Time 74.7919(74.2506) | Bit/dim 3.9304(3.9208) | Xent 0.2543(0.2574) | Loss 4.0576(4.0495) | Error 0.0877(0.0918) Steps 814(798.85) | Grad Norm 7.7001(5.4554) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0547 | Time 29.5363, Epoch Time 488.9460(490.1657), Bit/dim 3.9336(best: 3.9334), Xent 2.3628, Loss 5.1150, Error 0.4388(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3283 | Time 74.5727(74.2603) | Bit/dim 3.9224(3.9208) | Xent 0.2480(0.2571) | Loss 4.0465(4.0494) | Error 0.0900(0.0917) Steps 802(798.95) | Grad Norm 3.3046(5.3909) | Total Time 14.00(14.00)\n",
      "Iter 3284 | Time 74.0860(74.2550) | Bit/dim 3.9268(3.9210) | Xent 0.2457(0.2568) | Loss 4.0496(4.0494) | Error 0.0881(0.0916) Steps 802(799.04) | Grad Norm 3.7628(5.3420) | Total Time 14.00(14.00)\n",
      "Iter 3285 | Time 75.3171(74.2869) | Bit/dim 3.9140(3.9208) | Xent 0.2643(0.2570) | Loss 4.0461(4.0493) | Error 0.0979(0.0918) Steps 802(799.13) | Grad Norm 4.4623(5.3157) | Total Time 14.00(14.00)\n",
      "Iter 3286 | Time 75.2192(74.3149) | Bit/dim 3.9162(3.9207) | Xent 0.2542(0.2569) | Loss 4.0433(4.0491) | Error 0.0876(0.0917) Steps 790(798.85) | Grad Norm 5.1483(5.3106) | Total Time 14.00(14.00)\n",
      "Iter 3287 | Time 72.7262(74.2672) | Bit/dim 3.9166(3.9206) | Xent 0.2443(0.2565) | Loss 4.0388(4.0488) | Error 0.0865(0.0915) Steps 796(798.77) | Grad Norm 3.6592(5.2611) | Total Time 14.00(14.00)\n",
      "Iter 3288 | Time 76.1573(74.3239) | Bit/dim 3.9134(3.9203) | Xent 0.2520(0.2564) | Loss 4.0394(4.0485) | Error 0.0901(0.0915) Steps 802(798.87) | Grad Norm 5.9872(5.2829) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0548 | Time 29.5116, Epoch Time 492.8862(490.2473), Bit/dim 3.9333(best: 3.9334), Xent 2.2966, Loss 5.0816, Error 0.4372(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3289 | Time 74.3309(74.3241) | Bit/dim 3.9216(3.9204) | Xent 0.2467(0.2561) | Loss 4.0449(4.0484) | Error 0.0884(0.0914) Steps 802(798.96) | Grad Norm 4.6235(5.2631) | Total Time 14.00(14.00)\n",
      "Iter 3290 | Time 73.6035(74.3025) | Bit/dim 3.9147(3.9202) | Xent 0.2406(0.2556) | Loss 4.0350(4.0480) | Error 0.0866(0.0913) Steps 808(799.23) | Grad Norm 2.8568(5.1909) | Total Time 14.00(14.00)\n",
      "Iter 3291 | Time 73.1446(74.2678) | Bit/dim 3.9141(3.9200) | Xent 0.2453(0.2553) | Loss 4.0368(4.0477) | Error 0.0855(0.0911) Steps 796(799.13) | Grad Norm 3.1940(5.1310) | Total Time 14.00(14.00)\n",
      "Iter 3292 | Time 72.1153(74.2032) | Bit/dim 3.9195(3.9200) | Xent 0.2499(0.2552) | Loss 4.0445(4.0476) | Error 0.0893(0.0910) Steps 796(799.04) | Grad Norm 2.8040(5.0612) | Total Time 14.00(14.00)\n",
      "Iter 3293 | Time 74.5540(74.2137) | Bit/dim 3.9195(3.9200) | Xent 0.2384(0.2547) | Loss 4.0387(4.0473) | Error 0.0835(0.0908) Steps 802(799.13) | Grad Norm 2.2992(4.9783) | Total Time 14.00(14.00)\n",
      "Iter 3294 | Time 76.7842(74.2908) | Bit/dim 3.9215(3.9200) | Xent 0.2492(0.2545) | Loss 4.0461(4.0473) | Error 0.0876(0.0907) Steps 796(799.03) | Grad Norm 2.9116(4.9163) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0549 | Time 29.5145, Epoch Time 489.4737(490.2241), Bit/dim 3.9328(best: 3.9333), Xent 2.3288, Loss 5.0972, Error 0.4358(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3295 | Time 72.1446(74.2264) | Bit/dim 3.9306(3.9204) | Xent 0.2398(0.2541) | Loss 4.0505(4.0474) | Error 0.0863(0.0906) Steps 790(798.76) | Grad Norm 2.2361(4.8359) | Total Time 14.00(14.00)\n",
      "Iter 3296 | Time 72.9775(74.1890) | Bit/dim 3.9114(3.9201) | Xent 0.2442(0.2538) | Loss 4.0335(4.0470) | Error 0.0884(0.0905) Steps 796(798.68) | Grad Norm 3.3594(4.7916) | Total Time 14.00(14.00)\n",
      "Iter 3297 | Time 74.4502(74.1968) | Bit/dim 3.9232(3.9202) | Xent 0.2274(0.2530) | Loss 4.0369(4.0467) | Error 0.0835(0.0903) Steps 796(798.60) | Grad Norm 3.6258(4.7566) | Total Time 14.00(14.00)\n",
      "Iter 3298 | Time 74.8968(74.2178) | Bit/dim 3.9069(3.9198) | Xent 0.2623(0.2533) | Loss 4.0380(4.0464) | Error 0.0920(0.0903) Steps 814(799.06) | Grad Norm 5.5609(4.7808) | Total Time 14.00(14.00)\n",
      "Iter 3299 | Time 74.7900(74.2350) | Bit/dim 3.9163(3.9197) | Xent 0.2485(0.2531) | Loss 4.0406(4.0462) | Error 0.0849(0.0902) Steps 796(798.97) | Grad Norm 5.6515(4.8069) | Total Time 14.00(14.00)\n",
      "Iter 3300 | Time 72.5474(74.1843) | Bit/dim 3.9181(3.9196) | Xent 0.2502(0.2530) | Loss 4.0432(4.0461) | Error 0.0916(0.0902) Steps 808(799.24) | Grad Norm 7.4100(4.8850) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0550 | Time 29.7995, Epoch Time 487.3181(490.1369), Bit/dim 3.9324(best: 3.9328), Xent 2.3544, Loss 5.1096, Error 0.4378(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3301 | Time 74.8102(74.2031) | Bit/dim 3.9193(3.9196) | Xent 0.2553(0.2531) | Loss 4.0470(4.0462) | Error 0.0901(0.0902) Steps 808(799.50) | Grad Norm 5.0564(4.8901) | Total Time 14.00(14.00)\n",
      "Iter 3302 | Time 72.2552(74.1447) | Bit/dim 3.9213(3.9197) | Xent 0.2418(0.2528) | Loss 4.0422(4.0460) | Error 0.0875(0.0901) Steps 808(799.76) | Grad Norm 3.7591(4.8562) | Total Time 14.00(14.00)\n",
      "Iter 3303 | Time 75.6535(74.1899) | Bit/dim 3.9098(3.9194) | Xent 0.2380(0.2523) | Loss 4.0288(4.0455) | Error 0.0865(0.0900) Steps 802(799.83) | Grad Norm 5.8830(4.8870) | Total Time 14.00(14.00)\n",
      "Iter 3304 | Time 75.4254(74.2270) | Bit/dim 3.9247(3.9195) | Xent 0.2659(0.2527) | Loss 4.0576(4.0459) | Error 0.0945(0.0902) Steps 796(799.71) | Grad Norm 10.0404(5.0416) | Total Time 14.00(14.00)\n",
      "Iter 3305 | Time 76.0454(74.2816) | Bit/dim 3.9136(3.9194) | Xent 0.2711(0.2533) | Loss 4.0492(4.0460) | Error 0.0976(0.0904) Steps 808(799.96) | Grad Norm 9.8169(5.1849) | Total Time 14.00(14.00)\n",
      "Iter 3306 | Time 74.6238(74.2918) | Bit/dim 3.9143(3.9192) | Xent 0.2396(0.2529) | Loss 4.0341(4.0456) | Error 0.0787(0.0900) Steps 784(799.48) | Grad Norm 4.5852(5.1669) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0551 | Time 29.3570, Epoch Time 493.6156(490.2413), Bit/dim 3.9324(best: 3.9324), Xent 2.3418, Loss 5.1033, Error 0.4379(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3307 | Time 75.3442(74.3234) | Bit/dim 3.9197(3.9192) | Xent 0.2360(0.2524) | Loss 4.0377(4.0454) | Error 0.0867(0.0899) Steps 802(799.56) | Grad Norm 5.3850(5.1734) | Total Time 14.00(14.00)\n",
      "Iter 3308 | Time 75.8785(74.3701) | Bit/dim 3.9088(3.9189) | Xent 0.2584(0.2525) | Loss 4.0380(4.0452) | Error 0.0924(0.0900) Steps 802(799.63) | Grad Norm 10.0070(5.3184) | Total Time 14.00(14.00)\n",
      "Iter 3309 | Time 72.3084(74.3082) | Bit/dim 3.9117(3.9187) | Xent 0.2628(0.2528) | Loss 4.0431(4.0451) | Error 0.0956(0.0902) Steps 796(799.52) | Grad Norm 7.4112(5.3812) | Total Time 14.00(14.00)\n",
      "Iter 3310 | Time 71.9286(74.2368) | Bit/dim 3.9192(3.9187) | Xent 0.2428(0.2525) | Loss 4.0406(4.0450) | Error 0.0837(0.0900) Steps 802(799.60) | Grad Norm 2.5197(5.2954) | Total Time 14.00(14.00)\n",
      "Iter 3311 | Time 74.5587(74.2465) | Bit/dim 3.9210(3.9188) | Xent 0.2397(0.2522) | Loss 4.0409(4.0449) | Error 0.0863(0.0899) Steps 808(799.85) | Grad Norm 5.7491(5.3090) | Total Time 14.00(14.00)\n",
      "Iter 3312 | Time 72.7122(74.2004) | Bit/dim 3.9216(3.9189) | Xent 0.2669(0.2526) | Loss 4.0550(4.0452) | Error 0.0952(0.0900) Steps 790(799.55) | Grad Norm 7.4363(5.3728) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0552 | Time 29.4067, Epoch Time 487.6274(490.1629), Bit/dim 3.9313(best: 3.9324), Xent 2.3510, Loss 5.1068, Error 0.4408(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3313 | Time 75.7905(74.2482) | Bit/dim 3.9051(3.9184) | Xent 0.2432(0.2523) | Loss 4.0267(4.0446) | Error 0.0907(0.0901) Steps 796(799.45) | Grad Norm 4.3111(5.3409) | Total Time 14.00(14.00)\n",
      "Iter 3314 | Time 75.0149(74.2712) | Bit/dim 3.9200(3.9185) | Xent 0.2440(0.2521) | Loss 4.0420(4.0445) | Error 0.0884(0.0900) Steps 790(799.16) | Grad Norm 5.2969(5.3396) | Total Time 14.00(14.00)\n",
      "Iter 3315 | Time 77.8871(74.3796) | Bit/dim 3.9175(3.9185) | Xent 0.2648(0.2525) | Loss 4.0499(4.0447) | Error 0.0961(0.0902) Steps 796(799.07) | Grad Norm 8.4755(5.4337) | Total Time 14.00(14.00)\n",
      "Iter 3316 | Time 74.2173(74.3748) | Bit/dim 3.9189(3.9185) | Xent 0.2425(0.2522) | Loss 4.0401(4.0446) | Error 0.0833(0.0900) Steps 808(799.34) | Grad Norm 3.7492(5.3832) | Total Time 14.00(14.00)\n",
      "Iter 3317 | Time 71.8652(74.2995) | Bit/dim 3.9179(3.9185) | Xent 0.2438(0.2519) | Loss 4.0398(4.0444) | Error 0.0870(0.0899) Steps 796(799.24) | Grad Norm 5.3438(5.3820) | Total Time 14.00(14.00)\n",
      "Iter 3318 | Time 72.3100(74.2398) | Bit/dim 3.9209(3.9185) | Xent 0.2340(0.2514) | Loss 4.0379(4.0442) | Error 0.0836(0.0897) Steps 802(799.32) | Grad Norm 5.0436(5.3718) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0553 | Time 29.5907, Epoch Time 492.4740(490.2322), Bit/dim 3.9313(best: 3.9313), Xent 2.3215, Loss 5.0920, Error 0.4333(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3319 | Time 74.8123(74.2570) | Bit/dim 3.9089(3.9182) | Xent 0.2372(0.2509) | Loss 4.0275(4.0437) | Error 0.0873(0.0896) Steps 802(799.40) | Grad Norm 4.1463(5.3351) | Total Time 14.00(14.00)\n",
      "Iter 3320 | Time 77.3169(74.3488) | Bit/dim 3.9268(3.9185) | Xent 0.2542(0.2510) | Loss 4.0539(4.0440) | Error 0.0889(0.0896) Steps 796(799.30) | Grad Norm 5.4792(5.3394) | Total Time 14.00(14.00)\n",
      "Iter 3321 | Time 74.6424(74.3576) | Bit/dim 3.9150(3.9184) | Xent 0.2488(0.2510) | Loss 4.0394(4.0439) | Error 0.0850(0.0895) Steps 802(799.38) | Grad Norm 6.0801(5.3616) | Total Time 14.00(14.00)\n",
      "Iter 3322 | Time 74.2611(74.3547) | Bit/dim 3.9235(3.9185) | Xent 0.2354(0.2505) | Loss 4.0412(4.0438) | Error 0.0833(0.0893) Steps 790(799.10) | Grad Norm 2.1764(5.2661) | Total Time 14.00(14.00)\n",
      "Iter 3323 | Time 73.7202(74.3356) | Bit/dim 3.9114(3.9183) | Xent 0.2506(0.2505) | Loss 4.0367(4.0436) | Error 0.0895(0.0893) Steps 808(799.36) | Grad Norm 8.0729(5.3503) | Total Time 14.00(14.00)\n",
      "Iter 3324 | Time 74.0141(74.3260) | Bit/dim 3.9146(3.9182) | Xent 0.2553(0.2507) | Loss 4.0423(4.0435) | Error 0.0875(0.0892) Steps 808(799.62) | Grad Norm 9.2261(5.4665) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0554 | Time 29.6849, Epoch Time 493.8882(490.3419), Bit/dim 3.9321(best: 3.9313), Xent 2.3765, Loss 5.1203, Error 0.4386(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3325 | Time 74.4902(74.3309) | Bit/dim 3.9096(3.9180) | Xent 0.2409(0.2504) | Loss 4.0300(4.0431) | Error 0.0899(0.0893) Steps 802(799.69) | Grad Norm 4.8725(5.4487) | Total Time 14.00(14.00)\n",
      "Iter 3326 | Time 75.0692(74.3531) | Bit/dim 3.9208(3.9180) | Xent 0.2352(0.2499) | Loss 4.0384(4.0430) | Error 0.0854(0.0891) Steps 808(799.94) | Grad Norm 4.0734(5.4075) | Total Time 14.00(14.00)\n",
      "Iter 3327 | Time 74.6060(74.3607) | Bit/dim 3.9194(3.9181) | Xent 0.2437(0.2497) | Loss 4.0412(4.0429) | Error 0.0854(0.0890) Steps 796(799.83) | Grad Norm 7.0833(5.4577) | Total Time 14.00(14.00)\n",
      "Iter 3328 | Time 74.2989(74.3588) | Bit/dim 3.9164(3.9180) | Xent 0.2347(0.2493) | Loss 4.0337(4.0427) | Error 0.0843(0.0889) Steps 790(799.53) | Grad Norm 2.5365(5.3701) | Total Time 14.00(14.00)\n",
      "Iter 3329 | Time 75.5187(74.3936) | Bit/dim 3.9157(3.9180) | Xent 0.2442(0.2491) | Loss 4.0378(4.0425) | Error 0.0856(0.0888) Steps 802(799.60) | Grad Norm 6.6533(5.4086) | Total Time 14.00(14.00)\n",
      "Iter 3330 | Time 74.8731(74.4080) | Bit/dim 3.9208(3.9181) | Xent 0.2534(0.2492) | Loss 4.0475(4.0427) | Error 0.0901(0.0888) Steps 808(799.86) | Grad Norm 7.5822(5.4738) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0555 | Time 29.7496, Epoch Time 494.1198(490.4552), Bit/dim 3.9310(best: 3.9313), Xent 2.4068, Loss 5.1344, Error 0.4378(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3331 | Time 74.8848(74.4223) | Bit/dim 3.9100(3.9178) | Xent 0.2503(0.2493) | Loss 4.0352(4.0424) | Error 0.0875(0.0888) Steps 802(799.92) | Grad Norm 6.5719(5.5067) | Total Time 14.00(14.00)\n",
      "Iter 3332 | Time 75.8193(74.4642) | Bit/dim 3.9090(3.9175) | Xent 0.2420(0.2491) | Loss 4.0299(4.0421) | Error 0.0845(0.0887) Steps 814(800.34) | Grad Norm 2.8061(5.4257) | Total Time 14.00(14.00)\n",
      "Iter 3333 | Time 73.2903(74.4290) | Bit/dim 3.9148(3.9175) | Xent 0.2323(0.2486) | Loss 4.0310(4.0417) | Error 0.0811(0.0884) Steps 802(800.39) | Grad Norm 2.8562(5.3486) | Total Time 14.00(14.00)\n",
      "Iter 3334 | Time 75.6486(74.4656) | Bit/dim 3.9283(3.9178) | Xent 0.2504(0.2486) | Loss 4.0535(4.0421) | Error 0.0895(0.0885) Steps 796(800.26) | Grad Norm 4.1931(5.3140) | Total Time 14.00(14.00)\n",
      "Iter 3335 | Time 75.1214(74.4853) | Bit/dim 3.9234(3.9180) | Xent 0.2297(0.2480) | Loss 4.0382(4.0420) | Error 0.0807(0.0882) Steps 790(799.95) | Grad Norm 3.5035(5.2597) | Total Time 14.00(14.00)\n",
      "Iter 3336 | Time 77.2325(74.5677) | Bit/dim 3.9114(3.9178) | Xent 0.2376(0.2477) | Loss 4.0302(4.0416) | Error 0.0841(0.0881) Steps 808(800.19) | Grad Norm 4.2766(5.2302) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0556 | Time 29.3822, Epoch Time 497.1509(490.6561), Bit/dim 3.9314(best: 3.9310), Xent 2.3772, Loss 5.1200, Error 0.4378(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3337 | Time 74.7937(74.5744) | Bit/dim 3.9125(3.9176) | Xent 0.2348(0.2473) | Loss 4.0299(4.0413) | Error 0.0850(0.0880) Steps 790(799.89) | Grad Norm 3.3548(5.1739) | Total Time 14.00(14.00)\n",
      "Iter 3338 | Time 75.5535(74.6038) | Bit/dim 3.9174(3.9176) | Xent 0.2387(0.2471) | Loss 4.0368(4.0411) | Error 0.0849(0.0879) Steps 802(799.95) | Grad Norm 3.8848(5.1352) | Total Time 14.00(14.00)\n",
      "Iter 3339 | Time 73.8112(74.5800) | Bit/dim 3.9084(3.9173) | Xent 0.2369(0.2468) | Loss 4.0269(4.0407) | Error 0.0857(0.0879) Steps 796(799.83) | Grad Norm 4.2467(5.1086) | Total Time 14.00(14.00)\n",
      "Iter 3340 | Time 75.3704(74.6038) | Bit/dim 3.9159(3.9173) | Xent 0.2294(0.2463) | Loss 4.0306(4.0404) | Error 0.0823(0.0877) Steps 802(799.90) | Grad Norm 4.7667(5.0983) | Total Time 14.00(14.00)\n",
      "Iter 3341 | Time 75.8903(74.6423) | Bit/dim 3.9246(3.9175) | Xent 0.2406(0.2461) | Loss 4.0449(4.0405) | Error 0.0855(0.0876) Steps 796(799.78) | Grad Norm 2.7219(5.0270) | Total Time 14.00(14.00)\n",
      "Iter 3342 | Time 74.9542(74.6517) | Bit/dim 3.9225(3.9177) | Xent 0.2342(0.2457) | Loss 4.0396(4.0405) | Error 0.0841(0.0875) Steps 802(799.85) | Grad Norm 4.1538(5.0008) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0557 | Time 29.9134, Epoch Time 495.8457(490.8118), Bit/dim 3.9308(best: 3.9310), Xent 2.4238, Loss 5.1427, Error 0.4381(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3343 | Time 72.8243(74.5969) | Bit/dim 3.9054(3.9173) | Xent 0.2474(0.2458) | Loss 4.0291(4.0402) | Error 0.0891(0.0876) Steps 802(799.91) | Grad Norm 2.9044(4.9379) | Total Time 14.00(14.00)\n",
      "Iter 3344 | Time 75.0291(74.6099) | Bit/dim 3.9224(3.9174) | Xent 0.2372(0.2455) | Loss 4.0410(4.0402) | Error 0.0831(0.0874) Steps 796(799.80) | Grad Norm 7.8312(5.0247) | Total Time 14.00(14.00)\n",
      "Iter 3345 | Time 73.3808(74.5730) | Bit/dim 3.9258(3.9177) | Xent 0.2325(0.2451) | Loss 4.0421(4.0403) | Error 0.0826(0.0873) Steps 808(800.04) | Grad Norm 4.5623(5.0109) | Total Time 14.00(14.00)\n",
      "Iter 3346 | Time 76.8294(74.6407) | Bit/dim 3.9137(3.9176) | Xent 0.2452(0.2451) | Loss 4.0363(4.0401) | Error 0.0880(0.0873) Steps 802(800.10) | Grad Norm 7.7378(5.0927) | Total Time 14.00(14.00)\n",
      "Iter 3347 | Time 73.4351(74.6045) | Bit/dim 3.9160(3.9175) | Xent 0.2319(0.2447) | Loss 4.0319(4.0399) | Error 0.0774(0.0870) Steps 802(800.16) | Grad Norm 5.5034(5.1050) | Total Time 14.00(14.00)\n",
      "Iter 3348 | Time 74.9127(74.6137) | Bit/dim 3.9040(3.9171) | Xent 0.2413(0.2446) | Loss 4.0246(4.0394) | Error 0.0849(0.0869) Steps 790(799.85) | Grad Norm 5.9786(5.1312) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0558 | Time 29.4561, Epoch Time 491.2681(490.8255), Bit/dim 3.9324(best: 3.9308), Xent 2.4429, Loss 5.1539, Error 0.4392(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3349 | Time 74.2193(74.6019) | Bit/dim 3.9188(3.9172) | Xent 0.2315(0.2442) | Loss 4.0345(4.0393) | Error 0.0795(0.0867) Steps 814(800.28) | Grad Norm 4.3694(5.1083) | Total Time 14.00(14.00)\n",
      "Iter 3350 | Time 75.7225(74.6355) | Bit/dim 3.9242(3.9174) | Xent 0.2384(0.2441) | Loss 4.0435(4.0394) | Error 0.0846(0.0867) Steps 802(800.33) | Grad Norm 5.9937(5.1349) | Total Time 14.00(14.00)\n",
      "Iter 3351 | Time 74.0803(74.6189) | Bit/dim 3.9154(3.9173) | Xent 0.2323(0.2437) | Loss 4.0316(4.0392) | Error 0.0836(0.0866) Steps 802(800.38) | Grad Norm 6.3795(5.1722) | Total Time 14.00(14.00)\n",
      "Iter 3352 | Time 75.1395(74.6345) | Bit/dim 3.9129(3.9172) | Xent 0.2418(0.2437) | Loss 4.0338(4.0390) | Error 0.0861(0.0866) Steps 796(800.25) | Grad Norm 10.1985(5.3230) | Total Time 14.00(14.00)\n",
      "Iter 3353 | Time 73.2455(74.5928) | Bit/dim 3.9152(3.9171) | Xent 0.2586(0.2441) | Loss 4.0445(4.0392) | Error 0.0966(0.0869) Steps 808(800.48) | Grad Norm 8.9449(5.4317) | Total Time 14.00(14.00)\n",
      "Iter 3354 | Time 73.8948(74.5719) | Bit/dim 3.9109(3.9169) | Xent 0.2344(0.2438) | Loss 4.0281(4.0388) | Error 0.0843(0.0868) Steps 808(800.71) | Grad Norm 4.7703(5.4118) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0559 | Time 29.5841, Epoch Time 491.3762(490.8420), Bit/dim 3.9317(best: 3.9308), Xent 2.4277, Loss 5.1456, Error 0.4406(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3355 | Time 71.9998(74.4947) | Bit/dim 3.9263(3.9172) | Xent 0.2540(0.2441) | Loss 4.0533(4.0393) | Error 0.0893(0.0869) Steps 802(800.74) | Grad Norm 10.1583(5.5542) | Total Time 14.00(14.00)\n",
      "Iter 3356 | Time 75.1352(74.5139) | Bit/dim 3.9206(3.9173) | Xent 0.2398(0.2440) | Loss 4.0404(4.0393) | Error 0.0854(0.0868) Steps 808(800.96) | Grad Norm 5.4576(5.5513) | Total Time 14.00(14.00)\n",
      "Iter 3357 | Time 75.0957(74.5314) | Bit/dim 3.9111(3.9171) | Xent 0.2414(0.2439) | Loss 4.0318(4.0391) | Error 0.0829(0.0867) Steps 796(800.81) | Grad Norm 4.7743(5.5280) | Total Time 14.00(14.00)\n",
      "Iter 3358 | Time 75.5388(74.5616) | Bit/dim 3.9126(3.9170) | Xent 0.2608(0.2444) | Loss 4.0430(4.0392) | Error 0.0931(0.0869) Steps 820(801.39) | Grad Norm 5.4915(5.5269) | Total Time 14.00(14.00)\n",
      "Iter 3359 | Time 77.6806(74.6552) | Bit/dim 3.9075(3.9167) | Xent 0.2295(0.2440) | Loss 4.0223(4.0387) | Error 0.0816(0.0867) Steps 796(801.23) | Grad Norm 4.5601(5.4979) | Total Time 14.00(14.00)\n",
      "Iter 3360 | Time 73.9738(74.6347) | Bit/dim 3.9167(3.9167) | Xent 0.2504(0.2442) | Loss 4.0419(4.0388) | Error 0.0865(0.0867) Steps 802(801.25) | Grad Norm 5.5349(5.4990) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0560 | Time 29.3690, Epoch Time 494.6215(490.9554), Bit/dim 3.9298(best: 3.9308), Xent 2.4025, Loss 5.1310, Error 0.4360(best: 0.4093)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3361 | Time 72.1051(74.5588) | Bit/dim 3.9158(3.9167) | Xent 0.2305(0.2437) | Loss 4.0310(4.0386) | Error 0.0796(0.0865) Steps 790(800.91) | Grad Norm 3.8697(5.4502) | Total Time 14.00(14.00)\n",
      "Iter 3362 | Time 73.9332(74.5401) | Bit/dim 3.9106(3.9165) | Xent 0.2371(0.2436) | Loss 4.0292(4.0383) | Error 0.0851(0.0865) Steps 808(801.13) | Grad Norm 3.7179(5.3982) | Total Time 14.00(14.00)\n",
      "Iter 3363 | Time 74.1939(74.5297) | Bit/dim 3.9180(3.9165) | Xent 0.2399(0.2434) | Loss 4.0380(4.0383) | Error 0.0836(0.0864) Steps 808(801.33) | Grad Norm 3.2729(5.3344) | Total Time 14.00(14.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_drop_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_conditional_cifar10_8K_drop_0_5_baseline_run1_post --load_dir ../experiments_published/cnf_conditional_cifar10_8K_drop_0_5_baseline_run1 --seed 1 --conditional True --controlled_tol False --train_mode semisup --lr 0.001 --warmup_iters 1000 --atol 1e-5  --rtol 1e-5 --weight_y 0.5 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
