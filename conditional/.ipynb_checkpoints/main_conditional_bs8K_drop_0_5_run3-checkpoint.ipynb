{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_drop.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz = modules.GaussianDiag.logp(mean, logs, z).view(-1,1)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z = model.module.dropout(z)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z = modules.GaussianDiag.sample(mean, logs)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, conditional=True, controlled_tol=True, conv=True, data='mnist', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.01, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rtol=0.0001, save='../experiments_published/cnf_conditional_8K_drop_0_5_run1', seed=0, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=113.0, weight_decay=0.0, weight_y=0.5)\n",
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=1568, bias=True)\n",
      "  (project_class): LinearZeros(in_features=784, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 828890\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 0001 | Time 56.8669(56.8669) | Bit/dim 33.8952(33.8952) | Xent 2.3026(2.3026) | Loss 35.0465(35.0465) | Error 0.9018(0.9018) Steps 290(290.00) | Grad Norm 272.1849(272.1849) | Total Time 10.00(10.00)\n",
      "Iter 0002 | Time 19.9376(55.7590) | Bit/dim 24.7841(33.6219) | Xent 2.2535(2.3011) | Loss 25.9109(34.7724) | Error 0.8631(0.9006) Steps 290(290.00) | Grad Norm 199.1698(269.9945) | Total Time 10.00(10.00)\n",
      "Iter 0003 | Time 21.0631(54.7181) | Bit/dim 16.6717(33.1134) | Xent 2.0812(2.2945) | Loss 17.7123(34.2606) | Error 0.5072(0.8888) Steps 314(290.72) | Grad Norm 108.8679(265.1607) | Total Time 10.00(10.00)\n",
      "Iter 0004 | Time 24.7128(53.8180) | Bit/dim 13.7145(32.5314) | Xent 1.9407(2.2839) | Loss 14.6848(33.6734) | Error 0.5136(0.8775) Steps 374(293.22) | Grad Norm 46.7129(258.6072) | Total Time 10.00(10.00)\n",
      "Iter 0005 | Time 26.5891(53.0011) | Bit/dim 15.4636(32.0194) | Xent 1.8193(2.2700) | Loss 16.3732(33.1544) | Error 0.4864(0.8658) Steps 410(296.72) | Grad Norm 111.5623(254.1959) | Total Time 10.00(10.00)\n",
      "Iter 0006 | Time 27.7861(52.2447) | Bit/dim 15.5827(31.5263) | Xent 1.7014(2.2529) | Loss 16.4334(32.6527) | Error 0.4515(0.8534) Steps 416(300.30) | Grad Norm 128.9757(250.4393) | Total Time 10.00(10.00)\n",
      "Iter 0007 | Time 27.7650(51.5103) | Bit/dim 12.9834(30.9700) | Xent 1.5691(2.2324) | Loss 13.7680(32.0862) | Error 0.3365(0.8379) Steps 404(303.41) | Grad Norm 100.4676(245.9401) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 24.6132, Epoch Time 242.1223(242.1223), Bit/dim 10.1942(best: inf), Xent 1.4123, Loss 10.9003, Error 0.2150(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0008 | Time 27.7791(50.7983) | Bit/dim 10.0353(30.3419) | Xent 1.4658(2.2094) | Loss 10.7682(31.4466) | Error 0.2844(0.8213) Steps 392(306.07) | Grad Norm 62.1347(240.4260) | Total Time 10.00(10.00)\n",
      "Iter 0009 | Time 26.3083(50.0636) | Bit/dim 8.2672(29.6797) | Xent 1.3724(2.1843) | Loss 8.9534(30.7718) | Error 0.2812(0.8051) Steps 380(308.29) | Grad Norm 32.3102(234.1825) | Total Time 10.00(10.00)\n",
      "Iter 0010 | Time 25.1236(49.3154) | Bit/dim 7.7035(29.0204) | Xent 1.2826(2.1572) | Loss 8.3448(30.0990) | Error 0.2861(0.7895) Steps 344(309.36) | Grad Norm 24.5457(227.8934) | Total Time 10.00(10.00)\n",
      "Iter 0011 | Time 23.0854(48.5285) | Bit/dim 7.6856(28.3804) | Xent 1.1902(2.1282) | Loss 8.2807(29.4445) | Error 0.2589(0.7736) Steps 338(310.22) | Grad Norm 33.0359(222.0477) | Total Time 10.00(10.00)\n",
      "Iter 0012 | Time 22.8045(47.7568) | Bit/dim 7.5455(27.7553) | Xent 1.1074(2.0976) | Loss 8.0992(28.8041) | Error 0.2392(0.7575) Steps 338(311.05) | Grad Norm 37.5218(216.5119) | Total Time 10.00(10.00)\n",
      "Iter 0013 | Time 23.3854(47.0257) | Bit/dim 6.8496(27.1282) | Xent 1.0711(2.0668) | Loss 7.3851(28.1616) | Error 0.2501(0.7423) Steps 338(311.86) | Grad Norm 34.9153(211.0640) | Total Time 10.00(10.00)\n",
      "Iter 0014 | Time 23.6028(46.3230) | Bit/dim 5.7914(26.4880) | Xent 1.0775(2.0371) | Loss 6.3302(27.5066) | Error 0.2719(0.7282) Steps 350(313.00) | Grad Norm 27.4684(205.5561) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 13.8275, Epoch Time 198.2455(240.8060), Bit/dim 4.7264(best: 10.1942), Xent 1.0410, Loss 5.2469, Error 0.2523(best: 0.2150)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0015 | Time 24.9685(45.6823) | Bit/dim 4.7207(25.8350) | Xent 1.1116(2.0094) | Loss 5.2765(26.8397) | Error 0.3011(0.7154) Steps 350(314.11) | Grad Norm 18.3279(199.9393) | Total Time 10.00(10.00)\n",
      "Iter 0016 | Time 25.0659(45.0639) | Bit/dim 3.9386(25.1781) | Xent 1.1741(1.9843) | Loss 4.5257(26.1703) | Error 0.3266(0.7037) Steps 368(315.73) | Grad Norm 10.2631(194.2490) | Total Time 10.00(10.00)\n",
      "Iter 0017 | Time 25.3579(44.4727) | Bit/dim 3.4846(24.5273) | Xent 1.2381(1.9619) | Loss 4.1037(25.5083) | Error 0.3478(0.6931) Steps 362(317.12) | Grad Norm 6.0146(188.6020) | Total Time 10.00(10.00)\n",
      "Iter 0018 | Time 24.0945(43.8613) | Bit/dim 3.3029(23.8906) | Xent 1.3702(1.9442) | Loss 3.9880(24.8627) | Error 0.4077(0.6845) Steps 356(318.28) | Grad Norm 6.9907(183.1536) | Total Time 10.00(10.00)\n",
      "Iter 0019 | Time 23.5901(43.2532) | Bit/dim 3.2203(23.2705) | Xent 1.4875(1.9305) | Loss 3.9641(24.2357) | Error 0.4474(0.6774) Steps 350(319.24) | Grad Norm 8.5449(177.9154) | Total Time 10.00(10.00)\n",
      "Iter 0020 | Time 24.6427(42.6949) | Bit/dim 3.1388(22.6665) | Xent 1.5960(1.9204) | Loss 3.9367(23.6268) | Error 0.4738(0.6713) Steps 362(320.52) | Grad Norm 8.8108(172.8422) | Total Time 10.00(10.00)\n",
      "Iter 0021 | Time 25.7516(42.1866) | Bit/dim 3.0104(22.0769) | Xent 1.6846(1.9134) | Loss 3.8527(23.0335) | Error 0.4799(0.6655) Steps 368(321.94) | Grad Norm 7.9490(167.8954) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 14.6623, Epoch Time 200.6708(239.6019), Bit/dim 2.8589(best: 4.7264), Xent 1.6952, Loss 3.7065, Error 0.3415(best: 0.2150)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0022 | Time 25.8202(41.6956) | Bit/dim 2.8665(21.5005) | Xent 1.7758(1.9092) | Loss 3.7544(22.4552) | Error 0.5010(0.6606) Steps 374(323.51) | Grad Norm 6.5639(163.0555) | Total Time 10.00(10.00)\n",
      "Iter 0023 | Time 25.9046(41.2219) | Bit/dim 2.7533(20.9381) | Xent 1.8552(1.9076) | Loss 3.6809(21.8919) | Error 0.5575(0.6575) Steps 374(325.02) | Grad Norm 5.2870(158.3224) | Total Time 10.00(10.00)\n",
      "Iter 0024 | Time 25.3348(40.7453) | Bit/dim 2.6684(20.3900) | Xent 1.9314(1.9083) | Loss 3.6340(21.3442) | Error 0.6122(0.6561) Steps 368(326.31) | Grad Norm 4.5600(153.7095) | Total Time 10.00(10.00)\n",
      "Iter 0025 | Time 30.1728(40.4281) | Bit/dim 2.6376(19.8575) | Xent 1.9903(1.9108) | Loss 3.6328(20.8128) | Error 0.6643(0.6564) Steps 410(328.82) | Grad Norm 4.4843(149.2328) | Total Time 10.00(10.00)\n",
      "Iter 0026 | Time 30.9845(40.1448) | Bit/dim 2.6308(19.3407) | Xent 2.0349(1.9145) | Loss 3.6483(20.2979) | Error 0.6896(0.6574) Steps 404(331.08) | Grad Norm 4.6144(144.8942) | Total Time 10.00(10.00)\n",
      "Iter 0027 | Time 28.3979(39.7924) | Bit/dim 2.6406(18.8397) | Xent 2.0388(1.9182) | Loss 3.6600(19.7988) | Error 0.6991(0.6586) Steps 398(333.08) | Grad Norm 4.7664(140.6904) | Total Time 10.00(10.00)\n",
      "Iter 0028 | Time 28.4054(39.4508) | Bit/dim 2.6483(18.3539) | Xent 2.0471(1.9221) | Loss 3.6718(19.3150) | Error 0.7001(0.6599) Steps 398(335.03) | Grad Norm 4.7800(136.6131) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 15.6696, Epoch Time 223.0159(239.1044), Bit/dim 2.6228(best: 2.8589), Xent 1.9456, Loss 3.5956, Error 0.5553(best: 0.2150)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0029 | Time 27.7680(39.1003) | Bit/dim 2.6345(17.8823) | Xent 2.0246(1.9252) | Loss 3.6468(18.8449) | Error 0.6894(0.6608) Steps 392(336.74) | Grad Norm 4.7175(132.6562) | Total Time 10.00(10.00)\n",
      "Iter 0030 | Time 28.4547(38.7809) | Bit/dim 2.6031(17.4240) | Xent 1.9986(1.9274) | Loss 3.6024(18.3876) | Error 0.6765(0.6612) Steps 392(338.40) | Grad Norm 4.6185(128.8151) | Total Time 10.00(10.00)\n",
      "Iter 0031 | Time 28.2667(38.4655) | Bit/dim 2.5751(16.9785) | Xent 1.9457(1.9279) | Loss 3.5479(17.9425) | Error 0.6460(0.6608) Steps 392(340.01) | Grad Norm 4.6598(125.0904) | Total Time 10.00(10.00)\n",
      "Iter 0032 | Time 29.1476(38.1859) | Bit/dim 2.5233(16.5448) | Xent 1.8750(1.9263) | Loss 3.4607(17.5080) | Error 0.6139(0.6594) Steps 398(341.75) | Grad Norm 4.8152(121.4822) | Total Time 10.00(10.00)\n",
      "Iter 0033 | Time 29.6053(37.9285) | Bit/dim 2.4802(16.1229) | Xent 1.7765(1.9218) | Loss 3.3684(17.0838) | Error 0.5653(0.6565) Steps 398(343.43) | Grad Norm 4.8200(117.9823) | Total Time 10.00(10.00)\n",
      "Iter 0034 | Time 28.3829(37.6422) | Bit/dim 2.4319(15.7122) | Xent 1.5995(1.9122) | Loss 3.2317(16.6683) | Error 0.4839(0.6514) Steps 392(344.89) | Grad Norm 4.5169(114.5783) | Total Time 10.00(10.00)\n",
      "Iter 0035 | Time 27.5710(37.3400) | Bit/dim 2.3952(15.3127) | Xent 1.4453(1.8982) | Loss 3.1178(16.2617) | Error 0.4276(0.6447) Steps 386(346.12) | Grad Norm 3.7317(111.2529) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 14.4746, Epoch Time 226.0191(238.7118), Bit/dim 2.3818(best: 2.6228), Xent 1.1178, Loss 2.9407, Error 0.2665(best: 0.2150)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0036 | Time 28.7429(37.0821) | Bit/dim 2.3871(14.9249) | Xent 1.2727(1.8794) | Loss 3.0235(15.8646) | Error 0.3778(0.6366) Steps 386(347.32) | Grad Norm 3.5564(108.0220) | Total Time 10.00(10.00)\n",
      "Iter 0037 | Time 27.9559(36.8083) | Bit/dim 2.3962(14.5490) | Xent 1.1096(1.8563) | Loss 2.9510(15.4772) | Error 0.3376(0.6277) Steps 362(347.76) | Grad Norm 4.8160(104.9259) | Total Time 10.00(10.00)\n",
      "Iter 0038 | Time 27.6887(36.5347) | Bit/dim 2.3999(14.1846) | Xent 1.0107(1.8309) | Loss 2.9053(15.1000) | Error 0.3095(0.6181) Steps 374(348.55) | Grad Norm 4.5773(101.9154) | Total Time 10.00(10.00)\n",
      "Iter 0039 | Time 27.5332(36.2647) | Bit/dim 2.3964(13.8309) | Xent 0.9213(1.8036) | Loss 2.8571(14.7327) | Error 0.2812(0.6080) Steps 362(348.95) | Grad Norm 2.3335(98.9280) | Total Time 10.00(10.00)\n",
      "Iter 0040 | Time 25.6508(35.9463) | Bit/dim 2.4010(13.4880) | Xent 0.8962(1.7764) | Loss 2.8491(14.3762) | Error 0.2806(0.5982) Steps 368(349.52) | Grad Norm 3.4229(96.0628) | Total Time 10.00(10.00)\n",
      "Iter 0041 | Time 26.0336(35.6489) | Bit/dim 2.4141(13.1558) | Xent 0.8538(1.7487) | Loss 2.8410(14.0302) | Error 0.2609(0.5881) Steps 356(349.72) | Grad Norm 4.7020(93.3220) | Total Time 10.00(10.00)\n",
      "Iter 0042 | Time 24.5505(35.3159) | Bit/dim 2.3893(12.8328) | Xent 0.8110(1.7206) | Loss 2.7948(13.6931) | Error 0.2489(0.5779) Steps 356(349.91) | Grad Norm 4.5880(90.6600) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 14.3927, Epoch Time 214.8961(237.9973), Bit/dim 2.3395(best: 2.3818), Xent 0.6546, Loss 2.6668, Error 0.1752(best: 0.2150)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0043 | Time 24.8524(35.0020) | Bit/dim 2.3423(12.5181) | Xent 0.7775(1.6923) | Loss 2.7310(13.3642) | Error 0.2314(0.5675) Steps 356(350.09) | Grad Norm 2.8624(88.0260) | Total Time 10.00(10.00)\n",
      "Iter 0044 | Time 25.7811(34.7254) | Bit/dim 2.3033(12.2116) | Xent 0.7933(1.6653) | Loss 2.6999(13.0443) | Error 0.2355(0.5576) Steps 374(350.81) | Grad Norm 2.8315(85.4702) | Total Time 10.00(10.00)\n",
      "Iter 0045 | Time 25.4576(34.4474) | Bit/dim 2.2775(11.9136) | Xent 0.8308(1.6403) | Loss 2.6929(12.7338) | Error 0.2416(0.5481) Steps 374(351.50) | Grad Norm 4.2469(83.0335) | Total Time 10.00(10.00)\n",
      "Iter 0046 | Time 27.7451(34.2463) | Bit/dim 2.2411(11.6234) | Xent 0.8746(1.6173) | Loss 2.6784(12.4321) | Error 0.2440(0.5390) Steps 380(352.36) | Grad Norm 3.2137(80.6389) | Total Time 10.00(10.00)\n",
      "Iter 0047 | Time 27.8928(34.0557) | Bit/dim 2.2214(11.3414) | Xent 0.8656(1.5948) | Loss 2.6542(12.1388) | Error 0.2526(0.5304) Steps 386(353.37) | Grad Norm 3.4308(78.3227) | Total Time 10.00(10.00)\n",
      "Iter 0048 | Time 27.9076(33.8713) | Bit/dim 2.2164(11.0676) | Xent 0.8314(1.5719) | Loss 2.6321(11.8536) | Error 0.2381(0.5216) Steps 386(354.34) | Grad Norm 3.6227(76.0817) | Total Time 10.00(10.00)\n",
      "Iter 0049 | Time 26.5261(33.6509) | Bit/dim 2.2010(10.8016) | Xent 0.7915(1.5485) | Loss 2.5968(11.5759) | Error 0.2365(0.5130) Steps 392(355.47) | Grad Norm 2.1739(73.8644) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 15.5048, Epoch Time 213.9309(237.2753), Bit/dim 2.2017(best: 2.3395), Xent 0.5918, Loss 2.4976, Error 0.1582(best: 0.1752)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0050 | Time 26.0152(33.4218) | Bit/dim 2.2047(10.5437) | Xent 0.7159(1.5235) | Loss 2.5626(11.3055) | Error 0.2219(0.5043) Steps 386(356.39) | Grad Norm 1.6126(71.6969) | Total Time 10.00(10.00)\n",
      "Iter 0051 | Time 25.8340(33.1942) | Bit/dim 2.2120(10.2938) | Xent 0.6812(1.4982) | Loss 2.5526(11.0429) | Error 0.2147(0.4956) Steps 386(357.28) | Grad Norm 2.4703(69.6201) | Total Time 10.00(10.00)\n",
      "Iter 0052 | Time 25.9115(32.9757) | Bit/dim 2.1962(10.0508) | Xent 0.6673(1.4733) | Loss 2.5298(10.7875) | Error 0.2114(0.4871) Steps 386(358.14) | Grad Norm 2.3902(67.6032) | Total Time 10.00(10.00)\n",
      "Iter 0053 | Time 27.7111(32.8178) | Bit/dim 2.1756(9.8146) | Xent 0.6578(1.4488) | Loss 2.5045(10.5390) | Error 0.2019(0.4785) Steps 392(359.16) | Grad Norm 1.9914(65.6348) | Total Time 10.00(10.00)\n",
      "Iter 0054 | Time 25.8474(32.6087) | Bit/dim 2.1344(9.5842) | Xent 0.6748(1.4256) | Loss 2.4718(10.2970) | Error 0.2069(0.4704) Steps 386(359.96) | Grad Norm 1.5293(63.7117) | Total Time 10.00(10.00)\n",
      "Iter 0055 | Time 25.3926(32.3922) | Bit/dim 2.1045(9.3598) | Xent 0.7274(1.4047) | Loss 2.4682(10.0621) | Error 0.2230(0.4630) Steps 380(360.56) | Grad Norm 1.8366(61.8554) | Total Time 10.00(10.00)\n",
      "Iter 0056 | Time 28.3562(32.2711) | Bit/dim 2.0813(9.1414) | Xent 0.7342(1.3846) | Loss 2.4484(9.8337) | Error 0.2226(0.4558) Steps 392(361.51) | Grad Norm 2.5845(60.0773) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 15.1273, Epoch Time 212.6895(236.5378), Bit/dim 2.0626(best: 2.2017), Xent 0.5647, Loss 2.3449, Error 0.1494(best: 0.1582)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0057 | Time 27.4163(32.1255) | Bit/dim 2.0660(8.9292) | Xent 0.7353(1.3651) | Loss 2.4336(9.6117) | Error 0.2234(0.4488) Steps 386(362.24) | Grad Norm 2.4048(58.3471) | Total Time 10.00(10.00)\n",
      "Iter 0058 | Time 28.7770(32.0250) | Bit/dim 2.0614(8.7231) | Xent 0.6810(1.3445) | Loss 2.4018(9.3954) | Error 0.2044(0.4415) Steps 392(363.13) | Grad Norm 1.0120(56.6271) | Total Time 10.00(10.00)\n",
      "Iter 0059 | Time 26.4829(31.8587) | Bit/dim 2.0694(8.5235) | Xent 0.6508(1.3237) | Loss 2.3948(9.1854) | Error 0.2037(0.4343) Steps 380(363.64) | Grad Norm 1.9242(54.9860) | Total Time 10.00(10.00)\n",
      "Iter 0060 | Time 26.2241(31.6897) | Bit/dim 2.0560(8.3295) | Xent 0.6473(1.3034) | Loss 2.3797(8.9812) | Error 0.1991(0.4273) Steps 374(363.95) | Grad Norm 2.4372(53.4095) | Total Time 10.00(10.00)\n",
      "Iter 0061 | Time 26.2713(31.5271) | Bit/dim 2.0334(8.1406) | Xent 0.6364(1.2834) | Loss 2.3516(8.7823) | Error 0.1946(0.4203) Steps 368(364.07) | Grad Norm 1.4703(51.8513) | Total Time 10.00(10.00)\n",
      "Iter 0062 | Time 26.2038(31.3675) | Bit/dim 1.9984(7.9564) | Xent 0.6786(1.2653) | Loss 2.3377(8.5890) | Error 0.2039(0.4138) Steps 368(364.19) | Grad Norm 2.1755(50.3611) | Total Time 10.00(10.00)\n",
      "Iter 0063 | Time 26.9103(31.2337) | Bit/dim 1.9953(7.7775) | Xent 0.6488(1.2468) | Loss 2.3197(8.4009) | Error 0.1917(0.4071) Steps 368(364.30) | Grad Norm 2.6931(48.9310) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 14.7806, Epoch Time 215.5481(235.9081), Bit/dim 1.9896(best: 2.0626), Xent 0.4656, Loss 2.2224, Error 0.1282(best: 0.1494)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0064 | Time 25.9129(31.0741) | Bit/dim 1.9915(7.6039) | Xent 0.6110(1.2277) | Loss 2.2970(8.2178) | Error 0.1839(0.4004) Steps 374(364.59) | Grad Norm 0.7987(47.4870) | Total Time 10.00(10.00)\n",
      "Iter 0065 | Time 26.7132(30.9433) | Bit/dim 2.0061(7.4360) | Xent 0.6060(1.2091) | Loss 2.3090(8.0405) | Error 0.1857(0.3940) Steps 380(365.06) | Grad Norm 2.9660(46.1514) | Total Time 10.00(10.00)\n",
      "Iter 0066 | Time 27.8028(30.8491) | Bit/dim 1.9774(7.2722) | Xent 0.5707(1.1899) | Loss 2.2628(7.8672) | Error 0.1819(0.3876) Steps 398(366.04) | Grad Norm 1.4337(44.8099) | Total Time 10.00(10.00)\n",
      "Iter 0067 | Time 27.9249(30.7613) | Bit/dim 1.9557(7.1128) | Xent 0.6380(1.1734) | Loss 2.2747(7.6994) | Error 0.1983(0.3819) Steps 404(367.18) | Grad Norm 2.6694(43.5457) | Total Time 10.00(10.00)\n",
      "Iter 0068 | Time 27.9538(30.6771) | Bit/dim 1.9529(6.9580) | Xent 0.6217(1.1568) | Loss 2.2638(7.5364) | Error 0.1866(0.3761) Steps 398(368.11) | Grad Norm 1.4348(42.2823) | Total Time 10.00(10.00)\n",
      "Iter 0069 | Time 28.8410(30.6220) | Bit/dim 1.9588(6.8080) | Xent 0.5723(1.1393) | Loss 2.2450(7.3776) | Error 0.1795(0.3702) Steps 392(368.82) | Grad Norm 2.5872(41.0915) | Total Time 10.00(10.00)\n",
      "Iter 0070 | Time 27.0853(30.5159) | Bit/dim 1.9315(6.6617) | Xent 0.5806(1.1225) | Loss 2.2218(7.2229) | Error 0.1811(0.3645) Steps 386(369.34) | Grad Norm 1.1610(39.8936) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 15.0899, Epoch Time 219.8879(235.4275), Bit/dim 1.9111(best: 1.9896), Xent 0.4429, Loss 2.1326, Error 0.1219(best: 0.1282)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0071 | Time 26.7625(30.4033) | Bit/dim 1.9137(6.5192) | Xent 0.6205(1.1075) | Loss 2.2239(7.0730) | Error 0.1895(0.3593) Steps 380(369.66) | Grad Norm 2.5963(38.7747) | Total Time 10.00(10.00)\n",
      "Iter 0072 | Time 26.1766(30.2765) | Bit/dim 1.9258(6.3814) | Xent 0.6072(1.0924) | Loss 2.2294(6.9277) | Error 0.1929(0.3543) Steps 368(369.61) | Grad Norm 2.4609(37.6852) | Total Time 10.00(10.00)\n",
      "Iter 0073 | Time 25.0860(30.1208) | Bit/dim 1.9150(6.2475) | Xent 0.5917(1.0774) | Loss 2.2109(6.7862) | Error 0.1871(0.3493) Steps 362(369.38) | Grad Norm 1.4046(36.5968) | Total Time 10.00(10.00)\n",
      "Iter 0074 | Time 25.2636(29.9751) | Bit/dim 1.8963(6.1169) | Xent 0.5965(1.0630) | Loss 2.1946(6.6484) | Error 0.1836(0.3443) Steps 368(369.34) | Grad Norm 2.5270(35.5747) | Total Time 10.00(10.00)\n",
      "Iter 0075 | Time 25.2511(29.8334) | Bit/dim 1.9111(5.9907) | Xent 0.5718(1.0483) | Loss 2.1970(6.5149) | Error 0.1801(0.3394) Steps 368(369.30) | Grad Norm 5.6278(34.6763) | Total Time 10.00(10.00)\n",
      "Iter 0076 | Time 26.7930(29.7422) | Bit/dim 1.8994(5.8680) | Xent 0.6337(1.0358) | Loss 2.2162(6.3859) | Error 0.1926(0.3350) Steps 374(369.44) | Grad Norm 8.8723(33.9022) | Total Time 10.00(10.00)\n",
      "Iter 0077 | Time 25.8300(29.6248) | Bit/dim 1.9838(5.7515) | Xent 0.5070(1.0200) | Loss 2.2373(6.2615) | Error 0.1535(0.3295) Steps 368(369.40) | Grad Norm 11.4237(33.2278) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 14.6272, Epoch Time 208.3164(234.6141), Bit/dim 1.8979(best: 1.9111), Xent 0.4421, Loss 2.1190, Error 0.1208(best: 0.1219)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0078 | Time 26.7128(29.5374) | Bit/dim 1.9035(5.6360) | Xent 0.6296(1.0082) | Loss 2.2183(6.1402) | Error 0.1935(0.3254) Steps 374(369.54) | Grad Norm 10.8343(32.5560) | Total Time 10.00(10.00)\n",
      "Iter 0079 | Time 25.9918(29.4311) | Bit/dim 1.8925(5.5237) | Xent 0.5796(0.9954) | Loss 2.1823(6.0214) | Error 0.1797(0.3211) Steps 368(369.49) | Grad Norm 5.2949(31.7382) | Total Time 10.00(10.00)\n",
      "Iter 0080 | Time 26.0568(29.3298) | Bit/dim 1.8909(5.4147) | Xent 0.5636(0.9824) | Loss 2.1727(5.9060) | Error 0.1740(0.3167) Steps 362(369.27) | Grad Norm 4.3651(30.9170) | Total Time 10.00(10.00)\n",
      "Iter 0081 | Time 26.4617(29.2438) | Bit/dim 1.8926(5.3091) | Xent 0.6016(0.9710) | Loss 2.1934(5.7946) | Error 0.1861(0.3127) Steps 374(369.41) | Grad Norm 10.8874(30.3161) | Total Time 10.00(10.00)\n",
      "Iter 0082 | Time 26.5989(29.1645) | Bit/dim 1.9223(5.2075) | Xent 0.5638(0.9588) | Loss 2.2042(5.6869) | Error 0.1726(0.3085) Steps 374(369.54) | Grad Norm 8.8991(29.6736) | Total Time 10.00(10.00)\n",
      "Iter 0083 | Time 26.2545(29.0772) | Bit/dim 1.8678(5.1073) | Xent 0.5929(0.9478) | Loss 2.1643(5.5812) | Error 0.1870(0.3049) Steps 380(369.86) | Grad Norm 3.2750(28.8817) | Total Time 10.00(10.00)\n",
      "Iter 0084 | Time 27.4531(29.0284) | Bit/dim 1.8750(5.0103) | Xent 0.5749(0.9366) | Loss 2.1624(5.4786) | Error 0.1804(0.3012) Steps 380(370.16) | Grad Norm 6.5878(28.2128) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 14.3834, Epoch Time 212.2910(233.9444), Bit/dim 1.8963(best: 1.8979), Xent 0.3740, Loss 2.0833, Error 0.1116(best: 0.1208)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0085 | Time 27.8066(28.9918) | Bit/dim 1.8979(4.9169) | Xent 0.5140(0.9239) | Loss 2.1549(5.3789) | Error 0.1560(0.2968) Steps 368(370.10) | Grad Norm 6.7194(27.5680) | Total Time 10.00(10.00)\n",
      "Iter 0086 | Time 26.2241(28.9087) | Bit/dim 1.8537(4.8251) | Xent 0.5724(0.9134) | Loss 2.1399(5.2818) | Error 0.1734(0.2931) Steps 368(370.04) | Grad Norm 1.9605(26.7998) | Total Time 10.00(10.00)\n",
      "Iter 0087 | Time 26.7728(28.8447) | Bit/dim 1.8517(4.7359) | Xent 0.6213(0.9046) | Loss 2.1623(5.1882) | Error 0.1959(0.2902) Steps 380(370.33) | Grad Norm 7.2154(26.2123) | Total Time 10.00(10.00)\n",
      "Iter 0088 | Time 26.8692(28.7854) | Bit/dim 1.9071(4.6510) | Xent 0.5106(0.8928) | Loss 2.1624(5.0974) | Error 0.1509(0.2860) Steps 374(370.44) | Grad Norm 7.9270(25.6637) | Total Time 10.00(10.00)\n",
      "Iter 0089 | Time 25.4542(28.6855) | Bit/dim 1.8560(4.5671) | Xent 0.5332(0.8820) | Loss 2.1227(5.0082) | Error 0.1641(0.2823) Steps 368(370.37) | Grad Norm 4.3776(25.0251) | Total Time 10.00(10.00)\n",
      "Iter 0090 | Time 25.2879(28.5835) | Bit/dim 1.8457(4.4855) | Xent 0.5740(0.8728) | Loss 2.1327(4.9219) | Error 0.1831(0.2794) Steps 368(370.30) | Grad Norm 5.3108(24.4337) | Total Time 10.00(10.00)\n",
      "Iter 0091 | Time 27.6546(28.5557) | Bit/dim 1.8976(4.4079) | Xent 0.5242(0.8623) | Loss 2.1597(4.8390) | Error 0.1629(0.2759) Steps 380(370.59) | Grad Norm 7.4196(23.9233) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 14.4796, Epoch Time 212.8831(233.3126), Bit/dim 1.8309(best: 1.8963), Xent 0.3739, Loss 2.0179, Error 0.1064(best: 0.1116)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0092 | Time 25.2408(28.4562) | Bit/dim 1.8343(4.3307) | Xent 0.5617(0.8533) | Loss 2.1152(4.7573) | Error 0.1796(0.2730) Steps 368(370.51) | Grad Norm 3.0430(23.2969) | Total Time 10.00(10.00)\n",
      "Iter 0093 | Time 25.7606(28.3754) | Bit/dim 1.8379(4.2559) | Xent 0.5534(0.8443) | Loss 2.1146(4.6780) | Error 0.1724(0.2700) Steps 368(370.44) | Grad Norm 4.3986(22.7299) | Total Time 10.00(10.00)\n",
      "Iter 0094 | Time 26.0819(28.3066) | Bit/dim 1.8814(4.1846) | Xent 0.4986(0.8339) | Loss 2.1307(4.6016) | Error 0.1514(0.2664) Steps 374(370.54) | Grad Norm 6.6106(22.2463) | Total Time 10.00(10.00)\n",
      "Iter 0095 | Time 26.5712(28.2545) | Bit/dim 1.8354(4.1142) | Xent 0.5355(0.8250) | Loss 2.1032(4.5267) | Error 0.1669(0.2634) Steps 368(370.47) | Grad Norm 2.0711(21.6411) | Total Time 10.00(10.00)\n",
      "Iter 0096 | Time 25.4176(28.1694) | Bit/dim 1.8263(4.0455) | Xent 0.5549(0.8169) | Loss 2.1038(4.4540) | Error 0.1726(0.2607) Steps 368(370.39) | Grad Norm 4.9064(21.1390) | Total Time 10.00(10.00)\n",
      "Iter 0097 | Time 26.2235(28.1110) | Bit/dim 1.8939(3.9810) | Xent 0.5083(0.8076) | Loss 2.1481(4.3848) | Error 0.1545(0.2575) Steps 374(370.50) | Grad Norm 8.2718(20.7530) | Total Time 10.00(10.00)\n",
      "Iter 0098 | Time 25.8121(28.0420) | Bit/dim 1.8413(3.9168) | Xent 0.5511(0.7999) | Loss 2.1168(4.3168) | Error 0.1710(0.2549) Steps 380(370.79) | Grad Norm 6.9949(20.3403) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 14.7387, Epoch Time 208.2502(232.5607), Bit/dim 1.8240(best: 1.8309), Xent 0.3451, Loss 1.9965, Error 0.1021(best: 0.1064)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0099 | Time 25.9035(27.9779) | Bit/dim 1.8244(3.8540) | Xent 0.5068(0.7911) | Loss 2.0778(4.2496) | Error 0.1570(0.2520) Steps 368(370.70) | Grad Norm 1.0511(19.7616) | Total Time 10.00(10.00)\n",
      "Iter 0100 | Time 25.8318(27.9135) | Bit/dim 1.8458(3.7938) | Xent 0.4875(0.7820) | Loss 2.0896(4.1848) | Error 0.1486(0.2489) Steps 368(370.62) | Grad Norm 4.9861(19.3183) | Total Time 10.00(10.00)\n",
      "Iter 0101 | Time 26.7768(27.8794) | Bit/dim 1.8307(3.7349) | Xent 0.5550(0.7752) | Loss 2.1082(4.1225) | Error 0.1766(0.2467) Steps 380(370.90) | Grad Norm 6.3878(18.9304) | Total Time 10.00(10.00)\n",
      "Iter 0102 | Time 26.5402(27.8392) | Bit/dim 1.8473(3.6782) | Xent 0.4796(0.7664) | Loss 2.0871(4.0614) | Error 0.1496(0.2438) Steps 368(370.82) | Grad Norm 4.3604(18.4933) | Total Time 10.00(10.00)\n",
      "Iter 0103 | Time 25.6105(27.7724) | Bit/dim 1.8254(3.6227) | Xent 0.4926(0.7581) | Loss 2.0717(4.0017) | Error 0.1556(0.2412) Steps 368(370.73) | Grad Norm 1.1660(17.9735) | Total Time 10.00(10.00)\n",
      "Iter 0104 | Time 26.0258(27.7200) | Bit/dim 1.8175(3.5685) | Xent 0.5468(0.7518) | Loss 2.0909(3.9444) | Error 0.1737(0.2391) Steps 380(371.01) | Grad Norm 5.2856(17.5929) | Total Time 10.00(10.00)\n",
      "Iter 0105 | Time 25.4195(27.6510) | Bit/dim 1.8586(3.5172) | Xent 0.4780(0.7436) | Loss 2.0976(3.8890) | Error 0.1431(0.2363) Steps 368(370.92) | Grad Norm 7.1461(17.2795) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 14.9585, Epoch Time 209.5421(231.8702), Bit/dim 1.8186(best: 1.8240), Xent 0.3507, Loss 1.9939, Error 0.0975(best: 0.1021)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0106 | Time 26.3851(27.6130) | Bit/dim 1.8237(3.4664) | Xent 0.5137(0.7367) | Loss 2.0806(3.8348) | Error 0.1637(0.2341) Steps 380(371.19) | Grad Norm 6.5637(16.9580) | Total Time 10.00(10.00)\n",
      "Iter 0107 | Time 24.7067(27.5258) | Bit/dim 1.8250(3.4172) | Xent 0.4787(0.7290) | Loss 2.0644(3.7816) | Error 0.1524(0.2316) Steps 374(371.28) | Grad Norm 3.4275(16.5521) | Total Time 10.00(10.00)\n",
      "Iter 0108 | Time 25.6353(27.4691) | Bit/dim 1.8147(3.3691) | Xent 0.4928(0.7219) | Loss 2.0611(3.7300) | Error 0.1492(0.2292) Steps 380(371.54) | Grad Norm 1.7691(16.1086) | Total Time 10.00(10.00)\n",
      "Iter 0109 | Time 27.0123(27.4554) | Bit/dim 1.8137(3.3224) | Xent 0.5221(0.7159) | Loss 2.0748(3.6804) | Error 0.1633(0.2272) Steps 386(371.97) | Grad Norm 6.1975(15.8113) | Total Time 10.00(10.00)\n",
      "Iter 0110 | Time 25.7631(27.4046) | Bit/dim 1.8689(3.2788) | Xent 0.4677(0.7084) | Loss 2.1028(3.6330) | Error 0.1452(0.2247) Steps 368(371.85) | Grad Norm 8.1020(15.5800) | Total Time 10.00(10.00)\n",
      "Iter 0111 | Time 27.0319(27.3934) | Bit/dim 1.8109(3.2348) | Xent 0.5551(0.7038) | Loss 2.0885(3.5867) | Error 0.1724(0.2232) Steps 386(372.28) | Grad Norm 6.8614(15.3184) | Total Time 10.00(10.00)\n",
      "Iter 0112 | Time 26.3132(27.3610) | Bit/dim 1.8191(3.1923) | Xent 0.4630(0.6966) | Loss 2.0506(3.5406) | Error 0.1436(0.2208) Steps 380(372.51) | Grad Norm 3.3823(14.9603) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 15.1320, Epoch Time 210.5330(231.2301), Bit/dim 1.8045(best: 1.8186), Xent 0.3263, Loss 1.9677, Error 0.0948(best: 0.0975)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0113 | Time 26.0556(27.3219) | Bit/dim 1.8145(3.1510) | Xent 0.4826(0.6902) | Loss 2.0558(3.4961) | Error 0.1486(0.2186) Steps 380(372.73) | Grad Norm 2.3144(14.5810) | Total Time 10.00(10.00)\n",
      "Iter 0114 | Time 27.3229(27.3219) | Bit/dim 1.7958(3.1103) | Xent 0.5556(0.6861) | Loss 2.0735(3.4534) | Error 0.1745(0.2173) Steps 386(373.13) | Grad Norm 6.0994(14.3265) | Total Time 10.00(10.00)\n",
      "Iter 0115 | Time 26.4810(27.2967) | Bit/dim 1.8435(3.0723) | Xent 0.4435(0.6789) | Loss 2.0653(3.4118) | Error 0.1402(0.2150) Steps 374(373.16) | Grad Norm 5.8260(14.0715) | Total Time 10.00(10.00)\n",
      "Iter 0116 | Time 25.2904(27.2365) | Bit/dim 1.7988(3.0341) | Xent 0.4824(0.6730) | Loss 2.0400(3.3706) | Error 0.1515(0.2131) Steps 380(373.36) | Grad Norm 2.6046(13.7275) | Total Time 10.00(10.00)\n",
      "Iter 0117 | Time 27.8601(27.2552) | Bit/dim 1.7842(2.9966) | Xent 0.5255(0.6686) | Loss 2.0469(3.3309) | Error 0.1670(0.2117) Steps 380(373.56) | Grad Norm 4.1534(13.4403) | Total Time 10.00(10.00)\n",
      "Iter 0118 | Time 25.4763(27.2018) | Bit/dim 1.8276(2.9616) | Xent 0.4516(0.6620) | Loss 2.0535(3.2926) | Error 0.1388(0.2095) Steps 374(373.58) | Grad Norm 5.8415(13.2123) | Total Time 10.00(10.00)\n",
      "Iter 0119 | Time 26.1306(27.1697) | Bit/dim 1.7835(2.9262) | Xent 0.5024(0.6573) | Loss 2.0347(3.2548) | Error 0.1576(0.2079) Steps 380(373.77) | Grad Norm 3.9926(12.9357) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 15.1529, Epoch Time 212.1316(230.6571), Bit/dim 1.7782(best: 1.8045), Xent 0.3255, Loss 1.9410, Error 0.0937(best: 0.0948)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0120 | Time 26.4133(27.1470) | Bit/dim 1.7803(2.8918) | Xent 0.4898(0.6522) | Loss 2.0252(3.2179) | Error 0.1540(0.2063) Steps 380(373.95) | Grad Norm 1.4891(12.5923) | Total Time 10.00(10.00)\n",
      "Iter 0121 | Time 28.0804(27.1750) | Bit/dim 1.8104(2.8594) | Xent 0.4631(0.6466) | Loss 2.0419(3.1827) | Error 0.1478(0.2046) Steps 380(374.14) | Grad Norm 4.6828(12.3550) | Total Time 10.00(10.00)\n",
      "Iter 0122 | Time 26.2603(27.1476) | Bit/dim 1.7797(2.8270) | Xent 0.5073(0.6424) | Loss 2.0333(3.1482) | Error 0.1615(0.2033) Steps 380(374.31) | Grad Norm 4.4626(12.1183) | Total Time 10.00(10.00)\n",
      "Iter 0123 | Time 26.7536(27.1357) | Bit/dim 1.7896(2.7959) | Xent 0.4650(0.6371) | Loss 2.0221(3.1144) | Error 0.1460(0.2016) Steps 380(374.48) | Grad Norm 2.2792(11.8231) | Total Time 10.00(10.00)\n",
      "Iter 0124 | Time 26.3655(27.1126) | Bit/dim 1.7799(2.7654) | Xent 0.4608(0.6318) | Loss 2.0103(3.0813) | Error 0.1470(0.1999) Steps 380(374.65) | Grad Norm 1.4011(11.5104) | Total Time 10.00(10.00)\n",
      "Iter 0125 | Time 25.7788(27.0726) | Bit/dim 1.7664(2.7354) | Xent 0.4956(0.6277) | Loss 2.0142(3.0493) | Error 0.1593(0.1987) Steps 380(374.81) | Grad Norm 3.2605(11.2629) | Total Time 10.00(10.00)\n",
      "Iter 0126 | Time 27.0912(27.0732) | Bit/dim 1.8064(2.7076) | Xent 0.4655(0.6228) | Loss 2.0392(3.0190) | Error 0.1414(0.1970) Steps 374(374.78) | Grad Norm 4.4441(11.0584) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 15.0444, Epoch Time 214.1330(230.1614), Bit/dim 1.7603(best: 1.7782), Xent 0.3387, Loss 1.9296, Error 0.0922(best: 0.0937)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0127 | Time 26.2668(27.0490) | Bit/dim 1.7659(2.6793) | Xent 0.5055(0.6193) | Loss 2.0186(2.9890) | Error 0.1596(0.1959) Steps 380(374.94) | Grad Norm 4.9117(10.8740) | Total Time 10.00(10.00)\n",
      "Iter 0128 | Time 27.7740(27.0707) | Bit/dim 1.7886(2.6526) | Xent 0.4436(0.6140) | Loss 2.0104(2.9596) | Error 0.1415(0.1942) Steps 380(375.09) | Grad Norm 4.6925(10.6885) | Total Time 10.00(10.00)\n",
      "Iter 0129 | Time 26.3709(27.0497) | Bit/dim 1.7619(2.6259) | Xent 0.5037(0.6107) | Loss 2.0137(2.9312) | Error 0.1550(0.1930) Steps 380(375.24) | Grad Norm 4.3072(10.4971) | Total Time 10.00(10.00)\n",
      "Iter 0130 | Time 26.0784(27.0206) | Bit/dim 1.7828(2.6006) | Xent 0.4554(0.6061) | Loss 2.0105(2.9036) | Error 0.1435(0.1916) Steps 380(375.38) | Grad Norm 3.3654(10.2831) | Total Time 10.00(10.00)\n",
      "Iter 0131 | Time 26.2266(26.9968) | Bit/dim 1.7559(2.5752) | Xent 0.4875(0.6025) | Loss 1.9997(2.8765) | Error 0.1562(0.1905) Steps 380(375.52) | Grad Norm 2.5870(10.0522) | Total Time 10.00(10.00)\n",
      "Iter 0132 | Time 25.8317(26.9618) | Bit/dim 1.7663(2.5510) | Xent 0.4704(0.5985) | Loss 2.0015(2.8502) | Error 0.1491(0.1893) Steps 380(375.66) | Grad Norm 1.7513(9.8032) | Total Time 10.00(10.00)\n",
      "Iter 0133 | Time 25.8476(26.9284) | Bit/dim 1.7591(2.5272) | Xent 0.4611(0.5944) | Loss 1.9897(2.8244) | Error 0.1441(0.1879) Steps 380(375.79) | Grad Norm 1.1077(9.5423) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 15.0801, Epoch Time 211.7972(229.6105), Bit/dim 1.7455(best: 1.7603), Xent 0.3172, Loss 1.9041, Error 0.0929(best: 0.0922)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0134 | Time 26.1105(26.9039) | Bit/dim 1.7536(2.5040) | Xent 0.4659(0.5906) | Loss 1.9866(2.7993) | Error 0.1489(0.1867) Steps 380(375.91) | Grad Norm 1.6285(9.3049) | Total Time 10.00(10.00)\n",
      "Iter 0135 | Time 26.0673(26.8788) | Bit/dim 1.7495(2.4814) | Xent 0.4508(0.5864) | Loss 1.9749(2.7746) | Error 0.1414(0.1854) Steps 380(376.04) | Grad Norm 1.0490(9.0573) | Total Time 10.00(10.00)\n",
      "Iter 0136 | Time 27.6773(26.9027) | Bit/dim 1.7483(2.4594) | Xent 0.4623(0.5826) | Loss 1.9795(2.7507) | Error 0.1440(0.1841) Steps 380(376.15) | Grad Norm 1.3762(8.8268) | Total Time 10.00(10.00)\n",
      "Iter 0137 | Time 26.2763(26.8839) | Bit/dim 1.7539(2.4382) | Xent 0.4451(0.5785) | Loss 1.9764(2.7275) | Error 0.1435(0.1829) Steps 380(376.27) | Grad Norm 2.9008(8.6490) | Total Time 10.00(10.00)\n",
      "Iter 0138 | Time 26.4304(26.8703) | Bit/dim 1.7436(2.4174) | Xent 0.4875(0.5758) | Loss 1.9874(2.7053) | Error 0.1559(0.1821) Steps 380(376.38) | Grad Norm 5.0555(8.5412) | Total Time 10.00(10.00)\n",
      "Iter 0139 | Time 26.5741(26.8614) | Bit/dim 1.8355(2.3999) | Xent 0.4302(0.5714) | Loss 2.0506(2.6856) | Error 0.1305(0.1806) Steps 386(376.67) | Grad Norm 10.8833(8.6115) | Total Time 10.00(10.00)\n",
      "Iter 0140 | Time 30.6467(26.9750) | Bit/dim 1.9598(2.3867) | Xent 0.8312(0.5792) | Loss 2.3754(2.6763) | Error 0.2646(0.1831) Steps 410(377.67) | Grad Norm 22.2929(9.0219) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 13.6336, Epoch Time 215.7878(229.1958), Bit/dim 2.2855(best: 1.7455), Xent 0.3632, Loss 2.4671, Error 0.0913(best: 0.0922)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0141 | Time 23.8280(26.8806) | Bit/dim 2.2868(2.3837) | Xent 0.5183(0.5774) | Loss 2.5460(2.6724) | Error 0.1275(0.1814) Steps 350(376.84) | Grad Norm 24.0625(9.4732) | Total Time 10.00(10.00)\n",
      "Iter 0142 | Time 25.7863(26.8478) | Bit/dim 1.8418(2.3675) | Xent 0.5265(0.5759) | Loss 2.1051(2.6554) | Error 0.1751(0.1812) Steps 368(376.57) | Grad Norm 7.3386(9.4091) | Total Time 10.00(10.00)\n",
      "Iter 0143 | Time 26.1650(26.8273) | Bit/dim 1.9069(2.3536) | Xent 0.9325(0.5866) | Loss 2.3732(2.6469) | Error 0.3034(0.1849) Steps 374(376.50) | Grad Norm 12.2361(9.4939) | Total Time 10.00(10.00)\n",
      "Iter 0144 | Time 25.7226(26.7941) | Bit/dim 1.8533(2.3386) | Xent 0.6590(0.5887) | Loss 2.1828(2.6330) | Error 0.2086(0.1856) Steps 374(376.42) | Grad Norm 4.8288(9.3540) | Total Time 10.00(10.00)\n",
      "Iter 0145 | Time 24.1243(26.7140) | Bit/dim 1.9010(2.3255) | Xent 0.5353(0.5871) | Loss 2.1687(2.6191) | Error 0.1660(0.1850) Steps 362(375.99) | Grad Norm 4.4626(9.2072) | Total Time 10.00(10.00)\n",
      "Iter 0146 | Time 25.2096(26.6689) | Bit/dim 1.9731(2.3149) | Xent 0.4620(0.5834) | Loss 2.2042(2.6066) | Error 0.1325(0.1834) Steps 362(375.57) | Grad Norm 4.7894(9.0747) | Total Time 10.00(10.00)\n",
      "Iter 0147 | Time 23.8358(26.5839) | Bit/dim 1.9131(2.3029) | Xent 0.4723(0.5800) | Loss 2.1492(2.5929) | Error 0.1385(0.1821) Steps 362(375.16) | Grad Norm 3.3875(8.9041) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 14.1308, Epoch Time 201.0588(228.3517), Bit/dim 1.8445(best: 1.7455), Xent 0.3357, Loss 2.0124, Error 0.0951(best: 0.0913)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0148 | Time 24.3243(26.5161) | Bit/dim 1.8458(2.2892) | Xent 0.5057(0.5778) | Loss 2.0986(2.5781) | Error 0.1562(0.1813) Steps 362(374.77) | Grad Norm 1.5445(8.6833) | Total Time 10.00(10.00)\n",
      "Iter 0149 | Time 26.5173(26.5162) | Bit/dim 1.8591(2.2763) | Xent 0.5780(0.5778) | Loss 2.1481(2.5652) | Error 0.1855(0.1814) Steps 380(374.92) | Grad Norm 4.7262(8.5646) | Total Time 10.00(10.00)\n",
      "Iter 0150 | Time 26.4406(26.5139) | Bit/dim 1.8524(2.2635) | Xent 0.5379(0.5766) | Loss 2.1213(2.5519) | Error 0.1663(0.1810) Steps 380(375.08) | Grad Norm 3.3274(8.4075) | Total Time 10.00(10.00)\n",
      "Iter 0151 | Time 26.9889(26.5281) | Bit/dim 1.8545(2.2513) | Xent 0.4867(0.5739) | Loss 2.0978(2.5382) | Error 0.1525(0.1801) Steps 374(375.04) | Grad Norm 1.3432(8.1955) | Total Time 10.00(10.00)\n",
      "Iter 0152 | Time 25.7088(26.5036) | Bit/dim 1.8821(2.2402) | Xent 0.4590(0.5705) | Loss 2.1116(2.5254) | Error 0.1411(0.1790) Steps 368(374.83) | Grad Norm 2.7864(8.0333) | Total Time 10.00(10.00)\n",
      "Iter 0153 | Time 25.1708(26.4636) | Bit/dim 1.8679(2.2290) | Xent 0.4550(0.5670) | Loss 2.0954(2.5125) | Error 0.1410(0.1778) Steps 368(374.63) | Grad Norm 2.6164(7.8708) | Total Time 10.00(10.00)\n",
      "Iter 0154 | Time 24.5553(26.4063) | Bit/dim 1.8395(2.2173) | Xent 0.4815(0.5644) | Loss 2.0802(2.4996) | Error 0.1508(0.1770) Steps 362(374.25) | Grad Norm 1.4152(7.6771) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 14.2414, Epoch Time 206.5086(227.6964), Bit/dim 1.8049(best: 1.7455), Xent 0.3419, Loss 1.9758, Error 0.1035(best: 0.0913)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0155 | Time 25.3704(26.3752) | Bit/dim 1.8093(2.2051) | Xent 0.4980(0.5625) | Loss 2.0583(2.4863) | Error 0.1574(0.1764) Steps 374(374.24) | Grad Norm 2.0181(7.5073) | Total Time 10.00(10.00)\n",
      "Iter 0156 | Time 25.4398(26.3472) | Bit/dim 1.8054(2.1931) | Xent 0.5209(0.5612) | Loss 2.0659(2.4737) | Error 0.1657(0.1761) Steps 374(374.23) | Grad Norm 2.9835(7.3716) | Total Time 10.00(10.00)\n",
      "Iter 0157 | Time 25.9537(26.3354) | Bit/dim 1.7967(2.1812) | Xent 0.4886(0.5590) | Loss 2.0409(2.4607) | Error 0.1552(0.1755) Steps 374(374.23) | Grad Norm 1.3931(7.1923) | Total Time 10.00(10.00)\n",
      "Iter 0158 | Time 24.6529(26.2849) | Bit/dim 1.8072(2.1700) | Xent 0.4438(0.5556) | Loss 2.0291(2.4478) | Error 0.1432(0.1745) Steps 362(373.86) | Grad Norm 1.4735(7.0207) | Total Time 10.00(10.00)\n",
      "Iter 0159 | Time 24.8581(26.2421) | Bit/dim 1.8089(2.1592) | Xent 0.4777(0.5532) | Loss 2.0478(2.4358) | Error 0.1495(0.1738) Steps 362(373.51) | Grad Norm 2.7352(6.8921) | Total Time 10.00(10.00)\n",
      "Iter 0160 | Time 26.7904(26.2586) | Bit/dim 1.7808(2.1478) | Xent 0.4745(0.5509) | Loss 2.0180(2.4232) | Error 0.1498(0.1730) Steps 386(373.88) | Grad Norm 1.1118(6.7187) | Total Time 10.00(10.00)\n",
      "Iter 0161 | Time 27.1386(26.2850) | Bit/dim 1.7663(2.1364) | Xent 0.5104(0.5497) | Loss 2.0215(2.4112) | Error 0.1645(0.1728) Steps 386(374.24) | Grad Norm 2.7535(6.5998) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 15.1227, Epoch Time 207.8600(227.1013), Bit/dim 1.7538(best: 1.7455), Xent 0.3216, Loss 1.9146, Error 0.0959(best: 0.0913)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0162 | Time 27.4266(26.3192) | Bit/dim 1.7550(2.1249) | Xent 0.4986(0.5481) | Loss 2.0043(2.3990) | Error 0.1591(0.1724) Steps 386(374.60) | Grad Norm 1.5610(6.4486) | Total Time 10.00(10.00)\n",
      "Iter 0163 | Time 24.7044(26.2708) | Bit/dim 1.7654(2.1141) | Xent 0.4787(0.5460) | Loss 2.0047(2.3872) | Error 0.1469(0.1716) Steps 368(374.40) | Grad Norm 1.5277(6.3010) | Total Time 10.00(10.00)\n",
      "Iter 0164 | Time 24.0894(26.2053) | Bit/dim 1.7624(2.1036) | Xent 0.4789(0.5440) | Loss 2.0018(2.3756) | Error 0.1501(0.1710) Steps 362(374.03) | Grad Norm 1.6908(6.1627) | Total Time 10.00(10.00)\n",
      "Iter 0165 | Time 24.8300(26.1641) | Bit/dim 1.7521(2.0930) | Xent 0.4668(0.5417) | Loss 1.9855(2.3639) | Error 0.1530(0.1704) Steps 368(373.85) | Grad Norm 1.9027(6.0349) | Total Time 10.00(10.00)\n",
      "Iter 0166 | Time 24.7392(26.1213) | Bit/dim 1.7407(2.0825) | Xent 0.4983(0.5404) | Loss 1.9898(2.3527) | Error 0.1609(0.1701) Steps 368(373.67) | Grad Norm 2.9810(5.9432) | Total Time 10.00(10.00)\n",
      "Iter 0167 | Time 26.1592(26.1225) | Bit/dim 1.7353(2.0721) | Xent 0.4505(0.5377) | Loss 1.9605(2.3409) | Error 0.1451(0.1694) Steps 368(373.50) | Grad Norm 1.6071(5.8132) | Total Time 10.00(10.00)\n",
      "Iter 0168 | Time 24.5746(26.0760) | Bit/dim 1.7436(2.0622) | Xent 0.4559(0.5353) | Loss 1.9716(2.3298) | Error 0.1426(0.1686) Steps 362(373.16) | Grad Norm 1.3011(5.6778) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 14.5103, Epoch Time 203.3074(226.3875), Bit/dim 1.7271(best: 1.7455), Xent 0.3066, Loss 1.8804, Error 0.0898(best: 0.0913)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0169 | Time 24.2265(26.0205) | Bit/dim 1.7327(2.0523) | Xent 0.4485(0.5327) | Loss 1.9570(2.3186) | Error 0.1376(0.1677) Steps 362(372.82) | Grad Norm 1.2889(5.5461) | Total Time 10.00(10.00)\n",
      "Iter 0170 | Time 26.0590(26.0217) | Bit/dim 1.7172(2.0423) | Xent 0.4735(0.5309) | Loss 1.9539(2.3077) | Error 0.1492(0.1671) Steps 380(373.04) | Grad Norm 1.7274(5.4316) | Total Time 10.00(10.00)\n",
      "Iter 0171 | Time 26.1866(26.0266) | Bit/dim 1.7175(2.0325) | Xent 0.4818(0.5294) | Loss 1.9584(2.2972) | Error 0.1515(0.1666) Steps 380(373.24) | Grad Norm 1.5752(5.3159) | Total Time 10.00(10.00)\n",
      "Iter 0172 | Time 25.8005(26.0198) | Bit/dim 1.7113(2.0229) | Xent 0.4738(0.5277) | Loss 1.9482(2.2867) | Error 0.1510(0.1662) Steps 380(373.45) | Grad Norm 2.3686(5.2275) | Total Time 10.00(10.00)\n",
      "Iter 0173 | Time 25.7928(26.0130) | Bit/dim 1.7307(2.0141) | Xent 0.4375(0.5250) | Loss 1.9495(2.2766) | Error 0.1379(0.1653) Steps 380(373.64) | Grad Norm 5.2013(5.2267) | Total Time 10.00(10.00)\n",
      "Iter 0174 | Time 27.7238(26.0644) | Bit/dim 1.7068(2.0049) | Xent 0.5382(0.5254) | Loss 1.9759(2.2676) | Error 0.1751(0.1656) Steps 392(374.19) | Grad Norm 11.5156(5.4153) | Total Time 10.00(10.00)\n",
      "Iter 0175 | Time 26.1543(26.0671) | Bit/dim 1.9549(2.0034) | Xent 0.5269(0.5255) | Loss 2.2184(2.2661) | Error 0.1667(0.1656) Steps 380(374.37) | Grad Norm 21.7688(5.9059) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 14.9185, Epoch Time 209.4167(225.8783), Bit/dim 1.8312(best: 1.7271), Xent 0.4469, Loss 2.0546, Error 0.1276(best: 0.0898)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0176 | Time 27.4805(26.1095) | Bit/dim 1.8378(1.9984) | Xent 0.6687(0.5298) | Loss 2.1721(2.2633) | Error 0.2164(0.1672) Steps 392(374.90) | Grad Norm 18.5614(6.2856) | Total Time 10.00(10.00)\n",
      "Iter 0177 | Time 25.7256(26.0979) | Bit/dim 1.7295(1.9904) | Xent 0.4785(0.5282) | Loss 1.9687(2.2545) | Error 0.1504(0.1667) Steps 380(375.05) | Grad Norm 3.3049(6.1962) | Total Time 10.00(10.00)\n",
      "Iter 0178 | Time 25.4405(26.0782) | Bit/dim 1.8300(1.9855) | Xent 0.4983(0.5273) | Loss 2.0792(2.2492) | Error 0.1558(0.1663) Steps 350(374.30) | Grad Norm 9.2751(6.2886) | Total Time 10.00(10.00)\n",
      "Iter 0179 | Time 26.0188(26.0764) | Bit/dim 1.7255(1.9777) | Xent 0.4697(0.5256) | Loss 1.9604(2.2405) | Error 0.1548(0.1660) Steps 386(374.65) | Grad Norm 2.2219(6.1666) | Total Time 10.00(10.00)\n",
      "Iter 0180 | Time 26.4956(26.0890) | Bit/dim 1.7430(1.9707) | Xent 0.5879(0.5275) | Loss 2.0370(2.2344) | Error 0.1930(0.1668) Steps 392(375.17) | Grad Norm 10.2238(6.2883) | Total Time 10.00(10.00)\n",
      "Iter 0181 | Time 27.8433(26.1416) | Bit/dim 1.7167(1.9631) | Xent 0.4640(0.5256) | Loss 1.9487(2.2259) | Error 0.1446(0.1661) Steps 392(375.68) | Grad Norm 2.5042(6.1748) | Total Time 10.00(10.00)\n",
      "Iter 0182 | Time 26.6504(26.1569) | Bit/dim 1.7462(1.9566) | Xent 0.4870(0.5244) | Loss 1.9897(2.2188) | Error 0.1474(0.1656) Steps 380(375.81) | Grad Norm 4.6558(6.1292) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 15.3874, Epoch Time 213.3989(225.5040), Bit/dim 1.7051(best: 1.7271), Xent 0.3179, Loss 1.8640, Error 0.0966(best: 0.0898)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0183 | Time 26.3999(26.1642) | Bit/dim 1.7078(1.9491) | Xent 0.4833(0.5232) | Loss 1.9495(2.2107) | Error 0.1484(0.1651) Steps 386(376.11) | Grad Norm 2.4272(6.0181) | Total Time 10.00(10.00)\n",
      "Iter 0184 | Time 26.7918(26.1830) | Bit/dim 1.6897(1.9413) | Xent 0.5051(0.5226) | Loss 1.9422(2.2027) | Error 0.1663(0.1651) Steps 398(376.77) | Grad Norm 3.5270(5.9434) | Total Time 10.00(10.00)\n",
      "Iter 0185 | Time 26.7552(26.2002) | Bit/dim 1.6741(1.9333) | Xent 0.5254(0.5227) | Loss 1.9368(2.1947) | Error 0.1680(0.1652) Steps 386(377.04) | Grad Norm 3.6267(5.8739) | Total Time 10.00(10.00)\n",
      "Iter 0186 | Time 26.0063(26.1944) | Bit/dim 1.6715(1.9255) | Xent 0.4532(0.5206) | Loss 1.8981(2.1858) | Error 0.1388(0.1644) Steps 386(377.31) | Grad Norm 1.6333(5.7467) | Total Time 10.00(10.00)\n",
      "Iter 0187 | Time 26.4526(26.2021) | Bit/dim 1.6900(1.9184) | Xent 0.4314(0.5180) | Loss 1.9057(2.1774) | Error 0.1306(0.1634) Steps 392(377.75) | Grad Norm 3.0822(5.6667) | Total Time 10.00(10.00)\n",
      "Iter 0188 | Time 26.6609(26.2159) | Bit/dim 1.6655(1.9108) | Xent 0.4339(0.5154) | Loss 1.8825(2.1685) | Error 0.1342(0.1625) Steps 380(377.82) | Grad Norm 1.9621(5.5556) | Total Time 10.00(10.00)\n",
      "Iter 0189 | Time 26.4847(26.2239) | Bit/dim 1.6413(1.9027) | Xent 0.4915(0.5147) | Loss 1.8870(2.1601) | Error 0.1514(0.1622) Steps 386(378.07) | Grad Norm 2.2494(5.4564) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 15.4409, Epoch Time 213.2342(225.1359), Bit/dim 1.6173(best: 1.7051), Xent 0.3071, Loss 1.7708, Error 0.0894(best: 0.0898)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0190 | Time 26.6211(26.2359) | Bit/dim 1.6221(1.8943) | Xent 0.4893(0.5140) | Loss 1.8668(2.1513) | Error 0.1541(0.1619) Steps 392(378.48) | Grad Norm 1.7778(5.3461) | Total Time 10.00(10.00)\n",
      "Iter 0191 | Time 25.8648(26.2247) | Bit/dim 1.6388(1.8866) | Xent 0.4634(0.5124) | Loss 1.8705(2.1429) | Error 0.1432(0.1614) Steps 386(378.71) | Grad Norm 1.5446(5.2320) | Total Time 10.00(10.00)\n",
      "Iter 0192 | Time 27.3408(26.2582) | Bit/dim 1.6251(1.8788) | Xent 0.4468(0.5105) | Loss 1.8485(2.1340) | Error 0.1404(0.1607) Steps 386(378.93) | Grad Norm 1.5099(5.1203) | Total Time 10.00(10.00)\n",
      "Iter 0193 | Time 26.5866(26.2681) | Bit/dim 1.6056(1.8706) | Xent 0.4405(0.5084) | Loss 1.8258(2.1248) | Error 0.1395(0.1601) Steps 392(379.32) | Grad Norm 0.9666(4.9957) | Total Time 10.00(10.00)\n",
      "Iter 0194 | Time 26.9584(26.2888) | Bit/dim 1.6012(1.8625) | Xent 0.4484(0.5066) | Loss 1.8254(2.1158) | Error 0.1458(0.1597) Steps 392(379.70) | Grad Norm 1.4065(4.8881) | Total Time 10.00(10.00)\n",
      "Iter 0195 | Time 26.9492(26.3086) | Bit/dim 1.6026(1.8547) | Xent 0.4342(0.5044) | Loss 1.8197(2.1069) | Error 0.1420(0.1591) Steps 392(380.07) | Grad Norm 1.6085(4.7897) | Total Time 10.00(10.00)\n",
      "Iter 0196 | Time 26.4039(26.3114) | Bit/dim 1.5825(1.8466) | Xent 0.4357(0.5023) | Loss 1.8004(2.0977) | Error 0.1401(0.1586) Steps 380(380.07) | Grad Norm 0.8059(4.6702) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 14.7480, Epoch Time 213.7454(224.7942), Bit/dim 1.5709(best: 1.6173), Xent 0.2941, Loss 1.7179, Error 0.0889(best: 0.0894)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0197 | Time 27.6176(26.3506) | Bit/dim 1.5781(1.8385) | Xent 0.4540(0.5009) | Loss 1.8051(2.0889) | Error 0.1416(0.1581) Steps 386(380.25) | Grad Norm 2.5055(4.6052) | Total Time 10.00(10.00)\n",
      "Iter 0198 | Time 25.5724(26.3273) | Bit/dim 1.5678(1.8304) | Xent 0.4569(0.4996) | Loss 1.7963(2.0802) | Error 0.1459(0.1577) Steps 374(380.06) | Grad Norm 1.3693(4.5081) | Total Time 10.00(10.00)\n",
      "Iter 0199 | Time 26.0135(26.3179) | Bit/dim 1.5679(1.8225) | Xent 0.4275(0.4974) | Loss 1.7817(2.0712) | Error 0.1348(0.1570) Steps 374(379.88) | Grad Norm 2.0205(4.4335) | Total Time 10.00(10.00)\n",
      "Iter 0200 | Time 27.0691(26.3404) | Bit/dim 1.5527(1.8144) | Xent 0.4618(0.4963) | Loss 1.7836(2.0626) | Error 0.1485(0.1567) Steps 392(380.24) | Grad Norm 2.8385(4.3857) | Total Time 10.00(10.00)\n",
      "Iter 0201 | Time 26.3593(26.3410) | Bit/dim 1.5602(1.8068) | Xent 0.4202(0.4941) | Loss 1.7703(2.0538) | Error 0.1361(0.1561) Steps 380(380.23) | Grad Norm 1.1404(4.2883) | Total Time 10.00(10.00)\n",
      "Iter 0202 | Time 25.9361(26.3288) | Bit/dim 1.5466(1.7990) | Xent 0.4442(0.4926) | Loss 1.7688(2.0453) | Error 0.1409(0.1557) Steps 374(380.05) | Grad Norm 1.2975(4.1986) | Total Time 10.00(10.00)\n",
      "Iter 0203 | Time 26.3760(26.3302) | Bit/dim 1.5273(1.7908) | Xent 0.4360(0.4909) | Loss 1.7453(2.0363) | Error 0.1410(0.1552) Steps 380(380.05) | Grad Norm 1.9178(4.1302) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 14.7931, Epoch Time 212.2561(224.4180), Bit/dim 1.5416(best: 1.5709), Xent 0.2742, Loss 1.6787, Error 0.0832(best: 0.0889)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0204 | Time 26.4688(26.3344) | Bit/dim 1.5447(1.7834) | Xent 0.4199(0.4887) | Loss 1.7547(2.0278) | Error 0.1296(0.1545) Steps 380(380.04) | Grad Norm 3.0871(4.0989) | Total Time 10.00(10.00)\n",
      "Iter 0205 | Time 28.0053(26.3845) | Bit/dim 1.5304(1.7759) | Xent 0.4504(0.4876) | Loss 1.7556(2.0196) | Error 0.1454(0.1542) Steps 380(380.04) | Grad Norm 4.8919(4.1227) | Total Time 10.00(10.00)\n",
      "Iter 0206 | Time 26.2395(26.3802) | Bit/dim 1.5716(1.7697) | Xent 0.3942(0.4848) | Loss 1.7687(2.0121) | Error 0.1256(0.1533) Steps 374(379.86) | Grad Norm 6.1188(4.1825) | Total Time 10.00(10.00)\n",
      "Iter 0207 | Time 26.1662(26.3738) | Bit/dim 1.5578(1.7634) | Xent 0.4848(0.4848) | Loss 1.8002(2.0058) | Error 0.1594(0.1535) Steps 380(379.87) | Grad Norm 7.9118(4.2944) | Total Time 10.00(10.00)\n",
      "Iter 0208 | Time 25.0658(26.3345) | Bit/dim 1.6206(1.7591) | Xent 0.3810(0.4817) | Loss 1.8111(1.9999) | Error 0.1160(0.1524) Steps 368(379.51) | Grad Norm 8.8711(4.4317) | Total Time 10.00(10.00)\n",
      "Iter 0209 | Time 27.2168(26.3610) | Bit/dim 1.5344(1.7523) | Xent 0.4152(0.4797) | Loss 1.7420(1.9922) | Error 0.1281(0.1517) Steps 386(379.70) | Grad Norm 4.7990(4.4427) | Total Time 10.00(10.00)\n",
      "Iter 0210 | Time 27.0965(26.3831) | Bit/dim 1.5241(1.7455) | Xent 0.4185(0.4778) | Loss 1.7334(1.9844) | Error 0.1369(0.1512) Steps 386(379.89) | Grad Norm 2.7421(4.3917) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 14.7210, Epoch Time 213.2727(224.0837), Bit/dim 1.5565(best: 1.5416), Xent 0.2549, Loss 1.6840, Error 0.0803(best: 0.0832)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0211 | Time 25.8585(26.3673) | Bit/dim 1.5613(1.7400) | Xent 0.3659(0.4745) | Loss 1.7442(1.9772) | Error 0.1144(0.1501) Steps 380(379.90) | Grad Norm 4.4372(4.3931) | Total Time 10.00(10.00)\n",
      "Iter 0212 | Time 27.0814(26.3887) | Bit/dim 1.5161(1.7333) | Xent 0.4110(0.4726) | Loss 1.7216(1.9695) | Error 0.1301(0.1495) Steps 386(380.08) | Grad Norm 1.1037(4.2944) | Total Time 10.00(10.00)\n",
      "Iter 0213 | Time 26.7296(26.3990) | Bit/dim 1.5085(1.7265) | Xent 0.4142(0.4708) | Loss 1.7156(1.9619) | Error 0.1348(0.1491) Steps 386(380.26) | Grad Norm 3.1159(4.2590) | Total Time 10.00(10.00)\n",
      "Iter 0214 | Time 27.7748(26.4402) | Bit/dim 1.5419(1.7210) | Xent 0.3734(0.4679) | Loss 1.7285(1.9549) | Error 0.1144(0.1480) Steps 386(380.43) | Grad Norm 3.0940(4.2241) | Total Time 10.00(10.00)\n",
      "Iter 0215 | Time 26.3965(26.4389) | Bit/dim 1.4980(1.7143) | Xent 0.4159(0.4663) | Loss 1.7060(1.9475) | Error 0.1278(0.1474) Steps 386(380.60) | Grad Norm 1.1722(4.1325) | Total Time 10.00(10.00)\n",
      "Iter 0216 | Time 27.3587(26.4665) | Bit/dim 1.5078(1.7081) | Xent 0.4105(0.4647) | Loss 1.7130(1.9404) | Error 0.1305(0.1469) Steps 386(380.76) | Grad Norm 3.1832(4.1041) | Total Time 10.00(10.00)\n",
      "Iter 0217 | Time 26.9241(26.4802) | Bit/dim 1.5212(1.7025) | Xent 0.3352(0.4608) | Loss 1.6888(1.9329) | Error 0.1029(0.1456) Steps 386(380.92) | Grad Norm 3.8016(4.0950) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 14.6101, Epoch Time 215.3507(223.8217), Bit/dim 1.4849(best: 1.5416), Xent 0.2504, Loss 1.6101, Error 0.0742(best: 0.0803)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0218 | Time 26.7155(26.4873) | Bit/dim 1.4950(1.6963) | Xent 0.3931(0.4588) | Loss 1.6916(1.9256) | Error 0.1262(0.1450) Steps 386(381.07) | Grad Norm 0.9716(4.0013) | Total Time 10.00(10.00)\n",
      "Iter 0219 | Time 26.7412(26.4949) | Bit/dim 1.4904(1.6901) | Xent 0.3998(0.4570) | Loss 1.6903(1.9186) | Error 0.1269(0.1445) Steps 386(381.22) | Grad Norm 3.2152(3.9777) | Total Time 10.00(10.00)\n",
      "Iter 0220 | Time 27.9674(26.5391) | Bit/dim 1.5216(1.6850) | Xent 0.3740(0.4545) | Loss 1.7086(1.9123) | Error 0.1192(0.1437) Steps 386(381.36) | Grad Norm 4.7834(4.0019) | Total Time 10.00(10.00)\n",
      "Iter 0221 | Time 27.3233(26.5626) | Bit/dim 1.4795(1.6789) | Xent 0.3873(0.4525) | Loss 1.6732(1.9051) | Error 0.1256(0.1432) Steps 392(381.68) | Grad Norm 3.9604(4.0006) | Total Time 10.00(10.00)\n",
      "Iter 0222 | Time 26.5175(26.5613) | Bit/dim 1.4887(1.6732) | Xent 0.3615(0.4497) | Loss 1.6695(1.8980) | Error 0.1142(0.1423) Steps 392(381.99) | Grad Norm 2.1553(3.9453) | Total Time 10.00(10.00)\n",
      "Iter 0223 | Time 26.7104(26.5657) | Bit/dim 1.4687(1.6670) | Xent 0.3530(0.4468) | Loss 1.6452(1.8905) | Error 0.1152(0.1415) Steps 392(382.29) | Grad Norm 1.4730(3.8711) | Total Time 10.00(10.00)\n",
      "Iter 0224 | Time 26.8996(26.5758) | Bit/dim 1.4730(1.6612) | Xent 0.3772(0.4448) | Loss 1.6616(1.8836) | Error 0.1221(0.1409) Steps 392(382.58) | Grad Norm 3.9179(3.8725) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 14.7186, Epoch Time 215.8724(223.5832), Bit/dim 1.5204(best: 1.4849), Xent 0.2335, Loss 1.6372, Error 0.0708(best: 0.0742)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0225 | Time 25.9802(26.5579) | Bit/dim 1.5223(1.6570) | Xent 0.3621(0.4423) | Loss 1.7034(1.8782) | Error 0.1159(0.1402) Steps 380(382.50) | Grad Norm 7.5470(3.9827) | Total Time 10.00(10.00)\n",
      "Iter 0226 | Time 26.6560(26.5608) | Bit/dim 1.5488(1.6538) | Xent 0.4161(0.4415) | Loss 1.7568(1.8745) | Error 0.1342(0.1400) Steps 392(382.79) | Grad Norm 12.3959(4.2351) | Total Time 10.00(10.00)\n",
      "Iter 0227 | Time 25.1480(26.5184) | Bit/dim 1.7168(1.6557) | Xent 0.3491(0.4387) | Loss 1.8914(1.8750) | Error 0.1126(0.1392) Steps 362(382.16) | Grad Norm 11.3824(4.4495) | Total Time 10.00(10.00)\n",
      "Iter 0228 | Time 26.9214(26.5305) | Bit/dim 1.5342(1.6520) | Xent 0.3841(0.4371) | Loss 1.7262(1.8706) | Error 0.1241(0.1387) Steps 392(382.46) | Grad Norm 3.3318(4.4160) | Total Time 10.00(10.00)\n",
      "Iter 0229 | Time 27.0333(26.5456) | Bit/dim 1.6234(1.6512) | Xent 0.4456(0.4373) | Loss 1.8462(1.8698) | Error 0.1428(0.1388) Steps 392(382.75) | Grad Norm 10.5720(4.6007) | Total Time 10.00(10.00)\n",
      "Iter 0230 | Time 25.9710(26.5284) | Bit/dim 1.6027(1.6497) | Xent 0.8563(0.4499) | Loss 2.0309(1.8747) | Error 0.2929(0.1435) Steps 374(382.48) | Grad Norm 13.2662(4.8607) | Total Time 10.00(10.00)\n",
      "Iter 0231 | Time 23.9483(26.4510) | Bit/dim 2.1818(1.6657) | Xent 0.7753(0.4597) | Loss 2.5695(1.8955) | Error 0.1850(0.1447) Steps 356(381.69) | Grad Norm 14.1022(5.1379) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 13.7885, Epoch Time 207.7087(223.1070), Bit/dim 1.9776(best: 1.4849), Xent 0.3525, Loss 2.1538, Error 0.1073(best: 0.0708)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0232 | Time 24.9866(26.4070) | Bit/dim 1.9819(1.6752) | Xent 0.4924(0.4606) | Loss 2.2281(1.9055) | Error 0.1461(0.1447) Steps 362(381.10) | Grad Norm 7.0908(5.1965) | Total Time 10.00(10.00)\n",
      "Iter 0233 | Time 26.4745(26.4091) | Bit/dim 1.7033(1.6760) | Xent 0.5246(0.4626) | Loss 1.9656(1.9073) | Error 0.1720(0.1456) Steps 386(381.24) | Grad Norm 3.7870(5.1542) | Total Time 10.00(10.00)\n",
      "Iter 0234 | Time 26.5797(26.4142) | Bit/dim 1.6648(1.6757) | Xent 0.7524(0.4713) | Loss 2.0410(1.9113) | Error 0.2499(0.1487) Steps 386(381.39) | Grad Norm 8.1608(5.2444) | Total Time 10.00(10.00)\n",
      "Iter 0235 | Time 28.3045(26.4709) | Bit/dim 1.7357(1.6775) | Xent 0.8947(0.4840) | Loss 2.1830(1.9195) | Error 0.2943(0.1531) Steps 386(381.53) | Grad Norm 10.5849(5.4046) | Total Time 10.00(10.00)\n",
      "Iter 0236 | Time 25.8366(26.4519) | Bit/dim 1.6959(1.6780) | Xent 0.5825(0.4869) | Loss 1.9871(1.9215) | Error 0.1829(0.1539) Steps 380(381.48) | Grad Norm 2.7888(5.3261) | Total Time 10.00(10.00)\n",
      "Iter 0237 | Time 26.5008(26.4533) | Bit/dim 1.6664(1.6777) | Xent 0.6438(0.4916) | Loss 1.9884(1.9235) | Error 0.1986(0.1553) Steps 380(381.44) | Grad Norm 5.0756(5.3186) | Total Time 10.00(10.00)\n",
      "Iter 0238 | Time 26.1010(26.4428) | Bit/dim 1.6753(1.6776) | Xent 0.5496(0.4934) | Loss 1.9501(1.9243) | Error 0.1681(0.1557) Steps 380(381.39) | Grad Norm 3.0781(5.2514) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 14.7143, Epoch Time 211.8912(222.7705), Bit/dim 1.6832(best: 1.4849), Xent 0.3481, Loss 1.8573, Error 0.1091(best: 0.0708)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0239 | Time 26.5132(26.4449) | Bit/dim 1.6813(1.6777) | Xent 0.5217(0.4942) | Loss 1.9422(1.9248) | Error 0.1593(0.1558) Steps 380(381.35) | Grad Norm 3.5006(5.1989) | Total Time 10.00(10.00)\n",
      "Iter 0240 | Time 26.7039(26.4527) | Bit/dim 1.6345(1.6764) | Xent 0.4813(0.4938) | Loss 1.8752(1.9233) | Error 0.1521(0.1557) Steps 386(381.49) | Grad Norm 1.9218(5.1006) | Total Time 10.00(10.00)\n",
      "Iter 0241 | Time 27.5324(26.4850) | Bit/dim 1.6098(1.6744) | Xent 0.5993(0.4970) | Loss 1.9094(1.9229) | Error 0.2025(0.1571) Steps 392(381.81) | Grad Norm 3.5209(5.0532) | Total Time 10.00(10.00)\n",
      "Iter 0242 | Time 27.5682(26.5175) | Bit/dim 1.5933(1.6720) | Xent 0.5351(0.4981) | Loss 1.8608(1.9211) | Error 0.1735(0.1576) Steps 392(382.11) | Grad Norm 2.5514(4.9781) | Total Time 10.00(10.00)\n",
      "Iter 0243 | Time 26.7238(26.5237) | Bit/dim 1.5881(1.6695) | Xent 0.5085(0.4984) | Loss 1.8423(1.9187) | Error 0.1671(0.1579) Steps 380(382.05) | Grad Norm 2.9941(4.9186) | Total Time 10.00(10.00)\n",
      "Iter 0244 | Time 26.2727(26.5162) | Bit/dim 1.5679(1.6664) | Xent 0.5353(0.4996) | Loss 1.8356(1.9162) | Error 0.1689(0.1582) Steps 392(382.35) | Grad Norm 2.4127(4.8434) | Total Time 10.00(10.00)\n",
      "Iter 0245 | Time 27.3838(26.5422) | Bit/dim 1.5569(1.6631) | Xent 0.5468(0.5010) | Loss 1.8303(1.9136) | Error 0.1753(0.1587) Steps 398(382.82) | Grad Norm 4.2558(4.8258) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 14.7280, Epoch Time 215.7698(222.5605), Bit/dim 1.5611(best: 1.4849), Xent 0.3253, Loss 1.7237, Error 0.0995(best: 0.0708)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0246 | Time 25.9090(26.5232) | Bit/dim 1.5637(1.6602) | Xent 0.4865(0.5005) | Loss 1.8069(1.9104) | Error 0.1526(0.1585) Steps 380(382.73) | Grad Norm 2.5584(4.7578) | Total Time 10.00(10.00)\n",
      "Iter 0247 | Time 25.9284(26.5054) | Bit/dim 1.5426(1.6566) | Xent 0.4947(0.5004) | Loss 1.7900(1.9068) | Error 0.1554(0.1584) Steps 380(382.65) | Grad Norm 2.1089(4.6783) | Total Time 10.00(10.00)\n",
      "Iter 0248 | Time 28.8384(26.5754) | Bit/dim 1.5154(1.6524) | Xent 0.5174(0.5009) | Loss 1.7741(1.9028) | Error 0.1686(0.1587) Steps 398(383.11) | Grad Norm 4.5247(4.6737) | Total Time 10.00(10.00)\n",
      "Iter 0249 | Time 26.1562(26.5628) | Bit/dim 1.5347(1.6489) | Xent 0.4983(0.5008) | Loss 1.7838(1.8993) | Error 0.1545(0.1586) Steps 374(382.84) | Grad Norm 5.1624(4.6884) | Total Time 10.00(10.00)\n",
      "Iter 0250 | Time 27.7500(26.5984) | Bit/dim 1.5167(1.6449) | Xent 0.5311(0.5017) | Loss 1.7822(1.8958) | Error 0.1751(0.1591) Steps 380(382.75) | Grad Norm 4.2409(4.6749) | Total Time 10.00(10.00)\n",
      "Iter 0251 | Time 25.8504(26.5760) | Bit/dim 1.5275(1.6414) | Xent 0.4866(0.5012) | Loss 1.7708(1.8920) | Error 0.1540(0.1589) Steps 374(382.49) | Grad Norm 4.4081(4.6669) | Total Time 10.00(10.00)\n",
      "Iter 0252 | Time 26.4072(26.5709) | Bit/dim 1.4951(1.6370) | Xent 0.4890(0.5009) | Loss 1.7396(1.8874) | Error 0.1540(0.1588) Steps 380(382.41) | Grad Norm 2.0132(4.5873) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 14.5432, Epoch Time 213.7520(222.2962), Bit/dim 1.4800(best: 1.4849), Xent 0.3109, Loss 1.6354, Error 0.0946(best: 0.0708)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0253 | Time 26.3056(26.5630) | Bit/dim 1.4836(1.6324) | Xent 0.4907(0.5006) | Loss 1.7290(1.8827) | Error 0.1617(0.1589) Steps 380(382.34) | Grad Norm 2.1255(4.5135) | Total Time 10.00(10.00)\n",
      "Iter 0254 | Time 25.9110(26.5434) | Bit/dim 1.5074(1.6286) | Xent 0.4503(0.4991) | Loss 1.7326(1.8782) | Error 0.1494(0.1586) Steps 374(382.09) | Grad Norm 4.0146(4.4985) | Total Time 10.00(10.00)\n",
      "Iter 0255 | Time 28.8822(26.6136) | Bit/dim 1.4900(1.6245) | Xent 0.4849(0.4986) | Loss 1.7325(1.8738) | Error 0.1532(0.1584) Steps 410(382.93) | Grad Norm 6.5260(4.5593) | Total Time 10.00(10.00)\n",
      "Iter 0256 | Time 25.8934(26.5920) | Bit/dim 1.5425(1.6220) | Xent 0.3982(0.4956) | Loss 1.7416(1.8698) | Error 0.1290(0.1576) Steps 374(382.66) | Grad Norm 7.9838(4.6621) | Total Time 10.00(10.00)\n",
      "Iter 0257 | Time 27.5397(26.6204) | Bit/dim 1.4824(1.6178) | Xent 0.4727(0.4949) | Loss 1.7187(1.8653) | Error 0.1499(0.1573) Steps 404(383.30) | Grad Norm 5.7987(4.6962) | Total Time 10.00(10.00)\n",
      "Iter 0258 | Time 25.5511(26.5883) | Bit/dim 1.4763(1.6136) | Xent 0.4532(0.4937) | Loss 1.7029(1.8604) | Error 0.1401(0.1568) Steps 374(383.02) | Grad Norm 2.7530(4.6379) | Total Time 10.00(10.00)\n",
      "Iter 0259 | Time 25.8889(26.5673) | Bit/dim 1.4645(1.6091) | Xent 0.4358(0.4920) | Loss 1.6824(1.8551) | Error 0.1401(0.1563) Steps 374(382.75) | Grad Norm 1.0925(4.5315) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 14.4690, Epoch Time 212.8902(222.0140), Bit/dim 1.4503(best: 1.4800), Xent 0.3035, Loss 1.6020, Error 0.0958(best: 0.0708)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0260 | Time 26.9542(26.5789) | Bit/dim 1.4561(1.6045) | Xent 0.4632(0.4911) | Loss 1.6877(1.8501) | Error 0.1495(0.1561) Steps 374(382.49) | Grad Norm 4.8698(4.5417) | Total Time 10.00(10.00)\n",
      "Iter 0261 | Time 26.2182(26.5681) | Bit/dim 1.5153(1.6018) | Xent 0.3840(0.4879) | Loss 1.7073(1.8458) | Error 0.1234(0.1551) Steps 374(382.23) | Grad Norm 7.9981(4.6453) | Total Time 10.00(10.00)\n",
      "Iter 0262 | Time 27.3771(26.5924) | Bit/dim 1.4862(1.5984) | Xent 0.4779(0.4876) | Loss 1.7252(1.8422) | Error 0.1554(0.1551) Steps 392(382.53) | Grad Norm 9.3485(4.7864) | Total Time 10.00(10.00)\n",
      "Iter 0263 | Time 25.6427(26.5639) | Bit/dim 1.5342(1.5964) | Xent 0.3906(0.4847) | Loss 1.7295(1.8388) | Error 0.1240(0.1542) Steps 374(382.27) | Grad Norm 8.4865(4.8974) | Total Time 10.00(10.00)\n",
      "Iter 0264 | Time 25.5252(26.5327) | Bit/dim 1.4576(1.5923) | Xent 0.3975(0.4821) | Loss 1.6563(1.8333) | Error 0.1274(0.1534) Steps 374(382.02) | Grad Norm 1.6457(4.7999) | Total Time 10.00(10.00)\n",
      "Iter 0265 | Time 27.8831(26.5732) | Bit/dim 1.4750(1.5888) | Xent 0.4636(0.4815) | Loss 1.7068(1.8295) | Error 0.1476(0.1532) Steps 398(382.50) | Grad Norm 8.2600(4.9037) | Total Time 10.00(10.00)\n",
      "Iter 0266 | Time 25.9442(26.5544) | Bit/dim 1.5535(1.5877) | Xent 0.4021(0.4791) | Loss 1.7546(1.8273) | Error 0.1249(0.1524) Steps 374(382.25) | Grad Norm 8.4749(5.0108) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 14.6652, Epoch Time 212.6895(221.7343), Bit/dim 1.4681(best: 1.4503), Xent 0.2523, Loss 1.5943, Error 0.0790(best: 0.0708)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0267 | Time 25.9856(26.5373) | Bit/dim 1.4803(1.5845) | Xent 0.3923(0.4765) | Loss 1.6765(1.8227) | Error 0.1239(0.1515) Steps 380(382.18) | Grad Norm 3.7303(4.9724) | Total Time 10.00(10.00)\n",
      "Iter 0268 | Time 28.5512(26.5977) | Bit/dim 1.5473(1.5834) | Xent 0.4593(0.4760) | Loss 1.7770(1.8214) | Error 0.1466(0.1514) Steps 398(382.65) | Grad Norm 11.1258(5.1570) | Total Time 10.00(10.00)\n",
      "Iter 0269 | Time 26.9323(26.6078) | Bit/dim 1.4762(1.5802) | Xent 0.3982(0.4737) | Loss 1.6753(1.8170) | Error 0.1250(0.1506) Steps 380(382.58) | Grad Norm 3.5700(5.1094) | Total Time 10.00(10.00)\n",
      "Iter 0270 | Time 26.0296(26.5904) | Bit/dim 1.5302(1.5787) | Xent 0.3864(0.4710) | Loss 1.7234(1.8142) | Error 0.1229(0.1497) Steps 374(382.32) | Grad Norm 5.4501(5.1196) | Total Time 10.00(10.00)\n",
      "Iter 0271 | Time 27.3979(26.6146) | Bit/dim 1.4544(1.5749) | Xent 0.3903(0.4686) | Loss 1.6496(1.8092) | Error 0.1275(0.1491) Steps 380(382.25) | Grad Norm 0.9063(4.9932) | Total Time 10.00(10.00)\n",
      "Iter 0272 | Time 26.2180(26.6027) | Bit/dim 1.4890(1.5724) | Xent 0.4092(0.4668) | Loss 1.6936(1.8058) | Error 0.1330(0.1486) Steps 380(382.18) | Grad Norm 6.4099(5.0357) | Total Time 10.00(10.00)\n",
      "Iter 0273 | Time 27.6252(26.6334) | Bit/dim 1.4626(1.5691) | Xent 0.3733(0.4640) | Loss 1.6493(1.8011) | Error 0.1188(0.1477) Steps 392(382.48) | Grad Norm 1.9518(4.9432) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 14.6075, Epoch Time 215.6433(221.5516), Bit/dim 1.4861(best: 1.4503), Xent 0.2500, Loss 1.6111, Error 0.0755(best: 0.0708)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0274 | Time 26.5038(26.6295) | Bit/dim 1.4917(1.5667) | Xent 0.3624(0.4610) | Loss 1.6729(1.7972) | Error 0.1156(0.1467) Steps 380(382.40) | Grad Norm 4.2111(4.9212) | Total Time 10.00(10.00)\n",
      "Iter 0275 | Time 27.1565(26.6453) | Bit/dim 1.4454(1.5631) | Xent 0.3861(0.4587) | Loss 1.6385(1.7925) | Error 0.1250(0.1461) Steps 398(382.87) | Grad Norm 1.4170(4.8161) | Total Time 10.00(10.00)\n",
      "Iter 0276 | Time 26.1772(26.6313) | Bit/dim 1.4477(1.5596) | Xent 0.4265(0.4578) | Loss 1.6609(1.7885) | Error 0.1341(0.1457) Steps 386(382.96) | Grad Norm 5.6033(4.8397) | Total Time 10.00(10.00)\n",
      "Iter 0277 | Time 26.3867(26.6240) | Bit/dim 1.4728(1.5570) | Xent 0.3697(0.4551) | Loss 1.6577(1.7846) | Error 0.1190(0.1449) Steps 380(382.87) | Grad Norm 4.1354(4.8186) | Total Time 10.00(10.00)\n",
      "Iter 0278 | Time 25.5084(26.5905) | Bit/dim 1.4619(1.5542) | Xent 0.3607(0.4523) | Loss 1.6422(1.7803) | Error 0.1071(0.1438) Steps 368(382.43) | Grad Norm 3.8791(4.7904) | Total Time 10.00(10.00)\n",
      "Iter 0279 | Time 25.2522(26.5503) | Bit/dim 1.4424(1.5508) | Xent 0.4052(0.4509) | Loss 1.6450(1.7763) | Error 0.1336(0.1435) Steps 368(382.00) | Grad Norm 6.1245(4.8304) | Total Time 10.00(10.00)\n",
      "Iter 0280 | Time 26.8910(26.5606) | Bit/dim 1.4175(1.5468) | Xent 0.3574(0.4481) | Loss 1.5962(1.7709) | Error 0.1162(0.1427) Steps 368(381.58) | Grad Norm 1.3341(4.7256) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 14.5361, Epoch Time 210.7957(221.2289), Bit/dim 1.4405(best: 1.4503), Xent 0.2322, Loss 1.5566, Error 0.0714(best: 0.0708)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0281 | Time 25.1017(26.5168) | Bit/dim 1.4497(1.5439) | Xent 0.3553(0.4453) | Loss 1.6273(1.7666) | Error 0.1094(0.1417) Steps 362(380.99) | Grad Norm 3.7845(4.6973) | Total Time 10.00(10.00)\n",
      "Iter 0282 | Time 25.1340(26.4753) | Bit/dim 1.4241(1.5403) | Xent 0.3457(0.4423) | Loss 1.5970(1.7615) | Error 0.1114(0.1408) Steps 362(380.42) | Grad Norm 2.7382(4.6385) | Total Time 10.00(10.00)\n",
      "Iter 0283 | Time 25.3693(26.4421) | Bit/dim 1.4087(1.5364) | Xent 0.3665(0.4400) | Loss 1.5919(1.7564) | Error 0.1142(0.1400) Steps 362(379.87) | Grad Norm 2.0357(4.5605) | Total Time 10.00(10.00)\n",
      "Iter 0284 | Time 24.7884(26.3925) | Bit/dim 1.4358(1.5334) | Xent 0.3309(0.4368) | Loss 1.6012(1.7517) | Error 0.1032(0.1389) Steps 362(379.33) | Grad Norm 4.1336(4.5477) | Total Time 10.00(10.00)\n",
      "Iter 0285 | Time 25.1567(26.3554) | Bit/dim 1.4026(1.5294) | Xent 0.3765(0.4350) | Loss 1.5909(1.7469) | Error 0.1226(0.1384) Steps 356(378.63) | Grad Norm 1.2519(4.4488) | Total Time 10.00(10.00)\n",
      "Iter 0286 | Time 25.1792(26.3202) | Bit/dim 1.4041(1.5257) | Xent 0.3547(0.4325) | Loss 1.5815(1.7419) | Error 0.1149(0.1377) Steps 356(377.95) | Grad Norm 3.9597(4.4341) | Total Time 10.00(10.00)\n",
      "Iter 0287 | Time 24.9637(26.2795) | Bit/dim 1.4450(1.5233) | Xent 0.3323(0.4295) | Loss 1.6112(1.7380) | Error 0.1020(0.1366) Steps 362(377.47) | Grad Norm 5.6839(4.4716) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 14.0106, Epoch Time 202.1193(220.6556), Bit/dim 1.3949(best: 1.4405), Xent 0.2198, Loss 1.5049, Error 0.0661(best: 0.0708)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0288 | Time 25.0549(26.2427) | Bit/dim 1.4030(1.5196) | Xent 0.3504(0.4272) | Loss 1.5782(1.7332) | Error 0.1075(0.1357) Steps 356(376.83) | Grad Norm 3.5014(4.4425) | Total Time 10.00(10.00)\n",
      "Iter 0289 | Time 24.9597(26.2042) | Bit/dim 1.3938(1.5159) | Xent 0.3493(0.4248) | Loss 1.5685(1.7283) | Error 0.1092(0.1349) Steps 356(376.20) | Grad Norm 0.6656(4.3292) | Total Time 10.00(10.00)\n",
      "Iter 0290 | Time 25.3142(26.1775) | Bit/dim 1.3948(1.5122) | Xent 0.3333(0.4221) | Loss 1.5615(1.7233) | Error 0.1068(0.1341) Steps 356(375.60) | Grad Norm 2.5333(4.2753) | Total Time 10.00(10.00)\n",
      "Iter 0291 | Time 25.4902(26.1569) | Bit/dim 1.3986(1.5088) | Xent 0.3514(0.4200) | Loss 1.5743(1.7188) | Error 0.1158(0.1335) Steps 368(375.37) | Grad Norm 5.6424(4.3163) | Total Time 10.00(10.00)\n",
      "Iter 0292 | Time 25.1140(26.1256) | Bit/dim 1.4494(1.5070) | Xent 0.3168(0.4169) | Loss 1.6078(1.7155) | Error 0.0978(0.1325) Steps 362(374.97) | Grad Norm 8.2254(4.4336) | Total Time 10.00(10.00)\n",
      "Iter 0293 | Time 26.7582(26.1446) | Bit/dim 1.4219(1.5045) | Xent 0.3637(0.4153) | Loss 1.6037(1.7121) | Error 0.1204(0.1321) Steps 374(374.94) | Grad Norm 8.9471(4.5690) | Total Time 10.00(10.00)\n",
      "Iter 0294 | Time 24.9454(26.1086) | Bit/dim 1.4601(1.5032) | Xent 0.3073(0.4120) | Loss 1.6138(1.7092) | Error 0.0933(0.1309) Steps 356(374.37) | Grad Norm 7.4140(4.6544) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 14.1019, Epoch Time 204.1122(220.1593), Bit/dim 1.3875(best: 1.3949), Xent 0.2045, Loss 1.4897, Error 0.0588(best: 0.0661)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0295 | Time 25.0397(26.0766) | Bit/dim 1.3934(1.4999) | Xent 0.3279(0.4095) | Loss 1.5573(1.7046) | Error 0.1029(0.1301) Steps 356(373.82) | Grad Norm 1.0470(4.5461) | Total Time 10.00(10.00)\n",
      "Iter 0296 | Time 26.5782(26.0916) | Bit/dim 1.4242(1.4976) | Xent 0.3653(0.4082) | Loss 1.6069(1.7017) | Error 0.1218(0.1298) Steps 374(373.83) | Grad Norm 8.0420(4.6510) | Total Time 10.00(10.00)\n",
      "Iter 0297 | Time 25.0580(26.0606) | Bit/dim 1.4841(1.4972) | Xent 0.2969(0.4048) | Loss 1.6326(1.6996) | Error 0.0954(0.1288) Steps 362(373.47) | Grad Norm 7.4270(4.7343) | Total Time 10.00(10.00)\n",
      "Iter 0298 | Time 25.5655(26.0457) | Bit/dim 1.4251(1.4950) | Xent 0.2914(0.4014) | Loss 1.5708(1.6957) | Error 0.0924(0.1277) Steps 356(372.95) | Grad Norm 3.7546(4.7049) | Total Time 10.00(10.00)\n",
      "Iter 0299 | Time 26.9766(26.0737) | Bit/dim 1.4683(1.4942) | Xent 0.3674(0.4004) | Loss 1.6520(1.6944) | Error 0.1216(0.1275) Steps 374(372.98) | Grad Norm 9.8530(4.8593) | Total Time 10.00(10.00)\n",
      "Iter 0300 | Time 25.8621(26.0673) | Bit/dim 1.4108(1.4917) | Xent 0.3102(0.3977) | Loss 1.5659(1.6906) | Error 0.0965(0.1266) Steps 356(372.47) | Grad Norm 3.5786(4.8209) | Total Time 10.00(10.00)\n",
      "Iter 0301 | Time 24.8751(26.0316) | Bit/dim 1.4506(1.4905) | Xent 0.2786(0.3941) | Loss 1.5899(1.6876) | Error 0.0861(0.1254) Steps 356(371.97) | Grad Norm 5.0700(4.8284) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 13.9858, Epoch Time 206.4455(219.7479), Bit/dim 1.4043(best: 1.3875), Xent 0.2001, Loss 1.5043, Error 0.0618(best: 0.0588)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0302 | Time 27.1271(26.0644) | Bit/dim 1.4046(1.4879) | Xent 0.3045(0.3914) | Loss 1.5568(1.6836) | Error 0.0955(0.1245) Steps 356(371.50) | Grad Norm 3.1131(4.7769) | Total Time 10.00(10.00)\n",
      "Iter 0303 | Time 24.9492(26.0310) | Bit/dim 1.4087(1.4855) | Xent 0.3682(0.3908) | Loss 1.5928(1.6809) | Error 0.1196(0.1243) Steps 356(371.03) | Grad Norm 5.0663(4.7856) | Total Time 10.00(10.00)\n",
      "Iter 0304 | Time 24.7869(25.9936) | Bit/dim 1.4266(1.4838) | Xent 0.2753(0.3873) | Loss 1.5642(1.6774) | Error 0.0859(0.1232) Steps 356(370.58) | Grad Norm 3.2849(4.7406) | Total Time 10.00(10.00)\n",
      "Iter 0305 | Time 24.8594(25.9596) | Bit/dim 1.4278(1.4821) | Xent 0.2943(0.3845) | Loss 1.5750(1.6743) | Error 0.0949(0.1223) Steps 356(370.14) | Grad Norm 3.2601(4.6962) | Total Time 10.00(10.00)\n",
      "Iter 0306 | Time 25.3734(25.9420) | Bit/dim 1.3885(1.4793) | Xent 0.3530(0.3836) | Loss 1.5650(1.6711) | Error 0.1158(0.1221) Steps 356(369.72) | Grad Norm 4.2095(4.6816) | Total Time 10.00(10.00)\n",
      "Iter 0307 | Time 25.0601(25.9156) | Bit/dim 1.3755(1.4762) | Xent 0.2910(0.3808) | Loss 1.5211(1.6666) | Error 0.0942(0.1213) Steps 356(369.31) | Grad Norm 0.9748(4.5704) | Total Time 10.00(10.00)\n",
      "Iter 0308 | Time 24.7982(25.8820) | Bit/dim 1.4099(1.4742) | Xent 0.2797(0.3777) | Loss 1.5498(1.6631) | Error 0.0907(0.1204) Steps 356(368.91) | Grad Norm 3.7669(4.5463) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 13.9287, Epoch Time 203.3173(219.2550), Bit/dim 1.3682(best: 1.3875), Xent 0.1852, Loss 1.4608, Error 0.0581(best: 0.0588)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0309 | Time 27.1171(25.9191) | Bit/dim 1.3768(1.4713) | Xent 0.3037(0.3755) | Loss 1.5286(1.6590) | Error 0.0982(0.1197) Steps 356(368.52) | Grad Norm 1.7712(4.4630) | Total Time 10.00(10.00)\n",
      "Iter 0310 | Time 24.9087(25.8888) | Bit/dim 1.3622(1.4680) | Xent 0.3423(0.3745) | Loss 1.5334(1.6553) | Error 0.1138(0.1195) Steps 356(368.14) | Grad Norm 3.4419(4.4324) | Total Time 10.00(10.00)\n",
      "Iter 0311 | Time 25.1867(25.8677) | Bit/dim 1.3944(1.4658) | Xent 0.2884(0.3719) | Loss 1.5386(1.6518) | Error 0.0890(0.1186) Steps 356(367.78) | Grad Norm 4.9417(4.4477) | Total Time 10.00(10.00)\n",
      "Iter 0312 | Time 25.9748(25.8709) | Bit/dim 1.3880(1.4634) | Xent 0.2932(0.3696) | Loss 1.5346(1.6482) | Error 0.0975(0.1180) Steps 368(367.79) | Grad Norm 4.3615(4.4451) | Total Time 10.00(10.00)\n",
      "Iter 0313 | Time 25.1810(25.8502) | Bit/dim 1.3700(1.4606) | Xent 0.2983(0.3674) | Loss 1.5192(1.6444) | Error 0.0989(0.1174) Steps 356(367.43) | Grad Norm 2.9247(4.3995) | Total Time 10.00(10.00)\n",
      "Iter 0314 | Time 24.9730(25.8239) | Bit/dim 1.3537(1.4574) | Xent 0.3143(0.3658) | Loss 1.5108(1.6404) | Error 0.0982(0.1168) Steps 356(367.09) | Grad Norm 1.7462(4.3199) | Total Time 10.00(10.00)\n",
      "Iter 0315 | Time 26.0743(25.8314) | Bit/dim 1.3603(1.4545) | Xent 0.2877(0.3635) | Loss 1.5041(1.6363) | Error 0.0901(0.1160) Steps 368(367.12) | Grad Norm 1.5409(4.2365) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 13.9112, Epoch Time 205.5501(218.8438), Bit/dim 1.3510(best: 1.3682), Xent 0.1753, Loss 1.4387, Error 0.0551(best: 0.0581)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0316 | Time 24.7863(25.8001) | Bit/dim 1.3604(1.4517) | Xent 0.2905(0.3613) | Loss 1.5056(1.6324) | Error 0.0931(0.1154) Steps 356(366.78) | Grad Norm 2.0505(4.1709) | Total Time 10.00(10.00)\n",
      "Iter 0317 | Time 25.8495(25.8016) | Bit/dim 1.3566(1.4488) | Xent 0.2961(0.3594) | Loss 1.5047(1.6285) | Error 0.0941(0.1147) Steps 368(366.82) | Grad Norm 3.6853(4.1564) | Total Time 10.00(10.00)\n",
      "Iter 0318 | Time 25.2354(25.7846) | Bit/dim 1.3831(1.4469) | Xent 0.2676(0.3566) | Loss 1.5169(1.6252) | Error 0.0846(0.1138) Steps 356(366.50) | Grad Norm 6.3252(4.2214) | Total Time 10.00(10.00)\n",
      "Iter 0319 | Time 27.1235(25.8247) | Bit/dim 1.4337(1.4465) | Xent 0.3376(0.3560) | Loss 1.6025(1.6245) | Error 0.1052(0.1136) Steps 380(366.90) | Grad Norm 13.4272(4.4976) | Total Time 10.00(10.00)\n",
      "Iter 0320 | Time 25.3744(25.8112) | Bit/dim 1.6694(1.4532) | Xent 0.2997(0.3543) | Loss 1.8193(1.6303) | Error 0.0949(0.1130) Steps 362(366.75) | Grad Norm 13.7836(4.7762) | Total Time 10.00(10.00)\n",
      "Iter 0321 | Time 25.4546(25.8005) | Bit/dim 1.4575(1.4533) | Xent 0.2914(0.3525) | Loss 1.6032(1.6295) | Error 0.0894(0.1123) Steps 362(366.61) | Grad Norm 3.3852(4.7344) | Total Time 10.00(10.00)\n",
      "Iter 0322 | Time 27.1338(25.8405) | Bit/dim 1.5193(1.4553) | Xent 0.3883(0.3535) | Loss 1.7135(1.6320) | Error 0.1240(0.1126) Steps 374(366.83) | Grad Norm 7.2859(4.8110) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 14.5564, Epoch Time 207.9384(218.5167), Bit/dim 1.4499(best: 1.3510), Xent 0.1901, Loss 1.5450, Error 0.0589(best: 0.0551)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0323 | Time 25.2950(25.8242) | Bit/dim 1.4546(1.4553) | Xent 0.2941(0.3517) | Loss 1.6016(1.6311) | Error 0.0920(0.1120) Steps 362(366.69) | Grad Norm 2.5571(4.7434) | Total Time 10.00(10.00)\n",
      "Iter 0324 | Time 25.1139(25.8029) | Bit/dim 1.4584(1.4554) | Xent 0.2813(0.3496) | Loss 1.5991(1.6302) | Error 0.0897(0.1114) Steps 368(366.73) | Grad Norm 3.2104(4.6974) | Total Time 10.00(10.00)\n",
      "Iter 0325 | Time 25.2809(25.7872) | Bit/dim 1.4640(1.4556) | Xent 0.2908(0.3479) | Loss 1.6095(1.6295) | Error 0.0946(0.1109) Steps 368(366.77) | Grad Norm 3.4954(4.6613) | Total Time 10.00(10.00)\n",
      "Iter 0326 | Time 25.1147(25.7670) | Bit/dim 1.4234(1.4546) | Xent 0.2836(0.3459) | Loss 1.5652(1.6276) | Error 0.0921(0.1103) Steps 368(366.80) | Grad Norm 1.8376(4.5766) | Total Time 10.00(10.00)\n",
      "Iter 0327 | Time 27.8064(25.8282) | Bit/dim 1.4321(1.4540) | Xent 0.3034(0.3447) | Loss 1.5838(1.6263) | Error 0.0972(0.1099) Steps 386(367.38) | Grad Norm 3.7535(4.5519) | Total Time 10.00(10.00)\n",
      "Iter 0328 | Time 26.8658(25.8593) | Bit/dim 1.4174(1.4529) | Xent 0.2908(0.3431) | Loss 1.5628(1.6244) | Error 0.0900(0.1093) Steps 380(367.76) | Grad Norm 1.8209(4.4700) | Total Time 10.00(10.00)\n",
      "Iter 0329 | Time 25.4761(25.8478) | Bit/dim 1.4263(1.4521) | Xent 0.2885(0.3414) | Loss 1.5705(1.6228) | Error 0.0919(0.1088) Steps 368(367.76) | Grad Norm 2.1938(4.4017) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 14.4038, Epoch Time 207.6654(218.1911), Bit/dim 1.4054(best: 1.3510), Xent 0.1614, Loss 1.4861, Error 0.0530(best: 0.0551)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0330 | Time 25.3232(25.8321) | Bit/dim 1.4080(1.4508) | Xent 0.2685(0.3392) | Loss 1.5422(1.6204) | Error 0.0840(0.1080) Steps 362(367.59) | Grad Norm 1.9303(4.3276) | Total Time 10.00(10.00)\n",
      "Iter 0331 | Time 24.8971(25.8040) | Bit/dim 1.3963(1.4491) | Xent 0.2693(0.3371) | Loss 1.5309(1.6177) | Error 0.0836(0.1073) Steps 356(367.24) | Grad Norm 2.3820(4.2692) | Total Time 10.00(10.00)\n",
      "Iter 0332 | Time 25.4074(25.7921) | Bit/dim 1.3957(1.4475) | Xent 0.2712(0.3352) | Loss 1.5313(1.6151) | Error 0.0863(0.1067) Steps 356(366.91) | Grad Norm 2.1047(4.2043) | Total Time 10.00(10.00)\n",
      "Iter 0333 | Time 25.1714(25.7735) | Bit/dim 1.3795(1.4455) | Xent 0.2777(0.3334) | Loss 1.5183(1.6122) | Error 0.0896(0.1062) Steps 356(366.58) | Grad Norm 1.4589(4.1219) | Total Time 10.00(10.00)\n",
      "Iter 0334 | Time 25.7769(25.7736) | Bit/dim 1.3671(1.4431) | Xent 0.3228(0.3331) | Loss 1.5285(1.6097) | Error 0.0995(0.1060) Steps 368(366.62) | Grad Norm 3.1164(4.0917) | Total Time 10.00(10.00)\n",
      "Iter 0335 | Time 25.0185(25.7510) | Bit/dim 1.3810(1.4413) | Xent 0.2664(0.3311) | Loss 1.5142(1.6068) | Error 0.0834(0.1053) Steps 362(366.48) | Grad Norm 3.9033(4.0861) | Total Time 10.00(10.00)\n",
      "Iter 0336 | Time 26.8409(25.7837) | Bit/dim 1.3742(1.4392) | Xent 0.2817(0.3296) | Loss 1.5150(1.6041) | Error 0.0850(0.1047) Steps 368(366.53) | Grad Norm 2.9160(4.0510) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 15.0266, Epoch Time 205.7658(217.8184), Bit/dim 1.3579(best: 1.3510), Xent 0.1486, Loss 1.4322, Error 0.0474(best: 0.0530)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0337 | Time 26.4109(25.8025) | Bit/dim 1.3643(1.4370) | Xent 0.2552(0.3274) | Loss 1.4919(1.6007) | Error 0.0819(0.1040) Steps 374(366.75) | Grad Norm 1.2725(3.9676) | Total Time 10.00(10.00)\n",
      "Iter 0338 | Time 26.6363(25.8275) | Bit/dim 1.3584(1.4346) | Xent 0.2666(0.3256) | Loss 1.4917(1.5974) | Error 0.0851(0.1034) Steps 374(366.97) | Grad Norm 1.7246(3.9003) | Total Time 10.00(10.00)\n",
      "Iter 0339 | Time 28.5297(25.9086) | Bit/dim 1.3554(1.4323) | Xent 0.2545(0.3234) | Loss 1.4826(1.5940) | Error 0.0804(0.1027) Steps 374(367.18) | Grad Norm 2.8967(3.8702) | Total Time 10.00(10.00)\n",
      "Iter 0340 | Time 26.2215(25.9180) | Bit/dim 1.3678(1.4303) | Xent 0.2459(0.3211) | Loss 1.4908(1.5909) | Error 0.0786(0.1020) Steps 374(367.39) | Grad Norm 4.4782(3.8885) | Total Time 10.00(10.00)\n",
      "Iter 0341 | Time 26.9574(25.9491) | Bit/dim 1.3601(1.4282) | Xent 0.3165(0.3210) | Loss 1.5183(1.5887) | Error 0.1011(0.1020) Steps 374(367.58) | Grad Norm 8.1639(4.0167) | Total Time 10.00(10.00)\n",
      "Iter 0342 | Time 26.3983(25.9626) | Bit/dim 1.5031(1.4305) | Xent 0.2355(0.3184) | Loss 1.6208(1.5897) | Error 0.0746(0.1012) Steps 362(367.42) | Grad Norm 9.7790(4.1896) | Total Time 10.00(10.00)\n",
      "Iter 0343 | Time 25.8501(25.9592) | Bit/dim 1.3576(1.4283) | Xent 0.2464(0.3162) | Loss 1.4808(1.5864) | Error 0.0774(0.1005) Steps 368(367.43) | Grad Norm 1.7200(4.1155) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 14.9409, Epoch Time 214.1807(217.7092), Bit/dim 1.5018(best: 1.3510), Xent 0.1877, Loss 1.5957, Error 0.0595(best: 0.0474)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0344 | Time 26.7430(25.9828) | Bit/dim 1.5092(1.4307) | Xent 0.3685(0.3178) | Loss 1.6935(1.5896) | Error 0.1168(0.1009) Steps 374(367.63) | Grad Norm 16.0502(4.4735) | Total Time 10.00(10.00)\n",
      "Iter 0345 | Time 24.4709(25.9374) | Bit/dim 1.6540(1.4374) | Xent 0.2402(0.3155) | Loss 1.7741(1.5952) | Error 0.0774(0.1002) Steps 350(367.10) | Grad Norm 7.1165(4.5528) | Total Time 10.00(10.00)\n",
      "Iter 0346 | Time 22.9131(25.8467) | Bit/dim 1.7286(1.4461) | Xent 0.2357(0.3131) | Loss 1.8464(1.6027) | Error 0.0736(0.0994) Steps 344(366.41) | Grad Norm 5.1888(4.5719) | Total Time 10.00(10.00)\n",
      "Iter 0347 | Time 23.6574(25.7810) | Bit/dim 1.6167(1.4513) | Xent 0.2319(0.3107) | Loss 1.7326(1.6066) | Error 0.0701(0.0986) Steps 344(365.74) | Grad Norm 3.2385(4.5319) | Total Time 10.00(10.00)\n",
      "Iter 0348 | Time 24.3368(25.7377) | Bit/dim 1.5784(1.4551) | Xent 0.2528(0.3089) | Loss 1.7048(1.6095) | Error 0.0797(0.0980) Steps 350(365.26) | Grad Norm 2.3528(4.4665) | Total Time 10.00(10.00)\n",
      "Iter 0349 | Time 24.7447(25.7079) | Bit/dim 1.5943(1.4592) | Xent 0.2662(0.3076) | Loss 1.7275(1.6131) | Error 0.0867(0.0977) Steps 362(365.17) | Grad Norm 2.5491(4.4090) | Total Time 10.00(10.00)\n",
      "Iter 0350 | Time 25.4885(25.7013) | Bit/dim 1.5537(1.4621) | Xent 0.3028(0.3075) | Loss 1.7051(1.6158) | Error 0.0968(0.0976) Steps 362(365.07) | Grad Norm 2.4579(4.3505) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 14.3393, Epoch Time 199.0146(217.1484), Bit/dim 1.5223(best: 1.3510), Xent 0.1538, Loss 1.5992, Error 0.0472(best: 0.0474)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0351 | Time 25.0762(25.6825) | Bit/dim 1.5276(1.4640) | Xent 0.2665(0.3063) | Loss 1.6609(1.6172) | Error 0.0875(0.0973) Steps 362(364.98) | Grad Norm 1.7646(4.2729) | Total Time 10.00(10.00)\n",
      "Iter 0352 | Time 24.9074(25.6593) | Bit/dim 1.5216(1.4658) | Xent 0.2320(0.3040) | Loss 1.6376(1.6178) | Error 0.0741(0.0966) Steps 362(364.89) | Grad Norm 1.5602(4.1915) | Total Time 10.00(10.00)\n",
      "Iter 0353 | Time 24.8411(25.6347) | Bit/dim 1.5071(1.4670) | Xent 0.2133(0.3013) | Loss 1.6137(1.6177) | Error 0.0686(0.0958) Steps 356(364.62) | Grad Norm 1.6484(4.1152) | Total Time 10.00(10.00)\n",
      "Iter 0354 | Time 24.6309(25.6046) | Bit/dim 1.4702(1.4671) | Xent 0.2296(0.2992) | Loss 1.5850(1.6167) | Error 0.0720(0.0951) Steps 356(364.36) | Grad Norm 1.6210(4.0404) | Total Time 10.00(10.00)\n",
      "Iter 0355 | Time 26.3720(25.6276) | Bit/dim 1.4361(1.4662) | Xent 0.2493(0.2977) | Loss 1.5608(1.6150) | Error 0.0844(0.0948) Steps 356(364.11) | Grad Norm 1.9639(3.9781) | Total Time 10.00(10.00)\n",
      "Iter 0356 | Time 25.9685(25.6379) | Bit/dim 1.4028(1.4643) | Xent 0.2775(0.2971) | Loss 1.5416(1.6128) | Error 0.0895(0.0946) Steps 368(364.23) | Grad Norm 1.6441(3.9081) | Total Time 10.00(10.00)\n",
      "Iter 0357 | Time 26.6202(25.6673) | Bit/dim 1.4081(1.4626) | Xent 0.2724(0.2963) | Loss 1.5443(1.6108) | Error 0.0886(0.0944) Steps 362(364.16) | Grad Norm 1.3357(3.8309) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 14.0497, Epoch Time 205.1329(216.7879), Bit/dim 1.4034(best: 1.3510), Xent 0.1388, Loss 1.4728, Error 0.0464(best: 0.0472)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0358 | Time 25.1146(25.6508) | Bit/dim 1.4126(1.4611) | Xent 0.2346(0.2945) | Loss 1.5299(1.6083) | Error 0.0723(0.0938) Steps 356(363.92) | Grad Norm 1.5661(3.7630) | Total Time 10.00(10.00)\n",
      "Iter 0359 | Time 26.6293(25.6801) | Bit/dim 1.4221(1.4599) | Xent 0.2134(0.2920) | Loss 1.5289(1.6059) | Error 0.0680(0.0930) Steps 368(364.04) | Grad Norm 1.7256(3.7019) | Total Time 10.00(10.00)\n",
      "Iter 0360 | Time 26.7127(25.7111) | Bit/dim 1.4042(1.4583) | Xent 0.2467(0.2907) | Loss 1.5275(1.6036) | Error 0.0767(0.0925) Steps 374(364.34) | Grad Norm 1.7553(3.6435) | Total Time 10.00(10.00)\n",
      "Iter 0361 | Time 25.8052(25.7139) | Bit/dim 1.3861(1.4561) | Xent 0.2181(0.2885) | Loss 1.4952(1.6003) | Error 0.0669(0.0917) Steps 368(364.45) | Grad Norm 1.3087(3.5734) | Total Time 10.00(10.00)\n",
      "Iter 0362 | Time 26.7106(25.7438) | Bit/dim 1.3747(1.4536) | Xent 0.2392(0.2870) | Loss 1.4943(1.5972) | Error 0.0801(0.0914) Steps 374(364.74) | Grad Norm 1.3043(3.5053) | Total Time 10.00(10.00)\n",
      "Iter 0363 | Time 26.6042(25.7696) | Bit/dim 1.3663(1.4510) | Xent 0.2538(0.2860) | Loss 1.4932(1.5940) | Error 0.0807(0.0911) Steps 374(365.01) | Grad Norm 1.4506(3.4437) | Total Time 10.00(10.00)\n",
      "Iter 0364 | Time 26.0587(25.7783) | Bit/dim 1.3673(1.4485) | Xent 0.2451(0.2848) | Loss 1.4899(1.5909) | Error 0.0797(0.0907) Steps 368(365.10) | Grad Norm 0.9428(3.3687) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 14.4926, Epoch Time 210.4035(216.5964), Bit/dim 1.3707(best: 1.3510), Xent 0.1316, Loss 1.4365, Error 0.0428(best: 0.0464)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0365 | Time 25.9917(25.7847) | Bit/dim 1.3741(1.4463) | Xent 0.2187(0.2828) | Loss 1.4835(1.5877) | Error 0.0669(0.0900) Steps 368(365.19) | Grad Norm 1.2469(3.3050) | Total Time 10.00(10.00)\n",
      "Iter 0366 | Time 25.9272(25.7890) | Bit/dim 1.3653(1.4439) | Xent 0.2229(0.2810) | Loss 1.4768(1.5844) | Error 0.0731(0.0895) Steps 374(365.45) | Grad Norm 1.4036(3.2480) | Total Time 10.00(10.00)\n",
      "Iter 0367 | Time 26.7434(25.8176) | Bit/dim 1.3514(1.4411) | Xent 0.2481(0.2800) | Loss 1.4754(1.5811) | Error 0.0796(0.0892) Steps 380(365.89) | Grad Norm 1.9689(3.2096) | Total Time 10.00(10.00)\n",
      "Iter 0368 | Time 25.8736(25.8193) | Bit/dim 1.3601(1.4387) | Xent 0.2277(0.2785) | Loss 1.4740(1.5779) | Error 0.0713(0.0887) Steps 368(365.95) | Grad Norm 2.5186(3.1889) | Total Time 10.00(10.00)\n",
      "Iter 0369 | Time 26.3236(25.8344) | Bit/dim 1.3515(1.4360) | Xent 0.2245(0.2768) | Loss 1.4637(1.5745) | Error 0.0720(0.0882) Steps 380(366.38) | Grad Norm 1.6436(3.1425) | Total Time 10.00(10.00)\n",
      "Iter 0370 | Time 26.4371(25.8525) | Bit/dim 1.3406(1.4332) | Xent 0.2255(0.2753) | Loss 1.4534(1.5708) | Error 0.0691(0.0876) Steps 374(366.60) | Grad Norm 1.7030(3.0993) | Total Time 10.00(10.00)\n",
      "Iter 0371 | Time 26.6700(25.8770) | Bit/dim 1.3511(1.4307) | Xent 0.2049(0.2732) | Loss 1.4536(1.5673) | Error 0.0683(0.0870) Steps 374(366.83) | Grad Norm 1.9114(3.0637) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 15.3414, Epoch Time 211.7939(216.4523), Bit/dim 1.3340(best: 1.3510), Xent 0.1231, Loss 1.3955, Error 0.0407(best: 0.0428)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0372 | Time 26.7805(25.9041) | Bit/dim 1.3365(1.4279) | Xent 0.2227(0.2717) | Loss 1.4478(1.5637) | Error 0.0700(0.0865) Steps 380(367.22) | Grad Norm 2.3226(3.0415) | Total Time 10.00(10.00)\n",
      "Iter 0373 | Time 27.7166(25.9585) | Bit/dim 1.3379(1.4252) | Xent 0.2123(0.2699) | Loss 1.4440(1.5601) | Error 0.0680(0.0859) Steps 374(367.42) | Grad Norm 3.6351(3.0593) | Total Time 10.00(10.00)\n",
      "Iter 0374 | Time 25.9697(25.9588) | Bit/dim 1.3526(1.4230) | Xent 0.2111(0.2681) | Loss 1.4582(1.5571) | Error 0.0660(0.0853) Steps 368(367.44) | Grad Norm 5.4337(3.1305) | Total Time 10.00(10.00)\n",
      "Iter 0375 | Time 27.4731(26.0043) | Bit/dim 1.3600(1.4211) | Xent 0.2521(0.2676) | Loss 1.4861(1.5549) | Error 0.0800(0.0852) Steps 380(367.82) | Grad Norm 8.3156(3.2861) | Total Time 10.00(10.00)\n",
      "Iter 0376 | Time 25.3415(25.9844) | Bit/dim 1.4624(1.4224) | Xent 0.2797(0.2680) | Loss 1.6022(1.5564) | Error 0.0909(0.0854) Steps 368(367.82) | Grad Norm 14.4817(3.6219) | Total Time 10.00(10.00)\n",
      "Iter 0377 | Time 27.3107(26.0242) | Bit/dim 1.5229(1.4254) | Xent 0.2629(0.2679) | Loss 1.6543(1.5593) | Error 0.0835(0.0853) Steps 386(368.37) | Grad Norm 15.3157(3.9727) | Total Time 10.00(10.00)\n",
      "Iter 0378 | Time 25.6540(26.0131) | Bit/dim 1.4528(1.4262) | Xent 0.2089(0.2661) | Loss 1.5572(1.5592) | Error 0.0645(0.0847) Steps 368(368.36) | Grad Norm 5.7013(4.0246) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 14.9240, Epoch Time 213.3987(216.3607), Bit/dim 1.4554(best: 1.3340), Xent 0.1331, Loss 1.5220, Error 0.0412(best: 0.0407)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0379 | Time 25.9406(26.0109) | Bit/dim 1.4641(1.4273) | Xent 0.2279(0.2649) | Loss 1.5781(1.5598) | Error 0.0733(0.0843) Steps 368(368.35) | Grad Norm 5.7248(4.0756) | Total Time 10.00(10.00)\n",
      "Iter 0380 | Time 25.1420(25.9848) | Bit/dim 1.3946(1.4264) | Xent 0.2251(0.2637) | Loss 1.5071(1.5582) | Error 0.0713(0.0839) Steps 368(368.34) | Grad Norm 2.2010(4.0194) | Total Time 10.00(10.00)\n",
      "Iter 0381 | Time 25.9835(25.9848) | Bit/dim 1.4487(1.4270) | Xent 0.2356(0.2629) | Loss 1.5665(1.5585) | Error 0.0759(0.0837) Steps 380(368.69) | Grad Norm 5.7782(4.0721) | Total Time 10.00(10.00)\n",
      "Iter 0382 | Time 25.4934(25.9700) | Bit/dim 1.3901(1.4259) | Xent 0.2198(0.2616) | Loss 1.5000(1.5567) | Error 0.0739(0.0834) Steps 368(368.67) | Grad Norm 3.3366(4.0501) | Total Time 10.00(10.00)\n",
      "Iter 0383 | Time 25.7149(25.9624) | Bit/dim 1.4077(1.4254) | Xent 0.2116(0.2601) | Loss 1.5135(1.5554) | Error 0.0629(0.0828) Steps 368(368.65) | Grad Norm 2.6811(4.0090) | Total Time 10.00(10.00)\n",
      "Iter 0384 | Time 24.7962(25.9274) | Bit/dim 1.4081(1.4248) | Xent 0.2656(0.2603) | Loss 1.5409(1.5550) | Error 0.0843(0.0828) Steps 368(368.63) | Grad Norm 3.0494(3.9802) | Total Time 10.00(10.00)\n",
      "Iter 0385 | Time 25.0329(25.9006) | Bit/dim 1.3731(1.4233) | Xent 0.2421(0.2597) | Loss 1.4942(1.5532) | Error 0.0764(0.0826) Steps 368(368.61) | Grad Norm 1.9115(3.9181) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 15.3620, Epoch Time 205.8823(216.0464), Bit/dim 1.3863(best: 1.3340), Xent 0.1288, Loss 1.4507, Error 0.0416(best: 0.0407)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0386 | Time 25.7848(25.8971) | Bit/dim 1.3914(1.4223) | Xent 0.2314(0.2589) | Loss 1.5071(1.5518) | Error 0.0729(0.0823) Steps 380(368.95) | Grad Norm 3.0732(3.8928) | Total Time 10.00(10.00)\n",
      "Iter 0387 | Time 25.8590(25.8960) | Bit/dim 1.3796(1.4211) | Xent 0.2093(0.2574) | Loss 1.4843(1.5498) | Error 0.0644(0.0818) Steps 380(369.28) | Grad Norm 2.4306(3.8489) | Total Time 10.00(10.00)\n",
      "Iter 0388 | Time 25.0378(25.8702) | Bit/dim 1.3682(1.4195) | Xent 0.2196(0.2563) | Loss 1.4780(1.5476) | Error 0.0674(0.0814) Steps 362(369.06) | Grad Norm 3.2135(3.8299) | Total Time 10.00(10.00)\n",
      "Iter 0389 | Time 24.6680(25.8341) | Bit/dim 1.3554(1.4176) | Xent 0.2319(0.2555) | Loss 1.4714(1.5453) | Error 0.0753(0.0812) Steps 362(368.85) | Grad Norm 2.1865(3.7806) | Total Time 10.00(10.00)\n",
      "Iter 0390 | Time 25.4574(25.8228) | Bit/dim 1.3400(1.4152) | Xent 0.2372(0.2550) | Loss 1.4586(1.5427) | Error 0.0756(0.0810) Steps 362(368.65) | Grad Norm 3.4136(3.7696) | Total Time 10.00(10.00)\n",
      "Iter 0391 | Time 25.2915(25.8069) | Bit/dim 1.3512(1.4133) | Xent 0.2401(0.2545) | Loss 1.4712(1.5406) | Error 0.0756(0.0809) Steps 368(368.63) | Grad Norm 2.5752(3.7337) | Total Time 10.00(10.00)\n",
      "Iter 0392 | Time 26.0594(25.8145) | Bit/dim 1.3498(1.4114) | Xent 0.1852(0.2525) | Loss 1.4424(1.5376) | Error 0.0626(0.0803) Steps 368(368.61) | Grad Norm 1.1130(3.6551) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 14.2585, Epoch Time 204.7822(215.7084), Bit/dim 1.3357(best: 1.3340), Xent 0.1167, Loss 1.3940, Error 0.0383(best: 0.0407)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0393 | Time 26.3367(25.8301) | Bit/dim 1.3405(1.4093) | Xent 0.2242(0.2516) | Loss 1.4526(1.5351) | Error 0.0724(0.0801) Steps 362(368.41) | Grad Norm 3.1140(3.6389) | Total Time 10.00(10.00)\n",
      "Iter 0394 | Time 26.3846(25.8468) | Bit/dim 1.3510(1.4075) | Xent 0.1904(0.2498) | Loss 1.4462(1.5324) | Error 0.0581(0.0794) Steps 362(368.22) | Grad Norm 4.0106(3.6500) | Total Time 10.00(10.00)\n",
      "Iter 0395 | Time 26.1891(25.8570) | Bit/dim 1.3277(1.4051) | Xent 0.2064(0.2485) | Loss 1.4309(1.5294) | Error 0.0673(0.0791) Steps 374(368.39) | Grad Norm 3.2815(3.6390) | Total Time 10.00(10.00)\n",
      "Iter 0396 | Time 26.2052(25.8675) | Bit/dim 1.3285(1.4028) | Xent 0.2140(0.2474) | Loss 1.4355(1.5265) | Error 0.0685(0.0787) Steps 374(368.56) | Grad Norm 3.1273(3.6236) | Total Time 10.00(10.00)\n",
      "Iter 0397 | Time 27.1412(25.9057) | Bit/dim 1.3147(1.4002) | Xent 0.2148(0.2465) | Loss 1.4221(1.5234) | Error 0.0669(0.0784) Steps 374(368.72) | Grad Norm 2.6566(3.5946) | Total Time 10.00(10.00)\n",
      "Iter 0398 | Time 26.0221(25.9092) | Bit/dim 1.3316(1.3981) | Xent 0.2086(0.2453) | Loss 1.4359(1.5208) | Error 0.0654(0.0780) Steps 362(368.52) | Grad Norm 2.8253(3.5715) | Total Time 10.00(10.00)\n",
      "Iter 0399 | Time 26.4949(25.9268) | Bit/dim 1.3204(1.3958) | Xent 0.2058(0.2441) | Loss 1.4234(1.5179) | Error 0.0680(0.0777) Steps 374(368.68) | Grad Norm 3.4857(3.5690) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 15.1169, Epoch Time 212.1803(215.6026), Bit/dim 1.3192(best: 1.3340), Xent 0.1074, Loss 1.3728, Error 0.0348(best: 0.0383)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0400 | Time 26.7179(25.9505) | Bit/dim 1.3245(1.3937) | Xent 0.1921(0.2426) | Loss 1.4206(1.5149) | Error 0.0585(0.0771) Steps 386(369.20) | Grad Norm 3.7782(3.5752) | Total Time 10.00(10.00)\n",
      "Iter 0401 | Time 27.8123(26.0064) | Bit/dim 1.3255(1.3916) | Xent 0.2158(0.2418) | Loss 1.4334(1.5125) | Error 0.0684(0.0769) Steps 386(369.71) | Grad Norm 5.6626(3.6379) | Total Time 10.00(10.00)\n",
      "Iter 0402 | Time 25.6474(25.9956) | Bit/dim 1.3723(1.3910) | Xent 0.1954(0.2404) | Loss 1.4700(1.5112) | Error 0.0639(0.0765) Steps 368(369.66) | Grad Norm 8.3109(3.7780) | Total Time 10.00(10.00)\n",
      "Iter 0403 | Time 28.0863(26.0583) | Bit/dim 1.3275(1.3891) | Xent 0.2400(0.2404) | Loss 1.4475(1.5093) | Error 0.0810(0.0766) Steps 386(370.15) | Grad Norm 8.8894(3.9314) | Total Time 10.00(10.00)\n",
      "Iter 0404 | Time 25.5606(26.0434) | Bit/dim 1.3793(1.3888) | Xent 0.1576(0.2379) | Loss 1.4581(1.5078) | Error 0.0467(0.0757) Steps 368(370.08) | Grad Norm 6.9009(4.0205) | Total Time 10.00(10.00)\n",
      "Iter 0405 | Time 26.8822(26.0685) | Bit/dim 1.3136(1.3866) | Xent 0.1799(0.2361) | Loss 1.4035(1.5046) | Error 0.0540(0.0751) Steps 380(370.38) | Grad Norm 1.2854(3.9384) | Total Time 10.00(10.00)\n",
      "Iter 0406 | Time 27.6471(26.1159) | Bit/dim 1.3470(1.3854) | Xent 0.2330(0.2360) | Loss 1.4635(1.5034) | Error 0.0743(0.0750) Steps 386(370.85) | Grad Norm 8.1339(4.0643) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 14.7179, Epoch Time 215.5509(215.6010), Bit/dim 1.4168(best: 1.3192), Xent 0.1068, Loss 1.4702, Error 0.0337(best: 0.0348)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0407 | Time 25.2196(26.0890) | Bit/dim 1.4268(1.3866) | Xent 0.1734(0.2342) | Loss 1.5135(1.5037) | Error 0.0535(0.0744) Steps 362(370.58) | Grad Norm 7.7020(4.1734) | Total Time 10.00(10.00)\n",
      "Iter 0408 | Time 25.4166(26.0688) | Bit/dim 1.3675(1.3861) | Xent 0.1782(0.2325) | Loss 1.4566(1.5023) | Error 0.0539(0.0738) Steps 362(370.33) | Grad Norm 4.6939(4.1890) | Total Time 10.00(10.00)\n",
      "Iter 0409 | Time 27.4034(26.1089) | Bit/dim 1.3785(1.3858) | Xent 0.2204(0.2321) | Loss 1.4887(1.5019) | Error 0.0723(0.0737) Steps 386(370.80) | Grad Norm 8.8295(4.3282) | Total Time 10.00(10.00)\n",
      "Iter 0410 | Time 24.9664(26.0746) | Bit/dim 1.3157(1.3837) | Xent 0.1859(0.2307) | Loss 1.4087(1.4991) | Error 0.0565(0.0732) Steps 362(370.53) | Grad Norm 1.0917(4.2311) | Total Time 10.00(10.00)\n",
      "Iter 0411 | Time 25.3151(26.0518) | Bit/dim 1.3647(1.3832) | Xent 0.1920(0.2296) | Loss 1.4607(1.4979) | Error 0.0604(0.0728) Steps 362(370.28) | Grad Norm 4.2757(4.2325) | Total Time 10.00(10.00)\n",
      "Iter 0412 | Time 25.1193(26.0238) | Bit/dim 1.3349(1.3817) | Xent 0.1694(0.2278) | Loss 1.4196(1.4956) | Error 0.0560(0.0723) Steps 362(370.03) | Grad Norm 2.3397(4.1757) | Total Time 10.00(10.00)\n",
      "Iter 0413 | Time 27.1368(26.0572) | Bit/dim 1.3327(1.3802) | Xent 0.1958(0.2268) | Loss 1.4306(1.4936) | Error 0.0589(0.0719) Steps 380(370.33) | Grad Norm 4.0511(4.1720) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 15.2273, Epoch Time 208.1466(215.3774), Bit/dim 1.3121(best: 1.3192), Xent 0.1015, Loss 1.3629, Error 0.0323(best: 0.0337)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0414 | Time 25.6693(26.0456) | Bit/dim 1.3170(1.3783) | Xent 0.2093(0.2263) | Loss 1.4217(1.4915) | Error 0.0637(0.0717) Steps 374(370.44) | Grad Norm 2.4283(4.1197) | Total Time 10.00(10.00)\n",
      "Iter 0415 | Time 25.1656(26.0192) | Bit/dim 1.3357(1.3771) | Xent 0.1677(0.2245) | Loss 1.4195(1.4893) | Error 0.0519(0.0711) Steps 362(370.18) | Grad Norm 2.8880(4.0827) | Total Time 10.00(10.00)\n",
      "Iter 0416 | Time 25.2710(25.9967) | Bit/dim 1.3261(1.3755) | Xent 0.1604(0.2226) | Loss 1.4063(1.4868) | Error 0.0506(0.0705) Steps 362(369.94) | Grad Norm 2.7368(4.0423) | Total Time 10.00(10.00)\n",
      "Iter 0417 | Time 26.3037(26.0060) | Bit/dim 1.3061(1.3735) | Xent 0.1896(0.2216) | Loss 1.4009(1.4843) | Error 0.0621(0.0702) Steps 380(370.24) | Grad Norm 2.9207(4.0087) | Total Time 10.00(10.00)\n",
      "Iter 0418 | Time 25.9078(26.0030) | Bit/dim 1.3029(1.3713) | Xent 0.1861(0.2205) | Loss 1.3959(1.4816) | Error 0.0553(0.0698) Steps 374(370.35) | Grad Norm 2.5268(3.9642) | Total Time 10.00(10.00)\n",
      "Iter 0419 | Time 25.0487(25.9744) | Bit/dim 1.3253(1.3700) | Xent 0.1640(0.2189) | Loss 1.4073(1.4794) | Error 0.0513(0.0692) Steps 362(370.10) | Grad Norm 3.1547(3.9399) | Total Time 10.00(10.00)\n",
      "Iter 0420 | Time 25.3013(25.9542) | Bit/dim 1.3096(1.3681) | Xent 0.1715(0.2174) | Loss 1.3953(1.4769) | Error 0.0515(0.0687) Steps 368(370.04) | Grad Norm 1.7552(3.8744) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 15.1416, Epoch Time 206.1469(215.1005), Bit/dim 1.3015(best: 1.3121), Xent 0.1039, Loss 1.3534, Error 0.0328(best: 0.0323)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0421 | Time 27.2463(25.9930) | Bit/dim 1.3028(1.3662) | Xent 0.1888(0.2166) | Loss 1.3972(1.4745) | Error 0.0610(0.0684) Steps 380(370.34) | Grad Norm 4.4955(3.8930) | Total Time 10.00(10.00)\n",
      "Iter 0422 | Time 25.5139(25.9786) | Bit/dim 1.2993(1.3642) | Xent 0.1978(0.2160) | Loss 1.3982(1.4722) | Error 0.0641(0.0683) Steps 362(370.09) | Grad Norm 2.3908(3.8480) | Total Time 10.00(10.00)\n",
      "Iter 0423 | Time 24.9140(25.9466) | Bit/dim 1.3007(1.3623) | Xent 0.1806(0.2149) | Loss 1.3910(1.4697) | Error 0.0567(0.0680) Steps 362(369.85) | Grad Norm 2.4088(3.8048) | Total Time 10.00(10.00)\n",
      "Iter 0424 | Time 28.7795(26.0316) | Bit/dim 1.3088(1.3607) | Xent 0.1988(0.2145) | Loss 1.4082(1.4679) | Error 0.0607(0.0678) Steps 386(370.33) | Grad Norm 4.4308(3.8236) | Total Time 10.00(10.00)\n",
      "Iter 0425 | Time 26.6746(26.0509) | Bit/dim 1.2918(1.3586) | Xent 0.1850(0.2136) | Loss 1.3843(1.4654) | Error 0.0585(0.0675) Steps 380(370.62) | Grad Norm 2.6552(3.7885) | Total Time 10.00(10.00)\n",
      "Iter 0426 | Time 26.4369(26.0625) | Bit/dim 1.2913(1.3566) | Xent 0.1904(0.2129) | Loss 1.3865(1.4630) | Error 0.0580(0.0672) Steps 374(370.72) | Grad Norm 1.5567(3.7216) | Total Time 10.00(10.00)\n",
      "Iter 0427 | Time 27.6585(26.1104) | Bit/dim 1.2932(1.3547) | Xent 0.2071(0.2127) | Loss 1.3967(1.4610) | Error 0.0647(0.0671) Steps 392(371.36) | Grad Norm 3.6111(3.7182) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 14.9530, Epoch Time 214.6151(215.0859), Bit/dim 1.3112(best: 1.3015), Xent 0.0900, Loss 1.3562, Error 0.0303(best: 0.0323)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0428 | Time 26.0230(26.1078) | Bit/dim 1.3179(1.3536) | Xent 0.1613(0.2112) | Loss 1.3986(1.4592) | Error 0.0501(0.0666) Steps 374(371.44) | Grad Norm 3.5537(3.7133) | Total Time 10.00(10.00)\n",
      "Iter 0429 | Time 25.5807(26.0919) | Bit/dim 1.2839(1.3515) | Xent 0.1667(0.2098) | Loss 1.3672(1.4564) | Error 0.0540(0.0662) Steps 374(371.52) | Grad Norm 1.5230(3.6476) | Total Time 10.00(10.00)\n",
      "Iter 0430 | Time 28.4438(26.1625) | Bit/dim 1.2812(1.3494) | Xent 0.1898(0.2092) | Loss 1.3761(1.4540) | Error 0.0595(0.0660) Steps 380(371.77) | Grad Norm 2.8467(3.6236) | Total Time 10.00(10.00)\n",
      "Iter 0431 | Time 26.1936(26.1634) | Bit/dim 1.3189(1.3485) | Xent 0.1673(0.2080) | Loss 1.4025(1.4525) | Error 0.0513(0.0656) Steps 374(371.84) | Grad Norm 5.0316(3.6658) | Total Time 10.00(10.00)\n",
      "Iter 0432 | Time 26.9545(26.1872) | Bit/dim 1.2952(1.3469) | Xent 0.1792(0.2071) | Loss 1.3848(1.4504) | Error 0.0593(0.0654) Steps 380(372.08) | Grad Norm 5.5375(3.7220) | Total Time 10.00(10.00)\n",
      "Iter 0433 | Time 26.8913(26.2083) | Bit/dim 1.3170(1.3460) | Xent 0.1645(0.2058) | Loss 1.3993(1.4489) | Error 0.0506(0.0650) Steps 386(372.50) | Grad Norm 6.3291(3.8002) | Total Time 10.00(10.00)\n",
      "Iter 0434 | Time 27.0276(26.2329) | Bit/dim 1.2962(1.3445) | Xent 0.1719(0.2048) | Loss 1.3822(1.4469) | Error 0.0519(0.0646) Steps 380(372.72) | Grad Norm 6.4242(3.8789) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 14.8586, Epoch Time 214.4077(215.0656), Bit/dim 1.3036(best: 1.3015), Xent 0.0897, Loss 1.3484, Error 0.0281(best: 0.0303)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0435 | Time 27.2620(26.2637) | Bit/dim 1.3084(1.3434) | Xent 0.1606(0.2035) | Loss 1.3887(1.4451) | Error 0.0486(0.0641) Steps 380(372.94) | Grad Norm 5.0948(3.9154) | Total Time 10.00(10.00)\n",
      "Iter 0436 | Time 28.2719(26.3240) | Bit/dim 1.2804(1.3415) | Xent 0.1717(0.2025) | Loss 1.3663(1.4428) | Error 0.0534(0.0638) Steps 392(373.51) | Grad Norm 3.1022(3.8910) | Total Time 10.00(10.00)\n",
      "Iter 0437 | Time 27.3638(26.3552) | Bit/dim 1.2756(1.3395) | Xent 0.1827(0.2019) | Loss 1.3670(1.4405) | Error 0.0581(0.0636) Steps 380(373.71) | Grad Norm 1.1413(3.8085) | Total Time 10.00(10.00)\n",
      "Iter 0438 | Time 27.5157(26.3900) | Bit/dim 1.2825(1.3378) | Xent 0.1608(0.2007) | Loss 1.3630(1.4382) | Error 0.0520(0.0632) Steps 386(374.08) | Grad Norm 1.5653(3.7412) | Total Time 10.00(10.00)\n",
      "Iter 0439 | Time 28.1784(26.4436) | Bit/dim 1.2800(1.3361) | Xent 0.1629(0.1996) | Loss 1.3614(1.4359) | Error 0.0514(0.0629) Steps 386(374.44) | Grad Norm 3.6940(3.7398) | Total Time 10.00(10.00)\n",
      "Iter 0440 | Time 26.9775(26.4597) | Bit/dim 1.2981(1.3349) | Xent 0.1548(0.1982) | Loss 1.3755(1.4341) | Error 0.0460(0.0624) Steps 374(374.42) | Grad Norm 5.9014(3.8046) | Total Time 10.00(10.00)\n",
      "Iter 0441 | Time 27.3219(26.4855) | Bit/dim 1.3093(1.3342) | Xent 0.1845(0.1978) | Loss 1.4016(1.4331) | Error 0.0601(0.0623) Steps 380(374.59) | Grad Norm 8.7355(3.9526) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 14.6938, Epoch Time 220.0608(215.2154), Bit/dim 1.3950(best: 1.3015), Xent 0.0919, Loss 1.4410, Error 0.0313(best: 0.0281)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0442 | Time 25.9599(26.4698) | Bit/dim 1.3971(1.3361) | Xent 0.1586(0.1966) | Loss 1.4764(1.4344) | Error 0.0447(0.0618) Steps 368(374.39) | Grad Norm 9.6030(4.1221) | Total Time 10.00(10.00)\n",
      "Iter 0443 | Time 27.1396(26.4899) | Bit/dim 1.2882(1.3346) | Xent 0.1506(0.1953) | Loss 1.3635(1.4323) | Error 0.0453(0.0613) Steps 386(374.74) | Grad Norm 2.9054(4.0856) | Total Time 10.00(10.00)\n",
      "Iter 0444 | Time 27.4567(26.5189) | Bit/dim 1.3253(1.3343) | Xent 0.2189(0.1960) | Loss 1.4347(1.4323) | Error 0.0703(0.0616) Steps 386(375.08) | Grad Norm 9.5410(4.2492) | Total Time 10.00(10.00)\n",
      "Iter 0445 | Time 25.2616(26.4811) | Bit/dim 1.4606(1.3381) | Xent 0.1656(0.1951) | Loss 1.5434(1.4357) | Error 0.0530(0.0613) Steps 362(374.69) | Grad Norm 9.0985(4.3947) | Total Time 10.00(10.00)\n",
      "Iter 0446 | Time 25.2600(26.4445) | Bit/dim 1.4064(1.3402) | Xent 0.1338(0.1932) | Loss 1.4733(1.4368) | Error 0.0406(0.0607) Steps 368(374.49) | Grad Norm 4.9566(4.4116) | Total Time 10.00(10.00)\n",
      "Iter 0447 | Time 27.7228(26.4829) | Bit/dim 1.3328(1.3400) | Xent 0.1871(0.1930) | Loss 1.4264(1.4365) | Error 0.0584(0.0606) Steps 380(374.65) | Grad Norm 5.0698(4.4313) | Total Time 10.00(10.00)\n",
      "Iter 0448 | Time 28.7501(26.5509) | Bit/dim 1.3658(1.3407) | Xent 0.2349(0.1943) | Loss 1.4833(1.4379) | Error 0.0767(0.0611) Steps 380(374.81) | Grad Norm 6.2049(4.4845) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 14.5665, Epoch Time 214.4646(215.1929), Bit/dim 1.3417(best: 1.3015), Xent 0.0841, Loss 1.3837, Error 0.0282(best: 0.0281)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0449 | Time 25.3654(26.5153) | Bit/dim 1.3489(1.3410) | Xent 0.1472(0.1929) | Loss 1.4225(1.4374) | Error 0.0484(0.0607) Steps 362(374.43) | Grad Norm 3.2559(4.4477) | Total Time 10.00(10.00)\n",
      "Iter 0450 | Time 25.6999(26.4908) | Bit/dim 1.4152(1.3432) | Xent 0.1385(0.1912) | Loss 1.4844(1.4388) | Error 0.0443(0.0602) Steps 362(374.05) | Grad Norm 4.3124(4.4436) | Total Time 10.00(10.00)\n",
      "Iter 0451 | Time 25.3201(26.4557) | Bit/dim 1.3300(1.3428) | Xent 0.1580(0.1903) | Loss 1.4090(1.4379) | Error 0.0493(0.0599) Steps 368(373.87) | Grad Norm 3.0126(4.4007) | Total Time 10.00(10.00)\n",
      "Iter 0452 | Time 28.5240(26.5178) | Bit/dim 1.3420(1.3428) | Xent 0.2166(0.1910) | Loss 1.4503(1.4383) | Error 0.0709(0.0602) Steps 392(374.42) | Grad Norm 5.5155(4.4341) | Total Time 10.00(10.00)\n",
      "Iter 0453 | Time 25.9719(26.5014) | Bit/dim 1.3112(1.3418) | Xent 0.1955(0.1912) | Loss 1.4089(1.4374) | Error 0.0633(0.0603) Steps 362(374.04) | Grad Norm 2.2581(4.3688) | Total Time 10.00(10.00)\n",
      "Iter 0454 | Time 25.4603(26.4702) | Bit/dim 1.3305(1.3415) | Xent 0.1395(0.1896) | Loss 1.4002(1.4363) | Error 0.0454(0.0599) Steps 362(373.68) | Grad Norm 2.3937(4.3096) | Total Time 10.00(10.00)\n",
      "Iter 0455 | Time 25.3380(26.4362) | Bit/dim 1.3566(1.3420) | Xent 0.1626(0.1888) | Loss 1.4379(1.4364) | Error 0.0513(0.0596) Steps 362(373.33) | Grad Norm 2.7136(4.2617) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 14.4134, Epoch Time 208.3980(214.9891), Bit/dim 1.2948(best: 1.3015), Xent 0.0837, Loss 1.3366, Error 0.0285(best: 0.0281)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0456 | Time 25.5064(26.4083) | Bit/dim 1.3032(1.3408) | Xent 0.1572(0.1879) | Loss 1.3818(1.4347) | Error 0.0476(0.0592) Steps 362(372.99) | Grad Norm 0.8002(4.1579) | Total Time 10.00(10.00)\n",
      "Iter 0457 | Time 27.2098(26.4324) | Bit/dim 1.3146(1.3400) | Xent 0.1932(0.1880) | Loss 1.4112(1.4340) | Error 0.0586(0.0592) Steps 380(373.20) | Grad Norm 3.5433(4.1394) | Total Time 10.00(10.00)\n",
      "Iter 0458 | Time 26.0740(26.4216) | Bit/dim 1.2861(1.3384) | Xent 0.1942(0.1882) | Loss 1.3832(1.4325) | Error 0.0590(0.0592) Steps 380(373.41) | Grad Norm 1.6797(4.0656) | Total Time 10.00(10.00)\n",
      "Iter 0459 | Time 26.4053(26.4211) | Bit/dim 1.3158(1.3377) | Xent 0.1519(0.1871) | Loss 1.3917(1.4313) | Error 0.0476(0.0589) Steps 362(373.06) | Grad Norm 3.0632(4.0356) | Total Time 10.00(10.00)\n",
      "Iter 0460 | Time 26.8769(26.4348) | Bit/dim 1.3063(1.3368) | Xent 0.1520(0.1861) | Loss 1.3823(1.4298) | Error 0.0496(0.0586) Steps 362(372.73) | Grad Norm 2.1185(3.9780) | Total Time 10.00(10.00)\n",
      "Iter 0461 | Time 27.2856(26.4603) | Bit/dim 1.2954(1.3355) | Xent 0.1707(0.1856) | Loss 1.3807(1.4283) | Error 0.0509(0.0584) Steps 368(372.59) | Grad Norm 3.1482(3.9532) | Total Time 10.00(10.00)\n",
      "Iter 0462 | Time 25.9232(26.4442) | Bit/dim 1.2915(1.3342) | Xent 0.1759(0.1853) | Loss 1.3794(1.4269) | Error 0.0543(0.0582) Steps 374(372.63) | Grad Norm 1.7923(3.8883) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 15.0445, Epoch Time 212.6967(214.9203), Bit/dim 1.2835(best: 1.2948), Xent 0.0883, Loss 1.3276, Error 0.0294(best: 0.0281)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0463 | Time 27.6968(26.4818) | Bit/dim 1.2921(1.3329) | Xent 0.1590(0.1845) | Loss 1.3716(1.4252) | Error 0.0494(0.0580) Steps 380(372.85) | Grad Norm 1.7061(3.8229) | Total Time 10.00(10.00)\n",
      "Iter 0464 | Time 26.8651(26.4933) | Bit/dim 1.2894(1.3316) | Xent 0.1632(0.1839) | Loss 1.3710(1.4236) | Error 0.0490(0.0577) Steps 380(373.07) | Grad Norm 2.0028(3.7683) | Total Time 10.00(10.00)\n",
      "Iter 0465 | Time 27.1443(26.5128) | Bit/dim 1.2760(1.3300) | Xent 0.1622(0.1832) | Loss 1.3571(1.4216) | Error 0.0546(0.0576) Steps 380(373.28) | Grad Norm 1.4082(3.6975) | Total Time 10.00(10.00)\n",
      "Iter 0466 | Time 27.4847(26.5420) | Bit/dim 1.2796(1.3285) | Xent 0.1638(0.1827) | Loss 1.3615(1.4198) | Error 0.0493(0.0574) Steps 380(373.48) | Grad Norm 2.5949(3.6644) | Total Time 10.00(10.00)\n",
      "Iter 0467 | Time 26.4907(26.5404) | Bit/dim 1.2834(1.3271) | Xent 0.1531(0.1818) | Loss 1.3600(1.4180) | Error 0.0459(0.0570) Steps 380(373.67) | Grad Norm 1.7311(3.6064) | Total Time 10.00(10.00)\n",
      "Iter 0468 | Time 26.2979(26.5331) | Bit/dim 1.2754(1.3256) | Xent 0.1675(0.1813) | Loss 1.3592(1.4162) | Error 0.0525(0.0569) Steps 374(373.68) | Grad Norm 1.5860(3.5458) | Total Time 10.00(10.00)\n",
      "Iter 0469 | Time 26.3037(26.5263) | Bit/dim 1.2700(1.3239) | Xent 0.1539(0.1805) | Loss 1.3469(1.4141) | Error 0.0481(0.0566) Steps 374(373.69) | Grad Norm 1.3215(3.4790) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 15.3312, Epoch Time 215.9459(214.9511), Bit/dim 1.2642(best: 1.2835), Xent 0.0845, Loss 1.3065, Error 0.0278(best: 0.0281)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0470 | Time 27.6177(26.5590) | Bit/dim 1.2738(1.3224) | Xent 0.1611(0.1799) | Loss 1.3543(1.4123) | Error 0.0499(0.0564) Steps 380(373.88) | Grad Norm 3.0940(3.4675) | Total Time 10.00(10.00)\n",
      "Iter 0471 | Time 26.7990(26.5662) | Bit/dim 1.2889(1.3214) | Xent 0.1664(0.1795) | Loss 1.3721(1.4111) | Error 0.0506(0.0562) Steps 374(373.89) | Grad Norm 6.4165(3.5560) | Total Time 10.00(10.00)\n",
      "Iter 0472 | Time 27.5661(26.5962) | Bit/dim 1.3324(1.3217) | Xent 0.2343(0.1812) | Loss 1.4496(1.4123) | Error 0.0733(0.0568) Steps 386(374.25) | Grad Norm 11.5296(3.7952) | Total Time 10.00(10.00)\n",
      "Iter 0473 | Time 25.8489(26.5738) | Bit/dim 1.4618(1.3259) | Xent 0.2659(0.1837) | Loss 1.5947(1.4178) | Error 0.0864(0.0576) Steps 368(374.06) | Grad Norm 11.8385(4.0365) | Total Time 10.00(10.00)\n",
      "Iter 0474 | Time 26.5348(26.5726) | Bit/dim 1.3563(1.3268) | Xent 0.1496(0.1827) | Loss 1.4311(1.4182) | Error 0.0454(0.0573) Steps 368(373.88) | Grad Norm 3.2909(4.0141) | Total Time 10.00(10.00)\n",
      "Iter 0475 | Time 27.5311(26.6014) | Bit/dim 1.4516(1.3306) | Xent 0.2271(0.1840) | Loss 1.5651(1.4226) | Error 0.0716(0.0577) Steps 386(374.24) | Grad Norm 12.1763(4.2590) | Total Time 10.00(10.00)\n",
      "Iter 0476 | Time 25.4992(26.5683) | Bit/dim 1.3497(1.3311) | Xent 0.1827(0.1840) | Loss 1.4411(1.4231) | Error 0.0553(0.0576) Steps 368(374.06) | Grad Norm 4.0868(4.2538) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 14.7515, Epoch Time 214.4627(214.9364), Bit/dim 1.3952(best: 1.2642), Xent 0.0966, Loss 1.4435, Error 0.0295(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0477 | Time 26.2913(26.5600) | Bit/dim 1.3984(1.3332) | Xent 0.1763(0.1837) | Loss 1.4865(1.4250) | Error 0.0560(0.0576) Steps 386(374.41) | Grad Norm 4.6394(4.2654) | Total Time 10.00(10.00)\n",
      "Iter 0478 | Time 26.4867(26.5578) | Bit/dim 1.3702(1.3343) | Xent 0.1946(0.1841) | Loss 1.4675(1.4263) | Error 0.0634(0.0578) Steps 386(374.76) | Grad Norm 2.8540(4.2230) | Total Time 10.00(10.00)\n",
      "Iter 0479 | Time 25.7298(26.5330) | Bit/dim 1.3421(1.3345) | Xent 0.1920(0.1843) | Loss 1.4381(1.4267) | Error 0.0615(0.0579) Steps 380(374.92) | Grad Norm 2.7967(4.1802) | Total Time 10.00(10.00)\n",
      "Iter 0480 | Time 26.1475(26.5214) | Bit/dim 1.3369(1.3346) | Xent 0.2043(0.1849) | Loss 1.4391(1.4270) | Error 0.0633(0.0580) Steps 380(375.07) | Grad Norm 2.5964(4.1327) | Total Time 10.00(10.00)\n",
      "Iter 0481 | Time 25.3563(26.4864) | Bit/dim 1.3291(1.3344) | Xent 0.1542(0.1840) | Loss 1.4062(1.4264) | Error 0.0500(0.0578) Steps 368(374.86) | Grad Norm 1.3398(4.0489) | Total Time 10.00(10.00)\n",
      "Iter 0482 | Time 25.5269(26.4577) | Bit/dim 1.3557(1.3351) | Xent 0.1660(0.1834) | Loss 1.4386(1.4268) | Error 0.0491(0.0575) Steps 368(374.65) | Grad Norm 2.3325(3.9974) | Total Time 10.00(10.00)\n",
      "Iter 0483 | Time 25.3298(26.4238) | Bit/dim 1.3238(1.3347) | Xent 0.1696(0.1830) | Loss 1.4086(1.4262) | Error 0.0545(0.0574) Steps 362(374.27) | Grad Norm 1.4363(3.9206) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 15.1034, Epoch Time 208.4328(214.7413), Bit/dim 1.2953(best: 1.2642), Xent 0.0973, Loss 1.3439, Error 0.0301(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0484 | Time 25.8021(26.4052) | Bit/dim 1.3025(1.3337) | Xent 0.1930(0.1833) | Loss 1.3990(1.4254) | Error 0.0623(0.0576) Steps 374(374.27) | Grad Norm 2.0839(3.8655) | Total Time 10.00(10.00)\n",
      "Iter 0485 | Time 26.1725(26.3982) | Bit/dim 1.3021(1.3328) | Xent 0.1760(0.1831) | Loss 1.3901(1.4244) | Error 0.0571(0.0576) Steps 374(374.26) | Grad Norm 1.8493(3.8050) | Total Time 10.00(10.00)\n",
      "Iter 0486 | Time 25.8130(26.3806) | Bit/dim 1.3026(1.3319) | Xent 0.1560(0.1823) | Loss 1.3806(1.4230) | Error 0.0479(0.0573) Steps 374(374.25) | Grad Norm 1.6676(3.7409) | Total Time 10.00(10.00)\n",
      "Iter 0487 | Time 25.8419(26.3645) | Bit/dim 1.3086(1.3312) | Xent 0.1589(0.1816) | Loss 1.3881(1.4220) | Error 0.0499(0.0571) Steps 362(373.88) | Grad Norm 1.8378(3.6838) | Total Time 10.00(10.00)\n",
      "Iter 0488 | Time 25.7002(26.3445) | Bit/dim 1.2905(1.3300) | Xent 0.1535(0.1808) | Loss 1.3673(1.4204) | Error 0.0495(0.0568) Steps 374(373.89) | Grad Norm 0.9174(3.6008) | Total Time 10.00(10.00)\n",
      "Iter 0489 | Time 27.2542(26.3718) | Bit/dim 1.2954(1.3289) | Xent 0.1708(0.1805) | Loss 1.3808(1.4192) | Error 0.0546(0.0568) Steps 386(374.25) | Grad Norm 2.2163(3.5593) | Total Time 10.00(10.00)\n",
      "Iter 0490 | Time 27.3445(26.4010) | Bit/dim 1.2863(1.3277) | Xent 0.1534(0.1796) | Loss 1.3630(1.4175) | Error 0.0481(0.0565) Steps 380(374.42) | Grad Norm 1.4995(3.4975) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 15.4550, Epoch Time 211.8486(214.6545), Bit/dim 1.2660(best: 1.2642), Xent 0.0983, Loss 1.3152, Error 0.0315(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0491 | Time 27.6939(26.4398) | Bit/dim 1.2778(1.3262) | Xent 0.1806(0.1797) | Loss 1.3681(1.4160) | Error 0.0576(0.0565) Steps 380(374.59) | Grad Norm 1.3119(3.4319) | Total Time 10.00(10.00)\n",
      "Iter 0492 | Time 26.9812(26.4560) | Bit/dim 1.2680(1.3244) | Xent 0.1626(0.1792) | Loss 1.3493(1.4140) | Error 0.0524(0.0564) Steps 380(374.75) | Grad Norm 1.2626(3.3668) | Total Time 10.00(10.00)\n",
      "Iter 0493 | Time 26.4346(26.4554) | Bit/dim 1.2667(1.3227) | Xent 0.1627(0.1787) | Loss 1.3480(1.4120) | Error 0.0534(0.0563) Steps 386(375.09) | Grad Norm 1.3413(3.3061) | Total Time 10.00(10.00)\n",
      "Iter 0494 | Time 27.2962(26.4806) | Bit/dim 1.2763(1.3213) | Xent 0.1594(0.1781) | Loss 1.3560(1.4103) | Error 0.0504(0.0561) Steps 386(375.42) | Grad Norm 1.6997(3.2579) | Total Time 10.00(10.00)\n",
      "Iter 0495 | Time 26.9665(26.4952) | Bit/dim 1.2777(1.3200) | Xent 0.1592(0.1775) | Loss 1.3573(1.4087) | Error 0.0507(0.0560) Steps 386(375.73) | Grad Norm 2.0148(3.2206) | Total Time 10.00(10.00)\n",
      "Iter 0496 | Time 26.4643(26.4943) | Bit/dim 1.2706(1.3185) | Xent 0.1440(0.1765) | Loss 1.3426(1.4068) | Error 0.0444(0.0556) Steps 374(375.68) | Grad Norm 2.2480(3.1914) | Total Time 10.00(10.00)\n",
      "Iter 0497 | Time 28.4288(26.5523) | Bit/dim 1.2708(1.3171) | Xent 0.1688(0.1763) | Loss 1.3552(1.4052) | Error 0.0553(0.0556) Steps 386(375.99) | Grad Norm 4.3247(3.2254) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 15.0554, Epoch Time 218.0367(214.7560), Bit/dim 1.2950(best: 1.2642), Xent 0.0922, Loss 1.3411, Error 0.0289(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0498 | Time 27.6173(26.5843) | Bit/dim 1.3027(1.3166) | Xent 0.1665(0.1760) | Loss 1.3859(1.4046) | Error 0.0511(0.0555) Steps 380(376.11) | Grad Norm 8.8019(3.3927) | Total Time 10.00(10.00)\n",
      "Iter 0499 | Time 27.4473(26.6102) | Bit/dim 1.4034(1.3192) | Xent 0.3299(0.1806) | Loss 1.5684(1.4095) | Error 0.1055(0.0570) Steps 386(376.41) | Grad Norm 19.5048(3.8761) | Total Time 10.00(10.00)\n",
      "Iter 0500 | Time 26.4014(26.6039) | Bit/dim 1.7753(1.3329) | Xent 0.4154(0.1877) | Loss 1.9830(1.4268) | Error 0.1115(0.0586) Steps 356(375.80) | Grad Norm 16.3839(4.2513) | Total Time 10.00(10.00)\n",
      "Iter 0501 | Time 24.9848(26.5553) | Bit/dim 1.7761(1.3462) | Xent 0.1477(0.1865) | Loss 1.8500(1.4395) | Error 0.0439(0.0582) Steps 350(375.02) | Grad Norm 4.8128(4.2681) | Total Time 10.00(10.00)\n",
      "Iter 0502 | Time 24.2111(26.4850) | Bit/dim 1.7607(1.3587) | Xent 0.2212(0.1875) | Loss 1.8713(1.4524) | Error 0.0684(0.0585) Steps 350(374.27) | Grad Norm 5.3681(4.3011) | Total Time 10.00(10.00)\n",
      "Iter 0503 | Time 26.9140(26.4979) | Bit/dim 1.6138(1.3663) | Xent 0.1838(0.1874) | Loss 1.7058(1.4600) | Error 0.0577(0.0585) Steps 374(374.26) | Grad Norm 3.8924(4.2889) | Total Time 10.00(10.00)\n",
      "Iter 0504 | Time 26.1913(26.4887) | Bit/dim 1.5635(1.3722) | Xent 0.3001(0.1908) | Loss 1.7135(1.4676) | Error 0.0956(0.0596) Steps 374(374.26) | Grad Norm 4.9752(4.3095) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 14.6467, Epoch Time 210.6504(214.6328), Bit/dim 1.5268(best: 1.2642), Xent 0.1325, Loss 1.5930, Error 0.0410(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0505 | Time 28.4693(26.5481) | Bit/dim 1.5318(1.3770) | Xent 0.2893(0.1937) | Loss 1.6765(1.4739) | Error 0.0910(0.0605) Steps 374(374.25) | Grad Norm 3.2965(4.2791) | Total Time 10.00(10.00)\n",
      "Iter 0506 | Time 26.4887(26.5463) | Bit/dim 1.5458(1.3821) | Xent 0.2124(0.1943) | Loss 1.6520(1.4792) | Error 0.0629(0.0606) Steps 374(374.24) | Grad Norm 3.7713(4.2639) | Total Time 10.00(10.00)\n",
      "Iter 0507 | Time 26.7839(26.5534) | Bit/dim 1.4991(1.3856) | Xent 0.1979(0.1944) | Loss 1.5980(1.4828) | Error 0.0587(0.0605) Steps 374(374.23) | Grad Norm 3.0032(4.2260) | Total Time 10.00(10.00)\n",
      "Iter 0508 | Time 25.0980(26.5098) | Bit/dim 1.4442(1.3873) | Xent 0.1989(0.1945) | Loss 1.5437(1.4846) | Error 0.0613(0.0606) Steps 362(373.87) | Grad Norm 3.1001(4.1923) | Total Time 10.00(10.00)\n",
      "Iter 0509 | Time 26.1743(26.4997) | Bit/dim 1.4295(1.3886) | Xent 0.2152(0.1951) | Loss 1.5371(1.4862) | Error 0.0670(0.0608) Steps 380(374.05) | Grad Norm 2.2499(4.1340) | Total Time 10.00(10.00)\n",
      "Iter 0510 | Time 27.2499(26.5222) | Bit/dim 1.4391(1.3901) | Xent 0.2159(0.1958) | Loss 1.5470(1.4880) | Error 0.0686(0.0610) Steps 386(374.41) | Grad Norm 2.5755(4.0872) | Total Time 10.00(10.00)\n",
      "Iter 0511 | Time 27.8864(26.5631) | Bit/dim 1.4200(1.3910) | Xent 0.2184(0.1964) | Loss 1.5292(1.4892) | Error 0.0695(0.0612) Steps 380(374.58) | Grad Norm 2.0934(4.0274) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 14.9846, Epoch Time 215.7666(214.6668), Bit/dim 1.3903(best: 1.2642), Xent 0.1053, Loss 1.4430, Error 0.0336(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0512 | Time 28.7776(26.6296) | Bit/dim 1.3954(1.3912) | Xent 0.2025(0.1966) | Loss 1.4967(1.4895) | Error 0.0635(0.0613) Steps 380(374.74) | Grad Norm 1.4095(3.9489) | Total Time 10.00(10.00)\n",
      "Iter 0513 | Time 27.2689(26.6487) | Bit/dim 1.3952(1.3913) | Xent 0.1973(0.1966) | Loss 1.4938(1.4896) | Error 0.0629(0.0614) Steps 386(375.08) | Grad Norm 2.2963(3.8993) | Total Time 10.00(10.00)\n",
      "Iter 0514 | Time 26.6000(26.6473) | Bit/dim 1.3901(1.3912) | Xent 0.1896(0.1964) | Loss 1.4849(1.4895) | Error 0.0586(0.0613) Steps 386(375.40) | Grad Norm 2.2909(3.8510) | Total Time 10.00(10.00)\n",
      "Iter 0515 | Time 27.3949(26.6697) | Bit/dim 1.3628(1.3904) | Xent 0.1808(0.1960) | Loss 1.4532(1.4884) | Error 0.0566(0.0611) Steps 386(375.72) | Grad Norm 1.9743(3.7947) | Total Time 10.00(10.00)\n",
      "Iter 0516 | Time 27.9062(26.7068) | Bit/dim 1.3482(1.3891) | Xent 0.2004(0.1961) | Loss 1.4484(1.4872) | Error 0.0646(0.0612) Steps 386(376.03) | Grad Norm 3.7433(3.7932) | Total Time 10.00(10.00)\n",
      "Iter 0517 | Time 28.8222(26.7703) | Bit/dim 1.3452(1.3878) | Xent 0.1937(0.1960) | Loss 1.4420(1.4858) | Error 0.0620(0.0613) Steps 386(376.33) | Grad Norm 2.3124(3.7488) | Total Time 10.00(10.00)\n",
      "Iter 0518 | Time 27.5181(26.7927) | Bit/dim 1.3367(1.3863) | Xent 0.1879(0.1958) | Loss 1.4307(1.4842) | Error 0.0604(0.0612) Steps 386(376.62) | Grad Norm 1.5844(3.6838) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 15.1625, Epoch Time 221.6745(214.8771), Bit/dim 1.3327(best: 1.2642), Xent 0.1042, Loss 1.3848, Error 0.0333(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0519 | Time 28.6670(26.8489) | Bit/dim 1.3343(1.3847) | Xent 0.1942(0.1957) | Loss 1.4314(1.4826) | Error 0.0611(0.0612) Steps 386(376.90) | Grad Norm 3.2846(3.6719) | Total Time 10.00(10.00)\n",
      "Iter 0520 | Time 28.0947(26.8863) | Bit/dim 1.3366(1.3833) | Xent 0.1782(0.1952) | Loss 1.4257(1.4809) | Error 0.0555(0.0611) Steps 380(376.99) | Grad Norm 2.9238(3.6494) | Total Time 10.00(10.00)\n",
      "Iter 0521 | Time 27.6381(26.9089) | Bit/dim 1.3114(1.3811) | Xent 0.1746(0.1946) | Loss 1.3987(1.4784) | Error 0.0561(0.0609) Steps 380(377.08) | Grad Norm 1.2046(3.5761) | Total Time 10.00(10.00)\n",
      "Iter 0522 | Time 27.6234(26.9303) | Bit/dim 1.3082(1.3789) | Xent 0.1779(0.1941) | Loss 1.3972(1.4760) | Error 0.0561(0.0608) Steps 386(377.35) | Grad Norm 3.1205(3.5624) | Total Time 10.00(10.00)\n",
      "Iter 0523 | Time 26.0238(26.9031) | Bit/dim 1.3175(1.3771) | Xent 0.1995(0.1943) | Loss 1.4173(1.4742) | Error 0.0637(0.0609) Steps 380(377.43) | Grad Norm 4.3046(3.5847) | Total Time 10.00(10.00)\n",
      "Iter 0524 | Time 28.1520(26.9406) | Bit/dim 1.3051(1.3749) | Xent 0.1918(0.1942) | Loss 1.4011(1.4720) | Error 0.0620(0.0609) Steps 386(377.69) | Grad Norm 3.0853(3.5697) | Total Time 10.00(10.00)\n",
      "Iter 0525 | Time 27.4967(26.9573) | Bit/dim 1.3005(1.3727) | Xent 0.1724(0.1935) | Loss 1.3867(1.4695) | Error 0.0543(0.0607) Steps 380(377.76) | Grad Norm 2.1097(3.5259) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 15.4657, Epoch Time 221.5138(215.0762), Bit/dim 1.2872(best: 1.2642), Xent 0.0884, Loss 1.3314, Error 0.0295(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0526 | Time 27.9126(26.9859) | Bit/dim 1.2910(1.3702) | Xent 0.1653(0.1927) | Loss 1.3737(1.4666) | Error 0.0540(0.0605) Steps 392(378.19) | Grad Norm 1.2788(3.4585) | Total Time 10.00(10.00)\n",
      "Iter 0527 | Time 27.8725(27.0125) | Bit/dim 1.2929(1.3679) | Xent 0.1689(0.1920) | Loss 1.3774(1.4639) | Error 0.0523(0.0602) Steps 392(378.60) | Grad Norm 1.6884(3.4054) | Total Time 10.00(10.00)\n",
      "Iter 0528 | Time 28.2668(27.0501) | Bit/dim 1.3008(1.3659) | Xent 0.1603(0.1910) | Loss 1.3810(1.4614) | Error 0.0507(0.0600) Steps 386(378.82) | Grad Norm 2.4521(3.3768) | Total Time 10.00(10.00)\n",
      "Iter 0529 | Time 27.7105(27.0699) | Bit/dim 1.2830(1.3634) | Xent 0.1871(0.1909) | Loss 1.3765(1.4589) | Error 0.0581(0.0599) Steps 392(379.22) | Grad Norm 4.2177(3.4020) | Total Time 10.00(10.00)\n",
      "Iter 0530 | Time 26.6226(27.0565) | Bit/dim 1.3131(1.3619) | Xent 0.1710(0.1903) | Loss 1.3986(1.4571) | Error 0.0545(0.0597) Steps 380(379.24) | Grad Norm 6.4006(3.4920) | Total Time 10.00(10.00)\n",
      "Iter 0531 | Time 27.7995(27.0788) | Bit/dim 1.3117(1.3604) | Xent 0.2047(0.1907) | Loss 1.4140(1.4558) | Error 0.0644(0.0599) Steps 392(379.62) | Grad Norm 9.5874(3.6748) | Total Time 10.00(10.00)\n",
      "Iter 0532 | Time 25.9281(27.0443) | Bit/dim 1.3782(1.3609) | Xent 0.1813(0.1905) | Loss 1.4688(1.4562) | Error 0.0551(0.0597) Steps 368(379.27) | Grad Norm 9.0552(3.8362) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 14.9224, Epoch Time 219.5275(215.2097), Bit/dim 1.2873(best: 1.2642), Xent 0.0793, Loss 1.3269, Error 0.0278(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0533 | Time 26.3866(27.0246) | Bit/dim 1.2983(1.3591) | Xent 0.1429(0.1890) | Loss 1.3697(1.4536) | Error 0.0443(0.0593) Steps 386(379.48) | Grad Norm 1.7040(3.7723) | Total Time 10.00(10.00)\n",
      "Iter 0534 | Time 27.0910(27.0266) | Bit/dim 1.3663(1.3593) | Xent 0.2516(0.1909) | Loss 1.4920(1.4547) | Error 0.0819(0.0600) Steps 386(379.67) | Grad Norm 12.9684(4.0482) | Total Time 10.00(10.00)\n",
      "Iter 0535 | Time 25.3810(26.9772) | Bit/dim 1.4171(1.3610) | Xent 0.1825(0.1907) | Loss 1.5084(1.4563) | Error 0.0603(0.0600) Steps 362(379.14) | Grad Norm 6.5002(4.1217) | Total Time 10.00(10.00)\n",
      "Iter 0536 | Time 26.5520(26.9644) | Bit/dim 1.4571(1.3639) | Xent 0.1733(0.1901) | Loss 1.5437(1.4590) | Error 0.0577(0.0599) Steps 380(379.17) | Grad Norm 5.5331(4.1641) | Total Time 10.00(10.00)\n",
      "Iter 0537 | Time 26.6405(26.9547) | Bit/dim 1.3521(1.3635) | Xent 0.1486(0.1889) | Loss 1.4264(1.4580) | Error 0.0436(0.0594) Steps 386(379.37) | Grad Norm 2.7957(4.1230) | Total Time 10.00(10.00)\n",
      "Iter 0538 | Time 28.1941(26.9919) | Bit/dim 1.3643(1.3636) | Xent 0.1955(0.1891) | Loss 1.4620(1.4581) | Error 0.0624(0.0595) Steps 386(379.57) | Grad Norm 4.4087(4.1316) | Total Time 10.00(10.00)\n",
      "Iter 0539 | Time 27.3820(27.0036) | Bit/dim 1.3786(1.3640) | Xent 0.1956(0.1893) | Loss 1.4764(1.4587) | Error 0.0613(0.0595) Steps 386(379.76) | Grad Norm 5.0113(4.1580) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 14.8379, Epoch Time 214.9711(215.2025), Bit/dim 1.3228(best: 1.2642), Xent 0.0770, Loss 1.3614, Error 0.0257(best: 0.0278)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0540 | Time 25.4845(26.9580) | Bit/dim 1.3308(1.3630) | Xent 0.1414(0.1878) | Loss 1.4014(1.4569) | Error 0.0445(0.0591) Steps 368(379.41) | Grad Norm 1.4226(4.0759) | Total Time 10.00(10.00)\n",
      "Iter 0541 | Time 26.4517(26.9428) | Bit/dim 1.3762(1.3634) | Xent 0.1244(0.1859) | Loss 1.4384(1.4564) | Error 0.0381(0.0585) Steps 380(379.43) | Grad Norm 2.9933(4.0434) | Total Time 10.00(10.00)\n",
      "Iter 0542 | Time 24.8777(26.8809) | Bit/dim 1.3689(1.3636) | Xent 0.1400(0.1846) | Loss 1.4389(1.4559) | Error 0.0435(0.0580) Steps 362(378.91) | Grad Norm 3.2875(4.0208) | Total Time 10.00(10.00)\n",
      "Iter 0543 | Time 26.2276(26.8613) | Bit/dim 1.3109(1.3620) | Xent 0.1574(0.1837) | Loss 1.3895(1.4539) | Error 0.0516(0.0578) Steps 368(378.58) | Grad Norm 1.3439(3.9405) | Total Time 10.00(10.00)\n",
      "Iter 0544 | Time 27.2967(26.8743) | Bit/dim 1.3227(1.3608) | Xent 0.1870(0.1838) | Loss 1.4161(1.4527) | Error 0.0595(0.0579) Steps 386(378.80) | Grad Norm 4.5152(3.9577) | Total Time 10.00(10.00)\n",
      "Iter 0545 | Time 27.0563(26.8798) | Bit/dim 1.3122(1.3594) | Xent 0.1707(0.1834) | Loss 1.3975(1.4511) | Error 0.0567(0.0578) Steps 386(379.02) | Grad Norm 3.4061(3.9411) | Total Time 10.00(10.00)\n",
      "Iter 0546 | Time 25.4399(26.8366) | Bit/dim 1.3115(1.3579) | Xent 0.1448(0.1823) | Loss 1.3839(1.4491) | Error 0.0461(0.0575) Steps 362(378.51) | Grad Norm 2.5207(3.8985) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 14.3108, Epoch Time 209.7022(215.0375), Bit/dim 1.3334(best: 1.2642), Xent 0.0710, Loss 1.3689, Error 0.0232(best: 0.0257)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0547 | Time 25.0040(26.7816) | Bit/dim 1.3398(1.3574) | Xent 0.1310(0.1808) | Loss 1.4053(1.4477) | Error 0.0407(0.0570) Steps 362(378.01) | Grad Norm 3.1956(3.8774) | Total Time 10.00(10.00)\n",
      "Iter 0548 | Time 24.8991(26.7252) | Bit/dim 1.3021(1.3557) | Xent 0.1303(0.1792) | Loss 1.3672(1.4453) | Error 0.0431(0.0566) Steps 362(377.53) | Grad Norm 1.6378(3.8103) | Total Time 10.00(10.00)\n",
      "Iter 0549 | Time 27.3720(26.7446) | Bit/dim 1.2984(1.3540) | Xent 0.1629(0.1787) | Loss 1.3799(1.4434) | Error 0.0499(0.0564) Steps 380(377.61) | Grad Norm 3.8060(3.8101) | Total Time 10.00(10.00)\n",
      "Iter 0550 | Time 27.4377(26.7654) | Bit/dim 1.2875(1.3520) | Xent 0.1741(0.1786) | Loss 1.3746(1.4413) | Error 0.0511(0.0562) Steps 374(377.50) | Grad Norm 2.3238(3.7655) | Total Time 10.00(10.00)\n",
      "Iter 0551 | Time 25.6032(26.7305) | Bit/dim 1.2919(1.3502) | Xent 0.1395(0.1774) | Loss 1.3617(1.4389) | Error 0.0445(0.0559) Steps 362(377.03) | Grad Norm 2.4106(3.7249) | Total Time 10.00(10.00)\n",
      "Iter 0552 | Time 25.5517(26.6951) | Bit/dim 1.3029(1.3488) | Xent 0.1291(0.1760) | Loss 1.3675(1.4368) | Error 0.0414(0.0554) Steps 362(376.58) | Grad Norm 2.8149(3.6976) | Total Time 10.00(10.00)\n",
      "Iter 0553 | Time 26.1766(26.6796) | Bit/dim 1.2780(1.3467) | Xent 0.1410(0.1749) | Loss 1.3485(1.4341) | Error 0.0436(0.0551) Steps 362(376.14) | Grad Norm 1.1103(3.6200) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 15.1981, Epoch Time 209.7313(214.8784), Bit/dim 1.2791(best: 1.2642), Xent 0.0767, Loss 1.3174, Error 0.0246(best: 0.0232)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0554 | Time 26.4581(26.6729) | Bit/dim 1.2894(1.3449) | Xent 0.1552(0.1743) | Loss 1.3670(1.4321) | Error 0.0464(0.0548) Steps 380(376.26) | Grad Norm 3.6931(3.6222) | Total Time 10.00(10.00)\n",
      "Iter 0555 | Time 26.1567(26.6574) | Bit/dim 1.2688(1.3427) | Xent 0.1355(0.1732) | Loss 1.3365(1.4292) | Error 0.0423(0.0544) Steps 374(376.19) | Grad Norm 1.0277(3.5443) | Total Time 10.00(10.00)\n",
      "Iter 0556 | Time 25.7647(26.6307) | Bit/dim 1.2820(1.3408) | Xent 0.1348(0.1720) | Loss 1.3495(1.4268) | Error 0.0433(0.0541) Steps 362(375.77) | Grad Norm 2.6738(3.5182) | Total Time 10.00(10.00)\n",
      "Iter 0557 | Time 26.4501(26.6252) | Bit/dim 1.2631(1.3385) | Xent 0.1390(0.1710) | Loss 1.3326(1.4240) | Error 0.0457(0.0539) Steps 380(375.89) | Grad Norm 0.8237(3.4374) | Total Time 10.00(10.00)\n",
      "Iter 0558 | Time 27.4912(26.6512) | Bit/dim 1.2672(1.3364) | Xent 0.1616(0.1708) | Loss 1.3480(1.4217) | Error 0.0470(0.0536) Steps 386(376.20) | Grad Norm 3.2486(3.4317) | Total Time 10.00(10.00)\n",
      "Iter 0559 | Time 26.0072(26.6319) | Bit/dim 1.2631(1.3342) | Xent 0.1416(0.1699) | Loss 1.3339(1.4191) | Error 0.0481(0.0535) Steps 374(376.13) | Grad Norm 0.6635(3.3487) | Total Time 10.00(10.00)\n",
      "Iter 0560 | Time 26.1282(26.6168) | Bit/dim 1.2822(1.3326) | Xent 0.1392(0.1690) | Loss 1.3518(1.4171) | Error 0.0435(0.0532) Steps 374(376.07) | Grad Norm 2.7569(3.3309) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 15.3699, Epoch Time 212.4790(214.8064), Bit/dim 1.2512(best: 1.2642), Xent 0.0696, Loss 1.2860, Error 0.0237(best: 0.0232)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0561 | Time 26.3249(26.6080) | Bit/dim 1.2621(1.3305) | Xent 0.1470(0.1683) | Loss 1.3356(1.4146) | Error 0.0454(0.0529) Steps 374(376.00) | Grad Norm 0.7204(3.2526) | Total Time 10.00(10.00)\n",
      "Iter 0562 | Time 27.5211(26.6354) | Bit/dim 1.2583(1.3283) | Xent 0.1395(0.1674) | Loss 1.3280(1.4120) | Error 0.0430(0.0526) Steps 386(376.30) | Grad Norm 3.3130(3.2544) | Total Time 10.00(10.00)\n",
      "Iter 0563 | Time 26.4006(26.6284) | Bit/dim 1.2673(1.3265) | Xent 0.1400(0.1666) | Loss 1.3373(1.4098) | Error 0.0436(0.0524) Steps 380(376.42) | Grad Norm 2.9143(3.2442) | Total Time 10.00(10.00)\n",
      "Iter 0564 | Time 26.1336(26.6135) | Bit/dim 1.2637(1.3246) | Xent 0.1169(0.1651) | Loss 1.3221(1.4072) | Error 0.0356(0.0519) Steps 380(376.52) | Grad Norm 1.5933(3.1947) | Total Time 10.00(10.00)\n",
      "Iter 0565 | Time 27.8428(26.6504) | Bit/dim 1.2589(1.3226) | Xent 0.1629(0.1651) | Loss 1.3403(1.4052) | Error 0.0489(0.0518) Steps 386(376.81) | Grad Norm 3.4759(3.2031) | Total Time 10.00(10.00)\n",
      "Iter 0566 | Time 26.3778(26.6422) | Bit/dim 1.2560(1.3206) | Xent 0.1322(0.1641) | Loss 1.3221(1.4027) | Error 0.0396(0.0514) Steps 380(376.90) | Grad Norm 1.5891(3.1547) | Total Time 10.00(10.00)\n",
      "Iter 0567 | Time 26.3809(26.6344) | Bit/dim 1.2531(1.3186) | Xent 0.1332(0.1631) | Loss 1.3197(1.4002) | Error 0.0429(0.0512) Steps 374(376.82) | Grad Norm 1.9151(3.1175) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 15.3853, Epoch Time 214.8879(214.8088), Bit/dim 1.2466(best: 1.2512), Xent 0.0755, Loss 1.2844, Error 0.0252(best: 0.0232)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0568 | Time 27.4501(26.6589) | Bit/dim 1.2570(1.3168) | Xent 0.1515(0.1628) | Loss 1.3327(1.3982) | Error 0.0464(0.0510) Steps 380(376.91) | Grad Norm 3.3920(3.1257) | Total Time 10.00(10.00)\n",
      "Iter 0569 | Time 26.5442(26.6554) | Bit/dim 1.2477(1.3147) | Xent 0.1146(0.1613) | Loss 1.3050(1.3954) | Error 0.0390(0.0507) Steps 374(376.82) | Grad Norm 2.0036(3.0921) | Total Time 10.00(10.00)\n",
      "Iter 0570 | Time 25.8866(26.6324) | Bit/dim 1.2549(1.3129) | Xent 0.1184(0.1601) | Loss 1.3142(1.3929) | Error 0.0360(0.0502) Steps 374(376.74) | Grad Norm 1.3517(3.0399) | Total Time 10.00(10.00)\n",
      "Iter 0571 | Time 27.9120(26.6708) | Bit/dim 1.2488(1.3110) | Xent 0.1446(0.1596) | Loss 1.3211(1.3908) | Error 0.0474(0.0501) Steps 386(377.02) | Grad Norm 3.0577(3.0404) | Total Time 10.00(10.00)\n",
      "Iter 0572 | Time 26.8681(26.6767) | Bit/dim 1.2529(1.3092) | Xent 0.1247(0.1585) | Loss 1.3152(1.3885) | Error 0.0381(0.0498) Steps 374(376.93) | Grad Norm 2.8352(3.0342) | Total Time 10.00(10.00)\n",
      "Iter 0573 | Time 27.2484(26.6938) | Bit/dim 1.2532(1.3076) | Xent 0.1303(0.1577) | Loss 1.3183(1.3864) | Error 0.0410(0.0495) Steps 386(377.20) | Grad Norm 2.4995(3.0182) | Total Time 10.00(10.00)\n",
      "Iter 0574 | Time 28.7489(26.7555) | Bit/dim 1.2429(1.3056) | Xent 0.1478(0.1574) | Loss 1.3168(1.3843) | Error 0.0477(0.0495) Steps 386(377.46) | Grad Norm 2.1158(2.9911) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 15.3730, Epoch Time 218.4469(214.9180), Bit/dim 1.2288(best: 1.2466), Xent 0.0659, Loss 1.2617, Error 0.0208(best: 0.0232)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0575 | Time 28.1070(26.7960) | Bit/dim 1.2390(1.3036) | Xent 0.1440(0.1570) | Loss 1.3110(1.3821) | Error 0.0449(0.0493) Steps 380(377.54) | Grad Norm 0.5265(2.9172) | Total Time 10.00(10.00)\n",
      "Iter 0576 | Time 26.8417(26.7974) | Bit/dim 1.2530(1.3021) | Xent 0.1213(0.1559) | Loss 1.3136(1.3801) | Error 0.0371(0.0490) Steps 380(377.61) | Grad Norm 1.7002(2.8807) | Total Time 10.00(10.00)\n",
      "Iter 0577 | Time 27.6280(26.8223) | Bit/dim 1.2334(1.3000) | Xent 0.1134(0.1546) | Loss 1.2901(1.3774) | Error 0.0369(0.0486) Steps 386(377.86) | Grad Norm 1.1508(2.8288) | Total Time 10.00(10.00)\n",
      "Iter 0578 | Time 26.7656(26.8206) | Bit/dim 1.2364(1.2981) | Xent 0.1417(0.1543) | Loss 1.3072(1.3753) | Error 0.0449(0.0485) Steps 386(378.11) | Grad Norm 2.4760(2.8182) | Total Time 10.00(10.00)\n",
      "Iter 0579 | Time 25.9966(26.7959) | Bit/dim 1.2581(1.2969) | Xent 0.1084(0.1529) | Loss 1.3123(1.3734) | Error 0.0357(0.0481) Steps 374(377.99) | Grad Norm 4.5577(2.8704) | Total Time 10.00(10.00)\n",
      "Iter 0580 | Time 27.2710(26.8101) | Bit/dim 1.2895(1.2967) | Xent 0.1584(0.1530) | Loss 1.3687(1.3732) | Error 0.0500(0.0482) Steps 380(378.05) | Grad Norm 11.2660(3.1223) | Total Time 10.00(10.00)\n",
      "Iter 0581 | Time 27.8131(26.8402) | Bit/dim 1.5303(1.3037) | Xent 0.1525(0.1530) | Loss 1.6065(1.3802) | Error 0.0491(0.0482) Steps 386(378.28) | Grad Norm 11.3098(3.3679) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 14.8574, Epoch Time 217.5437(214.9967), Bit/dim 1.3605(best: 1.2288), Xent 0.0634, Loss 1.3922, Error 0.0207(best: 0.0208)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0582 | Time 25.8959(26.8119) | Bit/dim 1.3675(1.3056) | Xent 0.1104(0.1518) | Loss 1.4228(1.3815) | Error 0.0330(0.0477) Steps 380(378.34) | Grad Norm 5.5036(3.4320) | Total Time 10.00(10.00)\n",
      "Iter 0583 | Time 28.0416(26.8488) | Bit/dim 1.4595(1.3102) | Xent 0.1838(0.1527) | Loss 1.5514(1.3866) | Error 0.0596(0.0481) Steps 380(378.39) | Grad Norm 14.6984(3.7699) | Total Time 10.00(10.00)\n",
      "Iter 0584 | Time 26.2642(26.8313) | Bit/dim 1.3423(1.3112) | Xent 0.1308(0.1521) | Loss 1.4077(1.3872) | Error 0.0414(0.0479) Steps 380(378.43) | Grad Norm 3.8789(3.7732) | Total Time 10.00(10.00)\n",
      "Iter 0585 | Time 27.3897(26.8480) | Bit/dim 1.4162(1.3143) | Xent 0.1406(0.1517) | Loss 1.4865(1.3902) | Error 0.0455(0.0478) Steps 380(378.48) | Grad Norm 5.2780(3.8184) | Total Time 10.00(10.00)\n",
      "Iter 0586 | Time 26.0303(26.8235) | Bit/dim 1.3403(1.3151) | Xent 0.1427(0.1514) | Loss 1.4117(1.3909) | Error 0.0447(0.0477) Steps 374(378.35) | Grad Norm 2.9867(3.7934) | Total Time 10.00(10.00)\n",
      "Iter 0587 | Time 27.3938(26.8406) | Bit/dim 1.3444(1.3160) | Xent 0.1436(0.1512) | Loss 1.4163(1.3916) | Error 0.0466(0.0477) Steps 380(378.40) | Grad Norm 3.7449(3.7920) | Total Time 10.00(10.00)\n",
      "Iter 0588 | Time 29.6964(26.9263) | Bit/dim 1.3480(1.3170) | Xent 0.1636(0.1516) | Loss 1.4298(1.3928) | Error 0.0496(0.0477) Steps 380(378.44) | Grad Norm 4.7461(3.8206) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 14.3083, Epoch Time 217.4270(215.0696), Bit/dim 1.2950(best: 1.2288), Xent 0.0672, Loss 1.3287, Error 0.0217(best: 0.0207)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0589 | Time 27.4316(26.9414) | Bit/dim 1.3058(1.3166) | Xent 0.1420(0.1513) | Loss 1.3768(1.3923) | Error 0.0460(0.0477) Steps 380(378.49) | Grad Norm 1.9623(3.7648) | Total Time 10.00(10.00)\n",
      "Iter 0590 | Time 25.6194(26.9018) | Bit/dim 1.3363(1.3172) | Xent 0.1365(0.1509) | Loss 1.4045(1.3926) | Error 0.0426(0.0475) Steps 362(378.00) | Grad Norm 3.6668(3.7619) | Total Time 10.00(10.00)\n",
      "Iter 0591 | Time 28.4109(26.9470) | Bit/dim 1.3106(1.3170) | Xent 0.1200(0.1499) | Loss 1.3706(1.3920) | Error 0.0397(0.0473) Steps 362(377.52) | Grad Norm 1.9846(3.7086) | Total Time 10.00(10.00)\n",
      "Iter 0592 | Time 27.5107(26.9639) | Bit/dim 1.2992(1.3165) | Xent 0.1280(0.1493) | Loss 1.3632(1.3911) | Error 0.0421(0.0472) Steps 380(377.59) | Grad Norm 2.9452(3.6857) | Total Time 10.00(10.00)\n",
      "Iter 0593 | Time 26.8303(26.9599) | Bit/dim 1.3023(1.3161) | Xent 0.1435(0.1491) | Loss 1.3740(1.3906) | Error 0.0451(0.0471) Steps 380(377.66) | Grad Norm 4.1700(3.7002) | Total Time 10.00(10.00)\n",
      "Iter 0594 | Time 24.8715(26.8973) | Bit/dim 1.2784(1.3149) | Xent 0.1283(0.1485) | Loss 1.3425(1.3892) | Error 0.0389(0.0468) Steps 362(377.19) | Grad Norm 1.6187(3.6378) | Total Time 10.00(10.00)\n",
      "Iter 0595 | Time 25.3731(26.8516) | Bit/dim 1.3085(1.3147) | Xent 0.1160(0.1475) | Loss 1.3665(1.3885) | Error 0.0356(0.0465) Steps 362(376.74) | Grad Norm 3.5934(3.6364) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 14.5213, Epoch Time 212.9788(215.0069), Bit/dim 1.2812(best: 1.2288), Xent 0.0625, Loss 1.3125, Error 0.0199(best: 0.0207)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0596 | Time 25.5532(26.8126) | Bit/dim 1.2867(1.3139) | Xent 0.1206(0.1467) | Loss 1.3470(1.3872) | Error 0.0383(0.0463) Steps 362(376.30) | Grad Norm 1.5206(3.5730) | Total Time 10.00(10.00)\n",
      "Iter 0597 | Time 27.8716(26.8444) | Bit/dim 1.2765(1.3128) | Xent 0.1462(0.1467) | Loss 1.3496(1.3861) | Error 0.0467(0.0463) Steps 380(376.41) | Grad Norm 3.5256(3.5715) | Total Time 10.00(10.00)\n",
      "Iter 0598 | Time 25.7119(26.8104) | Bit/dim 1.2697(1.3115) | Xent 0.1493(0.1468) | Loss 1.3444(1.3849) | Error 0.0471(0.0463) Steps 374(376.33) | Grad Norm 1.5182(3.5099) | Total Time 10.00(10.00)\n",
      "Iter 0599 | Time 27.9395(26.8443) | Bit/dim 1.2778(1.3105) | Xent 0.1109(0.1457) | Loss 1.3332(1.3833) | Error 0.0351(0.0460) Steps 362(375.90) | Grad Norm 2.5010(3.4797) | Total Time 10.00(10.00)\n",
      "Iter 0600 | Time 26.0236(26.8197) | Bit/dim 1.2712(1.3093) | Xent 0.1147(0.1448) | Loss 1.3286(1.3817) | Error 0.0391(0.0458) Steps 362(375.49) | Grad Norm 1.3022(3.4143) | Total Time 10.00(10.00)\n",
      "Iter 0601 | Time 26.5384(26.8112) | Bit/dim 1.2634(1.3079) | Xent 0.1406(0.1446) | Loss 1.3337(1.3802) | Error 0.0456(0.0458) Steps 374(375.44) | Grad Norm 2.9389(3.4001) | Total Time 10.00(10.00)\n",
      "Iter 0602 | Time 26.1322(26.7908) | Bit/dim 1.2565(1.3064) | Xent 0.1485(0.1447) | Loss 1.3308(1.3787) | Error 0.0436(0.0457) Steps 374(375.40) | Grad Norm 1.5206(3.3437) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 15.2257, Epoch Time 213.4548(214.9603), Bit/dim 1.2504(best: 1.2288), Xent 0.0650, Loss 1.2829, Error 0.0201(best: 0.0199)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0603 | Time 27.9126(26.8245) | Bit/dim 1.2559(1.3049) | Xent 0.1285(0.1443) | Loss 1.3201(1.3770) | Error 0.0380(0.0455) Steps 374(375.36) | Grad Norm 1.8737(3.2996) | Total Time 10.00(10.00)\n",
      "Iter 0604 | Time 26.2921(26.8085) | Bit/dim 1.2558(1.3034) | Xent 0.1268(0.1437) | Loss 1.3192(1.3753) | Error 0.0376(0.0452) Steps 374(375.32) | Grad Norm 1.7534(3.2532) | Total Time 10.00(10.00)\n",
      "Iter 0605 | Time 27.0631(26.8162) | Bit/dim 1.2421(1.3016) | Xent 0.1393(0.1436) | Loss 1.3118(1.3733) | Error 0.0441(0.0452) Steps 374(375.28) | Grad Norm 1.5241(3.2013) | Total Time 10.00(10.00)\n",
      "Iter 0606 | Time 27.1489(26.8261) | Bit/dim 1.2540(1.3001) | Xent 0.1296(0.1432) | Loss 1.3188(1.3717) | Error 0.0417(0.0451) Steps 392(375.78) | Grad Norm 2.3693(3.1764) | Total Time 10.00(10.00)\n",
      "Iter 0607 | Time 26.0856(26.8039) | Bit/dim 1.2438(1.2984) | Xent 0.1226(0.1426) | Loss 1.3051(1.3697) | Error 0.0410(0.0450) Steps 374(375.73) | Grad Norm 0.7193(3.1027) | Total Time 10.00(10.00)\n",
      "Iter 0608 | Time 26.6535(26.7994) | Bit/dim 1.2505(1.2970) | Xent 0.1279(0.1421) | Loss 1.3145(1.3681) | Error 0.0406(0.0448) Steps 374(375.67) | Grad Norm 2.1376(3.0737) | Total Time 10.00(10.00)\n",
      "Iter 0609 | Time 26.3792(26.7868) | Bit/dim 1.2501(1.2956) | Xent 0.1205(0.1415) | Loss 1.3104(1.3663) | Error 0.0369(0.0446) Steps 380(375.80) | Grad Norm 2.0728(3.0437) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 15.4713, Epoch Time 215.9606(214.9904), Bit/dim 1.2315(best: 1.2288), Xent 0.0641, Loss 1.2635, Error 0.0209(best: 0.0199)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0610 | Time 27.5431(26.8095) | Bit/dim 1.2395(1.2939) | Xent 0.1293(0.1411) | Loss 1.3042(1.3645) | Error 0.0413(0.0445) Steps 374(375.75) | Grad Norm 0.8857(2.9789) | Total Time 10.00(10.00)\n",
      "Iter 0611 | Time 26.9997(26.8152) | Bit/dim 1.2386(1.2923) | Xent 0.1169(0.1404) | Loss 1.2970(1.3624) | Error 0.0363(0.0443) Steps 380(375.88) | Grad Norm 1.7140(2.9410) | Total Time 10.00(10.00)\n",
      "Iter 0612 | Time 27.2273(26.8276) | Bit/dim 1.2455(1.2908) | Xent 0.1260(0.1399) | Loss 1.3085(1.3608) | Error 0.0389(0.0441) Steps 374(375.82) | Grad Norm 2.7590(2.9355) | Total Time 10.00(10.00)\n",
      "Iter 0613 | Time 26.7332(26.8247) | Bit/dim 1.2376(1.2892) | Xent 0.1345(0.1398) | Loss 1.3048(1.3591) | Error 0.0433(0.0441) Steps 386(376.13) | Grad Norm 3.2218(2.9441) | Total Time 10.00(10.00)\n",
      "Iter 0614 | Time 27.3684(26.8410) | Bit/dim 1.2450(1.2879) | Xent 0.1188(0.1392) | Loss 1.3044(1.3575) | Error 0.0363(0.0438) Steps 374(376.06) | Grad Norm 3.2822(2.9543) | Total Time 10.00(10.00)\n",
      "Iter 0615 | Time 27.6372(26.8649) | Bit/dim 1.2360(1.2864) | Xent 0.1196(0.1386) | Loss 1.2958(1.3556) | Error 0.0396(0.0437) Steps 380(376.18) | Grad Norm 2.7084(2.9469) | Total Time 10.00(10.00)\n",
      "Iter 0616 | Time 26.7832(26.8625) | Bit/dim 1.2286(1.2846) | Xent 0.1135(0.1378) | Loss 1.2854(1.3535) | Error 0.0367(0.0435) Steps 374(376.11) | Grad Norm 1.4423(2.9018) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 15.2593, Epoch Time 217.9136(215.0781), Bit/dim 1.2210(best: 1.2288), Xent 0.0636, Loss 1.2528, Error 0.0203(best: 0.0199)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0617 | Time 27.0431(26.8679) | Bit/dim 1.2264(1.2829) | Xent 0.1226(0.1374) | Loss 1.2877(1.3516) | Error 0.0400(0.0434) Steps 380(376.23) | Grad Norm 0.9582(2.8434) | Total Time 10.00(10.00)\n",
      "Iter 0618 | Time 28.9094(26.9291) | Bit/dim 1.2292(1.2813) | Xent 0.1180(0.1368) | Loss 1.2882(1.3497) | Error 0.0396(0.0433) Steps 380(376.34) | Grad Norm 0.8496(2.7836) | Total Time 10.00(10.00)\n",
      "Iter 0619 | Time 29.2491(26.9987) | Bit/dim 1.2198(1.2794) | Xent 0.1126(0.1361) | Loss 1.2761(1.3475) | Error 0.0365(0.0431) Steps 380(376.45) | Grad Norm 0.8394(2.7253) | Total Time 10.00(10.00)\n",
      "Iter 0620 | Time 27.9772(27.0281) | Bit/dim 1.2228(1.2777) | Xent 0.1165(0.1355) | Loss 1.2810(1.3455) | Error 0.0363(0.0429) Steps 386(376.74) | Grad Norm 1.0132(2.6739) | Total Time 10.00(10.00)\n",
      "Iter 0621 | Time 27.5000(27.0423) | Bit/dim 1.2215(1.2760) | Xent 0.1113(0.1347) | Loss 1.2771(1.3434) | Error 0.0364(0.0427) Steps 380(376.84) | Grad Norm 1.2692(2.6318) | Total Time 10.00(10.00)\n",
      "Iter 0622 | Time 28.7648(27.0939) | Bit/dim 1.2287(1.2746) | Xent 0.1119(0.1341) | Loss 1.2847(1.3417) | Error 0.0377(0.0425) Steps 380(376.93) | Grad Norm 2.2484(2.6203) | Total Time 10.00(10.00)\n",
      "Iter 0623 | Time 28.6279(27.1400) | Bit/dim 1.2362(1.2735) | Xent 0.1303(0.1339) | Loss 1.3014(1.3404) | Error 0.0384(0.0424) Steps 380(377.03) | Grad Norm 5.5617(2.7085) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 14.6165, Epoch Time 224.9674(215.3747), Bit/dim 1.3339(best: 1.2210), Xent 0.0613, Loss 1.3645, Error 0.0202(best: 0.0199)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0624 | Time 27.3329(27.1457) | Bit/dim 1.3366(1.2754) | Xent 0.0956(0.1328) | Loss 1.3844(1.3418) | Error 0.0305(0.0420) Steps 374(376.93) | Grad Norm 9.3634(2.9082) | Total Time 10.00(10.00)\n",
      "Iter 0625 | Time 28.3780(27.1827) | Bit/dim 1.2855(1.2757) | Xent 0.1518(0.1334) | Loss 1.3614(1.3423) | Error 0.0483(0.0422) Steps 380(377.03) | Grad Norm 11.1717(3.1561) | Total Time 10.00(10.00)\n",
      "Iter 0626 | Time 26.3088(27.1565) | Bit/dim 1.3725(1.2786) | Xent 0.1341(0.1334) | Loss 1.4395(1.3453) | Error 0.0405(0.0422) Steps 380(377.12) | Grad Norm 8.3406(3.3116) | Total Time 10.00(10.00)\n",
      "Iter 0627 | Time 26.9230(27.1495) | Bit/dim 1.2728(1.2784) | Xent 0.1048(0.1325) | Loss 1.3252(1.3447) | Error 0.0323(0.0419) Steps 386(377.38) | Grad Norm 3.5394(3.3185) | Total Time 10.00(10.00)\n",
      "Iter 0628 | Time 27.6145(27.1634) | Bit/dim 1.4217(1.2827) | Xent 0.1965(0.1344) | Loss 1.5200(1.3499) | Error 0.0627(0.0425) Steps 386(377.64) | Grad Norm 15.1299(3.6728) | Total Time 10.00(10.00)\n",
      "Iter 0629 | Time 28.4923(27.2033) | Bit/dim 1.4243(1.2869) | Xent 0.1107(0.1337) | Loss 1.4796(1.3538) | Error 0.0345(0.0423) Steps 386(377.89) | Grad Norm 6.1210(3.7462) | Total Time 10.00(10.00)\n",
      "Iter 0630 | Time 25.7123(27.1586) | Bit/dim 1.5154(1.2938) | Xent 0.1134(0.1331) | Loss 1.5720(1.3604) | Error 0.0360(0.0421) Steps 374(377.77) | Grad Norm 5.2865(3.7925) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 14.6414, Epoch Time 217.5626(215.4404), Bit/dim 1.4311(best: 1.2210), Xent 0.0614, Loss 1.4618, Error 0.0192(best: 0.0199)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0631 | Time 26.6823(27.1443) | Bit/dim 1.4344(1.2980) | Xent 0.1078(0.1324) | Loss 1.4883(1.3642) | Error 0.0341(0.0418) Steps 380(377.84) | Grad Norm 3.4077(3.7809) | Total Time 10.00(10.00)\n",
      "Iter 0632 | Time 26.4339(27.1230) | Bit/dim 1.3501(1.2996) | Xent 0.1219(0.1321) | Loss 1.4110(1.3656) | Error 0.0377(0.0417) Steps 380(377.91) | Grad Norm 2.1805(3.7329) | Total Time 10.00(10.00)\n",
      "Iter 0633 | Time 27.4476(27.1327) | Bit/dim 1.3649(1.3015) | Xent 0.1627(0.1330) | Loss 1.4463(1.3680) | Error 0.0515(0.0420) Steps 380(377.97) | Grad Norm 5.2362(3.7780) | Total Time 10.00(10.00)\n",
      "Iter 0634 | Time 27.3578(27.1395) | Bit/dim 1.3700(1.3036) | Xent 0.1466(0.1334) | Loss 1.4433(1.3703) | Error 0.0474(0.0422) Steps 374(377.85) | Grad Norm 3.9804(3.7841) | Total Time 10.00(10.00)\n",
      "Iter 0635 | Time 26.3480(27.1157) | Bit/dim 1.3380(1.3046) | Xent 0.1122(0.1327) | Loss 1.3941(1.3710) | Error 0.0354(0.0420) Steps 380(377.91) | Grad Norm 2.3952(3.7424) | Total Time 10.00(10.00)\n",
      "Iter 0636 | Time 26.0047(27.0824) | Bit/dim 1.3664(1.3065) | Xent 0.1071(0.1320) | Loss 1.4199(1.3725) | Error 0.0335(0.0417) Steps 380(377.98) | Grad Norm 3.0980(3.7231) | Total Time 10.00(10.00)\n",
      "Iter 0637 | Time 28.5409(27.1261) | Bit/dim 1.3351(1.3073) | Xent 0.1214(0.1317) | Loss 1.3958(1.3732) | Error 0.0395(0.0416) Steps 386(378.22) | Grad Norm 2.8480(3.6968) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 14.6549, Epoch Time 215.7047(215.4483), Bit/dim 1.2993(best: 1.2210), Xent 0.0767, Loss 1.3377, Error 0.0232(best: 0.0192)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0638 | Time 27.8689(27.1484) | Bit/dim 1.3078(1.3073) | Xent 0.1614(0.1325) | Loss 1.3885(1.3736) | Error 0.0500(0.0419) Steps 392(378.63) | Grad Norm 2.0396(3.6471) | Total Time 10.00(10.00)\n",
      "Iter 0639 | Time 28.0635(27.1759) | Bit/dim 1.3014(1.3072) | Xent 0.1469(0.1330) | Loss 1.3749(1.3737) | Error 0.0455(0.0420) Steps 398(379.21) | Grad Norm 3.1254(3.6315) | Total Time 10.00(10.00)\n",
      "Iter 0640 | Time 28.9875(27.2302) | Bit/dim 1.2967(1.3069) | Xent 0.1397(0.1332) | Loss 1.3665(1.3734) | Error 0.0451(0.0421) Steps 386(379.42) | Grad Norm 2.8613(3.6083) | Total Time 10.00(10.00)\n",
      "Iter 0641 | Time 27.5202(27.2389) | Bit/dim 1.3040(1.3068) | Xent 0.1019(0.1322) | Loss 1.3550(1.3729) | Error 0.0339(0.0419) Steps 362(378.89) | Grad Norm 1.7574(3.5528) | Total Time 10.00(10.00)\n",
      "Iter 0642 | Time 27.3608(27.2426) | Bit/dim 1.3168(1.3071) | Xent 0.1027(0.1314) | Loss 1.3681(1.3727) | Error 0.0315(0.0415) Steps 362(378.39) | Grad Norm 2.5609(3.5231) | Total Time 10.00(10.00)\n",
      "Iter 0643 | Time 24.8455(27.1707) | Bit/dim 1.2926(1.3066) | Xent 0.1129(0.1308) | Loss 1.3491(1.3720) | Error 0.0373(0.0414) Steps 362(377.89) | Grad Norm 2.1238(3.4811) | Total Time 10.00(10.00)\n",
      "Iter 0644 | Time 27.1943(27.1714) | Bit/dim 1.2837(1.3059) | Xent 0.1385(0.1310) | Loss 1.3529(1.3715) | Error 0.0441(0.0415) Steps 392(378.32) | Grad Norm 1.9564(3.4353) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 14.7718, Epoch Time 219.0372(215.5560), Bit/dim 1.2670(best: 1.2210), Xent 0.0668, Loss 1.3004, Error 0.0214(best: 0.0192)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0645 | Time 26.6983(27.1572) | Bit/dim 1.2714(1.3049) | Xent 0.1409(0.1313) | Loss 1.3418(1.3706) | Error 0.0423(0.0415) Steps 368(378.01) | Grad Norm 2.2499(3.3998) | Total Time 10.00(10.00)\n",
      "Iter 0646 | Time 26.4841(27.1370) | Bit/dim 1.2649(1.3037) | Xent 0.1196(0.1310) | Loss 1.3247(1.3692) | Error 0.0375(0.0414) Steps 380(378.07) | Grad Norm 1.4055(3.3399) | Total Time 10.00(10.00)\n",
      "Iter 0647 | Time 26.7872(27.1265) | Bit/dim 1.2768(1.3029) | Xent 0.1099(0.1303) | Loss 1.3317(1.3681) | Error 0.0331(0.0411) Steps 380(378.13) | Grad Norm 1.8238(3.2945) | Total Time 10.00(10.00)\n",
      "Iter 0648 | Time 26.8900(27.1194) | Bit/dim 1.2694(1.3019) | Xent 0.1155(0.1299) | Loss 1.3272(1.3668) | Error 0.0350(0.0410) Steps 392(378.54) | Grad Norm 1.1851(3.2312) | Total Time 10.00(10.00)\n",
      "Iter 0649 | Time 27.8707(27.1419) | Bit/dim 1.2605(1.3007) | Xent 0.1212(0.1296) | Loss 1.3211(1.3655) | Error 0.0375(0.0409) Steps 374(378.41) | Grad Norm 1.6147(3.1827) | Total Time 10.00(10.00)\n",
      "Iter 0650 | Time 27.1878(27.1433) | Bit/dim 1.2477(1.2991) | Xent 0.1278(0.1296) | Loss 1.3116(1.3639) | Error 0.0421(0.0409) Steps 380(378.45) | Grad Norm 1.1833(3.1227) | Total Time 10.00(10.00)\n",
      "Iter 0651 | Time 29.4444(27.2124) | Bit/dim 1.2508(1.2976) | Xent 0.1167(0.1292) | Loss 1.3091(1.3622) | Error 0.0381(0.0408) Steps 386(378.68) | Grad Norm 1.2238(3.0657) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 15.2781, Epoch Time 218.9974(215.6592), Bit/dim 1.2439(best: 1.2210), Xent 0.0595, Loss 1.2736, Error 0.0201(best: 0.0192)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0652 | Time 28.0990(27.2390) | Bit/dim 1.2498(1.2962) | Xent 0.1107(0.1286) | Loss 1.3051(1.3605) | Error 0.0349(0.0406) Steps 374(378.54) | Grad Norm 1.2031(3.0099) | Total Time 10.00(10.00)\n",
      "Iter 0653 | Time 28.0251(27.2625) | Bit/dim 1.2445(1.2946) | Xent 0.1164(0.1283) | Loss 1.3027(1.3588) | Error 0.0365(0.0405) Steps 374(378.40) | Grad Norm 0.8254(2.9443) | Total Time 10.00(10.00)\n",
      "Iter 0654 | Time 28.4842(27.2992) | Bit/dim 1.2499(1.2933) | Xent 0.1219(0.1281) | Loss 1.3109(1.3573) | Error 0.0383(0.0404) Steps 398(378.99) | Grad Norm 1.3228(2.8957) | Total Time 10.00(10.00)\n",
      "Iter 0655 | Time 28.1885(27.3259) | Bit/dim 1.2430(1.2918) | Xent 0.1204(0.1279) | Loss 1.3032(1.3557) | Error 0.0384(0.0404) Steps 380(379.02) | Grad Norm 1.0263(2.8396) | Total Time 10.00(10.00)\n",
      "Iter 0656 | Time 27.0455(27.3175) | Bit/dim 1.2326(1.2900) | Xent 0.1140(0.1274) | Loss 1.2896(1.3537) | Error 0.0345(0.0402) Steps 380(379.05) | Grad Norm 0.9645(2.7834) | Total Time 10.00(10.00)\n",
      "Iter 0657 | Time 29.2615(27.3758) | Bit/dim 1.2369(1.2884) | Xent 0.1126(0.1270) | Loss 1.2932(1.3519) | Error 0.0353(0.0401) Steps 386(379.26) | Grad Norm 0.9203(2.7275) | Total Time 10.00(10.00)\n",
      "Iter 0658 | Time 29.6766(27.4448) | Bit/dim 1.2348(1.2868) | Xent 0.1125(0.1266) | Loss 1.2910(1.3501) | Error 0.0351(0.0399) Steps 386(379.46) | Grad Norm 0.8772(2.6720) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 15.3172, Epoch Time 226.5901(215.9871), Bit/dim 1.2250(best: 1.2210), Xent 0.0570, Loss 1.2536, Error 0.0192(best: 0.0192)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0659 | Time 27.4794(27.4458) | Bit/dim 1.2403(1.2854) | Xent 0.1165(0.1263) | Loss 1.2986(1.3485) | Error 0.0370(0.0398) Steps 374(379.30) | Grad Norm 1.0779(2.6241) | Total Time 10.00(10.00)\n",
      "Iter 0660 | Time 28.7213(27.4841) | Bit/dim 1.2243(1.2836) | Xent 0.1153(0.1259) | Loss 1.2819(1.3465) | Error 0.0367(0.0397) Steps 398(379.86) | Grad Norm 0.7596(2.5682) | Total Time 10.00(10.00)\n",
      "Iter 0661 | Time 28.8640(27.5255) | Bit/dim 1.2244(1.2818) | Xent 0.1153(0.1256) | Loss 1.2820(1.3446) | Error 0.0354(0.0396) Steps 380(379.86) | Grad Norm 1.0601(2.5230) | Total Time 10.00(10.00)\n",
      "Iter 0662 | Time 27.7345(27.5318) | Bit/dim 1.2278(1.2802) | Xent 0.1107(0.1252) | Loss 1.2831(1.3428) | Error 0.0350(0.0395) Steps 392(380.23) | Grad Norm 0.8407(2.4725) | Total Time 10.00(10.00)\n",
      "Iter 0663 | Time 27.3613(27.5267) | Bit/dim 1.2278(1.2786) | Xent 0.1123(0.1248) | Loss 1.2840(1.3410) | Error 0.0354(0.0393) Steps 392(380.58) | Grad Norm 0.8688(2.4244) | Total Time 10.00(10.00)\n",
      "Iter 0664 | Time 29.4335(27.5839) | Bit/dim 1.2221(1.2769) | Xent 0.1096(0.1243) | Loss 1.2769(1.3391) | Error 0.0354(0.0392) Steps 392(380.92) | Grad Norm 1.0725(2.3838) | Total Time 10.00(10.00)\n",
      "Iter 0665 | Time 28.4185(27.6089) | Bit/dim 1.2221(1.2753) | Xent 0.1204(0.1242) | Loss 1.2823(1.3374) | Error 0.0349(0.0391) Steps 392(381.26) | Grad Norm 2.3485(2.3828) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 15.2111, Epoch Time 225.6622(216.2774), Bit/dim 1.2352(best: 1.2210), Xent 0.0541, Loss 1.2623, Error 0.0177(best: 0.0192)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0666 | Time 26.6879(27.5813) | Bit/dim 1.2417(1.2743) | Xent 0.1087(0.1237) | Loss 1.2960(1.3361) | Error 0.0321(0.0389) Steps 392(381.58) | Grad Norm 4.3798(2.4427) | Total Time 10.00(10.00)\n",
      "Iter 0667 | Time 29.1943(27.6297) | Bit/dim 1.2423(1.2733) | Xent 0.1170(0.1235) | Loss 1.3008(1.3351) | Error 0.0386(0.0389) Steps 380(381.53) | Grad Norm 6.6052(2.5675) | Total Time 10.00(10.00)\n",
      "Iter 0668 | Time 26.6936(27.6016) | Bit/dim 1.2901(1.2738) | Xent 0.1347(0.1239) | Loss 1.3575(1.3357) | Error 0.0430(0.0390) Steps 374(381.30) | Grad Norm 8.3698(2.7416) | Total Time 10.00(10.00)\n",
      "Iter 0669 | Time 27.5097(27.5988) | Bit/dim 1.2810(1.2740) | Xent 0.1229(0.1238) | Loss 1.3424(1.3359) | Error 0.0375(0.0390) Steps 392(381.63) | Grad Norm 7.9671(2.8984) | Total Time 10.00(10.00)\n",
      "Iter 0670 | Time 26.7483(27.5733) | Bit/dim 1.2568(1.2735) | Xent 0.0970(0.1230) | Loss 1.3053(1.3350) | Error 0.0311(0.0387) Steps 386(381.76) | Grad Norm 4.5632(2.9483) | Total Time 10.00(10.00)\n",
      "Iter 0671 | Time 26.4688(27.5402) | Bit/dim 1.2296(1.2722) | Xent 0.1128(0.1227) | Loss 1.2860(1.3335) | Error 0.0379(0.0387) Steps 386(381.88) | Grad Norm 1.5993(2.9079) | Total Time 10.00(10.00)\n",
      "Iter 0672 | Time 28.4550(27.5676) | Bit/dim 1.2559(1.2717) | Xent 0.1224(0.1227) | Loss 1.3171(1.3331) | Error 0.0385(0.0387) Steps 392(382.19) | Grad Norm 6.3430(3.0109) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 14.7540, Epoch Time 218.8094(216.3533), Bit/dim 1.2854(best: 1.2210), Xent 0.0595, Loss 1.3151, Error 0.0193(best: 0.0177)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0673 | Time 26.7126(27.5420) | Bit/dim 1.2857(1.2721) | Xent 0.1068(0.1222) | Loss 1.3391(1.3332) | Error 0.0329(0.0385) Steps 392(382.48) | Grad Norm 6.3179(3.1101) | Total Time 10.00(10.00)\n",
      "Iter 0674 | Time 26.9782(27.5251) | Bit/dim 1.2348(1.2710) | Xent 0.1003(0.1216) | Loss 1.2850(1.3318) | Error 0.0311(0.0383) Steps 392(382.77) | Grad Norm 2.0347(3.0779) | Total Time 10.00(10.00)\n",
      "Iter 0675 | Time 28.1254(27.5431) | Bit/dim 1.2882(1.2715) | Xent 0.1497(0.1224) | Loss 1.3630(1.3327) | Error 0.0490(0.0386) Steps 398(383.22) | Grad Norm 10.0094(3.2858) | Total Time 10.00(10.00)\n",
      "Iter 0676 | Time 27.5952(27.5446) | Bit/dim 1.3390(1.2735) | Xent 0.1198(0.1223) | Loss 1.3989(1.3347) | Error 0.0363(0.0385) Steps 386(383.31) | Grad Norm 6.3165(3.3767) | Total Time 10.00(10.00)\n",
      "Iter 0677 | Time 25.6284(27.4871) | Bit/dim 1.3241(1.2751) | Xent 0.0781(0.1210) | Loss 1.3632(1.3356) | Error 0.0252(0.0381) Steps 374(383.03) | Grad Norm 4.9219(3.4231) | Total Time 10.00(10.00)\n",
      "Iter 0678 | Time 28.4239(27.5152) | Bit/dim 1.2670(1.2748) | Xent 0.1229(0.1211) | Loss 1.3284(1.3354) | Error 0.0369(0.0381) Steps 380(382.94) | Grad Norm 3.6576(3.4301) | Total Time 10.00(10.00)\n",
      "Iter 0679 | Time 27.1517(27.5043) | Bit/dim 1.2900(1.2753) | Xent 0.1465(0.1218) | Loss 1.3633(1.3362) | Error 0.0465(0.0384) Steps 380(382.85) | Grad Norm 7.1164(3.5407) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 14.5250, Epoch Time 217.5231(216.3884), Bit/dim 1.2871(best: 1.2210), Xent 0.0564, Loss 1.3154, Error 0.0189(best: 0.0177)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0680 | Time 26.3349(27.4693) | Bit/dim 1.2907(1.2757) | Xent 0.1048(0.1213) | Loss 1.3431(1.3364) | Error 0.0335(0.0382) Steps 374(382.58) | Grad Norm 4.4541(3.5681) | Total Time 10.00(10.00)\n",
      "Iter 0681 | Time 26.5701(27.4423) | Bit/dim 1.3325(1.2774) | Xent 0.0985(0.1206) | Loss 1.3817(1.3378) | Error 0.0315(0.0380) Steps 398(383.05) | Grad Norm 4.2879(3.5897) | Total Time 10.00(10.00)\n",
      "Iter 0682 | Time 27.6051(27.4472) | Bit/dim 1.2589(1.2769) | Xent 0.1056(0.1202) | Loss 1.3117(1.3370) | Error 0.0321(0.0378) Steps 398(383.50) | Grad Norm 1.8559(3.5377) | Total Time 10.00(10.00)\n",
      "Iter 0683 | Time 27.6079(27.4520) | Bit/dim 1.2891(1.2772) | Xent 0.1490(0.1211) | Loss 1.3636(1.3378) | Error 0.0476(0.0381) Steps 380(383.39) | Grad Norm 6.4446(3.6249) | Total Time 10.00(10.00)\n",
      "Iter 0684 | Time 27.2289(27.4453) | Bit/dim 1.2397(1.2761) | Xent 0.1315(0.1214) | Loss 1.3055(1.3368) | Error 0.0411(0.0382) Steps 380(383.29) | Grad Norm 1.2157(3.5526) | Total Time 10.00(10.00)\n",
      "Iter 0685 | Time 25.9930(27.4017) | Bit/dim 1.2843(1.2764) | Xent 0.1042(0.1209) | Loss 1.3364(1.3368) | Error 0.0335(0.0381) Steps 380(383.19) | Grad Norm 2.8227(3.5307) | Total Time 10.00(10.00)\n",
      "Iter 0686 | Time 27.0759(27.3920) | Bit/dim 1.2720(1.2762) | Xent 0.0917(0.1200) | Loss 1.3179(1.3362) | Error 0.0276(0.0378) Steps 380(383.09) | Grad Norm 2.5183(3.5003) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 15.0909, Epoch Time 215.8757(216.3731), Bit/dim 1.2351(best: 1.2210), Xent 0.0597, Loss 1.2649, Error 0.0182(best: 0.0177)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0687 | Time 27.5707(27.3973) | Bit/dim 1.2371(1.2751) | Xent 0.1173(0.1199) | Loss 1.2957(1.3350) | Error 0.0356(0.0377) Steps 374(382.82) | Grad Norm 1.5118(3.4407) | Total Time 10.00(10.00)\n",
      "Iter 0688 | Time 27.3452(27.3958) | Bit/dim 1.2577(1.2745) | Xent 0.1352(0.1204) | Loss 1.3253(1.3347) | Error 0.0421(0.0378) Steps 380(382.74) | Grad Norm 4.5455(3.4738) | Total Time 10.00(10.00)\n",
      "Iter 0689 | Time 26.8879(27.3805) | Bit/dim 1.2467(1.2737) | Xent 0.1004(0.1198) | Loss 1.2969(1.3336) | Error 0.0300(0.0376) Steps 374(382.47) | Grad Norm 1.8451(3.4250) | Total Time 10.00(10.00)\n",
      "Iter 0690 | Time 25.5148(27.3245) | Bit/dim 1.2596(1.2733) | Xent 0.0937(0.1190) | Loss 1.3064(1.3328) | Error 0.0317(0.0374) Steps 374(382.22) | Grad Norm 2.6712(3.4024) | Total Time 10.00(10.00)\n",
      "Iter 0691 | Time 27.4262(27.3276) | Bit/dim 1.2382(1.2722) | Xent 0.1122(0.1188) | Loss 1.2943(1.3316) | Error 0.0339(0.0373) Steps 386(382.33) | Grad Norm 1.2085(3.3365) | Total Time 10.00(10.00)\n",
      "Iter 0692 | Time 29.5303(27.3937) | Bit/dim 1.2382(1.2712) | Xent 0.1299(0.1191) | Loss 1.3031(1.3308) | Error 0.0397(0.0374) Steps 380(382.26) | Grad Norm 2.6240(3.3152) | Total Time 10.00(10.00)\n",
      "Iter 0693 | Time 27.5596(27.3987) | Bit/dim 1.2288(1.2699) | Xent 0.1231(0.1192) | Loss 1.2904(1.3295) | Error 0.0400(0.0375) Steps 380(382.20) | Grad Norm 1.3721(3.2569) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 15.1669, Epoch Time 219.6216(216.4705), Bit/dim 1.2259(best: 1.2210), Xent 0.0577, Loss 1.2547, Error 0.0181(best: 0.0177)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0694 | Time 28.0870(27.4193) | Bit/dim 1.2326(1.2688) | Xent 0.1116(0.1190) | Loss 1.2884(1.3283) | Error 0.0366(0.0374) Steps 392(382.49) | Grad Norm 1.4081(3.2014) | Total Time 10.00(10.00)\n",
      "Iter 0695 | Time 26.1966(27.3826) | Bit/dim 1.2378(1.2679) | Xent 0.0959(0.1183) | Loss 1.2857(1.3270) | Error 0.0300(0.0372) Steps 374(382.24) | Grad Norm 2.1547(3.1700) | Total Time 10.00(10.00)\n",
      "Iter 0696 | Time 27.2766(27.3794) | Bit/dim 1.2224(1.2665) | Xent 0.1132(0.1182) | Loss 1.2790(1.3256) | Error 0.0363(0.0372) Steps 386(382.35) | Grad Norm 0.8552(3.1006) | Total Time 10.00(10.00)\n",
      "Iter 0697 | Time 28.1088(27.4013) | Bit/dim 1.2347(1.2656) | Xent 0.1180(0.1181) | Loss 1.2937(1.3246) | Error 0.0351(0.0371) Steps 392(382.64) | Grad Norm 3.1555(3.1022) | Total Time 10.00(10.00)\n",
      "Iter 0698 | Time 26.6420(27.3785) | Bit/dim 1.2303(1.2645) | Xent 0.1006(0.1176) | Loss 1.2806(1.3233) | Error 0.0320(0.0370) Steps 386(382.74) | Grad Norm 3.3506(3.1097) | Total Time 10.00(10.00)\n",
      "Iter 0699 | Time 29.7463(27.4496) | Bit/dim 1.2363(1.2637) | Xent 0.1238(0.1178) | Loss 1.2983(1.3226) | Error 0.0375(0.0370) Steps 392(383.02) | Grad Norm 3.2882(3.1150) | Total Time 10.00(10.00)\n",
      "Iter 0700 | Time 27.1209(27.4397) | Bit/dim 1.2342(1.2628) | Xent 0.1076(0.1175) | Loss 1.2880(1.3215) | Error 0.0361(0.0370) Steps 374(382.75) | Grad Norm 4.1514(3.1461) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 15.3591, Epoch Time 220.9154(216.6039), Bit/dim 1.2182(best: 1.2210), Xent 0.0568, Loss 1.2466, Error 0.0185(best: 0.0177)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0701 | Time 28.1690(27.4616) | Bit/dim 1.2288(1.2618) | Xent 0.1232(0.1177) | Loss 1.2904(1.3206) | Error 0.0387(0.0370) Steps 380(382.66) | Grad Norm 4.2651(3.1797) | Total Time 10.00(10.00)\n",
      "Iter 0702 | Time 27.5917(27.4655) | Bit/dim 1.2209(1.2605) | Xent 0.1133(0.1175) | Loss 1.2776(1.3193) | Error 0.0341(0.0369) Steps 386(382.76) | Grad Norm 2.7150(3.1657) | Total Time 10.00(10.00)\n",
      "Iter 0703 | Time 27.0502(27.4530) | Bit/dim 1.2232(1.2594) | Xent 0.1016(0.1171) | Loss 1.2740(1.3179) | Error 0.0317(0.0368) Steps 386(382.86) | Grad Norm 1.0466(3.1022) | Total Time 10.00(10.00)\n",
      "Iter 0704 | Time 26.9817(27.4389) | Bit/dim 1.2187(1.2582) | Xent 0.1085(0.1168) | Loss 1.2729(1.3166) | Error 0.0353(0.0367) Steps 386(382.95) | Grad Norm 1.4887(3.0538) | Total Time 10.00(10.00)\n",
      "Iter 0705 | Time 27.4642(27.4397) | Bit/dim 1.2171(1.2570) | Xent 0.1049(0.1165) | Loss 1.2695(1.3152) | Error 0.0320(0.0366) Steps 404(383.59) | Grad Norm 2.2455(3.0295) | Total Time 10.00(10.00)\n",
      "Iter 0706 | Time 28.3340(27.4665) | Bit/dim 1.2236(1.2560) | Xent 0.1093(0.1162) | Loss 1.2783(1.3141) | Error 0.0361(0.0366) Steps 392(383.84) | Grad Norm 3.8061(3.0528) | Total Time 10.00(10.00)\n",
      "Iter 0707 | Time 27.4895(27.4672) | Bit/dim 1.2334(1.2553) | Xent 0.1130(0.1161) | Loss 1.2899(1.3134) | Error 0.0379(0.0366) Steps 386(383.90) | Grad Norm 4.9951(3.1111) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 15.3745, Epoch Time 220.8315(216.7307), Bit/dim 1.2350(best: 1.2182), Xent 0.0598, Loss 1.2649, Error 0.0196(best: 0.0177)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0708 | Time 28.5695(27.5003) | Bit/dim 1.2462(1.2550) | Xent 0.1142(0.1161) | Loss 1.3034(1.3131) | Error 0.0334(0.0365) Steps 392(384.15) | Grad Norm 5.6560(3.1874) | Total Time 10.00(10.00)\n",
      "Iter 0709 | Time 26.4338(27.4683) | Bit/dim 1.2337(1.2544) | Xent 0.0933(0.1154) | Loss 1.2803(1.3121) | Error 0.0302(0.0363) Steps 374(383.84) | Grad Norm 4.8399(3.2370) | Total Time 10.00(10.00)\n",
      "Iter 0710 | Time 28.4637(27.4981) | Bit/dim 1.2113(1.2531) | Xent 0.1063(0.1151) | Loss 1.2645(1.3106) | Error 0.0339(0.0363) Steps 392(384.09) | Grad Norm 2.6870(3.2205) | Total Time 10.00(10.00)\n",
      "Iter 0711 | Time 27.8773(27.5095) | Bit/dim 1.2125(1.2519) | Xent 0.0998(0.1147) | Loss 1.2624(1.3092) | Error 0.0316(0.0361) Steps 392(384.32) | Grad Norm 1.1825(3.1594) | Total Time 10.00(10.00)\n",
      "Iter 0712 | Time 26.7936(27.4880) | Bit/dim 1.2224(1.2510) | Xent 0.0982(0.1142) | Loss 1.2715(1.3081) | Error 0.0296(0.0359) Steps 386(384.37) | Grad Norm 3.2394(3.1618) | Total Time 10.00(10.00)\n",
      "Iter 0713 | Time 28.8782(27.5297) | Bit/dim 1.2187(1.2500) | Xent 0.1149(0.1142) | Loss 1.2761(1.3071) | Error 0.0341(0.0359) Steps 392(384.60) | Grad Norm 4.7564(3.2096) | Total Time 10.00(10.00)\n",
      "Iter 0714 | Time 26.8510(27.5094) | Bit/dim 1.2331(1.2495) | Xent 0.0951(0.1136) | Loss 1.2806(1.3063) | Error 0.0311(0.0357) Steps 386(384.65) | Grad Norm 5.3196(3.2729) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 15.3838, Epoch Time 221.9755(216.8880), Bit/dim 1.2167(best: 1.2182), Xent 0.0508, Loss 1.2421, Error 0.0169(best: 0.0177)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0715 | Time 27.8092(27.5184) | Bit/dim 1.2203(1.2486) | Xent 0.0960(0.1131) | Loss 1.2683(1.3052) | Error 0.0309(0.0356) Steps 392(384.87) | Grad Norm 4.1655(3.2997) | Total Time 10.00(10.00)\n",
      "Iter 0716 | Time 27.2174(27.5093) | Bit/dim 1.2099(1.2475) | Xent 0.0944(0.1125) | Loss 1.2571(1.3037) | Error 0.0314(0.0355) Steps 386(384.90) | Grad Norm 1.9450(3.2590) | Total Time 10.00(10.00)\n",
      "Iter 0717 | Time 28.1110(27.5274) | Bit/dim 1.2043(1.2462) | Xent 0.0975(0.1121) | Loss 1.2531(1.3022) | Error 0.0314(0.0353) Steps 392(385.11) | Grad Norm 0.6032(3.1794) | Total Time 10.00(10.00)\n",
      "Iter 0718 | Time 27.9700(27.5407) | Bit/dim 1.2140(1.2452) | Xent 0.0931(0.1115) | Loss 1.2606(1.3010) | Error 0.0298(0.0352) Steps 392(385.32) | Grad Norm 2.0385(3.1451) | Total Time 10.00(10.00)\n",
      "Iter 0719 | Time 27.0318(27.5254) | Bit/dim 1.2204(1.2445) | Xent 0.1070(0.1114) | Loss 1.2739(1.3002) | Error 0.0341(0.0351) Steps 386(385.34) | Grad Norm 3.8686(3.1668) | Total Time 10.00(10.00)\n",
      "Iter 0720 | Time 28.1864(27.5452) | Bit/dim 1.2228(1.2438) | Xent 0.1104(0.1113) | Loss 1.2780(1.2995) | Error 0.0364(0.0352) Steps 392(385.54) | Grad Norm 6.4416(3.2651) | Total Time 10.00(10.00)\n",
      "Iter 0721 | Time 27.0992(27.5318) | Bit/dim 1.3001(1.2455) | Xent 0.1044(0.1111) | Loss 1.3524(1.3011) | Error 0.0314(0.0351) Steps 392(385.73) | Grad Norm 8.0989(3.4101) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 15.4680, Epoch Time 221.3411(217.0216), Bit/dim 1.2241(best: 1.2167), Xent 0.0484, Loss 1.2483, Error 0.0163(best: 0.0169)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0722 | Time 28.4996(27.5609) | Bit/dim 1.2294(1.2450) | Xent 0.0903(0.1105) | Loss 1.2745(1.3003) | Error 0.0300(0.0349) Steps 398(386.10) | Grad Norm 4.1840(3.4333) | Total Time 10.00(10.00)\n",
      "Iter 0723 | Time 28.3457(27.5844) | Bit/dim 1.2207(1.2443) | Xent 0.1156(0.1107) | Loss 1.2785(1.2996) | Error 0.0346(0.0349) Steps 398(386.46) | Grad Norm 3.1913(3.4261) | Total Time 10.00(10.00)\n",
      "Iter 0724 | Time 26.4602(27.5507) | Bit/dim 1.2509(1.2445) | Xent 0.0996(0.1103) | Loss 1.3007(1.2997) | Error 0.0301(0.0348) Steps 386(386.44) | Grad Norm 5.1075(3.4765) | Total Time 10.00(10.00)\n",
      "Iter 0725 | Time 28.1924(27.5699) | Bit/dim 1.2239(1.2439) | Xent 0.0942(0.1098) | Loss 1.2710(1.2988) | Error 0.0305(0.0346) Steps 398(386.79) | Grad Norm 1.9370(3.4303) | Total Time 10.00(10.00)\n",
      "Iter 0726 | Time 28.2054(27.5890) | Bit/dim 1.2246(1.2433) | Xent 0.1136(0.1100) | Loss 1.2814(1.2983) | Error 0.0349(0.0346) Steps 398(387.13) | Grad Norm 4.3503(3.4579) | Total Time 10.00(10.00)\n",
      "Iter 0727 | Time 27.2073(27.5776) | Bit/dim 1.2708(1.2441) | Xent 0.0934(0.1095) | Loss 1.3174(1.2989) | Error 0.0288(0.0345) Steps 392(387.27) | Grad Norm 6.2255(3.5409) | Total Time 10.00(10.00)\n",
      "Iter 0728 | Time 28.1833(27.5957) | Bit/dim 1.2190(1.2434) | Xent 0.0866(0.1088) | Loss 1.2623(1.2978) | Error 0.0305(0.0343) Steps 392(387.42) | Grad Norm 2.0648(3.4967) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 15.4298, Epoch Time 222.9353(217.1990), Bit/dim 1.2418(best: 1.2167), Xent 0.0541, Loss 1.2688, Error 0.0171(best: 0.0163)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0729 | Time 27.8479(27.6033) | Bit/dim 1.2458(1.2434) | Xent 0.1160(0.1090) | Loss 1.3038(1.2979) | Error 0.0371(0.0344) Steps 398(387.73) | Grad Norm 7.8031(3.6259) | Total Time 10.00(10.00)\n",
      "Iter 0730 | Time 26.5487(27.5717) | Bit/dim 1.3388(1.2463) | Xent 0.1011(0.1088) | Loss 1.3893(1.3007) | Error 0.0325(0.0344) Steps 392(387.86) | Grad Norm 7.5898(3.7448) | Total Time 10.00(10.00)\n",
      "Iter 0731 | Time 26.3306(27.5344) | Bit/dim 1.2708(1.2470) | Xent 0.0842(0.1080) | Loss 1.3129(1.3010) | Error 0.0259(0.0341) Steps 392(387.99) | Grad Norm 4.2552(3.7601) | Total Time 10.00(10.00)\n",
      "Iter 0732 | Time 27.6719(27.5385) | Bit/dim 1.3186(1.2492) | Xent 0.1264(0.1086) | Loss 1.3817(1.3035) | Error 0.0389(0.0343) Steps 398(388.29) | Grad Norm 10.5852(3.9648) | Total Time 10.00(10.00)\n",
      "Iter 0733 | Time 27.9191(27.5500) | Bit/dim 1.2567(1.2494) | Xent 0.0892(0.1080) | Loss 1.3013(1.3034) | Error 0.0278(0.0341) Steps 392(388.40) | Grad Norm 3.3956(3.9478) | Total Time 10.00(10.00)\n",
      "Iter 0734 | Time 26.8259(27.5282) | Bit/dim 1.3059(1.2511) | Xent 0.0897(0.1074) | Loss 1.3508(1.3048) | Error 0.0259(0.0338) Steps 392(388.51) | Grad Norm 4.9238(3.9770) | Total Time 10.00(10.00)\n",
      "Iter 0735 | Time 25.9981(27.4823) | Bit/dim 1.2315(1.2505) | Xent 0.0816(0.1067) | Loss 1.2723(1.3038) | Error 0.0251(0.0335) Steps 374(388.07) | Grad Norm 1.4089(3.9000) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 15.0318, Epoch Time 216.3915(217.1748), Bit/dim 1.2834(best: 1.2167), Xent 0.0561, Loss 1.3115, Error 0.0176(best: 0.0163)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0736 | Time 27.3639(27.4788) | Bit/dim 1.2862(1.2516) | Xent 0.1258(0.1072) | Loss 1.3491(1.3052) | Error 0.0379(0.0337) Steps 392(388.19) | Grad Norm 7.2814(4.0014) | Total Time 10.00(10.00)\n",
      "Iter 0737 | Time 25.8986(27.4314) | Bit/dim 1.2363(1.2511) | Xent 0.0954(0.1069) | Loss 1.2840(1.3046) | Error 0.0320(0.0336) Steps 380(387.94) | Grad Norm 2.1011(3.9444) | Total Time 10.00(10.00)\n",
      "Iter 0738 | Time 27.1159(27.4219) | Bit/dim 1.2815(1.2520) | Xent 0.0784(0.1060) | Loss 1.3207(1.3051) | Error 0.0262(0.0334) Steps 392(388.06) | Grad Norm 4.3258(3.9559) | Total Time 10.00(10.00)\n",
      "Iter 0739 | Time 27.3028(27.4183) | Bit/dim 1.2362(1.2516) | Xent 0.0924(0.1056) | Loss 1.2824(1.3044) | Error 0.0278(0.0332) Steps 398(388.36) | Grad Norm 1.7309(3.8891) | Total Time 10.00(10.00)\n",
      "Iter 0740 | Time 27.4243(27.4185) | Bit/dim 1.2570(1.2517) | Xent 0.1111(0.1058) | Loss 1.3126(1.3046) | Error 0.0355(0.0333) Steps 392(388.47) | Grad Norm 5.3758(3.9337) | Total Time 10.00(10.00)\n",
      "Iter 0741 | Time 27.2441(27.4133) | Bit/dim 1.2269(1.2510) | Xent 0.1159(0.1061) | Loss 1.2848(1.3040) | Error 0.0371(0.0334) Steps 374(388.04) | Grad Norm 1.5123(3.8611) | Total Time 10.00(10.00)\n",
      "Iter 0742 | Time 26.4812(27.3853) | Bit/dim 1.2403(1.2507) | Xent 0.0966(0.1058) | Loss 1.2886(1.3036) | Error 0.0285(0.0333) Steps 386(387.98) | Grad Norm 3.3622(3.8461) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 14.6794, Epoch Time 215.8923(217.1363), Bit/dim 1.2293(best: 1.2167), Xent 0.0531, Loss 1.2558, Error 0.0186(best: 0.0163)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0743 | Time 27.0330(27.3748) | Bit/dim 1.2330(1.2501) | Xent 0.0921(0.1054) | Loss 1.2791(1.3028) | Error 0.0302(0.0332) Steps 386(387.92) | Grad Norm 1.7611(3.7836) | Total Time 10.00(10.00)\n",
      "Iter 0744 | Time 28.7413(27.4158) | Bit/dim 1.2324(1.2496) | Xent 0.0953(0.1051) | Loss 1.2800(1.3021) | Error 0.0316(0.0331) Steps 392(388.04) | Grad Norm 3.6135(3.7785) | Total Time 10.00(10.00)\n",
      "Iter 0745 | Time 27.7211(27.4249) | Bit/dim 1.2242(1.2488) | Xent 0.1233(0.1056) | Loss 1.2858(1.3017) | Error 0.0373(0.0333) Steps 374(387.62) | Grad Norm 1.6655(3.7151) | Total Time 10.00(10.00)\n",
      "Iter 0746 | Time 26.2041(27.3883) | Bit/dim 1.2249(1.2481) | Xent 0.0849(0.1050) | Loss 1.2673(1.3006) | Error 0.0266(0.0331) Steps 374(387.21) | Grad Norm 2.1004(3.6666) | Total Time 10.00(10.00)\n",
      "Iter 0747 | Time 28.1637(27.4116) | Bit/dim 1.2284(1.2475) | Xent 0.0964(0.1048) | Loss 1.2767(1.2999) | Error 0.0272(0.0329) Steps 386(387.17) | Grad Norm 1.9021(3.6137) | Total Time 10.00(10.00)\n",
      "Iter 0748 | Time 26.9899(27.3989) | Bit/dim 1.2180(1.2466) | Xent 0.0966(0.1045) | Loss 1.2663(1.2989) | Error 0.0289(0.0328) Steps 386(387.14) | Grad Norm 1.3375(3.5454) | Total Time 10.00(10.00)\n",
      "Iter 0749 | Time 26.3414(27.3672) | Bit/dim 1.2170(1.2457) | Xent 0.1125(0.1048) | Loss 1.2732(1.2981) | Error 0.0361(0.0329) Steps 386(387.10) | Grad Norm 1.9731(3.4982) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 15.1426, Epoch Time 218.6918(217.1830), Bit/dim 1.2009(best: 1.2167), Xent 0.0520, Loss 1.2269, Error 0.0173(best: 0.0163)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0750 | Time 27.5532(27.3728) | Bit/dim 1.2052(1.2445) | Xent 0.1148(0.1051) | Loss 1.2626(1.2971) | Error 0.0371(0.0330) Steps 386(387.07) | Grad Norm 1.0938(3.4261) | Total Time 10.00(10.00)\n",
      "Iter 0751 | Time 28.2796(27.4000) | Bit/dim 1.2096(1.2435) | Xent 0.0907(0.1046) | Loss 1.2550(1.2958) | Error 0.0301(0.0329) Steps 392(387.22) | Grad Norm 1.3911(3.3651) | Total Time 10.00(10.00)\n",
      "Iter 0752 | Time 27.1477(27.3924) | Bit/dim 1.2178(1.2427) | Xent 0.0984(0.1044) | Loss 1.2670(1.2949) | Error 0.0278(0.0328) Steps 386(387.18) | Grad Norm 1.7692(3.3172) | Total Time 10.00(10.00)\n",
      "Iter 0753 | Time 26.8659(27.3766) | Bit/dim 1.2109(1.2418) | Xent 0.0955(0.1042) | Loss 1.2587(1.2938) | Error 0.0300(0.0327) Steps 386(387.15) | Grad Norm 0.9732(3.2469) | Total Time 10.00(10.00)\n",
      "Iter 0754 | Time 28.2107(27.4016) | Bit/dim 1.2046(1.2406) | Xent 0.0996(0.1040) | Loss 1.2544(1.2927) | Error 0.0301(0.0326) Steps 392(387.29) | Grad Norm 2.0614(3.2113) | Total Time 10.00(10.00)\n",
      "Iter 0755 | Time 27.1956(27.3954) | Bit/dim 1.2074(1.2396) | Xent 0.1086(0.1042) | Loss 1.2617(1.2917) | Error 0.0349(0.0327) Steps 398(387.61) | Grad Norm 2.7556(3.1976) | Total Time 10.00(10.00)\n",
      "Iter 0756 | Time 27.6414(27.4028) | Bit/dim 1.2112(1.2388) | Xent 0.0913(0.1038) | Loss 1.2568(1.2907) | Error 0.0286(0.0325) Steps 392(387.75) | Grad Norm 2.2262(3.1685) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 15.2286, Epoch Time 220.5858(217.2851), Bit/dim 1.2011(best: 1.2009), Xent 0.0449, Loss 1.2236, Error 0.0145(best: 0.0163)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0757 | Time 26.5552(27.3774) | Bit/dim 1.2115(1.2380) | Xent 0.0789(0.1030) | Loss 1.2510(1.2895) | Error 0.0236(0.0323) Steps 386(387.69) | Grad Norm 1.4170(3.1159) | Total Time 10.00(10.00)\n",
      "Iter 0758 | Time 29.5016(27.4411) | Bit/dim 1.2076(1.2371) | Xent 0.0933(0.1027) | Loss 1.2542(1.2884) | Error 0.0309(0.0322) Steps 392(387.82) | Grad Norm 1.3255(3.0622) | Total Time 10.00(10.00)\n",
      "Iter 0759 | Time 27.8142(27.4523) | Bit/dim 1.1938(1.2358) | Xent 0.1014(0.1027) | Loss 1.2445(1.2871) | Error 0.0327(0.0322) Steps 392(387.95) | Grad Norm 0.8749(2.9966) | Total Time 10.00(10.00)\n",
      "Iter 0760 | Time 29.2084(27.5050) | Bit/dim 1.1997(1.2347) | Xent 0.0899(0.1023) | Loss 1.2446(1.2858) | Error 0.0284(0.0321) Steps 392(388.07) | Grad Norm 1.4225(2.9494) | Total Time 10.00(10.00)\n",
      "Iter 0761 | Time 27.6113(27.5082) | Bit/dim 1.1977(1.2336) | Xent 0.0961(0.1021) | Loss 1.2458(1.2846) | Error 0.0308(0.0321) Steps 392(388.19) | Grad Norm 2.5430(2.9372) | Total Time 10.00(10.00)\n",
      "Iter 0762 | Time 27.2206(27.4996) | Bit/dim 1.2171(1.2331) | Xent 0.0914(0.1018) | Loss 1.2629(1.2840) | Error 0.0302(0.0320) Steps 404(388.66) | Grad Norm 4.4298(2.9820) | Total Time 10.00(10.00)\n",
      "Iter 0763 | Time 28.8083(27.5388) | Bit/dim 1.2434(1.2334) | Xent 0.1130(0.1021) | Loss 1.2999(1.2845) | Error 0.0384(0.0322) Steps 398(388.94) | Grad Norm 9.2982(3.1715) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 15.2330, Epoch Time 224.5752(217.5038), Bit/dim 1.4032(best: 1.2009), Xent 0.0609, Loss 1.4337, Error 0.0193(best: 0.0145)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0764 | Time 28.3267(27.5625) | Bit/dim 1.4095(1.2387) | Xent 0.1159(0.1026) | Loss 1.4674(1.2900) | Error 0.0359(0.0323) Steps 404(389.39) | Grad Norm 11.8230(3.4310) | Total Time 10.00(10.00)\n",
      "Iter 0765 | Time 26.4698(27.5297) | Bit/dim 1.2527(1.2391) | Xent 0.0831(0.1020) | Loss 1.2943(1.2901) | Error 0.0259(0.0321) Steps 398(389.65) | Grad Norm 2.9651(3.4170) | Total Time 10.00(10.00)\n",
      "Iter 0766 | Time 27.8951(27.5406) | Bit/dim 1.3432(1.2422) | Xent 0.1676(0.1039) | Loss 1.4270(1.2942) | Error 0.0555(0.0328) Steps 398(389.90) | Grad Norm 11.9739(3.6737) | Total Time 10.00(10.00)\n",
      "Iter 0767 | Time 27.9421(27.5527) | Bit/dim 1.3625(1.2458) | Xent 0.1090(0.1041) | Loss 1.4170(1.2979) | Error 0.0336(0.0329) Steps 398(390.14) | Grad Norm 5.2863(3.7221) | Total Time 10.00(10.00)\n",
      "Iter 0768 | Time 27.9224(27.5638) | Bit/dim 1.4271(1.2513) | Xent 0.0948(0.1038) | Loss 1.4745(1.3032) | Error 0.0289(0.0327) Steps 392(390.20) | Grad Norm 4.9868(3.7600) | Total Time 10.00(10.00)\n",
      "Iter 0769 | Time 26.5658(27.5338) | Bit/dim 1.3393(1.2539) | Xent 0.0926(0.1035) | Loss 1.3856(1.3056) | Error 0.0300(0.0327) Steps 392(390.25) | Grad Norm 3.4314(3.7502) | Total Time 10.00(10.00)\n",
      "Iter 0770 | Time 28.7167(27.5693) | Bit/dim 1.3024(1.2554) | Xent 0.1345(0.1044) | Loss 1.3696(1.3076) | Error 0.0405(0.0329) Steps 404(390.67) | Grad Norm 3.5373(3.7438) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 15.3044, Epoch Time 221.7176(217.6302), Bit/dim 1.3258(best: 1.2009), Xent 0.0600, Loss 1.3558, Error 0.0186(best: 0.0145)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0771 | Time 28.0074(27.5825) | Bit/dim 1.3386(1.2579) | Xent 0.1356(0.1053) | Loss 1.4064(1.3105) | Error 0.0424(0.0332) Steps 398(390.89) | Grad Norm 5.6111(3.7998) | Total Time 10.00(10.00)\n",
      "Iter 0772 | Time 26.7829(27.5585) | Bit/dim 1.2861(1.2587) | Xent 0.0939(0.1050) | Loss 1.3330(1.3112) | Error 0.0315(0.0331) Steps 392(390.92) | Grad Norm 1.9927(3.7456) | Total Time 10.00(10.00)\n",
      "Iter 0773 | Time 28.1500(27.5762) | Bit/dim 1.3307(1.2609) | Xent 0.0811(0.1043) | Loss 1.3713(1.3130) | Error 0.0222(0.0328) Steps 398(391.13) | Grad Norm 3.0759(3.7255) | Total Time 10.00(10.00)\n",
      "Iter 0774 | Time 26.7819(27.5524) | Bit/dim 1.3046(1.2622) | Xent 0.0773(0.1035) | Loss 1.3432(1.3139) | Error 0.0241(0.0325) Steps 386(390.98) | Grad Norm 2.7205(3.6954) | Total Time 10.00(10.00)\n",
      "Iter 0775 | Time 27.0157(27.5363) | Bit/dim 1.2543(1.2619) | Xent 0.1164(0.1039) | Loss 1.3125(1.3139) | Error 0.0371(0.0327) Steps 398(391.19) | Grad Norm 1.3899(3.6262) | Total Time 10.00(10.00)\n",
      "Iter 0776 | Time 29.5635(27.5971) | Bit/dim 1.2892(1.2628) | Xent 0.1399(0.1049) | Loss 1.3591(1.3152) | Error 0.0435(0.0330) Steps 380(390.85) | Grad Norm 5.4223(3.6801) | Total Time 10.00(10.00)\n",
      "Iter 0777 | Time 27.0849(27.5817) | Bit/dim 1.2443(1.2622) | Xent 0.1022(0.1049) | Loss 1.2954(1.3146) | Error 0.0330(0.0330) Steps 398(391.07) | Grad Norm 1.0892(3.6024) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 15.0202, Epoch Time 220.7941(217.7251), Bit/dim 1.2779(best: 1.2009), Xent 0.0474, Loss 1.3016, Error 0.0153(best: 0.0145)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0778 | Time 26.3530(27.5449) | Bit/dim 1.2782(1.2627) | Xent 0.0850(0.1043) | Loss 1.3207(1.3148) | Error 0.0268(0.0328) Steps 392(391.10) | Grad Norm 3.2337(3.5913) | Total Time 10.00(10.00)\n",
      "Iter 0779 | Time 26.2557(27.5062) | Bit/dim 1.2731(1.2630) | Xent 0.0867(0.1037) | Loss 1.3165(1.3149) | Error 0.0254(0.0326) Steps 380(390.76) | Grad Norm 2.5091(3.5588) | Total Time 10.00(10.00)\n",
      "Iter 0780 | Time 26.9305(27.4889) | Bit/dim 1.2444(1.2624) | Xent 0.1138(0.1040) | Loss 1.3014(1.3145) | Error 0.0346(0.0327) Steps 386(390.62) | Grad Norm 2.0170(3.5126) | Total Time 10.00(10.00)\n",
      "Iter 0781 | Time 28.0734(27.5065) | Bit/dim 1.2399(1.2618) | Xent 0.1271(0.1047) | Loss 1.3034(1.3141) | Error 0.0400(0.0329) Steps 392(390.66) | Grad Norm 2.5239(3.4829) | Total Time 10.00(10.00)\n",
      "Iter 0782 | Time 27.3833(27.5028) | Bit/dim 1.2331(1.2609) | Xent 0.1085(0.1048) | Loss 1.2873(1.3133) | Error 0.0343(0.0329) Steps 380(390.34) | Grad Norm 1.1406(3.4126) | Total Time 10.00(10.00)\n",
      "Iter 0783 | Time 28.2713(27.5258) | Bit/dim 1.2400(1.2603) | Xent 0.1093(0.1050) | Loss 1.2947(1.3128) | Error 0.0349(0.0330) Steps 380(390.03) | Grad Norm 2.0220(3.3709) | Total Time 10.00(10.00)\n",
      "Iter 0784 | Time 27.4734(27.5243) | Bit/dim 1.2359(1.2596) | Xent 0.0907(0.1045) | Loss 1.2813(1.3118) | Error 0.0281(0.0328) Steps 398(390.27) | Grad Norm 1.2224(3.3065) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 15.2918, Epoch Time 218.4239(217.7461), Bit/dim 1.2261(best: 1.2009), Xent 0.0579, Loss 1.2550, Error 0.0198(best: 0.0145)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0785 | Time 28.1005(27.5415) | Bit/dim 1.2358(1.2588) | Xent 0.1164(0.1049) | Loss 1.2940(1.3113) | Error 0.0355(0.0329) Steps 404(390.68) | Grad Norm 2.2334(3.2743) | Total Time 10.00(10.00)\n",
      "Iter 0786 | Time 26.9458(27.5237) | Bit/dim 1.2211(1.2577) | Xent 0.0995(0.1047) | Loss 1.2708(1.3101) | Error 0.0311(0.0329) Steps 386(390.54) | Grad Norm 1.3492(3.2165) | Total Time 10.00(10.00)\n",
      "Iter 0787 | Time 27.4663(27.5219) | Bit/dim 1.2331(1.2570) | Xent 0.0947(0.1044) | Loss 1.2804(1.3092) | Error 0.0317(0.0328) Steps 386(390.41) | Grad Norm 1.9187(3.1776) | Total Time 10.00(10.00)\n",
      "Iter 0788 | Time 27.1041(27.5094) | Bit/dim 1.2202(1.2559) | Xent 0.0916(0.1041) | Loss 1.2660(1.3079) | Error 0.0276(0.0327) Steps 386(390.27) | Grad Norm 1.4520(3.1258) | Total Time 10.00(10.00)\n",
      "Iter 0789 | Time 27.9377(27.5223) | Bit/dim 1.2197(1.2548) | Xent 0.1080(0.1042) | Loss 1.2737(1.3069) | Error 0.0340(0.0327) Steps 392(390.33) | Grad Norm 2.3866(3.1037) | Total Time 10.00(10.00)\n",
      "Iter 0790 | Time 28.0270(27.5374) | Bit/dim 1.2142(1.2536) | Xent 0.1023(0.1041) | Loss 1.2653(1.3056) | Error 0.0312(0.0327) Steps 392(390.38) | Grad Norm 0.8231(3.0352) | Total Time 10.00(10.00)\n",
      "Iter 0791 | Time 27.7346(27.5433) | Bit/dim 1.2131(1.2523) | Xent 0.0913(0.1037) | Loss 1.2588(1.3042) | Error 0.0270(0.0325) Steps 392(390.42) | Grad Norm 1.7236(2.9959) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 14.8065, Epoch Time 220.7341(217.8357), Bit/dim 1.2024(best: 1.2009), Xent 0.0464, Loss 1.2256, Error 0.0157(best: 0.0145)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0792 | Time 28.8292(27.5819) | Bit/dim 1.2019(1.2508) | Xent 0.0890(0.1033) | Loss 1.2464(1.3025) | Error 0.0280(0.0324) Steps 386(390.29) | Grad Norm 0.9161(2.9335) | Total Time 10.00(10.00)\n",
      "Iter 0793 | Time 28.0282(27.5953) | Bit/dim 1.2104(1.2496) | Xent 0.0960(0.1031) | Loss 1.2584(1.3012) | Error 0.0300(0.0323) Steps 392(390.34) | Grad Norm 1.1877(2.8811) | Total Time 10.00(10.00)\n",
      "Iter 0794 | Time 28.3388(27.6176) | Bit/dim 1.2115(1.2485) | Xent 0.0951(0.1028) | Loss 1.2590(1.2999) | Error 0.0326(0.0323) Steps 398(390.57) | Grad Norm 1.5988(2.8426) | Total Time 10.00(10.00)\n",
      "Iter 0795 | Time 27.4251(27.6118) | Bit/dim 1.2126(1.2474) | Xent 0.0974(0.1027) | Loss 1.2613(1.2987) | Error 0.0309(0.0323) Steps 392(390.62) | Grad Norm 2.1250(2.8211) | Total Time 10.00(10.00)\n",
      "Iter 0796 | Time 28.3272(27.6333) | Bit/dim 1.2023(1.2460) | Xent 0.0865(0.1022) | Loss 1.2455(1.2971) | Error 0.0265(0.0321) Steps 404(391.02) | Grad Norm 2.5199(2.8121) | Total Time 10.00(10.00)\n",
      "Iter 0797 | Time 27.9454(27.6426) | Bit/dim 1.2027(1.2447) | Xent 0.1079(0.1024) | Loss 1.2567(1.2959) | Error 0.0315(0.0321) Steps 392(391.05) | Grad Norm 2.6656(2.8077) | Total Time 10.00(10.00)\n",
      "Iter 0798 | Time 27.0883(27.6260) | Bit/dim 1.1985(1.2434) | Xent 0.1012(0.1023) | Loss 1.2491(1.2945) | Error 0.0327(0.0321) Steps 398(391.25) | Grad Norm 1.7371(2.7756) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 15.0575, Epoch Time 223.4432(218.0039), Bit/dim 1.1929(best: 1.2009), Xent 0.0496, Loss 1.2177, Error 0.0155(best: 0.0145)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0799 | Time 27.7833(27.6307) | Bit/dim 1.1950(1.2419) | Xent 0.1044(0.1024) | Loss 1.2472(1.2931) | Error 0.0321(0.0321) Steps 392(391.28) | Grad Norm 1.3108(2.7316) | Total Time 10.00(10.00)\n",
      "Iter 0800 | Time 27.6952(27.6327) | Bit/dim 1.1959(1.2405) | Xent 0.0946(0.1021) | Loss 1.2433(1.2916) | Error 0.0291(0.0320) Steps 398(391.48) | Grad Norm 1.3165(2.6892) | Total Time 10.00(10.00)\n",
      "Iter 0801 | Time 27.4911(27.6284) | Bit/dim 1.1920(1.2391) | Xent 0.0923(0.1019) | Loss 1.2382(1.2900) | Error 0.0301(0.0319) Steps 392(391.49) | Grad Norm 1.6755(2.6588) | Total Time 10.00(10.00)\n",
      "Iter 0802 | Time 27.6193(27.6281) | Bit/dim 1.2012(1.2379) | Xent 0.0886(0.1015) | Loss 1.2455(1.2887) | Error 0.0286(0.0318) Steps 404(391.87) | Grad Norm 2.2758(2.6473) | Total Time 10.00(10.00)\n",
      "Iter 0803 | Time 27.7926(27.6331) | Bit/dim 1.2080(1.2370) | Xent 0.0930(0.1012) | Loss 1.2545(1.2876) | Error 0.0298(0.0318) Steps 392(391.87) | Grad Norm 4.1047(2.6910) | Total Time 10.00(10.00)\n",
      "Iter 0804 | Time 29.8475(27.6995) | Bit/dim 1.2416(1.2372) | Xent 0.0912(0.1009) | Loss 1.2872(1.2876) | Error 0.0279(0.0317) Steps 410(392.42) | Grad Norm 6.8817(2.8167) | Total Time 10.00(10.00)\n",
      "Iter 0805 | Time 29.0671(27.7405) | Bit/dim 1.2585(1.2378) | Xent 0.1035(0.1010) | Loss 1.3102(1.2883) | Error 0.0336(0.0317) Steps 398(392.58) | Grad Norm 10.5869(3.0498) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 15.5617, Epoch Time 225.3718(218.2250), Bit/dim 1.3511(best: 1.1929), Xent 0.0623, Loss 1.3822, Error 0.0208(best: 0.0145)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0806 | Time 27.6223(27.7370) | Bit/dim 1.3572(1.2414) | Xent 0.1064(0.1011) | Loss 1.4104(1.2920) | Error 0.0325(0.0317) Steps 404(392.93) | Grad Norm 9.1045(3.2315) | Total Time 10.00(10.00)\n",
      "Iter 0807 | Time 27.2610(27.7227) | Bit/dim 1.2683(1.2422) | Xent 0.0683(0.1002) | Loss 1.3025(1.2923) | Error 0.0218(0.0314) Steps 392(392.90) | Grad Norm 3.2706(3.2326) | Total Time 10.00(10.00)\n",
      "Iter 0808 | Time 28.5410(27.7473) | Bit/dim 1.3174(1.2445) | Xent 0.1484(0.1016) | Loss 1.3916(1.2953) | Error 0.0445(0.0318) Steps 398(393.05) | Grad Norm 10.5079(3.4509) | Total Time 10.00(10.00)\n",
      "Iter 0809 | Time 27.7526(27.7474) | Bit/dim 1.2747(1.2454) | Xent 0.0990(0.1015) | Loss 1.3242(1.2961) | Error 0.0320(0.0318) Steps 392(393.02) | Grad Norm 3.8069(3.4616) | Total Time 10.00(10.00)\n",
      "Iter 0810 | Time 27.9812(27.7544) | Bit/dim 1.3011(1.2470) | Xent 0.0916(0.1012) | Loss 1.3469(1.2977) | Error 0.0306(0.0318) Steps 398(393.17) | Grad Norm 4.2007(3.4838) | Total Time 10.00(10.00)\n",
      "Iter 0811 | Time 26.1114(27.7051) | Bit/dim 1.2640(1.2476) | Xent 0.0771(0.1005) | Loss 1.3026(1.2978) | Error 0.0254(0.0316) Steps 392(393.14) | Grad Norm 2.2833(3.4477) | Total Time 10.00(10.00)\n",
      "Iter 0812 | Time 29.5926(27.7618) | Bit/dim 1.2705(1.2482) | Xent 0.1156(0.1010) | Loss 1.3283(1.2987) | Error 0.0351(0.0317) Steps 404(393.46) | Grad Norm 5.5753(3.5116) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 15.6216, Epoch Time 222.8935(218.3650), Bit/dim 1.2299(best: 1.1929), Xent 0.0492, Loss 1.2545, Error 0.0155(best: 0.0145)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0813 | Time 28.8878(27.7955) | Bit/dim 1.2355(1.2479) | Xent 0.1136(0.1013) | Loss 1.2924(1.2985) | Error 0.0346(0.0318) Steps 404(393.78) | Grad Norm 1.9268(3.4640) | Total Time 10.00(10.00)\n",
      "Iter 0814 | Time 26.5534(27.7583) | Bit/dim 1.2477(1.2479) | Xent 0.0805(0.1007) | Loss 1.2880(1.2982) | Error 0.0258(0.0316) Steps 398(393.90) | Grad Norm 3.0456(3.4515) | Total Time 10.00(10.00)\n",
      "Iter 0815 | Time 26.9763(27.7348) | Bit/dim 1.2451(1.2478) | Xent 0.0865(0.1003) | Loss 1.2884(1.2979) | Error 0.0268(0.0315) Steps 398(394.03) | Grad Norm 2.1648(3.4129) | Total Time 10.00(10.00)\n",
      "Iter 0816 | Time 28.6294(27.7617) | Bit/dim 1.2339(1.2474) | Xent 0.0885(0.0999) | Loss 1.2782(1.2973) | Error 0.0281(0.0314) Steps 404(394.33) | Grad Norm 2.4823(3.3850) | Total Time 10.00(10.00)\n",
      "Iter 0817 | Time 28.9598(27.7976) | Bit/dim 1.2241(1.2467) | Xent 0.1209(0.1006) | Loss 1.2845(1.2969) | Error 0.0384(0.0316) Steps 392(394.26) | Grad Norm 2.6484(3.3629) | Total Time 10.00(10.00)\n",
      "Iter 0818 | Time 27.1334(27.7777) | Bit/dim 1.2311(1.2462) | Xent 0.0875(0.1002) | Loss 1.2748(1.2963) | Error 0.0289(0.0315) Steps 380(393.83) | Grad Norm 2.0902(3.3247) | Total Time 10.00(10.00)\n",
      "Iter 0819 | Time 26.8150(27.7488) | Bit/dim 1.2293(1.2457) | Xent 0.0921(0.0999) | Loss 1.2754(1.2957) | Error 0.0276(0.0314) Steps 398(393.95) | Grad Norm 1.8272(3.2798) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 15.3140, Epoch Time 221.8240(218.4688), Bit/dim 1.2121(best: 1.1929), Xent 0.0443, Loss 1.2343, Error 0.0144(best: 0.0145)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0820 | Time 28.1489(27.7608) | Bit/dim 1.2116(1.2447) | Xent 0.0823(0.0994) | Loss 1.2528(1.2944) | Error 0.0251(0.0312) Steps 398(394.08) | Grad Norm 1.5139(3.2268) | Total Time 10.00(10.00)\n",
      "Iter 0821 | Time 27.8974(27.7649) | Bit/dim 1.2179(1.2439) | Xent 0.1101(0.0997) | Loss 1.2730(1.2937) | Error 0.0335(0.0313) Steps 386(393.83) | Grad Norm 2.0380(3.1911) | Total Time 10.00(10.00)\n",
      "Iter 0822 | Time 28.3509(27.7825) | Bit/dim 1.2049(1.2427) | Xent 0.1061(0.0999) | Loss 1.2579(1.2926) | Error 0.0326(0.0313) Steps 392(393.78) | Grad Norm 1.1329(3.1294) | Total Time 10.00(10.00)\n",
      "Iter 0823 | Time 27.3961(27.7709) | Bit/dim 1.2150(1.2419) | Xent 0.0945(0.0998) | Loss 1.2623(1.2917) | Error 0.0284(0.0312) Steps 398(393.90) | Grad Norm 1.9473(3.0939) | Total Time 10.00(10.00)\n",
      "Iter 0824 | Time 27.9955(27.7776) | Bit/dim 1.2175(1.2411) | Xent 0.0762(0.0990) | Loss 1.2556(1.2907) | Error 0.0236(0.0310) Steps 398(394.03) | Grad Norm 1.8654(3.0570) | Total Time 10.00(10.00)\n",
      "Iter 0825 | Time 27.9852(27.7838) | Bit/dim 1.2063(1.2401) | Xent 0.0947(0.0989) | Loss 1.2536(1.2895) | Error 0.0301(0.0310) Steps 392(393.97) | Grad Norm 1.0050(2.9955) | Total Time 10.00(10.00)\n",
      "Iter 0826 | Time 29.7116(27.8417) | Bit/dim 1.2013(1.2389) | Xent 0.1033(0.0990) | Loss 1.2529(1.2884) | Error 0.0339(0.0311) Steps 398(394.09) | Grad Norm 1.9753(2.9649) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 15.1955, Epoch Time 224.8891(218.6614), Bit/dim 1.2033(best: 1.1929), Xent 0.0408, Loss 1.2237, Error 0.0136(best: 0.0144)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0827 | Time 28.3466(27.8568) | Bit/dim 1.2089(1.2380) | Xent 0.0800(0.0985) | Loss 1.2489(1.2873) | Error 0.0261(0.0309) Steps 392(394.03) | Grad Norm 2.6618(2.9558) | Total Time 10.00(10.00)\n",
      "Iter 0828 | Time 28.7310(27.8831) | Bit/dim 1.2042(1.2370) | Xent 0.0971(0.0984) | Loss 1.2527(1.2862) | Error 0.0312(0.0309) Steps 398(394.14) | Grad Norm 3.0358(2.9582) | Total Time 10.00(10.00)\n",
      "Iter 0829 | Time 29.3095(27.9258) | Bit/dim 1.2015(1.2359) | Xent 0.0826(0.0980) | Loss 1.2428(1.2849) | Error 0.0241(0.0307) Steps 398(394.26) | Grad Norm 1.9224(2.9271) | Total Time 10.00(10.00)\n",
      "Iter 0830 | Time 28.7216(27.9497) | Bit/dim 1.1983(1.2348) | Xent 0.0887(0.0977) | Loss 1.2426(1.2836) | Error 0.0264(0.0306) Steps 392(394.19) | Grad Norm 1.0737(2.8715) | Total Time 10.00(10.00)\n",
      "Iter 0831 | Time 27.5093(27.9365) | Bit/dim 1.1950(1.2336) | Xent 0.1023(0.0978) | Loss 1.2462(1.2825) | Error 0.0343(0.0307) Steps 392(394.13) | Grad Norm 2.8051(2.8695) | Total Time 10.00(10.00)\n",
      "Iter 0832 | Time 27.4179(27.9209) | Bit/dim 1.2134(1.2330) | Xent 0.0841(0.0974) | Loss 1.2555(1.2817) | Error 0.0250(0.0305) Steps 404(394.42) | Grad Norm 4.3871(2.9150) | Total Time 10.00(10.00)\n",
      "Iter 0833 | Time 28.2908(27.9320) | Bit/dim 1.2104(1.2323) | Xent 0.1026(0.0976) | Loss 1.2617(1.2811) | Error 0.0319(0.0306) Steps 392(394.35) | Grad Norm 6.1816(3.0130) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 15.5137, Epoch Time 226.6392(218.9007), Bit/dim 1.2444(best: 1.1929), Xent 0.0448, Loss 1.2668, Error 0.0141(best: 0.0136)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0834 | Time 27.8598(27.9299) | Bit/dim 1.2526(1.2329) | Xent 0.0867(0.0972) | Loss 1.2960(1.2816) | Error 0.0251(0.0304) Steps 404(394.64) | Grad Norm 6.3446(3.1130) | Total Time 10.00(10.00)\n",
      "Iter 0835 | Time 28.0664(27.9340) | Bit/dim 1.1957(1.2318) | Xent 0.0849(0.0969) | Loss 1.2382(1.2803) | Error 0.0246(0.0302) Steps 398(394.74) | Grad Norm 2.4252(3.0924) | Total Time 10.00(10.00)\n",
      "Iter 0836 | Time 29.5021(27.9810) | Bit/dim 1.1945(1.2307) | Xent 0.0971(0.0969) | Loss 1.2431(1.2791) | Error 0.0315(0.0303) Steps 398(394.84) | Grad Norm 4.2920(3.1283) | Total Time 10.00(10.00)\n",
      "Iter 0837 | Time 28.2547(27.9892) | Bit/dim 1.2565(1.2315) | Xent 0.0819(0.0964) | Loss 1.2975(1.2797) | Error 0.0241(0.0301) Steps 398(394.93) | Grad Norm 6.5834(3.2320) | Total Time 10.00(10.00)\n",
      "Iter 0838 | Time 28.1698(27.9946) | Bit/dim 1.2086(1.2308) | Xent 0.0870(0.0961) | Loss 1.2521(1.2789) | Error 0.0276(0.0300) Steps 404(395.20) | Grad Norm 2.1791(3.2004) | Total Time 10.00(10.00)\n",
      "Iter 0839 | Time 28.1637(27.9997) | Bit/dim 1.2222(1.2305) | Xent 0.0986(0.0962) | Loss 1.2715(1.2786) | Error 0.0319(0.0301) Steps 392(395.11) | Grad Norm 6.8555(3.3101) | Total Time 10.00(10.00)\n",
      "Iter 0840 | Time 28.8532(28.0253) | Bit/dim 1.3091(1.2329) | Xent 0.0968(0.0962) | Loss 1.3575(1.2810) | Error 0.0292(0.0300) Steps 404(395.38) | Grad Norm 7.6895(3.4414) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 15.2329, Epoch Time 226.8117(219.1381), Bit/dim 1.2313(best: 1.1929), Xent 0.0416, Loss 1.2521, Error 0.0127(best: 0.0136)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0841 | Time 27.5940(28.0124) | Bit/dim 1.2397(1.2331) | Xent 0.0673(0.0954) | Loss 1.2734(1.2808) | Error 0.0220(0.0298) Steps 398(395.45) | Grad Norm 3.2408(3.4354) | Total Time 10.00(10.00)\n",
      "Iter 0842 | Time 28.4043(28.0241) | Bit/dim 1.3002(1.2351) | Xent 0.1166(0.0960) | Loss 1.3585(1.2831) | Error 0.0356(0.0300) Steps 398(395.53) | Grad Norm 10.2188(3.6389) | Total Time 10.00(10.00)\n",
      "Iter 0843 | Time 28.9394(28.0516) | Bit/dim 1.2518(1.2356) | Xent 0.0917(0.0959) | Loss 1.2977(1.2835) | Error 0.0290(0.0299) Steps 410(395.96) | Grad Norm 4.1976(3.6557) | Total Time 10.00(10.00)\n",
      "Iter 0844 | Time 27.7445(28.0424) | Bit/dim 1.2887(1.2372) | Xent 0.0877(0.0956) | Loss 1.3325(1.2850) | Error 0.0271(0.0299) Steps 404(396.21) | Grad Norm 4.6320(3.6850) | Total Time 10.00(10.00)\n",
      "Iter 0845 | Time 26.7257(28.0029) | Bit/dim 1.2234(1.2368) | Xent 0.0874(0.0954) | Loss 1.2671(1.2845) | Error 0.0269(0.0298) Steps 392(396.08) | Grad Norm 1.5829(3.6219) | Total Time 10.00(10.00)\n",
      "Iter 0846 | Time 28.9538(28.0314) | Bit/dim 1.2852(1.2382) | Xent 0.1120(0.0959) | Loss 1.3412(1.2862) | Error 0.0349(0.0299) Steps 398(396.14) | Grad Norm 7.6649(3.7432) | Total Time 10.00(10.00)\n",
      "Iter 0847 | Time 26.6172(27.9890) | Bit/dim 1.2352(1.2382) | Xent 0.1071(0.0962) | Loss 1.2888(1.2863) | Error 0.0345(0.0301) Steps 392(396.01) | Grad Norm 3.3547(3.7315) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 15.5606, Epoch Time 222.9856(219.2535), Bit/dim 1.2528(best: 1.1929), Xent 0.0405, Loss 1.2730, Error 0.0134(best: 0.0127)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0848 | Time 28.0389(27.9905) | Bit/dim 1.2562(1.2387) | Xent 0.0745(0.0956) | Loss 1.2935(1.2865) | Error 0.0245(0.0299) Steps 404(396.25) | Grad Norm 3.6259(3.7284) | Total Time 10.00(10.00)\n",
      "Iter 0849 | Time 28.3831(28.0023) | Bit/dim 1.2350(1.2386) | Xent 0.0958(0.0956) | Loss 1.2829(1.2864) | Error 0.0302(0.0299) Steps 410(396.67) | Grad Norm 1.6827(3.6670) | Total Time 10.00(10.00)\n",
      "Iter 0850 | Time 28.5495(28.0187) | Bit/dim 1.2288(1.2383) | Xent 0.0917(0.0955) | Loss 1.2746(1.2860) | Error 0.0304(0.0299) Steps 410(397.07) | Grad Norm 4.4378(3.6901) | Total Time 10.00(10.00)\n",
      "Iter 0851 | Time 27.1725(27.9933) | Bit/dim 1.2263(1.2379) | Xent 0.0975(0.0955) | Loss 1.2750(1.2857) | Error 0.0296(0.0299) Steps 404(397.27) | Grad Norm 1.6265(3.6282) | Total Time 10.00(10.00)\n",
      "Iter 0852 | Time 27.7380(27.9856) | Bit/dim 1.2314(1.2377) | Xent 0.0781(0.0950) | Loss 1.2704(1.2852) | Error 0.0254(0.0298) Steps 392(397.11) | Grad Norm 2.9566(3.6081) | Total Time 10.00(10.00)\n",
      "Iter 0853 | Time 26.6602(27.9459) | Bit/dim 1.2129(1.2370) | Xent 0.0776(0.0945) | Loss 1.2517(1.2842) | Error 0.0249(0.0296) Steps 386(396.78) | Grad Norm 1.3779(3.5412) | Total Time 10.00(10.00)\n",
      "Iter 0854 | Time 27.9869(27.9471) | Bit/dim 1.2176(1.2364) | Xent 0.1125(0.0950) | Loss 1.2738(1.2839) | Error 0.0359(0.0298) Steps 386(396.46) | Grad Norm 3.4072(3.5371) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 16.2299, Epoch Time 222.9749(219.3651), Bit/dim 1.1966(best: 1.1929), Xent 0.0486, Loss 1.2209, Error 0.0153(best: 0.0127)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0855 | Time 27.8376(27.9438) | Bit/dim 1.2041(1.2354) | Xent 0.0941(0.0950) | Loss 1.2512(1.2829) | Error 0.0294(0.0298) Steps 404(396.68) | Grad Norm 1.1335(3.4650) | Total Time 10.00(10.00)\n",
      "Iter 0856 | Time 26.2425(27.8928) | Bit/dim 1.2166(1.2349) | Xent 0.0750(0.0944) | Loss 1.2541(1.2821) | Error 0.0241(0.0296) Steps 392(396.54) | Grad Norm 2.1338(3.4251) | Total Time 10.00(10.00)\n",
      "Iter 0857 | Time 28.0892(27.8987) | Bit/dim 1.2075(1.2340) | Xent 0.0829(0.0940) | Loss 1.2490(1.2811) | Error 0.0251(0.0295) Steps 392(396.41) | Grad Norm 1.5217(3.3680) | Total Time 10.00(10.00)\n",
      "Iter 0858 | Time 28.2562(27.9094) | Bit/dim 1.1975(1.2330) | Xent 0.0878(0.0939) | Loss 1.2414(1.2799) | Error 0.0278(0.0294) Steps 398(396.46) | Grad Norm 2.0171(3.3275) | Total Time 10.00(10.00)\n",
      "Iter 0859 | Time 29.3899(27.9538) | Bit/dim 1.1978(1.2319) | Xent 0.0886(0.0937) | Loss 1.2421(1.2788) | Error 0.0274(0.0294) Steps 410(396.86) | Grad Norm 1.9131(3.2850) | Total Time 10.00(10.00)\n",
      "Iter 0860 | Time 27.8909(27.9519) | Bit/dim 1.1985(1.2309) | Xent 0.0812(0.0933) | Loss 1.2390(1.2776) | Error 0.0251(0.0293) Steps 398(396.90) | Grad Norm 1.0051(3.2166) | Total Time 10.00(10.00)\n",
      "Iter 0861 | Time 28.3696(27.9645) | Bit/dim 1.1988(1.2299) | Xent 0.0846(0.0931) | Loss 1.2411(1.2765) | Error 0.0268(0.0292) Steps 398(396.93) | Grad Norm 2.1702(3.1852) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 15.9783, Epoch Time 224.3746(219.5154), Bit/dim 1.1905(best: 1.1929), Xent 0.0433, Loss 1.2122, Error 0.0150(best: 0.0127)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0862 | Time 27.3286(27.9454) | Bit/dim 1.1949(1.2289) | Xent 0.0897(0.0930) | Loss 1.2397(1.2754) | Error 0.0269(0.0291) Steps 398(396.96) | Grad Norm 1.7111(3.1410) | Total Time 10.00(10.00)\n",
      "Iter 0863 | Time 26.9685(27.9161) | Bit/dim 1.1830(1.2275) | Xent 0.0772(0.0925) | Loss 1.2216(1.2738) | Error 0.0260(0.0290) Steps 392(396.81) | Grad Norm 0.8014(3.0708) | Total Time 10.00(10.00)\n",
      "Iter 0864 | Time 28.0663(27.9206) | Bit/dim 1.1965(1.2266) | Xent 0.0899(0.0924) | Loss 1.2414(1.2728) | Error 0.0279(0.0290) Steps 398(396.85) | Grad Norm 2.1597(3.0435) | Total Time 10.00(10.00)\n",
      "Iter 0865 | Time 29.5606(27.9698) | Bit/dim 1.1965(1.2257) | Xent 0.0798(0.0920) | Loss 1.2364(1.2717) | Error 0.0250(0.0289) Steps 404(397.06) | Grad Norm 2.4676(3.0262) | Total Time 10.00(10.00)\n",
      "Iter 0866 | Time 29.1472(28.0051) | Bit/dim 1.1934(1.2247) | Xent 0.0843(0.0918) | Loss 1.2356(1.2706) | Error 0.0266(0.0288) Steps 416(397.63) | Grad Norm 1.3225(2.9751) | Total Time 10.00(10.00)\n",
      "Iter 0867 | Time 30.2126(28.0713) | Bit/dim 1.1880(1.2236) | Xent 0.0753(0.0913) | Loss 1.2256(1.2693) | Error 0.0234(0.0286) Steps 404(397.82) | Grad Norm 1.1022(2.9189) | Total Time 10.00(10.00)\n",
      "Iter 0868 | Time 27.7653(28.0621) | Bit/dim 1.1901(1.2226) | Xent 0.0825(0.0910) | Loss 1.2313(1.2681) | Error 0.0261(0.0286) Steps 404(398.01) | Grad Norm 2.0154(2.8918) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 15.4500, Epoch Time 226.9682(219.7390), Bit/dim 1.1788(best: 1.1905), Xent 0.0415, Loss 1.1995, Error 0.0144(best: 0.0127)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0869 | Time 28.1222(28.0639) | Bit/dim 1.1831(1.2214) | Xent 0.0851(0.0909) | Loss 1.2256(1.2668) | Error 0.0280(0.0285) Steps 398(398.01) | Grad Norm 2.7176(2.8866) | Total Time 10.00(10.00)\n",
      "Iter 0870 | Time 27.8204(28.0566) | Bit/dim 1.2001(1.2208) | Xent 0.0767(0.0904) | Loss 1.2384(1.2660) | Error 0.0232(0.0284) Steps 410(398.37) | Grad Norm 3.6414(2.9092) | Total Time 10.00(10.00)\n",
      "Iter 0871 | Time 28.1834(28.0604) | Bit/dim 1.1990(1.2201) | Xent 0.0844(0.0903) | Loss 1.2412(1.2652) | Error 0.0272(0.0283) Steps 404(398.54) | Grad Norm 4.8361(2.9670) | Total Time 10.00(10.00)\n",
      "Iter 0872 | Time 27.2285(28.0355) | Bit/dim 1.2209(1.2201) | Xent 0.0790(0.0899) | Loss 1.2604(1.2651) | Error 0.0250(0.0282) Steps 392(398.34) | Grad Norm 5.3220(3.0377) | Total Time 10.00(10.00)\n",
      "Iter 0873 | Time 28.8990(28.0614) | Bit/dim 1.1981(1.2195) | Xent 0.0941(0.0900) | Loss 1.2451(1.2645) | Error 0.0294(0.0283) Steps 398(398.33) | Grad Norm 5.2784(3.1049) | Total Time 10.00(10.00)\n",
      "Iter 0874 | Time 28.2109(28.0659) | Bit/dim 1.2071(1.2191) | Xent 0.0840(0.0899) | Loss 1.2491(1.2640) | Error 0.0278(0.0283) Steps 410(398.68) | Grad Norm 4.6723(3.1519) | Total Time 10.00(10.00)\n",
      "Iter 0875 | Time 28.5317(28.0799) | Bit/dim 1.1878(1.2182) | Xent 0.0789(0.0895) | Loss 1.2273(1.2629) | Error 0.0241(0.0281) Steps 404(398.84) | Grad Norm 3.0339(3.1484) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 15.8483, Epoch Time 225.2276(219.9037), Bit/dim 1.1779(best: 1.1788), Xent 0.0387, Loss 1.1973, Error 0.0125(best: 0.0127)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0876 | Time 29.4441(28.1208) | Bit/dim 1.1810(1.2171) | Xent 0.0730(0.0890) | Loss 1.2175(1.2616) | Error 0.0235(0.0280) Steps 404(398.99) | Grad Norm 0.9307(3.0819) | Total Time 10.00(10.00)\n",
      "Iter 0877 | Time 28.5310(28.1331) | Bit/dim 1.1786(1.2159) | Xent 0.0739(0.0886) | Loss 1.2155(1.2602) | Error 0.0226(0.0278) Steps 410(399.32) | Grad Norm 1.6739(3.0396) | Total Time 10.00(10.00)\n",
      "Iter 0878 | Time 28.5777(28.1464) | Bit/dim 1.1876(1.2151) | Xent 0.0924(0.0887) | Loss 1.2338(1.2594) | Error 0.0312(0.0279) Steps 398(399.28) | Grad Norm 4.2866(3.0770) | Total Time 10.00(10.00)\n",
      "Iter 0879 | Time 27.0971(28.1149) | Bit/dim 1.2382(1.2157) | Xent 0.0676(0.0881) | Loss 1.2720(1.2598) | Error 0.0234(0.0278) Steps 392(399.07) | Grad Norm 6.4093(3.1770) | Total Time 10.00(10.00)\n",
      "Iter 0880 | Time 27.8600(28.1073) | Bit/dim 1.2060(1.2155) | Xent 0.0790(0.0878) | Loss 1.2455(1.2594) | Error 0.0249(0.0277) Steps 398(399.03) | Grad Norm 6.2137(3.2681) | Total Time 10.00(10.00)\n",
      "Iter 0881 | Time 27.5711(28.0912) | Bit/dim 1.2038(1.2151) | Xent 0.0853(0.0877) | Loss 1.2464(1.2590) | Error 0.0265(0.0277) Steps 398(399.00) | Grad Norm 4.1997(3.2960) | Total Time 10.00(10.00)\n",
      "Iter 0882 | Time 28.9196(28.1161) | Bit/dim 1.1843(1.2142) | Xent 0.0796(0.0875) | Loss 1.2241(1.2579) | Error 0.0242(0.0276) Steps 416(399.51) | Grad Norm 0.9719(3.2263) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 15.9438, Epoch Time 226.6979(220.1075), Bit/dim 1.1839(best: 1.1779), Xent 0.0408, Loss 1.2044, Error 0.0132(best: 0.0125)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0883 | Time 28.4715(28.1267) | Bit/dim 1.1898(1.2134) | Xent 0.0896(0.0875) | Loss 1.2345(1.2572) | Error 0.0285(0.0276) Steps 404(399.65) | Grad Norm 3.8723(3.2457) | Total Time 10.00(10.00)\n",
      "Iter 0884 | Time 27.0743(28.0952) | Bit/dim 1.2426(1.2143) | Xent 0.0767(0.0872) | Loss 1.2809(1.2579) | Error 0.0232(0.0275) Steps 398(399.60) | Grad Norm 6.1566(3.3330) | Total Time 10.00(10.00)\n",
      "Iter 0885 | Time 29.6623(28.1422) | Bit/dim 1.1868(1.2135) | Xent 0.0761(0.0869) | Loss 1.2249(1.2569) | Error 0.0248(0.0274) Steps 404(399.73) | Grad Norm 3.5122(3.3384) | Total Time 10.00(10.00)\n",
      "Iter 0886 | Time 30.1820(28.2034) | Bit/dim 1.1757(1.2124) | Xent 0.0737(0.0865) | Loss 1.2125(1.2556) | Error 0.0249(0.0273) Steps 410(400.04) | Grad Norm 1.3425(3.2785) | Total Time 10.00(10.00)\n",
      "Iter 0887 | Time 30.4489(28.2707) | Bit/dim 1.2003(1.2120) | Xent 0.0776(0.0862) | Loss 1.2391(1.2551) | Error 0.0252(0.0273) Steps 410(400.34) | Grad Norm 3.7818(3.2936) | Total Time 10.00(10.00)\n",
      "Iter 0888 | Time 29.1934(28.2984) | Bit/dim 1.1874(1.2113) | Xent 0.0743(0.0859) | Loss 1.2246(1.2542) | Error 0.0230(0.0271) Steps 410(400.63) | Grad Norm 3.3504(3.2953) | Total Time 10.00(10.00)\n",
      "Iter 0889 | Time 28.5141(28.3049) | Bit/dim 1.1796(1.2103) | Xent 0.0819(0.0857) | Loss 1.2206(1.2532) | Error 0.0246(0.0271) Steps 404(400.73) | Grad Norm 1.7494(3.2489) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 15.7119, Epoch Time 231.7695(220.4574), Bit/dim 1.1724(best: 1.1779), Xent 0.0440, Loss 1.1944, Error 0.0141(best: 0.0125)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0890 | Time 29.8596(28.3515) | Bit/dim 1.1799(1.2094) | Xent 0.0812(0.0856) | Loss 1.2205(1.2522) | Error 0.0254(0.0270) Steps 410(401.01) | Grad Norm 1.1230(3.1852) | Total Time 10.00(10.00)\n",
      "Iter 0891 | Time 29.8771(28.3973) | Bit/dim 1.1813(1.2086) | Xent 0.0725(0.0852) | Loss 1.2176(1.2512) | Error 0.0231(0.0269) Steps 410(401.28) | Grad Norm 2.0247(3.1504) | Total Time 10.00(10.00)\n",
      "Iter 0892 | Time 28.8989(28.4123) | Bit/dim 1.1885(1.2080) | Xent 0.0822(0.0851) | Loss 1.2296(1.2505) | Error 0.0256(0.0268) Steps 410(401.54) | Grad Norm 3.2960(3.1547) | Total Time 10.00(10.00)\n",
      "Iter 0893 | Time 30.4220(28.4726) | Bit/dim 1.1904(1.2074) | Xent 0.0992(0.0855) | Loss 1.2400(1.2502) | Error 0.0312(0.0270) Steps 404(401.61) | Grad Norm 5.3728(3.2213) | Total Time 10.00(10.00)\n",
      "Iter 0894 | Time 26.7447(28.4208) | Bit/dim 1.2477(1.2086) | Xent 0.0606(0.0848) | Loss 1.2781(1.2510) | Error 0.0184(0.0267) Steps 392(401.32) | Grad Norm 6.3412(3.3149) | Total Time 10.00(10.00)\n",
      "Iter 0895 | Time 29.3796(28.4495) | Bit/dim 1.1854(1.2079) | Xent 0.0709(0.0844) | Loss 1.2208(1.2501) | Error 0.0224(0.0266) Steps 416(401.76) | Grad Norm 2.4187(3.2880) | Total Time 10.00(10.00)\n",
      "Iter 0896 | Time 29.7793(28.4894) | Bit/dim 1.1939(1.2075) | Xent 0.0987(0.0848) | Loss 1.2432(1.2499) | Error 0.0305(0.0267) Steps 398(401.65) | Grad Norm 5.3024(3.3484) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 15.2302, Epoch Time 233.3189(220.8432), Bit/dim 1.2703(best: 1.1724), Xent 0.0436, Loss 1.2921, Error 0.0136(best: 0.0125)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0897 | Time 28.5326(28.4907) | Bit/dim 1.2780(1.2096) | Xent 0.0751(0.0845) | Loss 1.3155(1.2519) | Error 0.0249(0.0267) Steps 398(401.54) | Grad Norm 6.7998(3.4520) | Total Time 10.00(10.00)\n",
      "Iter 0898 | Time 27.9771(28.4753) | Bit/dim 1.2105(1.2097) | Xent 0.0577(0.0837) | Loss 1.2394(1.2515) | Error 0.0185(0.0264) Steps 410(401.79) | Grad Norm 2.5457(3.4248) | Total Time 10.00(10.00)\n",
      "Iter 0899 | Time 29.0153(28.4915) | Bit/dim 1.3041(1.2125) | Xent 0.1486(0.0857) | Loss 1.3784(1.2553) | Error 0.0469(0.0270) Steps 392(401.50) | Grad Norm 13.1732(3.7172) | Total Time 10.00(10.00)\n",
      "Iter 0900 | Time 27.8450(28.4721) | Bit/dim 1.4158(1.2186) | Xent 0.0795(0.0855) | Loss 1.4556(1.2613) | Error 0.0248(0.0270) Steps 404(401.58) | Grad Norm 7.1906(3.8214) | Total Time 10.00(10.00)\n",
      "Iter 0901 | Time 27.3472(28.4384) | Bit/dim 1.4739(1.2263) | Xent 0.0752(0.0852) | Loss 1.5115(1.2688) | Error 0.0210(0.0268) Steps 392(401.29) | Grad Norm 4.1138(3.8302) | Total Time 10.00(10.00)\n",
      "Iter 0902 | Time 27.3166(28.4047) | Bit/dim 1.4075(1.2317) | Xent 0.0591(0.0844) | Loss 1.4370(1.2739) | Error 0.0180(0.0265) Steps 392(401.01) | Grad Norm 3.0171(3.8058) | Total Time 10.00(10.00)\n",
      "Iter 0903 | Time 28.1793(28.3980) | Bit/dim 1.3186(1.2343) | Xent 0.0821(0.0843) | Loss 1.3596(1.2765) | Error 0.0251(0.0265) Steps 404(401.10) | Grad Norm 1.8595(3.7474) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 16.1874, Epoch Time 224.9217(220.9656), Bit/dim 1.3406(best: 1.1724), Xent 0.0552, Loss 1.3682, Error 0.0180(best: 0.0125)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0904 | Time 29.3756(28.4273) | Bit/dim 1.3418(1.2375) | Xent 0.1348(0.0858) | Loss 1.4092(1.2804) | Error 0.0420(0.0269) Steps 410(401.37) | Grad Norm 3.9458(3.7534) | Total Time 10.00(10.00)\n",
      "Iter 0905 | Time 28.1634(28.4194) | Bit/dim 1.3335(1.2404) | Xent 0.1081(0.0865) | Loss 1.3875(1.2836) | Error 0.0333(0.0271) Steps 416(401.81) | Grad Norm 4.3836(3.7723) | Total Time 10.00(10.00)\n",
      "Iter 0906 | Time 28.7328(28.4288) | Bit/dim 1.2915(1.2419) | Xent 0.0800(0.0863) | Loss 1.3315(1.2851) | Error 0.0248(0.0271) Steps 398(401.69) | Grad Norm 2.0231(3.7198) | Total Time 10.00(10.00)\n",
      "Iter 0907 | Time 28.1909(28.4216) | Bit/dim 1.3130(1.2441) | Xent 0.0670(0.0857) | Loss 1.3465(1.2869) | Error 0.0216(0.0269) Steps 410(401.94) | Grad Norm 2.9813(3.6976) | Total Time 10.00(10.00)\n",
      "Iter 0908 | Time 28.5440(28.4253) | Bit/dim 1.2852(1.2453) | Xent 0.0858(0.0857) | Loss 1.3281(1.2882) | Error 0.0258(0.0269) Steps 410(402.18) | Grad Norm 3.0030(3.6768) | Total Time 10.00(10.00)\n",
      "Iter 0909 | Time 27.4816(28.3970) | Bit/dim 1.2627(1.2458) | Xent 0.1060(0.0863) | Loss 1.3157(1.2890) | Error 0.0306(0.0270) Steps 398(402.06) | Grad Norm 2.2573(3.6342) | Total Time 10.00(10.00)\n",
      "Iter 0910 | Time 28.4210(28.3977) | Bit/dim 1.2625(1.2463) | Xent 0.0951(0.0866) | Loss 1.3100(1.2896) | Error 0.0302(0.0271) Steps 398(401.94) | Grad Norm 3.7833(3.6387) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 15.6168, Epoch Time 226.7307(221.1385), Bit/dim 1.2363(best: 1.1724), Xent 0.0437, Loss 1.2581, Error 0.0145(best: 0.0125)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0911 | Time 28.5084(28.4010) | Bit/dim 1.2416(1.2462) | Xent 0.0853(0.0866) | Loss 1.2842(1.2895) | Error 0.0246(0.0270) Steps 398(401.82) | Grad Norm 1.6908(3.5802) | Total Time 10.00(10.00)\n",
      "Iter 0912 | Time 27.8113(28.3834) | Bit/dim 1.2665(1.2468) | Xent 0.0802(0.0864) | Loss 1.3067(1.2900) | Error 0.0241(0.0269) Steps 386(401.34) | Grad Norm 2.3611(3.5437) | Total Time 10.00(10.00)\n",
      "Iter 0913 | Time 28.0998(28.3748) | Bit/dim 1.2580(1.2471) | Xent 0.0656(0.0857) | Loss 1.2909(1.2900) | Error 0.0189(0.0267) Steps 386(400.88) | Grad Norm 2.1013(3.5004) | Total Time 10.00(10.00)\n",
      "Iter 0914 | Time 29.2569(28.4013) | Bit/dim 1.2287(1.2466) | Xent 0.0831(0.0857) | Loss 1.2702(1.2894) | Error 0.0278(0.0267) Steps 380(400.26) | Grad Norm 1.1535(3.4300) | Total Time 10.00(10.00)\n",
      "Iter 0915 | Time 28.3089(28.3985) | Bit/dim 1.2265(1.2460) | Xent 0.0981(0.0860) | Loss 1.2755(1.2890) | Error 0.0317(0.0269) Steps 398(400.19) | Grad Norm 2.4644(3.4010) | Total Time 10.00(10.00)\n",
      "Iter 0916 | Time 28.2496(28.3941) | Bit/dim 1.2251(1.2453) | Xent 0.0757(0.0857) | Loss 1.2629(1.2882) | Error 0.0240(0.0268) Steps 404(400.30) | Grad Norm 1.2760(3.3373) | Total Time 10.00(10.00)\n",
      "Iter 0917 | Time 27.8956(28.3791) | Bit/dim 1.2317(1.2449) | Xent 0.0719(0.0853) | Loss 1.2677(1.2876) | Error 0.0218(0.0266) Steps 404(400.41) | Grad Norm 1.4690(3.2812) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 14.6400, Epoch Time 225.2652(221.2623), Bit/dim 1.2217(best: 1.1724), Xent 0.0398, Loss 1.2416, Error 0.0122(best: 0.0125)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0918 | Time 28.6308(28.3867) | Bit/dim 1.2246(1.2443) | Xent 0.0752(0.0850) | Loss 1.2622(1.2868) | Error 0.0219(0.0265) Steps 404(400.52) | Grad Norm 1.4906(3.2275) | Total Time 10.00(10.00)\n",
      "Iter 0919 | Time 28.1555(28.3797) | Bit/dim 1.2124(1.2434) | Xent 0.0949(0.0853) | Loss 1.2598(1.2860) | Error 0.0279(0.0265) Steps 398(400.45) | Grad Norm 1.4335(3.1737) | Total Time 10.00(10.00)\n",
      "Iter 0920 | Time 27.9319(28.3663) | Bit/dim 1.2072(1.2423) | Xent 0.0968(0.0857) | Loss 1.2556(1.2851) | Error 0.0320(0.0267) Steps 404(400.55) | Grad Norm 1.2658(3.1165) | Total Time 10.00(10.00)\n",
      "Iter 0921 | Time 28.0704(28.3574) | Bit/dim 1.2085(1.2413) | Xent 0.0713(0.0852) | Loss 1.2441(1.2839) | Error 0.0226(0.0266) Steps 398(400.48) | Grad Norm 0.7356(3.0450) | Total Time 10.00(10.00)\n",
      "Iter 0922 | Time 29.4773(28.3910) | Bit/dim 1.2167(1.2405) | Xent 0.0775(0.0850) | Loss 1.2555(1.2830) | Error 0.0221(0.0264) Steps 386(400.04) | Grad Norm 1.0398(2.9849) | Total Time 10.00(10.00)\n",
      "Iter 0923 | Time 28.4649(28.3932) | Bit/dim 1.2019(1.2394) | Xent 0.0703(0.0845) | Loss 1.2371(1.2816) | Error 0.0224(0.0263) Steps 398(399.98) | Grad Norm 0.9298(2.9232) | Total Time 10.00(10.00)\n",
      "Iter 0924 | Time 29.5377(28.4276) | Bit/dim 1.1980(1.2381) | Xent 0.0857(0.0846) | Loss 1.2408(1.2804) | Error 0.0256(0.0263) Steps 404(400.10) | Grad Norm 1.1187(2.8691) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 15.7395, Epoch Time 228.3261(221.4742), Bit/dim 1.1887(best: 1.1724), Xent 0.0387, Loss 1.2080, Error 0.0126(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0925 | Time 29.2027(28.4508) | Bit/dim 1.1952(1.2368) | Xent 0.0837(0.0846) | Loss 1.2370(1.2791) | Error 0.0245(0.0262) Steps 398(400.04) | Grad Norm 1.1809(2.8184) | Total Time 10.00(10.00)\n",
      "Iter 0926 | Time 29.7615(28.4901) | Bit/dim 1.1997(1.2357) | Xent 0.0747(0.0843) | Loss 1.2371(1.2779) | Error 0.0234(0.0261) Steps 398(399.98) | Grad Norm 2.1131(2.7973) | Total Time 10.00(10.00)\n",
      "Iter 0927 | Time 28.3413(28.4857) | Bit/dim 1.1974(1.2346) | Xent 0.0725(0.0839) | Loss 1.2336(1.2765) | Error 0.0226(0.0260) Steps 416(400.46) | Grad Norm 1.1358(2.7474) | Total Time 10.00(10.00)\n",
      "Iter 0928 | Time 29.7674(28.5241) | Bit/dim 1.1844(1.2331) | Xent 0.0677(0.0834) | Loss 1.2182(1.2748) | Error 0.0211(0.0259) Steps 410(400.74) | Grad Norm 1.1774(2.7003) | Total Time 10.00(10.00)\n",
      "Iter 0929 | Time 28.6494(28.5279) | Bit/dim 1.1898(1.2318) | Xent 0.0790(0.0833) | Loss 1.2292(1.2734) | Error 0.0235(0.0258) Steps 416(401.20) | Grad Norm 1.9315(2.6773) | Total Time 10.00(10.00)\n",
      "Iter 0930 | Time 30.3990(28.5840) | Bit/dim 1.1944(1.2306) | Xent 0.0719(0.0829) | Loss 1.2303(1.2721) | Error 0.0221(0.0257) Steps 404(401.29) | Grad Norm 2.9426(2.6852) | Total Time 10.00(10.00)\n",
      "Iter 0931 | Time 28.4830(28.5810) | Bit/dim 1.2083(1.2300) | Xent 0.0712(0.0826) | Loss 1.2438(1.2713) | Error 0.0220(0.0256) Steps 404(401.37) | Grad Norm 4.0121(2.7250) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 15.1703, Epoch Time 232.4146(221.8024), Bit/dim 1.1863(best: 1.1724), Xent 0.0408, Loss 1.2067, Error 0.0128(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0932 | Time 29.9812(28.6230) | Bit/dim 1.1949(1.2289) | Xent 0.0706(0.0822) | Loss 1.2302(1.2700) | Error 0.0229(0.0255) Steps 404(401.45) | Grad Norm 4.0385(2.7644) | Total Time 10.00(10.00)\n",
      "Iter 0933 | Time 28.9252(28.6321) | Bit/dim 1.1903(1.2278) | Xent 0.0783(0.0821) | Loss 1.2294(1.2688) | Error 0.0250(0.0255) Steps 416(401.88) | Grad Norm 3.8087(2.7958) | Total Time 10.00(10.00)\n",
      "Iter 0934 | Time 30.5572(28.6898) | Bit/dim 1.1904(1.2266) | Xent 0.0786(0.0820) | Loss 1.2297(1.2676) | Error 0.0245(0.0255) Steps 410(402.13) | Grad Norm 3.6715(2.8220) | Total Time 10.00(10.00)\n",
      "Iter 0935 | Time 29.5617(28.7160) | Bit/dim 1.1959(1.2257) | Xent 0.0717(0.0817) | Loss 1.2317(1.2666) | Error 0.0212(0.0253) Steps 416(402.54) | Grad Norm 3.1385(2.8315) | Total Time 10.00(10.00)\n",
      "Iter 0936 | Time 30.3650(28.7654) | Bit/dim 1.1821(1.2244) | Xent 0.0747(0.0815) | Loss 1.2194(1.2652) | Error 0.0228(0.0253) Steps 410(402.77) | Grad Norm 2.0454(2.8080) | Total Time 10.00(10.00)\n",
      "Iter 0937 | Time 30.4509(28.8160) | Bit/dim 1.1798(1.2231) | Xent 0.0718(0.0812) | Loss 1.2157(1.2637) | Error 0.0242(0.0252) Steps 416(403.16) | Grad Norm 1.1438(2.7580) | Total Time 10.00(10.00)\n",
      "Iter 0938 | Time 29.3927(28.8333) | Bit/dim 1.1797(1.2218) | Xent 0.0700(0.0809) | Loss 1.2147(1.2622) | Error 0.0218(0.0251) Steps 416(403.55) | Grad Norm 0.6094(2.6936) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 15.8231, Epoch Time 237.2858(222.2669), Bit/dim 1.1693(best: 1.1724), Xent 0.0382, Loss 1.1884, Error 0.0122(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0939 | Time 29.5954(28.8562) | Bit/dim 1.1805(1.2205) | Xent 0.0788(0.0808) | Loss 1.2199(1.2609) | Error 0.0254(0.0251) Steps 422(404.10) | Grad Norm 0.9236(2.6405) | Total Time 10.00(10.00)\n",
      "Iter 0940 | Time 28.7586(28.8532) | Bit/dim 1.1760(1.2192) | Xent 0.0624(0.0803) | Loss 1.2072(1.2593) | Error 0.0201(0.0250) Steps 416(404.46) | Grad Norm 1.8038(2.6154) | Total Time 10.00(10.00)\n",
      "Iter 0941 | Time 29.3771(28.8690) | Bit/dim 1.1873(1.2182) | Xent 0.0821(0.0803) | Loss 1.2284(1.2584) | Error 0.0262(0.0250) Steps 410(404.62) | Grad Norm 4.0867(2.6595) | Total Time 10.00(10.00)\n",
      "Iter 0942 | Time 28.2303(28.8498) | Bit/dim 1.2307(1.2186) | Xent 0.0796(0.0803) | Loss 1.2705(1.2588) | Error 0.0264(0.0251) Steps 404(404.61) | Grad Norm 7.4679(2.8038) | Total Time 10.00(10.00)\n",
      "Iter 0943 | Time 28.6471(28.8437) | Bit/dim 1.2717(1.2202) | Xent 0.1125(0.0813) | Loss 1.3280(1.2608) | Error 0.0360(0.0254) Steps 398(404.41) | Grad Norm 13.4927(3.1244) | Total Time 10.00(10.00)\n",
      "Iter 0944 | Time 27.6965(28.8093) | Bit/dim 1.4689(1.2277) | Xent 0.1069(0.0820) | Loss 1.5223(1.2687) | Error 0.0327(0.0256) Steps 404(404.40) | Grad Norm 9.2690(3.3088) | Total Time 10.00(10.00)\n",
      "Iter 0945 | Time 29.4232(28.8277) | Bit/dim 1.3916(1.2326) | Xent 0.0666(0.0816) | Loss 1.4249(1.2734) | Error 0.0210(0.0255) Steps 410(404.56) | Grad Norm 4.5417(3.3458) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 15.5792, Epoch Time 229.5286(222.4848), Bit/dim 1.2887(best: 1.1693), Xent 0.0460, Loss 1.3117, Error 0.0141(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0946 | Time 27.2756(28.7812) | Bit/dim 1.2895(1.2343) | Xent 0.0791(0.0815) | Loss 1.3291(1.2750) | Error 0.0245(0.0254) Steps 398(404.37) | Grad Norm 2.1010(3.3084) | Total Time 10.00(10.00)\n",
      "Iter 0947 | Time 29.4583(28.8015) | Bit/dim 1.3620(1.2381) | Xent 0.2268(0.0858) | Loss 1.4754(1.2811) | Error 0.0733(0.0269) Steps 404(404.36) | Grad Norm 8.9184(3.4767) | Total Time 10.00(10.00)\n",
      "Iter 0948 | Time 29.9714(28.8366) | Bit/dim 1.2993(1.2400) | Xent 0.1513(0.0878) | Loss 1.3750(1.2839) | Error 0.0444(0.0274) Steps 410(404.53) | Grad Norm 3.0146(3.4628) | Total Time 10.00(10.00)\n",
      "Iter 0949 | Time 28.2070(28.8177) | Bit/dim 1.3445(1.2431) | Xent 0.1211(0.0888) | Loss 1.4050(1.2875) | Error 0.0376(0.0277) Steps 416(404.87) | Grad Norm 3.5199(3.4646) | Total Time 10.00(10.00)\n",
      "Iter 0950 | Time 29.9745(28.8524) | Bit/dim 1.3323(1.2458) | Xent 0.0970(0.0891) | Loss 1.3808(1.2903) | Error 0.0331(0.0279) Steps 416(405.20) | Grad Norm 3.0411(3.4519) | Total Time 10.00(10.00)\n",
      "Iter 0951 | Time 27.6485(28.8163) | Bit/dim 1.2812(1.2468) | Xent 0.1251(0.0901) | Loss 1.3437(1.2919) | Error 0.0421(0.0283) Steps 404(405.17) | Grad Norm 2.3094(3.4176) | Total Time 10.00(10.00)\n",
      "Iter 0952 | Time 29.2449(28.8291) | Bit/dim 1.2957(1.2483) | Xent 0.1345(0.0915) | Loss 1.3629(1.2940) | Error 0.0397(0.0286) Steps 416(405.49) | Grad Norm 3.6903(3.4258) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 15.9168, Epoch Time 230.0991(222.7132), Bit/dim 1.2641(best: 1.1693), Xent 0.0514, Loss 1.2898, Error 0.0161(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0953 | Time 28.2587(28.8120) | Bit/dim 1.2699(1.2490) | Xent 0.1172(0.0922) | Loss 1.3285(1.2951) | Error 0.0354(0.0288) Steps 404(405.45) | Grad Norm 3.5963(3.4309) | Total Time 10.00(10.00)\n",
      "Iter 0954 | Time 28.3131(28.7970) | Bit/dim 1.2632(1.2494) | Xent 0.0907(0.0922) | Loss 1.3086(1.2955) | Error 0.0288(0.0288) Steps 398(405.22) | Grad Norm 2.1226(3.3916) | Total Time 10.00(10.00)\n",
      "Iter 0955 | Time 27.5484(28.7596) | Bit/dim 1.2709(1.2500) | Xent 0.1039(0.0925) | Loss 1.3229(1.2963) | Error 0.0326(0.0290) Steps 392(404.83) | Grad Norm 3.2693(3.3880) | Total Time 10.00(10.00)\n",
      "Iter 0956 | Time 26.8774(28.7031) | Bit/dim 1.2479(1.2500) | Xent 0.0929(0.0926) | Loss 1.2943(1.2962) | Error 0.0302(0.0290) Steps 380(404.08) | Grad Norm 1.6749(3.3366) | Total Time 10.00(10.00)\n",
      "Iter 0957 | Time 28.8265(28.7068) | Bit/dim 1.2634(1.2504) | Xent 0.0944(0.0926) | Loss 1.3106(1.2967) | Error 0.0304(0.0290) Steps 404(404.08) | Grad Norm 3.9138(3.3539) | Total Time 10.00(10.00)\n",
      "Iter 0958 | Time 30.2589(28.7534) | Bit/dim 1.2340(1.2499) | Xent 0.0835(0.0923) | Loss 1.2758(1.2960) | Error 0.0268(0.0290) Steps 416(404.44) | Grad Norm 1.5405(3.2995) | Total Time 10.00(10.00)\n",
      "Iter 0959 | Time 29.3025(28.7699) | Bit/dim 1.2430(1.2497) | Xent 0.0942(0.0924) | Loss 1.2901(1.2959) | Error 0.0309(0.0290) Steps 404(404.42) | Grad Norm 2.4851(3.2751) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 14.8232, Epoch Time 226.5305(222.8277), Bit/dim 1.2194(best: 1.1693), Xent 0.0460, Loss 1.2425, Error 0.0145(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0960 | Time 27.7921(28.7405) | Bit/dim 1.2239(1.2489) | Xent 0.0953(0.0925) | Loss 1.2716(1.2951) | Error 0.0302(0.0291) Steps 392(404.05) | Grad Norm 1.6635(3.2267) | Total Time 10.00(10.00)\n",
      "Iter 0961 | Time 28.6968(28.7392) | Bit/dim 1.2194(1.2480) | Xent 0.1128(0.0931) | Loss 1.2758(1.2946) | Error 0.0373(0.0293) Steps 404(404.05) | Grad Norm 2.7798(3.2133) | Total Time 10.00(10.00)\n",
      "Iter 0962 | Time 28.0088(28.7173) | Bit/dim 1.2200(1.2472) | Xent 0.0960(0.0932) | Loss 1.2680(1.2938) | Error 0.0323(0.0294) Steps 398(403.87) | Grad Norm 1.1129(3.1503) | Total Time 10.00(10.00)\n",
      "Iter 0963 | Time 27.8464(28.6912) | Bit/dim 1.2247(1.2465) | Xent 0.0976(0.0933) | Loss 1.2735(1.2932) | Error 0.0301(0.0294) Steps 398(403.69) | Grad Norm 1.9337(3.1138) | Total Time 10.00(10.00)\n",
      "Iter 0964 | Time 28.2410(28.6777) | Bit/dim 1.2160(1.2456) | Xent 0.0887(0.0932) | Loss 1.2603(1.2922) | Error 0.0290(0.0294) Steps 404(403.70) | Grad Norm 0.9155(3.0478) | Total Time 10.00(10.00)\n",
      "Iter 0965 | Time 27.6668(28.6473) | Bit/dim 1.2017(1.2443) | Xent 0.1017(0.0934) | Loss 1.2525(1.2910) | Error 0.0320(0.0295) Steps 398(403.53) | Grad Norm 1.7039(3.0075) | Total Time 10.00(10.00)\n",
      "Iter 0966 | Time 27.5561(28.6146) | Bit/dim 1.2059(1.2431) | Xent 0.0931(0.0934) | Loss 1.2525(1.2898) | Error 0.0284(0.0295) Steps 392(403.18) | Grad Norm 1.4565(2.9610) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 15.4926, Epoch Time 223.7928(222.8567), Bit/dim 1.1973(best: 1.1693), Xent 0.0416, Loss 1.2181, Error 0.0124(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0967 | Time 28.2271(28.6030) | Bit/dim 1.2006(1.2418) | Xent 0.0875(0.0932) | Loss 1.2444(1.2885) | Error 0.0262(0.0294) Steps 404(403.21) | Grad Norm 0.9537(2.9008) | Total Time 10.00(10.00)\n",
      "Iter 0968 | Time 28.2688(28.5930) | Bit/dim 1.2028(1.2407) | Xent 0.0794(0.0928) | Loss 1.2425(1.2871) | Error 0.0249(0.0292) Steps 404(403.23) | Grad Norm 1.5984(2.8617) | Total Time 10.00(10.00)\n",
      "Iter 0969 | Time 28.4192(28.5877) | Bit/dim 1.1984(1.2394) | Xent 0.0829(0.0925) | Loss 1.2399(1.2857) | Error 0.0264(0.0291) Steps 404(403.26) | Grad Norm 0.7646(2.7988) | Total Time 10.00(10.00)\n",
      "Iter 0970 | Time 28.2848(28.5787) | Bit/dim 1.2001(1.2382) | Xent 0.0870(0.0924) | Loss 1.2436(1.2844) | Error 0.0249(0.0290) Steps 404(403.28) | Grad Norm 1.6232(2.7635) | Total Time 10.00(10.00)\n",
      "Iter 0971 | Time 29.2515(28.5988) | Bit/dim 1.1910(1.2368) | Xent 0.0831(0.0921) | Loss 1.2325(1.2828) | Error 0.0270(0.0289) Steps 410(403.48) | Grad Norm 1.5385(2.7268) | Total Time 10.00(10.00)\n",
      "Iter 0972 | Time 29.4898(28.6256) | Bit/dim 1.1902(1.2354) | Xent 0.0799(0.0917) | Loss 1.2302(1.2813) | Error 0.0254(0.0288) Steps 404(403.50) | Grad Norm 1.0122(2.6753) | Total Time 10.00(10.00)\n",
      "Iter 0973 | Time 28.0057(28.6070) | Bit/dim 1.1913(1.2341) | Xent 0.0831(0.0915) | Loss 1.2329(1.2798) | Error 0.0241(0.0287) Steps 404(403.51) | Grad Norm 0.7913(2.6188) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 15.7838, Epoch Time 228.1893(223.0167), Bit/dim 1.1802(best: 1.1693), Xent 0.0454, Loss 1.2029, Error 0.0140(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0974 | Time 28.6620(28.6086) | Bit/dim 1.1900(1.2328) | Xent 0.0792(0.0911) | Loss 1.2296(1.2783) | Error 0.0258(0.0286) Steps 404(403.53) | Grad Norm 1.8130(2.5946) | Total Time 10.00(10.00)\n",
      "Iter 0975 | Time 30.6499(28.6699) | Bit/dim 1.1908(1.2315) | Xent 0.0761(0.0906) | Loss 1.2288(1.2768) | Error 0.0250(0.0285) Steps 416(403.90) | Grad Norm 2.1099(2.5801) | Total Time 10.00(10.00)\n",
      "Iter 0976 | Time 29.5511(28.6963) | Bit/dim 1.1833(1.2301) | Xent 0.0832(0.0904) | Loss 1.2248(1.2753) | Error 0.0252(0.0284) Steps 410(404.08) | Grad Norm 2.0812(2.5651) | Total Time 10.00(10.00)\n",
      "Iter 0977 | Time 30.3354(28.7455) | Bit/dim 1.1760(1.2284) | Xent 0.0679(0.0897) | Loss 1.2100(1.2733) | Error 0.0234(0.0283) Steps 416(404.44) | Grad Norm 1.9348(2.5462) | Total Time 10.00(10.00)\n",
      "Iter 0978 | Time 30.3927(28.7949) | Bit/dim 1.1809(1.2270) | Xent 0.0868(0.0897) | Loss 1.2243(1.2718) | Error 0.0271(0.0282) Steps 410(404.61) | Grad Norm 1.4881(2.5145) | Total Time 10.00(10.00)\n",
      "Iter 0979 | Time 30.7972(28.8550) | Bit/dim 1.1834(1.2257) | Xent 0.0741(0.0892) | Loss 1.2204(1.2703) | Error 0.0244(0.0281) Steps 416(404.95) | Grad Norm 1.0546(2.4707) | Total Time 10.00(10.00)\n",
      "Iter 0980 | Time 28.9948(28.8592) | Bit/dim 1.1714(1.2241) | Xent 0.0719(0.0887) | Loss 1.2073(1.2684) | Error 0.0224(0.0279) Steps 410(405.10) | Grad Norm 0.7982(2.4205) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 15.9560, Epoch Time 237.9700(223.4653), Bit/dim 1.1664(best: 1.1693), Xent 0.0409, Loss 1.1869, Error 0.0137(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0981 | Time 29.5664(28.8804) | Bit/dim 1.1752(1.2226) | Xent 0.0740(0.0882) | Loss 1.2122(1.2667) | Error 0.0242(0.0278) Steps 410(405.25) | Grad Norm 0.7760(2.3712) | Total Time 10.00(10.00)\n",
      "Iter 0982 | Time 28.4401(28.8672) | Bit/dim 1.1728(1.2211) | Xent 0.0766(0.0879) | Loss 1.2111(1.2650) | Error 0.0238(0.0277) Steps 404(405.21) | Grad Norm 0.6977(2.3210) | Total Time 10.00(10.00)\n",
      "Iter 0983 | Time 28.8450(28.8665) | Bit/dim 1.1691(1.2196) | Xent 0.0725(0.0874) | Loss 1.2054(1.2633) | Error 0.0230(0.0276) Steps 416(405.53) | Grad Norm 1.0096(2.2816) | Total Time 10.00(10.00)\n",
      "Iter 0984 | Time 28.2859(28.8491) | Bit/dim 1.1767(1.2183) | Xent 0.0880(0.0874) | Loss 1.2207(1.2620) | Error 0.0281(0.0276) Steps 404(405.49) | Grad Norm 2.5795(2.2906) | Total Time 10.00(10.00)\n",
      "Iter 0985 | Time 28.6377(28.8427) | Bit/dim 1.1953(1.2176) | Xent 0.0725(0.0870) | Loss 1.2316(1.2611) | Error 0.0204(0.0274) Steps 416(405.80) | Grad Norm 5.3991(2.3838) | Total Time 10.00(10.00)\n",
      "Iter 0986 | Time 28.0438(28.8188) | Bit/dim 1.2707(1.2192) | Xent 0.1200(0.0880) | Loss 1.3307(1.2632) | Error 0.0376(0.0277) Steps 392(405.39) | Grad Norm 13.4267(2.7151) | Total Time 10.00(10.00)\n",
      "Iter 0987 | Time 28.6428(28.8135) | Bit/dim 1.5532(1.2292) | Xent 0.0866(0.0879) | Loss 1.5965(1.2732) | Error 0.0294(0.0277) Steps 410(405.53) | Grad Norm 9.7439(2.9260) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 15.4595, Epoch Time 228.4047(223.6135), Bit/dim 1.4550(best: 1.1664), Xent 0.0399, Loss 1.4749, Error 0.0130(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0988 | Time 28.1514(28.7936) | Bit/dim 1.4581(1.2361) | Xent 0.0659(0.0873) | Loss 1.4910(1.2797) | Error 0.0194(0.0275) Steps 410(405.66) | Grad Norm 4.5158(2.9737) | Total Time 10.00(10.00)\n",
      "Iter 0989 | Time 28.1295(28.7737) | Bit/dim 1.3664(1.2400) | Xent 0.0652(0.0866) | Loss 1.3990(1.2833) | Error 0.0196(0.0272) Steps 404(405.61) | Grad Norm 3.1622(2.9793) | Total Time 10.00(10.00)\n",
      "Iter 0990 | Time 28.9446(28.7788) | Bit/dim 1.3481(1.2432) | Xent 0.1242(0.0877) | Loss 1.4102(1.2871) | Error 0.0416(0.0277) Steps 404(405.56) | Grad Norm 4.9767(3.0392) | Total Time 10.00(10.00)\n",
      "Iter 0991 | Time 28.2319(28.7624) | Bit/dim 1.3426(1.2462) | Xent 0.1675(0.0901) | Loss 1.4263(1.2913) | Error 0.0530(0.0284) Steps 404(405.52) | Grad Norm 5.6449(3.1174) | Total Time 10.00(10.00)\n",
      "Iter 0992 | Time 29.8865(28.7961) | Bit/dim 1.2974(1.2477) | Xent 0.0926(0.0902) | Loss 1.3437(1.2928) | Error 0.0304(0.0285) Steps 410(405.65) | Grad Norm 1.9095(3.0812) | Total Time 10.00(10.00)\n",
      "Iter 0993 | Time 28.1884(28.7779) | Bit/dim 1.3530(1.2509) | Xent 0.0770(0.0898) | Loss 1.3916(1.2958) | Error 0.0234(0.0283) Steps 416(405.96) | Grad Norm 3.1116(3.0821) | Total Time 10.00(10.00)\n",
      "Iter 0994 | Time 29.1279(28.7884) | Bit/dim 1.3165(1.2529) | Xent 0.0942(0.0899) | Loss 1.3636(1.2978) | Error 0.0290(0.0284) Steps 410(406.08) | Grad Norm 2.8256(3.0744) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 16.3845, Epoch Time 229.4114(223.7874), Bit/dim 1.2750(best: 1.1664), Xent 0.0514, Loss 1.3008, Error 0.0161(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 0995 | Time 29.2488(28.8022) | Bit/dim 1.2789(1.2536) | Xent 0.0983(0.0902) | Loss 1.3280(1.2987) | Error 0.0310(0.0284) Steps 416(406.38) | Grad Norm 1.9984(3.0421) | Total Time 10.00(10.00)\n",
      "Iter 0996 | Time 29.8395(28.8333) | Bit/dim 1.2842(1.2546) | Xent 0.1166(0.0910) | Loss 1.3426(1.3000) | Error 0.0354(0.0286) Steps 410(406.49) | Grad Norm 3.7351(3.0629) | Total Time 10.00(10.00)\n",
      "Iter 0997 | Time 27.2773(28.7867) | Bit/dim 1.2417(1.2542) | Xent 0.0857(0.0908) | Loss 1.2846(1.2996) | Error 0.0255(0.0285) Steps 404(406.41) | Grad Norm 1.7749(3.0243) | Total Time 10.00(10.00)\n",
      "Iter 0998 | Time 27.1020(28.7361) | Bit/dim 1.2554(1.2542) | Xent 0.0829(0.0906) | Loss 1.2969(1.2995) | Error 0.0261(0.0285) Steps 392(405.98) | Grad Norm 2.2968(3.0024) | Total Time 10.00(10.00)\n",
      "Iter 0999 | Time 26.7404(28.6762) | Bit/dim 1.2619(1.2544) | Xent 0.0868(0.0905) | Loss 1.3053(1.2997) | Error 0.0250(0.0284) Steps 392(405.56) | Grad Norm 2.0855(2.9749) | Total Time 10.00(10.00)\n",
      "Iter 1000 | Time 27.7625(28.6488) | Bit/dim 1.2519(1.2544) | Xent 0.0902(0.0905) | Loss 1.2970(1.2996) | Error 0.0275(0.0283) Steps 386(404.98) | Grad Norm 1.6530(2.9353) | Total Time 10.00(10.00)\n",
      "Iter 1001 | Time 28.3451(28.6397) | Bit/dim 1.2432(1.2540) | Xent 0.1043(0.0909) | Loss 1.2954(1.2995) | Error 0.0325(0.0285) Steps 398(404.77) | Grad Norm 2.4035(2.9193) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 15.7197, Epoch Time 224.4109(223.8061), Bit/dim 1.2222(best: 1.1664), Xent 0.0487, Loss 1.2465, Error 0.0160(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1002 | Time 28.2866(28.6291) | Bit/dim 1.2318(1.2534) | Xent 0.0922(0.0909) | Loss 1.2779(1.2988) | Error 0.0268(0.0284) Steps 398(404.56) | Grad Norm 1.6601(2.8815) | Total Time 10.00(10.00)\n",
      "Iter 1003 | Time 27.0407(28.5815) | Bit/dim 1.2264(1.2526) | Xent 0.0845(0.0907) | Loss 1.2687(1.2979) | Error 0.0260(0.0283) Steps 392(404.19) | Grad Norm 1.7648(2.8480) | Total Time 10.00(10.00)\n",
      "Iter 1004 | Time 28.9967(28.5939) | Bit/dim 1.2180(1.2515) | Xent 0.0866(0.0906) | Loss 1.2614(1.2968) | Error 0.0278(0.0283) Steps 404(404.18) | Grad Norm 1.6999(2.8136) | Total Time 10.00(10.00)\n",
      "Iter 1005 | Time 28.9855(28.6057) | Bit/dim 1.2188(1.2505) | Xent 0.0995(0.0909) | Loss 1.2685(1.2960) | Error 0.0314(0.0284) Steps 404(404.18) | Grad Norm 1.6698(2.7793) | Total Time 10.00(10.00)\n",
      "Iter 1006 | Time 28.4070(28.5997) | Bit/dim 1.2158(1.2495) | Xent 0.0934(0.0910) | Loss 1.2625(1.2950) | Error 0.0298(0.0285) Steps 404(404.17) | Grad Norm 1.9590(2.7547) | Total Time 10.00(10.00)\n",
      "Iter 1007 | Time 29.2829(28.6202) | Bit/dim 1.2126(1.2484) | Xent 0.0916(0.0910) | Loss 1.2585(1.2939) | Error 0.0274(0.0284) Steps 404(404.16) | Grad Norm 1.1279(2.7059) | Total Time 10.00(10.00)\n",
      "Iter 1008 | Time 29.1987(28.6376) | Bit/dim 1.2083(1.2472) | Xent 0.0803(0.0906) | Loss 1.2485(1.2925) | Error 0.0232(0.0283) Steps 410(404.34) | Grad Norm 2.1348(2.6887) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 15.3258, Epoch Time 227.9867(223.9315), Bit/dim 1.1946(best: 1.1664), Xent 0.0373, Loss 1.2132, Error 0.0120(best: 0.0122)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1009 | Time 28.2862(28.6270) | Bit/dim 1.2006(1.2458) | Xent 0.0883(0.0906) | Loss 1.2447(1.2911) | Error 0.0266(0.0282) Steps 404(404.33) | Grad Norm 0.9724(2.6372) | Total Time 10.00(10.00)\n",
      "Iter 1010 | Time 29.3967(28.6501) | Bit/dim 1.2032(1.2445) | Xent 0.0821(0.0903) | Loss 1.2442(1.2897) | Error 0.0264(0.0282) Steps 392(403.96) | Grad Norm 1.7495(2.6106) | Total Time 10.00(10.00)\n",
      "Iter 1011 | Time 29.0456(28.6620) | Bit/dim 1.1976(1.2431) | Xent 0.0857(0.0902) | Loss 1.2404(1.2882) | Error 0.0271(0.0281) Steps 410(404.14) | Grad Norm 1.9666(2.5913) | Total Time 10.00(10.00)\n",
      "Iter 1012 | Time 29.4209(28.6847) | Bit/dim 1.1969(1.2417) | Xent 0.0672(0.0895) | Loss 1.2305(1.2865) | Error 0.0220(0.0279) Steps 416(404.50) | Grad Norm 0.6610(2.5334) | Total Time 10.00(10.00)\n",
      "Iter 1013 | Time 28.9597(28.6930) | Bit/dim 1.1994(1.2404) | Xent 0.0817(0.0893) | Loss 1.2403(1.2851) | Error 0.0245(0.0278) Steps 416(404.84) | Grad Norm 1.5925(2.5052) | Total Time 10.00(10.00)\n",
      "Iter 1014 | Time 29.2381(28.7093) | Bit/dim 1.1923(1.2390) | Xent 0.0781(0.0889) | Loss 1.2314(1.2835) | Error 0.0244(0.0277) Steps 410(405.00) | Grad Norm 1.3517(2.4706) | Total Time 10.00(10.00)\n",
      "Iter 1015 | Time 28.4739(28.7023) | Bit/dim 1.1854(1.2374) | Xent 0.0708(0.0884) | Loss 1.2207(1.2816) | Error 0.0214(0.0276) Steps 404(404.97) | Grad Norm 0.8066(2.4206) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 15.9557, Epoch Time 230.9983(224.1435), Bit/dim 1.1780(best: 1.1664), Xent 0.0381, Loss 1.1970, Error 0.0124(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1016 | Time 28.8241(28.7059) | Bit/dim 1.1814(1.2357) | Xent 0.0811(0.0882) | Loss 1.2220(1.2798) | Error 0.0244(0.0275) Steps 410(405.12) | Grad Norm 0.9363(2.3761) | Total Time 10.00(10.00)\n",
      "Iter 1017 | Time 29.1091(28.7180) | Bit/dim 1.1843(1.2342) | Xent 0.0762(0.0878) | Loss 1.2224(1.2781) | Error 0.0260(0.0274) Steps 410(405.26) | Grad Norm 1.9444(2.3632) | Total Time 10.00(10.00)\n",
      "Iter 1018 | Time 28.7402(28.7187) | Bit/dim 1.1912(1.2329) | Xent 0.0806(0.0876) | Loss 1.2315(1.2767) | Error 0.0242(0.0273) Steps 416(405.59) | Grad Norm 2.6037(2.3704) | Total Time 10.00(10.00)\n",
      "Iter 1019 | Time 29.3067(28.7363) | Bit/dim 1.1835(1.2314) | Xent 0.0814(0.0874) | Loss 1.2242(1.2751) | Error 0.0260(0.0273) Steps 410(405.72) | Grad Norm 3.0865(2.3919) | Total Time 10.00(10.00)\n",
      "Iter 1020 | Time 29.9649(28.7732) | Bit/dim 1.1915(1.2302) | Xent 0.0673(0.0868) | Loss 1.2252(1.2736) | Error 0.0216(0.0271) Steps 416(406.03) | Grad Norm 3.2243(2.4168) | Total Time 10.00(10.00)\n",
      "Iter 1021 | Time 31.0266(28.8408) | Bit/dim 1.1857(1.2289) | Xent 0.0768(0.0865) | Loss 1.2241(1.2721) | Error 0.0251(0.0270) Steps 410(406.15) | Grad Norm 3.0382(2.4355) | Total Time 10.00(10.00)\n",
      "Iter 1022 | Time 30.2641(28.8835) | Bit/dim 1.1905(1.2277) | Xent 0.0683(0.0860) | Loss 1.2247(1.2707) | Error 0.0221(0.0269) Steps 416(406.44) | Grad Norm 2.7665(2.4454) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 15.5030, Epoch Time 235.0185(224.4698), Bit/dim 1.1707(best: 1.1664), Xent 0.0413, Loss 1.1914, Error 0.0133(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1023 | Time 29.3243(28.8967) | Bit/dim 1.1770(1.2262) | Xent 0.0783(0.0857) | Loss 1.2162(1.2691) | Error 0.0235(0.0268) Steps 410(406.55) | Grad Norm 2.5907(2.4498) | Total Time 10.00(10.00)\n",
      "Iter 1024 | Time 28.2516(28.8774) | Bit/dim 1.1754(1.2247) | Xent 0.0730(0.0853) | Loss 1.2119(1.2673) | Error 0.0218(0.0266) Steps 416(406.83) | Grad Norm 2.4517(2.4498) | Total Time 10.00(10.00)\n",
      "Iter 1025 | Time 30.6772(28.9314) | Bit/dim 1.1726(1.2231) | Xent 0.0779(0.0851) | Loss 1.2115(1.2657) | Error 0.0235(0.0266) Steps 410(406.93) | Grad Norm 3.2733(2.4745) | Total Time 10.00(10.00)\n",
      "Iter 1026 | Time 28.8067(28.9276) | Bit/dim 1.2015(1.2225) | Xent 0.0721(0.0847) | Loss 1.2375(1.2648) | Error 0.0216(0.0264) Steps 416(407.20) | Grad Norm 4.8431(2.5456) | Total Time 10.00(10.00)\n",
      "Iter 1027 | Time 28.6022(28.9179) | Bit/dim 1.2063(1.2220) | Xent 0.0788(0.0846) | Loss 1.2457(1.2643) | Error 0.0255(0.0264) Steps 404(407.10) | Grad Norm 7.8104(2.7035) | Total Time 10.00(10.00)\n",
      "Iter 1028 | Time 28.6120(28.9087) | Bit/dim 1.3034(1.2244) | Xent 0.0690(0.0841) | Loss 1.3378(1.2665) | Error 0.0220(0.0262) Steps 404(407.01) | Grad Norm 7.5902(2.8501) | Total Time 10.00(10.00)\n",
      "Iter 1029 | Time 28.6072(28.8996) | Bit/dim 1.1898(1.2234) | Xent 0.0665(0.0836) | Loss 1.2231(1.2652) | Error 0.0211(0.0261) Steps 416(407.28) | Grad Norm 2.3479(2.8351) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0147 | Time 16.2557, Epoch Time 231.6716(224.6858), Bit/dim 1.3572(best: 1.1664), Xent 0.0583, Loss 1.3864, Error 0.0183(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1030 | Time 29.0052(28.9028) | Bit/dim 1.3591(1.2275) | Xent 0.1356(0.0851) | Loss 1.4269(1.2700) | Error 0.0420(0.0266) Steps 404(407.18) | Grad Norm 15.4416(3.2132) | Total Time 10.00(10.00)\n",
      "Iter 1031 | Time 28.0930(28.8785) | Bit/dim 1.4407(1.2339) | Xent 0.0917(0.0853) | Loss 1.4865(1.2765) | Error 0.0290(0.0266) Steps 410(407.27) | Grad Norm 6.0603(3.2987) | Total Time 10.00(10.00)\n",
      "Iter 1032 | Time 28.3710(28.8633) | Bit/dim 1.5344(1.2429) | Xent 0.0608(0.0846) | Loss 1.5647(1.2852) | Error 0.0184(0.0264) Steps 398(406.99) | Grad Norm 3.6645(3.3096) | Total Time 10.00(10.00)\n",
      "Iter 1033 | Time 27.9855(28.8370) | Bit/dim 1.5211(1.2512) | Xent 0.0707(0.0842) | Loss 1.5565(1.2933) | Error 0.0202(0.0262) Steps 386(406.36) | Grad Norm 2.8050(3.2945) | Total Time 10.00(10.00)\n",
      "Iter 1034 | Time 27.7900(28.8055) | Bit/dim 1.4399(1.2569) | Xent 0.0538(0.0833) | Loss 1.4668(1.2985) | Error 0.0179(0.0260) Steps 410(406.47) | Grad Norm 2.2047(3.2618) | Total Time 10.00(10.00)\n",
      "Iter 1035 | Time 28.9167(28.8089) | Bit/dim 1.3861(1.2608) | Xent 0.0976(0.0837) | Loss 1.4349(1.3026) | Error 0.0301(0.0261) Steps 410(406.57) | Grad Norm 1.8662(3.2199) | Total Time 10.00(10.00)\n",
      "Iter 1036 | Time 27.6331(28.7736) | Bit/dim 1.3535(1.2635) | Xent 0.1092(0.0844) | Loss 1.4081(1.3058) | Error 0.0347(0.0263) Steps 398(406.32) | Grad Norm 1.8309(3.1783) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 15.1933, Epoch Time 225.5952(224.7131), Bit/dim 1.3530(best: 1.1664), Xent 0.0510, Loss 1.3786, Error 0.0159(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1037 | Time 27.6676(28.7404) | Bit/dim 1.3589(1.2664) | Xent 0.0974(0.0848) | Loss 1.4076(1.3088) | Error 0.0310(0.0265) Steps 398(406.07) | Grad Norm 2.8006(3.1669) | Total Time 10.00(10.00)\n",
      "Iter 1038 | Time 28.8631(28.7441) | Bit/dim 1.3680(1.2694) | Xent 0.0885(0.0849) | Loss 1.4123(1.3119) | Error 0.0286(0.0265) Steps 392(405.64) | Grad Norm 3.0059(3.1621) | Total Time 10.00(10.00)\n",
      "Iter 1039 | Time 29.1886(28.7574) | Bit/dim 1.3178(1.2709) | Xent 0.0805(0.0848) | Loss 1.3581(1.3133) | Error 0.0240(0.0265) Steps 392(405.24) | Grad Norm 1.8800(3.1236) | Total Time 10.00(10.00)\n",
      "Iter 1040 | Time 29.2297(28.7716) | Bit/dim 1.2970(1.2717) | Xent 0.0764(0.0846) | Loss 1.3352(1.3140) | Error 0.0240(0.0264) Steps 416(405.56) | Grad Norm 1.8068(3.0841) | Total Time 10.00(10.00)\n",
      "Iter 1041 | Time 29.5082(28.7937) | Bit/dim 1.3025(1.2726) | Xent 0.0763(0.0843) | Loss 1.3407(1.3148) | Error 0.0250(0.0264) Steps 410(405.69) | Grad Norm 1.7244(3.0433) | Total Time 10.00(10.00)\n",
      "Iter 1042 | Time 29.8677(28.8259) | Bit/dim 1.2909(1.2732) | Xent 0.0861(0.0844) | Loss 1.3340(1.3153) | Error 0.0255(0.0263) Steps 416(406.00) | Grad Norm 1.9466(3.0104) | Total Time 10.00(10.00)\n",
      "Iter 1043 | Time 28.2244(28.8079) | Bit/dim 1.2704(1.2731) | Xent 0.0833(0.0843) | Loss 1.3120(1.3152) | Error 0.0252(0.0263) Steps 410(406.12) | Grad Norm 1.5773(2.9674) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 15.3286, Epoch Time 230.3880(224.8834), Bit/dim 1.2400(best: 1.1664), Xent 0.0431, Loss 1.2616, Error 0.0124(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1044 | Time 29.8305(28.8386) | Bit/dim 1.2426(1.2722) | Xent 0.0846(0.0843) | Loss 1.2849(1.3143) | Error 0.0269(0.0263) Steps 404(406.06) | Grad Norm 1.1433(2.9127) | Total Time 10.00(10.00)\n",
      "Iter 1045 | Time 28.3324(28.8234) | Bit/dim 1.2535(1.2716) | Xent 0.0723(0.0840) | Loss 1.2896(1.3136) | Error 0.0228(0.0262) Steps 392(405.64) | Grad Norm 1.6360(2.8744) | Total Time 10.00(10.00)\n",
      "Iter 1046 | Time 27.5956(28.7865) | Bit/dim 1.2504(1.2710) | Xent 0.0738(0.0837) | Loss 1.2873(1.3128) | Error 0.0232(0.0261) Steps 386(405.05) | Grad Norm 2.0563(2.8499) | Total Time 10.00(10.00)\n",
      "Iter 1047 | Time 29.3558(28.8036) | Bit/dim 1.2370(1.2699) | Xent 0.0779(0.0835) | Loss 1.2759(1.3117) | Error 0.0246(0.0261) Steps 386(404.48) | Grad Norm 1.5895(2.8121) | Total Time 10.00(10.00)\n",
      "Iter 1048 | Time 29.1727(28.8147) | Bit/dim 1.2253(1.2686) | Xent 0.0823(0.0835) | Loss 1.2664(1.3103) | Error 0.0231(0.0260) Steps 416(404.82) | Grad Norm 1.0345(2.7587) | Total Time 10.00(10.00)\n",
      "Iter 1049 | Time 28.9493(28.8187) | Bit/dim 1.2364(1.2676) | Xent 0.0887(0.0836) | Loss 1.2807(1.3094) | Error 0.0288(0.0261) Steps 422(405.34) | Grad Norm 1.5844(2.7235) | Total Time 10.00(10.00)\n",
      "Iter 1050 | Time 27.9292(28.7920) | Bit/dim 1.2232(1.2663) | Xent 0.0828(0.0836) | Loss 1.2646(1.3081) | Error 0.0258(0.0261) Steps 404(405.30) | Grad Norm 0.8994(2.6688) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 14.9361, Epoch Time 228.5061(224.9920), Bit/dim 1.2104(best: 1.1664), Xent 0.0433, Loss 1.2321, Error 0.0135(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1051 | Time 28.1159(28.7718) | Bit/dim 1.2171(1.2648) | Xent 0.0817(0.0835) | Loss 1.2579(1.3066) | Error 0.0266(0.0261) Steps 398(405.08) | Grad Norm 1.0585(2.6205) | Total Time 10.00(10.00)\n",
      "Iter 1052 | Time 29.4656(28.7926) | Bit/dim 1.2140(1.2633) | Xent 0.0765(0.0833) | Loss 1.2522(1.3050) | Error 0.0252(0.0261) Steps 410(405.23) | Grad Norm 1.0895(2.5745) | Total Time 10.00(10.00)\n",
      "Iter 1053 | Time 28.4385(28.7820) | Bit/dim 1.2098(1.2617) | Xent 0.0853(0.0834) | Loss 1.2524(1.3034) | Error 0.0269(0.0261) Steps 404(405.19) | Grad Norm 1.1257(2.5311) | Total Time 10.00(10.00)\n",
      "Iter 1054 | Time 28.4196(28.7711) | Bit/dim 1.2006(1.2599) | Xent 0.0726(0.0831) | Loss 1.2369(1.3014) | Error 0.0222(0.0260) Steps 404(405.15) | Grad Norm 1.2094(2.4914) | Total Time 10.00(10.00)\n",
      "Iter 1055 | Time 28.5317(28.7639) | Bit/dim 1.1971(1.2580) | Xent 0.0721(0.0827) | Loss 1.2332(1.2993) | Error 0.0222(0.0259) Steps 386(404.58) | Grad Norm 0.7131(2.4381) | Total Time 10.00(10.00)\n",
      "Iter 1056 | Time 28.7859(28.7646) | Bit/dim 1.2035(1.2563) | Xent 0.0872(0.0829) | Loss 1.2471(1.2978) | Error 0.0268(0.0259) Steps 404(404.56) | Grad Norm 1.6123(2.4133) | Total Time 10.00(10.00)\n",
      "Iter 1057 | Time 27.9632(28.7405) | Bit/dim 1.1966(1.2546) | Xent 0.0747(0.0826) | Loss 1.2339(1.2959) | Error 0.0241(0.0258) Steps 404(404.54) | Grad Norm 1.1789(2.3763) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0151 | Time 15.1415, Epoch Time 227.3018(225.0613), Bit/dim 1.1863(best: 1.1664), Xent 0.0393, Loss 1.2059, Error 0.0135(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1058 | Time 27.8774(28.7146) | Bit/dim 1.1956(1.2528) | Xent 0.0739(0.0824) | Loss 1.2325(1.2940) | Error 0.0222(0.0257) Steps 404(404.53) | Grad Norm 0.6108(2.3233) | Total Time 10.00(10.00)\n",
      "Iter 1059 | Time 29.0778(28.7255) | Bit/dim 1.1895(1.2509) | Xent 0.0678(0.0819) | Loss 1.2234(1.2918) | Error 0.0216(0.0256) Steps 416(404.87) | Grad Norm 1.3412(2.2938) | Total Time 10.00(10.00)\n",
      "Iter 1060 | Time 28.1697(28.7088) | Bit/dim 1.1956(1.2492) | Xent 0.0633(0.0814) | Loss 1.2273(1.2899) | Error 0.0204(0.0254) Steps 398(404.67) | Grad Norm 0.9379(2.2532) | Total Time 10.00(10.00)\n",
      "Iter 1061 | Time 28.0206(28.6882) | Bit/dim 1.1858(1.2473) | Xent 0.0732(0.0811) | Loss 1.2225(1.2879) | Error 0.0234(0.0254) Steps 398(404.47) | Grad Norm 1.2611(2.2234) | Total Time 10.00(10.00)\n",
      "Iter 1062 | Time 28.1843(28.6731) | Bit/dim 1.1827(1.2454) | Xent 0.0794(0.0811) | Loss 1.2224(1.2859) | Error 0.0244(0.0253) Steps 398(404.27) | Grad Norm 1.6731(2.2069) | Total Time 10.00(10.00)\n",
      "Iter 1063 | Time 27.7627(28.6458) | Bit/dim 1.1806(1.2434) | Xent 0.0701(0.0807) | Loss 1.2156(1.2838) | Error 0.0220(0.0252) Steps 398(404.08) | Grad Norm 0.9389(2.1689) | Total Time 10.00(10.00)\n",
      "Iter 1064 | Time 27.4585(28.6102) | Bit/dim 1.1806(1.2416) | Xent 0.0640(0.0802) | Loss 1.2126(1.2817) | Error 0.0210(0.0251) Steps 398(403.90) | Grad Norm 0.6192(2.1224) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0152 | Time 15.5958, Epoch Time 224.5758(225.0468), Bit/dim 1.1757(best: 1.1664), Xent 0.0394, Loss 1.1955, Error 0.0133(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1065 | Time 29.4332(28.6348) | Bit/dim 1.1812(1.2397) | Xent 0.0742(0.0801) | Loss 1.2183(1.2798) | Error 0.0229(0.0251) Steps 398(403.72) | Grad Norm 1.7996(2.1127) | Total Time 10.00(10.00)\n",
      "Iter 1066 | Time 28.9155(28.6433) | Bit/dim 1.1835(1.2381) | Xent 0.0607(0.0795) | Loss 1.2138(1.2778) | Error 0.0199(0.0249) Steps 416(404.09) | Grad Norm 2.6347(2.1283) | Total Time 10.00(10.00)\n",
      "Iter 1067 | Time 30.2376(28.6911) | Bit/dim 1.1805(1.2363) | Xent 0.0782(0.0794) | Loss 1.2196(1.2760) | Error 0.0221(0.0248) Steps 422(404.63) | Grad Norm 3.0134(2.1549) | Total Time 10.00(10.00)\n",
      "Iter 1068 | Time 28.2103(28.6767) | Bit/dim 1.1844(1.2348) | Xent 0.0698(0.0791) | Loss 1.2194(1.2743) | Error 0.0199(0.0247) Steps 404(404.61) | Grad Norm 2.8791(2.1766) | Total Time 10.00(10.00)\n",
      "Iter 1069 | Time 29.7305(28.7083) | Bit/dim 1.1758(1.2330) | Xent 0.0672(0.0788) | Loss 1.2094(1.2724) | Error 0.0209(0.0246) Steps 404(404.59) | Grad Norm 2.6621(2.1912) | Total Time 10.00(10.00)\n",
      "Iter 1070 | Time 29.0348(28.7181) | Bit/dim 1.1794(1.2314) | Xent 0.0644(0.0784) | Loss 1.2116(1.2706) | Error 0.0196(0.0244) Steps 404(404.57) | Grad Norm 2.4250(2.1982) | Total Time 10.00(10.00)\n",
      "Iter 1071 | Time 28.7811(28.7200) | Bit/dim 1.1736(1.2297) | Xent 0.0782(0.0783) | Loss 1.2127(1.2688) | Error 0.0244(0.0244) Steps 416(404.92) | Grad Norm 2.0103(2.1926) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0153 | Time 15.4470, Epoch Time 232.1474(225.2598), Bit/dim 1.1664(best: 1.1664), Xent 0.0348, Loss 1.1838, Error 0.0121(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1072 | Time 28.6007(28.7164) | Bit/dim 1.1736(1.2280) | Xent 0.0618(0.0778) | Loss 1.2045(1.2669) | Error 0.0200(0.0243) Steps 416(405.25) | Grad Norm 1.7567(2.1795) | Total Time 10.00(10.00)\n",
      "Iter 1073 | Time 30.8405(28.7801) | Bit/dim 1.1665(1.2261) | Xent 0.0677(0.0775) | Loss 1.2004(1.2649) | Error 0.0224(0.0242) Steps 422(405.75) | Grad Norm 1.5708(2.1612) | Total Time 10.00(10.00)\n",
      "Iter 1074 | Time 28.9713(28.7859) | Bit/dim 1.1690(1.2244) | Xent 0.0685(0.0773) | Loss 1.2032(1.2631) | Error 0.0208(0.0241) Steps 416(406.06) | Grad Norm 2.1006(2.1594) | Total Time 10.00(10.00)\n",
      "Iter 1075 | Time 30.5820(28.8397) | Bit/dim 1.1722(1.2229) | Xent 0.0822(0.0774) | Loss 1.2133(1.2616) | Error 0.0248(0.0241) Steps 416(406.36) | Grad Norm 3.8003(2.2086) | Total Time 10.00(10.00)\n",
      "Iter 1076 | Time 28.2070(28.8208) | Bit/dim 1.2090(1.2224) | Xent 0.0585(0.0769) | Loss 1.2383(1.2609) | Error 0.0172(0.0239) Steps 398(406.11) | Grad Norm 5.8941(2.3192) | Total Time 10.00(10.00)\n",
      "Iter 1077 | Time 30.1103(28.8594) | Bit/dim 1.2173(1.2223) | Xent 0.0888(0.0772) | Loss 1.2617(1.2609) | Error 0.0266(0.0240) Steps 404(406.04) | Grad Norm 9.0296(2.5205) | Total Time 10.00(10.00)\n",
      "Iter 1078 | Time 27.8204(28.8283) | Bit/dim 1.2999(1.2246) | Xent 0.0730(0.0771) | Loss 1.3364(1.2632) | Error 0.0242(0.0240) Steps 404(405.98) | Grad Norm 8.5005(2.6999) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0154 | Time 15.4394, Epoch Time 233.0059(225.4922), Bit/dim 1.1932(best: 1.1664), Xent 0.0335, Loss 1.2100, Error 0.0119(best: 0.0120)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1079 | Time 28.6305(28.8223) | Bit/dim 1.2032(1.2240) | Xent 0.0505(0.0763) | Loss 1.2285(1.2621) | Error 0.0171(0.0238) Steps 398(405.74) | Grad Norm 1.7441(2.6712) | Total Time 10.00(10.00)\n",
      "Iter 1080 | Time 28.2911(28.8064) | Bit/dim 1.2716(1.2254) | Xent 0.1196(0.0776) | Loss 1.3314(1.2642) | Error 0.0380(0.0242) Steps 404(405.69) | Grad Norm 9.7553(2.8838) | Total Time 10.00(10.00)\n",
      "Iter 1081 | Time 27.6125(28.7706) | Bit/dim 1.2577(1.2264) | Xent 0.0734(0.0775) | Loss 1.2944(1.2651) | Error 0.0214(0.0241) Steps 398(405.46) | Grad Norm 4.8140(2.9417) | Total Time 10.00(10.00)\n",
      "Iter 1082 | Time 27.9752(28.7467) | Bit/dim 1.2875(1.2282) | Xent 0.0647(0.0771) | Loss 1.3199(1.2667) | Error 0.0181(0.0240) Steps 404(405.42) | Grad Norm 4.4337(2.9864) | Total Time 10.00(10.00)\n",
      "Iter 1083 | Time 27.9462(28.7227) | Bit/dim 1.2166(1.2279) | Xent 0.0572(0.0765) | Loss 1.2452(1.2661) | Error 0.0188(0.0238) Steps 398(405.19) | Grad Norm 1.5560(2.9435) | Total Time 10.00(10.00)\n",
      "Iter 1084 | Time 30.5278(28.7769) | Bit/dim 1.2758(1.2293) | Xent 0.1001(0.0772) | Loss 1.3259(1.2679) | Error 0.0316(0.0240) Steps 410(405.34) | Grad Norm 7.0496(3.0667) | Total Time 10.00(10.00)\n",
      "Iter 1085 | Time 30.1960(28.8194) | Bit/dim 1.2183(1.2290) | Xent 0.0802(0.0773) | Loss 1.2584(1.2676) | Error 0.0264(0.0241) Steps 422(405.84) | Grad Norm 1.8274(3.0295) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0155 | Time 14.7973, Epoch Time 228.5689(225.5845), Bit/dim 1.2385(best: 1.1664), Xent 0.0356, Loss 1.2563, Error 0.0124(best: 0.0119)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1086 | Time 28.1119(28.7982) | Bit/dim 1.2487(1.2296) | Xent 0.0635(0.0769) | Loss 1.2805(1.2680) | Error 0.0198(0.0240) Steps 398(405.60) | Grad Norm 3.0575(3.0304) | Total Time 10.00(10.00)\n",
      "Iter 1087 | Time 28.0119(28.7746) | Bit/dim 1.2381(1.2298) | Xent 0.0630(0.0765) | Loss 1.2696(1.2680) | Error 0.0205(0.0239) Steps 398(405.37) | Grad Norm 2.3331(3.0094) | Total Time 10.00(10.00)\n",
      "Iter 1088 | Time 29.4507(28.7949) | Bit/dim 1.2039(1.2290) | Xent 0.0634(0.0761) | Loss 1.2355(1.2671) | Error 0.0198(0.0238) Steps 404(405.33) | Grad Norm 1.4747(2.9634) | Total Time 10.00(10.00)\n",
      "Iter 1089 | Time 30.2671(28.8391) | Bit/dim 1.2202(1.2288) | Xent 0.1087(0.0770) | Loss 1.2746(1.2673) | Error 0.0365(0.0241) Steps 422(405.83) | Grad Norm 4.0529(2.9961) | Total Time 10.00(10.00)\n",
      "Iter 1090 | Time 28.1488(28.8184) | Bit/dim 1.1978(1.2278) | Xent 0.0683(0.0768) | Loss 1.2319(1.2662) | Error 0.0212(0.0240) Steps 404(405.78) | Grad Norm 1.3744(2.9474) | Total Time 10.00(10.00)\n",
      "Iter 1091 | Time 27.5264(28.7796) | Bit/dim 1.2162(1.2275) | Xent 0.0690(0.0765) | Loss 1.2507(1.2658) | Error 0.0218(0.0240) Steps 398(405.55) | Grad Norm 2.2969(2.9279) | Total Time 10.00(10.00)\n",
      "Iter 1092 | Time 29.2558(28.7939) | Bit/dim 1.2093(1.2270) | Xent 0.0699(0.0763) | Loss 1.2443(1.2651) | Error 0.0235(0.0240) Steps 398(405.32) | Grad Norm 1.3327(2.8801) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0156 | Time 16.0103, Epoch Time 229.2992(225.6959), Bit/dim 1.1908(best: 1.1664), Xent 0.0413, Loss 1.2114, Error 0.0138(best: 0.0119)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1093 | Time 31.2430(28.8674) | Bit/dim 1.1982(1.2261) | Xent 0.0762(0.0763) | Loss 1.2363(1.2643) | Error 0.0242(0.0240) Steps 428(406.00) | Grad Norm 2.2630(2.8615) | Total Time 10.00(10.00)\n",
      "Iter 1094 | Time 28.7385(28.8635) | Bit/dim 1.1867(1.2249) | Xent 0.0762(0.0763) | Loss 1.2248(1.2631) | Error 0.0244(0.0240) Steps 416(406.30) | Grad Norm 1.2666(2.8137) | Total Time 10.00(10.00)\n",
      "Iter 1095 | Time 27.9112(28.8349) | Bit/dim 1.1917(1.2239) | Xent 0.0727(0.0762) | Loss 1.2280(1.2620) | Error 0.0241(0.0240) Steps 404(406.23) | Grad Norm 1.6931(2.7801) | Total Time 10.00(10.00)\n",
      "Iter 1096 | Time 28.5095(28.8252) | Bit/dim 1.1883(1.2228) | Xent 0.0698(0.0760) | Loss 1.2233(1.2609) | Error 0.0226(0.0239) Steps 410(406.34) | Grad Norm 1.2396(2.7339) | Total Time 10.00(10.00)\n",
      "Iter 1097 | Time 28.7594(28.8232) | Bit/dim 1.1846(1.2217) | Xent 0.0672(0.0758) | Loss 1.2182(1.2596) | Error 0.0219(0.0239) Steps 410(406.45) | Grad Norm 1.4703(2.6960) | Total Time 10.00(10.00)\n",
      "Iter 1098 | Time 29.5067(28.8437) | Bit/dim 1.1829(1.2205) | Xent 0.0698(0.0756) | Loss 1.2178(1.2583) | Error 0.0208(0.0238) Steps 422(406.92) | Grad Norm 1.0119(2.6454) | Total Time 10.00(10.00)\n",
      "Iter 1099 | Time 28.6713(28.8385) | Bit/dim 1.1806(1.2193) | Xent 0.0662(0.0753) | Loss 1.2137(1.2570) | Error 0.0200(0.0237) Steps 404(406.83) | Grad Norm 1.1309(2.6000) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0157 | Time 15.0911, Epoch Time 230.9756(225.8543), Bit/dim 1.1707(best: 1.1664), Xent 0.0380, Loss 1.1897, Error 0.0129(best: 0.0119)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1100 | Time 28.2552(28.8210) | Bit/dim 1.1775(1.2181) | Xent 0.0682(0.0751) | Loss 1.2116(1.2556) | Error 0.0218(0.0236) Steps 398(406.57) | Grad Norm 0.9792(2.5514) | Total Time 10.00(10.00)\n",
      "Iter 1101 | Time 28.9673(28.8254) | Bit/dim 1.1762(1.2168) | Xent 0.0660(0.0748) | Loss 1.2091(1.2542) | Error 0.0231(0.0236) Steps 410(406.67) | Grad Norm 0.9796(2.5042) | Total Time 10.00(10.00)\n",
      "Iter 1102 | Time 28.9796(28.8300) | Bit/dim 1.1707(1.2154) | Xent 0.0737(0.0748) | Loss 1.2075(1.2528) | Error 0.0222(0.0236) Steps 398(406.41) | Grad Norm 0.9849(2.4586) | Total Time 10.00(10.00)\n",
      "Iter 1103 | Time 28.7964(28.8290) | Bit/dim 1.1731(1.2142) | Xent 0.0671(0.0746) | Loss 1.2067(1.2515) | Error 0.0219(0.0235) Steps 416(406.70) | Grad Norm 1.1116(2.4182) | Total Time 10.00(10.00)\n",
      "Iter 1104 | Time 29.7182(28.8557) | Bit/dim 1.1742(1.2130) | Xent 0.0520(0.0739) | Loss 1.2002(1.2499) | Error 0.0160(0.0233) Steps 398(406.44) | Grad Norm 1.3396(2.3859) | Total Time 10.00(10.00)\n",
      "Iter 1105 | Time 28.6208(28.8487) | Bit/dim 1.1699(1.2117) | Xent 0.0704(0.0738) | Loss 1.2051(1.2486) | Error 0.0216(0.0232) Steps 410(406.54) | Grad Norm 1.1237(2.3480) | Total Time 10.00(10.00)\n",
      "Iter 1106 | Time 29.4723(28.8674) | Bit/dim 1.1675(1.2104) | Xent 0.0621(0.0734) | Loss 1.1985(1.2471) | Error 0.0188(0.0231) Steps 398(406.29) | Grad Norm 0.8064(2.3018) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0158 | Time 15.8788, Epoch Time 230.9246(226.0064), Bit/dim 1.1620(best: 1.1664), Xent 0.0335, Loss 1.1788, Error 0.0110(best: 0.0119)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1107 | Time 28.6485(28.8608) | Bit/dim 1.1692(1.2091) | Xent 0.0601(0.0730) | Loss 1.1993(1.2456) | Error 0.0186(0.0230) Steps 416(406.58) | Grad Norm 0.8659(2.2587) | Total Time 10.00(10.00)\n",
      "Iter 1108 | Time 28.4082(28.8472) | Bit/dim 1.1662(1.2078) | Xent 0.0595(0.0726) | Loss 1.1960(1.2441) | Error 0.0186(0.0228) Steps 398(406.32) | Grad Norm 0.8007(2.2149) | Total Time 10.00(10.00)\n",
      "Iter 1109 | Time 28.5494(28.8383) | Bit/dim 1.1641(1.2065) | Xent 0.0664(0.0724) | Loss 1.1973(1.2427) | Error 0.0194(0.0227) Steps 410(406.43) | Grad Norm 1.4613(2.1923) | Total Time 10.00(10.00)\n",
      "Iter 1110 | Time 29.6654(28.8631) | Bit/dim 1.1619(1.2052) | Xent 0.0706(0.0724) | Loss 1.1972(1.2414) | Error 0.0232(0.0228) Steps 416(406.72) | Grad Norm 2.1643(2.1915) | Total Time 10.00(10.00)\n",
      "Iter 1111 | Time 29.0067(28.8674) | Bit/dim 1.1798(1.2044) | Xent 0.0726(0.0724) | Loss 1.2161(1.2406) | Error 0.0214(0.0227) Steps 416(407.00) | Grad Norm 4.3456(2.2561) | Total Time 10.00(10.00)\n",
      "Iter 1112 | Time 28.8641(28.8673) | Bit/dim 1.2185(1.2048) | Xent 0.0940(0.0730) | Loss 1.2656(1.2414) | Error 0.0320(0.0230) Steps 410(407.09) | Grad Norm 10.2971(2.4974) | Total Time 10.00(10.00)\n",
      "Iter 1113 | Time 28.1620(28.8461) | Bit/dim 1.4501(1.2122) | Xent 0.1240(0.0746) | Loss 1.5121(1.2495) | Error 0.0370(0.0234) Steps 404(406.99) | Grad Norm 11.6949(2.7733) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0159 | Time 15.8124, Epoch Time 229.3863(226.1078), Bit/dim 1.2838(best: 1.1620), Xent 0.0549, Loss 1.3113, Error 0.0163(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1114 | Time 29.5801(28.8682) | Bit/dim 1.2871(1.2145) | Xent 0.0757(0.0746) | Loss 1.3250(1.2518) | Error 0.0235(0.0234) Steps 416(407.26) | Grad Norm 4.4531(2.8237) | Total Time 10.00(10.00)\n",
      "Iter 1115 | Time 29.6339(28.8911) | Bit/dim 1.3278(1.2179) | Xent 0.1398(0.0766) | Loss 1.3977(1.2561) | Error 0.0431(0.0240) Steps 410(407.35) | Grad Norm 10.3517(3.0495) | Total Time 10.00(10.00)\n",
      "Iter 1116 | Time 27.9710(28.8635) | Bit/dim 1.2589(1.2191) | Xent 0.1052(0.0774) | Loss 1.3115(1.2578) | Error 0.0345(0.0243) Steps 410(407.43) | Grad Norm 3.0040(3.0481) | Total Time 10.00(10.00)\n",
      "Iter 1117 | Time 29.2353(28.8747) | Bit/dim 1.2875(1.2211) | Xent 0.0732(0.0773) | Loss 1.3241(1.2598) | Error 0.0219(0.0242) Steps 404(407.32) | Grad Norm 3.2868(3.0553) | Total Time 10.00(10.00)\n",
      "Iter 1118 | Time 27.9599(28.8472) | Bit/dim 1.2787(1.2229) | Xent 0.0791(0.0773) | Loss 1.3182(1.2615) | Error 0.0225(0.0242) Steps 404(407.22) | Grad Norm 2.5963(3.0415) | Total Time 10.00(10.00)\n",
      "Iter 1119 | Time 28.8715(28.8480) | Bit/dim 1.2411(1.2234) | Xent 0.1027(0.0781) | Loss 1.2924(1.2625) | Error 0.0289(0.0243) Steps 416(407.49) | Grad Norm 1.8327(3.0053) | Total Time 10.00(10.00)\n",
      "Iter 1120 | Time 29.9525(28.8811) | Bit/dim 1.2709(1.2248) | Xent 0.0977(0.0787) | Loss 1.3197(1.2642) | Error 0.0306(0.0245) Steps 422(407.92) | Grad Norm 4.7520(3.0577) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0160 | Time 15.0204, Epoch Time 230.3690(226.2356), Bit/dim 1.2284(best: 1.1620), Xent 0.0498, Loss 1.2533, Error 0.0166(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1121 | Time 29.2496(28.8922) | Bit/dim 1.2328(1.2251) | Xent 0.0927(0.0791) | Loss 1.2791(1.2646) | Error 0.0301(0.0247) Steps 410(407.98) | Grad Norm 2.5405(3.0422) | Total Time 10.00(10.00)\n",
      "Iter 1122 | Time 28.4965(28.8803) | Bit/dim 1.2472(1.2257) | Xent 0.0759(0.0790) | Loss 1.2851(1.2652) | Error 0.0220(0.0246) Steps 410(408.05) | Grad Norm 2.1176(3.0144) | Total Time 10.00(10.00)\n",
      "Iter 1123 | Time 28.9907(28.8836) | Bit/dim 1.2373(1.2261) | Xent 0.0753(0.0789) | Loss 1.2750(1.2655) | Error 0.0231(0.0246) Steps 410(408.10) | Grad Norm 1.5788(2.9714) | Total Time 10.00(10.00)\n",
      "Iter 1124 | Time 28.9217(28.8848) | Bit/dim 1.2194(1.2259) | Xent 0.1009(0.0796) | Loss 1.2699(1.2657) | Error 0.0309(0.0248) Steps 404(407.98) | Grad Norm 1.7933(2.9360) | Total Time 10.00(10.00)\n",
      "Iter 1125 | Time 29.8340(28.9132) | Bit/dim 1.2252(1.2259) | Xent 0.0891(0.0798) | Loss 1.2698(1.2658) | Error 0.0281(0.0249) Steps 422(408.40) | Grad Norm 3.5643(2.9549) | Total Time 10.00(10.00)\n",
      "Iter 1126 | Time 28.5095(28.9011) | Bit/dim 1.2194(1.2257) | Xent 0.0634(0.0794) | Loss 1.2511(1.2653) | Error 0.0216(0.0248) Steps 410(408.45) | Grad Norm 1.5393(2.9124) | Total Time 10.00(10.00)\n",
      "Iter 1127 | Time 27.7933(28.8679) | Bit/dim 1.2257(1.2257) | Xent 0.0644(0.0789) | Loss 1.2578(1.2651) | Error 0.0196(0.0246) Steps 404(408.32) | Grad Norm 1.9507(2.8835) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0161 | Time 15.8886, Epoch Time 230.2288(226.3554), Bit/dim 1.2142(best: 1.1620), Xent 0.0383, Loss 1.2333, Error 0.0124(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1128 | Time 28.3280(28.8517) | Bit/dim 1.2167(1.2254) | Xent 0.0697(0.0786) | Loss 1.2516(1.2647) | Error 0.0229(0.0246) Steps 404(408.19) | Grad Norm 1.7770(2.8504) | Total Time 10.00(10.00)\n",
      "Iter 1129 | Time 27.8836(28.8226) | Bit/dim 1.1974(1.2246) | Xent 0.0781(0.0786) | Loss 1.2364(1.2639) | Error 0.0249(0.0246) Steps 404(408.06) | Grad Norm 1.2479(2.8023) | Total Time 10.00(10.00)\n",
      "Iter 1130 | Time 28.2378(28.8051) | Bit/dim 1.1908(1.2235) | Xent 0.0838(0.0788) | Loss 1.2327(1.2629) | Error 0.0262(0.0246) Steps 404(407.94) | Grad Norm 1.1140(2.7516) | Total Time 10.00(10.00)\n",
      "Iter 1131 | Time 28.8541(28.8066) | Bit/dim 1.1990(1.2228) | Xent 0.0780(0.0787) | Loss 1.2381(1.2622) | Error 0.0235(0.0246) Steps 416(408.18) | Grad Norm 1.7767(2.7224) | Total Time 10.00(10.00)\n",
      "Iter 1132 | Time 28.4667(28.7964) | Bit/dim 1.1935(1.2219) | Xent 0.0711(0.0785) | Loss 1.2291(1.2612) | Error 0.0229(0.0245) Steps 404(408.06) | Grad Norm 1.3164(2.6802) | Total Time 10.00(10.00)\n",
      "Iter 1133 | Time 28.9224(28.8002) | Bit/dim 1.1914(1.2210) | Xent 0.0661(0.0781) | Loss 1.2244(1.2601) | Error 0.0199(0.0244) Steps 410(408.11) | Grad Norm 1.2968(2.6387) | Total Time 10.00(10.00)\n",
      "Iter 1134 | Time 29.9430(28.8344) | Bit/dim 1.1869(1.2200) | Xent 0.0845(0.0783) | Loss 1.2291(1.2592) | Error 0.0274(0.0245) Steps 422(408.53) | Grad Norm 2.2970(2.6284) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0162 | Time 15.5484, Epoch Time 228.4493(226.4183), Bit/dim 1.1766(best: 1.1620), Xent 0.0399, Loss 1.1965, Error 0.0127(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1135 | Time 28.3998(28.8214) | Bit/dim 1.1841(1.2189) | Xent 0.0655(0.0780) | Loss 1.2169(1.2579) | Error 0.0204(0.0244) Steps 416(408.75) | Grad Norm 1.7156(2.6011) | Total Time 10.00(10.00)\n",
      "Iter 1136 | Time 28.8886(28.8234) | Bit/dim 1.1868(1.2180) | Xent 0.0670(0.0776) | Loss 1.2203(1.2568) | Error 0.0214(0.0243) Steps 392(408.25) | Grad Norm 1.0460(2.5544) | Total Time 10.00(10.00)\n",
      "Iter 1137 | Time 27.8934(28.7955) | Bit/dim 1.1791(1.2168) | Xent 0.0645(0.0772) | Loss 1.2113(1.2554) | Error 0.0189(0.0241) Steps 398(407.94) | Grad Norm 0.7378(2.4999) | Total Time 10.00(10.00)\n",
      "Iter 1138 | Time 27.6113(28.7600) | Bit/dim 1.1740(1.2155) | Xent 0.0758(0.0772) | Loss 1.2119(1.2541) | Error 0.0252(0.0241) Steps 398(407.65) | Grad Norm 1.4740(2.4691) | Total Time 10.00(10.00)\n",
      "Iter 1139 | Time 29.4421(28.7805) | Bit/dim 1.1735(1.2142) | Xent 0.0759(0.0771) | Loss 1.2114(1.2528) | Error 0.0228(0.0241) Steps 410(407.72) | Grad Norm 1.9116(2.4524) | Total Time 10.00(10.00)\n",
      "Iter 1140 | Time 29.5896(28.8047) | Bit/dim 1.1694(1.2129) | Xent 0.0667(0.0768) | Loss 1.2028(1.2513) | Error 0.0211(0.0240) Steps 398(407.43) | Grad Norm 1.4118(2.4212) | Total Time 10.00(10.00)\n",
      "Iter 1141 | Time 28.5089(28.7958) | Bit/dim 1.1754(1.2118) | Xent 0.0612(0.0764) | Loss 1.2060(1.2500) | Error 0.0196(0.0239) Steps 416(407.68) | Grad Norm 0.9255(2.3763) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0163 | Time 15.2694, Epoch Time 227.9525(226.4643), Bit/dim 1.1639(best: 1.1620), Xent 0.0343, Loss 1.1811, Error 0.0114(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1142 | Time 29.2164(28.8085) | Bit/dim 1.1706(1.2105) | Xent 0.0679(0.0761) | Loss 1.2046(1.2486) | Error 0.0218(0.0238) Steps 404(407.57) | Grad Norm 0.6673(2.3250) | Total Time 10.00(10.00)\n",
      "Iter 1143 | Time 28.7721(28.8074) | Bit/dim 1.1718(1.2094) | Xent 0.0627(0.0757) | Loss 1.2032(1.2472) | Error 0.0206(0.0237) Steps 416(407.82) | Grad Norm 1.8198(2.3099) | Total Time 10.00(10.00)\n",
      "Iter 1144 | Time 30.7434(28.8655) | Bit/dim 1.1712(1.2082) | Xent 0.0690(0.0755) | Loss 1.2057(1.2460) | Error 0.0219(0.0237) Steps 422(408.25) | Grad Norm 4.2658(2.3686) | Total Time 10.00(10.00)\n",
      "Iter 1145 | Time 27.6903(28.8302) | Bit/dim 1.2202(1.2086) | Xent 0.0659(0.0752) | Loss 1.2532(1.2462) | Error 0.0201(0.0236) Steps 398(407.94) | Grad Norm 6.1693(2.4826) | Total Time 10.00(10.00)\n",
      "Iter 1146 | Time 29.5176(28.8508) | Bit/dim 1.1973(1.2083) | Xent 0.1072(0.0762) | Loss 1.2509(1.2463) | Error 0.0312(0.0238) Steps 416(408.18) | Grad Norm 7.5009(2.6331) | Total Time 10.00(10.00)\n",
      "Iter 1147 | Time 27.2406(28.8025) | Bit/dim 1.2526(1.2096) | Xent 0.0841(0.0764) | Loss 1.2946(1.2478) | Error 0.0258(0.0238) Steps 398(407.88) | Grad Norm 6.9536(2.7628) | Total Time 10.00(10.00)\n",
      "Iter 1148 | Time 28.7987(28.8024) | Bit/dim 1.1739(1.2085) | Xent 0.0613(0.0760) | Loss 1.2045(1.2465) | Error 0.0182(0.0237) Steps 422(408.30) | Grad Norm 1.2462(2.7173) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0164 | Time 16.2329, Epoch Time 230.4824(226.5848), Bit/dim 1.2257(best: 1.1620), Xent 0.0414, Loss 1.2464, Error 0.0143(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1149 | Time 30.0631(28.8402) | Bit/dim 1.2343(1.2093) | Xent 0.0877(0.0763) | Loss 1.2782(1.2474) | Error 0.0285(0.0238) Steps 410(408.35) | Grad Norm 8.0806(2.8782) | Total Time 10.00(10.00)\n",
      "Iter 1150 | Time 28.0548(28.8167) | Bit/dim 1.2791(1.2114) | Xent 0.0606(0.0758) | Loss 1.3094(1.2493) | Error 0.0189(0.0237) Steps 404(408.22) | Grad Norm 5.2094(2.9481) | Total Time 10.00(10.00)\n",
      "Iter 1151 | Time 27.9262(28.7899) | Bit/dim 1.2964(1.2139) | Xent 0.0473(0.0750) | Loss 1.3201(1.2514) | Error 0.0150(0.0234) Steps 410(408.28) | Grad Norm 4.3519(2.9902) | Total Time 10.00(10.00)\n",
      "Iter 1152 | Time 28.6451(28.7856) | Bit/dim 1.1998(1.2135) | Xent 0.0635(0.0746) | Loss 1.2316(1.2508) | Error 0.0204(0.0233) Steps 416(408.51) | Grad Norm 1.6655(2.9505) | Total Time 10.00(10.00)\n",
      "Iter 1153 | Time 28.7158(28.7835) | Bit/dim 1.2767(1.2154) | Xent 0.1197(0.0760) | Loss 1.3366(1.2534) | Error 0.0361(0.0237) Steps 410(408.55) | Grad Norm 8.5012(3.1170) | Total Time 10.00(10.00)\n",
      "Iter 1154 | Time 28.3426(28.7703) | Bit/dim 1.2238(1.2157) | Xent 0.0654(0.0757) | Loss 1.2565(1.2535) | Error 0.0221(0.0237) Steps 404(408.42) | Grad Norm 3.1564(3.1182) | Total Time 10.00(10.00)\n",
      "Iter 1155 | Time 27.6133(28.7356) | Bit/dim 1.2727(1.2174) | Xent 0.0605(0.0752) | Loss 1.3030(1.2550) | Error 0.0185(0.0235) Steps 404(408.28) | Grad Norm 3.3825(3.1261) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0165 | Time 15.4040, Epoch Time 227.3727(226.6085), Bit/dim 1.2308(best: 1.1620), Xent 0.0378, Loss 1.2497, Error 0.0129(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1156 | Time 27.7407(28.7057) | Bit/dim 1.2342(1.2179) | Xent 0.0583(0.0747) | Loss 1.2634(1.2552) | Error 0.0188(0.0234) Steps 404(408.15) | Grad Norm 2.4797(3.1067) | Total Time 10.00(10.00)\n",
      "Iter 1157 | Time 30.4369(28.7577) | Bit/dim 1.2130(1.2177) | Xent 0.0732(0.0747) | Loss 1.2497(1.2551) | Error 0.0235(0.0234) Steps 422(408.57) | Grad Norm 2.5519(3.0901) | Total Time 10.00(10.00)\n",
      "Iter 1158 | Time 30.4351(28.8080) | Bit/dim 1.2233(1.2179) | Xent 0.0969(0.0753) | Loss 1.2717(1.2556) | Error 0.0285(0.0235) Steps 428(409.15) | Grad Norm 4.1374(3.1215) | Total Time 10.00(10.00)\n",
      "Iter 1159 | Time 28.1887(28.7894) | Bit/dim 1.1992(1.2173) | Xent 0.0594(0.0749) | Loss 1.2289(1.2548) | Error 0.0198(0.0234) Steps 398(408.82) | Grad Norm 1.7104(3.0791) | Total Time 10.00(10.00)\n",
      "Iter 1160 | Time 27.7503(28.7582) | Bit/dim 1.2433(1.2181) | Xent 0.0665(0.0746) | Loss 1.2765(1.2554) | Error 0.0200(0.0233) Steps 398(408.49) | Grad Norm 2.6842(3.0673) | Total Time 10.00(10.00)\n",
      "Iter 1161 | Time 29.9028(28.7926) | Bit/dim 1.2003(1.2176) | Xent 0.0665(0.0744) | Loss 1.2335(1.2548) | Error 0.0198(0.0232) Steps 410(408.54) | Grad Norm 1.6834(3.0258) | Total Time 10.00(10.00)\n",
      "Iter 1162 | Time 29.9155(28.8263) | Bit/dim 1.2097(1.2173) | Xent 0.0624(0.0740) | Loss 1.2409(1.2543) | Error 0.0199(0.0231) Steps 422(408.94) | Grad Norm 3.1098(3.0283) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0166 | Time 16.3210, Epoch Time 233.2624(226.8081), Bit/dim 1.1918(best: 1.1620), Xent 0.0371, Loss 1.2103, Error 0.0123(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1163 | Time 29.3351(28.8415) | Bit/dim 1.2013(1.2169) | Xent 0.0692(0.0739) | Loss 1.2359(1.2538) | Error 0.0212(0.0230) Steps 422(409.33) | Grad Norm 2.3092(3.0067) | Total Time 10.00(10.00)\n",
      "Iter 1164 | Time 27.7451(28.8086) | Bit/dim 1.2004(1.2164) | Xent 0.0583(0.0734) | Loss 1.2296(1.2531) | Error 0.0186(0.0229) Steps 404(409.17) | Grad Norm 2.3642(2.9875) | Total Time 10.00(10.00)\n",
      "Iter 1165 | Time 28.3025(28.7934) | Bit/dim 1.1966(1.2158) | Xent 0.0559(0.0729) | Loss 1.2246(1.2522) | Error 0.0175(0.0227) Steps 410(409.20) | Grad Norm 2.2832(2.9663) | Total Time 10.00(10.00)\n",
      "Iter 1166 | Time 28.5814(28.7871) | Bit/dim 1.1850(1.2149) | Xent 0.0803(0.0731) | Loss 1.2251(1.2514) | Error 0.0245(0.0228) Steps 410(409.22) | Grad Norm 1.9449(2.9357) | Total Time 10.00(10.00)\n",
      "Iter 1167 | Time 27.8383(28.7586) | Bit/dim 1.1823(1.2139) | Xent 0.0694(0.0730) | Loss 1.2170(1.2504) | Error 0.0220(0.0228) Steps 398(408.89) | Grad Norm 2.1022(2.9107) | Total Time 10.00(10.00)\n",
      "Iter 1168 | Time 28.1132(28.7393) | Bit/dim 1.1919(1.2132) | Xent 0.0687(0.0729) | Loss 1.2263(1.2496) | Error 0.0211(0.0227) Steps 404(408.74) | Grad Norm 1.6716(2.8735) | Total Time 10.00(10.00)\n",
      "Iter 1169 | Time 27.9911(28.7168) | Bit/dim 1.1845(1.2124) | Xent 0.0514(0.0722) | Loss 1.2102(1.2485) | Error 0.0161(0.0225) Steps 398(408.42) | Grad Norm 1.6714(2.8374) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0167 | Time 15.7602, Epoch Time 225.9762(226.7831), Bit/dim 1.1720(best: 1.1620), Xent 0.0341, Loss 1.1890, Error 0.0118(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1170 | Time 28.5291(28.7112) | Bit/dim 1.1738(1.2112) | Xent 0.0613(0.0719) | Loss 1.2044(1.2471) | Error 0.0205(0.0225) Steps 410(408.47) | Grad Norm 1.3550(2.7930) | Total Time 10.00(10.00)\n",
      "Iter 1171 | Time 28.7447(28.7122) | Bit/dim 1.1736(1.2101) | Xent 0.0742(0.0720) | Loss 1.2106(1.2460) | Error 0.0220(0.0225) Steps 410(408.51) | Grad Norm 1.6592(2.7590) | Total Time 10.00(10.00)\n",
      "Iter 1172 | Time 29.3908(28.7325) | Bit/dim 1.1767(1.2091) | Xent 0.0531(0.0714) | Loss 1.2033(1.2448) | Error 0.0162(0.0223) Steps 398(408.20) | Grad Norm 1.6974(2.7271) | Total Time 10.00(10.00)\n",
      "Iter 1173 | Time 28.2176(28.7171) | Bit/dim 1.1677(1.2078) | Xent 0.0614(0.0711) | Loss 1.1984(1.2434) | Error 0.0194(0.0222) Steps 416(408.43) | Grad Norm 0.8447(2.6706) | Total Time 10.00(10.00)\n",
      "Iter 1174 | Time 28.1460(28.7000) | Bit/dim 1.1740(1.2068) | Xent 0.0592(0.0707) | Loss 1.2037(1.2422) | Error 0.0188(0.0221) Steps 410(408.48) | Grad Norm 1.6334(2.6395) | Total Time 10.00(10.00)\n",
      "Iter 1175 | Time 30.0245(28.7397) | Bit/dim 1.1730(1.2058) | Xent 0.0742(0.0708) | Loss 1.2101(1.2412) | Error 0.0228(0.0221) Steps 410(408.52) | Grad Norm 1.2419(2.5976) | Total Time 10.00(10.00)\n",
      "Iter 1176 | Time 28.2059(28.7237) | Bit/dim 1.1672(1.2046) | Xent 0.0618(0.0706) | Loss 1.1981(1.2399) | Error 0.0180(0.0220) Steps 398(408.21) | Grad Norm 0.6637(2.5396) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0168 | Time 15.2365, Epoch Time 228.8252(226.8444), Bit/dim 1.1620(best: 1.1620), Xent 0.0322, Loss 1.1781, Error 0.0103(best: 0.0110)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1177 | Time 28.3030(28.7111) | Bit/dim 1.1702(1.2036) | Xent 0.0599(0.0702) | Loss 1.2002(1.2387) | Error 0.0168(0.0218) Steps 410(408.26) | Grad Norm 1.3971(2.5053) | Total Time 10.00(10.00)\n",
      "Iter 1178 | Time 30.3209(28.7594) | Bit/dim 1.1592(1.2023) | Xent 0.0573(0.0699) | Loss 1.1878(1.2372) | Error 0.0174(0.0217) Steps 410(408.31) | Grad Norm 1.0694(2.4622) | Total Time 10.00(10.00)\n",
      "Iter 1179 | Time 28.5323(28.7525) | Bit/dim 1.1650(1.2012) | Xent 0.0603(0.0696) | Loss 1.1951(1.2359) | Error 0.0181(0.0216) Steps 410(408.36) | Grad Norm 0.7912(2.4121) | Total Time 10.00(10.00)\n",
      "Iter 1180 | Time 28.8029(28.7541) | Bit/dim 1.1657(1.2001) | Xent 0.0549(0.0691) | Loss 1.1932(1.2347) | Error 0.0180(0.0215) Steps 410(408.41) | Grad Norm 1.0366(2.3708) | Total Time 10.00(10.00)\n",
      "Iter 1181 | Time 28.1960(28.7373) | Bit/dim 1.1634(1.1990) | Xent 0.0586(0.0688) | Loss 1.1927(1.2334) | Error 0.0182(0.0214) Steps 410(408.46) | Grad Norm 1.2943(2.3385) | Total Time 10.00(10.00)\n",
      "Iter 1182 | Time 28.8314(28.7401) | Bit/dim 1.1566(1.1977) | Xent 0.0637(0.0687) | Loss 1.1884(1.2320) | Error 0.0189(0.0213) Steps 416(408.69) | Grad Norm 1.3533(2.3090) | Total Time 10.00(10.00)\n",
      "Iter 1183 | Time 28.5190(28.7335) | Bit/dim 1.1578(1.1965) | Xent 0.0486(0.0681) | Loss 1.1821(1.2305) | Error 0.0145(0.0211) Steps 410(408.73) | Grad Norm 0.8823(2.2662) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0169 | Time 15.4412, Epoch Time 229.4067(226.9213), Bit/dim 1.1521(best: 1.1620), Xent 0.0299, Loss 1.1671, Error 0.0096(best: 0.0103)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1184 | Time 30.0791(28.7739) | Bit/dim 1.1576(1.1954) | Xent 0.0588(0.0678) | Loss 1.1870(1.2292) | Error 0.0189(0.0210) Steps 410(408.76) | Grad Norm 0.9012(2.2252) | Total Time 10.00(10.00)\n",
      "Iter 1185 | Time 28.1256(28.7544) | Bit/dim 1.1537(1.1941) | Xent 0.0562(0.0674) | Loss 1.1818(1.2278) | Error 0.0196(0.0210) Steps 410(408.80) | Grad Norm 0.7555(2.1811) | Total Time 10.00(10.00)\n",
      "Iter 1186 | Time 29.7559(28.7845) | Bit/dim 1.1551(1.1929) | Xent 0.0610(0.0672) | Loss 1.1856(1.2266) | Error 0.0174(0.0209) Steps 410(408.84) | Grad Norm 0.6721(2.1359) | Total Time 10.00(10.00)\n",
      "Iter 1187 | Time 28.6595(28.7807) | Bit/dim 1.1568(1.1918) | Xent 0.0635(0.0671) | Loss 1.1885(1.2254) | Error 0.0191(0.0208) Steps 410(408.87) | Grad Norm 0.7139(2.0932) | Total Time 10.00(10.00)\n",
      "Iter 1188 | Time 29.4498(28.8008) | Bit/dim 1.1553(1.1908) | Xent 0.0599(0.0669) | Loss 1.1852(1.2242) | Error 0.0184(0.0208) Steps 416(409.09) | Grad Norm 1.3249(2.0702) | Total Time 10.00(10.00)\n",
      "Iter 1189 | Time 27.9722(28.7759) | Bit/dim 1.1577(1.1898) | Xent 0.0530(0.0665) | Loss 1.1842(1.2230) | Error 0.0175(0.0207) Steps 410(409.11) | Grad Norm 2.4682(2.0821) | Total Time 10.00(10.00)\n",
      "Iter 1190 | Time 31.1758(28.8479) | Bit/dim 1.1653(1.1890) | Xent 0.0656(0.0665) | Loss 1.1981(1.2223) | Error 0.0219(0.0207) Steps 416(409.32) | Grad Norm 5.6652(2.1896) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0170 | Time 15.2688, Epoch Time 232.9512(227.1022), Bit/dim 1.2715(best: 1.1521), Xent 0.0383, Loss 1.2906, Error 0.0124(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1191 | Time 27.9334(28.8205) | Bit/dim 1.2757(1.1916) | Xent 0.0656(0.0664) | Loss 1.3085(1.2248) | Error 0.0212(0.0207) Steps 398(408.98) | Grad Norm 8.7025(2.3850) | Total Time 10.00(10.00)\n",
      "Iter 1192 | Time 29.7926(28.8497) | Bit/dim 1.2112(1.1922) | Xent 0.0610(0.0663) | Loss 1.2418(1.2253) | Error 0.0180(0.0206) Steps 422(409.37) | Grad Norm 7.4476(2.5369) | Total Time 10.00(10.00)\n",
      "Iter 1193 | Time 28.2780(28.8325) | Bit/dim 1.1839(1.1920) | Xent 0.0560(0.0660) | Loss 1.2119(1.2249) | Error 0.0178(0.0205) Steps 410(409.39) | Grad Norm 3.4384(2.5639) | Total Time 10.00(10.00)\n",
      "Iter 1194 | Time 28.5913(28.8253) | Bit/dim 1.1687(1.1913) | Xent 0.0519(0.0655) | Loss 1.1946(1.2240) | Error 0.0158(0.0204) Steps 416(409.59) | Grad Norm 1.6380(2.5361) | Total Time 10.00(10.00)\n",
      "Iter 1195 | Time 30.0020(28.8606) | Bit/dim 1.1909(1.1913) | Xent 0.0677(0.0656) | Loss 1.2247(1.2241) | Error 0.0206(0.0204) Steps 416(409.78) | Grad Norm 5.6509(2.6296) | Total Time 10.00(10.00)\n",
      "Iter 1196 | Time 29.9671(28.8938) | Bit/dim 1.2136(1.1919) | Xent 0.0600(0.0654) | Loss 1.2436(1.2246) | Error 0.0181(0.0203) Steps 416(409.97) | Grad Norm 4.4846(2.6852) | Total Time 10.00(10.00)\n",
      "Iter 1197 | Time 28.1233(28.8707) | Bit/dim 1.1783(1.1915) | Xent 0.0565(0.0652) | Loss 1.2066(1.2241) | Error 0.0191(0.0203) Steps 416(410.15) | Grad Norm 2.6844(2.6852) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0171 | Time 15.8384, Epoch Time 231.0407(227.2203), Bit/dim 1.2247(best: 1.1521), Xent 0.0453, Loss 1.2474, Error 0.0145(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1198 | Time 28.9727(28.8737) | Bit/dim 1.2293(1.1926) | Xent 0.0969(0.0661) | Loss 1.2777(1.2257) | Error 0.0299(0.0206) Steps 416(410.32) | Grad Norm 8.6158(2.8631) | Total Time 10.00(10.00)\n",
      "Iter 1199 | Time 27.6740(28.8377) | Bit/dim 1.2405(1.1941) | Xent 0.0566(0.0658) | Loss 1.2688(1.2270) | Error 0.0185(0.0205) Steps 404(410.13) | Grad Norm 4.7656(2.9202) | Total Time 10.00(10.00)\n",
      "Iter 1200 | Time 28.0851(28.8151) | Bit/dim 1.2439(1.1956) | Xent 0.0535(0.0655) | Loss 1.2707(1.2283) | Error 0.0166(0.0204) Steps 404(409.95) | Grad Norm 4.0773(2.9549) | Total Time 10.00(10.00)\n",
      "Iter 1201 | Time 28.3606(28.8015) | Bit/dim 1.1872(1.1953) | Xent 0.0567(0.0652) | Loss 1.2156(1.2279) | Error 0.0166(0.0203) Steps 416(410.13) | Grad Norm 1.8666(2.9223) | Total Time 10.00(10.00)\n",
      "Iter 1202 | Time 30.0228(28.8382) | Bit/dim 1.2345(1.1965) | Xent 0.0908(0.0660) | Loss 1.2799(1.2295) | Error 0.0271(0.0205) Steps 416(410.31) | Grad Norm 6.9053(3.0417) | Total Time 10.00(10.00)\n",
      "Iter 1203 | Time 28.0276(28.8138) | Bit/dim 1.2102(1.1969) | Xent 0.0660(0.0660) | Loss 1.2432(1.2299) | Error 0.0208(0.0205) Steps 398(409.94) | Grad Norm 3.8480(3.0659) | Total Time 10.00(10.00)\n",
      "Iter 1204 | Time 27.7340(28.7814) | Bit/dim 1.2413(1.1982) | Xent 0.0577(0.0657) | Loss 1.2701(1.2311) | Error 0.0182(0.0204) Steps 404(409.76) | Grad Norm 3.1941(3.0698) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0172 | Time 15.7942, Epoch Time 227.4743(227.2279), Bit/dim 1.1911(best: 1.1521), Xent 0.0366, Loss 1.2094, Error 0.0121(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1205 | Time 29.8014(28.8120) | Bit/dim 1.1963(1.1982) | Xent 0.0628(0.0656) | Loss 1.2277(1.2310) | Error 0.0196(0.0204) Steps 416(409.95) | Grad Norm 1.5148(3.0231) | Total Time 10.00(10.00)\n",
      "Iter 1206 | Time 28.6056(28.8058) | Bit/dim 1.1965(1.1981) | Xent 0.0942(0.0665) | Loss 1.2436(1.2314) | Error 0.0290(0.0207) Steps 410(409.95) | Grad Norm 3.2432(3.0297) | Total Time 10.00(10.00)\n",
      "Iter 1207 | Time 26.8805(28.7481) | Bit/dim 1.1825(1.1977) | Xent 0.0722(0.0667) | Loss 1.2186(1.2310) | Error 0.0225(0.0207) Steps 392(409.41) | Grad Norm 1.4021(2.9809) | Total Time 10.00(10.00)\n",
      "Iter 1208 | Time 28.0527(28.7272) | Bit/dim 1.1806(1.1972) | Xent 0.0588(0.0664) | Loss 1.2100(1.2304) | Error 0.0191(0.0207) Steps 398(409.07) | Grad Norm 1.2601(2.9293) | Total Time 10.00(10.00)\n",
      "Iter 1209 | Time 28.7965(28.7293) | Bit/dim 1.1981(1.1972) | Xent 0.0703(0.0665) | Loss 1.2332(1.2305) | Error 0.0199(0.0207) Steps 416(409.28) | Grad Norm 1.4822(2.8859) | Total Time 10.00(10.00)\n",
      "Iter 1210 | Time 28.2697(28.7155) | Bit/dim 1.1764(1.1966) | Xent 0.0593(0.0663) | Loss 1.2060(1.2297) | Error 0.0176(0.0206) Steps 410(409.30) | Grad Norm 1.0063(2.8295) | Total Time 10.00(10.00)\n",
      "Iter 1211 | Time 28.5726(28.7112) | Bit/dim 1.1736(1.1959) | Xent 0.0584(0.0661) | Loss 1.2028(1.2289) | Error 0.0190(0.0205) Steps 410(409.32) | Grad Norm 1.4196(2.7872) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0173 | Time 15.2920, Epoch Time 227.0149(227.2215), Bit/dim 1.1699(best: 1.1521), Xent 0.0360, Loss 1.1879, Error 0.0111(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1212 | Time 30.9259(28.7777) | Bit/dim 1.1785(1.1953) | Xent 0.0563(0.0658) | Loss 1.2067(1.2282) | Error 0.0171(0.0204) Steps 404(409.16) | Grad Norm 2.1113(2.7669) | Total Time 10.00(10.00)\n",
      "Iter 1213 | Time 28.6243(28.7731) | Bit/dim 1.1706(1.1946) | Xent 0.0558(0.0655) | Loss 1.1985(1.2274) | Error 0.0180(0.0203) Steps 410(409.18) | Grad Norm 1.6343(2.7329) | Total Time 10.00(10.00)\n",
      "Iter 1214 | Time 28.3540(28.7605) | Bit/dim 1.1782(1.1941) | Xent 0.0594(0.0653) | Loss 1.2079(1.2268) | Error 0.0189(0.0203) Steps 404(409.03) | Grad Norm 1.4685(2.6950) | Total Time 10.00(10.00)\n",
      "Iter 1215 | Time 28.3831(28.7492) | Bit/dim 1.1646(1.1932) | Xent 0.0630(0.0652) | Loss 1.1961(1.2258) | Error 0.0212(0.0203) Steps 404(408.88) | Grad Norm 1.5704(2.6613) | Total Time 10.00(10.00)\n",
      "Iter 1216 | Time 27.8262(28.7215) | Bit/dim 1.1692(1.1925) | Xent 0.0653(0.0652) | Loss 1.2018(1.2251) | Error 0.0194(0.0203) Steps 398(408.55) | Grad Norm 1.3307(2.6213) | Total Time 10.00(10.00)\n",
      "Iter 1217 | Time 29.5884(28.7475) | Bit/dim 1.1613(1.1916) | Xent 0.0618(0.0651) | Loss 1.1922(1.2241) | Error 0.0196(0.0203) Steps 410(408.60) | Grad Norm 1.1160(2.5762) | Total Time 10.00(10.00)\n",
      "Iter 1218 | Time 28.5033(28.7402) | Bit/dim 1.1622(1.1907) | Xent 0.0682(0.0652) | Loss 1.1963(1.2233) | Error 0.0201(0.0203) Steps 410(408.64) | Grad Norm 0.7667(2.5219) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0174 | Time 15.5997, Epoch Time 230.2470(227.3123), Bit/dim 1.1608(best: 1.1521), Xent 0.0317, Loss 1.1766, Error 0.0103(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1219 | Time 28.7885(28.7416) | Bit/dim 1.1619(1.1898) | Xent 0.0534(0.0649) | Loss 1.1886(1.2223) | Error 0.0171(0.0202) Steps 410(408.68) | Grad Norm 1.7313(2.4982) | Total Time 10.00(10.00)\n",
      "Iter 1220 | Time 28.6134(28.7378) | Bit/dim 1.1590(1.1889) | Xent 0.0652(0.0649) | Loss 1.1916(1.2213) | Error 0.0209(0.0202) Steps 410(408.72) | Grad Norm 1.7030(2.4743) | Total Time 10.00(10.00)\n",
      "Iter 1221 | Time 29.6717(28.7658) | Bit/dim 1.1625(1.1881) | Xent 0.0572(0.0647) | Loss 1.1912(1.2204) | Error 0.0170(0.0201) Steps 398(408.40) | Grad Norm 1.4465(2.4435) | Total Time 10.00(10.00)\n",
      "Iter 1222 | Time 28.7413(28.7650) | Bit/dim 1.1519(1.1870) | Xent 0.0605(0.0645) | Loss 1.1822(1.2193) | Error 0.0198(0.0201) Steps 410(408.44) | Grad Norm 1.5572(2.4169) | Total Time 10.00(10.00)\n",
      "Iter 1223 | Time 29.7231(28.7938) | Bit/dim 1.1608(1.1862) | Xent 0.0558(0.0643) | Loss 1.1887(1.2184) | Error 0.0185(0.0200) Steps 410(408.49) | Grad Norm 1.6205(2.3930) | Total Time 10.00(10.00)\n",
      "Iter 1224 | Time 29.1308(28.8039) | Bit/dim 1.1583(1.1854) | Xent 0.0653(0.0643) | Loss 1.1909(1.2175) | Error 0.0208(0.0201) Steps 404(408.36) | Grad Norm 2.1589(2.3860) | Total Time 10.00(10.00)\n",
      "Iter 1225 | Time 28.9935(28.8096) | Bit/dim 1.1683(1.1849) | Xent 0.0551(0.0640) | Loss 1.1959(1.2169) | Error 0.0158(0.0199) Steps 410(408.41) | Grad Norm 3.5166(2.4199) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0175 | Time 16.1257, Epoch Time 232.2379(227.4601), Bit/dim 1.1735(best: 1.1521), Xent 0.0367, Loss 1.1918, Error 0.0123(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1226 | Time 29.3171(28.8248) | Bit/dim 1.1783(1.1847) | Xent 0.0579(0.0638) | Loss 1.2072(1.2166) | Error 0.0192(0.0199) Steps 416(408.63) | Grad Norm 5.8988(2.5243) | Total Time 10.00(10.00)\n",
      "Iter 1227 | Time 28.4120(28.8124) | Bit/dim 1.2228(1.1858) | Xent 0.0759(0.0642) | Loss 1.2607(1.2179) | Error 0.0238(0.0200) Steps 410(408.67) | Grad Norm 7.1451(2.6629) | Total Time 10.00(10.00)\n",
      "Iter 1228 | Time 29.0377(28.8192) | Bit/dim 1.1903(1.1860) | Xent 0.0851(0.0648) | Loss 1.2328(1.2184) | Error 0.0266(0.0202) Steps 416(408.89) | Grad Norm 5.9457(2.7614) | Total Time 10.00(10.00)\n",
      "Iter 1229 | Time 28.8067(28.8188) | Bit/dim 1.1740(1.1856) | Xent 0.0453(0.0642) | Loss 1.1966(1.2177) | Error 0.0142(0.0200) Steps 416(409.11) | Grad Norm 2.8750(2.7648) | Total Time 10.00(10.00)\n",
      "Iter 1230 | Time 28.9954(28.8241) | Bit/dim 1.1682(1.1851) | Xent 0.0604(0.0641) | Loss 1.1984(1.2171) | Error 0.0196(0.0200) Steps 416(409.31) | Grad Norm 1.6464(2.7312) | Total Time 10.00(10.00)\n",
      "Iter 1231 | Time 30.5158(28.8749) | Bit/dim 1.1791(1.1849) | Xent 0.0742(0.0644) | Loss 1.2162(1.2171) | Error 0.0238(0.0201) Steps 416(409.51) | Grad Norm 5.1830(2.8048) | Total Time 10.00(10.00)\n",
      "Iter 1232 | Time 29.0132(28.8790) | Bit/dim 1.1985(1.1853) | Xent 0.0496(0.0640) | Loss 1.2234(1.2173) | Error 0.0158(0.0200) Steps 416(409.71) | Grad Norm 4.2282(2.8475) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0176 | Time 15.9661, Epoch Time 232.6531(227.6159), Bit/dim 1.1649(best: 1.1521), Xent 0.0332, Loss 1.1815, Error 0.0109(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1233 | Time 30.2413(28.9199) | Bit/dim 1.1742(1.1850) | Xent 0.0540(0.0637) | Loss 1.2012(1.2168) | Error 0.0178(0.0199) Steps 410(409.72) | Grad Norm 2.1737(2.8273) | Total Time 10.00(10.00)\n",
      "Iter 1234 | Time 28.5409(28.9085) | Bit/dim 1.2167(1.1859) | Xent 0.0913(0.0645) | Loss 1.2624(1.2182) | Error 0.0281(0.0202) Steps 416(409.91) | Grad Norm 7.7536(2.9751) | Total Time 10.00(10.00)\n",
      "Iter 1235 | Time 28.1939(28.8871) | Bit/dim 1.2292(1.1872) | Xent 0.0514(0.0641) | Loss 1.2549(1.2193) | Error 0.0172(0.0201) Steps 416(410.09) | Grad Norm 5.0675(3.0378) | Total Time 10.00(10.00)\n",
      "Iter 1236 | Time 28.0767(28.8628) | Bit/dim 1.2216(1.1883) | Xent 0.0421(0.0635) | Loss 1.2426(1.2200) | Error 0.0130(0.0199) Steps 410(410.09) | Grad Norm 3.6782(3.0571) | Total Time 10.00(10.00)\n",
      "Iter 1237 | Time 28.6154(28.8553) | Bit/dim 1.1927(1.1884) | Xent 0.0675(0.0636) | Loss 1.2264(1.2202) | Error 0.0192(0.0199) Steps 416(410.26) | Grad Norm 3.6856(3.0759) | Total Time 10.00(10.00)\n",
      "Iter 1238 | Time 28.7698(28.8528) | Bit/dim 1.1843(1.1883) | Xent 0.0757(0.0639) | Loss 1.2221(1.2202) | Error 0.0249(0.0200) Steps 416(410.44) | Grad Norm 3.6527(3.0932) | Total Time 10.00(10.00)\n",
      "Iter 1239 | Time 27.8165(28.8217) | Bit/dim 1.1994(1.1886) | Xent 0.0532(0.0636) | Loss 1.2260(1.2204) | Error 0.0170(0.0199) Steps 404(410.24) | Grad Norm 3.1544(3.0951) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0177 | Time 15.9787, Epoch Time 228.6867(227.6480), Bit/dim 1.1953(best: 1.1521), Xent 0.0366, Loss 1.2136, Error 0.0115(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1240 | Time 28.5536(28.8136) | Bit/dim 1.2021(1.1890) | Xent 0.0561(0.0634) | Loss 1.2301(1.2207) | Error 0.0169(0.0198) Steps 422(410.60) | Grad Norm 2.6496(3.0817) | Total Time 10.00(10.00)\n",
      "Iter 1241 | Time 28.9385(28.8174) | Bit/dim 1.1797(1.1887) | Xent 0.0575(0.0632) | Loss 1.2084(1.2203) | Error 0.0195(0.0198) Steps 416(410.76) | Grad Norm 2.7693(3.0723) | Total Time 10.00(10.00)\n",
      "Iter 1242 | Time 29.9091(28.8501) | Bit/dim 1.1810(1.1885) | Xent 0.0619(0.0632) | Loss 1.2119(1.2201) | Error 0.0192(0.0198) Steps 416(410.92) | Grad Norm 2.2040(3.0463) | Total Time 10.00(10.00)\n",
      "Iter 1243 | Time 28.3715(28.8358) | Bit/dim 1.1827(1.1883) | Xent 0.0576(0.0630) | Loss 1.2114(1.2198) | Error 0.0170(0.0197) Steps 404(410.71) | Grad Norm 2.5636(3.0318) | Total Time 10.00(10.00)\n",
      "Iter 1244 | Time 28.9747(28.8399) | Bit/dim 1.1783(1.1880) | Xent 0.0493(0.0626) | Loss 1.2030(1.2193) | Error 0.0159(0.0196) Steps 404(410.51) | Grad Norm 1.4334(2.9838) | Total Time 10.00(10.00)\n",
      "Iter 1245 | Time 29.7987(28.8687) | Bit/dim 1.1741(1.1876) | Xent 0.0751(0.0630) | Loss 1.2116(1.2191) | Error 0.0216(0.0197) Steps 422(410.85) | Grad Norm 3.0132(2.9847) | Total Time 10.00(10.00)\n",
      "Iter 1246 | Time 28.7089(28.8639) | Bit/dim 1.1626(1.1869) | Xent 0.0523(0.0626) | Loss 1.1888(1.2182) | Error 0.0152(0.0195) Steps 416(411.01) | Grad Norm 1.3559(2.9359) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0178 | Time 15.2610, Epoch Time 230.8304(227.7435), Bit/dim 1.1651(best: 1.1521), Xent 0.0350, Loss 1.1826, Error 0.0124(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1247 | Time 27.4633(28.8219) | Bit/dim 1.1745(1.1865) | Xent 0.0553(0.0624) | Loss 1.2021(1.2177) | Error 0.0171(0.0195) Steps 404(410.80) | Grad Norm 1.7485(2.9002) | Total Time 10.00(10.00)\n",
      "Iter 1248 | Time 29.8844(28.8538) | Bit/dim 1.1638(1.1858) | Xent 0.0561(0.0622) | Loss 1.1919(1.2169) | Error 0.0185(0.0194) Steps 416(410.95) | Grad Norm 2.2188(2.8798) | Total Time 10.00(10.00)\n",
      "Iter 1249 | Time 28.4269(28.8410) | Bit/dim 1.1589(1.1850) | Xent 0.0465(0.0618) | Loss 1.1821(1.2159) | Error 0.0144(0.0193) Steps 416(411.10) | Grad Norm 1.2815(2.8318) | Total Time 10.00(10.00)\n",
      "Iter 1250 | Time 28.2074(28.8220) | Bit/dim 1.1572(1.1842) | Xent 0.0550(0.0616) | Loss 1.1847(1.2149) | Error 0.0176(0.0192) Steps 410(411.07) | Grad Norm 1.3451(2.7872) | Total Time 10.00(10.00)\n",
      "Iter 1251 | Time 28.8556(28.8230) | Bit/dim 1.1535(1.1832) | Xent 0.0593(0.0615) | Loss 1.1831(1.2140) | Error 0.0194(0.0192) Steps 416(411.22) | Grad Norm 1.9124(2.7610) | Total Time 10.00(10.00)\n",
      "Iter 1252 | Time 28.7523(28.8209) | Bit/dim 1.1630(1.1826) | Xent 0.0509(0.0612) | Loss 1.1884(1.2132) | Error 0.0156(0.0191) Steps 416(411.36) | Grad Norm 1.3664(2.7192) | Total Time 10.00(10.00)\n",
      "Iter 1253 | Time 27.5436(28.7825) | Bit/dim 1.1527(1.1817) | Xent 0.0591(0.0611) | Loss 1.1822(1.2123) | Error 0.0190(0.0191) Steps 410(411.32) | Grad Norm 0.7543(2.6602) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0179 | Time 15.7414, Epoch Time 227.3844(227.7327), Bit/dim 1.1498(best: 1.1521), Xent 0.0356, Loss 1.1676, Error 0.0114(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1254 | Time 28.7249(28.7808) | Bit/dim 1.1562(1.1810) | Xent 0.0566(0.0610) | Loss 1.1845(1.2115) | Error 0.0176(0.0191) Steps 404(411.10) | Grad Norm 1.4581(2.6241) | Total Time 10.00(10.00)\n",
      "Iter 1255 | Time 28.9563(28.7861) | Bit/dim 1.1599(1.1803) | Xent 0.0450(0.0605) | Loss 1.1824(1.2106) | Error 0.0139(0.0189) Steps 410(411.07) | Grad Norm 2.1490(2.6099) | Total Time 10.00(10.00)\n",
      "Iter 1256 | Time 28.2951(28.7713) | Bit/dim 1.1516(1.1795) | Xent 0.0506(0.0602) | Loss 1.1769(1.2096) | Error 0.0151(0.0188) Steps 410(411.04) | Grad Norm 2.1768(2.5969) | Total Time 10.00(10.00)\n",
      "Iter 1257 | Time 28.6590(28.7680) | Bit/dim 1.1535(1.1787) | Xent 0.0579(0.0601) | Loss 1.1825(1.2088) | Error 0.0178(0.0188) Steps 410(411.00) | Grad Norm 1.7563(2.5717) | Total Time 10.00(10.00)\n",
      "Iter 1258 | Time 29.9961(28.8048) | Bit/dim 1.1495(1.1778) | Xent 0.0547(0.0600) | Loss 1.1768(1.2078) | Error 0.0159(0.0187) Steps 416(411.15) | Grad Norm 1.4067(2.5367) | Total Time 10.00(10.00)\n",
      "Iter 1259 | Time 28.5662(28.7977) | Bit/dim 1.1469(1.1769) | Xent 0.0560(0.0599) | Loss 1.1749(1.2068) | Error 0.0179(0.0187) Steps 410(411.12) | Grad Norm 0.6915(2.4814) | Total Time 10.00(10.00)\n",
      "Iter 1260 | Time 28.4566(28.7874) | Bit/dim 1.1441(1.1759) | Xent 0.0495(0.0595) | Loss 1.1689(1.2057) | Error 0.0159(0.0186) Steps 416(411.27) | Grad Norm 0.6701(2.4270) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0180 | Time 15.8661, Epoch Time 230.3235(227.8104), Bit/dim 1.1390(best: 1.1498), Xent 0.0327, Loss 1.1554, Error 0.0121(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1261 | Time 28.3818(28.7753) | Bit/dim 1.1490(1.1751) | Xent 0.0481(0.0592) | Loss 1.1730(1.2047) | Error 0.0142(0.0185) Steps 410(411.23) | Grad Norm 0.6642(2.3741) | Total Time 10.00(10.00)\n",
      "Iter 1262 | Time 27.5899(28.7397) | Bit/dim 1.1450(1.1742) | Xent 0.0570(0.0591) | Loss 1.1735(1.2038) | Error 0.0192(0.0185) Steps 404(411.01) | Grad Norm 1.5782(2.3503) | Total Time 10.00(10.00)\n",
      "Iter 1263 | Time 29.6684(28.7676) | Bit/dim 1.1536(1.1736) | Xent 0.0567(0.0591) | Loss 1.1820(1.2031) | Error 0.0174(0.0184) Steps 416(411.16) | Grad Norm 3.8643(2.3957) | Total Time 10.00(10.00)\n",
      "Iter 1264 | Time 29.5881(28.7922) | Bit/dim 1.2087(1.1746) | Xent 0.0472(0.0587) | Loss 1.2323(1.2040) | Error 0.0151(0.0183) Steps 404(410.95) | Grad Norm 6.6118(2.5222) | Total Time 10.00(10.00)\n",
      "Iter 1265 | Time 28.5109(28.7837) | Bit/dim 1.2200(1.1760) | Xent 0.0716(0.0591) | Loss 1.2558(1.2055) | Error 0.0231(0.0185) Steps 416(411.10) | Grad Norm 10.4266(2.7593) | Total Time 10.00(10.00)\n",
      "Iter 1266 | Time 28.6062(28.7784) | Bit/dim 1.3463(1.1811) | Xent 0.0580(0.0591) | Loss 1.3753(1.2106) | Error 0.0200(0.0185) Steps 404(410.89) | Grad Norm 7.9102(2.9138) | Total Time 10.00(10.00)\n",
      "Iter 1267 | Time 30.2177(28.8216) | Bit/dim 1.2438(1.1830) | Xent 0.0350(0.0583) | Loss 1.2613(1.2121) | Error 0.0110(0.0183) Steps 422(411.22) | Grad Norm 4.1742(2.9516) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0181 | Time 15.8360, Epoch Time 230.6851(227.8966), Bit/dim 1.2497(best: 1.1390), Xent 0.0393, Loss 1.2694, Error 0.0124(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1268 | Time 29.0154(28.8274) | Bit/dim 1.2572(1.1852) | Xent 0.0790(0.0590) | Loss 1.2967(1.2147) | Error 0.0261(0.0185) Steps 416(411.36) | Grad Norm 7.3415(3.0833) | Total Time 10.00(10.00)\n",
      "Iter 1269 | Time 28.8850(28.8291) | Bit/dim 1.1920(1.1854) | Xent 0.0660(0.0592) | Loss 1.2250(1.2150) | Error 0.0226(0.0187) Steps 416(411.50) | Grad Norm 1.6815(3.0413) | Total Time 10.00(10.00)\n",
      "Iter 1270 | Time 28.5203(28.8199) | Bit/dim 1.2244(1.1866) | Xent 0.0552(0.0590) | Loss 1.2520(1.2161) | Error 0.0164(0.0186) Steps 404(411.28) | Grad Norm 2.9059(3.0372) | Total Time 10.00(10.00)\n",
      "Iter 1271 | Time 29.5269(28.8411) | Bit/dim 1.2119(1.1873) | Xent 0.0492(0.0588) | Loss 1.2365(1.2167) | Error 0.0161(0.0185) Steps 410(411.24) | Grad Norm 2.2075(3.0123) | Total Time 10.00(10.00)\n",
      "Iter 1272 | Time 29.1507(28.8504) | Bit/dim 1.2003(1.1877) | Xent 0.0501(0.0585) | Loss 1.2254(1.2170) | Error 0.0160(0.0184) Steps 416(411.38) | Grad Norm 2.3258(2.9917) | Total Time 10.00(10.00)\n",
      "Iter 1273 | Time 28.8357(28.8499) | Bit/dim 1.1908(1.1878) | Xent 0.0686(0.0588) | Loss 1.2251(1.2172) | Error 0.0206(0.0185) Steps 416(411.52) | Grad Norm 2.4783(2.9763) | Total Time 10.00(10.00)\n",
      "Iter 1274 | Time 28.6312(28.8434) | Bit/dim 1.2005(1.1882) | Xent 0.0498(0.0585) | Loss 1.2254(1.2175) | Error 0.0158(0.0184) Steps 398(411.11) | Grad Norm 2.5045(2.9622) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0182 | Time 15.8043, Epoch Time 230.7275(227.9816), Bit/dim 1.1823(best: 1.1390), Xent 0.0343, Loss 1.1995, Error 0.0106(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1275 | Time 28.4456(28.8314) | Bit/dim 1.1886(1.1882) | Xent 0.0455(0.0581) | Loss 1.2113(1.2173) | Error 0.0158(0.0183) Steps 410(411.08) | Grad Norm 1.9640(2.9322) | Total Time 10.00(10.00)\n",
      "Iter 1276 | Time 29.6306(28.8554) | Bit/dim 1.1808(1.1880) | Xent 0.0607(0.0582) | Loss 1.2111(1.2171) | Error 0.0210(0.0184) Steps 422(411.41) | Grad Norm 1.9746(2.9035) | Total Time 10.00(10.00)\n",
      "Iter 1277 | Time 29.0832(28.8622) | Bit/dim 1.1779(1.1877) | Xent 0.0600(0.0583) | Loss 1.2079(1.2168) | Error 0.0201(0.0185) Steps 416(411.55) | Grad Norm 2.0873(2.8790) | Total Time 10.00(10.00)\n",
      "Iter 1278 | Time 27.3593(28.8171) | Bit/dim 1.1835(1.1876) | Xent 0.0558(0.0582) | Loss 1.2114(1.2167) | Error 0.0175(0.0185) Steps 404(411.32) | Grad Norm 2.1210(2.8563) | Total Time 10.00(10.00)\n",
      "Iter 1279 | Time 29.8885(28.8493) | Bit/dim 1.1754(1.1872) | Xent 0.0515(0.0580) | Loss 1.2011(1.2162) | Error 0.0161(0.0184) Steps 410(411.28) | Grad Norm 1.2815(2.8090) | Total Time 10.00(10.00)\n",
      "Iter 1280 | Time 28.7682(28.8469) | Bit/dim 1.1760(1.1869) | Xent 0.0552(0.0579) | Loss 1.2036(1.2158) | Error 0.0181(0.0184) Steps 416(411.42) | Grad Norm 2.6755(2.8050) | Total Time 10.00(10.00)\n",
      "Iter 1281 | Time 28.2242(28.8282) | Bit/dim 1.1689(1.1863) | Xent 0.0524(0.0577) | Loss 1.1951(1.2152) | Error 0.0169(0.0183) Steps 404(411.20) | Grad Norm 1.9925(2.7807) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0183 | Time 15.2711, Epoch Time 229.1244(228.0159), Bit/dim 1.1553(best: 1.1390), Xent 0.0319, Loss 1.1713, Error 0.0115(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1282 | Time 28.2733(28.8115) | Bit/dim 1.1579(1.1855) | Xent 0.0513(0.0575) | Loss 1.1835(1.2142) | Error 0.0145(0.0182) Steps 404(410.98) | Grad Norm 1.2661(2.7352) | Total Time 10.00(10.00)\n",
      "Iter 1283 | Time 29.5693(28.8343) | Bit/dim 1.1664(1.1849) | Xent 0.0650(0.0578) | Loss 1.1989(1.2138) | Error 0.0185(0.0182) Steps 422(411.31) | Grad Norm 2.6734(2.7334) | Total Time 10.00(10.00)\n",
      "Iter 1284 | Time 29.1915(28.8450) | Bit/dim 1.1649(1.1843) | Xent 0.0510(0.0576) | Loss 1.1905(1.2131) | Error 0.0158(0.0181) Steps 410(411.27) | Grad Norm 1.2210(2.6880) | Total Time 10.00(10.00)\n",
      "Iter 1285 | Time 27.9125(28.8170) | Bit/dim 1.1667(1.1838) | Xent 0.0558(0.0575) | Loss 1.1946(1.2125) | Error 0.0170(0.0181) Steps 410(411.24) | Grad Norm 1.4622(2.6512) | Total Time 10.00(10.00)\n",
      "Iter 1286 | Time 29.3086(28.8318) | Bit/dim 1.1578(1.1830) | Xent 0.0594(0.0576) | Loss 1.1875(1.2118) | Error 0.0171(0.0181) Steps 410(411.20) | Grad Norm 2.1723(2.6369) | Total Time 10.00(10.00)\n",
      "Iter 1287 | Time 28.6674(28.8268) | Bit/dim 1.1580(1.1822) | Xent 0.0511(0.0574) | Loss 1.1835(1.2109) | Error 0.0158(0.0180) Steps 416(411.34) | Grad Norm 1.6142(2.6062) | Total Time 10.00(10.00)\n",
      "Iter 1288 | Time 28.8909(28.8287) | Bit/dim 1.1506(1.1813) | Xent 0.0523(0.0572) | Loss 1.1767(1.2099) | Error 0.0179(0.0180) Steps 416(411.48) | Grad Norm 0.7314(2.5499) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0184 | Time 16.0133, Epoch Time 230.3729(228.0866), Bit/dim 1.1521(best: 1.1390), Xent 0.0316, Loss 1.1679, Error 0.0110(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1289 | Time 28.9474(28.8323) | Bit/dim 1.1573(1.1806) | Xent 0.0515(0.0571) | Loss 1.1830(1.2091) | Error 0.0170(0.0180) Steps 416(411.62) | Grad Norm 2.3498(2.5439) | Total Time 10.00(10.00)\n",
      "Iter 1290 | Time 29.0628(28.8392) | Bit/dim 1.1609(1.1800) | Xent 0.0571(0.0571) | Loss 1.1894(1.2085) | Error 0.0190(0.0180) Steps 404(411.39) | Grad Norm 2.8145(2.5520) | Total Time 10.00(10.00)\n",
      "Iter 1291 | Time 28.6498(28.8335) | Bit/dim 1.1548(1.1792) | Xent 0.0600(0.0571) | Loss 1.1848(1.2078) | Error 0.0182(0.0180) Steps 416(411.53) | Grad Norm 1.9102(2.5328) | Total Time 10.00(10.00)\n",
      "Iter 1292 | Time 28.2323(28.8155) | Bit/dim 1.1482(1.1783) | Xent 0.0526(0.0570) | Loss 1.1745(1.2068) | Error 0.0162(0.0180) Steps 416(411.66) | Grad Norm 0.5912(2.4745) | Total Time 10.00(10.00)\n",
      "Iter 1293 | Time 28.3778(28.8024) | Bit/dim 1.1538(1.1776) | Xent 0.0433(0.0566) | Loss 1.1755(1.2059) | Error 0.0145(0.0179) Steps 410(411.61) | Grad Norm 1.6969(2.4512) | Total Time 10.00(10.00)\n",
      "Iter 1294 | Time 30.1774(28.8436) | Bit/dim 1.1492(1.1767) | Xent 0.0502(0.0564) | Loss 1.1744(1.2049) | Error 0.0166(0.0178) Steps 416(411.74) | Grad Norm 2.8837(2.4642) | Total Time 10.00(10.00)\n",
      "Iter 1295 | Time 27.5263(28.8041) | Bit/dim 1.1665(1.1764) | Xent 0.0504(0.0562) | Loss 1.1917(1.2045) | Error 0.0170(0.0178) Steps 404(411.51) | Grad Norm 3.8899(2.5070) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0185 | Time 16.0291, Epoch Time 229.4414(228.1272), Bit/dim 1.1586(best: 1.1390), Xent 0.0355, Loss 1.1764, Error 0.0111(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1296 | Time 28.8818(28.8064) | Bit/dim 1.1639(1.1760) | Xent 0.0656(0.0565) | Loss 1.1967(1.2043) | Error 0.0221(0.0179) Steps 416(411.65) | Grad Norm 5.6933(2.6025) | Total Time 10.00(10.00)\n",
      "Iter 1297 | Time 29.0895(28.8149) | Bit/dim 1.2207(1.1774) | Xent 0.0467(0.0562) | Loss 1.2441(1.2055) | Error 0.0161(0.0179) Steps 410(411.60) | Grad Norm 5.9320(2.7024) | Total Time 10.00(10.00)\n",
      "Iter 1298 | Time 30.4716(28.8646) | Bit/dim 1.1583(1.1768) | Xent 0.0535(0.0561) | Loss 1.1850(1.2049) | Error 0.0171(0.0179) Steps 416(411.73) | Grad Norm 1.7841(2.6749) | Total Time 10.00(10.00)\n",
      "Iter 1299 | Time 30.6715(28.9188) | Bit/dim 1.1828(1.1770) | Xent 0.0646(0.0564) | Loss 1.2151(1.2052) | Error 0.0208(0.0179) Steps 428(412.22) | Grad Norm 6.4213(2.7873) | Total Time 10.00(10.00)\n",
      "Iter 1300 | Time 27.2825(28.8697) | Bit/dim 1.2659(1.1796) | Xent 0.0547(0.0563) | Loss 1.2932(1.2078) | Error 0.0166(0.0179) Steps 404(411.97) | Grad Norm 6.3499(2.8941) | Total Time 10.00(10.00)\n",
      "Iter 1301 | Time 29.2214(28.8803) | Bit/dim 1.2131(1.1806) | Xent 0.0381(0.0558) | Loss 1.2322(1.2085) | Error 0.0120(0.0177) Steps 422(412.27) | Grad Norm 3.7056(2.9185) | Total Time 10.00(10.00)\n",
      "Iter 1302 | Time 29.7530(28.9065) | Bit/dim 1.2539(1.1828) | Xent 0.0707(0.0562) | Loss 1.2892(1.2110) | Error 0.0215(0.0178) Steps 428(412.74) | Grad Norm 8.7498(3.0934) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0186 | Time 15.9233, Epoch Time 233.5205(228.2890), Bit/dim 1.1908(best: 1.1390), Xent 0.0379, Loss 1.2097, Error 0.0138(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1303 | Time 28.1879(28.8849) | Bit/dim 1.1998(1.1834) | Xent 0.0643(0.0565) | Loss 1.2319(1.2116) | Error 0.0204(0.0179) Steps 410(412.66) | Grad Norm 3.2779(3.0990) | Total Time 10.00(10.00)\n",
      "Iter 1304 | Time 28.1578(28.8631) | Bit/dim 1.2225(1.1845) | Xent 0.0468(0.0562) | Loss 1.2459(1.2126) | Error 0.0165(0.0179) Steps 410(412.58) | Grad Norm 3.3142(3.1054) | Total Time 10.00(10.00)\n",
      "Iter 1305 | Time 27.4686(28.8213) | Bit/dim 1.1800(1.1844) | Xent 0.0420(0.0558) | Loss 1.2010(1.2123) | Error 0.0132(0.0177) Steps 410(412.50) | Grad Norm 1.0280(3.0431) | Total Time 10.00(10.00)\n",
      "Iter 1306 | Time 28.6503(28.8161) | Bit/dim 1.2166(1.1854) | Xent 0.0626(0.0560) | Loss 1.2479(1.2133) | Error 0.0190(0.0178) Steps 416(412.61) | Grad Norm 4.7762(3.0951) | Total Time 10.00(10.00)\n",
      "Iter 1307 | Time 27.7992(28.7856) | Bit/dim 1.1683(1.1848) | Xent 0.0550(0.0559) | Loss 1.1958(1.2128) | Error 0.0180(0.0178) Steps 410(412.53) | Grad Norm 1.4813(3.0467) | Total Time 10.00(10.00)\n",
      "Iter 1308 | Time 28.2396(28.7692) | Bit/dim 1.1939(1.1851) | Xent 0.0586(0.0560) | Loss 1.2232(1.2131) | Error 0.0189(0.0178) Steps 410(412.45) | Grad Norm 2.9988(3.0452) | Total Time 10.00(10.00)\n",
      "Iter 1309 | Time 27.4179(28.7287) | Bit/dim 1.1736(1.1848) | Xent 0.0513(0.0559) | Loss 1.1993(1.2127) | Error 0.0170(0.0178) Steps 410(412.38) | Grad Norm 1.0007(2.9839) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0187 | Time 15.9805, Epoch Time 224.4826(228.1748), Bit/dim 1.1767(best: 1.1390), Xent 0.0404, Loss 1.1969, Error 0.0131(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1310 | Time 28.1561(28.7115) | Bit/dim 1.1822(1.1847) | Xent 0.0779(0.0565) | Loss 1.2211(1.2130) | Error 0.0235(0.0180) Steps 416(412.49) | Grad Norm 3.9758(3.0137) | Total Time 10.00(10.00)\n",
      "Iter 1311 | Time 28.0978(28.6931) | Bit/dim 1.1783(1.1845) | Xent 0.0568(0.0565) | Loss 1.2067(1.2128) | Error 0.0185(0.0180) Steps 410(412.41) | Grad Norm 2.3185(2.9928) | Total Time 10.00(10.00)\n",
      "Iter 1312 | Time 27.5654(28.6593) | Bit/dim 1.1684(1.1840) | Xent 0.0490(0.0563) | Loss 1.1930(1.2122) | Error 0.0159(0.0179) Steps 410(412.34) | Grad Norm 1.9575(2.9617) | Total Time 10.00(10.00)\n",
      "Iter 1313 | Time 27.8986(28.6365) | Bit/dim 1.1698(1.1836) | Xent 0.0723(0.0568) | Loss 1.2060(1.2120) | Error 0.0218(0.0180) Steps 410(412.27) | Grad Norm 2.8076(2.9571) | Total Time 10.00(10.00)\n",
      "Iter 1314 | Time 27.4136(28.5998) | Bit/dim 1.1591(1.1829) | Xent 0.0481(0.0565) | Loss 1.1831(1.2111) | Error 0.0152(0.0179) Steps 410(412.20) | Grad Norm 1.1740(2.9036) | Total Time 10.00(10.00)\n",
      "Iter 1315 | Time 28.1027(28.5849) | Bit/dim 1.1672(1.1824) | Xent 0.0607(0.0567) | Loss 1.1975(1.2107) | Error 0.0185(0.0180) Steps 410(412.14) | Grad Norm 1.6160(2.8650) | Total Time 10.00(10.00)\n",
      "Iter 1316 | Time 27.5908(28.5550) | Bit/dim 1.1665(1.1819) | Xent 0.0536(0.0566) | Loss 1.1933(1.2102) | Error 0.0182(0.0180) Steps 410(412.07) | Grad Norm 2.0852(2.8416) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0188 | Time 15.7675, Epoch Time 222.8924(228.0163), Bit/dim 1.1468(best: 1.1390), Xent 0.0331, Loss 1.1634, Error 0.0118(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1317 | Time 27.5375(28.5245) | Bit/dim 1.1583(1.1812) | Xent 0.0423(0.0561) | Loss 1.1794(1.2093) | Error 0.0134(0.0178) Steps 410(412.01) | Grad Norm 0.5535(2.7730) | Total Time 10.00(10.00)\n",
      "Iter 1318 | Time 27.4274(28.4916) | Bit/dim 1.1561(1.1804) | Xent 0.0622(0.0563) | Loss 1.1872(1.2086) | Error 0.0199(0.0179) Steps 404(411.77) | Grad Norm 1.8702(2.7459) | Total Time 10.00(10.00)\n",
      "Iter 1319 | Time 27.8659(28.4728) | Bit/dim 1.1559(1.1797) | Xent 0.0449(0.0560) | Loss 1.1784(1.2077) | Error 0.0148(0.0178) Steps 410(411.72) | Grad Norm 1.0539(2.6951) | Total Time 10.00(10.00)\n",
      "Iter 1320 | Time 27.6337(28.4477) | Bit/dim 1.1500(1.1788) | Xent 0.0457(0.0557) | Loss 1.1729(1.2067) | Error 0.0142(0.0177) Steps 410(411.67) | Grad Norm 0.9692(2.6433) | Total Time 10.00(10.00)\n",
      "Iter 1321 | Time 28.0751(28.4365) | Bit/dim 1.1544(1.1781) | Xent 0.0550(0.0557) | Loss 1.1819(1.2059) | Error 0.0159(0.0176) Steps 410(411.62) | Grad Norm 1.3315(2.6040) | Total Time 10.00(10.00)\n",
      "Iter 1322 | Time 28.7639(28.4463) | Bit/dim 1.1478(1.1772) | Xent 0.0456(0.0554) | Loss 1.1706(1.2049) | Error 0.0145(0.0175) Steps 410(411.57) | Grad Norm 1.1959(2.5617) | Total Time 10.00(10.00)\n",
      "Iter 1323 | Time 28.0064(28.4331) | Bit/dim 1.1466(1.1763) | Xent 0.0568(0.0554) | Loss 1.1750(1.2040) | Error 0.0184(0.0176) Steps 410(411.52) | Grad Norm 0.7773(2.5082) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0189 | Time 15.7309, Epoch Time 223.5088(227.8811), Bit/dim 1.1419(best: 1.1390), Xent 0.0333, Loss 1.1586, Error 0.0112(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1324 | Time 27.2547(28.3978) | Bit/dim 1.1542(1.1756) | Xent 0.0522(0.0553) | Loss 1.1803(1.2033) | Error 0.0160(0.0175) Steps 410(411.48) | Grad Norm 1.3027(2.4720) | Total Time 10.00(10.00)\n",
      "Iter 1325 | Time 28.6679(28.4059) | Bit/dim 1.1465(1.1747) | Xent 0.0395(0.0548) | Loss 1.1663(1.2021) | Error 0.0128(0.0174) Steps 416(411.61) | Grad Norm 1.9753(2.4571) | Total Time 10.00(10.00)\n",
      "Iter 1326 | Time 27.9237(28.3914) | Bit/dim 1.1492(1.1740) | Xent 0.0491(0.0547) | Loss 1.1737(1.2013) | Error 0.0148(0.0173) Steps 410(411.56) | Grad Norm 2.6530(2.4630) | Total Time 10.00(10.00)\n",
      "Iter 1327 | Time 28.1138(28.3831) | Bit/dim 1.1543(1.1734) | Xent 0.0557(0.0547) | Loss 1.1822(1.2007) | Error 0.0168(0.0173) Steps 416(411.70) | Grad Norm 3.9246(2.5069) | Total Time 10.00(10.00)\n",
      "Iter 1328 | Time 28.3652(28.3825) | Bit/dim 1.1724(1.1733) | Xent 0.0575(0.0548) | Loss 1.2011(1.2007) | Error 0.0184(0.0173) Steps 404(411.46) | Grad Norm 5.0215(2.5823) | Total Time 10.00(10.00)\n",
      "Iter 1329 | Time 29.5789(28.4184) | Bit/dim 1.1651(1.1731) | Xent 0.0582(0.0549) | Loss 1.1942(1.2005) | Error 0.0176(0.0173) Steps 428(411.96) | Grad Norm 5.3042(2.6640) | Total Time 10.00(10.00)\n",
      "Iter 1330 | Time 27.8981(28.4028) | Bit/dim 1.1796(1.1733) | Xent 0.0412(0.0545) | Loss 1.2002(1.2005) | Error 0.0121(0.0172) Steps 416(412.08) | Grad Norm 4.3971(2.7160) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0190 | Time 15.6245, Epoch Time 225.7947(227.8185), Bit/dim 1.1401(best: 1.1390), Xent 0.0285, Loss 1.1543, Error 0.0095(best: 0.0096)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1331 | Time 27.7678(28.3838) | Bit/dim 1.1473(1.1725) | Xent 0.0480(0.0543) | Loss 1.1713(1.1996) | Error 0.0135(0.0171) Steps 410(412.02) | Grad Norm 1.2432(2.6718) | Total Time 10.00(10.00)\n",
      "Iter 1332 | Time 29.0057(28.4024) | Bit/dim 1.1585(1.1721) | Xent 0.0536(0.0543) | Loss 1.1853(1.1992) | Error 0.0171(0.0171) Steps 416(412.14) | Grad Norm 4.1378(2.7158) | Total Time 10.00(10.00)\n",
      "Iter 1333 | Time 27.8959(28.3872) | Bit/dim 1.2030(1.1730) | Xent 0.0467(0.0540) | Loss 1.2263(1.2000) | Error 0.0145(0.0170) Steps 410(412.07) | Grad Norm 5.4012(2.7963) | Total Time 10.00(10.00)\n",
      "Iter 1334 | Time 27.5839(28.3631) | Bit/dim 1.1460(1.1722) | Xent 0.0450(0.0538) | Loss 1.1685(1.1991) | Error 0.0136(0.0169) Steps 410(412.01) | Grad Norm 0.7672(2.7354) | Total Time 10.00(10.00)\n",
      "Iter 1335 | Time 31.8220(28.4669) | Bit/dim 1.2111(1.1734) | Xent 0.0697(0.0542) | Loss 1.2460(1.2005) | Error 0.0228(0.0171) Steps 440(412.85) | Grad Norm 8.2361(2.9005) | Total Time 10.00(10.00)\n",
      "Iter 1336 | Time 28.0530(28.4545) | Bit/dim 1.2771(1.1765) | Xent 0.0420(0.0539) | Loss 1.2981(1.2034) | Error 0.0128(0.0169) Steps 410(412.77) | Grad Norm 5.8093(2.9877) | Total Time 10.00(10.00)\n",
      "Iter 1337 | Time 28.1740(28.4461) | Bit/dim 1.2632(1.1791) | Xent 0.0350(0.0533) | Loss 1.2807(1.2057) | Error 0.0108(0.0167) Steps 410(412.68) | Grad Norm 4.2359(3.0252) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0191 | Time 16.2143, Epoch Time 228.7930(227.8478), Bit/dim 1.1795(best: 1.1390), Xent 0.0328, Loss 1.1959, Error 0.0110(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1338 | Time 27.4141(28.4151) | Bit/dim 1.1846(1.1793) | Xent 0.0485(0.0532) | Loss 1.2089(1.2058) | Error 0.0164(0.0167) Steps 410(412.60) | Grad Norm 1.9385(2.9926) | Total Time 10.00(10.00)\n",
      "Iter 1339 | Time 29.3881(28.4443) | Bit/dim 1.2576(1.1816) | Xent 0.0947(0.0544) | Loss 1.3050(1.2088) | Error 0.0304(0.0171) Steps 428(413.07) | Grad Norm 7.9226(3.1405) | Total Time 10.00(10.00)\n",
      "Iter 1340 | Time 29.0944(28.4638) | Bit/dim 1.2150(1.1826) | Xent 0.0490(0.0542) | Loss 1.2395(1.2097) | Error 0.0142(0.0171) Steps 422(413.33) | Grad Norm 3.2926(3.1450) | Total Time 10.00(10.00)\n",
      "Iter 1341 | Time 28.7540(28.4725) | Bit/dim 1.2731(1.1853) | Xent 0.0411(0.0538) | Loss 1.2937(1.2122) | Error 0.0126(0.0169) Steps 410(413.23) | Grad Norm 3.2803(3.1491) | Total Time 10.00(10.00)\n",
      "Iter 1342 | Time 26.6553(28.4180) | Bit/dim 1.2342(1.1868) | Xent 0.0380(0.0534) | Loss 1.2532(1.2135) | Error 0.0115(0.0168) Steps 404(412.96) | Grad Norm 2.4824(3.1291) | Total Time 10.00(10.00)\n",
      "Iter 1343 | Time 29.7434(28.4577) | Bit/dim 1.2076(1.1874) | Xent 0.0568(0.0535) | Loss 1.2360(1.2141) | Error 0.0185(0.0168) Steps 422(413.23) | Grad Norm 2.4579(3.1090) | Total Time 10.00(10.00)\n",
      "Iter 1344 | Time 28.4577(28.4577) | Bit/dim 1.2207(1.1884) | Xent 0.0678(0.0539) | Loss 1.2546(1.2154) | Error 0.0215(0.0170) Steps 416(413.31) | Grad Norm 3.5461(3.1221) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0192 | Time 16.0805, Epoch Time 228.0669(227.8543), Bit/dim 1.1837(best: 1.1390), Xent 0.0403, Loss 1.2039, Error 0.0150(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1345 | Time 29.1320(28.4780) | Bit/dim 1.1866(1.1884) | Xent 0.0546(0.0539) | Loss 1.2139(1.2153) | Error 0.0198(0.0170) Steps 410(413.21) | Grad Norm 1.5618(3.0753) | Total Time 10.00(10.00)\n",
      "Iter 1346 | Time 27.1490(28.4381) | Bit/dim 1.2133(1.1891) | Xent 0.0387(0.0535) | Loss 1.2326(1.2158) | Error 0.0135(0.0169) Steps 410(413.11) | Grad Norm 2.2746(3.0512) | Total Time 10.00(10.00)\n",
      "Iter 1347 | Time 28.9610(28.4538) | Bit/dim 1.1920(1.1892) | Xent 0.0517(0.0534) | Loss 1.2179(1.2159) | Error 0.0152(0.0169) Steps 410(413.02) | Grad Norm 1.5398(3.0059) | Total Time 10.00(10.00)\n",
      "Iter 1348 | Time 27.4240(28.4229) | Bit/dim 1.1882(1.1892) | Xent 0.0480(0.0533) | Loss 1.2122(1.2158) | Error 0.0139(0.0168) Steps 410(412.93) | Grad Norm 1.6982(2.9667) | Total Time 10.00(10.00)\n",
      "Iter 1349 | Time 29.2227(28.4469) | Bit/dim 1.1942(1.1893) | Xent 0.0520(0.0532) | Loss 1.2202(1.2159) | Error 0.0176(0.0168) Steps 416(413.02) | Grad Norm 2.7556(2.9603) | Total Time 10.00(10.00)\n",
      "Iter 1350 | Time 27.8518(28.4290) | Bit/dim 1.1690(1.1887) | Xent 0.0700(0.0537) | Loss 1.2040(1.2156) | Error 0.0219(0.0170) Steps 410(412.93) | Grad Norm 1.4029(2.9136) | Total Time 10.00(10.00)\n",
      "Iter 1351 | Time 27.1242(28.3899) | Bit/dim 1.1815(1.1885) | Xent 0.0460(0.0535) | Loss 1.2045(1.2152) | Error 0.0140(0.0169) Steps 410(412.84) | Grad Norm 2.1517(2.8908) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0193 | Time 15.9821, Epoch Time 225.3464(227.7791), Bit/dim 1.1699(best: 1.1390), Xent 0.0347, Loss 1.1872, Error 0.0104(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1352 | Time 28.2534(28.3858) | Bit/dim 1.1751(1.1881) | Xent 0.0547(0.0535) | Loss 1.2025(1.2148) | Error 0.0175(0.0169) Steps 410(412.76) | Grad Norm 1.3340(2.8441) | Total Time 10.00(10.00)\n",
      "Iter 1353 | Time 27.8594(28.3700) | Bit/dim 1.1716(1.1876) | Xent 0.0541(0.0535) | Loss 1.1986(1.2144) | Error 0.0164(0.0169) Steps 410(412.68) | Grad Norm 1.2810(2.7972) | Total Time 10.00(10.00)\n",
      "Iter 1354 | Time 28.9562(28.3876) | Bit/dim 1.1662(1.1870) | Xent 0.0486(0.0534) | Loss 1.1905(1.2136) | Error 0.0168(0.0169) Steps 410(412.60) | Grad Norm 1.2096(2.7495) | Total Time 10.00(10.00)\n",
      "Iter 1355 | Time 27.8434(28.3713) | Bit/dim 1.1664(1.1863) | Xent 0.0504(0.0533) | Loss 1.1916(1.2130) | Error 0.0142(0.0168) Steps 410(412.52) | Grad Norm 0.8927(2.6938) | Total Time 10.00(10.00)\n",
      "Iter 1356 | Time 28.2958(28.3690) | Bit/dim 1.1590(1.1855) | Xent 0.0498(0.0532) | Loss 1.1839(1.2121) | Error 0.0146(0.0167) Steps 410(412.44) | Grad Norm 1.1236(2.6467) | Total Time 10.00(10.00)\n",
      "Iter 1357 | Time 27.5223(28.3436) | Bit/dim 1.1530(1.1845) | Xent 0.0459(0.0530) | Loss 1.1760(1.2110) | Error 0.0145(0.0167) Steps 404(412.19) | Grad Norm 0.9021(2.5944) | Total Time 10.00(10.00)\n",
      "Iter 1358 | Time 27.4819(28.3177) | Bit/dim 1.1588(1.1838) | Xent 0.0467(0.0528) | Loss 1.1821(1.2102) | Error 0.0152(0.0166) Steps 410(412.12) | Grad Norm 0.9566(2.5452) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0194 | Time 15.5133, Epoch Time 224.1563(227.6704), Bit/dim 1.1492(best: 1.1390), Xent 0.0286, Loss 1.1635, Error 0.0103(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1359 | Time 27.8987(28.3052) | Bit/dim 1.1555(1.1829) | Xent 0.0528(0.0528) | Loss 1.1819(1.2093) | Error 0.0168(0.0166) Steps 410(412.06) | Grad Norm 0.9482(2.4973) | Total Time 10.00(10.00)\n",
      "Iter 1360 | Time 27.7007(28.2870) | Bit/dim 1.1527(1.1820) | Xent 0.0460(0.0526) | Loss 1.1757(1.2083) | Error 0.0141(0.0166) Steps 410(412.00) | Grad Norm 0.9230(2.4501) | Total Time 10.00(10.00)\n",
      "Iter 1361 | Time 27.6248(28.2672) | Bit/dim 1.1572(1.1813) | Xent 0.0594(0.0528) | Loss 1.1869(1.2077) | Error 0.0182(0.0166) Steps 410(411.94) | Grad Norm 1.0195(2.4072) | Total Time 10.00(10.00)\n",
      "Iter 1362 | Time 27.8546(28.2548) | Bit/dim 1.1491(1.1803) | Xent 0.0553(0.0529) | Loss 1.1768(1.2067) | Error 0.0174(0.0166) Steps 410(411.88) | Grad Norm 1.1986(2.3709) | Total Time 10.00(10.00)\n",
      "Iter 1363 | Time 27.9795(28.2465) | Bit/dim 1.1487(1.1794) | Xent 0.0519(0.0528) | Loss 1.1747(1.2058) | Error 0.0166(0.0166) Steps 410(411.82) | Grad Norm 1.5211(2.3454) | Total Time 10.00(10.00)\n",
      "Iter 1364 | Time 27.9207(28.2368) | Bit/dim 1.1512(1.1785) | Xent 0.0496(0.0527) | Loss 1.1760(1.2049) | Error 0.0154(0.0166) Steps 410(411.77) | Grad Norm 1.6543(2.3247) | Total Time 10.00(10.00)\n",
      "Iter 1365 | Time 28.2427(28.2369) | Bit/dim 1.1430(1.1774) | Xent 0.0516(0.0527) | Loss 1.1688(1.2038) | Error 0.0148(0.0165) Steps 410(411.72) | Grad Norm 1.7449(2.3073) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0195 | Time 15.9212, Epoch Time 223.5756(227.5476), Bit/dim 1.1380(best: 1.1390), Xent 0.0293, Loss 1.1527, Error 0.0105(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1366 | Time 27.8944(28.2267) | Bit/dim 1.1365(1.1762) | Xent 0.0488(0.0526) | Loss 1.1609(1.2025) | Error 0.0156(0.0165) Steps 410(411.66) | Grad Norm 1.1451(2.2724) | Total Time 10.00(10.00)\n",
      "Iter 1367 | Time 27.5181(28.2054) | Bit/dim 1.1505(1.1754) | Xent 0.0488(0.0525) | Loss 1.1749(1.2017) | Error 0.0141(0.0164) Steps 410(411.61) | Grad Norm 0.9793(2.2337) | Total Time 10.00(10.00)\n",
      "Iter 1368 | Time 27.9059(28.1964) | Bit/dim 1.1375(1.1743) | Xent 0.0492(0.0524) | Loss 1.1621(1.2005) | Error 0.0164(0.0164) Steps 410(411.57) | Grad Norm 0.9259(2.1944) | Total Time 10.00(10.00)\n",
      "Iter 1369 | Time 27.4225(28.1732) | Bit/dim 1.1441(1.1734) | Xent 0.0496(0.0523) | Loss 1.1689(1.1995) | Error 0.0166(0.0164) Steps 410(411.52) | Grad Norm 1.2910(2.1673) | Total Time 10.00(10.00)\n",
      "Iter 1370 | Time 29.6989(28.2190) | Bit/dim 1.1425(1.1725) | Xent 0.0437(0.0520) | Loss 1.1644(1.1985) | Error 0.0148(0.0164) Steps 422(411.83) | Grad Norm 0.8869(2.1289) | Total Time 10.00(10.00)\n",
      "Iter 1371 | Time 27.5945(28.2002) | Bit/dim 1.1475(1.1717) | Xent 0.0502(0.0520) | Loss 1.1726(1.1977) | Error 0.0161(0.0164) Steps 410(411.78) | Grad Norm 1.6450(2.1144) | Total Time 10.00(10.00)\n",
      "Iter 1372 | Time 30.0270(28.2550) | Bit/dim 1.1446(1.1709) | Xent 0.0441(0.0517) | Loss 1.1666(1.1968) | Error 0.0129(0.0163) Steps 434(412.45) | Grad Norm 3.7852(2.1645) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0196 | Time 16.0720, Epoch Time 226.7142(227.5226), Bit/dim 1.1965(best: 1.1380), Xent 0.0338, Loss 1.2134, Error 0.0110(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1373 | Time 27.7812(28.2408) | Bit/dim 1.2014(1.1718) | Xent 0.0508(0.0517) | Loss 1.2268(1.1977) | Error 0.0165(0.0163) Steps 410(412.37) | Grad Norm 7.2080(2.3158) | Total Time 10.00(10.00)\n",
      "Iter 1374 | Time 30.9945(28.3234) | Bit/dim 1.2702(1.1748) | Xent 0.0973(0.0531) | Loss 1.3189(1.2013) | Error 0.0337(0.0168) Steps 440(413.20) | Grad Norm 13.8787(2.6627) | Total Time 10.00(10.00)\n",
      "Iter 1375 | Time 26.7375(28.2759) | Bit/dim 1.4719(1.1837) | Xent 0.0924(0.0543) | Loss 1.5181(1.2108) | Error 0.0290(0.0172) Steps 398(412.74) | Grad Norm 8.8901(2.8495) | Total Time 10.00(10.00)\n",
      "Iter 1376 | Time 30.6668(28.3476) | Bit/dim 1.4740(1.1924) | Xent 0.1803(0.0580) | Loss 1.5641(1.2214) | Error 0.0413(0.0179) Steps 428(413.20) | Grad Norm 5.9933(2.9438) | Total Time 10.00(10.00)\n",
      "Iter 1377 | Time 29.0013(28.3672) | Bit/dim 1.3476(1.1971) | Xent 0.1039(0.0594) | Loss 1.3995(1.2268) | Error 0.0337(0.0184) Steps 416(413.29) | Grad Norm 2.6176(2.9341) | Total Time 10.00(10.00)\n",
      "Iter 1378 | Time 28.6160(28.3747) | Bit/dim 1.3364(1.2012) | Xent 0.1493(0.0621) | Loss 1.4110(1.2323) | Error 0.0484(0.0193) Steps 416(413.37) | Grad Norm 2.8754(2.9323) | Total Time 10.00(10.00)\n",
      "Iter 1379 | Time 30.1070(28.4266) | Bit/dim 1.3460(1.2056) | Xent 0.2036(0.0664) | Loss 1.4478(1.2388) | Error 0.0593(0.0205) Steps 440(414.17) | Grad Norm 5.4020(3.0064) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0197 | Time 16.5701, Epoch Time 232.8846(227.6834), Bit/dim 1.4013(best: 1.1380), Xent 0.4093, Loss 1.6060, Error 0.1107(best: 0.0095)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 1380 | Time 29.5270(28.4596) | Bit/dim 1.4065(1.2116) | Xent 0.5261(0.0802) | Loss 1.6696(1.2517) | Error 0.1332(0.0239) Steps 440(414.94) | Grad Norm 15.7808(3.3896) | Total Time 10.00(10.00)\n",
      "Iter 1381 | Time 28.6164(28.4643) | Bit/dim 1.8614(1.2311) | Xent 4.2479(0.2052) | Loss 3.9853(1.3337) | Error 0.6270(0.0419) Steps 410(414.79) | Grad Norm 39.1787(4.4633) | Total Time 10.00(10.00)\n",
      "Iter 1382 | Time 33.4419(28.6137) | Bit/dim 14.8072(1.6384) | Xent 29.9062(1.0962) | Loss 29.7603(2.1865) | Error 0.7511(0.0632) Steps 482(416.81) | Grad Norm 341.8049(14.5835) | Total Time 10.00(10.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_drop.py --data mnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_conditional_8K_drop_0_5_run1 --seed 0 --conditional True --controlled_tol True --train_mode semisup --lr 0.01 --warmup_iters 113 --atol 1e-4  --rtol 1e-4 --weight_y 0.5 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
