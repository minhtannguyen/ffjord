{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_2cond.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"colormnist\", \"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional_2cond as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, y_color, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "    y_onehot_color = thops.onehot(y_color, num_classes=model.module.y_color).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "    mean_color, logs_color = model.module._prior_color(y_onehot_color)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_color_sup = modules.GaussianDiag.logp(mean_color, logs_color, z[:, dim_sup:(2*dim_sup)]).view(-1,1)  # logp(z)_color_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, (2*dim_sup):]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_color_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "        zcolorsup = model.module.dropout_color(z[:, dim_sup:(2*dim_sup)])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "        zcolorsup = z[:, dim_sup:(2*dim_sup)]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "    \n",
      "    y_logits_color = model.module.project_color(zcolorsup)\n",
      "    loss_xent_color = model.module.loss_class(y_logits_color, y_color.to(x.get_device()))\n",
      "    y_color_predicted = np.argmax(y_logits_color.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, loss_xent_color, y_predicted, y_color_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class,\n",
      "            y_color = args.y_color)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    xent_color_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    error_color_meter = utils.RunningAverageMeter(0.97)\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        xent_color_meter.set(checkpt['xent_train_color'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        error_color_meter.set(checkpt['error_train_color'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        \n",
      "        fixed_y_color = torch.from_numpy(np.arange(model.module.y_color)).repeat(model.module.y_color).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot_color = thops.onehot(fixed_y_color, num_classes=model.module.y_color)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            mean_color, logs_color = model.module._prior_color(fixed_y_onehot_color)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_color_sup = modules.GaussianDiag.sample(mean_color, logs_color)\n",
      "            dim_unsup = np.prod(data_shape) - np.prod(fixed_z_sup.shape[1:]) - np.prod(fixed_z_color_sup.shape[1:])\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_color_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    best_error_score_color = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y_all) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            \n",
      "            y = y_all[0]\n",
      "            y_color = y_all[1]\n",
      "            \n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, loss_xent_color, y_predicted, y_color_predicted = compute_bits_per_dim_conditional(x, y, y_color, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * 0.5 * (loss_xent + loss_xent_color)\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  0.5 * (loss_xent + loss_xent_color)\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy()) \n",
      "                error_score_color = 1. - np.mean(y_color_predicted.astype(int) == y_color.numpy())\n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, loss_xent_color, error_score, error_score_color = loss, 0., 0., 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "                xent_color_meter.update(loss_xent_color.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "                xent_color_meter.update(loss_xent_color)\n",
      "            error_meter.update(error_score)\n",
      "            error_color_meter.update(error_score_color)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('xent_color', {'train_iter': xent_color_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('error_color', {'train_iter': error_color_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Xent Color {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) | Error Color {:.4f}({:.4f}) |\"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, xent_color_meter.val, xent_color_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, error_color_meter.val, error_color_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent_color', {'train_epoch': xent_color_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('error_color', {'train_epoch': error_color_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses_xent_color = []; losses = []\n",
      "                total_correct = 0\n",
      "                total_correct_color = 0\n",
      "                \n",
      "                for (x, y_all) in test_loader:\n",
      "                    y = y_all[0]\n",
      "                    y_color = y_all[1]\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, loss_xent_color, y_predicted, y_color_predicted = compute_bits_per_dim_conditional(x, y, y_color, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * 0.5 * (loss_xent + loss_xent_color)\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  0.5 * (loss_xent + loss_xent_color)\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                        total_correct_color += np.sum(y_color_predicted.astype(int) == y_color.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent, loss_xent_color = loss, 0., 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                        losses_xent_color.append(loss_xent_color.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                        losses_xent_color.append(loss_xent_color)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss_xent_color = np.mean(losses_xent_color); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                error_score_color =  1. - total_correct_color / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('xent_color', {'validation': loss_xent_color}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                writer.add_scalars('error_color', {'validation': error_score_color}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Xent Color {:.4f}. Loss {:.4f}, Error {:.4f}(best: {:.4f}), Error Color {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss_xent_color, loss, error_score, best_error_score, error_score_color, best_error_score_color)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"error_color\": error_score_color,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"xent_color\": loss_xent_color,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"best_error_score_color\": best_error_score_color,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"error_train_color\": error_color_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"xent_train_color\": xent_color_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"error_color\": error_score_color,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"xent_color\": loss_xent_color,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"best_error_score_color\": best_error_score_color,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"error_train_color\": error_color_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"xent_train_color\": xent_color_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"error_color\": error_score_color,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"xent_color\": loss_xent_color,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"best_error_score_color\": best_error_score_color,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"error_train_color\": error_color_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"xent_train_color\": xent_color_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"error_color\": error_score_color,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"xent_color\": loss_xent_color,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"best_error_score_color\": best_error_score_color,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"error_train_color\": error_color_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"xent_train_color\": xent_color_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "                    if error_score_color < best_error_score_color:\n",
      "                        best_error_score_color = error_score_color\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"error_color\": error_score_color,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"xent_color\": loss_xent_color,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"best_error_score_color\": best_error_score_color,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"error_train_color\": error_color_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"xent_train_color\": xent_color_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_color_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.16667, conditional=True, controlled_tol=False, conv=True, data='colormnist', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_colormnist_bs900_sratio_1_6th_drop_0_5_2cond_linear_run1/current_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_colormnist_bs900_sratio_1_6th_drop_0_5_2cond_linear_run1', seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n",
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=784, bias=True)\n",
      "  (project_ycond_color): LinearZeros(in_features=10, out_features=784, bias=True)\n",
      "  (project_class): LinearZeros(in_features=392, out_features=10, bias=True)\n",
      "  (project_color): LinearZeros(in_features=392, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (dropout_color): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 917222\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 1850 | Time 12.2851(13.1864) | Bit/dim 1.4067(1.5170) | Xent 0.3688(0.4321) | Xent Color 0.3019(0.6112) | Loss 1.5743(1.7779) | Error 0.1178(0.1385) | Error Color 0.1067(0.1931) |Steps 530(548.04) | Grad Norm 2.2171(6.8315) | Total Time 10.00(10.00)\n",
      "Iter 1860 | Time 12.3364(12.9304) | Bit/dim 1.3538(1.4779) | Xent 0.3738(0.4185) | Xent Color 0.2831(0.5281) | Loss 1.5180(1.7146) | Error 0.1189(0.1351) | Error Color 0.1056(0.1702) |Steps 524(542.00) | Grad Norm 6.8240(6.2171) | Total Time 10.00(10.00)\n",
      "Iter 1870 | Time 12.1938(12.7306) | Bit/dim 1.3329(1.4416) | Xent 0.3699(0.4073) | Xent Color 0.1825(0.4455) | Loss 1.4710(1.6548) | Error 0.1200(0.1312) | Error Color 0.0544(0.1432) |Steps 524(537.57) | Grad Norm 3.3105(5.6726) | Total Time 10.00(10.00)\n",
      "Iter 1880 | Time 12.0943(12.6048) | Bit/dim 1.3060(1.4090) | Xent 0.3652(0.3951) | Xent Color 0.1630(0.3699) | Loss 1.4381(1.6003) | Error 0.1256(0.1277) | Error Color 0.0456(0.1171) |Steps 524(534.01) | Grad Norm 4.1234(5.1435) | Total Time 10.00(10.00)\n",
      "Iter 1890 | Time 11.9367(12.5067) | Bit/dim 1.2939(1.3806) | Xent 0.3603(0.3877) | Xent Color 0.1202(0.3076) | Loss 1.4141(1.5545) | Error 0.1211(0.1257) | Error Color 0.0367(0.0959) |Steps 518(530.70) | Grad Norm 3.6524(4.5868) | Total Time 10.00(10.00)\n",
      "Iter 1900 | Time 12.1184(12.4158) | Bit/dim 1.2615(1.3544) | Xent 0.3431(0.3766) | Xent Color 0.1131(0.2558) | Loss 1.3755(1.5125) | Error 0.1033(0.1210) | Error Color 0.0267(0.0774) |Steps 518(527.37) | Grad Norm 3.0805(4.0349) | Total Time 10.00(10.00)\n",
      "Iter 1910 | Time 12.2190(12.3493) | Bit/dim 1.2690(1.3323) | Xent 0.3167(0.3603) | Xent Color 0.0815(0.2117) | Loss 1.3685(1.4753) | Error 0.0944(0.1157) | Error Color 0.0233(0.0617) |Steps 518(524.91) | Grad Norm 2.7072(3.5093) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 71.8475, Epoch Time 918.8447(802.3223), Bit/dim 1.2591(best: inf), Xent 0.2098, Xent Color 0.0290. Loss 1.3188, Error 0.0665(best: inf), Error Color 0.0013(best: inf)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1920 | Time 12.5380(12.3485) | Bit/dim 1.2475(1.3129) | Xent 0.3254(0.3531) | Xent Color 0.0731(0.1767) | Loss 1.3471(1.4454) | Error 0.0900(0.1128) | Error Color 0.0167(0.0496) |Steps 518(522.79) | Grad Norm 2.0344(3.0744) | Total Time 10.00(10.00)\n",
      "Iter 1930 | Time 12.2457(12.3332) | Bit/dim 1.2466(1.2953) | Xent 0.3453(0.3479) | Xent Color 0.0738(0.1506) | Loss 1.3514(1.4200) | Error 0.1089(0.1110) | Error Color 0.0122(0.0406) |Steps 518(520.73) | Grad Norm 1.6254(2.8618) | Total Time 10.00(10.00)\n",
      "Iter 1940 | Time 12.2232(12.2821) | Bit/dim 1.2332(1.2799) | Xent 0.3106(0.3409) | Xent Color 0.0692(0.1278) | Loss 1.3282(1.3971) | Error 0.1022(0.1104) | Error Color 0.0167(0.0332) |Steps 524(520.37) | Grad Norm 2.6633(2.5239) | Total Time 10.00(10.00)\n",
      "Iter 1950 | Time 12.3419(12.2811) | Bit/dim 1.2302(1.2666) | Xent 0.2969(0.3352) | Xent Color 0.0464(0.1097) | Loss 1.3160(1.3778) | Error 0.0956(0.1078) | Error Color 0.0089(0.0272) |Steps 518(520.40) | Grad Norm 1.6276(2.5063) | Total Time 10.00(10.00)\n",
      "Iter 1960 | Time 12.9765(12.3863) | Bit/dim 1.2165(1.2553) | Xent 0.3343(0.3305) | Xent Color 0.0592(0.0957) | Loss 1.3149(1.3618) | Error 0.1256(0.1068) | Error Color 0.0122(0.0228) |Steps 530(522.56) | Grad Norm 2.0827(2.4318) | Total Time 10.00(10.00)\n",
      "Iter 1970 | Time 12.6640(12.4731) | Bit/dim 1.2136(1.2435) | Xent 0.2546(0.3227) | Xent Color 0.0541(0.0849) | Loss 1.2907(1.3454) | Error 0.1000(0.1050) | Error Color 0.0089(0.0194) |Steps 542(526.91) | Grad Norm 1.8576(2.2874) | Total Time 10.00(10.00)\n",
      "Iter 1980 | Time 12.2192(12.5313) | Bit/dim 1.2059(1.2323) | Xent 0.3375(0.3173) | Xent Color 0.0596(0.0770) | Loss 1.3052(1.3309) | Error 0.1144(0.1030) | Error Color 0.0100(0.0170) |Steps 548(531.42) | Grad Norm 2.4275(2.4233) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 72.2140, Epoch Time 918.0467(805.7940), Bit/dim 1.2017(best: 1.2591), Xent 0.1790, Xent Color 0.0156. Loss 1.2503, Error 0.0587(best: 0.0665), Error Color 0.0002(best: 0.0013)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 1990 | Time 12.9723(12.6169) | Bit/dim 1.1902(1.2229) | Xent 0.3070(0.3156) | Xent Color 0.0490(0.0691) | Loss 1.2791(1.3191) | Error 0.1056(0.1022) | Error Color 0.0078(0.0146) |Steps 548(535.95) | Grad Norm 3.6883(2.5754) | Total Time 10.00(10.00)\n",
      "Iter 2000 | Time 13.3504(12.6829) | Bit/dim 1.1871(1.2160) | Xent 0.2875(0.3083) | Xent Color 0.0508(0.0636) | Loss 1.2716(1.3090) | Error 0.1000(0.1006) | Error Color 0.0133(0.0133) |Steps 548(539.40) | Grad Norm 4.8861(2.7910) | Total Time 10.00(10.00)\n",
      "Iter 2010 | Time 12.7851(12.6974) | Bit/dim 1.1870(1.2076) | Xent 0.2701(0.3002) | Xent Color 0.0389(0.0588) | Loss 1.2643(1.2973) | Error 0.0800(0.0980) | Error Color 0.0022(0.0118) |Steps 548(541.66) | Grad Norm 4.2653(2.8350) | Total Time 10.00(10.00)\n",
      "Iter 2020 | Time 12.2727(12.7242) | Bit/dim 1.1623(1.1979) | Xent 0.2915(0.2996) | Xent Color 0.0351(0.0540) | Loss 1.2440(1.2863) | Error 0.1033(0.0979) | Error Color 0.0067(0.0104) |Steps 548(543.19) | Grad Norm 2.5039(2.7214) | Total Time 10.00(10.00)\n",
      "Iter 2030 | Time 12.6358(12.7536) | Bit/dim 1.1607(1.1899) | Xent 0.2719(0.2973) | Xent Color 0.0532(0.0506) | Loss 1.2419(1.2769) | Error 0.0856(0.0964) | Error Color 0.0144(0.0095) |Steps 548(545.28) | Grad Norm 4.6900(2.7934) | Total Time 10.00(10.00)\n",
      "Iter 2040 | Time 13.0203(12.7896) | Bit/dim 1.1538(1.1827) | Xent 0.3076(0.2964) | Xent Color 0.0340(0.0470) | Loss 1.2392(1.2686) | Error 0.1033(0.0958) | Error Color 0.0044(0.0085) |Steps 548(547.71) | Grad Norm 1.7100(2.8858) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 73.5301, Epoch Time 944.1444(809.9445), Bit/dim 1.1564(best: 1.2017), Xent 0.1746, Xent Color 0.0109. Loss 1.2028, Error 0.0554(best: 0.0587), Error Color 0.0000(best: 0.0002)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2050 | Time 12.6474(12.8207) | Bit/dim 1.1675(1.1764) | Xent 0.2971(0.2957) | Xent Color 0.0428(0.0438) | Loss 1.2525(1.2613) | Error 0.0956(0.0959) | Error Color 0.0067(0.0077) |Steps 560(549.83) | Grad Norm 4.8634(2.9494) | Total Time 10.00(10.00)\n",
      "Iter 2060 | Time 12.7247(12.8203) | Bit/dim 1.1427(1.1698) | Xent 0.2820(0.2928) | Xent Color 0.0307(0.0417) | Loss 1.2209(1.2535) | Error 0.0978(0.0947) | Error Color 0.0044(0.0071) |Steps 554(551.23) | Grad Norm 3.0197(3.1173) | Total Time 10.00(10.00)\n",
      "Iter 2070 | Time 12.8241(12.8561) | Bit/dim 1.1291(1.1631) | Xent 0.2786(0.2883) | Xent Color 0.0512(0.0410) | Loss 1.2115(1.2454) | Error 0.0856(0.0933) | Error Color 0.0122(0.0073) |Steps 554(552.44) | Grad Norm 5.5253(3.5481) | Total Time 10.00(10.00)\n",
      "Iter 2080 | Time 13.2247(12.8905) | Bit/dim 1.1341(1.1584) | Xent 0.3037(0.2862) | Xent Color 0.0331(0.0385) | Loss 1.2183(1.2395) | Error 0.1000(0.0934) | Error Color 0.0078(0.0067) |Steps 560(553.95) | Grad Norm 2.9304(3.5705) | Total Time 10.00(10.00)\n",
      "Iter 2090 | Time 13.1853(12.9225) | Bit/dim 1.1271(1.1511) | Xent 0.2804(0.2838) | Xent Color 0.0270(0.0367) | Loss 1.2039(1.2312) | Error 0.0922(0.0926) | Error Color 0.0033(0.0062) |Steps 554(554.58) | Grad Norm 3.5341(3.5120) | Total Time 10.00(10.00)\n",
      "Iter 2100 | Time 13.0322(12.9500) | Bit/dim 1.1165(1.1439) | Xent 0.2787(0.2869) | Xent Color 0.0309(0.0349) | Loss 1.1939(1.2244) | Error 0.0900(0.0937) | Error Color 0.0056(0.0057) |Steps 560(555.22) | Grad Norm 4.1733(3.6139) | Total Time 10.00(10.00)\n",
      "Iter 2110 | Time 13.0236(12.9343) | Bit/dim 1.1175(1.1402) | Xent 0.2983(0.2837) | Xent Color 0.0266(0.0334) | Loss 1.1987(1.2195) | Error 0.0856(0.0917) | Error Color 0.0033(0.0052) |Steps 554(555.55) | Grad Norm 1.8633(3.5840) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 78.8788, Epoch Time 956.4509(814.3397), Bit/dim 1.1458(best: 1.1564), Xent 0.1722, Xent Color 0.1697. Loss 1.2313, Error 0.0535(best: 0.0554), Error Color 0.0631(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2120 | Time 15.1459(12.9896) | Bit/dim 2.1909(1.3426) | Xent 0.7366(0.3443) | Xent Color 1.6209(1.3006) | Loss 2.7802(1.7538) | Error 0.2256(0.1085) | Error Color 0.4822(0.1346) |Steps 650(561.36) | Grad Norm 9.8954(17.7933) | Total Time 10.00(10.00)\n",
      "Iter 2130 | Time 14.4780(13.4794) | Bit/dim 2.0673(1.5507) | Xent 0.4675(0.4156) | Xent Color 0.8377(1.2699) | Loss 2.3936(1.9720) | Error 0.1600(0.1331) | Error Color 0.3333(0.2193) |Steps 650(587.90) | Grad Norm 3.7543(15.3118) | Total Time 10.00(10.00)\n",
      "Iter 2140 | Time 13.3737(13.5156) | Bit/dim 1.9385(1.6637) | Xent 0.3789(0.4158) | Xent Color 0.5945(1.1329) | Loss 2.1819(2.0508) | Error 0.1144(0.1327) | Error Color 0.2278(0.2389) |Steps 578(591.13) | Grad Norm 4.1757(12.1884) | Total Time 10.00(10.00)\n",
      "Iter 2150 | Time 13.1309(13.4858) | Bit/dim 1.8447(1.7221) | Xent 0.3520(0.3994) | Xent Color 0.3677(0.9550) | Loss 2.0246(2.0607) | Error 0.1156(0.1271) | Error Color 0.1122(0.2176) |Steps 626(591.22) | Grad Norm 2.6312(9.5649) | Total Time 10.00(10.00)\n",
      "Iter 2160 | Time 13.7037(13.5597) | Bit/dim 1.7879(1.7449) | Xent 0.3544(0.3827) | Xent Color 0.2242(0.7731) | Loss 1.9325(2.0339) | Error 0.1144(0.1223) | Error Color 0.0456(0.1795) |Steps 602(594.41) | Grad Norm 1.8812(7.5427) | Total Time 10.00(10.00)\n",
      "Iter 2170 | Time 13.5538(13.5891) | Bit/dim 1.6957(1.7398) | Xent 0.3151(0.3663) | Xent Color 0.1537(0.6161) | Loss 1.8129(1.9854) | Error 0.1011(0.1177) | Error Color 0.0300(0.1426) |Steps 602(596.28) | Grad Norm 1.3072(5.9680) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 76.1008, Epoch Time 1006.9224(820.1172), Bit/dim 1.6539(best: 1.1458), Xent 0.2073, Xent Color 0.0655. Loss 1.7221, Error 0.0635(best: 0.0535), Error Color 0.0038(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2180 | Time 13.1002(13.5717) | Bit/dim 1.6386(1.7229) | Xent 0.3274(0.3534) | Xent Color 0.1476(0.4921) | Loss 1.7573(1.9343) | Error 0.1044(0.1131) | Error Color 0.0311(0.1135) |Steps 560(594.46) | Grad Norm 3.5340(5.2386) | Total Time 10.00(10.00)\n",
      "Iter 2190 | Time 13.4285(13.4806) | Bit/dim 1.5694(1.6883) | Xent 0.2877(0.3454) | Xent Color 0.1312(0.3981) | Loss 1.6741(1.8742) | Error 0.0900(0.1105) | Error Color 0.0322(0.0919) |Steps 578(590.45) | Grad Norm 1.5982(4.5467) | Total Time 10.00(10.00)\n",
      "Iter 2200 | Time 12.6889(13.2854) | Bit/dim 1.5014(1.6469) | Xent 0.3543(0.3308) | Xent Color 0.1088(0.3226) | Loss 1.6172(1.8102) | Error 0.1022(0.1071) | Error Color 0.0244(0.0736) |Steps 554(580.98) | Grad Norm 2.1878(3.8182) | Total Time 10.00(10.00)\n",
      "Iter 2210 | Time 12.6269(13.1212) | Bit/dim 1.4403(1.6001) | Xent 0.3258(0.3283) | Xent Color 0.1060(0.2695) | Loss 1.5482(1.7495) | Error 0.1067(0.1057) | Error Color 0.0244(0.0626) |Steps 548(573.27) | Grad Norm 4.8668(3.8481) | Total Time 10.00(10.00)\n",
      "Iter 2220 | Time 12.9866(13.0414) | Bit/dim 1.4004(1.5505) | Xent 0.2668(0.3189) | Xent Color 0.1203(0.2289) | Loss 1.4971(1.6875) | Error 0.0933(0.1023) | Error Color 0.0333(0.0539) |Steps 554(568.36) | Grad Norm 5.1510(4.2229) | Total Time 10.00(10.00)\n",
      "Iter 2230 | Time 12.8269(13.0159) | Bit/dim 1.3236(1.5016) | Xent 0.2628(0.3117) | Xent Color 0.1071(0.1949) | Loss 1.4161(1.6282) | Error 0.1000(0.1017) | Error Color 0.0244(0.0456) |Steps 554(565.05) | Grad Norm 1.0640(3.9418) | Total Time 10.00(10.00)\n",
      "Iter 2240 | Time 13.0334(12.9954) | Bit/dim 1.2934(1.4562) | Xent 0.2525(0.3042) | Xent Color 0.0954(0.1683) | Loss 1.3804(1.5743) | Error 0.0778(0.0990) | Error Color 0.0244(0.0393) |Steps 560(563.27) | Grad Norm 5.4625(3.9497) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 74.2075, Epoch Time 950.1150(824.0171), Bit/dim 1.2967(best: 1.1458), Xent 0.1755, Xent Color 0.0283. Loss 1.3476, Error 0.0546(best: 0.0535), Error Color 0.0009(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2250 | Time 13.0065(13.0112) | Bit/dim 1.2697(1.4132) | Xent 0.3096(0.3007) | Xent Color 0.0742(0.1450) | Loss 1.3657(1.5247) | Error 0.1000(0.0975) | Error Color 0.0144(0.0334) |Steps 560(562.41) | Grad Norm 1.5801(3.7344) | Total Time 10.00(10.00)\n",
      "Iter 2260 | Time 12.7454(12.9942) | Bit/dim 1.2464(1.3738) | Xent 0.2711(0.2947) | Xent Color 0.0771(0.1265) | Loss 1.3334(1.4791) | Error 0.0878(0.0961) | Error Color 0.0144(0.0287) |Steps 560(561.78) | Grad Norm 4.0872(3.4927) | Total Time 10.00(10.00)\n",
      "Iter 2270 | Time 12.5571(12.9704) | Bit/dim 1.2465(1.3395) | Xent 0.2346(0.2926) | Xent Color 0.0646(0.1117) | Loss 1.3214(1.4406) | Error 0.0789(0.0951) | Error Color 0.0078(0.0251) |Steps 560(561.31) | Grad Norm 2.6999(3.2490) | Total Time 10.00(10.00)\n",
      "Iter 2280 | Time 13.2462(12.9688) | Bit/dim 1.2190(1.3128) | Xent 0.2965(0.2858) | Xent Color 0.0952(0.1014) | Loss 1.3169(1.4096) | Error 0.0989(0.0934) | Error Color 0.0256(0.0226) |Steps 560(560.97) | Grad Norm 8.0407(3.8536) | Total Time 10.00(10.00)\n",
      "Iter 2290 | Time 13.1758(12.9919) | Bit/dim 1.2100(1.2851) | Xent 0.2777(0.2854) | Xent Color 0.0600(0.0927) | Loss 1.2944(1.3797) | Error 0.0822(0.0917) | Error Color 0.0100(0.0206) |Steps 560(560.87) | Grad Norm 4.5506(4.0069) | Total Time 10.00(10.00)\n",
      "Iter 2300 | Time 13.1352(12.9943) | Bit/dim 1.1862(1.2616) | Xent 0.2915(0.2816) | Xent Color 0.0645(0.0849) | Loss 1.2752(1.3532) | Error 0.0956(0.0902) | Error Color 0.0167(0.0187) |Steps 560(560.81) | Grad Norm 3.1382(4.0745) | Total Time 10.00(10.00)\n",
      "Iter 2310 | Time 13.0642(12.9763) | Bit/dim 1.1696(1.2411) | Xent 0.2732(0.2812) | Xent Color 0.0564(0.0776) | Loss 1.2520(1.3308) | Error 0.0922(0.0902) | Error Color 0.0122(0.0166) |Steps 560(560.76) | Grad Norm 3.4311(3.8854) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 75.5577, Epoch Time 954.4036(827.9287), Bit/dim 1.1826(best: 1.1458), Xent 0.1578, Xent Color 0.0182. Loss 1.2266, Error 0.0504(best: 0.0535), Error Color 0.0005(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2320 | Time 13.2400(12.9672) | Bit/dim 1.1731(1.2239) | Xent 0.2987(0.2773) | Xent Color 0.0578(0.0717) | Loss 1.2622(1.3111) | Error 0.0967(0.0896) | Error Color 0.0133(0.0152) |Steps 566(561.37) | Grad Norm 5.7850(4.0261) | Total Time 10.00(10.00)\n",
      "Iter 2330 | Time 13.0071(12.9708) | Bit/dim 1.1644(1.2090) | Xent 0.2800(0.2769) | Xent Color 0.0567(0.0672) | Loss 1.2486(1.2950) | Error 0.0900(0.0892) | Error Color 0.0089(0.0142) |Steps 578(563.23) | Grad Norm 8.2489(4.1549) | Total Time 10.00(10.00)\n",
      "Iter 2340 | Time 12.7080(13.0680) | Bit/dim 1.7012(1.2990) | Xent 0.4895(0.3231) | Xent Color 0.8459(0.6750) | Loss 2.0351(1.5485) | Error 0.1544(0.1048) | Error Color 0.3456(0.1139) |Steps 542(567.03) | Grad Norm 9.2375(10.4995) | Total Time 10.00(10.00)\n",
      "Iter 2350 | Time 13.8603(13.1353) | Bit/dim 1.5028(1.3816) | Xent 0.3350(0.3500) | Xent Color 0.6312(0.6752) | Loss 1.7443(1.6379) | Error 0.1133(0.1147) | Error Color 0.2744(0.1554) |Steps 602(570.72) | Grad Norm 3.3206(8.9912) | Total Time 10.00(10.00)\n",
      "Iter 2360 | Time 13.3004(13.2912) | Bit/dim 1.4047(1.3990) | Xent 0.3363(0.3459) | Xent Color 0.3796(0.6211) | Loss 1.5837(1.6408) | Error 0.1022(0.1122) | Error Color 0.1411(0.1639) |Steps 578(579.72) | Grad Norm 2.3184(7.5025) | Total Time 10.00(10.00)\n",
      "Iter 2370 | Time 13.3026(13.2684) | Bit/dim 1.3137(1.3872) | Xent 0.2931(0.3291) | Xent Color 0.3159(0.5506) | Loss 1.4660(1.6071) | Error 0.1000(0.1075) | Error Color 0.1211(0.1572) |Steps 572(578.71) | Grad Norm 3.6709(6.1362) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 75.2024, Epoch Time 973.6259(832.2996), Bit/dim 1.2786(best: 1.1458), Xent 0.1726, Xent Color 0.1566. Loss 1.3609, Error 0.0574(best: 0.0504), Error Color 0.0286(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2380 | Time 13.0928(13.2515) | Bit/dim 1.2566(1.3603) | Xent 0.3159(0.3163) | Xent Color 0.2320(0.4757) | Loss 1.3936(1.5583) | Error 0.1000(0.1028) | Error Color 0.0867(0.1417) |Steps 572(576.12) | Grad Norm 1.3299(4.9545) | Total Time 10.00(10.00)\n",
      "Iter 2390 | Time 13.2019(13.2001) | Bit/dim 1.2392(1.3292) | Xent 0.2627(0.3069) | Xent Color 0.1898(0.4050) | Loss 1.3523(1.5072) | Error 0.0833(0.0997) | Error Color 0.0544(0.1217) |Steps 572(573.87) | Grad Norm 2.0760(4.0869) | Total Time 10.00(10.00)\n",
      "Iter 2400 | Time 13.3405(13.1720) | Bit/dim 1.1898(1.2985) | Xent 0.2194(0.2904) | Xent Color 0.1404(0.3360) | Loss 1.2797(1.4551) | Error 0.0756(0.0939) | Error Color 0.0322(0.0992) |Steps 566(571.02) | Grad Norm 0.9755(3.3408) | Total Time 10.00(10.00)\n",
      "Iter 2410 | Time 13.3252(13.1602) | Bit/dim 1.2050(1.2719) | Xent 0.2525(0.2838) | Xent Color 0.0951(0.2768) | Loss 1.2919(1.4121) | Error 0.0833(0.0918) | Error Color 0.0133(0.0793) |Steps 560(568.89) | Grad Norm 1.0103(2.8336) | Total Time 10.00(10.00)\n",
      "Iter 2420 | Time 13.0709(13.1476) | Bit/dim 1.1640(1.2465) | Xent 0.2273(0.2781) | Xent Color 0.0732(0.2269) | Loss 1.2391(1.3728) | Error 0.0767(0.0903) | Error Color 0.0089(0.0629) |Steps 566(567.41) | Grad Norm 1.1471(2.4401) | Total Time 10.00(10.00)\n",
      "Iter 2430 | Time 13.2540(13.1621) | Bit/dim 1.1546(1.2244) | Xent 0.2602(0.2723) | Xent Color 0.0770(0.1889) | Loss 1.2389(1.3397) | Error 0.0667(0.0877) | Error Color 0.0122(0.0508) |Steps 560(566.52) | Grad Norm 2.1295(2.1784) | Total Time 10.00(10.00)\n",
      "Iter 2440 | Time 13.0941(13.1448) | Bit/dim 1.1428(1.2053) | Xent 0.2506(0.2692) | Xent Color 0.0700(0.1569) | Loss 1.2229(1.3118) | Error 0.0800(0.0869) | Error Color 0.0156(0.0405) |Steps 566(566.68) | Grad Norm 2.8517(2.1597) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 75.1609, Epoch Time 963.9557(836.2493), Bit/dim 1.1469(best: 1.1458), Xent 0.1588, Xent Color 0.0262. Loss 1.1931, Error 0.0523(best: 0.0504), Error Color 0.0013(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2450 | Time 12.6796(13.1278) | Bit/dim 1.1325(1.1883) | Xent 0.2493(0.2669) | Xent Color 0.0716(0.1331) | Loss 1.2127(1.2883) | Error 0.0811(0.0857) | Error Color 0.0189(0.0331) |Steps 560(566.02) | Grad Norm 1.1038(2.1004) | Total Time 10.00(10.00)\n",
      "Iter 2460 | Time 13.0327(13.1018) | Bit/dim 1.1396(1.1735) | Xent 0.2723(0.2652) | Xent Color 0.0563(0.1134) | Loss 1.2217(1.2682) | Error 0.0956(0.0855) | Error Color 0.0111(0.0268) |Steps 560(565.96) | Grad Norm 1.7294(2.0732) | Total Time 10.00(10.00)\n",
      "Iter 2470 | Time 13.3791(13.1053) | Bit/dim 1.1232(1.1602) | Xent 0.2649(0.2609) | Xent Color 0.0520(0.0982) | Loss 1.2024(1.2499) | Error 0.0833(0.0837) | Error Color 0.0078(0.0227) |Steps 566(565.35) | Grad Norm 1.1188(1.9256) | Total Time 10.00(10.00)\n",
      "Iter 2480 | Time 12.6941(13.1361) | Bit/dim 1.1159(1.1488) | Xent 0.2649(0.2600) | Xent Color 0.0461(0.0857) | Loss 1.1936(1.2352) | Error 0.0911(0.0836) | Error Color 0.0056(0.0189) |Steps 560(565.83) | Grad Norm 1.6402(1.8556) | Total Time 10.00(10.00)\n",
      "Iter 2490 | Time 13.3047(13.1676) | Bit/dim 1.1114(1.1399) | Xent 0.2302(0.2616) | Xent Color 0.0464(0.0754) | Loss 1.1806(1.2241) | Error 0.0778(0.0842) | Error Color 0.0056(0.0157) |Steps 560(566.81) | Grad Norm 2.0728(1.8222) | Total Time 10.00(10.00)\n",
      "Iter 2500 | Time 13.0785(13.2067) | Bit/dim 1.0991(1.1308) | Xent 0.2234(0.2602) | Xent Color 0.0474(0.0671) | Loss 1.1668(1.2126) | Error 0.0644(0.0845) | Error Color 0.0122(0.0135) |Steps 572(568.03) | Grad Norm 1.3360(1.8800) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 75.8571, Epoch Time 968.6859(840.2224), Bit/dim 1.1017(best: 1.1458), Xent 0.1464, Xent Color 0.0158. Loss 1.1423, Error 0.0466(best: 0.0504), Error Color 0.0002(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2510 | Time 13.1430(13.1928) | Bit/dim 1.1007(1.1245) | Xent 0.2288(0.2613) | Xent Color 0.0503(0.0620) | Loss 1.1705(1.2053) | Error 0.0844(0.0853) | Error Color 0.0100(0.0123) |Steps 572(568.78) | Grad Norm 2.3320(2.0667) | Total Time 10.00(10.00)\n",
      "Iter 2520 | Time 13.2436(13.2231) | Bit/dim 1.0727(1.1162) | Xent 0.2764(0.2564) | Xent Color 0.0527(0.0570) | Loss 1.1550(1.1945) | Error 0.0878(0.0832) | Error Color 0.0089(0.0108) |Steps 572(569.33) | Grad Norm 1.0301(2.1449) | Total Time 10.00(10.00)\n",
      "Iter 2530 | Time 13.5186(13.2492) | Bit/dim 1.0917(1.1087) | Xent 0.2536(0.2536) | Xent Color 0.0313(0.0518) | Loss 1.1629(1.1851) | Error 0.0744(0.0814) | Error Color 0.0011(0.0094) |Steps 572(570.03) | Grad Norm 2.0631(2.0618) | Total Time 10.00(10.00)\n",
      "Iter 2540 | Time 13.1466(13.2168) | Bit/dim 1.0869(1.1025) | Xent 0.2698(0.2566) | Xent Color 0.0308(0.0478) | Loss 1.1620(1.1786) | Error 0.0856(0.0828) | Error Color 0.0033(0.0082) |Steps 572(570.71) | Grad Norm 1.9031(2.0450) | Total Time 10.00(10.00)\n",
      "Iter 2550 | Time 13.1687(13.2195) | Bit/dim 1.0892(1.0977) | Xent 0.2672(0.2555) | Xent Color 0.0378(0.0451) | Loss 1.1654(1.1728) | Error 0.0778(0.0829) | Error Color 0.0033(0.0074) |Steps 578(571.55) | Grad Norm 3.3765(2.2590) | Total Time 10.00(10.00)\n",
      "Iter 2560 | Time 13.3591(13.2035) | Bit/dim 1.0690(1.0920) | Xent 0.2313(0.2506) | Xent Color 0.0353(0.0425) | Loss 1.1356(1.1653) | Error 0.0844(0.0816) | Error Color 0.0033(0.0069) |Steps 578(572.02) | Grad Norm 3.0969(2.6372) | Total Time 10.00(10.00)\n",
      "Iter 2570 | Time 12.9804(13.1876) | Bit/dim 1.0748(1.0875) | Xent 0.2170(0.2477) | Xent Color 0.0441(0.0403) | Loss 1.1401(1.1595) | Error 0.0656(0.0800) | Error Color 0.0089(0.0065) |Steps 560(571.84) | Grad Norm 4.2115(2.8493) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 76.4279, Epoch Time 972.3389(844.1859), Bit/dim 1.0679(best: 1.1017), Xent 0.1433, Xent Color 0.0092. Loss 1.1060, Error 0.0457(best: 0.0466), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2580 | Time 13.2964(13.2136) | Bit/dim 1.0673(1.0826) | Xent 0.2265(0.2421) | Xent Color 0.0320(0.0375) | Loss 1.1319(1.1525) | Error 0.0756(0.0791) | Error Color 0.0056(0.0060) |Steps 572(572.52) | Grad Norm 3.4950(2.8879) | Total Time 10.00(10.00)\n",
      "Iter 2590 | Time 13.1254(13.2376) | Bit/dim 1.0669(1.0779) | Xent 0.2127(0.2407) | Xent Color 0.0314(0.0356) | Loss 1.1279(1.1470) | Error 0.0711(0.0789) | Error Color 0.0022(0.0055) |Steps 560(573.40) | Grad Norm 3.2130(2.9088) | Total Time 10.00(10.00)\n",
      "Iter 2600 | Time 13.3281(13.2147) | Bit/dim 1.0567(1.0741) | Xent 0.2139(0.2421) | Xent Color 0.0274(0.0345) | Loss 1.1170(1.1432) | Error 0.0656(0.0786) | Error Color 0.0044(0.0052) |Steps 572(574.31) | Grad Norm 1.9123(3.0493) | Total Time 10.00(10.00)\n",
      "Iter 2610 | Time 13.4611(13.2075) | Bit/dim 1.0625(1.0692) | Xent 0.2199(0.2391) | Xent Color 0.0228(0.0334) | Loss 1.1232(1.1373) | Error 0.0689(0.0780) | Error Color 0.0033(0.0053) |Steps 572(574.30) | Grad Norm 2.2921(2.9593) | Total Time 10.00(10.00)\n",
      "Iter 2620 | Time 13.4402(13.2448) | Bit/dim 1.0636(1.0645) | Xent 0.2180(0.2385) | Xent Color 0.0195(0.0319) | Loss 1.1229(1.1321) | Error 0.0711(0.0776) | Error Color 0.0000(0.0049) |Steps 578(575.46) | Grad Norm 2.1262(2.7891) | Total Time 10.00(10.00)\n",
      "Iter 2630 | Time 13.2791(13.2688) | Bit/dim 1.0476(1.0606) | Xent 0.2033(0.2394) | Xent Color 0.0243(0.0302) | Loss 1.1045(1.1280) | Error 0.0711(0.0774) | Error Color 0.0033(0.0045) |Steps 578(576.62) | Grad Norm 6.0138(3.0123) | Total Time 10.00(10.00)\n",
      "Iter 2640 | Time 13.4608(13.2789) | Bit/dim 1.0391(1.0559) | Xent 0.2670(0.2418) | Xent Color 0.0232(0.0293) | Loss 1.1117(1.1237) | Error 0.0822(0.0782) | Error Color 0.0033(0.0043) |Steps 578(577.93) | Grad Norm 2.0040(2.9513) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 76.0119, Epoch Time 975.0863(848.1129), Bit/dim 1.0457(best: 1.0679), Xent 0.1273, Xent Color 0.0069. Loss 1.0792, Error 0.0421(best: 0.0457), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2650 | Time 13.7921(13.3123) | Bit/dim 1.0323(1.0515) | Xent 0.2744(0.2436) | Xent Color 0.0254(0.0284) | Loss 1.1073(1.1195) | Error 0.0933(0.0786) | Error Color 0.0067(0.0043) |Steps 584(577.82) | Grad Norm 3.4697(2.9427) | Total Time 10.00(10.00)\n",
      "Iter 2660 | Time 13.5980(13.3449) | Bit/dim 1.0434(1.0488) | Xent 0.2391(0.2404) | Xent Color 0.0273(0.0280) | Loss 1.1101(1.1158) | Error 0.0689(0.0770) | Error Color 0.0033(0.0044) |Steps 584(579.30) | Grad Norm 3.2175(3.0867) | Total Time 10.00(10.00)\n",
      "Iter 2670 | Time 13.3329(13.3871) | Bit/dim 1.0339(1.0436) | Xent 0.1911(0.2330) | Xent Color 0.0224(0.0273) | Loss 1.0872(1.1087) | Error 0.0589(0.0754) | Error Color 0.0022(0.0045) |Steps 584(580.51) | Grad Norm 3.6030(3.0703) | Total Time 10.00(10.00)\n",
      "Iter 2680 | Time 13.3102(13.3777) | Bit/dim 1.0319(1.0403) | Xent 0.1822(0.2284) | Xent Color 0.0215(0.0262) | Loss 1.0829(1.1040) | Error 0.0667(0.0744) | Error Color 0.0022(0.0043) |Steps 584(581.58) | Grad Norm 3.9430(3.2612) | Total Time 10.00(10.00)\n",
      "Iter 2690 | Time 13.4210(13.3512) | Bit/dim 1.0269(1.0388) | Xent 0.2234(0.2287) | Xent Color 0.0252(0.0279) | Loss 1.0891(1.1030) | Error 0.0756(0.0751) | Error Color 0.0022(0.0048) |Steps 584(581.54) | Grad Norm 4.6303(4.2073) | Total Time 10.00(10.00)\n",
      "Iter 2700 | Time 13.1487(13.3254) | Bit/dim 1.0295(1.0349) | Xent 0.1912(0.2285) | Xent Color 0.0212(0.0264) | Loss 1.0826(1.0986) | Error 0.0633(0.0745) | Error Color 0.0033(0.0045) |Steps 578(580.73) | Grad Norm 4.7112(4.2822) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 78.3293, Epoch Time 983.4084(852.1718), Bit/dim 1.0182(best: 1.0457), Xent 0.1267, Xent Color 0.0057. Loss 1.0513, Error 0.0408(best: 0.0421), Error Color 0.0001(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2710 | Time 13.2224(13.2940) | Bit/dim 1.0139(1.0316) | Xent 0.2512(0.2276) | Xent Color 0.0190(0.0255) | Loss 1.0815(1.0949) | Error 0.0756(0.0736) | Error Color 0.0022(0.0042) |Steps 584(579.70) | Grad Norm 2.4087(4.0724) | Total Time 10.00(10.00)\n",
      "Iter 2720 | Time 13.2159(13.2773) | Bit/dim 1.0153(1.0272) | Xent 0.2288(0.2288) | Xent Color 0.0194(0.0246) | Loss 1.0774(1.0905) | Error 0.0744(0.0743) | Error Color 0.0022(0.0039) |Steps 578(580.04) | Grad Norm 3.1322(3.6836) | Total Time 10.00(10.00)\n",
      "Iter 2730 | Time 15.6810(13.4234) | Bit/dim 1.8208(1.1232) | Xent 3.6306(0.4238) | Xent Color 2.2899(0.8593) | Loss 3.3010(1.4439) | Error 0.7478(0.1119) | Error Color 0.6167(0.0859) |Steps 722(588.55) | Grad Norm 35.2523(14.3173) | Total Time 10.00(10.00)\n",
      "Iter 2740 | Time 18.4385(14.2142) | Bit/dim 1.8503(1.3297) | Xent 0.5644(0.4482) | Xent Color 0.9071(1.0311) | Loss 2.2182(1.6995) | Error 0.1889(0.1268) | Error Color 0.3833(0.1803) |Steps 812(624.56) | Grad Norm 8.5289(13.5439) | Total Time 10.00(10.00)\n",
      "Iter 2750 | Time 16.6444(14.9700) | Bit/dim 1.7222(1.4446) | Xent 0.3972(0.4337) | Xent Color 0.5214(0.9463) | Loss 1.9518(1.7896) | Error 0.1233(0.1271) | Error Color 0.1944(0.2084) |Steps 722(662.32) | Grad Norm 1.9478(11.0262) | Total Time 10.00(10.00)\n",
      "Iter 2760 | Time 16.2103(15.3547) | Bit/dim 1.5855(1.4956) | Xent 0.2865(0.4070) | Xent Color 0.4133(0.8203) | Loss 1.7605(1.8025) | Error 0.0822(0.1211) | Error Color 0.1544(0.1990) |Steps 710(679.99) | Grad Norm 3.5504(8.9253) | Total Time 10.00(10.00)\n",
      "Iter 2770 | Time 16.5224(15.5635) | Bit/dim 1.4607(1.5024) | Xent 0.2921(0.3783) | Xent Color 0.2557(0.6848) | Loss 1.5976(1.7681) | Error 0.0878(0.1146) | Error Color 0.0811(0.1739) |Steps 692(685.81) | Grad Norm 1.8148(7.1807) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 82.8678, Epoch Time 1121.4191(860.2492), Bit/dim 1.4404(best: 1.0182), Xent 0.1690, Xent Color 0.1162. Loss 1.5117, Error 0.0519(best: 0.0408), Error Color 0.0109(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2780 | Time 15.3541(15.5434) | Bit/dim 1.3673(1.4782) | Xent 0.2575(0.3545) | Xent Color 0.1480(0.5555) | Loss 1.4686(1.7057) | Error 0.0789(0.1080) | Error Color 0.0389(0.1421) |Steps 668(684.30) | Grad Norm 1.2109(5.6512) | Total Time 10.00(10.00)\n",
      "Iter 2790 | Time 15.9322(15.6245) | Bit/dim 1.2772(1.4373) | Xent 0.2692(0.3368) | Xent Color 0.1039(0.4418) | Loss 1.3705(1.6320) | Error 0.0889(0.1045) | Error Color 0.0189(0.1120) |Steps 692(685.53) | Grad Norm 1.2689(4.5018) | Total Time 10.00(10.00)\n",
      "Iter 2800 | Time 14.9129(15.5460) | Bit/dim 1.2050(1.3853) | Xent 0.2729(0.3199) | Xent Color 0.1085(0.3550) | Loss 1.3003(1.5541) | Error 0.0900(0.1007) | Error Color 0.0244(0.0888) |Steps 662(682.28) | Grad Norm 0.9079(3.6086) | Total Time 10.00(10.00)\n",
      "Iter 2810 | Time 14.9422(15.4074) | Bit/dim 1.1771(1.3331) | Xent 0.2482(0.3040) | Xent Color 0.0892(0.2855) | Loss 1.2614(1.4805) | Error 0.0800(0.0961) | Error Color 0.0144(0.0700) |Steps 662(679.52) | Grad Norm 1.0149(2.9681) | Total Time 10.00(10.00)\n",
      "Iter 2820 | Time 14.7464(15.2900) | Bit/dim 1.1560(1.2872) | Xent 0.2536(0.2908) | Xent Color 0.0783(0.2312) | Loss 1.2390(1.4177) | Error 0.0856(0.0920) | Error Color 0.0100(0.0546) |Steps 662(676.43) | Grad Norm 2.4247(2.5528) | Total Time 10.00(10.00)\n",
      "Iter 2830 | Time 14.7763(15.2071) | Bit/dim 1.1156(1.2463) | Xent 0.2305(0.2796) | Xent Color 0.0629(0.1897) | Loss 1.1889(1.3637) | Error 0.0756(0.0885) | Error Color 0.0133(0.0437) |Steps 656(671.53) | Grad Norm 1.0810(2.2907) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 82.7100, Epoch Time 1108.0579(867.6835), Bit/dim 1.1079(best: 1.0182), Xent 0.1449, Xent Color 0.0229. Loss 1.1499, Error 0.0462(best: 0.0408), Error Color 0.0003(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2840 | Time 14.7901(15.0718) | Bit/dim 1.1075(1.2107) | Xent 0.2315(0.2693) | Xent Color 0.0587(0.1571) | Loss 1.1801(1.3173) | Error 0.0811(0.0855) | Error Color 0.0100(0.0348) |Steps 656(667.29) | Grad Norm 1.3294(2.0279) | Total Time 10.00(10.00)\n",
      "Iter 2850 | Time 14.4675(14.9907) | Bit/dim 1.0999(1.1812) | Xent 0.2489(0.2626) | Xent Color 0.0614(0.1315) | Loss 1.1775(1.2797) | Error 0.0833(0.0840) | Error Color 0.0122(0.0280) |Steps 650(664.41) | Grad Norm 1.3520(1.8134) | Total Time 10.00(10.00)\n",
      "Iter 2860 | Time 14.5405(14.9339) | Bit/dim 1.0732(1.1554) | Xent 0.2640(0.2610) | Xent Color 0.0526(0.1129) | Loss 1.1524(1.2489) | Error 0.0789(0.0833) | Error Color 0.0100(0.0237) |Steps 656(662.53) | Grad Norm 1.3133(1.7034) | Total Time 10.00(10.00)\n",
      "Iter 2870 | Time 14.9208(14.8786) | Bit/dim 1.0670(1.1337) | Xent 0.2412(0.2555) | Xent Color 0.0465(0.0967) | Loss 1.1389(1.2217) | Error 0.0700(0.0809) | Error Color 0.0044(0.0196) |Steps 656(660.82) | Grad Norm 1.2902(1.6335) | Total Time 10.00(10.00)\n",
      "Iter 2880 | Time 14.6718(14.8536) | Bit/dim 1.0595(1.1146) | Xent 0.2474(0.2516) | Xent Color 0.0565(0.0852) | Loss 1.1355(1.1988) | Error 0.0822(0.0799) | Error Color 0.0133(0.0167) |Steps 644(658.91) | Grad Norm 1.5985(1.6285) | Total Time 10.00(10.00)\n",
      "Iter 2890 | Time 15.0152(14.7904) | Bit/dim 1.0492(1.0998) | Xent 0.2575(0.2474) | Xent Color 0.0516(0.0755) | Loss 1.1265(1.1805) | Error 0.0867(0.0790) | Error Color 0.0111(0.0143) |Steps 644(655.76) | Grad Norm 1.6489(1.6485) | Total Time 10.00(10.00)\n",
      "Iter 2900 | Time 14.1805(14.7067) | Bit/dim 1.0468(1.0861) | Xent 0.2187(0.2435) | Xent Color 0.0498(0.0679) | Loss 1.1139(1.1640) | Error 0.0789(0.0785) | Error Color 0.0100(0.0124) |Steps 632(652.51) | Grad Norm 1.2808(1.5732) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 83.2578, Epoch Time 1075.4819(873.9174), Bit/dim 1.0431(best: 1.0182), Xent 0.1366, Xent Color 0.0133. Loss 1.0805, Error 0.0444(best: 0.0408), Error Color 0.0001(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2910 | Time 15.0429(14.6433) | Bit/dim 1.0433(1.0738) | Xent 0.2452(0.2387) | Xent Color 0.0346(0.0618) | Loss 1.1133(1.1489) | Error 0.0733(0.0762) | Error Color 0.0044(0.0111) |Steps 638(648.43) | Grad Norm 1.8591(1.5728) | Total Time 10.00(10.00)\n",
      "Iter 2920 | Time 14.2546(14.6059) | Bit/dim 1.0285(1.0635) | Xent 0.2355(0.2376) | Xent Color 0.0349(0.0557) | Loss 1.0961(1.1368) | Error 0.0678(0.0762) | Error Color 0.0033(0.0095) |Steps 638(645.58) | Grad Norm 2.5639(1.6762) | Total Time 10.00(10.00)\n",
      "Iter 2930 | Time 14.4091(14.5595) | Bit/dim 1.0109(1.0541) | Xent 0.2433(0.2365) | Xent Color 0.0344(0.0514) | Loss 1.0803(1.1261) | Error 0.0700(0.0754) | Error Color 0.0033(0.0085) |Steps 644(643.63) | Grad Norm 1.4474(1.7496) | Total Time 10.00(10.00)\n",
      "Iter 2940 | Time 14.4971(14.4963) | Bit/dim 1.0182(1.0459) | Xent 0.2042(0.2328) | Xent Color 0.0377(0.0476) | Loss 1.0787(1.1160) | Error 0.0589(0.0739) | Error Color 0.0044(0.0078) |Steps 638(640.61) | Grad Norm 2.2133(1.8557) | Total Time 10.00(10.00)\n",
      "Iter 2950 | Time 14.2510(14.4544) | Bit/dim 1.0164(1.0382) | Xent 0.2204(0.2316) | Xent Color 0.0377(0.0443) | Loss 1.0809(1.1072) | Error 0.0711(0.0735) | Error Color 0.0089(0.0069) |Steps 638(639.61) | Grad Norm 1.7705(1.8578) | Total Time 10.00(10.00)\n",
      "Iter 2960 | Time 14.5324(14.4329) | Bit/dim 1.0252(1.0325) | Xent 0.2212(0.2339) | Xent Color 0.0387(0.0417) | Loss 1.0902(1.1014) | Error 0.0622(0.0750) | Error Color 0.0044(0.0066) |Steps 632(639.00) | Grad Norm 3.2418(1.9651) | Total Time 10.00(10.00)\n",
      "Iter 2970 | Time 14.2619(14.4227) | Bit/dim 0.9936(1.0263) | Xent 0.2723(0.2332) | Xent Color 0.0296(0.0394) | Loss 1.0690(1.0945) | Error 0.0867(0.0749) | Error Color 0.0011(0.0061) |Steps 650(640.08) | Grad Norm 1.3986(1.9811) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 83.1083, Epoch Time 1056.5196(879.3955), Bit/dim 1.0056(best: 1.0182), Xent 0.1260, Xent Color 0.0092. Loss 1.0394, Error 0.0395(best: 0.0408), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 2980 | Time 14.4438(14.4431) | Bit/dim 1.0086(1.0207) | Xent 0.2241(0.2303) | Xent Color 0.0309(0.0373) | Loss 1.0724(1.0876) | Error 0.0889(0.0743) | Error Color 0.0033(0.0057) |Steps 644(640.81) | Grad Norm 2.0692(2.0437) | Total Time 10.00(10.00)\n",
      "Iter 2990 | Time 14.2288(14.4577) | Bit/dim 0.9989(1.0158) | Xent 0.2234(0.2318) | Xent Color 0.0305(0.0359) | Loss 1.0624(1.0828) | Error 0.0700(0.0743) | Error Color 0.0011(0.0053) |Steps 632(641.33) | Grad Norm 1.6427(2.1423) | Total Time 10.00(10.00)\n",
      "Iter 3000 | Time 14.3681(14.4532) | Bit/dim 0.9987(1.0118) | Xent 0.2338(0.2315) | Xent Color 0.0332(0.0347) | Loss 1.0655(1.0783) | Error 0.0756(0.0736) | Error Color 0.0044(0.0052) |Steps 644(640.60) | Grad Norm 4.2598(2.4272) | Total Time 10.00(10.00)\n",
      "Iter 3010 | Time 14.8974(14.4410) | Bit/dim 0.9861(1.0062) | Xent 0.2249(0.2293) | Xent Color 0.0311(0.0332) | Loss 1.0501(1.0719) | Error 0.0756(0.0727) | Error Color 0.0056(0.0049) |Steps 644(640.23) | Grad Norm 3.2194(2.5802) | Total Time 10.00(10.00)\n",
      "Iter 3020 | Time 14.4049(14.4495) | Bit/dim 0.9970(1.0025) | Xent 0.1722(0.2234) | Xent Color 0.0291(0.0317) | Loss 1.0473(1.0663) | Error 0.0589(0.0720) | Error Color 0.0044(0.0047) |Steps 644(641.71) | Grad Norm 1.9989(2.4790) | Total Time 10.00(10.00)\n",
      "Iter 3030 | Time 14.2169(14.4701) | Bit/dim 0.9906(0.9981) | Xent 0.1996(0.2246) | Xent Color 0.0270(0.0308) | Loss 1.0472(1.0619) | Error 0.0589(0.0714) | Error Color 0.0033(0.0045) |Steps 620(640.23) | Grad Norm 2.8004(2.3393) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 83.6228, Epoch Time 1062.8337(884.8986), Bit/dim 0.9839(best: 1.0056), Xent 0.1243, Xent Color 0.0072. Loss 1.0168, Error 0.0396(best: 0.0395), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3040 | Time 14.3623(14.4677) | Bit/dim 0.9849(0.9951) | Xent 0.2172(0.2250) | Xent Color 0.0265(0.0297) | Loss 1.0458(1.0588) | Error 0.0689(0.0716) | Error Color 0.0033(0.0042) |Steps 632(639.66) | Grad Norm 1.3078(2.7520) | Total Time 10.00(10.00)\n",
      "Iter 3050 | Time 14.4763(14.4680) | Bit/dim 0.9683(0.9908) | Xent 0.2110(0.2242) | Xent Color 0.0219(0.0287) | Loss 1.0265(1.0540) | Error 0.0644(0.0715) | Error Color 0.0011(0.0039) |Steps 644(639.00) | Grad Norm 2.5130(2.6097) | Total Time 10.00(10.00)\n",
      "Iter 3060 | Time 14.3467(14.4705) | Bit/dim 0.9780(0.9870) | Xent 0.1967(0.2220) | Xent Color 0.0261(0.0283) | Loss 1.0337(1.0496) | Error 0.0622(0.0706) | Error Color 0.0033(0.0041) |Steps 620(636.35) | Grad Norm 2.3752(2.7128) | Total Time 10.00(10.00)\n",
      "Iter 3070 | Time 14.3445(14.4833) | Bit/dim 0.9823(0.9844) | Xent 0.2115(0.2202) | Xent Color 0.0328(0.0274) | Loss 1.0434(1.0463) | Error 0.0667(0.0698) | Error Color 0.0044(0.0040) |Steps 632(635.70) | Grad Norm 2.5833(2.5998) | Total Time 10.00(10.00)\n",
      "Iter 3080 | Time 14.4066(14.4858) | Bit/dim 0.9628(0.9797) | Xent 0.2376(0.2171) | Xent Color 0.0300(0.0266) | Loss 1.0297(1.0407) | Error 0.0789(0.0695) | Error Color 0.0089(0.0038) |Steps 626(634.60) | Grad Norm 2.4955(2.9776) | Total Time 10.00(10.00)\n",
      "Iter 3090 | Time 14.4858(14.5355) | Bit/dim 0.9654(0.9761) | Xent 0.2202(0.2146) | Xent Color 0.0276(0.0265) | Loss 1.0274(1.0364) | Error 0.0689(0.0684) | Error Color 0.0056(0.0037) |Steps 620(630.06) | Grad Norm 3.1076(2.9194) | Total Time 10.00(10.00)\n",
      "Iter 3100 | Time 14.3192(14.5457) | Bit/dim 0.9745(0.9757) | Xent 0.2041(0.2110) | Xent Color 0.0175(0.0261) | Loss 1.0299(1.0350) | Error 0.0578(0.0667) | Error Color 0.0011(0.0034) |Steps 626(629.39) | Grad Norm 5.3498(3.8493) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 82.4995, Epoch Time 1065.2934(890.3105), Bit/dim 0.9644(best: 0.9839), Xent 0.1167, Xent Color 0.0052. Loss 0.9949, Error 0.0372(best: 0.0395), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3110 | Time 14.5152(14.5156) | Bit/dim 0.9641(0.9729) | Xent 0.2167(0.2095) | Xent Color 0.0165(0.0248) | Loss 1.0224(1.0315) | Error 0.0722(0.0663) | Error Color 0.0000(0.0030) |Steps 626(630.07) | Grad Norm 4.4673(3.9320) | Total Time 10.00(10.00)\n",
      "Iter 3120 | Time 14.0557(14.4316) | Bit/dim 0.9626(0.9689) | Xent 0.2203(0.2090) | Xent Color 0.0216(0.0240) | Loss 1.0231(1.0272) | Error 0.0744(0.0665) | Error Color 0.0033(0.0030) |Steps 632(627.58) | Grad Norm 2.6425(3.5899) | Total Time 10.00(10.00)\n",
      "Iter 3130 | Time 14.3740(14.3310) | Bit/dim 0.9400(0.9644) | Xent 0.2119(0.2123) | Xent Color 0.0187(0.0233) | Loss 0.9977(1.0234) | Error 0.0700(0.0675) | Error Color 0.0022(0.0030) |Steps 614(624.17) | Grad Norm 3.3336(3.3377) | Total Time 10.00(10.00)\n",
      "Iter 3140 | Time 13.9007(14.2650) | Bit/dim 0.9478(0.9615) | Xent 0.1703(0.2083) | Xent Color 0.0228(0.0227) | Loss 0.9961(1.0193) | Error 0.0611(0.0665) | Error Color 0.0022(0.0029) |Steps 614(621.74) | Grad Norm 2.2020(3.3620) | Total Time 10.00(10.00)\n",
      "Iter 3150 | Time 14.0410(14.2108) | Bit/dim 0.9529(0.9580) | Xent 0.1905(0.2068) | Xent Color 0.0191(0.0222) | Loss 1.0053(1.0152) | Error 0.0567(0.0662) | Error Color 0.0011(0.0027) |Steps 614(621.05) | Grad Norm 5.5078(3.4829) | Total Time 10.00(10.00)\n",
      "Iter 3160 | Time 13.9999(14.1764) | Bit/dim 0.9391(0.9558) | Xent 0.2410(0.2113) | Xent Color 0.0270(0.0223) | Loss 1.0061(1.0142) | Error 0.0789(0.0672) | Error Color 0.0044(0.0027) |Steps 614(618.53) | Grad Norm 5.0028(3.9748) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 82.0294, Epoch Time 1037.4268(894.7240), Bit/dim 0.9465(best: 0.9644), Xent 0.1138, Xent Color 0.0049. Loss 0.9762, Error 0.0341(best: 0.0372), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3170 | Time 14.4951(14.1483) | Bit/dim 0.9504(0.9527) | Xent 0.2538(0.2106) | Xent Color 0.0215(0.0220) | Loss 1.0193(1.0108) | Error 0.0867(0.0674) | Error Color 0.0022(0.0027) |Steps 632(617.39) | Grad Norm 3.7322(4.1754) | Total Time 10.00(10.00)\n",
      "Iter 3180 | Time 13.4646(14.1011) | Bit/dim 0.9342(0.9497) | Xent 0.2168(0.2122) | Xent Color 0.0185(0.0217) | Loss 0.9930(1.0082) | Error 0.0744(0.0680) | Error Color 0.0011(0.0028) |Steps 602(615.57) | Grad Norm 2.9381(4.3030) | Total Time 10.00(10.00)\n",
      "Iter 3190 | Time 13.3444(14.0701) | Bit/dim 0.9464(0.9476) | Xent 0.2015(0.2113) | Xent Color 0.0243(0.0210) | Loss 1.0029(1.0056) | Error 0.0656(0.0674) | Error Color 0.0022(0.0027) |Steps 602(614.85) | Grad Norm 4.8312(4.2123) | Total Time 10.00(10.00)\n",
      "Iter 3200 | Time 14.1718(14.0524) | Bit/dim 0.9357(0.9446) | Xent 0.2028(0.2070) | Xent Color 0.0182(0.0205) | Loss 0.9909(1.0015) | Error 0.0567(0.0661) | Error Color 0.0022(0.0025) |Steps 626(615.49) | Grad Norm 2.0066(3.9879) | Total Time 10.00(10.00)\n",
      "Iter 3210 | Time 14.6315(14.0500) | Bit/dim 1.1344(0.9518) | Xent 0.2268(0.2100) | Xent Color 2.3930(0.0982) | Loss 1.7894(1.0288) | Error 0.0700(0.0667) | Error Color 0.4722(0.0193) |Steps 650(616.04) | Grad Norm 93.2579(8.3987) | Total Time 10.00(10.00)\n",
      "Iter 3220 | Time 15.7058(14.4168) | Bit/dim 1.9320(1.2179) | Xent 0.3135(0.2938) | Xent Color 1.4722(1.0136) | Loss 2.3784(1.5447) | Error 0.1033(0.0917) | Error Color 0.4956(0.1806) |Steps 734(638.13) | Grad Norm 17.5339(17.3968) | Total Time 10.00(10.00)\n",
      "Iter 3230 | Time 16.3577(14.8979) | Bit/dim 1.7511(1.3757) | Xent 0.4322(0.3097) | Xent Color 0.7449(0.9882) | Loss 2.0454(1.7002) | Error 0.1378(0.0977) | Error Color 0.2844(0.2266) |Steps 728(668.14) | Grad Norm 5.2157(14.6778) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 82.7277, Epoch Time 1073.7970(900.0962), Bit/dim 1.6651(best: 0.9465), Xent 0.1714, Xent Color 0.3788. Loss 1.8026, Error 0.0555(best: 0.0341), Error Color 0.1303(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3240 | Time 14.6541(14.9575) | Bit/dim 1.5597(1.4441) | Xent 0.2941(0.3129) | Xent Color 0.4481(0.8728) | Loss 1.7453(1.7405) | Error 0.0978(0.0993) | Error Color 0.1667(0.2235) |Steps 644(669.46) | Grad Norm 2.2287(11.5226) | Total Time 10.00(10.00)\n",
      "Iter 3250 | Time 13.9979(14.7097) | Bit/dim 1.4876(1.4642) | Xent 0.2257(0.2996) | Xent Color 0.2933(0.7398) | Loss 1.6174(1.7241) | Error 0.0822(0.0956) | Error Color 0.1022(0.2003) |Steps 632(658.14) | Grad Norm 2.1384(9.1200) | Total Time 10.00(10.00)\n",
      "Iter 3260 | Time 13.2681(14.3485) | Bit/dim 1.4106(1.4572) | Xent 0.2253(0.2901) | Xent Color 0.1819(0.6031) | Loss 1.5124(1.6805) | Error 0.0733(0.0922) | Error Color 0.0567(0.1663) |Steps 584(642.02) | Grad Norm 3.1284(7.5430) | Total Time 10.00(10.00)\n",
      "Iter 3270 | Time 13.1313(14.0525) | Bit/dim 1.3505(1.4365) | Xent 0.2655(0.2781) | Xent Color 0.1304(0.4847) | Loss 1.4495(1.6272) | Error 0.0867(0.0888) | Error Color 0.0278(0.1335) |Steps 596(628.50) | Grad Norm 1.3982(6.0694) | Total Time 10.00(10.00)\n",
      "Iter 3280 | Time 13.7696(13.8882) | Bit/dim 1.2963(1.4033) | Xent 0.1986(0.2665) | Xent Color 0.1310(0.3906) | Loss 1.3787(1.5676) | Error 0.0756(0.0853) | Error Color 0.0333(0.1072) |Steps 608(624.80) | Grad Norm 1.4253(4.9130) | Total Time 10.00(10.00)\n",
      "Iter 3290 | Time 13.7286(13.8522) | Bit/dim 1.2749(1.3714) | Xent 0.2349(0.2587) | Xent Color 0.1013(0.3181) | Loss 1.3589(1.5157) | Error 0.0700(0.0831) | Error Color 0.0233(0.0868) |Steps 626(625.49) | Grad Norm 2.3064(4.1709) | Total Time 10.00(10.00)\n",
      "Iter 3300 | Time 14.1179(13.8897) | Bit/dim 1.2350(1.3385) | Xent 0.2081(0.2480) | Xent Color 0.1069(0.2638) | Loss 1.3137(1.4665) | Error 0.0644(0.0800) | Error Color 0.0300(0.0717) |Steps 626(626.36) | Grad Norm 3.6510(4.2774) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 81.3081, Epoch Time 1010.6618(903.4131), Bit/dim 1.2380(best: 0.9465), Xent 0.1278, Xent Color 0.0417. Loss 1.2803, Error 0.0408(best: 0.0341), Error Color 0.0025(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3310 | Time 14.3410(13.8932) | Bit/dim 1.2020(1.3073) | Xent 0.2174(0.2425) | Xent Color 0.1035(0.2189) | Loss 1.2823(1.4226) | Error 0.0733(0.0781) | Error Color 0.0267(0.0587) |Steps 632(627.57) | Grad Norm 3.7174(3.9010) | Total Time 10.00(10.00)\n",
      "Iter 3320 | Time 14.0498(13.9189) | Bit/dim 1.1683(1.2755) | Xent 0.2181(0.2375) | Xent Color 0.0795(0.1831) | Loss 1.2427(1.3806) | Error 0.0756(0.0765) | Error Color 0.0167(0.0480) |Steps 632(628.56) | Grad Norm 2.2106(3.4202) | Total Time 10.00(10.00)\n",
      "Iter 3330 | Time 14.0985(13.9048) | Bit/dim 1.1570(1.2478) | Xent 0.2801(0.2337) | Xent Color 0.0827(0.1541) | Loss 1.2476(1.3448) | Error 0.0944(0.0760) | Error Color 0.0189(0.0391) |Steps 626(629.12) | Grad Norm 3.7177(3.2003) | Total Time 10.00(10.00)\n",
      "Iter 3340 | Time 13.7022(13.9064) | Bit/dim 1.1441(1.2214) | Xent 0.2119(0.2282) | Xent Color 0.0616(0.1332) | Loss 1.2125(1.3118) | Error 0.0678(0.0742) | Error Color 0.0100(0.0334) |Steps 632(630.01) | Grad Norm 1.9059(3.0610) | Total Time 10.00(10.00)\n",
      "Iter 3350 | Time 14.6291(14.0031) | Bit/dim 1.1488(1.1970) | Xent 0.2129(0.2236) | Xent Color 0.0639(0.1178) | Loss 1.2180(1.2824) | Error 0.0700(0.0729) | Error Color 0.0200(0.0297) |Steps 620(631.30) | Grad Norm 6.3241(3.4324) | Total Time 10.00(10.00)\n",
      "Iter 3360 | Time 14.4215(14.0905) | Bit/dim 1.1135(1.1733) | Xent 0.2186(0.2229) | Xent Color 0.0547(0.1044) | Loss 1.1819(1.2551) | Error 0.0756(0.0734) | Error Color 0.0111(0.0258) |Steps 638(633.82) | Grad Norm 3.6119(3.4119) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 81.2027, Epoch Time 1032.9533(907.2993), Bit/dim 1.0796(best: 0.9465), Xent 0.1191, Xent Color 0.0206. Loss 1.1145, Error 0.0379(best: 0.0341), Error Color 0.0009(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3370 | Time 14.3050(14.1141) | Bit/dim 1.0819(1.1503) | Xent 0.1607(0.2221) | Xent Color 0.0615(0.0910) | Loss 1.1375(1.2286) | Error 0.0544(0.0731) | Error Color 0.0156(0.0216) |Steps 644(636.15) | Grad Norm 2.3607(3.0484) | Total Time 10.00(10.00)\n",
      "Iter 3380 | Time 14.0402(14.1212) | Bit/dim 1.0521(1.1277) | Xent 0.2000(0.2175) | Xent Color 0.0512(0.0810) | Loss 1.1150(1.2023) | Error 0.0689(0.0710) | Error Color 0.0122(0.0186) |Steps 614(634.85) | Grad Norm 1.6446(2.9213) | Total Time 10.00(10.00)\n",
      "Iter 3390 | Time 14.1547(14.1399) | Bit/dim 1.0436(1.1067) | Xent 0.2415(0.2169) | Xent Color 0.0459(0.0716) | Loss 1.1155(1.1788) | Error 0.0833(0.0711) | Error Color 0.0067(0.0157) |Steps 626(634.01) | Grad Norm 2.4179(2.7388) | Total Time 10.00(10.00)\n",
      "Iter 3400 | Time 13.8866(14.1367) | Bit/dim 1.0307(1.0878) | Xent 0.2122(0.2159) | Xent Color 0.0425(0.0642) | Loss 1.0944(1.1579) | Error 0.0711(0.0700) | Error Color 0.0067(0.0137) |Steps 626(632.63) | Grad Norm 1.6554(2.4740) | Total Time 10.00(10.00)\n",
      "Iter 3410 | Time 14.6235(14.1124) | Bit/dim 1.0216(1.0699) | Xent 0.2270(0.2140) | Xent Color 0.0411(0.0587) | Loss 1.0886(1.1381) | Error 0.0700(0.0692) | Error Color 0.0056(0.0122) |Steps 644(631.85) | Grad Norm 2.8397(2.4986) | Total Time 10.00(10.00)\n",
      "Iter 3420 | Time 13.6335(14.0512) | Bit/dim 1.0000(1.0541) | Xent 0.1815(0.2121) | Xent Color 0.0299(0.0533) | Loss 1.0528(1.1204) | Error 0.0500(0.0682) | Error Color 0.0044(0.0106) |Steps 620(630.26) | Grad Norm 1.2634(2.5536) | Total Time 10.00(10.00)\n",
      "Iter 3430 | Time 13.7880(14.0209) | Bit/dim 0.9999(1.0403) | Xent 0.1962(0.2092) | Xent Color 0.0453(0.0501) | Loss 1.0603(1.1052) | Error 0.0589(0.0678) | Error Color 0.0111(0.0099) |Steps 626(628.62) | Grad Norm 5.0455(2.8963) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 80.5546, Epoch Time 1032.1425(911.0446), Bit/dim 0.9956(best: 0.9465), Xent 0.1186, Xent Color 0.0101. Loss 1.0277, Error 0.0379(best: 0.0341), Error Color 0.0001(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3440 | Time 13.8028(14.0136) | Bit/dim 0.9937(1.0280) | Xent 0.1723(0.2087) | Xent Color 0.0369(0.0474) | Loss 1.0460(1.0920) | Error 0.0511(0.0672) | Error Color 0.0056(0.0093) |Steps 626(626.15) | Grad Norm 4.5034(3.0199) | Total Time 10.00(10.00)\n",
      "Iter 3450 | Time 14.5403(14.0103) | Bit/dim 0.9805(1.0174) | Xent 0.2486(0.2073) | Xent Color 0.0379(0.0450) | Loss 1.0521(1.0805) | Error 0.0733(0.0671) | Error Color 0.0067(0.0086) |Steps 638(623.58) | Grad Norm 3.9137(3.2758) | Total Time 10.00(10.00)\n",
      "Iter 3460 | Time 14.2579(13.9853) | Bit/dim 0.9741(1.0081) | Xent 0.1905(0.2067) | Xent Color 0.0426(0.0416) | Loss 1.0324(1.0702) | Error 0.0578(0.0663) | Error Color 0.0056(0.0077) |Steps 614(621.36) | Grad Norm 3.9863(3.3564) | Total Time 10.00(10.00)\n",
      "Iter 3470 | Time 14.2037(13.9667) | Bit/dim 0.9522(0.9980) | Xent 0.2036(0.2075) | Xent Color 0.0295(0.0390) | Loss 1.0105(1.0596) | Error 0.0644(0.0663) | Error Color 0.0056(0.0070) |Steps 620(618.55) | Grad Norm 2.1178(3.2936) | Total Time 10.00(10.00)\n",
      "Iter 3480 | Time 13.2972(13.9331) | Bit/dim 1.0205(0.9922) | Xent 0.2072(0.2059) | Xent Color 1.0026(0.0765) | Loss 1.3229(1.0628) | Error 0.0578(0.0651) | Error Color 0.2567(0.0186) |Steps 602(617.02) | Grad Norm 59.3821(6.2956) | Total Time 10.00(10.00)\n",
      "Iter 3490 | Time 15.3323(14.1089) | Bit/dim 1.2445(1.0801) | Xent 0.2982(0.2384) | Xent Color 0.2950(0.4302) | Loss 1.3928(1.2472) | Error 0.0989(0.0767) | Error Color 0.1044(0.1028) |Steps 680(625.21) | Grad Norm 4.1610(9.0373) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 79.7722, Epoch Time 1037.6673(914.8433), Bit/dim 1.1874(best: 0.9465), Xent 0.1260, Xent Color 0.1246. Loss 1.2501, Error 0.0416(best: 0.0341), Error Color 0.0120(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3500 | Time 14.4331(14.3090) | Bit/dim 1.1604(1.1139) | Xent 0.2223(0.2362) | Xent Color 0.1949(0.4045) | Loss 1.2647(1.2740) | Error 0.0667(0.0765) | Error Color 0.0556(0.1092) |Steps 632(634.71) | Grad Norm 2.9064(7.7808) | Total Time 10.00(10.00)\n",
      "Iter 3510 | Time 14.6119(14.3353) | Bit/dim 1.0800(1.1165) | Xent 0.2469(0.2327) | Xent Color 0.1307(0.3394) | Loss 1.1744(1.2595) | Error 0.0833(0.0759) | Error Color 0.0344(0.0927) |Steps 644(634.32) | Grad Norm 1.6455(6.3408) | Total Time 10.00(10.00)\n",
      "Iter 3520 | Time 13.9463(14.2779) | Bit/dim 1.0386(1.1018) | Xent 0.1755(0.2273) | Xent Color 0.1068(0.2798) | Loss 1.1091(1.2286) | Error 0.0622(0.0738) | Error Color 0.0256(0.0764) |Steps 584(629.25) | Grad Norm 1.5581(5.1007) | Total Time 10.00(10.00)\n",
      "Iter 3530 | Time 13.6357(14.0377) | Bit/dim 0.9970(1.0793) | Xent 0.1934(0.2249) | Xent Color 0.0928(0.2299) | Loss 1.0686(1.1930) | Error 0.0667(0.0731) | Error Color 0.0244(0.0616) |Steps 602(617.38) | Grad Norm 1.2543(4.0781) | Total Time 10.00(10.00)\n",
      "Iter 3540 | Time 13.4121(13.9012) | Bit/dim 0.9750(1.0568) | Xent 0.2429(0.2177) | Xent Color 0.0601(0.1876) | Loss 1.0507(1.1581) | Error 0.0833(0.0696) | Error Color 0.0111(0.0486) |Steps 602(612.44) | Grad Norm 1.0903(3.2575) | Total Time 10.00(10.00)\n",
      "Iter 3550 | Time 13.7074(13.8354) | Bit/dim 0.9649(1.0356) | Xent 0.2314(0.2150) | Xent Color 0.0604(0.1532) | Loss 1.0379(1.1276) | Error 0.0611(0.0687) | Error Color 0.0100(0.0384) |Steps 608(609.88) | Grad Norm 1.0827(2.6721) | Total Time 10.00(10.00)\n",
      "Iter 3560 | Time 13.6871(13.8346) | Bit/dim 0.9596(1.0181) | Xent 0.1940(0.2116) | Xent Color 0.0560(0.1267) | Loss 1.0221(1.1027) | Error 0.0689(0.0678) | Error Color 0.0122(0.0304) |Steps 614(610.71) | Grad Norm 1.2103(2.2365) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 79.4709, Epoch Time 1015.1301(917.8519), Bit/dim 0.9563(best: 0.9465), Xent 0.1104, Xent Color 0.0166. Loss 0.9880, Error 0.0343(best: 0.0341), Error Color 0.0003(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3570 | Time 13.8681(13.8348) | Bit/dim 0.9594(1.0016) | Xent 0.1846(0.2100) | Xent Color 0.0478(0.1061) | Loss 1.0175(1.0806) | Error 0.0567(0.0666) | Error Color 0.0089(0.0249) |Steps 614(611.90) | Grad Norm 0.7398(1.8936) | Total Time 10.00(10.00)\n",
      "Iter 3580 | Time 13.7687(13.8749) | Bit/dim 0.9325(0.9868) | Xent 0.1797(0.2054) | Xent Color 0.0351(0.0900) | Loss 0.9862(1.0606) | Error 0.0600(0.0664) | Error Color 0.0011(0.0205) |Steps 626(613.89) | Grad Norm 0.8990(1.6630) | Total Time 10.00(10.00)\n",
      "Iter 3590 | Time 13.7618(13.8799) | Bit/dim 0.9344(0.9756) | Xent 0.2058(0.2024) | Xent Color 0.0405(0.0765) | Loss 0.9959(1.0453) | Error 0.0733(0.0663) | Error Color 0.0100(0.0166) |Steps 626(616.27) | Grad Norm 1.4921(1.5288) | Total Time 10.00(10.00)\n",
      "Iter 3600 | Time 13.8737(13.8794) | Bit/dim 0.9455(0.9662) | Xent 0.2118(0.1993) | Xent Color 0.0351(0.0657) | Loss 1.0073(1.0324) | Error 0.0611(0.0651) | Error Color 0.0056(0.0137) |Steps 614(617.54) | Grad Norm 2.0387(1.5222) | Total Time 10.00(10.00)\n",
      "Iter 3610 | Time 14.0744(13.9069) | Bit/dim 0.9366(0.9575) | Xent 0.2138(0.2003) | Xent Color 0.0340(0.0572) | Loss 0.9985(1.0218) | Error 0.0711(0.0654) | Error Color 0.0056(0.0112) |Steps 620(619.03) | Grad Norm 1.7234(1.5465) | Total Time 10.00(10.00)\n",
      "Iter 3620 | Time 14.1929(13.9062) | Bit/dim 0.9289(0.9501) | Xent 0.1926(0.1993) | Xent Color 0.0306(0.0509) | Loss 0.9847(1.0126) | Error 0.0689(0.0649) | Error Color 0.0022(0.0098) |Steps 626(620.38) | Grad Norm 1.2007(1.4209) | Total Time 10.00(10.00)\n",
      "Iter 3630 | Time 14.2828(13.9769) | Bit/dim 0.9235(0.9432) | Xent 0.1855(0.1974) | Xent Color 0.0324(0.0459) | Loss 0.9780(1.0041) | Error 0.0656(0.0640) | Error Color 0.0056(0.0084) |Steps 626(621.14) | Grad Norm 1.1246(1.2848) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 82.3100, Epoch Time 1027.4829(921.1408), Bit/dim 0.9225(best: 0.9465), Xent 0.1029, Xent Color 0.0082. Loss 0.9503, Error 0.0319(best: 0.0341), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3640 | Time 14.1086(14.0047) | Bit/dim 0.9243(0.9374) | Xent 0.2329(0.1999) | Xent Color 0.0259(0.0412) | Loss 0.9890(0.9976) | Error 0.0767(0.0641) | Error Color 0.0044(0.0073) |Steps 626(622.41) | Grad Norm 3.1073(1.3865) | Total Time 10.00(10.00)\n",
      "Iter 3650 | Time 14.1638(14.0451) | Bit/dim 0.9165(0.9328) | Xent 0.1845(0.1974) | Xent Color 0.0248(0.0377) | Loss 0.9688(0.9916) | Error 0.0556(0.0634) | Error Color 0.0033(0.0064) |Steps 620(623.34) | Grad Norm 1.5403(1.7158) | Total Time 10.00(10.00)\n",
      "Iter 3660 | Time 13.8762(14.0494) | Bit/dim 0.9045(0.9294) | Xent 0.1868(0.1955) | Xent Color 0.0323(0.0355) | Loss 0.9593(0.9871) | Error 0.0622(0.0624) | Error Color 0.0067(0.0059) |Steps 620(623.82) | Grad Norm 3.5054(1.8320) | Total Time 10.00(10.00)\n",
      "Iter 3670 | Time 13.5585(14.0532) | Bit/dim 0.9157(0.9257) | Xent 0.1720(0.1940) | Xent Color 0.0272(0.0327) | Loss 0.9656(0.9823) | Error 0.0567(0.0622) | Error Color 0.0022(0.0052) |Steps 626(623.95) | Grad Norm 1.4735(1.8997) | Total Time 10.00(10.00)\n",
      "Iter 3680 | Time 13.9440(14.0352) | Bit/dim 0.9092(0.9211) | Xent 0.2076(0.1926) | Xent Color 0.0262(0.0306) | Loss 0.9676(0.9769) | Error 0.0656(0.0616) | Error Color 0.0033(0.0047) |Steps 626(623.20) | Grad Norm 1.3222(1.8007) | Total Time 10.00(10.00)\n",
      "Iter 3690 | Time 14.1839(14.0891) | Bit/dim 0.9257(0.9180) | Xent 0.2085(0.1929) | Xent Color 0.0265(0.0289) | Loss 0.9845(0.9734) | Error 0.0644(0.0628) | Error Color 0.0044(0.0043) |Steps 620(623.21) | Grad Norm 5.6298(2.1353) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 79.4473, Epoch Time 1033.8750(924.5229), Bit/dim 0.9073(best: 0.9225), Xent 0.1007, Xent Color 0.0057. Loss 0.9339, Error 0.0326(best: 0.0319), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3700 | Time 14.2168(14.0947) | Bit/dim 0.9078(0.9145) | Xent 0.1771(0.1909) | Xent Color 0.0168(0.0274) | Loss 0.9563(0.9690) | Error 0.0600(0.0622) | Error Color 0.0000(0.0039) |Steps 620(621.90) | Grad Norm 1.3995(2.2605) | Total Time 10.00(10.00)\n",
      "Iter 3710 | Time 13.7904(14.0458) | Bit/dim 0.9060(0.9114) | Xent 0.2273(0.1916) | Xent Color 0.0255(0.0260) | Loss 0.9692(0.9658) | Error 0.0656(0.0621) | Error Color 0.0033(0.0036) |Steps 620(620.63) | Grad Norm 3.0357(2.1570) | Total Time 10.00(10.00)\n",
      "Iter 3720 | Time 14.2747(14.0120) | Bit/dim 0.8883(0.9088) | Xent 0.1637(0.1884) | Xent Color 0.0274(0.0247) | Loss 0.9360(0.9620) | Error 0.0533(0.0619) | Error Color 0.0067(0.0035) |Steps 614(619.38) | Grad Norm 3.8905(2.2820) | Total Time 10.00(10.00)\n",
      "Iter 3730 | Time 14.0684(14.0247) | Bit/dim 0.9085(0.9066) | Xent 0.1970(0.1856) | Xent Color 0.0172(0.0238) | Loss 0.9621(0.9590) | Error 0.0589(0.0602) | Error Color 0.0011(0.0033) |Steps 614(618.61) | Grad Norm 3.0428(2.5362) | Total Time 10.00(10.00)\n",
      "Iter 3740 | Time 13.6578(13.9767) | Bit/dim 0.8966(0.9032) | Xent 0.1798(0.1872) | Xent Color 0.0178(0.0226) | Loss 0.9460(0.9557) | Error 0.0644(0.0606) | Error Color 0.0011(0.0030) |Steps 608(618.07) | Grad Norm 2.5057(2.5790) | Total Time 10.00(10.00)\n",
      "Iter 3750 | Time 14.0927(13.9631) | Bit/dim 0.8919(0.9001) | Xent 0.1813(0.1855) | Xent Color 0.0219(0.0216) | Loss 0.9427(0.9518) | Error 0.0667(0.0601) | Error Color 0.0033(0.0027) |Steps 608(617.22) | Grad Norm 1.6690(2.3989) | Total Time 10.00(10.00)\n",
      "Iter 3760 | Time 14.1119(13.9411) | Bit/dim 0.8881(0.8976) | Xent 0.1618(0.1845) | Xent Color 0.0163(0.0208) | Loss 0.9326(0.9490) | Error 0.0489(0.0595) | Error Color 0.0011(0.0026) |Steps 620(617.56) | Grad Norm 1.3535(2.6746) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 77.4677, Epoch Time 1020.7474(927.4096), Bit/dim 0.8958(best: 0.9073), Xent 0.0988, Xent Color 0.0042. Loss 0.9215, Error 0.0316(best: 0.0319), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3770 | Time 13.6811(13.9382) | Bit/dim 0.9028(0.8957) | Xent 0.2119(0.1845) | Xent Color 0.0160(0.0200) | Loss 0.9597(0.9468) | Error 0.0678(0.0593) | Error Color 0.0011(0.0025) |Steps 608(616.10) | Grad Norm 3.9024(2.7867) | Total Time 10.00(10.00)\n",
      "Iter 3780 | Time 13.6811(13.9116) | Bit/dim 0.8896(0.8934) | Xent 0.2224(0.1855) | Xent Color 0.0244(0.0199) | Loss 0.9513(0.9447) | Error 0.0700(0.0588) | Error Color 0.0044(0.0027) |Steps 590(612.19) | Grad Norm 2.1471(2.8405) | Total Time 10.00(10.00)\n",
      "Iter 3790 | Time 13.7430(13.8941) | Bit/dim 0.8862(0.8917) | Xent 0.1782(0.1841) | Xent Color 0.0149(0.0192) | Loss 0.9345(0.9425) | Error 0.0567(0.0579) | Error Color 0.0011(0.0024) |Steps 602(609.62) | Grad Norm 4.1285(2.9139) | Total Time 10.00(10.00)\n",
      "Iter 3800 | Time 13.9878(13.9000) | Bit/dim 0.8792(0.8899) | Xent 0.2198(0.1852) | Xent Color 0.0144(0.0187) | Loss 0.9378(0.9409) | Error 0.0633(0.0578) | Error Color 0.0011(0.0024) |Steps 602(608.57) | Grad Norm 2.1139(3.0028) | Total Time 10.00(10.00)\n",
      "Iter 3810 | Time 13.6565(13.8871) | Bit/dim 0.8701(0.8856) | Xent 0.1554(0.1781) | Xent Color 0.0117(0.0181) | Loss 0.9118(0.9346) | Error 0.0489(0.0556) | Error Color 0.0000(0.0023) |Steps 608(607.38) | Grad Norm 3.6130(2.8736) | Total Time 10.00(10.00)\n",
      "Iter 3820 | Time 14.2251(13.9118) | Bit/dim 0.8703(0.8844) | Xent 0.1958(0.1743) | Xent Color 0.0168(0.0179) | Loss 0.9235(0.9324) | Error 0.0578(0.0544) | Error Color 0.0044(0.0024) |Steps 608(606.93) | Grad Norm 3.1184(3.3242) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 77.2896, Epoch Time 1017.3780(930.1087), Bit/dim 0.8738(best: 0.8958), Xent 0.0913, Xent Color 0.0034. Loss 0.8975, Error 0.0300(best: 0.0316), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3830 | Time 13.6994(13.9018) | Bit/dim 0.8715(0.8827) | Xent 0.2008(0.1767) | Xent Color 0.0220(0.0175) | Loss 0.9272(0.9313) | Error 0.0667(0.0556) | Error Color 0.0033(0.0024) |Steps 602(606.62) | Grad Norm 2.3547(3.0815) | Total Time 10.00(10.00)\n",
      "Iter 3840 | Time 13.3234(13.9109) | Bit/dim 0.8875(0.8817) | Xent 0.1658(0.1750) | Xent Color 0.0257(0.0178) | Loss 0.9353(0.9299) | Error 0.0467(0.0548) | Error Color 0.0044(0.0024) |Steps 596(606.32) | Grad Norm 9.2719(3.4594) | Total Time 10.00(10.00)\n",
      "Iter 3850 | Time 14.0369(13.9096) | Bit/dim 0.8759(0.8803) | Xent 0.1905(0.1735) | Xent Color 0.0158(0.0171) | Loss 0.9275(0.9279) | Error 0.0600(0.0544) | Error Color 0.0022(0.0022) |Steps 614(606.16) | Grad Norm 4.2621(3.6890) | Total Time 10.00(10.00)\n",
      "Iter 3860 | Time 14.1458(13.8883) | Bit/dim 0.8770(0.8780) | Xent 0.1755(0.1757) | Xent Color 0.0175(0.0166) | Loss 0.9253(0.9261) | Error 0.0633(0.0561) | Error Color 0.0022(0.0022) |Steps 614(605.37) | Grad Norm 3.1641(3.7903) | Total Time 10.00(10.00)\n",
      "Iter 3870 | Time 14.2882(13.9073) | Bit/dim 0.8575(0.8752) | Xent 0.1670(0.1771) | Xent Color 0.0158(0.0161) | Loss 0.9032(0.9235) | Error 0.0611(0.0573) | Error Color 0.0011(0.0020) |Steps 632(606.25) | Grad Norm 5.9240(3.8769) | Total Time 10.00(10.00)\n",
      "Iter 3880 | Time 13.9043(13.9095) | Bit/dim 0.8783(0.8736) | Xent 0.2014(0.1806) | Xent Color 0.0109(0.0158) | Loss 0.9314(0.9227) | Error 0.0678(0.0579) | Error Color 0.0000(0.0021) |Steps 614(608.08) | Grad Norm 6.7791(4.0894) | Total Time 10.00(10.00)\n",
      "Iter 3890 | Time 13.7345(13.9232) | Bit/dim 0.8901(0.8741) | Xent 0.1658(0.1783) | Xent Color 0.0211(0.0157) | Loss 0.9368(0.9226) | Error 0.0600(0.0571) | Error Color 0.0022(0.0021) |Steps 590(607.52) | Grad Norm 8.1421(4.3700) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 76.8269, Epoch Time 1019.4191(932.7880), Bit/dim 0.8704(best: 0.8738), Xent 0.0912, Xent Color 0.0038. Loss 0.8942, Error 0.0297(best: 0.0300), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3900 | Time 13.5241(13.9033) | Bit/dim 0.8492(0.8724) | Xent 0.1911(0.1789) | Xent Color 0.0131(0.0154) | Loss 0.9002(0.9209) | Error 0.0644(0.0569) | Error Color 0.0011(0.0020) |Steps 596(606.62) | Grad Norm 4.5980(4.3664) | Total Time 10.00(10.00)\n",
      "Iter 3910 | Time 14.0640(13.8907) | Bit/dim 0.8659(0.8713) | Xent 0.1545(0.1759) | Xent Color 0.0099(0.0151) | Loss 0.9071(0.9190) | Error 0.0478(0.0555) | Error Color 0.0011(0.0020) |Steps 614(606.88) | Grad Norm 3.1060(4.4980) | Total Time 10.00(10.00)\n",
      "Iter 3920 | Time 14.2920(13.9086) | Bit/dim 0.8589(0.8702) | Xent 0.1776(0.1753) | Xent Color 0.0143(0.0148) | Loss 0.9069(0.9177) | Error 0.0511(0.0552) | Error Color 0.0011(0.0017) |Steps 614(605.07) | Grad Norm 3.3639(4.5485) | Total Time 10.00(10.00)\n",
      "Iter 3930 | Time 13.9095(13.9376) | Bit/dim 0.8699(0.8675) | Xent 0.1733(0.1763) | Xent Color 0.0147(0.0145) | Loss 0.9169(0.9152) | Error 0.0567(0.0553) | Error Color 0.0044(0.0018) |Steps 596(605.50) | Grad Norm 5.2295(4.3280) | Total Time 10.00(10.00)\n",
      "Iter 3940 | Time 13.6483(13.9303) | Bit/dim 0.8524(0.8657) | Xent 0.1516(0.1715) | Xent Color 0.0137(0.0143) | Loss 0.8938(0.9121) | Error 0.0589(0.0552) | Error Color 0.0011(0.0017) |Steps 596(604.94) | Grad Norm 2.5215(4.4681) | Total Time 10.00(10.00)\n",
      "Iter 3950 | Time 14.0409(13.8802) | Bit/dim 0.8426(0.8626) | Xent 0.1792(0.1721) | Xent Color 0.0097(0.0135) | Loss 0.8899(0.9089) | Error 0.0656(0.0559) | Error Color 0.0000(0.0014) |Steps 602(603.45) | Grad Norm 1.2490(4.2344) | Total Time 10.00(10.00)\n",
      "Iter 3960 | Time 13.9031(13.8968) | Bit/dim 0.9065(0.8659) | Xent 0.1974(0.1711) | Xent Color 0.1887(0.0210) | Loss 1.0030(0.9139) | Error 0.0733(0.0552) | Error Color 0.0744(0.0046) |Steps 614(601.89) | Grad Norm 26.5852(5.8329) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 77.5239, Epoch Time 1017.7261(935.3361), Bit/dim 1.0523(best: 0.8704), Xent 0.1000, Xent Color 1.8498. Loss 1.5397, Error 0.0316(best: 0.0297), Error Color 0.2738(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 3970 | Time 15.0116(14.0568) | Bit/dim 1.5798(1.0295) | Xent 0.3449(0.2516) | Xent Color 0.3035(0.6486) | Loss 1.7419(1.2546) | Error 0.0933(0.0799) | Error Color 0.1100(0.1119) |Steps 668(613.31) | Grad Norm 6.4554(12.9282) | Total Time 10.00(10.00)\n",
      "Iter 3980 | Time 14.8655(14.2019) | Bit/dim 1.3365(1.1470) | Xent 0.2858(0.2684) | Xent Color 0.2309(0.5501) | Loss 1.4656(1.3517) | Error 0.0900(0.0837) | Error Color 0.0878(0.1086) |Steps 656(623.13) | Grad Norm 2.8570(10.8544) | Total Time 10.00(10.00)\n",
      "Iter 3990 | Time 14.6131(14.3264) | Bit/dim 1.1969(1.1785) | Xent 0.2052(0.2647) | Xent Color 0.1403(0.4483) | Loss 1.2833(1.3567) | Error 0.0656(0.0835) | Error Color 0.0422(0.0932) |Steps 644(629.57) | Grad Norm 2.2484(8.6906) | Total Time 10.00(10.00)\n",
      "Iter 4000 | Time 14.2022(14.2513) | Bit/dim 1.1063(1.1699) | Xent 0.2411(0.2544) | Xent Color 0.0872(0.3556) | Loss 1.1884(1.3224) | Error 0.0756(0.0803) | Error Color 0.0178(0.0746) |Steps 614(626.68) | Grad Norm 1.1518(6.8669) | Total Time 10.00(10.00)\n",
      "Iter 4010 | Time 13.3983(14.0915) | Bit/dim 1.0380(1.1426) | Xent 0.1786(0.2416) | Xent Color 0.0673(0.2818) | Loss 1.0995(1.2734) | Error 0.0589(0.0767) | Error Color 0.0144(0.0587) |Steps 584(619.08) | Grad Norm 0.8057(5.4012) | Total Time 10.00(10.00)\n",
      "Iter 4020 | Time 13.5126(13.9185) | Bit/dim 0.9898(1.1077) | Xent 0.1961(0.2306) | Xent Color 0.0690(0.2250) | Loss 1.0561(1.2216) | Error 0.0622(0.0731) | Error Color 0.0111(0.0466) |Steps 578(609.85) | Grad Norm 1.3628(4.3039) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 76.0953, Epoch Time 1028.2234(938.1227), Bit/dim 0.9646(best: 0.8704), Xent 0.1093, Xent Color 0.0189. Loss 0.9966, Error 0.0335(best: 0.0297), Error Color 0.0004(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4030 | Time 13.3298(13.7486) | Bit/dim 0.9588(1.0711) | Xent 0.2277(0.2217) | Xent Color 0.0529(0.1800) | Loss 1.0289(1.1715) | Error 0.0689(0.0703) | Error Color 0.0067(0.0366) |Steps 584(602.58) | Grad Norm 1.5210(3.5407) | Total Time 10.00(10.00)\n",
      "Iter 4040 | Time 13.5904(13.6827) | Bit/dim 0.9232(1.0368) | Xent 0.1396(0.2122) | Xent Color 0.0454(0.1457) | Loss 0.9695(1.1263) | Error 0.0467(0.0682) | Error Color 0.0089(0.0294) |Steps 596(598.30) | Grad Norm 1.4198(2.8728) | Total Time 10.00(10.00)\n",
      "Iter 4050 | Time 13.9968(13.7335) | Bit/dim 0.9220(1.0061) | Xent 0.1756(0.2040) | Xent Color 0.0459(0.1189) | Loss 0.9773(1.0868) | Error 0.0467(0.0653) | Error Color 0.0122(0.0232) |Steps 596(598.39) | Grad Norm 1.3725(2.4327) | Total Time 10.00(10.00)\n",
      "Iter 4060 | Time 13.8976(13.7851) | Bit/dim 0.8990(0.9813) | Xent 0.1677(0.2005) | Xent Color 0.0376(0.0985) | Loss 0.9503(1.0560) | Error 0.0578(0.0647) | Error Color 0.0056(0.0188) |Steps 602(598.48) | Grad Norm 1.0158(2.0976) | Total Time 10.00(10.00)\n",
      "Iter 4070 | Time 14.0375(13.8382) | Bit/dim 0.8936(0.9600) | Xent 0.1563(0.2002) | Xent Color 0.0386(0.0828) | Loss 0.9424(1.0308) | Error 0.0522(0.0641) | Error Color 0.0044(0.0154) |Steps 602(600.06) | Grad Norm 0.8624(1.8499) | Total Time 10.00(10.00)\n",
      "Iter 4080 | Time 14.0142(13.8468) | Bit/dim 0.8910(0.9416) | Xent 0.2138(0.1961) | Xent Color 0.0300(0.0699) | Loss 0.9520(1.0081) | Error 0.0689(0.0633) | Error Color 0.0022(0.0126) |Steps 608(602.01) | Grad Norm 2.7650(1.8121) | Total Time 10.00(10.00)\n",
      "Iter 4090 | Time 14.1754(13.8759) | Bit/dim 0.8803(0.9266) | Xent 0.2079(0.1914) | Xent Color 0.0349(0.0599) | Loss 0.9410(0.9894) | Error 0.0711(0.0613) | Error Color 0.0056(0.0105) |Steps 614(603.42) | Grad Norm 2.5470(1.9284) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 78.8705, Epoch Time 1013.6432(940.3883), Bit/dim 0.8781(best: 0.8704), Xent 0.1011, Xent Color 0.0088. Loss 0.9056, Error 0.0324(best: 0.0297), Error Color 0.0002(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4100 | Time 13.5853(13.8101) | Bit/dim 0.8758(0.9147) | Xent 0.1577(0.1886) | Xent Color 0.0293(0.0523) | Loss 0.9226(0.9749) | Error 0.0567(0.0600) | Error Color 0.0044(0.0090) |Steps 608(604.45) | Grad Norm 3.2941(2.0954) | Total Time 10.00(10.00)\n",
      "Iter 4110 | Time 13.7555(13.7895) | Bit/dim 0.8698(0.9040) | Xent 0.1789(0.1878) | Xent Color 0.0277(0.0461) | Loss 0.9214(0.9625) | Error 0.0633(0.0593) | Error Color 0.0022(0.0076) |Steps 602(605.21) | Grad Norm 1.7631(2.0251) | Total Time 10.00(10.00)\n",
      "Iter 4120 | Time 13.9115(13.7709) | Bit/dim 0.8791(0.8955) | Xent 0.1523(0.1845) | Xent Color 0.0249(0.0415) | Loss 0.9234(0.9520) | Error 0.0500(0.0588) | Error Color 0.0000(0.0066) |Steps 608(605.45) | Grad Norm 6.6266(2.3669) | Total Time 10.00(10.00)\n",
      "Iter 4130 | Time 13.4924(13.7828) | Bit/dim 0.8643(0.8878) | Xent 0.1734(0.1821) | Xent Color 0.0274(0.0377) | Loss 0.9145(0.9428) | Error 0.0533(0.0583) | Error Color 0.0056(0.0061) |Steps 602(605.63) | Grad Norm 2.6307(2.6158) | Total Time 10.00(10.00)\n",
      "Iter 4140 | Time 13.6625(13.7582) | Bit/dim 0.8626(0.8809) | Xent 0.1901(0.1793) | Xent Color 0.0205(0.0347) | Loss 0.9153(0.9344) | Error 0.0700(0.0580) | Error Color 0.0033(0.0056) |Steps 608(606.67) | Grad Norm 2.9748(2.6102) | Total Time 10.00(10.00)\n",
      "Iter 4150 | Time 13.6317(13.7591) | Bit/dim 0.8565(0.8749) | Xent 0.2124(0.1786) | Xent Color 0.0253(0.0326) | Loss 0.9159(0.9277) | Error 0.0622(0.0571) | Error Color 0.0056(0.0052) |Steps 608(606.90) | Grad Norm 2.1732(2.7591) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 80.0149, Epoch Time 1009.2439(942.4540), Bit/dim 0.8558(best: 0.8704), Xent 0.0936, Xent Color 0.0049. Loss 0.8804, Error 0.0297(best: 0.0297), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4160 | Time 13.4606(13.7569) | Bit/dim 0.8560(0.8707) | Xent 0.1908(0.1788) | Xent Color 0.0239(0.0299) | Loss 0.9097(0.9228) | Error 0.0644(0.0575) | Error Color 0.0044(0.0046) |Steps 608(607.18) | Grad Norm 3.9993(2.8825) | Total Time 10.00(10.00)\n",
      "Iter 4170 | Time 13.6552(13.7230) | Bit/dim 0.8534(0.8660) | Xent 0.1612(0.1751) | Xent Color 0.0153(0.0274) | Loss 0.8976(0.9166) | Error 0.0578(0.0562) | Error Color 0.0000(0.0041) |Steps 608(606.79) | Grad Norm 2.7246(2.7640) | Total Time 10.00(10.00)\n",
      "Iter 4180 | Time 14.0372(13.7310) | Bit/dim 0.8456(0.8611) | Xent 0.1584(0.1736) | Xent Color 0.0149(0.0257) | Loss 0.8890(0.9109) | Error 0.0578(0.0558) | Error Color 0.0000(0.0037) |Steps 608(607.25) | Grad Norm 2.6215(2.5413) | Total Time 10.00(10.00)\n",
      "Iter 4190 | Time 13.4855(13.7243) | Bit/dim 0.8491(0.8589) | Xent 0.1657(0.1740) | Xent Color 0.0176(0.0242) | Loss 0.8949(0.9085) | Error 0.0589(0.0561) | Error Color 0.0022(0.0033) |Steps 608(607.34) | Grad Norm 4.1215(3.1303) | Total Time 10.00(10.00)\n",
      "Iter 4200 | Time 13.7297(13.7433) | Bit/dim 0.8443(0.8562) | Xent 0.1303(0.1706) | Xent Color 0.0180(0.0228) | Loss 0.8814(0.9045) | Error 0.0356(0.0546) | Error Color 0.0011(0.0029) |Steps 596(606.13) | Grad Norm 1.3897(3.0281) | Total Time 10.00(10.00)\n",
      "Iter 4210 | Time 14.0277(13.7640) | Bit/dim 0.8387(0.8528) | Xent 0.1720(0.1688) | Xent Color 0.0196(0.0220) | Loss 0.8866(0.9005) | Error 0.0511(0.0542) | Error Color 0.0022(0.0027) |Steps 608(606.01) | Grad Norm 1.6506(2.8163) | Total Time 10.00(10.00)\n",
      "Iter 4220 | Time 13.5768(13.7750) | Bit/dim 0.8362(0.8493) | Xent 0.1623(0.1675) | Xent Color 0.0207(0.0213) | Loss 0.8820(0.8965) | Error 0.0433(0.0536) | Error Color 0.0022(0.0026) |Steps 590(605.51) | Grad Norm 3.3700(2.7750) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 78.0317, Epoch Time 1009.6307(944.4693), Bit/dim 0.8401(best: 0.8558), Xent 0.0911, Xent Color 0.0037. Loss 0.8638, Error 0.0292(best: 0.0297), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4230 | Time 13.6002(13.8072) | Bit/dim 0.8515(0.8474) | Xent 0.1786(0.1660) | Xent Color 0.0158(0.0204) | Loss 0.9001(0.8940) | Error 0.0600(0.0530) | Error Color 0.0022(0.0026) |Steps 608(605.81) | Grad Norm 4.9980(3.1756) | Total Time 10.00(10.00)\n",
      "Iter 4240 | Time 14.0800(13.8296) | Bit/dim 0.8261(0.8439) | Xent 0.1808(0.1665) | Xent Color 0.0149(0.0198) | Loss 0.8751(0.8905) | Error 0.0567(0.0528) | Error Color 0.0022(0.0025) |Steps 584(604.59) | Grad Norm 3.6064(3.2717) | Total Time 10.00(10.00)\n",
      "Iter 4250 | Time 13.9419(13.8335) | Bit/dim 0.8407(0.8421) | Xent 0.1666(0.1675) | Xent Color 0.0141(0.0190) | Loss 0.8859(0.8887) | Error 0.0489(0.0532) | Error Color 0.0000(0.0023) |Steps 602(602.91) | Grad Norm 5.4681(3.4157) | Total Time 10.00(10.00)\n",
      "Iter 4260 | Time 13.5755(13.8254) | Bit/dim 0.8376(0.8414) | Xent 0.1567(0.1679) | Xent Color 0.0176(0.0189) | Loss 0.8812(0.8881) | Error 0.0489(0.0529) | Error Color 0.0022(0.0022) |Steps 584(600.99) | Grad Norm 4.3961(3.9462) | Total Time 10.00(10.00)\n",
      "Iter 4270 | Time 14.1794(13.8492) | Bit/dim 0.8437(0.8407) | Xent 0.1877(0.1691) | Xent Color 0.0166(0.0187) | Loss 0.8948(0.8876) | Error 0.0522(0.0529) | Error Color 0.0033(0.0023) |Steps 584(598.64) | Grad Norm 7.3943(4.2018) | Total Time 10.00(10.00)\n",
      "Iter 4280 | Time 13.6018(13.7819) | Bit/dim 0.8324(0.8385) | Xent 0.1784(0.1672) | Xent Color 0.0124(0.0177) | Loss 0.8801(0.8847) | Error 0.0567(0.0524) | Error Color 0.0011(0.0020) |Steps 578(597.32) | Grad Norm 3.6643(4.1419) | Total Time 10.00(10.00)\n",
      "Iter 4290 | Time 13.0906(13.7411) | Bit/dim 0.8733(0.8398) | Xent 0.1852(0.1647) | Xent Color 0.0218(0.0175) | Loss 0.9250(0.8854) | Error 0.0600(0.0523) | Error Color 0.0056(0.0021) |Steps 578(595.03) | Grad Norm 11.7707(4.7977) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 80.9844, Epoch Time 1014.3563(946.5659), Bit/dim 0.8320(best: 0.8401), Xent 0.0866, Xent Color 0.0035. Loss 0.8545, Error 0.0290(best: 0.0292), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4300 | Time 13.4175(13.6527) | Bit/dim 0.8309(0.8411) | Xent 0.1512(0.1656) | Xent Color 0.0182(0.0175) | Loss 0.8732(0.8868) | Error 0.0511(0.0522) | Error Color 0.0011(0.0021) |Steps 590(593.85) | Grad Norm 3.9951(5.1851) | Total Time 10.00(10.00)\n",
      "Iter 4310 | Time 13.3002(13.5924) | Bit/dim 0.8252(0.8404) | Xent 0.1341(0.1630) | Xent Color 0.0142(0.0167) | Loss 0.8623(0.8853) | Error 0.0422(0.0515) | Error Color 0.0011(0.0021) |Steps 590(592.01) | Grad Norm 1.6505(5.1318) | Total Time 10.00(10.00)\n",
      "Iter 4320 | Time 13.8232(13.5315) | Bit/dim 0.8259(0.8381) | Xent 0.1390(0.1614) | Xent Color 0.0139(0.0161) | Loss 0.8642(0.8825) | Error 0.0444(0.0508) | Error Color 0.0022(0.0019) |Steps 596(589.63) | Grad Norm 3.6513(4.8782) | Total Time 10.00(10.00)\n",
      "Iter 4330 | Time 13.4738(13.4353) | Bit/dim 0.8164(0.8349) | Xent 0.1794(0.1612) | Xent Color 0.0128(0.0152) | Loss 0.8644(0.8790) | Error 0.0533(0.0503) | Error Color 0.0000(0.0017) |Steps 584(585.51) | Grad Norm 3.1655(4.3560) | Total Time 10.00(10.00)\n",
      "Iter 4340 | Time 13.5327(13.4451) | Bit/dim 0.8242(0.8305) | Xent 0.1622(0.1628) | Xent Color 0.0144(0.0150) | Loss 0.8683(0.8750) | Error 0.0522(0.0508) | Error Color 0.0022(0.0017) |Steps 578(583.86) | Grad Norm 3.4324(3.9179) | Total Time 10.00(10.00)\n",
      "Iter 4350 | Time 13.8877(13.4355) | Bit/dim 0.8178(0.8276) | Xent 0.1601(0.1617) | Xent Color 0.0142(0.0149) | Loss 0.8614(0.8718) | Error 0.0489(0.0508) | Error Color 0.0033(0.0018) |Steps 590(584.07) | Grad Norm 5.0752(3.8112) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 77.8360, Epoch Time 985.8151(947.7434), Bit/dim 0.8456(best: 0.8320), Xent 0.0852, Xent Color 0.0051. Loss 0.8682, Error 0.0279(best: 0.0290), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4360 | Time 13.3021(13.4961) | Bit/dim 0.8337(0.8344) | Xent 0.1602(0.1602) | Xent Color 0.0172(0.0201) | Loss 0.8780(0.8795) | Error 0.0489(0.0501) | Error Color 0.0022(0.0036) |Steps 578(585.30) | Grad Norm 4.3197(5.7787) | Total Time 10.00(10.00)\n",
      "Iter 4370 | Time 13.7307(13.5309) | Bit/dim 0.8281(0.8363) | Xent 0.1762(0.1577) | Xent Color 0.0137(0.0194) | Loss 0.8756(0.8806) | Error 0.0544(0.0494) | Error Color 0.0022(0.0034) |Steps 602(587.00) | Grad Norm 6.0008(6.2791) | Total Time 10.00(10.00)\n",
      "Iter 4380 | Time 13.6093(13.5938) | Bit/dim 0.8335(0.8339) | Xent 0.1788(0.1586) | Xent Color 0.0117(0.0176) | Loss 0.8811(0.8780) | Error 0.0544(0.0504) | Error Color 0.0000(0.0027) |Steps 584(588.53) | Grad Norm 3.2942(5.9294) | Total Time 10.00(10.00)\n",
      "Iter 4390 | Time 13.1599(13.5675) | Bit/dim 0.8185(0.8294) | Xent 0.1590(0.1577) | Xent Color 0.0116(0.0162) | Loss 0.8611(0.8728) | Error 0.0522(0.0498) | Error Color 0.0000(0.0022) |Steps 590(588.90) | Grad Norm 2.7258(5.0720) | Total Time 10.00(10.00)\n",
      "Iter 4400 | Time 13.8293(13.5881) | Bit/dim 0.8180(0.8255) | Xent 0.1547(0.1580) | Xent Color 0.0142(0.0151) | Loss 0.8603(0.8687) | Error 0.0478(0.0502) | Error Color 0.0033(0.0020) |Steps 614(590.74) | Grad Norm 5.7465(4.7058) | Total Time 10.00(10.00)\n",
      "Iter 4410 | Time 13.8160(13.5626) | Bit/dim 0.8161(0.8234) | Xent 0.1882(0.1532) | Xent Color 0.0114(0.0144) | Loss 0.8660(0.8653) | Error 0.0700(0.0490) | Error Color 0.0022(0.0019) |Steps 590(591.12) | Grad Norm 2.7316(4.7202) | Total Time 10.00(10.00)\n",
      "Iter 4420 | Time 13.7578(13.5757) | Bit/dim 0.8071(0.8210) | Xent 0.1458(0.1570) | Xent Color 0.0174(0.0141) | Loss 0.8479(0.8638) | Error 0.0489(0.0497) | Error Color 0.0022(0.0019) |Steps 608(592.91) | Grad Norm 3.3135(4.7053) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 79.0923, Epoch Time 1000.5862(949.3287), Bit/dim 0.8124(best: 0.8320), Xent 0.0812, Xent Color 0.0019. Loss 0.8331, Error 0.0268(best: 0.0279), Error Color 0.0001(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4430 | Time 13.2647(13.6104) | Bit/dim 0.8198(0.8184) | Xent 0.1252(0.1546) | Xent Color 0.0094(0.0137) | Loss 0.8534(0.8605) | Error 0.0433(0.0489) | Error Color 0.0000(0.0019) |Steps 590(594.56) | Grad Norm 4.8638(4.6153) | Total Time 10.00(10.00)\n",
      "Iter 4440 | Time 13.4172(13.6145) | Bit/dim 0.8136(0.8162) | Xent 0.1443(0.1562) | Xent Color 0.0134(0.0131) | Loss 0.8530(0.8586) | Error 0.0500(0.0497) | Error Color 0.0033(0.0018) |Steps 590(594.67) | Grad Norm 2.6291(4.5602) | Total Time 10.00(10.00)\n",
      "Iter 4450 | Time 13.5493(13.6699) | Bit/dim 0.8085(0.8145) | Xent 0.1637(0.1562) | Xent Color 0.0110(0.0126) | Loss 0.8522(0.8568) | Error 0.0500(0.0491) | Error Color 0.0000(0.0017) |Steps 602(596.78) | Grad Norm 4.8404(4.5748) | Total Time 10.00(10.00)\n",
      "Iter 4460 | Time 13.6192(13.6960) | Bit/dim 0.8170(0.8136) | Xent 0.1361(0.1553) | Xent Color 0.0092(0.0120) | Loss 0.8533(0.8554) | Error 0.0511(0.0491) | Error Color 0.0000(0.0014) |Steps 602(599.02) | Grad Norm 4.5640(4.6444) | Total Time 10.00(10.00)\n",
      "Iter 4470 | Time 13.9854(13.7342) | Bit/dim 0.7942(0.8107) | Xent 0.1297(0.1541) | Xent Color 0.0095(0.0116) | Loss 0.8290(0.8522) | Error 0.0411(0.0488) | Error Color 0.0000(0.0013) |Steps 608(599.98) | Grad Norm 3.9015(4.4949) | Total Time 10.00(10.00)\n",
      "Iter 4480 | Time 14.0315(13.7191) | Bit/dim 0.8198(0.8176) | Xent 0.1310(0.1499) | Xent Color 0.0128(0.0140) | Loss 0.8558(0.8586) | Error 0.0467(0.0474) | Error Color 0.0011(0.0019) |Steps 608(600.02) | Grad Norm 6.5315(6.1677) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 83.1298, Epoch Time 1012.4409(951.2220), Bit/dim 0.8591(best: 0.8124), Xent 0.0871, Xent Color 0.0057. Loss 0.8823, Error 0.0276(best: 0.0268), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4490 | Time 13.7504(13.7090) | Bit/dim 0.8193(0.8241) | Xent 0.1510(0.1507) | Xent Color 0.0137(0.0157) | Loss 0.8604(0.8657) | Error 0.0411(0.0476) | Error Color 0.0022(0.0025) |Steps 596(600.86) | Grad Norm 4.4783(7.0487) | Total Time 10.00(10.00)\n",
      "Iter 4500 | Time 13.7276(13.7269) | Bit/dim 0.8269(0.8253) | Xent 0.1438(0.1478) | Xent Color 0.0148(0.0159) | Loss 0.8665(0.8662) | Error 0.0478(0.0470) | Error Color 0.0022(0.0025) |Steps 602(600.11) | Grad Norm 9.0930(7.3203) | Total Time 10.00(10.00)\n",
      "Iter 4510 | Time 13.8680(13.6983) | Bit/dim 0.8073(0.8221) | Xent 0.1785(0.1485) | Xent Color 0.0137(0.0153) | Loss 0.8554(0.8631) | Error 0.0622(0.0474) | Error Color 0.0022(0.0024) |Steps 614(599.07) | Grad Norm 6.5120(7.1197) | Total Time 10.00(10.00)\n",
      "Iter 4520 | Time 13.3261(13.6768) | Bit/dim 0.7936(0.8173) | Xent 0.1230(0.1497) | Xent Color 0.0105(0.0141) | Loss 0.8269(0.8582) | Error 0.0422(0.0474) | Error Color 0.0011(0.0022) |Steps 596(599.41) | Grad Norm 3.7744(6.2998) | Total Time 10.00(10.00)\n",
      "Iter 4530 | Time 13.8741(13.7351) | Bit/dim 0.7956(0.8128) | Xent 0.1652(0.1495) | Xent Color 0.0123(0.0131) | Loss 0.8399(0.8534) | Error 0.0489(0.0476) | Error Color 0.0022(0.0019) |Steps 608(600.87) | Grad Norm 5.6459(5.6098) | Total Time 10.00(10.00)\n",
      "Iter 4540 | Time 13.6944(13.7075) | Bit/dim 0.8110(0.8133) | Xent 0.1440(0.1506) | Xent Color 0.0076(0.0124) | Loss 0.8489(0.8540) | Error 0.0411(0.0470) | Error Color 0.0000(0.0017) |Steps 596(600.36) | Grad Norm 6.9606(5.8957) | Total Time 10.00(10.00)\n",
      "Iter 4550 | Time 13.7860(13.6820) | Bit/dim 0.8002(0.8099) | Xent 0.1848(0.1503) | Xent Color 0.0093(0.0120) | Loss 0.8487(0.8505) | Error 0.0589(0.0466) | Error Color 0.0000(0.0017) |Steps 602(599.08) | Grad Norm 6.5668(5.6688) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 82.1212, Epoch Time 1009.9066(952.9826), Bit/dim 0.7936(best: 0.8124), Xent 0.0779, Xent Color 0.0013. Loss 0.8134, Error 0.0248(best: 0.0268), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4560 | Time 13.0323(13.6806) | Bit/dim 0.8004(0.8062) | Xent 0.1500(0.1463) | Xent Color 0.0135(0.0113) | Loss 0.8413(0.8456) | Error 0.0467(0.0461) | Error Color 0.0033(0.0014) |Steps 596(599.76) | Grad Norm 4.6061(5.3156) | Total Time 10.00(10.00)\n",
      "Iter 4570 | Time 14.0775(13.7390) | Bit/dim 0.7989(0.8045) | Xent 0.1562(0.1479) | Xent Color 0.0095(0.0110) | Loss 0.8404(0.8442) | Error 0.0467(0.0473) | Error Color 0.0000(0.0014) |Steps 614(603.07) | Grad Norm 3.4825(5.3169) | Total Time 10.00(10.00)\n",
      "Iter 4580 | Time 13.6770(13.7862) | Bit/dim 0.8073(0.8044) | Xent 0.1613(0.1484) | Xent Color 0.0070(0.0105) | Loss 0.8494(0.8441) | Error 0.0567(0.0482) | Error Color 0.0011(0.0013) |Steps 602(603.95) | Grad Norm 3.7594(5.5563) | Total Time 10.00(10.00)\n",
      "Iter 4590 | Time 14.2210(13.7881) | Bit/dim 0.7868(0.8007) | Xent 0.1385(0.1474) | Xent Color 0.0084(0.0101) | Loss 0.8235(0.8401) | Error 0.0511(0.0475) | Error Color 0.0011(0.0012) |Steps 614(602.74) | Grad Norm 3.1922(5.2238) | Total Time 10.00(10.00)\n",
      "Iter 4600 | Time 13.3707(13.7964) | Bit/dim 0.8189(0.7994) | Xent 0.1647(0.1470) | Xent Color 0.0094(0.0098) | Loss 0.8624(0.8386) | Error 0.0467(0.0460) | Error Color 0.0022(0.0011) |Steps 590(604.01) | Grad Norm 10.2617(5.3579) | Total Time 10.00(10.00)\n",
      "Iter 4610 | Time 13.7149(13.8291) | Bit/dim 0.7995(0.7992) | Xent 0.1479(0.1444) | Xent Color 0.0097(0.0097) | Loss 0.8389(0.8377) | Error 0.0456(0.0456) | Error Color 0.0000(0.0011) |Steps 578(603.86) | Grad Norm 6.2968(5.3778) | Total Time 10.00(10.00)\n",
      "Iter 4620 | Time 14.0742(13.8451) | Bit/dim 0.7856(0.7969) | Xent 0.1262(0.1434) | Xent Color 0.0061(0.0093) | Loss 0.8187(0.8351) | Error 0.0400(0.0450) | Error Color 0.0000(0.0009) |Steps 596(603.83) | Grad Norm 5.4621(5.1073) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 81.9266, Epoch Time 1019.7909(954.9868), Bit/dim 0.7905(best: 0.7936), Xent 0.0752, Xent Color 0.0016. Loss 0.8097, Error 0.0249(best: 0.0248), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4630 | Time 13.3555(13.8406) | Bit/dim 0.8146(0.7980) | Xent 0.1574(0.1420) | Xent Color 0.0071(0.0093) | Loss 0.8557(0.8359) | Error 0.0511(0.0446) | Error Color 0.0000(0.0009) |Steps 596(604.05) | Grad Norm 9.5587(5.7101) | Total Time 10.00(10.00)\n",
      "Iter 4640 | Time 14.4107(13.8787) | Bit/dim 0.7869(0.7951) | Xent 0.1926(0.1439) | Xent Color 0.0116(0.0092) | Loss 0.8380(0.8333) | Error 0.0611(0.0457) | Error Color 0.0022(0.0009) |Steps 614(604.67) | Grad Norm 3.4941(5.1946) | Total Time 10.00(10.00)\n",
      "Iter 4650 | Time 13.4313(13.8524) | Bit/dim 0.8075(0.7966) | Xent 0.1298(0.1447) | Xent Color 0.0095(0.0095) | Loss 0.8423(0.8351) | Error 0.0367(0.0456) | Error Color 0.0000(0.0010) |Steps 608(603.94) | Grad Norm 7.5349(5.8032) | Total Time 10.00(10.00)\n",
      "Iter 4660 | Time 13.7369(13.8429) | Bit/dim 0.7929(0.7950) | Xent 0.1512(0.1451) | Xent Color 0.0060(0.0092) | Loss 0.8322(0.8336) | Error 0.0567(0.0460) | Error Color 0.0000(0.0009) |Steps 584(601.36) | Grad Norm 6.6750(5.7006) | Total Time 10.00(10.00)\n",
      "Iter 4670 | Time 13.3084(13.8294) | Bit/dim 0.7849(0.7923) | Xent 0.1357(0.1450) | Xent Color 0.0054(0.0088) | Loss 0.8202(0.8308) | Error 0.0444(0.0454) | Error Color 0.0000(0.0007) |Steps 608(602.34) | Grad Norm 2.8775(5.3813) | Total Time 10.00(10.00)\n",
      "Iter 4680 | Time 14.0901(13.8639) | Bit/dim 0.7771(0.7902) | Xent 0.1555(0.1459) | Xent Color 0.0067(0.0086) | Loss 0.8176(0.8288) | Error 0.0567(0.0455) | Error Color 0.0000(0.0007) |Steps 602(603.66) | Grad Norm 4.3436(5.1535) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 81.2591, Epoch Time 1019.1913(956.9130), Bit/dim 0.7749(best: 0.7905), Xent 0.0747, Xent Color 0.0015. Loss 0.7940, Error 0.0241(best: 0.0248), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4690 | Time 13.7378(13.8443) | Bit/dim 0.8045(0.7880) | Xent 0.1482(0.1454) | Xent Color 0.0108(0.0088) | Loss 0.8442(0.8265) | Error 0.0433(0.0453) | Error Color 0.0011(0.0009) |Steps 584(603.80) | Grad Norm 9.9543(5.1109) | Total Time 10.00(10.00)\n",
      "Iter 4700 | Time 13.7321(13.8259) | Bit/dim 0.8002(0.7902) | Xent 0.1310(0.1425) | Xent Color 0.0093(0.0098) | Loss 0.8352(0.8283) | Error 0.0378(0.0439) | Error Color 0.0011(0.0013) |Steps 590(603.93) | Grad Norm 7.3742(6.1072) | Total Time 10.00(10.00)\n",
      "Iter 4710 | Time 13.4574(13.7743) | Bit/dim 0.7838(0.7889) | Xent 0.1613(0.1423) | Xent Color 0.0067(0.0093) | Loss 0.8257(0.8268) | Error 0.0533(0.0446) | Error Color 0.0000(0.0011) |Steps 608(603.30) | Grad Norm 3.9053(5.8727) | Total Time 10.00(10.00)\n",
      "Iter 4720 | Time 13.6778(13.7356) | Bit/dim 0.7756(0.7881) | Xent 0.1247(0.1435) | Xent Color 0.0082(0.0088) | Loss 0.8088(0.8262) | Error 0.0344(0.0447) | Error Color 0.0011(0.0010) |Steps 602(602.96) | Grad Norm 3.8742(5.7624) | Total Time 10.00(10.00)\n",
      "Iter 4730 | Time 13.7583(13.7771) | Bit/dim 0.7746(0.7854) | Xent 0.1302(0.1422) | Xent Color 0.0105(0.0086) | Loss 0.8098(0.8231) | Error 0.0478(0.0445) | Error Color 0.0011(0.0009) |Steps 602(602.44) | Grad Norm 5.5568(5.6761) | Total Time 10.00(10.00)\n",
      "Iter 4740 | Time 13.4370(13.7490) | Bit/dim 0.8250(0.7940) | Xent 0.1937(0.1454) | Xent Color 0.0097(0.0093) | Loss 0.8758(0.8327) | Error 0.0478(0.0452) | Error Color 0.0022(0.0012) |Steps 596(601.37) | Grad Norm 8.1075(6.7103) | Total Time 10.00(10.00)\n",
      "Iter 4750 | Time 13.5427(13.7207) | Bit/dim 0.8007(0.7958) | Xent 0.1373(0.1386) | Xent Color 0.0079(0.0090) | Loss 0.8370(0.8327) | Error 0.0367(0.0430) | Error Color 0.0011(0.0010) |Steps 596(598.98) | Grad Norm 8.0190(6.6826) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 78.1238, Epoch Time 1005.9389(958.3837), Bit/dim 0.7912(best: 0.7749), Xent 0.0741, Xent Color 0.0011. Loss 0.8100, Error 0.0248(best: 0.0241), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4760 | Time 13.8349(13.6570) | Bit/dim 0.7897(0.7931) | Xent 0.1371(0.1386) | Xent Color 0.0063(0.0087) | Loss 0.8256(0.8299) | Error 0.0422(0.0424) | Error Color 0.0000(0.0009) |Steps 590(594.33) | Grad Norm 4.2355(6.3629) | Total Time 10.00(10.00)\n",
      "Iter 4770 | Time 13.0510(13.6593) | Bit/dim 0.7806(0.7886) | Xent 0.1334(0.1378) | Xent Color 0.0077(0.0082) | Loss 0.8159(0.8251) | Error 0.0356(0.0423) | Error Color 0.0000(0.0007) |Steps 590(593.32) | Grad Norm 4.8940(5.8059) | Total Time 10.00(10.00)\n",
      "Iter 4780 | Time 14.1449(13.7330) | Bit/dim 0.7726(0.7859) | Xent 0.1370(0.1381) | Xent Color 0.0050(0.0078) | Loss 0.8081(0.8223) | Error 0.0478(0.0432) | Error Color 0.0000(0.0007) |Steps 620(597.52) | Grad Norm 4.6988(5.7233) | Total Time 10.00(10.00)\n",
      "Iter 4790 | Time 14.2730(13.8339) | Bit/dim 0.7767(0.7835) | Xent 0.1378(0.1393) | Xent Color 0.0076(0.0077) | Loss 0.8131(0.8203) | Error 0.0433(0.0441) | Error Color 0.0000(0.0007) |Steps 632(601.75) | Grad Norm 7.7322(5.7331) | Total Time 10.00(10.00)\n",
      "Iter 4800 | Time 13.8104(13.8829) | Bit/dim 0.7836(0.7815) | Xent 0.1126(0.1356) | Xent Color 0.0151(0.0084) | Loss 0.8156(0.8175) | Error 0.0389(0.0434) | Error Color 0.0022(0.0010) |Steps 602(603.41) | Grad Norm 10.7060(6.2063) | Total Time 10.00(10.00)\n",
      "Iter 4810 | Time 14.3615(13.9513) | Bit/dim 0.7836(0.7802) | Xent 0.1594(0.1364) | Xent Color 0.0115(0.0083) | Loss 0.8264(0.8164) | Error 0.0478(0.0434) | Error Color 0.0022(0.0010) |Steps 620(605.74) | Grad Norm 7.1906(6.2708) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 79.1538, Epoch Time 1022.7579(960.3150), Bit/dim 0.7751(best: 0.7749), Xent 0.0688, Xent Color 0.0007. Loss 0.7924, Error 0.0234(best: 0.0241), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4820 | Time 13.9921(13.9868) | Bit/dim 0.7764(0.7795) | Xent 0.1134(0.1349) | Xent Color 0.0057(0.0080) | Loss 0.8062(0.8152) | Error 0.0400(0.0426) | Error Color 0.0000(0.0011) |Steps 608(606.81) | Grad Norm 6.6287(6.4323) | Total Time 10.00(10.00)\n",
      "Iter 4830 | Time 14.2993(13.9821) | Bit/dim 0.7782(0.7778) | Xent 0.1079(0.1326) | Xent Color 0.0075(0.0076) | Loss 0.8071(0.8128) | Error 0.0367(0.0418) | Error Color 0.0000(0.0009) |Steps 602(607.12) | Grad Norm 6.8193(6.2068) | Total Time 10.00(10.00)\n",
      "Iter 4840 | Time 14.3957(14.0221) | Bit/dim 0.7863(0.7786) | Xent 0.1355(0.1352) | Xent Color 0.0100(0.0077) | Loss 0.8226(0.8143) | Error 0.0378(0.0422) | Error Color 0.0033(0.0009) |Steps 632(609.18) | Grad Norm 7.1310(6.6934) | Total Time 10.00(10.00)\n",
      "Iter 4850 | Time 14.0602(14.0327) | Bit/dim 0.7809(0.7771) | Xent 0.1533(0.1354) | Xent Color 0.0049(0.0076) | Loss 0.8205(0.8129) | Error 0.0467(0.0425) | Error Color 0.0000(0.0008) |Steps 608(610.10) | Grad Norm 4.7507(6.2721) | Total Time 10.00(10.00)\n",
      "Iter 4860 | Time 13.7507(14.0348) | Bit/dim 0.7862(0.7776) | Xent 0.1213(0.1364) | Xent Color 0.0068(0.0076) | Loss 0.8183(0.8136) | Error 0.0356(0.0429) | Error Color 0.0000(0.0009) |Steps 584(610.22) | Grad Norm 8.1700(6.3398) | Total Time 10.00(10.00)\n",
      "Iter 4870 | Time 14.3411(14.0515) | Bit/dim 0.7556(0.7762) | Xent 0.1447(0.1340) | Xent Color 0.0050(0.0077) | Loss 0.7930(0.8116) | Error 0.0433(0.0420) | Error Color 0.0011(0.0009) |Steps 620(612.04) | Grad Norm 4.1877(6.2695) | Total Time 10.00(10.00)\n",
      "Iter 4880 | Time 14.3147(14.0256) | Bit/dim 0.7729(0.7747) | Xent 0.1263(0.1358) | Xent Color 0.0131(0.0078) | Loss 0.8077(0.8106) | Error 0.0389(0.0423) | Error Color 0.0022(0.0009) |Steps 620(612.28) | Grad Norm 7.7855(6.2300) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 82.4904, Epoch Time 1030.9603(962.4343), Bit/dim 0.7659(best: 0.7749), Xent 0.0693, Xent Color 0.0009. Loss 0.7835, Error 0.0227(best: 0.0234), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4890 | Time 14.2191(13.9531) | Bit/dim 0.7683(0.7738) | Xent 0.1243(0.1336) | Xent Color 0.0088(0.0074) | Loss 0.8016(0.8090) | Error 0.0389(0.0415) | Error Color 0.0011(0.0008) |Steps 626(612.59) | Grad Norm 4.5584(6.2364) | Total Time 10.00(10.00)\n",
      "Iter 4900 | Time 13.8641(13.9636) | Bit/dim 0.7699(0.7729) | Xent 0.1409(0.1330) | Xent Color 0.0101(0.0072) | Loss 0.8076(0.8080) | Error 0.0400(0.0411) | Error Color 0.0011(0.0007) |Steps 620(613.12) | Grad Norm 6.6855(6.1620) | Total Time 10.00(10.00)\n",
      "Iter 4910 | Time 13.1665(13.9232) | Bit/dim 0.8017(0.7772) | Xent 0.1474(0.1333) | Xent Color 0.0083(0.0078) | Loss 0.8406(0.8125) | Error 0.0444(0.0414) | Error Color 0.0000(0.0008) |Steps 578(611.63) | Grad Norm 10.5360(7.2512) | Total Time 10.00(10.00)\n",
      "Iter 4920 | Time 14.1124(13.9325) | Bit/dim 0.7634(0.7775) | Xent 0.1170(0.1363) | Xent Color 0.0038(0.0077) | Loss 0.7936(0.8135) | Error 0.0389(0.0421) | Error Color 0.0000(0.0008) |Steps 596(609.25) | Grad Norm 4.2698(7.0535) | Total Time 10.00(10.00)\n",
      "Iter 4930 | Time 14.3972(13.9215) | Bit/dim 0.7605(0.7759) | Xent 0.1354(0.1333) | Xent Color 0.0055(0.0072) | Loss 0.7958(0.8111) | Error 0.0444(0.0417) | Error Color 0.0000(0.0006) |Steps 596(608.69) | Grad Norm 4.4285(6.5776) | Total Time 10.00(10.00)\n",
      "Iter 4940 | Time 14.0011(13.9160) | Bit/dim 0.7636(0.7794) | Xent 0.1302(0.1317) | Xent Color 0.0063(0.0085) | Loss 0.7977(0.8144) | Error 0.0422(0.0411) | Error Color 0.0000(0.0009) |Steps 626(607.38) | Grad Norm 6.3538(7.5771) | Total Time 10.00(10.00)\n",
      "Iter 4950 | Time 13.9081(13.9131) | Bit/dim 0.7740(0.7778) | Xent 0.1570(0.1335) | Xent Color 0.0051(0.0080) | Loss 0.8146(0.8132) | Error 0.0389(0.0412) | Error Color 0.0000(0.0007) |Steps 626(605.95) | Grad Norm 8.2310(7.4949) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 78.8343, Epoch Time 1019.8190(964.1559), Bit/dim 0.7687(best: 0.7659), Xent 0.0676, Xent Color 0.0011. Loss 0.7859, Error 0.0217(best: 0.0227), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 4960 | Time 13.5453(13.9331) | Bit/dim 0.7608(0.7751) | Xent 0.0987(0.1295) | Xent Color 0.0067(0.0073) | Loss 0.7871(0.8093) | Error 0.0333(0.0407) | Error Color 0.0000(0.0005) |Steps 584(606.85) | Grad Norm 5.4851(7.0482) | Total Time 10.00(10.00)\n",
      "Iter 4970 | Time 13.6661(13.9800) | Bit/dim 0.7613(0.7713) | Xent 0.1424(0.1318) | Xent Color 0.0071(0.0070) | Loss 0.7986(0.8060) | Error 0.0389(0.0409) | Error Color 0.0011(0.0006) |Steps 596(608.00) | Grad Norm 4.8823(6.5748) | Total Time 10.00(10.00)\n",
      "Iter 4980 | Time 14.0967(13.9518) | Bit/dim 0.7488(0.7661) | Xent 0.1284(0.1333) | Xent Color 0.0035(0.0066) | Loss 0.7818(0.8011) | Error 0.0489(0.0411) | Error Color 0.0000(0.0005) |Steps 596(606.63) | Grad Norm 2.4315(5.6945) | Total Time 10.00(10.00)\n",
      "Iter 4990 | Time 14.3138(13.9947) | Bit/dim 0.7719(0.7663) | Xent 0.1174(0.1317) | Xent Color 0.0101(0.0069) | Loss 0.8037(0.8010) | Error 0.0389(0.0411) | Error Color 0.0022(0.0007) |Steps 614(609.39) | Grad Norm 8.7083(6.1531) | Total Time 10.00(10.00)\n",
      "Iter 5000 | Time 13.7432(13.9978) | Bit/dim 0.7707(0.7672) | Xent 0.1602(0.1309) | Xent Color 0.0103(0.0069) | Loss 0.8134(0.8016) | Error 0.0556(0.0409) | Error Color 0.0022(0.0007) |Steps 632(610.96) | Grad Norm 10.0177(6.4599) | Total Time 10.00(10.00)\n",
      "Iter 5010 | Time 13.6517(13.9767) | Bit/dim 0.7702(0.7665) | Xent 0.1274(0.1295) | Xent Color 0.0042(0.0071) | Loss 0.8031(0.8006) | Error 0.0356(0.0404) | Error Color 0.0000(0.0008) |Steps 608(611.05) | Grad Norm 7.1807(6.5727) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 83.3837, Epoch Time 1031.7621(966.1841), Bit/dim 0.7670(best: 0.7659), Xent 0.0876, Xent Color 0.0007. Loss 0.7891, Error 0.0280(best: 0.0217), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5020 | Time 13.9642(13.9877) | Bit/dim 0.7615(0.7654) | Xent 0.1032(0.1285) | Xent Color 0.0043(0.0068) | Loss 0.7884(0.7992) | Error 0.0333(0.0410) | Error Color 0.0000(0.0007) |Steps 614(612.31) | Grad Norm 4.1351(6.3424) | Total Time 10.00(10.00)\n",
      "Iter 5030 | Time 13.8144(13.9817) | Bit/dim 0.7478(0.7634) | Xent 0.1358(0.1295) | Xent Color 0.0068(0.0066) | Loss 0.7835(0.7974) | Error 0.0389(0.0406) | Error Color 0.0022(0.0007) |Steps 620(613.63) | Grad Norm 3.6673(6.3163) | Total Time 10.00(10.00)\n",
      "Iter 5040 | Time 13.1448(13.9594) | Bit/dim 0.7803(0.7618) | Xent 0.1393(0.1273) | Xent Color 0.0036(0.0063) | Loss 0.8161(0.7952) | Error 0.0422(0.0397) | Error Color 0.0000(0.0006) |Steps 578(612.68) | Grad Norm 10.3300(6.5521) | Total Time 10.00(10.00)\n",
      "Iter 5050 | Time 14.1699(14.0099) | Bit/dim 0.7525(0.7583) | Xent 0.1293(0.1232) | Xent Color 0.0049(0.0062) | Loss 0.7861(0.7907) | Error 0.0367(0.0379) | Error Color 0.0000(0.0007) |Steps 614(614.05) | Grad Norm 5.5298(6.3077) | Total Time 10.00(10.00)\n",
      "Iter 5060 | Time 14.1758(14.0162) | Bit/dim 0.7660(0.7597) | Xent 0.1846(0.1234) | Xent Color 0.0070(0.0064) | Loss 0.8139(0.7922) | Error 0.0522(0.0382) | Error Color 0.0011(0.0008) |Steps 614(614.84) | Grad Norm 12.1204(6.9454) | Total Time 10.00(10.00)\n",
      "Iter 5070 | Time 14.1002(14.0042) | Bit/dim 0.7547(0.7594) | Xent 0.1067(0.1244) | Xent Color 0.0050(0.0063) | Loss 0.7827(0.7920) | Error 0.0367(0.0385) | Error Color 0.0000(0.0007) |Steps 608(613.13) | Grad Norm 4.5831(6.6858) | Total Time 10.00(10.00)\n",
      "Iter 5080 | Time 13.5242(14.0196) | Bit/dim 0.7597(0.7614) | Xent 0.1277(0.1281) | Xent Color 0.0061(0.0069) | Loss 0.7931(0.7951) | Error 0.0389(0.0396) | Error Color 0.0000(0.0008) |Steps 608(614.03) | Grad Norm 7.1614(7.2866) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 80.6330, Epoch Time 1028.7632(968.0614), Bit/dim 0.7612(best: 0.7659), Xent 0.0641, Xent Color 0.0016. Loss 0.7777, Error 0.0201(best: 0.0217), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5090 | Time 13.6054(13.9901) | Bit/dim 0.7718(0.7603) | Xent 0.0994(0.1249) | Xent Color 0.0063(0.0067) | Loss 0.7982(0.7932) | Error 0.0300(0.0388) | Error Color 0.0022(0.0008) |Steps 578(610.69) | Grad Norm 7.9643(7.0583) | Total Time 10.00(10.00)\n",
      "Iter 5100 | Time 13.6154(13.9549) | Bit/dim 0.7545(0.7578) | Xent 0.1021(0.1235) | Xent Color 0.0049(0.0064) | Loss 0.7813(0.7903) | Error 0.0344(0.0388) | Error Color 0.0000(0.0007) |Steps 590(610.18) | Grad Norm 7.8099(6.8458) | Total Time 10.00(10.00)\n",
      "Iter 5110 | Time 13.4018(13.9342) | Bit/dim 0.7376(0.7563) | Xent 0.1391(0.1247) | Xent Color 0.0051(0.0064) | Loss 0.7736(0.7890) | Error 0.0433(0.0394) | Error Color 0.0011(0.0007) |Steps 608(612.40) | Grad Norm 4.8282(6.8524) | Total Time 10.00(10.00)\n",
      "Iter 5120 | Time 14.0500(13.9284) | Bit/dim 0.7507(0.7559) | Xent 0.1024(0.1244) | Xent Color 0.0074(0.0062) | Loss 0.7782(0.7885) | Error 0.0322(0.0395) | Error Color 0.0011(0.0007) |Steps 608(612.37) | Grad Norm 7.1033(6.8423) | Total Time 10.00(10.00)\n",
      "Iter 5130 | Time 14.1057(13.9472) | Bit/dim 0.7539(0.7547) | Xent 0.1328(0.1230) | Xent Color 0.0062(0.0059) | Loss 0.7887(0.7869) | Error 0.0478(0.0393) | Error Color 0.0000(0.0006) |Steps 626(612.47) | Grad Norm 8.4759(6.6202) | Total Time 10.00(10.00)\n",
      "Iter 5140 | Time 13.7487(13.9597) | Bit/dim 0.7515(0.7620) | Xent 0.1228(0.1243) | Xent Color 0.0112(0.0069) | Loss 0.7850(0.7948) | Error 0.0444(0.0393) | Error Color 0.0022(0.0008) |Steps 626(613.64) | Grad Norm 4.1572(7.8219) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 82.4805, Epoch Time 1024.8177(969.7641), Bit/dim 0.7597(best: 0.7612), Xent 0.0680, Xent Color 0.0008. Loss 0.7769, Error 0.0218(best: 0.0201), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5150 | Time 13.5997(13.9384) | Bit/dim 0.7793(0.7632) | Xent 0.0843(0.1236) | Xent Color 0.0047(0.0068) | Loss 0.8016(0.7958) | Error 0.0233(0.0392) | Error Color 0.0011(0.0007) |Steps 584(611.35) | Grad Norm 9.3092(7.8491) | Total Time 10.00(10.00)\n",
      "Iter 5160 | Time 13.7208(13.9095) | Bit/dim 0.7622(0.7637) | Xent 0.1262(0.1233) | Xent Color 0.0102(0.0069) | Loss 0.7963(0.7962) | Error 0.0400(0.0389) | Error Color 0.0022(0.0007) |Steps 602(610.37) | Grad Norm 5.9087(7.6149) | Total Time 10.00(10.00)\n",
      "Iter 5170 | Time 13.7829(13.9023) | Bit/dim 0.7495(0.7606) | Xent 0.1381(0.1241) | Xent Color 0.0049(0.0064) | Loss 0.7853(0.7933) | Error 0.0456(0.0392) | Error Color 0.0000(0.0007) |Steps 602(607.18) | Grad Norm 4.7142(6.9792) | Total Time 10.00(10.00)\n",
      "Iter 5180 | Time 14.2259(13.9171) | Bit/dim 0.7511(0.7573) | Xent 0.1263(0.1242) | Xent Color 0.0031(0.0062) | Loss 0.7835(0.7898) | Error 0.0400(0.0388) | Error Color 0.0000(0.0006) |Steps 608(607.80) | Grad Norm 6.9155(6.7080) | Total Time 10.00(10.00)\n",
      "Iter 5190 | Time 13.5598(13.9427) | Bit/dim 0.7454(0.7542) | Xent 0.1013(0.1244) | Xent Color 0.0065(0.0060) | Loss 0.7724(0.7868) | Error 0.0311(0.0391) | Error Color 0.0022(0.0007) |Steps 602(608.44) | Grad Norm 6.7529(6.4376) | Total Time 10.00(10.00)\n",
      "Iter 5200 | Time 13.4823(13.9633) | Bit/dim 0.7639(0.7545) | Xent 0.1158(0.1221) | Xent Color 0.0087(0.0061) | Loss 0.7951(0.7866) | Error 0.0389(0.0389) | Error Color 0.0011(0.0007) |Steps 584(608.35) | Grad Norm 10.2448(6.8768) | Total Time 10.00(10.00)\n",
      "Iter 5210 | Time 14.0136(13.9500) | Bit/dim 0.8122(0.7605) | Xent 0.1005(0.1214) | Xent Color 0.0215(0.0069) | Loss 0.8427(0.7926) | Error 0.0400(0.0386) | Error Color 0.0044(0.0010) |Steps 614(608.30) | Grad Norm 14.5901(7.6504) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 80.6906, Epoch Time 1024.1658(971.3962), Bit/dim 0.7729(best: 0.7597), Xent 0.0770, Xent Color 0.0008. Loss 0.7924, Error 0.0247(best: 0.0201), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5220 | Time 14.0317(13.9123) | Bit/dim 0.7652(0.7643) | Xent 0.1438(0.1223) | Xent Color 0.0056(0.0073) | Loss 0.8025(0.7968) | Error 0.0489(0.0392) | Error Color 0.0011(0.0011) |Steps 602(607.09) | Grad Norm 8.9760(7.9521) | Total Time 10.00(10.00)\n",
      "Iter 5230 | Time 14.1235(13.9498) | Bit/dim 0.7421(0.7623) | Xent 0.1193(0.1210) | Xent Color 0.0051(0.0070) | Loss 0.7732(0.7943) | Error 0.0356(0.0382) | Error Color 0.0000(0.0010) |Steps 602(606.91) | Grad Norm 4.5604(7.5539) | Total Time 10.00(10.00)\n",
      "Iter 5240 | Time 13.5555(13.8879) | Bit/dim 0.7378(0.7580) | Xent 0.1360(0.1216) | Xent Color 0.0033(0.0065) | Loss 0.7726(0.7900) | Error 0.0433(0.0380) | Error Color 0.0000(0.0009) |Steps 584(604.16) | Grad Norm 3.8332(7.1015) | Total Time 10.00(10.00)\n",
      "Iter 5250 | Time 14.1656(13.8779) | Bit/dim 0.7376(0.7521) | Xent 0.1322(0.1235) | Xent Color 0.0040(0.0059) | Loss 0.7717(0.7844) | Error 0.0389(0.0387) | Error Color 0.0000(0.0008) |Steps 590(602.88) | Grad Norm 3.7342(6.3370) | Total Time 10.00(10.00)\n",
      "Iter 5260 | Time 13.9993(13.9364) | Bit/dim 0.7503(0.7474) | Xent 0.1127(0.1217) | Xent Color 0.0033(0.0055) | Loss 0.7793(0.7793) | Error 0.0367(0.0382) | Error Color 0.0011(0.0007) |Steps 602(604.72) | Grad Norm 7.1064(5.8198) | Total Time 10.00(10.00)\n",
      "Iter 5270 | Time 13.4791(13.9359) | Bit/dim 0.7799(0.7507) | Xent 0.1370(0.1185) | Xent Color 0.0102(0.0061) | Loss 0.8167(0.7819) | Error 0.0411(0.0369) | Error Color 0.0011(0.0008) |Steps 596(606.21) | Grad Norm 10.6858(6.9960) | Total Time 10.00(10.00)\n",
      "Iter 5280 | Time 14.2303(13.9905) | Bit/dim 0.7850(0.7559) | Xent 0.1670(0.1188) | Xent Color 0.0091(0.0061) | Loss 0.8290(0.7871) | Error 0.0456(0.0368) | Error Color 0.0011(0.0008) |Steps 626(608.24) | Grad Norm 14.0812(7.5648) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 79.8579, Epoch Time 1023.5723(972.9615), Bit/dim 0.7928(best: 0.7597), Xent 0.0658, Xent Color 0.0006. Loss 0.8094, Error 0.0206(best: 0.0201), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5290 | Time 13.5898(13.9571) | Bit/dim 0.7549(0.7592) | Xent 0.0827(0.1182) | Xent Color 0.0041(0.0059) | Loss 0.7766(0.7902) | Error 0.0256(0.0364) | Error Color 0.0000(0.0007) |Steps 578(605.51) | Grad Norm 6.2289(7.7036) | Total Time 10.00(10.00)\n",
      "Iter 5300 | Time 14.4695(13.9306) | Bit/dim 0.7426(0.7552) | Xent 0.1203(0.1187) | Xent Color 0.0064(0.0057) | Loss 0.7743(0.7863) | Error 0.0422(0.0371) | Error Color 0.0000(0.0006) |Steps 632(604.22) | Grad Norm 4.2666(6.9466) | Total Time 10.00(10.00)\n",
      "Iter 5310 | Time 13.7998(13.8963) | Bit/dim 0.7304(0.7497) | Xent 0.1626(0.1219) | Xent Color 0.0037(0.0054) | Loss 0.7720(0.7815) | Error 0.0478(0.0379) | Error Color 0.0000(0.0006) |Steps 608(601.58) | Grad Norm 5.3739(6.3801) | Total Time 10.00(10.00)\n",
      "Iter 5320 | Time 13.6778(13.9095) | Bit/dim 0.7265(0.7443) | Xent 0.0874(0.1193) | Xent Color 0.0053(0.0051) | Loss 0.7497(0.7754) | Error 0.0311(0.0372) | Error Color 0.0011(0.0006) |Steps 620(602.98) | Grad Norm 4.4046(5.7351) | Total Time 10.00(10.00)\n",
      "Iter 5330 | Time 13.8342(13.8836) | Bit/dim 0.7417(0.7456) | Xent 0.1067(0.1170) | Xent Color 0.0059(0.0052) | Loss 0.7698(0.7762) | Error 0.0389(0.0365) | Error Color 0.0000(0.0005) |Steps 608(604.16) | Grad Norm 7.4735(6.7348) | Total Time 10.00(10.00)\n",
      "Iter 5340 | Time 13.4386(13.9111) | Bit/dim 0.7712(0.7454) | Xent 0.1117(0.1162) | Xent Color 0.0033(0.0051) | Loss 0.8000(0.7757) | Error 0.0356(0.0361) | Error Color 0.0000(0.0005) |Steps 578(604.61) | Grad Norm 9.2851(6.9523) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 83.4501, Epoch Time 1022.5815(974.4501), Bit/dim 0.7308(best: 0.7597), Xent 0.0630, Xent Color 0.0005. Loss 0.7467, Error 0.0188(best: 0.0201), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5350 | Time 14.1988(13.9013) | Bit/dim 0.7276(0.7436) | Xent 0.1100(0.1159) | Xent Color 0.0032(0.0050) | Loss 0.7559(0.7739) | Error 0.0356(0.0361) | Error Color 0.0000(0.0005) |Steps 602(604.80) | Grad Norm 4.4559(6.6262) | Total Time 10.00(10.00)\n",
      "Iter 5360 | Time 13.9973(13.8957) | Bit/dim 0.7365(0.7407) | Xent 0.0816(0.1167) | Xent Color 0.0036(0.0046) | Loss 0.7578(0.7710) | Error 0.0300(0.0360) | Error Color 0.0000(0.0004) |Steps 620(605.71) | Grad Norm 7.3914(6.1917) | Total Time 10.00(10.00)\n",
      "Iter 5370 | Time 13.9294(13.9309) | Bit/dim 0.7218(0.7381) | Xent 0.1313(0.1174) | Xent Color 0.0044(0.0047) | Loss 0.7557(0.7686) | Error 0.0422(0.0360) | Error Color 0.0011(0.0004) |Steps 596(605.85) | Grad Norm 4.1726(5.8774) | Total Time 10.00(10.00)\n",
      "Iter 5380 | Time 13.5345(13.9563) | Bit/dim 0.7294(0.7365) | Xent 0.1431(0.1149) | Xent Color 0.0046(0.0045) | Loss 0.7663(0.7664) | Error 0.0456(0.0357) | Error Color 0.0011(0.0004) |Steps 608(608.29) | Grad Norm 5.4532(6.1575) | Total Time 10.00(10.00)\n",
      "Iter 5390 | Time 14.2144(13.9942) | Bit/dim 0.7321(0.7385) | Xent 0.1341(0.1144) | Xent Color 0.0069(0.0052) | Loss 0.7674(0.7684) | Error 0.0433(0.0357) | Error Color 0.0011(0.0007) |Steps 626(609.98) | Grad Norm 6.1427(6.7888) | Total Time 10.00(10.00)\n",
      "Iter 5400 | Time 13.6020(13.9990) | Bit/dim 0.7318(0.7383) | Xent 0.1156(0.1115) | Xent Color 0.0031(0.0048) | Loss 0.7615(0.7673) | Error 0.0367(0.0351) | Error Color 0.0000(0.0006) |Steps 602(609.53) | Grad Norm 3.8374(6.5786) | Total Time 10.00(10.00)\n",
      "Iter 5410 | Time 14.0475(14.0072) | Bit/dim 0.7288(0.7347) | Xent 0.1009(0.1121) | Xent Color 0.0064(0.0046) | Loss 0.7556(0.7639) | Error 0.0333(0.0352) | Error Color 0.0011(0.0006) |Steps 608(609.92) | Grad Norm 6.0519(6.0136) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 82.8435, Epoch Time 1030.5872(976.1342), Bit/dim 0.7488(best: 0.7308), Xent 0.0576, Xent Color 0.0005. Loss 0.7633, Error 0.0184(best: 0.0188), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5420 | Time 14.2401(14.0044) | Bit/dim 0.7377(0.7363) | Xent 0.1338(0.1119) | Xent Color 0.0035(0.0049) | Loss 0.7720(0.7655) | Error 0.0433(0.0354) | Error Color 0.0000(0.0006) |Steps 626(611.80) | Grad Norm 6.7090(6.7041) | Total Time 10.00(10.00)\n",
      "Iter 5430 | Time 14.0073(14.0158) | Bit/dim 0.7414(0.7364) | Xent 0.1307(0.1135) | Xent Color 0.0045(0.0046) | Loss 0.7752(0.7659) | Error 0.0433(0.0358) | Error Color 0.0000(0.0005) |Steps 626(611.59) | Grad Norm 11.8674(6.6555) | Total Time 10.00(10.00)\n",
      "Iter 5440 | Time 14.1604(13.9526) | Bit/dim 0.7650(0.7484) | Xent 0.0959(0.1142) | Xent Color 0.0028(0.0053) | Loss 0.7897(0.7783) | Error 0.0278(0.0363) | Error Color 0.0000(0.0006) |Steps 614(609.77) | Grad Norm 6.7075(7.7867) | Total Time 10.00(10.00)\n",
      "Iter 5450 | Time 14.0629(13.8839) | Bit/dim 0.7358(0.7506) | Xent 0.1375(0.1135) | Xent Color 0.0130(0.0054) | Loss 0.7734(0.7804) | Error 0.0433(0.0358) | Error Color 0.0022(0.0007) |Steps 608(605.04) | Grad Norm 4.8501(7.5912) | Total Time 10.00(10.00)\n",
      "Iter 5460 | Time 13.2821(13.7728) | Bit/dim 0.7246(0.7470) | Xent 0.0863(0.1127) | Xent Color 0.0034(0.0051) | Loss 0.7470(0.7764) | Error 0.0300(0.0361) | Error Color 0.0000(0.0006) |Steps 584(599.38) | Grad Norm 3.5167(6.8641) | Total Time 10.00(10.00)\n",
      "Iter 5470 | Time 13.6989(13.7940) | Bit/dim 0.7192(0.7435) | Xent 0.1153(0.1133) | Xent Color 0.0025(0.0047) | Loss 0.7486(0.7730) | Error 0.0300(0.0360) | Error Color 0.0000(0.0005) |Steps 596(599.97) | Grad Norm 2.8490(6.7123) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 83.5313, Epoch Time 1017.5125(977.3755), Bit/dim 0.7280(best: 0.7308), Xent 0.0558, Xent Color 0.0004. Loss 0.7420, Error 0.0180(best: 0.0184), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5480 | Time 13.6745(13.8006) | Bit/dim 0.7383(0.7386) | Xent 0.0961(0.1118) | Xent Color 0.0043(0.0045) | Loss 0.7634(0.7677) | Error 0.0267(0.0355) | Error Color 0.0000(0.0004) |Steps 596(599.39) | Grad Norm 7.7147(6.3027) | Total Time 10.00(10.00)\n",
      "Iter 5490 | Time 14.2994(13.8674) | Bit/dim 0.7164(0.7347) | Xent 0.1289(0.1103) | Xent Color 0.0044(0.0043) | Loss 0.7497(0.7633) | Error 0.0411(0.0347) | Error Color 0.0011(0.0004) |Steps 614(603.55) | Grad Norm 3.5214(6.2127) | Total Time 10.00(10.00)\n",
      "Iter 5500 | Time 14.2659(13.8780) | Bit/dim 0.7248(0.7354) | Xent 0.0901(0.1112) | Xent Color 0.0057(0.0043) | Loss 0.7488(0.7643) | Error 0.0322(0.0348) | Error Color 0.0011(0.0004) |Steps 620(606.02) | Grad Norm 7.0065(6.7353) | Total Time 10.00(10.00)\n",
      "Iter 5510 | Time 14.7682(13.9008) | Bit/dim 0.7372(0.7393) | Xent 0.1569(0.1121) | Xent Color 0.0040(0.0044) | Loss 0.7774(0.7684) | Error 0.0467(0.0347) | Error Color 0.0000(0.0004) |Steps 632(606.09) | Grad Norm 9.0967(7.4247) | Total Time 10.00(10.00)\n",
      "Iter 5520 | Time 13.5637(13.9173) | Bit/dim 0.7601(0.7459) | Xent 0.1179(0.1146) | Xent Color 0.0041(0.0053) | Loss 0.7906(0.7759) | Error 0.0378(0.0355) | Error Color 0.0000(0.0008) |Steps 596(604.91) | Grad Norm 7.8619(7.8770) | Total Time 10.00(10.00)\n",
      "Iter 5530 | Time 13.5732(13.7846) | Bit/dim 0.7676(0.7495) | Xent 0.1366(0.1130) | Xent Color 0.0059(0.0056) | Loss 0.8032(0.7791) | Error 0.0356(0.0353) | Error Color 0.0022(0.0008) |Steps 578(596.49) | Grad Norm 10.8575(8.3409) | Total Time 10.00(10.00)\n",
      "Iter 5540 | Time 13.7993(13.7611) | Bit/dim 0.7369(0.7461) | Xent 0.0994(0.1116) | Xent Color 0.0037(0.0052) | Loss 0.7626(0.7752) | Error 0.0378(0.0350) | Error Color 0.0000(0.0007) |Steps 614(594.34) | Grad Norm 6.1003(7.6975) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 81.8458, Epoch Time 1017.7139(978.5857), Bit/dim 0.7282(best: 0.7280), Xent 0.0557, Xent Color 0.0003. Loss 0.7422, Error 0.0169(best: 0.0180), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5550 | Time 13.6482(13.7673) | Bit/dim 0.7164(0.7400) | Xent 0.0853(0.1132) | Xent Color 0.0036(0.0047) | Loss 0.7387(0.7694) | Error 0.0267(0.0348) | Error Color 0.0000(0.0005) |Steps 602(595.05) | Grad Norm 5.7293(7.0645) | Total Time 10.00(10.00)\n",
      "Iter 5560 | Time 14.1326(13.8272) | Bit/dim 0.7214(0.7341) | Xent 0.1172(0.1106) | Xent Color 0.0047(0.0043) | Loss 0.7519(0.7628) | Error 0.0367(0.0342) | Error Color 0.0000(0.0004) |Steps 620(597.77) | Grad Norm 4.5909(6.2774) | Total Time 10.00(10.00)\n",
      "Iter 5570 | Time 14.0504(13.8336) | Bit/dim 0.7198(0.7292) | Xent 0.0792(0.1084) | Xent Color 0.0026(0.0041) | Loss 0.7402(0.7573) | Error 0.0244(0.0335) | Error Color 0.0000(0.0003) |Steps 620(600.23) | Grad Norm 2.9244(5.5573) | Total Time 10.00(10.00)\n",
      "Iter 5580 | Time 14.2947(13.9132) | Bit/dim 0.7416(0.7324) | Xent 0.0773(0.1072) | Xent Color 0.0029(0.0046) | Loss 0.7617(0.7604) | Error 0.0300(0.0336) | Error Color 0.0000(0.0004) |Steps 626(604.12) | Grad Norm 8.1539(6.7044) | Total Time 10.00(10.00)\n",
      "Iter 5590 | Time 13.7183(13.9675) | Bit/dim 0.7320(0.7366) | Xent 0.0885(0.1063) | Xent Color 0.0041(0.0051) | Loss 0.7551(0.7644) | Error 0.0322(0.0338) | Error Color 0.0000(0.0005) |Steps 620(608.96) | Grad Norm 4.3879(7.1894) | Total Time 10.00(10.00)\n",
      "Iter 5600 | Time 13.9811(13.9924) | Bit/dim 0.7326(0.7365) | Xent 0.1250(0.1081) | Xent Color 0.0032(0.0051) | Loss 0.7647(0.7647) | Error 0.0333(0.0341) | Error Color 0.0000(0.0005) |Steps 620(609.50) | Grad Norm 9.2933(7.2524) | Total Time 10.00(10.00)\n",
      "Iter 5610 | Time 14.0200(14.0115) | Bit/dim 0.7358(0.7356) | Xent 0.1090(0.1083) | Xent Color 0.0054(0.0048) | Loss 0.7644(0.7639) | Error 0.0311(0.0342) | Error Color 0.0000(0.0005) |Steps 614(610.13) | Grad Norm 6.4822(7.3649) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 85.1851, Epoch Time 1033.5422(980.2344), Bit/dim 0.7313(best: 0.7280), Xent 0.0605, Xent Color 0.0005. Loss 0.7465, Error 0.0200(best: 0.0169), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5620 | Time 14.2092(13.9753) | Bit/dim 0.7153(0.7340) | Xent 0.1085(0.1069) | Xent Color 0.0036(0.0045) | Loss 0.7434(0.7619) | Error 0.0267(0.0336) | Error Color 0.0000(0.0004) |Steps 614(608.74) | Grad Norm 6.4528(7.2360) | Total Time 10.00(10.00)\n",
      "Iter 5630 | Time 13.7770(13.9571) | Bit/dim 0.7104(0.7313) | Xent 0.0785(0.1043) | Xent Color 0.0053(0.0043) | Loss 0.7313(0.7584) | Error 0.0233(0.0326) | Error Color 0.0011(0.0004) |Steps 608(608.26) | Grad Norm 2.8627(6.7952) | Total Time 10.00(10.00)\n",
      "Iter 5640 | Time 13.9492(13.9601) | Bit/dim 0.7255(0.7290) | Xent 0.1233(0.1070) | Xent Color 0.0048(0.0042) | Loss 0.7576(0.7568) | Error 0.0356(0.0334) | Error Color 0.0022(0.0005) |Steps 626(608.39) | Grad Norm 7.7522(6.7009) | Total Time 10.00(10.00)\n",
      "Iter 5650 | Time 13.8342(13.9302) | Bit/dim 0.7189(0.7296) | Xent 0.0912(0.1053) | Xent Color 0.0028(0.0040) | Loss 0.7424(0.7570) | Error 0.0278(0.0327) | Error Color 0.0000(0.0004) |Steps 602(608.40) | Grad Norm 4.9388(6.9758) | Total Time 10.00(10.00)\n",
      "Iter 5660 | Time 13.8785(13.9329) | Bit/dim 0.7224(0.7285) | Xent 0.1202(0.1072) | Xent Color 0.0063(0.0039) | Loss 0.7541(0.7563) | Error 0.0389(0.0334) | Error Color 0.0011(0.0005) |Steps 608(608.87) | Grad Norm 5.8369(6.8244) | Total Time 10.00(10.00)\n",
      "Iter 5670 | Time 13.6706(13.9135) | Bit/dim 0.7154(0.7253) | Xent 0.0830(0.1076) | Xent Color 0.0022(0.0037) | Loss 0.7367(0.7532) | Error 0.0222(0.0335) | Error Color 0.0000(0.0004) |Steps 590(607.85) | Grad Norm 6.1893(6.4618) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 84.8215, Epoch Time 1024.3783(981.5587), Bit/dim 0.7294(best: 0.7280), Xent 0.0559, Xent Color 0.0007. Loss 0.7436, Error 0.0168(best: 0.0169), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5680 | Time 13.2877(13.8705) | Bit/dim 0.7839(0.7271) | Xent 0.1071(0.1040) | Xent Color 0.0081(0.0041) | Loss 0.8127(0.7541) | Error 0.0356(0.0329) | Error Color 0.0022(0.0004) |Steps 590(608.01) | Grad Norm 16.2315(7.2239) | Total Time 10.00(10.00)\n",
      "Iter 5690 | Time 14.0782(13.9010) | Bit/dim 0.7238(0.7282) | Xent 0.1208(0.1019) | Xent Color 0.0034(0.0042) | Loss 0.7548(0.7547) | Error 0.0322(0.0318) | Error Color 0.0000(0.0005) |Steps 620(609.86) | Grad Norm 5.5208(7.4219) | Total Time 10.00(10.00)\n",
      "Iter 5700 | Time 14.3446(13.9321) | Bit/dim 0.7124(0.7264) | Xent 0.0993(0.1034) | Xent Color 0.0027(0.0041) | Loss 0.7378(0.7533) | Error 0.0311(0.0319) | Error Color 0.0000(0.0004) |Steps 632(611.31) | Grad Norm 4.7271(7.1231) | Total Time 10.00(10.00)\n",
      "Iter 5710 | Time 13.8200(13.9417) | Bit/dim 0.7455(0.7247) | Xent 0.0953(0.1033) | Xent Color 0.0014(0.0038) | Loss 0.7696(0.7515) | Error 0.0267(0.0326) | Error Color 0.0000(0.0004) |Steps 590(612.80) | Grad Norm 9.9498(7.1882) | Total Time 10.00(10.00)\n",
      "Iter 5720 | Time 14.0422(14.0048) | Bit/dim 0.7103(0.7228) | Xent 0.1280(0.1030) | Xent Color 0.0069(0.0040) | Loss 0.7440(0.7496) | Error 0.0256(0.0322) | Error Color 0.0022(0.0005) |Steps 626(614.83) | Grad Norm 4.2628(6.9654) | Total Time 10.00(10.00)\n",
      "Iter 5730 | Time 14.2833(13.9601) | Bit/dim 0.7105(0.7205) | Xent 0.0952(0.1022) | Xent Color 0.0031(0.0039) | Loss 0.7351(0.7471) | Error 0.0300(0.0314) | Error Color 0.0000(0.0004) |Steps 626(615.10) | Grad Norm 5.3506(6.8315) | Total Time 10.00(10.00)\n",
      "Iter 5740 | Time 14.2719(14.0514) | Bit/dim 0.7183(0.7201) | Xent 0.0911(0.1033) | Xent Color 0.0028(0.0038) | Loss 0.7418(0.7469) | Error 0.0344(0.0318) | Error Color 0.0000(0.0004) |Steps 614(616.84) | Grad Norm 7.3943(6.7519) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 83.5722, Epoch Time 1033.5700(983.1190), Bit/dim 0.7167(best: 0.7280), Xent 0.0576, Xent Color 0.0004. Loss 0.7312, Error 0.0189(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5750 | Time 14.3507(14.0857) | Bit/dim 0.7169(0.7204) | Xent 0.1057(0.1060) | Xent Color 0.0038(0.0039) | Loss 0.7443(0.7479) | Error 0.0367(0.0325) | Error Color 0.0000(0.0004) |Steps 626(617.12) | Grad Norm 4.8625(7.0253) | Total Time 10.00(10.00)\n",
      "Iter 5760 | Time 14.4420(14.1260) | Bit/dim 0.7191(0.7213) | Xent 0.1153(0.1062) | Xent Color 0.0029(0.0037) | Loss 0.7486(0.7488) | Error 0.0289(0.0325) | Error Color 0.0000(0.0004) |Steps 620(617.11) | Grad Norm 4.2935(7.1945) | Total Time 10.00(10.00)\n",
      "Iter 5770 | Time 16.4428(14.1846) | Bit/dim 4.1174(0.8905) | Xent 11.5268(0.4590) | Xent Color 37.2651(2.3112) | Loss 16.3153(1.5831) | Error 0.8622(0.0606) | Error Color 0.8433(0.0611) |Steps 692(620.11) | Grad Norm 284.0112(26.8864) | Total Time 10.00(10.00)\n",
      "Iter 5780 | Time 16.7181(14.9901) | Bit/dim 2.3149(1.3424) | Xent 1.1899(0.6247) | Xent Color 1.1366(3.7949) | Loss 2.8965(2.4473) | Error 0.4011(0.1365) | Error Color 0.4167(0.2095) |Steps 812(672.33) | Grad Norm 6.1295(32.6024) | Total Time 10.00(10.00)\n",
      "Iter 5790 | Time 13.2222(15.0040) | Bit/dim 2.1430(1.5718) | Xent 0.5764(0.6606) | Xent Color 0.7819(3.0716) | Loss 2.4826(2.5048) | Error 0.1811(0.1659) | Error Color 0.3189(0.2582) |Steps 626(679.98) | Grad Norm 4.9774(25.5414) | Total Time 10.00(10.00)\n",
      "Iter 5800 | Time 13.3845(14.5448) | Bit/dim 2.0382(1.7032) | Xent 0.3780(0.6072) | Xent Color 0.5839(2.4311) | Loss 2.2787(2.4628) | Error 0.1111(0.1601) | Error Color 0.2256(0.2549) |Steps 614(660.62) | Grad Norm 14.0703(20.3837) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 78.5438, Epoch Time 1063.3831(985.5269), Bit/dim 1.9889(best: 0.7167), Xent 0.2142, Xent Color 0.3033. Loss 2.1183, Error 0.0664(best: 0.0168), Error Color 0.0974(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5810 | Time 13.6629(14.2321) | Bit/dim 1.9609(1.7795) | Xent 0.3420(0.5451) | Xent Color 0.3743(1.9328) | Loss 2.1399(2.3990) | Error 0.1000(0.1486) | Error Color 0.1378(0.2425) |Steps 626(647.48) | Grad Norm 5.6389(16.8210) | Total Time 10.00(10.00)\n",
      "Iter 5820 | Time 12.8584(14.0092) | Bit/dim 1.9121(1.8221) | Xent 0.3511(0.4919) | Xent Color 0.2451(1.5008) | Loss 2.0611(2.3202) | Error 0.1144(0.1381) | Error Color 0.0867(0.2050) |Steps 584(635.34) | Grad Norm 3.8414(13.2761) | Total Time 10.00(10.00)\n",
      "Iter 5830 | Time 13.0979(13.7824) | Bit/dim 1.8558(1.8397) | Xent 0.2888(0.4445) | Xent Color 0.1611(1.1563) | Loss 1.9682(2.2399) | Error 0.0889(0.1266) | Error Color 0.0489(0.1668) |Steps 590(624.38) | Grad Norm 2.2508(10.4035) | Total Time 10.00(10.00)\n",
      "Iter 5840 | Time 13.3355(13.6297) | Bit/dim 1.8115(1.8390) | Xent 0.2617(0.4041) | Xent Color 0.1467(0.8933) | Loss 1.9136(2.1634) | Error 0.0789(0.1174) | Error Color 0.0411(0.1351) |Steps 590(615.00) | Grad Norm 3.1144(8.4323) | Total Time 10.00(10.00)\n",
      "Iter 5850 | Time 13.6941(13.5108) | Bit/dim 1.7957(1.8291) | Xent 0.3100(0.3711) | Xent Color 0.0991(0.6906) | Loss 1.8979(2.0945) | Error 0.0889(0.1087) | Error Color 0.0178(0.1086) |Steps 602(608.56) | Grad Norm 1.3148(6.8547) | Total Time 10.00(10.00)\n",
      "Iter 5860 | Time 12.8695(13.4175) | Bit/dim 1.7430(1.8097) | Xent 0.2509(0.3391) | Xent Color 0.0840(0.5359) | Loss 1.8267(2.0285) | Error 0.0822(0.1008) | Error Color 0.0189(0.0877) |Steps 590(603.80) | Grad Norm 0.6752(5.4859) | Total Time 10.00(10.00)\n",
      "Iter 5870 | Time 13.1432(13.3052) | Bit/dim 1.7177(1.7862) | Xent 0.2686(0.3188) | Xent Color 0.1067(0.4208) | Loss 1.8115(1.9711) | Error 0.0878(0.0972) | Error Color 0.0311(0.0713) |Steps 590(599.55) | Grad Norm 4.0281(4.9773) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 75.7490, Epoch Time 969.4531(985.0447), Bit/dim 1.6952(best: 0.7167), Xent 0.1395, Xent Color 0.0343. Loss 1.7386, Error 0.0433(best: 0.0168), Error Color 0.0061(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5880 | Time 13.4575(13.2419) | Bit/dim 1.6845(1.7614) | Xent 0.2743(0.2979) | Xent Color 0.0840(0.3351) | Loss 1.7741(1.9197) | Error 0.0889(0.0912) | Error Color 0.0211(0.0590) |Steps 602(597.71) | Grad Norm 3.0205(4.4564) | Total Time 10.00(10.00)\n",
      "Iter 5890 | Time 13.6269(13.2752) | Bit/dim 1.6518(1.7339) | Xent 0.2812(0.2834) | Xent Color 0.0695(0.2728) | Loss 1.7395(1.8730) | Error 0.0956(0.0887) | Error Color 0.0156(0.0508) |Steps 608(597.53) | Grad Norm 4.2904(4.5741) | Total Time 10.00(10.00)\n",
      "Iter 5900 | Time 13.4035(13.3170) | Bit/dim 1.6193(1.7059) | Xent 0.2637(0.2757) | Xent Color 0.1026(0.2212) | Loss 1.7109(1.8301) | Error 0.0822(0.0859) | Error Color 0.0267(0.0429) |Steps 614(597.76) | Grad Norm 3.8659(4.2710) | Total Time 10.00(10.00)\n",
      "Iter 5910 | Time 13.7076(13.3804) | Bit/dim 1.6042(1.6783) | Xent 0.1707(0.2621) | Xent Color 0.0676(0.1824) | Loss 1.6638(1.7894) | Error 0.0578(0.0829) | Error Color 0.0167(0.0369) |Steps 596(597.38) | Grad Norm 2.7188(4.1724) | Total Time 10.00(10.00)\n",
      "Iter 5920 | Time 13.0274(13.4245) | Bit/dim 1.5520(1.6498) | Xent 0.2059(0.2531) | Xent Color 0.0490(0.1494) | Loss 1.6157(1.7504) | Error 0.0689(0.0799) | Error Color 0.0067(0.0304) |Steps 590(599.31) | Grad Norm 1.6437(3.6761) | Total Time 10.00(10.00)\n",
      "Iter 5930 | Time 13.6512(13.4140) | Bit/dim 1.7834(1.6423) | Xent 0.4839(0.2559) | Xent Color 2.8015(0.3886) | Loss 2.6047(1.8034) | Error 0.1433(0.0796) | Error Color 0.4656(0.0739) |Steps 596(597.82) | Grad Norm 98.8251(9.6163) | Total Time 10.00(10.00)\n",
      "Iter 5940 | Time 15.6717(13.6020) | Bit/dim 1.8629(1.7077) | Xent 0.5752(0.2884) | Xent Color 0.5874(0.5785) | Loss 2.1535(1.9244) | Error 0.1878(0.0909) | Error Color 0.2422(0.1527) |Steps 656(604.86) | Grad Norm 8.1780(10.0046) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 83.0616, Epoch Time 998.6332(985.4524), Bit/dim 1.8714(best: 0.7167), Xent 0.2340, Xent Color 0.3076. Loss 2.0068, Error 0.0633(best: 0.0168), Error Color 0.0890(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 5950 | Time 14.2439(13.8161) | Bit/dim 1.7948(1.7368) | Xent 0.3107(0.2941) | Xent Color 0.3919(0.5459) | Loss 1.9704(1.9468) | Error 0.0944(0.0927) | Error Color 0.1444(0.1585) |Steps 644(615.94) | Grad Norm 2.6287(8.2080) | Total Time 10.00(10.00)\n",
      "Iter 5960 | Time 14.1938(13.8941) | Bit/dim 1.7190(1.7393) | Xent 0.2219(0.2830) | Xent Color 0.2379(0.4752) | Loss 1.8339(1.9289) | Error 0.0644(0.0888) | Error Color 0.0711(0.1414) |Steps 632(620.15) | Grad Norm 1.2760(6.4391) | Total Time 10.00(10.00)\n",
      "Iter 5970 | Time 13.5181(13.8779) | Bit/dim 1.6794(1.7262) | Xent 0.2554(0.2735) | Xent Color 0.1665(0.4000) | Loss 1.7849(1.8946) | Error 0.0900(0.0852) | Error Color 0.0522(0.1200) |Steps 608(619.52) | Grad Norm 0.8845(5.0208) | Total Time 10.00(10.00)\n",
      "Iter 5980 | Time 13.1048(13.7001) | Bit/dim 1.6223(1.7030) | Xent 0.2167(0.2650) | Xent Color 0.1251(0.3324) | Loss 1.7077(1.8524) | Error 0.0756(0.0825) | Error Color 0.0333(0.0988) |Steps 596(614.36) | Grad Norm 0.7674(3.9518) | Total Time 10.00(10.00)\n",
      "Iter 5990 | Time 13.1675(13.5198) | Bit/dim 1.5877(1.6757) | Xent 0.2274(0.2529) | Xent Color 0.1133(0.2757) | Loss 1.6729(1.8079) | Error 0.0722(0.0789) | Error Color 0.0244(0.0798) |Steps 590(609.23) | Grad Norm 0.9670(3.1106) | Total Time 10.00(10.00)\n",
      "Iter 6000 | Time 13.1670(13.3649) | Bit/dim 1.5501(1.6482) | Xent 0.2105(0.2421) | Xent Color 0.0823(0.2280) | Loss 1.6233(1.7657) | Error 0.0622(0.0764) | Error Color 0.0122(0.0640) |Steps 590(602.97) | Grad Norm 0.9241(2.6946) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 75.8486, Epoch Time 993.3607(985.6896), Bit/dim 1.5317(best: 0.7167), Xent 0.1212, Xent Color 0.0348. Loss 1.5707, Error 0.0378(best: 0.0168), Error Color 0.0009(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6010 | Time 12.9790(13.3031) | Bit/dim 1.5117(1.6183) | Xent 0.2097(0.2354) | Xent Color 0.0779(0.1898) | Loss 1.5836(1.7246) | Error 0.0656(0.0744) | Error Color 0.0144(0.0514) |Steps 590(599.81) | Grad Norm 1.8377(2.3534) | Total Time 10.00(10.00)\n",
      "Iter 6020 | Time 13.7035(13.3301) | Bit/dim 1.4658(1.5867) | Xent 0.2049(0.2282) | Xent Color 0.0702(0.1600) | Loss 1.5346(1.6837) | Error 0.0600(0.0718) | Error Color 0.0144(0.0416) |Steps 584(597.97) | Grad Norm 0.8821(2.0779) | Total Time 10.00(10.00)\n",
      "Iter 6030 | Time 13.2982(13.3031) | Bit/dim 1.4527(1.5543) | Xent 0.1982(0.2218) | Xent Color 0.0593(0.1356) | Loss 1.5171(1.6436) | Error 0.0644(0.0697) | Error Color 0.0078(0.0335) |Steps 584(596.34) | Grad Norm 0.9680(1.7988) | Total Time 10.00(10.00)\n",
      "Iter 6040 | Time 13.1429(13.2607) | Bit/dim 1.3963(1.5186) | Xent 0.2424(0.2183) | Xent Color 0.0594(0.1156) | Loss 1.4717(1.6020) | Error 0.0667(0.0680) | Error Color 0.0100(0.0272) |Steps 578(592.98) | Grad Norm 0.9702(1.5908) | Total Time 10.00(10.00)\n",
      "Iter 6050 | Time 13.9831(13.2710) | Bit/dim 1.3747(1.4846) | Xent 0.1981(0.2142) | Xent Color 0.0663(0.0998) | Loss 1.4408(1.5631) | Error 0.0667(0.0676) | Error Color 0.0111(0.0224) |Steps 590(591.63) | Grad Norm 1.3847(1.4221) | Total Time 10.00(10.00)\n",
      "Iter 6060 | Time 13.4204(13.3699) | Bit/dim 1.3399(1.4509) | Xent 0.1701(0.2139) | Xent Color 0.0480(0.0874) | Loss 1.3944(1.5262) | Error 0.0500(0.0673) | Error Color 0.0067(0.0189) |Steps 602(593.74) | Grad Norm 0.9885(1.3704) | Total Time 10.00(10.00)\n",
      "Iter 6070 | Time 13.9481(13.4742) | Bit/dim 1.2978(1.4158) | Xent 0.1880(0.2107) | Xent Color 0.0448(0.0781) | Loss 1.3560(1.4880) | Error 0.0567(0.0664) | Error Color 0.0089(0.0164) |Steps 602(596.06) | Grad Norm 1.9597(1.4400) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 76.6133, Epoch Time 985.2267(985.6757), Bit/dim 1.2907(best: 0.7167), Xent 0.1136, Xent Color 0.0155. Loss 1.3230, Error 0.0365(best: 0.0168), Error Color 0.0003(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6080 | Time 13.5974(13.5579) | Bit/dim 1.2489(1.3791) | Xent 0.1908(0.2065) | Xent Color 0.0707(0.0727) | Loss 1.3142(1.4489) | Error 0.0622(0.0660) | Error Color 0.0189(0.0148) |Steps 602(597.79) | Grad Norm 2.8566(1.7706) | Total Time 10.00(10.00)\n",
      "Iter 6090 | Time 13.9209(13.6004) | Bit/dim 1.2270(1.3419) | Xent 0.1637(0.2000) | Xent Color 0.0526(0.0697) | Loss 1.2811(1.4093) | Error 0.0567(0.0638) | Error Color 0.0133(0.0146) |Steps 602(599.19) | Grad Norm 3.3281(2.3220) | Total Time 10.00(10.00)\n",
      "Iter 6100 | Time 13.8260(13.6520) | Bit/dim 1.2155(1.3088) | Xent 0.2201(0.1990) | Xent Color 0.0449(0.0672) | Loss 1.2817(1.3754) | Error 0.0722(0.0629) | Error Color 0.0078(0.0143) |Steps 608(601.16) | Grad Norm 3.5600(2.8792) | Total Time 10.00(10.00)\n",
      "Iter 6110 | Time 13.7813(13.6919) | Bit/dim 1.1890(1.2765) | Xent 0.1954(0.2017) | Xent Color 0.0495(0.0631) | Loss 1.2502(1.3427) | Error 0.0633(0.0636) | Error Color 0.0133(0.0133) |Steps 602(602.68) | Grad Norm 3.8553(2.8680) | Total Time 10.00(10.00)\n",
      "Iter 6120 | Time 13.8826(13.7096) | Bit/dim 1.1721(1.2501) | Xent 0.2244(0.2002) | Xent Color 0.0426(0.0568) | Loss 1.2388(1.3143) | Error 0.0689(0.0626) | Error Color 0.0100(0.0115) |Steps 602(603.91) | Grad Norm 2.2137(2.8738) | Total Time 10.00(10.00)\n",
      "Iter 6130 | Time 14.1188(13.7523) | Bit/dim 1.1465(1.2257) | Xent 0.1966(0.1988) | Xent Color 0.0293(0.0525) | Loss 1.2030(1.2885) | Error 0.0611(0.0617) | Error Color 0.0044(0.0103) |Steps 608(605.62) | Grad Norm 2.9301(2.6631) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 78.8629, Epoch Time 1013.3513(986.5060), Bit/dim 1.1393(best: 0.7167), Xent 0.1024, Xent Color 0.0094. Loss 1.1673, Error 0.0321(best: 0.0168), Error Color 0.0003(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6140 | Time 13.7958(13.7908) | Bit/dim 1.1332(1.2042) | Xent 0.1746(0.1932) | Xent Color 0.0380(0.0485) | Loss 1.1864(1.2646) | Error 0.0522(0.0598) | Error Color 0.0078(0.0093) |Steps 620(608.01) | Grad Norm 1.3971(2.9288) | Total Time 10.00(10.00)\n",
      "Iter 6150 | Time 14.4524(13.8762) | Bit/dim 1.1013(1.1836) | Xent 0.1821(0.1910) | Xent Color 0.0441(0.0452) | Loss 1.1578(1.2427) | Error 0.0611(0.0594) | Error Color 0.0078(0.0085) |Steps 632(610.05) | Grad Norm 2.2221(2.7430) | Total Time 10.00(10.00)\n",
      "Iter 6160 | Time 14.4541(13.9256) | Bit/dim 1.1088(1.1650) | Xent 0.1808(0.1856) | Xent Color 0.0297(0.0417) | Loss 1.1614(1.2219) | Error 0.0622(0.0585) | Error Color 0.0033(0.0077) |Steps 620(612.17) | Grad Norm 1.1226(2.4569) | Total Time 10.00(10.00)\n",
      "Iter 6170 | Time 14.0542(14.0038) | Bit/dim 1.1061(1.1481) | Xent 0.2006(0.1847) | Xent Color 0.0318(0.0390) | Loss 1.1642(1.2040) | Error 0.0622(0.0579) | Error Color 0.0078(0.0071) |Steps 614(612.87) | Grad Norm 6.7261(2.5667) | Total Time 10.00(10.00)\n",
      "Iter 6180 | Time 14.6049(14.0721) | Bit/dim 1.0830(1.1333) | Xent 0.1780(0.1823) | Xent Color 0.0297(0.0372) | Loss 1.1350(1.1882) | Error 0.0633(0.0571) | Error Color 0.0056(0.0067) |Steps 614(611.76) | Grad Norm 1.3127(2.8059) | Total Time 10.00(10.00)\n",
      "Iter 6190 | Time 14.2352(14.0966) | Bit/dim 1.0599(1.1184) | Xent 0.1824(0.1812) | Xent Color 0.0334(0.0353) | Loss 1.1139(1.1725) | Error 0.0589(0.0571) | Error Color 0.0056(0.0063) |Steps 602(611.07) | Grad Norm 2.1679(2.7009) | Total Time 10.00(10.00)\n",
      "Iter 6200 | Time 14.1867(14.1378) | Bit/dim 1.0577(1.1042) | Xent 0.1497(0.1775) | Xent Color 0.0305(0.0336) | Loss 1.1027(1.1570) | Error 0.0400(0.0560) | Error Color 0.0033(0.0058) |Steps 626(611.20) | Grad Norm 1.1310(2.4705) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 81.9962, Epoch Time 1041.2510(988.1484), Bit/dim 1.0498(best: 0.7167), Xent 0.0903, Xent Color 0.0066. Loss 1.0740, Error 0.0279(best: 0.0168), Error Color 0.0004(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6210 | Time 13.9474(14.1978) | Bit/dim 1.0623(1.0900) | Xent 0.1830(0.1767) | Xent Color 0.0388(0.0327) | Loss 1.1177(1.1424) | Error 0.0556(0.0558) | Error Color 0.0100(0.0057) |Steps 590(611.97) | Grad Norm 5.9311(2.3849) | Total Time 10.00(10.00)\n",
      "Iter 6220 | Time 14.3270(14.2193) | Bit/dim 1.0417(1.0796) | Xent 0.1945(0.1750) | Xent Color 0.0359(0.0327) | Loss 1.0993(1.1316) | Error 0.0544(0.0556) | Error Color 0.0067(0.0058) |Steps 626(612.42) | Grad Norm 2.6189(3.0203) | Total Time 10.00(10.00)\n",
      "Iter 6230 | Time 14.2240(14.2267) | Bit/dim 1.0312(1.0666) | Xent 0.1706(0.1712) | Xent Color 0.0292(0.0316) | Loss 1.0812(1.1173) | Error 0.0578(0.0546) | Error Color 0.0067(0.0058) |Steps 608(613.11) | Grad Norm 1.9581(2.7354) | Total Time 10.00(10.00)\n",
      "Iter 6240 | Time 14.2747(14.2809) | Bit/dim 1.0309(1.0552) | Xent 0.2129(0.1711) | Xent Color 0.0265(0.0301) | Loss 1.0907(1.1054) | Error 0.0556(0.0542) | Error Color 0.0044(0.0053) |Steps 614(614.35) | Grad Norm 2.3828(2.5555) | Total Time 10.00(10.00)\n",
      "Iter 6250 | Time 14.4965(14.3330) | Bit/dim 1.0176(1.0429) | Xent 0.1967(0.1702) | Xent Color 0.0221(0.0291) | Loss 1.0723(1.0927) | Error 0.0589(0.0529) | Error Color 0.0022(0.0049) |Steps 620(615.63) | Grad Norm 3.1918(2.6554) | Total Time 10.00(10.00)\n",
      "Iter 6260 | Time 14.3850(14.3486) | Bit/dim 1.0044(1.0344) | Xent 0.1869(0.1693) | Xent Color 0.0220(0.0282) | Loss 1.0567(1.0837) | Error 0.0578(0.0524) | Error Color 0.0011(0.0046) |Steps 620(617.32) | Grad Norm 3.3467(2.8827) | Total Time 10.00(10.00)\n",
      "Iter 6270 | Time 14.7516(14.4178) | Bit/dim 1.0019(1.0255) | Xent 0.1692(0.1658) | Xent Color 0.0217(0.0267) | Loss 1.0496(1.0736) | Error 0.0500(0.0516) | Error Color 0.0022(0.0042) |Steps 638(620.15) | Grad Norm 6.2635(2.9574) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 80.8637, Epoch Time 1054.5583(990.1407), Bit/dim 1.0017(best: 0.7167), Xent 0.0862, Xent Color 0.0069. Loss 1.0250, Error 0.0267(best: 0.0168), Error Color 0.0003(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6280 | Time 14.5910(14.4513) | Bit/dim 1.0021(1.0182) | Xent 0.1465(0.1640) | Xent Color 0.0180(0.0275) | Loss 1.0432(1.0661) | Error 0.0444(0.0508) | Error Color 0.0022(0.0046) |Steps 620(621.12) | Grad Norm 2.6401(3.3874) | Total Time 10.00(10.00)\n",
      "Iter 6290 | Time 14.3400(14.5057) | Bit/dim 0.9931(1.0105) | Xent 0.1353(0.1615) | Xent Color 0.0214(0.0271) | Loss 1.0322(1.0577) | Error 0.0411(0.0503) | Error Color 0.0044(0.0047) |Steps 626(624.28) | Grad Norm 2.6358(3.5535) | Total Time 10.00(10.00)\n",
      "Iter 6300 | Time 14.4958(14.5145) | Bit/dim 0.9693(1.0030) | Xent 0.1706(0.1606) | Xent Color 0.0241(0.0263) | Loss 1.0180(1.0497) | Error 0.0511(0.0503) | Error Color 0.0044(0.0047) |Steps 632(626.40) | Grad Norm 2.8023(3.4590) | Total Time 10.00(10.00)\n",
      "Iter 6310 | Time 14.7942(14.5219) | Bit/dim 0.9833(0.9961) | Xent 0.1303(0.1590) | Xent Color 0.0206(0.0258) | Loss 1.0210(1.0423) | Error 0.0422(0.0497) | Error Color 0.0011(0.0046) |Steps 626(627.03) | Grad Norm 3.5029(3.3930) | Total Time 10.00(10.00)\n",
      "Iter 6320 | Time 13.8737(14.5305) | Bit/dim 0.9713(0.9897) | Xent 0.1728(0.1589) | Xent Color 0.0230(0.0269) | Loss 1.0203(1.0361) | Error 0.0489(0.0498) | Error Color 0.0022(0.0050) |Steps 620(628.15) | Grad Norm 6.9076(4.0424) | Total Time 10.00(10.00)\n",
      "Iter 6330 | Time 13.8998(14.5173) | Bit/dim 0.9500(0.9830) | Xent 0.1554(0.1566) | Xent Color 0.0352(0.0269) | Loss 0.9976(1.0289) | Error 0.0500(0.0492) | Error Color 0.0067(0.0049) |Steps 632(628.66) | Grad Norm 3.0757(4.1740) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 82.0714, Epoch Time 1066.8126(992.4408), Bit/dim 0.9573(best: 0.7167), Xent 0.0810, Xent Color 0.0034. Loss 0.9784, Error 0.0243(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6340 | Time 14.6056(14.5469) | Bit/dim 0.9507(0.9780) | Xent 0.1468(0.1539) | Xent Color 0.0168(0.0253) | Loss 0.9916(1.0228) | Error 0.0467(0.0481) | Error Color 0.0011(0.0042) |Steps 638(629.09) | Grad Norm 3.6377(4.0688) | Total Time 10.00(10.00)\n",
      "Iter 6350 | Time 14.6160(14.5367) | Bit/dim 0.9511(0.9714) | Xent 0.1693(0.1532) | Xent Color 0.0218(0.0241) | Loss 0.9989(1.0157) | Error 0.0522(0.0483) | Error Color 0.0033(0.0042) |Steps 632(629.15) | Grad Norm 2.4126(3.6206) | Total Time 10.00(10.00)\n",
      "Iter 6360 | Time 15.2218(14.6074) | Bit/dim 0.9550(0.9650) | Xent 0.1661(0.1543) | Xent Color 0.0227(0.0227) | Loss 1.0022(1.0092) | Error 0.0522(0.0489) | Error Color 0.0056(0.0038) |Steps 638(631.16) | Grad Norm 4.4879(3.4499) | Total Time 10.00(10.00)\n",
      "Iter 6370 | Time 14.9835(14.6324) | Bit/dim 0.9579(0.9611) | Xent 0.1255(0.1512) | Xent Color 0.0278(0.0228) | Loss 0.9962(1.0046) | Error 0.0411(0.0479) | Error Color 0.0067(0.0038) |Steps 638(632.95) | Grad Norm 5.3630(3.9688) | Total Time 10.00(10.00)\n",
      "Iter 6380 | Time 14.8180(14.6853) | Bit/dim 0.9389(0.9556) | Xent 0.1694(0.1506) | Xent Color 0.0215(0.0220) | Loss 0.9866(0.9988) | Error 0.0589(0.0478) | Error Color 0.0033(0.0036) |Steps 638(633.31) | Grad Norm 2.1840(3.8091) | Total Time 10.00(10.00)\n",
      "Iter 6390 | Time 14.3924(14.6620) | Bit/dim 0.9335(0.9487) | Xent 0.1617(0.1504) | Xent Color 0.0246(0.0214) | Loss 0.9801(0.9917) | Error 0.0444(0.0479) | Error Color 0.0078(0.0034) |Steps 632(633.44) | Grad Norm 4.2396(3.5607) | Total Time 10.00(10.00)\n",
      "Iter 6400 | Time 14.6311(14.6184) | Bit/dim 0.9387(0.9440) | Xent 0.1652(0.1507) | Xent Color 0.0171(0.0210) | Loss 0.9842(0.9869) | Error 0.0567(0.0472) | Error Color 0.0033(0.0034) |Steps 656(632.59) | Grad Norm 8.9578(3.9392) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 82.3409, Epoch Time 1071.6932(994.8184), Bit/dim 0.9314(best: 0.7167), Xent 0.0781, Xent Color 0.0042. Loss 0.9520, Error 0.0251(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6410 | Time 14.4541(14.5440) | Bit/dim 0.9217(0.9403) | Xent 0.1327(0.1482) | Xent Color 0.0118(0.0200) | Loss 0.9579(0.9823) | Error 0.0444(0.0467) | Error Color 0.0000(0.0031) |Steps 626(630.03) | Grad Norm 2.1681(4.0504) | Total Time 10.00(10.00)\n",
      "Iter 6420 | Time 14.6356(14.5420) | Bit/dim 0.9166(0.9355) | Xent 0.1015(0.1452) | Xent Color 0.0194(0.0194) | Loss 0.9468(0.9766) | Error 0.0333(0.0460) | Error Color 0.0044(0.0031) |Steps 626(628.79) | Grad Norm 3.4665(3.8870) | Total Time 10.00(10.00)\n",
      "Iter 6430 | Time 14.4933(14.5165) | Bit/dim 0.9199(0.9316) | Xent 0.1417(0.1442) | Xent Color 0.0151(0.0190) | Loss 0.9591(0.9724) | Error 0.0422(0.0457) | Error Color 0.0011(0.0030) |Steps 614(627.39) | Grad Norm 3.1346(4.0410) | Total Time 10.00(10.00)\n",
      "Iter 6440 | Time 14.2567(14.4510) | Bit/dim 0.9075(0.9259) | Xent 0.1287(0.1451) | Xent Color 0.0148(0.0180) | Loss 0.9434(0.9667) | Error 0.0467(0.0458) | Error Color 0.0022(0.0028) |Steps 620(627.45) | Grad Norm 3.3556(3.6309) | Total Time 10.00(10.00)\n",
      "Iter 6450 | Time 14.6012(14.4545) | Bit/dim 0.9129(0.9235) | Xent 0.1674(0.1452) | Xent Color 0.0172(0.0183) | Loss 0.9591(0.9644) | Error 0.0522(0.0458) | Error Color 0.0033(0.0028) |Steps 632(626.04) | Grad Norm 3.6756(4.2772) | Total Time 10.00(10.00)\n",
      "Iter 6460 | Time 14.3544(14.4411) | Bit/dim 0.9212(0.9209) | Xent 0.1530(0.1460) | Xent Color 0.0236(0.0185) | Loss 0.9654(0.9620) | Error 0.0456(0.0448) | Error Color 0.0033(0.0029) |Steps 626(625.82) | Grad Norm 6.2890(4.3861) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 79.7654, Epoch Time 1053.8200(996.5884), Bit/dim 0.9177(best: 0.7167), Xent 0.0740, Xent Color 0.0031. Loss 0.9369, Error 0.0230(best: 0.0168), Error Color 0.0002(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6470 | Time 14.2052(14.3875) | Bit/dim 0.9025(0.9180) | Xent 0.1138(0.1448) | Xent Color 0.0172(0.0180) | Loss 0.9353(0.9586) | Error 0.0356(0.0452) | Error Color 0.0033(0.0027) |Steps 632(623.94) | Grad Norm 4.0758(4.5151) | Total Time 10.00(10.00)\n",
      "Iter 6480 | Time 14.4051(14.3207) | Bit/dim 0.8998(0.9144) | Xent 0.1475(0.1447) | Xent Color 0.0219(0.0178) | Loss 0.9421(0.9550) | Error 0.0500(0.0449) | Error Color 0.0022(0.0027) |Steps 632(622.40) | Grad Norm 6.1536(4.4906) | Total Time 10.00(10.00)\n",
      "Iter 6490 | Time 14.4314(14.3492) | Bit/dim 0.8948(0.9102) | Xent 0.1235(0.1415) | Xent Color 0.0148(0.0174) | Loss 0.9293(0.9500) | Error 0.0378(0.0441) | Error Color 0.0011(0.0027) |Steps 626(623.14) | Grad Norm 3.9205(4.5165) | Total Time 10.00(10.00)\n",
      "Iter 6500 | Time 14.5713(14.3972) | Bit/dim 0.8879(0.9060) | Xent 0.1285(0.1360) | Xent Color 0.0141(0.0165) | Loss 0.9235(0.9442) | Error 0.0411(0.0422) | Error Color 0.0000(0.0024) |Steps 602(624.68) | Grad Norm 4.1247(4.0905) | Total Time 10.00(10.00)\n",
      "Iter 6510 | Time 14.2908(14.3900) | Bit/dim 0.8992(0.9044) | Xent 0.1389(0.1390) | Xent Color 0.0171(0.0173) | Loss 0.9381(0.9435) | Error 0.0511(0.0431) | Error Color 0.0022(0.0026) |Steps 626(624.20) | Grad Norm 4.7752(4.7546) | Total Time 10.00(10.00)\n",
      "Iter 6520 | Time 15.0357(14.4493) | Bit/dim 0.8916(0.9013) | Xent 0.1084(0.1366) | Xent Color 0.0133(0.0167) | Loss 0.9220(0.9396) | Error 0.0300(0.0423) | Error Color 0.0000(0.0024) |Steps 638(626.15) | Grad Norm 1.7671(4.6062) | Total Time 10.00(10.00)\n",
      "Iter 6530 | Time 14.9532(14.4990) | Bit/dim 0.8787(0.8957) | Xent 0.1532(0.1350) | Xent Color 0.0159(0.0159) | Loss 0.9209(0.9334) | Error 0.0467(0.0421) | Error Color 0.0033(0.0023) |Steps 638(627.99) | Grad Norm 2.2907(4.3761) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 82.3361, Epoch Time 1059.1144(998.4642), Bit/dim 0.8803(best: 0.7167), Xent 0.0751, Xent Color 0.0025. Loss 0.8997, Error 0.0235(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6540 | Time 13.8089(14.5168) | Bit/dim 1.1046(0.9005) | Xent 0.1765(0.1383) | Xent Color 2.4871(0.0937) | Loss 1.7705(0.9585) | Error 0.0489(0.0433) | Error Color 0.3844(0.0156) |Steps 608(629.42) | Grad Norm 74.8792(7.1342) | Total Time 10.00(10.00)\n",
      "Iter 6550 | Time 16.3614(14.9681) | Bit/dim 1.8891(1.1677) | Xent 0.4667(0.3773) | Xent Color 1.0802(1.3245) | Loss 2.2758(1.5931) | Error 0.1433(0.1139) | Error Color 0.3922(0.1631) |Steps 752(657.48) | Grad Norm 12.8600(16.3948) | Total Time 10.00(10.00)\n",
      "Iter 6560 | Time 16.5160(15.2587) | Bit/dim 1.6780(1.3322) | Xent 0.3114(0.3655) | Xent Color 0.4792(1.1233) | Loss 1.8757(1.7044) | Error 0.0956(0.1114) | Error Color 0.2011(0.1770) |Steps 746(681.38) | Grad Norm 6.3611(13.9205) | Total Time 10.00(10.00)\n",
      "Iter 6570 | Time 16.1716(15.4122) | Bit/dim 1.5610(1.4049) | Xent 0.2061(0.3398) | Xent Color 0.3148(0.9070) | Loss 1.6912(1.7166) | Error 0.0644(0.1049) | Error Color 0.1200(0.1572) |Steps 740(694.26) | Grad Norm 4.9972(11.4709) | Total Time 10.00(10.00)\n",
      "Iter 6580 | Time 16.0954(15.6331) | Bit/dim 1.4576(1.4300) | Xent 0.2247(0.3067) | Xent Color 0.1235(0.7194) | Loss 1.5447(1.6865) | Error 0.0678(0.0947) | Error Color 0.0344(0.1314) |Steps 746(707.84) | Grad Norm 1.9035(9.0915) | Total Time 10.00(10.00)\n",
      "Iter 6590 | Time 15.6575(15.7160) | Bit/dim 1.3440(1.4208) | Xent 0.1619(0.2755) | Xent Color 0.1099(0.5617) | Loss 1.4119(1.6301) | Error 0.0589(0.0853) | Error Color 0.0267(0.1045) |Steps 716(713.29) | Grad Norm 1.4935(7.2218) | Total Time 10.00(10.00)\n",
      "Iter 6600 | Time 16.3356(15.7701) | Bit/dim 1.2497(1.3873) | Xent 0.1621(0.2562) | Xent Color 0.0957(0.4419) | Loss 1.3142(1.5618) | Error 0.0489(0.0795) | Error Color 0.0267(0.0846) |Steps 710(714.48) | Grad Norm 2.5257(5.9569) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 87.5875, Epoch Time 1161.4536(1003.3539), Bit/dim 1.2534(best: 0.7167), Xent 0.1002, Xent Color 0.0324. Loss 1.2866, Error 0.0314(best: 0.0168), Error Color 0.0020(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6610 | Time 16.2775(15.8664) | Bit/dim 1.2021(1.3447) | Xent 0.1763(0.2371) | Xent Color 0.0897(0.3493) | Loss 1.2686(1.4913) | Error 0.0533(0.0738) | Error Color 0.0211(0.0676) |Steps 728(717.99) | Grad Norm 1.5033(4.8110) | Total Time 10.00(10.00)\n",
      "Iter 6620 | Time 15.7530(15.8705) | Bit/dim 1.1556(1.2994) | Xent 0.1750(0.2221) | Xent Color 0.0673(0.2780) | Loss 1.2161(1.4244) | Error 0.0544(0.0694) | Error Color 0.0122(0.0545) |Steps 734(716.82) | Grad Norm 4.5894(4.3724) | Total Time 10.00(10.00)\n",
      "Iter 6630 | Time 15.6371(15.8057) | Bit/dim 1.1326(1.2584) | Xent 0.1828(0.2052) | Xent Color 0.0695(0.2212) | Loss 1.1957(1.3650) | Error 0.0522(0.0640) | Error Color 0.0200(0.0438) |Steps 716(714.91) | Grad Norm 0.9916(3.6503) | Total Time 10.00(10.00)\n",
      "Iter 6640 | Time 15.8755(15.7475) | Bit/dim 1.0953(1.2195) | Xent 0.1801(0.1956) | Xent Color 0.0526(0.1771) | Loss 1.1535(1.3127) | Error 0.0622(0.0616) | Error Color 0.0144(0.0356) |Steps 692(711.83) | Grad Norm 1.9356(3.0806) | Total Time 10.00(10.00)\n",
      "Iter 6650 | Time 15.1282(15.6674) | Bit/dim 1.0742(1.1857) | Xent 0.1621(0.1894) | Xent Color 0.0454(0.1439) | Loss 1.1260(1.2691) | Error 0.0533(0.0600) | Error Color 0.0078(0.0291) |Steps 704(709.81) | Grad Norm 0.9083(2.5249) | Total Time 10.00(10.00)\n",
      "Iter 6660 | Time 16.0026(15.6966) | Bit/dim 1.0759(1.1568) | Xent 0.1381(0.1806) | Xent Color 0.0418(0.1184) | Loss 1.1209(1.2316) | Error 0.0456(0.0572) | Error Color 0.0089(0.0239) |Steps 704(708.46) | Grad Norm 2.1289(2.2655) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 86.3476, Epoch Time 1147.5131(1007.6787), Bit/dim 1.0566(best: 0.7167), Xent 0.0830, Xent Color 0.0106. Loss 1.0800, Error 0.0245(best: 0.0168), Error Color 0.0004(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6670 | Time 15.7953(15.6749) | Bit/dim 1.0515(1.1301) | Xent 0.1850(0.1750) | Xent Color 0.0372(0.0989) | Loss 1.1071(1.1986) | Error 0.0578(0.0557) | Error Color 0.0033(0.0195) |Steps 692(704.53) | Grad Norm 1.8705(2.0541) | Total Time 10.00(10.00)\n",
      "Iter 6680 | Time 15.3779(15.6071) | Bit/dim 1.0504(1.1082) | Xent 0.1684(0.1700) | Xent Color 0.0374(0.0827) | Loss 1.1019(1.1714) | Error 0.0556(0.0535) | Error Color 0.0056(0.0162) |Steps 686(700.12) | Grad Norm 1.3644(1.8987) | Total Time 10.00(10.00)\n",
      "Iter 6690 | Time 15.3813(15.5807) | Bit/dim 1.0303(1.0877) | Xent 0.1227(0.1669) | Xent Color 0.0344(0.0709) | Loss 1.0696(1.1471) | Error 0.0400(0.0523) | Error Color 0.0089(0.0138) |Steps 686(696.87) | Grad Norm 1.4853(1.7470) | Total Time 10.00(10.00)\n",
      "Iter 6700 | Time 15.4651(15.5480) | Bit/dim 1.0211(1.0707) | Xent 0.1570(0.1621) | Xent Color 0.0289(0.0613) | Loss 1.0676(1.1265) | Error 0.0444(0.0511) | Error Color 0.0022(0.0114) |Steps 686(694.64) | Grad Norm 1.2720(1.7357) | Total Time 10.00(10.00)\n",
      "Iter 6710 | Time 15.6093(15.5323) | Bit/dim 1.0058(1.0549) | Xent 0.1494(0.1582) | Xent Color 0.0372(0.0542) | Loss 1.0524(1.1081) | Error 0.0478(0.0492) | Error Color 0.0056(0.0100) |Steps 686(692.50) | Grad Norm 2.4669(1.7798) | Total Time 10.00(10.00)\n",
      "Iter 6720 | Time 15.2448(15.5363) | Bit/dim 0.9922(1.0412) | Xent 0.1169(0.1546) | Xent Color 0.0402(0.0489) | Loss 1.0315(1.0921) | Error 0.0367(0.0488) | Error Color 0.0078(0.0090) |Steps 686(690.79) | Grad Norm 1.1109(1.7025) | Total Time 10.00(10.00)\n",
      "Iter 6730 | Time 15.6314(15.5086) | Bit/dim 0.9876(1.0292) | Xent 0.1287(0.1513) | Xent Color 0.0247(0.0435) | Loss 1.0260(1.0779) | Error 0.0433(0.0481) | Error Color 0.0033(0.0078) |Steps 680(689.67) | Grad Norm 1.0098(1.7216) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 83.6792, Epoch Time 1129.0851(1011.3209), Bit/dim 0.9911(best: 0.7167), Xent 0.0799, Xent Color 0.0063. Loss 1.0127, Error 0.0260(best: 0.0168), Error Color 0.0001(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6740 | Time 15.1782(15.4882) | Bit/dim 0.9839(1.0183) | Xent 0.1177(0.1455) | Xent Color 0.0254(0.0394) | Loss 1.0197(1.0646) | Error 0.0400(0.0464) | Error Color 0.0067(0.0070) |Steps 674(686.30) | Grad Norm 1.2208(1.6837) | Total Time 10.00(10.00)\n",
      "Iter 6750 | Time 15.4752(15.4445) | Bit/dim 0.9752(1.0085) | Xent 0.1360(0.1480) | Xent Color 0.0266(0.0363) | Loss 1.0158(1.0546) | Error 0.0478(0.0466) | Error Color 0.0022(0.0064) |Steps 674(683.65) | Grad Norm 2.3762(1.7461) | Total Time 10.00(10.00)\n",
      "Iter 6760 | Time 15.4878(15.4018) | Bit/dim 0.9627(0.9998) | Xent 0.1431(0.1453) | Xent Color 0.0215(0.0334) | Loss 1.0039(1.0445) | Error 0.0367(0.0454) | Error Color 0.0011(0.0055) |Steps 680(682.20) | Grad Norm 1.8573(1.9724) | Total Time 10.00(10.00)\n",
      "Iter 6770 | Time 15.1627(15.3666) | Bit/dim 0.9688(0.9914) | Xent 0.1431(0.1435) | Xent Color 0.0219(0.0311) | Loss 1.0101(1.0351) | Error 0.0411(0.0450) | Error Color 0.0022(0.0051) |Steps 668(679.86) | Grad Norm 1.0022(2.0004) | Total Time 10.00(10.00)\n",
      "Iter 6780 | Time 15.1423(15.3552) | Bit/dim 0.9637(0.9843) | Xent 0.1427(0.1426) | Xent Color 0.0225(0.0287) | Loss 1.0050(1.0271) | Error 0.0467(0.0445) | Error Color 0.0022(0.0044) |Steps 668(677.21) | Grad Norm 2.1664(1.9346) | Total Time 10.00(10.00)\n",
      "Iter 6790 | Time 14.6989(15.3276) | Bit/dim 0.9428(0.9762) | Xent 0.1367(0.1410) | Xent Color 0.0219(0.0274) | Loss 0.9825(1.0183) | Error 0.0444(0.0440) | Error Color 0.0033(0.0041) |Steps 668(675.39) | Grad Norm 2.3916(2.1833) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 86.2164, Epoch Time 1120.4631(1014.5951), Bit/dim 0.9483(best: 0.7167), Xent 0.0743, Xent Color 0.0052. Loss 0.9682, Error 0.0226(best: 0.0168), Error Color 0.0001(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6800 | Time 15.1804(15.3271) | Bit/dim 0.9592(0.9689) | Xent 0.1562(0.1426) | Xent Color 0.0246(0.0264) | Loss 1.0044(1.0112) | Error 0.0511(0.0447) | Error Color 0.0033(0.0041) |Steps 668(673.45) | Grad Norm 1.1281(2.0932) | Total Time 10.00(10.00)\n",
      "Iter 6810 | Time 14.8587(15.2360) | Bit/dim 0.9471(0.9620) | Xent 0.1419(0.1399) | Xent Color 0.0236(0.0258) | Loss 0.9884(1.0034) | Error 0.0378(0.0431) | Error Color 0.0033(0.0039) |Steps 674(672.20) | Grad Norm 1.0685(2.0378) | Total Time 10.00(10.00)\n",
      "Iter 6820 | Time 15.2261(15.2121) | Bit/dim 0.9489(0.9566) | Xent 0.1455(0.1385) | Xent Color 0.0301(0.0255) | Loss 0.9928(0.9976) | Error 0.0456(0.0425) | Error Color 0.0078(0.0040) |Steps 680(671.59) | Grad Norm 3.5628(2.4480) | Total Time 10.00(10.00)\n",
      "Iter 6830 | Time 15.4572(15.2144) | Bit/dim 0.9303(0.9508) | Xent 0.1064(0.1390) | Xent Color 0.0167(0.0239) | Loss 0.9611(0.9915) | Error 0.0333(0.0429) | Error Color 0.0022(0.0037) |Steps 668(671.57) | Grad Norm 1.8393(2.4840) | Total Time 10.00(10.00)\n",
      "Iter 6840 | Time 15.3897(15.2428) | Bit/dim 0.9334(0.9452) | Xent 0.1337(0.1393) | Xent Color 0.0217(0.0230) | Loss 0.9722(0.9858) | Error 0.0489(0.0434) | Error Color 0.0044(0.0035) |Steps 686(672.04) | Grad Norm 2.8481(2.3534) | Total Time 10.00(10.00)\n",
      "Iter 6850 | Time 15.8108(15.3203) | Bit/dim 0.9336(0.9422) | Xent 0.1441(0.1378) | Xent Color 0.0196(0.0223) | Loss 0.9745(0.9822) | Error 0.0500(0.0432) | Error Color 0.0033(0.0033) |Steps 686(675.13) | Grad Norm 4.2435(2.6109) | Total Time 10.00(10.00)\n",
      "Iter 6860 | Time 15.4067(15.3809) | Bit/dim 0.9249(0.9373) | Xent 0.1520(0.1369) | Xent Color 0.0228(0.0218) | Loss 0.9686(0.9770) | Error 0.0467(0.0437) | Error Color 0.0044(0.0032) |Steps 680(676.56) | Grad Norm 3.9913(2.7032) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 84.3283, Epoch Time 1118.4017(1017.7093), Bit/dim 0.9198(best: 0.7167), Xent 0.0738, Xent Color 0.0037. Loss 0.9392, Error 0.0237(best: 0.0168), Error Color 0.0001(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6870 | Time 15.4148(15.4270) | Bit/dim 0.9111(0.9317) | Xent 0.1252(0.1365) | Xent Color 0.0206(0.0212) | Loss 0.9476(0.9712) | Error 0.0389(0.0430) | Error Color 0.0056(0.0032) |Steps 686(677.73) | Grad Norm 1.4846(2.6564) | Total Time 10.00(10.00)\n",
      "Iter 6880 | Time 15.4193(15.4522) | Bit/dim 0.9209(0.9275) | Xent 0.1257(0.1367) | Xent Color 0.0158(0.0203) | Loss 0.9563(0.9667) | Error 0.0422(0.0429) | Error Color 0.0022(0.0031) |Steps 686(679.08) | Grad Norm 2.6227(2.5808) | Total Time 10.00(10.00)\n",
      "Iter 6890 | Time 16.2527(15.5638) | Bit/dim 0.9073(0.9231) | Xent 0.1490(0.1332) | Xent Color 0.0169(0.0197) | Loss 0.9488(0.9614) | Error 0.0433(0.0422) | Error Color 0.0022(0.0030) |Steps 686(681.20) | Grad Norm 1.2494(2.5773) | Total Time 10.00(10.00)\n",
      "Iter 6900 | Time 15.3469(15.6484) | Bit/dim 0.9171(0.9206) | Xent 0.1385(0.1338) | Xent Color 0.0209(0.0199) | Loss 0.9569(0.9590) | Error 0.0433(0.0423) | Error Color 0.0033(0.0032) |Steps 680(684.15) | Grad Norm 6.3374(2.7821) | Total Time 10.00(10.00)\n",
      "Iter 6910 | Time 16.0738(15.7103) | Bit/dim 0.8979(0.9168) | Xent 0.1370(0.1324) | Xent Color 0.0210(0.0194) | Loss 0.9374(0.9548) | Error 0.0422(0.0412) | Error Color 0.0044(0.0031) |Steps 686(684.71) | Grad Norm 1.4569(2.6917) | Total Time 10.00(10.00)\n",
      "Iter 6920 | Time 16.1403(15.7710) | Bit/dim 0.9038(0.9130) | Xent 0.1201(0.1307) | Xent Color 0.0185(0.0184) | Loss 0.9384(0.9502) | Error 0.0356(0.0407) | Error Color 0.0056(0.0028) |Steps 698(687.44) | Grad Norm 3.2950(2.6481) | Total Time 10.00(10.00)\n",
      "Iter 6930 | Time 15.5616(15.8067) | Bit/dim 0.8915(0.9092) | Xent 0.1099(0.1335) | Xent Color 0.0143(0.0178) | Loss 0.9226(0.9470) | Error 0.0367(0.0407) | Error Color 0.0000(0.0026) |Steps 692(688.86) | Grad Norm 4.0733(2.7386) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 85.7913, Epoch Time 1152.1237(1021.7418), Bit/dim 0.8972(best: 0.7167), Xent 0.0735, Xent Color 0.0028. Loss 0.9162, Error 0.0232(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 6940 | Time 15.8212(15.8388) | Bit/dim 0.8935(0.9058) | Xent 0.0956(0.1309) | Xent Color 0.0173(0.0172) | Loss 0.9217(0.9428) | Error 0.0300(0.0404) | Error Color 0.0022(0.0024) |Steps 692(689.67) | Grad Norm 1.6997(2.6980) | Total Time 10.00(10.00)\n",
      "Iter 6950 | Time 16.2415(15.8926) | Bit/dim 0.9000(0.9029) | Xent 0.1298(0.1325) | Xent Color 0.0153(0.0169) | Loss 0.9363(0.9403) | Error 0.0389(0.0406) | Error Color 0.0033(0.0025) |Steps 692(690.61) | Grad Norm 4.2009(2.9168) | Total Time 10.00(10.00)\n",
      "Iter 6960 | Time 15.8321(15.8988) | Bit/dim 0.8743(0.8992) | Xent 0.1201(0.1326) | Xent Color 0.0175(0.0164) | Loss 0.9086(0.9365) | Error 0.0400(0.0416) | Error Color 0.0044(0.0023) |Steps 692(690.78) | Grad Norm 0.9815(2.6258) | Total Time 10.00(10.00)\n",
      "Iter 6970 | Time 16.0900(15.9268) | Bit/dim 0.8921(0.8974) | Xent 0.0830(0.1295) | Xent Color 0.0137(0.0159) | Loss 0.9163(0.9337) | Error 0.0244(0.0403) | Error Color 0.0000(0.0021) |Steps 698(691.77) | Grad Norm 1.3312(2.8349) | Total Time 10.00(10.00)\n",
      "Iter 6980 | Time 16.0257(15.9547) | Bit/dim 0.8881(0.8942) | Xent 0.1224(0.1287) | Xent Color 0.0138(0.0154) | Loss 0.9222(0.9302) | Error 0.0400(0.0400) | Error Color 0.0011(0.0020) |Steps 692(692.30) | Grad Norm 1.4743(2.8013) | Total Time 10.00(10.00)\n",
      "Iter 6990 | Time 16.1974(15.9684) | Bit/dim 0.8802(0.8912) | Xent 0.1265(0.1275) | Xent Color 0.0107(0.0153) | Loss 0.9145(0.9269) | Error 0.0400(0.0399) | Error Color 0.0000(0.0020) |Steps 680(691.08) | Grad Norm 2.3293(2.9829) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 85.0203, Epoch Time 1164.4162(1026.0220), Bit/dim 0.8798(best: 0.7167), Xent 0.0679, Xent Color 0.0023. Loss 0.8974, Error 0.0205(best: 0.0168), Error Color 0.0001(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7000 | Time 16.2423(16.0242) | Bit/dim 0.8750(0.8876) | Xent 0.1069(0.1242) | Xent Color 0.0129(0.0150) | Loss 0.9049(0.9224) | Error 0.0389(0.0386) | Error Color 0.0011(0.0020) |Steps 680(690.16) | Grad Norm 3.7598(2.8621) | Total Time 10.00(10.00)\n",
      "Iter 7010 | Time 16.3195(16.0201) | Bit/dim 0.8781(0.8853) | Xent 0.1264(0.1252) | Xent Color 0.0102(0.0149) | Loss 0.9122(0.9203) | Error 0.0422(0.0394) | Error Color 0.0000(0.0019) |Steps 692(690.52) | Grad Norm 3.4090(3.1508) | Total Time 10.00(10.00)\n",
      "Iter 7020 | Time 15.7430(15.9995) | Bit/dim 0.8749(0.8827) | Xent 0.1342(0.1252) | Xent Color 0.0135(0.0146) | Loss 0.9119(0.9177) | Error 0.0500(0.0400) | Error Color 0.0011(0.0018) |Steps 692(690.91) | Grad Norm 2.8845(3.1103) | Total Time 10.00(10.00)\n",
      "Iter 7030 | Time 16.0127(15.9938) | Bit/dim 0.8789(0.8806) | Xent 0.1168(0.1241) | Xent Color 0.0108(0.0144) | Loss 0.9108(0.9152) | Error 0.0311(0.0393) | Error Color 0.0011(0.0019) |Steps 674(690.04) | Grad Norm 3.1791(3.1240) | Total Time 10.00(10.00)\n",
      "Iter 7040 | Time 15.7986(15.9827) | Bit/dim 0.8787(0.8789) | Xent 0.1563(0.1273) | Xent Color 0.0138(0.0144) | Loss 0.9213(0.9143) | Error 0.0456(0.0399) | Error Color 0.0011(0.0019) |Steps 680(687.74) | Grad Norm 5.4964(3.1728) | Total Time 10.00(10.00)\n",
      "Iter 7050 | Time 15.5813(15.9934) | Bit/dim 0.8781(0.8764) | Xent 0.1199(0.1259) | Xent Color 0.0100(0.0144) | Loss 0.9106(0.9115) | Error 0.0367(0.0395) | Error Color 0.0000(0.0019) |Steps 692(686.03) | Grad Norm 1.3975(3.1953) | Total Time 10.00(10.00)\n",
      "Iter 7060 | Time 16.0343(15.9306) | Bit/dim 0.8700(0.8730) | Xent 0.1093(0.1249) | Xent Color 0.0160(0.0142) | Loss 0.9013(0.9078) | Error 0.0322(0.0396) | Error Color 0.0011(0.0018) |Steps 686(683.44) | Grad Norm 2.2800(3.1749) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 86.0187, Epoch Time 1161.5932(1030.0891), Bit/dim 0.8691(best: 0.7167), Xent 0.0668, Xent Color 0.0021. Loss 0.8863, Error 0.0227(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7070 | Time 15.8071(15.8348) | Bit/dim 0.8589(0.8711) | Xent 0.1086(0.1257) | Xent Color 0.0160(0.0138) | Loss 0.8901(0.9059) | Error 0.0300(0.0399) | Error Color 0.0022(0.0018) |Steps 674(682.51) | Grad Norm 2.2548(3.6076) | Total Time 10.00(10.00)\n",
      "Iter 7080 | Time 15.6888(15.8184) | Bit/dim 0.8634(0.8684) | Xent 0.0846(0.1244) | Xent Color 0.0129(0.0135) | Loss 0.8878(0.9029) | Error 0.0333(0.0398) | Error Color 0.0033(0.0019) |Steps 674(680.64) | Grad Norm 2.0421(3.3716) | Total Time 10.00(10.00)\n",
      "Iter 7090 | Time 15.8601(15.8550) | Bit/dim 0.8532(0.8655) | Xent 0.1242(0.1242) | Xent Color 0.0138(0.0133) | Loss 0.8877(0.8998) | Error 0.0378(0.0399) | Error Color 0.0033(0.0019) |Steps 680(680.66) | Grad Norm 2.4710(3.2222) | Total Time 10.00(10.00)\n",
      "Iter 7100 | Time 16.3886(15.8992) | Bit/dim 0.8674(0.8648) | Xent 0.1136(0.1249) | Xent Color 0.0134(0.0132) | Loss 0.8991(0.8993) | Error 0.0400(0.0399) | Error Color 0.0000(0.0020) |Steps 692(682.09) | Grad Norm 3.2508(3.3275) | Total Time 10.00(10.00)\n",
      "Iter 7110 | Time 16.1789(15.9094) | Bit/dim 0.8584(0.8633) | Xent 0.1386(0.1258) | Xent Color 0.0094(0.0128) | Loss 0.8954(0.8979) | Error 0.0411(0.0404) | Error Color 0.0000(0.0018) |Steps 692(683.49) | Grad Norm 3.6211(3.2670) | Total Time 10.00(10.00)\n",
      "Iter 7120 | Time 15.7190(15.8923) | Bit/dim 0.8509(0.8617) | Xent 0.1054(0.1241) | Xent Color 0.0126(0.0127) | Loss 0.8804(0.8959) | Error 0.0311(0.0395) | Error Color 0.0022(0.0018) |Steps 686(683.28) | Grad Norm 3.8062(3.4807) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 89.4916, Epoch Time 1159.9934(1033.9863), Bit/dim 0.8511(best: 0.7167), Xent 0.0650, Xent Color 0.0017. Loss 0.8678, Error 0.0221(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7130 | Time 15.9602(15.8980) | Bit/dim 0.8596(0.8599) | Xent 0.1301(0.1230) | Xent Color 0.0138(0.0123) | Loss 0.8955(0.8937) | Error 0.0444(0.0392) | Error Color 0.0011(0.0016) |Steps 692(684.49) | Grad Norm 3.2877(3.6690) | Total Time 10.00(10.00)\n",
      "Iter 7140 | Time 15.9676(15.8685) | Bit/dim 0.8499(0.8567) | Xent 0.1316(0.1235) | Xent Color 0.0103(0.0122) | Loss 0.8854(0.8906) | Error 0.0456(0.0395) | Error Color 0.0011(0.0017) |Steps 692(685.43) | Grad Norm 3.3968(3.8114) | Total Time 10.00(10.00)\n",
      "Iter 7150 | Time 16.0353(15.8804) | Bit/dim 0.8489(0.8539) | Xent 0.1162(0.1214) | Xent Color 0.0147(0.0119) | Loss 0.8816(0.8873) | Error 0.0311(0.0381) | Error Color 0.0022(0.0016) |Steps 686(685.19) | Grad Norm 3.0486(3.4827) | Total Time 10.00(10.00)\n",
      "Iter 7160 | Time 15.7729(15.8534) | Bit/dim 0.8584(0.8535) | Xent 0.1098(0.1167) | Xent Color 0.0175(0.0120) | Loss 0.8902(0.8856) | Error 0.0356(0.0369) | Error Color 0.0033(0.0015) |Steps 674(684.40) | Grad Norm 7.2016(3.9944) | Total Time 10.00(10.00)\n",
      "Iter 7170 | Time 15.8327(15.8428) | Bit/dim 0.8547(0.8538) | Xent 0.1409(0.1207) | Xent Color 0.0179(0.0124) | Loss 0.8944(0.8871) | Error 0.0411(0.0379) | Error Color 0.0022(0.0017) |Steps 680(683.27) | Grad Norm 3.7143(4.1874) | Total Time 10.00(10.00)\n",
      "Iter 7180 | Time 15.4682(15.8297) | Bit/dim 0.8361(0.8521) | Xent 0.0905(0.1227) | Xent Color 0.0162(0.0124) | Loss 0.8627(0.8859) | Error 0.0322(0.0386) | Error Color 0.0044(0.0017) |Steps 680(681.84) | Grad Norm 2.1142(4.1109) | Total Time 10.00(10.00)\n",
      "Iter 7190 | Time 15.9116(15.8576) | Bit/dim 0.8369(0.8499) | Xent 0.1171(0.1198) | Xent Color 0.0108(0.0121) | Loss 0.8689(0.8829) | Error 0.0311(0.0377) | Error Color 0.0022(0.0016) |Steps 686(682.49) | Grad Norm 3.5805(3.9762) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 87.9199, Epoch Time 1156.4559(1037.6604), Bit/dim 0.8375(best: 0.7167), Xent 0.0661, Xent Color 0.0018. Loss 0.8544, Error 0.0213(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7200 | Time 15.6571(15.8302) | Bit/dim 0.8337(0.8469) | Xent 0.1152(0.1194) | Xent Color 0.0136(0.0119) | Loss 0.8659(0.8797) | Error 0.0433(0.0377) | Error Color 0.0022(0.0016) |Steps 686(681.85) | Grad Norm 4.9945(4.1295) | Total Time 10.00(10.00)\n",
      "Iter 7210 | Time 15.6756(15.8274) | Bit/dim 0.8390(0.8439) | Xent 0.1195(0.1180) | Xent Color 0.0081(0.0113) | Loss 0.8709(0.8763) | Error 0.0411(0.0367) | Error Color 0.0000(0.0015) |Steps 686(680.91) | Grad Norm 3.2653(4.0495) | Total Time 10.00(10.00)\n",
      "Iter 7220 | Time 15.7307(15.8223) | Bit/dim 0.8345(0.8416) | Xent 0.1095(0.1181) | Xent Color 0.0108(0.0111) | Loss 0.8646(0.8739) | Error 0.0333(0.0372) | Error Color 0.0011(0.0015) |Steps 686(681.93) | Grad Norm 3.3714(3.9959) | Total Time 10.00(10.00)\n",
      "Iter 7230 | Time 15.8419(15.8172) | Bit/dim 0.8459(0.8410) | Xent 0.1201(0.1220) | Xent Color 0.0092(0.0108) | Loss 0.8782(0.8742) | Error 0.0344(0.0377) | Error Color 0.0000(0.0014) |Steps 680(681.10) | Grad Norm 7.8890(4.1318) | Total Time 10.00(10.00)\n",
      "Iter 7240 | Time 15.6609(15.8409) | Bit/dim 0.8291(0.8390) | Xent 0.1358(0.1216) | Xent Color 0.0118(0.0106) | Loss 0.8660(0.8721) | Error 0.0378(0.0374) | Error Color 0.0011(0.0013) |Steps 692(681.39) | Grad Norm 2.5100(4.0676) | Total Time 10.00(10.00)\n",
      "Iter 7250 | Time 15.5467(15.7937) | Bit/dim 0.8278(0.8382) | Xent 0.1011(0.1193) | Xent Color 0.0123(0.0104) | Loss 0.8562(0.8706) | Error 0.0356(0.0371) | Error Color 0.0022(0.0014) |Steps 680(680.60) | Grad Norm 4.5598(4.1715) | Total Time 10.00(10.00)\n",
      "Iter 7260 | Time 15.9435(15.8025) | Bit/dim 0.8384(0.8365) | Xent 0.1150(0.1163) | Xent Color 0.0092(0.0101) | Loss 0.8695(0.8681) | Error 0.0311(0.0366) | Error Color 0.0000(0.0012) |Steps 680(681.66) | Grad Norm 4.4054(4.1622) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 88.4427, Epoch Time 1155.2940(1041.1894), Bit/dim 0.8286(best: 0.7167), Xent 0.0624, Xent Color 0.0016. Loss 0.8445, Error 0.0206(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7270 | Time 15.9086(15.7876) | Bit/dim 0.8201(0.8336) | Xent 0.1326(0.1170) | Xent Color 0.0108(0.0102) | Loss 0.8559(0.8654) | Error 0.0356(0.0364) | Error Color 0.0011(0.0013) |Steps 686(681.54) | Grad Norm 2.9344(4.3831) | Total Time 10.00(10.00)\n",
      "Iter 7280 | Time 15.7917(15.8023) | Bit/dim 0.8190(0.8312) | Xent 0.1011(0.1163) | Xent Color 0.0121(0.0103) | Loss 0.8473(0.8628) | Error 0.0322(0.0365) | Error Color 0.0033(0.0014) |Steps 680(682.74) | Grad Norm 4.3691(4.3806) | Total Time 10.00(10.00)\n",
      "Iter 7290 | Time 15.8437(15.8215) | Bit/dim 0.8276(0.8307) | Xent 0.1042(0.1175) | Xent Color 0.0130(0.0107) | Loss 0.8569(0.8628) | Error 0.0333(0.0368) | Error Color 0.0022(0.0015) |Steps 686(683.66) | Grad Norm 5.4956(4.8001) | Total Time 10.00(10.00)\n",
      "Iter 7300 | Time 15.5141(15.8233) | Bit/dim 0.8269(0.8287) | Xent 0.1257(0.1188) | Xent Color 0.0086(0.0103) | Loss 0.8605(0.8610) | Error 0.0400(0.0370) | Error Color 0.0000(0.0012) |Steps 668(682.50) | Grad Norm 6.0113(4.7904) | Total Time 10.00(10.00)\n",
      "Iter 7310 | Time 16.0336(15.8596) | Bit/dim 0.8211(0.8289) | Xent 0.1273(0.1179) | Xent Color 0.0103(0.0103) | Loss 0.8555(0.8610) | Error 0.0433(0.0366) | Error Color 0.0011(0.0014) |Steps 704(682.78) | Grad Norm 6.5932(4.8784) | Total Time 10.00(10.00)\n",
      "Iter 7320 | Time 16.1776(15.7985) | Bit/dim 0.8272(0.8279) | Xent 0.1282(0.1214) | Xent Color 0.0057(0.0101) | Loss 0.8607(0.8608) | Error 0.0467(0.0381) | Error Color 0.0000(0.0013) |Steps 668(680.67) | Grad Norm 2.4871(4.8879) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 88.3803, Epoch Time 1155.6581(1044.6234), Bit/dim 0.8262(best: 0.7167), Xent 0.0636, Xent Color 0.0010. Loss 0.8423, Error 0.0213(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7330 | Time 15.9387(15.7736) | Bit/dim 0.8404(0.8285) | Xent 0.1044(0.1199) | Xent Color 0.0177(0.0100) | Loss 0.8709(0.8610) | Error 0.0322(0.0380) | Error Color 0.0022(0.0013) |Steps 704(678.62) | Grad Norm 9.3443(5.1527) | Total Time 10.00(10.00)\n",
      "Iter 7340 | Time 15.3713(15.7445) | Bit/dim 0.8235(0.8280) | Xent 0.1080(0.1177) | Xent Color 0.0063(0.0100) | Loss 0.8521(0.8600) | Error 0.0311(0.0374) | Error Color 0.0000(0.0013) |Steps 662(677.76) | Grad Norm 4.7958(5.5055) | Total Time 10.00(10.00)\n",
      "Iter 7350 | Time 16.0538(15.7552) | Bit/dim 0.8223(0.8266) | Xent 0.1112(0.1185) | Xent Color 0.0093(0.0097) | Loss 0.8524(0.8586) | Error 0.0367(0.0375) | Error Color 0.0011(0.0011) |Steps 686(677.57) | Grad Norm 3.7472(5.2583) | Total Time 10.00(10.00)\n",
      "Iter 7360 | Time 15.7811(15.6934) | Bit/dim 0.8144(0.8233) | Xent 0.1455(0.1183) | Xent Color 0.0078(0.0095) | Loss 0.8527(0.8553) | Error 0.0433(0.0370) | Error Color 0.0011(0.0011) |Steps 668(675.37) | Grad Norm 4.7478(4.8746) | Total Time 10.00(10.00)\n",
      "Iter 7370 | Time 16.2219(15.6701) | Bit/dim 0.8101(0.8208) | Xent 0.1023(0.1170) | Xent Color 0.0101(0.0095) | Loss 0.8382(0.8524) | Error 0.0400(0.0369) | Error Color 0.0011(0.0010) |Steps 674(675.23) | Grad Norm 5.1059(4.9513) | Total Time 10.00(10.00)\n",
      "Iter 7380 | Time 15.2202(15.6748) | Bit/dim 0.8166(0.8207) | Xent 0.1123(0.1167) | Xent Color 0.0084(0.0092) | Loss 0.8467(0.8521) | Error 0.0356(0.0367) | Error Color 0.0011(0.0011) |Steps 662(675.99) | Grad Norm 5.0995(5.1455) | Total Time 10.00(10.00)\n",
      "Iter 7390 | Time 15.5764(15.6623) | Bit/dim 0.8193(0.8193) | Xent 0.0727(0.1131) | Xent Color 0.0137(0.0094) | Loss 0.8409(0.8499) | Error 0.0311(0.0357) | Error Color 0.0011(0.0011) |Steps 656(675.49) | Grad Norm 7.5577(5.3218) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 88.4863, Epoch Time 1143.3200(1047.5843), Bit/dim 0.8227(best: 0.7167), Xent 0.0568, Xent Color 0.0014. Loss 0.8373, Error 0.0181(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7400 | Time 15.5427(15.6065) | Bit/dim 0.8340(0.8202) | Xent 0.1305(0.1140) | Xent Color 0.0100(0.0100) | Loss 0.8691(0.8512) | Error 0.0311(0.0356) | Error Color 0.0000(0.0015) |Steps 662(674.41) | Grad Norm 8.5286(5.7691) | Total Time 10.00(10.00)\n",
      "Iter 7410 | Time 17.6635(15.7251) | Bit/dim 2.0688(0.9520) | Xent 1.0652(0.1778) | Xent Color 6.0971(1.0622) | Loss 3.8594(1.2620) | Error 0.2533(0.0517) | Error Color 0.5711(0.0714) |Steps 794(682.37) | Grad Norm 42.1004(16.1279) | Total Time 10.00(10.00)\n",
      "Iter 7420 | Time 15.8993(16.1246) | Bit/dim 1.7450(1.1780) | Xent 0.2569(0.2415) | Xent Color 1.2746(1.4019) | Loss 2.1279(1.5889) | Error 0.0744(0.0723) | Error Color 0.4700(0.1950) |Steps 734(707.75) | Grad Norm 10.0386(15.2358) | Total Time 10.00(10.00)\n",
      "Iter 7430 | Time 15.4051(16.0470) | Bit/dim 1.5167(1.2912) | Xent 0.1828(0.2434) | Xent Color 0.6628(1.2685) | Loss 1.7281(1.6691) | Error 0.0522(0.0741) | Error Color 0.2722(0.2357) |Steps 716(710.88) | Grad Norm 3.7269(12.5885) | Total Time 10.00(10.00)\n",
      "Iter 7440 | Time 15.8002(15.9726) | Bit/dim 1.3586(1.3277) | Xent 0.2119(0.2334) | Xent Color 0.4450(1.0697) | Loss 1.5228(1.6535) | Error 0.0622(0.0711) | Error Color 0.1589(0.2242) |Steps 728(710.25) | Grad Norm 1.8678(9.9451) | Total Time 10.00(10.00)\n",
      "Iter 7450 | Time 14.7910(15.8563) | Bit/dim 1.2831(1.3200) | Xent 0.1370(0.2157) | Xent Color 0.2791(0.8811) | Loss 1.3872(1.5942) | Error 0.0444(0.0659) | Error Color 0.0833(0.1976) |Steps 698(708.92) | Grad Norm 1.6569(7.8669) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 90.9508, Epoch Time 1168.4001(1051.2088), Bit/dim 1.2041(best: 0.7167), Xent 0.0810, Xent Color 0.0815. Loss 1.2447, Error 0.0249(best: 0.0168), Error Color 0.0052(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7460 | Time 15.9209(15.8126) | Bit/dim 1.1820(1.2951) | Xent 0.1645(0.1996) | Xent Color 0.1872(0.7060) | Loss 1.2699(1.5215) | Error 0.0533(0.0617) | Error Color 0.0544(0.1623) |Steps 722(706.95) | Grad Norm 1.5125(6.1966) | Total Time 10.00(10.00)\n",
      "Iter 7470 | Time 15.3071(15.7681) | Bit/dim 1.1271(1.2597) | Xent 0.1724(0.1881) | Xent Color 0.1294(0.5559) | Loss 1.2026(1.4457) | Error 0.0489(0.0582) | Error Color 0.0267(0.1274) |Steps 704(706.14) | Grad Norm 1.6174(4.9309) | Total Time 10.00(10.00)\n",
      "Iter 7480 | Time 16.2108(15.8176) | Bit/dim 1.0902(1.2193) | Xent 0.1295(0.1754) | Xent Color 0.0894(0.4372) | Loss 1.1450(1.3725) | Error 0.0422(0.0543) | Error Color 0.0178(0.0997) |Steps 710(707.31) | Grad Norm 0.7772(3.9777) | Total Time 10.00(10.00)\n",
      "Iter 7490 | Time 16.0846(15.8555) | Bit/dim 1.0649(1.1782) | Xent 0.1286(0.1657) | Xent Color 0.0768(0.3432) | Loss 1.1162(1.3054) | Error 0.0467(0.0518) | Error Color 0.0156(0.0778) |Steps 716(709.28) | Grad Norm 0.8842(3.2381) | Total Time 10.00(10.00)\n",
      "Iter 7500 | Time 16.7068(15.9216) | Bit/dim 1.0077(1.1389) | Xent 0.0864(0.1556) | Xent Color 0.0787(0.2712) | Loss 1.0489(1.2456) | Error 0.0267(0.0485) | Error Color 0.0189(0.0607) |Steps 722(710.64) | Grad Norm 1.0041(2.6518) | Total Time 10.00(10.00)\n",
      "Iter 7510 | Time 16.7820(16.0919) | Bit/dim 0.9895(1.1030) | Xent 0.1293(0.1476) | Xent Color 0.0617(0.2162) | Loss 1.0373(1.1940) | Error 0.0511(0.0460) | Error Color 0.0156(0.0479) |Steps 734(715.58) | Grad Norm 1.3565(2.2394) | Total Time 10.00(10.00)\n",
      "Iter 7520 | Time 16.6511(16.2722) | Bit/dim 0.9692(1.0706) | Xent 0.1723(0.1439) | Xent Color 0.0595(0.1743) | Loss 1.0271(1.1501) | Error 0.0478(0.0451) | Error Color 0.0111(0.0380) |Steps 728(719.99) | Grad Norm 1.7501(2.0371) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 92.0654, Epoch Time 1183.6498(1055.1820), Bit/dim 0.9651(best: 0.7167), Xent 0.0713, Xent Color 0.0147. Loss 0.9866, Error 0.0244(best: 0.0168), Error Color 0.0002(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7530 | Time 16.7058(16.3926) | Bit/dim 0.9621(1.0436) | Xent 0.0927(0.1408) | Xent Color 0.0488(0.1423) | Loss 0.9975(1.1143) | Error 0.0356(0.0446) | Error Color 0.0067(0.0302) |Steps 740(724.06) | Grad Norm 3.8593(1.9704) | Total Time 10.00(10.00)\n",
      "Iter 7540 | Time 16.9685(16.4489) | Bit/dim 0.9432(1.0196) | Xent 0.1140(0.1362) | Xent Color 0.0564(0.1195) | Loss 0.9858(1.0835) | Error 0.0378(0.0428) | Error Color 0.0111(0.0253) |Steps 740(727.91) | Grad Norm 2.5594(2.5893) | Total Time 10.00(10.00)\n",
      "Iter 7550 | Time 16.4566(16.5044) | Bit/dim 0.9343(0.9999) | Xent 0.1243(0.1329) | Xent Color 0.0449(0.1004) | Loss 0.9766(1.0582) | Error 0.0356(0.0412) | Error Color 0.0078(0.0210) |Steps 728(729.09) | Grad Norm 4.4742(2.8747) | Total Time 10.00(10.00)\n",
      "Iter 7560 | Time 16.4482(16.4955) | Bit/dim 0.9362(0.9815) | Xent 0.1563(0.1326) | Xent Color 0.0484(0.0868) | Loss 0.9874(1.0363) | Error 0.0478(0.0409) | Error Color 0.0167(0.0182) |Steps 716(728.42) | Grad Norm 4.0447(3.1430) | Total Time 10.00(10.00)\n",
      "Iter 7570 | Time 16.5712(16.5285) | Bit/dim 0.9093(0.9654) | Xent 0.1107(0.1309) | Xent Color 0.0339(0.0758) | Loss 0.9454(1.0171) | Error 0.0300(0.0404) | Error Color 0.0022(0.0156) |Steps 710(728.13) | Grad Norm 2.7443(3.2341) | Total Time 10.00(10.00)\n",
      "Iter 7580 | Time 16.6753(16.5424) | Bit/dim 0.9175(0.9514) | Xent 0.1171(0.1298) | Xent Color 0.0359(0.0667) | Loss 0.9558(1.0005) | Error 0.0389(0.0407) | Error Color 0.0067(0.0133) |Steps 734(726.66) | Grad Norm 3.0699(3.1046) | Total Time 10.00(10.00)\n",
      "Iter 7590 | Time 16.6839(16.5463) | Bit/dim 0.9082(0.9369) | Xent 0.1290(0.1301) | Xent Color 0.0355(0.0601) | Loss 0.9493(0.9845) | Error 0.0511(0.0405) | Error Color 0.0067(0.0118) |Steps 728(724.60) | Grad Norm 5.6499(3.2335) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 87.3698, Epoch Time 1206.2444(1059.7139), Bit/dim 0.9082(best: 0.7167), Xent 0.0638, Xent Color 0.0098. Loss 0.9266, Error 0.0207(best: 0.0168), Error Color 0.0001(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7600 | Time 16.4627(16.5195) | Bit/dim 0.8922(0.9259) | Xent 0.1032(0.1280) | Xent Color 0.0254(0.0542) | Loss 0.9244(0.9714) | Error 0.0278(0.0395) | Error Color 0.0044(0.0105) |Steps 710(722.61) | Grad Norm 3.2161(3.4126) | Total Time 10.00(10.00)\n",
      "Iter 7610 | Time 15.9506(16.4613) | Bit/dim 0.8797(0.9155) | Xent 0.1049(0.1252) | Xent Color 0.0387(0.0493) | Loss 0.9156(0.9591) | Error 0.0311(0.0392) | Error Color 0.0067(0.0092) |Steps 710(719.72) | Grad Norm 2.6736(3.4243) | Total Time 10.00(10.00)\n",
      "Iter 7620 | Time 15.9834(16.3711) | Bit/dim 0.8728(0.9072) | Xent 0.1421(0.1271) | Xent Color 0.0316(0.0461) | Loss 0.9162(0.9505) | Error 0.0389(0.0395) | Error Color 0.0044(0.0085) |Steps 704(716.38) | Grad Norm 2.5170(3.3529) | Total Time 10.00(10.00)\n",
      "Iter 7630 | Time 16.3461(16.3479) | Bit/dim 0.8795(0.8992) | Xent 0.1190(0.1252) | Xent Color 0.0232(0.0429) | Loss 0.9151(0.9412) | Error 0.0400(0.0388) | Error Color 0.0044(0.0079) |Steps 704(715.53) | Grad Norm 4.2470(3.6012) | Total Time 10.00(10.00)\n",
      "Iter 7640 | Time 16.0814(16.2900) | Bit/dim 0.8725(0.8923) | Xent 0.1277(0.1240) | Xent Color 0.0454(0.0408) | Loss 0.9157(0.9335) | Error 0.0422(0.0381) | Error Color 0.0122(0.0076) |Steps 704(714.89) | Grad Norm 5.8093(3.9596) | Total Time 10.00(10.00)\n",
      "Iter 7650 | Time 15.8800(16.2603) | Bit/dim 0.8617(0.8846) | Xent 0.1203(0.1245) | Xent Color 0.0372(0.0381) | Loss 0.9011(0.9253) | Error 0.0389(0.0386) | Error Color 0.0056(0.0069) |Steps 698(713.72) | Grad Norm 4.8374(3.8235) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 90.0943, Epoch Time 1185.5178(1063.4880), Bit/dim 0.8655(best: 0.7167), Xent 0.0642, Xent Color 0.0065. Loss 0.8831, Error 0.0202(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7660 | Time 15.9192(16.2342) | Bit/dim 0.8572(0.8795) | Xent 0.1153(0.1221) | Xent Color 0.0368(0.0362) | Loss 0.8952(0.9190) | Error 0.0333(0.0377) | Error Color 0.0078(0.0063) |Steps 722(713.85) | Grad Norm 4.4836(4.1898) | Total Time 10.00(10.00)\n",
      "Iter 7670 | Time 16.3176(16.1961) | Bit/dim 0.8591(0.8749) | Xent 0.1363(0.1216) | Xent Color 0.0235(0.0335) | Loss 0.8990(0.9137) | Error 0.0400(0.0374) | Error Color 0.0022(0.0057) |Steps 716(712.82) | Grad Norm 2.4005(4.2295) | Total Time 10.00(10.00)\n",
      "Iter 7680 | Time 16.3303(16.2048) | Bit/dim 0.8579(0.8702) | Xent 0.1064(0.1203) | Xent Color 0.0179(0.0308) | Loss 0.8890(0.9080) | Error 0.0289(0.0367) | Error Color 0.0000(0.0051) |Steps 716(712.45) | Grad Norm 1.7382(3.8612) | Total Time 10.00(10.00)\n",
      "Iter 7690 | Time 16.6119(16.2134) | Bit/dim 0.8383(0.8642) | Xent 0.1172(0.1221) | Xent Color 0.0223(0.0292) | Loss 0.8732(0.9020) | Error 0.0322(0.0373) | Error Color 0.0011(0.0048) |Steps 704(711.86) | Grad Norm 2.3165(3.8168) | Total Time 10.00(10.00)\n",
      "Iter 7700 | Time 16.3537(16.2297) | Bit/dim 0.8374(0.8584) | Xent 0.1232(0.1195) | Xent Color 0.0209(0.0277) | Loss 0.8734(0.8952) | Error 0.0322(0.0363) | Error Color 0.0011(0.0044) |Steps 722(711.65) | Grad Norm 3.8839(3.9302) | Total Time 10.00(10.00)\n",
      "Iter 7710 | Time 16.4252(16.1776) | Bit/dim 0.8403(0.8538) | Xent 0.1059(0.1176) | Xent Color 0.0236(0.0264) | Loss 0.8727(0.8898) | Error 0.0322(0.0360) | Error Color 0.0033(0.0040) |Steps 716(708.71) | Grad Norm 4.1063(3.8631) | Total Time 10.00(10.00)\n",
      "Iter 7720 | Time 15.8759(16.1295) | Bit/dim 0.8476(0.8495) | Xent 0.1144(0.1152) | Xent Color 0.0191(0.0248) | Loss 0.8810(0.8845) | Error 0.0356(0.0352) | Error Color 0.0033(0.0038) |Steps 698(706.50) | Grad Norm 2.1859(3.4736) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 88.2726, Epoch Time 1176.6309(1066.8823), Bit/dim 0.8399(best: 0.7167), Xent 0.0604, Xent Color 0.0035. Loss 0.8559, Error 0.0192(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7730 | Time 15.9552(16.0712) | Bit/dim 0.8301(0.8452) | Xent 0.0777(0.1124) | Xent Color 0.0197(0.0236) | Loss 0.8544(0.8792) | Error 0.0256(0.0344) | Error Color 0.0011(0.0037) |Steps 710(704.97) | Grad Norm 5.1221(3.5183) | Total Time 10.00(10.00)\n",
      "Iter 7740 | Time 15.7357(16.0264) | Bit/dim 0.8379(0.8418) | Xent 0.1250(0.1129) | Xent Color 0.0163(0.0225) | Loss 0.8732(0.8757) | Error 0.0378(0.0351) | Error Color 0.0011(0.0034) |Steps 680(700.92) | Grad Norm 3.0107(3.7364) | Total Time 10.00(10.00)\n",
      "Iter 7750 | Time 15.6566(15.9412) | Bit/dim 0.8259(0.8397) | Xent 0.1121(0.1150) | Xent Color 0.0160(0.0212) | Loss 0.8579(0.8737) | Error 0.0322(0.0356) | Error Color 0.0000(0.0030) |Steps 698(698.58) | Grad Norm 4.3676(3.8520) | Total Time 10.00(10.00)\n",
      "Iter 7760 | Time 15.8011(15.9241) | Bit/dim 0.8181(0.8367) | Xent 0.1024(0.1162) | Xent Color 0.0155(0.0203) | Loss 0.8476(0.8709) | Error 0.0233(0.0353) | Error Color 0.0022(0.0028) |Steps 680(697.73) | Grad Norm 2.9628(3.7549) | Total Time 10.00(10.00)\n",
      "Iter 7770 | Time 15.5496(15.8967) | Bit/dim 0.8374(0.8338) | Xent 0.1337(0.1168) | Xent Color 0.0122(0.0197) | Loss 0.8739(0.8679) | Error 0.0433(0.0363) | Error Color 0.0000(0.0028) |Steps 692(697.63) | Grad Norm 3.1693(3.6778) | Total Time 10.00(10.00)\n",
      "Iter 7780 | Time 15.6018(15.8921) | Bit/dim 0.8306(0.8319) | Xent 0.0974(0.1157) | Xent Color 0.0143(0.0191) | Loss 0.8586(0.8656) | Error 0.0289(0.0361) | Error Color 0.0033(0.0027) |Steps 686(697.08) | Grad Norm 5.1738(3.9819) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 91.2762, Epoch Time 1161.6738(1069.7260), Bit/dim 0.8231(best: 0.7167), Xent 0.0641, Xent Color 0.0030. Loss 0.8399, Error 0.0213(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7790 | Time 15.7825(15.9097) | Bit/dim 0.8256(0.8311) | Xent 0.1108(0.1154) | Xent Color 0.0160(0.0190) | Loss 0.8573(0.8647) | Error 0.0356(0.0359) | Error Color 0.0011(0.0027) |Steps 704(696.51) | Grad Norm 5.1897(4.3666) | Total Time 10.00(10.00)\n",
      "Iter 7800 | Time 15.7817(15.8935) | Bit/dim 0.8245(0.8291) | Xent 0.1239(0.1155) | Xent Color 0.0150(0.0181) | Loss 0.8592(0.8625) | Error 0.0478(0.0360) | Error Color 0.0011(0.0025) |Steps 686(696.14) | Grad Norm 4.7510(4.4493) | Total Time 10.00(10.00)\n",
      "Iter 7810 | Time 16.0124(15.8676) | Bit/dim 0.8086(0.8260) | Xent 0.0814(0.1137) | Xent Color 0.0171(0.0173) | Loss 0.8332(0.8587) | Error 0.0278(0.0360) | Error Color 0.0044(0.0024) |Steps 698(695.58) | Grad Norm 1.6092(4.2349) | Total Time 10.00(10.00)\n",
      "Iter 7820 | Time 16.0697(15.8943) | Bit/dim 0.8317(0.8244) | Xent 0.1001(0.1137) | Xent Color 0.0166(0.0170) | Loss 0.8609(0.8571) | Error 0.0322(0.0360) | Error Color 0.0033(0.0024) |Steps 692(694.84) | Grad Norm 5.7315(4.5342) | Total Time 10.00(10.00)\n",
      "Iter 7830 | Time 16.0664(15.8882) | Bit/dim 0.8255(0.8230) | Xent 0.1468(0.1133) | Xent Color 0.0104(0.0162) | Loss 0.8648(0.8553) | Error 0.0389(0.0357) | Error Color 0.0000(0.0021) |Steps 692(694.23) | Grad Norm 5.2392(4.5244) | Total Time 10.00(10.00)\n",
      "Iter 7840 | Time 15.4501(15.8620) | Bit/dim 0.8164(0.8203) | Xent 0.0911(0.1096) | Xent Color 0.0143(0.0154) | Loss 0.8427(0.8516) | Error 0.0356(0.0350) | Error Color 0.0033(0.0020) |Steps 692(694.29) | Grad Norm 3.8156(4.3555) | Total Time 10.00(10.00)\n",
      "Iter 7850 | Time 15.9671(15.8913) | Bit/dim 0.8145(0.8181) | Xent 0.0980(0.1105) | Xent Color 0.0164(0.0152) | Loss 0.8431(0.8496) | Error 0.0322(0.0345) | Error Color 0.0022(0.0021) |Steps 698(695.76) | Grad Norm 4.2492(4.4750) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 89.7160, Epoch Time 1161.0227(1072.4649), Bit/dim 0.8183(best: 0.7167), Xent 0.0603, Xent Color 0.0020. Loss 0.8339, Error 0.0189(best: 0.0168), Error Color 0.0000(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7860 | Time 15.5449(15.8501) | Bit/dim 0.8201(0.8171) | Xent 0.1328(0.1129) | Xent Color 0.0175(0.0151) | Loss 0.8577(0.8491) | Error 0.0378(0.0357) | Error Color 0.0011(0.0020) |Steps 698(697.42) | Grad Norm 8.6954(4.8068) | Total Time 10.00(10.00)\n",
      "Iter 7870 | Time 15.6892(15.8664) | Bit/dim 0.8034(0.8187) | Xent 0.0870(0.1112) | Xent Color 0.0132(0.0159) | Loss 0.8284(0.8505) | Error 0.0311(0.0353) | Error Color 0.0011(0.0024) |Steps 704(697.37) | Grad Norm 4.2670(5.4859) | Total Time 10.00(10.00)\n",
      "Iter 7880 | Time 15.7796(15.8622) | Bit/dim 0.8056(0.8178) | Xent 0.1296(0.1118) | Xent Color 0.0189(0.0160) | Loss 0.8427(0.8498) | Error 0.0444(0.0357) | Error Color 0.0056(0.0023) |Steps 704(696.69) | Grad Norm 4.8994(5.5964) | Total Time 10.00(10.00)\n",
      "Iter 7890 | Time 16.3778(15.8743) | Bit/dim 0.8018(0.8142) | Xent 0.0951(0.1113) | Xent Color 0.0113(0.0147) | Loss 0.8284(0.8457) | Error 0.0300(0.0355) | Error Color 0.0011(0.0022) |Steps 704(698.30) | Grad Norm 4.0340(4.9862) | Total Time 10.00(10.00)\n",
      "Iter 7900 | Time 15.7943(15.9124) | Bit/dim 0.8134(0.8119) | Xent 0.1251(0.1113) | Xent Color 0.0114(0.0140) | Loss 0.8475(0.8432) | Error 0.0344(0.0344) | Error Color 0.0000(0.0020) |Steps 710(699.96) | Grad Norm 7.0008(4.8133) | Total Time 10.00(10.00)\n",
      "Iter 7910 | Time 17.4586(16.0370) | Bit/dim 1.8235(0.9369) | Xent 0.3396(0.1890) | Xent Color 2.7526(0.6938) | Loss 2.5965(1.1576) | Error 0.0967(0.0590) | Error Color 0.5478(0.0953) |Steps 770(705.76) | Grad Norm 23.2080(15.2953) | Total Time 10.00(10.00)\n",
      "Iter 7920 | Time 16.5934(16.3669) | Bit/dim 1.6956(1.1496) | Xent 0.2636(0.2412) | Xent Color 0.5520(0.7647) | Loss 1.8995(1.4011) | Error 0.0856(0.0763) | Error Color 0.2367(0.1494) |Steps 770(725.87) | Grad Norm 9.6051(14.1367) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 91.3001, Epoch Time 1181.7658(1075.7440), Bit/dim 1.6547(best: 0.7167), Xent 0.1664, Xent Color 0.2425. Loss 1.7569, Error 0.0546(best: 0.0168), Error Color 0.1076(best: 0.0000)\n",
      "===> Using batch size 900. Total 66 iterations/epoch.\n",
      "Iter 7930 | Time 15.9750(16.3913) | Bit/dim 1.4459(1.2504) | Xent 0.1566(0.2291) | Xent Color 0.2225(0.6468) | Loss 1.5407(1.4694) | Error 0.0389(0.0721) | Error Color 0.0778(0.1424) |Steps 710(731.00) | Grad Norm 2.7232(11.4981) | Total Time 10.00(10.00)\n",
      "Iter 7940 | Time 15.0086(16.0025) | Bit/dim 1.3100(1.2800) | Xent 0.1462(0.2140) | Xent Color 0.1905(0.5347) | Loss 1.3942(1.4671) | Error 0.0500(0.0672) | Error Color 0.0667(0.1265) |Steps 692(717.45) | Grad Norm 2.1389(9.1381) | Total Time 10.00(10.00)\n",
      "Iter 7950 | Time 14.9747(15.7067) | Bit/dim 1.2092(1.2674) | Xent 0.1211(0.1990) | Xent Color 0.1257(0.4332) | Loss 1.2709(1.4254) | Error 0.0433(0.0623) | Error Color 0.0256(0.1053) |Steps 680(705.69) | Grad Norm 1.1474(7.1977) | Total Time 10.00(10.00)\n",
      "Iter 7960 | Time 15.8060(15.5907) | Bit/dim 1.1078(1.2350) | Xent 0.1634(0.1842) | Xent Color 0.0872(0.3466) | Loss 1.1704(1.3677) | Error 0.0511(0.0578) | Error Color 0.0211(0.0847) |Steps 710(700.44) | Grad Norm 1.1279(5.6954) | Total Time 10.00(10.00)\n",
      "Iter 7970 | Time 15.8918(15.6430) | Bit/dim 1.0154(1.1874) | Xent 0.1206(0.1701) | Xent Color 0.0693(0.2776) | Loss 1.0628(1.2993) | Error 0.0456(0.0536) | Error Color 0.0133(0.0672) |Steps 710(702.15) | Grad Norm 0.7480(4.5002) | Total Time 10.00(10.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_2cond.py --data colormnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_colormnist_bs900_sratio_1_6th_drop_0_5_2cond_linear_run1 --resume ../experiments_published/cnf_conditional_disentangle_colormnist_bs900_sratio_1_6th_drop_0_5_2cond_linear_run1/current_checkpt.pth --seed 1 --lr 0.001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.16667 --dropout_rate 0.5 --y_color 10 --y_class 10\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
