{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=0.0001, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=True, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rtol=0.0001, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_tunetol_run2', seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1414198\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 0010 | Time 12.3751(31.8485) | Bit/dim 9.0202(9.4432) | Xent 2.2828(2.3002) | Loss 10.1616(10.5933) | Error 0.7444(0.8543) Steps 550(560.82) | Grad Norm 18.0012(22.2790) | Total Time 14.00(14.00)\n",
      "Iter 0020 | Time 11.9417(26.6860) | Bit/dim 8.5416(9.2736) | Xent 2.2275(2.2874) | Loss 9.6553(10.4173) | Error 0.7511(0.8272) Steps 550(557.98) | Grad Norm 7.2681(19.5851) | Total Time 14.00(14.00)\n",
      "Iter 0030 | Time 12.2536(22.8779) | Bit/dim 8.3762(9.0671) | Xent 2.1755(2.2642) | Loss 9.4639(10.1992) | Error 0.7600(0.8096) Steps 550(555.88) | Grad Norm 4.8852(15.7536) | Total Time 14.00(14.00)\n",
      "Iter 0040 | Time 12.4155(20.1855) | Bit/dim 8.3057(8.8781) | Xent 2.1282(2.2340) | Loss 9.3698(9.9951) | Error 0.7256(0.7911) Steps 550(555.42) | Grad Norm 3.1354(12.7902) | Total Time 14.00(14.00)\n",
      "Iter 0050 | Time 12.5184(18.1523) | Bit/dim 7.9804(8.6710) | Xent 2.0996(2.2037) | Loss 9.0302(9.7728) | Error 0.7389(0.7770) Steps 550(554.48) | Grad Norm 3.1883(10.2342) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 78.7025, Epoch Time 806.8273(806.8273), Bit/dim 7.8719(best: inf), Xent 2.0783, Loss 8.9111, Error 0.7070(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 12.9320(16.7327) | Bit/dim 7.8150(8.4649) | Xent 2.0962(2.1738) | Loss 8.8631(9.5518) | Error 0.7133(0.7582) Steps 556(554.88) | Grad Norm 3.0094(8.3010) | Total Time 14.00(14.00)\n",
      "Iter 0070 | Time 12.8341(15.6890) | Bit/dim 7.5120(8.2424) | Xent 2.0449(2.1436) | Loss 8.5345(9.3142) | Error 0.6744(0.7375) Steps 568(557.91) | Grad Norm 2.5833(6.8211) | Total Time 14.00(14.00)\n",
      "Iter 0080 | Time 13.1943(15.0355) | Bit/dim 7.2802(8.0132) | Xent 2.0742(2.1250) | Loss 8.3173(9.0758) | Error 0.6989(0.7262) Steps 574(561.71) | Grad Norm 1.9928(5.6207) | Total Time 14.00(14.00)\n",
      "Iter 0090 | Time 13.3881(14.5843) | Bit/dim 7.1765(7.8016) | Xent 2.0724(2.1130) | Loss 8.2127(8.8581) | Error 0.6744(0.7171) Steps 574(564.94) | Grad Norm 1.6954(4.6351) | Total Time 14.00(14.00)\n",
      "Iter 0100 | Time 13.0921(14.2363) | Bit/dim 7.0704(7.6196) | Xent 2.0704(2.1039) | Loss 8.1056(8.6716) | Error 0.7122(0.7135) Steps 574(567.32) | Grad Norm 1.9601(3.8750) | Total Time 14.00(14.00)\n",
      "Iter 0110 | Time 13.3843(14.0066) | Bit/dim 7.0408(7.4717) | Xent 2.0338(2.0908) | Loss 8.0577(8.5171) | Error 0.6944(0.7095) Steps 574(569.07) | Grad Norm 0.9235(3.2327) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 75.3349, Epoch Time 816.1148(807.1059), Bit/dim 7.0359(best: 7.8719), Xent 2.0433, Loss 8.0576, Error 0.6736(best: 0.7070)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 13.1990(13.7865) | Bit/dim 7.0199(7.3530) | Xent 2.0894(2.0806) | Loss 8.0647(8.3933) | Error 0.7156(0.7050) Steps 574(570.37) | Grad Norm 0.8292(2.7398) | Total Time 14.00(14.00)\n",
      "Iter 0130 | Time 13.0105(13.6250) | Bit/dim 6.9894(7.2545) | Xent 2.0116(2.0705) | Loss 7.9952(8.2898) | Error 0.6722(0.7000) Steps 574(571.32) | Grad Norm 0.9449(2.3436) | Total Time 14.00(14.00)\n",
      "Iter 0140 | Time 13.2329(13.5002) | Bit/dim 6.9258(7.1739) | Xent 2.0486(2.0631) | Loss 7.9501(8.2055) | Error 0.6933(0.6971) Steps 574(572.02) | Grad Norm 0.8166(2.4712) | Total Time 14.00(14.00)\n",
      "Iter 0150 | Time 13.1177(13.4586) | Bit/dim 6.9061(7.1068) | Xent 2.0161(2.0545) | Loss 7.9141(8.1341) | Error 0.6789(0.6953) Steps 574(572.54) | Grad Norm 1.6100(2.6693) | Total Time 14.00(14.00)\n",
      "Iter 0160 | Time 13.2060(13.4074) | Bit/dim 6.8667(7.0450) | Xent 2.0412(2.0472) | Loss 7.8873(8.0686) | Error 0.7056(0.6902) Steps 574(572.93) | Grad Norm 3.3865(2.8949) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 75.2387, Epoch Time 820.0435(807.4940), Bit/dim 6.8266(best: 7.0359), Xent 2.0035, Loss 7.8283, Error 0.6674(best: 0.6736)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 13.4405(13.3533) | Bit/dim 6.8018(6.9886) | Xent 2.0380(2.0410) | Loss 7.8208(8.0091) | Error 0.7056(0.6893) Steps 574(573.21) | Grad Norm 9.8789(3.7514) | Total Time 14.00(14.00)\n",
      "Iter 0180 | Time 13.1815(13.3030) | Bit/dim 6.7312(6.9305) | Xent 2.0711(2.0394) | Loss 7.7668(7.9502) | Error 0.7244(0.6937) Steps 574(573.42) | Grad Norm 18.6478(5.6586) | Total Time 14.00(14.00)\n",
      "Iter 0190 | Time 13.3804(13.2687) | Bit/dim 6.6354(6.8659) | Xent 1.9867(2.0338) | Loss 7.6288(7.8828) | Error 0.6578(0.6961) Steps 574(573.74) | Grad Norm 11.1935(7.8565) | Total Time 14.00(14.00)\n",
      "Iter 0200 | Time 13.5683(13.3499) | Bit/dim 6.5339(6.7909) | Xent 2.0498(2.0291) | Loss 7.5588(7.8054) | Error 0.7300(0.6964) Steps 580(574.93) | Grad Norm 12.7167(8.8484) | Total Time 14.00(14.00)\n",
      "Iter 0210 | Time 13.1499(13.3449) | Bit/dim 6.3852(6.6988) | Xent 2.0541(2.0203) | Loss 7.4123(7.7090) | Error 0.7511(0.6927) Steps 580(576.26) | Grad Norm 28.3654(9.1691) | Total Time 14.00(14.00)\n",
      "Iter 0220 | Time 13.7183(13.4551) | Bit/dim 6.3072(6.6054) | Xent 1.9912(2.0434) | Loss 7.3028(7.6272) | Error 0.7133(0.7052) Steps 580(578.34) | Grad Norm 25.4004(16.3481) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 77.2003, Epoch Time 830.8789(808.1956), Bit/dim 6.2296(best: 6.8266), Xent 1.9886, Loss 7.2239, Error 0.6824(best: 0.6674)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 13.4696(13.4949) | Bit/dim 6.0748(6.4850) | Xent 2.0204(2.0335) | Loss 7.0850(7.5018) | Error 0.7189(0.7017) Steps 586(579.90) | Grad Norm 25.4728(15.6191) | Total Time 14.00(14.00)\n",
      "Iter 0240 | Time 13.5261(13.5400) | Bit/dim 5.9859(6.3659) | Xent 2.1708(2.0818) | Loss 7.0713(7.4068) | Error 0.7656(0.7221) Steps 586(581.50) | Grad Norm 23.1327(20.8793) | Total Time 14.00(14.00)\n",
      "Iter 0250 | Time 13.1982(13.5361) | Bit/dim 5.8583(6.2473) | Xent 2.0446(2.0802) | Loss 6.8806(7.2874) | Error 0.7056(0.7229) Steps 586(582.68) | Grad Norm 5.7238(17.9112) | Total Time 14.00(14.00)\n",
      "Iter 0260 | Time 13.4698(13.6157) | Bit/dim 5.7750(6.1333) | Xent 2.0633(2.0696) | Loss 6.8067(7.1681) | Error 0.6933(0.7138) Steps 592(584.71) | Grad Norm 13.4911(14.9494) | Total Time 14.00(14.00)\n",
      "Iter 0270 | Time 14.3970(13.7552) | Bit/dim 5.7287(6.0340) | Xent 1.9805(2.0573) | Loss 6.7190(7.0627) | Error 0.6489(0.7074) Steps 592(586.92) | Grad Norm 10.1848(14.3191) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 76.8060, Epoch Time 852.7686(809.5328), Bit/dim 5.7131(best: 6.2296), Xent 1.9709, Loss 6.6986, Error 0.6580(best: 0.6674)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 13.7742(13.8614) | Bit/dim 5.7137(5.9544) | Xent 2.0077(2.0435) | Loss 6.7175(6.9761) | Error 0.7111(0.7040) Steps 598(589.07) | Grad Norm 28.6938(15.0704) | Total Time 14.00(14.00)\n",
      "Iter 0290 | Time 14.2033(14.0001) | Bit/dim 5.6550(5.8812) | Xent 1.9303(2.0277) | Loss 6.6202(6.8951) | Error 0.6411(0.6964) Steps 598(591.26) | Grad Norm 6.3236(14.6552) | Total Time 14.00(14.00)\n",
      "Iter 0300 | Time 14.3167(14.0906) | Bit/dim 5.6860(5.8259) | Xent 2.0088(2.0146) | Loss 6.6904(6.8332) | Error 0.6933(0.6928) Steps 598(593.03) | Grad Norm 4.3738(14.2382) | Total Time 14.00(14.00)\n",
      "Iter 0310 | Time 14.0656(14.1478) | Bit/dim 5.6690(5.7751) | Xent 1.9820(1.9985) | Loss 6.6599(6.7743) | Error 0.6778(0.6847) Steps 592(594.32) | Grad Norm 11.3655(12.2906) | Total Time 14.00(14.00)\n",
      "Iter 0320 | Time 14.3782(14.2057) | Bit/dim 5.6471(5.7432) | Xent 1.9896(1.9997) | Loss 6.6419(6.7431) | Error 0.6900(0.6890) Steps 598(595.88) | Grad Norm 16.1266(17.2821) | Total Time 14.00(14.00)\n",
      "Iter 0330 | Time 13.7895(14.1913) | Bit/dim 5.5718(5.7038) | Xent 1.9529(1.9924) | Loss 6.5483(6.7000) | Error 0.6822(0.6873) Steps 592(595.60) | Grad Norm 8.2001(15.5500) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 77.3194, Epoch Time 881.7588(811.6996), Bit/dim 5.5834(best: 5.7131), Xent 1.9491, Loss 6.5579, Error 0.6563(best: 0.6580)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 13.9651(14.1173) | Bit/dim 5.5780(5.6687) | Xent 1.9392(1.9802) | Loss 6.5476(6.6588) | Error 0.6567(0.6824) Steps 598(595.34) | Grad Norm 5.3157(13.2991) | Total Time 14.00(14.00)\n",
      "Iter 0350 | Time 14.5646(14.1283) | Bit/dim 5.5235(5.6324) | Xent 2.0040(1.9781) | Loss 6.5256(6.6215) | Error 0.7089(0.6829) Steps 598(596.04) | Grad Norm 19.5306(13.2370) | Total Time 14.00(14.00)\n",
      "Iter 0360 | Time 14.0262(14.1142) | Bit/dim 5.5702(5.6078) | Xent 1.9868(1.9848) | Loss 6.5636(6.6003) | Error 0.6911(0.6877) Steps 598(596.24) | Grad Norm 4.9460(13.7558) | Total Time 14.00(14.00)\n",
      "Iter 0370 | Time 13.8169(14.0724) | Bit/dim 5.4386(5.5751) | Xent 1.9587(1.9810) | Loss 6.4180(6.5656) | Error 0.6833(0.6825) Steps 598(596.70) | Grad Norm 6.3841(12.2850) | Total Time 14.00(14.00)\n",
      "Iter 0380 | Time 14.0498(14.0814) | Bit/dim 5.4736(5.5584) | Xent 2.0280(2.0050) | Loss 6.4877(6.5609) | Error 0.7278(0.6950) Steps 604(597.91) | Grad Norm 13.6430(16.7946) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 78.4959, Epoch Time 869.2571(813.4263), Bit/dim 5.4445(best: 5.5834), Xent 1.9992, Loss 6.4441, Error 0.7001(best: 0.6563)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 13.9211(14.0913) | Bit/dim 5.4546(5.5299) | Xent 1.9638(2.0073) | Loss 6.4365(6.5335) | Error 0.6667(0.6967) Steps 592(598.47) | Grad Norm 5.0690(14.3507) | Total Time 14.00(14.00)\n",
      "Iter 0400 | Time 14.1242(14.0573) | Bit/dim 5.3943(5.4966) | Xent 1.9975(2.0009) | Loss 6.3931(6.4971) | Error 0.6911(0.6957) Steps 598(598.20) | Grad Norm 3.3153(11.8281) | Total Time 14.00(14.00)\n",
      "Iter 0410 | Time 13.8996(14.0312) | Bit/dim 5.3441(5.4636) | Xent 1.9713(1.9943) | Loss 6.3298(6.4608) | Error 0.7056(0.6934) Steps 598(598.15) | Grad Norm 5.0146(9.7335) | Total Time 14.00(14.00)\n",
      "Iter 0420 | Time 14.1771(14.0426) | Bit/dim 5.2972(5.4258) | Xent 1.9196(1.9792) | Loss 6.2570(6.4154) | Error 0.6433(0.6867) Steps 604(598.15) | Grad Norm 3.9086(8.3075) | Total Time 14.00(14.00)\n",
      "Iter 0430 | Time 14.3155(14.1276) | Bit/dim 5.2928(5.3895) | Xent 1.9221(1.9706) | Loss 6.2538(6.3748) | Error 0.6611(0.6840) Steps 598(598.28) | Grad Norm 16.3749(9.0346) | Total Time 14.00(14.00)\n",
      "Iter 0440 | Time 14.3718(14.2101) | Bit/dim 5.2289(5.3519) | Xent 1.9852(1.9662) | Loss 6.2215(6.3351) | Error 0.7078(0.6828) Steps 598(599.16) | Grad Norm 20.9308(9.3908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 79.3786, Epoch Time 875.0665(815.2755), Bit/dim 5.2478(best: 5.4445), Xent 1.9204, Loss 6.2080, Error 0.6786(best: 0.6563)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 13.8538(14.2457) | Bit/dim 5.2186(5.3233) | Xent 1.9615(1.9590) | Loss 6.1994(6.3028) | Error 0.6744(0.6821) Steps 604(600.38) | Grad Norm 12.9338(10.4077) | Total Time 14.00(14.00)\n",
      "Iter 0460 | Time 14.0154(14.2638) | Bit/dim 5.1595(5.2889) | Xent 1.9105(1.9530) | Loss 6.1148(6.2655) | Error 0.6556(0.6807) Steps 598(600.37) | Grad Norm 6.1087(10.3913) | Total Time 14.00(14.00)\n",
      "Iter 0470 | Time 13.9797(14.1751) | Bit/dim 5.1540(5.2588) | Xent 1.8963(1.9423) | Loss 6.1021(6.2300) | Error 0.6800(0.6776) Steps 592(598.59) | Grad Norm 3.8014(9.2285) | Total Time 14.00(14.00)\n",
      "Iter 0480 | Time 13.9259(14.1401) | Bit/dim 5.1333(5.2380) | Xent 1.9613(1.9407) | Loss 6.1140(6.2083) | Error 0.6967(0.6790) Steps 592(597.53) | Grad Norm 9.0831(11.6083) | Total Time 14.00(14.00)\n",
      "Iter 0490 | Time 13.9119(14.0610) | Bit/dim 5.1475(5.2088) | Xent 1.9203(1.9405) | Loss 6.1076(6.1791) | Error 0.6956(0.6820) Steps 598(597.18) | Grad Norm 8.2908(11.3931) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 77.0195, Epoch Time 869.6341(816.9062), Bit/dim 5.1033(best: 5.2478), Xent 1.8985, Loss 6.0525, Error 0.6660(best: 0.6563)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 13.9747(14.0397) | Bit/dim 5.0832(5.1788) | Xent 1.9194(1.9347) | Loss 6.0429(6.1462) | Error 0.6956(0.6805) Steps 592(595.99) | Grad Norm 9.8778(10.1537) | Total Time 14.00(14.00)\n",
      "Iter 0510 | Time 13.6604(13.9989) | Bit/dim 5.0716(5.1503) | Xent 1.8856(1.9268) | Loss 6.0144(6.1137) | Error 0.6644(0.6768) Steps 586(594.11) | Grad Norm 8.9261(9.2481) | Total Time 14.00(14.00)\n",
      "Iter 0520 | Time 13.7644(13.9646) | Bit/dim 5.0085(5.1210) | Xent 1.8794(1.9162) | Loss 5.9482(6.0790) | Error 0.6700(0.6706) Steps 592(592.32) | Grad Norm 8.7274(8.6851) | Total Time 14.00(14.00)\n",
      "Iter 0530 | Time 14.0469(13.9761) | Bit/dim 4.9532(5.0929) | Xent 1.9187(1.9079) | Loss 5.9125(6.0469) | Error 0.6667(0.6683) Steps 598(592.10) | Grad Norm 12.4478(9.5066) | Total Time 14.00(14.00)\n",
      "Iter 0540 | Time 14.1602(13.9530) | Bit/dim 4.9652(5.0682) | Xent 1.9135(1.9040) | Loss 5.9220(6.0203) | Error 0.6656(0.6666) Steps 598(592.72) | Grad Norm 12.1630(9.3945) | Total Time 14.00(14.00)\n",
      "Iter 0550 | Time 13.7077(13.9758) | Bit/dim 4.9303(5.0401) | Xent 1.9195(1.8968) | Loss 5.8900(5.9885) | Error 0.6711(0.6668) Steps 592(593.92) | Grad Norm 8.8061(9.5450) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 78.3564, Epoch Time 862.9270(818.2869), Bit/dim 4.9414(best: 5.1033), Xent 1.8182, Loss 5.8505, Error 0.6241(best: 0.6563)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 14.2131(14.0242) | Bit/dim 4.9445(5.0136) | Xent 1.7535(1.8784) | Loss 5.8212(5.9528) | Error 0.6200(0.6597) Steps 598(595.00) | Grad Norm 7.9297(8.5309) | Total Time 14.00(14.00)\n",
      "Iter 0570 | Time 15.0271(14.2141) | Bit/dim 5.0910(5.0159) | Xent 2.1704(1.9321) | Loss 6.1762(5.9820) | Error 0.7489(0.6744) Steps 616(598.46) | Grad Norm 17.0291(11.6438) | Total Time 14.00(14.00)\n",
      "Iter 0580 | Time 15.2231(14.4648) | Bit/dim 4.9417(5.0067) | Xent 1.9875(1.9411) | Loss 5.9355(5.9772) | Error 0.7289(0.6848) Steps 634(610.25) | Grad Norm 11.0820(10.8760) | Total Time 14.00(14.00)\n",
      "Iter 0590 | Time 14.2964(14.5230) | Bit/dim 4.8964(4.9799) | Xent 1.9717(1.9425) | Loss 5.8823(5.9512) | Error 0.6978(0.6866) Steps 610(612.86) | Grad Norm 3.0617(9.0958) | Total Time 14.00(14.00)\n",
      "Iter 0600 | Time 14.3533(14.5599) | Bit/dim 4.8568(4.9491) | Xent 1.9068(1.9358) | Loss 5.8102(5.9170) | Error 0.6867(0.6853) Steps 604(611.76) | Grad Norm 10.2135(8.3377) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 79.6159, Epoch Time 904.9812(820.8877), Bit/dim 4.8242(best: 4.9414), Xent 1.8431, Loss 5.7457, Error 0.6519(best: 0.6241)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 14.7548(14.5829) | Bit/dim 4.8222(4.9161) | Xent 1.9221(1.9254) | Loss 5.7833(5.8788) | Error 0.6744(0.6810) Steps 622(612.00) | Grad Norm 14.4539(8.2402) | Total Time 14.00(14.00)\n",
      "Iter 0620 | Time 14.7021(14.6017) | Bit/dim 4.7819(4.8889) | Xent 1.8400(1.9136) | Loss 5.7019(5.8457) | Error 0.6533(0.6782) Steps 616(612.79) | Grad Norm 4.5528(8.3616) | Total Time 14.00(14.00)\n",
      "Iter 0630 | Time 14.7200(14.6117) | Bit/dim 4.8305(4.8634) | Xent 1.8792(1.8993) | Loss 5.7702(5.8130) | Error 0.6489(0.6721) Steps 622(614.26) | Grad Norm 10.6621(8.4514) | Total Time 14.00(14.00)\n",
      "Iter 0640 | Time 14.4120(14.6211) | Bit/dim 4.7283(4.8367) | Xent 1.8360(1.8858) | Loss 5.6463(5.7796) | Error 0.6578(0.6684) Steps 616(615.47) | Grad Norm 6.5072(9.0937) | Total Time 14.00(14.00)\n",
      "Iter 0650 | Time 14.5717(14.6837) | Bit/dim 4.7610(4.8139) | Xent 1.8603(1.8751) | Loss 5.6911(5.7514) | Error 0.6467(0.6655) Steps 616(616.87) | Grad Norm 10.7370(9.2831) | Total Time 14.00(14.00)\n",
      "Iter 0660 | Time 14.7008(14.7058) | Bit/dim 4.7262(4.7896) | Xent 1.7670(1.8581) | Loss 5.6097(5.7187) | Error 0.6333(0.6590) Steps 622(619.31) | Grad Norm 18.9034(9.1849) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 80.8716, Epoch Time 907.6653(823.4910), Bit/dim 4.7405(best: 4.8242), Xent 1.8133, Loss 5.6471, Error 0.6451(best: 0.6241)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 15.3338(14.8339) | Bit/dim 4.7234(4.7737) | Xent 1.7986(1.8605) | Loss 5.6227(5.7039) | Error 0.6511(0.6607) Steps 628(624.63) | Grad Norm 12.3606(10.8657) | Total Time 14.00(14.00)\n",
      "Iter 0680 | Time 15.3360(14.9915) | Bit/dim 4.6766(4.7531) | Xent 1.7708(1.8456) | Loss 5.5620(5.6758) | Error 0.6211(0.6561) Steps 640(628.79) | Grad Norm 3.9947(10.1001) | Total Time 14.00(14.00)\n",
      "Iter 0690 | Time 14.8179(15.0687) | Bit/dim 4.6671(4.7369) | Xent 1.8052(1.8386) | Loss 5.5697(5.6561) | Error 0.6133(0.6510) Steps 634(630.47) | Grad Norm 12.3515(10.8490) | Total Time 14.00(14.00)\n",
      "Iter 0700 | Time 14.9944(15.1142) | Bit/dim 4.6630(4.7194) | Xent 1.8285(1.8290) | Loss 5.5772(5.6339) | Error 0.6622(0.6477) Steps 646(631.92) | Grad Norm 13.5693(10.7133) | Total Time 14.00(14.00)\n",
      "Iter 0710 | Time 15.0887(15.1780) | Bit/dim 4.6788(4.7025) | Xent 1.8540(1.8253) | Loss 5.6059(5.6152) | Error 0.6578(0.6466) Steps 640(634.33) | Grad Norm 9.9026(11.6915) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 81.3478, Epoch Time 942.3228(827.0560), Bit/dim 4.6532(best: 4.7405), Xent 1.7922, Loss 5.5493, Error 0.6410(best: 0.6241)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 15.3153(15.2361) | Bit/dim 4.6666(4.6964) | Xent 1.7550(1.8195) | Loss 5.5441(5.6062) | Error 0.6378(0.6457) Steps 634(636.24) | Grad Norm 6.8201(11.0831) | Total Time 14.00(14.00)\n",
      "Iter 0730 | Time 15.0574(15.2211) | Bit/dim 4.5925(4.6753) | Xent 1.6850(1.7998) | Loss 5.4350(5.5751) | Error 0.6022(0.6382) Steps 628(635.68) | Grad Norm 3.6267(9.7974) | Total Time 14.00(14.00)\n",
      "Iter 0740 | Time 14.9383(15.1469) | Bit/dim 4.6409(4.6642) | Xent 1.8034(1.7969) | Loss 5.5426(5.5626) | Error 0.6533(0.6391) Steps 634(634.20) | Grad Norm 15.4557(11.1903) | Total Time 14.00(14.00)\n",
      "Iter 0750 | Time 15.3838(15.1025) | Bit/dim 4.6254(4.6485) | Xent 1.7479(1.7862) | Loss 5.4993(5.5416) | Error 0.6178(0.6351) Steps 634(633.67) | Grad Norm 7.7464(10.4591) | Total Time 14.00(14.00)\n",
      "Iter 0760 | Time 14.9790(15.1188) | Bit/dim 4.6581(4.6411) | Xent 1.8462(1.7986) | Loss 5.5812(5.5404) | Error 0.6656(0.6402) Steps 640(633.87) | Grad Norm 11.1333(11.2830) | Total Time 14.00(14.00)\n",
      "Iter 0770 | Time 15.0311(15.0610) | Bit/dim 4.5801(4.6275) | Xent 1.8165(1.7920) | Loss 5.4883(5.5236) | Error 0.6489(0.6371) Steps 622(632.75) | Grad Norm 9.4063(10.4833) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 79.0680, Epoch Time 924.3141(829.9737), Bit/dim 4.5818(best: 4.6532), Xent 1.6872, Loss 5.4254, Error 0.5966(best: 0.6241)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 14.9228(14.9699) | Bit/dim 4.5170(4.6076) | Xent 1.7827(1.7730) | Loss 5.4084(5.4941) | Error 0.6233(0.6288) Steps 622(627.69) | Grad Norm 8.8806(9.6235) | Total Time 14.00(14.00)\n",
      "Iter 0790 | Time 15.1693(14.8744) | Bit/dim 4.4958(4.5910) | Xent 1.6889(1.7510) | Loss 5.3403(5.4665) | Error 0.6011(0.6233) Steps 622(623.96) | Grad Norm 8.7688(9.7761) | Total Time 14.00(14.00)\n",
      "Iter 0800 | Time 14.5562(14.8309) | Bit/dim 4.5442(4.5723) | Xent 1.7324(1.7328) | Loss 5.4103(5.4387) | Error 0.6333(0.6193) Steps 628(624.21) | Grad Norm 16.5152(9.4930) | Total Time 14.00(14.00)\n",
      "Iter 0810 | Time 14.8984(14.8105) | Bit/dim 4.5326(4.5604) | Xent 1.7315(1.7308) | Loss 5.3983(5.4258) | Error 0.6000(0.6171) Steps 634(624.91) | Grad Norm 12.2455(10.5921) | Total Time 14.00(14.00)\n",
      "Iter 0820 | Time 15.0371(14.8632) | Bit/dim 4.5364(4.5500) | Xent 1.8776(1.7505) | Loss 5.4752(5.4252) | Error 0.6700(0.6235) Steps 628(627.13) | Grad Norm 13.9910(11.1816) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 79.4008, Epoch Time 909.9191(832.3721), Bit/dim 4.4989(best: 4.5818), Xent 1.6316, Loss 5.3147, Error 0.5817(best: 0.5966)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 15.1743(14.8764) | Bit/dim 4.4622(4.5358) | Xent 1.6626(1.7370) | Loss 5.2935(5.4043) | Error 0.6067(0.6204) Steps 634(628.14) | Grad Norm 6.8980(9.9747) | Total Time 14.00(14.00)\n",
      "Iter 0840 | Time 14.7139(14.8864) | Bit/dim 4.4652(4.5195) | Xent 1.6262(1.7220) | Loss 5.2783(5.3805) | Error 0.6022(0.6175) Steps 640(629.79) | Grad Norm 4.0679(9.2563) | Total Time 14.00(14.00)\n",
      "Iter 0850 | Time 14.8272(14.9376) | Bit/dim 4.4277(4.4996) | Xent 1.6255(1.6980) | Loss 5.2404(5.3487) | Error 0.5700(0.6066) Steps 634(631.52) | Grad Norm 14.4253(8.8046) | Total Time 14.00(14.00)\n",
      "Iter 0860 | Time 15.0860(15.0006) | Bit/dim 4.4497(4.4902) | Xent 1.6689(1.6921) | Loss 5.2842(5.3362) | Error 0.6222(0.6041) Steps 646(634.14) | Grad Norm 7.2175(9.2656) | Total Time 14.00(14.00)\n",
      "Iter 0870 | Time 15.3932(15.1387) | Bit/dim 4.4927(4.4888) | Xent 1.8059(1.7076) | Loss 5.3956(5.3426) | Error 0.6556(0.6091) Steps 652(637.81) | Grad Norm 8.7984(10.3083) | Total Time 14.00(14.00)\n",
      "Iter 0880 | Time 14.8610(15.1334) | Bit/dim 4.4391(4.4774) | Xent 1.6541(1.7079) | Loss 5.2662(5.3314) | Error 0.5878(0.6124) Steps 634(639.22) | Grad Norm 5.7106(9.3986) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 79.6813, Epoch Time 929.7615(835.2938), Bit/dim 4.4268(best: 4.4989), Xent 1.6196, Loss 5.2366, Error 0.5845(best: 0.5817)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 14.6381(15.0458) | Bit/dim 4.3835(4.4610) | Xent 1.5553(1.6857) | Loss 5.1612(5.3039) | Error 0.5633(0.6051) Steps 640(636.09) | Grad Norm 3.9971(8.4343) | Total Time 14.00(14.00)\n",
      "Iter 0900 | Time 15.1525(14.9855) | Bit/dim 4.3989(4.4411) | Xent 1.5223(1.6610) | Loss 5.1600(5.2716) | Error 0.5378(0.5956) Steps 640(634.67) | Grad Norm 4.5602(7.3040) | Total Time 14.00(14.00)\n",
      "Iter 0910 | Time 15.1648(14.9491) | Bit/dim 4.3660(4.4261) | Xent 1.5865(1.6590) | Loss 5.1593(5.2556) | Error 0.5722(0.5955) Steps 634(632.44) | Grad Norm 4.1102(8.0390) | Total Time 14.00(14.00)\n",
      "Iter 0920 | Time 14.8759(14.9461) | Bit/dim 4.3805(4.4098) | Xent 1.6949(1.6463) | Loss 5.2280(5.2329) | Error 0.6200(0.5910) Steps 610(630.77) | Grad Norm 16.1193(7.6585) | Total Time 14.00(14.00)\n",
      "Iter 0930 | Time 14.8220(14.9545) | Bit/dim 4.4036(4.4090) | Xent 1.5961(1.6654) | Loss 5.2017(5.2417) | Error 0.5878(0.5986) Steps 640(631.57) | Grad Norm 7.3602(8.5100) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 83.4509, Epoch Time 922.7561(837.9176), Bit/dim 4.3554(best: 4.4268), Xent 1.5070, Loss 5.1089, Error 0.5383(best: 0.5817)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 15.1418(15.0647) | Bit/dim 4.3256(4.3963) | Xent 1.5048(1.6441) | Loss 5.0780(5.2183) | Error 0.5589(0.5916) Steps 610(631.45) | Grad Norm 3.3828(7.6040) | Total Time 14.00(14.00)\n",
      "Iter 0950 | Time 14.3881(14.9639) | Bit/dim 4.3115(4.3792) | Xent 1.6383(1.6207) | Loss 5.1306(5.1896) | Error 0.5589(0.5816) Steps 616(627.72) | Grad Norm 10.4308(7.7815) | Total Time 14.00(14.00)\n",
      "Iter 0960 | Time 14.9522(14.9438) | Bit/dim 4.3178(4.3642) | Xent 1.5174(1.6007) | Loss 5.0765(5.1646) | Error 0.5578(0.5744) Steps 622(625.40) | Grad Norm 7.3298(7.7294) | Total Time 14.00(14.00)\n",
      "Iter 0970 | Time 14.7046(14.8409) | Bit/dim 4.2980(4.3457) | Xent 1.5063(1.5863) | Loss 5.0512(5.1388) | Error 0.5444(0.5697) Steps 616(621.27) | Grad Norm 5.1535(7.6766) | Total Time 14.00(14.00)\n",
      "Iter 0980 | Time 14.8033(14.8584) | Bit/dim 4.3380(4.3432) | Xent 1.7637(1.6223) | Loss 5.2198(5.1543) | Error 0.6333(0.5806) Steps 628(621.29) | Grad Norm 10.6523(9.5754) | Total Time 14.00(14.00)\n",
      "Iter 0990 | Time 15.2770(14.9497) | Bit/dim 4.3401(4.3498) | Xent 1.6230(1.6366) | Loss 5.1516(5.1681) | Error 0.6167(0.5885) Steps 604(623.70) | Grad Norm 5.1956(9.1913) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 79.7705, Epoch Time 916.0107(840.2604), Bit/dim 4.3289(best: 4.3554), Xent 1.5364, Loss 5.0971, Error 0.5573(best: 0.5383)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 15.1638(14.9743) | Bit/dim 4.2497(4.3363) | Xent 1.5590(1.6178) | Loss 5.0292(5.1452) | Error 0.5633(0.5836) Steps 604(620.52) | Grad Norm 3.5345(8.0763) | Total Time 14.00(14.00)\n",
      "Iter 1010 | Time 15.2709(14.8663) | Bit/dim 4.2497(4.3173) | Xent 1.4788(1.5925) | Loss 4.9891(5.1135) | Error 0.5333(0.5745) Steps 604(616.65) | Grad Norm 10.2908(7.1853) | Total Time 14.00(14.00)\n",
      "Iter 1020 | Time 14.5604(14.7906) | Bit/dim 4.2415(4.2963) | Xent 1.5409(1.5785) | Loss 5.0119(5.0855) | Error 0.5689(0.5703) Steps 604(612.72) | Grad Norm 6.5167(7.1004) | Total Time 14.00(14.00)\n",
      "Iter 1030 | Time 15.8663(14.7919) | Bit/dim 4.2259(4.2797) | Xent 1.5485(1.5620) | Loss 5.0001(5.0607) | Error 0.5611(0.5650) Steps 610(611.12) | Grad Norm 6.6714(6.9053) | Total Time 14.00(14.00)\n",
      "Iter 1040 | Time 15.0937(14.8360) | Bit/dim 4.2284(4.2624) | Xent 1.5021(1.5507) | Loss 4.9795(5.0378) | Error 0.5233(0.5591) Steps 622(611.42) | Grad Norm 10.0457(7.4926) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 82.7104, Epoch Time 914.7146(842.4941), Bit/dim 4.2229(best: 4.3289), Xent 1.3997, Loss 4.9228, Error 0.5018(best: 0.5383)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 15.4924(14.8812) | Bit/dim 4.2316(4.2504) | Xent 1.4707(1.5335) | Loss 4.9669(5.0171) | Error 0.5411(0.5537) Steps 634(613.04) | Grad Norm 10.4435(7.3420) | Total Time 14.00(14.00)\n",
      "Iter 1060 | Time 14.8168(14.8615) | Bit/dim 4.2122(4.2380) | Xent 1.4748(1.5131) | Loss 4.9496(4.9946) | Error 0.5389(0.5484) Steps 628(614.38) | Grad Norm 8.1820(7.3748) | Total Time 14.00(14.00)\n",
      "Iter 1070 | Time 14.9600(14.8736) | Bit/dim 4.2149(4.2384) | Xent 1.5874(1.5106) | Loss 5.0086(4.9937) | Error 0.5644(0.5470) Steps 640(616.08) | Grad Norm 16.8255(8.6475) | Total Time 14.00(14.00)\n",
      "Iter 1080 | Time 15.8270(15.0822) | Bit/dim 4.2356(4.2439) | Xent 1.5948(1.5450) | Loss 5.0330(5.0165) | Error 0.5811(0.5563) Steps 670(625.11) | Grad Norm 10.9836(9.6493) | Total Time 14.00(14.00)\n",
      "Iter 1090 | Time 14.9391(15.1687) | Bit/dim 4.1977(4.2333) | Xent 1.4823(1.5386) | Loss 4.9388(5.0027) | Error 0.5467(0.5546) Steps 616(625.80) | Grad Norm 3.2799(8.4866) | Total Time 14.00(14.00)\n",
      "Iter 1100 | Time 14.2046(15.0508) | Bit/dim 4.1589(4.2161) | Xent 1.3643(1.5160) | Loss 4.8411(4.9741) | Error 0.4856(0.5457) Steps 592(618.68) | Grad Norm 2.2108(7.3288) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 78.8024, Epoch Time 927.3655(845.0402), Bit/dim 4.1666(best: 4.2229), Xent 1.3390, Loss 4.8361, Error 0.4864(best: 0.5018)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 15.0450(14.9194) | Bit/dim 4.1677(4.2013) | Xent 1.3422(1.4883) | Loss 4.8388(4.9454) | Error 0.5167(0.5366) Steps 604(611.71) | Grad Norm 4.2749(6.3997) | Total Time 14.00(14.00)\n",
      "Iter 1120 | Time 14.7146(14.8679) | Bit/dim 4.1201(4.1851) | Xent 1.4187(1.4644) | Loss 4.8294(4.9173) | Error 0.5011(0.5279) Steps 610(608.80) | Grad Norm 9.4284(6.1797) | Total Time 14.00(14.00)\n",
      "Iter 1130 | Time 15.2767(14.9497) | Bit/dim 4.1343(4.1717) | Xent 1.4431(1.4493) | Loss 4.8558(4.8963) | Error 0.5033(0.5214) Steps 610(608.44) | Grad Norm 8.8349(6.1861) | Total Time 14.00(14.00)\n",
      "Iter 1140 | Time 15.8501(15.0350) | Bit/dim 4.1278(4.1645) | Xent 1.4055(1.4538) | Loss 4.8305(4.8914) | Error 0.5111(0.5239) Steps 628(609.46) | Grad Norm 8.7446(7.7300) | Total Time 14.00(14.00)\n",
      "Iter 1150 | Time 15.5888(15.1030) | Bit/dim 4.1722(4.1715) | Xent 1.4434(1.4727) | Loss 4.8939(4.9078) | Error 0.5356(0.5303) Steps 640(616.48) | Grad Norm 6.4901(8.5845) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 80.0626, Epoch Time 923.3557(847.3897), Bit/dim 4.1418(best: 4.1666), Xent 1.3605, Loss 4.8221, Error 0.4942(best: 0.4864)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 15.0236(15.0868) | Bit/dim 4.1620(4.1647) | Xent 1.3325(1.4564) | Loss 4.8283(4.8930) | Error 0.4844(0.5245) Steps 640(619.01) | Grad Norm 7.2838(7.8589) | Total Time 14.00(14.00)\n",
      "Iter 1170 | Time 14.7664(15.0487) | Bit/dim 4.1225(4.1527) | Xent 1.4294(1.4416) | Loss 4.8372(4.8735) | Error 0.5033(0.5202) Steps 610(616.65) | Grad Norm 9.6489(7.4699) | Total Time 14.00(14.00)\n",
      "Iter 1180 | Time 15.2446(15.0270) | Bit/dim 4.1397(4.1461) | Xent 1.4374(1.4354) | Loss 4.8584(4.8638) | Error 0.5411(0.5187) Steps 616(615.65) | Grad Norm 5.5760(7.8388) | Total Time 14.00(14.00)\n",
      "Iter 1190 | Time 14.8506(15.0158) | Bit/dim 4.0817(4.1345) | Xent 1.4180(1.4238) | Loss 4.7907(4.8464) | Error 0.4922(0.5134) Steps 604(614.56) | Grad Norm 5.3422(7.3359) | Total Time 14.00(14.00)\n",
      "Iter 1200 | Time 14.7946(14.9739) | Bit/dim 4.0815(4.1187) | Xent 1.3457(1.4068) | Loss 4.7544(4.8221) | Error 0.4744(0.5079) Steps 616(613.56) | Grad Norm 3.0822(6.5060) | Total Time 14.00(14.00)\n",
      "Iter 1210 | Time 15.5796(15.0025) | Bit/dim 4.0897(4.1106) | Xent 1.4879(1.4021) | Loss 4.8336(4.8117) | Error 0.5367(0.5051) Steps 616(613.63) | Grad Norm 11.8616(6.9657) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 80.9573, Epoch Time 921.3850(849.6095), Bit/dim 4.0793(best: 4.1418), Xent 1.2926, Loss 4.7256, Error 0.4614(best: 0.4864)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 14.7224(14.9937) | Bit/dim 4.0856(4.1003) | Xent 1.3740(1.3969) | Loss 4.7726(4.7987) | Error 0.4922(0.5028) Steps 628(614.78) | Grad Norm 8.3873(7.1915) | Total Time 14.00(14.00)\n",
      "Iter 1230 | Time 14.7922(14.9847) | Bit/dim 4.0779(4.0954) | Xent 1.3682(1.3876) | Loss 4.7621(4.7892) | Error 0.4856(0.4977) Steps 610(614.93) | Grad Norm 8.4929(7.4023) | Total Time 14.00(14.00)\n",
      "Iter 1240 | Time 15.3745(14.9577) | Bit/dim 4.0840(4.0884) | Xent 1.2881(1.3828) | Loss 4.7280(4.7798) | Error 0.4678(0.4948) Steps 610(615.36) | Grad Norm 3.3300(7.7281) | Total Time 14.00(14.00)\n",
      "Iter 1250 | Time 14.7495(14.9919) | Bit/dim 4.0487(4.0812) | Xent 1.3839(1.3778) | Loss 4.7407(4.7701) | Error 0.4933(0.4932) Steps 622(616.35) | Grad Norm 8.6371(7.8350) | Total Time 14.00(14.00)\n",
      "Iter 1260 | Time 14.3638(14.9823) | Bit/dim 4.0752(4.0771) | Xent 1.3526(1.3873) | Loss 4.7515(4.7707) | Error 0.4856(0.4983) Steps 610(617.35) | Grad Norm 10.5594(8.4487) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 79.4812, Epoch Time 921.4560(851.7649), Bit/dim 4.0542(best: 4.0793), Xent 1.2774, Loss 4.6929, Error 0.4652(best: 0.4614)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 15.2825(15.0041) | Bit/dim 4.0727(4.0701) | Xent 1.3093(1.3777) | Loss 4.7273(4.7589) | Error 0.4656(0.4947) Steps 628(617.92) | Grad Norm 5.6154(7.6190) | Total Time 14.00(14.00)\n",
      "Iter 1280 | Time 14.5835(14.9928) | Bit/dim 4.0123(4.0615) | Xent 1.2514(1.3617) | Loss 4.6379(4.7423) | Error 0.4489(0.4897) Steps 592(616.63) | Grad Norm 8.1721(7.4956) | Total Time 14.00(14.00)\n",
      "Iter 1290 | Time 14.5465(14.9567) | Bit/dim 4.0465(4.0561) | Xent 1.3846(1.3681) | Loss 4.7388(4.7401) | Error 0.4889(0.4914) Steps 592(613.40) | Grad Norm 4.7772(8.2218) | Total Time 14.00(14.00)\n",
      "Iter 1300 | Time 14.7375(14.8855) | Bit/dim 4.0284(4.0498) | Xent 1.2759(1.3600) | Loss 4.6663(4.7298) | Error 0.4633(0.4876) Steps 604(611.55) | Grad Norm 2.8260(7.4779) | Total Time 14.00(14.00)\n",
      "Iter 1310 | Time 14.8068(14.8295) | Bit/dim 4.0543(4.0467) | Xent 1.3677(1.3567) | Loss 4.7381(4.7251) | Error 0.5022(0.4877) Steps 628(609.63) | Grad Norm 7.0671(7.5792) | Total Time 14.00(14.00)\n",
      "Iter 1320 | Time 14.6622(14.8946) | Bit/dim 4.0441(4.0426) | Xent 1.3033(1.3488) | Loss 4.6957(4.7170) | Error 0.4789(0.4846) Steps 616(609.67) | Grad Norm 8.3708(7.3421) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 77.4201, Epoch Time 913.8944(853.6288), Bit/dim 4.0298(best: 4.0542), Xent 1.2410, Loss 4.6503, Error 0.4474(best: 0.4614)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 14.6021(14.9662) | Bit/dim 4.0139(4.0351) | Xent 1.3052(1.3371) | Loss 4.6665(4.7036) | Error 0.4878(0.4812) Steps 628(612.16) | Grad Norm 5.9747(7.2436) | Total Time 14.00(14.00)\n",
      "Iter 1340 | Time 14.7415(14.9453) | Bit/dim 4.0327(4.0290) | Xent 1.3295(1.3339) | Loss 4.6975(4.6959) | Error 0.4544(0.4778) Steps 598(609.91) | Grad Norm 6.1398(7.6004) | Total Time 14.00(14.00)\n",
      "Iter 1350 | Time 15.4968(14.9307) | Bit/dim 4.0156(4.0324) | Xent 1.3807(1.3726) | Loss 4.7059(4.7187) | Error 0.5322(0.4946) Steps 622(609.61) | Grad Norm 6.8668(8.0451) | Total Time 14.00(14.00)\n",
      "Iter 1360 | Time 14.0218(14.8722) | Bit/dim 4.0090(4.0257) | Xent 1.3175(1.3753) | Loss 4.6677(4.7134) | Error 0.4656(0.4944) Steps 580(608.40) | Grad Norm 3.2582(7.2069) | Total Time 14.00(14.00)\n",
      "Iter 1370 | Time 15.4774(14.8995) | Bit/dim 4.0228(4.0195) | Xent 1.3082(1.3608) | Loss 4.6769(4.7000) | Error 0.4711(0.4904) Steps 574(604.37) | Grad Norm 5.7677(6.4487) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 75.2207, Epoch Time 912.7425(855.4022), Bit/dim 3.9924(best: 4.0298), Xent 1.2554, Loss 4.6201, Error 0.4481(best: 0.4474)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 15.4726(14.8937) | Bit/dim 3.9968(4.0133) | Xent 1.3774(1.3524) | Loss 4.6855(4.6895) | Error 0.4878(0.4859) Steps 616(602.87) | Grad Norm 8.0786(6.6756) | Total Time 14.00(14.00)\n",
      "Iter 1390 | Time 14.8698(14.9411) | Bit/dim 4.0057(4.0065) | Xent 1.2741(1.3395) | Loss 4.6428(4.6762) | Error 0.4578(0.4819) Steps 628(606.02) | Grad Norm 4.5392(6.2918) | Total Time 14.00(14.00)\n",
      "Iter 1400 | Time 15.5383(14.9524) | Bit/dim 3.9547(3.9993) | Xent 1.3779(1.3398) | Loss 4.6437(4.6692) | Error 0.5011(0.4824) Steps 622(606.93) | Grad Norm 12.5221(7.1626) | Total Time 14.00(14.00)\n",
      "Iter 1410 | Time 15.1577(15.0376) | Bit/dim 3.9738(3.9954) | Xent 1.3015(1.3448) | Loss 4.6246(4.6678) | Error 0.4789(0.4835) Steps 622(610.71) | Grad Norm 3.8065(7.4757) | Total Time 14.00(14.00)\n",
      "Iter 1420 | Time 14.4029(15.0531) | Bit/dim 4.0021(3.9907) | Xent 1.3518(1.3366) | Loss 4.6780(4.6590) | Error 0.4756(0.4800) Steps 586(610.78) | Grad Norm 11.6104(7.1657) | Total Time 14.00(14.00)\n",
      "Iter 1430 | Time 15.2343(15.0869) | Bit/dim 3.9603(3.9857) | Xent 1.3279(1.3240) | Loss 4.6243(4.6477) | Error 0.4844(0.4755) Steps 616(610.42) | Grad Norm 7.6666(6.9497) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 76.9119, Epoch Time 926.0000(857.5201), Bit/dim 3.9659(best: 3.9924), Xent 1.2025, Loss 4.5672, Error 0.4284(best: 0.4474)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 15.0630(15.0933) | Bit/dim 3.9464(3.9803) | Xent 1.2554(1.3131) | Loss 4.5741(4.6369) | Error 0.4500(0.4711) Steps 610(611.73) | Grad Norm 5.0328(6.2268) | Total Time 14.00(14.00)\n",
      "Iter 1450 | Time 14.7984(15.1075) | Bit/dim 3.9682(3.9760) | Xent 1.2916(1.3048) | Loss 4.6140(4.6284) | Error 0.4556(0.4684) Steps 616(611.16) | Grad Norm 10.2612(6.7748) | Total Time 14.00(14.00)\n",
      "Iter 1460 | Time 15.0962(15.1582) | Bit/dim 4.0050(3.9743) | Xent 1.2300(1.3005) | Loss 4.6200(4.6245) | Error 0.4456(0.4671) Steps 622(612.03) | Grad Norm 8.3687(7.3539) | Total Time 14.00(14.00)\n",
      "Iter 1470 | Time 15.3393(15.1933) | Bit/dim 3.9013(3.9652) | Xent 1.2819(1.2906) | Loss 4.5423(4.6104) | Error 0.4567(0.4628) Steps 616(612.05) | Grad Norm 8.1771(7.1192) | Total Time 14.00(14.00)\n",
      "Iter 1480 | Time 15.0284(15.1772) | Bit/dim 3.9941(3.9643) | Xent 1.3049(1.2942) | Loss 4.6465(4.6114) | Error 0.4767(0.4641) Steps 610(611.79) | Grad Norm 5.1401(7.1118) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 74.3143, Epoch Time 927.0878(859.6072), Bit/dim 3.9380(best: 3.9659), Xent 1.1908, Loss 4.5334, Error 0.4213(best: 0.4284)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 15.2081(15.1347) | Bit/dim 3.9866(3.9619) | Xent 1.3367(1.2926) | Loss 4.6549(4.6082) | Error 0.4700(0.4623) Steps 628(611.39) | Grad Norm 9.7957(7.2022) | Total Time 14.00(14.00)\n",
      "Iter 1500 | Time 15.0269(15.0161) | Bit/dim 3.9334(3.9559) | Xent 1.2561(1.2843) | Loss 4.5615(4.5980) | Error 0.4500(0.4595) Steps 598(609.24) | Grad Norm 6.6419(6.9861) | Total Time 14.00(14.00)\n",
      "Iter 1510 | Time 14.6367(14.9907) | Bit/dim 3.9595(3.9521) | Xent 1.3048(1.2806) | Loss 4.6119(4.5924) | Error 0.4533(0.4579) Steps 592(608.46) | Grad Norm 10.5290(7.3680) | Total Time 14.00(14.00)\n",
      "Iter 1520 | Time 14.8925(14.9297) | Bit/dim 3.9188(3.9468) | Xent 1.2726(1.2779) | Loss 4.5551(4.5857) | Error 0.4789(0.4581) Steps 616(606.87) | Grad Norm 8.5619(6.9821) | Total Time 14.00(14.00)\n",
      "Iter 1530 | Time 14.6266(14.8379) | Bit/dim 3.9361(3.9407) | Xent 1.1765(1.2682) | Loss 4.5243(4.5748) | Error 0.4222(0.4553) Steps 598(603.56) | Grad Norm 3.3409(6.3963) | Total Time 14.00(14.00)\n",
      "Iter 1540 | Time 14.8470(14.8563) | Bit/dim 3.9290(3.9391) | Xent 1.1971(1.2565) | Loss 4.5275(4.5673) | Error 0.4367(0.4519) Steps 610(605.37) | Grad Norm 7.3007(6.0589) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 76.7697, Epoch Time 908.0149(861.0594), Bit/dim 3.9226(best: 3.9380), Xent 1.1786, Loss 4.5119, Error 0.4203(best: 0.4213)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 15.5607(14.9134) | Bit/dim 3.9485(3.9362) | Xent 1.2507(1.2470) | Loss 4.5738(4.5597) | Error 0.4578(0.4493) Steps 622(606.25) | Grad Norm 5.6932(6.1974) | Total Time 14.00(14.00)\n",
      "Iter 1560 | Time 15.1922(14.9020) | Bit/dim 3.9220(3.9335) | Xent 1.3914(1.2520) | Loss 4.6177(4.5595) | Error 0.5011(0.4492) Steps 622(608.04) | Grad Norm 13.1049(6.9516) | Total Time 14.00(14.00)\n",
      "Iter 1570 | Time 15.4020(14.9859) | Bit/dim 3.9436(3.9332) | Xent 1.3427(1.2719) | Loss 4.6150(4.5692) | Error 0.4844(0.4563) Steps 610(611.29) | Grad Norm 10.1923(7.2820) | Total Time 14.00(14.00)\n",
      "Iter 1580 | Time 15.1438(14.9594) | Bit/dim 3.9197(3.9300) | Xent 1.3016(1.2754) | Loss 4.5705(4.5677) | Error 0.4300(0.4544) Steps 598(609.17) | Grad Norm 8.4643(7.0280) | Total Time 14.00(14.00)\n",
      "Iter 1590 | Time 14.1437(14.9070) | Bit/dim 3.9279(3.9246) | Xent 1.1955(1.2650) | Loss 4.5256(4.5571) | Error 0.4478(0.4519) Steps 574(604.96) | Grad Norm 4.8586(6.4721) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 74.5618, Epoch Time 912.8900(862.6143), Bit/dim 3.9064(best: 3.9226), Xent 1.1501, Loss 4.4814, Error 0.4124(best: 0.4203)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 14.8155(14.8079) | Bit/dim 3.9340(3.9203) | Xent 1.2216(1.2500) | Loss 4.5448(4.5453) | Error 0.4433(0.4483) Steps 604(600.58) | Grad Norm 3.0473(5.9634) | Total Time 14.00(14.00)\n",
      "Iter 1610 | Time 14.4914(14.7806) | Bit/dim 3.9058(3.9162) | Xent 1.2378(1.2444) | Loss 4.5247(4.5384) | Error 0.4411(0.4448) Steps 592(598.14) | Grad Norm 6.4131(6.4330) | Total Time 14.00(14.00)\n",
      "Iter 1620 | Time 14.2434(14.7094) | Bit/dim 3.9233(3.9124) | Xent 1.2698(1.2425) | Loss 4.5582(4.5336) | Error 0.4411(0.4436) Steps 580(597.77) | Grad Norm 14.8789(7.0868) | Total Time 14.00(14.00)\n",
      "Iter 1630 | Time 15.3720(14.6714) | Bit/dim 3.9068(3.9119) | Xent 1.2367(1.2495) | Loss 4.5252(4.5367) | Error 0.4456(0.4472) Steps 604(597.84) | Grad Norm 7.2369(7.4945) | Total Time 14.00(14.00)\n",
      "Iter 1640 | Time 13.9186(14.5917) | Bit/dim 3.8940(3.9111) | Xent 1.2040(1.2444) | Loss 4.4959(4.5333) | Error 0.4222(0.4451) Steps 580(596.67) | Grad Norm 3.6170(7.0743) | Total Time 14.00(14.00)\n",
      "Iter 1650 | Time 14.3163(14.5439) | Bit/dim 3.9095(3.9093) | Xent 1.2855(1.2344) | Loss 4.5523(4.5266) | Error 0.4600(0.4414) Steps 598(594.40) | Grad Norm 4.7854(6.5096) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 75.9950, Epoch Time 892.7002(863.5169), Bit/dim 3.8928(best: 3.9064), Xent 1.1302, Loss 4.4579, Error 0.4034(best: 0.4124)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 14.2701(14.5267) | Bit/dim 3.8530(3.9024) | Xent 1.1784(1.2254) | Loss 4.4422(4.5151) | Error 0.4122(0.4384) Steps 592(593.57) | Grad Norm 3.9734(5.8817) | Total Time 14.00(14.00)\n",
      "Iter 1670 | Time 14.3289(14.4360) | Bit/dim 3.8907(3.9003) | Xent 1.1582(1.2161) | Loss 4.4698(4.5083) | Error 0.4156(0.4345) Steps 604(592.56) | Grad Norm 6.1231(5.8982) | Total Time 14.00(14.00)\n",
      "Iter 1680 | Time 14.3335(14.4022) | Bit/dim 3.8916(3.8978) | Xent 1.3269(1.2229) | Loss 4.5550(4.5092) | Error 0.4633(0.4355) Steps 598(592.91) | Grad Norm 15.2612(6.8586) | Total Time 14.00(14.00)\n",
      "Iter 1690 | Time 14.2856(14.4260) | Bit/dim 3.8833(3.8962) | Xent 1.1798(1.2370) | Loss 4.4732(4.5148) | Error 0.4189(0.4410) Steps 598(594.07) | Grad Norm 3.6179(7.3639) | Total Time 14.00(14.00)\n",
      "Iter 1700 | Time 14.5425(14.3749) | Bit/dim 3.8724(3.8940) | Xent 1.1509(1.2234) | Loss 4.4479(4.5057) | Error 0.4233(0.4366) Steps 598(592.29) | Grad Norm 2.9275(6.6919) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 76.0595, Epoch Time 882.4779(864.0857), Bit/dim 3.8791(best: 3.8928), Xent 1.1206, Loss 4.4395, Error 0.4003(best: 0.4034)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 14.3289(14.3645) | Bit/dim 3.8873(3.8900) | Xent 1.1339(1.2207) | Loss 4.4542(4.5004) | Error 0.4133(0.4351) Steps 598(591.84) | Grad Norm 6.2843(6.7604) | Total Time 14.00(14.00)\n",
      "Iter 1720 | Time 14.3032(14.3972) | Bit/dim 3.8598(3.8859) | Xent 1.1617(1.2116) | Loss 4.4406(4.4917) | Error 0.4089(0.4321) Steps 592(593.75) | Grad Norm 2.4316(6.1320) | Total Time 14.00(14.00)\n",
      "Iter 1730 | Time 14.3215(14.3647) | Bit/dim 3.8510(3.8845) | Xent 1.1022(1.2005) | Loss 4.4022(4.4847) | Error 0.3933(0.4277) Steps 586(591.90) | Grad Norm 4.9546(5.9224) | Total Time 14.00(14.00)\n",
      "Iter 1740 | Time 14.5584(14.3935) | Bit/dim 3.8522(3.8813) | Xent 1.1872(1.2036) | Loss 4.4458(4.4831) | Error 0.4289(0.4296) Steps 610(593.10) | Grad Norm 6.2199(6.5116) | Total Time 14.00(14.00)\n",
      "Iter 1750 | Time 14.6010(14.4795) | Bit/dim 3.8797(3.8804) | Xent 1.2054(1.2095) | Loss 4.4824(4.4851) | Error 0.4422(0.4334) Steps 604(595.86) | Grad Norm 6.6436(6.8869) | Total Time 14.00(14.00)\n",
      "Iter 1760 | Time 14.3657(14.4653) | Bit/dim 3.8635(3.8771) | Xent 1.2026(1.2076) | Loss 4.4648(4.4809) | Error 0.4289(0.4327) Steps 592(595.88) | Grad Norm 9.0768(6.9385) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 78.0293, Epoch Time 891.4961(864.9080), Bit/dim 3.8680(best: 3.8791), Xent 1.1239, Loss 4.4299, Error 0.4022(best: 0.4003)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 14.7809(14.4876) | Bit/dim 3.8954(3.8757) | Xent 1.1760(1.1934) | Loss 4.4834(4.4724) | Error 0.4322(0.4267) Steps 598(596.56) | Grad Norm 6.5712(6.7812) | Total Time 14.00(14.00)\n",
      "Iter 1780 | Time 15.1598(14.5641) | Bit/dim 3.8460(3.8720) | Xent 1.1715(1.1831) | Loss 4.4318(4.4635) | Error 0.4189(0.4213) Steps 592(596.93) | Grad Norm 3.3888(6.2060) | Total Time 14.00(14.00)\n",
      "Iter 1790 | Time 14.3786(14.6274) | Bit/dim 3.8649(3.8683) | Xent 1.2362(1.1828) | Loss 4.4831(4.4598) | Error 0.4544(0.4231) Steps 598(598.31) | Grad Norm 9.0485(6.1702) | Total Time 14.00(14.00)\n",
      "Iter 1800 | Time 14.6612(14.6362) | Bit/dim 3.8953(3.8690) | Xent 1.1434(1.1895) | Loss 4.4671(4.4637) | Error 0.4056(0.4254) Steps 598(599.31) | Grad Norm 7.8394(6.6546) | Total Time 14.00(14.00)\n",
      "Iter 1810 | Time 14.4450(14.5932) | Bit/dim 3.8410(3.8645) | Xent 1.1206(1.1823) | Loss 4.4013(4.4557) | Error 0.3956(0.4234) Steps 604(600.09) | Grad Norm 3.3325(6.4039) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 77.5673, Epoch Time 899.8149(865.9552), Bit/dim 3.8498(best: 3.8680), Xent 1.0972, Loss 4.3984, Error 0.3927(best: 0.4003)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 15.1825(14.5932) | Bit/dim 3.8429(3.8624) | Xent 1.0857(1.1746) | Loss 4.3858(4.4497) | Error 0.3822(0.4200) Steps 610(600.15) | Grad Norm 4.5033(6.1645) | Total Time 14.00(14.00)\n",
      "Iter 1830 | Time 14.6245(14.6297) | Bit/dim 3.8715(3.8614) | Xent 1.1836(1.1686) | Loss 4.4633(4.4457) | Error 0.4178(0.4181) Steps 610(600.77) | Grad Norm 7.8661(6.1111) | Total Time 14.00(14.00)\n",
      "Iter 1840 | Time 14.0150(14.5909) | Bit/dim 3.8506(3.8598) | Xent 1.1732(1.1685) | Loss 4.4372(4.4441) | Error 0.4167(0.4187) Steps 592(599.46) | Grad Norm 6.7924(6.4965) | Total Time 14.00(14.00)\n",
      "Iter 1850 | Time 14.5766(14.6134) | Bit/dim 3.8933(3.8601) | Xent 1.1454(1.1610) | Loss 4.4660(4.4406) | Error 0.4133(0.4164) Steps 592(599.99) | Grad Norm 4.6133(6.2532) | Total Time 14.00(14.00)\n",
      "Iter 1860 | Time 15.0653(14.6526) | Bit/dim 3.8243(3.8540) | Xent 1.1175(1.1524) | Loss 4.3830(4.4302) | Error 0.3800(0.4130) Steps 604(600.30) | Grad Norm 5.7743(5.8051) | Total Time 14.00(14.00)\n",
      "Iter 1870 | Time 15.1901(14.6310) | Bit/dim 3.8684(3.8504) | Xent 1.0843(1.1465) | Loss 4.4105(4.4237) | Error 0.3811(0.4098) Steps 604(600.40) | Grad Norm 3.3000(5.5745) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 78.6280, Epoch Time 902.1620(867.0414), Bit/dim 3.8448(best: 3.8498), Xent 1.0646, Loss 4.3771, Error 0.3785(best: 0.3927)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 14.1424(14.6058) | Bit/dim 3.8424(3.8477) | Xent 1.1336(1.1419) | Loss 4.4092(4.4186) | Error 0.4100(0.4079) Steps 598(602.06) | Grad Norm 5.6425(5.5418) | Total Time 14.00(14.00)\n",
      "Iter 1890 | Time 14.4504(14.6225) | Bit/dim 3.8320(3.8451) | Xent 1.0546(1.1414) | Loss 4.3593(4.4158) | Error 0.3811(0.4085) Steps 598(601.37) | Grad Norm 3.9338(5.9959) | Total Time 14.00(14.00)\n",
      "Iter 1900 | Time 13.9754(14.6285) | Bit/dim 3.8353(3.8444) | Xent 1.1088(1.1439) | Loss 4.3896(4.4163) | Error 0.4033(0.4093) Steps 592(601.61) | Grad Norm 6.1278(6.3941) | Total Time 14.00(14.00)\n",
      "Iter 1910 | Time 14.7893(14.6321) | Bit/dim 3.8157(3.8431) | Xent 1.1420(1.1442) | Loss 4.3867(4.4152) | Error 0.4167(0.4093) Steps 604(601.27) | Grad Norm 5.2158(6.2271) | Total Time 14.00(14.00)\n",
      "Iter 1920 | Time 14.2079(14.5967) | Bit/dim 3.8507(3.8419) | Xent 1.0900(1.1336) | Loss 4.3957(4.4087) | Error 0.3933(0.4061) Steps 604(601.58) | Grad Norm 2.9593(5.6017) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 78.0843, Epoch Time 899.3735(868.0114), Bit/dim 3.8320(best: 3.8448), Xent 1.0429, Loss 4.3534, Error 0.3692(best: 0.3785)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 14.8572(14.5744) | Bit/dim 3.8348(3.8418) | Xent 1.0604(1.1245) | Loss 4.3650(4.4040) | Error 0.4000(0.4024) Steps 610(601.62) | Grad Norm 6.4329(5.4073) | Total Time 14.00(14.00)\n",
      "Iter 1940 | Time 14.4278(14.5483) | Bit/dim 3.8348(3.8390) | Xent 1.1892(1.1303) | Loss 4.4294(4.4041) | Error 0.4356(0.4060) Steps 604(602.27) | Grad Norm 6.4524(5.6529) | Total Time 14.00(14.00)\n",
      "Iter 1950 | Time 14.9434(14.5179) | Bit/dim 3.8157(3.8386) | Xent 1.1692(1.1326) | Loss 4.4003(4.4049) | Error 0.4300(0.4057) Steps 610(601.92) | Grad Norm 7.2257(6.0257) | Total Time 14.00(14.00)\n",
      "Iter 1960 | Time 14.8630(14.5861) | Bit/dim 3.8454(3.8354) | Xent 1.1123(1.1279) | Loss 4.4016(4.3994) | Error 0.4100(0.4031) Steps 616(602.63) | Grad Norm 6.8799(6.0381) | Total Time 14.00(14.00)\n",
      "Iter 1970 | Time 14.6236(14.6149) | Bit/dim 3.8128(3.8331) | Xent 1.0826(1.1221) | Loss 4.3541(4.3941) | Error 0.3978(0.4000) Steps 604(602.61) | Grad Norm 2.9863(5.8660) | Total Time 14.00(14.00)\n",
      "Iter 1980 | Time 14.5709(14.5791) | Bit/dim 3.8329(3.8310) | Xent 1.1275(1.1164) | Loss 4.3967(4.3892) | Error 0.4133(0.3974) Steps 604(603.76) | Grad Norm 3.8470(5.7744) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 79.2606, Epoch Time 897.7503(868.9036), Bit/dim 3.8258(best: 3.8320), Xent 1.0391, Loss 4.3453, Error 0.3741(best: 0.3692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 14.5401(14.6033) | Bit/dim 3.8040(3.8277) | Xent 1.0681(1.1111) | Loss 4.3380(4.3832) | Error 0.4000(0.3962) Steps 610(604.79) | Grad Norm 3.5827(5.8287) | Total Time 14.00(14.00)\n",
      "Iter 2000 | Time 14.9100(14.6322) | Bit/dim 3.8410(3.8250) | Xent 1.0119(1.0985) | Loss 4.3469(4.3743) | Error 0.3722(0.3923) Steps 604(605.48) | Grad Norm 3.8493(5.6600) | Total Time 14.00(14.00)\n",
      "Iter 2010 | Time 15.0854(14.6585) | Bit/dim 3.8293(3.8214) | Xent 1.0818(1.0952) | Loss 4.3701(4.3690) | Error 0.3756(0.3902) Steps 604(605.73) | Grad Norm 8.1736(5.9907) | Total Time 14.00(14.00)\n",
      "Iter 2020 | Time 15.2089(14.7166) | Bit/dim 3.8458(3.8260) | Xent 1.1447(1.1037) | Loss 4.4182(4.3779) | Error 0.4256(0.3927) Steps 610(607.01) | Grad Norm 9.0374(6.7118) | Total Time 14.00(14.00)\n",
      "Iter 2030 | Time 14.6001(14.8003) | Bit/dim 3.8636(3.8287) | Xent 1.2480(1.1153) | Loss 4.4876(4.3864) | Error 0.4367(0.3962) Steps 604(608.66) | Grad Norm 8.9259(6.8369) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 82.0777, Epoch Time 914.3869(870.2681), Bit/dim 3.8164(best: 3.8258), Xent 1.0496, Loss 4.3412, Error 0.3752(best: 0.3692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 14.4719(14.7793) | Bit/dim 3.8142(3.8272) | Xent 1.0627(1.1120) | Loss 4.3455(4.3832) | Error 0.3822(0.3964) Steps 598(609.02) | Grad Norm 5.7348(6.5339) | Total Time 14.00(14.00)\n",
      "Iter 2050 | Time 14.5215(14.7995) | Bit/dim 3.8151(3.8255) | Xent 1.0775(1.1166) | Loss 4.3538(4.3838) | Error 0.3578(0.3972) Steps 598(610.59) | Grad Norm 2.2855(6.5991) | Total Time 14.00(14.00)\n",
      "Iter 2060 | Time 14.4912(14.7527) | Bit/dim 3.8298(3.8229) | Xent 1.1095(1.1092) | Loss 4.3846(4.3775) | Error 0.3878(0.3935) Steps 610(611.42) | Grad Norm 2.5219(6.0234) | Total Time 14.00(14.00)\n",
      "Iter 2070 | Time 14.4891(14.7291) | Bit/dim 3.8088(3.8193) | Xent 1.0857(1.1014) | Loss 4.3516(4.3700) | Error 0.3911(0.3924) Steps 622(611.42) | Grad Norm 4.7140(5.2383) | Total Time 14.00(14.00)\n",
      "Iter 2080 | Time 14.7839(14.7428) | Bit/dim 3.8382(3.8169) | Xent 1.0740(1.0976) | Loss 4.3752(4.3657) | Error 0.3811(0.3920) Steps 628(613.28) | Grad Norm 7.2633(5.5506) | Total Time 14.00(14.00)\n",
      "Iter 2090 | Time 14.7605(14.8178) | Bit/dim 3.7992(3.8162) | Xent 1.0774(1.0959) | Loss 4.3379(4.3641) | Error 0.3900(0.3924) Steps 628(615.84) | Grad Norm 8.4620(5.9897) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 83.5041, Epoch Time 913.8296(871.5749), Bit/dim 3.8142(best: 3.8164), Xent 1.0397, Loss 4.3341, Error 0.3680(best: 0.3692)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 15.6016(14.8198) | Bit/dim 3.8281(3.8128) | Xent 1.0844(1.0923) | Loss 4.3702(4.3590) | Error 0.4011(0.3924) Steps 634(617.68) | Grad Norm 7.5980(5.9005) | Total Time 14.00(14.00)\n",
      "Iter 2110 | Time 15.1767(14.8215) | Bit/dim 3.8174(3.8107) | Xent 1.0488(1.0877) | Loss 4.3418(4.3545) | Error 0.3556(0.3896) Steps 622(618.84) | Grad Norm 6.2634(5.8446) | Total Time 14.00(14.00)\n",
      "Iter 2120 | Time 14.1206(14.7963) | Bit/dim 3.7722(3.8102) | Xent 1.0383(1.0744) | Loss 4.2913(4.3474) | Error 0.4011(0.3845) Steps 616(620.27) | Grad Norm 4.7784(5.4751) | Total Time 14.00(14.00)\n",
      "Iter 2130 | Time 14.9637(14.8381) | Bit/dim 3.8221(3.8084) | Xent 1.0779(1.0651) | Loss 4.3610(4.3410) | Error 0.3822(0.3806) Steps 616(621.05) | Grad Norm 3.6466(5.2734) | Total Time 14.00(14.00)\n",
      "Iter 2140 | Time 14.7895(14.8590) | Bit/dim 3.8352(3.8094) | Xent 1.0313(1.0779) | Loss 4.3509(4.3484) | Error 0.3644(0.3849) Steps 628(621.14) | Grad Norm 6.8902(5.9003) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 83.6178, Epoch Time 919.0836(873.0002), Bit/dim 3.8168(best: 3.8142), Xent 1.0265, Loss 4.3300, Error 0.3679(best: 0.3680)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 15.6638(14.9048) | Bit/dim 3.8138(3.8117) | Xent 1.0562(1.0749) | Loss 4.3420(4.3491) | Error 0.3822(0.3845) Steps 628(622.02) | Grad Norm 6.7815(5.9143) | Total Time 14.00(14.00)\n",
      "Iter 2160 | Time 14.8287(14.8737) | Bit/dim 3.7947(3.8092) | Xent 1.0511(1.0659) | Loss 4.3203(4.3422) | Error 0.3800(0.3810) Steps 616(622.28) | Grad Norm 5.6499(5.7355) | Total Time 14.00(14.00)\n",
      "Iter 2170 | Time 14.2504(14.8644) | Bit/dim 3.8067(3.8049) | Xent 1.0261(1.0590) | Loss 4.3198(4.3344) | Error 0.3656(0.3774) Steps 616(622.50) | Grad Norm 5.3274(5.6655) | Total Time 14.00(14.00)\n",
      "Iter 2180 | Time 14.7295(14.8258) | Bit/dim 3.7977(3.8026) | Xent 1.0207(1.0511) | Loss 4.3080(4.3282) | Error 0.3656(0.3751) Steps 616(621.62) | Grad Norm 6.8449(5.3233) | Total Time 14.00(14.00)\n",
      "Iter 2190 | Time 14.7141(14.8213) | Bit/dim 3.7788(3.7991) | Xent 0.9979(1.0471) | Loss 4.2777(4.3226) | Error 0.3556(0.3739) Steps 628(622.38) | Grad Norm 3.4760(5.2325) | Total Time 14.00(14.00)\n",
      "Iter 2200 | Time 14.7018(14.8291) | Bit/dim 3.8051(3.7966) | Xent 1.0013(1.0485) | Loss 4.3058(4.3209) | Error 0.3700(0.3742) Steps 628(621.48) | Grad Norm 9.0725(5.6255) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 83.1483, Epoch Time 916.1162(874.2937), Bit/dim 3.7988(best: 3.8142), Xent 1.0708, Loss 4.3342, Error 0.3815(best: 0.3679)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 14.9935(14.8688) | Bit/dim 3.8237(3.7984) | Xent 1.0822(1.0590) | Loss 4.3648(4.3279) | Error 0.3800(0.3783) Steps 628(622.26) | Grad Norm 6.8150(6.2317) | Total Time 14.00(14.00)\n",
      "Iter 2220 | Time 14.8018(14.8209) | Bit/dim 3.7736(3.7998) | Xent 1.1204(1.0664) | Loss 4.3337(4.3329) | Error 0.3911(0.3815) Steps 628(622.85) | Grad Norm 9.0513(6.3077) | Total Time 14.00(14.00)\n",
      "Iter 2230 | Time 14.6067(14.8205) | Bit/dim 3.7391(3.7987) | Xent 1.0733(1.0640) | Loss 4.2758(4.3307) | Error 0.3933(0.3795) Steps 622(623.51) | Grad Norm 5.4479(6.3955) | Total Time 14.00(14.00)\n",
      "Iter 2240 | Time 15.2292(14.8470) | Bit/dim 3.7732(3.7959) | Xent 1.0241(1.0537) | Loss 4.2852(4.3228) | Error 0.3678(0.3762) Steps 616(622.16) | Grad Norm 6.6589(6.0394) | Total Time 14.00(14.00)\n",
      "Iter 2250 | Time 14.9086(14.7964) | Bit/dim 3.7699(3.7918) | Xent 1.0549(1.0453) | Loss 4.2974(4.3145) | Error 0.3633(0.3719) Steps 628(622.59) | Grad Norm 4.1203(5.5415) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 82.4649, Epoch Time 915.2309(875.5218), Bit/dim 3.7796(best: 3.7988), Xent 0.9721, Loss 4.2657, Error 0.3456(best: 0.3679)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 14.8405(14.8254) | Bit/dim 3.7994(3.7891) | Xent 1.0120(1.0320) | Loss 4.3054(4.3051) | Error 0.3633(0.3677) Steps 616(622.69) | Grad Norm 3.7600(5.1922) | Total Time 14.00(14.00)\n",
      "Iter 2270 | Time 14.5970(14.8077) | Bit/dim 3.7560(3.7890) | Xent 0.9515(1.0232) | Loss 4.2318(4.3006) | Error 0.3356(0.3632) Steps 628(622.87) | Grad Norm 4.1050(5.1583) | Total Time 14.00(14.00)\n",
      "Iter 2280 | Time 14.6510(14.8203) | Bit/dim 3.7806(3.7877) | Xent 1.0975(1.0251) | Loss 4.3293(4.3002) | Error 0.3922(0.3646) Steps 616(622.80) | Grad Norm 9.6893(5.5308) | Total Time 14.00(14.00)\n",
      "Iter 2290 | Time 14.7752(14.8294) | Bit/dim 3.7901(3.7863) | Xent 1.0017(1.0253) | Loss 4.2909(4.2990) | Error 0.3567(0.3655) Steps 622(622.63) | Grad Norm 5.2295(5.5880) | Total Time 14.00(14.00)\n",
      "Iter 2300 | Time 14.7757(14.8213) | Bit/dim 3.8216(3.7853) | Xent 0.9777(1.0221) | Loss 4.3104(4.2963) | Error 0.3511(0.3655) Steps 628(622.50) | Grad Norm 4.7417(5.6738) | Total Time 14.00(14.00)\n",
      "Iter 2310 | Time 14.6796(14.7998) | Bit/dim 3.7720(3.7847) | Xent 1.0168(1.0156) | Loss 4.2804(4.2925) | Error 0.3544(0.3625) Steps 628(623.02) | Grad Norm 6.2454(5.7305) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 82.7332, Epoch Time 915.3688(876.7172), Bit/dim 3.7816(best: 3.7796), Xent 0.9511, Loss 4.2572, Error 0.3382(best: 0.3456)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 14.5916(14.7944) | Bit/dim 3.8102(3.7846) | Xent 0.9883(1.0115) | Loss 4.3043(4.2904) | Error 0.3322(0.3607) Steps 616(622.68) | Grad Norm 5.5450(5.5662) | Total Time 14.00(14.00)\n",
      "Iter 2330 | Time 14.7897(14.7800) | Bit/dim 3.7720(3.7821) | Xent 1.0807(1.0126) | Loss 4.3124(4.2885) | Error 0.3767(0.3620) Steps 628(622.98) | Grad Norm 6.0794(5.8169) | Total Time 14.00(14.00)\n",
      "Iter 2340 | Time 14.9394(14.7690) | Bit/dim 3.7713(3.7830) | Xent 0.9907(1.0064) | Loss 4.2667(4.2862) | Error 0.3633(0.3605) Steps 628(623.06) | Grad Norm 3.6898(5.5663) | Total Time 14.00(14.00)\n",
      "Iter 2350 | Time 14.8381(14.7709) | Bit/dim 3.7926(3.7827) | Xent 0.9860(1.0042) | Loss 4.2856(4.2848) | Error 0.3478(0.3591) Steps 622(623.76) | Grad Norm 4.5797(5.4286) | Total Time 14.00(14.00)\n",
      "Iter 2360 | Time 14.7221(14.7572) | Bit/dim 3.7861(3.7790) | Xent 0.9491(0.9975) | Loss 4.2607(4.2777) | Error 0.3422(0.3575) Steps 622(622.82) | Grad Norm 6.7440(5.3181) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 83.1122, Epoch Time 911.8970(877.7726), Bit/dim 3.7768(best: 3.7796), Xent 0.9674, Loss 4.2605, Error 0.3421(best: 0.3382)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 14.9568(14.7686) | Bit/dim 3.7518(3.7766) | Xent 0.9060(0.9964) | Loss 4.2048(4.2748) | Error 0.3378(0.3568) Steps 622(623.06) | Grad Norm 5.1568(5.6423) | Total Time 14.00(14.00)\n",
      "Iter 2380 | Time 14.8582(14.8194) | Bit/dim 3.7542(3.7757) | Xent 1.0132(0.9935) | Loss 4.2608(4.2724) | Error 0.3511(0.3545) Steps 622(623.07) | Grad Norm 4.3783(5.6626) | Total Time 14.00(14.00)\n",
      "Iter 2390 | Time 14.9650(14.8646) | Bit/dim 3.7404(3.7732) | Xent 0.9628(0.9918) | Loss 4.2218(4.2691) | Error 0.3567(0.3553) Steps 628(624.34) | Grad Norm 5.9446(5.4859) | Total Time 14.00(14.00)\n",
      "Iter 2400 | Time 15.3545(14.9057) | Bit/dim 3.7545(3.7721) | Xent 0.9804(0.9891) | Loss 4.2447(4.2666) | Error 0.3367(0.3534) Steps 622(623.86) | Grad Norm 5.7125(5.2766) | Total Time 14.00(14.00)\n",
      "Iter 2410 | Time 14.9608(14.8723) | Bit/dim 3.7749(3.7720) | Xent 0.9866(0.9853) | Loss 4.2682(4.2646) | Error 0.3578(0.3526) Steps 628(623.88) | Grad Norm 3.8812(5.1861) | Total Time 14.00(14.00)\n",
      "Iter 2420 | Time 14.9258(14.9066) | Bit/dim 3.7584(3.7711) | Xent 0.9782(0.9909) | Loss 4.2475(4.2665) | Error 0.3567(0.3529) Steps 628(623.89) | Grad Norm 7.1241(5.5252) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 83.4051, Epoch Time 922.8952(879.1263), Bit/dim 3.7677(best: 3.7768), Xent 0.9651, Loss 4.2503, Error 0.3374(best: 0.3382)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 14.8468(14.8906) | Bit/dim 3.7568(3.7710) | Xent 0.9890(0.9935) | Loss 4.2514(4.2678) | Error 0.3578(0.3550) Steps 628(624.50) | Grad Norm 5.6529(5.5605) | Total Time 14.00(14.00)\n",
      "Iter 2440 | Time 15.4902(14.9039) | Bit/dim 3.7527(3.7679) | Xent 0.9431(0.9823) | Loss 4.2242(4.2590) | Error 0.3100(0.3489) Steps 622(623.69) | Grad Norm 4.1375(5.3177) | Total Time 14.00(14.00)\n",
      "Iter 2450 | Time 14.9177(14.8878) | Bit/dim 3.7828(3.7687) | Xent 0.9755(0.9788) | Loss 4.2706(4.2580) | Error 0.3422(0.3489) Steps 628(623.46) | Grad Norm 4.8201(5.3183) | Total Time 14.00(14.00)\n",
      "Iter 2460 | Time 15.1037(14.8632) | Bit/dim 3.7419(3.7682) | Xent 0.9210(0.9713) | Loss 4.2024(4.2538) | Error 0.3411(0.3453) Steps 622(623.17) | Grad Norm 5.6280(5.2939) | Total Time 14.00(14.00)\n",
      "Iter 2470 | Time 15.5629(14.9125) | Bit/dim 3.7480(3.7664) | Xent 1.0103(0.9876) | Loss 4.2531(4.2602) | Error 0.3522(0.3511) Steps 628(623.50) | Grad Norm 9.4365(5.9189) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 84.4170, Epoch Time 922.6818(880.4329), Bit/dim 3.7784(best: 3.7677), Xent 0.9570, Loss 4.2569, Error 0.3400(best: 0.3374)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 14.7917(14.9544) | Bit/dim 3.7481(3.7682) | Xent 1.0273(0.9891) | Loss 4.2618(4.2627) | Error 0.3400(0.3516) Steps 634(624.27) | Grad Norm 5.3508(5.9792) | Total Time 14.00(14.00)\n",
      "Iter 2490 | Time 15.4409(14.9424) | Bit/dim 3.7232(3.7644) | Xent 0.9420(0.9796) | Loss 4.1942(4.2542) | Error 0.3333(0.3487) Steps 628(623.34) | Grad Norm 3.3569(5.3943) | Total Time 14.00(14.00)\n",
      "Iter 2500 | Time 14.9177(14.9584) | Bit/dim 3.7398(3.7632) | Xent 0.9644(0.9769) | Loss 4.2220(4.2517) | Error 0.3389(0.3468) Steps 628(623.31) | Grad Norm 4.9827(5.5608) | Total Time 14.00(14.00)\n",
      "Iter 2510 | Time 14.8637(14.9693) | Bit/dim 3.7877(3.7659) | Xent 0.9771(0.9654) | Loss 4.2763(4.2486) | Error 0.3600(0.3433) Steps 622(623.01) | Grad Norm 9.2739(5.4681) | Total Time 14.00(14.00)\n",
      "Iter 2520 | Time 14.7139(14.9464) | Bit/dim 3.7559(3.7659) | Xent 0.9623(0.9833) | Loss 4.2370(4.2575) | Error 0.3300(0.3495) Steps 622(622.46) | Grad Norm 5.3706(5.8978) | Total Time 14.00(14.00)\n",
      "Iter 2530 | Time 14.9624(14.9582) | Bit/dim 3.7486(3.7656) | Xent 0.9477(0.9809) | Loss 4.2225(4.2561) | Error 0.3389(0.3491) Steps 628(622.17) | Grad Norm 5.2654(5.8769) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 85.4371, Epoch Time 925.7920(881.7937), Bit/dim 3.7659(best: 3.7677), Xent 0.9199, Loss 4.2259, Error 0.3233(best: 0.3374)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 14.6712(14.9140) | Bit/dim 3.7477(3.7660) | Xent 0.9989(0.9772) | Loss 4.2472(4.2546) | Error 0.3444(0.3478) Steps 622(622.58) | Grad Norm 5.1263(5.5188) | Total Time 14.00(14.00)\n",
      "Iter 2550 | Time 15.3449(14.9519) | Bit/dim 3.7578(3.7645) | Xent 0.9233(0.9716) | Loss 4.2194(4.2503) | Error 0.3289(0.3458) Steps 622(622.12) | Grad Norm 5.2813(5.8360) | Total Time 14.00(14.00)\n",
      "Iter 2560 | Time 14.6961(14.9396) | Bit/dim 3.7421(3.7645) | Xent 0.9577(0.9690) | Loss 4.2210(4.2490) | Error 0.3356(0.3436) Steps 622(622.10) | Grad Norm 3.0749(5.5960) | Total Time 14.00(14.00)\n",
      "Iter 2570 | Time 14.7835(14.9434) | Bit/dim 3.7536(3.7627) | Xent 0.8809(0.9621) | Loss 4.1941(4.2437) | Error 0.2978(0.3414) Steps 622(621.92) | Grad Norm 4.9860(5.5951) | Total Time 14.00(14.00)\n",
      "Iter 2580 | Time 14.8905(14.9674) | Bit/dim 3.7335(3.7593) | Xent 0.9656(0.9594) | Loss 4.2163(4.2390) | Error 0.3311(0.3390) Steps 622(622.43) | Grad Norm 5.0196(5.4332) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 83.0076, Epoch Time 923.0903(883.0326), Bit/dim 3.7582(best: 3.7659), Xent 0.9248, Loss 4.2206, Error 0.3274(best: 0.3233)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 14.7547(14.9811) | Bit/dim 3.7566(3.7570) | Xent 0.9681(0.9505) | Loss 4.2406(4.2322) | Error 0.3467(0.3358) Steps 616(622.76) | Grad Norm 4.9990(5.3488) | Total Time 14.00(14.00)\n",
      "Iter 2600 | Time 14.8404(14.9597) | Bit/dim 3.7206(3.7527) | Xent 0.9319(0.9492) | Loss 4.1865(4.2273) | Error 0.3411(0.3373) Steps 622(622.04) | Grad Norm 3.1852(5.5212) | Total Time 14.00(14.00)\n",
      "Iter 2610 | Time 14.8988(14.9006) | Bit/dim 3.7181(3.7523) | Xent 0.9389(0.9457) | Loss 4.1875(4.2251) | Error 0.3289(0.3354) Steps 616(621.06) | Grad Norm 10.1812(5.5258) | Total Time 14.00(14.00)\n",
      "Iter 2620 | Time 14.9274(14.8585) | Bit/dim 3.7627(3.7543) | Xent 0.9630(0.9539) | Loss 4.2442(4.2313) | Error 0.3467(0.3398) Steps 616(620.40) | Grad Norm 5.0505(5.4962) | Total Time 14.00(14.00)\n",
      "Iter 2630 | Time 15.1707(14.8200) | Bit/dim 3.7347(3.7532) | Xent 0.9619(0.9514) | Loss 4.2157(4.2289) | Error 0.3278(0.3366) Steps 634(620.73) | Grad Norm 3.7814(5.3079) | Total Time 14.00(14.00)\n",
      "Iter 2640 | Time 15.0831(14.8780) | Bit/dim 3.7364(3.7539) | Xent 0.9766(0.9482) | Loss 4.2247(4.2280) | Error 0.3467(0.3370) Steps 634(621.60) | Grad Norm 3.9229(5.3947) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 82.3485, Epoch Time 916.3889(884.0333), Bit/dim 3.7511(best: 3.7582), Xent 0.9259, Loss 4.2140, Error 0.3267(best: 0.3233)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 14.9896(14.8775) | Bit/dim 3.7803(3.7553) | Xent 0.9200(0.9415) | Loss 4.2404(4.2260) | Error 0.3133(0.3346) Steps 622(620.62) | Grad Norm 4.4276(5.3738) | Total Time 14.00(14.00)\n",
      "Iter 2660 | Time 14.7953(14.8764) | Bit/dim 3.7374(3.7526) | Xent 0.8950(0.9379) | Loss 4.1849(4.2216) | Error 0.3189(0.3346) Steps 616(620.80) | Grad Norm 6.5222(5.2608) | Total Time 14.00(14.00)\n",
      "Iter 2670 | Time 14.8959(14.8847) | Bit/dim 3.7173(3.7525) | Xent 0.8817(0.9264) | Loss 4.1581(4.2157) | Error 0.2989(0.3302) Steps 628(620.55) | Grad Norm 4.0319(4.9307) | Total Time 14.00(14.00)\n",
      "Iter 2680 | Time 14.6535(14.9008) | Bit/dim 3.7236(3.7485) | Xent 0.9884(0.9366) | Loss 4.2178(4.2168) | Error 0.3522(0.3339) Steps 616(620.42) | Grad Norm 5.3645(5.3374) | Total Time 14.00(14.00)\n",
      "Iter 2690 | Time 15.5294(14.9277) | Bit/dim 3.7471(3.7496) | Xent 0.8091(0.9372) | Loss 4.1516(4.2182) | Error 0.2989(0.3341) Steps 622(620.21) | Grad Norm 3.1589(5.4946) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 82.9135, Epoch Time 921.7158(885.1638), Bit/dim 3.7417(best: 3.7511), Xent 0.8979, Loss 4.1907, Error 0.3163(best: 0.3233)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 14.7501(14.9764) | Bit/dim 3.7319(3.7480) | Xent 0.9105(0.9249) | Loss 4.1872(4.2104) | Error 0.3200(0.3299) Steps 622(620.40) | Grad Norm 2.7218(4.9606) | Total Time 14.00(14.00)\n",
      "Iter 2710 | Time 14.7413(14.9640) | Bit/dim 3.7404(3.7490) | Xent 0.9132(0.9180) | Loss 4.1970(4.2080) | Error 0.3444(0.3278) Steps 622(620.20) | Grad Norm 3.3570(4.7640) | Total Time 14.00(14.00)\n",
      "Iter 2720 | Time 15.0082(14.9542) | Bit/dim 3.7424(3.7482) | Xent 0.9243(0.9149) | Loss 4.2046(4.2057) | Error 0.3200(0.3257) Steps 628(620.37) | Grad Norm 4.3868(5.1132) | Total Time 14.00(14.00)\n",
      "Iter 2730 | Time 14.5601(14.9146) | Bit/dim 3.7749(3.7462) | Xent 0.9813(0.9203) | Loss 4.2656(4.2063) | Error 0.3511(0.3286) Steps 622(620.77) | Grad Norm 4.6648(5.0464) | Total Time 14.00(14.00)\n",
      "Iter 2740 | Time 14.9024(14.9053) | Bit/dim 3.7233(3.7452) | Xent 0.9438(0.9133) | Loss 4.1952(4.2019) | Error 0.3356(0.3264) Steps 610(621.09) | Grad Norm 6.5390(5.0637) | Total Time 14.00(14.00)\n",
      "Iter 2750 | Time 15.5562(14.9266) | Bit/dim 3.7741(3.7451) | Xent 0.9411(0.9227) | Loss 4.2446(4.2064) | Error 0.3311(0.3286) Steps 622(621.02) | Grad Norm 7.8854(5.5632) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 82.7694, Epoch Time 921.7053(886.2600), Bit/dim 3.7449(best: 3.7417), Xent 0.9330, Loss 4.2115, Error 0.3328(best: 0.3163)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 15.0672(14.9126) | Bit/dim 3.7283(3.7461) | Xent 0.8698(0.9212) | Loss 4.1632(4.2067) | Error 0.3022(0.3285) Steps 616(620.86) | Grad Norm 5.3427(5.3859) | Total Time 14.00(14.00)\n",
      "Iter 2770 | Time 15.2667(14.9177) | Bit/dim 3.7129(3.7474) | Xent 1.0177(0.9233) | Loss 4.2218(4.2090) | Error 0.3556(0.3287) Steps 616(620.04) | Grad Norm 5.8827(5.3651) | Total Time 14.00(14.00)\n",
      "Iter 2780 | Time 14.5664(14.9128) | Bit/dim 3.7263(3.7453) | Xent 0.9299(0.9244) | Loss 4.1913(4.2075) | Error 0.3300(0.3294) Steps 622(620.24) | Grad Norm 6.0144(5.7120) | Total Time 14.00(14.00)\n",
      "Iter 2790 | Time 14.7025(14.9496) | Bit/dim 3.7409(3.7449) | Xent 0.9001(0.9221) | Loss 4.1909(4.2059) | Error 0.3167(0.3297) Steps 616(620.74) | Grad Norm 3.4243(5.2981) | Total Time 14.00(14.00)\n",
      "Iter 2800 | Time 14.5561(14.9315) | Bit/dim 3.7682(3.7403) | Xent 0.9202(0.9144) | Loss 4.2283(4.1975) | Error 0.3256(0.3280) Steps 616(620.53) | Grad Norm 3.9945(5.0218) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 81.4284, Epoch Time 919.3394(887.2524), Bit/dim 3.7365(best: 3.7417), Xent 0.9227, Loss 4.1979, Error 0.3258(best: 0.3163)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 14.5985(14.9144) | Bit/dim 3.7474(3.7406) | Xent 0.8977(0.9078) | Loss 4.1963(4.1945) | Error 0.3233(0.3248) Steps 622(619.46) | Grad Norm 3.4634(5.0736) | Total Time 14.00(14.00)\n",
      "Iter 2820 | Time 14.6348(14.9157) | Bit/dim 3.7108(3.7388) | Xent 0.9159(0.9061) | Loss 4.1688(4.1919) | Error 0.3267(0.3248) Steps 616(619.04) | Grad Norm 4.7300(5.0811) | Total Time 14.00(14.00)\n",
      "Iter 2830 | Time 14.9488(14.9450) | Bit/dim 3.7479(3.7415) | Xent 0.9521(0.9148) | Loss 4.2240(4.1989) | Error 0.3422(0.3272) Steps 622(618.51) | Grad Norm 3.4558(5.4235) | Total Time 14.00(14.00)\n",
      "Iter 2840 | Time 14.9313(14.9513) | Bit/dim 3.7418(3.7414) | Xent 0.8896(0.9100) | Loss 4.1866(4.1965) | Error 0.3144(0.3260) Steps 610(618.11) | Grad Norm 4.0282(4.9960) | Total Time 14.00(14.00)\n",
      "Iter 2850 | Time 15.0972(14.9867) | Bit/dim 3.7075(3.7362) | Xent 0.9105(0.9070) | Loss 4.1628(4.1897) | Error 0.3422(0.3248) Steps 616(617.60) | Grad Norm 3.4916(4.7405) | Total Time 14.00(14.00)\n",
      "Iter 2860 | Time 15.5032(14.9825) | Bit/dim 3.7370(3.7339) | Xent 0.9251(0.9025) | Loss 4.1996(4.1852) | Error 0.3256(0.3225) Steps 622(617.84) | Grad Norm 9.0479(5.0665) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 81.7556, Epoch Time 924.1384(888.3590), Bit/dim 3.7352(best: 3.7365), Xent 0.8836, Loss 4.1770, Error 0.3133(best: 0.3163)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 14.6250(14.9188) | Bit/dim 3.7078(3.7327) | Xent 0.7800(0.8927) | Loss 4.0979(4.1791) | Error 0.2800(0.3189) Steps 616(617.80) | Grad Norm 5.0862(5.0870) | Total Time 14.00(14.00)\n",
      "Iter 2880 | Time 14.7969(14.9444) | Bit/dim 3.7422(3.7325) | Xent 0.9197(0.8905) | Loss 4.2020(4.1777) | Error 0.3300(0.3187) Steps 622(616.91) | Grad Norm 5.2049(4.9669) | Total Time 14.00(14.00)\n",
      "Iter 2890 | Time 15.7002(15.0212) | Bit/dim 3.7379(3.7329) | Xent 0.8940(0.8871) | Loss 4.1849(4.1765) | Error 0.3211(0.3180) Steps 622(618.00) | Grad Norm 4.2022(4.8334) | Total Time 14.00(14.00)\n",
      "Iter 2900 | Time 14.5872(15.0059) | Bit/dim 3.7546(3.7328) | Xent 0.8893(0.8855) | Loss 4.1993(4.1755) | Error 0.3044(0.3149) Steps 610(617.43) | Grad Norm 4.9117(4.9526) | Total Time 14.00(14.00)\n",
      "Iter 2910 | Time 14.6688(15.0240) | Bit/dim 3.7475(3.7348) | Xent 0.9035(0.9044) | Loss 4.1992(4.1870) | Error 0.3167(0.3200) Steps 610(616.53) | Grad Norm 7.2029(5.6908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 82.6008, Epoch Time 925.8020(889.4823), Bit/dim 3.7430(best: 3.7352), Xent 0.9085, Loss 4.1972, Error 0.3245(best: 0.3133)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 14.5561(15.0085) | Bit/dim 3.7013(3.7362) | Xent 0.8626(0.8962) | Loss 4.1326(4.1843) | Error 0.2856(0.3166) Steps 616(616.77) | Grad Norm 3.0537(5.3014) | Total Time 14.00(14.00)\n",
      "Iter 2930 | Time 14.8940(14.9542) | Bit/dim 3.7530(3.7338) | Xent 0.8832(0.8884) | Loss 4.1946(4.1780) | Error 0.3111(0.3152) Steps 604(616.23) | Grad Norm 3.2386(4.9005) | Total Time 14.00(14.00)\n",
      "Iter 2940 | Time 14.7186(14.9357) | Bit/dim 3.7282(3.7330) | Xent 0.8674(0.8838) | Loss 4.1619(4.1749) | Error 0.3011(0.3128) Steps 622(616.55) | Grad Norm 3.2024(4.8243) | Total Time 14.00(14.00)\n",
      "Iter 2950 | Time 14.8668(14.9740) | Bit/dim 3.7240(3.7325) | Xent 0.8153(0.8836) | Loss 4.1317(4.1743) | Error 0.2878(0.3129) Steps 616(617.74) | Grad Norm 4.4504(5.1179) | Total Time 14.00(14.00)\n",
      "Iter 2960 | Time 15.0439(15.0105) | Bit/dim 3.7067(3.7318) | Xent 0.8678(0.8877) | Loss 4.1406(4.1757) | Error 0.3167(0.3142) Steps 622(617.17) | Grad Norm 5.5177(5.3918) | Total Time 14.00(14.00)\n",
      "Iter 2970 | Time 14.5920(15.0215) | Bit/dim 3.7441(3.7321) | Xent 0.9245(0.8890) | Loss 4.2064(4.1766) | Error 0.3300(0.3156) Steps 610(617.24) | Grad Norm 6.2994(5.3402) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 81.3853, Epoch Time 923.7163(890.5093), Bit/dim 3.7316(best: 3.7352), Xent 0.8582, Loss 4.1607, Error 0.3011(best: 0.3133)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 15.6725(15.0516) | Bit/dim 3.7094(3.7304) | Xent 0.8512(0.8812) | Loss 4.1350(4.1710) | Error 0.3233(0.3131) Steps 616(617.09) | Grad Norm 3.1716(5.2360) | Total Time 14.00(14.00)\n",
      "Iter 2990 | Time 15.6141(15.0588) | Bit/dim 3.7100(3.7285) | Xent 0.8016(0.8784) | Loss 4.1108(4.1677) | Error 0.3022(0.3137) Steps 622(616.90) | Grad Norm 3.7487(5.2242) | Total Time 14.00(14.00)\n",
      "Iter 3000 | Time 14.7139(15.0184) | Bit/dim 3.7165(3.7305) | Xent 0.8678(0.8845) | Loss 4.1504(4.1727) | Error 0.3067(0.3162) Steps 616(616.51) | Grad Norm 5.6550(5.5327) | Total Time 14.00(14.00)\n",
      "Iter 3010 | Time 14.4477(14.9745) | Bit/dim 3.7515(3.7295) | Xent 0.8375(0.8894) | Loss 4.1703(4.1742) | Error 0.3056(0.3183) Steps 610(616.74) | Grad Norm 2.8397(5.6852) | Total Time 14.00(14.00)\n",
      "Iter 3020 | Time 14.5355(14.9625) | Bit/dim 3.7049(3.7277) | Xent 0.9562(0.8942) | Loss 4.1830(4.1748) | Error 0.3489(0.3199) Steps 616(616.55) | Grad Norm 2.7081(5.3505) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 81.7856, Epoch Time 924.1492(891.5185), Bit/dim 3.7287(best: 3.7316), Xent 0.8510, Loss 4.1542, Error 0.2989(best: 0.3011)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 15.3674(15.0270) | Bit/dim 3.7156(3.7282) | Xent 0.8345(0.8859) | Loss 4.1329(4.1711) | Error 0.3011(0.3171) Steps 610(616.82) | Grad Norm 3.2473(5.0685) | Total Time 14.00(14.00)\n",
      "Iter 3040 | Time 15.1489(14.9962) | Bit/dim 3.7446(3.7271) | Xent 0.9197(0.8803) | Loss 4.2044(4.1672) | Error 0.3333(0.3157) Steps 616(616.48) | Grad Norm 5.8454(4.9749) | Total Time 14.00(14.00)\n",
      "Iter 3050 | Time 15.4561(15.0222) | Bit/dim 3.7199(3.7242) | Xent 0.8331(0.8709) | Loss 4.1364(4.1596) | Error 0.2878(0.3109) Steps 610(615.80) | Grad Norm 2.6324(4.6090) | Total Time 14.00(14.00)\n",
      "Iter 3060 | Time 15.1839(14.9946) | Bit/dim 3.6993(3.7207) | Xent 0.8863(0.8662) | Loss 4.1424(4.1538) | Error 0.3267(0.3090) Steps 622(615.44) | Grad Norm 8.6687(4.6612) | Total Time 14.00(14.00)\n",
      "Iter 3070 | Time 14.8715(15.0180) | Bit/dim 3.7742(3.7222) | Xent 0.8152(0.8734) | Loss 4.1819(4.1589) | Error 0.2856(0.3118) Steps 610(614.72) | Grad Norm 6.2931(4.9884) | Total Time 14.00(14.00)\n",
      "Iter 3080 | Time 15.1703(15.0594) | Bit/dim 3.7125(3.7205) | Xent 0.8928(0.8737) | Loss 4.1589(4.1574) | Error 0.3022(0.3115) Steps 610(616.29) | Grad Norm 4.6911(5.1813) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 80.3141, Epoch Time 926.2117(892.5593), Bit/dim 3.7227(best: 3.7287), Xent 0.8552, Loss 4.1503, Error 0.2987(best: 0.2989)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 14.7234(14.9922) | Bit/dim 3.7084(3.7220) | Xent 0.8343(0.8649) | Loss 4.1256(4.1544) | Error 0.2811(0.3087) Steps 616(615.46) | Grad Norm 3.7204(5.0091) | Total Time 14.00(14.00)\n",
      "Iter 3100 | Time 15.0477(15.0103) | Bit/dim 3.7100(3.7189) | Xent 0.8346(0.8593) | Loss 4.1273(4.1486) | Error 0.2833(0.3063) Steps 622(615.61) | Grad Norm 3.1823(4.8396) | Total Time 14.00(14.00)\n",
      "Iter 3110 | Time 15.1394(14.9768) | Bit/dim 3.7441(3.7173) | Xent 0.8162(0.8557) | Loss 4.1522(4.1452) | Error 0.3000(0.3047) Steps 610(614.75) | Grad Norm 5.7012(4.8125) | Total Time 14.00(14.00)\n",
      "Iter 3120 | Time 14.6412(14.9716) | Bit/dim 3.7199(3.7184) | Xent 0.9624(0.8601) | Loss 4.2011(4.1485) | Error 0.3700(0.3068) Steps 610(614.90) | Grad Norm 3.9324(4.6792) | Total Time 14.00(14.00)\n",
      "Iter 3130 | Time 14.9607(14.9535) | Bit/dim 3.7286(3.7170) | Xent 0.9321(0.8615) | Loss 4.1946(4.1478) | Error 0.3378(0.3079) Steps 610(613.92) | Grad Norm 6.0589(4.7011) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 82.5034, Epoch Time 921.2316(893.4194), Bit/dim 3.7152(best: 3.7227), Xent 0.8686, Loss 4.1495, Error 0.3082(best: 0.2987)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 15.3771(14.9600) | Bit/dim 3.7270(3.7150) | Xent 0.8511(0.8516) | Loss 4.1525(4.1408) | Error 0.3044(0.3051) Steps 610(614.44) | Grad Norm 6.4479(4.8911) | Total Time 14.00(14.00)\n",
      "Iter 3150 | Time 14.9375(14.9604) | Bit/dim 3.7244(3.7140) | Xent 0.8500(0.8478) | Loss 4.1494(4.1379) | Error 0.3011(0.3035) Steps 610(613.72) | Grad Norm 8.2664(4.8884) | Total Time 14.00(14.00)\n",
      "Iter 3160 | Time 15.4174(15.0121) | Bit/dim 3.6916(3.7163) | Xent 0.8187(0.8444) | Loss 4.1009(4.1386) | Error 0.2944(0.3019) Steps 616(613.69) | Grad Norm 5.9123(4.7390) | Total Time 14.00(14.00)\n",
      "Iter 3170 | Time 14.3160(14.9855) | Bit/dim 3.7280(3.7174) | Xent 0.8035(0.8390) | Loss 4.1297(4.1369) | Error 0.2800(0.2991) Steps 610(613.51) | Grad Norm 7.1098(4.9272) | Total Time 14.00(14.00)\n",
      "Iter 3180 | Time 14.8679(14.9377) | Bit/dim 3.6874(3.7151) | Xent 0.8361(0.8425) | Loss 4.1055(4.1363) | Error 0.2944(0.2998) Steps 616(613.72) | Grad Norm 4.4357(5.0720) | Total Time 14.00(14.00)\n",
      "Iter 3190 | Time 15.0289(14.9679) | Bit/dim 3.6897(3.7146) | Xent 0.8102(0.8480) | Loss 4.0948(4.1386) | Error 0.3111(0.3044) Steps 616(614.32) | Grad Norm 5.2378(5.0734) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 81.6988, Epoch Time 923.7069(894.3281), Bit/dim 3.7169(best: 3.7152), Xent 0.8618, Loss 4.1478, Error 0.3059(best: 0.2987)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 14.9855(14.9419) | Bit/dim 3.7293(3.7158) | Xent 0.8424(0.8450) | Loss 4.1505(4.1383) | Error 0.3000(0.3029) Steps 610(613.85) | Grad Norm 6.9818(5.0952) | Total Time 14.00(14.00)\n",
      "Iter 3210 | Time 15.1837(14.9372) | Bit/dim 3.7007(3.7121) | Xent 0.8401(0.8413) | Loss 4.1208(4.1328) | Error 0.3233(0.3029) Steps 628(613.23) | Grad Norm 4.6776(5.1199) | Total Time 14.00(14.00)\n",
      "Iter 3220 | Time 14.4967(14.9421) | Bit/dim 3.6988(3.7119) | Xent 0.8268(0.8405) | Loss 4.1122(4.1321) | Error 0.2878(0.3020) Steps 616(614.20) | Grad Norm 3.1585(5.1009) | Total Time 14.00(14.00)\n",
      "Iter 3230 | Time 15.0984(14.9668) | Bit/dim 3.7108(3.7121) | Xent 0.8581(0.8445) | Loss 4.1398(4.1343) | Error 0.2967(0.3027) Steps 610(614.40) | Grad Norm 4.9967(5.3423) | Total Time 14.00(14.00)\n",
      "Iter 3240 | Time 14.9990(14.9608) | Bit/dim 3.7080(3.7162) | Xent 0.8790(0.8528) | Loss 4.1475(4.1426) | Error 0.3078(0.3048) Steps 616(614.65) | Grad Norm 5.7678(5.4682) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 80.8358, Epoch Time 921.0519(895.1298), Bit/dim 3.7095(best: 3.7152), Xent 0.8537, Loss 4.1364, Error 0.3024(best: 0.2987)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 15.6212(14.9920) | Bit/dim 3.7301(3.7143) | Xent 0.7880(0.8480) | Loss 4.1242(4.1383) | Error 0.2833(0.3039) Steps 616(614.38) | Grad Norm 3.2654(5.0355) | Total Time 14.00(14.00)\n",
      "Iter 3260 | Time 14.9152(15.0005) | Bit/dim 3.7278(3.7133) | Xent 0.8874(0.8358) | Loss 4.1715(4.1312) | Error 0.3233(0.3000) Steps 616(614.80) | Grad Norm 4.9973(4.9571) | Total Time 14.00(14.00)\n",
      "Iter 3270 | Time 14.8525(14.9733) | Bit/dim 3.7189(3.7116) | Xent 0.8829(0.8365) | Loss 4.1603(4.1298) | Error 0.3200(0.3003) Steps 610(614.00) | Grad Norm 4.9871(4.8629) | Total Time 14.00(14.00)\n",
      "Iter 3280 | Time 15.2389(15.0006) | Bit/dim 3.7165(3.7096) | Xent 0.9782(0.8394) | Loss 4.2056(4.1293) | Error 0.3411(0.3001) Steps 610(614.03) | Grad Norm 10.1936(5.2389) | Total Time 14.00(14.00)\n",
      "Iter 3290 | Time 14.8817(15.0103) | Bit/dim 3.7194(3.7116) | Xent 0.7950(0.8466) | Loss 4.1169(4.1349) | Error 0.2856(0.3016) Steps 616(614.38) | Grad Norm 6.1190(5.7034) | Total Time 14.00(14.00)\n",
      "Iter 3300 | Time 14.9981(14.9939) | Bit/dim 3.7069(3.7119) | Xent 0.7898(0.8430) | Loss 4.1018(4.1334) | Error 0.2822(0.3010) Steps 622(614.70) | Grad Norm 4.3199(5.3634) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 80.6249, Epoch Time 923.8158(895.9904), Bit/dim 3.7037(best: 3.7095), Xent 0.8422, Loss 4.1248, Error 0.2960(best: 0.2987)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 15.4143(14.9928) | Bit/dim 3.7253(3.7107) | Xent 0.8553(0.8411) | Loss 4.1530(4.1312) | Error 0.3122(0.3019) Steps 622(614.73) | Grad Norm 6.2058(5.2061) | Total Time 14.00(14.00)\n",
      "Iter 3320 | Time 14.9407(15.0009) | Bit/dim 3.7120(3.7104) | Xent 0.8552(0.8368) | Loss 4.1396(4.1288) | Error 0.3044(0.3003) Steps 622(614.89) | Grad Norm 6.9375(5.0797) | Total Time 14.00(14.00)\n",
      "Iter 3330 | Time 15.4235(15.0008) | Bit/dim 3.7465(3.7096) | Xent 0.7951(0.8300) | Loss 4.1440(4.1246) | Error 0.2856(0.2973) Steps 610(614.37) | Grad Norm 5.5062(5.0293) | Total Time 14.00(14.00)\n",
      "Iter 3340 | Time 14.9771(15.0430) | Bit/dim 3.6965(3.7076) | Xent 0.8312(0.8245) | Loss 4.1121(4.1199) | Error 0.2911(0.2952) Steps 616(614.94) | Grad Norm 4.9106(4.9994) | Total Time 14.00(14.00)\n",
      "Iter 3350 | Time 15.2564(15.0819) | Bit/dim 3.7159(3.7071) | Xent 0.8382(0.8182) | Loss 4.1350(4.1162) | Error 0.2856(0.2935) Steps 610(614.27) | Grad Norm 5.1063(4.8835) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 80.6347, Epoch Time 926.6286(896.9095), Bit/dim 3.7051(best: 3.7037), Xent 0.8432, Loss 4.1268, Error 0.2997(best: 0.2960)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 15.0601(15.0633) | Bit/dim 3.6739(3.7048) | Xent 0.7829(0.8226) | Loss 4.0653(4.1161) | Error 0.2856(0.2950) Steps 616(613.84) | Grad Norm 3.5131(4.7360) | Total Time 14.00(14.00)\n",
      "Iter 3370 | Time 15.2433(15.0659) | Bit/dim 3.6854(3.7013) | Xent 0.7312(0.8168) | Loss 4.0510(4.1098) | Error 0.2644(0.2919) Steps 622(614.54) | Grad Norm 2.6426(4.8223) | Total Time 14.00(14.00)\n",
      "Iter 3380 | Time 14.9535(15.0844) | Bit/dim 3.6875(3.7041) | Xent 0.8036(0.8212) | Loss 4.0893(4.1147) | Error 0.2889(0.2933) Steps 610(614.44) | Grad Norm 5.4943(4.9766) | Total Time 14.00(14.00)\n",
      "Iter 3390 | Time 15.1166(15.0725) | Bit/dim 3.6844(3.7046) | Xent 0.8554(0.8211) | Loss 4.1121(4.1152) | Error 0.3100(0.2935) Steps 622(614.26) | Grad Norm 7.3817(5.0093) | Total Time 14.00(14.00)\n",
      "Iter 3400 | Time 15.2233(15.1544) | Bit/dim 3.6956(3.7052) | Xent 0.8294(0.8178) | Loss 4.1103(4.1141) | Error 0.2856(0.2923) Steps 616(614.40) | Grad Norm 2.6980(4.6459) | Total Time 14.00(14.00)\n",
      "Iter 3410 | Time 14.6470(15.1490) | Bit/dim 3.7000(3.7046) | Xent 0.8757(0.8175) | Loss 4.1378(4.1134) | Error 0.3156(0.2921) Steps 610(614.50) | Grad Norm 3.7097(4.5219) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 81.1732, Epoch Time 932.0724(897.9644), Bit/dim 3.7009(best: 3.7037), Xent 0.7981, Loss 4.0999, Error 0.2834(best: 0.2960)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 15.2506(15.1479) | Bit/dim 3.7012(3.7049) | Xent 0.7931(0.8123) | Loss 4.0977(4.1111) | Error 0.2800(0.2904) Steps 610(614.59) | Grad Norm 4.3524(4.4696) | Total Time 14.00(14.00)\n",
      "Iter 3430 | Time 16.2259(15.2114) | Bit/dim 3.7035(3.7023) | Xent 0.8758(0.8127) | Loss 4.1414(4.1087) | Error 0.3033(0.2896) Steps 622(615.15) | Grad Norm 3.9050(4.4946) | Total Time 14.00(14.00)\n",
      "Iter 3440 | Time 15.0138(15.2181) | Bit/dim 3.7193(3.7025) | Xent 0.7828(0.8114) | Loss 4.1107(4.1082) | Error 0.2678(0.2884) Steps 616(614.89) | Grad Norm 3.5582(4.4381) | Total Time 14.00(14.00)\n",
      "Iter 3450 | Time 15.0086(15.2274) | Bit/dim 3.7104(3.7016) | Xent 0.8226(0.8102) | Loss 4.1217(4.1067) | Error 0.3067(0.2891) Steps 622(614.89) | Grad Norm 5.5452(4.6916) | Total Time 14.00(14.00)\n",
      "Iter 3460 | Time 14.9373(15.2599) | Bit/dim 3.7006(3.7003) | Xent 0.8306(0.8061) | Loss 4.1159(4.1033) | Error 0.3044(0.2883) Steps 610(615.51) | Grad Norm 9.3106(4.9851) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 80.5077, Epoch Time 938.1279(899.1693), Bit/dim 3.7012(best: 3.7009), Xent 0.8375, Loss 4.1199, Error 0.2954(best: 0.2834)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 14.5324(15.2269) | Bit/dim 3.7140(3.7007) | Xent 0.7843(0.8088) | Loss 4.1062(4.1051) | Error 0.2767(0.2893) Steps 610(616.39) | Grad Norm 3.6651(5.0621) | Total Time 14.00(14.00)\n",
      "Iter 3480 | Time 14.8802(15.2322) | Bit/dim 3.7231(3.7023) | Xent 0.8356(0.8096) | Loss 4.1409(4.1071) | Error 0.3044(0.2902) Steps 622(617.45) | Grad Norm 4.1477(5.0185) | Total Time 14.00(14.00)\n",
      "Iter 3490 | Time 15.8733(15.2484) | Bit/dim 3.7205(3.7055) | Xent 0.7150(0.8031) | Loss 4.0780(4.1070) | Error 0.2578(0.2873) Steps 622(617.22) | Grad Norm 4.3007(5.0012) | Total Time 14.00(14.00)\n",
      "Iter 3500 | Time 15.2681(15.2377) | Bit/dim 3.6726(3.7006) | Xent 0.7974(0.7958) | Loss 4.0713(4.0985) | Error 0.2800(0.2849) Steps 622(618.05) | Grad Norm 3.2685(4.6604) | Total Time 14.00(14.00)\n",
      "Iter 3510 | Time 15.1866(15.2364) | Bit/dim 3.7291(3.6985) | Xent 0.8035(0.7959) | Loss 4.1308(4.0964) | Error 0.2844(0.2839) Steps 616(619.03) | Grad Norm 4.7471(4.5618) | Total Time 14.00(14.00)\n",
      "Iter 3520 | Time 15.2766(15.2735) | Bit/dim 3.7400(3.6987) | Xent 0.7582(0.7940) | Loss 4.1191(4.0957) | Error 0.2589(0.2831) Steps 622(619.78) | Grad Norm 3.4959(4.3274) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 80.3596, Epoch Time 937.6233(900.3229), Bit/dim 3.7018(best: 3.7009), Xent 0.8011, Loss 4.1024, Error 0.2790(best: 0.2834)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 15.6115(15.3013) | Bit/dim 3.6975(3.6978) | Xent 0.8100(0.7931) | Loss 4.1025(4.0943) | Error 0.2811(0.2814) Steps 616(619.66) | Grad Norm 3.8410(4.5229) | Total Time 14.00(14.00)\n",
      "Iter 3540 | Time 15.1785(15.2940) | Bit/dim 3.7086(3.6967) | Xent 0.8083(0.7980) | Loss 4.1127(4.0957) | Error 0.2756(0.2836) Steps 622(620.26) | Grad Norm 4.5525(4.4606) | Total Time 14.00(14.00)\n",
      "Iter 3550 | Time 15.4070(15.2772) | Bit/dim 3.6858(3.6984) | Xent 0.8551(0.7980) | Loss 4.1134(4.0975) | Error 0.2989(0.2836) Steps 622(620.21) | Grad Norm 6.9319(4.6858) | Total Time 14.00(14.00)\n",
      "Iter 3560 | Time 15.3199(15.2517) | Bit/dim 3.7211(3.7010) | Xent 0.7807(0.7930) | Loss 4.1114(4.0975) | Error 0.2678(0.2819) Steps 616(619.86) | Grad Norm 3.7124(4.8752) | Total Time 14.00(14.00)\n",
      "Iter 3570 | Time 15.0665(15.2894) | Bit/dim 3.6781(3.6962) | Xent 0.8197(0.7967) | Loss 4.0879(4.0945) | Error 0.3100(0.2843) Steps 616(619.80) | Grad Norm 4.5072(4.8575) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 80.6833, Epoch Time 940.1466(901.5176), Bit/dim 3.6993(best: 3.7009), Xent 0.8133, Loss 4.1059, Error 0.2889(best: 0.2790)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 15.2956(15.3055) | Bit/dim 3.6958(3.6980) | Xent 0.7625(0.7957) | Loss 4.0770(4.0958) | Error 0.2667(0.2827) Steps 622(620.53) | Grad Norm 2.6417(4.6834) | Total Time 14.00(14.00)\n",
      "Iter 3590 | Time 16.0802(15.3304) | Bit/dim 3.6638(3.6931) | Xent 0.8042(0.7902) | Loss 4.0659(4.0882) | Error 0.3078(0.2814) Steps 628(621.23) | Grad Norm 6.2651(4.6340) | Total Time 14.00(14.00)\n",
      "Iter 3600 | Time 15.3452(15.3560) | Bit/dim 3.6968(3.6924) | Xent 0.7422(0.7900) | Loss 4.0679(4.0874) | Error 0.2567(0.2811) Steps 616(620.74) | Grad Norm 3.3879(4.6043) | Total Time 14.00(14.00)\n",
      "Iter 3610 | Time 15.3366(15.3586) | Bit/dim 3.7100(3.6941) | Xent 0.7350(0.7880) | Loss 4.0775(4.0881) | Error 0.2589(0.2805) Steps 616(620.49) | Grad Norm 4.6749(4.5619) | Total Time 14.00(14.00)\n",
      "Iter 3620 | Time 15.4143(15.3396) | Bit/dim 3.6891(3.6935) | Xent 0.7819(0.7857) | Loss 4.0801(4.0863) | Error 0.2800(0.2799) Steps 628(620.59) | Grad Norm 4.6822(4.5398) | Total Time 14.00(14.00)\n",
      "Iter 3630 | Time 15.3023(15.3302) | Bit/dim 3.7061(3.6939) | Xent 0.8117(0.7859) | Loss 4.1120(4.0868) | Error 0.2833(0.2795) Steps 628(621.29) | Grad Norm 8.1247(4.6096) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 80.6525, Epoch Time 942.8052(902.7563), Bit/dim 3.6918(best: 3.6993), Xent 0.8060, Loss 4.0948, Error 0.2835(best: 0.2790)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 15.2187(15.3015) | Bit/dim 3.7154(3.6949) | Xent 0.7325(0.7826) | Loss 4.0816(4.0862) | Error 0.2656(0.2786) Steps 628(621.96) | Grad Norm 5.4240(4.5650) | Total Time 14.00(14.00)\n",
      "Iter 3650 | Time 15.4093(15.2968) | Bit/dim 3.6874(3.6930) | Xent 0.7546(0.7756) | Loss 4.0647(4.0808) | Error 0.2556(0.2773) Steps 622(621.97) | Grad Norm 6.0147(4.4423) | Total Time 14.00(14.00)\n",
      "Iter 3660 | Time 15.2676(15.2539) | Bit/dim 3.6978(3.6945) | Xent 0.7867(0.7778) | Loss 4.0912(4.0834) | Error 0.2778(0.2785) Steps 628(621.99) | Grad Norm 7.9285(4.7782) | Total Time 14.00(14.00)\n",
      "Iter 3670 | Time 15.1130(15.2235) | Bit/dim 3.6708(3.6909) | Xent 0.8018(0.7789) | Loss 4.0716(4.0804) | Error 0.3022(0.2789) Steps 616(620.90) | Grad Norm 3.5623(4.6392) | Total Time 14.00(14.00)\n",
      "Iter 3680 | Time 15.1248(15.2359) | Bit/dim 3.6652(3.6886) | Xent 0.8351(0.7786) | Loss 4.0828(4.0779) | Error 0.3022(0.2782) Steps 622(621.69) | Grad Norm 5.7652(4.7670) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 80.9101, Epoch Time 936.2052(903.7597), Bit/dim 3.6889(best: 3.6918), Xent 0.7727, Loss 4.0753, Error 0.2717(best: 0.2790)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 15.6670(15.2882) | Bit/dim 3.6795(3.6889) | Xent 0.7484(0.7765) | Loss 4.0537(4.0771) | Error 0.2800(0.2774) Steps 622(621.64) | Grad Norm 4.3135(4.7788) | Total Time 14.00(14.00)\n",
      "Iter 3700 | Time 15.7710(15.3141) | Bit/dim 3.6580(3.6877) | Xent 0.7168(0.7756) | Loss 4.0164(4.0755) | Error 0.2600(0.2762) Steps 616(622.02) | Grad Norm 3.3951(4.7667) | Total Time 14.00(14.00)\n",
      "Iter 3710 | Time 15.2430(15.3276) | Bit/dim 3.6662(3.6865) | Xent 0.7766(0.7752) | Loss 4.0544(4.0741) | Error 0.2889(0.2767) Steps 622(621.73) | Grad Norm 5.1350(4.6502) | Total Time 14.00(14.00)\n",
      "Iter 3720 | Time 15.4831(15.3187) | Bit/dim 3.7258(3.6896) | Xent 0.7901(0.7731) | Loss 4.1208(4.0762) | Error 0.2767(0.2739) Steps 622(622.17) | Grad Norm 3.9532(4.6097) | Total Time 14.00(14.00)\n",
      "Iter 3730 | Time 15.6675(15.3550) | Bit/dim 3.6883(3.6897) | Xent 0.8412(0.7833) | Loss 4.1089(4.0813) | Error 0.2933(0.2776) Steps 622(622.15) | Grad Norm 4.0082(5.0787) | Total Time 14.00(14.00)\n",
      "Iter 3740 | Time 15.5047(15.3676) | Bit/dim 3.6898(3.6896) | Xent 0.7778(0.7807) | Loss 4.0787(4.0800) | Error 0.2811(0.2773) Steps 622(623.04) | Grad Norm 3.3352(4.8520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 80.2777, Epoch Time 944.0782(904.9693), Bit/dim 3.6884(best: 3.6889), Xent 0.7814, Loss 4.0791, Error 0.2773(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 15.6998(15.3509) | Bit/dim 3.6695(3.6881) | Xent 0.7705(0.7720) | Loss 4.0547(4.0741) | Error 0.2822(0.2757) Steps 622(623.06) | Grad Norm 5.4901(4.7849) | Total Time 14.00(14.00)\n",
      "Iter 3760 | Time 15.0043(15.3214) | Bit/dim 3.6957(3.6899) | Xent 0.8390(0.7750) | Loss 4.1153(4.0774) | Error 0.2900(0.2759) Steps 622(623.06) | Grad Norm 9.1923(5.1069) | Total Time 14.00(14.00)\n",
      "Iter 3770 | Time 15.3123(15.3275) | Bit/dim 3.6699(3.6927) | Xent 0.8460(0.7711) | Loss 4.0928(4.0782) | Error 0.2956(0.2753) Steps 616(623.51) | Grad Norm 2.9099(5.1248) | Total Time 14.00(14.00)\n",
      "Iter 3780 | Time 15.3517(15.3296) | Bit/dim 3.6890(3.6927) | Xent 0.7569(0.7680) | Loss 4.0675(4.0767) | Error 0.3011(0.2761) Steps 622(623.91) | Grad Norm 3.7967(4.8434) | Total Time 14.00(14.00)\n",
      "Iter 3790 | Time 15.1950(15.3154) | Bit/dim 3.6530(3.6893) | Xent 0.8167(0.7659) | Loss 4.0613(4.0722) | Error 0.2911(0.2748) Steps 616(623.06) | Grad Norm 7.6262(4.9134) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 81.6269, Epoch Time 940.1294(906.0241), Bit/dim 3.6834(best: 3.6884), Xent 0.7908, Loss 4.0788, Error 0.2772(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 14.9696(15.2902) | Bit/dim 3.6884(3.6882) | Xent 0.7316(0.7632) | Loss 4.0542(4.0698) | Error 0.2567(0.2731) Steps 622(622.91) | Grad Norm 4.2607(4.7115) | Total Time 14.00(14.00)\n",
      "Iter 3810 | Time 15.3699(15.2736) | Bit/dim 3.6639(3.6868) | Xent 0.8061(0.7666) | Loss 4.0670(4.0701) | Error 0.2878(0.2728) Steps 628(622.89) | Grad Norm 7.2423(4.8244) | Total Time 14.00(14.00)\n",
      "Iter 3820 | Time 15.6808(15.3376) | Bit/dim 3.6781(3.6863) | Xent 0.8076(0.7613) | Loss 4.0818(4.0670) | Error 0.2756(0.2695) Steps 622(623.61) | Grad Norm 4.5953(4.8335) | Total Time 14.00(14.00)\n",
      "Iter 3830 | Time 15.1531(15.3595) | Bit/dim 3.6639(3.6851) | Xent 0.7078(0.7563) | Loss 4.0178(4.0632) | Error 0.2589(0.2691) Steps 610(623.11) | Grad Norm 2.0464(4.6830) | Total Time 14.00(14.00)\n",
      "Iter 3840 | Time 16.0077(15.3660) | Bit/dim 3.7174(3.6862) | Xent 0.7644(0.7596) | Loss 4.0996(4.0660) | Error 0.2900(0.2707) Steps 622(623.78) | Grad Norm 4.1516(4.7196) | Total Time 14.00(14.00)\n",
      "Iter 3850 | Time 15.5148(15.3885) | Bit/dim 3.6848(3.6833) | Xent 0.8015(0.7579) | Loss 4.0855(4.0622) | Error 0.2933(0.2703) Steps 622(623.41) | Grad Norm 3.0710(4.5364) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 79.6302, Epoch Time 943.6199(907.1520), Bit/dim 3.6886(best: 3.6834), Xent 0.7901, Loss 4.0837, Error 0.2791(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 15.2638(15.3419) | Bit/dim 3.7041(3.6816) | Xent 0.6831(0.7474) | Loss 4.0456(4.0553) | Error 0.2378(0.2644) Steps 628(623.75) | Grad Norm 4.6126(4.2431) | Total Time 14.00(14.00)\n",
      "Iter 3870 | Time 15.5398(15.3395) | Bit/dim 3.7176(3.6823) | Xent 0.7290(0.7382) | Loss 4.0821(4.0514) | Error 0.2578(0.2631) Steps 616(623.45) | Grad Norm 5.6936(4.3769) | Total Time 14.00(14.00)\n",
      "Iter 3880 | Time 16.0612(15.3681) | Bit/dim 3.6717(3.6840) | Xent 0.6982(0.7413) | Loss 4.0208(4.0547) | Error 0.2500(0.2638) Steps 628(624.82) | Grad Norm 2.8832(4.4676) | Total Time 14.00(14.00)\n",
      "Iter 3890 | Time 14.7235(15.3654) | Bit/dim 3.6709(3.6823) | Xent 0.7994(0.7474) | Loss 4.0706(4.0560) | Error 0.2867(0.2658) Steps 622(625.37) | Grad Norm 8.5350(4.5941) | Total Time 14.00(14.00)\n",
      "Iter 3900 | Time 15.7755(15.3211) | Bit/dim 3.6854(3.6830) | Xent 0.8100(0.7471) | Loss 4.0904(4.0566) | Error 0.2833(0.2671) Steps 628(624.36) | Grad Norm 4.8282(4.4890) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 82.3483, Epoch Time 942.5029(908.2125), Bit/dim 3.6795(best: 3.6834), Xent 0.7879, Loss 4.0734, Error 0.2789(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 15.6764(15.3093) | Bit/dim 3.6652(3.6821) | Xent 0.6969(0.7464) | Loss 4.0137(4.0553) | Error 0.2356(0.2672) Steps 622(624.19) | Grad Norm 3.7525(4.5269) | Total Time 14.00(14.00)\n",
      "Iter 3920 | Time 15.3562(15.3511) | Bit/dim 3.6640(3.6831) | Xent 0.8106(0.7474) | Loss 4.0693(4.0568) | Error 0.2933(0.2670) Steps 628(624.30) | Grad Norm 3.6194(4.4906) | Total Time 14.00(14.00)\n",
      "Iter 3930 | Time 15.2286(15.3662) | Bit/dim 3.6839(3.6832) | Xent 0.7535(0.7528) | Loss 4.0607(4.0596) | Error 0.2644(0.2677) Steps 616(623.82) | Grad Norm 4.7162(4.5216) | Total Time 14.00(14.00)\n",
      "Iter 3940 | Time 15.8044(15.4184) | Bit/dim 3.6686(3.6824) | Xent 0.7185(0.7479) | Loss 4.0278(4.0563) | Error 0.2533(0.2662) Steps 622(623.51) | Grad Norm 4.2527(4.4754) | Total Time 14.00(14.00)\n",
      "Iter 3950 | Time 15.5833(15.4716) | Bit/dim 3.7070(3.6823) | Xent 0.7076(0.7475) | Loss 4.0608(4.0560) | Error 0.2544(0.2654) Steps 610(623.08) | Grad Norm 4.2846(4.7215) | Total Time 14.00(14.00)\n",
      "Iter 3960 | Time 15.3741(15.4169) | Bit/dim 3.6873(3.6801) | Xent 0.7917(0.7505) | Loss 4.0831(4.0554) | Error 0.2800(0.2675) Steps 622(622.67) | Grad Norm 4.7809(4.8663) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 80.5767, Epoch Time 948.0966(909.4090), Bit/dim 3.6823(best: 3.6795), Xent 0.7881, Loss 4.0763, Error 0.2748(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 15.0286(15.3833) | Bit/dim 3.7175(3.6818) | Xent 0.8016(0.7457) | Loss 4.1183(4.0547) | Error 0.2867(0.2652) Steps 622(622.83) | Grad Norm 7.1513(5.0167) | Total Time 14.00(14.00)\n",
      "Iter 3980 | Time 15.0476(15.3569) | Bit/dim 3.6731(3.6839) | Xent 0.6949(0.7431) | Loss 4.0206(4.0555) | Error 0.2544(0.2650) Steps 640(624.29) | Grad Norm 4.8933(4.8983) | Total Time 14.00(14.00)\n",
      "Iter 3990 | Time 15.7628(15.3525) | Bit/dim 3.6725(3.6818) | Xent 0.8021(0.7431) | Loss 4.0735(4.0534) | Error 0.2700(0.2655) Steps 628(623.55) | Grad Norm 3.3893(4.5273) | Total Time 14.00(14.00)\n",
      "Iter 4000 | Time 15.2071(15.3168) | Bit/dim 3.6656(3.6812) | Xent 0.6925(0.7359) | Loss 4.0118(4.0492) | Error 0.2567(0.2633) Steps 622(623.65) | Grad Norm 3.3385(4.4681) | Total Time 14.00(14.00)\n",
      "Iter 4010 | Time 15.9259(15.3282) | Bit/dim 3.6788(3.6802) | Xent 0.7087(0.7354) | Loss 4.0331(4.0479) | Error 0.2500(0.2626) Steps 628(622.99) | Grad Norm 5.4756(4.6570) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 81.4041, Epoch Time 940.8605(910.3526), Bit/dim 3.6803(best: 3.6795), Xent 0.8061, Loss 4.0834, Error 0.2825(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 15.0740(15.3178) | Bit/dim 3.6741(3.6783) | Xent 0.7313(0.7471) | Loss 4.0398(4.0518) | Error 0.2589(0.2663) Steps 616(622.85) | Grad Norm 3.6158(4.8336) | Total Time 14.00(14.00)\n",
      "Iter 4030 | Time 15.9549(15.2885) | Bit/dim 3.6713(3.6808) | Xent 0.7392(0.7460) | Loss 4.0409(4.0538) | Error 0.2611(0.2650) Steps 634(624.25) | Grad Norm 6.6095(5.2470) | Total Time 14.00(14.00)\n",
      "Iter 4040 | Time 15.2466(15.2607) | Bit/dim 3.6752(3.6812) | Xent 0.7697(0.7385) | Loss 4.0601(4.0505) | Error 0.2700(0.2619) Steps 634(625.08) | Grad Norm 5.8302(5.1923) | Total Time 14.00(14.00)\n",
      "Iter 4050 | Time 15.2258(15.2846) | Bit/dim 3.6691(3.6789) | Xent 0.7537(0.7383) | Loss 4.0459(4.0480) | Error 0.2556(0.2610) Steps 622(625.16) | Grad Norm 5.9717(5.0672) | Total Time 14.00(14.00)\n",
      "Iter 4060 | Time 15.3188(15.3185) | Bit/dim 3.6911(3.6772) | Xent 0.7121(0.7324) | Loss 4.0472(4.0434) | Error 0.2467(0.2591) Steps 628(625.83) | Grad Norm 3.1370(4.6467) | Total Time 14.00(14.00)\n",
      "Iter 4070 | Time 15.0841(15.3181) | Bit/dim 3.6449(3.6732) | Xent 0.7073(0.7374) | Loss 3.9985(4.0419) | Error 0.2333(0.2608) Steps 628(626.90) | Grad Norm 3.1724(4.3499) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 81.3927, Epoch Time 939.2754(911.2202), Bit/dim 3.6739(best: 3.6795), Xent 0.7802, Loss 4.0639, Error 0.2704(best: 0.2717)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 15.3340(15.2926) | Bit/dim 3.6422(3.6714) | Xent 0.7663(0.7337) | Loss 4.0254(4.0382) | Error 0.2756(0.2601) Steps 634(626.37) | Grad Norm 3.4329(4.6000) | Total Time 14.00(14.00)\n",
      "Iter 4090 | Time 15.2787(15.3046) | Bit/dim 3.6733(3.6728) | Xent 0.7034(0.7259) | Loss 4.0250(4.0357) | Error 0.2589(0.2585) Steps 628(626.63) | Grad Norm 4.2199(4.3522) | Total Time 14.00(14.00)\n",
      "Iter 4100 | Time 15.2683(15.3188) | Bit/dim 3.6801(3.6735) | Xent 0.7011(0.7289) | Loss 4.0307(4.0380) | Error 0.2589(0.2599) Steps 622(626.02) | Grad Norm 2.6599(4.4594) | Total Time 14.00(14.00)\n",
      "Iter 4110 | Time 15.2292(15.3087) | Bit/dim 3.6817(3.6769) | Xent 0.7497(0.7300) | Loss 4.0565(4.0420) | Error 0.2622(0.2600) Steps 628(626.20) | Grad Norm 3.5917(4.6204) | Total Time 14.00(14.00)\n",
      "Iter 4120 | Time 15.2891(15.3100) | Bit/dim 3.6804(3.6761) | Xent 0.6510(0.7233) | Loss 4.0060(4.0378) | Error 0.2167(0.2565) Steps 634(627.43) | Grad Norm 4.2715(4.6490) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 81.6377, Epoch Time 943.0594(912.1754), Bit/dim 3.6704(best: 3.6739), Xent 0.7821, Loss 4.0615, Error 0.2693(best: 0.2704)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 15.3068(15.3613) | Bit/dim 3.6696(3.6743) | Xent 0.7275(0.7270) | Loss 4.0333(4.0377) | Error 0.2478(0.2586) Steps 628(627.38) | Grad Norm 7.1435(4.7410) | Total Time 14.00(14.00)\n",
      "Iter 4140 | Time 15.5334(15.3289) | Bit/dim 3.7017(3.6745) | Xent 0.7573(0.7340) | Loss 4.0804(4.0414) | Error 0.2689(0.2615) Steps 616(626.78) | Grad Norm 6.2698(4.8967) | Total Time 14.00(14.00)\n",
      "Iter 4150 | Time 15.0977(15.3457) | Bit/dim 3.6614(3.6752) | Xent 0.7078(0.7312) | Loss 4.0153(4.0407) | Error 0.2500(0.2610) Steps 622(626.51) | Grad Norm 4.5397(4.7659) | Total Time 14.00(14.00)\n",
      "Iter 4160 | Time 15.7484(15.3985) | Bit/dim 3.6484(3.6734) | Xent 0.7223(0.7333) | Loss 4.0096(4.0401) | Error 0.2500(0.2603) Steps 634(626.67) | Grad Norm 3.2339(4.5135) | Total Time 14.00(14.00)\n",
      "Iter 4170 | Time 15.0868(15.3566) | Bit/dim 3.6951(3.6734) | Xent 0.7528(0.7258) | Loss 4.0715(4.0363) | Error 0.2622(0.2583) Steps 628(626.40) | Grad Norm 5.3613(4.2122) | Total Time 14.00(14.00)\n",
      "Iter 4180 | Time 15.3233(15.3154) | Bit/dim 3.6420(3.6734) | Xent 0.7229(0.7199) | Loss 4.0034(4.0333) | Error 0.2544(0.2559) Steps 622(625.36) | Grad Norm 4.6748(4.0700) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 80.8411, Epoch Time 941.4185(913.0527), Bit/dim 3.6708(best: 3.6704), Xent 0.7538, Loss 4.0477, Error 0.2625(best: 0.2693)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 15.6469(15.3043) | Bit/dim 3.6846(3.6744) | Xent 0.6473(0.7137) | Loss 4.0083(4.0313) | Error 0.2389(0.2530) Steps 628(623.58) | Grad Norm 5.6870(4.3226) | Total Time 14.00(14.00)\n",
      "Iter 4200 | Time 15.1227(15.3354) | Bit/dim 3.6755(3.6738) | Xent 0.7250(0.7131) | Loss 4.0379(4.0303) | Error 0.2544(0.2526) Steps 628(624.59) | Grad Norm 6.4452(4.6394) | Total Time 14.00(14.00)\n",
      "Iter 4210 | Time 15.3622(15.3616) | Bit/dim 3.7008(3.6757) | Xent 0.7824(0.7236) | Loss 4.0920(4.0374) | Error 0.2900(0.2561) Steps 622(625.13) | Grad Norm 6.9454(5.0643) | Total Time 14.00(14.00)\n",
      "Iter 4220 | Time 15.0667(15.2913) | Bit/dim 3.7095(3.6787) | Xent 0.7683(0.7283) | Loss 4.0937(4.0429) | Error 0.2678(0.2585) Steps 634(624.34) | Grad Norm 6.7358(5.0789) | Total Time 14.00(14.00)\n",
      "Iter 4230 | Time 15.3015(15.3187) | Bit/dim 3.6754(3.6754) | Xent 0.7054(0.7307) | Loss 4.0280(4.0408) | Error 0.2567(0.2596) Steps 634(625.56) | Grad Norm 3.2190(4.7885) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 82.3677, Epoch Time 942.7721(913.9443), Bit/dim 3.6776(best: 3.6704), Xent 0.7632, Loss 4.0592, Error 0.2683(best: 0.2625)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 15.2442(15.3102) | Bit/dim 3.6651(3.6748) | Xent 0.6436(0.7187) | Loss 3.9869(4.0342) | Error 0.2278(0.2557) Steps 622(625.68) | Grad Norm 2.7216(4.5322) | Total Time 14.00(14.00)\n",
      "Iter 4250 | Time 15.0944(15.3136) | Bit/dim 3.6665(3.6733) | Xent 0.7419(0.7169) | Loss 4.0375(4.0318) | Error 0.2644(0.2542) Steps 616(624.70) | Grad Norm 8.4695(4.7326) | Total Time 14.00(14.00)\n",
      "Iter 4260 | Time 15.3049(15.3022) | Bit/dim 3.6587(3.6721) | Xent 0.7388(0.7179) | Loss 4.0281(4.0311) | Error 0.2789(0.2555) Steps 622(623.47) | Grad Norm 2.5684(4.5992) | Total Time 14.00(14.00)\n",
      "Iter 4270 | Time 15.4460(15.2992) | Bit/dim 3.6736(3.6730) | Xent 0.7254(0.7181) | Loss 4.0362(4.0321) | Error 0.2556(0.2566) Steps 634(624.43) | Grad Norm 7.1659(4.5284) | Total Time 14.00(14.00)\n",
      "Iter 4280 | Time 15.1028(15.3081) | Bit/dim 3.6808(3.6717) | Xent 0.7549(0.7198) | Loss 4.0583(4.0316) | Error 0.2622(0.2563) Steps 622(625.36) | Grad Norm 4.0504(4.5485) | Total Time 14.00(14.00)\n",
      "Iter 4290 | Time 15.3321(15.3207) | Bit/dim 3.6748(3.6723) | Xent 0.7238(0.7175) | Loss 4.0367(4.0311) | Error 0.2500(0.2556) Steps 628(625.90) | Grad Norm 3.0269(4.5471) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 82.3251, Epoch Time 942.6312(914.8049), Bit/dim 3.6745(best: 3.6704), Xent 0.7403, Loss 4.0446, Error 0.2587(best: 0.2625)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 14.7849(15.3099) | Bit/dim 3.6446(3.6689) | Xent 0.6498(0.7069) | Loss 3.9694(4.0223) | Error 0.2422(0.2507) Steps 616(625.74) | Grad Norm 3.5127(4.5235) | Total Time 14.00(14.00)\n",
      "Iter 4310 | Time 15.0564(15.2650) | Bit/dim 3.6377(3.6678) | Xent 0.7194(0.6986) | Loss 3.9974(4.0171) | Error 0.2622(0.2482) Steps 628(626.21) | Grad Norm 4.1442(4.4598) | Total Time 14.00(14.00)\n",
      "Iter 4320 | Time 15.1666(15.2712) | Bit/dim 3.7142(3.6684) | Xent 0.6515(0.6935) | Loss 4.0399(4.0152) | Error 0.2433(0.2468) Steps 622(625.73) | Grad Norm 3.9700(4.4788) | Total Time 14.00(14.00)\n",
      "Iter 4330 | Time 15.2902(15.2641) | Bit/dim 3.6731(3.6669) | Xent 0.7478(0.6919) | Loss 4.0470(4.0128) | Error 0.2644(0.2451) Steps 622(625.44) | Grad Norm 3.8827(4.3865) | Total Time 14.00(14.00)\n",
      "Iter 4340 | Time 15.1276(15.2953) | Bit/dim 3.7185(3.6700) | Xent 0.6947(0.6975) | Loss 4.0658(4.0187) | Error 0.2500(0.2481) Steps 628(625.90) | Grad Norm 4.1954(4.5616) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 81.6627, Epoch Time 940.6087(915.5790), Bit/dim 3.6733(best: 3.6704), Xent 0.7601, Loss 4.0533, Error 0.2649(best: 0.2587)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 15.1361(15.3424) | Bit/dim 3.6561(3.6705) | Xent 0.7361(0.6979) | Loss 4.0242(4.0195) | Error 0.2733(0.2493) Steps 628(626.44) | Grad Norm 4.8855(4.3532) | Total Time 14.00(14.00)\n",
      "Iter 4360 | Time 15.6266(15.3285) | Bit/dim 3.6822(3.6690) | Xent 0.6492(0.6963) | Loss 4.0068(4.0172) | Error 0.2256(0.2489) Steps 622(625.35) | Grad Norm 4.9037(4.5279) | Total Time 14.00(14.00)\n",
      "Iter 4370 | Time 15.6062(15.3558) | Bit/dim 3.6718(3.6692) | Xent 0.6957(0.6931) | Loss 4.0196(4.0158) | Error 0.2478(0.2478) Steps 622(624.37) | Grad Norm 4.7693(4.4384) | Total Time 14.00(14.00)\n",
      "Iter 4380 | Time 15.8027(15.3377) | Bit/dim 3.6690(3.6675) | Xent 0.6815(0.6880) | Loss 4.0098(4.0115) | Error 0.2456(0.2468) Steps 622(623.78) | Grad Norm 4.8900(4.2574) | Total Time 14.00(14.00)\n",
      "Iter 4390 | Time 15.4715(15.3778) | Bit/dim 3.6757(3.6653) | Xent 0.6624(0.6822) | Loss 4.0069(4.0064) | Error 0.2333(0.2438) Steps 634(624.04) | Grad Norm 5.9978(4.0537) | Total Time 14.00(14.00)\n",
      "Iter 4400 | Time 15.1147(15.3290) | Bit/dim 3.6883(3.6658) | Xent 0.7169(0.6864) | Loss 4.0467(4.0089) | Error 0.2567(0.2453) Steps 628(622.92) | Grad Norm 4.9678(3.9997) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 82.1888, Epoch Time 943.6508(916.4212), Bit/dim 3.6661(best: 3.6704), Xent 0.7896, Loss 4.0609, Error 0.2769(best: 0.2587)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 15.6477(15.3516) | Bit/dim 3.7017(3.6686) | Xent 0.7113(0.6891) | Loss 4.0574(4.0132) | Error 0.2500(0.2457) Steps 616(623.89) | Grad Norm 3.2576(4.2986) | Total Time 14.00(14.00)\n",
      "Iter 4420 | Time 15.1298(15.3665) | Bit/dim 3.7003(3.6683) | Xent 0.7002(0.6927) | Loss 4.0504(4.0146) | Error 0.2444(0.2473) Steps 622(623.40) | Grad Norm 5.4034(4.3118) | Total Time 14.00(14.00)\n",
      "Iter 4430 | Time 15.5161(15.3447) | Bit/dim 3.6490(3.6702) | Xent 0.7623(0.6931) | Loss 4.0302(4.0167) | Error 0.2700(0.2465) Steps 610(621.29) | Grad Norm 4.1474(4.2339) | Total Time 14.00(14.00)\n",
      "Iter 4440 | Time 15.0232(15.3198) | Bit/dim 3.6539(3.6662) | Xent 0.7123(0.6888) | Loss 4.0101(4.0106) | Error 0.2456(0.2453) Steps 628(621.10) | Grad Norm 4.4950(4.0703) | Total Time 14.00(14.00)\n",
      "Iter 4450 | Time 15.5409(15.3350) | Bit/dim 3.6350(3.6630) | Xent 0.7177(0.6823) | Loss 3.9939(4.0041) | Error 0.2556(0.2425) Steps 622(621.82) | Grad Norm 4.0532(3.9546) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 81.2187, Epoch Time 941.7893(917.1822), Bit/dim 3.6632(best: 3.6661), Xent 0.7395, Loss 4.0330, Error 0.2626(best: 0.2587)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 15.4913(15.3085) | Bit/dim 3.6694(3.6627) | Xent 0.6353(0.6710) | Loss 3.9870(3.9982) | Error 0.2267(0.2387) Steps 622(621.86) | Grad Norm 3.4766(3.9249) | Total Time 14.00(14.00)\n",
      "Iter 4470 | Time 15.1590(15.2744) | Bit/dim 3.6389(3.6605) | Xent 0.6633(0.6737) | Loss 3.9705(3.9974) | Error 0.2422(0.2403) Steps 622(621.41) | Grad Norm 4.2140(4.0061) | Total Time 14.00(14.00)\n",
      "Iter 4480 | Time 15.3757(15.2580) | Bit/dim 3.6508(3.6624) | Xent 0.6724(0.6758) | Loss 3.9870(4.0004) | Error 0.2400(0.2412) Steps 616(621.14) | Grad Norm 5.7321(4.2227) | Total Time 14.00(14.00)\n",
      "Iter 4490 | Time 15.4531(15.2287) | Bit/dim 3.6371(3.6625) | Xent 0.6917(0.6821) | Loss 3.9829(4.0035) | Error 0.2667(0.2453) Steps 628(621.89) | Grad Norm 4.5512(4.2787) | Total Time 14.00(14.00)\n",
      "Iter 4500 | Time 14.9406(15.1880) | Bit/dim 3.6688(3.6646) | Xent 0.7702(0.6825) | Loss 4.0539(4.0059) | Error 0.2833(0.2468) Steps 628(621.44) | Grad Norm 7.5572(4.5171) | Total Time 14.00(14.00)\n",
      "Iter 4510 | Time 15.0381(15.2007) | Bit/dim 3.6551(3.6642) | Xent 0.5972(0.6859) | Loss 3.9536(4.0072) | Error 0.2111(0.2474) Steps 628(621.29) | Grad Norm 4.4584(4.4927) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 81.4743, Epoch Time 934.1464(917.6911), Bit/dim 3.6646(best: 3.6632), Xent 0.8035, Loss 4.0664, Error 0.2818(best: 0.2587)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 15.1749(15.2001) | Bit/dim 3.6780(3.6638) | Xent 0.5988(0.6932) | Loss 3.9774(4.0104) | Error 0.2200(0.2477) Steps 628(622.45) | Grad Norm 6.8182(4.8645) | Total Time 14.00(14.00)\n",
      "Iter 4530 | Time 15.5239(15.2796) | Bit/dim 3.6582(3.6650) | Xent 0.6441(0.6904) | Loss 3.9802(4.0102) | Error 0.2333(0.2472) Steps 628(622.74) | Grad Norm 4.1388(4.7797) | Total Time 14.00(14.00)\n",
      "Iter 4540 | Time 15.2632(15.2631) | Bit/dim 3.6772(3.6693) | Xent 0.7407(0.6916) | Loss 4.0475(4.0151) | Error 0.2500(0.2476) Steps 616(622.24) | Grad Norm 4.8223(4.8879) | Total Time 14.00(14.00)\n",
      "Iter 4550 | Time 15.0329(15.2704) | Bit/dim 3.6590(3.6681) | Xent 0.6419(0.6857) | Loss 3.9800(4.0110) | Error 0.2144(0.2444) Steps 616(621.06) | Grad Norm 4.9876(4.8755) | Total Time 14.00(14.00)\n",
      "Iter 4560 | Time 15.1941(15.2353) | Bit/dim 3.6668(3.6662) | Xent 0.6656(0.6794) | Loss 3.9996(4.0059) | Error 0.2533(0.2418) Steps 622(621.92) | Grad Norm 4.6271(4.6375) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 80.1099, Epoch Time 937.9483(918.2989), Bit/dim 3.6769(best: 3.6632), Xent 0.7576, Loss 4.0557, Error 0.2667(best: 0.2587)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 15.1874(15.2577) | Bit/dim 3.6724(3.6651) | Xent 0.6356(0.6781) | Loss 3.9902(4.0041) | Error 0.2444(0.2414) Steps 628(621.54) | Grad Norm 5.3702(4.6469) | Total Time 14.00(14.00)\n",
      "Iter 4580 | Time 15.1576(15.2297) | Bit/dim 3.6680(3.6631) | Xent 0.6467(0.6716) | Loss 3.9914(3.9989) | Error 0.2333(0.2393) Steps 628(621.86) | Grad Norm 5.8376(4.7350) | Total Time 14.00(14.00)\n",
      "Iter 4590 | Time 15.2521(15.2237) | Bit/dim 3.6666(3.6638) | Xent 0.6596(0.6693) | Loss 3.9964(3.9984) | Error 0.2278(0.2379) Steps 622(622.95) | Grad Norm 2.7543(4.5803) | Total Time 14.00(14.00)\n",
      "Iter 4600 | Time 15.5558(15.2740) | Bit/dim 3.6287(3.6617) | Xent 0.6953(0.6716) | Loss 3.9763(3.9975) | Error 0.2289(0.2383) Steps 622(622.54) | Grad Norm 4.0557(4.4970) | Total Time 14.00(14.00)\n",
      "Iter 4610 | Time 15.2456(15.2612) | Bit/dim 3.7090(3.6636) | Xent 0.6860(0.6650) | Loss 4.0520(3.9961) | Error 0.2589(0.2373) Steps 622(622.24) | Grad Norm 3.5705(4.4323) | Total Time 14.00(14.00)\n",
      "Iter 4620 | Time 15.2205(15.2593) | Bit/dim 3.6396(3.6623) | Xent 0.7266(0.6721) | Loss 4.0029(3.9984) | Error 0.2656(0.2389) Steps 616(621.50) | Grad Norm 7.2967(4.7294) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 82.0537, Epoch Time 939.5495(918.9364), Bit/dim 3.6642(best: 3.6632), Xent 0.7254, Loss 4.0269, Error 0.2533(best: 0.2587)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 15.4915(15.2543) | Bit/dim 3.6592(3.6616) | Xent 0.5805(0.6644) | Loss 3.9494(3.9938) | Error 0.2144(0.2355) Steps 616(621.74) | Grad Norm 2.6441(4.4725) | Total Time 14.00(14.00)\n",
      "Iter 4640 | Time 15.2513(15.2612) | Bit/dim 3.6993(3.6609) | Xent 0.6359(0.6595) | Loss 4.0172(3.9907) | Error 0.2256(0.2344) Steps 616(621.65) | Grad Norm 3.0240(4.1094) | Total Time 14.00(14.00)\n",
      "Iter 4650 | Time 15.5043(15.2638) | Bit/dim 3.6573(3.6626) | Xent 0.6342(0.6569) | Loss 3.9744(3.9910) | Error 0.2167(0.2325) Steps 622(621.78) | Grad Norm 3.7505(4.0615) | Total Time 14.00(14.00)\n",
      "Iter 4660 | Time 15.5132(15.2665) | Bit/dim 3.6693(3.6609) | Xent 0.6414(0.6575) | Loss 3.9900(3.9897) | Error 0.2144(0.2327) Steps 628(620.74) | Grad Norm 3.0813(4.2932) | Total Time 14.00(14.00)\n",
      "Iter 4670 | Time 15.8460(15.3566) | Bit/dim 3.6784(3.6615) | Xent 0.6215(0.6546) | Loss 3.9892(3.9888) | Error 0.2222(0.2321) Steps 622(621.97) | Grad Norm 2.5374(4.1069) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 82.1414, Epoch Time 943.7636(919.6812), Bit/dim 3.6646(best: 3.6632), Xent 0.7311, Loss 4.0301, Error 0.2552(best: 0.2533)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 15.1590(15.3566) | Bit/dim 3.6640(3.6617) | Xent 0.6744(0.6567) | Loss 4.0012(3.9901) | Error 0.2278(0.2330) Steps 622(622.10) | Grad Norm 2.7746(4.0802) | Total Time 14.00(14.00)\n",
      "Iter 4690 | Time 15.2845(15.3342) | Bit/dim 3.6565(3.6595) | Xent 0.6602(0.6509) | Loss 3.9866(3.9849) | Error 0.2267(0.2303) Steps 622(621.43) | Grad Norm 5.0289(3.9763) | Total Time 14.00(14.00)\n",
      "Iter 4700 | Time 15.1021(15.3423) | Bit/dim 3.6731(3.6598) | Xent 0.6038(0.6460) | Loss 3.9750(3.9828) | Error 0.2189(0.2290) Steps 616(621.72) | Grad Norm 4.2220(4.1529) | Total Time 14.00(14.00)\n",
      "Iter 4710 | Time 14.9137(15.3205) | Bit/dim 3.6305(3.6580) | Xent 0.6571(0.6473) | Loss 3.9591(3.9816) | Error 0.2322(0.2295) Steps 622(622.12) | Grad Norm 3.6111(4.0402) | Total Time 14.00(14.00)\n",
      "Iter 4720 | Time 15.4135(15.3066) | Bit/dim 3.6746(3.6598) | Xent 0.6688(0.6566) | Loss 4.0089(3.9881) | Error 0.2544(0.2348) Steps 622(623.00) | Grad Norm 4.9527(4.4312) | Total Time 14.00(14.00)\n",
      "Iter 4730 | Time 15.0070(15.3248) | Bit/dim 3.6504(3.6599) | Xent 0.6244(0.6566) | Loss 3.9626(3.9882) | Error 0.2322(0.2359) Steps 622(622.43) | Grad Norm 3.7088(4.5463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 82.0893, Epoch Time 941.5042(920.3359), Bit/dim 3.6635(best: 3.6632), Xent 0.7362, Loss 4.0316, Error 0.2578(best: 0.2533)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 15.8831(15.3933) | Bit/dim 3.6268(3.6574) | Xent 0.6327(0.6467) | Loss 3.9431(3.9807) | Error 0.2100(0.2322) Steps 628(622.98) | Grad Norm 5.5122(4.3167) | Total Time 14.00(14.00)\n",
      "Iter 4750 | Time 15.2846(15.4348) | Bit/dim 3.6931(3.6583) | Xent 0.8397(0.6578) | Loss 4.1130(3.9872) | Error 0.2744(0.2353) Steps 622(623.00) | Grad Norm 9.0469(4.9018) | Total Time 14.00(14.00)\n",
      "Iter 4760 | Time 15.8503(15.4189) | Bit/dim 3.6250(3.6576) | Xent 0.7160(0.6661) | Loss 3.9830(3.9907) | Error 0.2567(0.2370) Steps 616(621.67) | Grad Norm 3.3724(4.8959) | Total Time 14.00(14.00)\n",
      "Iter 4770 | Time 15.1909(15.4342) | Bit/dim 3.6604(3.6581) | Xent 0.7056(0.6646) | Loss 4.0131(3.9904) | Error 0.2400(0.2360) Steps 622(621.97) | Grad Norm 3.8331(4.5822) | Total Time 14.00(14.00)\n",
      "Iter 4780 | Time 15.8388(15.4124) | Bit/dim 3.6296(3.6610) | Xent 0.6975(0.6645) | Loss 3.9784(3.9932) | Error 0.2511(0.2367) Steps 628(622.07) | Grad Norm 3.0699(4.3706) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 81.1022, Epoch Time 948.1697(921.1709), Bit/dim 3.6656(best: 3.6632), Xent 0.7521, Loss 4.0417, Error 0.2612(best: 0.2533)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 15.4140(15.3913) | Bit/dim 3.6405(3.6603) | Xent 0.6566(0.6654) | Loss 3.9688(3.9930) | Error 0.2267(0.2376) Steps 622(622.13) | Grad Norm 3.6506(4.3664) | Total Time 14.00(14.00)\n",
      "Iter 4800 | Time 15.2537(15.3446) | Bit/dim 3.6694(3.6595) | Xent 0.6607(0.6564) | Loss 3.9998(3.9877) | Error 0.2256(0.2349) Steps 634(622.60) | Grad Norm 3.1975(4.2434) | Total Time 14.00(14.00)\n",
      "Iter 4810 | Time 15.1284(15.3146) | Bit/dim 3.6613(3.6595) | Xent 0.5955(0.6550) | Loss 3.9591(3.9870) | Error 0.2133(0.2343) Steps 622(622.74) | Grad Norm 3.3053(4.1980) | Total Time 14.00(14.00)\n",
      "Iter 4820 | Time 15.4415(15.3204) | Bit/dim 3.6564(3.6562) | Xent 0.6302(0.6528) | Loss 3.9716(3.9826) | Error 0.2256(0.2335) Steps 616(622.57) | Grad Norm 4.9685(4.1452) | Total Time 14.00(14.00)\n",
      "Iter 4830 | Time 15.5183(15.3430) | Bit/dim 3.6509(3.6559) | Xent 0.6619(0.6556) | Loss 3.9819(3.9837) | Error 0.2367(0.2336) Steps 616(623.49) | Grad Norm 5.3542(4.6393) | Total Time 14.00(14.00)\n",
      "Iter 4840 | Time 15.4704(15.3756) | Bit/dim 3.6462(3.6579) | Xent 0.6792(0.6532) | Loss 3.9858(3.9845) | Error 0.2400(0.2326) Steps 628(624.37) | Grad Norm 3.0448(4.3962) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 82.5138, Epoch Time 943.9275(921.8536), Bit/dim 3.6613(best: 3.6632), Xent 0.7160, Loss 4.0193, Error 0.2547(best: 0.2533)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 15.8999(15.3827) | Bit/dim 3.6567(3.6584) | Xent 0.6282(0.6485) | Loss 3.9708(3.9827) | Error 0.2322(0.2310) Steps 628(624.17) | Grad Norm 3.4314(4.5195) | Total Time 14.00(14.00)\n",
      "Iter 4860 | Time 15.1898(15.3756) | Bit/dim 3.6475(3.6560) | Xent 0.5817(0.6401) | Loss 3.9384(3.9761) | Error 0.2133(0.2280) Steps 622(624.36) | Grad Norm 3.0356(4.3449) | Total Time 14.00(14.00)\n",
      "Iter 4870 | Time 15.3667(15.3308) | Bit/dim 3.6592(3.6567) | Xent 0.5931(0.6356) | Loss 3.9557(3.9745) | Error 0.1989(0.2271) Steps 628(624.63) | Grad Norm 3.2752(4.3070) | Total Time 14.00(14.00)\n",
      "Iter 4880 | Time 15.7983(15.3261) | Bit/dim 3.6484(3.6565) | Xent 0.6219(0.6385) | Loss 3.9594(3.9758) | Error 0.2289(0.2291) Steps 628(624.46) | Grad Norm 2.6992(4.2372) | Total Time 14.00(14.00)\n",
      "Iter 4890 | Time 15.5319(15.3553) | Bit/dim 3.6661(3.6533) | Xent 0.6760(0.6403) | Loss 4.0041(3.9734) | Error 0.2444(0.2296) Steps 628(624.89) | Grad Norm 3.2473(4.0257) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 80.7853, Epoch Time 942.2059(922.4642), Bit/dim 3.6582(best: 3.6613), Xent 0.7290, Loss 4.0227, Error 0.2509(best: 0.2533)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 15.4576(15.3562) | Bit/dim 3.6299(3.6533) | Xent 0.6242(0.6412) | Loss 3.9420(3.9739) | Error 0.2256(0.2294) Steps 628(625.31) | Grad Norm 3.0946(4.1963) | Total Time 14.00(14.00)\n",
      "Iter 4910 | Time 15.5579(15.3773) | Bit/dim 3.6820(3.6534) | Xent 0.6422(0.6454) | Loss 4.0031(3.9761) | Error 0.2300(0.2311) Steps 634(627.38) | Grad Norm 7.4830(4.5022) | Total Time 14.00(14.00)\n",
      "Iter 4920 | Time 15.2637(15.3951) | Bit/dim 3.6730(3.6557) | Xent 0.7200(0.6431) | Loss 4.0330(3.9772) | Error 0.2633(0.2295) Steps 640(627.17) | Grad Norm 5.1540(4.3639) | Total Time 14.00(14.00)\n",
      "Iter 4930 | Time 15.2400(15.4156) | Bit/dim 3.6569(3.6570) | Xent 0.5938(0.6409) | Loss 3.9538(3.9775) | Error 0.2044(0.2291) Steps 622(628.27) | Grad Norm 3.1814(4.1289) | Total Time 14.00(14.00)\n",
      "Iter 4940 | Time 15.0214(15.3354) | Bit/dim 3.6260(3.6572) | Xent 0.6526(0.6397) | Loss 3.9523(3.9771) | Error 0.2444(0.2284) Steps 622(627.88) | Grad Norm 3.1070(4.1559) | Total Time 14.00(14.00)\n",
      "Iter 4950 | Time 15.3176(15.3351) | Bit/dim 3.6411(3.6558) | Xent 0.5942(0.6320) | Loss 3.9382(3.9718) | Error 0.2211(0.2263) Steps 634(627.92) | Grad Norm 3.3043(4.0351) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 80.0611, Epoch Time 943.1120(923.0836), Bit/dim 3.6517(best: 3.6582), Xent 0.7172, Loss 4.0102, Error 0.2506(best: 0.2509)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 15.3119(15.3208) | Bit/dim 3.6427(3.6549) | Xent 0.6336(0.6251) | Loss 3.9595(3.9675) | Error 0.2233(0.2226) Steps 628(627.04) | Grad Norm 2.7917(3.8609) | Total Time 14.00(14.00)\n",
      "Iter 4970 | Time 15.5234(15.3628) | Bit/dim 3.6156(3.6530) | Xent 0.6228(0.6207) | Loss 3.9270(3.9634) | Error 0.2100(0.2209) Steps 640(628.19) | Grad Norm 4.8710(4.0308) | Total Time 14.00(14.00)\n",
      "Iter 4980 | Time 15.3490(15.3676) | Bit/dim 3.6509(3.6535) | Xent 0.5762(0.6185) | Loss 3.9390(3.9628) | Error 0.1978(0.2202) Steps 640(628.34) | Grad Norm 5.3712(3.8920) | Total Time 14.00(14.00)\n",
      "Iter 4990 | Time 14.6113(15.3237) | Bit/dim 3.6594(3.6532) | Xent 0.5836(0.6209) | Loss 3.9512(3.9636) | Error 0.2000(0.2208) Steps 616(627.46) | Grad Norm 5.0772(4.0972) | Total Time 14.00(14.00)\n",
      "Iter 5000 | Time 15.1509(15.3941) | Bit/dim 3.6584(3.6500) | Xent 0.6490(0.6212) | Loss 3.9829(3.9606) | Error 0.2478(0.2220) Steps 622(627.30) | Grad Norm 3.6018(3.9912) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 82.8489, Epoch Time 947.7996(923.8251), Bit/dim 3.6540(best: 3.6517), Xent 0.7214, Loss 4.0147, Error 0.2481(best: 0.2506)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 15.6158(15.4092) | Bit/dim 3.6294(3.6505) | Xent 0.5805(0.6157) | Loss 3.9197(3.9583) | Error 0.2189(0.2208) Steps 634(626.87) | Grad Norm 2.7414(3.9058) | Total Time 14.00(14.00)\n",
      "Iter 5020 | Time 16.2181(15.4769) | Bit/dim 3.6453(3.6491) | Xent 0.6348(0.6181) | Loss 3.9627(3.9582) | Error 0.2233(0.2222) Steps 640(628.80) | Grad Norm 5.7550(4.1966) | Total Time 14.00(14.00)\n",
      "Iter 5030 | Time 15.7514(15.5215) | Bit/dim 3.6414(3.6482) | Xent 0.6031(0.6153) | Loss 3.9429(3.9559) | Error 0.2178(0.2211) Steps 646(631.10) | Grad Norm 8.9473(4.2981) | Total Time 14.00(14.00)\n",
      "Iter 5040 | Time 15.8218(15.4943) | Bit/dim 3.6766(3.6512) | Xent 0.7019(0.6254) | Loss 4.0275(3.9639) | Error 0.2444(0.2225) Steps 628(631.11) | Grad Norm 5.0168(4.4665) | Total Time 14.00(14.00)\n",
      "Iter 5050 | Time 15.0705(15.4328) | Bit/dim 3.6366(3.6525) | Xent 0.5905(0.6309) | Loss 3.9319(3.9679) | Error 0.2211(0.2240) Steps 622(630.99) | Grad Norm 5.1962(4.7412) | Total Time 14.00(14.00)\n",
      "Iter 5060 | Time 15.0446(15.3877) | Bit/dim 3.6426(3.6520) | Xent 0.6553(0.6336) | Loss 3.9703(3.9688) | Error 0.2478(0.2254) Steps 628(631.37) | Grad Norm 4.4984(4.7133) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 83.0395, Epoch Time 950.5384(924.6265), Bit/dim 3.6568(best: 3.6517), Xent 0.7255, Loss 4.0196, Error 0.2521(best: 0.2481)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 15.0792(15.3795) | Bit/dim 3.6216(3.6513) | Xent 0.6257(0.6311) | Loss 3.9344(3.9668) | Error 0.2122(0.2239) Steps 640(632.31) | Grad Norm 3.0826(4.5000) | Total Time 14.00(14.00)\n",
      "Iter 5080 | Time 15.4257(15.4586) | Bit/dim 3.6472(3.6491) | Xent 0.6082(0.6235) | Loss 3.9513(3.9609) | Error 0.2222(0.2217) Steps 640(633.26) | Grad Norm 5.2901(4.3318) | Total Time 14.00(14.00)\n",
      "Iter 5090 | Time 15.8569(15.4632) | Bit/dim 3.6451(3.6502) | Xent 0.6130(0.6188) | Loss 3.9517(3.9596) | Error 0.2200(0.2211) Steps 634(633.43) | Grad Norm 4.3607(4.4103) | Total Time 14.00(14.00)\n",
      "Iter 5100 | Time 15.8704(15.4881) | Bit/dim 3.6504(3.6532) | Xent 0.6042(0.6152) | Loss 3.9525(3.9609) | Error 0.2244(0.2218) Steps 634(633.62) | Grad Norm 3.5029(4.1912) | Total Time 14.00(14.00)\n",
      "Iter 5110 | Time 15.5394(15.5106) | Bit/dim 3.6759(3.6512) | Xent 0.6265(0.6150) | Loss 3.9891(3.9587) | Error 0.2256(0.2215) Steps 628(634.44) | Grad Norm 2.9059(4.0148) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 82.5736, Epoch Time 954.6315(925.5266), Bit/dim 3.6511(best: 3.6517), Xent 0.7116, Loss 4.0069, Error 0.2491(best: 0.2481)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 15.6883(15.5475) | Bit/dim 3.6495(3.6494) | Xent 0.6303(0.6154) | Loss 3.9647(3.9571) | Error 0.2344(0.2210) Steps 640(633.24) | Grad Norm 3.4290(3.8668) | Total Time 14.00(14.00)\n",
      "Iter 5130 | Time 15.6102(15.5736) | Bit/dim 3.6653(3.6469) | Xent 0.6252(0.6160) | Loss 3.9779(3.9549) | Error 0.2333(0.2213) Steps 640(634.86) | Grad Norm 6.7050(4.0998) | Total Time 14.00(14.00)\n",
      "Iter 5140 | Time 15.9244(15.6028) | Bit/dim 3.6695(3.6461) | Xent 0.6078(0.6182) | Loss 3.9734(3.9552) | Error 0.2322(0.2213) Steps 634(634.56) | Grad Norm 4.2125(4.1807) | Total Time 14.00(14.00)\n",
      "Iter 5150 | Time 15.6593(15.6063) | Bit/dim 3.6551(3.6481) | Xent 0.6037(0.6201) | Loss 3.9570(3.9582) | Error 0.2133(0.2226) Steps 628(635.46) | Grad Norm 3.6770(4.2622) | Total Time 14.00(14.00)\n",
      "Iter 5160 | Time 15.5947(15.6033) | Bit/dim 3.6655(3.6501) | Xent 0.5769(0.6198) | Loss 3.9540(3.9600) | Error 0.1978(0.2206) Steps 640(634.86) | Grad Norm 5.1824(4.2587) | Total Time 14.00(14.00)\n",
      "Iter 5170 | Time 15.5040(15.5730) | Bit/dim 3.6711(3.6525) | Xent 0.6060(0.6222) | Loss 3.9741(3.9636) | Error 0.2056(0.2207) Steps 640(635.78) | Grad Norm 4.6740(4.6015) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 86.6029, Epoch Time 963.4175(926.6633), Bit/dim 3.6565(best: 3.6511), Xent 0.7440, Loss 4.0285, Error 0.2562(best: 0.2481)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 15.4549(15.5675) | Bit/dim 3.6570(3.6519) | Xent 0.5707(0.6152) | Loss 3.9423(3.9595) | Error 0.2067(0.2181) Steps 634(636.19) | Grad Norm 3.7951(4.5632) | Total Time 14.00(14.00)\n",
      "Iter 5190 | Time 15.9938(15.5350) | Bit/dim 3.6477(3.6494) | Xent 0.5575(0.6053) | Loss 3.9264(3.9520) | Error 0.2056(0.2142) Steps 634(636.13) | Grad Norm 6.4323(4.5886) | Total Time 14.00(14.00)\n",
      "Iter 5200 | Time 15.3473(15.5478) | Bit/dim 3.6310(3.6489) | Xent 0.5985(0.6128) | Loss 3.9303(3.9553) | Error 0.1967(0.2163) Steps 628(635.05) | Grad Norm 3.2636(4.5489) | Total Time 14.00(14.00)\n",
      "Iter 5210 | Time 15.8164(15.5532) | Bit/dim 3.6533(3.6499) | Xent 0.6161(0.6135) | Loss 3.9614(3.9566) | Error 0.2211(0.2163) Steps 640(634.95) | Grad Norm 3.2152(4.4111) | Total Time 14.00(14.00)\n",
      "Iter 5220 | Time 15.8912(15.5955) | Bit/dim 3.6457(3.6538) | Xent 0.6112(0.6158) | Loss 3.9513(3.9617) | Error 0.2233(0.2192) Steps 640(635.19) | Grad Norm 5.7816(4.6580) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 84.7358, Epoch Time 958.8781(927.6298), Bit/dim 3.6601(best: 3.6511), Xent 0.7537, Loss 4.0370, Error 0.2578(best: 0.2481)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 15.3746(15.5665) | Bit/dim 3.6709(3.6551) | Xent 0.5804(0.6174) | Loss 3.9611(3.9638) | Error 0.2000(0.2185) Steps 646(635.76) | Grad Norm 5.1154(4.8550) | Total Time 14.00(14.00)\n",
      "Iter 5240 | Time 15.2710(15.5979) | Bit/dim 3.6594(3.6553) | Xent 0.6168(0.6136) | Loss 3.9678(3.9621) | Error 0.2467(0.2191) Steps 640(636.53) | Grad Norm 4.1135(4.7666) | Total Time 14.00(14.00)\n",
      "Iter 5250 | Time 15.9262(15.6273) | Bit/dim 3.6657(3.6530) | Xent 0.6521(0.6122) | Loss 3.9917(3.9591) | Error 0.2300(0.2200) Steps 640(636.65) | Grad Norm 3.1460(4.5461) | Total Time 14.00(14.00)\n",
      "Iter 5260 | Time 15.8057(15.6155) | Bit/dim 3.6724(3.6505) | Xent 0.5607(0.6093) | Loss 3.9527(3.9552) | Error 0.1944(0.2175) Steps 628(635.69) | Grad Norm 3.3389(4.3910) | Total Time 14.00(14.00)\n",
      "Iter 5270 | Time 15.5155(15.5704) | Bit/dim 3.6385(3.6508) | Xent 0.5895(0.6142) | Loss 3.9333(3.9579) | Error 0.2178(0.2198) Steps 634(635.98) | Grad Norm 5.4793(4.6971) | Total Time 14.00(14.00)\n",
      "Iter 5280 | Time 15.4063(15.5643) | Bit/dim 3.6723(3.6495) | Xent 0.6603(0.6210) | Loss 4.0025(3.9600) | Error 0.2356(0.2223) Steps 640(636.55) | Grad Norm 4.7819(4.5752) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 83.7302, Epoch Time 958.7268(928.5627), Bit/dim 3.6611(best: 3.6511), Xent 0.7204, Loss 4.0212, Error 0.2450(best: 0.2481)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 15.4266(15.5428) | Bit/dim 3.6248(3.6487) | Xent 0.6144(0.6153) | Loss 3.9320(3.9563) | Error 0.2311(0.2198) Steps 640(635.87) | Grad Norm 3.6181(4.4453) | Total Time 14.00(14.00)\n",
      "Iter 5300 | Time 15.4221(15.5267) | Bit/dim 3.6511(3.6486) | Xent 0.5762(0.6086) | Loss 3.9392(3.9529) | Error 0.2022(0.2178) Steps 640(636.54) | Grad Norm 3.4284(4.2061) | Total Time 14.00(14.00)\n",
      "Iter 5310 | Time 15.5137(15.5858) | Bit/dim 3.6242(3.6475) | Xent 0.6019(0.6044) | Loss 3.9251(3.9497) | Error 0.2100(0.2167) Steps 652(637.24) | Grad Norm 2.4931(4.0940) | Total Time 14.00(14.00)\n",
      "Iter 5320 | Time 15.5227(15.5837) | Bit/dim 3.6256(3.6474) | Xent 0.5866(0.6113) | Loss 3.9189(3.9531) | Error 0.2189(0.2188) Steps 640(637.71) | Grad Norm 3.1596(4.3485) | Total Time 14.00(14.00)\n",
      "Iter 5330 | Time 15.8489(15.5647) | Bit/dim 3.6680(3.6475) | Xent 0.5615(0.6008) | Loss 3.9487(3.9479) | Error 0.2078(0.2146) Steps 640(637.69) | Grad Norm 3.9302(4.1317) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 84.9643, Epoch Time 957.8612(929.4417), Bit/dim 3.6465(best: 3.6511), Xent 0.7163, Loss 4.0047, Error 0.2497(best: 0.2450)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 15.4398(15.5158) | Bit/dim 3.6353(3.6464) | Xent 0.5658(0.6005) | Loss 3.9182(3.9467) | Error 0.2000(0.2129) Steps 634(636.85) | Grad Norm 4.1104(4.4533) | Total Time 14.00(14.00)\n",
      "Iter 5350 | Time 15.1417(15.4628) | Bit/dim 3.6571(3.6459) | Xent 0.5579(0.5966) | Loss 3.9361(3.9442) | Error 0.1978(0.2118) Steps 634(636.73) | Grad Norm 3.4680(4.3250) | Total Time 14.00(14.00)\n",
      "Iter 5360 | Time 15.4481(15.4934) | Bit/dim 3.6485(3.6453) | Xent 0.6226(0.5973) | Loss 3.9598(3.9439) | Error 0.2367(0.2125) Steps 640(636.80) | Grad Norm 3.4878(4.3542) | Total Time 14.00(14.00)\n",
      "Iter 5370 | Time 15.0807(15.4569) | Bit/dim 3.6316(3.6468) | Xent 0.6131(0.5935) | Loss 3.9381(3.9436) | Error 0.2189(0.2112) Steps 628(636.48) | Grad Norm 6.3367(4.3361) | Total Time 14.00(14.00)\n",
      "Iter 5380 | Time 15.9539(15.5092) | Bit/dim 3.6530(3.6446) | Xent 0.5983(0.5951) | Loss 3.9522(3.9421) | Error 0.2233(0.2116) Steps 646(637.61) | Grad Norm 5.5118(4.5008) | Total Time 14.00(14.00)\n",
      "Iter 5390 | Time 15.4640(15.5082) | Bit/dim 3.6562(3.6431) | Xent 0.5431(0.5926) | Loss 3.9277(3.9394) | Error 0.1933(0.2098) Steps 640(637.59) | Grad Norm 3.9581(4.4128) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 85.8016, Epoch Time 954.8735(930.2046), Bit/dim 3.6449(best: 3.6465), Xent 0.7106, Loss 4.0002, Error 0.2436(best: 0.2450)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 15.0336(15.5346) | Bit/dim 3.6744(3.6428) | Xent 0.5575(0.5929) | Loss 3.9532(3.9393) | Error 0.2056(0.2110) Steps 640(637.27) | Grad Norm 5.1524(4.2239) | Total Time 14.00(14.00)\n",
      "Iter 5410 | Time 15.7549(15.6091) | Bit/dim 3.6469(3.6411) | Xent 0.5176(0.5930) | Loss 3.9057(3.9376) | Error 0.1767(0.2101) Steps 646(638.79) | Grad Norm 2.7497(4.0872) | Total Time 14.00(14.00)\n",
      "Iter 5420 | Time 15.8177(15.6567) | Bit/dim 3.6630(3.6447) | Xent 0.5575(0.5853) | Loss 3.9417(3.9373) | Error 0.1989(0.2076) Steps 646(639.49) | Grad Norm 5.6474(4.0954) | Total Time 14.00(14.00)\n",
      "Iter 5430 | Time 15.4846(15.6619) | Bit/dim 3.6550(3.6462) | Xent 0.5745(0.5863) | Loss 3.9422(3.9393) | Error 0.2078(0.2086) Steps 634(639.50) | Grad Norm 2.6867(4.1466) | Total Time 14.00(14.00)\n",
      "Iter 5440 | Time 16.2035(15.6987) | Bit/dim 3.6551(3.6437) | Xent 0.6491(0.5894) | Loss 3.9797(3.9384) | Error 0.2344(0.2088) Steps 640(638.99) | Grad Norm 5.6882(4.3788) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 85.3052, Epoch Time 968.8196(931.3631), Bit/dim 3.6557(best: 3.6449), Xent 0.7262, Loss 4.0188, Error 0.2495(best: 0.2436)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 15.5814(15.6865) | Bit/dim 3.6145(3.6416) | Xent 0.6286(0.6008) | Loss 3.9288(3.9420) | Error 0.2278(0.2125) Steps 646(639.30) | Grad Norm 5.4663(4.7775) | Total Time 14.00(14.00)\n",
      "Iter 5460 | Time 15.3015(15.6993) | Bit/dim 3.6413(3.6438) | Xent 0.5807(0.5962) | Loss 3.9316(3.9420) | Error 0.2122(0.2109) Steps 646(640.90) | Grad Norm 2.3301(4.5676) | Total Time 14.00(14.00)\n",
      "Iter 5470 | Time 15.2595(15.6486) | Bit/dim 3.6149(3.6427) | Xent 0.5732(0.5860) | Loss 3.9015(3.9357) | Error 0.1978(0.2079) Steps 640(640.49) | Grad Norm 3.7939(4.3760) | Total Time 14.00(14.00)\n",
      "Iter 5480 | Time 15.2808(15.6509) | Bit/dim 3.6272(3.6430) | Xent 0.6251(0.5872) | Loss 3.9398(3.9365) | Error 0.2222(0.2085) Steps 640(640.56) | Grad Norm 4.0193(4.2829) | Total Time 14.00(14.00)\n",
      "Iter 5490 | Time 16.0448(15.6453) | Bit/dim 3.6188(3.6412) | Xent 0.5952(0.5846) | Loss 3.9164(3.9335) | Error 0.2200(0.2074) Steps 646(640.79) | Grad Norm 4.3788(4.1858) | Total Time 14.00(14.00)\n",
      "Iter 5500 | Time 15.2068(15.6424) | Bit/dim 3.6821(3.6438) | Xent 0.5926(0.5834) | Loss 3.9784(3.9355) | Error 0.2211(0.2071) Steps 640(640.03) | Grad Norm 5.6721(4.1865) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 85.4766, Epoch Time 962.7393(932.3043), Bit/dim 3.6437(best: 3.6449), Xent 0.7106, Loss 3.9989, Error 0.2442(best: 0.2436)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 15.7919(15.6579) | Bit/dim 3.6068(3.6438) | Xent 0.5717(0.5770) | Loss 3.8926(3.9323) | Error 0.2089(0.2039) Steps 646(640.14) | Grad Norm 4.0990(4.3965) | Total Time 14.00(14.00)\n",
      "Iter 5520 | Time 16.1119(15.6973) | Bit/dim 3.6476(3.6434) | Xent 0.5300(0.5839) | Loss 3.9126(3.9354) | Error 0.2000(0.2068) Steps 646(640.74) | Grad Norm 2.6555(4.3061) | Total Time 14.00(14.00)\n",
      "Iter 5530 | Time 15.8138(15.6800) | Bit/dim 3.6400(3.6425) | Xent 0.6080(0.5796) | Loss 3.9441(3.9323) | Error 0.2144(0.2059) Steps 646(640.77) | Grad Norm 5.4506(4.3921) | Total Time 14.00(14.00)\n",
      "Iter 5540 | Time 15.5810(15.6964) | Bit/dim 3.6418(3.6423) | Xent 0.5848(0.5742) | Loss 3.9342(3.9294) | Error 0.2133(0.2042) Steps 646(640.99) | Grad Norm 4.1316(4.3962) | Total Time 14.00(14.00)\n",
      "Iter 5550 | Time 15.9584(15.7046) | Bit/dim 3.6146(3.6423) | Xent 0.5072(0.5803) | Loss 3.8682(3.9325) | Error 0.1900(0.2060) Steps 628(639.26) | Grad Norm 3.3933(4.4463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 85.2563, Epoch Time 968.8142(933.3996), Bit/dim 3.6368(best: 3.6437), Xent 0.7088, Loss 3.9913, Error 0.2447(best: 0.2436)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 15.6962(15.6977) | Bit/dim 3.6442(3.6419) | Xent 0.4419(0.5768) | Loss 3.8651(3.9303) | Error 0.1767(0.2061) Steps 634(639.14) | Grad Norm 2.1548(4.2946) | Total Time 14.00(14.00)\n",
      "Iter 5570 | Time 15.2311(15.6953) | Bit/dim 3.6499(3.6434) | Xent 0.6068(0.5809) | Loss 3.9534(3.9338) | Error 0.2256(0.2076) Steps 634(639.39) | Grad Norm 4.3253(4.3493) | Total Time 14.00(14.00)\n",
      "Iter 5580 | Time 15.4466(15.6616) | Bit/dim 3.6514(3.6408) | Xent 0.6107(0.5768) | Loss 3.9567(3.9292) | Error 0.1956(0.2045) Steps 646(639.73) | Grad Norm 5.6715(4.4678) | Total Time 14.00(14.00)\n",
      "Iter 5590 | Time 16.0371(15.6374) | Bit/dim 3.6389(3.6432) | Xent 0.5663(0.5791) | Loss 3.9221(3.9327) | Error 0.2022(0.2059) Steps 652(640.45) | Grad Norm 4.2612(4.3972) | Total Time 14.00(14.00)\n",
      "Iter 5600 | Time 15.2553(15.5896) | Bit/dim 3.6415(3.6406) | Xent 0.5585(0.5777) | Loss 3.9208(3.9294) | Error 0.1989(0.2050) Steps 640(639.59) | Grad Norm 3.0829(4.3348) | Total Time 14.00(14.00)\n",
      "Iter 5610 | Time 15.5617(15.6184) | Bit/dim 3.6280(3.6420) | Xent 0.5616(0.5798) | Loss 3.9088(3.9319) | Error 0.2000(0.2049) Steps 652(640.51) | Grad Norm 4.9625(4.2527) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 86.4117, Epoch Time 961.2607(934.2355), Bit/dim 3.6488(best: 3.6368), Xent 0.7136, Loss 4.0056, Error 0.2405(best: 0.2436)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 15.7102(15.5799) | Bit/dim 3.6455(3.6396) | Xent 0.6248(0.5759) | Loss 3.9579(3.9275) | Error 0.2211(0.2026) Steps 640(639.82) | Grad Norm 4.8422(4.2861) | Total Time 14.00(14.00)\n",
      "Iter 5630 | Time 15.2395(15.5918) | Bit/dim 3.6570(3.6406) | Xent 0.6032(0.5691) | Loss 3.9586(3.9252) | Error 0.2100(0.2015) Steps 640(639.30) | Grad Norm 6.6904(4.4512) | Total Time 14.00(14.00)\n",
      "Iter 5640 | Time 15.5645(15.6341) | Bit/dim 3.6464(3.6412) | Xent 0.5586(0.5717) | Loss 3.9257(3.9270) | Error 0.2078(0.2017) Steps 640(640.60) | Grad Norm 3.8538(4.4870) | Total Time 14.00(14.00)\n",
      "Iter 5650 | Time 15.5142(15.6388) | Bit/dim 3.6747(3.6443) | Xent 0.5111(0.5717) | Loss 3.9303(3.9302) | Error 0.1900(0.2036) Steps 646(640.44) | Grad Norm 3.0837(4.5712) | Total Time 14.00(14.00)\n",
      "Iter 5660 | Time 15.8439(15.6218) | Bit/dim 3.6407(3.6435) | Xent 0.5883(0.5753) | Loss 3.9349(3.9312) | Error 0.2033(0.2043) Steps 628(639.13) | Grad Norm 3.0649(4.5253) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 86.4508, Epoch Time 963.3969(935.1103), Bit/dim 3.6376(best: 3.6368), Xent 0.6965, Loss 3.9859, Error 0.2427(best: 0.2405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 15.8224(15.6208) | Bit/dim 3.6062(3.6399) | Xent 0.6276(0.5745) | Loss 3.9201(3.9272) | Error 0.2200(0.2042) Steps 652(639.24) | Grad Norm 3.7430(4.3571) | Total Time 14.00(14.00)\n",
      "Iter 5680 | Time 15.2716(15.5937) | Bit/dim 3.6568(3.6417) | Xent 0.5617(0.5687) | Loss 3.9377(3.9260) | Error 0.2022(0.2027) Steps 634(638.84) | Grad Norm 2.8878(4.3224) | Total Time 14.00(14.00)\n",
      "Iter 5690 | Time 15.8986(15.6510) | Bit/dim 3.6409(3.6400) | Xent 0.5567(0.5698) | Loss 3.9192(3.9249) | Error 0.2022(0.2027) Steps 640(639.48) | Grad Norm 3.4499(4.2225) | Total Time 14.00(14.00)\n",
      "Iter 5700 | Time 15.6572(15.6846) | Bit/dim 3.6204(3.6412) | Xent 0.5260(0.5683) | Loss 3.8833(3.9253) | Error 0.2000(0.2025) Steps 646(639.47) | Grad Norm 2.8822(4.2420) | Total Time 14.00(14.00)\n",
      "Iter 5710 | Time 15.4836(15.7269) | Bit/dim 3.6553(3.6396) | Xent 0.5408(0.5711) | Loss 3.9257(3.9251) | Error 0.2044(0.2026) Steps 646(640.68) | Grad Norm 4.1441(4.3569) | Total Time 14.00(14.00)\n",
      "Iter 5720 | Time 16.2174(15.7655) | Bit/dim 3.6237(3.6400) | Xent 0.6613(0.5766) | Loss 3.9544(3.9283) | Error 0.2200(0.2054) Steps 634(641.16) | Grad Norm 5.7213(4.3523) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 86.2977, Epoch Time 970.2203(936.1636), Bit/dim 3.6440(best: 3.6368), Xent 0.6997, Loss 3.9939, Error 0.2399(best: 0.2405)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 16.0648(15.7607) | Bit/dim 3.6677(3.6436) | Xent 0.5955(0.5700) | Loss 3.9654(3.9285) | Error 0.2156(0.2030) Steps 640(641.19) | Grad Norm 3.2319(4.3112) | Total Time 14.00(14.00)\n",
      "Iter 5740 | Time 16.4649(15.8118) | Bit/dim 3.6386(3.6399) | Xent 0.5799(0.5748) | Loss 3.9286(3.9273) | Error 0.1967(0.2036) Steps 652(642.45) | Grad Norm 4.4751(4.4169) | Total Time 14.00(14.00)\n",
      "Iter 5750 | Time 15.1862(15.8663) | Bit/dim 3.6160(3.6401) | Xent 0.5374(0.5707) | Loss 3.8847(3.9254) | Error 0.1878(0.2020) Steps 634(642.41) | Grad Norm 3.1441(4.4581) | Total Time 14.00(14.00)\n",
      "Iter 5760 | Time 15.8965(15.9177) | Bit/dim 3.6411(3.6435) | Xent 0.5864(0.5746) | Loss 3.9343(3.9308) | Error 0.2144(0.2036) Steps 640(643.22) | Grad Norm 6.3153(4.7917) | Total Time 14.00(14.00)\n",
      "Iter 5770 | Time 15.8409(15.8999) | Bit/dim 3.6194(3.6403) | Xent 0.6310(0.5804) | Loss 3.9349(3.9305) | Error 0.2289(0.2068) Steps 646(643.39) | Grad Norm 4.6057(4.6811) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 86.7382, Epoch Time 980.7853(937.5023), Bit/dim 3.6359(best: 3.6368), Xent 0.7173, Loss 3.9946, Error 0.2419(best: 0.2399)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 16.1017(15.9568) | Bit/dim 3.6174(3.6386) | Xent 0.7062(0.5855) | Loss 3.9705(3.9313) | Error 0.2467(0.2086) Steps 652(644.79) | Grad Norm 6.2240(4.6687) | Total Time 14.00(14.00)\n",
      "Iter 5790 | Time 15.4250(15.8981) | Bit/dim 3.6992(3.6422) | Xent 0.5408(0.5751) | Loss 3.9696(3.9297) | Error 0.2000(0.2055) Steps 640(645.40) | Grad Norm 4.5539(4.5511) | Total Time 14.00(14.00)\n",
      "Iter 5800 | Time 16.0545(15.8614) | Bit/dim 3.6472(3.6415) | Xent 0.5561(0.5714) | Loss 3.9252(3.9272) | Error 0.1933(0.2038) Steps 634(643.63) | Grad Norm 3.1299(4.4646) | Total Time 14.00(14.00)\n",
      "Iter 5810 | Time 15.4235(15.8902) | Bit/dim 3.6143(3.6364) | Xent 0.5363(0.5648) | Loss 3.8825(3.9189) | Error 0.2044(0.2015) Steps 640(643.84) | Grad Norm 3.4997(4.2746) | Total Time 14.00(14.00)\n",
      "Iter 5820 | Time 16.2328(15.9119) | Bit/dim 3.6137(3.6396) | Xent 0.6291(0.5736) | Loss 3.9283(3.9264) | Error 0.2244(0.2041) Steps 664(645.17) | Grad Norm 4.5480(4.5025) | Total Time 14.00(14.00)\n",
      "Iter 5830 | Time 15.9731(15.8197) | Bit/dim 3.6735(3.6421) | Xent 0.5628(0.5705) | Loss 3.9549(3.9274) | Error 0.1922(0.2022) Steps 664(644.48) | Grad Norm 4.9457(4.4943) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 86.3747, Epoch Time 974.7720(938.6204), Bit/dim 3.6385(best: 3.6359), Xent 0.6957, Loss 3.9864, Error 0.2410(best: 0.2399)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 16.3581(15.8557) | Bit/dim 3.6618(3.6401) | Xent 0.5936(0.5695) | Loss 3.9586(3.9248) | Error 0.2089(0.2031) Steps 640(645.67) | Grad Norm 7.0655(4.6258) | Total Time 14.00(14.00)\n",
      "Iter 5850 | Time 15.3163(15.7606) | Bit/dim 3.6617(3.6418) | Xent 0.5959(0.5661) | Loss 3.9596(3.9248) | Error 0.2100(0.2011) Steps 640(644.35) | Grad Norm 5.0744(4.6573) | Total Time 14.00(14.00)\n",
      "Iter 5860 | Time 16.3215(15.7270) | Bit/dim 3.6618(3.6409) | Xent 0.5433(0.5663) | Loss 3.9335(3.9240) | Error 0.1922(0.2012) Steps 640(642.59) | Grad Norm 3.4891(4.5503) | Total Time 14.00(14.00)\n",
      "Iter 5870 | Time 15.8732(15.7266) | Bit/dim 3.6576(3.6402) | Xent 0.6131(0.5654) | Loss 3.9641(3.9229) | Error 0.2111(0.2006) Steps 658(642.96) | Grad Norm 6.6758(4.5367) | Total Time 14.00(14.00)\n",
      "Iter 5880 | Time 16.4951(15.8373) | Bit/dim 3.6383(3.6386) | Xent 0.5310(0.5616) | Loss 3.9038(3.9194) | Error 0.1933(0.1987) Steps 658(644.07) | Grad Norm 3.4955(4.4077) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 85.5408, Epoch Time 971.4533(939.6053), Bit/dim 3.6380(best: 3.6359), Xent 0.6973, Loss 3.9867, Error 0.2426(best: 0.2399)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 15.8972(15.8357) | Bit/dim 3.6455(3.6418) | Xent 0.5362(0.5602) | Loss 3.9136(3.9219) | Error 0.1933(0.1985) Steps 646(643.55) | Grad Norm 2.5827(4.4989) | Total Time 14.00(14.00)\n",
      "Iter 5900 | Time 16.3034(15.8583) | Bit/dim 3.6359(3.6407) | Xent 0.5045(0.5519) | Loss 3.8882(3.9167) | Error 0.1744(0.1960) Steps 658(643.94) | Grad Norm 4.2617(4.2567) | Total Time 14.00(14.00)\n",
      "Iter 5910 | Time 15.8993(15.8932) | Bit/dim 3.6188(3.6371) | Xent 0.5072(0.5451) | Loss 3.8724(3.9097) | Error 0.1911(0.1933) Steps 646(644.57) | Grad Norm 2.6340(3.9618) | Total Time 14.00(14.00)\n",
      "Iter 5920 | Time 16.4705(15.8999) | Bit/dim 3.6683(3.6393) | Xent 0.5011(0.5447) | Loss 3.9188(3.9117) | Error 0.1789(0.1927) Steps 652(645.27) | Grad Norm 2.7870(4.0528) | Total Time 14.00(14.00)\n",
      "Iter 5930 | Time 15.6504(15.9479) | Bit/dim 3.6126(3.6365) | Xent 0.5752(0.5432) | Loss 3.9001(3.9081) | Error 0.2067(0.1928) Steps 646(647.89) | Grad Norm 7.4200(4.1325) | Total Time 14.00(14.00)\n",
      "Iter 5940 | Time 15.8735(15.9232) | Bit/dim 3.6456(3.6357) | Xent 0.5678(0.5560) | Loss 3.9295(3.9137) | Error 0.1944(0.1969) Steps 652(647.28) | Grad Norm 3.5347(4.1194) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 86.8196, Epoch Time 982.1179(940.8807), Bit/dim 3.6350(best: 3.6359), Xent 0.7510, Loss 4.0105, Error 0.2603(best: 0.2399)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 16.4458(16.0239) | Bit/dim 3.6449(3.6370) | Xent 0.5786(0.5620) | Loss 3.9342(3.9180) | Error 0.1911(0.1985) Steps 664(649.36) | Grad Norm 4.5847(4.2535) | Total Time 14.00(14.00)\n",
      "Iter 5960 | Time 16.3501(16.0568) | Bit/dim 3.6568(3.6368) | Xent 0.5379(0.5585) | Loss 3.9257(3.9161) | Error 0.1900(0.1976) Steps 646(648.67) | Grad Norm 4.1279(4.1714) | Total Time 14.00(14.00)\n",
      "Iter 5970 | Time 16.2068(16.0733) | Bit/dim 3.6379(3.6361) | Xent 0.5195(0.5536) | Loss 3.8976(3.9129) | Error 0.1867(0.1964) Steps 658(650.40) | Grad Norm 3.0922(4.2711) | Total Time 14.00(14.00)\n",
      "Iter 5980 | Time 15.8457(16.0397) | Bit/dim 3.6080(3.6344) | Xent 0.4931(0.5468) | Loss 3.8546(3.9078) | Error 0.1656(0.1942) Steps 640(649.36) | Grad Norm 2.8344(4.0003) | Total Time 14.00(14.00)\n",
      "Iter 5990 | Time 16.1350(16.0949) | Bit/dim 3.6238(3.6361) | Xent 0.4676(0.5451) | Loss 3.8575(3.9087) | Error 0.1622(0.1947) Steps 658(650.13) | Grad Norm 3.6466(4.2957) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 87.5123, Epoch Time 995.6157(942.5228), Bit/dim 3.6441(best: 3.6350), Xent 0.6862, Loss 3.9872, Error 0.2377(best: 0.2399)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 16.1367(16.1308) | Bit/dim 3.6310(3.6353) | Xent 0.5556(0.5452) | Loss 3.9088(3.9079) | Error 0.1967(0.1938) Steps 634(649.95) | Grad Norm 6.3446(4.3323) | Total Time 14.00(14.00)\n",
      "Iter 6010 | Time 16.0063(16.1640) | Bit/dim 3.6253(3.6342) | Xent 0.4606(0.5335) | Loss 3.8556(3.9010) | Error 0.1678(0.1911) Steps 646(650.07) | Grad Norm 3.6768(4.1361) | Total Time 14.00(14.00)\n",
      "Iter 6020 | Time 15.6957(16.1381) | Bit/dim 3.6475(3.6378) | Xent 0.5409(0.5356) | Loss 3.9179(3.9056) | Error 0.2056(0.1915) Steps 634(648.96) | Grad Norm 4.8968(4.4433) | Total Time 14.00(14.00)\n",
      "Iter 6030 | Time 15.8819(16.1678) | Bit/dim 3.6217(3.6373) | Xent 0.5082(0.5432) | Loss 3.8758(3.9089) | Error 0.1744(0.1936) Steps 652(649.55) | Grad Norm 2.8388(4.2633) | Total Time 14.00(14.00)\n",
      "Iter 6040 | Time 16.6395(16.1920) | Bit/dim 3.5966(3.6314) | Xent 0.4722(0.5342) | Loss 3.8327(3.8985) | Error 0.1700(0.1920) Steps 646(650.51) | Grad Norm 2.3959(4.0178) | Total Time 14.00(14.00)\n",
      "Iter 6050 | Time 15.9882(16.1740) | Bit/dim 3.6003(3.6321) | Xent 0.5301(0.5362) | Loss 3.8653(3.9002) | Error 0.1933(0.1921) Steps 640(649.43) | Grad Norm 5.7537(4.1411) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 89.1047, Epoch Time 996.3711(944.1382), Bit/dim 3.6421(best: 3.6350), Xent 0.6886, Loss 3.9864, Error 0.2341(best: 0.2377)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 15.8968(16.1450) | Bit/dim 3.6741(3.6304) | Xent 0.5335(0.5366) | Loss 3.9409(3.8987) | Error 0.1978(0.1919) Steps 658(650.70) | Grad Norm 4.3595(4.1732) | Total Time 14.00(14.00)\n",
      "Iter 6070 | Time 16.4746(16.1249) | Bit/dim 3.6376(3.6320) | Xent 0.5793(0.5318) | Loss 3.9273(3.8979) | Error 0.2144(0.1889) Steps 652(651.14) | Grad Norm 5.0849(4.2970) | Total Time 14.00(14.00)\n",
      "Iter 6080 | Time 16.3327(16.1701) | Bit/dim 3.6544(3.6331) | Xent 0.5970(0.5348) | Loss 3.9529(3.9005) | Error 0.2033(0.1883) Steps 658(651.12) | Grad Norm 7.4425(4.5712) | Total Time 14.00(14.00)\n",
      "Iter 6090 | Time 16.4337(16.1890) | Bit/dim 3.6312(3.6333) | Xent 0.5631(0.5381) | Loss 3.9128(3.9023) | Error 0.2000(0.1898) Steps 640(650.09) | Grad Norm 3.1422(4.4740) | Total Time 14.00(14.00)\n",
      "Iter 6100 | Time 16.9436(16.2509) | Bit/dim 3.6410(3.6356) | Xent 0.5351(0.5447) | Loss 3.9086(3.9079) | Error 0.1967(0.1931) Steps 688(651.50) | Grad Norm 2.4577(4.4221) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 87.3440, Epoch Time 996.3417(945.7043), Bit/dim 3.6369(best: 3.6350), Xent 0.6794, Loss 3.9766, Error 0.2328(best: 0.2341)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 15.8687(16.2044) | Bit/dim 3.6292(3.6340) | Xent 0.5068(0.5400) | Loss 3.8826(3.9041) | Error 0.1756(0.1916) Steps 640(651.41) | Grad Norm 4.1283(4.3125) | Total Time 14.00(14.00)\n",
      "Iter 6120 | Time 15.6130(16.1682) | Bit/dim 3.6117(3.6324) | Xent 0.5099(0.5349) | Loss 3.8666(3.8999) | Error 0.1722(0.1889) Steps 664(650.59) | Grad Norm 3.4616(4.1157) | Total Time 14.00(14.00)\n",
      "Iter 6130 | Time 16.5022(16.2508) | Bit/dim 3.6127(3.6309) | Xent 0.5263(0.5272) | Loss 3.8758(3.8945) | Error 0.2033(0.1883) Steps 652(652.26) | Grad Norm 2.6987(3.8214) | Total Time 14.00(14.00)\n",
      "Iter 6140 | Time 15.7334(16.2119) | Bit/dim 3.6362(3.6300) | Xent 0.5703(0.5292) | Loss 3.9214(3.8946) | Error 0.2033(0.1889) Steps 652(652.92) | Grad Norm 3.0838(3.8465) | Total Time 14.00(14.00)\n",
      "Iter 6150 | Time 16.2534(16.2161) | Bit/dim 3.6123(3.6316) | Xent 0.5597(0.5279) | Loss 3.8922(3.8956) | Error 0.2033(0.1884) Steps 646(652.12) | Grad Norm 6.1688(3.8320) | Total Time 14.00(14.00)\n",
      "Iter 6160 | Time 16.1229(16.2017) | Bit/dim 3.6075(3.6325) | Xent 0.5052(0.5229) | Loss 3.8601(3.8939) | Error 0.1800(0.1862) Steps 658(653.02) | Grad Norm 3.4018(3.9046) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 87.3148, Epoch Time 995.9951(947.2130), Bit/dim 3.6312(best: 3.6350), Xent 0.6900, Loss 3.9762, Error 0.2351(best: 0.2328)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 15.9737(16.1970) | Bit/dim 3.6220(3.6313) | Xent 0.4799(0.5216) | Loss 3.8619(3.8922) | Error 0.1700(0.1853) Steps 646(652.67) | Grad Norm 2.8032(3.7957) | Total Time 14.00(14.00)\n",
      "Iter 6180 | Time 16.6875(16.2486) | Bit/dim 3.6091(3.6277) | Xent 0.4970(0.5172) | Loss 3.8576(3.8863) | Error 0.1811(0.1837) Steps 664(653.97) | Grad Norm 2.8428(3.7244) | Total Time 14.00(14.00)\n",
      "Iter 6190 | Time 15.7536(16.2409) | Bit/dim 3.6506(3.6297) | Xent 0.5257(0.5209) | Loss 3.9134(3.8901) | Error 0.1778(0.1843) Steps 640(653.66) | Grad Norm 6.0081(3.7370) | Total Time 14.00(14.00)\n",
      "Iter 6200 | Time 16.0813(16.2408) | Bit/dim 3.6092(3.6293) | Xent 0.5928(0.5293) | Loss 3.9055(3.8940) | Error 0.2122(0.1881) Steps 664(654.52) | Grad Norm 7.3264(4.0710) | Total Time 14.00(14.00)\n",
      "Iter 6210 | Time 15.8732(16.2126) | Bit/dim 3.6324(3.6332) | Xent 0.5517(0.5354) | Loss 3.9083(3.9010) | Error 0.1989(0.1903) Steps 646(654.32) | Grad Norm 4.0194(4.3478) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 85.8636, Epoch Time 998.5179(948.7522), Bit/dim 3.6329(best: 3.6312), Xent 0.6911, Loss 3.9785, Error 0.2344(best: 0.2328)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 16.2508(16.3048) | Bit/dim 3.6375(3.6340) | Xent 0.4849(0.5326) | Loss 3.8799(3.9003) | Error 0.1867(0.1902) Steps 652(654.75) | Grad Norm 2.5893(4.0608) | Total Time 14.00(14.00)\n",
      "Iter 6230 | Time 15.8340(16.2100) | Bit/dim 3.6271(3.6361) | Xent 0.4919(0.5314) | Loss 3.8731(3.9018) | Error 0.1622(0.1891) Steps 658(655.21) | Grad Norm 4.5725(4.4317) | Total Time 14.00(14.00)\n",
      "Iter 6240 | Time 15.8077(16.2037) | Bit/dim 3.6379(3.6348) | Xent 0.5511(0.5355) | Loss 3.9135(3.9026) | Error 0.1956(0.1898) Steps 646(655.84) | Grad Norm 4.1029(4.6729) | Total Time 14.00(14.00)\n",
      "Iter 6250 | Time 16.7124(16.1944) | Bit/dim 3.6167(3.6328) | Xent 0.5424(0.5343) | Loss 3.8879(3.9000) | Error 0.1989(0.1898) Steps 670(655.44) | Grad Norm 2.6213(4.5536) | Total Time 14.00(14.00)\n",
      "Iter 6260 | Time 16.1611(16.3134) | Bit/dim 3.6297(3.6303) | Xent 0.5470(0.5273) | Loss 3.9032(3.8939) | Error 0.2044(0.1876) Steps 664(657.92) | Grad Norm 3.6638(4.2843) | Total Time 14.00(14.00)\n",
      "Iter 6270 | Time 16.5759(16.3564) | Bit/dim 3.6119(3.6296) | Xent 0.5086(0.5183) | Loss 3.8662(3.8888) | Error 0.1756(0.1841) Steps 652(656.61) | Grad Norm 3.5167(4.0688) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 86.8732, Epoch Time 1001.0339(950.3206), Bit/dim 3.6264(best: 3.6312), Xent 0.6609, Loss 3.9568, Error 0.2320(best: 0.2328)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 16.2779(16.3735) | Bit/dim 3.6288(3.6325) | Xent 0.4972(0.5059) | Loss 3.8774(3.8854) | Error 0.1756(0.1808) Steps 652(656.88) | Grad Norm 4.4061(3.8733) | Total Time 14.00(14.00)\n",
      "Iter 6290 | Time 16.2917(16.3661) | Bit/dim 3.6561(3.6311) | Xent 0.5209(0.5051) | Loss 3.9166(3.8837) | Error 0.1822(0.1809) Steps 646(656.25) | Grad Norm 4.2432(3.9037) | Total Time 14.00(14.00)\n",
      "Iter 6300 | Time 15.8313(16.3675) | Bit/dim 3.6374(3.6305) | Xent 0.5595(0.5141) | Loss 3.9172(3.8876) | Error 0.2000(0.1826) Steps 646(657.40) | Grad Norm 8.6096(4.2064) | Total Time 14.00(14.00)\n",
      "Iter 6310 | Time 16.5591(16.4145) | Bit/dim 3.6413(3.6323) | Xent 0.5082(0.5202) | Loss 3.8954(3.8923) | Error 0.1900(0.1862) Steps 664(658.05) | Grad Norm 2.7891(4.4247) | Total Time 14.00(14.00)\n",
      "Iter 6320 | Time 16.9360(16.4059) | Bit/dim 3.6084(3.6293) | Xent 0.5274(0.5217) | Loss 3.8721(3.8901) | Error 0.1833(0.1856) Steps 682(659.40) | Grad Norm 4.8779(4.2782) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 87.7718, Epoch Time 1009.2220(952.0877), Bit/dim 3.6380(best: 3.6264), Xent 0.6769, Loss 3.9765, Error 0.2283(best: 0.2320)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 16.5760(16.3976) | Bit/dim 3.6321(3.6286) | Xent 0.5263(0.5156) | Loss 3.8953(3.8864) | Error 0.1944(0.1835) Steps 676(660.60) | Grad Norm 4.2249(4.1776) | Total Time 14.00(14.00)\n",
      "Iter 6340 | Time 16.7319(16.4114) | Bit/dim 3.6608(3.6298) | Xent 0.5012(0.5184) | Loss 3.9114(3.8890) | Error 0.1622(0.1841) Steps 652(660.78) | Grad Norm 7.0362(4.2867) | Total Time 14.00(14.00)\n",
      "Iter 6350 | Time 16.5785(16.4803) | Bit/dim 3.6222(3.6295) | Xent 0.5059(0.5172) | Loss 3.8751(3.8881) | Error 0.1756(0.1829) Steps 658(661.62) | Grad Norm 5.0464(4.1291) | Total Time 14.00(14.00)\n",
      "Iter 6360 | Time 16.7524(16.4362) | Bit/dim 3.6469(3.6293) | Xent 0.4874(0.5131) | Loss 3.8906(3.8858) | Error 0.1811(0.1827) Steps 652(659.28) | Grad Norm 3.2526(3.8752) | Total Time 14.00(14.00)\n",
      "Iter 6370 | Time 16.0296(16.4607) | Bit/dim 3.6270(3.6288) | Xent 0.5049(0.5119) | Loss 3.8795(3.8847) | Error 0.1844(0.1819) Steps 652(660.38) | Grad Norm 2.8172(3.8498) | Total Time 14.00(14.00)\n",
      "Iter 6380 | Time 17.2377(16.4976) | Bit/dim 3.6308(3.6266) | Xent 0.5747(0.5157) | Loss 3.9181(3.8845) | Error 0.2111(0.1834) Steps 682(660.72) | Grad Norm 4.7555(4.0636) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 87.7984, Epoch Time 1012.2176(953.8916), Bit/dim 3.6288(best: 3.6264), Xent 0.6821, Loss 3.9699, Error 0.2325(best: 0.2283)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 15.7532(16.5156) | Bit/dim 3.6364(3.6273) | Xent 0.4892(0.5052) | Loss 3.8810(3.8799) | Error 0.1856(0.1800) Steps 658(661.44) | Grad Norm 2.9131(3.7753) | Total Time 14.00(14.00)\n",
      "Iter 6400 | Time 16.8122(16.5240) | Bit/dim 3.6094(3.6288) | Xent 0.5369(0.4989) | Loss 3.8778(3.8782) | Error 0.1900(0.1769) Steps 682(660.95) | Grad Norm 6.2501(3.6082) | Total Time 14.00(14.00)\n",
      "Iter 6410 | Time 16.0694(16.5370) | Bit/dim 3.6191(3.6274) | Xent 0.4983(0.4996) | Loss 3.8682(3.8772) | Error 0.1844(0.1771) Steps 664(663.14) | Grad Norm 2.3246(3.7920) | Total Time 14.00(14.00)\n",
      "Iter 6420 | Time 16.9857(16.6094) | Bit/dim 3.6079(3.6246) | Xent 0.5309(0.5041) | Loss 3.8734(3.8767) | Error 0.1833(0.1783) Steps 664(664.42) | Grad Norm 4.2644(4.2106) | Total Time 14.00(14.00)\n",
      "Iter 6430 | Time 16.6962(16.5512) | Bit/dim 3.6385(3.6260) | Xent 0.4852(0.5149) | Loss 3.8811(3.8835) | Error 0.1611(0.1821) Steps 676(662.36) | Grad Norm 2.5888(4.3211) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 87.4771, Epoch Time 1018.6105(955.8331), Bit/dim 3.6378(best: 3.6264), Xent 0.7081, Loss 3.9918, Error 0.2367(best: 0.2283)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 17.2447(16.6432) | Bit/dim 3.6540(3.6282) | Xent 0.5148(0.5166) | Loss 3.9114(3.8865) | Error 0.1878(0.1828) Steps 658(663.93) | Grad Norm 4.3769(4.3397) | Total Time 14.00(14.00)\n",
      "Iter 6450 | Time 16.3154(16.6506) | Bit/dim 3.6403(3.6295) | Xent 0.5298(0.5177) | Loss 3.9052(3.8883) | Error 0.1911(0.1834) Steps 652(664.43) | Grad Norm 7.9645(4.3498) | Total Time 14.00(14.00)\n",
      "Iter 6460 | Time 16.7051(16.5887) | Bit/dim 3.6631(3.6342) | Xent 0.4874(0.5126) | Loss 3.9068(3.8905) | Error 0.1833(0.1810) Steps 658(663.60) | Grad Norm 4.4454(4.7066) | Total Time 14.00(14.00)\n",
      "Iter 6470 | Time 17.0037(16.6805) | Bit/dim 3.6299(3.6337) | Xent 0.5021(0.5124) | Loss 3.8809(3.8898) | Error 0.1667(0.1822) Steps 676(664.99) | Grad Norm 5.9590(4.6103) | Total Time 14.00(14.00)\n",
      "Iter 6480 | Time 15.9865(16.5766) | Bit/dim 3.6336(3.6311) | Xent 0.5269(0.5191) | Loss 3.8970(3.8907) | Error 0.1956(0.1844) Steps 652(662.59) | Grad Norm 5.4297(4.5371) | Total Time 14.00(14.00)\n",
      "Iter 6490 | Time 16.4003(16.5799) | Bit/dim 3.6474(3.6286) | Xent 0.5488(0.5281) | Loss 3.9218(3.8927) | Error 0.2067(0.1873) Steps 652(662.10) | Grad Norm 5.1935(4.7796) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 86.9439, Epoch Time 1018.3897(957.7098), Bit/dim 3.6442(best: 3.6264), Xent 0.7265, Loss 4.0075, Error 0.2407(best: 0.2283)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 16.6018(16.5560) | Bit/dim 3.6308(3.6305) | Xent 0.5151(0.5256) | Loss 3.8884(3.8933) | Error 0.1833(0.1876) Steps 652(662.41) | Grad Norm 2.7123(4.6892) | Total Time 14.00(14.00)\n",
      "Iter 6510 | Time 16.5869(16.5444) | Bit/dim 3.6576(3.6295) | Xent 0.4660(0.5127) | Loss 3.8906(3.8859) | Error 0.1756(0.1839) Steps 670(664.14) | Grad Norm 3.9711(4.2061) | Total Time 14.00(14.00)\n",
      "Iter 6520 | Time 15.8013(16.4854) | Bit/dim 3.6035(3.6311) | Xent 0.5150(0.5125) | Loss 3.8610(3.8874) | Error 0.1911(0.1832) Steps 652(663.46) | Grad Norm 3.8939(4.2553) | Total Time 14.00(14.00)\n",
      "Iter 6530 | Time 16.7934(16.5449) | Bit/dim 3.6542(3.6313) | Xent 0.5400(0.5163) | Loss 3.9242(3.8894) | Error 0.2111(0.1849) Steps 664(665.79) | Grad Norm 5.0002(4.3648) | Total Time 14.00(14.00)\n",
      "Iter 6540 | Time 16.4345(16.5969) | Bit/dim 3.6266(3.6267) | Xent 0.4685(0.5090) | Loss 3.8609(3.8812) | Error 0.1611(0.1813) Steps 682(668.43) | Grad Norm 2.8526(4.0900) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 86.8957, Epoch Time 1015.7937(959.4524), Bit/dim 3.6289(best: 3.6264), Xent 0.6840, Loss 3.9709, Error 0.2282(best: 0.2283)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 17.0322(16.6293) | Bit/dim 3.6473(3.6273) | Xent 0.5262(0.5060) | Loss 3.9104(3.8803) | Error 0.1856(0.1811) Steps 670(669.00) | Grad Norm 4.9349(4.1551) | Total Time 14.00(14.00)\n",
      "Iter 6560 | Time 16.7204(16.5779) | Bit/dim 3.6219(3.6290) | Xent 0.5786(0.5131) | Loss 3.9113(3.8855) | Error 0.2067(0.1819) Steps 646(667.24) | Grad Norm 6.2689(4.4135) | Total Time 14.00(14.00)\n",
      "Iter 6570 | Time 16.6687(16.5727) | Bit/dim 3.6346(3.6265) | Xent 0.5122(0.5109) | Loss 3.8907(3.8820) | Error 0.1944(0.1818) Steps 664(665.67) | Grad Norm 3.7865(4.2369) | Total Time 14.00(14.00)\n",
      "Iter 6580 | Time 16.5021(16.6090) | Bit/dim 3.6260(3.6257) | Xent 0.4851(0.5016) | Loss 3.8686(3.8765) | Error 0.1622(0.1779) Steps 664(665.30) | Grad Norm 3.9098(3.9870) | Total Time 14.00(14.00)\n",
      "Iter 6590 | Time 16.8097(16.6274) | Bit/dim 3.6271(3.6255) | Xent 0.5093(0.5079) | Loss 3.8817(3.8795) | Error 0.1856(0.1807) Steps 676(666.97) | Grad Norm 5.9143(4.2392) | Total Time 14.00(14.00)\n",
      "Iter 6600 | Time 17.2639(16.7212) | Bit/dim 3.6298(3.6249) | Xent 0.4895(0.5088) | Loss 3.8745(3.8793) | Error 0.1800(0.1806) Steps 682(668.56) | Grad Norm 3.1087(4.1835) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 88.3738, Epoch Time 1023.2653(961.3667), Bit/dim 3.6248(best: 3.6264), Xent 0.6943, Loss 3.9719, Error 0.2345(best: 0.2282)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 16.4208(16.6874) | Bit/dim 3.6246(3.6223) | Xent 0.5024(0.5053) | Loss 3.8758(3.8749) | Error 0.1800(0.1797) Steps 676(669.85) | Grad Norm 6.5353(4.3325) | Total Time 14.00(14.00)\n",
      "Iter 6620 | Time 16.9077(16.7274) | Bit/dim 3.6408(3.6252) | Xent 0.4915(0.5165) | Loss 3.8866(3.8834) | Error 0.1789(0.1839) Steps 676(671.16) | Grad Norm 6.1219(4.8703) | Total Time 14.00(14.00)\n",
      "Iter 6630 | Time 16.7592(16.7601) | Bit/dim 3.6506(3.6255) | Xent 0.5275(0.5140) | Loss 3.9144(3.8825) | Error 0.1789(0.1826) Steps 670(671.58) | Grad Norm 3.4372(4.8279) | Total Time 14.00(14.00)\n",
      "Iter 6640 | Time 15.9469(16.6707) | Bit/dim 3.6221(3.6284) | Xent 0.5426(0.5098) | Loss 3.8934(3.8833) | Error 0.1933(0.1814) Steps 670(670.88) | Grad Norm 2.4615(4.4130) | Total Time 14.00(14.00)\n",
      "Iter 6650 | Time 16.5289(16.7500) | Bit/dim 3.6177(3.6277) | Xent 0.5193(0.5046) | Loss 3.8774(3.8800) | Error 0.1856(0.1799) Steps 658(671.96) | Grad Norm 3.7594(4.1738) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 88.8329, Epoch Time 1027.5449(963.3521), Bit/dim 3.6221(best: 3.6248), Xent 0.6616, Loss 3.9529, Error 0.2274(best: 0.2282)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 16.5720(16.7346) | Bit/dim 3.6297(3.6273) | Xent 0.4616(0.4941) | Loss 3.8604(3.8744) | Error 0.1711(0.1761) Steps 676(672.86) | Grad Norm 2.7991(3.8505) | Total Time 14.00(14.00)\n",
      "Iter 6670 | Time 16.9811(16.7216) | Bit/dim 3.6193(3.6250) | Xent 0.5132(0.4907) | Loss 3.8759(3.8704) | Error 0.1978(0.1751) Steps 682(674.21) | Grad Norm 3.9224(3.8629) | Total Time 14.00(14.00)\n",
      "Iter 6680 | Time 16.2507(16.7067) | Bit/dim 3.6067(3.6221) | Xent 0.5385(0.4908) | Loss 3.8759(3.8675) | Error 0.1889(0.1741) Steps 658(671.91) | Grad Norm 4.3048(3.7552) | Total Time 14.00(14.00)\n",
      "Iter 6690 | Time 17.2114(16.6814) | Bit/dim 3.6095(3.6206) | Xent 0.5183(0.4952) | Loss 3.8687(3.8682) | Error 0.1911(0.1752) Steps 676(672.19) | Grad Norm 3.6667(3.9743) | Total Time 14.00(14.00)\n",
      "Iter 6700 | Time 16.5896(16.7200) | Bit/dim 3.6338(3.6252) | Xent 0.6168(0.5029) | Loss 3.9422(3.8767) | Error 0.2200(0.1782) Steps 676(672.31) | Grad Norm 9.3862(4.3123) | Total Time 14.00(14.00)\n",
      "Iter 6710 | Time 17.3606(16.7639) | Bit/dim 3.6257(3.6275) | Xent 0.4856(0.5124) | Loss 3.8685(3.8837) | Error 0.1656(0.1821) Steps 676(672.39) | Grad Norm 3.3555(4.4941) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 88.8327, Epoch Time 1026.3077(965.2408), Bit/dim 3.6408(best: 3.6221), Xent 0.6852, Loss 3.9835, Error 0.2296(best: 0.2274)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 17.2285(16.7653) | Bit/dim 3.6419(3.6279) | Xent 0.5172(0.5074) | Loss 3.9005(3.8816) | Error 0.1889(0.1813) Steps 670(672.94) | Grad Norm 6.8193(4.4586) | Total Time 14.00(14.00)\n",
      "Iter 6730 | Time 16.6393(16.7645) | Bit/dim 3.6756(3.6303) | Xent 0.5154(0.5056) | Loss 3.9333(3.8831) | Error 0.1733(0.1800) Steps 658(672.41) | Grad Norm 3.9038(4.3136) | Total Time 14.00(14.00)\n",
      "Iter 6740 | Time 16.8411(16.7964) | Bit/dim 3.6301(3.6307) | Xent 0.4387(0.4938) | Loss 3.8494(3.8777) | Error 0.1722(0.1768) Steps 682(672.63) | Grad Norm 3.6218(4.1548) | Total Time 14.00(14.00)\n",
      "Iter 6750 | Time 16.6879(16.7767) | Bit/dim 3.5783(3.6222) | Xent 0.4914(0.4908) | Loss 3.8240(3.8676) | Error 0.1744(0.1752) Steps 664(674.84) | Grad Norm 3.3100(3.8737) | Total Time 14.00(14.00)\n",
      "Iter 6760 | Time 16.8963(16.7644) | Bit/dim 3.6453(3.6229) | Xent 0.5719(0.5002) | Loss 3.9313(3.8730) | Error 0.2033(0.1790) Steps 676(674.12) | Grad Norm 3.4596(4.1009) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 89.4199, Epoch Time 1030.2892(967.1922), Bit/dim 3.6284(best: 3.6221), Xent 0.6616, Loss 3.9592, Error 0.2230(best: 0.2274)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 16.7287(16.7732) | Bit/dim 3.6377(3.6266) | Xent 0.4752(0.4946) | Loss 3.8753(3.8738) | Error 0.1700(0.1771) Steps 664(673.39) | Grad Norm 2.6942(3.8989) | Total Time 14.00(14.00)\n",
      "Iter 6780 | Time 17.0610(16.8219) | Bit/dim 3.6305(3.6231) | Xent 0.4628(0.4797) | Loss 3.8619(3.8629) | Error 0.1667(0.1711) Steps 688(675.13) | Grad Norm 3.8136(3.7096) | Total Time 14.00(14.00)\n",
      "Iter 6790 | Time 17.1600(16.8747) | Bit/dim 3.5859(3.6204) | Xent 0.4741(0.4809) | Loss 3.8230(3.8608) | Error 0.1611(0.1721) Steps 682(673.94) | Grad Norm 4.0982(3.7369) | Total Time 14.00(14.00)\n",
      "Iter 6800 | Time 16.4013(16.8711) | Bit/dim 3.6338(3.6189) | Xent 0.5156(0.4840) | Loss 3.8915(3.8609) | Error 0.1833(0.1723) Steps 676(675.79) | Grad Norm 4.2953(3.8665) | Total Time 14.00(14.00)\n",
      "Iter 6810 | Time 16.8992(16.8268) | Bit/dim 3.6149(3.6207) | Xent 0.4537(0.4812) | Loss 3.8418(3.8614) | Error 0.1611(0.1715) Steps 688(675.08) | Grad Norm 3.4308(3.7931) | Total Time 14.00(14.00)\n",
      "Iter 6820 | Time 16.8593(16.8770) | Bit/dim 3.6429(3.6239) | Xent 0.4756(0.4827) | Loss 3.8807(3.8652) | Error 0.1789(0.1717) Steps 688(677.55) | Grad Norm 4.8084(3.8502) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 89.9201, Epoch Time 1037.0334(969.2874), Bit/dim 3.6273(best: 3.6221), Xent 0.6932, Loss 3.9739, Error 0.2304(best: 0.2230)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 16.4675(16.8912) | Bit/dim 3.6159(3.6245) | Xent 0.4924(0.4789) | Loss 3.8621(3.8640) | Error 0.1678(0.1702) Steps 688(680.01) | Grad Norm 5.5914(3.9590) | Total Time 14.00(14.00)\n",
      "Iter 6840 | Time 17.3714(16.8859) | Bit/dim 3.6287(3.6228) | Xent 0.5524(0.4801) | Loss 3.9049(3.8629) | Error 0.1856(0.1698) Steps 688(680.76) | Grad Norm 6.4774(4.2941) | Total Time 14.00(14.00)\n",
      "Iter 6850 | Time 17.6396(16.9137) | Bit/dim 3.6210(3.6219) | Xent 0.5182(0.4883) | Loss 3.8800(3.8660) | Error 0.1756(0.1736) Steps 694(681.66) | Grad Norm 4.7131(4.4210) | Total Time 14.00(14.00)\n",
      "Iter 6860 | Time 16.6730(16.9279) | Bit/dim 3.6331(3.6216) | Xent 0.4680(0.4892) | Loss 3.8671(3.8662) | Error 0.1622(0.1740) Steps 688(681.95) | Grad Norm 2.7167(4.0985) | Total Time 14.00(14.00)\n",
      "Iter 6870 | Time 17.2614(16.9648) | Bit/dim 3.5968(3.6218) | Xent 0.4989(0.4800) | Loss 3.8463(3.8618) | Error 0.1878(0.1708) Steps 664(683.23) | Grad Norm 2.3049(3.8876) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 87.6925, Epoch Time 1038.0353(971.3499), Bit/dim 3.6243(best: 3.6221), Xent 0.6846, Loss 3.9666, Error 0.2319(best: 0.2230)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 17.2581(16.9529) | Bit/dim 3.6008(3.6249) | Xent 0.4735(0.4766) | Loss 3.8375(3.8632) | Error 0.1678(0.1688) Steps 694(682.60) | Grad Norm 4.7907(3.8588) | Total Time 14.00(14.00)\n",
      "Iter 6890 | Time 16.5710(16.9118) | Bit/dim 3.6450(3.6286) | Xent 0.4958(0.4763) | Loss 3.8929(3.8668) | Error 0.1733(0.1683) Steps 688(682.50) | Grad Norm 4.4735(4.0701) | Total Time 14.00(14.00)\n",
      "Iter 6900 | Time 16.9255(16.8963) | Bit/dim 3.5964(3.6247) | Xent 0.5123(0.4746) | Loss 3.8526(3.8620) | Error 0.1889(0.1686) Steps 676(683.33) | Grad Norm 3.6446(3.9715) | Total Time 14.00(14.00)\n",
      "Iter 6910 | Time 16.8110(16.8964) | Bit/dim 3.6300(3.6247) | Xent 0.4837(0.4720) | Loss 3.8719(3.8608) | Error 0.1678(0.1667) Steps 694(683.21) | Grad Norm 3.0696(3.8664) | Total Time 14.00(14.00)\n",
      "Iter 6920 | Time 16.9164(16.9289) | Bit/dim 3.6173(3.6236) | Xent 0.4247(0.4722) | Loss 3.8297(3.8597) | Error 0.1556(0.1682) Steps 682(682.54) | Grad Norm 2.8441(3.8988) | Total Time 14.00(14.00)\n",
      "Iter 6930 | Time 17.0653(17.0171) | Bit/dim 3.6210(3.6218) | Xent 0.4795(0.4731) | Loss 3.8608(3.8583) | Error 0.1733(0.1688) Steps 676(683.51) | Grad Norm 3.9515(3.9192) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 88.4402, Epoch Time 1039.2635(973.3873), Bit/dim 3.6223(best: 3.6221), Xent 0.6660, Loss 3.9553, Error 0.2233(best: 0.2230)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 16.9652(17.0277) | Bit/dim 3.5781(3.6220) | Xent 0.4854(0.4717) | Loss 3.8208(3.8578) | Error 0.1722(0.1689) Steps 694(683.16) | Grad Norm 5.0314(3.8762) | Total Time 14.00(14.00)\n",
      "Iter 6950 | Time 17.2532(17.0398) | Bit/dim 3.6381(3.6200) | Xent 0.4465(0.4739) | Loss 3.8613(3.8570) | Error 0.1589(0.1691) Steps 706(684.57) | Grad Norm 4.3837(4.2585) | Total Time 14.00(14.00)\n",
      "Iter 6960 | Time 17.4186(17.1196) | Bit/dim 3.6241(3.6229) | Xent 0.5070(0.4745) | Loss 3.8776(3.8602) | Error 0.1856(0.1702) Steps 700(687.41) | Grad Norm 3.9875(4.3124) | Total Time 14.00(14.00)\n",
      "Iter 6970 | Time 16.7985(17.0983) | Bit/dim 3.6410(3.6227) | Xent 0.5128(0.4796) | Loss 3.8974(3.8625) | Error 0.1822(0.1711) Steps 694(689.84) | Grad Norm 5.7731(4.3426) | Total Time 14.00(14.00)\n",
      "Iter 6980 | Time 17.2436(17.1232) | Bit/dim 3.6214(3.6218) | Xent 0.4688(0.4773) | Loss 3.8558(3.8605) | Error 0.1644(0.1700) Steps 682(690.59) | Grad Norm 4.3151(4.2190) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 88.2319, Epoch Time 1049.3671(975.6667), Bit/dim 3.6248(best: 3.6221), Xent 0.6936, Loss 3.9716, Error 0.2273(best: 0.2230)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 16.5571(17.0763) | Bit/dim 3.6237(3.6215) | Xent 0.5122(0.4744) | Loss 3.8798(3.8587) | Error 0.1744(0.1693) Steps 676(688.53) | Grad Norm 5.3594(4.1231) | Total Time 14.00(14.00)\n",
      "Iter 7000 | Time 16.7145(16.9950) | Bit/dim 3.6460(3.6201) | Xent 0.4393(0.4672) | Loss 3.8656(3.8537) | Error 0.1489(0.1665) Steps 646(686.41) | Grad Norm 3.0416(3.9379) | Total Time 14.00(14.00)\n",
      "Iter 7010 | Time 16.9511(16.9433) | Bit/dim 3.6037(3.6202) | Xent 0.4605(0.4622) | Loss 3.8339(3.8512) | Error 0.1711(0.1655) Steps 694(685.49) | Grad Norm 3.8688(3.8907) | Total Time 14.00(14.00)\n",
      "Iter 7020 | Time 17.9179(17.0709) | Bit/dim 3.6097(3.6182) | Xent 0.4932(0.4634) | Loss 3.8563(3.8499) | Error 0.1744(0.1659) Steps 712(687.11) | Grad Norm 5.8157(4.0526) | Total Time 14.00(14.00)\n",
      "Iter 7030 | Time 17.1926(17.1356) | Bit/dim 3.6272(3.6193) | Xent 0.4600(0.4690) | Loss 3.8572(3.8537) | Error 0.1633(0.1684) Steps 676(687.52) | Grad Norm 2.7121(3.9374) | Total Time 14.00(14.00)\n",
      "Iter 7040 | Time 17.4011(17.1776) | Bit/dim 3.5871(3.6198) | Xent 0.4764(0.4600) | Loss 3.8253(3.8498) | Error 0.1678(0.1657) Steps 706(689.64) | Grad Norm 2.6620(3.6134) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 88.4260, Epoch Time 1045.6022(977.7647), Bit/dim 3.6192(best: 3.6221), Xent 0.6730, Loss 3.9557, Error 0.2228(best: 0.2230)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 17.1255(17.2082) | Bit/dim 3.6429(3.6171) | Xent 0.3995(0.4485) | Loss 3.8426(3.8414) | Error 0.1367(0.1621) Steps 682(690.54) | Grad Norm 3.7303(3.5213) | Total Time 14.00(14.00)\n",
      "Iter 7060 | Time 18.0405(17.2387) | Bit/dim 3.6450(3.6207) | Xent 0.4353(0.4507) | Loss 3.8627(3.8460) | Error 0.1611(0.1627) Steps 676(691.61) | Grad Norm 4.1798(3.8982) | Total Time 14.00(14.00)\n",
      "Iter 7070 | Time 17.5603(17.2941) | Bit/dim 3.6337(3.6214) | Xent 0.5133(0.4553) | Loss 3.8903(3.8490) | Error 0.1889(0.1640) Steps 694(693.59) | Grad Norm 4.4367(3.9158) | Total Time 14.00(14.00)\n",
      "Iter 7080 | Time 18.0771(17.3565) | Bit/dim 3.6390(3.6208) | Xent 0.4414(0.4600) | Loss 3.8597(3.8508) | Error 0.1589(0.1654) Steps 712(694.45) | Grad Norm 3.6154(4.0487) | Total Time 14.00(14.00)\n",
      "Iter 7090 | Time 16.9095(17.3317) | Bit/dim 3.5947(3.6182) | Xent 0.4936(0.4620) | Loss 3.8415(3.8492) | Error 0.1722(0.1651) Steps 682(696.14) | Grad Norm 5.9649(4.1190) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 87.8517, Epoch Time 1060.9351(980.2599), Bit/dim 3.6214(best: 3.6192), Xent 0.6739, Loss 3.9583, Error 0.2258(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 17.1484(17.3466) | Bit/dim 3.6148(3.6179) | Xent 0.4310(0.4610) | Loss 3.8303(3.8484) | Error 0.1556(0.1647) Steps 700(696.52) | Grad Norm 3.0713(4.1986) | Total Time 14.00(14.00)\n",
      "Iter 7110 | Time 17.7345(17.3096) | Bit/dim 3.5973(3.6165) | Xent 0.4653(0.4590) | Loss 3.8300(3.8461) | Error 0.1667(0.1631) Steps 724(696.70) | Grad Norm 4.1443(4.0883) | Total Time 14.00(14.00)\n",
      "Iter 7120 | Time 17.1361(17.2973) | Bit/dim 3.6168(3.6181) | Xent 0.4713(0.4605) | Loss 3.8525(3.8484) | Error 0.1589(0.1647) Steps 682(695.62) | Grad Norm 5.9935(4.1424) | Total Time 14.00(14.00)\n",
      "Iter 7130 | Time 17.2374(17.2754) | Bit/dim 3.6273(3.6188) | Xent 0.3865(0.4602) | Loss 3.8206(3.8489) | Error 0.1356(0.1647) Steps 682(696.38) | Grad Norm 2.5673(3.9144) | Total Time 14.00(14.00)\n",
      "Iter 7140 | Time 16.6641(17.2370) | Bit/dim 3.6059(3.6209) | Xent 0.4711(0.4663) | Loss 3.8415(3.8540) | Error 0.1811(0.1662) Steps 670(694.68) | Grad Norm 3.7948(3.9849) | Total Time 14.00(14.00)\n",
      "Iter 7150 | Time 17.2341(17.2954) | Bit/dim 3.5964(3.6212) | Xent 0.4808(0.4681) | Loss 3.8368(3.8552) | Error 0.1700(0.1662) Steps 670(694.87) | Grad Norm 4.0032(3.9246) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 89.1395, Epoch Time 1056.9529(982.5607), Bit/dim 3.6200(best: 3.6192), Xent 0.7133, Loss 3.9767, Error 0.2357(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 17.0977(17.2789) | Bit/dim 3.6296(3.6184) | Xent 0.4422(0.4630) | Loss 3.8506(3.8499) | Error 0.1556(0.1647) Steps 694(695.87) | Grad Norm 4.6360(4.0493) | Total Time 14.00(14.00)\n",
      "Iter 7170 | Time 16.6376(17.2680) | Bit/dim 3.5999(3.6195) | Xent 0.4543(0.4612) | Loss 3.8270(3.8501) | Error 0.1678(0.1651) Steps 694(695.57) | Grad Norm 2.6559(4.0853) | Total Time 14.00(14.00)\n",
      "Iter 7180 | Time 17.4889(17.3217) | Bit/dim 3.6195(3.6203) | Xent 0.4637(0.4651) | Loss 3.8514(3.8528) | Error 0.1589(0.1654) Steps 706(697.25) | Grad Norm 3.8431(4.1171) | Total Time 14.00(14.00)\n",
      "Iter 7190 | Time 17.5980(17.3081) | Bit/dim 3.6278(3.6211) | Xent 0.5392(0.4692) | Loss 3.8974(3.8556) | Error 0.1967(0.1671) Steps 706(695.23) | Grad Norm 3.6495(4.2066) | Total Time 14.00(14.00)\n",
      "Iter 7200 | Time 17.6950(17.2735) | Bit/dim 3.6257(3.6202) | Xent 0.5298(0.4741) | Loss 3.8906(3.8573) | Error 0.1922(0.1691) Steps 676(695.50) | Grad Norm 7.0655(4.2440) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 89.1100, Epoch Time 1056.1176(984.7674), Bit/dim 3.6257(best: 3.6192), Xent 0.7219, Loss 3.9867, Error 0.2382(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 17.7434(17.2403) | Bit/dim 3.6536(3.6202) | Xent 0.3626(0.4721) | Loss 3.8349(3.8562) | Error 0.1244(0.1688) Steps 706(694.63) | Grad Norm 4.0014(4.4748) | Total Time 14.00(14.00)\n",
      "Iter 7220 | Time 17.5583(17.3041) | Bit/dim 3.6128(3.6191) | Xent 0.4058(0.4611) | Loss 3.8157(3.8496) | Error 0.1378(0.1650) Steps 694(696.43) | Grad Norm 3.6319(4.3339) | Total Time 14.00(14.00)\n",
      "Iter 7230 | Time 17.2769(17.3059) | Bit/dim 3.6148(3.6203) | Xent 0.4152(0.4583) | Loss 3.8224(3.8494) | Error 0.1411(0.1621) Steps 706(698.08) | Grad Norm 5.1506(4.1284) | Total Time 14.00(14.00)\n",
      "Iter 7240 | Time 17.0806(17.2785) | Bit/dim 3.6232(3.6181) | Xent 0.4292(0.4706) | Loss 3.8378(3.8534) | Error 0.1567(0.1667) Steps 694(698.89) | Grad Norm 3.4702(4.5162) | Total Time 14.00(14.00)\n",
      "Iter 7250 | Time 17.5160(17.3363) | Bit/dim 3.6394(3.6223) | Xent 0.4700(0.4790) | Loss 3.8744(3.8618) | Error 0.1756(0.1698) Steps 688(699.22) | Grad Norm 4.0026(4.7038) | Total Time 14.00(14.00)\n",
      "Iter 7260 | Time 17.3666(17.3561) | Bit/dim 3.6352(3.6229) | Xent 0.4279(0.4817) | Loss 3.8491(3.8638) | Error 0.1478(0.1708) Steps 688(698.72) | Grad Norm 2.9445(4.6122) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 86.0176, Epoch Time 1058.5188(986.9799), Bit/dim 3.6313(best: 3.6192), Xent 0.6880, Loss 3.9753, Error 0.2238(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7270 | Time 17.7393(17.3311) | Bit/dim 3.6563(3.6231) | Xent 0.4300(0.4707) | Loss 3.8713(3.8584) | Error 0.1600(0.1668) Steps 682(698.47) | Grad Norm 4.2275(4.4401) | Total Time 14.00(14.00)\n",
      "Iter 7280 | Time 17.2025(17.2924) | Bit/dim 3.6121(3.6199) | Xent 0.4206(0.4645) | Loss 3.8224(3.8522) | Error 0.1511(0.1644) Steps 694(697.05) | Grad Norm 2.5236(4.0540) | Total Time 14.00(14.00)\n",
      "Iter 7290 | Time 17.3719(17.2957) | Bit/dim 3.6218(3.6193) | Xent 0.4099(0.4555) | Loss 3.8267(3.8471) | Error 0.1544(0.1627) Steps 706(699.31) | Grad Norm 4.1747(3.9299) | Total Time 14.00(14.00)\n",
      "Iter 7300 | Time 17.3294(17.2502) | Bit/dim 3.5804(3.6181) | Xent 0.4670(0.4501) | Loss 3.8140(3.8431) | Error 0.1622(0.1601) Steps 700(696.95) | Grad Norm 3.9922(3.7674) | Total Time 14.00(14.00)\n",
      "Iter 7310 | Time 17.7184(17.2950) | Bit/dim 3.6302(3.6185) | Xent 0.5193(0.4556) | Loss 3.8898(3.8462) | Error 0.1800(0.1624) Steps 700(697.54) | Grad Norm 5.8591(4.0366) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 89.7825, Epoch Time 1057.9625(989.1094), Bit/dim 3.6223(best: 3.6192), Xent 0.6884, Loss 3.9664, Error 0.2274(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7320 | Time 16.8427(17.3392) | Bit/dim 3.6113(3.6199) | Xent 0.4540(0.4552) | Loss 3.8383(3.8475) | Error 0.1589(0.1619) Steps 676(699.63) | Grad Norm 3.0962(4.0451) | Total Time 14.00(14.00)\n",
      "Iter 7330 | Time 17.8644(17.3134) | Bit/dim 3.5810(3.6189) | Xent 0.4939(0.4557) | Loss 3.8280(3.8468) | Error 0.1744(0.1615) Steps 664(696.57) | Grad Norm 3.4392(4.1527) | Total Time 14.00(14.00)\n",
      "Iter 7340 | Time 16.7926(17.3494) | Bit/dim 3.6242(3.6204) | Xent 0.4060(0.4584) | Loss 3.8272(3.8497) | Error 0.1456(0.1626) Steps 706(697.09) | Grad Norm 2.3660(4.2831) | Total Time 14.00(14.00)\n",
      "Iter 7350 | Time 18.0686(17.3705) | Bit/dim 3.6337(3.6209) | Xent 0.4326(0.4555) | Loss 3.8500(3.8487) | Error 0.1544(0.1618) Steps 682(696.87) | Grad Norm 3.4597(4.3286) | Total Time 14.00(14.00)\n",
      "Iter 7360 | Time 17.3308(17.3344) | Bit/dim 3.6283(3.6191) | Xent 0.4441(0.4536) | Loss 3.8503(3.8459) | Error 0.1733(0.1616) Steps 706(696.58) | Grad Norm 3.7396(4.2991) | Total Time 14.00(14.00)\n",
      "Iter 7370 | Time 16.9443(17.3377) | Bit/dim 3.5955(3.6198) | Xent 0.4460(0.4540) | Loss 3.8185(3.8468) | Error 0.1478(0.1612) Steps 700(698.80) | Grad Norm 2.7333(4.2066) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 89.2567, Epoch Time 1060.8019(991.2602), Bit/dim 3.6188(best: 3.6192), Xent 0.6902, Loss 3.9639, Error 0.2272(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7380 | Time 17.2489(17.3219) | Bit/dim 3.6192(3.6207) | Xent 0.4307(0.4497) | Loss 3.8345(3.8456) | Error 0.1444(0.1600) Steps 712(700.42) | Grad Norm 3.2580(4.1263) | Total Time 14.00(14.00)\n",
      "Iter 7390 | Time 17.9040(17.3369) | Bit/dim 3.6314(3.6205) | Xent 0.4518(0.4495) | Loss 3.8573(3.8453) | Error 0.1700(0.1606) Steps 712(702.62) | Grad Norm 3.7746(4.1079) | Total Time 14.00(14.00)\n",
      "Iter 7400 | Time 17.5363(17.4009) | Bit/dim 3.6165(3.6211) | Xent 0.4694(0.4458) | Loss 3.8512(3.8440) | Error 0.1689(0.1586) Steps 706(704.17) | Grad Norm 3.0251(3.9728) | Total Time 14.00(14.00)\n",
      "Iter 7410 | Time 16.9006(17.4159) | Bit/dim 3.6388(3.6172) | Xent 0.3939(0.4402) | Loss 3.8358(3.8373) | Error 0.1478(0.1565) Steps 694(703.96) | Grad Norm 4.3102(3.9115) | Total Time 14.00(14.00)\n",
      "Iter 7420 | Time 17.4641(17.4001) | Bit/dim 3.6125(3.6154) | Xent 0.4224(0.4372) | Loss 3.8237(3.8339) | Error 0.1411(0.1548) Steps 712(704.42) | Grad Norm 3.9836(3.9598) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 92.3101, Epoch Time 1068.1377(993.5665), Bit/dim 3.6249(best: 3.6188), Xent 0.7072, Loss 3.9785, Error 0.2341(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7430 | Time 17.0777(17.4054) | Bit/dim 3.6020(3.6164) | Xent 0.3889(0.4324) | Loss 3.7965(3.8326) | Error 0.1456(0.1538) Steps 700(706.94) | Grad Norm 4.0271(4.0169) | Total Time 14.00(14.00)\n",
      "Iter 7440 | Time 17.1390(17.3749) | Bit/dim 3.6317(3.6174) | Xent 0.3857(0.4304) | Loss 3.8246(3.8326) | Error 0.1367(0.1534) Steps 706(705.89) | Grad Norm 3.9687(4.1115) | Total Time 14.00(14.00)\n",
      "Iter 7450 | Time 17.4820(17.3637) | Bit/dim 3.6047(3.6169) | Xent 0.4219(0.4371) | Loss 3.8156(3.8355) | Error 0.1578(0.1554) Steps 700(705.93) | Grad Norm 5.2317(4.1869) | Total Time 14.00(14.00)\n",
      "Iter 7460 | Time 17.9044(17.3467) | Bit/dim 3.5894(3.6164) | Xent 0.4116(0.4323) | Loss 3.7952(3.8325) | Error 0.1522(0.1539) Steps 694(703.40) | Grad Norm 3.0927(3.9512) | Total Time 14.00(14.00)\n",
      "Iter 7470 | Time 17.5805(17.3556) | Bit/dim 3.5894(3.6149) | Xent 0.4248(0.4389) | Loss 3.8018(3.8343) | Error 0.1489(0.1555) Steps 694(701.87) | Grad Norm 2.3634(3.7874) | Total Time 14.00(14.00)\n",
      "Iter 7480 | Time 17.3348(17.3167) | Bit/dim 3.6277(3.6150) | Xent 0.4374(0.4457) | Loss 3.8464(3.8379) | Error 0.1456(0.1588) Steps 700(699.52) | Grad Norm 2.8572(3.9978) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 86.8263, Epoch Time 1056.4467(995.4529), Bit/dim 3.6194(best: 3.6188), Xent 0.7132, Loss 3.9760, Error 0.2296(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7490 | Time 17.4898(17.2746) | Bit/dim 3.6184(3.6173) | Xent 0.4086(0.4369) | Loss 3.8228(3.8358) | Error 0.1489(0.1563) Steps 700(698.71) | Grad Norm 3.5463(3.7348) | Total Time 14.00(14.00)\n",
      "Iter 7500 | Time 17.9494(17.3326) | Bit/dim 3.5940(3.6115) | Xent 0.4213(0.4276) | Loss 3.8047(3.8253) | Error 0.1511(0.1531) Steps 706(697.17) | Grad Norm 2.1113(3.5632) | Total Time 14.00(14.00)\n",
      "Iter 7510 | Time 17.6299(17.3351) | Bit/dim 3.5988(3.6125) | Xent 0.4435(0.4203) | Loss 3.8205(3.8227) | Error 0.1533(0.1514) Steps 700(695.95) | Grad Norm 2.9366(3.3780) | Total Time 14.00(14.00)\n",
      "Iter 7520 | Time 17.5483(17.3086) | Bit/dim 3.6318(3.6134) | Xent 0.4094(0.4216) | Loss 3.8365(3.8242) | Error 0.1556(0.1512) Steps 682(694.20) | Grad Norm 5.4723(3.8444) | Total Time 14.00(14.00)\n",
      "Iter 7530 | Time 17.4882(17.3172) | Bit/dim 3.5598(3.6153) | Xent 0.4500(0.4333) | Loss 3.7848(3.8319) | Error 0.1678(0.1552) Steps 706(695.97) | Grad Norm 2.8893(4.0447) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 87.9403, Epoch Time 1058.0559(997.3310), Bit/dim 3.6230(best: 3.6188), Xent 0.6859, Loss 3.9659, Error 0.2246(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7540 | Time 17.1192(17.2858) | Bit/dim 3.6601(3.6154) | Xent 0.4572(0.4436) | Loss 3.8887(3.8372) | Error 0.1667(0.1579) Steps 658(694.05) | Grad Norm 3.5568(4.2483) | Total Time 14.00(14.00)\n",
      "Iter 7550 | Time 17.9198(17.3495) | Bit/dim 3.5815(3.6137) | Xent 0.4402(0.4362) | Loss 3.8016(3.8318) | Error 0.1644(0.1557) Steps 688(695.42) | Grad Norm 3.5538(3.9914) | Total Time 14.00(14.00)\n",
      "Iter 7560 | Time 17.3982(17.3065) | Bit/dim 3.6152(3.6150) | Xent 0.3492(0.4337) | Loss 3.7898(3.8318) | Error 0.1233(0.1544) Steps 688(693.94) | Grad Norm 3.2582(4.0605) | Total Time 14.00(14.00)\n",
      "Iter 7570 | Time 17.6749(17.3057) | Bit/dim 3.6328(3.6182) | Xent 0.4745(0.4413) | Loss 3.8701(3.8389) | Error 0.1733(0.1575) Steps 670(694.02) | Grad Norm 4.6290(4.2128) | Total Time 14.00(14.00)\n",
      "Iter 7580 | Time 17.8845(17.3700) | Bit/dim 3.6071(3.6163) | Xent 0.4208(0.4401) | Loss 3.8175(3.8364) | Error 0.1578(0.1577) Steps 700(694.58) | Grad Norm 4.3490(4.1694) | Total Time 14.00(14.00)\n",
      "Iter 7590 | Time 17.1637(17.3512) | Bit/dim 3.5859(3.6168) | Xent 0.4220(0.4407) | Loss 3.7969(3.8371) | Error 0.1544(0.1578) Steps 700(693.76) | Grad Norm 2.5580(4.0694) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 89.6877, Epoch Time 1061.7968(999.2649), Bit/dim 3.6184(best: 3.6188), Xent 0.7000, Loss 3.9684, Error 0.2322(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7600 | Time 16.8821(17.3014) | Bit/dim 3.6296(3.6170) | Xent 0.4311(0.4385) | Loss 3.8451(3.8363) | Error 0.1400(0.1553) Steps 688(696.13) | Grad Norm 3.4498(3.8346) | Total Time 14.00(14.00)\n",
      "Iter 7610 | Time 17.1997(17.3303) | Bit/dim 3.6421(3.6181) | Xent 0.4915(0.4409) | Loss 3.8878(3.8385) | Error 0.1767(0.1565) Steps 706(695.53) | Grad Norm 8.0935(4.2975) | Total Time 14.00(14.00)\n",
      "Iter 7620 | Time 17.3126(17.2449) | Bit/dim 3.6003(3.6195) | Xent 0.4231(0.4395) | Loss 3.8118(3.8392) | Error 0.1478(0.1570) Steps 682(695.24) | Grad Norm 4.9874(4.2875) | Total Time 14.00(14.00)\n",
      "Iter 7630 | Time 17.6064(17.2915) | Bit/dim 3.6232(3.6176) | Xent 0.4119(0.4359) | Loss 3.8292(3.8356) | Error 0.1467(0.1552) Steps 700(697.39) | Grad Norm 4.1611(4.1664) | Total Time 14.00(14.00)\n",
      "Iter 7640 | Time 17.3452(17.2788) | Bit/dim 3.6333(3.6175) | Xent 0.4151(0.4339) | Loss 3.8409(3.8344) | Error 0.1400(0.1543) Steps 688(698.32) | Grad Norm 3.3086(4.0100) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 88.7802, Epoch Time 1056.2177(1000.9735), Bit/dim 3.6218(best: 3.6184), Xent 0.6819, Loss 3.9628, Error 0.2180(best: 0.2228)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7650 | Time 17.4089(17.3194) | Bit/dim 3.5837(3.6144) | Xent 0.4375(0.4265) | Loss 3.8025(3.8276) | Error 0.1567(0.1508) Steps 682(699.41) | Grad Norm 3.1552(3.8057) | Total Time 14.00(14.00)\n",
      "Iter 7660 | Time 16.9951(17.3331) | Bit/dim 3.6078(3.6141) | Xent 0.3440(0.4172) | Loss 3.7798(3.8227) | Error 0.1244(0.1480) Steps 706(698.37) | Grad Norm 2.6566(3.6522) | Total Time 14.00(14.00)\n",
      "Iter 7670 | Time 17.2168(17.3475) | Bit/dim 3.5998(3.6138) | Xent 0.4159(0.4147) | Loss 3.8077(3.8212) | Error 0.1433(0.1467) Steps 694(698.39) | Grad Norm 2.3372(3.7881) | Total Time 14.00(14.00)\n",
      "Iter 7680 | Time 17.1989(17.3254) | Bit/dim 3.5622(3.6125) | Xent 0.4480(0.4112) | Loss 3.7862(3.8181) | Error 0.1678(0.1453) Steps 706(699.19) | Grad Norm 3.7588(3.6612) | Total Time 14.00(14.00)\n",
      "Iter 7690 | Time 17.1802(17.3104) | Bit/dim 3.6227(3.6123) | Xent 0.4503(0.4163) | Loss 3.8478(3.8205) | Error 0.1644(0.1475) Steps 718(701.06) | Grad Norm 4.4690(4.2571) | Total Time 14.00(14.00)\n",
      "Iter 7700 | Time 17.1577(17.3422) | Bit/dim 3.6010(3.6132) | Xent 0.5084(0.4270) | Loss 3.8552(3.8267) | Error 0.1778(0.1518) Steps 688(702.30) | Grad Norm 3.8980(4.0730) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 88.4667, Epoch Time 1060.6805(1002.7647), Bit/dim 3.6203(best: 3.6184), Xent 0.6731, Loss 3.9569, Error 0.2207(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7710 | Time 17.3505(17.3438) | Bit/dim 3.6474(3.6152) | Xent 0.4954(0.4270) | Loss 3.8951(3.8287) | Error 0.1944(0.1514) Steps 694(701.03) | Grad Norm 5.4382(4.1045) | Total Time 14.00(14.00)\n",
      "Iter 7720 | Time 17.3884(17.3684) | Bit/dim 3.6177(3.6156) | Xent 0.3707(0.4238) | Loss 3.8031(3.8275) | Error 0.1311(0.1492) Steps 706(701.20) | Grad Norm 2.5426(4.3050) | Total Time 14.00(14.00)\n",
      "Iter 7730 | Time 17.1782(17.4063) | Bit/dim 3.6166(3.6146) | Xent 0.3729(0.4196) | Loss 3.8031(3.8244) | Error 0.1544(0.1487) Steps 718(703.21) | Grad Norm 2.5087(3.9957) | Total Time 14.00(14.00)\n",
      "Iter 7740 | Time 17.0578(17.3567) | Bit/dim 3.6398(3.6136) | Xent 0.4016(0.4190) | Loss 3.8406(3.8231) | Error 0.1411(0.1481) Steps 706(701.91) | Grad Norm 3.9820(4.0509) | Total Time 14.00(14.00)\n",
      "Iter 7750 | Time 17.8298(17.4016) | Bit/dim 3.6219(3.6133) | Xent 0.4700(0.4188) | Loss 3.8569(3.8227) | Error 0.1678(0.1488) Steps 724(701.88) | Grad Norm 3.4207(4.0049) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 89.4660, Epoch Time 1064.3242(1004.6115), Bit/dim 3.6118(best: 3.6184), Xent 0.7023, Loss 3.9630, Error 0.2214(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7760 | Time 17.9975(17.4077) | Bit/dim 3.6195(3.6124) | Xent 0.3700(0.4181) | Loss 3.8045(3.8215) | Error 0.1311(0.1482) Steps 688(702.67) | Grad Norm 2.7798(4.0072) | Total Time 14.00(14.00)\n",
      "Iter 7770 | Time 17.3978(17.4306) | Bit/dim 3.6049(3.6126) | Xent 0.3840(0.4128) | Loss 3.7969(3.8190) | Error 0.1367(0.1466) Steps 706(702.71) | Grad Norm 3.6586(3.9434) | Total Time 14.00(14.00)\n",
      "Iter 7780 | Time 17.1361(17.4307) | Bit/dim 3.6311(3.6129) | Xent 0.3913(0.4109) | Loss 3.8268(3.8183) | Error 0.1356(0.1459) Steps 724(703.15) | Grad Norm 5.2826(4.1075) | Total Time 14.00(14.00)\n",
      "Iter 7790 | Time 17.2156(17.4378) | Bit/dim 3.6497(3.6139) | Xent 0.3809(0.4056) | Loss 3.8401(3.8167) | Error 0.1289(0.1446) Steps 706(702.29) | Grad Norm 3.9517(3.9489) | Total Time 14.00(14.00)\n",
      "Iter 7800 | Time 17.3827(17.4261) | Bit/dim 3.6212(3.6151) | Xent 0.4108(0.4101) | Loss 3.8267(3.8202) | Error 0.1378(0.1462) Steps 700(703.53) | Grad Norm 4.0439(3.9173) | Total Time 14.00(14.00)\n",
      "Iter 7810 | Time 17.7920(17.4413) | Bit/dim 3.6085(3.6141) | Xent 0.4619(0.4196) | Loss 3.8395(3.8239) | Error 0.1700(0.1497) Steps 706(703.47) | Grad Norm 4.8371(4.1760) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 89.5647, Epoch Time 1067.1324(1006.4872), Bit/dim 3.6226(best: 3.6118), Xent 0.7709, Loss 4.0080, Error 0.2515(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7820 | Time 17.4701(17.4700) | Bit/dim 3.5748(3.6142) | Xent 0.4206(0.4208) | Loss 3.7850(3.8246) | Error 0.1467(0.1491) Steps 718(704.74) | Grad Norm 3.0358(4.3605) | Total Time 14.00(14.00)\n",
      "Iter 7830 | Time 17.2775(17.4647) | Bit/dim 3.5923(3.6152) | Xent 0.4583(0.4197) | Loss 3.8215(3.8251) | Error 0.1600(0.1494) Steps 706(704.40) | Grad Norm 4.6737(4.2102) | Total Time 14.00(14.00)\n",
      "Iter 7840 | Time 17.2183(17.4960) | Bit/dim 3.6212(3.6163) | Xent 0.3816(0.4150) | Loss 3.8119(3.8238) | Error 0.1289(0.1469) Steps 694(703.98) | Grad Norm 2.8600(4.3095) | Total Time 14.00(14.00)\n",
      "Iter 7850 | Time 17.3222(17.5141) | Bit/dim 3.6498(3.6148) | Xent 0.4093(0.4140) | Loss 3.8545(3.8218) | Error 0.1433(0.1465) Steps 718(704.38) | Grad Norm 5.1729(4.4025) | Total Time 14.00(14.00)\n",
      "Iter 7860 | Time 16.5784(17.5097) | Bit/dim 3.6170(3.6174) | Xent 0.4525(0.4257) | Loss 3.8432(3.8303) | Error 0.1656(0.1509) Steps 694(704.53) | Grad Norm 4.1160(4.8167) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 88.4950, Epoch Time 1070.6633(1008.4124), Bit/dim 3.6297(best: 3.6118), Xent 0.7156, Loss 3.9875, Error 0.2409(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7870 | Time 17.2661(17.4737) | Bit/dim 3.6288(3.6192) | Xent 0.4281(0.4310) | Loss 3.8429(3.8348) | Error 0.1544(0.1531) Steps 706(704.47) | Grad Norm 3.4784(4.9732) | Total Time 14.00(14.00)\n",
      "Iter 7880 | Time 17.2824(17.4573) | Bit/dim 3.6255(3.6192) | Xent 0.4664(0.4294) | Loss 3.8587(3.8339) | Error 0.1544(0.1522) Steps 712(705.01) | Grad Norm 6.6736(4.8580) | Total Time 14.00(14.00)\n",
      "Iter 7890 | Time 17.3335(17.4752) | Bit/dim 3.6298(3.6179) | Xent 0.4127(0.4226) | Loss 3.8362(3.8292) | Error 0.1444(0.1493) Steps 706(705.75) | Grad Norm 3.8071(4.5705) | Total Time 14.00(14.00)\n",
      "Iter 7900 | Time 17.3268(17.5233) | Bit/dim 3.5824(3.6153) | Xent 0.3917(0.4185) | Loss 3.7782(3.8246) | Error 0.1489(0.1497) Steps 682(705.56) | Grad Norm 2.4382(4.2413) | Total Time 14.00(14.00)\n",
      "Iter 7910 | Time 17.3226(17.4823) | Bit/dim 3.5982(3.6106) | Xent 0.4068(0.4173) | Loss 3.8017(3.8192) | Error 0.1411(0.1485) Steps 706(705.18) | Grad Norm 4.3574(3.9387) | Total Time 14.00(14.00)\n",
      "Iter 7920 | Time 16.8769(17.4702) | Bit/dim 3.6258(3.6127) | Xent 0.4221(0.4176) | Loss 3.8368(3.8215) | Error 0.1433(0.1482) Steps 706(707.44) | Grad Norm 3.5192(4.0295) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 90.1830, Epoch Time 1068.4447(1010.2134), Bit/dim 3.6140(best: 3.6118), Xent 0.6861, Loss 3.9571, Error 0.2228(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7930 | Time 17.4670(17.4470) | Bit/dim 3.5586(3.6116) | Xent 0.3666(0.4091) | Loss 3.7419(3.8162) | Error 0.1322(0.1451) Steps 712(709.26) | Grad Norm 2.3812(3.8469) | Total Time 14.00(14.00)\n",
      "Iter 7940 | Time 17.1107(17.4600) | Bit/dim 3.5930(3.6119) | Xent 0.3379(0.4110) | Loss 3.7620(3.8174) | Error 0.1167(0.1454) Steps 694(710.29) | Grad Norm 2.7135(3.9646) | Total Time 14.00(14.00)\n",
      "Iter 7950 | Time 17.6484(17.5043) | Bit/dim 3.6214(3.6101) | Xent 0.4041(0.4097) | Loss 3.8234(3.8150) | Error 0.1567(0.1462) Steps 718(710.15) | Grad Norm 3.6219(3.9412) | Total Time 14.00(14.00)\n",
      "Iter 7960 | Time 17.7305(17.5301) | Bit/dim 3.6446(3.6121) | Xent 0.3093(0.4096) | Loss 3.7993(3.8168) | Error 0.1100(0.1459) Steps 706(709.83) | Grad Norm 2.7049(4.2676) | Total Time 14.00(14.00)\n",
      "Iter 7970 | Time 17.3973(17.5288) | Bit/dim 3.6112(3.6149) | Xent 0.4344(0.4112) | Loss 3.8284(3.8205) | Error 0.1622(0.1463) Steps 712(709.19) | Grad Norm 6.5575(4.2657) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 89.2748, Epoch Time 1070.0145(1012.0074), Bit/dim 3.6229(best: 3.6118), Xent 0.7240, Loss 3.9849, Error 0.2281(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7980 | Time 17.3846(17.4786) | Bit/dim 3.6382(3.6144) | Xent 0.4239(0.4168) | Loss 3.8501(3.8228) | Error 0.1522(0.1490) Steps 718(708.62) | Grad Norm 4.5178(4.4658) | Total Time 14.00(14.00)\n",
      "Iter 7990 | Time 17.6574(17.4547) | Bit/dim 3.6191(3.6155) | Xent 0.4056(0.4152) | Loss 3.8219(3.8231) | Error 0.1500(0.1493) Steps 700(707.36) | Grad Norm 3.0918(4.3335) | Total Time 14.00(14.00)\n",
      "Iter 8000 | Time 17.7524(17.4692) | Bit/dim 3.5922(3.6141) | Xent 0.3742(0.4122) | Loss 3.7793(3.8202) | Error 0.1267(0.1472) Steps 718(707.18) | Grad Norm 4.7846(4.4099) | Total Time 14.00(14.00)\n",
      "Iter 8010 | Time 17.5148(17.4549) | Bit/dim 3.5952(3.6146) | Xent 0.4424(0.4199) | Loss 3.8164(3.8246) | Error 0.1589(0.1494) Steps 706(706.55) | Grad Norm 5.1437(4.5293) | Total Time 14.00(14.00)\n",
      "Iter 8020 | Time 17.7353(17.4427) | Bit/dim 3.5677(3.6131) | Xent 0.4233(0.4208) | Loss 3.7794(3.8235) | Error 0.1478(0.1494) Steps 712(706.44) | Grad Norm 3.6756(4.4160) | Total Time 14.00(14.00)\n",
      "Iter 8030 | Time 17.1167(17.4639) | Bit/dim 3.6475(3.6105) | Xent 0.3935(0.4143) | Loss 3.8443(3.8177) | Error 0.1344(0.1481) Steps 694(709.01) | Grad Norm 5.1260(4.2253) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 88.3070, Epoch Time 1065.3386(1013.6074), Bit/dim 3.6132(best: 3.6118), Xent 0.7478, Loss 3.9870, Error 0.2355(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8040 | Time 17.8579(17.4983) | Bit/dim 3.6190(3.6086) | Xent 0.4482(0.4090) | Loss 3.8431(3.8131) | Error 0.1589(0.1462) Steps 724(710.36) | Grad Norm 4.3035(4.2479) | Total Time 14.00(14.00)\n",
      "Iter 8050 | Time 17.3265(17.4855) | Bit/dim 3.5718(3.6078) | Xent 0.4440(0.4092) | Loss 3.7938(3.8125) | Error 0.1367(0.1458) Steps 724(712.05) | Grad Norm 3.9526(4.1657) | Total Time 14.00(14.00)\n",
      "Iter 8060 | Time 17.5051(17.4611) | Bit/dim 3.6176(3.6092) | Xent 0.3890(0.4093) | Loss 3.8121(3.8138) | Error 0.1444(0.1462) Steps 694(710.94) | Grad Norm 4.5110(4.3994) | Total Time 14.00(14.00)\n",
      "Iter 8070 | Time 17.0590(17.5024) | Bit/dim 3.5907(3.6115) | Xent 0.4184(0.4092) | Loss 3.7998(3.8160) | Error 0.1544(0.1463) Steps 724(711.70) | Grad Norm 5.2732(4.3281) | Total Time 14.00(14.00)\n",
      "Iter 8080 | Time 17.5098(17.5099) | Bit/dim 3.6322(3.6122) | Xent 0.3609(0.4086) | Loss 3.8127(3.8165) | Error 0.1211(0.1449) Steps 682(710.51) | Grad Norm 3.2901(4.2317) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0147 | Time 90.0974, Epoch Time 1070.4887(1015.3138), Bit/dim 3.6134(best: 3.6118), Xent 0.6884, Loss 3.9577, Error 0.2271(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8090 | Time 17.9109(17.4938) | Bit/dim 3.6063(3.6142) | Xent 0.3591(0.4060) | Loss 3.7858(3.8172) | Error 0.1322(0.1439) Steps 718(710.45) | Grad Norm 4.1859(4.1610) | Total Time 14.00(14.00)\n",
      "Iter 8100 | Time 17.9428(17.5494) | Bit/dim 3.5951(3.6115) | Xent 0.3988(0.3983) | Loss 3.7945(3.8107) | Error 0.1400(0.1421) Steps 706(712.58) | Grad Norm 4.5305(4.0271) | Total Time 14.00(14.00)\n",
      "Iter 8110 | Time 17.5466(17.5235) | Bit/dim 3.6424(3.6116) | Xent 0.4404(0.3963) | Loss 3.8626(3.8097) | Error 0.1600(0.1418) Steps 712(712.11) | Grad Norm 4.3388(3.8256) | Total Time 14.00(14.00)\n",
      "Iter 8120 | Time 18.0773(17.5232) | Bit/dim 3.6319(3.6117) | Xent 0.4141(0.3940) | Loss 3.8389(3.8087) | Error 0.1411(0.1401) Steps 700(711.45) | Grad Norm 4.6820(3.9159) | Total Time 14.00(14.00)\n",
      "Iter 8130 | Time 17.2076(17.5573) | Bit/dim 3.6123(3.6131) | Xent 0.4146(0.4029) | Loss 3.8195(3.8145) | Error 0.1589(0.1436) Steps 712(712.76) | Grad Norm 4.3553(4.2996) | Total Time 14.00(14.00)\n",
      "Iter 8140 | Time 17.4461(17.5626) | Bit/dim 3.5976(3.6094) | Xent 0.3716(0.4066) | Loss 3.7834(3.8127) | Error 0.1278(0.1447) Steps 706(711.98) | Grad Norm 2.8398(4.3119) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 91.0072, Epoch Time 1076.0305(1017.1353), Bit/dim 3.6117(best: 3.6118), Xent 0.6874, Loss 3.9555, Error 0.2190(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8150 | Time 17.7665(17.5732) | Bit/dim 3.6111(3.6107) | Xent 0.3653(0.3967) | Loss 3.7938(3.8090) | Error 0.1289(0.1413) Steps 706(712.38) | Grad Norm 3.5514(4.0115) | Total Time 14.00(14.00)\n",
      "Iter 8160 | Time 17.4296(17.6048) | Bit/dim 3.6064(3.6097) | Xent 0.3684(0.3928) | Loss 3.7906(3.8061) | Error 0.1333(0.1407) Steps 700(712.64) | Grad Norm 5.7059(4.0304) | Total Time 14.00(14.00)\n",
      "Iter 8170 | Time 17.9988(17.6128) | Bit/dim 3.6162(3.6080) | Xent 0.3632(0.3949) | Loss 3.7978(3.8055) | Error 0.1278(0.1409) Steps 724(714.09) | Grad Norm 4.5445(3.9049) | Total Time 14.00(14.00)\n",
      "Iter 8180 | Time 18.2999(17.6040) | Bit/dim 3.6309(3.6073) | Xent 0.4616(0.3931) | Loss 3.8617(3.8039) | Error 0.1633(0.1412) Steps 736(714.65) | Grad Norm 5.0028(3.8298) | Total Time 14.00(14.00)\n",
      "Iter 8190 | Time 17.6696(17.6415) | Bit/dim 3.6026(3.6063) | Xent 0.4363(0.4056) | Loss 3.8207(3.8091) | Error 0.1544(0.1458) Steps 712(716.07) | Grad Norm 3.8572(4.2327) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 89.8823, Epoch Time 1077.0677(1018.9333), Bit/dim 3.6151(best: 3.6117), Xent 0.7205, Loss 3.9754, Error 0.2356(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8200 | Time 17.2816(17.5650) | Bit/dim 3.5997(3.6097) | Xent 0.3755(0.4117) | Loss 3.7875(3.8155) | Error 0.1211(0.1465) Steps 718(714.63) | Grad Norm 4.0235(4.4566) | Total Time 14.00(14.00)\n",
      "Iter 8210 | Time 18.0125(17.5504) | Bit/dim 3.5948(3.6099) | Xent 0.3710(0.4010) | Loss 3.7803(3.8103) | Error 0.1389(0.1437) Steps 724(713.85) | Grad Norm 3.0706(4.1686) | Total Time 14.00(14.00)\n",
      "Iter 8220 | Time 17.5245(17.5842) | Bit/dim 3.6020(3.6138) | Xent 0.3863(0.3957) | Loss 3.7952(3.8117) | Error 0.1422(0.1425) Steps 718(713.45) | Grad Norm 3.7489(4.0724) | Total Time 14.00(14.00)\n",
      "Iter 8230 | Time 17.4443(17.6159) | Bit/dim 3.6428(3.6135) | Xent 0.3485(0.3879) | Loss 3.8170(3.8074) | Error 0.1200(0.1394) Steps 718(712.90) | Grad Norm 2.1340(3.7968) | Total Time 14.00(14.00)\n",
      "Iter 8240 | Time 17.7010(17.6231) | Bit/dim 3.5933(3.6088) | Xent 0.3074(0.3794) | Loss 3.7471(3.7985) | Error 0.1044(0.1367) Steps 724(714.10) | Grad Norm 2.9003(3.5427) | Total Time 14.00(14.00)\n",
      "Iter 8250 | Time 17.5055(17.6531) | Bit/dim 3.6224(3.6056) | Xent 0.3842(0.3883) | Loss 3.8145(3.7997) | Error 0.1389(0.1381) Steps 724(714.60) | Grad Norm 4.0226(3.7931) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 90.3168, Epoch Time 1077.2946(1020.6841), Bit/dim 3.6191(best: 3.6117), Xent 0.7398, Loss 3.9890, Error 0.2332(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8260 | Time 17.6723(17.6561) | Bit/dim 3.6347(3.6085) | Xent 0.4002(0.3898) | Loss 3.8348(3.8034) | Error 0.1467(0.1390) Steps 724(715.23) | Grad Norm 5.0523(3.9637) | Total Time 14.00(14.00)\n",
      "Iter 8270 | Time 17.5555(17.7190) | Bit/dim 3.6054(3.6079) | Xent 0.3796(0.3881) | Loss 3.7952(3.8020) | Error 0.1422(0.1380) Steps 712(715.22) | Grad Norm 2.9369(3.8626) | Total Time 14.00(14.00)\n",
      "Iter 8280 | Time 17.7808(17.7337) | Bit/dim 3.6496(3.6098) | Xent 0.3653(0.3890) | Loss 3.8323(3.8043) | Error 0.1278(0.1382) Steps 718(716.37) | Grad Norm 5.5726(3.9340) | Total Time 14.00(14.00)\n",
      "Iter 8290 | Time 18.5458(17.7557) | Bit/dim 3.6041(3.6087) | Xent 0.4091(0.3973) | Loss 3.8086(3.8073) | Error 0.1467(0.1412) Steps 724(717.29) | Grad Norm 4.9619(4.1305) | Total Time 14.00(14.00)\n",
      "Iter 8300 | Time 18.1217(17.7861) | Bit/dim 3.6166(3.6084) | Xent 0.3748(0.4101) | Loss 3.8040(3.8135) | Error 0.1311(0.1460) Steps 724(720.33) | Grad Norm 3.7864(4.0803) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0151 | Time 90.2074, Epoch Time 1086.3118(1022.6530), Bit/dim 3.6125(best: 3.6117), Xent 0.7115, Loss 3.9682, Error 0.2312(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8310 | Time 17.8978(17.7601) | Bit/dim 3.6175(3.6099) | Xent 0.2948(0.4036) | Loss 3.7649(3.8117) | Error 0.1000(0.1439) Steps 718(719.68) | Grad Norm 2.2733(3.8615) | Total Time 14.00(14.00)\n",
      "Iter 8320 | Time 17.6694(17.7602) | Bit/dim 3.5869(3.6095) | Xent 0.3753(0.3953) | Loss 3.7745(3.8072) | Error 0.1400(0.1407) Steps 724(718.97) | Grad Norm 3.5360(3.8751) | Total Time 14.00(14.00)\n",
      "Iter 8330 | Time 17.6188(17.6816) | Bit/dim 3.5684(3.6088) | Xent 0.3526(0.3856) | Loss 3.7447(3.8016) | Error 0.1256(0.1377) Steps 718(718.40) | Grad Norm 2.8223(3.6604) | Total Time 14.00(14.00)\n",
      "Iter 8340 | Time 17.1508(17.5761) | Bit/dim 3.6112(3.6082) | Xent 0.3535(0.3828) | Loss 3.7880(3.7996) | Error 0.1356(0.1365) Steps 718(717.41) | Grad Norm 3.0088(3.6039) | Total Time 14.00(14.00)\n",
      "Iter 8350 | Time 17.8148(17.5805) | Bit/dim 3.5690(3.6072) | Xent 0.3971(0.3834) | Loss 3.7675(3.7988) | Error 0.1489(0.1371) Steps 736(719.54) | Grad Norm 4.5375(3.7722) | Total Time 14.00(14.00)\n",
      "Iter 8360 | Time 17.5504(17.6273) | Bit/dim 3.5941(3.6068) | Xent 0.3900(0.3833) | Loss 3.7891(3.7984) | Error 0.1467(0.1366) Steps 730(722.64) | Grad Norm 2.4371(3.7805) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0152 | Time 90.2404, Epoch Time 1075.3392(1024.2335), Bit/dim 3.6136(best: 3.6117), Xent 0.6901, Loss 3.9587, Error 0.2182(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8370 | Time 18.2345(17.6934) | Bit/dim 3.6310(3.6064) | Xent 0.3520(0.3759) | Loss 3.8070(3.7944) | Error 0.1289(0.1342) Steps 712(723.18) | Grad Norm 3.9693(3.8316) | Total Time 14.00(14.00)\n",
      "Iter 8380 | Time 17.9444(17.7490) | Bit/dim 3.5915(3.6076) | Xent 0.3950(0.3688) | Loss 3.7890(3.7920) | Error 0.1378(0.1309) Steps 706(722.76) | Grad Norm 3.1153(3.7582) | Total Time 14.00(14.00)\n",
      "Iter 8390 | Time 18.1022(17.7508) | Bit/dim 3.6036(3.6068) | Xent 0.3307(0.3698) | Loss 3.7689(3.7917) | Error 0.1178(0.1315) Steps 712(722.82) | Grad Norm 2.5091(3.7807) | Total Time 14.00(14.00)\n",
      "Iter 8400 | Time 17.9168(17.7875) | Bit/dim 3.6105(3.6076) | Xent 0.4423(0.3837) | Loss 3.8316(3.7995) | Error 0.1522(0.1365) Steps 736(724.58) | Grad Norm 3.5218(4.0950) | Total Time 14.00(14.00)\n",
      "Iter 8410 | Time 17.4644(17.7958) | Bit/dim 3.6416(3.6091) | Xent 0.4848(0.3890) | Loss 3.8840(3.8036) | Error 0.1822(0.1391) Steps 718(724.32) | Grad Norm 4.6759(4.1873) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0153 | Time 90.8547, Epoch Time 1091.4998(1026.2515), Bit/dim 3.6168(best: 3.6117), Xent 0.7195, Loss 3.9766, Error 0.2234(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8420 | Time 18.2815(17.8407) | Bit/dim 3.5755(3.6071) | Xent 0.3706(0.3874) | Loss 3.7609(3.8007) | Error 0.1389(0.1382) Steps 724(724.98) | Grad Norm 4.6018(4.2641) | Total Time 14.00(14.00)\n",
      "Iter 8430 | Time 17.0860(17.8499) | Bit/dim 3.5832(3.6071) | Xent 0.4243(0.3911) | Loss 3.7954(3.8026) | Error 0.1544(0.1387) Steps 730(725.48) | Grad Norm 4.0978(4.3676) | Total Time 14.00(14.00)\n",
      "Iter 8440 | Time 17.3897(17.8578) | Bit/dim 3.6219(3.6092) | Xent 0.3699(0.3944) | Loss 3.8068(3.8064) | Error 0.1300(0.1390) Steps 736(727.41) | Grad Norm 5.6631(4.4641) | Total Time 14.00(14.00)\n",
      "Iter 8450 | Time 17.4929(17.7951) | Bit/dim 3.6210(3.6092) | Xent 0.3788(0.3929) | Loss 3.8104(3.8057) | Error 0.1344(0.1386) Steps 730(728.49) | Grad Norm 4.2598(4.5617) | Total Time 14.00(14.00)\n",
      "Iter 8460 | Time 18.1414(17.8328) | Bit/dim 3.5917(3.6099) | Xent 0.3234(0.3840) | Loss 3.7534(3.8019) | Error 0.1256(0.1367) Steps 730(726.65) | Grad Norm 2.3133(4.2330) | Total Time 14.00(14.00)\n",
      "Iter 8470 | Time 17.7606(17.8582) | Bit/dim 3.6023(3.6086) | Xent 0.3666(0.3783) | Loss 3.7856(3.7977) | Error 0.1144(0.1342) Steps 724(727.90) | Grad Norm 3.4497(3.8946) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0154 | Time 89.2366, Epoch Time 1089.2631(1028.1419), Bit/dim 3.6069(best: 3.6117), Xent 0.7028, Loss 3.9583, Error 0.2230(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8480 | Time 17.5696(17.8539) | Bit/dim 3.6015(3.6086) | Xent 0.3654(0.3695) | Loss 3.7842(3.7933) | Error 0.1233(0.1309) Steps 730(728.12) | Grad Norm 4.2970(3.8226) | Total Time 14.00(14.00)\n",
      "Iter 8490 | Time 18.1447(17.8995) | Bit/dim 3.6083(3.6077) | Xent 0.3434(0.3670) | Loss 3.7800(3.7912) | Error 0.1200(0.1308) Steps 724(727.35) | Grad Norm 2.7378(3.7798) | Total Time 14.00(14.00)\n",
      "Iter 8500 | Time 18.3628(17.9209) | Bit/dim 3.5918(3.6054) | Xent 0.3744(0.3664) | Loss 3.7790(3.7886) | Error 0.1378(0.1301) Steps 730(726.74) | Grad Norm 2.9390(3.5287) | Total Time 14.00(14.00)\n",
      "Iter 8510 | Time 17.9795(17.9448) | Bit/dim 3.6142(3.6058) | Xent 0.3460(0.3674) | Loss 3.7872(3.7895) | Error 0.1167(0.1306) Steps 760(728.48) | Grad Norm 3.1543(3.5703) | Total Time 14.00(14.00)\n",
      "Iter 8520 | Time 17.8986(18.0213) | Bit/dim 3.6201(3.6045) | Xent 0.4297(0.3743) | Loss 3.8350(3.7916) | Error 0.1500(0.1340) Steps 730(731.36) | Grad Norm 4.4311(3.8697) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0155 | Time 90.7943, Epoch Time 1101.0426(1030.3289), Bit/dim 3.6142(best: 3.6069), Xent 0.7115, Loss 3.9699, Error 0.2300(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8530 | Time 18.4413(18.0692) | Bit/dim 3.5986(3.6065) | Xent 0.4373(0.3848) | Loss 3.8172(3.7988) | Error 0.1478(0.1375) Steps 736(731.80) | Grad Norm 6.9383(4.3450) | Total Time 14.00(14.00)\n",
      "Iter 8540 | Time 18.4404(18.0497) | Bit/dim 3.5911(3.6071) | Xent 0.3496(0.3880) | Loss 3.7659(3.8011) | Error 0.1267(0.1387) Steps 736(730.92) | Grad Norm 3.7352(4.3059) | Total Time 14.00(14.00)\n",
      "Iter 8550 | Time 18.2882(18.0648) | Bit/dim 3.5973(3.6041) | Xent 0.3309(0.3787) | Loss 3.7627(3.7934) | Error 0.1311(0.1364) Steps 724(730.11) | Grad Norm 2.8527(4.1753) | Total Time 14.00(14.00)\n",
      "Iter 8560 | Time 18.0138(17.9720) | Bit/dim 3.6112(3.6082) | Xent 0.4802(0.4048) | Loss 3.8513(3.8105) | Error 0.1656(0.1443) Steps 730(729.87) | Grad Norm 6.6442(4.9323) | Total Time 14.00(14.00)\n",
      "Iter 8570 | Time 17.2799(17.9147) | Bit/dim 3.6572(3.6138) | Xent 0.4276(0.4147) | Loss 3.8710(3.8212) | Error 0.1511(0.1478) Steps 718(729.23) | Grad Norm 6.0282(4.8771) | Total Time 14.00(14.00)\n",
      "Iter 8580 | Time 18.2893(17.9485) | Bit/dim 3.6331(3.6158) | Xent 0.4701(0.4104) | Loss 3.8682(3.8211) | Error 0.1644(0.1470) Steps 742(729.12) | Grad Norm 4.6673(4.7455) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0156 | Time 90.0953, Epoch Time 1094.4673(1032.2531), Bit/dim 3.6241(best: 3.6069), Xent 0.7704, Loss 4.0093, Error 0.2362(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8590 | Time 18.3944(17.9944) | Bit/dim 3.5749(3.6145) | Xent 0.3687(0.4061) | Loss 3.7593(3.8175) | Error 0.1222(0.1445) Steps 748(729.70) | Grad Norm 2.7853(4.6077) | Total Time 14.00(14.00)\n",
      "Iter 8600 | Time 18.4816(18.0207) | Bit/dim 3.6048(3.6140) | Xent 0.3623(0.3892) | Loss 3.7859(3.8086) | Error 0.1311(0.1386) Steps 730(730.31) | Grad Norm 5.0471(4.3665) | Total Time 14.00(14.00)\n",
      "Iter 8610 | Time 17.8990(18.0356) | Bit/dim 3.5902(3.6128) | Xent 0.4157(0.3864) | Loss 3.7980(3.8060) | Error 0.1522(0.1396) Steps 742(730.93) | Grad Norm 5.3543(4.3799) | Total Time 14.00(14.00)\n",
      "Iter 8620 | Time 17.8365(18.0105) | Bit/dim 3.6194(3.6113) | Xent 0.4128(0.3879) | Loss 3.8258(3.8052) | Error 0.1367(0.1388) Steps 730(730.56) | Grad Norm 6.2917(4.3493) | Total Time 14.00(14.00)\n",
      "Iter 8630 | Time 18.6992(18.0601) | Bit/dim 3.6160(3.6085) | Xent 0.3316(0.3852) | Loss 3.7818(3.8011) | Error 0.1122(0.1376) Steps 754(731.63) | Grad Norm 3.3245(4.2825) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0157 | Time 90.4062, Epoch Time 1101.3830(1034.3270), Bit/dim 3.6056(best: 3.6069), Xent 0.7693, Loss 3.9903, Error 0.2340(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8640 | Time 18.2324(18.0234) | Bit/dim 3.5912(3.6041) | Xent 0.3524(0.3773) | Loss 3.7674(3.7928) | Error 0.1089(0.1338) Steps 736(732.20) | Grad Norm 3.1534(4.1113) | Total Time 14.00(14.00)\n",
      "Iter 8650 | Time 18.1412(18.0492) | Bit/dim 3.6148(3.6059) | Xent 0.3749(0.3693) | Loss 3.8023(3.7905) | Error 0.1300(0.1312) Steps 736(733.33) | Grad Norm 3.5716(3.9313) | Total Time 14.00(14.00)\n",
      "Iter 8660 | Time 18.4542(18.0737) | Bit/dim 3.5823(3.6041) | Xent 0.3856(0.3615) | Loss 3.7751(3.7849) | Error 0.1311(0.1286) Steps 724(733.93) | Grad Norm 4.4402(3.7411) | Total Time 14.00(14.00)\n",
      "Iter 8670 | Time 17.5658(18.0501) | Bit/dim 3.6208(3.6039) | Xent 0.3084(0.3588) | Loss 3.7750(3.7833) | Error 0.1089(0.1275) Steps 736(733.32) | Grad Norm 4.3404(3.9090) | Total Time 14.00(14.00)\n",
      "Iter 8680 | Time 17.7746(18.0630) | Bit/dim 3.6169(3.6052) | Xent 0.3332(0.3627) | Loss 3.7835(3.7865) | Error 0.1211(0.1289) Steps 724(732.34) | Grad Norm 2.3474(3.8305) | Total Time 14.00(14.00)\n",
      "Iter 8690 | Time 17.7225(18.0160) | Bit/dim 3.6197(3.6049) | Xent 0.3244(0.3615) | Loss 3.7819(3.7856) | Error 0.1167(0.1295) Steps 736(732.73) | Grad Norm 3.4710(3.7738) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0158 | Time 91.0550, Epoch Time 1101.1685(1036.3322), Bit/dim 3.6183(best: 3.6056), Xent 0.7646, Loss 4.0005, Error 0.2218(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8700 | Time 17.7581(18.0239) | Bit/dim 3.6215(3.6039) | Xent 0.3367(0.3559) | Loss 3.7899(3.7819) | Error 0.1156(0.1272) Steps 730(733.23) | Grad Norm 4.2305(3.7800) | Total Time 14.00(14.00)\n",
      "Iter 8710 | Time 17.9540(17.9870) | Bit/dim 3.6118(3.6027) | Xent 0.3087(0.3519) | Loss 3.7661(3.7787) | Error 0.1133(0.1252) Steps 730(732.96) | Grad Norm 2.3546(3.5318) | Total Time 14.00(14.00)\n",
      "Iter 8720 | Time 17.8807(17.9833) | Bit/dim 3.6086(3.6006) | Xent 0.3909(0.3533) | Loss 3.8041(3.7773) | Error 0.1422(0.1262) Steps 730(733.63) | Grad Norm 4.0823(3.5489) | Total Time 14.00(14.00)\n",
      "Iter 8730 | Time 17.8817(17.9275) | Bit/dim 3.6095(3.6008) | Xent 0.3882(0.3574) | Loss 3.8036(3.7795) | Error 0.1422(0.1276) Steps 736(733.22) | Grad Norm 6.4102(3.6792) | Total Time 14.00(14.00)\n",
      "Iter 8740 | Time 17.5142(17.9166) | Bit/dim 3.6186(3.6052) | Xent 0.3183(0.3564) | Loss 3.7778(3.7834) | Error 0.1111(0.1267) Steps 724(732.14) | Grad Norm 3.6373(3.7338) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0159 | Time 89.2282, Epoch Time 1090.0805(1037.9446), Bit/dim 3.6102(best: 3.6056), Xent 0.7465, Loss 3.9835, Error 0.2275(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8750 | Time 18.2436(17.8653) | Bit/dim 3.5994(3.6046) | Xent 0.3149(0.3543) | Loss 3.7568(3.7817) | Error 0.1189(0.1265) Steps 730(733.50) | Grad Norm 3.8658(3.5319) | Total Time 14.00(14.00)\n",
      "Iter 8760 | Time 18.4174(17.8923) | Bit/dim 3.5698(3.6042) | Xent 0.4024(0.3647) | Loss 3.7710(3.7865) | Error 0.1478(0.1298) Steps 736(732.29) | Grad Norm 5.2071(3.9310) | Total Time 14.00(14.00)\n",
      "Iter 8770 | Time 18.4429(17.9501) | Bit/dim 3.5959(3.6044) | Xent 0.3539(0.3619) | Loss 3.7728(3.7853) | Error 0.1289(0.1286) Steps 730(732.56) | Grad Norm 2.5268(3.8842) | Total Time 14.00(14.00)\n",
      "Iter 8780 | Time 18.2649(17.9590) | Bit/dim 3.6087(3.6036) | Xent 0.3843(0.3649) | Loss 3.8008(3.7860) | Error 0.1344(0.1307) Steps 736(733.24) | Grad Norm 2.5998(3.8381) | Total Time 14.00(14.00)\n",
      "Iter 8790 | Time 17.7779(17.9650) | Bit/dim 3.6049(3.6029) | Xent 0.3484(0.3644) | Loss 3.7792(3.7851) | Error 0.1333(0.1304) Steps 730(732.95) | Grad Norm 3.0382(3.8871) | Total Time 14.00(14.00)\n",
      "Iter 8800 | Time 18.1621(18.0030) | Bit/dim 3.6544(3.6045) | Xent 0.3723(0.3637) | Loss 3.8406(3.7864) | Error 0.1333(0.1307) Steps 742(731.90) | Grad Norm 5.1264(3.8867) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0160 | Time 89.3126, Epoch Time 1098.3181(1039.7559), Bit/dim 3.6186(best: 3.6056), Xent 0.7332, Loss 3.9852, Error 0.2222(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8810 | Time 17.7643(17.9559) | Bit/dim 3.5988(3.6096) | Xent 0.3629(0.3600) | Loss 3.7803(3.7896) | Error 0.1289(0.1287) Steps 736(732.07) | Grad Norm 3.2451(3.9768) | Total Time 14.00(14.00)\n",
      "Iter 8820 | Time 17.7579(17.9201) | Bit/dim 3.6178(3.6092) | Xent 0.3569(0.3580) | Loss 3.7963(3.7882) | Error 0.1289(0.1279) Steps 736(732.98) | Grad Norm 4.3657(4.1529) | Total Time 14.00(14.00)\n",
      "Iter 8830 | Time 17.8653(17.8682) | Bit/dim 3.6281(3.6075) | Xent 0.3364(0.3574) | Loss 3.7963(3.7862) | Error 0.1144(0.1273) Steps 748(734.12) | Grad Norm 3.4120(4.1144) | Total Time 14.00(14.00)\n",
      "Iter 8840 | Time 17.8084(17.8791) | Bit/dim 3.5529(3.6023) | Xent 0.4238(0.3570) | Loss 3.7648(3.7808) | Error 0.1433(0.1276) Steps 730(733.48) | Grad Norm 3.1233(3.9824) | Total Time 14.00(14.00)\n",
      "Iter 8850 | Time 17.4055(17.8251) | Bit/dim 3.5716(3.6024) | Xent 0.3121(0.3582) | Loss 3.7276(3.7815) | Error 0.1044(0.1288) Steps 730(731.25) | Grad Norm 2.8552(3.9604) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0161 | Time 89.7123, Epoch Time 1085.8714(1041.1393), Bit/dim 3.6155(best: 3.6056), Xent 0.7380, Loss 3.9845, Error 0.2223(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8860 | Time 18.3202(17.8379) | Bit/dim 3.6289(3.6063) | Xent 0.3347(0.3583) | Loss 3.7962(3.7854) | Error 0.1156(0.1289) Steps 742(732.35) | Grad Norm 6.9900(4.2421) | Total Time 14.00(14.00)\n",
      "Iter 8870 | Time 17.8919(17.8690) | Bit/dim 3.5838(3.6053) | Xent 0.3585(0.3555) | Loss 3.7631(3.7830) | Error 0.1356(0.1284) Steps 736(732.80) | Grad Norm 5.7921(4.1829) | Total Time 14.00(14.00)\n",
      "Iter 8880 | Time 17.9166(17.8861) | Bit/dim 3.6201(3.6057) | Xent 0.4133(0.3520) | Loss 3.8268(3.7817) | Error 0.1578(0.1268) Steps 718(732.85) | Grad Norm 5.1721(4.2408) | Total Time 14.00(14.00)\n",
      "Iter 8890 | Time 17.6713(17.9005) | Bit/dim 3.6311(3.6035) | Xent 0.4115(0.3616) | Loss 3.8368(3.7843) | Error 0.1289(0.1287) Steps 730(732.14) | Grad Norm 3.3055(4.3319) | Total Time 14.00(14.00)\n",
      "Iter 8900 | Time 18.6377(17.9744) | Bit/dim 3.5945(3.6041) | Xent 0.3189(0.3577) | Loss 3.7540(3.7829) | Error 0.1078(0.1264) Steps 742(732.86) | Grad Norm 3.1335(4.2411) | Total Time 14.00(14.00)\n",
      "Iter 8910 | Time 17.9373(18.0273) | Bit/dim 3.5939(3.6038) | Xent 0.4281(0.3663) | Loss 3.8079(3.7870) | Error 0.1589(0.1293) Steps 748(734.65) | Grad Norm 8.0551(4.4676) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0162 | Time 89.1552, Epoch Time 1098.6629(1042.8650), Bit/dim 3.6113(best: 3.6056), Xent 0.7219, Loss 3.9722, Error 0.2277(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8920 | Time 17.6801(17.9837) | Bit/dim 3.5866(3.6085) | Xent 0.4056(0.3622) | Loss 3.7893(3.7896) | Error 0.1411(0.1285) Steps 736(733.54) | Grad Norm 4.4118(4.4743) | Total Time 14.00(14.00)\n",
      "Iter 8930 | Time 18.3840(17.9964) | Bit/dim 3.5823(3.6081) | Xent 0.3357(0.3617) | Loss 3.7502(3.7889) | Error 0.1378(0.1285) Steps 724(733.18) | Grad Norm 3.1304(4.3235) | Total Time 14.00(14.00)\n",
      "Iter 8940 | Time 18.0440(17.9773) | Bit/dim 3.5914(3.6047) | Xent 0.2989(0.3553) | Loss 3.7409(3.7824) | Error 0.1122(0.1266) Steps 742(733.89) | Grad Norm 2.7251(4.1468) | Total Time 14.00(14.00)\n",
      "Iter 8950 | Time 18.1985(17.9921) | Bit/dim 3.5853(3.6033) | Xent 0.3502(0.3490) | Loss 3.7605(3.7778) | Error 0.1244(0.1240) Steps 730(734.03) | Grad Norm 3.5276(3.9643) | Total Time 14.00(14.00)\n",
      "Iter 8960 | Time 18.0270(18.0668) | Bit/dim 3.6021(3.6027) | Xent 0.3824(0.3515) | Loss 3.7933(3.7785) | Error 0.1411(0.1259) Steps 730(734.85) | Grad Norm 3.5837(3.8764) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0163 | Time 88.7720, Epoch Time 1097.8363(1044.5142), Bit/dim 3.6001(best: 3.6056), Xent 0.7387, Loss 3.9694, Error 0.2330(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8970 | Time 18.0646(18.0748) | Bit/dim 3.6104(3.6033) | Xent 0.3201(0.3475) | Loss 3.7704(3.7770) | Error 0.1133(0.1235) Steps 742(734.62) | Grad Norm 3.7726(3.7709) | Total Time 14.00(14.00)\n",
      "Iter 8980 | Time 18.0453(18.0524) | Bit/dim 3.5832(3.6020) | Xent 0.3903(0.3497) | Loss 3.7783(3.7769) | Error 0.1433(0.1245) Steps 736(734.01) | Grad Norm 4.1752(3.8108) | Total Time 14.00(14.00)\n",
      "Iter 8990 | Time 18.5017(18.0896) | Bit/dim 3.6133(3.6013) | Xent 0.3616(0.3519) | Loss 3.7941(3.7773) | Error 0.1378(0.1264) Steps 736(733.27) | Grad Norm 3.7961(3.9096) | Total Time 14.00(14.00)\n",
      "Iter 9000 | Time 17.4230(18.0301) | Bit/dim 3.6254(3.6057) | Xent 0.4291(0.3623) | Loss 3.8400(3.7869) | Error 0.1556(0.1299) Steps 712(731.78) | Grad Norm 4.7317(4.4036) | Total Time 14.00(14.00)\n",
      "Iter 9010 | Time 18.2400(18.0116) | Bit/dim 3.5841(3.6030) | Xent 0.4029(0.3716) | Loss 3.7855(3.7888) | Error 0.1578(0.1337) Steps 742(732.77) | Grad Norm 4.0689(4.4138) | Total Time 14.00(14.00)\n",
      "Iter 9020 | Time 17.4737(17.9684) | Bit/dim 3.6089(3.6036) | Xent 0.3324(0.3659) | Loss 3.7750(3.7866) | Error 0.1200(0.1319) Steps 724(731.66) | Grad Norm 3.0521(4.2549) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0164 | Time 88.9933, Epoch Time 1095.8466(1046.0541), Bit/dim 3.6100(best: 3.6001), Xent 0.7514, Loss 3.9858, Error 0.2244(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9030 | Time 17.4369(17.9811) | Bit/dim 3.6069(3.6013) | Xent 0.3662(0.3552) | Loss 3.7900(3.7789) | Error 0.1300(0.1280) Steps 736(733.16) | Grad Norm 3.1477(3.9995) | Total Time 14.00(14.00)\n",
      "Iter 9040 | Time 18.0078(18.0102) | Bit/dim 3.5823(3.6042) | Xent 0.3558(0.3477) | Loss 3.7602(3.7781) | Error 0.1233(0.1247) Steps 742(733.99) | Grad Norm 3.3681(4.0555) | Total Time 14.00(14.00)\n",
      "Iter 9050 | Time 18.5752(18.0551) | Bit/dim 3.6329(3.6042) | Xent 0.3868(0.3543) | Loss 3.8263(3.7814) | Error 0.1311(0.1266) Steps 742(733.11) | Grad Norm 4.1287(4.1231) | Total Time 14.00(14.00)\n",
      "Iter 9060 | Time 18.0199(18.0659) | Bit/dim 3.6094(3.6040) | Xent 0.3207(0.3540) | Loss 3.7697(3.7810) | Error 0.1111(0.1272) Steps 736(732.71) | Grad Norm 2.1640(4.1107) | Total Time 14.00(14.00)\n",
      "Iter 9070 | Time 18.4898(18.0618) | Bit/dim 3.5987(3.6043) | Xent 0.3458(0.3519) | Loss 3.7716(3.7802) | Error 0.1244(0.1256) Steps 730(732.77) | Grad Norm 2.6259(3.8685) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0165 | Time 90.5312, Epoch Time 1103.1769(1047.7678), Bit/dim 3.6081(best: 3.6001), Xent 0.7668, Loss 3.9915, Error 0.2306(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9080 | Time 17.6284(18.0569) | Bit/dim 3.5830(3.6024) | Xent 0.3356(0.3518) | Loss 3.7509(3.7782) | Error 0.1244(0.1257) Steps 736(734.08) | Grad Norm 3.6658(3.9424) | Total Time 14.00(14.00)\n",
      "Iter 9090 | Time 17.7122(17.9779) | Bit/dim 3.6150(3.6024) | Xent 0.3536(0.3504) | Loss 3.7919(3.7776) | Error 0.1244(0.1259) Steps 730(734.25) | Grad Norm 4.8084(3.9276) | Total Time 14.00(14.00)\n",
      "Iter 9100 | Time 17.5570(17.9201) | Bit/dim 3.6374(3.6031) | Xent 0.3663(0.3530) | Loss 3.8206(3.7796) | Error 0.1278(0.1267) Steps 730(733.66) | Grad Norm 4.0173(4.1737) | Total Time 14.00(14.00)\n",
      "Iter 9110 | Time 17.1238(17.8675) | Bit/dim 3.5856(3.6034) | Xent 0.4083(0.3520) | Loss 3.7897(3.7794) | Error 0.1422(0.1257) Steps 724(732.80) | Grad Norm 5.1562(4.1648) | Total Time 14.00(14.00)\n",
      "Iter 9120 | Time 17.5463(17.8970) | Bit/dim 3.5696(3.6014) | Xent 0.3461(0.3487) | Loss 3.7426(3.7757) | Error 0.1256(0.1249) Steps 736(735.76) | Grad Norm 3.8175(4.1994) | Total Time 14.00(14.00)\n",
      "Iter 9130 | Time 17.8184(17.9260) | Bit/dim 3.5823(3.6011) | Xent 0.3701(0.3459) | Loss 3.7673(3.7740) | Error 0.1222(0.1234) Steps 730(735.88) | Grad Norm 5.4694(4.0463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0166 | Time 89.0843, Epoch Time 1089.2644(1049.0127), Bit/dim 3.6068(best: 3.6001), Xent 0.7575, Loss 3.9855, Error 0.2307(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9140 | Time 17.6802(17.8942) | Bit/dim 3.5800(3.6001) | Xent 0.2916(0.3429) | Loss 3.7258(3.7715) | Error 0.1167(0.1213) Steps 736(734.69) | Grad Norm 4.0965(3.9767) | Total Time 14.00(14.00)\n",
      "Iter 9150 | Time 18.2073(17.9608) | Bit/dim 3.5710(3.5980) | Xent 0.3640(0.3401) | Loss 3.7530(3.7681) | Error 0.1344(0.1207) Steps 736(734.05) | Grad Norm 3.8888(4.0076) | Total Time 14.00(14.00)\n",
      "Iter 9160 | Time 17.9411(17.9742) | Bit/dim 3.6104(3.5999) | Xent 0.3600(0.3377) | Loss 3.7904(3.7688) | Error 0.1300(0.1197) Steps 730(733.85) | Grad Norm 6.5807(3.9977) | Total Time 14.00(14.00)\n",
      "Iter 9170 | Time 18.0834(17.9491) | Bit/dim 3.6025(3.6029) | Xent 0.2742(0.3309) | Loss 3.7396(3.7683) | Error 0.1044(0.1182) Steps 736(735.81) | Grad Norm 2.8851(3.8329) | Total Time 14.00(14.00)\n",
      "Iter 9180 | Time 17.4814(17.9465) | Bit/dim 3.6220(3.6026) | Xent 0.3451(0.3310) | Loss 3.7946(3.7681) | Error 0.1211(0.1183) Steps 730(735.61) | Grad Norm 3.5393(3.7818) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0167 | Time 90.5275, Epoch Time 1097.6325(1050.4713), Bit/dim 3.6049(best: 3.6001), Xent 0.7172, Loss 3.9635, Error 0.2141(best: 0.2180)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9190 | Time 18.0814(18.0339) | Bit/dim 3.5848(3.6017) | Xent 0.3216(0.3224) | Loss 3.7457(3.7629) | Error 0.1089(0.1144) Steps 730(736.41) | Grad Norm 3.0073(3.5431) | Total Time 14.00(14.00)\n",
      "Iter 9200 | Time 18.2720(18.0374) | Bit/dim 3.6006(3.5994) | Xent 0.3748(0.3281) | Loss 3.7880(3.7634) | Error 0.1133(0.1157) Steps 730(735.79) | Grad Norm 4.4135(3.6197) | Total Time 14.00(14.00)\n",
      "Iter 9210 | Time 18.5426(18.0264) | Bit/dim 3.6288(3.6019) | Xent 0.3426(0.3360) | Loss 3.8000(3.7699) | Error 0.1167(0.1183) Steps 736(735.62) | Grad Norm 3.3811(3.7060) | Total Time 14.00(14.00)\n",
      "Iter 9220 | Time 18.0189(18.0240) | Bit/dim 3.5925(3.6012) | Xent 0.4773(0.3473) | Loss 3.8312(3.7749) | Error 0.1644(0.1222) Steps 730(736.23) | Grad Norm 9.0639(4.0846) | Total Time 14.00(14.00)\n",
      "Iter 9230 | Time 18.2137(17.9785) | Bit/dim 3.6178(3.6046) | Xent 0.3868(0.3540) | Loss 3.8112(3.7816) | Error 0.1278(0.1250) Steps 742(735.78) | Grad Norm 4.5655(4.0864) | Total Time 14.00(14.00)\n",
      "Iter 9240 | Time 17.9736(17.9832) | Bit/dim 3.6113(3.6067) | Xent 0.3809(0.3572) | Loss 3.8018(3.7853) | Error 0.1456(0.1264) Steps 754(736.08) | Grad Norm 5.4850(4.1973) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0168 | Time 90.0508, Epoch Time 1097.8459(1051.8925), Bit/dim 3.6185(best: 3.6001), Xent 0.7560, Loss 3.9965, Error 0.2307(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9250 | Time 18.5822(18.0206) | Bit/dim 3.6270(3.6065) | Xent 0.2783(0.3507) | Loss 3.7662(3.7818) | Error 0.0967(0.1246) Steps 742(736.86) | Grad Norm 3.9420(4.2884) | Total Time 14.00(14.00)\n",
      "Iter 9260 | Time 18.4542(18.0391) | Bit/dim 3.6227(3.6059) | Xent 0.3656(0.3510) | Loss 3.8054(3.7814) | Error 0.1400(0.1256) Steps 724(735.42) | Grad Norm 2.7057(4.4044) | Total Time 14.00(14.00)\n",
      "Iter 9270 | Time 18.0870(18.0059) | Bit/dim 3.6303(3.6066) | Xent 0.3834(0.3549) | Loss 3.8220(3.7841) | Error 0.1333(0.1276) Steps 754(736.22) | Grad Norm 4.6996(4.5844) | Total Time 14.00(14.00)\n",
      "Iter 9280 | Time 18.1122(18.0160) | Bit/dim 3.6123(3.6067) | Xent 0.3722(0.3569) | Loss 3.7984(3.7852) | Error 0.1333(0.1279) Steps 736(736.17) | Grad Norm 3.3098(4.6439) | Total Time 14.00(14.00)\n",
      "Iter 9290 | Time 17.9725(18.0809) | Bit/dim 3.6193(3.6062) | Xent 0.3964(0.3583) | Loss 3.8175(3.7854) | Error 0.1356(0.1274) Steps 748(738.81) | Grad Norm 9.0707(4.7153) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0169 | Time 91.0151, Epoch Time 1102.8845(1053.4223), Bit/dim 3.6253(best: 3.6001), Xent 0.7360, Loss 3.9933, Error 0.2277(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9300 | Time 17.9387(18.0656) | Bit/dim 3.6117(3.6066) | Xent 0.3368(0.3602) | Loss 3.7800(3.7867) | Error 0.1289(0.1287) Steps 736(737.97) | Grad Norm 4.3256(4.8549) | Total Time 14.00(14.00)\n",
      "Iter 9310 | Time 18.0599(18.0562) | Bit/dim 3.5731(3.6068) | Xent 0.3170(0.3487) | Loss 3.7316(3.7812) | Error 0.1111(0.1244) Steps 754(739.60) | Grad Norm 2.9052(4.4776) | Total Time 14.00(14.00)\n",
      "Iter 9320 | Time 17.9664(18.0273) | Bit/dim 3.6395(3.6072) | Xent 0.2770(0.3380) | Loss 3.7780(3.7763) | Error 0.1011(0.1205) Steps 748(740.34) | Grad Norm 3.2212(4.1263) | Total Time 14.00(14.00)\n",
      "Iter 9330 | Time 18.3976(18.0644) | Bit/dim 3.5733(3.6016) | Xent 0.3383(0.3341) | Loss 3.7425(3.7687) | Error 0.1311(0.1193) Steps 748(741.69) | Grad Norm 2.3303(3.8904) | Total Time 14.00(14.00)\n",
      "Iter 9340 | Time 18.2860(17.9922) | Bit/dim 3.6171(3.6039) | Xent 0.3184(0.3311) | Loss 3.7763(3.7695) | Error 0.1300(0.1191) Steps 748(740.89) | Grad Norm 3.0695(3.7444) | Total Time 14.00(14.00)\n",
      "Iter 9350 | Time 18.2658(18.0594) | Bit/dim 3.5780(3.6031) | Xent 0.3191(0.3297) | Loss 3.7375(3.7680) | Error 0.1167(0.1183) Steps 754(742.96) | Grad Norm 3.1180(3.6439) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0170 | Time 92.4774, Epoch Time 1102.2671(1054.8876), Bit/dim 3.6086(best: 3.6001), Xent 0.7447, Loss 3.9809, Error 0.2220(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9360 | Time 17.6977(18.0150) | Bit/dim 3.5857(3.6010) | Xent 0.3202(0.3198) | Loss 3.7458(3.7609) | Error 0.1211(0.1151) Steps 736(741.87) | Grad Norm 2.7291(3.4517) | Total Time 14.00(14.00)\n",
      "Iter 9370 | Time 18.2145(18.1047) | Bit/dim 3.6099(3.5999) | Xent 0.3205(0.3192) | Loss 3.7701(3.7595) | Error 0.1133(0.1142) Steps 760(744.20) | Grad Norm 3.4907(3.5795) | Total Time 14.00(14.00)\n",
      "Iter 9380 | Time 17.8258(18.0704) | Bit/dim 3.5656(3.6003) | Xent 0.3176(0.3231) | Loss 3.7244(3.7618) | Error 0.1144(0.1157) Steps 742(745.93) | Grad Norm 3.4047(3.7014) | Total Time 14.00(14.00)\n",
      "Iter 9390 | Time 17.6516(18.0736) | Bit/dim 3.6282(3.5984) | Xent 0.3516(0.3266) | Loss 3.8040(3.7617) | Error 0.1300(0.1166) Steps 742(745.43) | Grad Norm 4.5849(3.9539) | Total Time 14.00(14.00)\n",
      "Iter 9400 | Time 17.3432(18.0985) | Bit/dim 3.6019(3.5998) | Xent 0.3290(0.3263) | Loss 3.7664(3.7630) | Error 0.1289(0.1169) Steps 742(746.90) | Grad Norm 3.2680(3.7962) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0171 | Time 92.3296, Epoch Time 1106.3485(1056.4315), Bit/dim 3.6055(best: 3.6001), Xent 0.7570, Loss 3.9839, Error 0.2262(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9410 | Time 18.3569(18.1441) | Bit/dim 3.6180(3.6002) | Xent 0.4042(0.3306) | Loss 3.8201(3.7655) | Error 0.1344(0.1185) Steps 730(747.68) | Grad Norm 4.8146(3.9947) | Total Time 14.00(14.00)\n",
      "Iter 9420 | Time 18.0546(18.1421) | Bit/dim 3.5996(3.6004) | Xent 0.4125(0.3361) | Loss 3.8058(3.7685) | Error 0.1556(0.1204) Steps 754(749.03) | Grad Norm 5.8540(4.3208) | Total Time 14.00(14.00)\n",
      "Iter 9430 | Time 17.9144(18.1320) | Bit/dim 3.6081(3.6032) | Xent 0.3760(0.3378) | Loss 3.7961(3.7721) | Error 0.1311(0.1203) Steps 754(749.59) | Grad Norm 4.7908(4.4810) | Total Time 14.00(14.00)\n",
      "Iter 9440 | Time 18.2862(18.1474) | Bit/dim 3.6202(3.6002) | Xent 0.2922(0.3340) | Loss 3.7663(3.7672) | Error 0.0989(0.1189) Steps 748(749.32) | Grad Norm 4.9942(4.3452) | Total Time 14.00(14.00)\n",
      "Iter 9450 | Time 18.1073(18.1411) | Bit/dim 3.6241(3.6022) | Xent 0.3740(0.3375) | Loss 3.8111(3.7710) | Error 0.1433(0.1197) Steps 754(747.39) | Grad Norm 6.6526(4.4516) | Total Time 14.00(14.00)\n",
      "Iter 9460 | Time 17.8564(18.1397) | Bit/dim 3.6248(3.6031) | Xent 0.4512(0.3550) | Loss 3.8504(3.7806) | Error 0.1544(0.1260) Steps 754(749.76) | Grad Norm 4.1661(4.6994) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0172 | Time 90.5086, Epoch Time 1106.1811(1057.9240), Bit/dim 3.6054(best: 3.6001), Xent 0.7112, Loss 3.9609, Error 0.2259(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9470 | Time 17.8645(18.1579) | Bit/dim 3.5659(3.6025) | Xent 0.3233(0.3479) | Loss 3.7275(3.7765) | Error 0.1100(0.1242) Steps 754(749.48) | Grad Norm 3.8852(4.4339) | Total Time 14.00(14.00)\n",
      "Iter 9480 | Time 17.7588(18.1644) | Bit/dim 3.6053(3.5992) | Xent 0.3346(0.3425) | Loss 3.7726(3.7704) | Error 0.1244(0.1221) Steps 754(749.83) | Grad Norm 3.3118(4.1742) | Total Time 14.00(14.00)\n",
      "Iter 9490 | Time 18.4650(18.2174) | Bit/dim 3.5984(3.6001) | Xent 0.3719(0.3421) | Loss 3.7844(3.7712) | Error 0.1278(0.1222) Steps 754(751.82) | Grad Norm 6.1745(4.2248) | Total Time 14.00(14.00)\n",
      "Iter 9500 | Time 18.1600(18.2567) | Bit/dim 3.5883(3.6016) | Xent 0.3575(0.3437) | Loss 3.7671(3.7734) | Error 0.1211(0.1228) Steps 754(751.81) | Grad Norm 4.4174(4.2230) | Total Time 14.00(14.00)\n",
      "Iter 9510 | Time 17.7993(18.2246) | Bit/dim 3.5945(3.6014) | Xent 0.3605(0.3425) | Loss 3.7747(3.7726) | Error 0.1322(0.1225) Steps 748(751.50) | Grad Norm 6.4080(4.2260) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0173 | Time 91.6608, Epoch Time 1113.1138(1059.5797), Bit/dim 3.6054(best: 3.6001), Xent 0.7494, Loss 3.9801, Error 0.2283(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9520 | Time 18.3050(18.2032) | Bit/dim 3.5796(3.6026) | Xent 0.3059(0.3409) | Loss 3.7326(3.7730) | Error 0.1067(0.1217) Steps 754(750.26) | Grad Norm 2.5987(4.2526) | Total Time 14.00(14.00)\n",
      "Iter 9530 | Time 18.4353(18.2077) | Bit/dim 3.6376(3.6031) | Xent 0.2960(0.3304) | Loss 3.7856(3.7683) | Error 0.1000(0.1172) Steps 760(750.11) | Grad Norm 3.2360(4.0345) | Total Time 14.00(14.00)\n",
      "Iter 9540 | Time 18.6065(18.1871) | Bit/dim 3.5903(3.5997) | Xent 0.3119(0.3251) | Loss 3.7462(3.7623) | Error 0.1233(0.1155) Steps 748(750.62) | Grad Norm 5.0502(4.0318) | Total Time 14.00(14.00)\n",
      "Iter 9550 | Time 18.1850(18.1352) | Bit/dim 3.5839(3.5976) | Xent 0.2574(0.3204) | Loss 3.7126(3.7577) | Error 0.0944(0.1146) Steps 760(750.45) | Grad Norm 2.6758(4.0035) | Total Time 14.00(14.00)\n",
      "Iter 9560 | Time 18.5300(18.1981) | Bit/dim 3.6207(3.5991) | Xent 0.3305(0.3213) | Loss 3.7859(3.7598) | Error 0.1189(0.1143) Steps 754(750.90) | Grad Norm 3.9630(3.9781) | Total Time 14.00(14.00)\n",
      "Iter 9570 | Time 17.9570(18.1317) | Bit/dim 3.6287(3.6007) | Xent 0.2592(0.3172) | Loss 3.7583(3.7593) | Error 0.0867(0.1120) Steps 760(751.14) | Grad Norm 2.5365(3.7362) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0174 | Time 91.9985, Epoch Time 1106.6095(1060.9906), Bit/dim 3.6049(best: 3.6001), Xent 0.7400, Loss 3.9749, Error 0.2217(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9580 | Time 18.3440(18.1429) | Bit/dim 3.5834(3.5992) | Xent 0.3668(0.3185) | Loss 3.7668(3.7585) | Error 0.1200(0.1125) Steps 760(750.49) | Grad Norm 3.8117(3.7225) | Total Time 14.00(14.00)\n",
      "Iter 9590 | Time 18.5750(18.2105) | Bit/dim 3.6070(3.5984) | Xent 0.3080(0.3161) | Loss 3.7610(3.7565) | Error 0.1111(0.1116) Steps 736(750.27) | Grad Norm 3.0241(3.9434) | Total Time 14.00(14.00)\n",
      "Iter 9600 | Time 18.4722(18.2115) | Bit/dim 3.6002(3.5989) | Xent 0.2939(0.3161) | Loss 3.7471(3.7570) | Error 0.1011(0.1123) Steps 748(749.79) | Grad Norm 2.4678(4.0329) | Total Time 14.00(14.00)\n",
      "Iter 9610 | Time 18.1301(18.2072) | Bit/dim 3.6074(3.5994) | Xent 0.3320(0.3166) | Loss 3.7734(3.7577) | Error 0.1167(0.1124) Steps 754(749.48) | Grad Norm 6.0914(4.1546) | Total Time 14.00(14.00)\n",
      "Iter 9620 | Time 18.1060(18.2665) | Bit/dim 3.6115(3.5997) | Xent 0.3437(0.3168) | Loss 3.7833(3.7581) | Error 0.1222(0.1136) Steps 748(749.73) | Grad Norm 3.7865(4.0724) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0175 | Time 91.2425, Epoch Time 1113.1470(1062.5552), Bit/dim 3.6029(best: 3.6001), Xent 0.7299, Loss 3.9678, Error 0.2202(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9630 | Time 18.7191(18.2428) | Bit/dim 3.5949(3.5994) | Xent 0.2970(0.3189) | Loss 3.7434(3.7588) | Error 0.1056(0.1138) Steps 742(747.80) | Grad Norm 2.3079(3.9955) | Total Time 14.00(14.00)\n",
      "Iter 9640 | Time 18.2826(18.2521) | Bit/dim 3.6276(3.6015) | Xent 0.2911(0.3138) | Loss 3.7731(3.7584) | Error 0.1067(0.1117) Steps 766(748.99) | Grad Norm 3.2054(3.8703) | Total Time 14.00(14.00)\n",
      "Iter 9650 | Time 18.4552(18.2295) | Bit/dim 3.5888(3.5993) | Xent 0.2852(0.3054) | Loss 3.7314(3.7520) | Error 0.1089(0.1082) Steps 760(750.87) | Grad Norm 2.1640(3.5392) | Total Time 14.00(14.00)\n",
      "Iter 9660 | Time 18.5122(18.2229) | Bit/dim 3.6088(3.5966) | Xent 0.3117(0.3112) | Loss 3.7646(3.7522) | Error 0.1167(0.1102) Steps 748(750.78) | Grad Norm 3.7463(3.7337) | Total Time 14.00(14.00)\n",
      "Iter 9670 | Time 18.2086(18.1907) | Bit/dim 3.6176(3.5947) | Xent 0.3977(0.3291) | Loss 3.8164(3.7592) | Error 0.1433(0.1172) Steps 748(750.78) | Grad Norm 3.2943(3.8387) | Total Time 14.00(14.00)\n",
      "Iter 9680 | Time 18.1929(18.2355) | Bit/dim 3.5910(3.5953) | Xent 0.3256(0.3287) | Loss 3.7538(3.7596) | Error 0.1122(0.1166) Steps 754(750.08) | Grad Norm 4.1788(3.8325) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0176 | Time 91.6997, Epoch Time 1111.6964(1064.0295), Bit/dim 3.6043(best: 3.6001), Xent 0.7636, Loss 3.9861, Error 0.2238(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9690 | Time 18.2712(18.2148) | Bit/dim 3.6000(3.5953) | Xent 0.3114(0.3207) | Loss 3.7557(3.7556) | Error 0.1167(0.1145) Steps 760(752.65) | Grad Norm 3.2973(3.6714) | Total Time 14.00(14.00)\n",
      "Iter 9700 | Time 17.9599(18.2781) | Bit/dim 3.6125(3.5978) | Xent 0.2620(0.3197) | Loss 3.7435(3.7577) | Error 0.1022(0.1143) Steps 742(751.24) | Grad Norm 2.6816(3.6896) | Total Time 14.00(14.00)\n",
      "Iter 9710 | Time 18.0783(18.2854) | Bit/dim 3.6275(3.5969) | Xent 0.3020(0.3098) | Loss 3.7785(3.7518) | Error 0.1111(0.1105) Steps 754(750.99) | Grad Norm 4.3372(3.6718) | Total Time 14.00(14.00)\n",
      "Iter 9720 | Time 18.2497(18.2738) | Bit/dim 3.5834(3.5950) | Xent 0.4117(0.3163) | Loss 3.7892(3.7532) | Error 0.1444(0.1122) Steps 760(751.83) | Grad Norm 4.3897(3.7239) | Total Time 14.00(14.00)\n",
      "Iter 9730 | Time 17.9143(18.2509) | Bit/dim 3.6118(3.5959) | Xent 0.3682(0.3237) | Loss 3.7959(3.7577) | Error 0.1278(0.1149) Steps 736(750.89) | Grad Norm 6.2087(3.9049) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0177 | Time 92.4472, Epoch Time 1115.2029(1065.5647), Bit/dim 3.6067(best: 3.6001), Xent 0.7553, Loss 3.9844, Error 0.2205(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9740 | Time 17.9427(18.2673) | Bit/dim 3.5889(3.5980) | Xent 0.3772(0.3313) | Loss 3.7775(3.7637) | Error 0.1356(0.1175) Steps 748(749.58) | Grad Norm 7.7404(4.3350) | Total Time 14.00(14.00)\n",
      "Iter 9750 | Time 18.0818(18.2995) | Bit/dim 3.6120(3.5993) | Xent 0.3639(0.3303) | Loss 3.7939(3.7645) | Error 0.1289(0.1182) Steps 736(750.08) | Grad Norm 3.3196(4.2691) | Total Time 14.00(14.00)\n",
      "Iter 9760 | Time 18.1580(18.1841) | Bit/dim 3.5936(3.5972) | Xent 0.3046(0.3290) | Loss 3.7459(3.7617) | Error 0.1078(0.1177) Steps 742(748.69) | Grad Norm 2.6077(4.3374) | Total Time 14.00(14.00)\n",
      "Iter 9770 | Time 18.0248(18.2283) | Bit/dim 3.6238(3.5963) | Xent 0.3298(0.3206) | Loss 3.7887(3.7566) | Error 0.1111(0.1140) Steps 754(748.76) | Grad Norm 4.5426(4.0144) | Total Time 14.00(14.00)\n",
      "Iter 9780 | Time 18.3135(18.2803) | Bit/dim 3.5911(3.5963) | Xent 0.3150(0.3152) | Loss 3.7486(3.7539) | Error 0.1111(0.1121) Steps 760(748.94) | Grad Norm 2.7750(3.8969) | Total Time 14.00(14.00)\n",
      "Iter 9790 | Time 18.2190(18.2492) | Bit/dim 3.6164(3.5972) | Xent 0.3070(0.3208) | Loss 3.7699(3.7576) | Error 0.1000(0.1134) Steps 754(750.49) | Grad Norm 3.7502(3.8200) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0178 | Time 92.4287, Epoch Time 1113.6481(1067.0072), Bit/dim 3.5981(best: 3.6001), Xent 0.7567, Loss 3.9764, Error 0.2322(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9800 | Time 17.9516(18.1963) | Bit/dim 3.5695(3.5961) | Xent 0.2888(0.3207) | Loss 3.7139(3.7565) | Error 0.0933(0.1129) Steps 748(749.44) | Grad Norm 2.5845(4.0313) | Total Time 14.00(14.00)\n",
      "Iter 9810 | Time 19.2336(18.2239) | Bit/dim 3.5831(3.5952) | Xent 0.3426(0.3153) | Loss 3.7544(3.7529) | Error 0.1222(0.1112) Steps 772(750.38) | Grad Norm 3.5665(3.9266) | Total Time 14.00(14.00)\n",
      "Iter 9820 | Time 17.6485(18.2000) | Bit/dim 3.6270(3.5959) | Xent 0.3522(0.3118) | Loss 3.8031(3.7518) | Error 0.1333(0.1103) Steps 748(751.19) | Grad Norm 3.1403(3.8020) | Total Time 14.00(14.00)\n",
      "Iter 9830 | Time 17.9065(18.2148) | Bit/dim 3.6059(3.5972) | Xent 0.2886(0.3101) | Loss 3.7502(3.7523) | Error 0.1044(0.1101) Steps 754(751.00) | Grad Norm 3.6338(3.8645) | Total Time 14.00(14.00)\n",
      "Iter 9840 | Time 18.8484(18.2793) | Bit/dim 3.5983(3.5990) | Xent 0.2922(0.3088) | Loss 3.7444(3.7534) | Error 0.1033(0.1101) Steps 742(751.07) | Grad Norm 3.5662(3.8729) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0179 | Time 93.6445, Epoch Time 1116.4349(1068.4900), Bit/dim 3.5967(best: 3.5981), Xent 0.7196, Loss 3.9565, Error 0.2204(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9850 | Time 18.4009(18.3184) | Bit/dim 3.5752(3.5950) | Xent 0.2682(0.3036) | Loss 3.7093(3.7468) | Error 0.1067(0.1088) Steps 766(753.62) | Grad Norm 2.3979(3.5846) | Total Time 14.00(14.00)\n",
      "Iter 9860 | Time 18.9433(18.3635) | Bit/dim 3.5654(3.5951) | Xent 0.3142(0.2989) | Loss 3.7225(3.7445) | Error 0.1111(0.1076) Steps 754(755.19) | Grad Norm 4.4713(3.7490) | Total Time 14.00(14.00)\n",
      "Iter 9870 | Time 18.0871(18.3395) | Bit/dim 3.5963(3.5986) | Xent 0.3374(0.3009) | Loss 3.7650(3.7490) | Error 0.1233(0.1079) Steps 754(755.71) | Grad Norm 3.0325(3.7618) | Total Time 14.00(14.00)\n",
      "Iter 9880 | Time 18.0928(18.3508) | Bit/dim 3.6002(3.5979) | Xent 0.3044(0.3038) | Loss 3.7524(3.7498) | Error 0.1222(0.1086) Steps 766(758.85) | Grad Norm 3.2181(3.7584) | Total Time 14.00(14.00)\n",
      "Iter 9890 | Time 17.9962(18.3546) | Bit/dim 3.6041(3.5963) | Xent 0.3358(0.3042) | Loss 3.7720(3.7484) | Error 0.1233(0.1084) Steps 754(758.99) | Grad Norm 3.8493(3.7824) | Total Time 14.00(14.00)\n",
      "Iter 9900 | Time 17.6316(18.3571) | Bit/dim 3.6267(3.5954) | Xent 0.2930(0.3102) | Loss 3.7732(3.7505) | Error 0.1078(0.1104) Steps 754(759.72) | Grad Norm 2.2716(3.7991) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0180 | Time 93.1423, Epoch Time 1121.1009(1070.0683), Bit/dim 3.6078(best: 3.5967), Xent 0.7818, Loss 3.9987, Error 0.2218(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9910 | Time 18.0272(18.3730) | Bit/dim 3.6179(3.5991) | Xent 0.3196(0.3019) | Loss 3.7777(3.7500) | Error 0.1156(0.1075) Steps 760(760.75) | Grad Norm 4.2201(3.7798) | Total Time 14.00(14.00)\n",
      "Iter 9920 | Time 18.3350(18.3049) | Bit/dim 3.6035(3.5996) | Xent 0.3418(0.3069) | Loss 3.7744(3.7531) | Error 0.1167(0.1092) Steps 754(759.81) | Grad Norm 5.2330(4.0674) | Total Time 14.00(14.00)\n",
      "Iter 9930 | Time 17.9995(18.2976) | Bit/dim 3.5703(3.5989) | Xent 0.3314(0.3173) | Loss 3.7359(3.7576) | Error 0.1156(0.1120) Steps 754(759.67) | Grad Norm 2.9585(4.2746) | Total Time 14.00(14.00)\n",
      "Iter 9940 | Time 18.2263(18.2148) | Bit/dim 3.6126(3.5982) | Xent 0.3891(0.3331) | Loss 3.8071(3.7647) | Error 0.1389(0.1178) Steps 754(758.48) | Grad Norm 5.8397(4.7656) | Total Time 14.00(14.00)\n",
      "Iter 9950 | Time 18.5931(18.2536) | Bit/dim 3.6282(3.6000) | Xent 0.3083(0.3301) | Loss 3.7823(3.7651) | Error 0.1078(0.1171) Steps 766(759.39) | Grad Norm 2.8266(4.4998) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0181 | Time 92.4212, Epoch Time 1113.1403(1071.3605), Bit/dim 3.6000(best: 3.5967), Xent 0.7425, Loss 3.9712, Error 0.2203(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9960 | Time 18.0310(18.2607) | Bit/dim 3.6182(3.5972) | Xent 0.2807(0.3204) | Loss 3.7586(3.7574) | Error 0.0967(0.1138) Steps 754(758.45) | Grad Norm 3.7940(4.1054) | Total Time 14.00(14.00)\n",
      "Iter 9970 | Time 17.9782(18.2926) | Bit/dim 3.6350(3.5962) | Xent 0.3088(0.3149) | Loss 3.7894(3.7537) | Error 0.1111(0.1116) Steps 760(758.13) | Grad Norm 6.9333(4.2157) | Total Time 14.00(14.00)\n",
      "Iter 9980 | Time 18.0334(18.2831) | Bit/dim 3.5856(3.5960) | Xent 0.2685(0.3102) | Loss 3.7199(3.7511) | Error 0.0956(0.1097) Steps 772(758.77) | Grad Norm 3.0515(4.0757) | Total Time 14.00(14.00)\n",
      "Iter 9990 | Time 18.2278(18.2668) | Bit/dim 3.5628(3.5970) | Xent 0.3413(0.3120) | Loss 3.7335(3.7531) | Error 0.1256(0.1108) Steps 754(758.16) | Grad Norm 3.2310(4.0326) | Total Time 14.00(14.00)\n",
      "Iter 10000 | Time 18.8217(18.2405) | Bit/dim 3.5985(3.5951) | Xent 0.3295(0.3182) | Loss 3.7633(3.7542) | Error 0.1256(0.1131) Steps 766(758.54) | Grad Norm 4.3259(4.1344) | Total Time 14.00(14.00)\n",
      "Iter 10010 | Time 18.3053(18.2540) | Bit/dim 3.5948(3.5986) | Xent 0.3105(0.3123) | Loss 3.7501(3.7548) | Error 0.1078(0.1113) Steps 778(759.41) | Grad Norm 2.9880(4.0741) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0182 | Time 92.8407, Epoch Time 1115.0571(1072.6714), Bit/dim 3.5952(best: 3.5967), Xent 0.7669, Loss 3.9786, Error 0.2273(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10020 | Time 18.9423(18.3169) | Bit/dim 3.5891(3.5980) | Xent 0.2543(0.3028) | Loss 3.7163(3.7494) | Error 0.0822(0.1065) Steps 784(760.75) | Grad Norm 3.0037(3.8092) | Total Time 14.00(14.00)\n",
      "Iter 10030 | Time 18.6102(18.3345) | Bit/dim 3.5977(3.5963) | Xent 0.3186(0.3033) | Loss 3.7570(3.7480) | Error 0.1244(0.1073) Steps 766(761.86) | Grad Norm 4.9949(3.7649) | Total Time 14.00(14.00)\n",
      "Iter 10040 | Time 18.4153(18.2813) | Bit/dim 3.5778(3.5952) | Xent 0.2327(0.3027) | Loss 3.6941(3.7466) | Error 0.0900(0.1077) Steps 754(762.32) | Grad Norm 2.3245(4.0341) | Total Time 14.00(14.00)\n",
      "Iter 10050 | Time 18.3949(18.3578) | Bit/dim 3.6034(3.5946) | Xent 0.2899(0.3013) | Loss 3.7483(3.7453) | Error 0.1100(0.1084) Steps 760(761.42) | Grad Norm 2.8821(3.9052) | Total Time 14.00(14.00)\n",
      "Iter 10060 | Time 18.5100(18.3987) | Bit/dim 3.5959(3.5943) | Xent 0.2862(0.3025) | Loss 3.7390(3.7455) | Error 0.1100(0.1090) Steps 778(762.77) | Grad Norm 3.3937(3.9161) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0183 | Time 93.1127, Epoch Time 1123.5043(1074.1964), Bit/dim 3.6005(best: 3.5952), Xent 0.7546, Loss 3.9778, Error 0.2178(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10070 | Time 18.3139(18.3909) | Bit/dim 3.5997(3.5943) | Xent 0.3103(0.3035) | Loss 3.7549(3.7460) | Error 0.1056(0.1083) Steps 754(762.79) | Grad Norm 2.8559(3.7719) | Total Time 14.00(14.00)\n",
      "Iter 10080 | Time 18.2922(18.3328) | Bit/dim 3.6197(3.5944) | Xent 0.2873(0.2970) | Loss 3.7633(3.7429) | Error 0.0978(0.1063) Steps 760(761.72) | Grad Norm 2.9539(3.7256) | Total Time 14.00(14.00)\n",
      "Iter 10090 | Time 18.6182(18.3231) | Bit/dim 3.5884(3.5934) | Xent 0.3342(0.2969) | Loss 3.7555(3.7419) | Error 0.1233(0.1066) Steps 772(762.50) | Grad Norm 3.8727(3.6983) | Total Time 14.00(14.00)\n",
      "Iter 10100 | Time 18.0147(18.3703) | Bit/dim 3.5832(3.5930) | Xent 0.3381(0.2970) | Loss 3.7522(3.7416) | Error 0.1144(0.1062) Steps 760(763.67) | Grad Norm 4.2368(3.6141) | Total Time 14.00(14.00)\n",
      "Iter 10110 | Time 18.4154(18.4500) | Bit/dim 3.5933(3.5924) | Xent 0.3024(0.2957) | Loss 3.7445(3.7403) | Error 0.1111(0.1061) Steps 766(763.67) | Grad Norm 2.6721(3.6616) | Total Time 14.00(14.00)\n",
      "Iter 10120 | Time 18.3388(18.4204) | Bit/dim 3.5909(3.5961) | Xent 0.2774(0.2917) | Loss 3.7297(3.7420) | Error 0.0989(0.1048) Steps 754(762.52) | Grad Norm 4.7786(3.7262) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0184 | Time 94.1825, Epoch Time 1124.0647(1075.6924), Bit/dim 3.5982(best: 3.5952), Xent 0.7714, Loss 3.9839, Error 0.2256(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10130 | Time 18.5583(18.4293) | Bit/dim 3.5774(3.5954) | Xent 0.2647(0.2826) | Loss 3.7097(3.7367) | Error 0.1011(0.1022) Steps 784(763.34) | Grad Norm 3.1370(3.5724) | Total Time 14.00(14.00)\n",
      "Iter 10140 | Time 18.3219(18.4706) | Bit/dim 3.5892(3.5926) | Xent 0.2828(0.2898) | Loss 3.7306(3.7375) | Error 0.1089(0.1044) Steps 760(760.76) | Grad Norm 3.4007(3.6797) | Total Time 14.00(14.00)\n",
      "Iter 10150 | Time 18.0177(18.4316) | Bit/dim 3.5799(3.5915) | Xent 0.2885(0.2887) | Loss 3.7241(3.7358) | Error 0.1178(0.1035) Steps 766(761.22) | Grad Norm 3.4003(3.5056) | Total Time 14.00(14.00)\n",
      "Iter 10160 | Time 18.2378(18.4617) | Bit/dim 3.5793(3.5930) | Xent 0.3029(0.2870) | Loss 3.7307(3.7365) | Error 0.0978(0.1022) Steps 760(761.53) | Grad Norm 3.5548(3.5688) | Total Time 14.00(14.00)\n",
      "Iter 10170 | Time 19.1873(18.5259) | Bit/dim 3.6142(3.5952) | Xent 0.2887(0.2894) | Loss 3.7585(3.7399) | Error 0.1044(0.1039) Steps 754(761.19) | Grad Norm 3.8670(3.6208) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0185 | Time 94.8581, Epoch Time 1131.4601(1077.3655), Bit/dim 3.5969(best: 3.5952), Xent 0.8636, Loss 4.0287, Error 0.2388(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10180 | Time 18.2121(18.4419) | Bit/dim 3.6023(3.5930) | Xent 0.2579(0.2877) | Loss 3.7313(3.7369) | Error 0.0944(0.1027) Steps 748(761.43) | Grad Norm 3.7871(3.8518) | Total Time 14.00(14.00)\n",
      "Iter 10190 | Time 18.3899(18.4395) | Bit/dim 3.5815(3.5938) | Xent 0.2808(0.2928) | Loss 3.7219(3.7401) | Error 0.0978(0.1048) Steps 748(760.87) | Grad Norm 6.6268(4.1859) | Total Time 14.00(14.00)\n",
      "Iter 10200 | Time 18.9385(18.4415) | Bit/dim 3.6053(3.5955) | Xent 0.2812(0.2878) | Loss 3.7459(3.7394) | Error 0.1089(0.1029) Steps 766(760.97) | Grad Norm 4.1730(3.9994) | Total Time 14.00(14.00)\n",
      "Iter 10210 | Time 18.3640(18.4291) | Bit/dim 3.5896(3.5949) | Xent 0.3179(0.2873) | Loss 3.7485(3.7386) | Error 0.1089(0.1023) Steps 760(763.03) | Grad Norm 3.7265(3.9865) | Total Time 14.00(14.00)\n",
      "Iter 10220 | Time 18.3344(18.4302) | Bit/dim 3.6055(3.5942) | Xent 0.3020(0.2891) | Loss 3.7565(3.7387) | Error 0.1022(0.1028) Steps 760(762.36) | Grad Norm 3.9492(4.0447) | Total Time 14.00(14.00)\n",
      "Iter 10230 | Time 19.1341(18.5318) | Bit/dim 3.6055(3.5958) | Xent 0.3321(0.2981) | Loss 3.7716(3.7448) | Error 0.1189(0.1055) Steps 766(765.92) | Grad Norm 6.6413(4.2980) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0186 | Time 94.9182, Epoch Time 1127.3092(1078.8638), Bit/dim 3.5993(best: 3.5952), Xent 0.8030, Loss 4.0008, Error 0.2246(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10240 | Time 18.4421(18.4714) | Bit/dim 3.6004(3.5977) | Xent 0.2639(0.2965) | Loss 3.7323(3.7459) | Error 0.0989(0.1061) Steps 766(765.91) | Grad Norm 3.0632(4.3037) | Total Time 14.00(14.00)\n",
      "Iter 10250 | Time 18.3703(18.4729) | Bit/dim 3.6347(3.5987) | Xent 0.3742(0.3016) | Loss 3.8219(3.7495) | Error 0.1389(0.1077) Steps 754(767.93) | Grad Norm 7.2535(4.5248) | Total Time 14.00(14.00)\n",
      "Iter 10260 | Time 17.9920(18.4614) | Bit/dim 3.5886(3.5977) | Xent 0.3370(0.3051) | Loss 3.7571(3.7503) | Error 0.1267(0.1092) Steps 754(767.35) | Grad Norm 3.9435(4.4362) | Total Time 14.00(14.00)\n",
      "Iter 10270 | Time 19.5749(18.5241) | Bit/dim 3.6173(3.5989) | Xent 0.3342(0.3072) | Loss 3.7844(3.7525) | Error 0.1078(0.1090) Steps 772(767.41) | Grad Norm 4.3741(4.4515) | Total Time 14.00(14.00)\n",
      "Iter 10280 | Time 18.8913(18.6037) | Bit/dim 3.5803(3.5949) | Xent 0.3235(0.3053) | Loss 3.7420(3.7475) | Error 0.1144(0.1089) Steps 778(769.33) | Grad Norm 2.6073(4.2634) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0187 | Time 93.5420, Epoch Time 1130.6744(1080.4181), Bit/dim 3.6093(best: 3.5952), Xent 0.8894, Loss 4.0540, Error 0.2419(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10290 | Time 18.0793(18.5710) | Bit/dim 3.5965(3.5950) | Xent 0.3180(0.3107) | Loss 3.7555(3.7503) | Error 0.1167(0.1115) Steps 760(769.40) | Grad Norm 4.7602(4.5569) | Total Time 14.00(14.00)\n",
      "Iter 10300 | Time 19.1651(18.5867) | Bit/dim 3.5696(3.5934) | Xent 0.3347(0.3109) | Loss 3.7369(3.7488) | Error 0.1211(0.1113) Steps 784(769.56) | Grad Norm 4.5038(4.4091) | Total Time 14.00(14.00)\n",
      "Iter 10310 | Time 18.3288(18.5899) | Bit/dim 3.5734(3.5953) | Xent 0.2550(0.3039) | Loss 3.7009(3.7472) | Error 0.0889(0.1086) Steps 766(768.55) | Grad Norm 4.5699(4.2152) | Total Time 14.00(14.00)\n",
      "Iter 10320 | Time 18.1270(18.5493) | Bit/dim 3.6275(3.5953) | Xent 0.2401(0.2928) | Loss 3.7476(3.7417) | Error 0.0878(0.1043) Steps 778(769.00) | Grad Norm 2.6501(3.9589) | Total Time 14.00(14.00)\n",
      "Iter 10330 | Time 18.6402(18.5106) | Bit/dim 3.5642(3.5947) | Xent 0.3340(0.2914) | Loss 3.7312(3.7404) | Error 0.1189(0.1040) Steps 772(768.67) | Grad Norm 4.5663(3.8124) | Total Time 14.00(14.00)\n",
      "Iter 10340 | Time 18.6207(18.5714) | Bit/dim 3.5967(3.5932) | Xent 0.3106(0.2947) | Loss 3.7519(3.7405) | Error 0.1033(0.1061) Steps 772(770.93) | Grad Norm 3.4621(3.7279) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0188 | Time 96.0907, Epoch Time 1134.3453(1082.0359), Bit/dim 3.5951(best: 3.5952), Xent 0.7712, Loss 3.9807, Error 0.2191(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10350 | Time 19.4875(18.5908) | Bit/dim 3.6020(3.5937) | Xent 0.4079(0.3007) | Loss 3.8060(3.7440) | Error 0.1344(0.1080) Steps 796(772.89) | Grad Norm 8.3011(4.2478) | Total Time 14.00(14.00)\n",
      "Iter 10360 | Time 19.0900(18.5892) | Bit/dim 3.5982(3.5931) | Xent 0.2670(0.2987) | Loss 3.7317(3.7424) | Error 0.0922(0.1065) Steps 778(770.81) | Grad Norm 3.0670(4.1746) | Total Time 14.00(14.00)\n",
      "Iter 10370 | Time 18.6615(18.6056) | Bit/dim 3.5811(3.5919) | Xent 0.2766(0.2937) | Loss 3.7194(3.7387) | Error 0.0922(0.1045) Steps 760(770.72) | Grad Norm 3.0711(3.9469) | Total Time 14.00(14.00)\n",
      "Iter 10380 | Time 19.1935(18.7125) | Bit/dim 3.6220(3.5944) | Xent 0.2395(0.2860) | Loss 3.7417(3.7373) | Error 0.0844(0.1014) Steps 778(773.87) | Grad Norm 2.8035(3.7948) | Total Time 14.00(14.00)\n",
      "Iter 10390 | Time 19.0826(18.7760) | Bit/dim 3.5952(3.5935) | Xent 0.2402(0.2859) | Loss 3.7152(3.7364) | Error 0.0822(0.1008) Steps 790(775.58) | Grad Norm 3.6516(3.7848) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0189 | Time 93.2527, Epoch Time 1143.4985(1083.8798), Bit/dim 3.5963(best: 3.5951), Xent 0.8052, Loss 3.9989, Error 0.2272(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10400 | Time 18.8168(18.8396) | Bit/dim 3.5751(3.5919) | Xent 0.2895(0.2793) | Loss 3.7198(3.7316) | Error 0.1067(0.0985) Steps 766(775.04) | Grad Norm 3.7554(3.6361) | Total Time 14.00(14.00)\n",
      "Iter 10410 | Time 19.0217(18.8243) | Bit/dim 3.5862(3.5927) | Xent 0.3533(0.2851) | Loss 3.7628(3.7352) | Error 0.1256(0.1009) Steps 766(774.37) | Grad Norm 6.2328(3.9025) | Total Time 14.00(14.00)\n",
      "Iter 10420 | Time 19.2275(18.8539) | Bit/dim 3.5900(3.5943) | Xent 0.3486(0.2928) | Loss 3.7643(3.7407) | Error 0.1300(0.1045) Steps 772(774.64) | Grad Norm 5.0444(4.2611) | Total Time 14.00(14.00)\n",
      "Iter 10430 | Time 18.1664(18.7014) | Bit/dim 3.5830(3.5946) | Xent 0.2667(0.2974) | Loss 3.7164(3.7433) | Error 0.1100(0.1060) Steps 760(772.04) | Grad Norm 3.4176(4.3134) | Total Time 14.00(14.00)\n",
      "Iter 10440 | Time 18.2511(18.6648) | Bit/dim 3.5950(3.5964) | Xent 0.3082(0.2982) | Loss 3.7491(3.7455) | Error 0.1056(0.1060) Steps 760(770.68) | Grad Norm 3.5739(4.1570) | Total Time 14.00(14.00)\n",
      "Iter 10450 | Time 18.1856(18.5899) | Bit/dim 3.6214(3.5941) | Xent 0.2837(0.2959) | Loss 3.7633(3.7421) | Error 0.0978(0.1050) Steps 760(769.20) | Grad Norm 2.7482(3.9457) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0190 | Time 91.2481, Epoch Time 1133.7285(1085.3753), Bit/dim 3.5979(best: 3.5951), Xent 0.7527, Loss 3.9743, Error 0.2217(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10460 | Time 18.9546(18.6115) | Bit/dim 3.5651(3.5952) | Xent 0.2128(0.2831) | Loss 3.6715(3.7368) | Error 0.0767(0.1004) Steps 784(770.64) | Grad Norm 3.3234(3.7684) | Total Time 14.00(14.00)\n",
      "Iter 10470 | Time 18.6106(18.6083) | Bit/dim 3.6131(3.5966) | Xent 0.2620(0.2772) | Loss 3.7441(3.7352) | Error 0.0878(0.0983) Steps 760(768.87) | Grad Norm 2.4303(3.6449) | Total Time 14.00(14.00)\n",
      "Iter 10480 | Time 18.2895(18.6159) | Bit/dim 3.5973(3.5930) | Xent 0.2961(0.2763) | Loss 3.7453(3.7312) | Error 0.0978(0.0984) Steps 766(770.20) | Grad Norm 3.7295(3.6652) | Total Time 14.00(14.00)\n",
      "Iter 10490 | Time 18.6801(18.6220) | Bit/dim 3.5782(3.5918) | Xent 0.3436(0.2818) | Loss 3.7500(3.7327) | Error 0.1189(0.0999) Steps 778(770.39) | Grad Norm 6.2271(3.8330) | Total Time 14.00(14.00)\n",
      "Iter 10500 | Time 18.3446(18.6080) | Bit/dim 3.5721(3.5900) | Xent 0.2946(0.2812) | Loss 3.7193(3.7306) | Error 0.1089(0.1009) Steps 772(770.15) | Grad Norm 3.7574(3.7679) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0191 | Time 93.6938, Epoch Time 1135.4167(1086.8765), Bit/dim 3.5988(best: 3.5951), Xent 0.7779, Loss 3.9877, Error 0.2205(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10510 | Time 18.6613(18.6342) | Bit/dim 3.5492(3.5892) | Xent 0.2633(0.2819) | Loss 3.6809(3.7302) | Error 0.0911(0.1013) Steps 766(772.14) | Grad Norm 3.7997(3.8160) | Total Time 14.00(14.00)\n",
      "Iter 10520 | Time 18.9809(18.6231) | Bit/dim 3.5717(3.5890) | Xent 0.2952(0.2771) | Loss 3.7193(3.7276) | Error 0.1000(0.0986) Steps 772(769.62) | Grad Norm 5.4232(3.7481) | Total Time 14.00(14.00)\n",
      "Iter 10530 | Time 18.6031(18.5386) | Bit/dim 3.5904(3.5890) | Xent 0.3449(0.2797) | Loss 3.7629(3.7288) | Error 0.1222(0.0995) Steps 760(769.28) | Grad Norm 4.1267(3.8549) | Total Time 14.00(14.00)\n",
      "Iter 10540 | Time 18.9753(18.5827) | Bit/dim 3.5930(3.5899) | Xent 0.2701(0.2878) | Loss 3.7280(3.7338) | Error 0.1022(0.1025) Steps 778(769.39) | Grad Norm 2.8180(4.0520) | Total Time 14.00(14.00)\n",
      "Iter 10550 | Time 19.2006(18.6019) | Bit/dim 3.6007(3.5919) | Xent 0.3434(0.2998) | Loss 3.7724(3.7418) | Error 0.1222(0.1060) Steps 796(771.58) | Grad Norm 3.2266(4.2432) | Total Time 14.00(14.00)\n",
      "Iter 10560 | Time 19.0500(18.6628) | Bit/dim 3.5966(3.5933) | Xent 0.2682(0.3016) | Loss 3.7307(3.7442) | Error 0.0956(0.1066) Steps 778(773.45) | Grad Norm 2.2967(4.1561) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0192 | Time 92.6405, Epoch Time 1135.1172(1088.3237), Bit/dim 3.5989(best: 3.5951), Xent 0.7750, Loss 3.9864, Error 0.2199(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10570 | Time 18.9873(18.7653) | Bit/dim 3.6266(3.5939) | Xent 0.2239(0.2965) | Loss 3.7386(3.7421) | Error 0.0811(0.1047) Steps 766(773.57) | Grad Norm 2.5645(4.0621) | Total Time 14.00(14.00)\n",
      "Iter 10580 | Time 18.6496(18.7330) | Bit/dim 3.5883(3.5918) | Xent 0.2323(0.2871) | Loss 3.7044(3.7354) | Error 0.0833(0.1019) Steps 778(771.62) | Grad Norm 3.6127(3.7728) | Total Time 14.00(14.00)\n",
      "Iter 10590 | Time 18.1898(18.7835) | Bit/dim 3.6134(3.5901) | Xent 0.2727(0.2837) | Loss 3.7497(3.7320) | Error 0.0878(0.1009) Steps 754(773.07) | Grad Norm 4.0379(3.9346) | Total Time 14.00(14.00)\n",
      "Iter 10600 | Time 19.1332(18.7778) | Bit/dim 3.5575(3.5895) | Xent 0.3512(0.2862) | Loss 3.7331(3.7326) | Error 0.1100(0.1016) Steps 772(772.21) | Grad Norm 7.1293(4.2629) | Total Time 14.00(14.00)\n",
      "Iter 10610 | Time 18.7713(18.7514) | Bit/dim 3.5913(3.5918) | Xent 0.2997(0.2891) | Loss 3.7411(3.7364) | Error 0.1022(0.1024) Steps 766(772.19) | Grad Norm 4.2263(4.2068) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0193 | Time 93.8264, Epoch Time 1147.7503(1090.1065), Bit/dim 3.6059(best: 3.5951), Xent 0.7795, Loss 3.9957, Error 0.2254(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10620 | Time 18.6083(18.7575) | Bit/dim 3.6115(3.5954) | Xent 0.2667(0.2829) | Loss 3.7448(3.7368) | Error 0.0944(0.1002) Steps 766(773.27) | Grad Norm 5.0257(4.2812) | Total Time 14.00(14.00)\n",
      "Iter 10630 | Time 19.2604(18.7197) | Bit/dim 3.5808(3.5960) | Xent 0.2187(0.2752) | Loss 3.6902(3.7336) | Error 0.0767(0.0976) Steps 790(774.37) | Grad Norm 2.6811(4.1141) | Total Time 14.00(14.00)\n",
      "Iter 10640 | Time 18.6660(18.7414) | Bit/dim 3.6117(3.5959) | Xent 0.2918(0.2762) | Loss 3.7576(3.7340) | Error 0.0911(0.0978) Steps 766(774.90) | Grad Norm 4.3345(4.2643) | Total Time 14.00(14.00)\n",
      "Iter 10650 | Time 18.4336(18.7279) | Bit/dim 3.6186(3.5961) | Xent 0.3035(0.2794) | Loss 3.7703(3.7358) | Error 0.0967(0.0987) Steps 760(773.52) | Grad Norm 3.9373(4.3321) | Total Time 14.00(14.00)\n",
      "Iter 10660 | Time 18.3112(18.7197) | Bit/dim 3.5661(3.5946) | Xent 0.3082(0.2937) | Loss 3.7202(3.7415) | Error 0.1167(0.1038) Steps 778(775.30) | Grad Norm 4.4829(4.4841) | Total Time 14.00(14.00)\n",
      "Iter 10670 | Time 19.0724(18.7038) | Bit/dim 3.5973(3.5917) | Xent 0.2930(0.3018) | Loss 3.7437(3.7426) | Error 0.1078(0.1067) Steps 790(774.97) | Grad Norm 5.0814(4.5097) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0194 | Time 95.9873, Epoch Time 1140.6406(1091.6225), Bit/dim 3.5995(best: 3.5951), Xent 0.7745, Loss 3.9867, Error 0.2255(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10680 | Time 18.3982(18.6553) | Bit/dim 3.5734(3.5935) | Xent 0.2387(0.2967) | Loss 3.6927(3.7418) | Error 0.0833(0.1044) Steps 778(774.51) | Grad Norm 2.9087(4.3227) | Total Time 14.00(14.00)\n",
      "Iter 10690 | Time 18.8110(18.7089) | Bit/dim 3.6046(3.5944) | Xent 0.2217(0.2860) | Loss 3.7154(3.7374) | Error 0.0800(0.1001) Steps 778(775.50) | Grad Norm 3.0425(4.0956) | Total Time 14.00(14.00)\n",
      "Iter 10700 | Time 19.7827(18.7585) | Bit/dim 3.6045(3.5933) | Xent 0.2889(0.2819) | Loss 3.7490(3.7343) | Error 0.1044(0.0984) Steps 796(776.19) | Grad Norm 4.2300(3.9213) | Total Time 14.00(14.00)\n",
      "Iter 10710 | Time 18.8854(18.7610) | Bit/dim 3.5865(3.5905) | Xent 0.3073(0.2785) | Loss 3.7402(3.7298) | Error 0.1122(0.0982) Steps 790(777.54) | Grad Norm 4.6833(3.9247) | Total Time 14.00(14.00)\n",
      "Iter 10720 | Time 18.6926(18.7367) | Bit/dim 3.6229(3.5908) | Xent 0.2656(0.2736) | Loss 3.7557(3.7275) | Error 0.1044(0.0969) Steps 778(777.75) | Grad Norm 3.0860(3.8428) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0195 | Time 94.1543, Epoch Time 1142.1329(1093.1379), Bit/dim 3.5936(best: 3.5951), Xent 0.8240, Loss 4.0055, Error 0.2265(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10730 | Time 18.8613(18.7661) | Bit/dim 3.6019(3.5924) | Xent 0.2495(0.2713) | Loss 3.7266(3.7280) | Error 0.0856(0.0963) Steps 790(779.52) | Grad Norm 4.0900(3.7888) | Total Time 14.00(14.00)\n",
      "Iter 10740 | Time 19.3289(18.9248) | Bit/dim 3.5758(3.5887) | Xent 0.3198(0.2777) | Loss 3.7357(3.7276) | Error 0.1156(0.0983) Steps 796(784.40) | Grad Norm 4.9922(4.0355) | Total Time 14.00(14.00)\n",
      "Iter 10750 | Time 18.8884(18.8649) | Bit/dim 3.5779(3.5892) | Xent 0.2157(0.2747) | Loss 3.6857(3.7266) | Error 0.0844(0.0975) Steps 778(782.71) | Grad Norm 3.0939(4.0211) | Total Time 14.00(14.00)\n",
      "Iter 10760 | Time 19.1774(18.9303) | Bit/dim 3.5866(3.5901) | Xent 0.3063(0.2760) | Loss 3.7398(3.7281) | Error 0.1022(0.0980) Steps 796(786.32) | Grad Norm 3.9251(4.0111) | Total Time 14.00(14.00)\n",
      "Iter 10770 | Time 19.5767(18.9617) | Bit/dim 3.5930(3.5903) | Xent 0.2673(0.2760) | Loss 3.7266(3.7283) | Error 0.0900(0.0983) Steps 802(788.23) | Grad Norm 2.8974(3.9714) | Total Time 14.00(14.00)\n",
      "Iter 10780 | Time 18.5242(18.9736) | Bit/dim 3.6061(3.5915) | Xent 0.2659(0.2766) | Loss 3.7390(3.7299) | Error 0.0956(0.0982) Steps 778(789.83) | Grad Norm 3.9158(4.0145) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0196 | Time 93.9988, Epoch Time 1159.3542(1095.1243), Bit/dim 3.6035(best: 3.5936), Xent 0.8030, Loss 4.0049, Error 0.2258(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10790 | Time 18.4599(18.9430) | Bit/dim 3.5936(3.5911) | Xent 0.2210(0.2694) | Loss 3.7041(3.7258) | Error 0.0756(0.0964) Steps 760(789.30) | Grad Norm 2.6352(3.8516) | Total Time 14.00(14.00)\n",
      "Iter 10800 | Time 18.9027(18.9256) | Bit/dim 3.5824(3.5906) | Xent 0.2565(0.2647) | Loss 3.7106(3.7229) | Error 0.0967(0.0946) Steps 772(789.18) | Grad Norm 3.7521(3.7662) | Total Time 14.00(14.00)\n",
      "Iter 10810 | Time 18.8198(18.9398) | Bit/dim 3.6124(3.5920) | Xent 0.3532(0.2672) | Loss 3.7890(3.7256) | Error 0.1144(0.0949) Steps 784(789.25) | Grad Norm 8.0979(4.0410) | Total Time 14.00(14.00)\n",
      "Iter 10820 | Time 18.9307(18.9411) | Bit/dim 3.5980(3.5921) | Xent 0.4031(0.2907) | Loss 3.7995(3.7375) | Error 0.1389(0.1031) Steps 814(790.55) | Grad Norm 6.8866(4.3516) | Total Time 14.00(14.00)\n",
      "Iter 10830 | Time 18.2564(18.9614) | Bit/dim 3.5977(3.5949) | Xent 0.3521(0.2965) | Loss 3.7737(3.7432) | Error 0.1222(0.1046) Steps 766(788.15) | Grad Norm 4.1208(4.3670) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0197 | Time 95.6696, Epoch Time 1155.7969(1096.9445), Bit/dim 3.5996(best: 3.5936), Xent 0.7573, Loss 3.9783, Error 0.2259(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10840 | Time 18.6470(18.9970) | Bit/dim 3.6023(3.5962) | Xent 0.2975(0.2978) | Loss 3.7510(3.7451) | Error 0.1122(0.1052) Steps 796(790.10) | Grad Norm 6.5274(4.4630) | Total Time 14.00(14.00)\n",
      "Iter 10850 | Time 19.4460(19.0607) | Bit/dim 3.5806(3.5944) | Xent 0.2638(0.2923) | Loss 3.7125(3.7406) | Error 0.1000(0.1034) Steps 796(789.17) | Grad Norm 2.7845(4.2992) | Total Time 14.00(14.00)\n",
      "Iter 10860 | Time 20.4381(19.1797) | Bit/dim 3.5866(3.5933) | Xent 0.2764(0.2841) | Loss 3.7248(3.7353) | Error 0.1011(0.1012) Steps 802(793.56) | Grad Norm 3.8151(4.1665) | Total Time 14.00(14.00)\n",
      "Iter 10870 | Time 19.1952(19.1836) | Bit/dim 3.5824(3.5929) | Xent 0.2972(0.2803) | Loss 3.7310(3.7331) | Error 0.0922(0.0996) Steps 802(794.32) | Grad Norm 3.7946(4.1187) | Total Time 14.00(14.00)\n",
      "Iter 10880 | Time 19.0048(19.1788) | Bit/dim 3.6033(3.5930) | Xent 0.2822(0.2799) | Loss 3.7444(3.7330) | Error 0.0944(0.1001) Steps 790(796.00) | Grad Norm 5.2664(4.1435) | Total Time 14.00(14.00)\n",
      "Iter 10890 | Time 19.2435(19.1337) | Bit/dim 3.5823(3.5922) | Xent 0.3098(0.2829) | Loss 3.7372(3.7337) | Error 0.1089(0.1020) Steps 790(793.72) | Grad Norm 3.4037(4.0849) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0198 | Time 94.3575, Epoch Time 1168.3135(1099.0856), Bit/dim 3.5945(best: 3.5936), Xent 0.8544, Loss 4.0217, Error 0.2366(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10900 | Time 19.3007(19.1590) | Bit/dim 3.5902(3.5915) | Xent 0.2550(0.2814) | Loss 3.7177(3.7321) | Error 0.0922(0.1013) Steps 796(795.30) | Grad Norm 4.2682(4.2783) | Total Time 14.00(14.00)\n",
      "Iter 10910 | Time 19.3334(19.1402) | Bit/dim 3.5928(3.5927) | Xent 0.2486(0.2751) | Loss 3.7170(3.7303) | Error 0.0789(0.0989) Steps 802(794.50) | Grad Norm 2.5668(4.0842) | Total Time 14.00(14.00)\n",
      "Iter 10920 | Time 18.5557(19.1605) | Bit/dim 3.5617(3.5893) | Xent 0.2523(0.2692) | Loss 3.6878(3.7239) | Error 0.0833(0.0960) Steps 790(795.52) | Grad Norm 3.3876(3.9319) | Total Time 14.00(14.00)\n",
      "Iter 10930 | Time 19.6998(19.2639) | Bit/dim 3.5897(3.5899) | Xent 0.3166(0.2711) | Loss 3.7480(3.7254) | Error 0.1189(0.0961) Steps 790(798.27) | Grad Norm 3.5141(3.8933) | Total Time 14.00(14.00)\n",
      "Iter 10940 | Time 19.9020(19.4181) | Bit/dim 3.5944(3.5893) | Xent 0.2421(0.2687) | Loss 3.7155(3.7236) | Error 0.0844(0.0954) Steps 826(803.19) | Grad Norm 2.7767(3.7778) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0199 | Time 95.0899, Epoch Time 1179.7194(1101.5046), Bit/dim 3.5971(best: 3.5936), Xent 0.7622, Loss 3.9783, Error 0.2165(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10950 | Time 18.6490(19.3943) | Bit/dim 3.6297(3.5889) | Xent 0.2113(0.2585) | Loss 3.7354(3.7181) | Error 0.0744(0.0916) Steps 790(804.96) | Grad Norm 2.5779(3.5030) | Total Time 14.00(14.00)\n",
      "Iter 10960 | Time 19.7500(19.3778) | Bit/dim 3.5974(3.5867) | Xent 0.2545(0.2528) | Loss 3.7246(3.7131) | Error 0.0922(0.0885) Steps 802(806.44) | Grad Norm 4.0362(3.5271) | Total Time 14.00(14.00)\n",
      "Iter 10970 | Time 19.2584(19.3880) | Bit/dim 3.6145(3.5874) | Xent 0.2625(0.2524) | Loss 3.7458(3.7136) | Error 0.0856(0.0888) Steps 802(805.69) | Grad Norm 3.6973(3.6330) | Total Time 14.00(14.00)\n",
      "Iter 10980 | Time 19.2096(19.3917) | Bit/dim 3.5757(3.5881) | Xent 0.3681(0.2712) | Loss 3.7598(3.7237) | Error 0.1389(0.0960) Steps 808(804.96) | Grad Norm 8.3412(4.2390) | Total Time 14.00(14.00)\n",
      "Iter 10990 | Time 19.6852(19.3688) | Bit/dim 3.5800(3.5917) | Xent 0.3030(0.2819) | Loss 3.7315(3.7326) | Error 0.1111(0.1001) Steps 814(806.27) | Grad Norm 4.6294(4.3693) | Total Time 14.00(14.00)\n",
      "Iter 11000 | Time 20.2658(19.4650) | Bit/dim 3.5977(3.5907) | Xent 0.2718(0.2818) | Loss 3.7336(3.7316) | Error 0.0989(0.1004) Steps 832(811.13) | Grad Norm 5.2596(4.4897) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0200 | Time 97.7775, Epoch Time 1182.7090(1103.9407), Bit/dim 3.6070(best: 3.5936), Xent 0.8185, Loss 4.0162, Error 0.2243(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11010 | Time 20.0819(19.5434) | Bit/dim 3.6298(3.5916) | Xent 0.3092(0.2764) | Loss 3.7844(3.7298) | Error 0.1133(0.0989) Steps 814(812.03) | Grad Norm 7.0476(4.5414) | Total Time 14.00(14.00)\n",
      "Iter 11020 | Time 18.9756(19.4932) | Bit/dim 3.5859(3.5930) | Xent 0.2752(0.2736) | Loss 3.7235(3.7298) | Error 0.1033(0.0983) Steps 808(809.48) | Grad Norm 3.8554(4.3219) | Total Time 14.00(14.00)\n",
      "Iter 11030 | Time 19.4240(19.4580) | Bit/dim 3.5927(3.5940) | Xent 0.2719(0.2696) | Loss 3.7286(3.7288) | Error 0.1000(0.0970) Steps 832(811.75) | Grad Norm 4.0333(4.2327) | Total Time 14.00(14.00)\n",
      "Iter 11040 | Time 20.3227(19.5399) | Bit/dim 3.5750(3.5963) | Xent 0.2603(0.2779) | Loss 3.7051(3.7353) | Error 0.1056(0.1002) Steps 820(814.43) | Grad Norm 3.1330(4.4407) | Total Time 14.00(14.00)\n",
      "Iter 11050 | Time 19.6098(19.5483) | Bit/dim 3.5563(3.5918) | Xent 0.3234(0.2773) | Loss 3.7180(3.7304) | Error 0.1167(0.0996) Steps 808(815.01) | Grad Norm 3.3278(4.2051) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0201 | Time 96.2804, Epoch Time 1188.6050(1106.4807), Bit/dim 3.5945(best: 3.5936), Xent 0.8062, Loss 3.9976, Error 0.2237(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11060 | Time 19.6222(19.5021) | Bit/dim 3.6042(3.5901) | Xent 0.2397(0.2734) | Loss 3.7240(3.7268) | Error 0.0856(0.0978) Steps 826(815.37) | Grad Norm 4.1124(3.9362) | Total Time 14.00(14.00)\n",
      "Iter 11070 | Time 19.6428(19.5448) | Bit/dim 3.6126(3.5891) | Xent 0.2357(0.2671) | Loss 3.7304(3.7227) | Error 0.0889(0.0957) Steps 814(816.05) | Grad Norm 2.6623(3.7711) | Total Time 14.00(14.00)\n",
      "Iter 11080 | Time 20.0566(19.5990) | Bit/dim 3.5708(3.5868) | Xent 0.3036(0.2737) | Loss 3.7226(3.7237) | Error 0.1033(0.0972) Steps 826(816.55) | Grad Norm 5.4273(4.0261) | Total Time 14.00(14.00)\n",
      "Iter 11090 | Time 19.3910(19.5920) | Bit/dim 3.6006(3.5877) | Xent 0.3439(0.2751) | Loss 3.7725(3.7253) | Error 0.1122(0.0970) Steps 826(817.68) | Grad Norm 4.3308(4.0946) | Total Time 14.00(14.00)\n",
      "Iter 11100 | Time 19.3529(19.6097) | Bit/dim 3.6151(3.5893) | Xent 0.2467(0.2747) | Loss 3.7384(3.7266) | Error 0.0911(0.0974) Steps 832(817.73) | Grad Norm 2.7351(3.9701) | Total Time 14.00(14.00)\n",
      "Iter 11110 | Time 19.4117(19.5309) | Bit/dim 3.5530(3.5880) | Xent 0.2947(0.2766) | Loss 3.7003(3.7263) | Error 0.1044(0.0980) Steps 796(816.21) | Grad Norm 5.0069(4.0093) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0202 | Time 95.9653, Epoch Time 1190.6836(1109.0068), Bit/dim 3.5961(best: 3.5936), Xent 0.8769, Loss 4.0345, Error 0.2317(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11120 | Time 19.7646(19.5546) | Bit/dim 3.5788(3.5876) | Xent 0.2890(0.2762) | Loss 3.7233(3.7257) | Error 0.1000(0.0980) Steps 808(816.00) | Grad Norm 2.7955(3.8776) | Total Time 14.00(14.00)\n",
      "Iter 11130 | Time 19.8794(19.5603) | Bit/dim 3.5807(3.5879) | Xent 0.1986(0.2754) | Loss 3.6800(3.7256) | Error 0.0611(0.0977) Steps 850(815.58) | Grad Norm 3.0099(3.8544) | Total Time 14.00(14.00)\n",
      "Iter 11140 | Time 18.5809(19.4904) | Bit/dim 3.5837(3.5865) | Xent 0.2054(0.2635) | Loss 3.6865(3.7183) | Error 0.0700(0.0933) Steps 784(815.07) | Grad Norm 1.9585(3.6167) | Total Time 14.00(14.00)\n",
      "Iter 11150 | Time 19.4305(19.4935) | Bit/dim 3.5486(3.5880) | Xent 0.2582(0.2590) | Loss 3.6777(3.7175) | Error 0.0933(0.0915) Steps 832(815.71) | Grad Norm 2.1043(3.3516) | Total Time 14.00(14.00)\n",
      "Iter 11160 | Time 19.2337(19.4571) | Bit/dim 3.6047(3.5864) | Xent 0.2620(0.2596) | Loss 3.7357(3.7162) | Error 0.1000(0.0917) Steps 814(814.31) | Grad Norm 4.0668(3.4897) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0203 | Time 96.4798, Epoch Time 1184.9230(1111.2842), Bit/dim 3.5895(best: 3.5936), Xent 0.8413, Loss 4.0101, Error 0.2267(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11170 | Time 19.8453(19.4711) | Bit/dim 3.6015(3.5887) | Xent 0.2348(0.2552) | Loss 3.7189(3.7163) | Error 0.0867(0.0905) Steps 814(815.01) | Grad Norm 4.0342(3.4032) | Total Time 14.00(14.00)\n",
      "Iter 11180 | Time 19.5154(19.5211) | Bit/dim 3.5608(3.5835) | Xent 0.2128(0.2484) | Loss 3.6673(3.7078) | Error 0.0767(0.0881) Steps 820(815.72) | Grad Norm 2.9111(3.3712) | Total Time 14.00(14.00)\n",
      "Iter 11190 | Time 20.0593(19.5960) | Bit/dim 3.5825(3.5875) | Xent 0.2314(0.2488) | Loss 3.6982(3.7119) | Error 0.0900(0.0887) Steps 832(818.39) | Grad Norm 3.0154(3.4853) | Total Time 14.00(14.00)\n",
      "Iter 11200 | Time 20.2664(19.6473) | Bit/dim 3.5931(3.5886) | Xent 0.2428(0.2451) | Loss 3.7145(3.7112) | Error 0.0778(0.0870) Steps 838(819.97) | Grad Norm 2.7157(3.5118) | Total Time 14.00(14.00)\n",
      "Iter 11210 | Time 20.2790(19.8256) | Bit/dim 3.6081(3.5867) | Xent 0.2859(0.2564) | Loss 3.7511(3.7149) | Error 0.1011(0.0910) Steps 832(824.16) | Grad Norm 5.0701(3.7604) | Total Time 14.00(14.00)\n",
      "Iter 11220 | Time 19.5905(19.8600) | Bit/dim 3.5988(3.5879) | Xent 0.2818(0.2689) | Loss 3.7396(3.7223) | Error 0.0989(0.0948) Steps 820(826.70) | Grad Norm 3.6286(3.7907) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0204 | Time 97.2726, Epoch Time 1208.4396(1114.1989), Bit/dim 3.5951(best: 3.5895), Xent 0.8364, Loss 4.0133, Error 0.2287(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11230 | Time 20.8787(19.9077) | Bit/dim 3.5938(3.5868) | Xent 0.2038(0.2609) | Loss 3.6957(3.7173) | Error 0.0689(0.0924) Steps 832(827.68) | Grad Norm 2.8968(3.6050) | Total Time 14.00(14.00)\n",
      "Iter 11240 | Time 20.2116(19.9297) | Bit/dim 3.5751(3.5862) | Xent 0.2187(0.2492) | Loss 3.6845(3.7108) | Error 0.0778(0.0876) Steps 832(828.07) | Grad Norm 2.6071(3.2985) | Total Time 14.00(14.00)\n",
      "Iter 11250 | Time 19.7301(19.9279) | Bit/dim 3.5823(3.5850) | Xent 0.3017(0.2446) | Loss 3.7331(3.7073) | Error 0.1044(0.0860) Steps 808(827.12) | Grad Norm 4.2127(3.2132) | Total Time 14.00(14.00)\n",
      "Iter 11260 | Time 20.3469(19.9342) | Bit/dim 3.5802(3.5824) | Xent 0.2379(0.2585) | Loss 3.6991(3.7117) | Error 0.0767(0.0906) Steps 850(829.93) | Grad Norm 4.7517(3.6003) | Total Time 14.00(14.00)\n",
      "Iter 11270 | Time 20.2616(20.0213) | Bit/dim 3.6313(3.5881) | Xent 0.2533(0.2614) | Loss 3.7579(3.7187) | Error 0.0856(0.0924) Steps 832(831.10) | Grad Norm 3.3451(4.0116) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0205 | Time 97.0410, Epoch Time 1215.9297(1117.2508), Bit/dim 3.5974(best: 3.5895), Xent 0.7932, Loss 3.9940, Error 0.2217(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11280 | Time 19.5932(20.0167) | Bit/dim 3.5875(3.5889) | Xent 0.2404(0.2573) | Loss 3.7078(3.7175) | Error 0.0811(0.0910) Steps 826(830.91) | Grad Norm 3.5626(3.8396) | Total Time 14.00(14.00)\n",
      "Iter 11290 | Time 20.3191(19.9958) | Bit/dim 3.5800(3.5891) | Xent 0.2275(0.2483) | Loss 3.6938(3.7133) | Error 0.0800(0.0875) Steps 814(829.94) | Grad Norm 3.2270(3.5032) | Total Time 14.00(14.00)\n",
      "Iter 11300 | Time 20.1814(20.0039) | Bit/dim 3.5824(3.5867) | Xent 0.3938(0.2544) | Loss 3.7793(3.7140) | Error 0.1356(0.0901) Steps 850(831.59) | Grad Norm 7.8670(3.8711) | Total Time 14.00(14.00)\n",
      "Iter 11310 | Time 19.8887(20.0706) | Bit/dim 3.6020(3.5877) | Xent 0.3138(0.2800) | Loss 3.7589(3.7277) | Error 0.1100(0.0996) Steps 814(832.75) | Grad Norm 4.7660(4.5145) | Total Time 14.00(14.00)\n",
      "Iter 11320 | Time 20.2313(20.0366) | Bit/dim 3.5610(3.5898) | Xent 0.2876(0.2856) | Loss 3.7048(3.7326) | Error 0.0978(0.1014) Steps 850(831.00) | Grad Norm 3.2782(4.4989) | Total Time 14.00(14.00)\n",
      "Iter 11330 | Time 19.1117(19.9894) | Bit/dim 3.6004(3.5921) | Xent 0.2709(0.2821) | Loss 3.7359(3.7332) | Error 0.0922(0.1004) Steps 802(828.94) | Grad Norm 4.0931(4.3717) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0206 | Time 97.0611, Epoch Time 1215.7334(1120.2053), Bit/dim 3.5976(best: 3.5895), Xent 0.8280, Loss 4.0116, Error 0.2309(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11340 | Time 21.0973(20.0559) | Bit/dim 3.5828(3.5912) | Xent 0.2370(0.2749) | Loss 3.7013(3.7286) | Error 0.0800(0.0984) Steps 826(829.19) | Grad Norm 3.4636(4.2098) | Total Time 14.00(14.00)\n",
      "Iter 11350 | Time 20.9094(20.0478) | Bit/dim 3.6292(3.5892) | Xent 0.2565(0.2750) | Loss 3.7575(3.7267) | Error 0.0933(0.0989) Steps 826(825.62) | Grad Norm 4.1380(4.2520) | Total Time 14.00(14.00)\n",
      "Iter 11360 | Time 20.0127(20.0740) | Bit/dim 3.5757(3.5888) | Xent 0.2452(0.2741) | Loss 3.6983(3.7259) | Error 0.0856(0.0983) Steps 826(827.41) | Grad Norm 3.2560(4.1819) | Total Time 14.00(14.00)\n",
      "Iter 11370 | Time 19.8504(20.0988) | Bit/dim 3.6244(3.5909) | Xent 0.2468(0.2695) | Loss 3.7479(3.7256) | Error 0.0989(0.0972) Steps 838(828.52) | Grad Norm 3.3516(4.2129) | Total Time 14.00(14.00)\n",
      "Iter 11380 | Time 20.0499(20.0680) | Bit/dim 3.5894(3.5886) | Xent 0.2940(0.2646) | Loss 3.7364(3.7210) | Error 0.0956(0.0945) Steps 826(828.65) | Grad Norm 4.4663(4.1308) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0207 | Time 98.0794, Epoch Time 1222.2750(1123.2674), Bit/dim 3.5964(best: 3.5895), Xent 0.8108, Loss 4.0018, Error 0.2251(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11390 | Time 19.7388(20.0715) | Bit/dim 3.5741(3.5880) | Xent 0.2614(0.2599) | Loss 3.7048(3.7180) | Error 0.1011(0.0933) Steps 826(826.69) | Grad Norm 3.7330(4.1191) | Total Time 14.00(14.00)\n",
      "Iter 11400 | Time 20.4469(20.0766) | Bit/dim 3.5679(3.5884) | Xent 0.2756(0.2637) | Loss 3.7057(3.7203) | Error 0.1011(0.0952) Steps 832(826.93) | Grad Norm 3.9229(4.3809) | Total Time 14.00(14.00)\n",
      "Iter 11410 | Time 20.7841(20.0872) | Bit/dim 3.6212(3.5891) | Xent 0.2399(0.2610) | Loss 3.7411(3.7197) | Error 0.0878(0.0937) Steps 838(826.66) | Grad Norm 3.4968(4.1678) | Total Time 14.00(14.00)\n",
      "Iter 11420 | Time 20.1885(20.1420) | Bit/dim 3.5851(3.5896) | Xent 0.2752(0.2678) | Loss 3.7227(3.7235) | Error 0.0967(0.0943) Steps 832(831.61) | Grad Norm 5.1007(4.2584) | Total Time 14.00(14.00)\n",
      "Iter 11430 | Time 21.0541(20.1784) | Bit/dim 3.5730(3.5894) | Xent 0.2390(0.2682) | Loss 3.6925(3.7236) | Error 0.0856(0.0944) Steps 844(832.67) | Grad Norm 5.7814(4.2943) | Total Time 14.00(14.00)\n",
      "Iter 11440 | Time 20.5836(20.2435) | Bit/dim 3.6022(3.5915) | Xent 0.2446(0.2697) | Loss 3.7245(3.7264) | Error 0.0867(0.0950) Steps 832(834.85) | Grad Norm 2.5686(4.1986) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0208 | Time 98.6317, Epoch Time 1227.6587(1126.3991), Bit/dim 3.5952(best: 3.5895), Xent 0.8281, Loss 4.0092, Error 0.2246(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11450 | Time 20.5103(20.2748) | Bit/dim 3.5692(3.5908) | Xent 0.1948(0.2588) | Loss 3.6666(3.7202) | Error 0.0633(0.0910) Steps 838(836.40) | Grad Norm 2.3246(4.0691) | Total Time 14.00(14.00)\n",
      "Iter 11460 | Time 19.7260(20.2487) | Bit/dim 3.5664(3.5901) | Xent 0.2437(0.2554) | Loss 3.6882(3.7178) | Error 0.0900(0.0901) Steps 826(835.56) | Grad Norm 2.8660(4.0213) | Total Time 14.00(14.00)\n",
      "Iter 11470 | Time 20.5901(20.1307) | Bit/dim 3.5637(3.5857) | Xent 0.2664(0.2484) | Loss 3.6969(3.7099) | Error 0.0900(0.0878) Steps 844(833.34) | Grad Norm 3.7714(3.9282) | Total Time 14.00(14.00)\n",
      "Iter 11480 | Time 19.6071(20.1531) | Bit/dim 3.5839(3.5846) | Xent 0.2538(0.2423) | Loss 3.7108(3.7058) | Error 0.0844(0.0858) Steps 838(837.02) | Grad Norm 4.1435(3.7276) | Total Time 14.00(14.00)\n",
      "Iter 11490 | Time 20.3666(20.1220) | Bit/dim 3.6069(3.5882) | Xent 0.2462(0.2459) | Loss 3.7300(3.7111) | Error 0.0933(0.0878) Steps 826(832.81) | Grad Norm 2.9808(3.7110) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0209 | Time 96.3973, Epoch Time 1223.7358(1129.3192), Bit/dim 3.5899(best: 3.5895), Xent 0.8202, Loss 4.0000, Error 0.2269(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11500 | Time 20.1448(20.2184) | Bit/dim 3.5835(3.5879) | Xent 0.2357(0.2507) | Loss 3.7013(3.7133) | Error 0.0856(0.0891) Steps 838(835.72) | Grad Norm 3.7034(3.9181) | Total Time 14.00(14.00)\n",
      "Iter 11510 | Time 21.0951(20.1623) | Bit/dim 3.5959(3.5898) | Xent 0.2785(0.2501) | Loss 3.7351(3.7149) | Error 0.0978(0.0889) Steps 838(835.61) | Grad Norm 4.9507(4.0344) | Total Time 14.00(14.00)\n",
      "Iter 11520 | Time 19.5221(20.1873) | Bit/dim 3.5891(3.5907) | Xent 0.1832(0.2454) | Loss 3.6807(3.7134) | Error 0.0611(0.0872) Steps 832(836.16) | Grad Norm 2.4838(3.8294) | Total Time 14.00(14.00)\n",
      "Iter 11530 | Time 20.2927(20.1549) | Bit/dim 3.6132(3.5904) | Xent 0.1993(0.2377) | Loss 3.7129(3.7093) | Error 0.0822(0.0846) Steps 820(834.77) | Grad Norm 3.1076(3.5325) | Total Time 14.00(14.00)\n",
      "Iter 11540 | Time 19.6188(20.0833) | Bit/dim 3.5624(3.5863) | Xent 0.2702(0.2360) | Loss 3.6975(3.7043) | Error 0.0922(0.0835) Steps 814(835.52) | Grad Norm 5.5635(3.6833) | Total Time 14.00(14.00)\n",
      "Iter 11550 | Time 20.0948(20.0842) | Bit/dim 3.5516(3.5817) | Xent 0.2327(0.2382) | Loss 3.6679(3.7008) | Error 0.0878(0.0838) Steps 856(837.76) | Grad Norm 3.0845(3.7434) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0210 | Time 98.0562, Epoch Time 1219.8005(1132.0337), Bit/dim 3.5871(best: 3.5895), Xent 0.8180, Loss 3.9961, Error 0.2224(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11560 | Time 20.0404(20.1357) | Bit/dim 3.5389(3.5799) | Xent 0.2791(0.2367) | Loss 3.6785(3.6982) | Error 0.1022(0.0832) Steps 826(837.78) | Grad Norm 4.0480(3.8026) | Total Time 14.00(14.00)\n",
      "Iter 11570 | Time 20.1164(20.1788) | Bit/dim 3.6033(3.5797) | Xent 0.2270(0.2360) | Loss 3.7168(3.6977) | Error 0.0767(0.0836) Steps 850(838.49) | Grad Norm 4.5434(3.7776) | Total Time 14.00(14.00)\n",
      "Iter 11580 | Time 20.0750(20.2114) | Bit/dim 3.5627(3.5814) | Xent 0.2424(0.2360) | Loss 3.6839(3.6994) | Error 0.0867(0.0834) Steps 856(838.98) | Grad Norm 3.7204(3.9189) | Total Time 14.00(14.00)\n",
      "Iter 11590 | Time 19.1804(20.2072) | Bit/dim 3.5589(3.5827) | Xent 0.2680(0.2438) | Loss 3.6929(3.7046) | Error 0.0922(0.0874) Steps 826(839.68) | Grad Norm 5.4036(4.0625) | Total Time 14.00(14.00)\n",
      "Iter 11600 | Time 20.1375(20.2143) | Bit/dim 3.5755(3.5842) | Xent 0.2469(0.2519) | Loss 3.6989(3.7101) | Error 0.0889(0.0900) Steps 850(840.77) | Grad Norm 3.9366(4.2240) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0211 | Time 96.0945, Epoch Time 1229.1564(1134.9473), Bit/dim 3.5960(best: 3.5871), Xent 0.8211, Loss 4.0066, Error 0.2275(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11610 | Time 20.0455(20.2394) | Bit/dim 3.5904(3.5865) | Xent 0.2191(0.2572) | Loss 3.6999(3.7151) | Error 0.0833(0.0918) Steps 844(841.95) | Grad Norm 2.5686(4.2717) | Total Time 14.00(14.00)\n",
      "Iter 11620 | Time 21.2182(20.3127) | Bit/dim 3.5824(3.5859) | Xent 0.2672(0.2500) | Loss 3.7160(3.7110) | Error 0.0933(0.0895) Steps 862(845.43) | Grad Norm 4.0552(3.9739) | Total Time 14.00(14.00)\n",
      "Iter 11630 | Time 20.4259(20.3202) | Bit/dim 3.5856(3.5855) | Xent 0.2437(0.2412) | Loss 3.7075(3.7060) | Error 0.0889(0.0864) Steps 880(848.23) | Grad Norm 3.7505(3.7172) | Total Time 14.00(14.00)\n",
      "Iter 11640 | Time 20.3771(20.2741) | Bit/dim 3.6218(3.5864) | Xent 0.2055(0.2433) | Loss 3.7246(3.7080) | Error 0.0778(0.0870) Steps 856(846.71) | Grad Norm 3.9903(3.9431) | Total Time 14.00(14.00)\n",
      "Iter 11650 | Time 20.4887(20.2389) | Bit/dim 3.5925(3.5852) | Xent 0.2663(0.2455) | Loss 3.7256(3.7080) | Error 0.0833(0.0873) Steps 856(846.58) | Grad Norm 3.9094(3.9542) | Total Time 14.00(14.00)\n",
      "Iter 11660 | Time 19.7272(20.3424) | Bit/dim 3.6086(3.5873) | Xent 0.2616(0.2468) | Loss 3.7394(3.7108) | Error 0.0889(0.0870) Steps 850(846.27) | Grad Norm 5.8077(3.9194) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0212 | Time 95.6138, Epoch Time 1232.4872(1137.8735), Bit/dim 3.5916(best: 3.5871), Xent 0.8364, Loss 4.0098, Error 0.2269(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11670 | Time 20.1959(20.3504) | Bit/dim 3.5856(3.5855) | Xent 0.2553(0.2486) | Loss 3.7132(3.7098) | Error 0.0878(0.0880) Steps 844(842.73) | Grad Norm 5.0960(4.0717) | Total Time 14.00(14.00)\n",
      "Iter 11680 | Time 21.0247(20.3943) | Bit/dim 3.5902(3.5837) | Xent 0.2382(0.2441) | Loss 3.7093(3.7058) | Error 0.0700(0.0865) Steps 820(844.50) | Grad Norm 3.1230(3.9687) | Total Time 14.00(14.00)\n",
      "Iter 11690 | Time 19.7179(20.3354) | Bit/dim 3.5859(3.5838) | Xent 0.2244(0.2475) | Loss 3.6982(3.7076) | Error 0.0833(0.0888) Steps 838(842.64) | Grad Norm 2.8388(3.9717) | Total Time 14.00(14.00)\n",
      "Iter 11700 | Time 20.3743(20.3179) | Bit/dim 3.5836(3.5855) | Xent 0.3186(0.2497) | Loss 3.7429(3.7103) | Error 0.1178(0.0896) Steps 862(843.78) | Grad Norm 4.3972(3.8889) | Total Time 14.00(14.00)\n",
      "Iter 11710 | Time 20.3753(20.3078) | Bit/dim 3.5900(3.5855) | Xent 0.2787(0.2583) | Loss 3.7293(3.7147) | Error 0.1044(0.0910) Steps 850(843.21) | Grad Norm 6.1029(4.0734) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0213 | Time 97.6622, Epoch Time 1235.2080(1140.7936), Bit/dim 3.5967(best: 3.5871), Xent 0.8217, Loss 4.0075, Error 0.2289(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11720 | Time 20.2280(20.3083) | Bit/dim 3.6014(3.5894) | Xent 0.2399(0.2631) | Loss 3.7213(3.7210) | Error 0.0856(0.0929) Steps 838(843.77) | Grad Norm 3.3621(4.1432) | Total Time 14.00(14.00)\n",
      "Iter 11730 | Time 19.9155(20.2775) | Bit/dim 3.6232(3.5872) | Xent 0.2469(0.2624) | Loss 3.7466(3.7184) | Error 0.0867(0.0931) Steps 856(843.79) | Grad Norm 5.3558(4.1663) | Total Time 14.00(14.00)\n",
      "Iter 11740 | Time 21.0598(20.2652) | Bit/dim 3.5984(3.5863) | Xent 0.2465(0.2619) | Loss 3.7217(3.7173) | Error 0.0878(0.0926) Steps 850(842.08) | Grad Norm 3.4788(4.2391) | Total Time 14.00(14.00)\n",
      "Iter 11750 | Time 20.0647(20.2546) | Bit/dim 3.6243(3.5857) | Xent 0.3504(0.2617) | Loss 3.7996(3.7166) | Error 0.1144(0.0923) Steps 838(843.14) | Grad Norm 7.0310(4.1504) | Total Time 14.00(14.00)\n",
      "Iter 11760 | Time 20.0971(20.3245) | Bit/dim 3.5822(3.5873) | Xent 0.3672(0.2746) | Loss 3.7658(3.7246) | Error 0.1333(0.0982) Steps 832(842.02) | Grad Norm 7.6362(4.5050) | Total Time 14.00(14.00)\n",
      "Iter 11770 | Time 21.3634(20.3803) | Bit/dim 3.5886(3.5880) | Xent 0.2804(0.2821) | Loss 3.7288(3.7290) | Error 0.0900(0.1006) Steps 868(843.03) | Grad Norm 4.0139(4.4992) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0214 | Time 96.7403, Epoch Time 1231.2204(1143.5064), Bit/dim 3.5958(best: 3.5871), Xent 0.8389, Loss 4.0152, Error 0.2291(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11780 | Time 20.4455(20.3720) | Bit/dim 3.6102(3.5880) | Xent 0.2667(0.2722) | Loss 3.7436(3.7241) | Error 0.0933(0.0966) Steps 838(842.50) | Grad Norm 3.4193(4.1957) | Total Time 14.00(14.00)\n",
      "Iter 11790 | Time 20.3749(20.3925) | Bit/dim 3.5998(3.5883) | Xent 0.3032(0.2667) | Loss 3.7514(3.7217) | Error 0.1056(0.0946) Steps 832(844.03) | Grad Norm 6.0508(4.1458) | Total Time 14.00(14.00)\n",
      "Iter 11800 | Time 20.5511(20.4145) | Bit/dim 3.5958(3.5873) | Xent 0.2602(0.2669) | Loss 3.7259(3.7207) | Error 0.0956(0.0948) Steps 862(844.82) | Grad Norm 2.7789(4.5417) | Total Time 14.00(14.00)\n",
      "Iter 11810 | Time 20.5379(20.3392) | Bit/dim 3.5735(3.5856) | Xent 0.2281(0.2614) | Loss 3.6875(3.7163) | Error 0.0711(0.0934) Steps 832(844.63) | Grad Norm 2.8314(4.4674) | Total Time 14.00(14.00)\n",
      "Iter 11820 | Time 19.6735(20.3419) | Bit/dim 3.5951(3.5872) | Xent 0.1998(0.2519) | Loss 3.6950(3.7131) | Error 0.0700(0.0899) Steps 844(844.86) | Grad Norm 2.8774(4.1177) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0215 | Time 96.5301, Epoch Time 1232.9583(1146.1899), Bit/dim 3.5894(best: 3.5871), Xent 0.8474, Loss 4.0131, Error 0.2251(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11830 | Time 20.3260(20.3527) | Bit/dim 3.5576(3.5854) | Xent 0.1826(0.2448) | Loss 3.6490(3.7078) | Error 0.0600(0.0870) Steps 868(847.13) | Grad Norm 2.3944(3.8648) | Total Time 14.00(14.00)\n",
      "Iter 11840 | Time 19.4654(20.3912) | Bit/dim 3.5709(3.5838) | Xent 0.2463(0.2413) | Loss 3.6940(3.7045) | Error 0.0911(0.0853) Steps 838(849.92) | Grad Norm 2.9671(3.7571) | Total Time 14.00(14.00)\n",
      "Iter 11850 | Time 21.1121(20.3755) | Bit/dim 3.5681(3.5848) | Xent 0.2691(0.2361) | Loss 3.7026(3.7028) | Error 0.1000(0.0845) Steps 856(849.08) | Grad Norm 4.0143(3.6537) | Total Time 14.00(14.00)\n",
      "Iter 11860 | Time 20.2604(20.3480) | Bit/dim 3.5699(3.5820) | Xent 0.2552(0.2366) | Loss 3.6975(3.7003) | Error 0.1000(0.0851) Steps 850(848.48) | Grad Norm 4.4175(3.6840) | Total Time 14.00(14.00)\n",
      "Iter 11870 | Time 20.8342(20.3608) | Bit/dim 3.5834(3.5827) | Xent 0.2159(0.2364) | Loss 3.6913(3.7009) | Error 0.0856(0.0851) Steps 874(847.76) | Grad Norm 3.4399(3.8902) | Total Time 14.00(14.00)\n",
      "Iter 11880 | Time 19.9757(20.4386) | Bit/dim 3.6118(3.5830) | Xent 0.2470(0.2349) | Loss 3.7353(3.7005) | Error 0.0867(0.0847) Steps 844(848.79) | Grad Norm 3.0008(3.7652) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0216 | Time 96.0102, Epoch Time 1238.0062(1148.9444), Bit/dim 3.5905(best: 3.5871), Xent 0.8392, Loss 4.0101, Error 0.2257(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11890 | Time 20.4753(20.4111) | Bit/dim 3.5642(3.5802) | Xent 0.1579(0.2230) | Loss 3.6431(3.6917) | Error 0.0500(0.0798) Steps 880(849.72) | Grad Norm 2.0280(3.5629) | Total Time 14.00(14.00)\n",
      "Iter 11900 | Time 20.4482(20.4101) | Bit/dim 3.5819(3.5802) | Xent 0.2335(0.2204) | Loss 3.6987(3.6904) | Error 0.0767(0.0789) Steps 844(851.55) | Grad Norm 4.6313(3.5882) | Total Time 14.00(14.00)\n",
      "Iter 11910 | Time 21.0920(20.4481) | Bit/dim 3.5560(3.5771) | Xent 0.1801(0.2210) | Loss 3.6460(3.6876) | Error 0.0644(0.0789) Steps 850(851.68) | Grad Norm 2.8484(3.4881) | Total Time 14.00(14.00)\n",
      "Iter 11920 | Time 19.6643(20.3970) | Bit/dim 3.5631(3.5802) | Xent 0.2128(0.2263) | Loss 3.6695(3.6933) | Error 0.0756(0.0808) Steps 856(851.35) | Grad Norm 3.1907(3.5732) | Total Time 14.00(14.00)\n",
      "Iter 11930 | Time 20.1753(20.4100) | Bit/dim 3.5864(3.5830) | Xent 0.2562(0.2304) | Loss 3.7145(3.6981) | Error 0.0900(0.0828) Steps 844(850.39) | Grad Norm 4.1003(3.6847) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0217 | Time 96.3022, Epoch Time 1234.0933(1151.4989), Bit/dim 3.5978(best: 3.5871), Xent 0.9057, Loss 4.0506, Error 0.2347(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11940 | Time 20.4716(20.3637) | Bit/dim 3.5990(3.5856) | Xent 0.2612(0.2406) | Loss 3.7297(3.7059) | Error 0.1000(0.0866) Steps 850(848.78) | Grad Norm 3.7134(4.0324) | Total Time 14.00(14.00)\n",
      "Iter 11950 | Time 20.0800(20.3037) | Bit/dim 3.5799(3.5855) | Xent 0.2404(0.2434) | Loss 3.7001(3.7072) | Error 0.0856(0.0868) Steps 850(847.20) | Grad Norm 3.7048(4.0606) | Total Time 14.00(14.00)\n",
      "Iter 11960 | Time 20.7388(20.2978) | Bit/dim 3.5844(3.5853) | Xent 0.2434(0.2436) | Loss 3.7061(3.7070) | Error 0.0856(0.0860) Steps 856(848.73) | Grad Norm 3.2601(4.0347) | Total Time 14.00(14.00)\n",
      "Iter 11970 | Time 19.7552(20.2879) | Bit/dim 3.5667(3.5839) | Xent 0.2570(0.2468) | Loss 3.6952(3.7072) | Error 0.0978(0.0883) Steps 868(851.61) | Grad Norm 4.1036(4.1029) | Total Time 14.00(14.00)\n",
      "Iter 11980 | Time 20.1995(20.2164) | Bit/dim 3.5296(3.5839) | Xent 0.2230(0.2445) | Loss 3.6411(3.7061) | Error 0.0800(0.0879) Steps 838(849.17) | Grad Norm 2.5674(4.0075) | Total Time 14.00(14.00)\n",
      "Iter 11990 | Time 20.2725(20.2933) | Bit/dim 3.5437(3.5854) | Xent 0.2956(0.2459) | Loss 3.6915(3.7084) | Error 0.1100(0.0882) Steps 856(850.27) | Grad Norm 3.6056(4.0704) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0218 | Time 97.3043, Epoch Time 1229.0610(1153.8258), Bit/dim 3.5912(best: 3.5871), Xent 0.8095, Loss 3.9959, Error 0.2184(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12000 | Time 21.2518(20.3533) | Bit/dim 3.5884(3.5854) | Xent 0.2312(0.2415) | Loss 3.7040(3.7061) | Error 0.0889(0.0870) Steps 832(849.76) | Grad Norm 3.5280(3.8862) | Total Time 14.00(14.00)\n",
      "Iter 12010 | Time 20.5445(20.3433) | Bit/dim 3.5749(3.5859) | Xent 0.2554(0.2378) | Loss 3.7026(3.7048) | Error 0.0922(0.0851) Steps 850(850.46) | Grad Norm 4.1318(3.7994) | Total Time 14.00(14.00)\n",
      "Iter 12020 | Time 20.8522(20.3466) | Bit/dim 3.5952(3.5855) | Xent 0.2256(0.2362) | Loss 3.7080(3.7036) | Error 0.0789(0.0839) Steps 868(850.31) | Grad Norm 3.4170(3.7143) | Total Time 14.00(14.00)\n",
      "Iter 12030 | Time 20.2695(20.3444) | Bit/dim 3.5444(3.5840) | Xent 0.2629(0.2361) | Loss 3.6759(3.7020) | Error 0.1000(0.0836) Steps 850(849.75) | Grad Norm 3.6657(3.9505) | Total Time 14.00(14.00)\n",
      "Iter 12040 | Time 20.3148(20.3778) | Bit/dim 3.5443(3.5821) | Xent 0.2255(0.2341) | Loss 3.6570(3.6992) | Error 0.0911(0.0834) Steps 850(851.80) | Grad Norm 4.2691(3.9723) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0219 | Time 96.6439, Epoch Time 1238.0290(1156.3519), Bit/dim 3.5858(best: 3.5871), Xent 0.8370, Loss 4.0043, Error 0.2224(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12050 | Time 20.0705(20.3530) | Bit/dim 3.5869(3.5787) | Xent 0.2122(0.2269) | Loss 3.6930(3.6921) | Error 0.0667(0.0803) Steps 850(851.77) | Grad Norm 3.6740(3.7626) | Total Time 14.00(14.00)\n",
      "Iter 12060 | Time 20.6737(20.3716) | Bit/dim 3.5858(3.5802) | Xent 0.2316(0.2232) | Loss 3.7016(3.6918) | Error 0.0900(0.0798) Steps 820(849.44) | Grad Norm 4.8974(3.7701) | Total Time 14.00(14.00)\n",
      "Iter 12070 | Time 20.3434(20.3923) | Bit/dim 3.5713(3.5825) | Xent 0.2361(0.2306) | Loss 3.6893(3.6978) | Error 0.0844(0.0827) Steps 850(848.85) | Grad Norm 4.1739(3.8205) | Total Time 14.00(14.00)\n",
      "Iter 12080 | Time 20.1296(20.4321) | Bit/dim 3.5435(3.5821) | Xent 0.2137(0.2335) | Loss 3.6503(3.6988) | Error 0.0689(0.0833) Steps 850(850.22) | Grad Norm 4.0509(3.7755) | Total Time 14.00(14.00)\n",
      "Iter 12090 | Time 20.6570(20.4172) | Bit/dim 3.5767(3.5831) | Xent 0.2088(0.2327) | Loss 3.6812(3.6995) | Error 0.0789(0.0835) Steps 838(850.40) | Grad Norm 4.3992(3.8476) | Total Time 14.00(14.00)\n",
      "Iter 12100 | Time 19.9005(20.4025) | Bit/dim 3.5747(3.5807) | Xent 0.2262(0.2351) | Loss 3.6878(3.6983) | Error 0.0756(0.0835) Steps 850(850.74) | Grad Norm 2.5480(3.6695) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0220 | Time 96.8277, Epoch Time 1235.8252(1158.7361), Bit/dim 3.5880(best: 3.5858), Xent 0.8285, Loss 4.0023, Error 0.2239(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12110 | Time 20.4841(20.3648) | Bit/dim 3.6082(3.5805) | Xent 0.2283(0.2309) | Loss 3.7223(3.6959) | Error 0.0856(0.0824) Steps 862(850.35) | Grad Norm 3.9098(3.6357) | Total Time 14.00(14.00)\n",
      "Iter 12120 | Time 20.1859(20.3942) | Bit/dim 3.5473(3.5782) | Xent 0.2343(0.2311) | Loss 3.6644(3.6938) | Error 0.0833(0.0823) Steps 844(850.46) | Grad Norm 4.1657(3.7434) | Total Time 14.00(14.00)\n",
      "Iter 12130 | Time 20.3334(20.3379) | Bit/dim 3.5840(3.5793) | Xent 0.2192(0.2299) | Loss 3.6935(3.6943) | Error 0.0756(0.0817) Steps 838(849.54) | Grad Norm 5.6839(3.8362) | Total Time 14.00(14.00)\n",
      "Iter 12140 | Time 20.2137(20.2584) | Bit/dim 3.6222(3.5810) | Xent 0.2813(0.2320) | Loss 3.7628(3.6969) | Error 0.0989(0.0826) Steps 862(851.32) | Grad Norm 3.3490(3.8213) | Total Time 14.00(14.00)\n",
      "Iter 12150 | Time 19.3569(20.2330) | Bit/dim 3.5797(3.5813) | Xent 0.2132(0.2284) | Loss 3.6863(3.6955) | Error 0.0800(0.0810) Steps 826(851.20) | Grad Norm 3.0084(3.7613) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0221 | Time 96.6476, Epoch Time 1227.9538(1160.8126), Bit/dim 3.5827(best: 3.5858), Xent 0.8912, Loss 4.0283, Error 0.2274(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12160 | Time 20.2005(20.2692) | Bit/dim 3.5805(3.5789) | Xent 0.2224(0.2234) | Loss 3.6917(3.6906) | Error 0.0722(0.0787) Steps 868(851.58) | Grad Norm 2.3164(3.6398) | Total Time 14.00(14.00)\n",
      "Iter 12170 | Time 20.6236(20.3054) | Bit/dim 3.5496(3.5799) | Xent 0.2238(0.2212) | Loss 3.6615(3.6905) | Error 0.0744(0.0775) Steps 850(852.12) | Grad Norm 3.5481(3.5737) | Total Time 14.00(14.00)\n",
      "Iter 12180 | Time 20.9624(20.3830) | Bit/dim 3.5639(3.5804) | Xent 0.2670(0.2214) | Loss 3.6974(3.6911) | Error 0.0911(0.0788) Steps 838(850.35) | Grad Norm 4.3200(3.5764) | Total Time 14.00(14.00)\n",
      "Iter 12190 | Time 20.9203(20.4894) | Bit/dim 3.5954(3.5801) | Xent 0.2260(0.2202) | Loss 3.7084(3.6902) | Error 0.0789(0.0776) Steps 844(851.80) | Grad Norm 3.1800(3.5316) | Total Time 14.00(14.00)\n",
      "Iter 12200 | Time 20.6741(20.6144) | Bit/dim 3.5892(3.5808) | Xent 0.2448(0.2324) | Loss 3.7117(3.6970) | Error 0.0833(0.0821) Steps 856(853.68) | Grad Norm 3.6650(3.7426) | Total Time 14.00(14.00)\n",
      "Iter 12210 | Time 21.1049(20.6141) | Bit/dim 3.5900(3.5835) | Xent 0.1925(0.2307) | Loss 3.6862(3.6988) | Error 0.0644(0.0814) Steps 874(853.78) | Grad Norm 3.4670(3.9043) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0222 | Time 96.3683, Epoch Time 1250.0260(1163.4890), Bit/dim 3.5911(best: 3.5827), Xent 0.9035, Loss 4.0428, Error 0.2337(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12220 | Time 20.5739(20.6361) | Bit/dim 3.5941(3.5850) | Xent 0.2240(0.2302) | Loss 3.7061(3.7001) | Error 0.0778(0.0811) Steps 832(853.83) | Grad Norm 2.7480(3.8083) | Total Time 14.00(14.00)\n",
      "Iter 12230 | Time 20.3334(20.6189) | Bit/dim 3.5579(3.5825) | Xent 0.1914(0.2222) | Loss 3.6536(3.6936) | Error 0.0633(0.0785) Steps 844(852.02) | Grad Norm 2.2480(3.7878) | Total Time 14.00(14.00)\n",
      "Iter 12240 | Time 20.3771(20.6124) | Bit/dim 3.5191(3.5802) | Xent 0.1836(0.2213) | Loss 3.6109(3.6909) | Error 0.0667(0.0785) Steps 856(851.43) | Grad Norm 2.7854(3.7080) | Total Time 14.00(14.00)\n",
      "Iter 12250 | Time 21.2795(20.6484) | Bit/dim 3.5698(3.5771) | Xent 0.2187(0.2198) | Loss 3.6791(3.6870) | Error 0.0778(0.0770) Steps 862(853.96) | Grad Norm 2.2613(3.5496) | Total Time 14.00(14.00)\n",
      "Iter 12260 | Time 20.6732(20.6035) | Bit/dim 3.5336(3.5780) | Xent 0.2670(0.2266) | Loss 3.6671(3.6913) | Error 0.0900(0.0787) Steps 844(848.42) | Grad Norm 4.1907(3.6560) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0223 | Time 97.7112, Epoch Time 1248.1654(1166.0293), Bit/dim 3.5875(best: 3.5827), Xent 0.8343, Loss 4.0046, Error 0.2235(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12270 | Time 20.9567(20.5458) | Bit/dim 3.5904(3.5831) | Xent 0.2018(0.2304) | Loss 3.6913(3.6983) | Error 0.0789(0.0808) Steps 838(846.86) | Grad Norm 2.4173(3.7307) | Total Time 14.00(14.00)\n",
      "Iter 12280 | Time 20.1703(20.6003) | Bit/dim 3.5765(3.5829) | Xent 0.2797(0.2313) | Loss 3.7163(3.6985) | Error 0.1033(0.0821) Steps 820(847.30) | Grad Norm 5.3952(3.9418) | Total Time 14.00(14.00)\n",
      "Iter 12290 | Time 20.8682(20.5794) | Bit/dim 3.5820(3.5831) | Xent 0.2514(0.2362) | Loss 3.7077(3.7012) | Error 0.0878(0.0838) Steps 850(846.62) | Grad Norm 3.6828(4.0875) | Total Time 14.00(14.00)\n",
      "Iter 12300 | Time 21.2967(20.6548) | Bit/dim 3.5702(3.5820) | Xent 0.2471(0.2430) | Loss 3.6937(3.7035) | Error 0.0889(0.0861) Steps 874(849.32) | Grad Norm 3.5965(4.1445) | Total Time 14.00(14.00)\n",
      "Iter 12310 | Time 21.3925(20.7231) | Bit/dim 3.6095(3.5823) | Xent 0.1827(0.2407) | Loss 3.7009(3.7027) | Error 0.0711(0.0850) Steps 880(848.35) | Grad Norm 3.9536(4.2668) | Total Time 14.00(14.00)\n",
      "Iter 12320 | Time 20.1677(20.7180) | Bit/dim 3.5890(3.5824) | Xent 0.2229(0.2399) | Loss 3.7005(3.7024) | Error 0.0778(0.0853) Steps 850(849.00) | Grad Norm 3.7734(4.1401) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0224 | Time 97.4297, Epoch Time 1254.3289(1168.6783), Bit/dim 3.5865(best: 3.5827), Xent 0.8614, Loss 4.0171, Error 0.2286(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12330 | Time 20.6658(20.7814) | Bit/dim 3.5753(3.5828) | Xent 0.2370(0.2307) | Loss 3.6938(3.6981) | Error 0.0978(0.0823) Steps 838(851.43) | Grad Norm 3.4015(3.8842) | Total Time 14.00(14.00)\n",
      "Iter 12340 | Time 20.5922(20.7462) | Bit/dim 3.5852(3.5829) | Xent 0.2383(0.2263) | Loss 3.7043(3.6961) | Error 0.0856(0.0811) Steps 844(850.46) | Grad Norm 3.1656(3.7479) | Total Time 14.00(14.00)\n",
      "Iter 12350 | Time 20.2394(20.7065) | Bit/dim 3.5830(3.5822) | Xent 0.1876(0.2256) | Loss 3.6768(3.6950) | Error 0.0711(0.0797) Steps 838(849.06) | Grad Norm 2.7106(3.6834) | Total Time 14.00(14.00)\n",
      "Iter 12360 | Time 20.4217(20.7236) | Bit/dim 3.5621(3.5786) | Xent 0.1753(0.2176) | Loss 3.6498(3.6874) | Error 0.0589(0.0761) Steps 838(850.21) | Grad Norm 4.4102(3.6009) | Total Time 14.00(14.00)\n",
      "Iter 12370 | Time 20.4981(20.6968) | Bit/dim 3.5875(3.5766) | Xent 0.1965(0.2153) | Loss 3.6857(3.6842) | Error 0.0733(0.0750) Steps 844(849.10) | Grad Norm 2.6359(3.3386) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0225 | Time 97.6472, Epoch Time 1255.5401(1171.2841), Bit/dim 3.5853(best: 3.5827), Xent 0.9476, Loss 4.0591, Error 0.2353(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12380 | Time 20.9636(20.7287) | Bit/dim 3.5786(3.5779) | Xent 0.1854(0.2126) | Loss 3.6713(3.6841) | Error 0.0733(0.0749) Steps 862(852.82) | Grad Norm 2.4227(3.4307) | Total Time 14.00(14.00)\n",
      "Iter 12390 | Time 21.0935(20.7472) | Bit/dim 3.5886(3.5790) | Xent 0.2044(0.2194) | Loss 3.6908(3.6888) | Error 0.0811(0.0781) Steps 850(853.60) | Grad Norm 3.0544(3.8681) | Total Time 14.00(14.00)\n",
      "Iter 12400 | Time 20.4288(20.7678) | Bit/dim 3.5749(3.5779) | Xent 0.2929(0.2209) | Loss 3.7214(3.6883) | Error 0.1044(0.0783) Steps 874(855.41) | Grad Norm 7.3642(3.9198) | Total Time 14.00(14.00)\n",
      "Iter 12410 | Time 19.8610(20.8319) | Bit/dim 3.5851(3.5817) | Xent 0.2277(0.2269) | Loss 3.6989(3.6952) | Error 0.0744(0.0799) Steps 850(856.88) | Grad Norm 3.6441(3.9559) | Total Time 14.00(14.00)\n",
      "Iter 12420 | Time 20.7521(20.7963) | Bit/dim 3.6023(3.5848) | Xent 0.1616(0.2300) | Loss 3.6831(3.6998) | Error 0.0533(0.0812) Steps 856(856.56) | Grad Norm 4.1782(4.2269) | Total Time 14.00(14.00)\n",
      "Iter 12430 | Time 21.4158(20.7520) | Bit/dim 3.5831(3.5831) | Xent 0.2120(0.2297) | Loss 3.6891(3.6980) | Error 0.0722(0.0818) Steps 862(855.56) | Grad Norm 5.8660(4.0791) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0226 | Time 98.3961, Epoch Time 1260.2337(1173.9526), Bit/dim 3.5888(best: 3.5827), Xent 0.9314, Loss 4.0545, Error 0.2344(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12440 | Time 20.2807(20.7532) | Bit/dim 3.5830(3.5816) | Xent 0.2983(0.2309) | Loss 3.7321(3.6971) | Error 0.1100(0.0821) Steps 856(856.25) | Grad Norm 5.0480(4.1627) | Total Time 14.00(14.00)\n",
      "Iter 12450 | Time 20.2896(20.8155) | Bit/dim 3.5607(3.5799) | Xent 0.2089(0.2258) | Loss 3.6651(3.6929) | Error 0.0789(0.0806) Steps 850(856.88) | Grad Norm 2.7659(4.0517) | Total Time 14.00(14.00)\n",
      "Iter 12460 | Time 20.9429(20.7744) | Bit/dim 3.5870(3.5821) | Xent 0.2050(0.2245) | Loss 3.6895(3.6943) | Error 0.0744(0.0795) Steps 874(857.09) | Grad Norm 2.9091(3.8683) | Total Time 14.00(14.00)\n",
      "Iter 12470 | Time 20.7834(20.7630) | Bit/dim 3.5576(3.5823) | Xent 0.1947(0.2223) | Loss 3.6549(3.6935) | Error 0.0722(0.0788) Steps 868(857.21) | Grad Norm 4.5706(3.9082) | Total Time 14.00(14.00)\n",
      "Iter 12480 | Time 21.2759(20.8005) | Bit/dim 3.5595(3.5803) | Xent 0.2292(0.2279) | Loss 3.6741(3.6943) | Error 0.0811(0.0820) Steps 874(858.90) | Grad Norm 4.8640(4.0723) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0227 | Time 98.1356, Epoch Time 1262.0280(1176.5949), Bit/dim 3.5921(best: 3.5827), Xent 0.8988, Loss 4.0415, Error 0.2441(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12490 | Time 20.6994(20.8998) | Bit/dim 3.5500(3.5787) | Xent 0.3183(0.2375) | Loss 3.7092(3.6974) | Error 0.1044(0.0855) Steps 868(860.26) | Grad Norm 6.5010(4.4199) | Total Time 14.00(14.00)\n",
      "Iter 12500 | Time 21.4735(20.8969) | Bit/dim 3.5768(3.5800) | Xent 0.2360(0.2392) | Loss 3.6948(3.6996) | Error 0.0767(0.0857) Steps 874(860.36) | Grad Norm 3.7636(4.3821) | Total Time 14.00(14.00)\n",
      "Iter 12510 | Time 21.0885(20.9169) | Bit/dim 3.5393(3.5809) | Xent 0.2059(0.2411) | Loss 3.6423(3.7015) | Error 0.0767(0.0861) Steps 874(861.42) | Grad Norm 3.4855(4.4112) | Total Time 14.00(14.00)\n",
      "Iter 12520 | Time 20.9614(20.8673) | Bit/dim 3.5905(3.5805) | Xent 0.2125(0.2382) | Loss 3.6967(3.6995) | Error 0.0744(0.0850) Steps 862(860.54) | Grad Norm 2.2004(4.3280) | Total Time 14.00(14.00)\n",
      "Iter 12530 | Time 20.5673(20.7901) | Bit/dim 3.6061(3.5824) | Xent 0.2225(0.2388) | Loss 3.7174(3.7018) | Error 0.0789(0.0846) Steps 862(858.89) | Grad Norm 2.7811(4.2285) | Total Time 14.00(14.00)\n",
      "Iter 12540 | Time 20.2160(20.6768) | Bit/dim 3.5943(3.5820) | Xent 0.2362(0.2407) | Loss 3.7124(3.7023) | Error 0.0900(0.0860) Steps 862(857.58) | Grad Norm 3.4187(4.1871) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0228 | Time 98.9305, Epoch Time 1257.9331(1179.0350), Bit/dim 3.5917(best: 3.5827), Xent 0.8584, Loss 4.0209, Error 0.2287(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12550 | Time 20.8044(20.7626) | Bit/dim 3.5972(3.5842) | Xent 0.2003(0.2409) | Loss 3.6974(3.7046) | Error 0.0711(0.0863) Steps 844(858.65) | Grad Norm 4.3121(4.3310) | Total Time 14.00(14.00)\n",
      "Iter 12560 | Time 20.7840(20.7717) | Bit/dim 3.5747(3.5840) | Xent 0.2149(0.2357) | Loss 3.6822(3.7019) | Error 0.0789(0.0848) Steps 856(860.73) | Grad Norm 3.5204(4.2199) | Total Time 14.00(14.00)\n",
      "Iter 12570 | Time 20.6603(20.7546) | Bit/dim 3.6113(3.5835) | Xent 0.2003(0.2331) | Loss 3.7115(3.7001) | Error 0.0633(0.0829) Steps 850(858.87) | Grad Norm 3.6781(4.0602) | Total Time 14.00(14.00)\n",
      "Iter 12580 | Time 20.8819(20.7047) | Bit/dim 3.5640(3.5815) | Xent 0.1996(0.2260) | Loss 3.6637(3.6945) | Error 0.0678(0.0806) Steps 850(859.15) | Grad Norm 2.6040(3.8371) | Total Time 14.00(14.00)\n",
      "Iter 12590 | Time 20.6309(20.7227) | Bit/dim 3.5198(3.5786) | Xent 0.2182(0.2191) | Loss 3.6289(3.6881) | Error 0.0822(0.0778) Steps 850(858.39) | Grad Norm 3.2113(3.5896) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0229 | Time 98.7318, Epoch Time 1257.9264(1181.4018), Bit/dim 3.5846(best: 3.5827), Xent 0.8881, Loss 4.0286, Error 0.2284(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12600 | Time 21.2213(20.6984) | Bit/dim 3.5622(3.5784) | Xent 0.2254(0.2177) | Loss 3.6749(3.6872) | Error 0.0811(0.0775) Steps 886(860.32) | Grad Norm 4.0738(3.6943) | Total Time 14.00(14.00)\n",
      "Iter 12610 | Time 20.3157(20.6552) | Bit/dim 3.5672(3.5779) | Xent 0.1704(0.2201) | Loss 3.6524(3.6880) | Error 0.0578(0.0771) Steps 844(858.30) | Grad Norm 5.5740(4.0367) | Total Time 14.00(14.00)\n",
      "Iter 12620 | Time 20.8433(20.7253) | Bit/dim 3.5704(3.5777) | Xent 0.2684(0.2290) | Loss 3.7047(3.6922) | Error 0.0956(0.0806) Steps 874(860.72) | Grad Norm 4.0789(4.2725) | Total Time 14.00(14.00)\n",
      "Iter 12630 | Time 20.7581(20.7131) | Bit/dim 3.5606(3.5750) | Xent 0.1852(0.2252) | Loss 3.6532(3.6876) | Error 0.0633(0.0794) Steps 856(859.92) | Grad Norm 1.9998(3.9642) | Total Time 14.00(14.00)\n",
      "Iter 12640 | Time 21.0636(20.6975) | Bit/dim 3.5652(3.5750) | Xent 0.1496(0.2208) | Loss 3.6400(3.6854) | Error 0.0522(0.0781) Steps 844(857.60) | Grad Norm 1.8642(3.7486) | Total Time 14.00(14.00)\n",
      "Iter 12650 | Time 20.5843(20.7064) | Bit/dim 3.5785(3.5793) | Xent 0.2102(0.2225) | Loss 3.6837(3.6906) | Error 0.0744(0.0784) Steps 844(856.51) | Grad Norm 2.5107(3.7833) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0230 | Time 97.5702, Epoch Time 1254.1110(1183.5830), Bit/dim 3.5846(best: 3.5827), Xent 0.8511, Loss 4.0101, Error 0.2239(best: 0.2141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_tunetol_run2 --resume ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_tunetol_run2/epoch_250_checkpt.pth --seed 2 --conditional True --controlled_tol True --train_mode semisup --lr 0.0001 --warmup_iters 1000 --atol 1e-4  --rtol 1e-4 --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
