{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl_multiscale.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['figure.dpi'] = 300\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"colormnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl_multiscale as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z_sup, z_unsup, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    z_sup = torch.cat(z_sup, 1)\n",
      "    z_unsup = torch.cat(z_unsup, 1)\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z_sup).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z_unsup).view(z_unsup.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z_sup = model.module.dropout(z_sup)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z_sup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            dim_unsup = np.prod(data_shape) - np.prod(fixed_z_sup.shape[1:])\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            \n",
      "            a_sup = fixed_z_sup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            a_unsup = fixed_z_unsup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            \n",
      "            fixed_z = []\n",
      "            start_sup = 0; start_unsup = 0\n",
      "            for ns in range(model.module.n_scale, 1, -1):\n",
      "                end_sup = start_sup + (2**(ns-2))*a_sup\n",
      "                end_unsup = start_unsup + (2**(ns-2))*a_unsup\n",
      "                \n",
      "                fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "                fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "                \n",
      "                start_sup = end_sup; start_unsup = end_unsup\n",
      "            \n",
      "            end_sup = start_sup + a_sup\n",
      "            end_unsup = start_unsup + a_unsup\n",
      "            \n",
      "            fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "            fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "            \n",
      "            # for i_z in range(len(fixed_z)): print(fixed_z[i_z].shape)\n",
      "            \n",
      "            fixed_z = torch.cat(fixed_z,1)\n",
      "            \n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            if args.data == \"colormnist\":\n",
      "                y = y[0]\n",
      "            \n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "            \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if args.data == \"colormnist\":\n",
      "                        y = y[0]\n",
      "                        \n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                    \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=False, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume=None, rl_weight=0.01, rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run2', scale=1.0, scale_fac=1.0, scale_std=6.0, seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0010 | Time 12.4878(30.9478) | Bit/dim 8.7898(8.9400) | Xent 2.2870(2.3008) | Loss 22.2181(22.5052) | Error 0.7733(0.8712) Steps 538(514.94) | Grad Norm 17.0838(24.2882) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 12.6167(26.1165) | Bit/dim 8.6380(8.8528) | Xent 2.2457(2.2911) | Loss 21.6195(22.2457) | Error 0.7278(0.8389) Steps 478(510.18) | Grad Norm 7.8655(20.6815) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 13.0370(22.5785) | Bit/dim 8.3363(8.7458) | Xent 2.2040(2.2732) | Loss 20.9663(21.9449) | Error 0.7344(0.8155) Steps 538(509.29) | Grad Norm 6.8955(17.2650) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 12.2751(19.9610) | Bit/dim 8.2209(8.6049) | Xent 2.1614(2.2498) | Loss 20.2098(21.5999) | Error 0.7356(0.7955) Steps 484(506.68) | Grad Norm 6.0588(14.3177) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 12.6849(17.9693) | Bit/dim 7.8913(8.4467) | Xent 2.1296(2.2238) | Loss 19.9288(21.2149) | Error 0.7111(0.7758) Steps 532(502.46) | Grad Norm 5.5346(12.0962) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 77.2583, Epoch Time 809.1110(809.1110), Bit/dim 7.6937(best: inf), Xent 2.1253, Loss 8.7564, Error 0.7048(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 12.4310(16.5690) | Bit/dim 7.5661(8.2524) | Xent 2.1214(2.1995) | Loss 19.0713(21.3335) | Error 0.6833(0.7564) Steps 460(501.96) | Grad Norm 5.1737(10.3751) | Total Time 0.00(0.00)\n",
      "Iter 0070 | Time 13.1372(15.5999) | Bit/dim 7.2828(8.0260) | Xent 2.1217(2.1798) | Loss 18.6717(20.6765) | Error 0.6511(0.7376) Steps 544(505.29) | Grad Norm 3.7065(8.8264) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 13.2586(15.0201) | Bit/dim 7.1130(7.8005) | Xent 2.1379(2.1682) | Loss 18.2678(20.0951) | Error 0.6811(0.7242) Steps 532(510.26) | Grad Norm 2.5880(7.3357) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 13.5538(14.6080) | Bit/dim 7.0515(7.6065) | Xent 2.1536(2.1626) | Loss 18.1119(19.5841) | Error 0.7078(0.7193) Steps 538(513.84) | Grad Norm 2.6784(6.0751) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 13.6628(14.3124) | Bit/dim 6.9993(7.4504) | Xent 2.1304(2.1551) | Loss 18.0384(19.1898) | Error 0.6756(0.7123) Steps 532(516.04) | Grad Norm 1.8392(5.0613) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 14.0522(14.1606) | Bit/dim 6.9827(7.3261) | Xent 2.1150(2.1464) | Loss 18.1897(18.8794) | Error 0.7011(0.7093) Steps 544(517.72) | Grad Norm 3.7620(4.4399) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 77.8316, Epoch Time 830.2640(809.7456), Bit/dim 6.9634(best: 7.6937), Xent 2.1107, Loss 8.0187, Error 0.6924(best: 0.7048)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 14.1491(14.1400) | Bit/dim 6.9385(7.2250) | Xent 2.1121(2.1370) | Loss 17.9174(19.1462) | Error 0.7167(0.7087) Steps 550(523.05) | Grad Norm 7.2726(4.2893) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 14.1038(14.1156) | Bit/dim 6.8962(7.1413) | Xent 2.0551(2.1236) | Loss 17.7873(18.7990) | Error 0.7056(0.7048) Steps 514(526.33) | Grad Norm 9.3766(4.9125) | Total Time 0.00(0.00)\n",
      "Iter 0140 | Time 13.9283(14.0838) | Bit/dim 6.8363(7.0673) | Xent 2.0714(2.1108) | Loss 17.6011(18.5094) | Error 0.7022(0.7057) Steps 532(528.83) | Grad Norm 12.8775(5.9368) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 13.5182(14.0561) | Bit/dim 6.7408(6.9938) | Xent 2.0192(2.0959) | Loss 17.4742(18.2553) | Error 0.6633(0.7014) Steps 532(532.70) | Grad Norm 2.2205(6.7262) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 14.1364(14.0700) | Bit/dim 6.6647(6.9179) | Xent 2.0388(2.0853) | Loss 17.2375(18.0346) | Error 0.7067(0.7030) Steps 514(534.81) | Grad Norm 15.3833(9.6283) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 79.0380, Epoch Time 869.7442(811.5455), Bit/dim 6.6024(best: 6.9634), Xent 2.0442, Loss 7.6245, Error 0.7141(best: 0.6924)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 13.5663(13.9659) | Bit/dim 6.5726(6.8351) | Xent 2.0691(2.0804) | Loss 17.2382(18.4310) | Error 0.7322(0.7084) Steps 550(535.57) | Grad Norm 50.9013(16.6892) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 13.3427(13.9430) | Bit/dim 6.4463(6.7446) | Xent 2.1008(2.0748) | Loss 16.7651(18.0407) | Error 0.7700(0.7125) Steps 526(536.56) | Grad Norm 52.7056(23.3420) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 13.6255(13.8598) | Bit/dim 6.2699(6.6388) | Xent 2.0654(2.0709) | Loss 16.4149(17.6597) | Error 0.7389(0.7163) Steps 520(537.77) | Grad Norm 38.0827(28.2646) | Total Time 0.00(0.00)\n",
      "Iter 0200 | Time 14.2328(13.8253) | Bit/dim 6.0958(6.5187) | Xent 1.9766(2.0529) | Loss 16.0051(17.2801) | Error 0.6489(0.7060) Steps 556(538.23) | Grad Norm 14.1673(27.0870) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 14.1155(13.8920) | Bit/dim 6.0331(6.4034) | Xent 2.2358(2.1077) | Loss 16.0614(17.0019) | Error 0.8178(0.7261) Steps 544(541.72) | Grad Norm 79.0223(49.7380) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 13.5219(13.8352) | Bit/dim 5.9451(6.2892) | Xent 2.0962(2.1032) | Loss 15.8847(16.7096) | Error 0.7022(0.7278) Steps 556(541.70) | Grad Norm 34.0225(49.0990) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 76.8928, Epoch Time 855.2287(812.8560), Bit/dim 5.8981(best: 6.6024), Xent 2.0520, Loss 6.9241, Error 0.6850(best: 0.6924)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 13.7627(13.7980) | Bit/dim 5.8155(6.1737) | Xent 2.0215(2.0939) | Loss 15.5550(16.9547) | Error 0.6722(0.7223) Steps 544(540.59) | Grad Norm 11.8230(42.1051) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 13.2320(13.7055) | Bit/dim 5.7460(6.0724) | Xent 1.9857(2.0784) | Loss 15.3947(16.5656) | Error 0.6478(0.7126) Steps 538(541.36) | Grad Norm 6.7806(34.6857) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 13.5484(13.6550) | Bit/dim 5.7632(5.9864) | Xent 2.0221(2.0622) | Loss 15.4699(16.2210) | Error 0.6711(0.7060) Steps 514(537.68) | Grad Norm 18.8647(31.9447) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 14.1707(13.6504) | Bit/dim 5.7034(5.9126) | Xent 1.9682(2.0450) | Loss 15.2112(15.9459) | Error 0.6644(0.6987) Steps 550(537.43) | Grad Norm 11.4078(27.2797) | Total Time 0.00(0.00)\n",
      "Iter 0270 | Time 13.6652(13.6688) | Bit/dim 5.6679(5.8528) | Xent 2.0062(2.0344) | Loss 15.1725(15.7275) | Error 0.7078(0.6967) Steps 514(533.61) | Grad Norm 50.4404(29.1998) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 76.9970, Epoch Time 845.0918(813.8231), Bit/dim 5.6657(best: 5.8981), Xent 1.9563, Loss 6.6438, Error 0.6578(best: 0.6850)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 12.8683(13.6265) | Bit/dim 5.6650(5.7998) | Xent 1.9965(2.0174) | Loss 14.9982(16.1734) | Error 0.6822(0.6930) Steps 526(534.54) | Grad Norm 3.1535(27.0438) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 13.3932(13.6072) | Bit/dim 5.6555(5.7606) | Xent 1.9580(2.0032) | Loss 15.1446(15.8851) | Error 0.6611(0.6875) Steps 526(533.11) | Grad Norm 34.9255(26.8425) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 13.6579(13.5976) | Bit/dim 5.6037(5.7237) | Xent 2.0112(1.9957) | Loss 15.1763(15.6547) | Error 0.7033(0.6858) Steps 550(534.86) | Grad Norm 63.2546(28.6167) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 13.2176(13.5268) | Bit/dim 5.6143(5.7069) | Xent 2.0019(2.0206) | Loss 15.0516(15.5393) | Error 0.6800(0.6968) Steps 502(532.56) | Grad Norm 36.2378(41.3396) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 13.8637(13.5579) | Bit/dim 5.5347(5.6769) | Xent 2.0036(2.0159) | Loss 14.6752(15.3717) | Error 0.6900(0.6953) Steps 508(531.04) | Grad Norm 10.3349(35.5091) | Total Time 0.00(0.00)\n",
      "Iter 0330 | Time 12.7366(13.5479) | Bit/dim 5.5503(5.6471) | Xent 1.9898(2.0111) | Loss 14.6745(15.2375) | Error 0.6756(0.6937) Steps 520(528.40) | Grad Norm 17.3737(30.7300) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 76.1779, Epoch Time 838.7445(814.5707), Bit/dim 5.5279(best: 5.6657), Xent 1.9599, Loss 6.5078, Error 0.6622(best: 0.6578)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 12.9654(13.5141) | Bit/dim 5.4967(5.6109) | Xent 1.9609(2.0009) | Loss 14.6593(15.6473) | Error 0.6589(0.6895) Steps 520(528.50) | Grad Norm 6.6385(25.3335) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 13.7316(13.5121) | Bit/dim 5.4686(5.5776) | Xent 1.9155(1.9877) | Loss 14.5423(15.3850) | Error 0.6600(0.6823) Steps 544(528.95) | Grad Norm 11.6208(21.0897) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 13.5548(13.5189) | Bit/dim 5.3653(5.5339) | Xent 1.9120(1.9759) | Loss 14.1804(15.1497) | Error 0.6600(0.6799) Steps 520(529.60) | Grad Norm 17.6623(20.1289) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 14.0560(13.5783) | Bit/dim 5.3443(5.4941) | Xent 1.9338(1.9685) | Loss 14.2354(14.9671) | Error 0.6567(0.6773) Steps 526(530.61) | Grad Norm 6.9150(19.3383) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 14.4782(13.6572) | Bit/dim 5.2968(5.4511) | Xent 1.9428(1.9590) | Loss 14.1451(14.8002) | Error 0.6789(0.6760) Steps 496(528.97) | Grad Norm 18.5557(20.2582) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 78.4072, Epoch Time 848.2996(815.5826), Bit/dim 5.2786(best: 5.5279), Xent 1.8824, Loss 6.2198, Error 0.6393(best: 0.6578)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 13.7411(13.7173) | Bit/dim 5.3123(5.4086) | Xent 1.9528(1.9542) | Loss 14.3770(15.2690) | Error 0.6900(0.6773) Steps 520(530.42) | Grad Norm 27.4749(20.9005) | Total Time 0.00(0.00)\n",
      "Iter 0400 | Time 13.5958(13.7468) | Bit/dim 5.2248(5.3684) | Xent 1.8697(1.9369) | Loss 13.9050(14.9642) | Error 0.6411(0.6692) Steps 538(532.05) | Grad Norm 7.8259(19.8472) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 13.9170(13.8371) | Bit/dim 5.1832(5.3278) | Xent 2.0335(1.9346) | Loss 14.2607(14.7333) | Error 0.7233(0.6725) Steps 556(533.76) | Grad Norm 72.8726(24.1139) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 13.8815(13.8956) | Bit/dim 5.1828(5.2874) | Xent 1.9130(1.9375) | Loss 14.0074(14.5473) | Error 0.6489(0.6740) Steps 562(535.71) | Grad Norm 10.6227(25.9755) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 14.1266(13.9665) | Bit/dim 5.1302(5.2496) | Xent 1.9667(1.9322) | Loss 13.9961(14.3787) | Error 0.6844(0.6734) Steps 562(535.93) | Grad Norm 8.8028(23.3644) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 14.6353(13.9788) | Bit/dim 5.0599(5.2121) | Xent 1.8839(1.9223) | Loss 13.6369(14.2321) | Error 0.6744(0.6702) Steps 574(537.30) | Grad Norm 18.1513(21.3001) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 78.1657, Epoch Time 868.7752(817.1784), Bit/dim 5.1003(best: 5.2786), Xent 1.8420, Loss 6.0213, Error 0.6245(best: 0.6393)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 14.0238(14.0099) | Bit/dim 5.0416(5.1772) | Xent 1.8634(1.9116) | Loss 13.6476(14.6319) | Error 0.6589(0.6687) Steps 550(538.37) | Grad Norm 13.7588(21.5801) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 13.3477(14.0393) | Bit/dim 5.0389(5.1439) | Xent 1.8559(1.9013) | Loss 13.8311(14.3973) | Error 0.6467(0.6649) Steps 544(539.97) | Grad Norm 23.1935(22.0939) | Total Time 0.00(0.00)\n",
      "Iter 0470 | Time 13.6127(14.0438) | Bit/dim 5.0036(5.1139) | Xent 1.8963(1.9004) | Loss 13.5889(14.2211) | Error 0.6700(0.6642) Steps 532(542.72) | Grad Norm 36.3876(25.0054) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 13.3831(14.0131) | Bit/dim 4.9932(5.0869) | Xent 1.8717(1.8953) | Loss 13.2619(14.0335) | Error 0.6633(0.6627) Steps 538(542.06) | Grad Norm 23.2208(23.9439) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 15.0504(14.0894) | Bit/dim 4.9964(5.0525) | Xent 1.8238(1.8843) | Loss 13.5064(13.8888) | Error 0.6067(0.6570) Steps 538(542.86) | Grad Norm 8.0098(21.5076) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 77.9329, Epoch Time 872.4308(818.8359), Bit/dim 4.9662(best: 5.1003), Xent 1.9275, Loss 5.9300, Error 0.6769(best: 0.6245)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 14.5874(14.0696) | Bit/dim 4.9632(5.0314) | Xent 1.9160(1.8907) | Loss 13.5159(14.4163) | Error 0.6756(0.6616) Steps 556(545.98) | Grad Norm 22.1535(23.3846) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 13.7375(14.0940) | Bit/dim 4.9358(5.0084) | Xent 1.8156(1.8780) | Loss 13.2315(14.1468) | Error 0.6400(0.6559) Steps 538(546.00) | Grad Norm 19.2020(22.3199) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 14.0972(14.0417) | Bit/dim 4.9237(5.0185) | Xent 1.9723(1.9241) | Loss 13.6613(14.0706) | Error 0.7078(0.6722) Steps 526(544.12) | Grad Norm 16.9023(32.0358) | Total Time 0.00(0.00)\n",
      "Iter 0530 | Time 14.5746(14.0415) | Bit/dim 4.9386(4.9982) | Xent 1.9542(1.9327) | Loss 13.4498(13.9201) | Error 0.6922(0.6785) Steps 508(542.14) | Grad Norm 9.6441(27.6858) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 14.6414(14.0743) | Bit/dim 4.8407(4.9666) | Xent 1.9104(1.9280) | Loss 13.4713(13.7732) | Error 0.6822(0.6788) Steps 544(541.60) | Grad Norm 7.4756(22.7192) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 13.5552(13.9976) | Bit/dim 4.8772(4.9327) | Xent 1.9079(1.9209) | Loss 13.2436(13.6202) | Error 0.6500(0.6757) Steps 490(537.76) | Grad Norm 8.7423(19.0829) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 76.0234, Epoch Time 866.3197(820.2605), Bit/dim 4.8290(best: 4.9662), Xent 1.8281, Loss 5.7431, Error 0.6335(best: 0.6245)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 13.6677(13.9322) | Bit/dim 4.8035(4.9010) | Xent 1.8988(1.9070) | Loss 13.0710(13.9962) | Error 0.6722(0.6698) Steps 532(533.81) | Grad Norm 11.3006(17.1169) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 13.8119(13.9017) | Bit/dim 4.7532(4.8714) | Xent 1.8245(1.8905) | Loss 12.9533(13.7444) | Error 0.6167(0.6637) Steps 514(529.24) | Grad Norm 8.8498(15.2543) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 14.1446(13.9279) | Bit/dim 4.7366(4.8437) | Xent 1.8862(1.8800) | Loss 12.9983(13.5602) | Error 0.6656(0.6606) Steps 514(527.23) | Grad Norm 13.6882(15.3614) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 14.5124(13.8589) | Bit/dim 4.7370(4.8193) | Xent 1.8527(1.8683) | Loss 13.0414(13.4023) | Error 0.6400(0.6553) Steps 562(525.42) | Grad Norm 15.3870(14.9870) | Total Time 0.00(0.00)\n",
      "Iter 0600 | Time 13.8753(13.8731) | Bit/dim 4.7294(4.7985) | Xent 1.8471(1.8553) | Loss 12.7604(13.2697) | Error 0.6444(0.6515) Steps 520(524.31) | Grad Norm 14.9941(15.9307) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 75.1837, Epoch Time 854.9153(821.3001), Bit/dim 4.7424(best: 4.8290), Xent 1.8909, Loss 5.6878, Error 0.6829(best: 0.6245)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 14.0640(13.8342) | Bit/dim 4.7093(4.7801) | Xent 1.8292(1.8542) | Loss 12.9277(13.7577) | Error 0.6167(0.6513) Steps 502(522.18) | Grad Norm 13.1005(19.3424) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 14.2969(13.8962) | Bit/dim 4.6869(4.7609) | Xent 1.8325(1.8450) | Loss 12.9524(13.5240) | Error 0.6722(0.6504) Steps 526(523.53) | Grad Norm 15.1676(19.6122) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 14.7401(13.8866) | Bit/dim 4.6997(4.7358) | Xent 1.7844(1.8275) | Loss 13.0140(13.3249) | Error 0.6444(0.6467) Steps 520(523.19) | Grad Norm 13.2273(17.5919) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 14.3504(13.9690) | Bit/dim 4.6722(4.7232) | Xent 1.8459(1.8196) | Loss 12.6487(13.1978) | Error 0.6489(0.6422) Steps 520(523.88) | Grad Norm 29.3764(19.3579) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 14.4377(14.0525) | Bit/dim 4.6829(4.7074) | Xent 1.8151(1.8077) | Loss 12.7789(13.0882) | Error 0.6456(0.6395) Steps 556(526.88) | Grad Norm 25.4812(19.8557) | Total Time 0.00(0.00)\n",
      "Iter 0660 | Time 13.7034(13.9637) | Bit/dim 4.7089(4.6951) | Xent 1.8430(1.8099) | Loss 12.9419(12.9896) | Error 0.6267(0.6411) Steps 520(524.61) | Grad Norm 41.9342(21.3251) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 77.2285, Epoch Time 866.3825(822.6526), Bit/dim 4.6752(best: 4.7424), Xent 1.7730, Loss 5.5618, Error 0.6219(best: 0.6245)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 13.9036(13.9339) | Bit/dim 4.6215(4.6818) | Xent 1.7472(1.8035) | Loss 12.7389(13.4684) | Error 0.6289(0.6387) Steps 526(525.07) | Grad Norm 11.1784(20.6421) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 14.2970(13.9682) | Bit/dim 4.5834(4.6640) | Xent 1.7332(1.7879) | Loss 12.5382(13.2350) | Error 0.6178(0.6331) Steps 544(525.67) | Grad Norm 10.0333(19.7776) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 13.3408(13.9639) | Bit/dim 4.6033(4.6498) | Xent 1.7580(1.7811) | Loss 12.3349(13.0706) | Error 0.6200(0.6310) Steps 520(527.11) | Grad Norm 17.2411(21.0666) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 14.2147(13.9616) | Bit/dim 4.6030(4.6484) | Xent 1.8685(1.7983) | Loss 12.6705(12.9844) | Error 0.6600(0.6363) Steps 484(524.02) | Grad Norm 21.4434(24.3040) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 14.5227(13.9798) | Bit/dim 4.5699(4.6336) | Xent 1.7540(1.7867) | Loss 12.5185(12.8723) | Error 0.6389(0.6346) Steps 544(523.98) | Grad Norm 15.2235(21.2849) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 77.8176, Epoch Time 865.2566(823.9307), Bit/dim 4.5843(best: 4.6752), Xent 1.6644, Loss 5.4165, Error 0.5864(best: 0.6219)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 13.7902(13.9865) | Bit/dim 4.5388(4.6165) | Xent 1.7263(1.7668) | Loss 12.5066(13.3683) | Error 0.6000(0.6270) Steps 544(526.86) | Grad Norm 13.5261(19.0123) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 14.4139(13.9959) | Bit/dim 4.6089(4.6061) | Xent 1.6318(1.7402) | Loss 12.5397(13.1219) | Error 0.5844(0.6180) Steps 550(525.40) | Grad Norm 24.2100(18.6590) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 14.5532(13.9858) | Bit/dim 4.5292(4.5895) | Xent 1.6876(1.7183) | Loss 12.4109(12.9149) | Error 0.5878(0.6100) Steps 526(523.37) | Grad Norm 13.9671(16.9703) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 13.7985(14.1014) | Bit/dim 4.5647(4.5828) | Xent 1.7116(1.7115) | Loss 12.2828(12.7973) | Error 0.6133(0.6093) Steps 538(528.46) | Grad Norm 24.4107(18.7867) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 14.2688(14.1922) | Bit/dim 4.5958(4.5896) | Xent 1.8221(1.7577) | Loss 12.6201(12.7824) | Error 0.6744(0.6246) Steps 568(535.54) | Grad Norm 14.4550(21.2618) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 14.7661(14.3564) | Bit/dim 4.5005(4.5802) | Xent 1.7112(1.7528) | Loss 12.4485(12.7191) | Error 0.5911(0.6230) Steps 520(540.22) | Grad Norm 14.8248(19.0199) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 79.6045, Epoch Time 886.8736(825.8190), Bit/dim 4.5309(best: 4.5843), Xent 1.6608, Loss 5.3613, Error 0.5900(best: 0.5864)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 14.6928(14.3660) | Bit/dim 4.5280(4.5632) | Xent 1.6881(1.7395) | Loss 12.4364(13.1585) | Error 0.5744(0.6177) Steps 544(539.82) | Grad Norm 15.7021(17.0366) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 14.4733(14.2553) | Bit/dim 4.4779(4.5447) | Xent 1.6714(1.7314) | Loss 12.1604(12.9284) | Error 0.5867(0.6142) Steps 574(538.24) | Grad Norm 24.4144(18.8717) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 14.8577(14.2281) | Bit/dim 4.4509(4.5311) | Xent 1.7178(1.7148) | Loss 12.4125(12.7646) | Error 0.6133(0.6104) Steps 580(541.23) | Grad Norm 22.5101(19.9980) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 14.0958(14.3338) | Bit/dim 4.4853(4.5221) | Xent 1.6094(1.7019) | Loss 12.1725(12.6521) | Error 0.5822(0.6081) Steps 544(544.01) | Grad Norm 23.7964(20.5530) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 13.3732(14.3386) | Bit/dim 4.4417(4.5049) | Xent 1.6451(1.6799) | Loss 11.9871(12.5232) | Error 0.5767(0.6005) Steps 544(548.72) | Grad Norm 16.7787(17.8115) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 77.9469, Epoch Time 885.5867(827.6120), Bit/dim 4.6472(best: 4.5309), Xent 1.8153, Loss 5.5549, Error 0.6688(best: 0.5864)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 14.0538(14.4321) | Bit/dim 4.5912(4.5402) | Xent 1.7915(1.7266) | Loss 12.6528(13.1851) | Error 0.6389(0.6160) Steps 532(549.14) | Grad Norm 20.2666(22.4318) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 14.6155(14.4226) | Bit/dim 4.5209(4.5442) | Xent 1.7019(1.7327) | Loss 12.4362(13.0114) | Error 0.6167(0.6199) Steps 568(548.97) | Grad Norm 12.3523(20.2018) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 14.2442(14.4215) | Bit/dim 4.4931(4.5275) | Xent 1.6501(1.7142) | Loss 12.3669(12.8339) | Error 0.5844(0.6146) Steps 526(547.62) | Grad Norm 9.5624(17.0530) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 14.7772(14.4643) | Bit/dim 4.4594(4.5061) | Xent 1.6670(1.6918) | Loss 12.2396(12.6561) | Error 0.5933(0.6072) Steps 550(547.83) | Grad Norm 10.6009(15.4331) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 14.8377(14.4716) | Bit/dim 4.4230(4.4859) | Xent 1.5078(1.6656) | Loss 11.9476(12.4999) | Error 0.5400(0.5975) Steps 508(543.00) | Grad Norm 4.2854(13.3383) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 14.5465(14.5454) | Bit/dim 4.3861(4.4637) | Xent 1.5681(1.6484) | Loss 12.0212(12.3794) | Error 0.5522(0.5909) Steps 580(544.30) | Grad Norm 18.0317(13.3716) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 78.3024, Epoch Time 898.4175(829.7362), Bit/dim 4.4014(best: 4.5309), Xent 1.5285, Loss 5.1656, Error 0.5528(best: 0.5864)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 14.8929(14.6062) | Bit/dim 4.4068(4.4457) | Xent 1.6182(1.6294) | Loss 12.1360(12.8038) | Error 0.5467(0.5830) Steps 604(551.94) | Grad Norm 31.0702(14.3845) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 14.7067(14.6043) | Bit/dim 4.4272(4.4351) | Xent 1.4898(1.6259) | Loss 12.1000(12.6136) | Error 0.5144(0.5819) Steps 550(555.43) | Grad Norm 10.5311(16.0202) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 13.8526(14.6027) | Bit/dim 4.3781(4.4231) | Xent 1.5347(1.6108) | Loss 11.9355(12.4461) | Error 0.5544(0.5770) Steps 556(556.02) | Grad Norm 19.3356(16.2139) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 14.0534(14.5525) | Bit/dim 4.3468(4.4105) | Xent 1.5339(1.5976) | Loss 11.8234(12.3078) | Error 0.5533(0.5717) Steps 550(555.43) | Grad Norm 7.9344(16.2555) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 15.3899(14.6440) | Bit/dim 4.3739(4.3978) | Xent 1.5972(1.5879) | Loss 12.1010(12.1947) | Error 0.5556(0.5692) Steps 562(554.99) | Grad Norm 20.0795(16.9365) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 80.0896, Epoch Time 909.1604(832.1189), Bit/dim 4.4218(best: 4.4014), Xent 1.5900, Loss 5.2169, Error 0.5721(best: 0.5528)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 15.0674(14.7413) | Bit/dim 4.4007(4.3942) | Xent 1.5121(1.5837) | Loss 11.8935(12.7498) | Error 0.5367(0.5678) Steps 562(560.30) | Grad Norm 15.4635(18.5006) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 14.7265(14.7988) | Bit/dim 4.3124(4.3831) | Xent 1.4825(1.5621) | Loss 11.7227(12.5119) | Error 0.5411(0.5605) Steps 550(559.05) | Grad Norm 10.2900(17.8333) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 15.9559(14.9405) | Bit/dim 4.3192(4.3692) | Xent 1.5223(1.5483) | Loss 11.8482(12.3182) | Error 0.5644(0.5571) Steps 556(559.12) | Grad Norm 13.4131(16.2167) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 15.7420(15.0192) | Bit/dim 4.3407(4.3593) | Xent 1.5453(1.5458) | Loss 11.8764(12.1813) | Error 0.5589(0.5570) Steps 556(561.28) | Grad Norm 21.9038(17.7352) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 15.8091(15.1252) | Bit/dim 4.7039(4.3730) | Xent 3.6427(1.6379) | Loss 14.6678(12.2414) | Error 0.7822(0.5717) Steps 640(569.55) | Grad Norm 113.3125(24.3210) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 16.4624(15.4350) | Bit/dim 4.6112(4.4575) | Xent 1.8573(1.7391) | Loss 12.9723(12.5163) | Error 0.6811(0.6089) Steps 682(592.71) | Grad Norm 11.9957(24.3029) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 88.6559, Epoch Time 953.1012(835.7484), Bit/dim 4.5680(best: 4.4014), Xent 1.7866, Loss 5.4613, Error 0.6276(best: 0.5528)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 15.7112(15.4618) | Bit/dim 4.4302(4.4628) | Xent 1.7853(1.7555) | Loss 12.5337(13.1801) | Error 0.6556(0.6174) Steps 640(597.66) | Grad Norm 6.8250(20.6625) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 15.3023(15.2971) | Bit/dim 4.3601(4.4425) | Xent 1.6952(1.7339) | Loss 12.0725(12.9049) | Error 0.6211(0.6123) Steps 580(595.47) | Grad Norm 6.0294(16.9781) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 16.4368(15.3661) | Bit/dim 4.3400(4.4145) | Xent 1.5835(1.7015) | Loss 11.9706(12.6687) | Error 0.5844(0.6050) Steps 598(597.16) | Grad Norm 21.3294(14.8679) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 16.0120(15.4219) | Bit/dim 4.3173(4.3886) | Xent 1.5055(1.6737) | Loss 11.8514(12.4731) | Error 0.5378(0.5960) Steps 616(598.69) | Grad Norm 9.7359(15.2926) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 14.6745(15.2673) | Bit/dim 4.2854(4.3650) | Xent 1.5595(1.6472) | Loss 11.6494(12.3081) | Error 0.5778(0.5876) Steps 544(588.50) | Grad Norm 8.3163(14.0236) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 82.4280, Epoch Time 939.8524(838.8715), Bit/dim 4.2830(best: 4.4014), Xent 1.5115, Loss 5.0387, Error 0.5403(best: 0.5528)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 15.4432(15.2353) | Bit/dim 4.2729(4.3422) | Xent 1.5361(1.6160) | Loss 11.7538(12.7924) | Error 0.5556(0.5765) Steps 538(581.61) | Grad Norm 12.9273(14.0179) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 15.5338(15.3321) | Bit/dim 4.2636(4.3238) | Xent 1.4632(1.5859) | Loss 11.5431(12.5136) | Error 0.5167(0.5687) Steps 586(583.81) | Grad Norm 10.5733(13.7928) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 15.2196(15.3361) | Bit/dim 4.1969(4.3032) | Xent 1.4056(1.5586) | Loss 11.4893(12.2705) | Error 0.5089(0.5617) Steps 592(583.64) | Grad Norm 9.2881(13.0882) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 16.0360(15.4407) | Bit/dim 4.2720(4.2875) | Xent 1.5282(1.5385) | Loss 11.8042(12.1025) | Error 0.5689(0.5555) Steps 592(587.14) | Grad Norm 30.6051(13.2756) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 16.1331(15.4910) | Bit/dim 4.2127(4.2721) | Xent 1.5042(1.5241) | Loss 11.5674(11.9844) | Error 0.5678(0.5510) Steps 634(593.21) | Grad Norm 15.6895(13.6506) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 14.8498(15.4853) | Bit/dim 4.2220(4.2594) | Xent 1.4851(1.5092) | Loss 11.4994(11.8699) | Error 0.5444(0.5458) Steps 598(595.31) | Grad Norm 13.6720(12.7276) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 82.8691, Epoch Time 957.5345(842.4314), Bit/dim 4.2171(best: 4.2830), Xent 1.4107, Loss 4.9224, Error 0.5102(best: 0.5403)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 16.4742(15.5911) | Bit/dim 4.2325(4.2495) | Xent 1.5390(1.4944) | Loss 11.6494(12.3288) | Error 0.5411(0.5388) Steps 568(597.23) | Grad Norm 26.4762(13.9070) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 16.7282(15.6139) | Bit/dim 4.2325(4.2412) | Xent 1.4649(1.4889) | Loss 11.6393(12.1365) | Error 0.5144(0.5359) Steps 592(598.34) | Grad Norm 10.7645(14.5310) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 15.5653(15.6246) | Bit/dim 4.2013(4.2302) | Xent 1.3621(1.4726) | Loss 11.4782(11.9712) | Error 0.4989(0.5280) Steps 592(601.51) | Grad Norm 6.4263(12.8395) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 15.1245(15.5774) | Bit/dim 4.1908(4.2176) | Xent 1.4561(1.4637) | Loss 11.3714(11.8268) | Error 0.5267(0.5251) Steps 610(600.15) | Grad Norm 12.8225(12.0199) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 16.0030(15.6887) | Bit/dim 4.1885(4.2057) | Xent 1.3943(1.4531) | Loss 11.4130(11.7293) | Error 0.4911(0.5213) Steps 586(598.29) | Grad Norm 15.0162(11.7259) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 81.5043, Epoch Time 966.3680(846.1495), Bit/dim 4.1953(best: 4.2171), Xent 1.4098, Loss 4.9002, Error 0.5085(best: 0.5102)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 15.9131(15.6746) | Bit/dim 4.1864(4.2030) | Xent 1.3638(1.4424) | Loss 11.4118(12.2872) | Error 0.4933(0.5175) Steps 634(602.79) | Grad Norm 14.3675(13.5420) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 15.8546(15.7243) | Bit/dim 4.1816(4.1965) | Xent 1.3368(1.4283) | Loss 11.4090(12.0539) | Error 0.4711(0.5140) Steps 550(600.51) | Grad Norm 11.4277(13.8090) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 15.2224(15.6619) | Bit/dim 4.2181(4.1901) | Xent 1.4229(1.4241) | Loss 11.5354(11.8735) | Error 0.5022(0.5124) Steps 592(602.53) | Grad Norm 10.7740(14.5633) | Total Time 0.00(0.00)\n",
      "Iter 1190 | Time 15.2182(15.5519) | Bit/dim 4.1709(4.1820) | Xent 1.4604(1.4196) | Loss 11.4297(11.7421) | Error 0.5333(0.5115) Steps 586(596.58) | Grad Norm 14.5685(14.6098) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 15.3437(15.5136) | Bit/dim 4.1496(4.1729) | Xent 1.3706(1.4050) | Loss 11.2000(11.6212) | Error 0.4922(0.5082) Steps 586(593.83) | Grad Norm 13.2416(13.2817) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 15.8214(15.6074) | Bit/dim 4.1199(4.1601) | Xent 1.3770(1.3919) | Loss 11.3159(11.5070) | Error 0.4967(0.5037) Steps 628(591.97) | Grad Norm 15.1108(13.1873) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 83.2313, Epoch Time 959.1390(849.5392), Bit/dim 4.1387(best: 4.1953), Xent 1.3135, Loss 4.7955, Error 0.4733(best: 0.5085)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 15.7179(15.5676) | Bit/dim 4.1357(4.1524) | Xent 1.2553(1.3742) | Loss 11.2109(11.9807) | Error 0.4633(0.4988) Steps 586(592.34) | Grad Norm 7.5375(12.6728) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 15.8240(15.5306) | Bit/dim 4.1384(4.1469) | Xent 1.4029(1.3787) | Loss 11.3058(11.7991) | Error 0.4878(0.4965) Steps 616(594.05) | Grad Norm 17.1162(14.6930) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 15.2356(15.4882) | Bit/dim 4.1150(4.1412) | Xent 1.3422(1.3684) | Loss 11.0978(11.6372) | Error 0.4844(0.4930) Steps 610(592.14) | Grad Norm 9.0916(14.3648) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 15.2294(15.4796) | Bit/dim 4.1011(4.1305) | Xent 1.3712(1.3597) | Loss 11.2577(11.5051) | Error 0.4956(0.4914) Steps 562(588.42) | Grad Norm 14.7952(13.7760) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 16.6196(15.4838) | Bit/dim 4.0768(4.1240) | Xent 1.3615(1.3490) | Loss 11.2084(11.4063) | Error 0.4933(0.4865) Steps 640(588.25) | Grad Norm 11.9388(13.9152) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 84.4522, Epoch Time 954.9283(852.7008), Bit/dim 4.1338(best: 4.1387), Xent 1.2991, Loss 4.7833, Error 0.4677(best: 0.4733)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 14.8610(15.4739) | Bit/dim 4.0772(4.1222) | Xent 1.4491(1.3580) | Loss 11.2535(12.0214) | Error 0.5378(0.4874) Steps 610(590.97) | Grad Norm 18.6287(15.7670) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 16.1037(15.4408) | Bit/dim 4.1109(4.1204) | Xent 1.3660(1.3583) | Loss 11.3282(11.8159) | Error 0.4967(0.4875) Steps 616(591.86) | Grad Norm 11.7806(16.8937) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 15.4196(15.4222) | Bit/dim 4.1029(4.1162) | Xent 1.3425(1.3440) | Loss 11.1631(11.6418) | Error 0.4856(0.4840) Steps 580(590.38) | Grad Norm 17.2412(16.0523) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 16.2074(15.4786) | Bit/dim 4.0759(4.1083) | Xent 1.3052(1.3346) | Loss 11.0564(11.5079) | Error 0.4367(0.4801) Steps 634(594.48) | Grad Norm 19.2630(15.7493) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 15.0852(15.4739) | Bit/dim 4.0875(4.1021) | Xent 1.3417(1.3340) | Loss 11.1584(11.4100) | Error 0.4944(0.4814) Steps 586(595.79) | Grad Norm 18.9766(16.2917) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 15.2760(15.4980) | Bit/dim 4.1080(4.0961) | Xent 1.3646(1.3308) | Loss 11.3229(11.3250) | Error 0.4922(0.4805) Steps 556(592.40) | Grad Norm 18.0783(15.4395) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 83.1677, Epoch Time 952.8987(855.7068), Bit/dim 4.0757(best: 4.1338), Xent 1.2618, Loss 4.7066, Error 0.4547(best: 0.4677)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 14.8720(15.4579) | Bit/dim 4.0900(4.0919) | Xent 1.3505(1.3196) | Loss 11.0679(11.7955) | Error 0.4756(0.4761) Steps 592(591.57) | Grad Norm 23.0393(16.0595) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 15.6067(15.5377) | Bit/dim 4.0475(4.0838) | Xent 1.2443(1.3085) | Loss 10.9122(11.6150) | Error 0.4733(0.4720) Steps 610(594.98) | Grad Norm 8.4937(15.4868) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 14.9839(15.5354) | Bit/dim 4.0474(4.0764) | Xent 1.2260(1.2905) | Loss 10.8893(11.4550) | Error 0.4300(0.4654) Steps 580(596.22) | Grad Norm 13.8610(14.6008) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 14.9445(15.5101) | Bit/dim 4.0270(4.0716) | Xent 1.2384(1.2896) | Loss 10.7859(11.3430) | Error 0.4344(0.4625) Steps 580(596.21) | Grad Norm 14.6406(16.0626) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 16.0754(15.5079) | Bit/dim 4.0387(4.0682) | Xent 1.2738(1.2825) | Loss 10.9985(11.2463) | Error 0.4700(0.4603) Steps 580(594.32) | Grad Norm 12.5337(15.2864) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 83.5471, Epoch Time 956.3881(858.7272), Bit/dim 4.0378(best: 4.0757), Xent 1.2015, Loss 4.6386, Error 0.4300(best: 0.4547)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 15.6661(15.4777) | Bit/dim 4.0040(4.0602) | Xent 1.2638(1.2669) | Loss 10.9776(11.7909) | Error 0.4444(0.4535) Steps 598(595.37) | Grad Norm 8.5174(14.5086) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 14.8631(15.4502) | Bit/dim 4.0545(4.0546) | Xent 1.2535(1.2582) | Loss 10.8312(11.5607) | Error 0.4478(0.4505) Steps 598(595.14) | Grad Norm 13.8201(14.8171) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 15.8339(15.4974) | Bit/dim 4.0393(4.0527) | Xent 1.1713(1.2437) | Loss 10.9695(11.4065) | Error 0.4200(0.4458) Steps 610(598.05) | Grad Norm 9.2499(14.0600) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 14.9605(15.5025) | Bit/dim 4.0034(4.0452) | Xent 1.1557(1.2344) | Loss 10.7942(11.2676) | Error 0.4300(0.4425) Steps 592(600.33) | Grad Norm 9.3955(14.1711) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 14.7130(15.4365) | Bit/dim 4.0828(4.0426) | Xent 1.1858(1.2234) | Loss 10.9217(11.1586) | Error 0.4356(0.4398) Steps 562(596.87) | Grad Norm 7.3255(12.9358) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 15.5599(15.4443) | Bit/dim 4.0145(4.0388) | Xent 1.2399(1.2251) | Loss 10.8352(11.0837) | Error 0.4556(0.4398) Steps 592(595.14) | Grad Norm 14.9803(14.3550) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 84.6775, Epoch Time 953.6894(861.5761), Bit/dim 4.0323(best: 4.0378), Xent 1.2460, Loss 4.6553, Error 0.4538(best: 0.4300)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 16.0950(15.4408) | Bit/dim 3.9848(4.0372) | Xent 1.3146(1.2354) | Loss 10.8515(11.5879) | Error 0.4722(0.4424) Steps 580(592.34) | Grad Norm 12.8965(15.6399) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 15.7236(15.4544) | Bit/dim 4.0266(4.0361) | Xent 1.1186(1.2290) | Loss 10.7946(11.4170) | Error 0.3967(0.4403) Steps 616(595.04) | Grad Norm 12.6968(14.9841) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 15.0168(15.4514) | Bit/dim 3.9596(4.0280) | Xent 1.1459(1.2146) | Loss 10.6659(11.2522) | Error 0.4100(0.4349) Steps 568(597.47) | Grad Norm 8.3177(13.6967) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 15.2407(15.4116) | Bit/dim 4.0140(4.0227) | Xent 1.2085(1.2034) | Loss 10.8213(11.1265) | Error 0.4189(0.4301) Steps 604(595.51) | Grad Norm 18.2282(12.8813) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 16.6455(15.5181) | Bit/dim 4.0303(4.0184) | Xent 1.2233(1.1976) | Loss 10.8600(11.0386) | Error 0.4378(0.4271) Steps 580(594.35) | Grad Norm 18.1639(13.0108) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 84.7211, Epoch Time 957.5234(864.4545), Bit/dim 4.0028(best: 4.0323), Xent 1.1432, Loss 4.5744, Error 0.4111(best: 0.4300)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 16.2927(15.5998) | Bit/dim 3.9839(4.0147) | Xent 1.2048(1.1952) | Loss 10.8545(11.6339) | Error 0.4311(0.4244) Steps 622(597.48) | Grad Norm 15.9198(13.5660) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 15.6182(15.6316) | Bit/dim 3.9889(4.0116) | Xent 1.1771(1.1821) | Loss 10.5805(11.3956) | Error 0.4167(0.4222) Steps 586(597.83) | Grad Norm 16.1824(13.4355) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 15.9192(15.6478) | Bit/dim 3.9906(4.0064) | Xent 1.1274(1.1764) | Loss 10.8082(11.2305) | Error 0.3967(0.4200) Steps 604(599.90) | Grad Norm 11.4321(13.0687) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 15.7373(15.6105) | Bit/dim 4.0153(4.0029) | Xent 1.1369(1.1693) | Loss 10.8376(11.1090) | Error 0.4200(0.4176) Steps 616(599.72) | Grad Norm 15.9102(12.9999) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 15.4610(15.6707) | Bit/dim 3.9364(3.9960) | Xent 1.1678(1.1640) | Loss 10.5164(10.9978) | Error 0.4200(0.4166) Steps 550(595.97) | Grad Norm 13.3350(13.4238) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 15.1365(15.6659) | Bit/dim 3.9926(3.9952) | Xent 1.0987(1.1594) | Loss 10.6985(10.9415) | Error 0.3900(0.4146) Steps 586(597.01) | Grad Norm 14.5403(13.1199) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 83.8773, Epoch Time 968.3190(867.5704), Bit/dim 3.9727(best: 4.0028), Xent 1.1411, Loss 4.5433, Error 0.4136(best: 0.4111)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 15.0865(15.5883) | Bit/dim 3.9608(3.9899) | Xent 1.1365(1.1472) | Loss 10.6370(11.4267) | Error 0.4178(0.4103) Steps 586(593.83) | Grad Norm 8.8185(12.6774) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 15.0671(15.6003) | Bit/dim 3.9921(3.9842) | Xent 1.0863(1.1368) | Loss 10.7028(11.2186) | Error 0.3800(0.4070) Steps 586(592.39) | Grad Norm 10.5434(12.2189) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 15.7417(15.6544) | Bit/dim 3.9771(3.9837) | Xent 1.0429(1.1233) | Loss 10.6014(11.0680) | Error 0.3767(0.4027) Steps 610(594.35) | Grad Norm 6.2328(11.7170) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 15.6938(15.6982) | Bit/dim 3.9333(3.9747) | Xent 1.1222(1.1208) | Loss 10.4016(10.9414) | Error 0.4078(0.4029) Steps 598(595.93) | Grad Norm 9.4709(11.3048) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 14.9245(15.6593) | Bit/dim 3.9325(3.9723) | Xent 1.1341(1.1260) | Loss 10.5568(10.8732) | Error 0.4200(0.4061) Steps 592(597.04) | Grad Norm 12.2951(12.2932) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 85.1505, Epoch Time 964.2504(870.4708), Bit/dim 3.9658(best: 3.9727), Xent 1.1332, Loss 4.5324, Error 0.4007(best: 0.4111)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 15.9513(15.6379) | Bit/dim 3.9136(3.9692) | Xent 1.0882(1.1243) | Loss 10.5339(11.4596) | Error 0.4044(0.4044) Steps 628(598.20) | Grad Norm 10.2152(12.5460) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 15.3526(15.5981) | Bit/dim 3.9908(3.9688) | Xent 1.1031(1.1178) | Loss 10.7810(11.2456) | Error 0.4011(0.4028) Steps 628(598.04) | Grad Norm 22.7939(13.8743) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 15.7195(15.6689) | Bit/dim 3.9697(3.9672) | Xent 1.1139(1.1119) | Loss 10.7540(11.0869) | Error 0.4011(0.4009) Steps 616(599.56) | Grad Norm 19.9935(14.4247) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 15.6129(15.6983) | Bit/dim 3.9551(3.9658) | Xent 1.0785(1.1114) | Loss 10.5912(10.9789) | Error 0.4000(0.3998) Steps 598(601.50) | Grad Norm 5.9640(14.1591) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 15.7969(15.7014) | Bit/dim 3.9682(3.9619) | Xent 1.0510(1.0997) | Loss 10.6080(10.8813) | Error 0.3733(0.3948) Steps 598(604.23) | Grad Norm 9.0026(13.1253) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 15.3098(15.7895) | Bit/dim 3.9504(3.9587) | Xent 1.0158(1.0979) | Loss 10.5323(10.8085) | Error 0.3667(0.3940) Steps 610(605.39) | Grad Norm 10.3269(12.8052) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 85.0459, Epoch Time 972.7461(873.5391), Bit/dim 3.9395(best: 3.9658), Xent 1.0726, Loss 4.4758, Error 0.3818(best: 0.4007)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 16.1114(15.7432) | Bit/dim 3.9315(3.9585) | Xent 1.0372(1.0838) | Loss 10.5125(11.2937) | Error 0.3778(0.3892) Steps 610(606.21) | Grad Norm 8.5692(12.1342) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 15.7639(15.7468) | Bit/dim 3.9327(3.9537) | Xent 1.0764(1.0700) | Loss 10.4243(11.0905) | Error 0.3744(0.3824) Steps 622(601.18) | Grad Norm 11.8644(12.1781) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 15.6968(15.7621) | Bit/dim 3.9570(3.9502) | Xent 1.1322(1.0732) | Loss 10.6947(10.9532) | Error 0.4089(0.3845) Steps 586(601.66) | Grad Norm 13.4756(12.7337) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 14.7358(15.7382) | Bit/dim 3.9392(3.9504) | Xent 1.1131(1.0803) | Loss 10.4850(10.8705) | Error 0.4033(0.3860) Steps 586(600.52) | Grad Norm 10.2905(13.0350) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 16.0479(15.7055) | Bit/dim 3.9383(3.9454) | Xent 1.0900(1.0850) | Loss 10.7115(10.7979) | Error 0.3856(0.3881) Steps 628(601.34) | Grad Norm 19.4900(12.8073) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 85.6263, Epoch Time 968.0925(876.3757), Bit/dim 3.9351(best: 3.9395), Xent 1.0853, Loss 4.4778, Error 0.3835(best: 0.3818)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 16.2765(15.7477) | Bit/dim 3.9270(3.9424) | Xent 1.0584(1.0774) | Loss 10.5272(11.3928) | Error 0.3933(0.3857) Steps 634(603.52) | Grad Norm 19.3955(13.0255) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 15.9487(15.8172) | Bit/dim 3.9149(3.9392) | Xent 1.0713(1.0683) | Loss 10.3119(11.1512) | Error 0.3822(0.3820) Steps 610(602.59) | Grad Norm 11.2416(12.2405) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 15.3639(15.9253) | Bit/dim 3.9073(3.9362) | Xent 0.9853(1.0578) | Loss 10.4387(10.9964) | Error 0.3611(0.3770) Steps 604(608.55) | Grad Norm 8.6443(11.8000) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 15.7152(15.9325) | Bit/dim 3.9503(3.9368) | Xent 0.9975(1.0466) | Loss 10.4913(10.8721) | Error 0.3578(0.3746) Steps 622(608.98) | Grad Norm 13.3033(12.1276) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 15.4653(15.8432) | Bit/dim 3.9125(3.9319) | Xent 1.0512(1.0456) | Loss 10.4766(10.7699) | Error 0.3756(0.3756) Steps 592(605.08) | Grad Norm 10.2344(11.7410) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 15.1827(15.8073) | Bit/dim 3.9344(3.9270) | Xent 0.9746(1.0405) | Loss 10.3546(10.6836) | Error 0.3811(0.3730) Steps 586(603.40) | Grad Norm 12.3508(11.5877) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 85.3003, Epoch Time 980.8970(879.5113), Bit/dim 3.9236(best: 3.9351), Xent 1.0733, Loss 4.4602, Error 0.3856(best: 0.3818)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 15.8641(15.8522) | Bit/dim 3.9315(3.9295) | Xent 1.0195(1.0313) | Loss 10.4388(11.1855) | Error 0.3800(0.3711) Steps 616(603.17) | Grad Norm 13.0260(12.2557) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 14.9855(15.8820) | Bit/dim 3.9545(3.9304) | Xent 1.0092(1.0271) | Loss 10.5795(11.0063) | Error 0.3533(0.3693) Steps 610(604.23) | Grad Norm 16.6223(12.4374) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 15.8830(15.8259) | Bit/dim 3.9637(3.9299) | Xent 0.9912(1.0209) | Loss 10.3779(10.8573) | Error 0.3611(0.3676) Steps 598(602.81) | Grad Norm 18.8967(12.5403) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 16.0643(15.9092) | Bit/dim 3.8954(3.9246) | Xent 1.0761(1.0184) | Loss 10.5344(10.7388) | Error 0.3956(0.3663) Steps 592(605.99) | Grad Norm 8.2872(12.1623) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 15.5124(16.0007) | Bit/dim 3.8685(3.9170) | Xent 1.0445(1.0191) | Loss 10.3234(10.6697) | Error 0.3711(0.3665) Steps 598(607.74) | Grad Norm 15.6328(11.9624) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 84.2649, Epoch Time 985.5875(882.6936), Bit/dim 3.9140(best: 3.9236), Xent 1.0595, Loss 4.4437, Error 0.3779(best: 0.3818)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 16.3730(16.0365) | Bit/dim 3.9085(3.9131) | Xent 0.9926(1.0150) | Loss 10.4122(11.2456) | Error 0.3811(0.3658) Steps 580(606.35) | Grad Norm 14.8011(11.8910) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 16.3339(16.1217) | Bit/dim 3.9132(3.9113) | Xent 0.9722(1.0061) | Loss 10.4776(11.0288) | Error 0.3333(0.3626) Steps 628(608.33) | Grad Norm 8.7249(11.5453) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 16.4526(16.0908) | Bit/dim 3.9434(3.9110) | Xent 0.9103(0.9937) | Loss 10.3021(10.8619) | Error 0.3300(0.3586) Steps 604(608.78) | Grad Norm 9.7317(11.3998) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 16.6133(16.1323) | Bit/dim 3.9096(3.9106) | Xent 0.9791(0.9959) | Loss 10.3426(10.7512) | Error 0.3511(0.3564) Steps 574(611.92) | Grad Norm 11.2548(11.6634) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 15.6990(16.1545) | Bit/dim 3.8684(3.9061) | Xent 1.0011(0.9926) | Loss 10.4013(10.6626) | Error 0.3544(0.3542) Steps 592(611.08) | Grad Norm 7.0878(11.4912) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 15.3562(16.1022) | Bit/dim 3.9399(3.9054) | Xent 0.9959(0.9940) | Loss 10.5081(10.6032) | Error 0.3756(0.3554) Steps 604(609.87) | Grad Norm 23.2755(11.7936) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 84.0182, Epoch Time 993.2797(886.0112), Bit/dim 3.9086(best: 3.9140), Xent 1.0174, Loss 4.4173, Error 0.3637(best: 0.3779)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 16.2895(16.0759) | Bit/dim 3.9336(3.9024) | Xent 0.9593(0.9816) | Loss 10.4922(11.1044) | Error 0.3400(0.3511) Steps 628(613.32) | Grad Norm 13.9109(11.6529) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 17.7332(16.1076) | Bit/dim 3.8739(3.9017) | Xent 0.9507(0.9767) | Loss 10.3378(10.9254) | Error 0.3267(0.3484) Steps 592(613.41) | Grad Norm 10.1392(11.6019) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 15.0970(16.0678) | Bit/dim 3.8878(3.8981) | Xent 1.0277(0.9702) | Loss 10.2688(10.7799) | Error 0.3933(0.3475) Steps 592(615.62) | Grad Norm 20.1625(11.4737) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 16.8166(16.0860) | Bit/dim 3.8873(3.8972) | Xent 1.0845(0.9738) | Loss 10.4504(10.6764) | Error 0.3822(0.3492) Steps 610(615.81) | Grad Norm 10.6535(11.6767) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 15.8591(16.0942) | Bit/dim 3.8815(3.8953) | Xent 0.8976(0.9744) | Loss 10.2377(10.5960) | Error 0.3256(0.3508) Steps 616(614.02) | Grad Norm 10.8080(11.3027) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 84.5768, Epoch Time 989.6262(889.1197), Bit/dim 3.8837(best: 3.9086), Xent 0.9991, Loss 4.3833, Error 0.3533(best: 0.3637)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 15.8294(16.0767) | Bit/dim 3.9046(3.8942) | Xent 0.9071(0.9675) | Loss 10.3168(11.1893) | Error 0.3267(0.3478) Steps 622(612.94) | Grad Norm 7.4628(10.5921) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 16.9727(16.0918) | Bit/dim 3.8959(3.8904) | Xent 0.9044(0.9578) | Loss 10.2856(10.9592) | Error 0.3244(0.3440) Steps 610(612.71) | Grad Norm 12.8284(10.8479) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 16.5734(16.1509) | Bit/dim 3.8810(3.8881) | Xent 0.9677(0.9482) | Loss 10.2081(10.7848) | Error 0.3544(0.3414) Steps 574(611.48) | Grad Norm 17.6968(11.7251) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 16.0183(16.0838) | Bit/dim 3.9030(3.8901) | Xent 0.9867(0.9497) | Loss 10.3952(10.6691) | Error 0.3467(0.3416) Steps 616(612.08) | Grad Norm 14.6803(12.4959) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 16.5618(16.0829) | Bit/dim 3.8727(3.8879) | Xent 1.0019(0.9498) | Loss 10.3025(10.5878) | Error 0.3689(0.3410) Steps 550(609.88) | Grad Norm 16.9438(12.2885) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 16.3708(16.1432) | Bit/dim 3.8512(3.8839) | Xent 0.9980(0.9521) | Loss 10.4747(10.5254) | Error 0.3533(0.3409) Steps 628(612.36) | Grad Norm 11.9586(12.1849) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 86.0336, Epoch Time 992.9915(892.2358), Bit/dim 3.8791(best: 3.8837), Xent 0.9971, Loss 4.3776, Error 0.3508(best: 0.3533)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 17.0032(16.1619) | Bit/dim 3.8544(3.8811) | Xent 0.8912(0.9402) | Loss 10.1949(11.0526) | Error 0.3200(0.3371) Steps 646(613.82) | Grad Norm 9.5598(12.3666) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 16.6407(16.2202) | Bit/dim 3.8773(3.8819) | Xent 0.9288(0.9302) | Loss 10.3818(10.8491) | Error 0.3333(0.3346) Steps 640(614.24) | Grad Norm 11.1558(11.9582) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 16.5161(16.2464) | Bit/dim 3.8653(3.8788) | Xent 0.9433(0.9237) | Loss 10.3856(10.6921) | Error 0.3422(0.3329) Steps 628(612.30) | Grad Norm 16.2212(12.2720) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 15.6607(16.2821) | Bit/dim 3.8439(3.8807) | Xent 0.8692(0.9215) | Loss 10.0198(10.5869) | Error 0.3256(0.3334) Steps 598(615.65) | Grad Norm 10.8400(12.5080) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 15.1645(16.2882) | Bit/dim 3.8995(3.8798) | Xent 0.9355(0.9164) | Loss 10.3334(10.5188) | Error 0.3356(0.3305) Steps 604(615.42) | Grad Norm 8.2677(11.6281) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 86.4946, Epoch Time 1001.4781(895.5131), Bit/dim 3.8715(best: 3.8791), Xent 0.9768, Loss 4.3599, Error 0.3444(best: 0.3508)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 16.3271(16.1577) | Bit/dim 3.8764(3.8779) | Xent 0.7895(0.9070) | Loss 10.1372(11.0723) | Error 0.2878(0.3256) Steps 652(615.29) | Grad Norm 15.2518(11.4720) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 16.9341(16.2207) | Bit/dim 3.8472(3.8742) | Xent 0.9101(0.8977) | Loss 10.2874(10.8465) | Error 0.3178(0.3235) Steps 646(616.12) | Grad Norm 11.1072(11.4680) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 15.4885(16.2447) | Bit/dim 3.8773(3.8715) | Xent 0.8910(0.8955) | Loss 10.2600(10.6935) | Error 0.3300(0.3219) Steps 586(615.06) | Grad Norm 12.4691(11.8067) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 16.5125(16.2775) | Bit/dim 3.8734(3.8714) | Xent 0.9542(0.9037) | Loss 10.3073(10.5895) | Error 0.3456(0.3238) Steps 604(614.22) | Grad Norm 18.7437(12.6032) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 16.5916(16.2588) | Bit/dim 3.8542(3.8691) | Xent 0.8915(0.9073) | Loss 10.1367(10.4946) | Error 0.3211(0.3243) Steps 592(611.94) | Grad Norm 9.5617(13.3260) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 15.8742(16.2425) | Bit/dim 3.8723(3.8682) | Xent 0.9535(0.9125) | Loss 10.3439(10.4323) | Error 0.3456(0.3274) Steps 592(611.49) | Grad Norm 14.5004(13.3739) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 85.4164, Epoch Time 998.7215(898.6093), Bit/dim 3.8822(best: 3.8715), Xent 1.0784, Loss 4.4213, Error 0.3767(best: 0.3444)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 17.0301(16.2184) | Bit/dim 3.8299(3.8636) | Xent 0.8769(0.9065) | Loss 10.1383(10.9472) | Error 0.3144(0.3249) Steps 544(608.19) | Grad Norm 6.2369(12.7034) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 15.7663(16.2726) | Bit/dim 3.8374(3.8643) | Xent 0.9005(0.8954) | Loss 10.0696(10.7558) | Error 0.3344(0.3209) Steps 616(613.46) | Grad Norm 12.7621(12.1414) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 16.6010(16.2981) | Bit/dim 3.8533(3.8643) | Xent 0.8874(0.8913) | Loss 10.0850(10.6135) | Error 0.3111(0.3182) Steps 646(616.98) | Grad Norm 11.6194(11.7503) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 16.0797(16.2996) | Bit/dim 3.8727(3.8645) | Xent 0.8527(0.8828) | Loss 10.2502(10.5083) | Error 0.3056(0.3145) Steps 610(616.94) | Grad Norm 12.9747(11.8604) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 16.4029(16.2860) | Bit/dim 3.8620(3.8621) | Xent 0.9116(0.8810) | Loss 10.2309(10.4283) | Error 0.3300(0.3145) Steps 556(612.38) | Grad Norm 7.0418(11.3941) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 84.3910, Epoch Time 1000.7365(901.6731), Bit/dim 3.8506(best: 3.8715), Xent 0.9541, Loss 4.3276, Error 0.3345(best: 0.3444)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 16.0044(16.2349) | Bit/dim 3.8209(3.8577) | Xent 0.7947(0.8674) | Loss 10.0791(11.0079) | Error 0.2578(0.3092) Steps 616(613.45) | Grad Norm 11.2212(10.7498) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 16.2903(16.2017) | Bit/dim 3.8604(3.8564) | Xent 0.8312(0.8568) | Loss 10.1508(10.7786) | Error 0.3056(0.3064) Steps 604(611.51) | Grad Norm 7.8854(10.5962) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 15.8941(16.2201) | Bit/dim 3.8766(3.8551) | Xent 0.7568(0.8447) | Loss 10.1835(10.6173) | Error 0.2667(0.3021) Steps 592(613.12) | Grad Norm 6.6841(9.9949) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 17.1039(16.3158) | Bit/dim 3.8329(3.8509) | Xent 0.8424(0.8460) | Loss 10.2402(10.4975) | Error 0.2822(0.3021) Steps 664(616.37) | Grad Norm 9.2460(10.4093) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 16.4485(16.2809) | Bit/dim 3.8446(3.8487) | Xent 0.7852(0.8436) | Loss 10.1240(10.4011) | Error 0.2844(0.3009) Steps 610(615.32) | Grad Norm 8.8601(10.3952) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 15.7512(16.2020) | Bit/dim 3.8553(3.8475) | Xent 0.8063(0.8467) | Loss 10.0958(10.3275) | Error 0.2778(0.3013) Steps 604(614.34) | Grad Norm 9.6964(10.6559) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 84.4406, Epoch Time 994.8783(904.4693), Bit/dim 3.8403(best: 3.8506), Xent 0.9617, Loss 4.3212, Error 0.3391(best: 0.3345)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 15.7975(16.2003) | Bit/dim 3.8411(3.8467) | Xent 0.8210(0.8361) | Loss 10.1482(10.8239) | Error 0.2956(0.2969) Steps 610(612.46) | Grad Norm 10.4387(11.4362) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 16.1495(16.2143) | Bit/dim 3.8755(3.8482) | Xent 0.8114(0.8312) | Loss 10.1517(10.6496) | Error 0.2922(0.2953) Steps 580(612.43) | Grad Norm 10.4269(11.0142) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 16.7987(16.2632) | Bit/dim 3.8205(3.8433) | Xent 0.7579(0.8236) | Loss 10.0576(10.5016) | Error 0.2833(0.2933) Steps 664(616.71) | Grad Norm 6.8582(10.4630) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 15.7483(16.2735) | Bit/dim 3.8560(3.8447) | Xent 0.8304(0.8276) | Loss 10.1253(10.4060) | Error 0.2867(0.2963) Steps 610(615.42) | Grad Norm 11.2887(11.1372) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 16.3496(16.3010) | Bit/dim 3.8363(3.8450) | Xent 0.8212(0.8333) | Loss 10.0412(10.3400) | Error 0.3078(0.2999) Steps 586(615.17) | Grad Norm 8.4092(11.6446) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 87.0051, Epoch Time 1007.7024(907.5663), Bit/dim 3.8484(best: 3.8403), Xent 0.9595, Loss 4.3282, Error 0.3308(best: 0.3345)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 16.0428(16.3803) | Bit/dim 3.8578(3.8419) | Xent 0.8059(0.8354) | Loss 10.0729(10.9749) | Error 0.2711(0.3001) Steps 598(618.20) | Grad Norm 14.1039(11.5644) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 16.4391(16.4206) | Bit/dim 3.8378(3.8417) | Xent 0.7406(0.8282) | Loss 10.0532(10.7433) | Error 0.2756(0.2980) Steps 628(618.51) | Grad Norm 11.2765(11.9801) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 16.5946(16.3113) | Bit/dim 3.8588(3.8438) | Xent 0.7521(0.8214) | Loss 10.0822(10.5665) | Error 0.2689(0.2952) Steps 598(617.27) | Grad Norm 9.1983(12.1458) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 16.8079(16.3752) | Bit/dim 3.8285(3.8408) | Xent 0.6967(0.8176) | Loss 9.9344(10.4484) | Error 0.2589(0.2931) Steps 628(620.09) | Grad Norm 9.3471(11.4947) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 15.9759(16.3359) | Bit/dim 3.8357(3.8362) | Xent 0.7410(0.8083) | Loss 10.0174(10.3551) | Error 0.2567(0.2893) Steps 628(619.85) | Grad Norm 9.4561(11.3984) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 16.2894(16.3374) | Bit/dim 3.8461(3.8358) | Xent 0.8419(0.8071) | Loss 10.1600(10.2908) | Error 0.3067(0.2886) Steps 616(620.21) | Grad Norm 12.8393(11.0668) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 86.3989, Epoch Time 1003.8459(910.4547), Bit/dim 3.8374(best: 3.8403), Xent 0.9673, Loss 4.3210, Error 0.3314(best: 0.3308)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 15.9130(16.2782) | Bit/dim 3.8047(3.8348) | Xent 0.8101(0.7977) | Loss 10.0546(10.8236) | Error 0.2811(0.2867) Steps 574(619.10) | Grad Norm 13.3152(10.7911) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 15.8818(16.3312) | Bit/dim 3.8514(3.8323) | Xent 0.6976(0.7864) | Loss 9.8961(10.6071) | Error 0.2478(0.2819) Steps 604(619.54) | Grad Norm 11.5385(10.6456) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 17.1786(16.3957) | Bit/dim 3.8005(3.8289) | Xent 0.7033(0.7804) | Loss 9.9459(10.4637) | Error 0.2422(0.2796) Steps 628(620.22) | Grad Norm 7.3367(10.3179) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 16.5009(16.4176) | Bit/dim 3.8343(3.8331) | Xent 0.8162(0.7910) | Loss 10.0931(10.3821) | Error 0.3000(0.2829) Steps 622(620.09) | Grad Norm 8.9461(11.4749) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 16.4711(16.5250) | Bit/dim 3.8232(3.8289) | Xent 0.8409(0.7949) | Loss 10.1756(10.3105) | Error 0.3111(0.2843) Steps 640(623.07) | Grad Norm 12.5831(11.6705) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 86.6051, Epoch Time 1013.9157(913.5585), Bit/dim 3.8316(best: 3.8374), Xent 0.9762, Loss 4.3197, Error 0.3365(best: 0.3308)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 16.3902(16.5332) | Bit/dim 3.8419(3.8307) | Xent 0.7748(0.7950) | Loss 10.1877(10.9246) | Error 0.2756(0.2839) Steps 622(621.87) | Grad Norm 8.4469(11.4434) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 17.1366(16.5460) | Bit/dim 3.8222(3.8297) | Xent 0.7456(0.7809) | Loss 10.0545(10.6910) | Error 0.2589(0.2778) Steps 610(623.06) | Grad Norm 13.9476(10.9351) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 16.7876(16.5563) | Bit/dim 3.8158(3.8294) | Xent 0.7167(0.7699) | Loss 9.9869(10.5104) | Error 0.2722(0.2748) Steps 610(622.49) | Grad Norm 11.1172(11.2310) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 17.2999(16.6087) | Bit/dim 3.8340(3.8279) | Xent 0.7726(0.7677) | Loss 10.1867(10.4014) | Error 0.2800(0.2737) Steps 622(620.83) | Grad Norm 14.4837(11.1540) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 16.9389(16.6923) | Bit/dim 3.8217(3.8271) | Xent 0.7500(0.7610) | Loss 9.9423(10.3148) | Error 0.2700(0.2724) Steps 646(626.48) | Grad Norm 8.3107(10.8150) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 16.3922(16.6756) | Bit/dim 3.8216(3.8216) | Xent 0.7642(0.7670) | Loss 9.9570(10.2342) | Error 0.2644(0.2741) Steps 628(628.53) | Grad Norm 9.9095(10.5355) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 86.8851, Epoch Time 1024.7997(916.8957), Bit/dim 3.8276(best: 3.8316), Xent 0.9434, Loss 4.2993, Error 0.3290(best: 0.3308)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 16.9605(16.6458) | Bit/dim 3.8685(3.8200) | Xent 0.8243(0.7594) | Loss 10.2220(10.7461) | Error 0.3022(0.2706) Steps 634(627.63) | Grad Norm 23.9745(11.2724) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 17.2834(16.6150) | Bit/dim 3.8486(3.8269) | Xent 0.7597(0.7768) | Loss 10.0728(10.5880) | Error 0.2711(0.2769) Steps 658(627.08) | Grad Norm 15.0112(12.7265) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 16.5145(16.6251) | Bit/dim 3.7968(3.8263) | Xent 0.7552(0.7698) | Loss 10.0022(10.4330) | Error 0.2800(0.2749) Steps 634(623.71) | Grad Norm 10.4204(12.9599) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 15.9801(16.6030) | Bit/dim 3.8303(3.8252) | Xent 0.6925(0.7622) | Loss 9.9939(10.3228) | Error 0.2511(0.2738) Steps 622(626.71) | Grad Norm 12.6564(12.2504) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 15.9897(16.5883) | Bit/dim 3.8187(3.8197) | Xent 0.6686(0.7548) | Loss 9.8117(10.2151) | Error 0.2556(0.2710) Steps 640(626.00) | Grad Norm 8.2021(11.7085) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 86.8138, Epoch Time 1019.0720(919.9610), Bit/dim 3.8272(best: 3.8276), Xent 0.9245, Loss 4.2894, Error 0.3211(best: 0.3290)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 16.4883(16.5961) | Bit/dim 3.8218(3.8195) | Xent 0.6423(0.7433) | Loss 9.7233(10.8288) | Error 0.2244(0.2659) Steps 598(623.38) | Grad Norm 13.9252(11.4615) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 17.4413(16.6232) | Bit/dim 3.8290(3.8205) | Xent 0.7638(0.7352) | Loss 10.0968(10.6131) | Error 0.2733(0.2627) Steps 664(624.33) | Grad Norm 10.3905(11.2766) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 17.6906(16.6329) | Bit/dim 3.8054(3.8194) | Xent 0.7102(0.7414) | Loss 10.0768(10.4698) | Error 0.2522(0.2655) Steps 676(628.03) | Grad Norm 16.3107(11.7460) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 17.2918(16.6447) | Bit/dim 3.8084(3.8171) | Xent 0.7406(0.7409) | Loss 10.0728(10.3433) | Error 0.2667(0.2644) Steps 604(624.71) | Grad Norm 10.3337(12.3935) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 16.5339(16.6941) | Bit/dim 3.7637(3.8159) | Xent 0.6993(0.7308) | Loss 9.7920(10.2374) | Error 0.2644(0.2605) Steps 616(623.96) | Grad Norm 8.1276(11.3766) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 16.4076(16.6915) | Bit/dim 3.7978(3.8132) | Xent 0.7041(0.7248) | Loss 9.8941(10.1602) | Error 0.2533(0.2593) Steps 640(626.21) | Grad Norm 10.3302(10.9748) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 87.4770, Epoch Time 1026.3819(923.1537), Bit/dim 3.8052(best: 3.8272), Xent 0.9498, Loss 4.2801, Error 0.3288(best: 0.3211)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 16.7659(16.6904) | Bit/dim 3.8428(3.8134) | Xent 0.5761(0.7074) | Loss 9.7764(10.6673) | Error 0.1978(0.2535) Steps 646(628.21) | Grad Norm 5.9161(10.7448) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 17.3950(16.7059) | Bit/dim 3.7847(3.8099) | Xent 0.7832(0.7067) | Loss 10.0672(10.4787) | Error 0.2833(0.2534) Steps 622(629.53) | Grad Norm 28.1004(11.3973) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 16.8430(16.6781) | Bit/dim 3.8272(3.8110) | Xent 0.7157(0.7061) | Loss 9.8603(10.3350) | Error 0.2711(0.2527) Steps 646(630.04) | Grad Norm 7.7696(11.9235) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 16.2139(16.7357) | Bit/dim 3.8214(3.8103) | Xent 0.7479(0.7047) | Loss 10.1123(10.2478) | Error 0.2622(0.2520) Steps 634(631.31) | Grad Norm 10.3586(12.1921) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 18.4092(16.7916) | Bit/dim 3.7850(3.8085) | Xent 0.7050(0.7073) | Loss 9.9940(10.1863) | Error 0.2522(0.2538) Steps 688(633.71) | Grad Norm 9.5329(11.9395) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 87.9166, Epoch Time 1032.0033(926.4191), Bit/dim 3.8044(best: 3.8052), Xent 0.9281, Loss 4.2684, Error 0.3152(best: 0.3211)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 16.6432(16.7426) | Bit/dim 3.8073(3.8068) | Xent 0.5678(0.6918) | Loss 9.8229(10.8025) | Error 0.1844(0.2482) Steps 652(633.74) | Grad Norm 8.7481(11.4744) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 16.3503(16.6888) | Bit/dim 3.7846(3.8046) | Xent 0.6122(0.6771) | Loss 9.6486(10.5543) | Error 0.2111(0.2426) Steps 628(632.90) | Grad Norm 7.1427(11.3170) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 16.3366(16.7706) | Bit/dim 3.7867(3.8019) | Xent 0.6085(0.6781) | Loss 9.8764(10.3907) | Error 0.2178(0.2420) Steps 658(634.78) | Grad Norm 7.4237(11.0539) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 17.6595(16.8490) | Bit/dim 3.7805(3.8016) | Xent 0.7240(0.6714) | Loss 9.8101(10.2555) | Error 0.2467(0.2395) Steps 598(629.85) | Grad Norm 9.0953(10.7675) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 16.3039(16.9036) | Bit/dim 3.7984(3.8012) | Xent 0.6376(0.6696) | Loss 9.9945(10.1785) | Error 0.2222(0.2395) Steps 652(633.68) | Grad Norm 9.4485(10.1294) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 16.6246(16.8590) | Bit/dim 3.8066(3.8031) | Xent 0.6848(0.6746) | Loss 9.9281(10.1178) | Error 0.2456(0.2406) Steps 640(636.57) | Grad Norm 8.5410(11.1340) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 88.9438, Epoch Time 1034.5373(929.6627), Bit/dim 3.8092(best: 3.8044), Xent 0.9611, Loss 4.2897, Error 0.3294(best: 0.3152)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 16.6713(16.7983) | Bit/dim 3.7997(3.8036) | Xent 0.6277(0.6754) | Loss 9.9075(10.6560) | Error 0.2133(0.2406) Steps 646(636.92) | Grad Norm 12.4159(11.7276) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 16.4694(16.7847) | Bit/dim 3.8185(3.8048) | Xent 0.6162(0.6690) | Loss 9.9256(10.4661) | Error 0.2244(0.2398) Steps 616(634.87) | Grad Norm 9.6799(11.5259) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 17.0756(16.8405) | Bit/dim 3.8110(3.8026) | Xent 0.6079(0.6634) | Loss 9.7978(10.3059) | Error 0.2244(0.2378) Steps 622(631.20) | Grad Norm 6.7838(10.8489) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 17.2108(16.8626) | Bit/dim 3.7881(3.8018) | Xent 0.6574(0.6604) | Loss 9.7136(10.1916) | Error 0.2389(0.2372) Steps 658(631.07) | Grad Norm 11.1678(11.2426) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 17.7571(16.8792) | Bit/dim 3.7904(3.8005) | Xent 0.6420(0.6606) | Loss 9.9993(10.1273) | Error 0.2322(0.2358) Steps 676(633.15) | Grad Norm 6.7577(10.6884) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 89.1842, Epoch Time 1037.0556(932.8845), Bit/dim 3.8062(best: 3.8044), Xent 0.9724, Loss 4.2924, Error 0.3305(best: 0.3152)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 16.2613(16.9105) | Bit/dim 3.8053(3.8019) | Xent 0.6502(0.6548) | Loss 9.9350(10.7621) | Error 0.2289(0.2344) Steps 646(637.49) | Grad Norm 7.0491(11.2531) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 17.0202(16.8719) | Bit/dim 3.8168(3.8013) | Xent 0.6408(0.6424) | Loss 9.9387(10.5138) | Error 0.2356(0.2296) Steps 646(635.85) | Grad Norm 16.3379(11.4717) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 16.4428(16.8647) | Bit/dim 3.7850(3.7999) | Xent 0.6099(0.6421) | Loss 9.7917(10.3334) | Error 0.2289(0.2302) Steps 640(635.19) | Grad Norm 7.7616(11.6347) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 16.4135(16.7888) | Bit/dim 3.7690(3.7994) | Xent 0.5990(0.6417) | Loss 9.7431(10.2060) | Error 0.2089(0.2298) Steps 664(635.88) | Grad Norm 12.9782(11.5538) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 16.7757(16.8071) | Bit/dim 3.8177(3.7990) | Xent 0.6096(0.6377) | Loss 9.8548(10.1153) | Error 0.2189(0.2284) Steps 652(638.85) | Grad Norm 9.1677(11.4923) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 16.6342(16.7767) | Bit/dim 3.8162(3.7974) | Xent 0.5874(0.6319) | Loss 9.8508(10.0450) | Error 0.2111(0.2263) Steps 634(637.20) | Grad Norm 7.0609(10.8389) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 88.9553, Epoch Time 1032.3821(935.8694), Bit/dim 3.7962(best: 3.8044), Xent 0.9998, Loss 4.2961, Error 0.3330(best: 0.3152)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 17.1936(16.7513) | Bit/dim 3.7911(3.7948) | Xent 0.5826(0.6208) | Loss 9.8910(10.5642) | Error 0.2033(0.2226) Steps 688(636.58) | Grad Norm 8.7111(10.6117) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 17.5044(16.8293) | Bit/dim 3.7763(3.7910) | Xent 0.6584(0.6166) | Loss 9.8801(10.3734) | Error 0.2311(0.2206) Steps 652(640.52) | Grad Norm 10.5431(10.4319) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 17.2029(16.8206) | Bit/dim 3.7565(3.7882) | Xent 0.5814(0.6160) | Loss 9.7765(10.2305) | Error 0.2156(0.2203) Steps 634(641.08) | Grad Norm 8.4601(10.8445) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 16.5276(16.7423) | Bit/dim 3.7666(3.7904) | Xent 0.5916(0.6116) | Loss 9.7692(10.1201) | Error 0.2044(0.2190) Steps 616(637.40) | Grad Norm 9.7077(10.5526) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 16.6185(16.8094) | Bit/dim 3.7843(3.7892) | Xent 0.6419(0.6160) | Loss 9.7736(10.0436) | Error 0.2289(0.2197) Steps 610(637.08) | Grad Norm 10.5036(10.7109) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 87.5291, Epoch Time 1032.7563(938.7760), Bit/dim 3.7887(best: 3.7962), Xent 1.0083, Loss 4.2929, Error 0.3257(best: 0.3152)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 17.5408(16.8603) | Bit/dim 3.8239(3.7917) | Xent 0.5579(0.6084) | Loss 9.8883(10.6956) | Error 0.1911(0.2168) Steps 664(639.10) | Grad Norm 7.8209(10.1432) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 15.8136(16.7855) | Bit/dim 3.7985(3.7865) | Xent 0.6010(0.5919) | Loss 9.6668(10.4336) | Error 0.2089(0.2117) Steps 640(635.43) | Grad Norm 7.4430(10.0701) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 16.8004(16.8020) | Bit/dim 3.7754(3.7841) | Xent 0.6047(0.5967) | Loss 9.8841(10.2657) | Error 0.2178(0.2119) Steps 634(635.52) | Grad Norm 10.2676(10.0627) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 16.4474(16.8418) | Bit/dim 3.7929(3.7849) | Xent 0.5832(0.5953) | Loss 9.7920(10.1481) | Error 0.2056(0.2109) Steps 640(637.53) | Grad Norm 18.6482(10.8944) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 17.2354(16.8619) | Bit/dim 3.7829(3.7864) | Xent 0.6548(0.6040) | Loss 9.8333(10.0663) | Error 0.2178(0.2145) Steps 640(638.08) | Grad Norm 13.4384(11.4402) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 17.3701(16.8837) | Bit/dim 3.7763(3.7865) | Xent 0.6354(0.6001) | Loss 9.8870(9.9963) | Error 0.2133(0.2126) Steps 646(635.65) | Grad Norm 21.1628(11.4797) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 89.0176, Epoch Time 1036.7435(941.7150), Bit/dim 3.7869(best: 3.7887), Xent 0.9660, Loss 4.2699, Error 0.3199(best: 0.3152)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 17.1703(16.8852) | Bit/dim 3.7639(3.7828) | Xent 0.5353(0.5927) | Loss 9.8153(10.5222) | Error 0.1956(0.2112) Steps 646(635.68) | Grad Norm 9.1026(11.8389) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 16.9694(16.8477) | Bit/dim 3.7817(3.7828) | Xent 0.6074(0.5745) | Loss 9.8723(10.3094) | Error 0.2133(0.2057) Steps 652(638.39) | Grad Norm 16.6496(11.3387) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 16.7861(16.8507) | Bit/dim 3.7933(3.7843) | Xent 0.4888(0.5698) | Loss 9.7109(10.1684) | Error 0.1667(0.2033) Steps 634(638.51) | Grad Norm 12.0419(11.2706) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 17.2072(16.8982) | Bit/dim 3.7769(3.7800) | Xent 0.5657(0.5647) | Loss 9.7365(10.0476) | Error 0.2089(0.2020) Steps 610(636.85) | Grad Norm 11.8824(10.9752) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 17.0916(16.9130) | Bit/dim 3.7326(3.7791) | Xent 0.4878(0.5675) | Loss 9.5241(9.9629) | Error 0.1600(0.2024) Steps 646(636.24) | Grad Norm 12.4497(11.2581) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 89.1053, Epoch Time 1041.5319(944.7095), Bit/dim 3.7853(best: 3.7869), Xent 0.9710, Loss 4.2708, Error 0.3122(best: 0.3152)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 17.4976(16.9908) | Bit/dim 3.7355(3.7793) | Xent 0.5446(0.5652) | Loss 9.7688(10.5929) | Error 0.1989(0.2014) Steps 676(639.77) | Grad Norm 9.9690(11.0267) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 17.6188(17.0265) | Bit/dim 3.7744(3.7811) | Xent 0.5056(0.5549) | Loss 9.6231(10.3683) | Error 0.1789(0.1985) Steps 640(641.53) | Grad Norm 11.2802(11.1491) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 17.1900(17.1042) | Bit/dim 3.7709(3.7796) | Xent 0.5501(0.5465) | Loss 9.7294(10.2022) | Error 0.1900(0.1941) Steps 646(643.31) | Grad Norm 8.4024(10.9147) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 16.9175(17.0907) | Bit/dim 3.7747(3.7783) | Xent 0.5157(0.5415) | Loss 9.6807(10.0587) | Error 0.1700(0.1927) Steps 658(642.43) | Grad Norm 7.2689(10.0742) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 17.4894(17.1111) | Bit/dim 3.7614(3.7775) | Xent 0.6492(0.5463) | Loss 9.8457(9.9680) | Error 0.2078(0.1938) Steps 664(642.24) | Grad Norm 13.8398(10.3564) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 17.3363(17.0540) | Bit/dim 3.7840(3.7763) | Xent 0.5698(0.5529) | Loss 9.7974(9.9113) | Error 0.2100(0.1970) Steps 646(641.41) | Grad Norm 14.0861(10.8373) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 89.6145, Epoch Time 1051.0315(947.8992), Bit/dim 3.7723(best: 3.7853), Xent 0.9777, Loss 4.2612, Error 0.3174(best: 0.3122)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 17.9881(17.1066) | Bit/dim 3.7866(3.7773) | Xent 0.5516(0.5411) | Loss 9.7366(10.4323) | Error 0.1889(0.1927) Steps 634(641.59) | Grad Norm 16.6931(10.7816) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 17.8258(17.0792) | Bit/dim 3.7851(3.7753) | Xent 0.5677(0.5343) | Loss 9.8426(10.2440) | Error 0.1978(0.1893) Steps 628(639.76) | Grad Norm 9.5325(9.9657) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 16.7878(17.0895) | Bit/dim 3.7491(3.7717) | Xent 0.5424(0.5276) | Loss 9.6500(10.0955) | Error 0.1900(0.1872) Steps 622(641.02) | Grad Norm 11.5921(9.7499) | Total Time 0.00(0.00)\n",
      "Iter 3010 | Time 17.2586(17.0894) | Bit/dim 3.7642(3.7714) | Xent 0.5204(0.5254) | Loss 9.6454(9.9813) | Error 0.1733(0.1866) Steps 658(643.30) | Grad Norm 10.4032(10.1031) | Total Time 0.00(0.00)\n",
      "Iter 3020 | Time 17.2574(17.0315) | Bit/dim 3.7938(3.7700) | Xent 0.5584(0.5245) | Loss 9.8991(9.9157) | Error 0.2011(0.1852) Steps 670(643.80) | Grad Norm 13.4229(10.3762) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 88.8543, Epoch Time 1046.3289(950.8521), Bit/dim 3.7787(best: 3.7723), Xent 1.0103, Loss 4.2839, Error 0.3243(best: 0.3122)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 17.4597(17.0165) | Bit/dim 3.7953(3.7719) | Xent 0.5138(0.5307) | Loss 9.7562(10.5546) | Error 0.1822(0.1871) Steps 634(645.16) | Grad Norm 12.0464(10.7743) | Total Time 0.00(0.00)\n",
      "Iter 3040 | Time 16.4777(17.0254) | Bit/dim 3.7963(3.7752) | Xent 0.5483(0.5294) | Loss 9.7307(10.3430) | Error 0.1856(0.1866) Steps 634(644.10) | Grad Norm 10.6040(11.0173) | Total Time 0.00(0.00)\n",
      "Iter 3050 | Time 17.3838(16.9915) | Bit/dim 3.7599(3.7720) | Xent 0.5905(0.5271) | Loss 9.8154(10.1674) | Error 0.2200(0.1867) Steps 658(643.55) | Grad Norm 17.8043(11.3023) | Total Time 0.00(0.00)\n",
      "Iter 3060 | Time 17.1713(16.9419) | Bit/dim 3.8097(3.7721) | Xent 0.4605(0.5226) | Loss 9.6682(10.0309) | Error 0.1689(0.1856) Steps 622(640.56) | Grad Norm 7.2357(11.0735) | Total Time 0.00(0.00)\n",
      "Iter 3070 | Time 16.6995(16.8983) | Bit/dim 3.7427(3.7690) | Xent 0.5155(0.5167) | Loss 9.6451(9.9357) | Error 0.1778(0.1831) Steps 634(640.97) | Grad Norm 7.4946(10.3752) | Total Time 0.00(0.00)\n",
      "Iter 3080 | Time 17.4622(16.9502) | Bit/dim 3.7427(3.7688) | Xent 0.5470(0.5098) | Loss 9.5841(9.8664) | Error 0.1933(0.1809) Steps 640(642.40) | Grad Norm 10.6523(10.8263) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 88.4944, Epoch Time 1041.5674(953.5736), Bit/dim 3.7686(best: 3.7723), Xent 1.0049, Loss 4.2710, Error 0.3145(best: 0.3122)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 16.4707(16.9258) | Bit/dim 3.7592(3.7706) | Xent 0.4185(0.5004) | Loss 9.5360(10.3975) | Error 0.1544(0.1773) Steps 604(640.66) | Grad Norm 11.0761(10.8479) | Total Time 0.00(0.00)\n",
      "Iter 3100 | Time 16.5709(16.9605) | Bit/dim 3.7756(3.7689) | Xent 0.4696(0.4908) | Loss 9.6705(10.1955) | Error 0.1611(0.1741) Steps 658(639.64) | Grad Norm 12.8804(10.8643) | Total Time 0.00(0.00)\n",
      "Iter 3110 | Time 17.2540(17.0080) | Bit/dim 3.7776(3.7671) | Xent 0.4498(0.4812) | Loss 9.7140(10.0405) | Error 0.1767(0.1719) Steps 622(637.67) | Grad Norm 8.5245(10.3087) | Total Time 0.00(0.00)\n",
      "Iter 3120 | Time 16.3625(16.9865) | Bit/dim 3.7576(3.7677) | Xent 0.4986(0.4849) | Loss 9.6452(9.9331) | Error 0.1878(0.1741) Steps 640(638.39) | Grad Norm 10.7510(10.7738) | Total Time 0.00(0.00)\n",
      "Iter 3130 | Time 18.2219(17.0008) | Bit/dim 3.7450(3.7685) | Xent 0.5675(0.4930) | Loss 9.7269(9.8666) | Error 0.1967(0.1760) Steps 688(641.74) | Grad Norm 9.2031(11.1045) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 88.4732, Epoch Time 1044.5386(956.3025), Bit/dim 3.7688(best: 3.7686), Xent 1.0170, Loss 4.2773, Error 0.3148(best: 0.3122)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 16.8735(17.0130) | Bit/dim 3.8034(3.7677) | Xent 0.4051(0.4846) | Loss 9.5759(10.4643) | Error 0.1300(0.1727) Steps 634(643.67) | Grad Norm 11.1825(11.0183) | Total Time 0.00(0.00)\n",
      "Iter 3150 | Time 17.2756(17.0490) | Bit/dim 3.7732(3.7641) | Xent 0.4642(0.4695) | Loss 9.6211(10.2305) | Error 0.1644(0.1668) Steps 670(644.34) | Grad Norm 6.5162(10.3642) | Total Time 0.00(0.00)\n",
      "Iter 3160 | Time 17.1339(17.0280) | Bit/dim 3.7470(3.7625) | Xent 0.5267(0.4700) | Loss 9.6738(10.0770) | Error 0.1922(0.1671) Steps 646(644.95) | Grad Norm 16.5957(10.4809) | Total Time 0.00(0.00)\n",
      "Iter 3170 | Time 17.1611(17.0952) | Bit/dim 3.7925(3.7650) | Xent 0.4490(0.4686) | Loss 9.5793(9.9551) | Error 0.1600(0.1660) Steps 628(644.24) | Grad Norm 13.0961(10.8530) | Total Time 0.00(0.00)\n",
      "Iter 3180 | Time 17.2861(17.0272) | Bit/dim 3.7681(3.7615) | Xent 0.4690(0.4653) | Loss 9.6230(9.8637) | Error 0.1667(0.1655) Steps 664(645.66) | Grad Norm 10.1866(10.4220) | Total Time 0.00(0.00)\n",
      "Iter 3190 | Time 16.6840(17.0493) | Bit/dim 3.7650(3.7640) | Xent 0.4068(0.4642) | Loss 9.6023(9.8090) | Error 0.1500(0.1654) Steps 628(644.57) | Grad Norm 7.9258(10.3419) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 89.0136, Epoch Time 1047.4861(959.0380), Bit/dim 3.7645(best: 3.7686), Xent 1.0457, Loss 4.2873, Error 0.3075(best: 0.3122)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 17.5710(17.0390) | Bit/dim 3.7775(3.7630) | Xent 0.4064(0.4505) | Loss 9.5278(10.3528) | Error 0.1422(0.1602) Steps 664(645.78) | Grad Norm 8.9923(10.0018) | Total Time 0.00(0.00)\n",
      "Iter 3210 | Time 17.0983(17.0983) | Bit/dim 3.7609(3.7607) | Xent 0.4369(0.4415) | Loss 9.6294(10.1510) | Error 0.1500(0.1567) Steps 640(648.22) | Grad Norm 13.0597(9.8032) | Total Time 0.00(0.00)\n",
      "Iter 3220 | Time 16.8039(17.1304) | Bit/dim 3.7485(3.7612) | Xent 0.4762(0.4449) | Loss 9.6242(10.0217) | Error 0.1678(0.1590) Steps 646(648.27) | Grad Norm 9.5476(10.2136) | Total Time 0.00(0.00)\n",
      "Iter 3230 | Time 17.0618(17.1723) | Bit/dim 3.7520(3.7591) | Xent 0.5151(0.4475) | Loss 9.6255(9.9104) | Error 0.1767(0.1596) Steps 640(648.70) | Grad Norm 18.7966(10.5085) | Total Time 0.00(0.00)\n",
      "Iter 3240 | Time 17.4042(17.1941) | Bit/dim 3.7541(3.7581) | Xent 0.4142(0.4469) | Loss 9.6985(9.8345) | Error 0.1333(0.1590) Steps 688(649.07) | Grad Norm 9.6506(10.6120) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 87.8739, Epoch Time 1052.2296(961.8338), Bit/dim 3.7718(best: 3.7645), Xent 1.1153, Loss 4.3294, Error 0.3451(best: 0.3075)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 17.3252(17.1475) | Bit/dim 3.7319(3.7576) | Xent 0.4387(0.4511) | Loss 9.5057(10.4686) | Error 0.1467(0.1594) Steps 598(646.64) | Grad Norm 14.6242(10.7610) | Total Time 0.00(0.00)\n",
      "Iter 3260 | Time 17.3117(17.1527) | Bit/dim 3.7456(3.7596) | Xent 0.3780(0.4388) | Loss 9.4182(10.2351) | Error 0.1356(0.1545) Steps 622(647.28) | Grad Norm 8.4618(10.5704) | Total Time 0.00(0.00)\n",
      "Iter 3270 | Time 17.7866(17.2031) | Bit/dim 3.7587(3.7591) | Xent 0.3636(0.4276) | Loss 9.5196(10.0470) | Error 0.1233(0.1496) Steps 676(648.37) | Grad Norm 5.1574(10.2403) | Total Time 0.00(0.00)\n",
      "Iter 3280 | Time 16.9460(17.1541) | Bit/dim 3.7307(3.7546) | Xent 0.4199(0.4300) | Loss 9.5183(9.9197) | Error 0.1611(0.1507) Steps 652(649.34) | Grad Norm 9.5431(10.7645) | Total Time 0.00(0.00)\n",
      "Iter 3290 | Time 17.3795(17.0911) | Bit/dim 3.7374(3.7546) | Xent 0.4689(0.4348) | Loss 9.6294(9.8261) | Error 0.1633(0.1532) Steps 646(648.14) | Grad Norm 10.3692(10.8000) | Total Time 0.00(0.00)\n",
      "Iter 3300 | Time 17.7607(17.1291) | Bit/dim 3.7609(3.7567) | Xent 0.4797(0.4392) | Loss 9.5407(9.7528) | Error 0.1733(0.1552) Steps 658(646.18) | Grad Norm 11.4480(11.0953) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 88.1617, Epoch Time 1050.9292(964.5066), Bit/dim 3.7723(best: 3.7645), Xent 1.0474, Loss 4.2960, Error 0.3112(best: 0.3075)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 16.2366(17.0811) | Bit/dim 3.7372(3.7580) | Xent 0.4379(0.4304) | Loss 9.5850(10.2776) | Error 0.1522(0.1528) Steps 646(647.79) | Grad Norm 13.7981(11.5476) | Total Time 0.00(0.00)\n",
      "Iter 3320 | Time 16.7866(17.0699) | Bit/dim 3.7673(3.7589) | Xent 0.4142(0.4229) | Loss 9.4953(10.0718) | Error 0.1478(0.1503) Steps 634(646.14) | Grad Norm 6.5497(11.1019) | Total Time 0.00(0.00)\n",
      "Iter 3330 | Time 17.4881(17.1273) | Bit/dim 3.7613(3.7586) | Xent 0.3389(0.4169) | Loss 9.4852(9.9309) | Error 0.1211(0.1480) Steps 634(645.91) | Grad Norm 10.3796(11.1591) | Total Time 0.00(0.00)\n",
      "Iter 3340 | Time 17.5997(17.1411) | Bit/dim 3.7323(3.7555) | Xent 0.4420(0.4067) | Loss 9.5214(9.8230) | Error 0.1567(0.1439) Steps 658(648.11) | Grad Norm 10.9904(10.3172) | Total Time 0.00(0.00)\n",
      "Iter 3350 | Time 16.7727(17.1024) | Bit/dim 3.7311(3.7540) | Xent 0.4906(0.4070) | Loss 9.4647(9.7423) | Error 0.1756(0.1444) Steps 628(646.74) | Grad Norm 12.9197(10.3938) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 89.0384, Epoch Time 1049.0957(967.0443), Bit/dim 3.7574(best: 3.7645), Xent 1.0381, Loss 4.2764, Error 0.3065(best: 0.3075)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 17.0533(17.0950) | Bit/dim 3.7560(3.7550) | Xent 0.3668(0.4058) | Loss 9.4510(10.3872) | Error 0.1356(0.1439) Steps 622(644.64) | Grad Norm 9.4240(10.2341) | Total Time 0.00(0.00)\n",
      "Iter 3370 | Time 17.1084(17.0524) | Bit/dim 3.7455(3.7543) | Xent 0.3254(0.3909) | Loss 9.5839(10.1487) | Error 0.1244(0.1387) Steps 664(647.84) | Grad Norm 9.2939(10.0762) | Total Time 0.00(0.00)\n",
      "Iter 3380 | Time 17.6339(17.0641) | Bit/dim 3.7704(3.7527) | Xent 0.4074(0.3908) | Loss 9.6283(9.9835) | Error 0.1444(0.1385) Steps 676(649.55) | Grad Norm 9.0243(10.4569) | Total Time 0.00(0.00)\n",
      "Iter 3390 | Time 16.6411(17.1527) | Bit/dim 3.7773(3.7513) | Xent 0.3441(0.3850) | Loss 9.5487(9.8585) | Error 0.1189(0.1361) Steps 634(651.77) | Grad Norm 10.6479(9.9632) | Total Time 0.00(0.00)\n",
      "Iter 3400 | Time 17.5369(17.1951) | Bit/dim 3.7982(3.7492) | Xent 0.4619(0.3872) | Loss 9.6504(9.7711) | Error 0.1456(0.1363) Steps 610(651.27) | Grad Norm 18.8252(10.7350) | Total Time 0.00(0.00)\n",
      "Iter 3410 | Time 17.0210(17.1797) | Bit/dim 3.7387(3.7521) | Xent 0.4295(0.3985) | Loss 9.4961(9.7274) | Error 0.1578(0.1406) Steps 622(652.29) | Grad Norm 7.9540(11.5198) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 88.1599, Epoch Time 1052.3472(969.6034), Bit/dim 3.7591(best: 3.7574), Xent 1.1434, Loss 4.3308, Error 0.3190(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 16.5383(17.1112) | Bit/dim 3.7581(3.7512) | Xent 0.3736(0.3919) | Loss 9.4665(10.2785) | Error 0.1300(0.1382) Steps 652(653.29) | Grad Norm 9.4201(11.0867) | Total Time 0.00(0.00)\n",
      "Iter 3430 | Time 16.9575(17.1060) | Bit/dim 3.7842(3.7533) | Xent 0.3661(0.3885) | Loss 9.6199(10.0792) | Error 0.1111(0.1366) Steps 634(652.47) | Grad Norm 11.5310(11.1196) | Total Time 0.00(0.00)\n",
      "Iter 3440 | Time 17.5276(17.1677) | Bit/dim 3.7635(3.7537) | Xent 0.4829(0.3854) | Loss 9.7557(9.9393) | Error 0.1711(0.1352) Steps 676(653.66) | Grad Norm 26.2906(11.4717) | Total Time 0.00(0.00)\n",
      "Iter 3450 | Time 16.7429(17.1734) | Bit/dim 3.7257(3.7512) | Xent 0.4127(0.3943) | Loss 9.5700(9.8463) | Error 0.1411(0.1379) Steps 652(652.40) | Grad Norm 11.2540(11.6145) | Total Time 0.00(0.00)\n",
      "Iter 3460 | Time 17.5116(17.1755) | Bit/dim 3.7598(3.7517) | Xent 0.4586(0.3951) | Loss 9.5839(9.7667) | Error 0.1622(0.1387) Steps 682(655.32) | Grad Norm 17.2549(11.3036) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 89.6322, Epoch Time 1054.2661(972.1433), Bit/dim 3.7561(best: 3.7574), Xent 1.1652, Loss 4.3387, Error 0.3373(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 16.9346(17.1613) | Bit/dim 3.7365(3.7506) | Xent 0.3410(0.3908) | Loss 9.4208(10.3935) | Error 0.1256(0.1382) Steps 634(655.92) | Grad Norm 6.9160(11.3745) | Total Time 0.00(0.00)\n",
      "Iter 3480 | Time 16.9486(17.1173) | Bit/dim 3.7542(3.7495) | Xent 0.3230(0.3781) | Loss 9.4131(10.1564) | Error 0.1078(0.1335) Steps 646(653.84) | Grad Norm 18.6143(11.6129) | Total Time 0.00(0.00)\n",
      "Iter 3490 | Time 16.7645(17.1777) | Bit/dim 3.7265(3.7467) | Xent 0.3549(0.3684) | Loss 9.4134(9.9786) | Error 0.1256(0.1292) Steps 646(652.28) | Grad Norm 9.5213(11.1431) | Total Time 0.00(0.00)\n",
      "Iter 3500 | Time 16.9128(17.1662) | Bit/dim 3.7601(3.7447) | Xent 0.3555(0.3620) | Loss 9.4992(9.8533) | Error 0.1233(0.1270) Steps 622(653.12) | Grad Norm 12.8795(10.4749) | Total Time 0.00(0.00)\n",
      "Iter 3510 | Time 16.8058(17.2030) | Bit/dim 3.7613(3.7456) | Xent 0.3817(0.3660) | Loss 9.4924(9.7595) | Error 0.1233(0.1281) Steps 634(652.07) | Grad Norm 6.8778(10.3180) | Total Time 0.00(0.00)\n",
      "Iter 3520 | Time 16.1364(17.1743) | Bit/dim 3.7536(3.7466) | Xent 0.3553(0.3701) | Loss 9.4683(9.6923) | Error 0.1278(0.1302) Steps 634(650.32) | Grad Norm 10.4729(10.5913) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 88.9700, Epoch Time 1052.4424(974.5522), Bit/dim 3.7562(best: 3.7561), Xent 1.1245, Loss 4.3184, Error 0.3172(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 17.3678(17.1343) | Bit/dim 3.7745(3.7476) | Xent 0.2551(0.3548) | Loss 9.3133(10.2335) | Error 0.0933(0.1254) Steps 658(651.31) | Grad Norm 11.2045(10.8353) | Total Time 0.00(0.00)\n",
      "Iter 3540 | Time 16.6216(17.1117) | Bit/dim 3.7318(3.7456) | Xent 0.3124(0.3414) | Loss 9.2558(10.0096) | Error 0.1067(0.1203) Steps 616(649.92) | Grad Norm 7.8617(10.1469) | Total Time 0.00(0.00)\n",
      "Iter 3550 | Time 17.6289(17.1571) | Bit/dim 3.7383(3.7410) | Xent 0.3210(0.3349) | Loss 9.4508(9.8461) | Error 0.1100(0.1182) Steps 622(647.22) | Grad Norm 14.2680(9.9315) | Total Time 0.00(0.00)\n",
      "Iter 3560 | Time 17.2479(17.1733) | Bit/dim 3.7309(3.7417) | Xent 0.4014(0.3471) | Loss 9.4858(9.7567) | Error 0.1411(0.1214) Steps 652(650.27) | Grad Norm 12.1304(11.2804) | Total Time 0.00(0.00)\n",
      "Iter 3570 | Time 17.9212(17.2237) | Bit/dim 3.7570(3.7439) | Xent 0.3734(0.3487) | Loss 9.5617(9.6785) | Error 0.1344(0.1230) Steps 634(647.18) | Grad Norm 10.8977(11.0496) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 89.2614, Epoch Time 1055.1682(976.9707), Bit/dim 3.7403(best: 3.7561), Xent 1.1677, Loss 4.3241, Error 0.3172(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 16.5683(17.2742) | Bit/dim 3.7385(3.7414) | Xent 0.2729(0.3378) | Loss 9.3458(10.3132) | Error 0.0922(0.1190) Steps 658(648.95) | Grad Norm 9.6714(9.9620) | Total Time 0.00(0.00)\n",
      "Iter 3590 | Time 16.7455(17.3361) | Bit/dim 3.7404(3.7398) | Xent 0.3200(0.3245) | Loss 9.4277(10.0810) | Error 0.1022(0.1141) Steps 652(654.27) | Grad Norm 8.6079(9.5039) | Total Time 0.00(0.00)\n",
      "Iter 3600 | Time 17.0640(17.3419) | Bit/dim 3.7254(3.7354) | Xent 0.3045(0.3178) | Loss 9.3571(9.8942) | Error 0.1022(0.1113) Steps 628(654.24) | Grad Norm 6.0466(9.2905) | Total Time 0.00(0.00)\n",
      "Iter 3610 | Time 18.1312(17.3871) | Bit/dim 3.6932(3.7355) | Xent 0.3349(0.3173) | Loss 9.3884(9.7642) | Error 0.1089(0.1117) Steps 682(655.78) | Grad Norm 6.8026(9.2263) | Total Time 0.00(0.00)\n",
      "Iter 3620 | Time 17.9948(17.3539) | Bit/dim 3.7357(3.7351) | Xent 0.3738(0.3197) | Loss 9.4261(9.6677) | Error 0.1356(0.1131) Steps 628(653.70) | Grad Norm 15.6934(9.1898) | Total Time 0.00(0.00)\n",
      "Iter 3630 | Time 16.7799(17.2470) | Bit/dim 3.6946(3.7355) | Xent 0.3363(0.3250) | Loss 9.4006(9.6105) | Error 0.1156(0.1148) Steps 652(653.27) | Grad Norm 8.4748(9.5527) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 88.5211, Epoch Time 1062.1825(979.5271), Bit/dim 3.7414(best: 3.7403), Xent 1.1459, Loss 4.3144, Error 0.3198(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 16.6343(17.1561) | Bit/dim 3.7413(3.7345) | Xent 0.3062(0.3159) | Loss 9.4275(10.1447) | Error 0.1144(0.1117) Steps 658(652.41) | Grad Norm 16.4793(9.5642) | Total Time 0.00(0.00)\n",
      "Iter 3650 | Time 17.7935(17.1912) | Bit/dim 3.7567(3.7376) | Xent 0.3439(0.3157) | Loss 9.5113(9.9607) | Error 0.1267(0.1117) Steps 688(652.05) | Grad Norm 8.2698(10.6237) | Total Time 0.00(0.00)\n",
      "Iter 3660 | Time 16.8536(17.2349) | Bit/dim 3.7543(3.7393) | Xent 0.4162(0.3307) | Loss 9.7096(9.8476) | Error 0.1567(0.1169) Steps 664(649.29) | Grad Norm 14.9408(11.2855) | Total Time 0.00(0.00)\n",
      "Iter 3670 | Time 18.1036(17.1546) | Bit/dim 3.7617(3.7423) | Xent 0.3227(0.3368) | Loss 9.4845(9.7524) | Error 0.1022(0.1189) Steps 652(647.09) | Grad Norm 8.9458(10.7856) | Total Time 0.00(0.00)\n",
      "Iter 3680 | Time 16.8507(17.1367) | Bit/dim 3.7374(3.7394) | Xent 0.3127(0.3331) | Loss 9.4851(9.6698) | Error 0.1089(0.1175) Steps 652(648.58) | Grad Norm 6.4746(10.3895) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 88.5974, Epoch Time 1049.6958(981.6321), Bit/dim 3.7475(best: 3.7403), Xent 1.1626, Loss 4.3288, Error 0.3186(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 16.8726(17.1107) | Bit/dim 3.7446(3.7400) | Xent 0.2718(0.3241) | Loss 9.4686(10.2925) | Error 0.0956(0.1135) Steps 658(646.99) | Grad Norm 9.6732(10.2057) | Total Time 0.00(0.00)\n",
      "Iter 3700 | Time 16.7909(17.1691) | Bit/dim 3.7330(3.7378) | Xent 0.2975(0.3180) | Loss 9.4537(10.0578) | Error 0.1189(0.1113) Steps 640(646.48) | Grad Norm 9.0836(9.9049) | Total Time 0.00(0.00)\n",
      "Iter 3710 | Time 16.8668(17.2209) | Bit/dim 3.7550(3.7355) | Xent 0.2937(0.3085) | Loss 9.3922(9.8821) | Error 0.1033(0.1085) Steps 664(648.32) | Grad Norm 11.1471(9.5971) | Total Time 0.00(0.00)\n",
      "Iter 3720 | Time 17.0388(17.1476) | Bit/dim 3.7656(3.7347) | Xent 0.3257(0.3145) | Loss 9.5255(9.7594) | Error 0.1189(0.1105) Steps 640(649.42) | Grad Norm 11.5403(10.1193) | Total Time 0.00(0.00)\n",
      "Iter 3730 | Time 17.5629(17.2375) | Bit/dim 3.7455(3.7351) | Xent 0.2461(0.3087) | Loss 9.3686(9.6600) | Error 0.0789(0.1092) Steps 682(650.77) | Grad Norm 7.1168(9.9840) | Total Time 0.00(0.00)\n",
      "Iter 3740 | Time 17.5780(17.2012) | Bit/dim 3.7488(3.7374) | Xent 0.2819(0.3033) | Loss 9.3498(9.5941) | Error 0.1078(0.1070) Steps 664(652.24) | Grad Norm 5.8831(9.4225) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 89.8349, Epoch Time 1057.6104(983.9115), Bit/dim 3.7356(best: 3.7403), Xent 1.1710, Loss 4.3211, Error 0.3109(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 16.7983(17.1784) | Bit/dim 3.7368(3.7334) | Xent 0.2504(0.2886) | Loss 9.3892(10.1326) | Error 0.0844(0.1011) Steps 634(652.46) | Grad Norm 8.3070(8.9082) | Total Time 0.00(0.00)\n",
      "Iter 3760 | Time 17.0376(17.1133) | Bit/dim 3.7452(3.7340) | Xent 0.2749(0.2867) | Loss 9.2544(9.9382) | Error 0.1100(0.1008) Steps 670(649.64) | Grad Norm 8.1412(9.3138) | Total Time 0.00(0.00)\n",
      "Iter 3770 | Time 17.5438(17.1431) | Bit/dim 3.7416(3.7352) | Xent 0.2174(0.2849) | Loss 9.3985(9.7950) | Error 0.0722(0.0993) Steps 616(649.26) | Grad Norm 9.0930(9.5604) | Total Time 0.00(0.00)\n",
      "Iter 3780 | Time 16.6580(17.1741) | Bit/dim 3.7192(3.7343) | Xent 0.3296(0.2827) | Loss 9.4202(9.6797) | Error 0.1067(0.0979) Steps 640(647.43) | Grad Norm 11.2321(9.5153) | Total Time 0.00(0.00)\n",
      "Iter 3790 | Time 17.7183(17.1690) | Bit/dim 3.7205(3.7322) | Xent 0.3305(0.2868) | Loss 9.2958(9.6045) | Error 0.1211(0.0998) Steps 646(647.44) | Grad Norm 18.4435(10.1804) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 87.8235, Epoch Time 1050.0386(985.8953), Bit/dim 3.7426(best: 3.7356), Xent 1.2565, Loss 4.3709, Error 0.3243(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 17.4695(17.1116) | Bit/dim 3.7341(3.7328) | Xent 0.2492(0.2842) | Loss 9.3111(10.2212) | Error 0.0889(0.0994) Steps 676(648.54) | Grad Norm 8.0352(10.1637) | Total Time 0.00(0.00)\n",
      "Iter 3810 | Time 16.4648(17.0428) | Bit/dim 3.7242(3.7302) | Xent 0.2384(0.2780) | Loss 9.1998(9.9816) | Error 0.0856(0.0972) Steps 640(650.15) | Grad Norm 7.1349(9.5739) | Total Time 0.00(0.00)\n",
      "Iter 3820 | Time 17.3448(16.9800) | Bit/dim 3.7392(3.7309) | Xent 0.2789(0.2733) | Loss 9.4812(9.8383) | Error 0.1000(0.0959) Steps 670(652.36) | Grad Norm 11.9335(9.8661) | Total Time 0.00(0.00)\n",
      "Iter 3830 | Time 16.9310(16.9856) | Bit/dim 3.7232(3.7329) | Xent 0.3022(0.2793) | Loss 9.4399(9.7275) | Error 0.1033(0.0981) Steps 628(650.61) | Grad Norm 7.3974(10.1317) | Total Time 0.00(0.00)\n",
      "Iter 3840 | Time 17.6932(17.0107) | Bit/dim 3.7333(3.7300) | Xent 0.2792(0.2758) | Loss 9.2522(9.6191) | Error 0.1011(0.0969) Steps 622(650.56) | Grad Norm 9.0795(10.0836) | Total Time 0.00(0.00)\n",
      "Iter 3850 | Time 17.3044(17.0898) | Bit/dim 3.7305(3.7292) | Xent 0.2599(0.2829) | Loss 9.4450(9.5592) | Error 0.0833(0.0992) Steps 658(653.88) | Grad Norm 6.1034(10.6445) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 88.4417, Epoch Time 1043.6509(987.6280), Bit/dim 3.7363(best: 3.7356), Xent 1.2879, Loss 4.3802, Error 0.3386(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 17.4489(17.0200) | Bit/dim 3.7024(3.7258) | Xent 0.2202(0.2789) | Loss 9.2391(10.1086) | Error 0.0700(0.0973) Steps 664(654.12) | Grad Norm 13.3387(10.9637) | Total Time 0.00(0.00)\n",
      "Iter 3870 | Time 16.3538(17.0615) | Bit/dim 3.7293(3.7257) | Xent 0.2539(0.2683) | Loss 9.3373(9.8933) | Error 0.0844(0.0932) Steps 658(655.58) | Grad Norm 11.1723(10.8268) | Total Time 0.00(0.00)\n",
      "Iter 3880 | Time 16.6679(17.0504) | Bit/dim 3.7239(3.7278) | Xent 0.2760(0.2635) | Loss 9.2984(9.7587) | Error 0.0889(0.0920) Steps 652(654.56) | Grad Norm 8.0232(9.9633) | Total Time 0.00(0.00)\n",
      "Iter 3890 | Time 16.8956(17.1314) | Bit/dim 3.7492(3.7278) | Xent 0.2567(0.2586) | Loss 9.5130(9.6504) | Error 0.0867(0.0904) Steps 664(655.34) | Grad Norm 13.9843(9.5291) | Total Time 0.00(0.00)\n",
      "Iter 3900 | Time 17.4324(17.1263) | Bit/dim 3.6852(3.7265) | Xent 0.3158(0.2702) | Loss 9.2852(9.5808) | Error 0.1100(0.0946) Steps 634(654.64) | Grad Norm 13.0810(10.0102) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 88.1345, Epoch Time 1048.4553(989.4528), Bit/dim 3.7384(best: 3.7356), Xent 1.3002, Loss 4.3886, Error 0.3356(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 16.8205(17.1312) | Bit/dim 3.7398(3.7286) | Xent 0.2279(0.2677) | Loss 9.2895(10.2414) | Error 0.0744(0.0934) Steps 646(656.09) | Grad Norm 7.1938(9.6981) | Total Time 0.00(0.00)\n",
      "Iter 3920 | Time 17.0795(17.0730) | Bit/dim 3.7234(3.7267) | Xent 0.2670(0.2596) | Loss 9.4758(9.9939) | Error 0.0878(0.0897) Steps 664(656.02) | Grad Norm 10.0106(9.7162) | Total Time 0.00(0.00)\n",
      "Iter 3930 | Time 17.3273(17.1614) | Bit/dim 3.7036(3.7271) | Xent 0.2261(0.2550) | Loss 9.3051(9.8211) | Error 0.0722(0.0879) Steps 664(652.90) | Grad Norm 14.8831(9.8216) | Total Time 0.00(0.00)\n",
      "Iter 3940 | Time 17.9641(17.1830) | Bit/dim 3.6775(3.7267) | Xent 0.3331(0.2633) | Loss 9.3750(9.7113) | Error 0.1122(0.0907) Steps 676(652.48) | Grad Norm 10.5901(10.1363) | Total Time 0.00(0.00)\n",
      "Iter 3950 | Time 17.4797(17.1632) | Bit/dim 3.7310(3.7249) | Xent 0.2898(0.2676) | Loss 9.4255(9.6219) | Error 0.1067(0.0924) Steps 670(652.42) | Grad Norm 9.3630(9.9743) | Total Time 0.00(0.00)\n",
      "Iter 3960 | Time 17.0117(17.0666) | Bit/dim 3.7089(3.7248) | Xent 0.2255(0.2699) | Loss 9.2782(9.5487) | Error 0.0822(0.0941) Steps 628(650.99) | Grad Norm 7.2219(9.7176) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 88.4783, Epoch Time 1047.9994(991.2092), Bit/dim 3.7400(best: 3.7356), Xent 1.2179, Loss 4.3490, Error 0.3091(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 17.0684(17.1078) | Bit/dim 3.7251(3.7250) | Xent 0.2143(0.2592) | Loss 9.4369(10.1045) | Error 0.0656(0.0902) Steps 670(653.55) | Grad Norm 17.5765(10.3421) | Total Time 0.00(0.00)\n",
      "Iter 3980 | Time 16.2138(17.0846) | Bit/dim 3.7084(3.7227) | Xent 0.2686(0.2541) | Loss 9.3254(9.8858) | Error 0.0989(0.0883) Steps 628(650.72) | Grad Norm 10.5651(10.0945) | Total Time 0.00(0.00)\n",
      "Iter 3990 | Time 18.3615(17.0532) | Bit/dim 3.7299(3.7211) | Xent 0.2919(0.2495) | Loss 9.4435(9.7326) | Error 0.1089(0.0870) Steps 646(649.62) | Grad Norm 10.8116(9.9961) | Total Time 0.00(0.00)\n",
      "Iter 4000 | Time 17.2445(17.0663) | Bit/dim 3.6831(3.7188) | Xent 0.2025(0.2441) | Loss 9.2773(9.6223) | Error 0.0711(0.0860) Steps 664(649.76) | Grad Norm 5.7695(9.3698) | Total Time 0.00(0.00)\n",
      "Iter 4010 | Time 17.4963(17.0727) | Bit/dim 3.7432(3.7208) | Xent 0.2335(0.2440) | Loss 9.4638(9.5512) | Error 0.0767(0.0856) Steps 676(653.23) | Grad Norm 9.2788(9.4185) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 87.4501, Epoch Time 1044.7735(992.8161), Bit/dim 3.7309(best: 3.7356), Xent 1.2944, Loss 4.3781, Error 0.3168(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 17.0526(16.9992) | Bit/dim 3.6679(3.7173) | Xent 0.2358(0.2440) | Loss 9.3352(10.1689) | Error 0.0789(0.0857) Steps 676(650.48) | Grad Norm 8.8392(9.5303) | Total Time 0.00(0.00)\n",
      "Iter 4030 | Time 18.3394(17.0715) | Bit/dim 3.7022(3.7182) | Xent 0.2550(0.2385) | Loss 9.3751(9.9497) | Error 0.0878(0.0832) Steps 652(652.16) | Grad Norm 13.8310(10.2785) | Total Time 0.00(0.00)\n",
      "Iter 4040 | Time 17.6248(17.0933) | Bit/dim 3.7407(3.7204) | Xent 0.2375(0.2343) | Loss 9.3358(9.7823) | Error 0.0889(0.0819) Steps 616(650.96) | Grad Norm 15.4486(10.3180) | Total Time 0.00(0.00)\n",
      "Iter 4050 | Time 17.3685(17.1492) | Bit/dim 3.6736(3.7196) | Xent 0.2388(0.2339) | Loss 9.2180(9.6687) | Error 0.0811(0.0812) Steps 646(652.89) | Grad Norm 7.8018(10.1128) | Total Time 0.00(0.00)\n",
      "Iter 4060 | Time 17.9932(17.1131) | Bit/dim 3.7108(3.7220) | Xent 0.3273(0.2426) | Loss 9.4391(9.5891) | Error 0.1067(0.0840) Steps 646(651.67) | Grad Norm 17.2803(10.3690) | Total Time 0.00(0.00)\n",
      "Iter 4070 | Time 16.4707(17.0610) | Bit/dim 3.7241(3.7226) | Xent 0.2807(0.2454) | Loss 9.3535(9.5306) | Error 0.0967(0.0849) Steps 646(653.89) | Grad Norm 9.3414(10.0931) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 90.0760, Epoch Time 1050.5654(994.5486), Bit/dim 3.7241(best: 3.7309), Xent 1.3492, Loss 4.3986, Error 0.3260(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 16.8134(16.9288) | Bit/dim 3.7175(3.7199) | Xent 0.1976(0.2360) | Loss 9.2378(10.0901) | Error 0.0667(0.0820) Steps 664(654.12) | Grad Norm 7.1968(9.9816) | Total Time 0.00(0.00)\n",
      "Iter 4090 | Time 16.6878(16.9661) | Bit/dim 3.7344(3.7213) | Xent 0.1672(0.2277) | Loss 9.2508(9.8822) | Error 0.0611(0.0789) Steps 628(652.78) | Grad Norm 5.5665(9.2798) | Total Time 0.00(0.00)\n",
      "Iter 4100 | Time 17.9279(16.9732) | Bit/dim 3.7009(3.7165) | Xent 0.1891(0.2240) | Loss 9.3554(9.7176) | Error 0.0622(0.0774) Steps 670(651.33) | Grad Norm 7.1919(9.0605) | Total Time 0.00(0.00)\n",
      "Iter 4110 | Time 17.1041(16.9591) | Bit/dim 3.7206(3.7158) | Xent 0.1751(0.2238) | Loss 9.4277(9.6073) | Error 0.0611(0.0773) Steps 646(651.56) | Grad Norm 5.3970(8.8461) | Total Time 0.00(0.00)\n",
      "Iter 4120 | Time 15.8271(16.9221) | Bit/dim 3.7150(3.7151) | Xent 0.1998(0.2259) | Loss 9.2125(9.5170) | Error 0.0711(0.0784) Steps 658(652.59) | Grad Norm 7.7325(8.5628) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 88.3946, Epoch Time 1038.2192(995.8587), Bit/dim 3.7369(best: 3.7241), Xent 1.2998, Loss 4.3868, Error 0.3133(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 17.1623(16.9365) | Bit/dim 3.7237(3.7184) | Xent 0.1868(0.2210) | Loss 9.2716(10.1662) | Error 0.0656(0.0759) Steps 676(650.95) | Grad Norm 12.7518(8.9079) | Total Time 0.00(0.00)\n",
      "Iter 4140 | Time 16.9568(16.9719) | Bit/dim 3.7098(3.7190) | Xent 0.2477(0.2137) | Loss 9.2940(9.9289) | Error 0.0767(0.0728) Steps 640(651.05) | Grad Norm 18.4295(8.9728) | Total Time 0.00(0.00)\n",
      "Iter 4150 | Time 18.0674(17.0338) | Bit/dim 3.6944(3.7156) | Xent 0.2364(0.2134) | Loss 9.3428(9.7565) | Error 0.0744(0.0728) Steps 700(650.09) | Grad Norm 11.9455(9.6286) | Total Time 0.00(0.00)\n",
      "Iter 4160 | Time 16.9765(17.0356) | Bit/dim 3.7273(3.7146) | Xent 0.2615(0.2187) | Loss 9.3360(9.6408) | Error 0.0900(0.0749) Steps 664(652.44) | Grad Norm 16.7312(10.0705) | Total Time 0.00(0.00)\n",
      "Iter 4170 | Time 17.1677(17.0108) | Bit/dim 3.6971(3.7128) | Xent 0.2446(0.2303) | Loss 9.4133(9.5661) | Error 0.0900(0.0795) Steps 676(652.31) | Grad Norm 10.3951(10.9916) | Total Time 0.00(0.00)\n",
      "Iter 4180 | Time 17.5986(17.0786) | Bit/dim 3.7574(3.7148) | Xent 0.2359(0.2335) | Loss 9.5758(9.5176) | Error 0.0800(0.0808) Steps 670(655.13) | Grad Norm 10.0493(10.8468) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 89.3637, Epoch Time 1048.8862(997.4495), Bit/dim 3.7308(best: 3.7241), Xent 1.4528, Loss 4.4572, Error 0.3327(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 16.1663(16.9777) | Bit/dim 3.7158(3.7157) | Xent 0.2224(0.2296) | Loss 9.2470(10.0683) | Error 0.0889(0.0797) Steps 658(652.52) | Grad Norm 7.7291(10.7434) | Total Time 0.00(0.00)\n",
      "Iter 4200 | Time 15.9020(17.0085) | Bit/dim 3.7503(3.7178) | Xent 0.2081(0.2241) | Loss 9.3228(9.8660) | Error 0.0733(0.0784) Steps 664(656.22) | Grad Norm 8.5832(9.9480) | Total Time 0.00(0.00)\n",
      "Iter 4210 | Time 18.0791(17.0744) | Bit/dim 3.7074(3.7152) | Xent 0.2324(0.2214) | Loss 9.3260(9.7049) | Error 0.0778(0.0766) Steps 646(657.17) | Grad Norm 16.3601(10.2446) | Total Time 0.00(0.00)\n",
      "Iter 4220 | Time 17.9691(16.9977) | Bit/dim 3.6738(3.7138) | Xent 0.2171(0.2168) | Loss 9.2844(9.5924) | Error 0.0711(0.0750) Steps 640(655.23) | Grad Norm 10.4061(10.6124) | Total Time 0.00(0.00)\n",
      "Iter 4230 | Time 16.8058(16.9634) | Bit/dim 3.6952(3.7139) | Xent 0.2029(0.2141) | Loss 9.2409(9.5143) | Error 0.0633(0.0738) Steps 628(656.23) | Grad Norm 9.1236(10.2089) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 88.6101, Epoch Time 1038.8753(998.6923), Bit/dim 3.7134(best: 3.7241), Xent 1.3149, Loss 4.3708, Error 0.3220(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 16.5845(16.8914) | Bit/dim 3.7005(3.7129) | Xent 0.1922(0.2097) | Loss 9.2104(10.1647) | Error 0.0633(0.0720) Steps 652(653.75) | Grad Norm 7.4332(9.6182) | Total Time 0.00(0.00)\n",
      "Iter 4250 | Time 17.8655(16.9926) | Bit/dim 3.6951(3.7101) | Xent 0.2174(0.2007) | Loss 9.2476(9.9258) | Error 0.0767(0.0686) Steps 682(654.31) | Grad Norm 7.2644(8.9615) | Total Time 0.00(0.00)\n",
      "Iter 4260 | Time 17.2072(17.0179) | Bit/dim 3.7217(3.7086) | Xent 0.1508(0.1939) | Loss 9.2490(9.7415) | Error 0.0511(0.0664) Steps 658(653.76) | Grad Norm 6.3833(8.7105) | Total Time 0.00(0.00)\n",
      "Iter 4270 | Time 17.9931(17.0882) | Bit/dim 3.7327(3.7088) | Xent 0.1503(0.1887) | Loss 9.3419(9.6172) | Error 0.0578(0.0657) Steps 646(650.05) | Grad Norm 9.0807(8.8734) | Total Time 0.00(0.00)\n",
      "Iter 4280 | Time 17.6259(17.2171) | Bit/dim 3.7253(3.7082) | Xent 0.2001(0.1886) | Loss 9.3684(9.5369) | Error 0.0656(0.0650) Steps 676(653.98) | Grad Norm 7.6359(8.9294) | Total Time 0.00(0.00)\n",
      "Iter 4290 | Time 17.4014(17.2583) | Bit/dim 3.7337(3.7059) | Xent 0.2473(0.1950) | Loss 9.3611(9.4565) | Error 0.0767(0.0669) Steps 628(652.58) | Grad Norm 10.8162(9.2177) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 89.5779, Epoch Time 1058.8048(1000.4957), Bit/dim 3.7210(best: 3.7134), Xent 1.3803, Loss 4.4112, Error 0.3271(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 17.4926(17.2335) | Bit/dim 3.7488(3.7051) | Xent 0.1583(0.1976) | Loss 9.3924(9.9938) | Error 0.0600(0.0680) Steps 682(652.08) | Grad Norm 6.2555(9.6852) | Total Time 0.00(0.00)\n",
      "Iter 4310 | Time 17.4180(17.2636) | Bit/dim 3.7165(3.7052) | Xent 0.1779(0.1917) | Loss 9.2015(9.7914) | Error 0.0611(0.0664) Steps 640(649.96) | Grad Norm 7.0723(9.5206) | Total Time 0.00(0.00)\n",
      "Iter 4320 | Time 16.9540(17.1945) | Bit/dim 3.6767(3.7037) | Xent 0.1257(0.1819) | Loss 9.0938(9.6296) | Error 0.0444(0.0634) Steps 628(647.77) | Grad Norm 4.4204(8.5315) | Total Time 0.00(0.00)\n",
      "Iter 4330 | Time 18.5223(17.1353) | Bit/dim 3.7465(3.7064) | Xent 0.1664(0.1829) | Loss 9.4377(9.5369) | Error 0.0511(0.0631) Steps 706(648.23) | Grad Norm 9.6786(9.1534) | Total Time 0.00(0.00)\n",
      "Iter 4340 | Time 16.8011(17.0521) | Bit/dim 3.7137(3.7060) | Xent 0.1895(0.1830) | Loss 9.1491(9.4401) | Error 0.0633(0.0629) Steps 652(648.75) | Grad Norm 5.2542(8.7755) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 89.1610, Epoch Time 1047.6761(1001.9111), Bit/dim 3.7192(best: 3.7134), Xent 1.4369, Loss 4.4377, Error 0.3140(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 17.9529(17.0629) | Bit/dim 3.6728(3.7041) | Xent 0.1424(0.1789) | Loss 9.1291(10.0851) | Error 0.0478(0.0617) Steps 682(647.77) | Grad Norm 6.4672(8.5533) | Total Time 0.00(0.00)\n",
      "Iter 4360 | Time 17.3005(17.0563) | Bit/dim 3.7276(3.7005) | Xent 0.1180(0.1695) | Loss 9.2055(9.8515) | Error 0.0433(0.0583) Steps 640(648.92) | Grad Norm 4.4011(7.9079) | Total Time 0.00(0.00)\n",
      "Iter 4370 | Time 17.5501(16.9506) | Bit/dim 3.7344(3.7018) | Xent 0.2838(0.1797) | Loss 9.3596(9.6890) | Error 0.0878(0.0608) Steps 634(646.91) | Grad Norm 22.8787(9.1501) | Total Time 0.00(0.00)\n",
      "Iter 4380 | Time 17.9599(16.9529) | Bit/dim 3.7145(3.7022) | Xent 0.1917(0.1854) | Loss 9.3300(9.5624) | Error 0.0689(0.0632) Steps 658(646.61) | Grad Norm 9.2344(9.6671) | Total Time 0.00(0.00)\n",
      "Iter 4390 | Time 17.0173(16.9497) | Bit/dim 3.6875(3.7040) | Xent 0.2061(0.1908) | Loss 9.2259(9.4846) | Error 0.0644(0.0648) Steps 628(645.69) | Grad Norm 10.1607(9.7423) | Total Time 0.00(0.00)\n",
      "Iter 4400 | Time 17.0579(16.9287) | Bit/dim 3.6993(3.7073) | Xent 0.1412(0.1949) | Loss 9.1828(9.4301) | Error 0.0478(0.0664) Steps 628(645.98) | Grad Norm 7.2941(9.4979) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 89.4611, Epoch Time 1039.0858(1003.0263), Bit/dim 3.7152(best: 3.7134), Xent 1.4087, Loss 4.4196, Error 0.3294(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 18.1407(17.0384) | Bit/dim 3.6904(3.7039) | Xent 0.2188(0.1894) | Loss 9.1853(9.9831) | Error 0.0767(0.0643) Steps 616(646.12) | Grad Norm 8.5855(9.0978) | Total Time 0.00(0.00)\n",
      "Iter 4420 | Time 16.0305(17.0064) | Bit/dim 3.7108(3.7041) | Xent 0.1538(0.1845) | Loss 9.1524(9.7857) | Error 0.0511(0.0636) Steps 640(645.90) | Grad Norm 12.3570(9.4064) | Total Time 0.00(0.00)\n",
      "Iter 4430 | Time 17.1845(17.0180) | Bit/dim 3.7308(3.7053) | Xent 0.1632(0.1810) | Loss 9.2902(9.6334) | Error 0.0656(0.0625) Steps 682(648.01) | Grad Norm 8.8844(9.7637) | Total Time 0.00(0.00)\n",
      "Iter 4440 | Time 17.3150(17.0102) | Bit/dim 3.7078(3.7037) | Xent 0.1365(0.1782) | Loss 9.2670(9.5264) | Error 0.0400(0.0609) Steps 658(649.19) | Grad Norm 6.7338(9.5813) | Total Time 0.00(0.00)\n",
      "Iter 4450 | Time 16.6338(17.0481) | Bit/dim 3.7239(3.7074) | Xent 0.1522(0.1743) | Loss 9.1061(9.4404) | Error 0.0489(0.0593) Steps 652(653.02) | Grad Norm 8.5939(9.5157) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 88.6128, Epoch Time 1049.7824(1004.4290), Bit/dim 3.7176(best: 3.7134), Xent 1.6264, Loss 4.5308, Error 0.3446(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 15.7925(17.0303) | Bit/dim 3.7053(3.7035) | Xent 0.1497(0.1744) | Loss 9.0791(10.0712) | Error 0.0467(0.0594) Steps 634(652.04) | Grad Norm 7.4533(9.3437) | Total Time 0.00(0.00)\n",
      "Iter 4470 | Time 17.3633(17.0416) | Bit/dim 3.7261(3.7068) | Xent 0.1761(0.1712) | Loss 9.2175(9.8525) | Error 0.0633(0.0580) Steps 604(651.79) | Grad Norm 10.8861(9.1701) | Total Time 0.00(0.00)\n",
      "Iter 4480 | Time 17.0658(17.0057) | Bit/dim 3.7073(3.7059) | Xent 0.1620(0.1677) | Loss 9.1878(9.6789) | Error 0.0511(0.0565) Steps 622(647.17) | Grad Norm 11.0236(9.1014) | Total Time 0.00(0.00)\n",
      "Iter 4490 | Time 16.5094(16.9781) | Bit/dim 3.6760(3.7032) | Xent 0.1740(0.1664) | Loss 9.1598(9.5549) | Error 0.0644(0.0565) Steps 622(645.89) | Grad Norm 7.6848(8.7494) | Total Time 0.00(0.00)\n",
      "Iter 4500 | Time 17.4507(16.9880) | Bit/dim 3.6879(3.7009) | Xent 0.1824(0.1673) | Loss 9.2321(9.4552) | Error 0.0578(0.0570) Steps 640(647.13) | Grad Norm 5.4857(8.3818) | Total Time 0.00(0.00)\n",
      "Iter 4510 | Time 17.8987(17.0297) | Bit/dim 3.6753(3.6997) | Xent 0.1919(0.1698) | Loss 9.0927(9.3886) | Error 0.0678(0.0571) Steps 682(648.77) | Grad Norm 7.1993(8.1398) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 89.7956, Epoch Time 1046.9100(1005.7034), Bit/dim 3.7045(best: 3.7134), Xent 1.4620, Loss 4.4355, Error 0.3346(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 17.3299(16.9975) | Bit/dim 3.7043(3.6986) | Xent 0.1619(0.1677) | Loss 9.2627(9.9599) | Error 0.0489(0.0556) Steps 658(646.63) | Grad Norm 7.7012(8.5053) | Total Time 0.00(0.00)\n",
      "Iter 4530 | Time 17.6093(16.9635) | Bit/dim 3.7038(3.6985) | Xent 0.1099(0.1645) | Loss 9.1652(9.7590) | Error 0.0322(0.0544) Steps 676(647.70) | Grad Norm 7.4781(8.5786) | Total Time 0.00(0.00)\n",
      "Iter 4540 | Time 17.0490(16.9554) | Bit/dim 3.6604(3.6976) | Xent 0.1368(0.1565) | Loss 9.0281(9.5975) | Error 0.0478(0.0513) Steps 622(644.37) | Grad Norm 6.8766(8.0527) | Total Time 0.00(0.00)\n",
      "Iter 4550 | Time 16.5548(16.9304) | Bit/dim 3.7122(3.6976) | Xent 0.2569(0.1719) | Loss 9.3806(9.5018) | Error 0.0878(0.0574) Steps 688(646.92) | Grad Norm 12.5605(9.1768) | Total Time 0.00(0.00)\n",
      "Iter 4560 | Time 16.9236(16.9612) | Bit/dim 3.7085(3.6986) | Xent 0.2584(0.1836) | Loss 9.3923(9.4326) | Error 0.0867(0.0618) Steps 652(646.03) | Grad Norm 10.9186(9.2583) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 89.8552, Epoch Time 1043.7942(1006.8462), Bit/dim 3.7208(best: 3.7045), Xent 1.4894, Loss 4.4655, Error 0.3334(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 16.4797(16.9447) | Bit/dim 3.7057(3.7009) | Xent 0.2075(0.1840) | Loss 9.3149(10.0919) | Error 0.0733(0.0622) Steps 658(647.95) | Grad Norm 13.1075(9.5224) | Total Time 0.00(0.00)\n",
      "Iter 4580 | Time 16.5255(17.0347) | Bit/dim 3.6969(3.7036) | Xent 0.2247(0.1765) | Loss 9.2585(9.8652) | Error 0.0744(0.0598) Steps 622(651.83) | Grad Norm 11.1037(9.5260) | Total Time 0.00(0.00)\n",
      "Iter 4590 | Time 17.2008(17.0504) | Bit/dim 3.6541(3.7003) | Xent 0.1749(0.1711) | Loss 9.1266(9.6837) | Error 0.0556(0.0572) Steps 658(656.13) | Grad Norm 6.1714(9.3673) | Total Time 0.00(0.00)\n",
      "Iter 4600 | Time 16.1730(17.0356) | Bit/dim 3.6824(3.6984) | Xent 0.1492(0.1643) | Loss 9.1052(9.5475) | Error 0.0578(0.0553) Steps 640(654.96) | Grad Norm 6.8486(8.6396) | Total Time 0.00(0.00)\n",
      "Iter 4610 | Time 17.1352(17.0180) | Bit/dim 3.6993(3.6990) | Xent 0.1617(0.1661) | Loss 9.2513(9.4589) | Error 0.0611(0.0558) Steps 640(654.23) | Grad Norm 11.1396(9.0311) | Total Time 0.00(0.00)\n",
      "Iter 4620 | Time 16.5942(17.0859) | Bit/dim 3.7049(3.6993) | Xent 0.1776(0.1666) | Loss 9.2753(9.4035) | Error 0.0611(0.0554) Steps 634(656.73) | Grad Norm 6.2950(8.8110) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 90.3148, Epoch Time 1055.6313(1008.3097), Bit/dim 3.7180(best: 3.7045), Xent 1.5583, Loss 4.4971, Error 0.3254(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 17.4396(17.1101) | Bit/dim 3.6848(3.6950) | Xent 0.2101(0.1665) | Loss 9.2193(9.9402) | Error 0.0644(0.0553) Steps 664(656.61) | Grad Norm 13.0498(8.7832) | Total Time 0.00(0.00)\n",
      "Iter 4640 | Time 15.8555(17.0786) | Bit/dim 3.7310(3.6974) | Xent 0.1447(0.1603) | Loss 9.2028(9.7414) | Error 0.0411(0.0532) Steps 640(655.73) | Grad Norm 9.6019(8.6903) | Total Time 0.00(0.00)\n",
      "Iter 4650 | Time 16.4379(17.0352) | Bit/dim 3.6720(3.6972) | Xent 0.1496(0.1612) | Loss 9.1976(9.5914) | Error 0.0533(0.0533) Steps 658(656.12) | Grad Norm 6.3359(8.8816) | Total Time 0.00(0.00)\n",
      "Iter 4660 | Time 16.6897(16.9809) | Bit/dim 3.7133(3.6971) | Xent 0.1578(0.1606) | Loss 9.2204(9.4932) | Error 0.0489(0.0529) Steps 634(655.46) | Grad Norm 9.2713(8.7407) | Total Time 0.00(0.00)\n",
      "Iter 4670 | Time 16.2639(16.9145) | Bit/dim 3.6844(3.6983) | Xent 0.1792(0.1607) | Loss 9.1442(9.4092) | Error 0.0589(0.0535) Steps 616(655.63) | Grad Norm 6.2647(8.7485) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 91.9080, Epoch Time 1043.1533(1009.3550), Bit/dim 3.7129(best: 3.7045), Xent 1.4982, Loss 4.4620, Error 0.3384(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 16.8138(16.8787) | Bit/dim 3.6461(3.6965) | Xent 0.1292(0.1630) | Loss 8.9754(10.0492) | Error 0.0467(0.0538) Steps 652(653.66) | Grad Norm 5.2514(8.8534) | Total Time 0.00(0.00)\n",
      "Iter 4690 | Time 17.5729(16.9306) | Bit/dim 3.6800(3.6939) | Xent 0.0922(0.1557) | Loss 9.1056(9.8106) | Error 0.0289(0.0515) Steps 670(653.00) | Grad Norm 9.0537(8.6929) | Total Time 0.00(0.00)\n",
      "Iter 4700 | Time 17.6983(17.0062) | Bit/dim 3.6990(3.6944) | Xent 0.1402(0.1537) | Loss 9.1468(9.6483) | Error 0.0467(0.0508) Steps 640(652.03) | Grad Norm 8.4444(8.7677) | Total Time 0.00(0.00)\n",
      "Iter 4710 | Time 16.7788(17.0310) | Bit/dim 3.6917(3.6959) | Xent 0.1278(0.1505) | Loss 9.1100(9.5218) | Error 0.0356(0.0496) Steps 628(649.69) | Grad Norm 8.1193(8.9907) | Total Time 0.00(0.00)\n",
      "Iter 4720 | Time 17.2433(17.1316) | Bit/dim 3.7166(3.6969) | Xent 0.1535(0.1519) | Loss 9.2553(9.4398) | Error 0.0567(0.0505) Steps 670(648.51) | Grad Norm 12.3234(9.2122) | Total Time 0.00(0.00)\n",
      "Iter 4730 | Time 16.1779(17.0775) | Bit/dim 3.7089(3.6951) | Xent 0.1095(0.1568) | Loss 9.0856(9.3759) | Error 0.0389(0.0528) Steps 628(648.30) | Grad Norm 10.3706(9.6818) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 89.9816, Epoch Time 1051.8572(1010.6301), Bit/dim 3.7070(best: 3.7045), Xent 1.4995, Loss 4.4567, Error 0.3236(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 17.3250(17.1018) | Bit/dim 3.7200(3.6970) | Xent 0.1557(0.1590) | Loss 9.2868(9.9535) | Error 0.0433(0.0526) Steps 646(647.29) | Grad Norm 8.1268(9.6430) | Total Time 0.00(0.00)\n",
      "Iter 4750 | Time 16.3704(17.0705) | Bit/dim 3.7157(3.6944) | Xent 0.1308(0.1570) | Loss 9.1380(9.7469) | Error 0.0456(0.0518) Steps 628(647.52) | Grad Norm 5.9212(9.0856) | Total Time 0.00(0.00)\n",
      "Iter 4760 | Time 16.3390(17.0265) | Bit/dim 3.7260(3.6949) | Xent 0.1617(0.1569) | Loss 9.2341(9.5969) | Error 0.0533(0.0522) Steps 664(647.70) | Grad Norm 11.1846(9.0588) | Total Time 0.00(0.00)\n",
      "Iter 4770 | Time 16.7715(17.0569) | Bit/dim 3.6746(3.6953) | Xent 0.2111(0.1548) | Loss 9.1248(9.4873) | Error 0.0644(0.0518) Steps 652(649.75) | Grad Norm 10.5102(9.0930) | Total Time 0.00(0.00)\n",
      "Iter 4780 | Time 16.5576(17.0423) | Bit/dim 3.6672(3.6921) | Xent 0.1341(0.1543) | Loss 9.0462(9.3912) | Error 0.0433(0.0514) Steps 640(648.76) | Grad Norm 14.9397(9.4838) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 89.5045, Epoch Time 1049.4097(1011.7935), Bit/dim 3.7046(best: 3.7045), Xent 1.5574, Loss 4.4833, Error 0.3294(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 17.2619(17.0335) | Bit/dim 3.7152(3.6922) | Xent 0.1759(0.1572) | Loss 9.2836(10.0660) | Error 0.0589(0.0522) Steps 694(649.85) | Grad Norm 10.7254(10.2396) | Total Time 0.00(0.00)\n",
      "Iter 4800 | Time 17.1511(16.9873) | Bit/dim 3.6676(3.6910) | Xent 0.0899(0.1474) | Loss 9.1388(9.8160) | Error 0.0267(0.0495) Steps 610(647.74) | Grad Norm 5.3006(9.6391) | Total Time 0.00(0.00)\n",
      "Iter 4810 | Time 16.7357(16.9705) | Bit/dim 3.6945(3.6903) | Xent 0.1268(0.1433) | Loss 9.1382(9.6351) | Error 0.0467(0.0484) Steps 664(648.77) | Grad Norm 8.6047(9.6288) | Total Time 0.00(0.00)\n",
      "Iter 4820 | Time 17.4917(16.9954) | Bit/dim 3.7310(3.6881) | Xent 0.1242(0.1381) | Loss 9.1725(9.4888) | Error 0.0444(0.0461) Steps 640(648.51) | Grad Norm 9.5133(9.0853) | Total Time 0.00(0.00)\n",
      "Iter 4830 | Time 16.8745(17.0006) | Bit/dim 3.7050(3.6903) | Xent 0.1931(0.1415) | Loss 9.3033(9.4164) | Error 0.0711(0.0468) Steps 664(648.81) | Grad Norm 8.5755(9.0283) | Total Time 0.00(0.00)\n",
      "Iter 4840 | Time 16.5349(16.9784) | Bit/dim 3.6769(3.6896) | Xent 0.1229(0.1427) | Loss 9.1600(9.3468) | Error 0.0378(0.0474) Steps 652(648.32) | Grad Norm 7.5193(8.9769) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 88.9593, Epoch Time 1043.1015(1012.7327), Bit/dim 3.7070(best: 3.7045), Xent 1.5776, Loss 4.4958, Error 0.3256(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 16.8047(17.0163) | Bit/dim 3.6662(3.6910) | Xent 0.1154(0.1425) | Loss 9.0919(9.9185) | Error 0.0456(0.0477) Steps 670(647.95) | Grad Norm 7.9458(9.0897) | Total Time 0.00(0.00)\n",
      "Iter 4860 | Time 17.2243(16.9778) | Bit/dim 3.6612(3.6875) | Xent 0.1673(0.1412) | Loss 9.0895(9.7135) | Error 0.0556(0.0472) Steps 658(649.27) | Grad Norm 9.4973(9.1830) | Total Time 0.00(0.00)\n",
      "Iter 4870 | Time 16.1967(16.9597) | Bit/dim 3.6851(3.6871) | Xent 0.1617(0.1401) | Loss 9.0413(9.5618) | Error 0.0600(0.0469) Steps 622(650.48) | Grad Norm 7.5334(8.6661) | Total Time 0.00(0.00)\n",
      "Iter 4880 | Time 16.3836(16.9090) | Bit/dim 3.7283(3.6914) | Xent 0.2242(0.1476) | Loss 9.3981(9.4717) | Error 0.0744(0.0486) Steps 688(652.93) | Grad Norm 11.9873(8.8025) | Total Time 0.00(0.00)\n",
      "Iter 4890 | Time 18.0521(16.9257) | Bit/dim 3.7181(3.6936) | Xent 0.1875(0.1594) | Loss 9.2425(9.4060) | Error 0.0656(0.0525) Steps 652(651.49) | Grad Norm 8.5687(9.9253) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 90.1926, Epoch Time 1055.4293(1014.0136), Bit/dim 3.7111(best: 3.7045), Xent 1.4810, Loss 4.4516, Error 0.3401(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 16.3758(17.0279) | Bit/dim 3.7157(3.6959) | Xent 0.1557(0.1625) | Loss 9.2240(10.0751) | Error 0.0533(0.0531) Steps 634(652.95) | Grad Norm 13.4272(10.4291) | Total Time 0.00(0.00)\n",
      "Iter 4910 | Time 16.4332(17.0183) | Bit/dim 3.6566(3.6899) | Xent 0.0928(0.1510) | Loss 8.9866(9.8128) | Error 0.0189(0.0489) Steps 610(649.48) | Grad Norm 3.2651(9.3558) | Total Time 0.00(0.00)\n",
      "Iter 4920 | Time 17.0317(17.0053) | Bit/dim 3.6789(3.6886) | Xent 0.0959(0.1429) | Loss 9.0665(9.6254) | Error 0.0367(0.0469) Steps 622(646.06) | Grad Norm 7.0027(8.7110) | Total Time 0.00(0.00)\n",
      "Iter 4930 | Time 16.2190(16.9568) | Bit/dim 3.6811(3.6862) | Xent 0.0940(0.1369) | Loss 9.1637(9.4966) | Error 0.0344(0.0453) Steps 652(647.54) | Grad Norm 7.8888(8.4921) | Total Time 0.00(0.00)\n",
      "Iter 4940 | Time 16.9314(16.9265) | Bit/dim 3.6804(3.6850) | Xent 0.1369(0.1408) | Loss 9.2169(9.4123) | Error 0.0433(0.0465) Steps 682(651.56) | Grad Norm 9.1857(8.6436) | Total Time 0.00(0.00)\n",
      "Iter 4950 | Time 17.1341(17.0454) | Bit/dim 3.6954(3.6884) | Xent 0.1482(0.1475) | Loss 9.2761(9.3545) | Error 0.0500(0.0483) Steps 664(651.95) | Grad Norm 6.5653(9.1024) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 90.5499, Epoch Time 1048.1586(1015.0380), Bit/dim 3.7020(best: 3.7045), Xent 1.5217, Loss 4.4628, Error 0.3159(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 16.6606(17.1288) | Bit/dim 3.7065(3.6875) | Xent 0.1176(0.1395) | Loss 9.1263(9.9115) | Error 0.0400(0.0458) Steps 658(653.63) | Grad Norm 10.4865(8.5985) | Total Time 0.00(0.00)\n",
      "Iter 4970 | Time 17.6705(17.1337) | Bit/dim 3.6695(3.6854) | Xent 0.1062(0.1352) | Loss 9.1298(9.6994) | Error 0.0322(0.0449) Steps 664(653.11) | Grad Norm 10.0865(8.4368) | Total Time 0.00(0.00)\n",
      "Iter 4980 | Time 17.0988(17.1579) | Bit/dim 3.6479(3.6807) | Xent 0.1112(0.1296) | Loss 8.9951(9.5345) | Error 0.0367(0.0429) Steps 664(654.59) | Grad Norm 6.0660(7.9222) | Total Time 0.00(0.00)\n",
      "Iter 4990 | Time 16.5544(17.2065) | Bit/dim 3.6504(3.6806) | Xent 0.1371(0.1305) | Loss 9.1100(9.4372) | Error 0.0511(0.0438) Steps 640(654.89) | Grad Norm 6.7967(8.0447) | Total Time 0.00(0.00)\n",
      "Iter 5000 | Time 17.5092(17.1550) | Bit/dim 3.6477(3.6788) | Xent 0.1312(0.1332) | Loss 9.1573(9.3573) | Error 0.0467(0.0446) Steps 694(656.37) | Grad Norm 6.1241(8.4027) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 90.7233, Epoch Time 1056.9203(1016.2944), Bit/dim 3.6951(best: 3.7020), Xent 1.6275, Loss 4.5089, Error 0.3285(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 17.3433(17.0875) | Bit/dim 3.7046(3.6815) | Xent 0.1095(0.1320) | Loss 9.2247(10.0081) | Error 0.0411(0.0445) Steps 604(654.91) | Grad Norm 8.0045(9.3782) | Total Time 0.00(0.00)\n",
      "Iter 5020 | Time 17.7080(17.0963) | Bit/dim 3.6839(3.6816) | Xent 0.1012(0.1298) | Loss 9.1752(9.7767) | Error 0.0311(0.0433) Steps 616(654.67) | Grad Norm 10.2933(9.3596) | Total Time 0.00(0.00)\n",
      "Iter 5030 | Time 16.8723(17.0886) | Bit/dim 3.6659(3.6828) | Xent 0.1598(0.1307) | Loss 9.2248(9.6086) | Error 0.0567(0.0437) Steps 640(655.34) | Grad Norm 8.7656(9.1221) | Total Time 0.00(0.00)\n",
      "Iter 5040 | Time 16.8187(17.0528) | Bit/dim 3.6981(3.6832) | Xent 0.0712(0.1260) | Loss 9.1870(9.4864) | Error 0.0267(0.0422) Steps 628(653.38) | Grad Norm 6.2939(8.7870) | Total Time 0.00(0.00)\n",
      "Iter 5050 | Time 16.2879(17.0337) | Bit/dim 3.6508(3.6813) | Xent 0.1226(0.1258) | Loss 9.0758(9.3952) | Error 0.0411(0.0417) Steps 646(655.14) | Grad Norm 7.8714(8.7202) | Total Time 0.00(0.00)\n",
      "Iter 5060 | Time 17.1169(17.1168) | Bit/dim 3.6801(3.6798) | Xent 0.1264(0.1247) | Loss 9.1613(9.3215) | Error 0.0378(0.0412) Steps 670(653.42) | Grad Norm 8.8973(8.5298) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 91.7284, Epoch Time 1051.0522(1017.3372), Bit/dim 3.6902(best: 3.6951), Xent 1.6431, Loss 4.5118, Error 0.3299(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 16.1884(16.9901) | Bit/dim 3.6831(3.6776) | Xent 0.0780(0.1178) | Loss 9.0053(9.8696) | Error 0.0289(0.0387) Steps 634(654.43) | Grad Norm 9.6118(8.3968) | Total Time 0.00(0.00)\n",
      "Iter 5080 | Time 16.5844(16.9235) | Bit/dim 3.6769(3.6761) | Xent 0.0901(0.1115) | Loss 9.1461(9.6645) | Error 0.0356(0.0367) Steps 634(651.36) | Grad Norm 5.3899(8.5900) | Total Time 0.00(0.00)\n",
      "Iter 5090 | Time 17.3044(17.0161) | Bit/dim 3.6803(3.6735) | Xent 0.1412(0.1162) | Loss 9.1110(9.5187) | Error 0.0456(0.0381) Steps 670(653.68) | Grad Norm 8.0804(8.4796) | Total Time 0.00(0.00)\n",
      "Iter 5100 | Time 17.3656(17.0377) | Bit/dim 3.6989(3.6742) | Xent 0.0983(0.1175) | Loss 9.0446(9.4132) | Error 0.0333(0.0390) Steps 640(652.95) | Grad Norm 7.4063(8.1611) | Total Time 0.00(0.00)\n",
      "Iter 5110 | Time 16.9920(17.0071) | Bit/dim 3.6771(3.6767) | Xent 0.1717(0.1189) | Loss 9.1474(9.3389) | Error 0.0567(0.0403) Steps 598(652.58) | Grad Norm 12.8700(8.1930) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 91.0268, Epoch Time 1045.4609(1018.1809), Bit/dim 3.7015(best: 3.6902), Xent 1.5615, Loss 4.4822, Error 0.3291(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 16.5513(17.0302) | Bit/dim 3.6474(3.6799) | Xent 0.1022(0.1216) | Loss 9.0260(10.0144) | Error 0.0289(0.0405) Steps 646(650.90) | Grad Norm 4.9010(8.3123) | Total Time 0.00(0.00)\n",
      "Iter 5130 | Time 18.0990(17.0949) | Bit/dim 3.6908(3.6795) | Xent 0.1254(0.1194) | Loss 9.1913(9.7795) | Error 0.0367(0.0393) Steps 670(650.88) | Grad Norm 5.3277(8.0335) | Total Time 0.00(0.00)\n",
      "Iter 5140 | Time 16.7783(17.0738) | Bit/dim 3.6458(3.6782) | Xent 0.1400(0.1197) | Loss 9.0815(9.6098) | Error 0.0422(0.0396) Steps 646(652.12) | Grad Norm 11.3274(8.2320) | Total Time 0.00(0.00)\n",
      "Iter 5150 | Time 16.8673(17.0788) | Bit/dim 3.6774(3.6795) | Xent 0.1592(0.1218) | Loss 9.0880(9.4819) | Error 0.0456(0.0403) Steps 646(650.40) | Grad Norm 9.0933(8.1950) | Total Time 0.00(0.00)\n",
      "Iter 5160 | Time 16.9079(17.0253) | Bit/dim 3.6821(3.6801) | Xent 0.1193(0.1211) | Loss 9.0290(9.3833) | Error 0.0400(0.0403) Steps 670(651.99) | Grad Norm 6.6969(8.3750) | Total Time 0.00(0.00)\n",
      "Iter 5170 | Time 16.5770(17.0264) | Bit/dim 3.7067(3.6790) | Xent 0.1794(0.1261) | Loss 9.2809(9.3165) | Error 0.0656(0.0418) Steps 652(653.66) | Grad Norm 7.4731(8.3406) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 91.1925, Epoch Time 1049.6509(1019.1250), Bit/dim 3.6961(best: 3.6902), Xent 1.6257, Loss 4.5090, Error 0.3266(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 17.7005(17.0310) | Bit/dim 3.6821(3.6778) | Xent 0.0938(0.1250) | Loss 9.1235(9.8722) | Error 0.0311(0.0413) Steps 682(653.99) | Grad Norm 5.7917(8.4869) | Total Time 0.00(0.00)\n",
      "Iter 5190 | Time 17.5311(16.9826) | Bit/dim 3.6723(3.6758) | Xent 0.1165(0.1219) | Loss 9.2278(9.6691) | Error 0.0433(0.0400) Steps 670(650.52) | Grad Norm 5.8694(8.3535) | Total Time 0.00(0.00)\n",
      "Iter 5200 | Time 16.5243(16.9787) | Bit/dim 3.6461(3.6753) | Xent 0.0805(0.1177) | Loss 8.9473(9.5234) | Error 0.0278(0.0391) Steps 652(652.76) | Grad Norm 5.2368(7.9629) | Total Time 0.00(0.00)\n",
      "Iter 5210 | Time 18.1743(17.1611) | Bit/dim 3.6946(3.6744) | Xent 0.1198(0.1161) | Loss 9.2387(9.4251) | Error 0.0433(0.0387) Steps 682(654.24) | Grad Norm 7.3347(7.7004) | Total Time 0.00(0.00)\n",
      "Iter 5220 | Time 18.0663(17.1841) | Bit/dim 3.6895(3.6780) | Xent 0.1462(0.1167) | Loss 9.1978(9.3493) | Error 0.0411(0.0382) Steps 676(655.79) | Grad Norm 12.9281(8.0131) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 91.4381, Epoch Time 1055.4484(1020.2147), Bit/dim 3.6935(best: 3.6902), Xent 1.5594, Loss 4.4732, Error 0.3271(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 16.9441(17.1789) | Bit/dim 3.6767(3.6758) | Xent 0.1541(0.1253) | Loss 9.1574(9.9989) | Error 0.0489(0.0407) Steps 652(658.40) | Grad Norm 12.1074(8.7806) | Total Time 0.00(0.00)\n",
      "Iter 5240 | Time 17.9078(17.2015) | Bit/dim 3.6286(3.6756) | Xent 0.1190(0.1254) | Loss 9.0773(9.7643) | Error 0.0344(0.0409) Steps 640(658.06) | Grad Norm 10.5419(8.4979) | Total Time 0.00(0.00)\n",
      "Iter 5250 | Time 17.4693(17.1938) | Bit/dim 3.7028(3.6776) | Xent 0.1093(0.1221) | Loss 9.1854(9.5944) | Error 0.0367(0.0396) Steps 682(661.09) | Grad Norm 6.6203(8.4190) | Total Time 0.00(0.00)\n",
      "Iter 5260 | Time 15.9834(17.1430) | Bit/dim 3.6555(3.6759) | Xent 0.0965(0.1181) | Loss 9.1149(9.4683) | Error 0.0278(0.0389) Steps 646(660.32) | Grad Norm 5.3630(8.2816) | Total Time 0.00(0.00)\n",
      "Iter 5270 | Time 16.8633(17.0691) | Bit/dim 3.6781(3.6756) | Xent 0.1081(0.1127) | Loss 9.0667(9.3616) | Error 0.0333(0.0369) Steps 658(658.62) | Grad Norm 4.8493(7.6083) | Total Time 0.00(0.00)\n",
      "Iter 5280 | Time 17.4931(17.1553) | Bit/dim 3.6508(3.6729) | Xent 0.1264(0.1148) | Loss 9.0518(9.2904) | Error 0.0400(0.0377) Steps 676(652.77) | Grad Norm 10.8021(7.6516) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 90.6758, Epoch Time 1053.8749(1021.2245), Bit/dim 3.6866(best: 3.6902), Xent 1.6774, Loss 4.5253, Error 0.3265(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 16.4936(17.0914) | Bit/dim 3.6834(3.6735) | Xent 0.1178(0.1147) | Loss 9.1384(9.8627) | Error 0.0389(0.0370) Steps 616(651.73) | Grad Norm 6.8306(7.4523) | Total Time 0.00(0.00)\n",
      "Iter 5300 | Time 17.2781(17.0435) | Bit/dim 3.6343(3.6721) | Xent 0.0719(0.1123) | Loss 9.0370(9.6608) | Error 0.0256(0.0359) Steps 676(651.52) | Grad Norm 5.2074(7.1449) | Total Time 0.00(0.00)\n",
      "Iter 5310 | Time 16.9145(17.0095) | Bit/dim 3.6582(3.6717) | Xent 0.0925(0.1160) | Loss 9.0776(9.5157) | Error 0.0367(0.0374) Steps 628(649.95) | Grad Norm 6.1897(7.7804) | Total Time 0.00(0.00)\n",
      "Iter 5320 | Time 17.5700(17.0293) | Bit/dim 3.6556(3.6719) | Xent 0.1220(0.1166) | Loss 9.0960(9.4153) | Error 0.0378(0.0376) Steps 634(650.91) | Grad Norm 8.5491(7.8241) | Total Time 0.00(0.00)\n",
      "Iter 5330 | Time 16.3864(16.9201) | Bit/dim 3.6587(3.6699) | Xent 0.1022(0.1168) | Loss 9.0340(9.3247) | Error 0.0367(0.0384) Steps 652(650.71) | Grad Norm 8.6039(7.9648) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 90.8178, Epoch Time 1040.5872(1021.8054), Bit/dim 3.6850(best: 3.6866), Xent 1.6184, Loss 4.4941, Error 0.3215(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 16.3424(16.9173) | Bit/dim 3.6501(3.6720) | Xent 0.1006(0.1167) | Loss 8.9360(9.9912) | Error 0.0344(0.0385) Steps 634(649.21) | Grad Norm 11.1826(7.9844) | Total Time 0.00(0.00)\n",
      "Iter 5350 | Time 17.3877(16.9336) | Bit/dim 3.6446(3.6685) | Xent 0.1169(0.1143) | Loss 9.1563(9.7579) | Error 0.0456(0.0380) Steps 640(648.09) | Grad Norm 10.8815(8.1312) | Total Time 0.00(0.00)\n",
      "Iter 5360 | Time 16.4201(16.9084) | Bit/dim 3.7047(3.6709) | Xent 0.1488(0.1267) | Loss 9.1675(9.6039) | Error 0.0567(0.0422) Steps 652(650.47) | Grad Norm 7.9085(9.0165) | Total Time 0.00(0.00)\n",
      "Iter 5370 | Time 17.1385(16.8899) | Bit/dim 3.6754(3.6744) | Xent 0.1304(0.1273) | Loss 9.1604(9.4860) | Error 0.0500(0.0422) Steps 664(648.09) | Grad Norm 9.7980(8.9347) | Total Time 0.00(0.00)\n",
      "Iter 5380 | Time 17.5045(16.8784) | Bit/dim 3.6849(3.6753) | Xent 0.1257(0.1227) | Loss 9.1122(9.3794) | Error 0.0467(0.0406) Steps 646(648.71) | Grad Norm 10.6473(9.0824) | Total Time 0.00(0.00)\n",
      "Iter 5390 | Time 16.9617(16.8589) | Bit/dim 3.6485(3.6729) | Xent 0.1566(0.1253) | Loss 9.1029(9.3054) | Error 0.0567(0.0411) Steps 664(649.48) | Grad Norm 6.6726(8.8081) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 90.7284, Epoch Time 1046.2523(1022.5388), Bit/dim 3.6813(best: 3.6850), Xent 1.5394, Loss 4.4510, Error 0.3174(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 17.0630(16.9318) | Bit/dim 3.6923(3.6715) | Xent 0.1186(0.1220) | Loss 9.2295(9.8756) | Error 0.0367(0.0395) Steps 682(648.71) | Grad Norm 8.8104(8.5298) | Total Time 0.00(0.00)\n",
      "Iter 5410 | Time 16.9710(16.9563) | Bit/dim 3.6510(3.6740) | Xent 0.0850(0.1177) | Loss 9.1104(9.6736) | Error 0.0333(0.0385) Steps 646(649.25) | Grad Norm 5.6155(7.8938) | Total Time 0.00(0.00)\n",
      "Iter 5420 | Time 17.2071(16.9696) | Bit/dim 3.6612(3.6715) | Xent 0.0700(0.1131) | Loss 9.1277(9.5194) | Error 0.0222(0.0368) Steps 646(648.51) | Grad Norm 5.8192(7.4320) | Total Time 0.00(0.00)\n",
      "Iter 5430 | Time 16.9971(16.9597) | Bit/dim 3.7008(3.6723) | Xent 0.0969(0.1133) | Loss 9.1056(9.4069) | Error 0.0322(0.0369) Steps 682(649.01) | Grad Norm 7.0623(7.6925) | Total Time 0.00(0.00)\n",
      "Iter 5440 | Time 17.0641(16.9576) | Bit/dim 3.6574(3.6685) | Xent 0.1073(0.1113) | Loss 9.1137(9.3198) | Error 0.0378(0.0359) Steps 670(651.79) | Grad Norm 7.1611(7.7408) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 91.2898, Epoch Time 1049.5506(1023.3491), Bit/dim 3.6762(best: 3.6813), Xent 1.6273, Loss 4.4898, Error 0.3239(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 16.4904(16.8644) | Bit/dim 3.6927(3.6688) | Xent 0.1089(0.1086) | Loss 9.1723(9.9715) | Error 0.0300(0.0350) Steps 634(650.92) | Grad Norm 5.7751(7.5388) | Total Time 0.00(0.00)\n",
      "Iter 5460 | Time 17.6926(16.9261) | Bit/dim 3.6468(3.6635) | Xent 0.1036(0.1072) | Loss 9.1176(9.7359) | Error 0.0300(0.0347) Steps 682(651.68) | Grad Norm 7.8978(7.6208) | Total Time 0.00(0.00)\n",
      "Iter 5470 | Time 17.4859(16.9182) | Bit/dim 3.6301(3.6612) | Xent 0.0798(0.1068) | Loss 8.9625(9.5524) | Error 0.0300(0.0348) Steps 646(651.28) | Grad Norm 7.2920(7.4221) | Total Time 0.00(0.00)\n",
      "Iter 5480 | Time 19.5195(17.0193) | Bit/dim 3.6737(3.6625) | Xent 0.1064(0.1050) | Loss 9.1302(9.4249) | Error 0.0322(0.0341) Steps 718(654.16) | Grad Norm 7.7013(7.7646) | Total Time 0.00(0.00)\n",
      "Iter 5490 | Time 17.9888(17.0238) | Bit/dim 3.6784(3.6655) | Xent 0.0875(0.1019) | Loss 9.1345(9.3315) | Error 0.0311(0.0331) Steps 652(654.04) | Grad Norm 5.2004(8.0185) | Total Time 0.00(0.00)\n",
      "Iter 5500 | Time 16.7702(16.9888) | Bit/dim 3.6434(3.6661) | Xent 0.0789(0.0979) | Loss 9.0192(9.2563) | Error 0.0222(0.0316) Steps 664(653.90) | Grad Norm 7.9459(7.5273) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 91.2808, Epoch Time 1045.4173(1024.0112), Bit/dim 3.6789(best: 3.6762), Xent 1.6757, Loss 4.5168, Error 0.3227(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 16.2818(16.9713) | Bit/dim 3.6657(3.6617) | Xent 0.1079(0.0929) | Loss 8.9480(9.7852) | Error 0.0333(0.0298) Steps 640(653.76) | Grad Norm 5.5693(7.0036) | Total Time 0.00(0.00)\n",
      "Iter 5520 | Time 17.0420(16.9899) | Bit/dim 3.6634(3.6604) | Xent 0.0863(0.0927) | Loss 9.0489(9.5938) | Error 0.0244(0.0295) Steps 640(651.87) | Grad Norm 5.4197(6.7160) | Total Time 0.00(0.00)\n",
      "Iter 5530 | Time 16.9785(17.0598) | Bit/dim 3.6633(3.6619) | Xent 0.0863(0.0895) | Loss 9.0328(9.4591) | Error 0.0256(0.0279) Steps 622(652.24) | Grad Norm 6.1108(6.3622) | Total Time 0.00(0.00)\n",
      "Iter 5540 | Time 17.4511(17.0169) | Bit/dim 3.6245(3.6609) | Xent 0.1191(0.0911) | Loss 9.0392(9.3480) | Error 0.0411(0.0287) Steps 658(650.98) | Grad Norm 9.8136(6.7561) | Total Time 0.00(0.00)\n",
      "Iter 5550 | Time 16.1187(17.0035) | Bit/dim 3.6499(3.6614) | Xent 0.1034(0.0951) | Loss 9.0548(9.2739) | Error 0.0311(0.0303) Steps 646(649.93) | Grad Norm 7.1249(6.8259) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 90.7682, Epoch Time 1048.5693(1024.7479), Bit/dim 3.6788(best: 3.6762), Xent 1.7069, Loss 4.5323, Error 0.3353(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 16.8774(16.9620) | Bit/dim 3.6603(3.6631) | Xent 0.1029(0.0992) | Loss 9.0537(9.9538) | Error 0.0289(0.0310) Steps 652(650.49) | Grad Norm 12.3969(7.7366) | Total Time 0.00(0.00)\n",
      "Iter 5570 | Time 15.8618(16.9946) | Bit/dim 3.7051(3.6695) | Xent 0.1459(0.1040) | Loss 9.1543(9.7284) | Error 0.0467(0.0325) Steps 646(650.32) | Grad Norm 15.2558(8.2044) | Total Time 0.00(0.00)\n",
      "Iter 5580 | Time 16.9829(17.0464) | Bit/dim 3.7011(3.6683) | Xent 0.1222(0.1082) | Loss 9.2004(9.5681) | Error 0.0333(0.0344) Steps 688(652.28) | Grad Norm 7.4899(8.7414) | Total Time 0.00(0.00)\n",
      "Iter 5590 | Time 17.2648(17.1754) | Bit/dim 3.6501(3.6668) | Xent 0.1126(0.1085) | Loss 9.1161(9.4501) | Error 0.0344(0.0353) Steps 682(656.06) | Grad Norm 8.5256(9.3457) | Total Time 0.00(0.00)\n",
      "Iter 5600 | Time 16.9182(17.1371) | Bit/dim 3.6740(3.6687) | Xent 0.1075(0.1192) | Loss 9.0925(9.3657) | Error 0.0344(0.0385) Steps 640(654.25) | Grad Norm 8.1904(9.5630) | Total Time 0.00(0.00)\n",
      "Iter 5610 | Time 16.5468(17.0703) | Bit/dim 3.6418(3.6655) | Xent 0.1090(0.1224) | Loss 8.9743(9.2880) | Error 0.0389(0.0398) Steps 652(654.96) | Grad Norm 7.2400(9.0413) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 92.3724, Epoch Time 1056.3008(1025.6945), Bit/dim 3.6836(best: 3.6762), Xent 1.6835, Loss 4.5253, Error 0.3308(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 17.4450(17.0871) | Bit/dim 3.7002(3.6666) | Xent 0.1010(0.1155) | Loss 9.1998(9.8630) | Error 0.0289(0.0374) Steps 646(655.01) | Grad Norm 7.7171(8.5082) | Total Time 0.00(0.00)\n",
      "Iter 5630 | Time 16.4868(17.0983) | Bit/dim 3.6618(3.6673) | Xent 0.0910(0.1090) | Loss 9.0020(9.6478) | Error 0.0267(0.0354) Steps 664(657.93) | Grad Norm 6.5967(8.0484) | Total Time 0.00(0.00)\n",
      "Iter 5640 | Time 17.4155(17.0739) | Bit/dim 3.6564(3.6636) | Xent 0.0687(0.1041) | Loss 8.9266(9.4760) | Error 0.0233(0.0337) Steps 694(659.28) | Grad Norm 6.7660(7.4747) | Total Time 0.00(0.00)\n",
      "Iter 5650 | Time 17.3085(17.0455) | Bit/dim 3.6535(3.6614) | Xent 0.0995(0.0986) | Loss 9.1803(9.3600) | Error 0.0344(0.0319) Steps 664(657.81) | Grad Norm 5.3783(6.9244) | Total Time 0.00(0.00)\n",
      "Iter 5660 | Time 16.8947(16.9643) | Bit/dim 3.6568(3.6607) | Xent 0.1318(0.1015) | Loss 9.1622(9.2801) | Error 0.0422(0.0332) Steps 658(655.28) | Grad Norm 7.8566(7.0536) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 89.8025, Epoch Time 1044.5394(1026.2599), Bit/dim 3.6748(best: 3.6762), Xent 1.6630, Loss 4.5063, Error 0.3291(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 16.7590(16.9990) | Bit/dim 3.6850(3.6607) | Xent 0.1330(0.1012) | Loss 9.2347(9.9334) | Error 0.0444(0.0332) Steps 658(655.18) | Grad Norm 6.7027(6.8986) | Total Time 0.00(0.00)\n",
      "Iter 5680 | Time 17.7597(17.0584) | Bit/dim 3.6386(3.6603) | Xent 0.0653(0.0962) | Loss 8.8849(9.6938) | Error 0.0200(0.0315) Steps 652(653.87) | Grad Norm 10.1393(7.1233) | Total Time 0.00(0.00)\n",
      "Iter 5690 | Time 16.9127(16.9996) | Bit/dim 3.6678(3.6575) | Xent 0.1548(0.0983) | Loss 9.1837(9.5189) | Error 0.0500(0.0324) Steps 664(652.55) | Grad Norm 15.0722(8.0850) | Total Time 0.00(0.00)\n",
      "Iter 5700 | Time 16.8254(16.9920) | Bit/dim 3.6954(3.6601) | Xent 0.0897(0.0968) | Loss 9.1740(9.4064) | Error 0.0267(0.0320) Steps 658(652.28) | Grad Norm 8.7998(7.9431) | Total Time 0.00(0.00)\n",
      "Iter 5710 | Time 16.6935(17.0265) | Bit/dim 3.6577(3.6635) | Xent 0.1234(0.0988) | Loss 9.1387(9.3300) | Error 0.0456(0.0323) Steps 682(654.99) | Grad Norm 12.5962(8.3413) | Total Time 0.00(0.00)\n",
      "Iter 5720 | Time 17.3860(17.0595) | Bit/dim 3.6349(3.6589) | Xent 0.1452(0.1045) | Loss 9.0022(9.2620) | Error 0.0456(0.0336) Steps 622(654.70) | Grad Norm 10.6275(8.5131) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 90.2201, Epoch Time 1049.5667(1026.9591), Bit/dim 3.6790(best: 3.6748), Xent 1.6566, Loss 4.5073, Error 0.3269(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 16.6166(17.0160) | Bit/dim 3.6349(3.6583) | Xent 0.0564(0.0991) | Loss 8.8534(9.8082) | Error 0.0178(0.0317) Steps 646(653.82) | Grad Norm 4.3793(7.7044) | Total Time 0.00(0.00)\n",
      "Iter 5740 | Time 17.0923(17.0177) | Bit/dim 3.6619(3.6569) | Xent 0.0826(0.0931) | Loss 9.0508(9.5942) | Error 0.0244(0.0299) Steps 682(654.04) | Grad Norm 7.1624(7.2709) | Total Time 0.00(0.00)\n",
      "Iter 5750 | Time 16.7831(17.0035) | Bit/dim 3.6968(3.6581) | Xent 0.1227(0.0922) | Loss 9.1660(9.4559) | Error 0.0400(0.0299) Steps 634(653.57) | Grad Norm 8.9525(7.1270) | Total Time 0.00(0.00)\n",
      "Iter 5760 | Time 17.1099(16.9304) | Bit/dim 3.6810(3.6592) | Xent 0.1033(0.0916) | Loss 9.2029(9.3468) | Error 0.0333(0.0296) Steps 664(651.98) | Grad Norm 6.0210(6.8673) | Total Time 0.00(0.00)\n",
      "Iter 5770 | Time 16.4821(16.8746) | Bit/dim 3.6422(3.6557) | Xent 0.0815(0.0939) | Loss 9.0423(9.2721) | Error 0.0278(0.0300) Steps 646(651.16) | Grad Norm 5.1343(6.9306) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 91.4142, Epoch Time 1043.4882(1027.4549), Bit/dim 3.6724(best: 3.6748), Xent 1.7463, Loss 4.5455, Error 0.3248(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 16.7401(16.9466) | Bit/dim 3.6650(3.6563) | Xent 0.0858(0.0916) | Loss 9.2052(9.9485) | Error 0.0344(0.0294) Steps 682(655.13) | Grad Norm 9.7861(6.9334) | Total Time 0.00(0.00)\n",
      "Iter 5790 | Time 17.8577(16.9620) | Bit/dim 3.6885(3.6591) | Xent 0.1234(0.0990) | Loss 9.1639(9.7238) | Error 0.0378(0.0317) Steps 664(656.53) | Grad Norm 13.3505(7.6892) | Total Time 0.00(0.00)\n",
      "Iter 5800 | Time 17.0541(16.9767) | Bit/dim 3.6504(3.6611) | Xent 0.1000(0.1002) | Loss 9.0588(9.5573) | Error 0.0344(0.0320) Steps 664(657.38) | Grad Norm 8.1682(7.9463) | Total Time 0.00(0.00)\n",
      "Iter 5810 | Time 16.4386(16.9767) | Bit/dim 3.6691(3.6606) | Xent 0.0889(0.1008) | Loss 8.9635(9.4295) | Error 0.0289(0.0321) Steps 628(655.22) | Grad Norm 11.8851(8.5487) | Total Time 0.00(0.00)\n",
      "Iter 5820 | Time 17.2094(16.9864) | Bit/dim 3.6678(3.6585) | Xent 0.0991(0.1063) | Loss 9.0811(9.3294) | Error 0.0344(0.0342) Steps 676(654.38) | Grad Norm 5.6021(8.4590) | Total Time 0.00(0.00)\n",
      "Iter 5830 | Time 17.1065(17.0306) | Bit/dim 3.6556(3.6592) | Xent 0.0784(0.1073) | Loss 9.1333(9.2751) | Error 0.0267(0.0347) Steps 658(655.78) | Grad Norm 10.5160(8.6341) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 91.1305, Epoch Time 1051.1938(1028.1671), Bit/dim 3.6817(best: 3.6724), Xent 1.6512, Loss 4.5073, Error 0.3203(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 17.2835(17.0768) | Bit/dim 3.6720(3.6616) | Xent 0.1205(0.1051) | Loss 9.1040(9.8306) | Error 0.0378(0.0344) Steps 694(654.67) | Grad Norm 10.7181(8.7690) | Total Time 0.00(0.00)\n",
      "Iter 5850 | Time 17.2639(17.0160) | Bit/dim 3.6545(3.6599) | Xent 0.1031(0.1075) | Loss 9.1103(9.6348) | Error 0.0322(0.0348) Steps 676(653.80) | Grad Norm 8.0751(8.4603) | Total Time 0.00(0.00)\n",
      "Iter 5860 | Time 17.1057(16.9897) | Bit/dim 3.6661(3.6620) | Xent 0.1186(0.1063) | Loss 9.1231(9.4918) | Error 0.0400(0.0344) Steps 640(653.42) | Grad Norm 13.6627(8.4719) | Total Time 0.00(0.00)\n",
      "Iter 5870 | Time 17.4424(17.0630) | Bit/dim 3.6314(3.6618) | Xent 0.1371(0.1066) | Loss 9.0038(9.3799) | Error 0.0511(0.0347) Steps 646(655.87) | Grad Norm 13.1516(8.8192) | Total Time 0.00(0.00)\n",
      "Iter 5880 | Time 17.2867(17.0783) | Bit/dim 3.6709(3.6609) | Xent 0.1313(0.1151) | Loss 9.0814(9.2987) | Error 0.0456(0.0371) Steps 676(655.67) | Grad Norm 10.0265(8.9651) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 91.6154, Epoch Time 1053.4961(1028.9270), Bit/dim 3.6729(best: 3.6724), Xent 1.8179, Loss 4.5819, Error 0.3517(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 17.9686(17.1374) | Bit/dim 3.6297(3.6595) | Xent 0.1001(0.1151) | Loss 8.9180(9.9453) | Error 0.0300(0.0368) Steps 652(655.94) | Grad Norm 6.8830(8.6730) | Total Time 0.00(0.00)\n",
      "Iter 5900 | Time 17.5056(17.1485) | Bit/dim 3.6545(3.6586) | Xent 0.0893(0.1110) | Loss 9.1405(9.7158) | Error 0.0256(0.0356) Steps 646(656.77) | Grad Norm 8.5269(8.2331) | Total Time 0.00(0.00)\n",
      "Iter 5910 | Time 17.0110(17.1259) | Bit/dim 3.6498(3.6594) | Xent 0.1390(0.1204) | Loss 9.0730(9.5618) | Error 0.0444(0.0383) Steps 640(657.24) | Grad Norm 12.1223(9.3433) | Total Time 0.00(0.00)\n",
      "Iter 5920 | Time 16.8987(17.0618) | Bit/dim 3.6611(3.6632) | Xent 0.1192(0.1249) | Loss 9.1234(9.4491) | Error 0.0344(0.0398) Steps 670(656.05) | Grad Norm 6.6652(9.8274) | Total Time 0.00(0.00)\n",
      "Iter 5930 | Time 17.2044(17.1351) | Bit/dim 3.6183(3.6626) | Xent 0.0777(0.1192) | Loss 9.0493(9.3515) | Error 0.0300(0.0382) Steps 670(658.00) | Grad Norm 4.7052(9.0413) | Total Time 0.00(0.00)\n",
      "Iter 5940 | Time 17.0778(17.1062) | Bit/dim 3.6582(3.6613) | Xent 0.1066(0.1150) | Loss 9.0576(9.2798) | Error 0.0322(0.0368) Steps 676(660.28) | Grad Norm 9.5348(8.4057) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 90.9174, Epoch Time 1054.2368(1029.6863), Bit/dim 3.6616(best: 3.6724), Xent 1.6771, Loss 4.5002, Error 0.3195(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 16.6657(17.0574) | Bit/dim 3.6392(3.6555) | Xent 0.1031(0.1071) | Loss 9.0179(9.8209) | Error 0.0256(0.0341) Steps 640(659.19) | Grad Norm 8.2362(8.2881) | Total Time 0.00(0.00)\n",
      "Iter 5960 | Time 17.2483(17.0938) | Bit/dim 3.6371(3.6538) | Xent 0.1024(0.1035) | Loss 9.0608(9.6082) | Error 0.0322(0.0328) Steps 694(659.50) | Grad Norm 6.3178(7.9014) | Total Time 0.00(0.00)\n",
      "Iter 5970 | Time 16.6445(17.0435) | Bit/dim 3.6607(3.6542) | Xent 0.1047(0.0973) | Loss 9.0777(9.4558) | Error 0.0389(0.0313) Steps 640(657.32) | Grad Norm 9.7560(7.6377) | Total Time 0.00(0.00)\n",
      "Iter 5980 | Time 17.3859(17.0523) | Bit/dim 3.6235(3.6545) | Xent 0.0968(0.0974) | Loss 8.9072(9.3475) | Error 0.0300(0.0311) Steps 670(658.94) | Grad Norm 4.6074(7.5648) | Total Time 0.00(0.00)\n",
      "Iter 5990 | Time 16.6811(17.0269) | Bit/dim 3.6291(3.6544) | Xent 0.0683(0.0940) | Loss 9.0000(9.2704) | Error 0.0144(0.0299) Steps 652(657.51) | Grad Norm 4.6541(7.2824) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 91.3300, Epoch Time 1047.3060(1030.2149), Bit/dim 3.6601(best: 3.6616), Xent 1.6711, Loss 4.4956, Error 0.3227(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 16.4578(16.9997) | Bit/dim 3.6144(3.6519) | Xent 0.0598(0.0887) | Loss 8.9245(9.9059) | Error 0.0189(0.0282) Steps 652(655.13) | Grad Norm 3.9481(6.8251) | Total Time 0.00(0.00)\n",
      "Iter 6010 | Time 17.0713(16.9791) | Bit/dim 3.6199(3.6493) | Xent 0.0516(0.0846) | Loss 8.8460(9.6638) | Error 0.0211(0.0268) Steps 616(651.47) | Grad Norm 4.4848(6.5183) | Total Time 0.00(0.00)\n",
      "Iter 6020 | Time 17.5519(17.0207) | Bit/dim 3.6384(3.6486) | Xent 0.0565(0.0843) | Loss 8.9402(9.4873) | Error 0.0189(0.0268) Steps 652(650.21) | Grad Norm 5.0243(6.8745) | Total Time 0.00(0.00)\n",
      "Iter 6030 | Time 17.3033(17.0145) | Bit/dim 3.6411(3.6448) | Xent 0.0866(0.0817) | Loss 9.0489(9.3514) | Error 0.0311(0.0259) Steps 658(650.15) | Grad Norm 8.7590(6.7319) | Total Time 0.00(0.00)\n",
      "Iter 6040 | Time 18.0172(17.0046) | Bit/dim 3.6867(3.6466) | Xent 0.1309(0.0853) | Loss 9.1738(9.2654) | Error 0.0400(0.0269) Steps 670(651.67) | Grad Norm 8.3050(6.9171) | Total Time 0.00(0.00)\n",
      "Iter 6050 | Time 17.0857(17.0413) | Bit/dim 3.6380(3.6466) | Xent 0.1191(0.0878) | Loss 8.9001(9.1983) | Error 0.0322(0.0278) Steps 622(652.31) | Grad Norm 6.3981(6.6324) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 90.8894, Epoch Time 1050.1795(1030.8138), Bit/dim 3.6642(best: 3.6601), Xent 1.6742, Loss 4.5013, Error 0.3215(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 17.0439(17.0642) | Bit/dim 3.6156(3.6464) | Xent 0.0586(0.0844) | Loss 8.9641(9.7500) | Error 0.0211(0.0271) Steps 604(648.60) | Grad Norm 5.7590(6.4710) | Total Time 0.00(0.00)\n",
      "Iter 6070 | Time 17.6163(17.0550) | Bit/dim 3.6439(3.6470) | Xent 0.0790(0.0820) | Loss 8.9775(9.5642) | Error 0.0200(0.0262) Steps 694(649.71) | Grad Norm 5.5317(6.5308) | Total Time 0.00(0.00)\n",
      "Iter 6080 | Time 16.3778(17.0128) | Bit/dim 3.6642(3.6495) | Xent 0.1249(0.0825) | Loss 9.0517(9.4358) | Error 0.0300(0.0261) Steps 634(649.32) | Grad Norm 12.8936(6.9871) | Total Time 0.00(0.00)\n",
      "Iter 6090 | Time 17.5101(17.0244) | Bit/dim 3.6503(3.6497) | Xent 0.1345(0.0857) | Loss 9.1287(9.3338) | Error 0.0467(0.0274) Steps 664(648.00) | Grad Norm 13.7880(7.6391) | Total Time 0.00(0.00)\n",
      "Iter 6100 | Time 16.7418(16.9830) | Bit/dim 3.6854(3.6535) | Xent 0.1231(0.1031) | Loss 9.1854(9.2828) | Error 0.0378(0.0322) Steps 664(648.84) | Grad Norm 9.2695(8.2650) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 90.2580, Epoch Time 1049.9491(1031.3879), Bit/dim 3.6779(best: 3.6601), Xent 1.5901, Loss 4.4729, Error 0.3200(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 16.6174(17.0173) | Bit/dim 3.6544(3.6578) | Xent 0.0958(0.1070) | Loss 9.0688(9.9443) | Error 0.0289(0.0337) Steps 646(648.45) | Grad Norm 6.5035(8.7391) | Total Time 0.00(0.00)\n",
      "Iter 6120 | Time 16.7152(17.0583) | Bit/dim 3.6239(3.6599) | Xent 0.0833(0.1065) | Loss 9.0403(9.7240) | Error 0.0233(0.0337) Steps 652(652.41) | Grad Norm 7.6776(9.0779) | Total Time 0.00(0.00)\n",
      "Iter 6130 | Time 17.8022(17.1088) | Bit/dim 3.6375(3.6574) | Xent 0.1502(0.1117) | Loss 9.0639(9.5511) | Error 0.0433(0.0349) Steps 640(652.53) | Grad Norm 9.8856(9.0965) | Total Time 0.00(0.00)\n",
      "Iter 6140 | Time 16.9173(17.0952) | Bit/dim 3.6530(3.6567) | Xent 0.1279(0.1121) | Loss 9.1219(9.4318) | Error 0.0400(0.0349) Steps 670(654.48) | Grad Norm 8.0354(8.5363) | Total Time 0.00(0.00)\n",
      "Iter 6150 | Time 16.8414(17.1153) | Bit/dim 3.6502(3.6513) | Xent 0.0851(0.1091) | Loss 9.1048(9.3301) | Error 0.0300(0.0340) Steps 658(656.48) | Grad Norm 5.8475(8.0187) | Total Time 0.00(0.00)\n",
      "Iter 6160 | Time 17.2329(17.1613) | Bit/dim 3.6627(3.6491) | Xent 0.0781(0.1123) | Loss 9.0380(9.2568) | Error 0.0267(0.0355) Steps 646(656.14) | Grad Norm 5.6060(8.0440) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 91.1435, Epoch Time 1056.0268(1032.1270), Bit/dim 3.6745(best: 3.6601), Xent 1.5662, Loss 4.4576, Error 0.3105(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 16.4593(17.2144) | Bit/dim 3.6538(3.6487) | Xent 0.0924(0.1079) | Loss 9.0388(9.8293) | Error 0.0356(0.0343) Steps 658(658.98) | Grad Norm 14.4583(8.4950) | Total Time 0.00(0.00)\n",
      "Iter 6180 | Time 16.5156(17.2389) | Bit/dim 3.6430(3.6465) | Xent 0.0818(0.1020) | Loss 9.0444(9.6194) | Error 0.0256(0.0328) Steps 652(659.97) | Grad Norm 5.2492(8.1119) | Total Time 0.00(0.00)\n",
      "Iter 6190 | Time 18.0812(17.2230) | Bit/dim 3.6402(3.6476) | Xent 0.1016(0.0969) | Loss 9.1460(9.4669) | Error 0.0244(0.0311) Steps 658(661.12) | Grad Norm 5.4319(7.5839) | Total Time 0.00(0.00)\n",
      "Iter 6200 | Time 17.2249(17.1928) | Bit/dim 3.6283(3.6473) | Xent 0.0668(0.0913) | Loss 9.0062(9.3422) | Error 0.0222(0.0297) Steps 616(657.08) | Grad Norm 5.1339(6.9853) | Total Time 0.00(0.00)\n",
      "Iter 6210 | Time 17.5306(17.1661) | Bit/dim 3.6733(3.6466) | Xent 0.0804(0.0851) | Loss 9.0585(9.2514) | Error 0.0244(0.0277) Steps 634(659.01) | Grad Norm 8.0299(6.9079) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 91.4812, Epoch Time 1061.4123(1033.0056), Bit/dim 3.6620(best: 3.6601), Xent 1.8768, Loss 4.6004, Error 0.3352(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 17.0587(17.1717) | Bit/dim 3.6322(3.6454) | Xent 0.0786(0.0852) | Loss 8.9523(9.9279) | Error 0.0256(0.0270) Steps 634(657.70) | Grad Norm 8.1951(7.1109) | Total Time 0.00(0.00)\n",
      "Iter 6230 | Time 17.5981(17.1780) | Bit/dim 3.6425(3.6448) | Xent 0.0584(0.0837) | Loss 8.8537(9.6844) | Error 0.0189(0.0267) Steps 670(657.37) | Grad Norm 4.2633(6.9939) | Total Time 0.00(0.00)\n",
      "Iter 6240 | Time 17.7145(17.2280) | Bit/dim 3.6773(3.6451) | Xent 0.1659(0.0873) | Loss 9.2094(9.5145) | Error 0.0600(0.0284) Steps 682(660.36) | Grad Norm 16.7361(7.6240) | Total Time 0.00(0.00)\n",
      "Iter 6250 | Time 17.0357(17.2470) | Bit/dim 3.6621(3.6508) | Xent 0.1729(0.1063) | Loss 9.1338(9.4171) | Error 0.0633(0.0336) Steps 664(660.99) | Grad Norm 11.1242(8.8906) | Total Time 0.00(0.00)\n",
      "Iter 6260 | Time 17.1107(17.2013) | Bit/dim 3.6555(3.6523) | Xent 0.0832(0.1073) | Loss 9.0038(9.3275) | Error 0.0278(0.0339) Steps 658(661.44) | Grad Norm 4.2184(8.2526) | Total Time 0.00(0.00)\n",
      "Iter 6270 | Time 17.8152(17.1492) | Bit/dim 3.6567(3.6529) | Xent 0.0898(0.1018) | Loss 9.0666(9.2518) | Error 0.0333(0.0327) Steps 676(659.55) | Grad Norm 6.2895(7.7264) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 90.9825, Epoch Time 1057.0048(1033.7256), Bit/dim 3.6668(best: 3.6601), Xent 1.7063, Loss 4.5200, Error 0.3224(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 17.0223(17.1196) | Bit/dim 3.6512(3.6535) | Xent 0.0627(0.0967) | Loss 8.9220(9.8001) | Error 0.0211(0.0310) Steps 634(657.25) | Grad Norm 7.5676(7.3802) | Total Time 0.00(0.00)\n",
      "Iter 6290 | Time 17.0310(17.1488) | Bit/dim 3.6484(3.6527) | Xent 0.0663(0.0884) | Loss 9.0625(9.6045) | Error 0.0122(0.0283) Steps 640(657.67) | Grad Norm 3.7785(6.9941) | Total Time 0.00(0.00)\n",
      "Iter 6300 | Time 17.4596(17.1849) | Bit/dim 3.5873(3.6484) | Xent 0.1002(0.0849) | Loss 8.8417(9.4469) | Error 0.0322(0.0273) Steps 664(659.45) | Grad Norm 7.0090(6.5878) | Total Time 0.00(0.00)\n",
      "Iter 6310 | Time 16.7711(17.2177) | Bit/dim 3.6493(3.6442) | Xent 0.0719(0.0819) | Loss 9.0535(9.3362) | Error 0.0233(0.0263) Steps 670(660.71) | Grad Norm 6.1425(6.6647) | Total Time 0.00(0.00)\n",
      "Iter 6320 | Time 18.0166(17.2378) | Bit/dim 3.6242(3.6413) | Xent 0.0855(0.0797) | Loss 9.0767(9.2453) | Error 0.0244(0.0253) Steps 688(661.60) | Grad Norm 5.5892(6.6748) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 90.4006, Epoch Time 1059.1472(1034.4882), Bit/dim 3.6619(best: 3.6601), Xent 1.7906, Loss 4.5572, Error 0.3301(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 17.1854(17.2505) | Bit/dim 3.6444(3.6400) | Xent 0.0758(0.0828) | Loss 8.9587(9.9202) | Error 0.0256(0.0263) Steps 676(661.31) | Grad Norm 6.6545(6.8145) | Total Time 0.00(0.00)\n",
      "Iter 6340 | Time 16.3197(17.1744) | Bit/dim 3.6689(3.6431) | Xent 0.0954(0.0822) | Loss 9.0936(9.6790) | Error 0.0289(0.0266) Steps 640(658.93) | Grad Norm 6.2045(6.6544) | Total Time 0.00(0.00)\n",
      "Iter 6350 | Time 16.3314(17.0860) | Bit/dim 3.6457(3.6418) | Xent 0.0620(0.0833) | Loss 8.9254(9.5068) | Error 0.0233(0.0268) Steps 640(657.09) | Grad Norm 9.9385(6.8423) | Total Time 0.00(0.00)\n",
      "Iter 6360 | Time 18.4375(17.1246) | Bit/dim 3.6377(3.6430) | Xent 0.1158(0.0844) | Loss 9.0588(9.3892) | Error 0.0356(0.0268) Steps 664(659.15) | Grad Norm 9.6309(7.1929) | Total Time 0.00(0.00)\n",
      "Iter 6370 | Time 16.7928(17.0596) | Bit/dim 3.6802(3.6424) | Xent 0.0653(0.0857) | Loss 9.0896(9.2823) | Error 0.0211(0.0272) Steps 640(656.54) | Grad Norm 8.6242(7.1425) | Total Time 0.00(0.00)\n",
      "Iter 6380 | Time 17.0582(17.0938) | Bit/dim 3.6399(3.6457) | Xent 0.2246(0.0971) | Loss 9.0803(9.2353) | Error 0.0600(0.0301) Steps 664(658.27) | Grad Norm 12.1584(8.1102) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 92.4984, Epoch Time 1053.0164(1035.0441), Bit/dim 3.6621(best: 3.6601), Xent 1.8073, Loss 4.5657, Error 0.3317(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 17.8589(17.1367) | Bit/dim 3.6283(3.6460) | Xent 0.0805(0.0962) | Loss 9.0429(9.8192) | Error 0.0267(0.0302) Steps 670(659.38) | Grad Norm 6.9471(7.7453) | Total Time 0.00(0.00)\n",
      "Iter 6400 | Time 16.6465(17.1761) | Bit/dim 3.6216(3.6449) | Xent 0.1094(0.0924) | Loss 8.9052(9.6015) | Error 0.0411(0.0290) Steps 646(659.32) | Grad Norm 11.4846(7.4233) | Total Time 0.00(0.00)\n",
      "Iter 6410 | Time 16.6851(17.1571) | Bit/dim 3.6218(3.6444) | Xent 0.0750(0.0876) | Loss 8.7689(9.4374) | Error 0.0289(0.0275) Steps 670(658.87) | Grad Norm 8.4635(7.1976) | Total Time 0.00(0.00)\n",
      "Iter 6420 | Time 16.7087(17.1366) | Bit/dim 3.6575(3.6413) | Xent 0.0775(0.0850) | Loss 9.1072(9.3338) | Error 0.0233(0.0265) Steps 664(659.44) | Grad Norm 7.5159(7.0945) | Total Time 0.00(0.00)\n",
      "Iter 6430 | Time 17.6732(17.1486) | Bit/dim 3.6734(3.6434) | Xent 0.0487(0.0848) | Loss 9.0945(9.2562) | Error 0.0178(0.0266) Steps 634(660.06) | Grad Norm 7.3975(7.2913) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 93.0300, Epoch Time 1058.7617(1035.7556), Bit/dim 3.6570(best: 3.6601), Xent 1.8256, Loss 4.5698, Error 0.3314(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 16.7748(17.1223) | Bit/dim 3.6493(3.6427) | Xent 0.0842(0.0856) | Loss 8.9841(9.9257) | Error 0.0289(0.0271) Steps 604(655.44) | Grad Norm 6.3419(7.4490) | Total Time 0.00(0.00)\n",
      "Iter 6450 | Time 17.4192(17.0730) | Bit/dim 3.6442(3.6450) | Xent 0.0804(0.0848) | Loss 9.0876(9.6965) | Error 0.0222(0.0266) Steps 688(658.85) | Grad Norm 7.3700(7.7141) | Total Time 0.00(0.00)\n",
      "Iter 6460 | Time 17.3641(17.0823) | Bit/dim 3.6331(3.6451) | Xent 0.0740(0.0810) | Loss 8.9935(9.5129) | Error 0.0233(0.0254) Steps 670(658.10) | Grad Norm 4.9499(7.2281) | Total Time 0.00(0.00)\n",
      "Iter 6470 | Time 17.5376(17.1028) | Bit/dim 3.6885(3.6436) | Xent 0.0744(0.0786) | Loss 9.1079(9.3760) | Error 0.0244(0.0248) Steps 676(659.53) | Grad Norm 9.8264(6.9028) | Total Time 0.00(0.00)\n",
      "Iter 6480 | Time 18.2716(17.1483) | Bit/dim 3.6471(3.6410) | Xent 0.0657(0.0799) | Loss 9.0878(9.2788) | Error 0.0233(0.0255) Steps 670(661.49) | Grad Norm 6.5551(7.2861) | Total Time 0.00(0.00)\n",
      "Iter 6490 | Time 17.9139(17.1767) | Bit/dim 3.6490(3.6396) | Xent 0.0903(0.0836) | Loss 8.9893(9.2071) | Error 0.0278(0.0270) Steps 670(660.91) | Grad Norm 4.7809(7.8765) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 91.4371, Epoch Time 1058.5140(1036.4383), Bit/dim 3.6704(best: 3.6570), Xent 1.7134, Loss 4.5271, Error 0.3260(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 17.1971(17.1067) | Bit/dim 3.6472(3.6383) | Xent 0.0874(0.0807) | Loss 8.9118(9.7627) | Error 0.0267(0.0258) Steps 676(661.50) | Grad Norm 6.4430(7.7548) | Total Time 0.00(0.00)\n",
      "Iter 6510 | Time 17.0550(17.0976) | Bit/dim 3.6348(3.6384) | Xent 0.1057(0.0825) | Loss 9.0371(9.5659) | Error 0.0256(0.0256) Steps 646(659.98) | Grad Norm 9.1929(7.9794) | Total Time 0.00(0.00)\n",
      "Iter 6520 | Time 17.1702(17.0446) | Bit/dim 3.6224(3.6351) | Xent 0.0748(0.0792) | Loss 9.0285(9.4109) | Error 0.0233(0.0247) Steps 676(660.81) | Grad Norm 7.5268(7.4245) | Total Time 0.00(0.00)\n",
      "Iter 6530 | Time 17.3065(17.0788) | Bit/dim 3.6118(3.6362) | Xent 0.0675(0.0771) | Loss 8.9268(9.3010) | Error 0.0200(0.0237) Steps 628(659.92) | Grad Norm 9.8359(7.3012) | Total Time 0.00(0.00)\n",
      "Iter 6540 | Time 17.5007(17.0640) | Bit/dim 3.6458(3.6371) | Xent 0.0666(0.0728) | Loss 8.9468(9.2155) | Error 0.0244(0.0224) Steps 640(659.33) | Grad Norm 5.7027(6.9350) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 91.2958, Epoch Time 1052.1769(1036.9105), Bit/dim 3.6528(best: 3.6570), Xent 1.7717, Loss 4.5387, Error 0.3198(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 17.0516(17.0429) | Bit/dim 3.6861(3.6379) | Xent 0.0491(0.0697) | Loss 9.0890(9.8912) | Error 0.0189(0.0215) Steps 652(656.45) | Grad Norm 4.3508(6.5046) | Total Time 0.00(0.00)\n",
      "Iter 6560 | Time 17.0114(17.0267) | Bit/dim 3.6565(3.6359) | Xent 0.0625(0.0686) | Loss 8.9759(9.6496) | Error 0.0200(0.0216) Steps 634(655.64) | Grad Norm 5.7356(6.8167) | Total Time 0.00(0.00)\n",
      "Iter 6570 | Time 16.7579(16.9872) | Bit/dim 3.6270(3.6333) | Xent 0.1228(0.0720) | Loss 9.0088(9.4730) | Error 0.0411(0.0227) Steps 664(655.82) | Grad Norm 7.8835(6.6381) | Total Time 0.00(0.00)\n",
      "Iter 6580 | Time 16.2538(17.0171) | Bit/dim 3.6247(3.6348) | Xent 0.0624(0.0768) | Loss 8.8688(9.3573) | Error 0.0222(0.0243) Steps 646(656.37) | Grad Norm 6.2550(6.7598) | Total Time 0.00(0.00)\n",
      "Iter 6590 | Time 16.5262(17.0306) | Bit/dim 3.6075(3.6334) | Xent 0.0387(0.0740) | Loss 8.9220(9.2594) | Error 0.0122(0.0237) Steps 664(660.02) | Grad Norm 5.1091(6.5801) | Total Time 0.00(0.00)\n",
      "Iter 6600 | Time 17.2332(17.0762) | Bit/dim 3.6965(3.6358) | Xent 0.1485(0.0757) | Loss 9.1896(9.1971) | Error 0.0478(0.0242) Steps 622(659.36) | Grad Norm 10.9949(6.4273) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 91.6822, Epoch Time 1048.4862(1037.2578), Bit/dim 3.6529(best: 3.6528), Xent 1.7490, Loss 4.5275, Error 0.3197(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 17.0458(17.0196) | Bit/dim 3.6485(3.6376) | Xent 0.0625(0.0781) | Loss 9.0573(9.7700) | Error 0.0178(0.0254) Steps 646(658.35) | Grad Norm 8.6217(7.5043) | Total Time 0.00(0.00)\n",
      "Iter 6620 | Time 16.6050(17.0482) | Bit/dim 3.6637(3.6411) | Xent 0.0413(0.0800) | Loss 8.9580(9.5778) | Error 0.0122(0.0258) Steps 670(657.06) | Grad Norm 6.9460(7.8151) | Total Time 0.00(0.00)\n",
      "Iter 6630 | Time 17.3977(17.1186) | Bit/dim 3.6795(3.6412) | Xent 0.1164(0.1025) | Loss 9.1220(9.4583) | Error 0.0322(0.0319) Steps 634(658.45) | Grad Norm 5.9023(8.3316) | Total Time 0.00(0.00)\n",
      "Iter 6640 | Time 17.9434(17.1687) | Bit/dim 3.6454(3.6418) | Xent 0.1054(0.1044) | Loss 9.1086(9.3508) | Error 0.0356(0.0325) Steps 700(657.60) | Grad Norm 7.8842(8.0043) | Total Time 0.00(0.00)\n",
      "Iter 6650 | Time 18.0868(17.2444) | Bit/dim 3.6603(3.6426) | Xent 0.1430(0.1015) | Loss 9.1033(9.2720) | Error 0.0456(0.0317) Steps 628(655.85) | Grad Norm 15.4454(8.1408) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 89.6032, Epoch Time 1059.0326(1037.9110), Bit/dim 3.6637(best: 3.6528), Xent 1.8071, Loss 4.5673, Error 0.3424(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 17.2135(17.2200) | Bit/dim 3.6975(3.6451) | Xent 0.0957(0.1078) | Loss 9.1904(9.9429) | Error 0.0289(0.0339) Steps 658(655.55) | Grad Norm 6.4144(8.1670) | Total Time 0.00(0.00)\n",
      "Iter 6670 | Time 17.7636(17.1913) | Bit/dim 3.6598(3.6440) | Xent 0.0799(0.1039) | Loss 9.1316(9.7011) | Error 0.0278(0.0332) Steps 652(654.51) | Grad Norm 6.9832(7.6150) | Total Time 0.00(0.00)\n",
      "Iter 6680 | Time 17.1699(17.2432) | Bit/dim 3.6280(3.6400) | Xent 0.0792(0.0986) | Loss 8.8226(9.4990) | Error 0.0278(0.0313) Steps 616(651.07) | Grad Norm 8.8660(7.5709) | Total Time 0.00(0.00)\n",
      "Iter 6690 | Time 16.6003(17.1962) | Bit/dim 3.6312(3.6409) | Xent 0.0579(0.0916) | Loss 8.8728(9.3609) | Error 0.0189(0.0291) Steps 658(653.09) | Grad Norm 4.4741(7.1713) | Total Time 0.00(0.00)\n",
      "Iter 6700 | Time 17.8850(17.1569) | Bit/dim 3.6469(3.6379) | Xent 0.0956(0.0862) | Loss 9.1799(9.2669) | Error 0.0311(0.0273) Steps 640(653.30) | Grad Norm 5.6146(6.5721) | Total Time 0.00(0.00)\n",
      "Iter 6710 | Time 16.7848(17.1929) | Bit/dim 3.6194(3.6367) | Xent 0.0659(0.0799) | Loss 8.8979(9.1904) | Error 0.0222(0.0252) Steps 634(652.60) | Grad Norm 5.1008(6.2752) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 90.6648, Epoch Time 1055.5642(1038.4406), Bit/dim 3.6414(best: 3.6528), Xent 1.7974, Loss 4.5401, Error 0.3255(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 17.0120(17.0991) | Bit/dim 3.6470(3.6328) | Xent 0.1001(0.0780) | Loss 8.9625(9.7420) | Error 0.0278(0.0246) Steps 634(652.68) | Grad Norm 6.1832(5.9334) | Total Time 0.00(0.00)\n",
      "Iter 6730 | Time 17.4736(17.0745) | Bit/dim 3.6402(3.6343) | Xent 0.0687(0.0786) | Loss 9.1365(9.5469) | Error 0.0156(0.0245) Steps 628(649.91) | Grad Norm 6.4473(6.2932) | Total Time 0.00(0.00)\n",
      "Iter 6740 | Time 17.2067(17.0404) | Bit/dim 3.6336(3.6339) | Xent 0.0753(0.0781) | Loss 8.8848(9.3857) | Error 0.0167(0.0236) Steps 640(649.30) | Grad Norm 5.7299(6.3135) | Total Time 0.00(0.00)\n",
      "Iter 6750 | Time 17.9639(17.1268) | Bit/dim 3.6345(3.6360) | Xent 0.0629(0.0764) | Loss 9.0586(9.2848) | Error 0.0244(0.0234) Steps 658(649.69) | Grad Norm 4.5142(6.1343) | Total Time 0.00(0.00)\n",
      "Iter 6760 | Time 17.5731(17.2318) | Bit/dim 3.6414(3.6373) | Xent 0.0901(0.0763) | Loss 9.0744(9.2168) | Error 0.0244(0.0231) Steps 688(655.30) | Grad Norm 9.8053(6.2266) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 92.4606, Epoch Time 1057.4770(1039.0117), Bit/dim 3.6438(best: 3.6414), Xent 1.7176, Loss 4.5026, Error 0.3242(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 16.8431(17.1773) | Bit/dim 3.6282(3.6340) | Xent 0.0870(0.0742) | Loss 9.0597(9.8817) | Error 0.0267(0.0226) Steps 646(656.47) | Grad Norm 6.4788(6.2537) | Total Time 0.00(0.00)\n",
      "Iter 6780 | Time 17.8434(17.2202) | Bit/dim 3.6638(3.6344) | Xent 0.0589(0.0759) | Loss 9.0414(9.6494) | Error 0.0200(0.0234) Steps 688(656.34) | Grad Norm 10.3238(6.9091) | Total Time 0.00(0.00)\n",
      "Iter 6790 | Time 16.5112(17.1393) | Bit/dim 3.6141(3.6333) | Xent 0.1044(0.0748) | Loss 8.9217(9.4574) | Error 0.0278(0.0229) Steps 670(654.69) | Grad Norm 8.9605(7.0457) | Total Time 0.00(0.00)\n",
      "Iter 6800 | Time 18.1070(17.1049) | Bit/dim 3.6310(3.6320) | Xent 0.0620(0.0729) | Loss 9.0254(9.3255) | Error 0.0167(0.0219) Steps 700(655.62) | Grad Norm 4.5194(6.6627) | Total Time 0.00(0.00)\n",
      "Iter 6810 | Time 17.3883(17.1075) | Bit/dim 3.6897(3.6322) | Xent 0.0855(0.0729) | Loss 9.0707(9.2317) | Error 0.0322(0.0220) Steps 670(656.62) | Grad Norm 10.2840(6.7379) | Total Time 0.00(0.00)\n",
      "Iter 6820 | Time 17.2857(17.1076) | Bit/dim 3.6430(3.6342) | Xent 0.0823(0.0759) | Loss 9.0018(9.1741) | Error 0.0267(0.0231) Steps 652(657.25) | Grad Norm 6.3939(6.6539) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 89.7388, Epoch Time 1052.2793(1039.4097), Bit/dim 3.6499(best: 3.6414), Xent 1.7364, Loss 4.5182, Error 0.3228(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 16.3987(17.1210) | Bit/dim 3.6444(3.6327) | Xent 0.0686(0.0748) | Loss 8.9385(9.7354) | Error 0.0167(0.0230) Steps 646(654.69) | Grad Norm 9.6333(6.9313) | Total Time 0.00(0.00)\n",
      "Iter 6840 | Time 17.5069(17.1708) | Bit/dim 3.6552(3.6358) | Xent 0.0617(0.0748) | Loss 9.0031(9.5516) | Error 0.0200(0.0234) Steps 652(654.73) | Grad Norm 6.0409(6.9319) | Total Time 0.00(0.00)\n",
      "Iter 6850 | Time 17.0144(17.2110) | Bit/dim 3.5951(3.6323) | Xent 0.0952(0.0764) | Loss 9.0108(9.4054) | Error 0.0289(0.0234) Steps 646(653.29) | Grad Norm 9.1466(7.0332) | Total Time 0.00(0.00)\n",
      "Iter 6860 | Time 18.0561(17.2418) | Bit/dim 3.6153(3.6317) | Xent 0.1100(0.0805) | Loss 8.9360(9.2962) | Error 0.0278(0.0249) Steps 700(657.78) | Grad Norm 8.6103(7.1908) | Total Time 0.00(0.00)\n",
      "Iter 6870 | Time 16.5383(17.1262) | Bit/dim 3.6360(3.6345) | Xent 0.0733(0.0814) | Loss 8.9707(9.2224) | Error 0.0289(0.0256) Steps 646(655.26) | Grad Norm 6.1868(7.0154) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 92.1366, Epoch Time 1056.1348(1039.9115), Bit/dim 3.6472(best: 3.6414), Xent 1.7074, Loss 4.5009, Error 0.3196(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 16.5153(17.0979) | Bit/dim 3.6552(3.6342) | Xent 0.0920(0.0809) | Loss 9.0770(9.8865) | Error 0.0311(0.0258) Steps 664(655.06) | Grad Norm 5.3834(6.6665) | Total Time 0.00(0.00)\n",
      "Iter 6890 | Time 17.6350(17.1457) | Bit/dim 3.6258(3.6331) | Xent 0.0759(0.0816) | Loss 8.8933(9.6508) | Error 0.0244(0.0260) Steps 610(653.54) | Grad Norm 8.7878(6.5302) | Total Time 0.00(0.00)\n",
      "Iter 6900 | Time 17.5056(17.1572) | Bit/dim 3.6537(3.6313) | Xent 0.0726(0.0805) | Loss 9.1367(9.4814) | Error 0.0244(0.0255) Steps 658(655.19) | Grad Norm 6.2746(6.5299) | Total Time 0.00(0.00)\n",
      "Iter 6910 | Time 16.7540(17.1345) | Bit/dim 3.6208(3.6312) | Xent 0.0349(0.0739) | Loss 8.7409(9.3425) | Error 0.0111(0.0230) Steps 646(655.33) | Grad Norm 5.2092(6.1232) | Total Time 0.00(0.00)\n",
      "Iter 6920 | Time 17.3395(17.1289) | Bit/dim 3.6405(3.6313) | Xent 0.0803(0.0780) | Loss 9.0872(9.2616) | Error 0.0222(0.0243) Steps 664(658.79) | Grad Norm 6.8439(6.7292) | Total Time 0.00(0.00)\n",
      "Iter 6930 | Time 18.0229(17.1960) | Bit/dim 3.6357(3.6314) | Xent 0.0678(0.0762) | Loss 9.0224(9.1884) | Error 0.0222(0.0241) Steps 706(663.98) | Grad Norm 7.9930(7.0372) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 90.9978, Epoch Time 1057.1325(1040.4281), Bit/dim 3.6544(best: 3.6414), Xent 1.8148, Loss 4.5618, Error 0.3212(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 16.3020(17.1616) | Bit/dim 3.6061(3.6283) | Xent 0.0978(0.0743) | Loss 8.8756(9.7418) | Error 0.0311(0.0236) Steps 664(664.88) | Grad Norm 7.6492(6.7709) | Total Time 0.00(0.00)\n",
      "Iter 6950 | Time 16.1102(17.1406) | Bit/dim 3.6086(3.6301) | Xent 0.0974(0.0733) | Loss 9.0010(9.5527) | Error 0.0256(0.0229) Steps 652(660.65) | Grad Norm 8.0351(6.8005) | Total Time 0.00(0.00)\n",
      "Iter 6960 | Time 16.7252(17.1382) | Bit/dim 3.6262(3.6276) | Xent 0.0443(0.0712) | Loss 8.9115(9.3899) | Error 0.0156(0.0226) Steps 640(659.97) | Grad Norm 4.4164(6.3336) | Total Time 0.00(0.00)\n",
      "Iter 6970 | Time 17.2566(17.1558) | Bit/dim 3.6635(3.6274) | Xent 0.0495(0.0695) | Loss 9.1091(9.2717) | Error 0.0156(0.0222) Steps 640(657.40) | Grad Norm 6.9791(6.4045) | Total Time 0.00(0.00)\n",
      "Iter 6980 | Time 16.6664(17.1431) | Bit/dim 3.6261(3.6285) | Xent 0.0714(0.0667) | Loss 8.9664(9.1951) | Error 0.0222(0.0210) Steps 646(658.88) | Grad Norm 5.2409(6.2603) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 90.7983, Epoch Time 1054.4423(1040.8485), Bit/dim 3.6421(best: 3.6414), Xent 1.8371, Loss 4.5607, Error 0.3265(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 17.1560(17.1737) | Bit/dim 3.6621(3.6287) | Xent 0.0562(0.0641) | Loss 9.1427(9.8515) | Error 0.0167(0.0203) Steps 682(658.79) | Grad Norm 7.2768(6.1051) | Total Time 0.00(0.00)\n",
      "Iter 7000 | Time 16.7730(17.1834) | Bit/dim 3.6366(3.6293) | Xent 0.0605(0.0667) | Loss 8.8677(9.6234) | Error 0.0189(0.0215) Steps 664(659.86) | Grad Norm 5.6907(6.3451) | Total Time 0.00(0.00)\n",
      "Iter 7010 | Time 16.4188(17.1726) | Bit/dim 3.6929(3.6300) | Xent 0.0459(0.0681) | Loss 9.0711(9.4512) | Error 0.0144(0.0214) Steps 664(658.28) | Grad Norm 8.6046(6.7213) | Total Time 0.00(0.00)\n",
      "Iter 7020 | Time 17.7490(17.2390) | Bit/dim 3.6284(3.6262) | Xent 0.0601(0.0723) | Loss 8.9400(9.3296) | Error 0.0211(0.0228) Steps 664(662.93) | Grad Norm 4.7628(6.6172) | Total Time 0.00(0.00)\n",
      "Iter 7030 | Time 16.8769(17.1864) | Bit/dim 3.6392(3.6268) | Xent 0.0655(0.0716) | Loss 8.8751(9.2189) | Error 0.0167(0.0222) Steps 652(662.51) | Grad Norm 5.2837(6.4009) | Total Time 0.00(0.00)\n",
      "Iter 7040 | Time 16.8588(17.1911) | Bit/dim 3.6380(3.6249) | Xent 0.0772(0.0692) | Loss 8.8996(9.1509) | Error 0.0189(0.0213) Steps 664(664.61) | Grad Norm 5.8688(6.1446) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 91.0113, Epoch Time 1059.9899(1041.4228), Bit/dim 3.6381(best: 3.6414), Xent 1.7746, Loss 4.5254, Error 0.3235(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 16.1473(17.1170) | Bit/dim 3.6232(3.6250) | Xent 0.0404(0.0648) | Loss 8.8756(9.7208) | Error 0.0144(0.0200) Steps 622(661.86) | Grad Norm 4.8503(6.0954) | Total Time 0.00(0.00)\n",
      "Iter 7060 | Time 16.7836(17.1118) | Bit/dim 3.6441(3.6235) | Xent 0.0802(0.0667) | Loss 9.0837(9.5247) | Error 0.0267(0.0206) Steps 664(662.63) | Grad Norm 12.2038(6.4609) | Total Time 0.00(0.00)\n",
      "Iter 7070 | Time 17.1466(17.1154) | Bit/dim 3.5970(3.6221) | Xent 0.0334(0.0631) | Loss 8.8230(9.3626) | Error 0.0144(0.0200) Steps 646(659.86) | Grad Norm 4.2333(6.1933) | Total Time 0.00(0.00)\n",
      "Iter 7080 | Time 17.5002(17.1418) | Bit/dim 3.6655(3.6220) | Xent 0.0606(0.0657) | Loss 9.1604(9.2630) | Error 0.0200(0.0206) Steps 676(661.80) | Grad Norm 9.1205(6.6526) | Total Time 0.00(0.00)\n",
      "Iter 7090 | Time 17.4342(17.2355) | Bit/dim 3.6415(3.6251) | Xent 0.0664(0.0692) | Loss 9.0448(9.1900) | Error 0.0233(0.0216) Steps 682(661.18) | Grad Norm 4.8530(6.9600) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 92.3858, Epoch Time 1060.5274(1041.9959), Bit/dim 3.6458(best: 3.6381), Xent 1.9684, Loss 4.6300, Error 0.3400(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 16.6936(17.2226) | Bit/dim 3.6228(3.6271) | Xent 0.0476(0.0738) | Loss 9.0746(9.8799) | Error 0.0178(0.0229) Steps 658(660.42) | Grad Norm 6.1388(7.2436) | Total Time 0.00(0.00)\n",
      "Iter 7110 | Time 17.7585(17.2846) | Bit/dim 3.6438(3.6311) | Xent 0.1233(0.0780) | Loss 8.9908(9.6525) | Error 0.0422(0.0246) Steps 652(663.67) | Grad Norm 11.3836(7.4966) | Total Time 0.00(0.00)\n",
      "Iter 7120 | Time 17.3267(17.3310) | Bit/dim 3.6337(3.6298) | Xent 0.0667(0.0812) | Loss 9.0601(9.4833) | Error 0.0244(0.0260) Steps 688(666.55) | Grad Norm 5.4693(7.5026) | Total Time 0.00(0.00)\n",
      "Iter 7130 | Time 18.2287(17.2906) | Bit/dim 3.6181(3.6292) | Xent 0.1240(0.0821) | Loss 9.1187(9.3564) | Error 0.0333(0.0261) Steps 676(667.33) | Grad Norm 10.1351(7.6527) | Total Time 0.00(0.00)\n",
      "Iter 7140 | Time 16.9391(17.3260) | Bit/dim 3.6275(3.6309) | Xent 0.0962(0.0801) | Loss 9.0363(9.2667) | Error 0.0322(0.0253) Steps 682(665.48) | Grad Norm 6.0180(7.1198) | Total Time 0.00(0.00)\n",
      "Iter 7150 | Time 17.0151(17.2880) | Bit/dim 3.6446(3.6287) | Xent 0.0961(0.0805) | Loss 8.9522(9.1882) | Error 0.0367(0.0259) Steps 664(663.67) | Grad Norm 10.1285(7.1955) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 91.2103, Epoch Time 1064.2656(1042.6640), Bit/dim 3.6439(best: 3.6381), Xent 1.8735, Loss 4.5806, Error 0.3257(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 18.5083(17.4422) | Bit/dim 3.6328(3.6264) | Xent 0.0482(0.0771) | Loss 8.9604(9.7614) | Error 0.0167(0.0249) Steps 682(665.87) | Grad Norm 4.2866(6.8669) | Total Time 0.00(0.00)\n",
      "Iter 7170 | Time 17.0368(17.3963) | Bit/dim 3.6295(3.6252) | Xent 0.0335(0.0723) | Loss 9.0420(9.5485) | Error 0.0133(0.0234) Steps 676(664.60) | Grad Norm 4.8433(6.4349) | Total Time 0.00(0.00)\n",
      "Iter 7180 | Time 16.6785(17.3179) | Bit/dim 3.6482(3.6267) | Xent 0.1005(0.0722) | Loss 9.0747(9.3959) | Error 0.0256(0.0226) Steps 658(665.22) | Grad Norm 8.4445(6.3111) | Total Time 0.00(0.00)\n",
      "Iter 7190 | Time 16.9772(17.3186) | Bit/dim 3.6309(3.6269) | Xent 0.0670(0.0748) | Loss 9.0336(9.2944) | Error 0.0211(0.0233) Steps 664(667.88) | Grad Norm 4.0567(6.2870) | Total Time 0.00(0.00)\n",
      "Iter 7200 | Time 16.7050(17.2759) | Bit/dim 3.6274(3.6250) | Xent 0.0681(0.0738) | Loss 8.9755(9.1987) | Error 0.0167(0.0228) Steps 676(664.91) | Grad Norm 7.9994(6.2757) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 91.1635, Epoch Time 1066.7070(1043.3853), Bit/dim 3.6456(best: 3.6381), Xent 1.7682, Loss 4.5297, Error 0.3259(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 17.4880(17.2736) | Bit/dim 3.6158(3.6245) | Xent 0.0736(0.0760) | Loss 9.0058(9.8626) | Error 0.0167(0.0234) Steps 652(665.31) | Grad Norm 5.2834(6.3732) | Total Time 0.00(0.00)\n",
      "Iter 7220 | Time 17.3401(17.2190) | Bit/dim 3.6329(3.6222) | Xent 0.0800(0.0734) | Loss 9.0013(9.6188) | Error 0.0244(0.0227) Steps 670(663.81) | Grad Norm 9.1321(6.0572) | Total Time 0.00(0.00)\n",
      "Iter 7230 | Time 17.1959(17.2501) | Bit/dim 3.6144(3.6210) | Xent 0.0569(0.0685) | Loss 8.8360(9.4312) | Error 0.0156(0.0214) Steps 646(661.52) | Grad Norm 6.2385(6.2868) | Total Time 0.00(0.00)\n",
      "Iter 7240 | Time 17.6427(17.2552) | Bit/dim 3.6531(3.6244) | Xent 0.0702(0.0703) | Loss 8.9877(9.3011) | Error 0.0233(0.0223) Steps 652(659.44) | Grad Norm 9.6182(6.6461) | Total Time 0.00(0.00)\n",
      "Iter 7250 | Time 17.1226(17.2568) | Bit/dim 3.6230(3.6271) | Xent 0.1241(0.0827) | Loss 9.0442(9.2334) | Error 0.0367(0.0261) Steps 682(662.11) | Grad Norm 7.8931(7.8394) | Total Time 0.00(0.00)\n",
      "Iter 7260 | Time 17.8339(17.3274) | Bit/dim 3.6534(3.6331) | Xent 0.2593(0.1111) | Loss 9.3312(9.2110) | Error 0.0756(0.0340) Steps 676(663.76) | Grad Norm 16.2265(9.5801) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 90.1553, Epoch Time 1062.9662(1043.9727), Bit/dim 3.6632(best: 3.6381), Xent 1.7117, Loss 4.5190, Error 0.3408(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7270 | Time 17.6313(17.4207) | Bit/dim 3.6622(3.6376) | Xent 0.1479(0.1213) | Loss 9.0696(9.8007) | Error 0.0522(0.0368) Steps 676(665.97) | Grad Norm 10.1845(9.7655) | Total Time 0.00(0.00)\n",
      "Iter 7280 | Time 18.1740(17.4501) | Bit/dim 3.6258(3.6396) | Xent 0.1275(0.1199) | Loss 9.0248(9.6024) | Error 0.0511(0.0372) Steps 682(669.56) | Grad Norm 8.6907(9.4167) | Total Time 0.00(0.00)\n",
      "Iter 7290 | Time 17.8624(17.4051) | Bit/dim 3.6234(3.6397) | Xent 0.1276(0.1157) | Loss 9.0472(9.4525) | Error 0.0344(0.0355) Steps 658(667.49) | Grad Norm 8.0174(8.9033) | Total Time 0.00(0.00)\n",
      "Iter 7300 | Time 17.0585(17.4733) | Bit/dim 3.6624(3.6383) | Xent 0.0701(0.1071) | Loss 9.1141(9.3287) | Error 0.0222(0.0328) Steps 688(667.86) | Grad Norm 8.3799(8.3054) | Total Time 0.00(0.00)\n",
      "Iter 7310 | Time 17.4126(17.4428) | Bit/dim 3.6361(3.6357) | Xent 0.0673(0.0972) | Loss 8.9803(9.2332) | Error 0.0244(0.0303) Steps 682(667.60) | Grad Norm 5.2123(7.6050) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 91.3511, Epoch Time 1073.3885(1044.8552), Bit/dim 3.6343(best: 3.6381), Xent 1.8184, Loss 4.5435, Error 0.3244(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7320 | Time 16.7708(17.3922) | Bit/dim 3.6023(3.6283) | Xent 0.0519(0.0855) | Loss 8.8417(9.8806) | Error 0.0144(0.0267) Steps 682(667.44) | Grad Norm 6.9833(7.0190) | Total Time 0.00(0.00)\n",
      "Iter 7330 | Time 16.8572(17.3372) | Bit/dim 3.6296(3.6246) | Xent 0.0498(0.0774) | Loss 9.0768(9.6310) | Error 0.0144(0.0240) Steps 670(668.07) | Grad Norm 7.4441(7.0601) | Total Time 0.00(0.00)\n",
      "Iter 7340 | Time 18.4617(17.3743) | Bit/dim 3.5832(3.6245) | Xent 0.0788(0.0762) | Loss 8.8029(9.4597) | Error 0.0233(0.0237) Steps 706(673.34) | Grad Norm 5.8112(7.0381) | Total Time 0.00(0.00)\n",
      "Iter 7350 | Time 16.9733(17.4053) | Bit/dim 3.5837(3.6279) | Xent 0.0477(0.0764) | Loss 8.7613(9.3404) | Error 0.0133(0.0232) Steps 658(672.89) | Grad Norm 4.4723(6.7782) | Total Time 0.00(0.00)\n",
      "Iter 7360 | Time 17.8099(17.5396) | Bit/dim 3.6427(3.6261) | Xent 0.0908(0.0737) | Loss 9.0553(9.2346) | Error 0.0311(0.0231) Steps 682(673.12) | Grad Norm 7.5342(6.4963) | Total Time 0.00(0.00)\n",
      "Iter 7370 | Time 16.7690(17.4685) | Bit/dim 3.6085(3.6238) | Xent 0.0677(0.0706) | Loss 9.0391(9.1579) | Error 0.0233(0.0221) Steps 658(673.90) | Grad Norm 4.8973(6.0471) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 91.6069, Epoch Time 1074.7404(1045.7518), Bit/dim 3.6349(best: 3.6343), Xent 1.8829, Loss 4.5763, Error 0.3320(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7380 | Time 17.9273(17.5071) | Bit/dim 3.6407(3.6203) | Xent 0.0653(0.0663) | Loss 8.9190(9.7154) | Error 0.0222(0.0211) Steps 664(672.49) | Grad Norm 7.6890(6.0385) | Total Time 0.00(0.00)\n",
      "Iter 7390 | Time 17.8747(17.5676) | Bit/dim 3.6127(3.6181) | Xent 0.0532(0.0669) | Loss 8.9994(9.5235) | Error 0.0167(0.0214) Steps 664(673.21) | Grad Norm 4.9907(6.3521) | Total Time 0.00(0.00)\n",
      "Iter 7400 | Time 16.1057(17.5025) | Bit/dim 3.6072(3.6205) | Xent 0.0802(0.0766) | Loss 9.0069(9.3977) | Error 0.0244(0.0236) Steps 634(669.67) | Grad Norm 8.6446(7.2612) | Total Time 0.00(0.00)\n",
      "Iter 7410 | Time 18.1664(17.5352) | Bit/dim 3.6293(3.6234) | Xent 0.0689(0.0780) | Loss 8.9995(9.2975) | Error 0.0200(0.0240) Steps 640(668.45) | Grad Norm 8.6650(7.4481) | Total Time 0.00(0.00)\n",
      "Iter 7420 | Time 17.8410(17.4810) | Bit/dim 3.6334(3.6247) | Xent 0.0796(0.0762) | Loss 9.0076(9.2157) | Error 0.0267(0.0239) Steps 664(668.16) | Grad Norm 6.9820(7.0019) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 91.1701, Epoch Time 1075.5808(1046.6466), Bit/dim 3.6406(best: 3.6343), Xent 1.7399, Loss 4.5106, Error 0.3141(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7430 | Time 18.1373(17.5382) | Bit/dim 3.6158(3.6260) | Xent 0.0875(0.0734) | Loss 9.0949(9.8925) | Error 0.0311(0.0234) Steps 646(669.07) | Grad Norm 8.3046(6.6957) | Total Time 0.00(0.00)\n",
      "Iter 7440 | Time 18.1882(17.6475) | Bit/dim 3.6280(3.6248) | Xent 0.0628(0.0727) | Loss 9.0632(9.6562) | Error 0.0233(0.0232) Steps 706(668.96) | Grad Norm 4.6211(6.5874) | Total Time 0.00(0.00)\n",
      "Iter 7450 | Time 17.6552(17.6648) | Bit/dim 3.5984(3.6247) | Xent 0.0787(0.0714) | Loss 8.9498(9.4864) | Error 0.0244(0.0229) Steps 688(671.52) | Grad Norm 8.4652(6.8182) | Total Time 0.00(0.00)\n",
      "Iter 7460 | Time 17.9413(17.6476) | Bit/dim 3.6069(3.6233) | Xent 0.0816(0.0702) | Loss 8.8244(9.3480) | Error 0.0256(0.0225) Steps 682(672.51) | Grad Norm 5.3149(6.5997) | Total Time 0.00(0.00)\n",
      "Iter 7470 | Time 17.0609(17.6683) | Bit/dim 3.6208(3.6197) | Xent 0.0425(0.0686) | Loss 8.9568(9.2422) | Error 0.0122(0.0217) Steps 658(671.10) | Grad Norm 7.2025(6.3879) | Total Time 0.00(0.00)\n",
      "Iter 7480 | Time 17.1512(17.5932) | Bit/dim 3.6580(3.6196) | Xent 0.0944(0.0703) | Loss 9.0545(9.1774) | Error 0.0267(0.0221) Steps 652(669.01) | Grad Norm 8.5904(6.8919) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 90.7696, Epoch Time 1085.1554(1047.8019), Bit/dim 3.6382(best: 3.6343), Xent 1.8646, Loss 4.5705, Error 0.3351(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7490 | Time 16.6544(17.5043) | Bit/dim 3.6465(3.6211) | Xent 0.0719(0.0701) | Loss 8.9735(9.7431) | Error 0.0233(0.0220) Steps 652(669.08) | Grad Norm 7.0491(6.9148) | Total Time 0.00(0.00)\n",
      "Iter 7500 | Time 16.3856(17.4981) | Bit/dim 3.6467(3.6233) | Xent 0.0983(0.0692) | Loss 9.0048(9.5423) | Error 0.0300(0.0218) Steps 652(668.47) | Grad Norm 8.3756(7.1564) | Total Time 0.00(0.00)\n",
      "Iter 7510 | Time 17.2527(17.5025) | Bit/dim 3.5923(3.6213) | Xent 0.0711(0.0696) | Loss 8.9184(9.3861) | Error 0.0233(0.0219) Steps 676(667.88) | Grad Norm 6.6885(7.1337) | Total Time 0.00(0.00)\n",
      "Iter 7520 | Time 18.3756(17.6089) | Bit/dim 3.6324(3.6243) | Xent 0.0647(0.0710) | Loss 8.8883(9.2925) | Error 0.0178(0.0222) Steps 652(672.77) | Grad Norm 7.2904(7.4948) | Total Time 0.00(0.00)\n",
      "Iter 7530 | Time 17.3839(17.6009) | Bit/dim 3.6368(3.6206) | Xent 0.0472(0.0692) | Loss 9.0184(9.1974) | Error 0.0100(0.0215) Steps 682(673.80) | Grad Norm 4.9799(7.0115) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 90.7387, Epoch Time 1074.3985(1048.5998), Bit/dim 3.6346(best: 3.6343), Xent 1.8080, Loss 4.5386, Error 0.3252(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7540 | Time 17.6536(17.4847) | Bit/dim 3.5973(3.6174) | Xent 0.0556(0.0661) | Loss 8.9093(9.8537) | Error 0.0200(0.0208) Steps 652(670.23) | Grad Norm 5.7684(6.4680) | Total Time 0.00(0.00)\n",
      "Iter 7550 | Time 17.5252(17.5190) | Bit/dim 3.5916(3.6164) | Xent 0.0466(0.0625) | Loss 8.9332(9.6150) | Error 0.0144(0.0192) Steps 640(669.66) | Grad Norm 4.5934(6.2220) | Total Time 0.00(0.00)\n",
      "Iter 7560 | Time 17.0289(17.4880) | Bit/dim 3.6020(3.6193) | Xent 0.0486(0.0695) | Loss 8.9037(9.4612) | Error 0.0144(0.0216) Steps 664(669.52) | Grad Norm 5.0265(7.0468) | Total Time 0.00(0.00)\n",
      "Iter 7570 | Time 17.5659(17.4066) | Bit/dim 3.6105(3.6201) | Xent 0.0953(0.0705) | Loss 9.0046(9.3219) | Error 0.0300(0.0220) Steps 682(668.87) | Grad Norm 6.6236(7.0278) | Total Time 0.00(0.00)\n",
      "Iter 7580 | Time 17.5748(17.4060) | Bit/dim 3.5776(3.6196) | Xent 0.0795(0.0700) | Loss 8.9573(9.2353) | Error 0.0211(0.0214) Steps 670(670.19) | Grad Norm 4.1200(6.8538) | Total Time 0.00(0.00)\n",
      "Iter 7590 | Time 18.6148(17.4092) | Bit/dim 3.6351(3.6180) | Xent 0.0742(0.0703) | Loss 9.0311(9.1636) | Error 0.0244(0.0217) Steps 670(667.49) | Grad Norm 6.0279(6.7397) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 91.1943, Epoch Time 1067.7713(1049.1749), Bit/dim 3.6302(best: 3.6343), Xent 1.7465, Loss 4.5034, Error 0.3176(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7600 | Time 16.5987(17.3641) | Bit/dim 3.6271(3.6217) | Xent 0.0423(0.0689) | Loss 8.9062(9.7292) | Error 0.0122(0.0208) Steps 670(668.49) | Grad Norm 4.2012(6.7635) | Total Time 0.00(0.00)\n",
      "Iter 7610 | Time 18.3554(17.3363) | Bit/dim 3.6116(3.6180) | Xent 0.0467(0.0684) | Loss 8.9237(9.5029) | Error 0.0156(0.0212) Steps 664(666.16) | Grad Norm 6.9747(6.8450) | Total Time 0.00(0.00)\n",
      "Iter 7620 | Time 17.8734(17.4037) | Bit/dim 3.6167(3.6201) | Xent 0.0564(0.0730) | Loss 8.9316(9.3676) | Error 0.0200(0.0229) Steps 712(668.93) | Grad Norm 6.9415(7.6818) | Total Time 0.00(0.00)\n",
      "Iter 7630 | Time 17.1242(17.3547) | Bit/dim 3.6003(3.6226) | Xent 0.0977(0.0723) | Loss 8.9759(9.2599) | Error 0.0300(0.0228) Steps 658(666.26) | Grad Norm 8.0290(7.5003) | Total Time 0.00(0.00)\n",
      "Iter 7640 | Time 17.2720(17.2749) | Bit/dim 3.5618(3.6185) | Xent 0.0656(0.0687) | Loss 8.8862(9.1751) | Error 0.0211(0.0220) Steps 640(665.49) | Grad Norm 6.6147(7.2029) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 90.6777, Epoch Time 1060.4724(1049.5139), Bit/dim 3.6325(best: 3.6302), Xent 1.6927, Loss 4.4788, Error 0.3114(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7650 | Time 18.4220(17.3351) | Bit/dim 3.5883(3.6172) | Xent 0.0803(0.0711) | Loss 8.8381(9.8185) | Error 0.0222(0.0224) Steps 664(663.82) | Grad Norm 8.8869(7.1298) | Total Time 0.00(0.00)\n",
      "Iter 7660 | Time 17.2399(17.3300) | Bit/dim 3.6234(3.6185) | Xent 0.1084(0.0712) | Loss 9.0013(9.5956) | Error 0.0322(0.0221) Steps 646(663.67) | Grad Norm 7.8063(6.9420) | Total Time 0.00(0.00)\n",
      "Iter 7670 | Time 18.0655(17.4583) | Bit/dim 3.6176(3.6139) | Xent 0.0999(0.0720) | Loss 9.0234(9.4274) | Error 0.0244(0.0222) Steps 682(670.53) | Grad Norm 5.0301(7.0005) | Total Time 0.00(0.00)\n",
      "Iter 7680 | Time 17.2867(17.5333) | Bit/dim 3.6325(3.6164) | Xent 0.0539(0.0683) | Loss 8.9091(9.3019) | Error 0.0233(0.0216) Steps 640(670.99) | Grad Norm 5.1007(6.7339) | Total Time 0.00(0.00)\n",
      "Iter 7690 | Time 18.0417(17.6527) | Bit/dim 3.6255(3.6172) | Xent 0.0889(0.0712) | Loss 9.0399(9.2179) | Error 0.0244(0.0219) Steps 670(672.27) | Grad Norm 8.5058(6.6825) | Total Time 0.00(0.00)\n",
      "Iter 7700 | Time 17.3451(17.6414) | Bit/dim 3.5843(3.6155) | Xent 0.0721(0.0736) | Loss 8.8345(9.1465) | Error 0.0189(0.0225) Steps 694(672.66) | Grad Norm 5.3803(6.9074) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 93.2790, Epoch Time 1088.2697(1050.6765), Bit/dim 3.6405(best: 3.6302), Xent 1.9221, Loss 4.6015, Error 0.3326(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7710 | Time 18.3328(17.6587) | Bit/dim 3.6497(3.6172) | Xent 0.0398(0.0709) | Loss 8.9968(9.7318) | Error 0.0089(0.0218) Steps 658(675.13) | Grad Norm 4.4820(6.7204) | Total Time 0.00(0.00)\n",
      "Iter 7720 | Time 16.9875(17.6403) | Bit/dim 3.6291(3.6162) | Xent 0.0834(0.0723) | Loss 8.9233(9.5383) | Error 0.0267(0.0223) Steps 682(674.56) | Grad Norm 8.3680(6.9004) | Total Time 0.00(0.00)\n",
      "Iter 7730 | Time 17.5969(17.5573) | Bit/dim 3.6396(3.6170) | Xent 0.0467(0.0674) | Loss 9.0181(9.3826) | Error 0.0167(0.0210) Steps 658(673.80) | Grad Norm 7.8848(6.9096) | Total Time 0.00(0.00)\n",
      "Iter 7740 | Time 17.3207(17.5831) | Bit/dim 3.5848(3.6160) | Xent 0.0804(0.0693) | Loss 8.8964(9.2717) | Error 0.0233(0.0218) Steps 670(674.62) | Grad Norm 6.5051(7.0401) | Total Time 0.00(0.00)\n",
      "Iter 7750 | Time 17.2481(17.5585) | Bit/dim 3.6433(3.6182) | Xent 0.0872(0.0737) | Loss 8.9761(9.2028) | Error 0.0244(0.0229) Steps 670(674.98) | Grad Norm 5.7636(6.8291) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 92.3017, Epoch Time 1082.8859(1051.6428), Bit/dim 3.6352(best: 3.6302), Xent 1.7818, Loss 4.5261, Error 0.3227(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7760 | Time 17.9003(17.6601) | Bit/dim 3.5688(3.6179) | Xent 0.0591(0.0699) | Loss 8.9221(9.8721) | Error 0.0233(0.0222) Steps 700(678.41) | Grad Norm 7.7948(6.7570) | Total Time 0.00(0.00)\n",
      "Iter 7770 | Time 17.2573(17.6260) | Bit/dim 3.5890(3.6162) | Xent 0.0594(0.0645) | Loss 8.9040(9.6266) | Error 0.0233(0.0204) Steps 664(675.81) | Grad Norm 6.8911(6.7339) | Total Time 0.00(0.00)\n",
      "Iter 7780 | Time 17.5737(17.6505) | Bit/dim 3.6016(3.6160) | Xent 0.0648(0.0630) | Loss 8.8843(9.4384) | Error 0.0200(0.0196) Steps 670(676.02) | Grad Norm 7.2361(6.8142) | Total Time 0.00(0.00)\n",
      "Iter 7790 | Time 18.0743(17.6923) | Bit/dim 3.5899(3.6156) | Xent 0.0769(0.0619) | Loss 8.9644(9.3069) | Error 0.0244(0.0190) Steps 694(676.09) | Grad Norm 5.6821(6.3304) | Total Time 0.00(0.00)\n",
      "Iter 7800 | Time 17.8534(17.5962) | Bit/dim 3.6398(3.6161) | Xent 0.0804(0.0656) | Loss 9.0864(9.2202) | Error 0.0222(0.0201) Steps 646(672.91) | Grad Norm 8.3100(6.4771) | Total Time 0.00(0.00)\n",
      "Iter 7810 | Time 18.0145(17.5498) | Bit/dim 3.6055(3.6157) | Xent 0.0548(0.0644) | Loss 9.0130(9.1484) | Error 0.0156(0.0198) Steps 658(672.48) | Grad Norm 7.4583(6.8176) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 90.4224, Epoch Time 1079.7379(1052.4857), Bit/dim 3.6310(best: 3.6302), Xent 1.9029, Loss 4.5824, Error 0.3327(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7820 | Time 16.3487(17.6213) | Bit/dim 3.5764(3.6141) | Xent 0.1018(0.0652) | Loss 8.8414(9.7196) | Error 0.0289(0.0200) Steps 646(674.38) | Grad Norm 11.2379(7.0271) | Total Time 0.00(0.00)\n",
      "Iter 7830 | Time 17.4857(17.5822) | Bit/dim 3.6005(3.6140) | Xent 0.0837(0.0676) | Loss 9.0502(9.5236) | Error 0.0267(0.0207) Steps 652(672.54) | Grad Norm 10.8294(6.9674) | Total Time 0.00(0.00)\n",
      "Iter 7840 | Time 17.9654(17.6065) | Bit/dim 3.5824(3.6117) | Xent 0.0329(0.0632) | Loss 8.8877(9.3680) | Error 0.0100(0.0196) Steps 706(673.71) | Grad Norm 5.7374(6.6192) | Total Time 0.00(0.00)\n",
      "Iter 7850 | Time 17.1904(17.6361) | Bit/dim 3.6248(3.6146) | Xent 0.0697(0.0631) | Loss 8.9603(9.2639) | Error 0.0200(0.0195) Steps 676(674.49) | Grad Norm 9.9237(6.7183) | Total Time 0.00(0.00)\n",
      "Iter 7860 | Time 17.6794(17.5564) | Bit/dim 3.6193(3.6159) | Xent 0.0819(0.0652) | Loss 9.0298(9.1840) | Error 0.0256(0.0200) Steps 646(672.64) | Grad Norm 4.1894(6.4687) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 91.6735, Epoch Time 1079.4773(1053.2954), Bit/dim 3.6314(best: 3.6302), Xent 1.8390, Loss 4.5509, Error 0.3237(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7870 | Time 16.9770(17.4501) | Bit/dim 3.6343(3.6145) | Xent 0.0352(0.0633) | Loss 8.9572(9.8353) | Error 0.0100(0.0197) Steps 652(670.84) | Grad Norm 4.8087(6.3329) | Total Time 0.00(0.00)\n",
      "Iter 7880 | Time 18.5422(17.4828) | Bit/dim 3.5973(3.6131) | Xent 0.0784(0.0617) | Loss 8.8984(9.6003) | Error 0.0256(0.0193) Steps 694(674.47) | Grad Norm 6.4368(6.1654) | Total Time 0.00(0.00)\n",
      "Iter 7890 | Time 17.7414(17.4896) | Bit/dim 3.6219(3.6131) | Xent 0.0770(0.0617) | Loss 8.9577(9.4383) | Error 0.0189(0.0192) Steps 676(674.49) | Grad Norm 4.0394(5.9582) | Total Time 0.00(0.00)\n",
      "Iter 7900 | Time 18.5120(17.5234) | Bit/dim 3.6621(3.6146) | Xent 0.0468(0.0614) | Loss 8.9496(9.3087) | Error 0.0144(0.0190) Steps 712(676.75) | Grad Norm 5.4479(5.7341) | Total Time 0.00(0.00)\n",
      "Iter 7910 | Time 18.2489(17.5324) | Bit/dim 3.6397(3.6149) | Xent 0.0631(0.0618) | Loss 9.0385(9.2113) | Error 0.0167(0.0188) Steps 664(674.40) | Grad Norm 3.8245(5.8165) | Total Time 0.00(0.00)\n",
      "Iter 7920 | Time 17.8580(17.4718) | Bit/dim 3.5693(3.6117) | Xent 0.0950(0.0642) | Loss 8.9465(9.1338) | Error 0.0289(0.0198) Steps 694(672.62) | Grad Norm 7.1730(5.7647) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 91.3619, Epoch Time 1072.3536(1053.8672), Bit/dim 3.6295(best: 3.6302), Xent 1.7685, Loss 4.5137, Error 0.3229(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7930 | Time 18.1599(17.5386) | Bit/dim 3.5907(3.6140) | Xent 0.0674(0.0654) | Loss 8.9888(9.7142) | Error 0.0244(0.0200) Steps 640(673.16) | Grad Norm 6.2222(6.0598) | Total Time 0.00(0.00)\n",
      "Iter 7940 | Time 18.2212(17.4881) | Bit/dim 3.6072(3.6118) | Xent 0.0509(0.0658) | Loss 8.9843(9.5090) | Error 0.0178(0.0202) Steps 700(672.44) | Grad Norm 7.1415(6.2436) | Total Time 0.00(0.00)\n",
      "Iter 7950 | Time 17.2235(17.4284) | Bit/dim 3.5924(3.6095) | Xent 0.0672(0.0631) | Loss 8.8826(9.3511) | Error 0.0200(0.0193) Steps 664(672.68) | Grad Norm 8.0589(6.2099) | Total Time 0.00(0.00)\n",
      "Iter 7960 | Time 18.0201(17.4395) | Bit/dim 3.6026(3.6089) | Xent 0.0630(0.0625) | Loss 8.9981(9.2427) | Error 0.0189(0.0191) Steps 730(673.56) | Grad Norm 6.1218(5.9729) | Total Time 0.00(0.00)\n",
      "Iter 7970 | Time 17.3890(17.4938) | Bit/dim 3.6455(3.6103) | Xent 0.0766(0.0636) | Loss 9.1277(9.1634) | Error 0.0222(0.0195) Steps 682(672.68) | Grad Norm 7.0159(6.0431) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 92.2423, Epoch Time 1076.3348(1054.5412), Bit/dim 3.6341(best: 3.6295), Xent 1.9637, Loss 4.6160, Error 0.3426(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7980 | Time 18.2190(17.5971) | Bit/dim 3.6414(3.6140) | Xent 0.0305(0.0664) | Loss 8.8974(9.8486) | Error 0.0100(0.0204) Steps 658(674.70) | Grad Norm 4.1576(6.1933) | Total Time 0.00(0.00)\n",
      "Iter 7990 | Time 17.7725(17.5835) | Bit/dim 3.5767(3.6086) | Xent 0.0469(0.0669) | Loss 8.7487(9.6024) | Error 0.0144(0.0204) Steps 694(676.38) | Grad Norm 4.7613(6.3639) | Total Time 0.00(0.00)\n",
      "Iter 8000 | Time 17.5104(17.5604) | Bit/dim 3.5774(3.6064) | Xent 0.0578(0.0654) | Loss 8.8276(9.4281) | Error 0.0178(0.0201) Steps 640(676.61) | Grad Norm 4.3114(6.2427) | Total Time 0.00(0.00)\n",
      "Iter 8010 | Time 18.0578(17.5112) | Bit/dim 3.6212(3.6119) | Xent 0.0733(0.0662) | Loss 9.0016(9.3078) | Error 0.0200(0.0203) Steps 664(673.02) | Grad Norm 7.9652(6.5984) | Total Time 0.00(0.00)\n",
      "Iter 8020 | Time 17.3468(17.5178) | Bit/dim 3.5961(3.6123) | Xent 0.0519(0.0640) | Loss 8.9474(9.2189) | Error 0.0144(0.0196) Steps 658(671.84) | Grad Norm 5.1078(6.4540) | Total Time 0.00(0.00)\n",
      "Iter 8030 | Time 17.4092(17.5197) | Bit/dim 3.6119(3.6137) | Xent 0.0394(0.0639) | Loss 8.8481(9.1478) | Error 0.0144(0.0198) Steps 652(671.16) | Grad Norm 4.5609(6.5668) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 90.8938, Epoch Time 1077.1424(1055.2192), Bit/dim 3.6327(best: 3.6295), Xent 1.9228, Loss 4.5941, Error 0.3310(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8040 | Time 16.5418(17.6203) | Bit/dim 3.6393(3.6142) | Xent 0.0568(0.0625) | Loss 9.0163(9.6865) | Error 0.0233(0.0192) Steps 652(671.41) | Grad Norm 4.0888(6.1770) | Total Time 0.00(0.00)\n",
      "Iter 8050 | Time 17.3118(17.6781) | Bit/dim 3.6047(3.6115) | Xent 0.0404(0.0587) | Loss 8.9923(9.4838) | Error 0.0144(0.0184) Steps 676(672.92) | Grad Norm 3.6144(5.9156) | Total Time 0.00(0.00)\n",
      "Iter 8060 | Time 17.6518(17.7290) | Bit/dim 3.5921(3.6108) | Xent 0.0869(0.0584) | Loss 8.9624(9.3451) | Error 0.0289(0.0183) Steps 688(676.12) | Grad Norm 11.4262(6.0515) | Total Time 0.00(0.00)\n",
      "Iter 8070 | Time 17.2134(17.6919) | Bit/dim 3.6068(3.6102) | Xent 0.0787(0.0609) | Loss 8.9160(9.2406) | Error 0.0222(0.0189) Steps 634(676.20) | Grad Norm 7.6097(6.2896) | Total Time 0.00(0.00)\n",
      "Iter 8080 | Time 17.6219(17.6883) | Bit/dim 3.6283(3.6117) | Xent 0.0726(0.0656) | Loss 8.8940(9.1802) | Error 0.0178(0.0204) Steps 676(676.74) | Grad Norm 5.4522(6.5799) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0147 | Time 91.8127, Epoch Time 1089.0434(1056.2339), Bit/dim 3.6359(best: 3.6295), Xent 1.8740, Loss 4.5729, Error 0.3311(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8090 | Time 18.2255(17.6906) | Bit/dim 3.6141(3.6151) | Xent 0.0697(0.0676) | Loss 9.0389(9.8585) | Error 0.0189(0.0206) Steps 718(679.18) | Grad Norm 5.5567(6.3896) | Total Time 0.00(0.00)\n",
      "Iter 8100 | Time 18.2105(17.7766) | Bit/dim 3.6139(3.6137) | Xent 0.0697(0.0675) | Loss 8.9740(9.6317) | Error 0.0200(0.0210) Steps 694(681.87) | Grad Norm 5.1536(6.8516) | Total Time 0.00(0.00)\n",
      "Iter 8110 | Time 18.1932(17.6997) | Bit/dim 3.5829(3.6131) | Xent 0.0575(0.0678) | Loss 8.9203(9.4476) | Error 0.0144(0.0210) Steps 712(681.72) | Grad Norm 7.4952(7.2572) | Total Time 0.00(0.00)\n",
      "Iter 8120 | Time 17.3595(17.6823) | Bit/dim 3.6345(3.6112) | Xent 0.0864(0.0698) | Loss 9.0530(9.3157) | Error 0.0267(0.0216) Steps 670(677.86) | Grad Norm 7.1926(7.0116) | Total Time 0.00(0.00)\n",
      "Iter 8130 | Time 18.2982(17.7290) | Bit/dim 3.6437(3.6101) | Xent 0.1045(0.0698) | Loss 9.1210(9.2306) | Error 0.0333(0.0219) Steps 670(679.20) | Grad Norm 8.9890(7.0547) | Total Time 0.00(0.00)\n",
      "Iter 8140 | Time 17.3021(17.7013) | Bit/dim 3.6141(3.6105) | Xent 0.0734(0.0720) | Loss 8.8485(9.1609) | Error 0.0256(0.0226) Steps 646(678.64) | Grad Norm 5.8608(7.2196) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 91.7539, Epoch Time 1090.6142(1057.2654), Bit/dim 3.6253(best: 3.6295), Xent 1.8123, Loss 4.5315, Error 0.3262(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8150 | Time 17.8700(17.6743) | Bit/dim 3.6430(3.6139) | Xent 0.0669(0.0734) | Loss 9.1293(9.7298) | Error 0.0244(0.0235) Steps 664(675.83) | Grad Norm 7.1898(7.3810) | Total Time 0.00(0.00)\n",
      "Iter 8160 | Time 18.5771(17.7055) | Bit/dim 3.5996(3.6113) | Xent 0.0429(0.0728) | Loss 8.7974(9.5258) | Error 0.0156(0.0232) Steps 706(676.76) | Grad Norm 4.5590(7.0878) | Total Time 0.00(0.00)\n",
      "Iter 8170 | Time 18.0715(17.7697) | Bit/dim 3.6284(3.6114) | Xent 0.0506(0.0709) | Loss 9.0178(9.3677) | Error 0.0178(0.0225) Steps 712(680.94) | Grad Norm 5.2170(6.8203) | Total Time 0.00(0.00)\n",
      "Iter 8180 | Time 18.0548(17.7327) | Bit/dim 3.5980(3.6115) | Xent 0.0728(0.0694) | Loss 8.8162(9.2541) | Error 0.0244(0.0220) Steps 688(677.91) | Grad Norm 5.3405(6.6676) | Total Time 0.00(0.00)\n",
      "Iter 8190 | Time 17.2301(17.7255) | Bit/dim 3.6042(3.6110) | Xent 0.0749(0.0713) | Loss 8.9067(9.1774) | Error 0.0222(0.0226) Steps 676(677.43) | Grad Norm 6.1177(6.6947) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 94.4632, Epoch Time 1090.4098(1058.2597), Bit/dim 3.6251(best: 3.6253), Xent 1.8247, Loss 4.5374, Error 0.3201(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8200 | Time 17.0321(17.6842) | Bit/dim 3.6044(3.6115) | Xent 0.0564(0.0674) | Loss 8.9548(9.8535) | Error 0.0167(0.0210) Steps 676(678.16) | Grad Norm 6.1175(6.2475) | Total Time 0.00(0.00)\n",
      "Iter 8210 | Time 17.9339(17.6465) | Bit/dim 3.5927(3.6093) | Xent 0.0573(0.0625) | Loss 8.9137(9.6032) | Error 0.0189(0.0197) Steps 658(675.64) | Grad Norm 6.2987(5.8528) | Total Time 0.00(0.00)\n",
      "Iter 8220 | Time 17.1931(17.6455) | Bit/dim 3.6262(3.6081) | Xent 0.0517(0.0645) | Loss 8.8743(9.4248) | Error 0.0156(0.0201) Steps 664(676.65) | Grad Norm 7.6673(5.9834) | Total Time 0.00(0.00)\n",
      "Iter 8230 | Time 17.8893(17.6981) | Bit/dim 3.6262(3.6073) | Xent 0.0678(0.0658) | Loss 8.8224(9.2971) | Error 0.0211(0.0208) Steps 694(676.90) | Grad Norm 4.0039(6.8549) | Total Time 0.00(0.00)\n",
      "Iter 8240 | Time 17.0536(17.7027) | Bit/dim 3.5995(3.6078) | Xent 0.1104(0.0685) | Loss 8.9556(9.2103) | Error 0.0300(0.0216) Steps 694(679.02) | Grad Norm 8.6057(6.9467) | Total Time 0.00(0.00)\n",
      "Iter 8250 | Time 19.0932(17.7669) | Bit/dim 3.6229(3.6105) | Xent 0.0348(0.0647) | Loss 9.0165(9.1477) | Error 0.0100(0.0201) Steps 658(679.61) | Grad Norm 5.5810(6.7348) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 92.0453, Epoch Time 1086.3741(1059.1031), Bit/dim 3.6227(best: 3.6251), Xent 1.8224, Loss 4.5340, Error 0.3188(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8260 | Time 17.4802(17.7803) | Bit/dim 3.6109(3.6095) | Xent 0.0608(0.0625) | Loss 8.8290(9.7210) | Error 0.0200(0.0193) Steps 646(678.62) | Grad Norm 4.5246(6.4085) | Total Time 0.00(0.00)\n",
      "Iter 8270 | Time 17.6835(17.6985) | Bit/dim 3.6027(3.6103) | Xent 0.0423(0.0594) | Loss 8.9356(9.5098) | Error 0.0089(0.0184) Steps 694(679.54) | Grad Norm 6.6042(6.4977) | Total Time 0.00(0.00)\n",
      "Iter 8280 | Time 16.9439(17.6911) | Bit/dim 3.6145(3.6077) | Xent 0.0303(0.0582) | Loss 8.8902(9.3574) | Error 0.0078(0.0177) Steps 688(679.37) | Grad Norm 3.3914(6.2888) | Total Time 0.00(0.00)\n",
      "Iter 8290 | Time 19.0240(17.8422) | Bit/dim 3.6034(3.6046) | Xent 0.0530(0.0569) | Loss 8.9085(9.2391) | Error 0.0178(0.0172) Steps 700(679.26) | Grad Norm 6.4322(6.0637) | Total Time 0.00(0.00)\n",
      "Iter 8300 | Time 18.3287(17.8551) | Bit/dim 3.6482(3.6059) | Xent 0.0526(0.0548) | Loss 9.0692(9.1607) | Error 0.0189(0.0169) Steps 694(679.81) | Grad Norm 4.4534(5.7784) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0151 | Time 94.2702, Epoch Time 1095.8897(1060.2067), Bit/dim 3.6176(best: 3.6227), Xent 1.9614, Loss 4.5983, Error 0.3338(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8310 | Time 18.2357(17.8693) | Bit/dim 3.6279(3.6022) | Xent 0.0458(0.0540) | Loss 9.0787(9.8241) | Error 0.0178(0.0165) Steps 688(681.79) | Grad Norm 5.3749(5.7248) | Total Time 0.00(0.00)\n",
      "Iter 8320 | Time 17.7786(17.8408) | Bit/dim 3.5832(3.6024) | Xent 0.0782(0.0544) | Loss 8.8327(9.5770) | Error 0.0244(0.0164) Steps 682(682.27) | Grad Norm 6.0805(5.6190) | Total Time 0.00(0.00)\n",
      "Iter 8330 | Time 18.2908(17.8941) | Bit/dim 3.5650(3.6011) | Xent 0.0488(0.0533) | Loss 8.8841(9.4145) | Error 0.0156(0.0164) Steps 664(685.31) | Grad Norm 7.5313(5.4243) | Total Time 0.00(0.00)\n",
      "Iter 8340 | Time 17.9841(17.8064) | Bit/dim 3.5791(3.5998) | Xent 0.0489(0.0511) | Loss 9.0039(9.2875) | Error 0.0133(0.0159) Steps 688(687.27) | Grad Norm 6.1207(5.3671) | Total Time 0.00(0.00)\n",
      "Iter 8350 | Time 18.2383(17.7743) | Bit/dim 3.5933(3.6004) | Xent 0.0913(0.0521) | Loss 9.0092(9.1982) | Error 0.0233(0.0163) Steps 670(682.84) | Grad Norm 6.9795(5.4500) | Total Time 0.00(0.00)\n",
      "Iter 8360 | Time 17.4894(17.8335) | Bit/dim 3.6658(3.6054) | Xent 0.3244(0.0785) | Loss 9.3829(9.1665) | Error 0.0922(0.0238) Steps 682(684.48) | Grad Norm 15.4709(6.9419) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0152 | Time 92.8376, Epoch Time 1093.4437(1061.2038), Bit/dim 3.6489(best: 3.6176), Xent 1.7357, Loss 4.5168, Error 0.3346(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8370 | Time 17.9777(17.8294) | Bit/dim 3.6301(3.6104) | Xent 0.0747(0.0948) | Loss 8.9649(9.7776) | Error 0.0267(0.0287) Steps 664(686.58) | Grad Norm 7.4127(7.3415) | Total Time 0.00(0.00)\n",
      "Iter 8380 | Time 17.0368(17.7741) | Bit/dim 3.6616(3.6159) | Xent 0.0521(0.0930) | Loss 9.0846(9.5816) | Error 0.0156(0.0279) Steps 694(686.40) | Grad Norm 4.6051(6.9827) | Total Time 0.00(0.00)\n",
      "Iter 8390 | Time 18.5738(17.7854) | Bit/dim 3.6151(3.6167) | Xent 0.0427(0.0835) | Loss 8.9999(9.4273) | Error 0.0133(0.0252) Steps 688(683.20) | Grad Norm 5.4547(6.4441) | Total Time 0.00(0.00)\n",
      "Iter 8400 | Time 17.8289(17.7921) | Bit/dim 3.5813(3.6120) | Xent 0.0563(0.0778) | Loss 8.7630(9.2856) | Error 0.0144(0.0233) Steps 670(681.91) | Grad Norm 4.7483(6.0281) | Total Time 0.00(0.00)\n",
      "Iter 8410 | Time 17.8122(17.8166) | Bit/dim 3.5854(3.6083) | Xent 0.0790(0.0715) | Loss 8.8713(9.1982) | Error 0.0211(0.0214) Steps 652(682.21) | Grad Norm 4.4185(5.5959) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0153 | Time 92.9554, Epoch Time 1093.0543(1062.1593), Bit/dim 3.6141(best: 3.6176), Xent 1.8288, Loss 4.5285, Error 0.3177(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8420 | Time 17.6501(17.8670) | Bit/dim 3.6094(3.6075) | Xent 0.0427(0.0639) | Loss 8.8736(9.8816) | Error 0.0111(0.0190) Steps 682(682.72) | Grad Norm 4.1819(5.3231) | Total Time 0.00(0.00)\n",
      "Iter 8430 | Time 18.1755(17.8591) | Bit/dim 3.6220(3.6069) | Xent 0.0913(0.0628) | Loss 9.1152(9.6379) | Error 0.0233(0.0189) Steps 706(681.73) | Grad Norm 9.5238(5.8265) | Total Time 0.00(0.00)\n",
      "Iter 8440 | Time 17.9345(17.8377) | Bit/dim 3.5975(3.6057) | Xent 0.0834(0.0611) | Loss 9.0301(9.4594) | Error 0.0233(0.0183) Steps 694(681.66) | Grad Norm 6.0521(5.9459) | Total Time 0.00(0.00)\n",
      "Iter 8450 | Time 17.8030(17.7872) | Bit/dim 3.5955(3.6051) | Xent 0.0458(0.0604) | Loss 8.9632(9.3189) | Error 0.0144(0.0183) Steps 706(679.27) | Grad Norm 4.9995(5.9850) | Total Time 0.00(0.00)\n",
      "Iter 8460 | Time 18.1405(17.7549) | Bit/dim 3.5674(3.6028) | Xent 0.0926(0.0600) | Loss 8.9174(9.2142) | Error 0.0311(0.0185) Steps 682(680.31) | Grad Norm 7.7004(6.1113) | Total Time 0.00(0.00)\n",
      "Iter 8470 | Time 17.2507(17.7329) | Bit/dim 3.5976(3.6054) | Xent 0.0403(0.0587) | Loss 8.9625(9.1494) | Error 0.0111(0.0180) Steps 682(682.67) | Grad Norm 5.8951(6.0745) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0154 | Time 92.0339, Epoch Time 1091.2538(1063.0322), Bit/dim 3.6242(best: 3.6141), Xent 1.7996, Loss 4.5240, Error 0.3143(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8480 | Time 18.0590(17.7815) | Bit/dim 3.6241(3.6081) | Xent 0.0843(0.0625) | Loss 8.9804(9.7404) | Error 0.0311(0.0193) Steps 688(683.95) | Grad Norm 6.0409(6.7207) | Total Time 0.00(0.00)\n",
      "Iter 8490 | Time 17.3415(17.7734) | Bit/dim 3.6062(3.6090) | Xent 0.0725(0.0674) | Loss 8.9329(9.5463) | Error 0.0233(0.0209) Steps 652(683.42) | Grad Norm 6.0206(6.8699) | Total Time 0.00(0.00)\n",
      "Iter 8500 | Time 17.5698(17.7484) | Bit/dim 3.6112(3.6087) | Xent 0.0426(0.0657) | Loss 8.9170(9.3829) | Error 0.0133(0.0204) Steps 658(680.78) | Grad Norm 4.7091(6.7455) | Total Time 0.00(0.00)\n",
      "Iter 8510 | Time 17.3324(17.7706) | Bit/dim 3.5983(3.6058) | Xent 0.0393(0.0664) | Loss 8.8732(9.2687) | Error 0.0100(0.0204) Steps 664(682.92) | Grad Norm 7.1048(6.7146) | Total Time 0.00(0.00)\n",
      "Iter 8520 | Time 17.1784(17.7458) | Bit/dim 3.6145(3.6068) | Xent 0.0666(0.0683) | Loss 9.0730(9.1928) | Error 0.0189(0.0211) Steps 694(682.92) | Grad Norm 5.5425(6.8545) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0155 | Time 92.4067, Epoch Time 1097.8073(1064.0754), Bit/dim 3.6214(best: 3.6141), Xent 1.7327, Loss 4.4877, Error 0.3215(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8530 | Time 18.1708(17.7871) | Bit/dim 3.5715(3.6062) | Xent 0.0741(0.0673) | Loss 8.8424(9.8472) | Error 0.0244(0.0210) Steps 682(685.22) | Grad Norm 5.5983(6.3975) | Total Time 0.00(0.00)\n",
      "Iter 8540 | Time 17.3398(17.8544) | Bit/dim 3.5994(3.6074) | Xent 0.0789(0.0634) | Loss 8.8862(9.6093) | Error 0.0211(0.0196) Steps 706(685.68) | Grad Norm 5.6011(5.9358) | Total Time 0.00(0.00)\n",
      "Iter 8550 | Time 17.4882(17.7983) | Bit/dim 3.5756(3.6042) | Xent 0.0469(0.0623) | Loss 8.7871(9.4262) | Error 0.0189(0.0197) Steps 664(684.20) | Grad Norm 6.5085(6.2567) | Total Time 0.00(0.00)\n",
      "Iter 8560 | Time 18.3407(17.8366) | Bit/dim 3.5973(3.6047) | Xent 0.0692(0.0631) | Loss 8.9426(9.3063) | Error 0.0222(0.0199) Steps 658(683.71) | Grad Norm 7.5171(6.8527) | Total Time 0.00(0.00)\n",
      "Iter 8570 | Time 17.4525(17.8530) | Bit/dim 3.5886(3.6044) | Xent 0.1512(0.0726) | Loss 8.9677(9.2189) | Error 0.0500(0.0228) Steps 700(686.69) | Grad Norm 9.0191(7.4500) | Total Time 0.00(0.00)\n",
      "Iter 8580 | Time 18.5230(17.8714) | Bit/dim 3.6221(3.6106) | Xent 0.0622(0.0767) | Loss 8.9809(9.1717) | Error 0.0211(0.0240) Steps 718(690.60) | Grad Norm 5.1275(7.8491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0156 | Time 92.6821, Epoch Time 1096.3913(1065.0449), Bit/dim 3.6405(best: 3.6141), Xent 1.6743, Loss 4.4777, Error 0.3138(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8590 | Time 17.2506(17.7981) | Bit/dim 3.6001(3.6082) | Xent 0.0712(0.0773) | Loss 8.9115(9.7413) | Error 0.0244(0.0240) Steps 694(691.02) | Grad Norm 5.4973(7.3554) | Total Time 0.00(0.00)\n",
      "Iter 8600 | Time 17.5463(17.8262) | Bit/dim 3.5829(3.6084) | Xent 0.0587(0.0735) | Loss 8.9829(9.5372) | Error 0.0133(0.0226) Steps 724(692.70) | Grad Norm 5.1617(6.8693) | Total Time 0.00(0.00)\n",
      "Iter 8610 | Time 17.7677(17.8773) | Bit/dim 3.6259(3.6074) | Xent 0.0308(0.0700) | Loss 8.9239(9.3791) | Error 0.0100(0.0215) Steps 700(692.91) | Grad Norm 4.1777(6.5492) | Total Time 0.00(0.00)\n",
      "Iter 8620 | Time 17.8753(17.9475) | Bit/dim 3.6199(3.6074) | Xent 0.0695(0.0679) | Loss 8.9922(9.2693) | Error 0.0233(0.0209) Steps 694(693.28) | Grad Norm 5.9576(6.4778) | Total Time 0.00(0.00)\n",
      "Iter 8630 | Time 18.3782(17.9345) | Bit/dim 3.5921(3.6069) | Xent 0.0880(0.0734) | Loss 8.9012(9.1785) | Error 0.0244(0.0222) Steps 652(691.79) | Grad Norm 8.3399(6.8651) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0157 | Time 92.3099, Epoch Time 1099.6184(1066.0821), Bit/dim 3.6301(best: 3.6141), Xent 1.7672, Loss 4.5137, Error 0.3227(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8640 | Time 18.0763(18.0106) | Bit/dim 3.6143(3.6107) | Xent 0.0395(0.0750) | Loss 8.8962(9.8691) | Error 0.0156(0.0228) Steps 664(692.95) | Grad Norm 3.8631(7.0336) | Total Time 0.00(0.00)\n",
      "Iter 8650 | Time 18.4598(18.0379) | Bit/dim 3.5680(3.6087) | Xent 0.0440(0.0690) | Loss 8.8706(9.6235) | Error 0.0100(0.0209) Steps 718(697.98) | Grad Norm 3.2228(6.3761) | Total Time 0.00(0.00)\n",
      "Iter 8660 | Time 18.5954(18.1061) | Bit/dim 3.5973(3.6031) | Xent 0.0668(0.0647) | Loss 9.0454(9.4361) | Error 0.0167(0.0194) Steps 718(700.32) | Grad Norm 8.3230(6.0748) | Total Time 0.00(0.00)\n",
      "Iter 8670 | Time 17.4606(18.0169) | Bit/dim 3.5875(3.6031) | Xent 0.0672(0.0616) | Loss 8.9649(9.3037) | Error 0.0233(0.0183) Steps 682(696.39) | Grad Norm 4.5574(5.8739) | Total Time 0.00(0.00)\n",
      "Iter 8680 | Time 18.1342(17.9929) | Bit/dim 3.5846(3.5996) | Xent 0.0465(0.0592) | Loss 8.8430(9.1927) | Error 0.0133(0.0179) Steps 718(698.45) | Grad Norm 3.6648(5.7355) | Total Time 0.00(0.00)\n",
      "Iter 8690 | Time 17.1645(17.9478) | Bit/dim 3.6142(3.5987) | Xent 0.0423(0.0563) | Loss 8.8662(9.1207) | Error 0.0111(0.0172) Steps 682(694.98) | Grad Norm 3.7442(5.7158) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0158 | Time 91.2903, Epoch Time 1104.9967(1067.2495), Bit/dim 3.6226(best: 3.6141), Xent 1.9284, Loss 4.5868, Error 0.3315(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8700 | Time 18.7637(17.9445) | Bit/dim 3.6038(3.5963) | Xent 0.0346(0.0527) | Loss 8.9694(9.6832) | Error 0.0100(0.0160) Steps 718(691.85) | Grad Norm 4.1938(5.4889) | Total Time 0.00(0.00)\n",
      "Iter 8710 | Time 18.2778(17.9965) | Bit/dim 3.6165(3.5977) | Xent 0.0400(0.0546) | Loss 8.9113(9.4936) | Error 0.0111(0.0166) Steps 676(692.42) | Grad Norm 5.0337(5.4955) | Total Time 0.00(0.00)\n",
      "Iter 8720 | Time 18.5484(17.9419) | Bit/dim 3.5780(3.5974) | Xent 0.0681(0.0559) | Loss 8.9709(9.3505) | Error 0.0189(0.0169) Steps 724(693.51) | Grad Norm 6.3350(5.4825) | Total Time 0.00(0.00)\n",
      "Iter 8730 | Time 17.5588(17.9272) | Bit/dim 3.6087(3.5986) | Xent 0.0564(0.0558) | Loss 8.9667(9.2472) | Error 0.0200(0.0169) Steps 712(694.54) | Grad Norm 6.2368(5.5120) | Total Time 0.00(0.00)\n",
      "Iter 8740 | Time 17.2598(17.9440) | Bit/dim 3.6189(3.5998) | Xent 0.0637(0.0557) | Loss 8.9457(9.1618) | Error 0.0156(0.0171) Steps 664(694.12) | Grad Norm 12.0118(5.8192) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0159 | Time 92.3679, Epoch Time 1101.1684(1068.2671), Bit/dim 3.6221(best: 3.6141), Xent 1.8649, Loss 4.5546, Error 0.3264(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8750 | Time 17.3140(17.9671) | Bit/dim 3.5548(3.6004) | Xent 0.0502(0.0566) | Loss 8.8416(9.8476) | Error 0.0156(0.0172) Steps 688(693.79) | Grad Norm 6.8958(5.9166) | Total Time 0.00(0.00)\n",
      "Iter 8760 | Time 17.6156(17.9425) | Bit/dim 3.5918(3.6025) | Xent 0.0554(0.0630) | Loss 8.9800(9.6327) | Error 0.0167(0.0192) Steps 700(693.06) | Grad Norm 7.0259(6.5207) | Total Time 0.00(0.00)\n",
      "Iter 8770 | Time 17.2117(17.9899) | Bit/dim 3.5976(3.6034) | Xent 0.0622(0.0664) | Loss 8.7532(9.4647) | Error 0.0189(0.0204) Steps 700(695.76) | Grad Norm 5.0258(6.5568) | Total Time 0.00(0.00)\n",
      "Iter 8780 | Time 17.6034(17.9528) | Bit/dim 3.6005(3.6033) | Xent 0.0586(0.0638) | Loss 8.9655(9.3255) | Error 0.0167(0.0195) Steps 718(696.54) | Grad Norm 4.2894(6.2595) | Total Time 0.00(0.00)\n",
      "Iter 8790 | Time 18.1931(17.9161) | Bit/dim 3.5785(3.6016) | Xent 0.0389(0.0595) | Loss 8.8476(9.2146) | Error 0.0156(0.0182) Steps 706(693.07) | Grad Norm 4.0091(5.8064) | Total Time 0.00(0.00)\n",
      "Iter 8800 | Time 18.8189(17.9267) | Bit/dim 3.6172(3.6004) | Xent 0.0592(0.0557) | Loss 9.0785(9.1309) | Error 0.0144(0.0167) Steps 700(692.40) | Grad Norm 3.7375(5.4091) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0160 | Time 92.0808, Epoch Time 1099.8741(1069.2153), Bit/dim 3.6109(best: 3.6141), Xent 1.8187, Loss 4.5202, Error 0.3156(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8810 | Time 17.8564(17.9079) | Bit/dim 3.6262(3.5985) | Xent 0.0854(0.0575) | Loss 9.0023(9.7041) | Error 0.0233(0.0171) Steps 670(689.22) | Grad Norm 7.1549(5.6151) | Total Time 0.00(0.00)\n",
      "Iter 8820 | Time 18.8304(17.9445) | Bit/dim 3.5948(3.5969) | Xent 0.0425(0.0560) | Loss 8.9400(9.4934) | Error 0.0167(0.0169) Steps 694(689.85) | Grad Norm 5.7003(5.7449) | Total Time 0.00(0.00)\n",
      "Iter 8830 | Time 18.1025(17.9731) | Bit/dim 3.5998(3.5992) | Xent 0.0659(0.0548) | Loss 9.0324(9.3563) | Error 0.0244(0.0168) Steps 706(694.16) | Grad Norm 8.4772(5.6080) | Total Time 0.00(0.00)\n",
      "Iter 8840 | Time 17.8966(17.9492) | Bit/dim 3.5923(3.5998) | Xent 0.0863(0.0572) | Loss 9.0154(9.2514) | Error 0.0244(0.0174) Steps 718(695.00) | Grad Norm 6.9458(5.8877) | Total Time 0.00(0.00)\n",
      "Iter 8850 | Time 17.7075(17.9568) | Bit/dim 3.5926(3.5984) | Xent 0.0638(0.0599) | Loss 8.9535(9.1735) | Error 0.0200(0.0182) Steps 688(694.35) | Grad Norm 6.2208(5.6939) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0161 | Time 93.9422, Epoch Time 1103.3537(1070.2395), Bit/dim 3.6269(best: 3.6109), Xent 1.8308, Loss 4.5423, Error 0.3326(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8860 | Time 18.6805(18.0321) | Bit/dim 3.5841(3.5982) | Xent 0.0647(0.0632) | Loss 9.0421(9.8556) | Error 0.0211(0.0194) Steps 706(698.67) | Grad Norm 6.1264(6.3712) | Total Time 0.00(0.00)\n",
      "Iter 8870 | Time 18.0535(18.0502) | Bit/dim 3.5876(3.6004) | Xent 0.1008(0.0667) | Loss 8.9476(9.6191) | Error 0.0278(0.0201) Steps 724(698.35) | Grad Norm 7.6502(6.7195) | Total Time 0.00(0.00)\n",
      "Iter 8880 | Time 17.6415(18.0702) | Bit/dim 3.5979(3.6016) | Xent 0.0962(0.0663) | Loss 9.0402(9.4459) | Error 0.0289(0.0202) Steps 670(696.52) | Grad Norm 6.4782(6.3812) | Total Time 0.00(0.00)\n",
      "Iter 8890 | Time 17.8131(17.9851) | Bit/dim 3.6117(3.6010) | Xent 0.0689(0.0687) | Loss 8.9024(9.3097) | Error 0.0267(0.0209) Steps 700(695.50) | Grad Norm 6.2162(6.3609) | Total Time 0.00(0.00)\n",
      "Iter 8900 | Time 18.0268(18.0346) | Bit/dim 3.6190(3.6025) | Xent 0.1358(0.0739) | Loss 8.8982(9.2218) | Error 0.0356(0.0222) Steps 682(694.40) | Grad Norm 13.2118(6.7394) | Total Time 0.00(0.00)\n",
      "Iter 8910 | Time 18.0337(18.0449) | Bit/dim 3.5813(3.6048) | Xent 0.0846(0.0801) | Loss 8.9709(9.1671) | Error 0.0278(0.0241) Steps 688(695.49) | Grad Norm 9.2449(7.2234) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0162 | Time 92.9266, Epoch Time 1108.6760(1071.3926), Bit/dim 3.6358(best: 3.6109), Xent 1.7600, Loss 4.5157, Error 0.3255(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8920 | Time 18.3698(18.0781) | Bit/dim 3.6194(3.6050) | Xent 0.0497(0.0753) | Loss 8.9144(9.7678) | Error 0.0167(0.0228) Steps 658(695.27) | Grad Norm 7.6921(7.1977) | Total Time 0.00(0.00)\n",
      "Iter 8930 | Time 18.4362(18.1246) | Bit/dim 3.6299(3.6044) | Xent 0.0424(0.0693) | Loss 9.1041(9.5431) | Error 0.0100(0.0208) Steps 718(695.88) | Grad Norm 5.5860(6.7647) | Total Time 0.00(0.00)\n",
      "Iter 8940 | Time 17.5419(18.0917) | Bit/dim 3.6153(3.6018) | Xent 0.0426(0.0625) | Loss 8.9256(9.3680) | Error 0.0122(0.0189) Steps 712(693.92) | Grad Norm 4.6196(6.0548) | Total Time 0.00(0.00)\n",
      "Iter 8950 | Time 18.3802(18.0487) | Bit/dim 3.5719(3.5968) | Xent 0.0635(0.0613) | Loss 8.9308(9.2478) | Error 0.0189(0.0184) Steps 706(693.68) | Grad Norm 5.6439(6.0651) | Total Time 0.00(0.00)\n",
      "Iter 8960 | Time 18.4970(18.0472) | Bit/dim 3.6218(3.5999) | Xent 0.0631(0.0630) | Loss 8.9840(9.1738) | Error 0.0144(0.0187) Steps 670(693.04) | Grad Norm 6.4740(6.2787) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0163 | Time 91.6164, Epoch Time 1104.7307(1072.3927), Bit/dim 3.6235(best: 3.6109), Xent 1.7598, Loss 4.5034, Error 0.3203(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8970 | Time 17.4995(17.9583) | Bit/dim 3.5863(3.6027) | Xent 0.0416(0.0636) | Loss 8.9533(9.8573) | Error 0.0111(0.0186) Steps 670(692.04) | Grad Norm 5.1035(6.3308) | Total Time 0.00(0.00)\n",
      "Iter 8980 | Time 17.6689(17.9119) | Bit/dim 3.5878(3.6017) | Xent 0.0406(0.0624) | Loss 8.9224(9.6115) | Error 0.0144(0.0184) Steps 712(688.56) | Grad Norm 4.4206(6.1343) | Total Time 0.00(0.00)\n",
      "Iter 8990 | Time 17.7296(17.9341) | Bit/dim 3.6439(3.6027) | Xent 0.0697(0.0620) | Loss 8.9660(9.4471) | Error 0.0189(0.0183) Steps 694(691.40) | Grad Norm 9.3824(6.0107) | Total Time 0.00(0.00)\n",
      "Iter 9000 | Time 17.8700(17.9704) | Bit/dim 3.6116(3.6015) | Xent 0.0570(0.0587) | Loss 8.9682(9.3148) | Error 0.0156(0.0173) Steps 700(694.34) | Grad Norm 7.3086(6.0530) | Total Time 0.00(0.00)\n",
      "Iter 9010 | Time 17.6380(18.0416) | Bit/dim 3.5793(3.5985) | Xent 0.0477(0.0559) | Loss 8.8926(9.2033) | Error 0.0111(0.0165) Steps 664(694.86) | Grad Norm 6.3783(5.9141) | Total Time 0.00(0.00)\n",
      "Iter 9020 | Time 18.4584(18.0156) | Bit/dim 3.5801(3.5964) | Xent 0.0711(0.0532) | Loss 8.9648(9.1250) | Error 0.0233(0.0157) Steps 718(698.30) | Grad Norm 5.7818(5.7852) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0164 | Time 92.5387, Epoch Time 1102.1929(1073.2867), Bit/dim 3.6103(best: 3.6109), Xent 1.9481, Loss 4.5843, Error 0.3335(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9030 | Time 18.9068(17.9791) | Bit/dim 3.6074(3.5964) | Xent 0.0517(0.0577) | Loss 8.9600(9.7159) | Error 0.0156(0.0180) Steps 688(695.16) | Grad Norm 7.4122(6.4017) | Total Time 0.00(0.00)\n",
      "Iter 9040 | Time 17.3396(17.9021) | Bit/dim 3.6363(3.5960) | Xent 0.0761(0.0583) | Loss 8.9085(9.5022) | Error 0.0233(0.0180) Steps 682(693.19) | Grad Norm 5.5806(6.2889) | Total Time 0.00(0.00)\n",
      "Iter 9050 | Time 18.1176(17.9088) | Bit/dim 3.5706(3.5966) | Xent 0.0616(0.0577) | Loss 8.8647(9.3463) | Error 0.0189(0.0178) Steps 706(692.73) | Grad Norm 5.5299(6.0878) | Total Time 0.00(0.00)\n",
      "Iter 9060 | Time 17.9340(17.9207) | Bit/dim 3.6000(3.5970) | Xent 0.0580(0.0552) | Loss 8.9057(9.2330) | Error 0.0144(0.0168) Steps 664(690.73) | Grad Norm 4.6420(5.8147) | Total Time 0.00(0.00)\n",
      "Iter 9070 | Time 17.8990(17.9398) | Bit/dim 3.6021(3.5986) | Xent 0.0464(0.0569) | Loss 8.8070(9.1540) | Error 0.0189(0.0176) Steps 712(691.67) | Grad Norm 5.5218(6.1574) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0165 | Time 92.9186, Epoch Time 1096.7370(1073.9902), Bit/dim 3.6123(best: 3.6103), Xent 1.7921, Loss 4.5084, Error 0.3188(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9080 | Time 17.9543(17.9171) | Bit/dim 3.5641(3.5975) | Xent 0.0438(0.0557) | Loss 8.8403(9.8528) | Error 0.0167(0.0171) Steps 712(694.32) | Grad Norm 3.6063(5.6959) | Total Time 0.00(0.00)\n",
      "Iter 9090 | Time 17.4796(17.8638) | Bit/dim 3.5904(3.5942) | Xent 0.0625(0.0567) | Loss 8.9159(9.6077) | Error 0.0222(0.0174) Steps 676(690.84) | Grad Norm 6.4515(5.5741) | Total Time 0.00(0.00)\n",
      "Iter 9100 | Time 18.0061(17.8661) | Bit/dim 3.6039(3.5942) | Xent 0.0492(0.0556) | Loss 8.9949(9.4265) | Error 0.0144(0.0173) Steps 712(689.94) | Grad Norm 3.5924(5.5401) | Total Time 0.00(0.00)\n",
      "Iter 9110 | Time 18.0818(17.9084) | Bit/dim 3.6000(3.5945) | Xent 0.0357(0.0535) | Loss 8.9796(9.2879) | Error 0.0111(0.0166) Steps 688(689.71) | Grad Norm 4.7027(5.5457) | Total Time 0.00(0.00)\n",
      "Iter 9120 | Time 17.9272(17.8491) | Bit/dim 3.5833(3.5934) | Xent 0.0460(0.0525) | Loss 8.8196(9.1869) | Error 0.0122(0.0161) Steps 658(688.64) | Grad Norm 3.4716(5.5117) | Total Time 0.00(0.00)\n",
      "Iter 9130 | Time 17.6779(17.8353) | Bit/dim 3.6186(3.5938) | Xent 0.0576(0.0551) | Loss 9.0225(9.1211) | Error 0.0200(0.0167) Steps 664(687.40) | Grad Norm 5.8693(5.6580) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0166 | Time 92.2081, Epoch Time 1094.2256(1074.5973), Bit/dim 3.6101(best: 3.6103), Xent 1.8669, Loss 4.5435, Error 0.3292(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9140 | Time 17.3636(17.8555) | Bit/dim 3.6103(3.5946) | Xent 0.0446(0.0539) | Loss 8.9484(9.7089) | Error 0.0122(0.0162) Steps 694(687.72) | Grad Norm 6.3303(5.5856) | Total Time 0.00(0.00)\n",
      "Iter 9150 | Time 17.1987(17.8691) | Bit/dim 3.5833(3.5949) | Xent 0.0370(0.0513) | Loss 8.8311(9.5036) | Error 0.0122(0.0153) Steps 694(686.53) | Grad Norm 4.4462(5.5356) | Total Time 0.00(0.00)\n",
      "Iter 9160 | Time 18.1864(17.9303) | Bit/dim 3.5706(3.5923) | Xent 0.0497(0.0547) | Loss 8.7917(9.3462) | Error 0.0144(0.0161) Steps 688(689.23) | Grad Norm 5.4564(5.6144) | Total Time 0.00(0.00)\n",
      "Iter 9170 | Time 17.6078(17.9486) | Bit/dim 3.6518(3.5965) | Xent 0.0886(0.0577) | Loss 9.1523(9.2509) | Error 0.0267(0.0171) Steps 688(692.33) | Grad Norm 8.3199(6.1160) | Total Time 0.00(0.00)\n",
      "Iter 9180 | Time 18.6895(18.0486) | Bit/dim 3.5860(3.5941) | Xent 0.0691(0.0597) | Loss 8.9281(9.1740) | Error 0.0233(0.0179) Steps 706(697.27) | Grad Norm 5.6928(6.1682) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0167 | Time 93.3139, Epoch Time 1105.4880(1075.5240), Bit/dim 3.6141(best: 3.6101), Xent 1.7151, Loss 4.4716, Error 0.3056(best: 0.3065)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9190 | Time 18.1941(18.0319) | Bit/dim 3.5894(3.5978) | Xent 0.0616(0.0599) | Loss 8.9580(9.8774) | Error 0.0189(0.0181) Steps 706(700.13) | Grad Norm 8.1154(6.3611) | Total Time 0.00(0.00)\n",
      "Iter 9200 | Time 18.8325(18.0826) | Bit/dim 3.5781(3.5958) | Xent 0.0572(0.0616) | Loss 8.9110(9.6246) | Error 0.0111(0.0184) Steps 688(699.34) | Grad Norm 7.2494(6.3403) | Total Time 0.00(0.00)\n",
      "Iter 9210 | Time 18.0831(18.0840) | Bit/dim 3.5921(3.5945) | Xent 0.0410(0.0601) | Loss 8.9208(9.4355) | Error 0.0122(0.0178) Steps 694(698.37) | Grad Norm 3.5829(6.0168) | Total Time 0.00(0.00)\n",
      "Iter 9220 | Time 18.5851(18.0655) | Bit/dim 3.5728(3.5908) | Xent 0.0392(0.0570) | Loss 8.8314(9.2766) | Error 0.0111(0.0171) Steps 736(693.44) | Grad Norm 4.5621(5.5306) | Total Time 0.00(0.00)\n",
      "Iter 9230 | Time 17.4288(17.9346) | Bit/dim 3.6070(3.5909) | Xent 0.0389(0.0552) | Loss 8.9629(9.1777) | Error 0.0122(0.0169) Steps 658(688.50) | Grad Norm 4.2887(5.1626) | Total Time 0.00(0.00)\n",
      "Iter 9240 | Time 17.1759(17.8635) | Bit/dim 3.5864(3.5896) | Xent 0.0506(0.0523) | Loss 8.9254(9.0936) | Error 0.0122(0.0159) Steps 658(685.88) | Grad Norm 3.6991(4.8952) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0168 | Time 91.4992, Epoch Time 1098.1486(1076.2028), Bit/dim 3.6094(best: 3.6101), Xent 1.8845, Loss 4.5516, Error 0.3211(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9250 | Time 17.7971(17.8206) | Bit/dim 3.5805(3.5911) | Xent 0.0611(0.0530) | Loss 8.9386(9.6632) | Error 0.0156(0.0157) Steps 694(682.55) | Grad Norm 3.5623(4.6843) | Total Time 0.00(0.00)\n",
      "Iter 9260 | Time 18.8241(17.9154) | Bit/dim 3.5794(3.5909) | Xent 0.0852(0.0549) | Loss 8.9276(9.4676) | Error 0.0189(0.0163) Steps 730(690.38) | Grad Norm 5.7263(4.8437) | Total Time 0.00(0.00)\n",
      "Iter 9270 | Time 18.5548(18.0257) | Bit/dim 3.5952(3.5936) | Xent 0.0457(0.0578) | Loss 8.9778(9.3367) | Error 0.0167(0.0175) Steps 682(694.13) | Grad Norm 10.6705(5.4576) | Total Time 0.00(0.00)\n",
      "Iter 9280 | Time 17.5559(18.0883) | Bit/dim 3.6061(3.5964) | Xent 0.0470(0.0583) | Loss 8.8395(9.2293) | Error 0.0156(0.0177) Steps 700(697.82) | Grad Norm 4.6639(5.5415) | Total Time 0.00(0.00)\n",
      "Iter 9290 | Time 17.6979(18.0549) | Bit/dim 3.5640(3.5911) | Xent 0.0381(0.0594) | Loss 8.8510(9.1337) | Error 0.0100(0.0181) Steps 670(697.21) | Grad Norm 5.0564(5.6534) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0169 | Time 92.0211, Epoch Time 1113.1904(1077.3124), Bit/dim 3.6134(best: 3.6094), Xent 1.8605, Loss 4.5436, Error 0.3291(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9300 | Time 18.6787(18.1505) | Bit/dim 3.5868(3.5948) | Xent 0.0528(0.0643) | Loss 9.0093(9.8407) | Error 0.0167(0.0194) Steps 700(699.74) | Grad Norm 7.8392(6.6153) | Total Time 0.00(0.00)\n",
      "Iter 9310 | Time 17.6369(18.1598) | Bit/dim 3.5976(3.5948) | Xent 0.0671(0.0632) | Loss 9.0371(9.6092) | Error 0.0122(0.0188) Steps 688(702.21) | Grad Norm 6.6664(6.8294) | Total Time 0.00(0.00)\n",
      "Iter 9320 | Time 18.1938(18.1393) | Bit/dim 3.6043(3.5948) | Xent 0.0662(0.0624) | Loss 9.0867(9.4331) | Error 0.0200(0.0187) Steps 688(700.40) | Grad Norm 5.2911(6.8650) | Total Time 0.00(0.00)\n",
      "Iter 9330 | Time 18.6180(18.1478) | Bit/dim 3.6218(3.5972) | Xent 0.0456(0.0639) | Loss 8.9918(9.3064) | Error 0.0200(0.0192) Steps 724(698.62) | Grad Norm 5.3403(6.6943) | Total Time 0.00(0.00)\n",
      "Iter 9340 | Time 17.7679(18.2004) | Bit/dim 3.5922(3.5971) | Xent 0.0507(0.0624) | Loss 8.7899(9.2029) | Error 0.0178(0.0185) Steps 706(699.41) | Grad Norm 4.3713(6.3768) | Total Time 0.00(0.00)\n",
      "Iter 9350 | Time 17.8721(18.1963) | Bit/dim 3.5906(3.5938) | Xent 0.0801(0.0643) | Loss 8.8960(9.1243) | Error 0.0244(0.0193) Steps 706(701.46) | Grad Norm 10.0897(6.4491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0170 | Time 91.7843, Epoch Time 1115.5252(1078.4588), Bit/dim 3.6100(best: 3.6094), Xent 1.7895, Loss 4.5048, Error 0.3204(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9360 | Time 18.4379(18.1456) | Bit/dim 3.6126(3.5968) | Xent 0.0670(0.0618) | Loss 9.0236(9.7112) | Error 0.0200(0.0184) Steps 724(699.01) | Grad Norm 7.9516(6.5318) | Total Time 0.00(0.00)\n",
      "Iter 9370 | Time 18.4898(18.1026) | Bit/dim 3.5818(3.5955) | Xent 0.0739(0.0606) | Loss 8.9697(9.5131) | Error 0.0211(0.0177) Steps 736(699.63) | Grad Norm 9.2308(6.6012) | Total Time 0.00(0.00)\n",
      "Iter 9380 | Time 18.8926(18.1673) | Bit/dim 3.5990(3.5971) | Xent 0.0852(0.0638) | Loss 9.0090(9.3634) | Error 0.0333(0.0188) Steps 640(696.75) | Grad Norm 8.0666(6.9963) | Total Time 0.00(0.00)\n",
      "Iter 9390 | Time 19.2650(18.1404) | Bit/dim 3.6030(3.5973) | Xent 0.0917(0.0710) | Loss 9.0694(9.2601) | Error 0.0267(0.0214) Steps 760(697.98) | Grad Norm 5.4170(7.0296) | Total Time 0.00(0.00)\n",
      "Iter 9400 | Time 18.6519(18.1562) | Bit/dim 3.5845(3.5967) | Xent 0.0482(0.0698) | Loss 8.8931(9.1808) | Error 0.0133(0.0211) Steps 730(700.30) | Grad Norm 6.4899(6.9726) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0171 | Time 93.2002, Epoch Time 1111.5046(1079.4501), Bit/dim 3.6218(best: 3.6094), Xent 1.8225, Loss 4.5330, Error 0.3188(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9410 | Time 17.7813(18.0893) | Bit/dim 3.6110(3.6009) | Xent 0.0570(0.0708) | Loss 8.8636(9.8381) | Error 0.0222(0.0215) Steps 676(693.63) | Grad Norm 11.6938(7.7521) | Total Time 0.00(0.00)\n",
      "Iter 9420 | Time 17.4367(18.0433) | Bit/dim 3.5686(3.6014) | Xent 0.0434(0.0686) | Loss 8.8556(9.6055) | Error 0.0133(0.0209) Steps 706(694.92) | Grad Norm 4.5829(7.5894) | Total Time 0.00(0.00)\n",
      "Iter 9430 | Time 18.7152(18.0720) | Bit/dim 3.5819(3.5997) | Xent 0.0247(0.0641) | Loss 8.7831(9.4258) | Error 0.0056(0.0191) Steps 700(696.22) | Grad Norm 4.1264(7.0738) | Total Time 0.00(0.00)\n",
      "Iter 9440 | Time 17.6725(18.1404) | Bit/dim 3.5756(3.5960) | Xent 0.0306(0.0614) | Loss 8.8330(9.2850) | Error 0.0089(0.0181) Steps 688(695.59) | Grad Norm 3.3975(6.3415) | Total Time 0.00(0.00)\n",
      "Iter 9450 | Time 18.3211(18.1083) | Bit/dim 3.5896(3.5956) | Xent 0.0546(0.0581) | Loss 9.0027(9.1849) | Error 0.0167(0.0171) Steps 694(693.23) | Grad Norm 6.2180(5.9430) | Total Time 0.00(0.00)\n",
      "Iter 9460 | Time 18.4594(18.1130) | Bit/dim 3.6185(3.5936) | Xent 0.0973(0.0579) | Loss 9.1311(9.1074) | Error 0.0300(0.0176) Steps 706(694.08) | Grad Norm 8.1487(5.9976) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0172 | Time 91.7494, Epoch Time 1108.7849(1080.3302), Bit/dim 3.6071(best: 3.6094), Xent 1.8451, Loss 4.5296, Error 0.3255(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9470 | Time 18.1170(18.1299) | Bit/dim 3.6106(3.5911) | Xent 0.0867(0.0601) | Loss 9.0181(9.7021) | Error 0.0244(0.0180) Steps 712(697.87) | Grad Norm 9.3133(6.4038) | Total Time 0.00(0.00)\n",
      "Iter 9480 | Time 17.8985(18.1409) | Bit/dim 3.6107(3.5962) | Xent 0.0710(0.0665) | Loss 8.9539(9.5121) | Error 0.0233(0.0204) Steps 670(696.07) | Grad Norm 7.2708(7.0800) | Total Time 0.00(0.00)\n",
      "Iter 9490 | Time 17.6151(18.0904) | Bit/dim 3.5923(3.5978) | Xent 0.0610(0.0681) | Loss 8.9562(9.3660) | Error 0.0189(0.0208) Steps 682(695.71) | Grad Norm 6.6972(7.2592) | Total Time 0.00(0.00)\n",
      "Iter 9500 | Time 18.8945(18.1167) | Bit/dim 3.6215(3.5975) | Xent 0.0405(0.0708) | Loss 8.9492(9.2626) | Error 0.0156(0.0218) Steps 706(696.51) | Grad Norm 6.1621(7.2804) | Total Time 0.00(0.00)\n",
      "Iter 9510 | Time 18.4057(18.1370) | Bit/dim 3.6307(3.5997) | Xent 0.0970(0.0712) | Loss 9.0747(9.1921) | Error 0.0256(0.0216) Steps 730(698.86) | Grad Norm 5.7218(6.9033) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0173 | Time 92.7566, Epoch Time 1109.2534(1081.1979), Bit/dim 3.6103(best: 3.6071), Xent 1.7769, Loss 4.4988, Error 0.3271(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9520 | Time 17.0481(18.0705) | Bit/dim 3.5992(3.5983) | Xent 0.0540(0.0678) | Loss 8.8985(9.8663) | Error 0.0144(0.0205) Steps 670(694.47) | Grad Norm 4.9449(6.3624) | Total Time 0.00(0.00)\n",
      "Iter 9530 | Time 17.3701(17.9991) | Bit/dim 3.6199(3.5958) | Xent 0.0505(0.0634) | Loss 8.8951(9.6149) | Error 0.0167(0.0193) Steps 682(693.77) | Grad Norm 4.8907(5.8588) | Total Time 0.00(0.00)\n",
      "Iter 9540 | Time 18.3052(18.0337) | Bit/dim 3.6089(3.5942) | Xent 0.0506(0.0588) | Loss 8.9449(9.4190) | Error 0.0189(0.0180) Steps 712(696.53) | Grad Norm 5.6682(5.4588) | Total Time 0.00(0.00)\n",
      "Iter 9550 | Time 18.3369(18.0983) | Bit/dim 3.5959(3.5881) | Xent 0.0509(0.0551) | Loss 8.8467(9.2743) | Error 0.0144(0.0170) Steps 706(699.04) | Grad Norm 5.3862(5.2715) | Total Time 0.00(0.00)\n",
      "Iter 9560 | Time 18.7276(18.1591) | Bit/dim 3.5644(3.5881) | Xent 0.0285(0.0516) | Loss 8.8482(9.1765) | Error 0.0078(0.0158) Steps 658(699.23) | Grad Norm 3.2095(4.9737) | Total Time 0.00(0.00)\n",
      "Iter 9570 | Time 18.8606(18.1097) | Bit/dim 3.5960(3.5897) | Xent 0.0700(0.0520) | Loss 8.9992(9.1155) | Error 0.0222(0.0159) Steps 736(699.17) | Grad Norm 5.8490(5.0246) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0174 | Time 94.1494, Epoch Time 1110.3210(1082.0716), Bit/dim 3.6031(best: 3.6071), Xent 1.8450, Loss 4.5256, Error 0.3215(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9580 | Time 18.1661(18.0545) | Bit/dim 3.6006(3.5878) | Xent 0.0425(0.0500) | Loss 8.9364(9.6800) | Error 0.0133(0.0153) Steps 700(698.45) | Grad Norm 4.2495(4.8450) | Total Time 0.00(0.00)\n",
      "Iter 9590 | Time 17.6605(18.0343) | Bit/dim 3.5829(3.5895) | Xent 0.0458(0.0540) | Loss 8.8964(9.4863) | Error 0.0122(0.0163) Steps 694(695.91) | Grad Norm 4.5411(5.2628) | Total Time 0.00(0.00)\n",
      "Iter 9600 | Time 17.4868(18.0493) | Bit/dim 3.5987(3.5942) | Xent 0.0590(0.0518) | Loss 8.9579(9.3386) | Error 0.0133(0.0153) Steps 694(697.42) | Grad Norm 7.3131(5.4254) | Total Time 0.00(0.00)\n",
      "Iter 9610 | Time 17.9084(17.9932) | Bit/dim 3.5746(3.5940) | Xent 0.0358(0.0530) | Loss 8.9117(9.2224) | Error 0.0144(0.0158) Steps 700(695.67) | Grad Norm 3.4555(5.9882) | Total Time 0.00(0.00)\n",
      "Iter 9620 | Time 17.9612(18.0229) | Bit/dim 3.6106(3.5920) | Xent 0.1031(0.0584) | Loss 9.1721(9.1510) | Error 0.0278(0.0174) Steps 700(697.80) | Grad Norm 8.7888(6.3508) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0175 | Time 95.0785, Epoch Time 1103.9429(1082.7277), Bit/dim 3.6180(best: 3.6031), Xent 1.8125, Loss 4.5242, Error 0.3228(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9630 | Time 17.1416(17.9487) | Bit/dim 3.5695(3.5916) | Xent 0.0655(0.0593) | Loss 8.6911(9.8252) | Error 0.0200(0.0180) Steps 670(694.26) | Grad Norm 4.8090(6.0597) | Total Time 0.00(0.00)\n",
      "Iter 9640 | Time 18.0238(17.9744) | Bit/dim 3.5811(3.5912) | Xent 0.0604(0.0571) | Loss 8.9320(9.5976) | Error 0.0189(0.0171) Steps 652(691.60) | Grad Norm 4.3476(5.6262) | Total Time 0.00(0.00)\n",
      "Iter 9650 | Time 17.9072(18.0636) | Bit/dim 3.5911(3.5911) | Xent 0.0625(0.0569) | Loss 8.8397(9.4235) | Error 0.0178(0.0168) Steps 712(693.14) | Grad Norm 6.4747(5.3238) | Total Time 0.00(0.00)\n",
      "Iter 9660 | Time 18.0607(18.1524) | Bit/dim 3.6225(3.5931) | Xent 0.0786(0.0568) | Loss 9.0660(9.2971) | Error 0.0178(0.0171) Steps 724(696.28) | Grad Norm 5.8676(5.9072) | Total Time 0.00(0.00)\n",
      "Iter 9670 | Time 17.8193(18.1872) | Bit/dim 3.5925(3.5948) | Xent 0.0577(0.0575) | Loss 9.0238(9.2152) | Error 0.0211(0.0179) Steps 676(698.70) | Grad Norm 6.8914(6.1627) | Total Time 0.00(0.00)\n",
      "Iter 9680 | Time 18.3179(18.1788) | Bit/dim 3.5457(3.5933) | Xent 0.0344(0.0555) | Loss 8.6174(9.1308) | Error 0.0133(0.0167) Steps 694(698.43) | Grad Norm 4.7809(5.9190) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0176 | Time 93.3055, Epoch Time 1116.4239(1083.7386), Bit/dim 3.6077(best: 3.6031), Xent 1.8261, Loss 4.5207, Error 0.3269(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9690 | Time 17.4563(18.1634) | Bit/dim 3.5755(3.5918) | Xent 0.0794(0.0532) | Loss 8.8342(9.7070) | Error 0.0233(0.0158) Steps 706(700.79) | Grad Norm 5.8528(5.4761) | Total Time 0.00(0.00)\n",
      "Iter 9700 | Time 19.8489(18.2388) | Bit/dim 3.5702(3.5871) | Xent 0.0449(0.0499) | Loss 8.8893(9.4901) | Error 0.0133(0.0145) Steps 688(699.89) | Grad Norm 4.8849(5.4147) | Total Time 0.00(0.00)\n",
      "Iter 9710 | Time 17.9790(18.3008) | Bit/dim 3.6350(3.5880) | Xent 0.0569(0.0536) | Loss 9.0350(9.3481) | Error 0.0122(0.0156) Steps 694(702.82) | Grad Norm 6.8118(5.7451) | Total Time 0.00(0.00)\n",
      "Iter 9720 | Time 18.2162(18.3170) | Bit/dim 3.5904(3.5910) | Xent 0.0946(0.0579) | Loss 9.0343(9.2463) | Error 0.0322(0.0171) Steps 718(703.51) | Grad Norm 8.9061(6.1331) | Total Time 0.00(0.00)\n",
      "Iter 9730 | Time 18.5020(18.3342) | Bit/dim 3.6198(3.5950) | Xent 0.0906(0.0667) | Loss 9.1123(9.1799) | Error 0.0289(0.0195) Steps 694(705.63) | Grad Norm 10.7931(6.7249) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0177 | Time 93.6073, Epoch Time 1124.8917(1084.9732), Bit/dim 3.6143(best: 3.6031), Xent 1.7066, Loss 4.4676, Error 0.3200(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9740 | Time 18.5483(18.4060) | Bit/dim 3.5841(3.5965) | Xent 0.0435(0.0695) | Loss 9.0292(9.8827) | Error 0.0122(0.0203) Steps 712(711.00) | Grad Norm 5.0686(6.6983) | Total Time 0.00(0.00)\n",
      "Iter 9750 | Time 18.2858(18.3518) | Bit/dim 3.5684(3.5949) | Xent 0.0636(0.0681) | Loss 8.8740(9.6394) | Error 0.0200(0.0204) Steps 712(708.83) | Grad Norm 5.2366(6.3597) | Total Time 0.00(0.00)\n",
      "Iter 9760 | Time 18.1399(18.3147) | Bit/dim 3.5783(3.5953) | Xent 0.0706(0.0669) | Loss 8.9422(9.4573) | Error 0.0200(0.0202) Steps 658(706.81) | Grad Norm 4.6068(6.2347) | Total Time 0.00(0.00)\n",
      "Iter 9770 | Time 17.3004(18.2473) | Bit/dim 3.6050(3.5924) | Xent 0.0706(0.0633) | Loss 8.9406(9.3160) | Error 0.0178(0.0190) Steps 688(706.80) | Grad Norm 5.4551(5.8143) | Total Time 0.00(0.00)\n",
      "Iter 9780 | Time 18.3276(18.1541) | Bit/dim 3.5999(3.5937) | Xent 0.0499(0.0627) | Loss 9.0319(9.2138) | Error 0.0122(0.0190) Steps 724(707.36) | Grad Norm 6.5532(5.6334) | Total Time 0.00(0.00)\n",
      "Iter 9790 | Time 18.1326(18.1146) | Bit/dim 3.6114(3.5894) | Xent 0.0250(0.0590) | Loss 8.8912(9.1203) | Error 0.0056(0.0179) Steps 700(703.88) | Grad Norm 3.3350(5.2748) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0178 | Time 94.5100, Epoch Time 1111.9297(1085.7819), Bit/dim 3.6009(best: 3.6031), Xent 1.8138, Loss 4.5078, Error 0.3248(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9800 | Time 18.3191(18.0688) | Bit/dim 3.5759(3.5888) | Xent 0.0236(0.0557) | Loss 8.8754(9.6964) | Error 0.0078(0.0170) Steps 688(704.14) | Grad Norm 3.0229(5.0549) | Total Time 0.00(0.00)\n",
      "Iter 9810 | Time 18.8650(18.0745) | Bit/dim 3.5729(3.5878) | Xent 0.0373(0.0545) | Loss 8.9151(9.4885) | Error 0.0122(0.0167) Steps 760(705.27) | Grad Norm 6.1225(5.0894) | Total Time 0.00(0.00)\n",
      "Iter 9820 | Time 18.4671(18.1345) | Bit/dim 3.5738(3.5862) | Xent 0.0327(0.0509) | Loss 8.9307(9.3394) | Error 0.0122(0.0157) Steps 706(706.52) | Grad Norm 5.7163(5.0242) | Total Time 0.00(0.00)\n",
      "Iter 9830 | Time 17.9315(18.1347) | Bit/dim 3.5753(3.5851) | Xent 0.0716(0.0514) | Loss 8.9653(9.2218) | Error 0.0189(0.0156) Steps 730(705.17) | Grad Norm 5.0106(5.1302) | Total Time 0.00(0.00)\n",
      "Iter 9840 | Time 17.6618(18.1115) | Bit/dim 3.5694(3.5842) | Xent 0.0714(0.0520) | Loss 8.8460(9.1443) | Error 0.0244(0.0161) Steps 664(705.35) | Grad Norm 7.4831(5.2056) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0179 | Time 93.1794, Epoch Time 1109.5067(1086.4936), Bit/dim 3.6076(best: 3.6009), Xent 1.8704, Loss 4.5428, Error 0.3269(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9850 | Time 18.7892(18.1370) | Bit/dim 3.5847(3.5833) | Xent 0.0568(0.0526) | Loss 8.9488(9.7930) | Error 0.0122(0.0163) Steps 724(703.27) | Grad Norm 3.8693(5.2520) | Total Time 0.00(0.00)\n",
      "Iter 9860 | Time 18.8426(18.1959) | Bit/dim 3.6087(3.5863) | Xent 0.0494(0.0503) | Loss 8.9620(9.5664) | Error 0.0144(0.0155) Steps 682(701.77) | Grad Norm 5.5441(5.0426) | Total Time 0.00(0.00)\n",
      "Iter 9870 | Time 18.6948(18.2336) | Bit/dim 3.5921(3.5852) | Xent 0.0259(0.0468) | Loss 8.8803(9.3914) | Error 0.0100(0.0144) Steps 742(703.40) | Grad Norm 3.6926(4.7780) | Total Time 0.00(0.00)\n",
      "Iter 9880 | Time 18.6626(18.2730) | Bit/dim 3.5645(3.5827) | Xent 0.0435(0.0467) | Loss 8.9403(9.2572) | Error 0.0122(0.0141) Steps 706(700.64) | Grad Norm 3.4226(4.7375) | Total Time 0.00(0.00)\n",
      "Iter 9890 | Time 17.7478(18.2182) | Bit/dim 3.5641(3.5819) | Xent 0.0433(0.0470) | Loss 8.7259(9.1589) | Error 0.0122(0.0140) Steps 676(699.99) | Grad Norm 4.5818(4.7035) | Total Time 0.00(0.00)\n",
      "Iter 9900 | Time 18.9778(18.2345) | Bit/dim 3.5658(3.5812) | Xent 0.0358(0.0484) | Loss 8.8829(9.0915) | Error 0.0122(0.0144) Steps 688(698.96) | Grad Norm 5.1502(4.6932) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0180 | Time 93.9394, Epoch Time 1119.9276(1087.4967), Bit/dim 3.5995(best: 3.6009), Xent 1.8504, Loss 4.5246, Error 0.3204(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9910 | Time 18.6443(18.2239) | Bit/dim 3.6016(3.5826) | Xent 0.0690(0.0515) | Loss 8.9188(9.6844) | Error 0.0167(0.0153) Steps 730(700.03) | Grad Norm 8.6588(5.4521) | Total Time 0.00(0.00)\n",
      "Iter 9920 | Time 19.5233(18.2319) | Bit/dim 3.5633(3.5853) | Xent 0.0906(0.0546) | Loss 8.8758(9.4827) | Error 0.0311(0.0165) Steps 730(700.26) | Grad Norm 9.4129(5.8595) | Total Time 0.00(0.00)\n",
      "Iter 9930 | Time 18.3110(18.1465) | Bit/dim 3.6130(3.5912) | Xent 0.0553(0.0556) | Loss 8.8609(9.3443) | Error 0.0167(0.0168) Steps 682(699.31) | Grad Norm 4.7110(6.1592) | Total Time 0.00(0.00)\n",
      "Iter 9940 | Time 17.4829(18.0791) | Bit/dim 3.5901(3.5895) | Xent 0.0413(0.0544) | Loss 8.8931(9.2257) | Error 0.0144(0.0166) Steps 670(698.27) | Grad Norm 3.9846(5.8329) | Total Time 0.00(0.00)\n",
      "Iter 9950 | Time 17.6374(18.0988) | Bit/dim 3.5865(3.5895) | Xent 0.0654(0.0567) | Loss 8.8922(9.1444) | Error 0.0222(0.0172) Steps 688(695.53) | Grad Norm 9.2221(5.9538) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0181 | Time 93.8501, Epoch Time 1111.3945(1088.2136), Bit/dim 3.6013(best: 3.5995), Xent 1.9602, Loss 4.5814, Error 0.3274(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9960 | Time 18.7600(18.1448) | Bit/dim 3.5626(3.5887) | Xent 0.0639(0.0554) | Loss 9.0141(9.8489) | Error 0.0167(0.0165) Steps 730(697.95) | Grad Norm 5.8662(6.0930) | Total Time 0.00(0.00)\n",
      "Iter 9970 | Time 19.3300(18.2158) | Bit/dim 3.6052(3.5896) | Xent 0.0316(0.0544) | Loss 9.0005(9.6047) | Error 0.0089(0.0160) Steps 724(700.05) | Grad Norm 4.0967(6.1081) | Total Time 0.00(0.00)\n",
      "Iter 9980 | Time 18.5035(18.3079) | Bit/dim 3.5670(3.5865) | Xent 0.0388(0.0512) | Loss 8.8413(9.4175) | Error 0.0111(0.0150) Steps 730(702.76) | Grad Norm 6.8248(5.9264) | Total Time 0.00(0.00)\n",
      "Iter 9990 | Time 19.3367(18.3156) | Bit/dim 3.5711(3.5850) | Xent 0.0972(0.0525) | Loss 9.0092(9.2836) | Error 0.0256(0.0154) Steps 748(705.66) | Grad Norm 8.2042(5.9528) | Total Time 0.00(0.00)\n",
      "Iter 10000 | Time 18.7153(18.2867) | Bit/dim 3.5830(3.5864) | Xent 0.0502(0.0536) | Loss 8.8487(9.1924) | Error 0.0167(0.0163) Steps 706(706.21) | Grad Norm 7.3770(6.0771) | Total Time 0.00(0.00)\n",
      "Iter 10010 | Time 17.3001(18.2742) | Bit/dim 3.6035(3.5871) | Xent 0.0796(0.0568) | Loss 8.8677(9.1238) | Error 0.0256(0.0173) Steps 688(703.01) | Grad Norm 8.4530(6.3575) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0182 | Time 92.8824, Epoch Time 1123.6082(1089.2754), Bit/dim 3.6030(best: 3.5995), Xent 1.8629, Loss 4.5345, Error 0.3245(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10020 | Time 18.6059(18.3065) | Bit/dim 3.5889(3.5869) | Xent 0.0632(0.0590) | Loss 8.9782(9.6885) | Error 0.0178(0.0180) Steps 700(705.67) | Grad Norm 6.1025(6.5502) | Total Time 0.00(0.00)\n",
      "Iter 10030 | Time 18.3260(18.3450) | Bit/dim 3.5715(3.5868) | Xent 0.0731(0.0663) | Loss 8.9783(9.4925) | Error 0.0244(0.0201) Steps 700(706.07) | Grad Norm 5.7113(6.9750) | Total Time 0.00(0.00)\n",
      "Iter 10040 | Time 19.1771(18.3808) | Bit/dim 3.5907(3.5887) | Xent 0.0544(0.0672) | Loss 8.9555(9.3514) | Error 0.0156(0.0205) Steps 748(706.68) | Grad Norm 4.2513(6.6441) | Total Time 0.00(0.00)\n",
      "Iter 10050 | Time 18.2877(18.3946) | Bit/dim 3.5620(3.5903) | Xent 0.0458(0.0647) | Loss 8.8309(9.2424) | Error 0.0111(0.0193) Steps 664(706.19) | Grad Norm 3.2058(5.9426) | Total Time 0.00(0.00)\n",
      "Iter 10060 | Time 18.3333(18.3357) | Bit/dim 3.6167(3.5894) | Xent 0.0608(0.0650) | Loss 9.0023(9.1564) | Error 0.0211(0.0196) Steps 730(706.13) | Grad Norm 5.8546(6.3452) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0183 | Time 93.8347, Epoch Time 1123.9020(1090.3142), Bit/dim 3.6131(best: 3.5995), Xent 1.7429, Loss 4.4845, Error 0.3240(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10070 | Time 18.1628(18.2943) | Bit/dim 3.5864(3.5937) | Xent 0.0777(0.0794) | Loss 8.9349(9.8537) | Error 0.0167(0.0234) Steps 706(707.65) | Grad Norm 5.8033(7.5588) | Total Time 0.00(0.00)\n",
      "Iter 10080 | Time 18.0842(18.2280) | Bit/dim 3.5752(3.5973) | Xent 0.0566(0.0748) | Loss 8.9552(9.6314) | Error 0.0178(0.0225) Steps 706(709.18) | Grad Norm 4.1932(7.0276) | Total Time 0.00(0.00)\n",
      "Iter 10090 | Time 17.7723(18.2040) | Bit/dim 3.5622(3.5919) | Xent 0.0463(0.0697) | Loss 8.8520(9.4425) | Error 0.0178(0.0210) Steps 676(706.02) | Grad Norm 4.9369(6.3783) | Total Time 0.00(0.00)\n",
      "Iter 10100 | Time 18.1309(18.1896) | Bit/dim 3.5676(3.5900) | Xent 0.0396(0.0657) | Loss 8.7918(9.2997) | Error 0.0111(0.0199) Steps 706(705.45) | Grad Norm 4.1184(5.8447) | Total Time 0.00(0.00)\n",
      "Iter 10110 | Time 18.0055(18.1452) | Bit/dim 3.5956(3.5856) | Xent 0.0386(0.0608) | Loss 8.8860(9.1827) | Error 0.0122(0.0185) Steps 718(703.29) | Grad Norm 3.3343(5.3494) | Total Time 0.00(0.00)\n",
      "Iter 10120 | Time 18.2516(18.1883) | Bit/dim 3.5863(3.5842) | Xent 0.0460(0.0599) | Loss 8.9724(9.1075) | Error 0.0089(0.0181) Steps 718(704.43) | Grad Norm 5.0148(5.6374) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0184 | Time 94.4903, Epoch Time 1112.8841(1090.9913), Bit/dim 3.6004(best: 3.5995), Xent 1.8080, Loss 4.5044, Error 0.3234(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10130 | Time 18.1706(18.2036) | Bit/dim 3.5823(3.5829) | Xent 0.0579(0.0547) | Loss 8.7902(9.6753) | Error 0.0178(0.0164) Steps 700(706.30) | Grad Norm 6.2239(5.2933) | Total Time 0.00(0.00)\n",
      "Iter 10140 | Time 18.1159(18.2923) | Bit/dim 3.5602(3.5816) | Xent 0.0262(0.0531) | Loss 8.8518(9.4656) | Error 0.0100(0.0155) Steps 694(705.68) | Grad Norm 6.3641(5.1092) | Total Time 0.00(0.00)\n",
      "Iter 10150 | Time 18.0927(18.4137) | Bit/dim 3.5666(3.5765) | Xent 0.0563(0.0505) | Loss 8.9508(9.3027) | Error 0.0156(0.0146) Steps 724(707.62) | Grad Norm 5.9281(4.9566) | Total Time 0.00(0.00)\n",
      "Iter 10160 | Time 17.7609(18.3542) | Bit/dim 3.5806(3.5777) | Xent 0.0232(0.0499) | Loss 8.9448(9.1922) | Error 0.0078(0.0148) Steps 718(707.70) | Grad Norm 4.4317(5.1433) | Total Time 0.00(0.00)\n",
      "Iter 10170 | Time 18.0647(18.3363) | Bit/dim 3.5949(3.5778) | Xent 0.0378(0.0474) | Loss 8.9236(9.1078) | Error 0.0067(0.0140) Steps 688(708.21) | Grad Norm 4.6135(5.0020) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0185 | Time 95.4090, Epoch Time 1127.0563(1092.0733), Bit/dim 3.5983(best: 3.5995), Xent 1.8753, Loss 4.5359, Error 0.3237(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10180 | Time 18.2502(18.3436) | Bit/dim 3.5975(3.5807) | Xent 0.0290(0.0473) | Loss 8.8857(9.8357) | Error 0.0078(0.0138) Steps 724(712.42) | Grad Norm 8.0508(5.3140) | Total Time 0.00(0.00)\n",
      "Iter 10190 | Time 18.7812(18.3528) | Bit/dim 3.5824(3.5812) | Xent 0.0228(0.0446) | Loss 8.8555(9.5876) | Error 0.0078(0.0132) Steps 724(711.86) | Grad Norm 5.8769(5.2331) | Total Time 0.00(0.00)\n",
      "Iter 10200 | Time 18.4197(18.3196) | Bit/dim 3.5971(3.5791) | Xent 0.0283(0.0453) | Loss 8.9229(9.4007) | Error 0.0044(0.0135) Steps 700(708.87) | Grad Norm 2.5912(5.3296) | Total Time 0.00(0.00)\n",
      "Iter 10210 | Time 17.1646(18.2540) | Bit/dim 3.5830(3.5834) | Xent 0.1330(0.0604) | Loss 9.0009(9.2842) | Error 0.0356(0.0178) Steps 676(708.77) | Grad Norm 10.8017(6.7446) | Total Time 0.00(0.00)\n",
      "Iter 10220 | Time 18.8775(18.3315) | Bit/dim 3.5956(3.5891) | Xent 0.0918(0.0667) | Loss 8.9537(9.2047) | Error 0.0333(0.0203) Steps 724(710.71) | Grad Norm 5.8206(7.0156) | Total Time 0.00(0.00)\n",
      "Iter 10230 | Time 18.7935(18.4784) | Bit/dim 3.6053(3.5885) | Xent 0.0524(0.0670) | Loss 8.9645(9.1320) | Error 0.0178(0.0199) Steps 694(710.88) | Grad Norm 4.4558(6.3465) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0186 | Time 95.9394, Epoch Time 1130.4674(1093.2251), Bit/dim 3.6088(best: 3.5983), Xent 1.8941, Loss 4.5559, Error 0.3329(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10240 | Time 19.0040(18.5623) | Bit/dim 3.5598(3.5852) | Xent 0.0623(0.0646) | Loss 8.9080(9.7417) | Error 0.0200(0.0190) Steps 742(714.16) | Grad Norm 3.8179(5.7774) | Total Time 0.00(0.00)\n",
      "Iter 10250 | Time 18.9282(18.5479) | Bit/dim 3.5678(3.5858) | Xent 0.0329(0.0620) | Loss 8.8345(9.5263) | Error 0.0100(0.0184) Steps 736(711.76) | Grad Norm 4.2069(5.3974) | Total Time 0.00(0.00)\n",
      "Iter 10260 | Time 17.8410(18.4603) | Bit/dim 3.5398(3.5835) | Xent 0.0463(0.0586) | Loss 8.7709(9.3540) | Error 0.0189(0.0180) Steps 718(710.25) | Grad Norm 5.6956(5.3940) | Total Time 0.00(0.00)\n",
      "Iter 10270 | Time 17.9875(18.4561) | Bit/dim 3.5867(3.5819) | Xent 0.0279(0.0558) | Loss 8.8374(9.2123) | Error 0.0067(0.0174) Steps 688(709.68) | Grad Norm 4.2721(5.1309) | Total Time 0.00(0.00)\n",
      "Iter 10280 | Time 18.4704(18.3964) | Bit/dim 3.5272(3.5782) | Xent 0.0507(0.0517) | Loss 8.7053(9.1120) | Error 0.0133(0.0162) Steps 712(708.98) | Grad Norm 4.2478(4.8603) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0187 | Time 94.1925, Epoch Time 1132.4703(1094.4024), Bit/dim 3.5970(best: 3.5983), Xent 1.9780, Loss 4.5860, Error 0.3310(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10290 | Time 17.6830(18.4030) | Bit/dim 3.5604(3.5814) | Xent 0.0492(0.0520) | Loss 8.8606(9.8137) | Error 0.0189(0.0162) Steps 694(705.15) | Grad Norm 4.9176(5.1430) | Total Time 0.00(0.00)\n",
      "Iter 10300 | Time 18.1836(18.3220) | Bit/dim 3.5715(3.5796) | Xent 0.0373(0.0489) | Loss 8.7559(9.5672) | Error 0.0078(0.0148) Steps 694(704.03) | Grad Norm 3.3473(4.8539) | Total Time 0.00(0.00)\n",
      "Iter 10310 | Time 17.8913(18.2832) | Bit/dim 3.5983(3.5797) | Xent 0.0255(0.0463) | Loss 8.9164(9.3849) | Error 0.0056(0.0139) Steps 730(704.71) | Grad Norm 3.3893(4.5638) | Total Time 0.00(0.00)\n",
      "Iter 10320 | Time 19.7397(18.3989) | Bit/dim 3.5756(3.5778) | Xent 0.0696(0.0466) | Loss 8.9494(9.2659) | Error 0.0178(0.0141) Steps 694(709.13) | Grad Norm 7.9833(4.7889) | Total Time 0.00(0.00)\n",
      "Iter 10330 | Time 17.7203(18.4602) | Bit/dim 3.6011(3.5777) | Xent 0.0548(0.0486) | Loss 8.9376(9.1709) | Error 0.0178(0.0144) Steps 718(712.20) | Grad Norm 7.3575(5.0553) | Total Time 0.00(0.00)\n",
      "Iter 10340 | Time 18.6524(18.4139) | Bit/dim 3.5741(3.5774) | Xent 0.0611(0.0522) | Loss 8.8648(9.1008) | Error 0.0144(0.0152) Steps 682(709.94) | Grad Norm 6.3314(5.2594) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0188 | Time 93.3699, Epoch Time 1123.7294(1095.2823), Bit/dim 3.5984(best: 3.5970), Xent 1.8803, Loss 4.5386, Error 0.3304(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10350 | Time 18.5101(18.4005) | Bit/dim 3.5534(3.5765) | Xent 0.0535(0.0519) | Loss 8.9606(9.6735) | Error 0.0189(0.0153) Steps 742(709.75) | Grad Norm 6.1620(5.3090) | Total Time 0.00(0.00)\n",
      "Iter 10360 | Time 18.5169(18.3869) | Bit/dim 3.5985(3.5788) | Xent 0.0361(0.0553) | Loss 8.8959(9.4663) | Error 0.0133(0.0165) Steps 694(708.89) | Grad Norm 3.7049(5.3369) | Total Time 0.00(0.00)\n",
      "Iter 10370 | Time 18.4185(18.4159) | Bit/dim 3.5842(3.5808) | Xent 0.0357(0.0557) | Loss 8.9226(9.3157) | Error 0.0100(0.0165) Steps 712(710.94) | Grad Norm 4.4847(5.1673) | Total Time 0.00(0.00)\n",
      "Iter 10380 | Time 18.0812(18.3712) | Bit/dim 3.5364(3.5796) | Xent 0.0411(0.0517) | Loss 8.7818(9.2073) | Error 0.0144(0.0153) Steps 706(710.77) | Grad Norm 3.9217(4.8082) | Total Time 0.00(0.00)\n",
      "Iter 10390 | Time 19.0573(18.3472) | Bit/dim 3.5333(3.5753) | Xent 0.0466(0.0486) | Loss 8.9010(9.1127) | Error 0.0111(0.0146) Steps 736(711.82) | Grad Norm 5.9960(4.6922) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0189 | Time 95.2590, Epoch Time 1125.4743(1096.1880), Bit/dim 3.5924(best: 3.5970), Xent 1.8824, Loss 4.5337, Error 0.3222(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10400 | Time 18.4423(18.4177) | Bit/dim 3.5742(3.5758) | Xent 0.0434(0.0490) | Loss 8.9069(9.8133) | Error 0.0122(0.0146) Steps 742(713.97) | Grad Norm 3.8052(4.6094) | Total Time 0.00(0.00)\n",
      "Iter 10410 | Time 18.0892(18.3786) | Bit/dim 3.5864(3.5763) | Xent 0.0305(0.0470) | Loss 8.8848(9.5661) | Error 0.0100(0.0139) Steps 712(714.97) | Grad Norm 3.5030(4.5597) | Total Time 0.00(0.00)\n",
      "Iter 10420 | Time 18.5637(18.3910) | Bit/dim 3.5778(3.5746) | Xent 0.0541(0.0457) | Loss 8.8643(9.3862) | Error 0.0133(0.0135) Steps 724(715.27) | Grad Norm 4.7041(4.6416) | Total Time 0.00(0.00)\n",
      "Iter 10430 | Time 18.1552(18.3576) | Bit/dim 3.5896(3.5763) | Xent 0.0820(0.0483) | Loss 8.9529(9.2532) | Error 0.0222(0.0142) Steps 688(714.46) | Grad Norm 7.9937(4.9070) | Total Time 0.00(0.00)\n",
      "Iter 10440 | Time 18.6018(18.3973) | Bit/dim 3.5898(3.5752) | Xent 0.0429(0.0492) | Loss 8.8784(9.1512) | Error 0.0122(0.0147) Steps 694(713.28) | Grad Norm 3.6923(5.0926) | Total Time 0.00(0.00)\n",
      "Iter 10450 | Time 17.8507(18.3742) | Bit/dim 3.5856(3.5818) | Xent 0.0521(0.0517) | Loss 8.8565(9.0971) | Error 0.0111(0.0151) Steps 718(714.98) | Grad Norm 6.1453(5.5220) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0190 | Time 93.9025, Epoch Time 1127.0013(1097.1124), Bit/dim 3.6107(best: 3.5924), Xent 1.8948, Loss 4.5581, Error 0.3351(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10460 | Time 17.7814(18.3206) | Bit/dim 3.5945(3.5798) | Xent 0.0988(0.0534) | Loss 8.9932(9.6854) | Error 0.0322(0.0161) Steps 700(715.27) | Grad Norm 9.4447(5.5020) | Total Time 0.00(0.00)\n",
      "Iter 10470 | Time 18.8553(18.4099) | Bit/dim 3.6221(3.5839) | Xent 0.0374(0.0564) | Loss 8.9221(9.4835) | Error 0.0122(0.0170) Steps 664(714.14) | Grad Norm 4.6570(5.8052) | Total Time 0.00(0.00)\n",
      "Iter 10480 | Time 19.1424(18.4863) | Bit/dim 3.5867(3.5838) | Xent 0.0297(0.0544) | Loss 8.7960(9.3265) | Error 0.0089(0.0165) Steps 724(712.71) | Grad Norm 3.3560(5.4566) | Total Time 0.00(0.00)\n",
      "Iter 10490 | Time 18.4499(18.5304) | Bit/dim 3.5598(3.5813) | Xent 0.0318(0.0530) | Loss 8.8907(9.2063) | Error 0.0122(0.0161) Steps 724(713.46) | Grad Norm 4.6057(5.2376) | Total Time 0.00(0.00)\n",
      "Iter 10500 | Time 17.5821(18.4979) | Bit/dim 3.5674(3.5795) | Xent 0.0411(0.0529) | Loss 8.8386(9.1257) | Error 0.0156(0.0162) Steps 718(715.67) | Grad Norm 4.2662(5.0785) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0191 | Time 93.1948, Epoch Time 1131.9414(1098.1573), Bit/dim 3.5938(best: 3.5924), Xent 1.9064, Loss 4.5469, Error 0.3285(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10510 | Time 18.9243(18.4825) | Bit/dim 3.5666(3.5824) | Xent 0.0643(0.0511) | Loss 8.9763(9.8338) | Error 0.0156(0.0156) Steps 736(713.62) | Grad Norm 5.0265(4.8897) | Total Time 0.00(0.00)\n",
      "Iter 10520 | Time 18.3672(18.4880) | Bit/dim 3.5926(3.5782) | Xent 0.0404(0.0509) | Loss 8.8479(9.5793) | Error 0.0111(0.0154) Steps 712(712.79) | Grad Norm 3.6612(4.9029) | Total Time 0.00(0.00)\n",
      "Iter 10530 | Time 18.4064(18.4913) | Bit/dim 3.5929(3.5795) | Xent 0.0925(0.0536) | Loss 9.0306(9.4070) | Error 0.0289(0.0165) Steps 742(713.76) | Grad Norm 5.2815(4.8296) | Total Time 0.00(0.00)\n",
      "Iter 10540 | Time 17.9381(18.5202) | Bit/dim 3.5678(3.5793) | Xent 0.0568(0.0509) | Loss 8.8473(9.2651) | Error 0.0178(0.0155) Steps 718(713.68) | Grad Norm 3.3887(4.5154) | Total Time 0.00(0.00)\n",
      "Iter 10550 | Time 18.1105(18.5323) | Bit/dim 3.5990(3.5784) | Xent 0.0456(0.0482) | Loss 8.9048(9.1670) | Error 0.0156(0.0147) Steps 694(716.45) | Grad Norm 5.7346(4.4152) | Total Time 0.00(0.00)\n",
      "Iter 10560 | Time 17.9071(18.5269) | Bit/dim 3.5798(3.5766) | Xent 0.0912(0.0508) | Loss 9.0194(9.1005) | Error 0.0300(0.0155) Steps 724(715.11) | Grad Norm 9.0820(4.7990) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0192 | Time 94.0213, Epoch Time 1134.3544(1099.2432), Bit/dim 3.5976(best: 3.5924), Xent 1.8600, Loss 4.5276, Error 0.3205(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10570 | Time 18.7516(18.5527) | Bit/dim 3.6058(3.5785) | Xent 0.0458(0.0500) | Loss 8.9296(9.7149) | Error 0.0167(0.0154) Steps 730(715.20) | Grad Norm 5.6639(4.9586) | Total Time 0.00(0.00)\n",
      "Iter 10580 | Time 18.3665(18.6308) | Bit/dim 3.5682(3.5799) | Xent 0.0516(0.0504) | Loss 8.7645(9.4943) | Error 0.0156(0.0157) Steps 724(718.91) | Grad Norm 3.6393(4.8029) | Total Time 0.00(0.00)\n",
      "Iter 10590 | Time 19.3589(18.6154) | Bit/dim 3.5595(3.5790) | Xent 0.0726(0.0506) | Loss 8.9217(9.3367) | Error 0.0211(0.0156) Steps 736(721.89) | Grad Norm 5.8109(4.7698) | Total Time 0.00(0.00)\n",
      "Iter 10600 | Time 19.1694(18.7268) | Bit/dim 3.5587(3.5767) | Xent 0.0378(0.0499) | Loss 8.8842(9.2100) | Error 0.0100(0.0153) Steps 742(719.49) | Grad Norm 3.9709(4.6002) | Total Time 0.00(0.00)\n",
      "Iter 10610 | Time 18.9211(18.7525) | Bit/dim 3.5621(3.5735) | Xent 0.0469(0.0476) | Loss 8.8847(9.1181) | Error 0.0167(0.0145) Steps 748(720.43) | Grad Norm 4.5375(4.3966) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0193 | Time 94.3973, Epoch Time 1148.4081(1100.7181), Bit/dim 3.5921(best: 3.5924), Xent 1.8858, Loss 4.5350, Error 0.3248(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10620 | Time 18.0850(18.7253) | Bit/dim 3.5898(3.5736) | Xent 0.0406(0.0474) | Loss 8.9000(9.8264) | Error 0.0111(0.0145) Steps 718(722.77) | Grad Norm 4.2387(4.6427) | Total Time 0.00(0.00)\n",
      "Iter 10630 | Time 19.5011(18.6953) | Bit/dim 3.5637(3.5742) | Xent 0.0654(0.0467) | Loss 8.8887(9.5873) | Error 0.0167(0.0140) Steps 754(722.36) | Grad Norm 5.5364(4.7907) | Total Time 0.00(0.00)\n",
      "Iter 10640 | Time 19.0996(18.6876) | Bit/dim 3.5935(3.5704) | Xent 0.0412(0.0464) | Loss 8.8956(9.3886) | Error 0.0133(0.0140) Steps 742(719.37) | Grad Norm 7.1057(4.8823) | Total Time 0.00(0.00)\n",
      "Iter 10650 | Time 18.7364(18.6671) | Bit/dim 3.5663(3.5713) | Xent 0.0378(0.0455) | Loss 8.8736(9.2543) | Error 0.0122(0.0135) Steps 694(717.35) | Grad Norm 4.8766(4.8254) | Total Time 0.00(0.00)\n",
      "Iter 10660 | Time 18.1322(18.7426) | Bit/dim 3.5550(3.5712) | Xent 0.0416(0.0440) | Loss 8.8248(9.1607) | Error 0.0100(0.0133) Steps 706(719.60) | Grad Norm 5.5352(4.8873) | Total Time 0.00(0.00)\n",
      "Iter 10670 | Time 19.3490(18.8037) | Bit/dim 3.5547(3.5725) | Xent 0.0330(0.0432) | Loss 8.8094(9.0922) | Error 0.0111(0.0133) Steps 718(719.76) | Grad Norm 3.7092(4.7563) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0194 | Time 93.9865, Epoch Time 1148.4328(1102.1496), Bit/dim 3.5921(best: 3.5921), Xent 1.9261, Loss 4.5551, Error 0.3264(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10680 | Time 18.9355(18.7574) | Bit/dim 3.5734(3.5723) | Xent 0.0355(0.0442) | Loss 8.8356(9.7097) | Error 0.0089(0.0135) Steps 700(720.54) | Grad Norm 5.2536(4.7745) | Total Time 0.00(0.00)\n",
      "Iter 10690 | Time 18.5007(18.6721) | Bit/dim 3.5697(3.5744) | Xent 0.0615(0.0448) | Loss 8.9422(9.5019) | Error 0.0167(0.0138) Steps 712(720.20) | Grad Norm 10.4306(5.3684) | Total Time 0.00(0.00)\n",
      "Iter 10700 | Time 18.9767(18.7088) | Bit/dim 3.5661(3.5791) | Xent 0.0814(0.0511) | Loss 8.9297(9.3647) | Error 0.0300(0.0156) Steps 742(723.59) | Grad Norm 8.9081(5.9957) | Total Time 0.00(0.00)\n",
      "Iter 10710 | Time 19.0494(18.7295) | Bit/dim 3.5900(3.5762) | Xent 0.0429(0.0572) | Loss 8.8335(9.2486) | Error 0.0156(0.0173) Steps 724(727.43) | Grad Norm 4.8308(6.0943) | Total Time 0.00(0.00)\n",
      "Iter 10720 | Time 20.2546(18.7305) | Bit/dim 3.5594(3.5755) | Xent 0.0436(0.0545) | Loss 8.9480(9.1603) | Error 0.0122(0.0163) Steps 766(729.19) | Grad Norm 4.7580(5.6353) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0195 | Time 93.7133, Epoch Time 1141.4250(1103.3278), Bit/dim 3.5882(best: 3.5921), Xent 1.8499, Loss 4.5131, Error 0.3207(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10730 | Time 18.7056(18.7424) | Bit/dim 3.5676(3.5761) | Xent 0.0565(0.0511) | Loss 9.0541(9.8502) | Error 0.0156(0.0151) Steps 724(725.36) | Grad Norm 4.5445(5.1822) | Total Time 0.00(0.00)\n",
      "Iter 10740 | Time 18.3368(18.6753) | Bit/dim 3.5919(3.5765) | Xent 0.0237(0.0466) | Loss 8.8176(9.5837) | Error 0.0100(0.0139) Steps 712(722.33) | Grad Norm 3.1227(4.8529) | Total Time 0.00(0.00)\n",
      "Iter 10750 | Time 18.7637(18.7690) | Bit/dim 3.5776(3.5721) | Xent 0.0620(0.0445) | Loss 8.8393(9.3928) | Error 0.0222(0.0137) Steps 718(725.18) | Grad Norm 3.8157(4.7839) | Total Time 0.00(0.00)\n",
      "Iter 10760 | Time 18.5463(18.7452) | Bit/dim 3.5781(3.5727) | Xent 0.0383(0.0482) | Loss 8.8922(9.2706) | Error 0.0078(0.0146) Steps 766(726.36) | Grad Norm 3.9617(4.7770) | Total Time 0.00(0.00)\n",
      "Iter 10770 | Time 18.9085(18.7887) | Bit/dim 3.5947(3.5745) | Xent 0.0414(0.0500) | Loss 8.9202(9.1840) | Error 0.0144(0.0148) Steps 724(726.67) | Grad Norm 6.9040(4.8309) | Total Time 0.00(0.00)\n",
      "Iter 10780 | Time 19.2443(18.7215) | Bit/dim 3.5769(3.5736) | Xent 0.0831(0.0522) | Loss 8.9001(9.1076) | Error 0.0278(0.0156) Steps 766(725.00) | Grad Norm 5.8183(5.0452) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0196 | Time 94.5180, Epoch Time 1147.2372(1104.6451), Bit/dim 3.5904(best: 3.5882), Xent 1.9020, Loss 4.5414, Error 0.3314(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10790 | Time 19.0476(18.7205) | Bit/dim 3.5967(3.5767) | Xent 0.0610(0.0516) | Loss 8.9722(9.7076) | Error 0.0156(0.0156) Steps 754(724.21) | Grad Norm 4.4382(5.0573) | Total Time 0.00(0.00)\n",
      "Iter 10800 | Time 18.7779(18.7851) | Bit/dim 3.5425(3.5751) | Xent 0.0920(0.0524) | Loss 8.8328(9.4947) | Error 0.0244(0.0158) Steps 718(723.46) | Grad Norm 6.0838(4.9329) | Total Time 0.00(0.00)\n",
      "Iter 10810 | Time 18.8153(18.7905) | Bit/dim 3.5593(3.5752) | Xent 0.0372(0.0529) | Loss 8.9164(9.3484) | Error 0.0089(0.0158) Steps 706(724.90) | Grad Norm 4.7650(4.9446) | Total Time 0.00(0.00)\n",
      "Iter 10820 | Time 18.4644(18.7597) | Bit/dim 3.5571(3.5727) | Xent 0.0321(0.0508) | Loss 8.7676(9.2144) | Error 0.0089(0.0156) Steps 712(721.89) | Grad Norm 5.9018(4.8402) | Total Time 0.00(0.00)\n",
      "Iter 10830 | Time 17.8080(18.7546) | Bit/dim 3.5654(3.5705) | Xent 0.0565(0.0491) | Loss 8.7147(9.1145) | Error 0.0200(0.0149) Steps 724(722.76) | Grad Norm 7.1217(5.2378) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0197 | Time 95.1736, Epoch Time 1149.8442(1106.0011), Bit/dim 3.5929(best: 3.5882), Xent 1.9203, Loss 4.5530, Error 0.3262(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10840 | Time 17.7769(18.6809) | Bit/dim 3.5776(3.5717) | Xent 0.0511(0.0501) | Loss 8.9255(9.8294) | Error 0.0133(0.0151) Steps 706(722.10) | Grad Norm 3.3859(4.9945) | Total Time 0.00(0.00)\n",
      "Iter 10850 | Time 19.3963(18.7835) | Bit/dim 3.5851(3.5745) | Xent 0.0490(0.0486) | Loss 9.0085(9.5913) | Error 0.0144(0.0145) Steps 748(721.97) | Grad Norm 5.0412(4.7770) | Total Time 0.00(0.00)\n",
      "Iter 10860 | Time 18.9680(18.7881) | Bit/dim 3.5244(3.5706) | Xent 0.1087(0.0490) | Loss 8.8870(9.3978) | Error 0.0244(0.0144) Steps 742(721.58) | Grad Norm 7.4496(4.8577) | Total Time 0.00(0.00)\n",
      "Iter 10870 | Time 18.7186(18.7904) | Bit/dim 3.6007(3.5698) | Xent 0.0624(0.0493) | Loss 9.0386(9.2626) | Error 0.0233(0.0150) Steps 730(723.29) | Grad Norm 6.7661(5.0044) | Total Time 0.00(0.00)\n",
      "Iter 10880 | Time 18.7551(18.7280) | Bit/dim 3.5671(3.5709) | Xent 0.0330(0.0485) | Loss 8.8854(9.1641) | Error 0.0056(0.0145) Steps 730(723.65) | Grad Norm 3.3954(4.8286) | Total Time 0.00(0.00)\n",
      "Iter 10890 | Time 18.6454(18.7021) | Bit/dim 3.5731(3.5723) | Xent 0.0591(0.0482) | Loss 8.8444(9.0860) | Error 0.0156(0.0142) Steps 712(722.70) | Grad Norm 4.7695(4.7316) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0198 | Time 95.2147, Epoch Time 1146.0088(1107.2013), Bit/dim 3.5912(best: 3.5882), Xent 1.9115, Loss 4.5469, Error 0.3187(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10900 | Time 19.0715(18.6920) | Bit/dim 3.5608(3.5688) | Xent 0.0289(0.0454) | Loss 8.9883(9.6881) | Error 0.0089(0.0136) Steps 724(723.43) | Grad Norm 4.1014(4.5092) | Total Time 0.00(0.00)\n",
      "Iter 10910 | Time 18.4502(18.6558) | Bit/dim 3.5664(3.5701) | Xent 0.0525(0.0455) | Loss 8.9752(9.4642) | Error 0.0167(0.0136) Steps 730(722.72) | Grad Norm 5.2025(4.6589) | Total Time 0.00(0.00)\n",
      "Iter 10920 | Time 19.0030(18.6383) | Bit/dim 3.5921(3.5701) | Xent 0.0936(0.0506) | Loss 8.9507(9.3115) | Error 0.0322(0.0150) Steps 700(718.29) | Grad Norm 5.5993(5.2227) | Total Time 0.00(0.00)\n",
      "Iter 10930 | Time 19.2408(18.7129) | Bit/dim 3.5919(3.5733) | Xent 0.0895(0.0543) | Loss 9.0167(9.2195) | Error 0.0267(0.0160) Steps 742(719.41) | Grad Norm 6.2505(5.3234) | Total Time 0.00(0.00)\n",
      "Iter 10940 | Time 18.3301(18.7398) | Bit/dim 3.6069(3.5742) | Xent 0.0547(0.0528) | Loss 8.9334(9.1369) | Error 0.0122(0.0156) Steps 718(720.50) | Grad Norm 4.5849(5.1414) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0199 | Time 95.6122, Epoch Time 1148.0099(1108.4256), Bit/dim 3.5871(best: 3.5882), Xent 1.8515, Loss 4.5129, Error 0.3219(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10950 | Time 19.0092(18.8302) | Bit/dim 3.5481(3.5720) | Xent 0.0294(0.0507) | Loss 8.8957(9.8488) | Error 0.0078(0.0151) Steps 718(722.65) | Grad Norm 4.8425(5.0739) | Total Time 0.00(0.00)\n",
      "Iter 10960 | Time 19.2948(18.9009) | Bit/dim 3.5581(3.5728) | Xent 0.0910(0.0509) | Loss 9.0620(9.6083) | Error 0.0267(0.0151) Steps 718(726.12) | Grad Norm 6.6033(5.2960) | Total Time 0.00(0.00)\n",
      "Iter 10970 | Time 19.3650(18.9061) | Bit/dim 3.5899(3.5778) | Xent 0.1040(0.0616) | Loss 8.9652(9.4464) | Error 0.0311(0.0185) Steps 688(726.43) | Grad Norm 13.0571(6.5508) | Total Time 0.00(0.00)\n",
      "Iter 10980 | Time 18.4283(18.8076) | Bit/dim 3.5991(3.5783) | Xent 0.0748(0.0628) | Loss 8.9615(9.3107) | Error 0.0211(0.0190) Steps 718(725.22) | Grad Norm 6.8387(6.5429) | Total Time 0.00(0.00)\n",
      "Iter 10990 | Time 18.0346(18.8040) | Bit/dim 3.5627(3.5805) | Xent 0.0396(0.0601) | Loss 8.7934(9.2032) | Error 0.0111(0.0183) Steps 730(723.78) | Grad Norm 4.8592(6.2919) | Total Time 0.00(0.00)\n",
      "Iter 11000 | Time 18.7190(18.8213) | Bit/dim 3.5637(3.5806) | Xent 0.0915(0.0611) | Loss 8.7599(9.1250) | Error 0.0289(0.0186) Steps 736(726.28) | Grad Norm 9.2888(6.3945) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0200 | Time 94.9656, Epoch Time 1152.1980(1109.7388), Bit/dim 3.5990(best: 3.5871), Xent 1.8106, Loss 4.5043, Error 0.3217(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11010 | Time 18.4189(18.8751) | Bit/dim 3.6078(3.5806) | Xent 0.0253(0.0573) | Loss 8.9400(9.7288) | Error 0.0078(0.0174) Steps 712(725.90) | Grad Norm 7.2185(6.4367) | Total Time 0.00(0.00)\n",
      "Iter 11020 | Time 19.4158(18.9346) | Bit/dim 3.5813(3.5808) | Xent 0.0488(0.0574) | Loss 8.8887(9.5160) | Error 0.0167(0.0172) Steps 712(728.84) | Grad Norm 8.7793(6.2832) | Total Time 0.00(0.00)\n",
      "Iter 11030 | Time 19.2051(18.9034) | Bit/dim 3.5680(3.5768) | Xent 0.0360(0.0538) | Loss 8.9348(9.3503) | Error 0.0111(0.0163) Steps 730(728.28) | Grad Norm 3.9407(5.9677) | Total Time 0.00(0.00)\n",
      "Iter 11040 | Time 19.1223(18.9638) | Bit/dim 3.5405(3.5712) | Xent 0.0354(0.0519) | Loss 8.7891(9.2292) | Error 0.0111(0.0156) Steps 730(732.02) | Grad Norm 5.6508(5.6717) | Total Time 0.00(0.00)\n",
      "Iter 11050 | Time 18.6144(18.9312) | Bit/dim 3.5496(3.5731) | Xent 0.0572(0.0492) | Loss 8.8300(9.1461) | Error 0.0144(0.0149) Steps 736(730.22) | Grad Norm 5.3499(5.3154) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0201 | Time 94.7700, Epoch Time 1159.7066(1111.2378), Bit/dim 3.5920(best: 3.5871), Xent 1.8477, Loss 4.5158, Error 0.3194(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11060 | Time 19.3920(18.9456) | Bit/dim 3.5571(3.5720) | Xent 0.0328(0.0474) | Loss 8.8508(9.8310) | Error 0.0111(0.0144) Steps 760(735.18) | Grad Norm 3.1217(5.1027) | Total Time 0.00(0.00)\n",
      "Iter 11070 | Time 18.1441(19.0111) | Bit/dim 3.5527(3.5722) | Xent 0.0538(0.0447) | Loss 8.8904(9.5888) | Error 0.0178(0.0137) Steps 712(736.94) | Grad Norm 5.7463(4.9318) | Total Time 0.00(0.00)\n",
      "Iter 11080 | Time 19.1219(18.9734) | Bit/dim 3.5559(3.5699) | Xent 0.0649(0.0503) | Loss 8.9243(9.4086) | Error 0.0189(0.0148) Steps 742(736.70) | Grad Norm 5.2963(5.3539) | Total Time 0.00(0.00)\n",
      "Iter 11090 | Time 19.7776(19.0121) | Bit/dim 3.6013(3.5743) | Xent 0.0582(0.0521) | Loss 8.9765(9.2892) | Error 0.0144(0.0155) Steps 736(737.33) | Grad Norm 4.7775(5.1216) | Total Time 0.00(0.00)\n",
      "Iter 11100 | Time 18.4904(19.0225) | Bit/dim 3.5985(3.5736) | Xent 0.0651(0.0562) | Loss 9.0589(9.1975) | Error 0.0267(0.0167) Steps 736(739.18) | Grad Norm 4.6757(5.1446) | Total Time 0.00(0.00)\n",
      "Iter 11110 | Time 18.9208(19.0899) | Bit/dim 3.5638(3.5761) | Xent 0.0558(0.0570) | Loss 8.9149(9.1280) | Error 0.0167(0.0170) Steps 754(743.71) | Grad Norm 4.0153(4.9224) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0202 | Time 95.1919, Epoch Time 1167.3691(1112.9217), Bit/dim 3.5934(best: 3.5871), Xent 1.8502, Loss 4.5185, Error 0.3269(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11120 | Time 19.3513(19.1112) | Bit/dim 3.5712(3.5768) | Xent 0.0212(0.0528) | Loss 8.9363(9.7376) | Error 0.0067(0.0156) Steps 706(740.76) | Grad Norm 2.9632(4.6589) | Total Time 0.00(0.00)\n",
      "Iter 11130 | Time 18.3268(19.0168) | Bit/dim 3.5688(3.5755) | Xent 0.0395(0.0508) | Loss 8.9393(9.5132) | Error 0.0189(0.0154) Steps 706(736.80) | Grad Norm 6.0936(4.6489) | Total Time 0.00(0.00)\n",
      "Iter 11140 | Time 18.7626(18.9305) | Bit/dim 3.5794(3.5720) | Xent 0.0539(0.0476) | Loss 8.9796(9.3462) | Error 0.0133(0.0145) Steps 748(735.70) | Grad Norm 5.0448(4.6413) | Total Time 0.00(0.00)\n",
      "Iter 11150 | Time 18.9897(18.9374) | Bit/dim 3.5623(3.5675) | Xent 0.0756(0.0470) | Loss 8.8523(9.2293) | Error 0.0144(0.0141) Steps 658(731.96) | Grad Norm 5.4760(4.6677) | Total Time 0.00(0.00)\n",
      "Iter 11160 | Time 18.7743(18.8974) | Bit/dim 3.5872(3.5667) | Xent 0.0397(0.0475) | Loss 8.8797(9.1342) | Error 0.0100(0.0142) Steps 730(731.51) | Grad Norm 5.1130(4.6976) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0203 | Time 95.2168, Epoch Time 1154.0030(1114.1542), Bit/dim 3.5882(best: 3.5871), Xent 2.0235, Loss 4.5999, Error 0.3380(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11170 | Time 19.4811(18.9480) | Bit/dim 3.5669(3.5703) | Xent 0.0526(0.0477) | Loss 8.9281(9.8412) | Error 0.0167(0.0145) Steps 736(731.90) | Grad Norm 7.6881(4.9533) | Total Time 0.00(0.00)\n",
      "Iter 11180 | Time 19.3006(18.9188) | Bit/dim 3.5527(3.5693) | Xent 0.0870(0.0494) | Loss 8.8053(9.5898) | Error 0.0222(0.0147) Steps 748(733.40) | Grad Norm 8.3352(5.0713) | Total Time 0.00(0.00)\n",
      "Iter 11190 | Time 19.5714(19.0031) | Bit/dim 3.5804(3.5719) | Xent 0.0396(0.0504) | Loss 8.8882(9.4121) | Error 0.0100(0.0150) Steps 742(734.61) | Grad Norm 4.0265(5.2050) | Total Time 0.00(0.00)\n",
      "Iter 11200 | Time 19.3632(19.0573) | Bit/dim 3.5694(3.5733) | Xent 0.0300(0.0487) | Loss 8.8450(9.2803) | Error 0.0089(0.0146) Steps 694(734.09) | Grad Norm 5.4004(5.0729) | Total Time 0.00(0.00)\n",
      "Iter 11210 | Time 19.1702(19.1125) | Bit/dim 3.5762(3.5729) | Xent 0.0514(0.0501) | Loss 9.0701(9.2013) | Error 0.0144(0.0150) Steps 748(736.28) | Grad Norm 4.0717(5.0062) | Total Time 0.00(0.00)\n",
      "Iter 11220 | Time 18.9959(19.1557) | Bit/dim 3.5803(3.5736) | Xent 0.0456(0.0529) | Loss 8.9759(9.1263) | Error 0.0178(0.0163) Steps 712(736.11) | Grad Norm 6.4384(5.2535) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0204 | Time 97.4204, Epoch Time 1174.0777(1115.9519), Bit/dim 3.6036(best: 3.5871), Xent 1.8239, Loss 4.5155, Error 0.3133(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11230 | Time 18.8013(19.2060) | Bit/dim 3.5730(3.5775) | Xent 0.0453(0.0525) | Loss 8.8849(9.7479) | Error 0.0111(0.0160) Steps 706(734.49) | Grad Norm 5.9078(5.3591) | Total Time 0.00(0.00)\n",
      "Iter 11240 | Time 19.8269(19.1861) | Bit/dim 3.5896(3.5762) | Xent 0.0296(0.0503) | Loss 9.0003(9.5225) | Error 0.0100(0.0154) Steps 748(735.46) | Grad Norm 3.8028(5.1096) | Total Time 0.00(0.00)\n",
      "Iter 11250 | Time 19.7697(19.1450) | Bit/dim 3.5998(3.5751) | Xent 0.0863(0.0504) | Loss 8.9654(9.3600) | Error 0.0278(0.0153) Steps 742(738.97) | Grad Norm 7.2377(5.1377) | Total Time 0.00(0.00)\n",
      "Iter 11260 | Time 18.6445(19.1536) | Bit/dim 3.5551(3.5731) | Xent 0.0430(0.0494) | Loss 8.8980(9.2397) | Error 0.0133(0.0149) Steps 742(740.32) | Grad Norm 4.7390(5.0133) | Total Time 0.00(0.00)\n",
      "Iter 11270 | Time 18.9479(19.1791) | Bit/dim 3.5752(3.5705) | Xent 0.0631(0.0479) | Loss 8.8013(9.1470) | Error 0.0167(0.0145) Steps 730(741.86) | Grad Norm 4.5098(4.9666) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0205 | Time 95.4073, Epoch Time 1172.4992(1117.6483), Bit/dim 3.5928(best: 3.5871), Xent 1.9212, Loss 4.5534, Error 0.3302(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11280 | Time 18.2943(19.1691) | Bit/dim 3.5656(3.5696) | Xent 0.0446(0.0492) | Loss 8.9426(9.8551) | Error 0.0122(0.0145) Steps 730(740.94) | Grad Norm 5.2530(4.9321) | Total Time 0.00(0.00)\n",
      "Iter 11290 | Time 20.0492(19.3027) | Bit/dim 3.5538(3.5695) | Xent 0.0456(0.0474) | Loss 8.8195(9.5932) | Error 0.0111(0.0142) Steps 724(741.33) | Grad Norm 3.4077(4.8001) | Total Time 0.00(0.00)\n",
      "Iter 11300 | Time 19.4227(19.2955) | Bit/dim 3.5738(3.5691) | Xent 0.0623(0.0466) | Loss 8.9388(9.4144) | Error 0.0200(0.0140) Steps 742(742.86) | Grad Norm 3.7414(4.7008) | Total Time 0.00(0.00)\n",
      "Iter 11310 | Time 18.6406(19.2698) | Bit/dim 3.6010(3.5713) | Xent 0.0445(0.0475) | Loss 8.9319(9.2870) | Error 0.0178(0.0145) Steps 724(743.24) | Grad Norm 3.8237(4.6600) | Total Time 0.00(0.00)\n",
      "Iter 11320 | Time 19.2740(19.2444) | Bit/dim 3.5766(3.5682) | Xent 0.0406(0.0471) | Loss 8.9433(9.1705) | Error 0.0111(0.0142) Steps 766(741.08) | Grad Norm 6.3055(4.7049) | Total Time 0.00(0.00)\n",
      "Iter 11330 | Time 19.7004(19.3417) | Bit/dim 3.5493(3.5694) | Xent 0.0792(0.0527) | Loss 8.9851(9.1113) | Error 0.0256(0.0161) Steps 778(742.98) | Grad Norm 7.7116(5.4880) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0206 | Time 97.5582, Epoch Time 1181.9089(1119.5761), Bit/dim 3.5965(best: 3.5871), Xent 1.8874, Loss 4.5402, Error 0.3304(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11340 | Time 18.5533(19.2699) | Bit/dim 3.5880(3.5707) | Xent 0.0909(0.0554) | Loss 9.1409(9.7305) | Error 0.0233(0.0165) Steps 742(745.43) | Grad Norm 5.9413(5.5269) | Total Time 0.00(0.00)\n",
      "Iter 11350 | Time 19.5307(19.3122) | Bit/dim 3.5872(3.5733) | Xent 0.0568(0.0566) | Loss 8.9848(9.5165) | Error 0.0233(0.0173) Steps 754(745.47) | Grad Norm 6.8939(5.7346) | Total Time 0.00(0.00)\n",
      "Iter 11360 | Time 19.4113(19.2477) | Bit/dim 3.5674(3.5732) | Xent 0.0717(0.0572) | Loss 8.8806(9.3560) | Error 0.0178(0.0170) Steps 712(742.41) | Grad Norm 4.5441(5.5670) | Total Time 0.00(0.00)\n",
      "Iter 11370 | Time 18.8073(19.2417) | Bit/dim 3.5821(3.5735) | Xent 0.0380(0.0549) | Loss 8.7892(9.2242) | Error 0.0144(0.0167) Steps 730(741.04) | Grad Norm 3.6080(5.4033) | Total Time 0.00(0.00)\n",
      "Iter 11380 | Time 18.8832(19.2059) | Bit/dim 3.5493(3.5735) | Xent 0.0582(0.0544) | Loss 8.8821(9.1458) | Error 0.0133(0.0164) Steps 730(738.38) | Grad Norm 4.5303(5.1713) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0207 | Time 97.8544, Epoch Time 1176.2181(1121.2754), Bit/dim 3.5902(best: 3.5871), Xent 1.8830, Loss 4.5317, Error 0.3283(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11390 | Time 18.2583(19.1855) | Bit/dim 3.5638(3.5725) | Xent 0.0792(0.0539) | Loss 8.8661(9.8452) | Error 0.0200(0.0156) Steps 742(739.40) | Grad Norm 4.6530(4.9982) | Total Time 0.00(0.00)\n",
      "Iter 11400 | Time 18.7897(19.1204) | Bit/dim 3.5675(3.5688) | Xent 0.0444(0.0509) | Loss 8.8978(9.5797) | Error 0.0156(0.0149) Steps 736(737.33) | Grad Norm 5.8873(4.7622) | Total Time 0.00(0.00)\n",
      "Iter 11410 | Time 18.7221(19.0703) | Bit/dim 3.5589(3.5685) | Xent 0.0388(0.0475) | Loss 8.8973(9.3987) | Error 0.0111(0.0141) Steps 718(736.08) | Grad Norm 5.4223(4.6462) | Total Time 0.00(0.00)\n",
      "Iter 11420 | Time 18.7434(19.0650) | Bit/dim 3.5569(3.5694) | Xent 0.0360(0.0483) | Loss 8.8192(9.2546) | Error 0.0111(0.0145) Steps 706(734.15) | Grad Norm 3.5466(4.7479) | Total Time 0.00(0.00)\n",
      "Iter 11430 | Time 18.9927(19.0568) | Bit/dim 3.5740(3.5693) | Xent 0.0520(0.0500) | Loss 9.0179(9.1609) | Error 0.0189(0.0147) Steps 754(735.63) | Grad Norm 5.6503(4.7975) | Total Time 0.00(0.00)\n",
      "Iter 11440 | Time 18.5066(19.0489) | Bit/dim 3.5499(3.5694) | Xent 0.0413(0.0519) | Loss 8.8333(9.0959) | Error 0.0167(0.0156) Steps 730(736.39) | Grad Norm 3.3244(4.8074) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0208 | Time 96.2153, Epoch Time 1159.3442(1122.4174), Bit/dim 3.5836(best: 3.5871), Xent 1.8167, Loss 4.4920, Error 0.3312(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11450 | Time 19.8356(19.0797) | Bit/dim 3.5405(3.5638) | Xent 0.0568(0.0527) | Loss 8.9022(9.6989) | Error 0.0167(0.0160) Steps 736(737.06) | Grad Norm 7.6077(4.9655) | Total Time 0.00(0.00)\n",
      "Iter 11460 | Time 18.9464(19.2180) | Bit/dim 3.5581(3.5666) | Xent 0.0544(0.0530) | Loss 9.0237(9.5045) | Error 0.0133(0.0160) Steps 748(738.62) | Grad Norm 4.3175(5.2235) | Total Time 0.00(0.00)\n",
      "Iter 11470 | Time 20.2941(19.2821) | Bit/dim 3.5854(3.5681) | Xent 0.0678(0.0521) | Loss 8.9049(9.3448) | Error 0.0167(0.0160) Steps 784(739.08) | Grad Norm 5.3580(5.4078) | Total Time 0.00(0.00)\n",
      "Iter 11480 | Time 18.9540(19.2915) | Bit/dim 3.5939(3.5716) | Xent 0.0525(0.0543) | Loss 8.9399(9.2364) | Error 0.0189(0.0168) Steps 730(740.32) | Grad Norm 8.2549(5.7832) | Total Time 0.00(0.00)\n",
      "Iter 11490 | Time 18.7016(19.2701) | Bit/dim 3.5824(3.5735) | Xent 0.0762(0.0549) | Loss 9.0031(9.1580) | Error 0.0233(0.0168) Steps 718(739.63) | Grad Norm 5.6255(5.7333) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0209 | Time 97.7824, Epoch Time 1182.3488(1124.2154), Bit/dim 3.5944(best: 3.5836), Xent 1.7732, Loss 4.4810, Error 0.3142(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11500 | Time 18.9330(19.2772) | Bit/dim 3.5455(3.5747) | Xent 0.0290(0.0553) | Loss 8.8139(9.8747) | Error 0.0100(0.0170) Steps 760(742.83) | Grad Norm 5.0469(5.5221) | Total Time 0.00(0.00)\n",
      "Iter 11510 | Time 19.6773(19.2979) | Bit/dim 3.5980(3.5747) | Xent 0.0806(0.0577) | Loss 9.0346(9.6308) | Error 0.0256(0.0175) Steps 724(742.14) | Grad Norm 9.6110(6.0570) | Total Time 0.00(0.00)\n",
      "Iter 11520 | Time 19.2249(19.4084) | Bit/dim 3.6045(3.5735) | Xent 0.0631(0.0564) | Loss 8.9641(9.4393) | Error 0.0222(0.0170) Steps 742(741.45) | Grad Norm 8.1020(6.0039) | Total Time 0.00(0.00)\n",
      "Iter 11530 | Time 19.6040(19.3491) | Bit/dim 3.5749(3.5748) | Xent 0.0454(0.0554) | Loss 8.8762(9.3040) | Error 0.0078(0.0165) Steps 748(739.90) | Grad Norm 4.1727(5.8399) | Total Time 0.00(0.00)\n",
      "Iter 11540 | Time 18.3817(19.2850) | Bit/dim 3.6189(3.5749) | Xent 0.0408(0.0583) | Loss 9.0448(9.2037) | Error 0.0144(0.0176) Steps 754(740.41) | Grad Norm 5.3307(5.7443) | Total Time 0.00(0.00)\n",
      "Iter 11550 | Time 19.3436(19.2364) | Bit/dim 3.5894(3.5744) | Xent 0.0923(0.0597) | Loss 8.8343(9.1275) | Error 0.0278(0.0179) Steps 724(742.31) | Grad Norm 6.5159(5.5120) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0210 | Time 96.9712, Epoch Time 1178.3174(1125.8384), Bit/dim 3.5931(best: 3.5836), Xent 1.8731, Loss 4.5297, Error 0.3295(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11560 | Time 18.6418(19.2911) | Bit/dim 3.5329(3.5759) | Xent 0.0888(0.0599) | Loss 8.8426(9.7152) | Error 0.0222(0.0177) Steps 736(741.85) | Grad Norm 5.4718(5.5173) | Total Time 0.00(0.00)\n",
      "Iter 11570 | Time 19.5372(19.2919) | Bit/dim 3.5515(3.5729) | Xent 0.0498(0.0571) | Loss 8.9858(9.5024) | Error 0.0144(0.0170) Steps 778(744.23) | Grad Norm 4.8827(5.1778) | Total Time 0.00(0.00)\n",
      "Iter 11580 | Time 18.9143(19.3053) | Bit/dim 3.5695(3.5719) | Xent 0.0738(0.0531) | Loss 8.8856(9.3476) | Error 0.0156(0.0155) Steps 748(746.98) | Grad Norm 6.0322(4.8886) | Total Time 0.00(0.00)\n",
      "Iter 11590 | Time 19.3349(19.3145) | Bit/dim 3.5433(3.5683) | Xent 0.0497(0.0497) | Loss 8.8213(9.2282) | Error 0.0156(0.0147) Steps 736(746.51) | Grad Norm 4.6631(4.7630) | Total Time 0.00(0.00)\n",
      "Iter 11600 | Time 19.7944(19.3136) | Bit/dim 3.5602(3.5676) | Xent 0.0360(0.0476) | Loss 8.8172(9.1378) | Error 0.0111(0.0143) Steps 736(745.36) | Grad Norm 4.1164(4.5855) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0211 | Time 97.0349, Epoch Time 1180.3019(1127.4723), Bit/dim 3.5844(best: 3.5836), Xent 1.8988, Loss 4.5338, Error 0.3232(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11610 | Time 20.4353(19.3591) | Bit/dim 3.5841(3.5673) | Xent 0.0517(0.0481) | Loss 8.9094(9.8405) | Error 0.0133(0.0143) Steps 730(745.19) | Grad Norm 3.2240(4.6244) | Total Time 0.00(0.00)\n",
      "Iter 11620 | Time 18.9017(19.2454) | Bit/dim 3.5610(3.5681) | Xent 0.0451(0.0483) | Loss 8.9272(9.5959) | Error 0.0111(0.0143) Steps 730(742.08) | Grad Norm 4.3006(4.7597) | Total Time 0.00(0.00)\n",
      "Iter 11630 | Time 19.3882(19.2096) | Bit/dim 3.5649(3.5661) | Xent 0.0612(0.0487) | Loss 8.8249(9.4079) | Error 0.0156(0.0145) Steps 748(742.55) | Grad Norm 5.4988(5.0730) | Total Time 0.00(0.00)\n",
      "Iter 11640 | Time 18.5601(19.1672) | Bit/dim 3.5561(3.5641) | Xent 0.0428(0.0464) | Loss 8.7592(9.2692) | Error 0.0178(0.0140) Steps 724(739.89) | Grad Norm 4.0057(4.9708) | Total Time 0.00(0.00)\n",
      "Iter 11650 | Time 20.4661(19.1281) | Bit/dim 3.5976(3.5675) | Xent 0.0368(0.0457) | Loss 9.0416(9.1820) | Error 0.0111(0.0138) Steps 754(741.51) | Grad Norm 4.0597(4.8643) | Total Time 0.00(0.00)\n",
      "Iter 11660 | Time 19.6540(19.2374) | Bit/dim 3.5593(3.5639) | Xent 0.0530(0.0465) | Loss 8.8951(9.0929) | Error 0.0156(0.0139) Steps 724(742.99) | Grad Norm 3.9204(4.6303) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0212 | Time 97.2339, Epoch Time 1176.7598(1128.9510), Bit/dim 3.5815(best: 3.5836), Xent 1.9033, Loss 4.5331, Error 0.3252(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11670 | Time 18.9885(19.2677) | Bit/dim 3.5816(3.5643) | Xent 0.0404(0.0455) | Loss 8.8546(9.7256) | Error 0.0122(0.0135) Steps 724(744.11) | Grad Norm 4.3601(4.7521) | Total Time 0.00(0.00)\n",
      "Iter 11680 | Time 19.8949(19.2654) | Bit/dim 3.5620(3.5629) | Xent 0.0434(0.0451) | Loss 8.9970(9.4996) | Error 0.0111(0.0133) Steps 784(746.32) | Grad Norm 5.3982(4.9199) | Total Time 0.00(0.00)\n",
      "Iter 11690 | Time 19.9094(19.3212) | Bit/dim 3.5360(3.5631) | Xent 0.0309(0.0440) | Loss 8.8036(9.3387) | Error 0.0078(0.0133) Steps 772(753.00) | Grad Norm 5.1235(5.0223) | Total Time 0.00(0.00)\n",
      "Iter 11700 | Time 19.3505(19.3421) | Bit/dim 3.6044(3.5652) | Xent 0.0491(0.0429) | Loss 8.8980(9.2245) | Error 0.0167(0.0131) Steps 772(755.56) | Grad Norm 4.3072(4.7014) | Total Time 0.00(0.00)\n",
      "Iter 11710 | Time 20.7680(19.4192) | Bit/dim 3.5774(3.5653) | Xent 0.0531(0.0426) | Loss 8.8847(9.1412) | Error 0.0178(0.0131) Steps 754(754.20) | Grad Norm 5.8998(4.6182) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0213 | Time 96.7309, Epoch Time 1184.2048(1130.6086), Bit/dim 3.5865(best: 3.5815), Xent 2.0121, Loss 4.5926, Error 0.3305(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11720 | Time 19.8204(19.3770) | Bit/dim 3.5743(3.5626) | Xent 0.0411(0.0436) | Loss 8.8949(9.8477) | Error 0.0122(0.0134) Steps 784(753.65) | Grad Norm 7.6481(4.9719) | Total Time 0.00(0.00)\n",
      "Iter 11730 | Time 18.7052(19.2811) | Bit/dim 3.5731(3.5622) | Xent 0.0286(0.0431) | Loss 8.8884(9.5902) | Error 0.0100(0.0133) Steps 748(748.91) | Grad Norm 3.5746(4.7235) | Total Time 0.00(0.00)\n",
      "Iter 11740 | Time 18.8087(19.2553) | Bit/dim 3.6019(3.5619) | Xent 0.0249(0.0406) | Loss 9.0359(9.4024) | Error 0.0067(0.0124) Steps 754(747.85) | Grad Norm 4.8359(4.5655) | Total Time 0.00(0.00)\n",
      "Iter 11750 | Time 19.6250(19.2845) | Bit/dim 3.5458(3.5619) | Xent 0.0435(0.0412) | Loss 8.8272(9.2678) | Error 0.0122(0.0125) Steps 760(747.28) | Grad Norm 5.0891(4.4917) | Total Time 0.00(0.00)\n",
      "Iter 11760 | Time 19.8860(19.3889) | Bit/dim 3.5876(3.5655) | Xent 0.0548(0.0409) | Loss 8.9474(9.1786) | Error 0.0111(0.0119) Steps 760(750.21) | Grad Norm 3.1818(4.2305) | Total Time 0.00(0.00)\n",
      "Iter 11770 | Time 19.8446(19.4222) | Bit/dim 3.5399(3.5608) | Xent 0.0749(0.0415) | Loss 8.9086(9.1021) | Error 0.0189(0.0119) Steps 766(750.95) | Grad Norm 6.4969(4.3902) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0214 | Time 95.4721, Epoch Time 1180.1010(1132.0934), Bit/dim 3.5801(best: 3.5815), Xent 1.9889, Loss 4.5746, Error 0.3293(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11780 | Time 19.3043(19.3726) | Bit/dim 3.5212(3.5639) | Xent 0.0530(0.0446) | Loss 8.9038(9.7246) | Error 0.0156(0.0128) Steps 766(748.46) | Grad Norm 7.9776(4.9985) | Total Time 0.00(0.00)\n",
      "Iter 11790 | Time 18.9390(19.4417) | Bit/dim 3.6066(3.5638) | Xent 0.0741(0.0485) | Loss 8.8837(9.5094) | Error 0.0211(0.0142) Steps 712(747.26) | Grad Norm 5.4954(5.2991) | Total Time 0.00(0.00)\n",
      "Iter 11800 | Time 19.1761(19.3650) | Bit/dim 3.5985(3.5675) | Xent 0.0579(0.0493) | Loss 8.9013(9.3410) | Error 0.0156(0.0143) Steps 742(741.86) | Grad Norm 10.1762(5.7915) | Total Time 0.00(0.00)\n",
      "Iter 11810 | Time 18.9433(19.3191) | Bit/dim 3.5883(3.5667) | Xent 0.0892(0.0520) | Loss 8.9887(9.2314) | Error 0.0256(0.0152) Steps 754(743.29) | Grad Norm 10.2285(5.9388) | Total Time 0.00(0.00)\n",
      "Iter 11820 | Time 19.4798(19.3186) | Bit/dim 3.5822(3.5682) | Xent 0.0457(0.0535) | Loss 8.9542(9.1521) | Error 0.0144(0.0156) Steps 778(746.69) | Grad Norm 5.2041(6.0931) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0215 | Time 96.6939, Epoch Time 1180.9220(1133.5582), Bit/dim 3.5893(best: 3.5801), Xent 1.8684, Loss 4.5235, Error 0.3275(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11830 | Time 19.2846(19.3006) | Bit/dim 3.5693(3.5678) | Xent 0.0358(0.0510) | Loss 8.8613(9.8440) | Error 0.0100(0.0150) Steps 742(747.27) | Grad Norm 4.0652(5.7201) | Total Time 0.00(0.00)\n",
      "Iter 11840 | Time 19.2252(19.4312) | Bit/dim 3.5943(3.5669) | Xent 0.0732(0.0509) | Loss 8.9157(9.6003) | Error 0.0222(0.0150) Steps 748(748.43) | Grad Norm 6.0918(5.4066) | Total Time 0.00(0.00)\n",
      "Iter 11850 | Time 18.9852(19.3375) | Bit/dim 3.5587(3.5662) | Xent 0.0444(0.0510) | Loss 8.8584(9.4119) | Error 0.0111(0.0149) Steps 766(747.82) | Grad Norm 5.1885(5.2140) | Total Time 0.00(0.00)\n",
      "Iter 11860 | Time 19.0830(19.3644) | Bit/dim 3.5811(3.5673) | Xent 0.0332(0.0476) | Loss 8.8356(9.2702) | Error 0.0178(0.0141) Steps 748(749.44) | Grad Norm 3.8716(5.0731) | Total Time 0.00(0.00)\n",
      "Iter 11870 | Time 19.1088(19.2784) | Bit/dim 3.5904(3.5681) | Xent 0.0480(0.0492) | Loss 8.9179(9.1763) | Error 0.0133(0.0144) Steps 748(748.39) | Grad Norm 4.9001(5.1023) | Total Time 0.00(0.00)\n",
      "Iter 11880 | Time 19.2942(19.2581) | Bit/dim 3.5459(3.5675) | Xent 0.0321(0.0497) | Loss 8.7755(9.0957) | Error 0.0122(0.0150) Steps 748(745.26) | Grad Norm 6.2770(5.3767) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0216 | Time 96.9323, Epoch Time 1179.1449(1134.9258), Bit/dim 3.5939(best: 3.5801), Xent 1.8387, Loss 4.5133, Error 0.3260(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11890 | Time 19.4998(19.3224) | Bit/dim 3.5686(3.5654) | Xent 0.0259(0.0455) | Loss 8.9940(9.7159) | Error 0.0111(0.0139) Steps 784(747.55) | Grad Norm 3.5963(4.9829) | Total Time 0.00(0.00)\n",
      "Iter 11900 | Time 18.9579(19.4613) | Bit/dim 3.5538(3.5628) | Xent 0.0618(0.0431) | Loss 8.8441(9.4995) | Error 0.0156(0.0130) Steps 748(750.63) | Grad Norm 4.0062(4.8677) | Total Time 0.00(0.00)\n",
      "Iter 11910 | Time 19.0539(19.3894) | Bit/dim 3.5847(3.5615) | Xent 0.0415(0.0430) | Loss 8.9616(9.3436) | Error 0.0133(0.0131) Steps 748(751.40) | Grad Norm 7.2324(4.9775) | Total Time 0.00(0.00)\n",
      "Iter 11920 | Time 19.7738(19.4202) | Bit/dim 3.5449(3.5629) | Xent 0.0389(0.0426) | Loss 8.8577(9.2261) | Error 0.0156(0.0128) Steps 784(755.45) | Grad Norm 5.0811(4.7817) | Total Time 0.00(0.00)\n",
      "Iter 11930 | Time 19.7802(19.4965) | Bit/dim 3.5693(3.5621) | Xent 0.0524(0.0441) | Loss 9.0148(9.1401) | Error 0.0189(0.0133) Steps 766(755.93) | Grad Norm 5.7375(4.7816) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0217 | Time 96.6198, Epoch Time 1192.5029(1136.6531), Bit/dim 3.5834(best: 3.5801), Xent 1.8861, Loss 4.5265, Error 0.3240(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11940 | Time 19.5618(19.5369) | Bit/dim 3.5786(3.5601) | Xent 0.0758(0.0457) | Loss 9.0671(9.8527) | Error 0.0211(0.0137) Steps 766(757.98) | Grad Norm 5.1846(4.6959) | Total Time 0.00(0.00)\n",
      "Iter 11950 | Time 18.8856(19.5258) | Bit/dim 3.5607(3.5604) | Xent 0.0315(0.0444) | Loss 8.9023(9.5959) | Error 0.0078(0.0130) Steps 766(759.12) | Grad Norm 3.3878(4.4174) | Total Time 0.00(0.00)\n",
      "Iter 11960 | Time 19.4996(19.5342) | Bit/dim 3.6088(3.5630) | Xent 0.0565(0.0470) | Loss 9.0750(9.4171) | Error 0.0156(0.0138) Steps 766(756.19) | Grad Norm 4.2539(4.4559) | Total Time 0.00(0.00)\n",
      "Iter 11970 | Time 17.9892(19.4902) | Bit/dim 3.6230(3.5653) | Xent 0.0530(0.0473) | Loss 8.9910(9.2800) | Error 0.0156(0.0142) Steps 754(754.37) | Grad Norm 3.4654(4.4480) | Total Time 0.00(0.00)\n",
      "Iter 11980 | Time 19.9950(19.4572) | Bit/dim 3.5138(3.5626) | Xent 0.0336(0.0454) | Loss 8.8503(9.1704) | Error 0.0100(0.0137) Steps 742(751.57) | Grad Norm 5.2843(4.4792) | Total Time 0.00(0.00)\n",
      "Iter 11990 | Time 19.3582(19.3968) | Bit/dim 3.5639(3.5611) | Xent 0.0632(0.0455) | Loss 8.8951(9.0882) | Error 0.0256(0.0142) Steps 730(748.01) | Grad Norm 6.5753(4.6049) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0218 | Time 98.7261, Epoch Time 1189.1266(1138.2273), Bit/dim 3.5855(best: 3.5801), Xent 1.9733, Loss 4.5721, Error 0.3352(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12000 | Time 19.2425(19.4270) | Bit/dim 3.5520(3.5602) | Xent 0.0584(0.0446) | Loss 8.7678(9.7053) | Error 0.0178(0.0140) Steps 760(749.66) | Grad Norm 6.2648(4.6624) | Total Time 0.00(0.00)\n",
      "Iter 12010 | Time 19.2906(19.3926) | Bit/dim 3.5432(3.5627) | Xent 0.0365(0.0454) | Loss 8.7747(9.4900) | Error 0.0156(0.0139) Steps 748(750.60) | Grad Norm 4.0542(4.5211) | Total Time 0.00(0.00)\n",
      "Iter 12020 | Time 19.7238(19.4037) | Bit/dim 3.5567(3.5630) | Xent 0.0288(0.0442) | Loss 8.8284(9.3307) | Error 0.0078(0.0134) Steps 730(748.69) | Grad Norm 3.0148(4.6193) | Total Time 0.00(0.00)\n",
      "Iter 12030 | Time 19.4816(19.4029) | Bit/dim 3.5449(3.5616) | Xent 0.0435(0.0431) | Loss 8.8434(9.2099) | Error 0.0167(0.0129) Steps 748(750.73) | Grad Norm 3.6922(4.5130) | Total Time 0.00(0.00)\n",
      "Iter 12040 | Time 19.3459(19.4055) | Bit/dim 3.5565(3.5608) | Xent 0.0511(0.0414) | Loss 8.8250(9.1203) | Error 0.0156(0.0126) Steps 736(752.06) | Grad Norm 3.4599(4.3879) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0219 | Time 97.4458, Epoch Time 1183.6885(1139.5912), Bit/dim 3.5831(best: 3.5801), Xent 1.9564, Loss 4.5613, Error 0.3239(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12050 | Time 20.3897(19.3966) | Bit/dim 3.5564(3.5575) | Xent 0.0268(0.0418) | Loss 8.9470(9.8467) | Error 0.0078(0.0126) Steps 796(752.69) | Grad Norm 3.8405(4.3352) | Total Time 0.00(0.00)\n",
      "Iter 12060 | Time 19.2871(19.3721) | Bit/dim 3.5743(3.5607) | Xent 0.1132(0.0546) | Loss 8.9120(9.6107) | Error 0.0344(0.0158) Steps 742(750.71) | Grad Norm 10.7978(5.5079) | Total Time 0.00(0.00)\n",
      "Iter 12070 | Time 19.2407(19.3750) | Bit/dim 3.5633(3.5684) | Xent 0.0619(0.0596) | Loss 8.9192(9.4509) | Error 0.0200(0.0174) Steps 736(754.74) | Grad Norm 3.5277(5.5965) | Total Time 0.00(0.00)\n",
      "Iter 12080 | Time 19.2173(19.4509) | Bit/dim 3.5721(3.5701) | Xent 0.0600(0.0621) | Loss 8.9449(9.3204) | Error 0.0211(0.0187) Steps 736(756.74) | Grad Norm 6.2530(5.9347) | Total Time 0.00(0.00)\n",
      "Iter 12090 | Time 19.6098(19.4164) | Bit/dim 3.5992(3.5694) | Xent 0.0314(0.0598) | Loss 9.0143(9.2040) | Error 0.0133(0.0186) Steps 718(753.06) | Grad Norm 3.7123(5.6844) | Total Time 0.00(0.00)\n",
      "Iter 12100 | Time 19.6545(19.4436) | Bit/dim 3.5853(3.5692) | Xent 0.0499(0.0625) | Loss 8.9395(9.1335) | Error 0.0133(0.0191) Steps 778(753.85) | Grad Norm 5.0047(5.8718) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0220 | Time 98.6104, Epoch Time 1189.0147(1141.0739), Bit/dim 3.5915(best: 3.5801), Xent 1.8482, Loss 4.5156, Error 0.3340(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12110 | Time 19.7114(19.4144) | Bit/dim 3.6281(3.5744) | Xent 0.0437(0.0626) | Loss 9.0763(9.7847) | Error 0.0156(0.0193) Steps 760(752.87) | Grad Norm 4.6741(6.3394) | Total Time 0.00(0.00)\n",
      "Iter 12120 | Time 19.2272(19.4007) | Bit/dim 3.5548(3.5736) | Xent 0.0412(0.0582) | Loss 8.8833(9.5594) | Error 0.0100(0.0176) Steps 736(750.75) | Grad Norm 4.5054(6.0274) | Total Time 0.00(0.00)\n",
      "Iter 12130 | Time 20.0451(19.4450) | Bit/dim 3.5600(3.5690) | Xent 0.0264(0.0523) | Loss 8.9109(9.3797) | Error 0.0067(0.0155) Steps 760(749.38) | Grad Norm 2.8920(5.8864) | Total Time 0.00(0.00)\n",
      "Iter 12140 | Time 19.0698(19.4550) | Bit/dim 3.5383(3.5660) | Xent 0.0950(0.0519) | Loss 8.7591(9.2568) | Error 0.0256(0.0155) Steps 766(752.98) | Grad Norm 6.7473(5.7711) | Total Time 0.00(0.00)\n",
      "Iter 12150 | Time 19.4851(19.4668) | Bit/dim 3.5510(3.5666) | Xent 0.0352(0.0521) | Loss 8.8703(9.1730) | Error 0.0122(0.0155) Steps 778(753.33) | Grad Norm 3.8618(5.6336) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0221 | Time 98.3061, Epoch Time 1187.5310(1142.4676), Bit/dim 3.5849(best: 3.5801), Xent 1.9709, Loss 4.5703, Error 0.3326(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12160 | Time 18.7269(19.4217) | Bit/dim 3.5917(3.5665) | Xent 0.0495(0.0506) | Loss 8.8817(9.9132) | Error 0.0144(0.0149) Steps 760(754.60) | Grad Norm 5.4150(5.3793) | Total Time 0.00(0.00)\n",
      "Iter 12170 | Time 19.1764(19.4169) | Bit/dim 3.5810(3.5696) | Xent 0.0232(0.0466) | Loss 9.0423(9.6475) | Error 0.0067(0.0140) Steps 760(751.12) | Grad Norm 3.6857(5.1728) | Total Time 0.00(0.00)\n",
      "Iter 12180 | Time 18.8800(19.4039) | Bit/dim 3.5346(3.5656) | Xent 0.0498(0.0475) | Loss 8.8099(9.4506) | Error 0.0144(0.0142) Steps 730(751.26) | Grad Norm 4.3633(5.0253) | Total Time 0.00(0.00)\n",
      "Iter 12190 | Time 18.8718(19.3702) | Bit/dim 3.5614(3.5627) | Xent 0.0447(0.0471) | Loss 8.9061(9.2985) | Error 0.0111(0.0141) Steps 736(750.55) | Grad Norm 4.1692(4.8631) | Total Time 0.00(0.00)\n",
      "Iter 12200 | Time 19.5996(19.3729) | Bit/dim 3.5617(3.5631) | Xent 0.0348(0.0444) | Loss 8.8057(9.2024) | Error 0.0111(0.0132) Steps 760(752.91) | Grad Norm 4.3526(4.9109) | Total Time 0.00(0.00)\n",
      "Iter 12210 | Time 19.4496(19.4261) | Bit/dim 3.5375(3.5610) | Xent 0.0622(0.0445) | Loss 8.8959(9.1197) | Error 0.0167(0.0135) Steps 730(751.62) | Grad Norm 3.9436(4.8047) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0222 | Time 97.5457, Epoch Time 1185.8607(1143.7694), Bit/dim 3.5752(best: 3.5801), Xent 1.8751, Loss 4.5127, Error 0.3212(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12220 | Time 20.2139(19.5164) | Bit/dim 3.5797(3.5632) | Xent 0.0714(0.0447) | Loss 9.0581(9.7230) | Error 0.0200(0.0137) Steps 790(755.81) | Grad Norm 5.5916(4.8788) | Total Time 0.00(0.00)\n",
      "Iter 12230 | Time 20.5007(19.6372) | Bit/dim 3.5466(3.5617) | Xent 0.0429(0.0490) | Loss 8.8230(9.5126) | Error 0.0144(0.0149) Steps 748(758.14) | Grad Norm 6.7874(5.6196) | Total Time 0.00(0.00)\n",
      "Iter 12240 | Time 18.9121(19.4809) | Bit/dim 3.5679(3.5641) | Xent 0.0626(0.0507) | Loss 8.9548(9.3675) | Error 0.0189(0.0158) Steps 754(756.18) | Grad Norm 6.2458(5.5405) | Total Time 0.00(0.00)\n",
      "Iter 12250 | Time 19.4527(19.4701) | Bit/dim 3.5502(3.5663) | Xent 0.0339(0.0507) | Loss 8.8963(9.2582) | Error 0.0156(0.0159) Steps 742(754.21) | Grad Norm 4.9536(5.3579) | Total Time 0.00(0.00)\n",
      "Iter 12260 | Time 18.5010(19.5042) | Bit/dim 3.5906(3.5666) | Xent 0.0553(0.0519) | Loss 8.8675(9.1680) | Error 0.0133(0.0157) Steps 760(755.06) | Grad Norm 4.7823(5.1612) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0223 | Time 97.1036, Epoch Time 1192.6722(1145.2365), Bit/dim 3.5884(best: 3.5752), Xent 1.9579, Loss 4.5673, Error 0.3310(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12270 | Time 19.4222(19.5410) | Bit/dim 3.5288(3.5657) | Xent 0.0574(0.0524) | Loss 8.8726(9.8680) | Error 0.0156(0.0158) Steps 748(751.58) | Grad Norm 5.1048(5.0729) | Total Time 0.00(0.00)\n",
      "Iter 12280 | Time 19.3751(19.4658) | Bit/dim 3.5721(3.5659) | Xent 0.0644(0.0512) | Loss 8.9539(9.6282) | Error 0.0133(0.0151) Steps 748(752.82) | Grad Norm 5.8360(4.9306) | Total Time 0.00(0.00)\n",
      "Iter 12290 | Time 18.8672(19.4605) | Bit/dim 3.5677(3.5662) | Xent 0.0417(0.0504) | Loss 8.9419(9.4485) | Error 0.0144(0.0153) Steps 748(752.44) | Grad Norm 2.7865(4.9332) | Total Time 0.00(0.00)\n",
      "Iter 12300 | Time 19.6138(19.5025) | Bit/dim 3.5671(3.5655) | Xent 0.0392(0.0493) | Loss 8.9631(9.3121) | Error 0.0078(0.0145) Steps 766(754.92) | Grad Norm 5.0035(4.8773) | Total Time 0.00(0.00)\n",
      "Iter 12310 | Time 19.0499(19.4676) | Bit/dim 3.5712(3.5624) | Xent 0.0441(0.0464) | Loss 8.5922(9.1786) | Error 0.0111(0.0136) Steps 730(751.83) | Grad Norm 2.7488(4.6122) | Total Time 0.00(0.00)\n",
      "Iter 12320 | Time 18.7487(19.3896) | Bit/dim 3.5510(3.5601) | Xent 0.0351(0.0433) | Loss 8.8893(9.0919) | Error 0.0100(0.0127) Steps 730(749.22) | Grad Norm 3.5054(4.5247) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0224 | Time 97.1421, Epoch Time 1185.7457(1146.4517), Bit/dim 3.5781(best: 3.5752), Xent 1.9109, Loss 4.5336, Error 0.3200(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12330 | Time 19.3277(19.3814) | Bit/dim 3.5855(3.5598) | Xent 0.0300(0.0407) | Loss 8.9035(9.7210) | Error 0.0100(0.0122) Steps 742(749.44) | Grad Norm 3.9823(4.5376) | Total Time 0.00(0.00)\n",
      "Iter 12340 | Time 19.0589(19.3940) | Bit/dim 3.5606(3.5599) | Xent 0.0218(0.0380) | Loss 8.8112(9.4935) | Error 0.0067(0.0112) Steps 748(749.06) | Grad Norm 3.8221(4.3336) | Total Time 0.00(0.00)\n",
      "Iter 12350 | Time 19.3508(19.3774) | Bit/dim 3.5283(3.5565) | Xent 0.0223(0.0346) | Loss 8.9084(9.3219) | Error 0.0078(0.0104) Steps 760(751.32) | Grad Norm 2.4974(4.1457) | Total Time 0.00(0.00)\n",
      "Iter 12360 | Time 19.5281(19.3351) | Bit/dim 3.5533(3.5544) | Xent 0.0548(0.0364) | Loss 8.8183(9.1913) | Error 0.0167(0.0110) Steps 724(749.58) | Grad Norm 5.3678(4.0994) | Total Time 0.00(0.00)\n",
      "Iter 12370 | Time 20.2171(19.3997) | Bit/dim 3.5752(3.5580) | Xent 0.0471(0.0400) | Loss 8.9248(9.1166) | Error 0.0144(0.0118) Steps 790(754.02) | Grad Norm 5.1130(4.4372) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0225 | Time 97.5118, Epoch Time 1187.2466(1147.6756), Bit/dim 3.5886(best: 3.5752), Xent 1.9415, Loss 4.5594, Error 0.3257(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12380 | Time 19.1261(19.3770) | Bit/dim 3.5854(3.5602) | Xent 0.0505(0.0437) | Loss 8.9237(9.8494) | Error 0.0133(0.0126) Steps 766(754.55) | Grad Norm 2.9738(4.6977) | Total Time 0.00(0.00)\n",
      "Iter 12390 | Time 19.7383(19.4332) | Bit/dim 3.5567(3.5633) | Xent 0.0245(0.0426) | Loss 8.9059(9.6067) | Error 0.0067(0.0121) Steps 766(754.86) | Grad Norm 3.2729(4.8025) | Total Time 0.00(0.00)\n",
      "Iter 12400 | Time 20.1212(19.4753) | Bit/dim 3.5429(3.5630) | Xent 0.0516(0.0434) | Loss 8.9497(9.4321) | Error 0.0144(0.0125) Steps 760(752.79) | Grad Norm 3.5642(4.6450) | Total Time 0.00(0.00)\n",
      "Iter 12410 | Time 18.3094(19.4506) | Bit/dim 3.5608(3.5633) | Xent 0.0480(0.0489) | Loss 8.8816(9.2848) | Error 0.0189(0.0145) Steps 742(748.84) | Grad Norm 6.7797(5.0572) | Total Time 0.00(0.00)\n",
      "Iter 12420 | Time 18.8958(19.4059) | Bit/dim 3.5455(3.5642) | Xent 0.0458(0.0517) | Loss 8.8705(9.1909) | Error 0.0144(0.0155) Steps 748(749.44) | Grad Norm 5.4553(5.3448) | Total Time 0.00(0.00)\n",
      "Iter 12430 | Time 18.9701(19.3468) | Bit/dim 3.5694(3.5649) | Xent 0.0455(0.0491) | Loss 8.9493(9.1188) | Error 0.0156(0.0150) Steps 736(748.27) | Grad Norm 3.9904(5.0503) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0226 | Time 98.4107, Epoch Time 1185.1251(1148.7991), Bit/dim 3.5763(best: 3.5752), Xent 1.8894, Loss 4.5210, Error 0.3247(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12440 | Time 19.6958(19.3768) | Bit/dim 3.5628(3.5617) | Xent 0.0180(0.0455) | Loss 8.9438(9.7703) | Error 0.0056(0.0138) Steps 772(752.84) | Grad Norm 2.9137(4.7715) | Total Time 0.00(0.00)\n",
      "Iter 12450 | Time 19.2325(19.4935) | Bit/dim 3.5244(3.5611) | Xent 0.0645(0.0441) | Loss 8.8339(9.5403) | Error 0.0189(0.0130) Steps 766(754.46) | Grad Norm 7.2618(4.6588) | Total Time 0.00(0.00)\n",
      "Iter 12460 | Time 19.5569(19.4733) | Bit/dim 3.5575(3.5609) | Xent 0.0337(0.0420) | Loss 8.8712(9.3705) | Error 0.0111(0.0127) Steps 772(753.82) | Grad Norm 3.2034(4.5876) | Total Time 0.00(0.00)\n",
      "Iter 12470 | Time 18.7535(19.4757) | Bit/dim 3.5785(3.5608) | Xent 0.0711(0.0448) | Loss 8.8302(9.2412) | Error 0.0178(0.0134) Steps 736(752.49) | Grad Norm 7.6191(4.8604) | Total Time 0.00(0.00)\n",
      "Iter 12480 | Time 19.5342(19.4524) | Bit/dim 3.5536(3.5619) | Xent 0.0499(0.0476) | Loss 8.9114(9.1595) | Error 0.0178(0.0144) Steps 760(752.12) | Grad Norm 4.9494(5.0638) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0227 | Time 97.4194, Epoch Time 1193.9998(1150.1551), Bit/dim 3.5861(best: 3.5752), Xent 1.9150, Loss 4.5436, Error 0.3296(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12490 | Time 19.8525(19.5363) | Bit/dim 3.5951(3.5634) | Xent 0.0568(0.0503) | Loss 8.9151(9.8944) | Error 0.0156(0.0152) Steps 760(756.72) | Grad Norm 4.9803(5.0034) | Total Time 0.00(0.00)\n",
      "Iter 12500 | Time 19.4974(19.5958) | Bit/dim 3.5354(3.5619) | Xent 0.0431(0.0478) | Loss 8.9073(9.6364) | Error 0.0089(0.0139) Steps 772(758.54) | Grad Norm 3.0530(4.7778) | Total Time 0.00(0.00)\n",
      "Iter 12510 | Time 19.4225(19.6231) | Bit/dim 3.5450(3.5581) | Xent 0.0377(0.0455) | Loss 8.7528(9.4298) | Error 0.0133(0.0134) Steps 742(758.95) | Grad Norm 4.6235(4.6257) | Total Time 0.00(0.00)\n",
      "Iter 12520 | Time 19.1989(19.5825) | Bit/dim 3.5158(3.5591) | Xent 0.0432(0.0456) | Loss 8.7098(9.2923) | Error 0.0133(0.0138) Steps 736(756.26) | Grad Norm 4.6503(4.7405) | Total Time 0.00(0.00)\n",
      "Iter 12530 | Time 19.1768(19.5067) | Bit/dim 3.5639(3.5616) | Xent 0.0368(0.0464) | Loss 8.8817(9.2081) | Error 0.0122(0.0141) Steps 760(758.14) | Grad Norm 4.6102(4.9651) | Total Time 0.00(0.00)\n",
      "Iter 12540 | Time 19.5412(19.4434) | Bit/dim 3.5425(3.5623) | Xent 0.0244(0.0450) | Loss 8.8560(9.1320) | Error 0.0056(0.0134) Steps 760(757.22) | Grad Norm 3.7433(5.2574) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0228 | Time 97.5950, Epoch Time 1192.0470(1151.4119), Bit/dim 3.5824(best: 3.5752), Xent 1.8950, Loss 4.5299, Error 0.3309(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12550 | Time 19.2232(19.4798) | Bit/dim 3.5351(3.5635) | Xent 0.0411(0.0438) | Loss 8.8076(9.7548) | Error 0.0100(0.0130) Steps 724(751.74) | Grad Norm 4.5832(5.3557) | Total Time 0.00(0.00)\n",
      "Iter 12560 | Time 19.0649(19.5164) | Bit/dim 3.5521(3.5646) | Xent 0.0274(0.0415) | Loss 8.8543(9.5335) | Error 0.0089(0.0122) Steps 754(750.75) | Grad Norm 2.9467(4.9538) | Total Time 0.00(0.00)\n",
      "Iter 12570 | Time 20.1811(19.5858) | Bit/dim 3.5401(3.5640) | Xent 0.0670(0.0463) | Loss 9.0799(9.3798) | Error 0.0233(0.0135) Steps 790(754.45) | Grad Norm 3.9277(5.0230) | Total Time 0.00(0.00)\n",
      "Iter 12580 | Time 19.6908(19.7150) | Bit/dim 3.5675(3.5596) | Xent 0.0480(0.0450) | Loss 8.8193(9.2435) | Error 0.0122(0.0134) Steps 754(757.10) | Grad Norm 3.1167(4.6989) | Total Time 0.00(0.00)\n",
      "Iter 12590 | Time 19.6654(19.7105) | Bit/dim 3.5094(3.5563) | Xent 0.0451(0.0427) | Loss 8.8562(9.1508) | Error 0.0122(0.0126) Steps 748(756.50) | Grad Norm 5.0180(4.5071) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0229 | Time 99.4302, Epoch Time 1208.6841(1153.1300), Bit/dim 3.5778(best: 3.5752), Xent 1.8628, Loss 4.5092, Error 0.3138(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12600 | Time 19.4658(19.7381) | Bit/dim 3.5918(3.5566) | Xent 0.0325(0.0420) | Loss 8.9785(9.8722) | Error 0.0133(0.0125) Steps 754(757.82) | Grad Norm 4.0492(4.4883) | Total Time 0.00(0.00)\n",
      "Iter 12610 | Time 19.6326(19.7420) | Bit/dim 3.5702(3.5584) | Xent 0.0578(0.0426) | Loss 8.9105(9.6256) | Error 0.0144(0.0123) Steps 760(759.06) | Grad Norm 4.8763(4.5442) | Total Time 0.00(0.00)\n",
      "Iter 12620 | Time 20.2328(19.7624) | Bit/dim 3.5312(3.5576) | Xent 0.0311(0.0426) | Loss 9.0049(9.4378) | Error 0.0111(0.0123) Steps 790(760.09) | Grad Norm 4.3498(4.5523) | Total Time 0.00(0.00)\n",
      "Iter 12630 | Time 20.0994(19.8433) | Bit/dim 3.5768(3.5560) | Xent 0.0503(0.0437) | Loss 8.8666(9.2856) | Error 0.0167(0.0131) Steps 766(762.18) | Grad Norm 6.0954(4.7047) | Total Time 0.00(0.00)\n",
      "Iter 12640 | Time 19.9800(19.7646) | Bit/dim 3.5776(3.5579) | Xent 0.0497(0.0471) | Loss 8.9372(9.1967) | Error 0.0156(0.0143) Steps 790(764.80) | Grad Norm 3.8046(4.7440) | Total Time 0.00(0.00)\n",
      "Iter 12650 | Time 19.4723(19.6429) | Bit/dim 3.5756(3.5607) | Xent 0.0762(0.0501) | Loss 8.8390(9.1197) | Error 0.0278(0.0153) Steps 736(758.07) | Grad Norm 6.0806(4.8538) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0230 | Time 97.3716, Epoch Time 1201.5567(1154.5828), Bit/dim 3.5846(best: 3.5752), Xent 1.7871, Loss 4.4781, Error 0.3219(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12660 | Time 20.1458(19.6741) | Bit/dim 3.5355(3.5620) | Xent 0.0243(0.0506) | Loss 8.9018(9.7283) | Error 0.0111(0.0152) Steps 712(754.48) | Grad Norm 4.0397(4.8335) | Total Time 0.00(0.00)\n",
      "Iter 12670 | Time 19.5655(19.6341) | Bit/dim 3.5747(3.5605) | Xent 0.0396(0.0499) | Loss 8.9028(9.5019) | Error 0.0156(0.0150) Steps 718(755.44) | Grad Norm 4.1760(4.7715) | Total Time 0.00(0.00)\n",
      "Iter 12680 | Time 19.4178(19.5896) | Bit/dim 3.5246(3.5570) | Xent 0.0314(0.0469) | Loss 8.7683(9.3318) | Error 0.0089(0.0142) Steps 730(756.18) | Grad Norm 3.7435(4.6446) | Total Time 0.00(0.00)\n",
      "Iter 12690 | Time 19.9009(19.5735) | Bit/dim 3.5529(3.5569) | Xent 0.0266(0.0451) | Loss 8.8925(9.2091) | Error 0.0067(0.0136) Steps 766(759.23) | Grad Norm 4.7542(4.7562) | Total Time 0.00(0.00)\n",
      "Iter 12700 | Time 19.9940(19.6495) | Bit/dim 3.5572(3.5581) | Xent 0.0467(0.0462) | Loss 8.8228(9.1322) | Error 0.0156(0.0135) Steps 772(761.87) | Grad Norm 3.7620(4.7272) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0231 | Time 99.4380, Epoch Time 1198.1497(1155.8898), Bit/dim 3.5799(best: 3.5752), Xent 1.9064, Loss 4.5331, Error 0.3269(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12710 | Time 19.8345(19.6164) | Bit/dim 3.5642(3.5598) | Xent 0.0438(0.0453) | Loss 8.8697(9.8902) | Error 0.0122(0.0133) Steps 724(760.02) | Grad Norm 3.9243(4.5413) | Total Time 0.00(0.00)\n",
      "Iter 12720 | Time 20.0707(19.6784) | Bit/dim 3.5830(3.5604) | Xent 0.0399(0.0456) | Loss 8.9616(9.6401) | Error 0.0122(0.0134) Steps 742(758.37) | Grad Norm 4.7529(4.6279) | Total Time 0.00(0.00)\n",
      "Iter 12730 | Time 19.4223(19.6480) | Bit/dim 3.5781(3.5611) | Xent 0.0346(0.0438) | Loss 8.9722(9.4457) | Error 0.0111(0.0130) Steps 772(758.44) | Grad Norm 4.1647(4.7237) | Total Time 0.00(0.00)\n",
      "Iter 12740 | Time 20.1246(19.7428) | Bit/dim 3.5556(3.5594) | Xent 0.0855(0.0422) | Loss 8.9239(9.2970) | Error 0.0189(0.0123) Steps 748(759.43) | Grad Norm 5.9074(4.6011) | Total Time 0.00(0.00)\n",
      "Iter 12750 | Time 19.4748(19.7847) | Bit/dim 3.5754(3.5564) | Xent 0.0403(0.0424) | Loss 9.0294(9.1883) | Error 0.0133(0.0125) Steps 772(761.85) | Grad Norm 4.5085(4.5385) | Total Time 0.00(0.00)\n",
      "Iter 12760 | Time 19.8256(19.7875) | Bit/dim 3.5552(3.5545) | Xent 0.0511(0.0413) | Loss 8.8556(9.0995) | Error 0.0167(0.0121) Steps 772(764.73) | Grad Norm 4.8448(4.3300) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0232 | Time 98.4002, Epoch Time 1208.8149(1157.4776), Bit/dim 3.5711(best: 3.5752), Xent 1.9086, Loss 4.5254, Error 0.3188(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12770 | Time 19.7039(19.7938) | Bit/dim 3.5736(3.5581) | Xent 0.0235(0.0394) | Loss 8.8795(9.7098) | Error 0.0100(0.0116) Steps 760(763.37) | Grad Norm 3.7307(4.3520) | Total Time 0.00(0.00)\n",
      "Iter 12780 | Time 19.9938(19.7746) | Bit/dim 3.5678(3.5555) | Xent 0.0258(0.0410) | Loss 8.9459(9.4935) | Error 0.0089(0.0124) Steps 784(764.27) | Grad Norm 4.1911(4.4716) | Total Time 0.00(0.00)\n",
      "Iter 12790 | Time 20.3956(19.7997) | Bit/dim 3.5669(3.5538) | Xent 0.0411(0.0399) | Loss 8.8238(9.3345) | Error 0.0111(0.0122) Steps 778(764.50) | Grad Norm 3.5151(4.2168) | Total Time 0.00(0.00)\n",
      "Iter 12800 | Time 19.6090(19.8776) | Bit/dim 3.5531(3.5523) | Xent 0.0456(0.0401) | Loss 8.7207(9.2046) | Error 0.0122(0.0121) Steps 718(762.32) | Grad Norm 3.4758(4.0954) | Total Time 0.00(0.00)\n",
      "Iter 12810 | Time 19.5006(19.8705) | Bit/dim 3.5259(3.5511) | Xent 0.0797(0.0449) | Loss 8.8474(9.1210) | Error 0.0222(0.0132) Steps 736(760.24) | Grad Norm 6.7636(4.3542) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0233 | Time 98.4480, Epoch Time 1213.2178(1159.1498), Bit/dim 3.5816(best: 3.5711), Xent 1.8273, Loss 4.4952, Error 0.3277(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12820 | Time 19.3766(19.8295) | Bit/dim 3.5595(3.5523) | Xent 0.0557(0.0482) | Loss 8.8714(9.8740) | Error 0.0167(0.0141) Steps 706(759.60) | Grad Norm 6.6147(4.7558) | Total Time 0.00(0.00)\n",
      "Iter 12830 | Time 19.5738(19.8262) | Bit/dim 3.5465(3.5572) | Xent 0.0436(0.0510) | Loss 8.8273(9.6223) | Error 0.0122(0.0149) Steps 748(758.31) | Grad Norm 3.9734(4.8036) | Total Time 0.00(0.00)\n",
      "Iter 12840 | Time 20.1452(19.7301) | Bit/dim 3.5377(3.5582) | Xent 0.0381(0.0509) | Loss 8.8122(9.4311) | Error 0.0078(0.0146) Steps 724(757.42) | Grad Norm 3.6651(4.5666) | Total Time 0.00(0.00)\n",
      "Iter 12850 | Time 19.5062(19.7259) | Bit/dim 3.5486(3.5581) | Xent 0.0350(0.0487) | Loss 8.8822(9.2924) | Error 0.0122(0.0141) Steps 784(760.90) | Grad Norm 5.4443(4.4804) | Total Time 0.00(0.00)\n",
      "Iter 12860 | Time 19.2588(19.6609) | Bit/dim 3.5514(3.5595) | Xent 0.1014(0.0537) | Loss 8.9545(9.1944) | Error 0.0256(0.0155) Steps 754(759.24) | Grad Norm 7.9283(4.9588) | Total Time 0.00(0.00)\n",
      "Iter 12870 | Time 20.2634(19.6788) | Bit/dim 3.5421(3.5588) | Xent 0.0643(0.0546) | Loss 8.8623(9.1205) | Error 0.0178(0.0161) Steps 748(760.31) | Grad Norm 3.0817(5.1170) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0234 | Time 97.4435, Epoch Time 1197.9148(1160.3127), Bit/dim 3.5886(best: 3.5711), Xent 1.7066, Loss 4.4419, Error 0.3137(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12880 | Time 20.0811(19.6928) | Bit/dim 3.5762(3.5593) | Xent 0.0352(0.0503) | Loss 8.9020(9.7230) | Error 0.0111(0.0151) Steps 778(762.21) | Grad Norm 4.5756(4.8911) | Total Time 0.00(0.00)\n",
      "Iter 12890 | Time 19.8935(19.7068) | Bit/dim 3.5803(3.5585) | Xent 0.0313(0.0468) | Loss 8.9358(9.5061) | Error 0.0089(0.0140) Steps 766(762.86) | Grad Norm 3.9599(4.9717) | Total Time 0.00(0.00)\n",
      "Iter 12900 | Time 19.9886(19.7245) | Bit/dim 3.5407(3.5577) | Xent 0.0366(0.0449) | Loss 8.8452(9.3315) | Error 0.0089(0.0133) Steps 766(761.54) | Grad Norm 3.5707(4.7014) | Total Time 0.00(0.00)\n",
      "Iter 12910 | Time 21.1329(19.7922) | Bit/dim 3.5617(3.5570) | Xent 0.0510(0.0439) | Loss 8.9773(9.2086) | Error 0.0156(0.0131) Steps 766(761.79) | Grad Norm 4.4050(4.7715) | Total Time 0.00(0.00)\n",
      "Iter 12920 | Time 19.6386(19.8259) | Bit/dim 3.5517(3.5549) | Xent 0.0681(0.0438) | Loss 9.0210(9.1227) | Error 0.0200(0.0129) Steps 772(767.85) | Grad Norm 6.0201(4.8678) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0235 | Time 99.3140, Epoch Time 1212.2582(1161.8711), Bit/dim 3.5763(best: 3.5711), Xent 1.8911, Loss 4.5219, Error 0.3173(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12930 | Time 21.4943(19.9658) | Bit/dim 3.5560(3.5527) | Xent 0.0440(0.0426) | Loss 8.9121(9.8577) | Error 0.0122(0.0124) Steps 826(772.70) | Grad Norm 5.5428(4.7596) | Total Time 0.00(0.00)\n",
      "Iter 12940 | Time 19.8711(20.0020) | Bit/dim 3.5712(3.5543) | Xent 0.0446(0.0407) | Loss 8.9085(9.5988) | Error 0.0078(0.0118) Steps 778(773.64) | Grad Norm 4.4124(4.6135) | Total Time 0.00(0.00)\n",
      "Iter 12950 | Time 20.3120(20.0207) | Bit/dim 3.5336(3.5522) | Xent 0.0446(0.0378) | Loss 8.8335(9.4084) | Error 0.0133(0.0109) Steps 766(775.61) | Grad Norm 4.3993(4.2451) | Total Time 0.00(0.00)\n",
      "Iter 12960 | Time 20.4948(20.0356) | Bit/dim 3.5565(3.5542) | Xent 0.0478(0.0386) | Loss 8.8769(9.2773) | Error 0.0122(0.0110) Steps 730(771.05) | Grad Norm 5.0687(4.2528) | Total Time 0.00(0.00)\n",
      "Iter 12970 | Time 20.0434(20.0382) | Bit/dim 3.5384(3.5546) | Xent 0.0570(0.0409) | Loss 8.9652(9.1762) | Error 0.0244(0.0119) Steps 784(771.97) | Grad Norm 7.1599(4.4520) | Total Time 0.00(0.00)\n",
      "Iter 12980 | Time 20.1400(20.1135) | Bit/dim 3.5602(3.5570) | Xent 0.0382(0.0397) | Loss 8.8962(9.0964) | Error 0.0100(0.0118) Steps 796(773.58) | Grad Norm 4.0357(4.4910) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0236 | Time 98.6542, Epoch Time 1228.4862(1163.8696), Bit/dim 3.5738(best: 3.5711), Xent 1.9172, Loss 4.5324, Error 0.3232(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12990 | Time 20.1071(20.1227) | Bit/dim 3.5416(3.5567) | Xent 0.0367(0.0368) | Loss 8.8872(9.7239) | Error 0.0100(0.0111) Steps 784(775.08) | Grad Norm 4.4023(4.2363) | Total Time 0.00(0.00)\n",
      "Iter 13000 | Time 20.6054(20.2154) | Bit/dim 3.5561(3.5559) | Xent 0.0405(0.0376) | Loss 8.8209(9.4923) | Error 0.0111(0.0117) Steps 802(775.20) | Grad Norm 3.8047(4.2722) | Total Time 0.00(0.00)\n",
      "Iter 13010 | Time 20.1000(20.2354) | Bit/dim 3.5514(3.5592) | Xent 0.0362(0.0396) | Loss 8.9203(9.3499) | Error 0.0122(0.0120) Steps 760(776.15) | Grad Norm 6.0202(4.7458) | Total Time 0.00(0.00)\n",
      "Iter 13020 | Time 20.3698(20.2525) | Bit/dim 3.5490(3.5578) | Xent 0.0622(0.0423) | Loss 8.8029(9.2284) | Error 0.0189(0.0127) Steps 784(778.06) | Grad Norm 6.3378(5.1813) | Total Time 0.00(0.00)\n",
      "Iter 13030 | Time 20.4219(20.2296) | Bit/dim 3.5490(3.5578) | Xent 0.0549(0.0446) | Loss 8.9446(9.1421) | Error 0.0178(0.0135) Steps 778(776.55) | Grad Norm 4.1507(5.1867) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0237 | Time 99.0816, Epoch Time 1235.3342(1166.0135), Bit/dim 3.5801(best: 3.5711), Xent 1.8805, Loss 4.5203, Error 0.3179(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13040 | Time 20.5913(20.2235) | Bit/dim 3.5520(3.5582) | Xent 0.0466(0.0430) | Loss 8.9234(9.8682) | Error 0.0133(0.0129) Steps 760(774.22) | Grad Norm 2.8860(4.8074) | Total Time 0.00(0.00)\n",
      "Iter 13050 | Time 21.1041(20.2734) | Bit/dim 3.5821(3.5572) | Xent 0.0451(0.0430) | Loss 8.9811(9.5982) | Error 0.0133(0.0126) Steps 760(774.24) | Grad Norm 4.8763(4.6574) | Total Time 0.00(0.00)\n",
      "Iter 13060 | Time 19.9142(20.3547) | Bit/dim 3.5299(3.5546) | Xent 0.0564(0.0438) | Loss 8.8664(9.4112) | Error 0.0189(0.0128) Steps 772(776.14) | Grad Norm 6.6227(4.6733) | Total Time 0.00(0.00)\n",
      "Iter 13070 | Time 20.5624(20.4609) | Bit/dim 3.5255(3.5586) | Xent 0.0608(0.0487) | Loss 8.8114(9.2908) | Error 0.0200(0.0142) Steps 766(775.98) | Grad Norm 4.9040(5.1582) | Total Time 0.00(0.00)\n",
      "Iter 13080 | Time 20.3674(20.4574) | Bit/dim 3.5487(3.5579) | Xent 0.0443(0.0466) | Loss 8.9070(9.1944) | Error 0.0122(0.0136) Steps 778(778.09) | Grad Norm 3.4578(4.7821) | Total Time 0.00(0.00)\n",
      "Iter 13090 | Time 20.7818(20.4445) | Bit/dim 3.5351(3.5552) | Xent 0.0241(0.0435) | Loss 8.9329(9.1037) | Error 0.0078(0.0129) Steps 790(776.87) | Grad Norm 3.3501(4.5082) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0238 | Time 99.1238, Epoch Time 1247.9588(1168.4719), Bit/dim 3.5743(best: 3.5711), Xent 1.9078, Loss 4.5282, Error 0.3188(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13100 | Time 20.8805(20.4467) | Bit/dim 3.5327(3.5514) | Xent 0.0375(0.0418) | Loss 8.8703(9.7138) | Error 0.0133(0.0123) Steps 778(778.40) | Grad Norm 3.6456(4.3285) | Total Time 0.00(0.00)\n",
      "Iter 13110 | Time 19.9059(20.4345) | Bit/dim 3.5623(3.5508) | Xent 0.0561(0.0389) | Loss 8.8818(9.4926) | Error 0.0178(0.0114) Steps 736(776.41) | Grad Norm 3.9854(4.0173) | Total Time 0.00(0.00)\n",
      "Iter 13120 | Time 20.5259(20.3900) | Bit/dim 3.5467(3.5550) | Xent 0.0557(0.0421) | Loss 8.9913(9.3442) | Error 0.0156(0.0126) Steps 796(778.40) | Grad Norm 5.3129(4.8169) | Total Time 0.00(0.00)\n",
      "Iter 13130 | Time 20.2012(20.3353) | Bit/dim 3.5266(3.5532) | Xent 0.0516(0.0429) | Loss 8.7989(9.2107) | Error 0.0111(0.0126) Steps 760(777.80) | Grad Norm 4.0107(4.7047) | Total Time 0.00(0.00)\n",
      "Iter 13140 | Time 20.9963(20.3726) | Bit/dim 3.5516(3.5530) | Xent 0.0222(0.0422) | Loss 8.9023(9.1217) | Error 0.0078(0.0127) Steps 760(777.67) | Grad Norm 3.7023(4.4208) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0239 | Time 98.1183, Epoch Time 1238.7881(1170.5813), Bit/dim 3.5717(best: 3.5711), Xent 1.9296, Loss 4.5365, Error 0.3182(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13150 | Time 20.7743(20.4002) | Bit/dim 3.5230(3.5531) | Xent 0.0702(0.0417) | Loss 8.8522(9.8783) | Error 0.0144(0.0125) Steps 790(778.36) | Grad Norm 3.8040(4.3193) | Total Time 0.00(0.00)\n",
      "Iter 13160 | Time 20.5216(20.3946) | Bit/dim 3.5771(3.5536) | Xent 0.0603(0.0440) | Loss 8.9637(9.6328) | Error 0.0156(0.0133) Steps 754(778.57) | Grad Norm 5.4027(4.6693) | Total Time 0.00(0.00)\n",
      "Iter 13170 | Time 19.6128(20.4148) | Bit/dim 3.5646(3.5537) | Xent 0.0658(0.0438) | Loss 8.7613(9.4420) | Error 0.0211(0.0133) Steps 766(780.00) | Grad Norm 7.8988(4.7006) | Total Time 0.00(0.00)\n",
      "Iter 13180 | Time 19.6414(20.3859) | Bit/dim 3.5661(3.5540) | Xent 0.0379(0.0444) | Loss 8.8223(9.3014) | Error 0.0100(0.0131) Steps 760(780.17) | Grad Norm 4.1287(4.7054) | Total Time 0.00(0.00)\n",
      "Iter 13190 | Time 20.0668(20.3603) | Bit/dim 3.6075(3.5574) | Xent 0.0282(0.0453) | Loss 8.7969(9.2044) | Error 0.0122(0.0137) Steps 760(778.31) | Grad Norm 5.0499(4.7307) | Total Time 0.00(0.00)\n",
      "Iter 13200 | Time 19.4349(20.3422) | Bit/dim 3.5602(3.5545) | Xent 0.0325(0.0450) | Loss 8.8197(9.1175) | Error 0.0100(0.0137) Steps 772(777.81) | Grad Norm 2.9123(4.6385) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0240 | Time 97.1276, Epoch Time 1238.8891(1172.6306), Bit/dim 3.5804(best: 3.5711), Xent 1.9096, Loss 4.5352, Error 0.3179(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13210 | Time 20.1197(20.3750) | Bit/dim 3.5163(3.5529) | Xent 0.0443(0.0437) | Loss 8.8733(9.7482) | Error 0.0100(0.0129) Steps 766(780.11) | Grad Norm 5.2099(4.5855) | Total Time 0.00(0.00)\n",
      "Iter 13220 | Time 19.7119(20.4209) | Bit/dim 3.5534(3.5543) | Xent 0.0839(0.0447) | Loss 8.8177(9.5254) | Error 0.0233(0.0133) Steps 748(778.61) | Grad Norm 7.1103(4.7482) | Total Time 0.00(0.00)\n",
      "Iter 13230 | Time 20.3903(20.4749) | Bit/dim 3.5580(3.5541) | Xent 0.0632(0.0483) | Loss 8.9232(9.3705) | Error 0.0178(0.0144) Steps 796(779.87) | Grad Norm 6.5270(4.8937) | Total Time 0.00(0.00)\n",
      "Iter 13240 | Time 20.0836(20.4736) | Bit/dim 3.5641(3.5534) | Xent 0.0565(0.0491) | Loss 8.8546(9.2407) | Error 0.0200(0.0144) Steps 766(779.97) | Grad Norm 4.8692(4.9144) | Total Time 0.00(0.00)\n",
      "Iter 13250 | Time 21.4178(20.5432) | Bit/dim 3.5539(3.5556) | Xent 0.0336(0.0480) | Loss 8.8811(9.1481) | Error 0.0067(0.0142) Steps 754(778.87) | Grad Norm 4.8393(4.8408) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0241 | Time 99.0736, Epoch Time 1248.3009(1174.9007), Bit/dim 3.5717(best: 3.5711), Xent 1.9244, Loss 4.5339, Error 0.3293(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13260 | Time 20.8359(20.4707) | Bit/dim 3.5605(3.5550) | Xent 0.0328(0.0469) | Loss 8.9179(9.8928) | Error 0.0089(0.0137) Steps 778(779.35) | Grad Norm 3.0045(4.6710) | Total Time 0.00(0.00)\n",
      "Iter 13270 | Time 20.5871(20.4539) | Bit/dim 3.5362(3.5539) | Xent 0.0577(0.0482) | Loss 8.8634(9.6383) | Error 0.0189(0.0141) Steps 742(778.12) | Grad Norm 5.7159(4.6659) | Total Time 0.00(0.00)\n",
      "Iter 13280 | Time 20.0901(20.3599) | Bit/dim 3.6090(3.5572) | Xent 0.0731(0.0506) | Loss 9.0612(9.4585) | Error 0.0244(0.0147) Steps 766(778.04) | Grad Norm 5.6471(4.7265) | Total Time 0.00(0.00)\n",
      "Iter 13290 | Time 20.0228(20.3926) | Bit/dim 3.5604(3.5582) | Xent 0.0681(0.0501) | Loss 8.9178(9.3137) | Error 0.0122(0.0145) Steps 766(781.07) | Grad Norm 3.8400(4.6446) | Total Time 0.00(0.00)\n",
      "Iter 13300 | Time 20.1123(20.3882) | Bit/dim 3.5295(3.5543) | Xent 0.0295(0.0471) | Loss 8.9233(9.1939) | Error 0.0078(0.0135) Steps 766(781.12) | Grad Norm 4.4947(4.5268) | Total Time 0.00(0.00)\n",
      "Iter 13310 | Time 19.6943(20.4601) | Bit/dim 3.5784(3.5532) | Xent 0.0502(0.0455) | Loss 8.8607(9.1180) | Error 0.0111(0.0130) Steps 784(783.07) | Grad Norm 4.4607(4.6380) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0242 | Time 98.2427, Epoch Time 1242.5094(1176.9289), Bit/dim 3.5661(best: 3.5711), Xent 1.8768, Loss 4.5045, Error 0.3243(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13320 | Time 20.0102(20.4720) | Bit/dim 3.5677(3.5503) | Xent 0.0353(0.0440) | Loss 8.8761(9.7168) | Error 0.0111(0.0124) Steps 766(782.94) | Grad Norm 3.2321(4.3510) | Total Time 0.00(0.00)\n",
      "Iter 13330 | Time 20.4961(20.4870) | Bit/dim 3.5444(3.5481) | Xent 0.0219(0.0418) | Loss 8.9668(9.4858) | Error 0.0067(0.0121) Steps 808(781.13) | Grad Norm 3.5643(4.1507) | Total Time 0.00(0.00)\n",
      "Iter 13340 | Time 20.1781(20.4420) | Bit/dim 3.5736(3.5497) | Xent 0.0371(0.0393) | Loss 8.8872(9.3247) | Error 0.0089(0.0114) Steps 778(780.12) | Grad Norm 3.0201(4.1282) | Total Time 0.00(0.00)\n",
      "Iter 13350 | Time 20.3644(20.3722) | Bit/dim 3.5411(3.5498) | Xent 0.0269(0.0371) | Loss 8.9373(9.1956) | Error 0.0078(0.0109) Steps 790(780.72) | Grad Norm 2.9194(4.0696) | Total Time 0.00(0.00)\n",
      "Iter 13360 | Time 20.0176(20.3332) | Bit/dim 3.5523(3.5477) | Xent 0.0428(0.0376) | Loss 8.7835(9.1040) | Error 0.0133(0.0109) Steps 772(779.99) | Grad Norm 4.0060(4.0947) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0243 | Time 98.6825, Epoch Time 1235.9322(1178.6990), Bit/dim 3.5700(best: 3.5661), Xent 1.9124, Loss 4.5262, Error 0.3141(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13370 | Time 19.9995(20.2652) | Bit/dim 3.5493(3.5508) | Xent 0.0383(0.0378) | Loss 8.8860(9.8198) | Error 0.0122(0.0112) Steps 772(779.87) | Grad Norm 4.4835(4.0380) | Total Time 0.00(0.00)\n",
      "Iter 13380 | Time 20.0410(20.3144) | Bit/dim 3.5556(3.5492) | Xent 0.0323(0.0383) | Loss 8.9393(9.5668) | Error 0.0056(0.0110) Steps 778(778.48) | Grad Norm 3.1626(4.0269) | Total Time 0.00(0.00)\n",
      "Iter 13390 | Time 20.4709(20.3599) | Bit/dim 3.5481(3.5506) | Xent 0.0347(0.0393) | Loss 8.8714(9.3859) | Error 0.0089(0.0112) Steps 790(781.98) | Grad Norm 3.9442(4.1078) | Total Time 0.00(0.00)\n",
      "Iter 13400 | Time 20.2164(20.3543) | Bit/dim 3.5514(3.5474) | Xent 0.0248(0.0407) | Loss 8.9036(9.2400) | Error 0.0089(0.0117) Steps 778(779.46) | Grad Norm 3.4117(4.1206) | Total Time 0.00(0.00)\n",
      "Iter 13410 | Time 20.6098(20.3728) | Bit/dim 3.5581(3.5488) | Xent 0.0401(0.0431) | Loss 8.9195(9.1462) | Error 0.0144(0.0122) Steps 802(777.56) | Grad Norm 5.2125(4.3278) | Total Time 0.00(0.00)\n",
      "Iter 13420 | Time 20.4191(20.3890) | Bit/dim 3.5730(3.5506) | Xent 0.0462(0.0439) | Loss 8.9662(9.0855) | Error 0.0144(0.0123) Steps 802(779.06) | Grad Norm 3.2864(4.3033) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0244 | Time 99.7013, Epoch Time 1244.1984(1180.6640), Bit/dim 3.5709(best: 3.5661), Xent 1.8316, Loss 4.4868, Error 0.3123(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13430 | Time 20.7384(20.3621) | Bit/dim 3.5762(3.5493) | Xent 0.0748(0.0430) | Loss 8.9441(9.6885) | Error 0.0244(0.0121) Steps 796(780.36) | Grad Norm 6.9880(4.2596) | Total Time 0.00(0.00)\n",
      "Iter 13440 | Time 20.3655(20.4023) | Bit/dim 3.5572(3.5519) | Xent 0.0447(0.0440) | Loss 8.8308(9.4819) | Error 0.0144(0.0126) Steps 796(780.39) | Grad Norm 8.1236(4.5196) | Total Time 0.00(0.00)\n",
      "Iter 13450 | Time 20.3182(20.3587) | Bit/dim 3.5997(3.5539) | Xent 0.0371(0.0467) | Loss 9.0007(9.3267) | Error 0.0133(0.0137) Steps 772(777.02) | Grad Norm 4.8497(4.7641) | Total Time 0.00(0.00)\n",
      "Iter 13460 | Time 20.9839(20.4227) | Bit/dim 3.5561(3.5539) | Xent 0.0705(0.0484) | Loss 9.0384(9.2409) | Error 0.0178(0.0140) Steps 808(782.00) | Grad Norm 4.4669(4.9158) | Total Time 0.00(0.00)\n",
      "Iter 13470 | Time 20.5541(20.4262) | Bit/dim 3.5489(3.5558) | Xent 0.0502(0.0497) | Loss 8.9968(9.1677) | Error 0.0133(0.0142) Steps 796(785.01) | Grad Norm 5.0660(5.0078) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0245 | Time 98.5535, Epoch Time 1242.1999(1182.5101), Bit/dim 3.5744(best: 3.5661), Xent 1.7702, Loss 4.4595, Error 0.3254(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13480 | Time 21.0014(20.4336) | Bit/dim 3.5606(3.5541) | Xent 0.0447(0.0498) | Loss 8.9774(9.8879) | Error 0.0111(0.0139) Steps 808(783.32) | Grad Norm 3.2153(4.6512) | Total Time 0.00(0.00)\n",
      "Iter 13490 | Time 20.6496(20.4025) | Bit/dim 3.5339(3.5554) | Xent 0.0283(0.0460) | Loss 8.7511(9.6186) | Error 0.0100(0.0131) Steps 784(782.56) | Grad Norm 2.7783(4.2909) | Total Time 0.00(0.00)\n",
      "Iter 13500 | Time 20.3153(20.4519) | Bit/dim 3.5618(3.5548) | Xent 0.0165(0.0437) | Loss 8.8851(9.4210) | Error 0.0067(0.0127) Steps 784(784.01) | Grad Norm 2.9458(4.0379) | Total Time 0.00(0.00)\n",
      "Iter 13510 | Time 20.5046(20.3975) | Bit/dim 3.5122(3.5512) | Xent 0.0310(0.0430) | Loss 8.7176(9.2737) | Error 0.0111(0.0128) Steps 754(782.22) | Grad Norm 3.4490(3.9936) | Total Time 0.00(0.00)\n",
      "Iter 13520 | Time 20.7877(20.4941) | Bit/dim 3.5285(3.5493) | Xent 0.0390(0.0449) | Loss 8.8568(9.1703) | Error 0.0111(0.0129) Steps 778(778.91) | Grad Norm 4.4899(4.1584) | Total Time 0.00(0.00)\n",
      "Iter 13530 | Time 19.7918(20.5236) | Bit/dim 3.5295(3.5483) | Xent 0.0384(0.0456) | Loss 8.7696(9.1029) | Error 0.0133(0.0133) Steps 778(779.73) | Grad Norm 5.8143(4.4495) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0246 | Time 99.3860, Epoch Time 1248.6165(1184.4933), Bit/dim 3.5775(best: 3.5661), Xent 1.8784, Loss 4.5167, Error 0.3325(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13540 | Time 20.0002(20.5963) | Bit/dim 3.5470(3.5508) | Xent 0.0645(0.0458) | Loss 8.9032(9.7380) | Error 0.0156(0.0135) Steps 784(779.29) | Grad Norm 8.5622(4.6874) | Total Time 0.00(0.00)\n",
      "Iter 13550 | Time 21.0619(20.6619) | Bit/dim 3.5695(3.5535) | Xent 0.0498(0.0476) | Loss 8.9659(9.5293) | Error 0.0100(0.0139) Steps 796(781.85) | Grad Norm 6.9588(4.6977) | Total Time 0.00(0.00)\n",
      "Iter 13560 | Time 20.0264(20.6324) | Bit/dim 3.5448(3.5545) | Xent 0.0373(0.0501) | Loss 8.9064(9.3609) | Error 0.0122(0.0151) Steps 796(783.00) | Grad Norm 2.8119(4.8728) | Total Time 0.00(0.00)\n",
      "Iter 13570 | Time 19.6113(20.5602) | Bit/dim 3.4967(3.5544) | Xent 0.0346(0.0509) | Loss 8.7728(9.2442) | Error 0.0111(0.0155) Steps 766(779.66) | Grad Norm 3.1397(4.6942) | Total Time 0.00(0.00)\n",
      "Iter 13580 | Time 21.1278(20.5433) | Bit/dim 3.5796(3.5556) | Xent 0.0545(0.0517) | Loss 9.0486(9.1645) | Error 0.0167(0.0158) Steps 808(782.28) | Grad Norm 7.5488(5.0792) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0247 | Time 98.3378, Epoch Time 1253.6359(1186.5676), Bit/dim 3.5825(best: 3.5661), Xent 1.9090, Loss 4.5370, Error 0.3221(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13590 | Time 20.7868(20.5823) | Bit/dim 3.5890(3.5564) | Xent 0.0728(0.0515) | Loss 8.9495(9.8952) | Error 0.0211(0.0154) Steps 790(784.64) | Grad Norm 9.5621(5.2614) | Total Time 0.00(0.00)\n",
      "Iter 13600 | Time 20.4550(20.5747) | Bit/dim 3.5695(3.5567) | Xent 0.0413(0.0492) | Loss 8.8087(9.6346) | Error 0.0122(0.0146) Steps 766(784.67) | Grad Norm 3.2154(4.9540) | Total Time 0.00(0.00)\n",
      "Iter 13610 | Time 21.5925(20.5370) | Bit/dim 3.5507(3.5558) | Xent 0.0262(0.0448) | Loss 8.8506(9.4270) | Error 0.0078(0.0136) Steps 778(784.65) | Grad Norm 5.7258(4.6426) | Total Time 0.00(0.00)\n",
      "Iter 13620 | Time 20.6716(20.5231) | Bit/dim 3.5390(3.5535) | Xent 0.0235(0.0410) | Loss 8.8746(9.2825) | Error 0.0089(0.0122) Steps 796(786.18) | Grad Norm 4.7538(4.5030) | Total Time 0.00(0.00)\n",
      "Iter 13630 | Time 19.8457(20.5203) | Bit/dim 3.5697(3.5513) | Xent 0.0399(0.0375) | Loss 8.8848(9.1733) | Error 0.0100(0.0114) Steps 766(784.41) | Grad Norm 4.9269(4.4074) | Total Time 0.00(0.00)\n",
      "Iter 13640 | Time 20.8160(20.5372) | Bit/dim 3.5843(3.5489) | Xent 0.0384(0.0376) | Loss 8.9068(9.1010) | Error 0.0144(0.0116) Steps 784(786.86) | Grad Norm 4.9641(4.3454) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0248 | Time 98.5628, Epoch Time 1247.5510(1188.3971), Bit/dim 3.5719(best: 3.5661), Xent 1.9252, Loss 4.5345, Error 0.3193(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13650 | Time 21.1580(20.5271) | Bit/dim 3.5401(3.5495) | Xent 0.0311(0.0389) | Loss 8.7092(9.7281) | Error 0.0133(0.0116) Steps 796(788.52) | Grad Norm 3.6970(4.6169) | Total Time 0.00(0.00)\n",
      "Iter 13660 | Time 20.8008(20.5446) | Bit/dim 3.5932(3.5527) | Xent 0.0556(0.0471) | Loss 9.0773(9.5220) | Error 0.0200(0.0138) Steps 778(785.33) | Grad Norm 6.1031(5.5828) | Total Time 0.00(0.00)\n",
      "Iter 13670 | Time 20.6762(20.5631) | Bit/dim 3.5753(3.5567) | Xent 0.0481(0.0495) | Loss 8.9842(9.3767) | Error 0.0156(0.0148) Steps 802(785.49) | Grad Norm 3.8764(5.5430) | Total Time 0.00(0.00)\n",
      "Iter 13680 | Time 20.1412(20.5728) | Bit/dim 3.5723(3.5560) | Xent 0.0586(0.0505) | Loss 9.0412(9.2616) | Error 0.0222(0.0156) Steps 790(785.26) | Grad Norm 5.4556(5.4387) | Total Time 0.00(0.00)\n",
      "Iter 13690 | Time 20.9807(20.6127) | Bit/dim 3.5299(3.5564) | Xent 0.0373(0.0469) | Loss 8.8494(9.1647) | Error 0.0122(0.0147) Steps 802(786.62) | Grad Norm 3.7685(5.0867) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0249 | Time 98.6299, Epoch Time 1254.0453(1190.3665), Bit/dim 3.5681(best: 3.5661), Xent 1.9234, Loss 4.5298, Error 0.3266(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13700 | Time 21.4173(20.6477) | Bit/dim 3.5494(3.5548) | Xent 0.0360(0.0455) | Loss 8.8898(9.8529) | Error 0.0100(0.0141) Steps 772(785.03) | Grad Norm 3.2523(4.7070) | Total Time 0.00(0.00)\n",
      "Iter 13710 | Time 20.9628(20.7137) | Bit/dim 3.5583(3.5566) | Xent 0.0380(0.0456) | Loss 9.0103(9.6144) | Error 0.0111(0.0142) Steps 796(786.77) | Grad Norm 3.6009(4.6239) | Total Time 0.00(0.00)\n",
      "Iter 13720 | Time 19.9764(20.6081) | Bit/dim 3.5411(3.5551) | Xent 0.0319(0.0436) | Loss 8.8904(9.4117) | Error 0.0122(0.0137) Steps 790(784.73) | Grad Norm 3.8483(4.5225) | Total Time 0.00(0.00)\n",
      "Iter 13730 | Time 21.4583(20.5704) | Bit/dim 3.5268(3.5539) | Xent 0.0360(0.0430) | Loss 8.9792(9.2846) | Error 0.0111(0.0132) Steps 790(786.07) | Grad Norm 3.9920(4.3608) | Total Time 0.00(0.00)\n",
      "Iter 13740 | Time 20.9341(20.6422) | Bit/dim 3.5621(3.5539) | Xent 0.0398(0.0423) | Loss 8.8783(9.1832) | Error 0.0122(0.0127) Steps 814(787.77) | Grad Norm 4.7620(4.3821) | Total Time 0.00(0.00)\n",
      "Iter 13750 | Time 20.4677(20.5813) | Bit/dim 3.5243(3.5503) | Xent 0.0391(0.0418) | Loss 8.9009(9.1041) | Error 0.0089(0.0125) Steps 772(785.03) | Grad Norm 3.8035(4.5098) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0250 | Time 99.0012, Epoch Time 1252.6308(1192.2344), Bit/dim 3.5762(best: 3.5661), Xent 1.9666, Loss 4.5595, Error 0.3237(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13760 | Time 20.5609(20.6030) | Bit/dim 3.5470(3.5496) | Xent 0.0336(0.0425) | Loss 8.8866(9.7433) | Error 0.0100(0.0124) Steps 784(785.74) | Grad Norm 5.2727(4.4544) | Total Time 0.00(0.00)\n",
      "Iter 13770 | Time 20.2198(20.6159) | Bit/dim 3.5656(3.5532) | Xent 0.0619(0.0470) | Loss 8.9474(9.5350) | Error 0.0211(0.0136) Steps 784(785.24) | Grad Norm 6.2539(5.2601) | Total Time 0.00(0.00)\n",
      "Iter 13780 | Time 19.5929(20.5002) | Bit/dim 3.5548(3.5562) | Xent 0.0502(0.0490) | Loss 8.8331(9.3707) | Error 0.0144(0.0141) Steps 784(782.72) | Grad Norm 5.2530(5.3492) | Total Time 0.00(0.00)\n",
      "Iter 13790 | Time 20.4033(20.5429) | Bit/dim 3.5144(3.5548) | Xent 0.0471(0.0481) | Loss 8.7790(9.2374) | Error 0.0144(0.0136) Steps 784(780.91) | Grad Norm 4.5106(5.1170) | Total Time 0.00(0.00)\n",
      "Iter 13800 | Time 20.9460(20.6671) | Bit/dim 3.5400(3.5575) | Xent 0.0424(0.0476) | Loss 8.9410(9.1650) | Error 0.0144(0.0137) Steps 820(784.83) | Grad Norm 3.9707(4.9307) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 100.9725, Epoch Time 1259.6441(1194.2567), Bit/dim 3.5699(best: 3.5661), Xent 1.9153, Loss 4.5275, Error 0.3311(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13810 | Time 20.6387(20.6607) | Bit/dim 3.5359(3.5545) | Xent 0.1016(0.0479) | Loss 8.9841(9.9268) | Error 0.0311(0.0141) Steps 814(786.16) | Grad Norm 7.4610(4.7789) | Total Time 0.00(0.00)\n",
      "Iter 13820 | Time 20.6615(20.5976) | Bit/dim 3.5674(3.5552) | Xent 0.0247(0.0461) | Loss 8.8861(9.6572) | Error 0.0067(0.0140) Steps 778(787.20) | Grad Norm 3.7384(4.7132) | Total Time 0.00(0.00)\n",
      "Iter 13830 | Time 20.7876(20.5833) | Bit/dim 3.5503(3.5524) | Xent 0.0347(0.0450) | Loss 8.8485(9.4568) | Error 0.0100(0.0133) Steps 790(788.66) | Grad Norm 4.8522(4.5046) | Total Time 0.00(0.00)\n",
      "Iter 13840 | Time 21.1144(20.5497) | Bit/dim 3.5478(3.5533) | Xent 0.0363(0.0442) | Loss 8.9523(9.3130) | Error 0.0100(0.0128) Steps 802(789.27) | Grad Norm 4.1995(4.2605) | Total Time 0.00(0.00)\n",
      "Iter 13850 | Time 20.4254(20.4840) | Bit/dim 3.5481(3.5518) | Xent 0.0447(0.0431) | Loss 8.9215(9.2020) | Error 0.0144(0.0126) Steps 796(788.01) | Grad Norm 4.5204(4.1757) | Total Time 0.00(0.00)\n",
      "Iter 13860 | Time 19.7134(20.3905) | Bit/dim 3.5309(3.5510) | Xent 0.0251(0.0422) | Loss 8.7907(9.1077) | Error 0.0044(0.0122) Steps 778(785.24) | Grad Norm 4.3376(4.1566) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 99.3148, Epoch Time 1240.7839(1195.6525), Bit/dim 3.5659(best: 3.5661), Xent 1.9323, Loss 4.5320, Error 0.3321(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13870 | Time 20.2859(20.3452) | Bit/dim 3.5551(3.5493) | Xent 0.0592(0.0420) | Loss 8.8847(9.7069) | Error 0.0144(0.0119) Steps 772(783.62) | Grad Norm 8.5938(4.2756) | Total Time 0.00(0.00)\n",
      "Iter 13880 | Time 20.7821(20.3585) | Bit/dim 3.5357(3.5510) | Xent 0.0385(0.0445) | Loss 8.8509(9.4953) | Error 0.0100(0.0127) Steps 766(784.22) | Grad Norm 4.0876(4.3775) | Total Time 0.00(0.00)\n",
      "Iter 13890 | Time 20.4682(20.3554) | Bit/dim 3.5934(3.5535) | Xent 0.0576(0.0430) | Loss 8.9241(9.3307) | Error 0.0167(0.0125) Steps 796(785.24) | Grad Norm 4.7609(4.2608) | Total Time 0.00(0.00)\n",
      "Iter 13900 | Time 21.1608(20.3980) | Bit/dim 3.5230(3.5509) | Xent 0.0375(0.0424) | Loss 8.9579(9.2090) | Error 0.0100(0.0123) Steps 784(783.96) | Grad Norm 3.4665(4.1087) | Total Time 0.00(0.00)\n",
      "Iter 13910 | Time 21.1707(20.5484) | Bit/dim 3.5860(3.5496) | Xent 0.0169(0.0400) | Loss 8.9720(9.1273) | Error 0.0056(0.0117) Steps 790(788.56) | Grad Norm 3.0743(3.9325) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 98.9103, Epoch Time 1247.2964(1197.2019), Bit/dim 3.5664(best: 3.5659), Xent 1.8998, Loss 4.5163, Error 0.3260(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13920 | Time 20.9222(20.5671) | Bit/dim 3.5825(3.5521) | Xent 0.0509(0.0378) | Loss 8.9031(9.8678) | Error 0.0122(0.0112) Steps 772(787.45) | Grad Norm 3.2858(3.8845) | Total Time 0.00(0.00)\n",
      "Iter 13930 | Time 21.3801(20.6529) | Bit/dim 3.5683(3.5521) | Xent 0.0515(0.0381) | Loss 8.9542(9.6013) | Error 0.0133(0.0113) Steps 766(787.68) | Grad Norm 5.7901(3.8130) | Total Time 0.00(0.00)\n",
      "Iter 13940 | Time 21.1474(20.7319) | Bit/dim 3.5641(3.5523) | Xent 0.0715(0.0397) | Loss 9.0568(9.4251) | Error 0.0222(0.0119) Steps 754(785.91) | Grad Norm 11.0438(4.2686) | Total Time 0.00(0.00)\n",
      "Iter 13950 | Time 20.8726(20.7090) | Bit/dim 3.5517(3.5529) | Xent 0.0659(0.0436) | Loss 8.9085(9.2966) | Error 0.0178(0.0133) Steps 808(789.73) | Grad Norm 5.8465(4.7704) | Total Time 0.00(0.00)\n",
      "Iter 13960 | Time 21.4040(20.8117) | Bit/dim 3.5707(3.5544) | Xent 0.0880(0.0483) | Loss 9.0323(9.2045) | Error 0.0256(0.0149) Steps 772(789.16) | Grad Norm 8.1560(4.9130) | Total Time 0.00(0.00)\n",
      "Iter 13970 | Time 21.6268(20.7852) | Bit/dim 3.5361(3.5558) | Xent 0.0364(0.0504) | Loss 8.7724(9.1232) | Error 0.0111(0.0152) Steps 778(790.12) | Grad Norm 5.5206(5.1283) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 98.3026, Epoch Time 1267.2090(1199.3021), Bit/dim 3.5876(best: 3.5659), Xent 1.9465, Loss 4.5608, Error 0.3306(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13980 | Time 20.3050(20.6681) | Bit/dim 3.5682(3.5588) | Xent 0.0273(0.0513) | Loss 8.9212(9.7622) | Error 0.0078(0.0153) Steps 796(791.67) | Grad Norm 3.2030(5.2783) | Total Time 0.00(0.00)\n",
      "Iter 13990 | Time 20.8148(20.6634) | Bit/dim 3.5936(3.5575) | Xent 0.0330(0.0513) | Loss 9.0408(9.5508) | Error 0.0078(0.0151) Steps 796(791.00) | Grad Norm 5.2141(5.2499) | Total Time 0.00(0.00)\n",
      "Iter 14000 | Time 20.8836(20.7223) | Bit/dim 3.5815(3.5547) | Xent 0.0446(0.0503) | Loss 9.0069(9.3837) | Error 0.0133(0.0148) Steps 802(791.70) | Grad Norm 3.4917(4.9758) | Total Time 0.00(0.00)\n",
      "Iter 14010 | Time 20.2851(20.7088) | Bit/dim 3.5235(3.5535) | Xent 0.0326(0.0501) | Loss 8.8318(9.2512) | Error 0.0100(0.0145) Steps 778(790.65) | Grad Norm 4.0258(4.8736) | Total Time 0.00(0.00)\n",
      "Iter 14020 | Time 20.1319(20.7322) | Bit/dim 3.5359(3.5511) | Xent 0.0286(0.0482) | Loss 8.8748(9.1525) | Error 0.0111(0.0140) Steps 754(789.21) | Grad Norm 3.6704(4.6222) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 99.3158, Epoch Time 1261.6691(1201.1731), Bit/dim 3.5695(best: 3.5659), Xent 1.8827, Loss 4.5109, Error 0.3216(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14030 | Time 20.1530(20.7308) | Bit/dim 3.5344(3.5499) | Xent 0.0234(0.0449) | Loss 8.7598(9.8804) | Error 0.0067(0.0131) Steps 730(787.80) | Grad Norm 3.7625(4.5133) | Total Time 0.00(0.00)\n",
      "Iter 14040 | Time 20.7757(20.7263) | Bit/dim 3.5559(3.5527) | Xent 0.0273(0.0415) | Loss 8.7835(9.6191) | Error 0.0100(0.0126) Steps 778(787.93) | Grad Norm 3.9144(4.4953) | Total Time 0.00(0.00)\n",
      "Iter 14050 | Time 21.3930(20.7010) | Bit/dim 3.5389(3.5513) | Xent 0.0311(0.0392) | Loss 8.8357(9.4172) | Error 0.0089(0.0117) Steps 796(789.59) | Grad Norm 2.8123(4.2110) | Total Time 0.00(0.00)\n",
      "Iter 14060 | Time 21.1007(20.7040) | Bit/dim 3.5623(3.5493) | Xent 0.0556(0.0403) | Loss 9.0369(9.2866) | Error 0.0156(0.0120) Steps 796(790.23) | Grad Norm 3.8939(4.2094) | Total Time 0.00(0.00)\n",
      "Iter 14070 | Time 19.9686(20.6104) | Bit/dim 3.5462(3.5475) | Xent 0.0368(0.0380) | Loss 8.8459(9.1794) | Error 0.0133(0.0113) Steps 772(791.20) | Grad Norm 2.8523(4.1557) | Total Time 0.00(0.00)\n",
      "Iter 14080 | Time 20.6912(20.6069) | Bit/dim 3.5585(3.5466) | Xent 0.0218(0.0360) | Loss 8.8397(9.0952) | Error 0.0067(0.0106) Steps 802(790.28) | Grad Norm 3.0275(4.0430) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 99.2125, Epoch Time 1254.4717(1202.7720), Bit/dim 3.5634(best: 3.5659), Xent 2.0137, Loss 4.5702, Error 0.3274(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14090 | Time 20.0148(20.5396) | Bit/dim 3.4986(3.5462) | Xent 0.0338(0.0344) | Loss 8.7249(9.7312) | Error 0.0100(0.0101) Steps 772(788.59) | Grad Norm 4.1197(4.0144) | Total Time 0.00(0.00)\n",
      "Iter 14100 | Time 21.4428(20.5580) | Bit/dim 3.5288(3.5424) | Xent 0.0224(0.0347) | Loss 8.8466(9.5049) | Error 0.0078(0.0104) Steps 814(790.18) | Grad Norm 3.7468(3.9062) | Total Time 0.00(0.00)\n",
      "Iter 14110 | Time 20.5702(20.6023) | Bit/dim 3.5814(3.5435) | Xent 0.0375(0.0342) | Loss 9.0276(9.3419) | Error 0.0111(0.0102) Steps 790(793.34) | Grad Norm 3.1812(3.9276) | Total Time 0.00(0.00)\n",
      "Iter 14120 | Time 20.3447(20.5943) | Bit/dim 3.5482(3.5435) | Xent 0.0417(0.0347) | Loss 8.8224(9.2203) | Error 0.0144(0.0105) Steps 778(792.91) | Grad Norm 6.1640(4.1548) | Total Time 0.00(0.00)\n",
      "Iter 14130 | Time 20.4305(20.5826) | Bit/dim 3.5419(3.5447) | Xent 0.0439(0.0346) | Loss 8.7974(9.1267) | Error 0.0144(0.0106) Steps 760(791.87) | Grad Norm 3.6205(4.4249) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 98.8051, Epoch Time 1253.0081(1204.2791), Bit/dim 3.5710(best: 3.5634), Xent 1.9336, Loss 4.5378, Error 0.3233(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14140 | Time 21.3066(20.7520) | Bit/dim 3.5519(3.5470) | Xent 0.0476(0.0352) | Loss 8.9796(9.8792) | Error 0.0178(0.0108) Steps 814(794.08) | Grad Norm 4.0481(4.5588) | Total Time 0.00(0.00)\n",
      "Iter 14150 | Time 21.1455(20.7672) | Bit/dim 3.5397(3.5472) | Xent 0.0381(0.0371) | Loss 8.7958(9.6215) | Error 0.0078(0.0113) Steps 802(792.75) | Grad Norm 2.7537(4.5459) | Total Time 0.00(0.00)\n",
      "Iter 14160 | Time 21.0916(20.7867) | Bit/dim 3.5514(3.5494) | Xent 0.0157(0.0363) | Loss 8.9136(9.4385) | Error 0.0033(0.0109) Steps 790(794.07) | Grad Norm 4.0069(4.5374) | Total Time 0.00(0.00)\n",
      "Iter 14170 | Time 20.9927(21.0305) | Bit/dim 3.5335(3.5490) | Xent 0.0597(0.0396) | Loss 8.7987(9.3004) | Error 0.0144(0.0119) Steps 778(795.63) | Grad Norm 4.9157(4.4874) | Total Time 0.00(0.00)\n",
      "Iter 14180 | Time 20.4717(21.0002) | Bit/dim 3.5395(3.5491) | Xent 0.0327(0.0399) | Loss 8.8496(9.2014) | Error 0.0100(0.0119) Steps 784(797.77) | Grad Norm 4.2398(4.5077) | Total Time 0.00(0.00)\n",
      "Iter 14190 | Time 21.4741(20.9821) | Bit/dim 3.5350(3.5483) | Xent 0.0464(0.0410) | Loss 8.8786(9.1261) | Error 0.0133(0.0122) Steps 802(796.55) | Grad Norm 3.7561(4.5151) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 99.4945, Epoch Time 1279.4967(1206.5357), Bit/dim 3.5707(best: 3.5634), Xent 1.8722, Loss 4.5068, Error 0.3303(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14200 | Time 20.4320(20.9825) | Bit/dim 3.5436(3.5457) | Xent 0.0301(0.0420) | Loss 8.8923(9.7654) | Error 0.0089(0.0125) Steps 796(796.75) | Grad Norm 3.8930(4.6766) | Total Time 0.00(0.00)\n",
      "Iter 14210 | Time 19.9902(20.9253) | Bit/dim 3.5432(3.5481) | Xent 0.0418(0.0419) | Loss 8.8071(9.5480) | Error 0.0144(0.0125) Steps 790(794.95) | Grad Norm 4.9880(4.5097) | Total Time 0.00(0.00)\n",
      "Iter 14220 | Time 20.8231(20.8338) | Bit/dim 3.5500(3.5461) | Xent 0.0523(0.0401) | Loss 8.9038(9.3571) | Error 0.0167(0.0119) Steps 784(791.69) | Grad Norm 6.9999(4.3141) | Total Time 0.00(0.00)\n",
      "Iter 14230 | Time 21.2140(20.8334) | Bit/dim 3.5453(3.5450) | Xent 0.0441(0.0401) | Loss 8.7642(9.2217) | Error 0.0133(0.0119) Steps 802(793.20) | Grad Norm 7.4954(4.4514) | Total Time 0.00(0.00)\n",
      "Iter 14240 | Time 21.0691(20.8884) | Bit/dim 3.5289(3.5483) | Xent 0.0802(0.0396) | Loss 8.9291(9.1361) | Error 0.0244(0.0116) Steps 778(794.74) | Grad Norm 7.0733(4.4879) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 100.4235, Epoch Time 1268.4189(1208.3922), Bit/dim 3.5721(best: 3.5634), Xent 1.9160, Loss 4.5301, Error 0.3286(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14250 | Time 19.8541(20.8661) | Bit/dim 3.5260(3.5506) | Xent 0.0498(0.0410) | Loss 8.8196(9.9332) | Error 0.0122(0.0122) Steps 784(794.60) | Grad Norm 4.2414(4.6400) | Total Time 0.00(0.00)\n",
      "Iter 14260 | Time 21.7175(20.9108) | Bit/dim 3.5217(3.5500) | Xent 0.0204(0.0402) | Loss 8.8847(9.6597) | Error 0.0067(0.0118) Steps 808(796.09) | Grad Norm 3.5896(4.4222) | Total Time 0.00(0.00)\n",
      "Iter 14270 | Time 21.5747(20.9193) | Bit/dim 3.5652(3.5510) | Xent 0.0269(0.0377) | Loss 8.9955(9.4567) | Error 0.0089(0.0109) Steps 808(796.09) | Grad Norm 3.1854(4.1746) | Total Time 0.00(0.00)\n",
      "Iter 14280 | Time 21.1662(20.8682) | Bit/dim 3.5216(3.5496) | Xent 0.0273(0.0398) | Loss 8.8571(9.3143) | Error 0.0100(0.0114) Steps 814(796.33) | Grad Norm 7.3577(4.2973) | Total Time 0.00(0.00)\n",
      "Iter 14290 | Time 20.9136(20.9500) | Bit/dim 3.5408(3.5483) | Xent 0.0455(0.0399) | Loss 8.8720(9.1993) | Error 0.0189(0.0117) Steps 796(795.80) | Grad Norm 5.3269(4.3160) | Total Time 0.00(0.00)\n",
      "Iter 14300 | Time 21.4393(20.9573) | Bit/dim 3.5265(3.5488) | Xent 0.0362(0.0392) | Loss 8.9329(9.1209) | Error 0.0089(0.0118) Steps 790(795.73) | Grad Norm 5.7782(4.2815) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 100.2422, Epoch Time 1271.7828(1210.2939), Bit/dim 3.5673(best: 3.5634), Xent 1.8604, Loss 4.4975, Error 0.3275(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14310 | Time 20.4234(20.9045) | Bit/dim 3.5483(3.5504) | Xent 0.0218(0.0384) | Loss 8.8843(9.7671) | Error 0.0078(0.0115) Steps 796(796.33) | Grad Norm 3.2322(4.3848) | Total Time 0.00(0.00)\n",
      "Iter 14320 | Time 21.3232(20.9029) | Bit/dim 3.5176(3.5471) | Xent 0.0561(0.0384) | Loss 9.0027(9.5453) | Error 0.0167(0.0116) Steps 814(798.77) | Grad Norm 5.0461(4.4017) | Total Time 0.00(0.00)\n",
      "Iter 14330 | Time 21.0792(20.8267) | Bit/dim 3.5601(3.5479) | Xent 0.0335(0.0367) | Loss 8.9801(9.3766) | Error 0.0089(0.0110) Steps 796(795.83) | Grad Norm 3.6609(4.2556) | Total Time 0.00(0.00)\n",
      "Iter 14340 | Time 20.7752(20.7856) | Bit/dim 3.5524(3.5468) | Xent 0.0176(0.0343) | Loss 9.0214(9.2546) | Error 0.0044(0.0102) Steps 790(793.32) | Grad Norm 3.4215(4.1401) | Total Time 0.00(0.00)\n",
      "Iter 14350 | Time 20.8132(20.8347) | Bit/dim 3.5589(3.5462) | Xent 0.0312(0.0320) | Loss 8.9082(9.1555) | Error 0.0111(0.0097) Steps 802(795.46) | Grad Norm 3.4645(4.1751) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 100.2295, Epoch Time 1264.4017(1211.9171), Bit/dim 3.5675(best: 3.5634), Xent 2.0762, Loss 4.6056, Error 0.3345(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14360 | Time 21.0580(20.8349) | Bit/dim 3.5435(3.5478) | Xent 0.0253(0.0331) | Loss 8.8275(9.9223) | Error 0.0056(0.0099) Steps 808(796.03) | Grad Norm 2.7895(4.2204) | Total Time 0.00(0.00)\n",
      "Iter 14370 | Time 20.7439(20.7959) | Bit/dim 3.5798(3.5496) | Xent 0.0687(0.0371) | Loss 8.9901(9.6623) | Error 0.0133(0.0110) Steps 772(795.87) | Grad Norm 8.3996(4.6425) | Total Time 0.00(0.00)\n",
      "Iter 14380 | Time 20.8929(20.8191) | Bit/dim 3.5231(3.5449) | Xent 0.0447(0.0377) | Loss 8.9478(9.4422) | Error 0.0089(0.0106) Steps 820(795.90) | Grad Norm 4.8258(4.5182) | Total Time 0.00(0.00)\n",
      "Iter 14390 | Time 20.0045(20.8362) | Bit/dim 3.5013(3.5419) | Xent 0.0392(0.0377) | Loss 8.8037(9.2825) | Error 0.0111(0.0109) Steps 796(795.70) | Grad Norm 2.4258(4.2533) | Total Time 0.00(0.00)\n",
      "Iter 14400 | Time 21.1061(20.8293) | Bit/dim 3.5526(3.5442) | Xent 0.0379(0.0390) | Loss 8.8885(9.1881) | Error 0.0133(0.0113) Steps 790(795.89) | Grad Norm 4.7283(4.3282) | Total Time 0.00(0.00)\n",
      "Iter 14410 | Time 20.4506(20.8610) | Bit/dim 3.5768(3.5494) | Xent 0.0379(0.0378) | Loss 8.9870(9.1231) | Error 0.0122(0.0111) Steps 772(795.67) | Grad Norm 3.8479(4.2105) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 99.8178, Epoch Time 1266.9453(1213.5680), Bit/dim 3.5660(best: 3.5634), Xent 1.8972, Loss 4.5145, Error 0.3205(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14420 | Time 21.2692(20.8240) | Bit/dim 3.5487(3.5484) | Xent 0.0999(0.0410) | Loss 8.9549(9.7649) | Error 0.0333(0.0118) Steps 796(796.44) | Grad Norm 8.1625(4.4287) | Total Time 0.00(0.00)\n",
      "Iter 14430 | Time 20.8288(20.8335) | Bit/dim 3.5395(3.5494) | Xent 0.0442(0.0445) | Loss 8.9255(9.5413) | Error 0.0122(0.0128) Steps 796(795.75) | Grad Norm 5.0469(4.9275) | Total Time 0.00(0.00)\n",
      "Iter 14440 | Time 20.6573(20.8875) | Bit/dim 3.5390(3.5514) | Xent 0.0887(0.0450) | Loss 9.0237(9.3901) | Error 0.0267(0.0129) Steps 784(798.14) | Grad Norm 6.3392(4.9055) | Total Time 0.00(0.00)\n",
      "Iter 14450 | Time 20.2446(20.8387) | Bit/dim 3.5543(3.5515) | Xent 0.0515(0.0439) | Loss 8.9334(9.2629) | Error 0.0133(0.0127) Steps 802(796.22) | Grad Norm 3.5937(4.5747) | Total Time 0.00(0.00)\n",
      "Iter 14460 | Time 21.5693(20.8305) | Bit/dim 3.5420(3.5493) | Xent 0.0528(0.0431) | Loss 8.9262(9.1631) | Error 0.0189(0.0127) Steps 778(795.48) | Grad Norm 3.8875(4.4040) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 100.7363, Epoch Time 1269.4312(1215.2439), Bit/dim 3.5647(best: 3.5634), Xent 1.9130, Loss 4.5213, Error 0.3220(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14470 | Time 21.0904(20.9165) | Bit/dim 3.5495(3.5493) | Xent 0.0370(0.0422) | Loss 8.8949(9.9172) | Error 0.0111(0.0125) Steps 808(797.18) | Grad Norm 5.0960(4.4030) | Total Time 0.00(0.00)\n",
      "Iter 14480 | Time 20.5437(20.9544) | Bit/dim 3.5236(3.5474) | Xent 0.0233(0.0380) | Loss 8.7139(9.6443) | Error 0.0078(0.0111) Steps 784(796.56) | Grad Norm 2.5147(4.0332) | Total Time 0.00(0.00)\n",
      "Iter 14490 | Time 20.7626(20.8976) | Bit/dim 3.5574(3.5472) | Xent 0.0282(0.0370) | Loss 8.8080(9.4315) | Error 0.0067(0.0107) Steps 790(794.92) | Grad Norm 3.2016(3.9363) | Total Time 0.00(0.00)\n",
      "Iter 14500 | Time 21.3245(20.8736) | Bit/dim 3.5334(3.5465) | Xent 0.0541(0.0414) | Loss 8.6826(9.2782) | Error 0.0156(0.0118) Steps 796(794.37) | Grad Norm 3.7743(4.2154) | Total Time 0.00(0.00)\n",
      "Iter 14510 | Time 20.3920(20.8548) | Bit/dim 3.5711(3.5488) | Xent 0.0330(0.0411) | Loss 8.9061(9.1807) | Error 0.0100(0.0121) Steps 778(794.37) | Grad Norm 3.7443(4.2290) | Total Time 0.00(0.00)\n",
      "Iter 14520 | Time 20.7137(20.9233) | Bit/dim 3.5560(3.5454) | Xent 0.0553(0.0412) | Loss 8.9364(9.1000) | Error 0.0144(0.0121) Steps 796(794.65) | Grad Norm 4.8569(4.1108) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 101.6869, Epoch Time 1274.6438(1217.0258), Bit/dim 3.5661(best: 3.5634), Xent 1.8799, Loss 4.5061, Error 0.3197(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14530 | Time 20.5871(20.9830) | Bit/dim 3.5764(3.5474) | Xent 0.0518(0.0418) | Loss 9.1057(9.7702) | Error 0.0144(0.0123) Steps 808(798.73) | Grad Norm 5.8774(4.2259) | Total Time 0.00(0.00)\n",
      "Iter 14540 | Time 21.3335(21.0292) | Bit/dim 3.5215(3.5476) | Xent 0.0391(0.0457) | Loss 8.9331(9.5564) | Error 0.0111(0.0131) Steps 802(800.82) | Grad Norm 4.3049(4.4294) | Total Time 0.00(0.00)\n",
      "Iter 14550 | Time 20.3450(20.8932) | Bit/dim 3.5704(3.5483) | Xent 0.0481(0.0464) | Loss 8.9712(9.3796) | Error 0.0167(0.0134) Steps 772(795.15) | Grad Norm 4.9495(4.5464) | Total Time 0.00(0.00)\n",
      "Iter 14560 | Time 21.9083(20.8487) | Bit/dim 3.5493(3.5489) | Xent 0.0233(0.0431) | Loss 8.9014(9.2512) | Error 0.0078(0.0127) Steps 778(795.37) | Grad Norm 3.5752(4.3141) | Total Time 0.00(0.00)\n",
      "Iter 14570 | Time 21.1451(20.8011) | Bit/dim 3.5541(3.5466) | Xent 0.0260(0.0407) | Loss 9.0170(9.1440) | Error 0.0089(0.0120) Steps 802(792.73) | Grad Norm 3.6296(4.1291) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 99.3503, Epoch Time 1265.1299(1218.4690), Bit/dim 3.5690(best: 3.5634), Xent 1.9818, Loss 4.5599, Error 0.3306(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14580 | Time 21.8619(20.8694) | Bit/dim 3.5740(3.5458) | Xent 0.0304(0.0443) | Loss 8.9461(9.8945) | Error 0.0067(0.0128) Steps 790(789.60) | Grad Norm 4.3813(4.3581) | Total Time 0.00(0.00)\n",
      "Iter 14590 | Time 20.5763(20.8901) | Bit/dim 3.5699(3.5463) | Xent 0.0349(0.0429) | Loss 8.8274(9.6304) | Error 0.0089(0.0124) Steps 778(791.10) | Grad Norm 3.3124(4.2509) | Total Time 0.00(0.00)\n",
      "Iter 14600 | Time 20.3689(20.8075) | Bit/dim 3.5572(3.5433) | Xent 0.0205(0.0399) | Loss 8.9152(9.4224) | Error 0.0044(0.0115) Steps 808(792.70) | Grad Norm 2.9596(4.0229) | Total Time 0.00(0.00)\n",
      "Iter 14610 | Time 21.5053(20.8806) | Bit/dim 3.5503(3.5424) | Xent 0.0671(0.0381) | Loss 9.0017(9.2755) | Error 0.0189(0.0112) Steps 802(793.75) | Grad Norm 6.1719(3.9406) | Total Time 0.00(0.00)\n",
      "Iter 14620 | Time 20.3348(20.8901) | Bit/dim 3.5368(3.5425) | Xent 0.0747(0.0406) | Loss 8.9215(9.1786) | Error 0.0222(0.0124) Steps 790(795.11) | Grad Norm 6.9083(4.4763) | Total Time 0.00(0.00)\n",
      "Iter 14630 | Time 20.4153(20.8182) | Bit/dim 3.5500(3.5462) | Xent 0.0268(0.0431) | Loss 8.8849(9.1100) | Error 0.0067(0.0133) Steps 820(798.09) | Grad Norm 3.9098(4.4489) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 100.7631, Epoch Time 1269.9503(1220.0134), Bit/dim 3.5718(best: 3.5634), Xent 1.8861, Loss 4.5148, Error 0.3266(best: 0.3056)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14640 | Time 20.6513(20.8568) | Bit/dim 3.5419(3.5484) | Xent 0.0342(0.0439) | Loss 8.8164(9.7525) | Error 0.0111(0.0132) Steps 796(799.25) | Grad Norm 3.1577(4.4154) | Total Time 0.00(0.00)\n",
      "Iter 14650 | Time 21.2548(20.8528) | Bit/dim 3.5671(3.5492) | Xent 0.0446(0.0455) | Loss 9.0455(9.5385) | Error 0.0122(0.0139) Steps 778(797.97) | Grad Norm 3.1979(4.4974) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl_multiscale.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run2 --resume ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run2/epoch_250_checkpt.pth --seed 2 --lr 0.0001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --scale_std 6.0\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
