{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_cifar10_bs8K_sratio_0_5_drop_0_5_baseline_run1/epoch_250_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs8K_sratio_0_5_drop_0_5_baseline_run1', seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1414198\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 1501 | Time 131.9712(74.6377) | Bit/dim 3.9756(3.9994) | Xent 1.2007(1.2558) | Loss 4.5759(4.6273) | Error 0.4343(0.4482) Steps 802(806.73) | Grad Norm 2.6350(5.9918) | Total Time 14.00(14.00)\n",
      "Iter 1502 | Time 73.9040(74.6157) | Bit/dim 3.9652(3.9984) | Xent 1.2111(1.2545) | Loss 4.5707(4.6256) | Error 0.4271(0.4475) Steps 802(806.59) | Grad Norm 2.1972(5.8780) | Total Time 14.00(14.00)\n",
      "Iter 1503 | Time 75.1091(74.6305) | Bit/dim 3.9694(3.9975) | Xent 1.2026(1.2529) | Loss 4.5706(4.6240) | Error 0.4391(0.4473) Steps 802(806.45) | Grad Norm 1.2939(5.7405) | Total Time 14.00(14.00)\n",
      "Iter 1504 | Time 73.6952(74.6025) | Bit/dim 3.9608(3.9964) | Xent 1.2172(1.2519) | Loss 4.5694(4.6223) | Error 0.4376(0.4470) Steps 802(806.32) | Grad Norm 1.1691(5.6033) | Total Time 14.00(14.00)\n",
      "Iter 1505 | Time 73.3825(74.5659) | Bit/dim 3.9646(3.9955) | Xent 1.1979(1.2502) | Loss 4.5635(4.6206) | Error 0.4277(0.4464) Steps 802(806.19) | Grad Norm 1.5671(5.4822) | Total Time 14.00(14.00)\n",
      "Iter 1506 | Time 75.0738(74.5811) | Bit/dim 3.9609(3.9944) | Xent 1.1949(1.2486) | Loss 4.5584(4.6187) | Error 0.4280(0.4459) Steps 802(806.06) | Grad Norm 1.6396(5.3669) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 44.4445, Epoch Time 563.7716(483.4405), Bit/dim 3.9643(best: inf), Xent 1.1648, Loss 4.5467, Error 0.4185(best: inf)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1507 | Time 85.4549(74.9073) | Bit/dim 3.9700(3.9937) | Xent 1.2256(1.2479) | Loss 4.5828(4.6176) | Error 0.4417(0.4457) Steps 802(805.94) | Grad Norm 1.7809(5.2594) | Total Time 14.00(14.00)\n",
      "Iter 1508 | Time 74.9357(74.9082) | Bit/dim 3.9597(3.9927) | Xent 1.2012(1.2465) | Loss 4.5603(4.6159) | Error 0.4293(0.4452) Steps 802(805.82) | Grad Norm 1.6745(5.1518) | Total Time 14.00(14.00)\n",
      "Iter 1509 | Time 74.8477(74.9063) | Bit/dim 3.9613(3.9917) | Xent 1.1886(1.2447) | Loss 4.5556(4.6141) | Error 0.4247(0.4446) Steps 802(805.71) | Grad Norm 0.8626(5.0231) | Total Time 14.00(14.00)\n",
      "Iter 1510 | Time 73.3480(74.8596) | Bit/dim 3.9675(3.9910) | Xent 1.2149(1.2438) | Loss 4.5750(4.6129) | Error 0.4315(0.4442) Steps 802(805.60) | Grad Norm 1.1527(4.9070) | Total Time 14.00(14.00)\n",
      "Iter 1511 | Time 75.1261(74.8676) | Bit/dim 3.9601(3.9901) | Xent 1.2076(1.2428) | Loss 4.5639(4.6115) | Error 0.4273(0.4437) Steps 802(805.49) | Grad Norm 1.5948(4.8077) | Total Time 14.00(14.00)\n",
      "Iter 1512 | Time 78.8578(74.9873) | Bit/dim 3.9588(3.9891) | Xent 1.1779(1.2408) | Loss 4.5478(4.6096) | Error 0.4220(0.4431) Steps 796(805.20) | Grad Norm 1.9535(4.7220) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 29.5578, Epoch Time 507.9170(484.1748), Bit/dim 3.9624(best: 3.9643), Xent 1.1588, Loss 4.5418, Error 0.4165(best: 0.4185)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1513 | Time 77.5078(75.0629) | Bit/dim 3.9730(3.9887) | Xent 1.1799(1.2390) | Loss 4.5629(4.6082) | Error 0.4230(0.4425) Steps 802(805.11) | Grad Norm 1.4593(4.6242) | Total Time 14.00(14.00)\n",
      "Iter 1514 | Time 76.2133(75.0974) | Bit/dim 3.9670(3.9880) | Xent 1.2157(1.2383) | Loss 4.5749(4.6072) | Error 0.4326(0.4422) Steps 802(805.01) | Grad Norm 1.1299(4.5193) | Total Time 14.00(14.00)\n",
      "Iter 1515 | Time 73.5181(75.0500) | Bit/dim 3.9536(3.9870) | Xent 1.2052(1.2373) | Loss 4.5562(4.6056) | Error 0.4343(0.4419) Steps 802(804.92) | Grad Norm 0.8799(4.4101) | Total Time 14.00(14.00)\n",
      "Iter 1516 | Time 75.8426(75.0738) | Bit/dim 3.9536(3.9860) | Xent 1.2051(1.2363) | Loss 4.5561(4.6041) | Error 0.4353(0.4417) Steps 802(804.84) | Grad Norm 1.1503(4.3123) | Total Time 14.00(14.00)\n",
      "Iter 1517 | Time 75.5811(75.0890) | Bit/dim 3.9563(3.9851) | Xent 1.1802(1.2346) | Loss 4.5464(4.6024) | Error 0.4250(0.4412) Steps 802(804.75) | Grad Norm 1.2726(4.2212) | Total Time 14.00(14.00)\n",
      "Iter 1518 | Time 75.5954(75.1042) | Bit/dim 3.9690(3.9846) | Xent 1.1754(1.2329) | Loss 4.5567(4.6010) | Error 0.4181(0.4405) Steps 802(804.67) | Grad Norm 1.3756(4.1358) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 29.1612, Epoch Time 499.4035(484.6317), Bit/dim 3.9618(best: 3.9624), Xent 1.1582, Loss 4.5409, Error 0.4194(best: 0.4165)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1519 | Time 71.8184(75.0057) | Bit/dim 3.9565(3.9838) | Xent 1.1818(1.2313) | Loss 4.5473(4.5994) | Error 0.4215(0.4400) Steps 802(804.59) | Grad Norm 0.9926(4.0415) | Total Time 14.00(14.00)\n",
      "Iter 1520 | Time 74.6171(74.9940) | Bit/dim 3.9680(3.9833) | Xent 1.1874(1.2300) | Loss 4.5617(4.5983) | Error 0.4300(0.4397) Steps 802(804.51) | Grad Norm 0.7353(3.9423) | Total Time 14.00(14.00)\n",
      "Iter 1521 | Time 72.6339(74.9232) | Bit/dim 3.9708(3.9829) | Xent 1.2099(1.2294) | Loss 4.5757(4.5976) | Error 0.4389(0.4396) Steps 802(804.44) | Grad Norm 0.9281(3.8519) | Total Time 14.00(14.00)\n",
      "Iter 1522 | Time 73.1551(74.8701) | Bit/dim 3.9491(3.9819) | Xent 1.2013(1.2286) | Loss 4.5497(4.5962) | Error 0.4241(0.4392) Steps 802(804.36) | Grad Norm 1.7266(3.7881) | Total Time 14.00(14.00)\n",
      "Iter 1523 | Time 73.5225(74.8297) | Bit/dim 3.9651(3.9814) | Xent 1.1834(1.2272) | Loss 4.5568(4.5950) | Error 0.4230(0.4387) Steps 802(804.29) | Grad Norm 1.8766(3.7308) | Total Time 14.00(14.00)\n",
      "Iter 1524 | Time 74.4859(74.8194) | Bit/dim 3.9564(3.9806) | Xent 1.2034(1.2265) | Loss 4.5581(4.5939) | Error 0.4319(0.4385) Steps 802(804.22) | Grad Norm 1.0660(3.6508) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 29.2168, Epoch Time 485.0525(484.6443), Bit/dim 3.9626(best: 3.9618), Xent 1.1547, Loss 4.5399, Error 0.4166(best: 0.4165)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1525 | Time 73.3582(74.7756) | Bit/dim 3.9552(3.9799) | Xent 1.2047(1.2258) | Loss 4.5576(4.5928) | Error 0.4327(0.4383) Steps 802(804.16) | Grad Norm 1.2489(3.5788) | Total Time 14.00(14.00)\n",
      "Iter 1526 | Time 74.6734(74.7725) | Bit/dim 3.9550(3.9791) | Xent 1.2004(1.2251) | Loss 4.5552(4.5917) | Error 0.4233(0.4379) Steps 802(804.09) | Grad Norm 1.2436(3.5087) | Total Time 14.00(14.00)\n",
      "Iter 1527 | Time 73.0635(74.7212) | Bit/dim 3.9646(3.9787) | Xent 1.1931(1.2241) | Loss 4.5612(4.5908) | Error 0.4286(0.4376) Steps 802(804.03) | Grad Norm 1.4672(3.4475) | Total Time 14.00(14.00)\n",
      "Iter 1528 | Time 74.7640(74.7225) | Bit/dim 3.9642(3.9783) | Xent 1.2024(1.2235) | Loss 4.5654(4.5900) | Error 0.4361(0.4375) Steps 802(803.97) | Grad Norm 1.3048(3.3832) | Total Time 14.00(14.00)\n",
      "Iter 1529 | Time 73.0155(74.6713) | Bit/dim 3.9617(3.9778) | Xent 1.1905(1.2225) | Loss 4.5570(4.5890) | Error 0.4225(0.4371) Steps 802(803.91) | Grad Norm 1.2542(3.3193) | Total Time 14.00(14.00)\n",
      "Iter 1530 | Time 77.3541(74.7518) | Bit/dim 3.9544(3.9771) | Xent 1.1980(1.2217) | Loss 4.5534(4.5879) | Error 0.4300(0.4369) Steps 802(803.85) | Grad Norm 1.1511(3.2543) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 28.8405, Epoch Time 490.7752(484.8282), Bit/dim 3.9609(best: 3.9618), Xent 1.1526, Loss 4.5372, Error 0.4146(best: 0.4165)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1531 | Time 74.2564(74.7369) | Bit/dim 3.9587(3.9765) | Xent 1.1916(1.2208) | Loss 4.5545(4.5869) | Error 0.4319(0.4367) Steps 802(803.80) | Grad Norm 0.9155(3.1841) | Total Time 14.00(14.00)\n",
      "Iter 1532 | Time 76.3081(74.7841) | Bit/dim 3.9636(3.9761) | Xent 1.1718(1.2194) | Loss 4.5495(4.5858) | Error 0.4209(0.4363) Steps 802(803.74) | Grad Norm 0.9212(3.1162) | Total Time 14.00(14.00)\n",
      "Iter 1533 | Time 76.2575(74.8283) | Bit/dim 3.9545(3.9755) | Xent 1.1716(1.2179) | Loss 4.5403(4.5844) | Error 0.4173(0.4357) Steps 808(803.87) | Grad Norm 1.2250(3.0595) | Total Time 14.00(14.00)\n",
      "Iter 1534 | Time 72.9342(74.7714) | Bit/dim 3.9602(3.9750) | Xent 1.2117(1.2178) | Loss 4.5661(4.5839) | Error 0.4374(0.4357) Steps 802(803.81) | Grad Norm 0.8951(2.9946) | Total Time 14.00(14.00)\n",
      "Iter 1535 | Time 75.7237(74.8000) | Bit/dim 3.9717(3.9749) | Xent 1.1930(1.2170) | Loss 4.5682(4.5834) | Error 0.4266(0.4355) Steps 802(803.76) | Grad Norm 0.8829(2.9312) | Total Time 14.00(14.00)\n",
      "Iter 1536 | Time 73.6143(74.7644) | Bit/dim 3.9556(3.9743) | Xent 1.2064(1.2167) | Loss 4.5588(4.5827) | Error 0.4260(0.4352) Steps 802(803.71) | Grad Norm 0.9367(2.8714) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 28.9601, Epoch Time 493.7057(485.0946), Bit/dim 3.9608(best: 3.9609), Xent 1.1523, Loss 4.5370, Error 0.4154(best: 0.4146)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1537 | Time 74.8751(74.7678) | Bit/dim 3.9595(3.9739) | Xent 1.2076(1.2164) | Loss 4.5632(4.5821) | Error 0.4384(0.4353) Steps 802(803.66) | Grad Norm 0.6182(2.8038) | Total Time 14.00(14.00)\n",
      "Iter 1538 | Time 75.8949(74.8016) | Bit/dim 3.9561(3.9734) | Xent 1.1842(1.2155) | Loss 4.5482(4.5811) | Error 0.4301(0.4351) Steps 802(803.61) | Grad Norm 1.1743(2.7549) | Total Time 14.00(14.00)\n",
      "Iter 1539 | Time 76.2686(74.8456) | Bit/dim 3.9685(3.9732) | Xent 1.1699(1.2141) | Loss 4.5535(4.5803) | Error 0.4191(0.4346) Steps 802(803.56) | Grad Norm 0.8508(2.6978) | Total Time 14.00(14.00)\n",
      "Iter 1540 | Time 77.2597(74.9180) | Bit/dim 3.9411(3.9723) | Xent 1.2032(1.2138) | Loss 4.5427(4.5791) | Error 0.4317(0.4346) Steps 802(803.51) | Grad Norm 0.6466(2.6362) | Total Time 14.00(14.00)\n",
      "Iter 1541 | Time 73.3475(74.8709) | Bit/dim 3.9639(3.9720) | Xent 1.1866(1.2129) | Loss 4.5572(4.5785) | Error 0.4224(0.4342) Steps 802(803.47) | Grad Norm 1.4730(2.6013) | Total Time 14.00(14.00)\n",
      "Iter 1542 | Time 77.1647(74.9397) | Bit/dim 3.9640(3.9718) | Xent 1.1802(1.2120) | Loss 4.5541(4.5777) | Error 0.4177(0.4337) Steps 802(803.42) | Grad Norm 0.6091(2.5416) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 29.0531, Epoch Time 499.7100(485.5330), Bit/dim 3.9592(best: 3.9608), Xent 1.1509, Loss 4.5347, Error 0.4116(best: 0.4146)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1543 | Time 71.5789(74.8389) | Bit/dim 3.9549(3.9713) | Xent 1.1889(1.2113) | Loss 4.5494(4.5769) | Error 0.4219(0.4333) Steps 802(803.38) | Grad Norm 0.6356(2.4844) | Total Time 14.00(14.00)\n",
      "Iter 1544 | Time 75.7353(74.8658) | Bit/dim 3.9551(3.9708) | Xent 1.2116(1.2113) | Loss 4.5610(4.5764) | Error 0.4326(0.4333) Steps 802(803.34) | Grad Norm 0.6840(2.4304) | Total Time 14.00(14.00)\n",
      "Iter 1545 | Time 75.8112(74.8941) | Bit/dim 3.9634(3.9706) | Xent 1.1903(1.2106) | Loss 4.5585(4.5759) | Error 0.4347(0.4334) Steps 802(803.30) | Grad Norm 0.8808(2.3839) | Total Time 14.00(14.00)\n",
      "Iter 1546 | Time 75.1459(74.9017) | Bit/dim 3.9613(3.9703) | Xent 1.1860(1.2099) | Loss 4.5543(4.5752) | Error 0.4225(0.4330) Steps 802(803.26) | Grad Norm 0.6040(2.3305) | Total Time 14.00(14.00)\n",
      "Iter 1547 | Time 74.4035(74.8867) | Bit/dim 3.9550(3.9698) | Xent 1.1774(1.2089) | Loss 4.5437(4.5743) | Error 0.4223(0.4327) Steps 802(803.22) | Grad Norm 0.8472(2.2860) | Total Time 14.00(14.00)\n",
      "Iter 1548 | Time 76.5017(74.9352) | Bit/dim 3.9615(3.9696) | Xent 1.1905(1.2084) | Loss 4.5567(4.5738) | Error 0.4223(0.4324) Steps 802(803.18) | Grad Norm 0.8082(2.2417) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 28.6998, Epoch Time 493.4155(485.7695), Bit/dim 3.9587(best: 3.9592), Xent 1.1500, Loss 4.5338, Error 0.4142(best: 0.4116)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1549 | Time 74.1476(74.9116) | Bit/dim 3.9516(3.9690) | Xent 1.2052(1.2083) | Loss 4.5542(4.5732) | Error 0.4284(0.4323) Steps 802(803.15) | Grad Norm 0.6341(2.1934) | Total Time 14.00(14.00)\n",
      "Iter 1550 | Time 77.1599(74.9790) | Bit/dim 3.9607(3.9688) | Xent 1.1781(1.2074) | Loss 4.5498(4.5725) | Error 0.4203(0.4319) Steps 802(803.11) | Grad Norm 0.8853(2.1542) | Total Time 14.00(14.00)\n",
      "Iter 1551 | Time 75.6888(75.0003) | Bit/dim 3.9553(3.9684) | Xent 1.1760(1.2064) | Loss 4.5433(4.5716) | Error 0.4175(0.4315) Steps 802(803.08) | Grad Norm 0.5763(2.1069) | Total Time 14.00(14.00)\n",
      "Iter 1552 | Time 74.7517(74.9929) | Bit/dim 3.9599(3.9681) | Xent 1.1741(1.2055) | Loss 4.5470(4.5709) | Error 0.4226(0.4312) Steps 802(803.05) | Grad Norm 0.7064(2.0648) | Total Time 14.00(14.00)\n",
      "Iter 1553 | Time 75.9200(75.0207) | Bit/dim 3.9658(3.9681) | Xent 1.2119(1.2057) | Loss 4.5717(4.5709) | Error 0.4375(0.4314) Steps 802(803.02) | Grad Norm 0.8001(2.0269) | Total Time 14.00(14.00)\n",
      "Iter 1554 | Time 72.8026(74.9541) | Bit/dim 3.9595(3.9678) | Xent 1.1868(1.2051) | Loss 4.5529(4.5703) | Error 0.4243(0.4312) Steps 802(802.99) | Grad Norm 0.7244(1.9878) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 29.0433, Epoch Time 495.0239(486.0471), Bit/dim 3.9586(best: 3.9587), Xent 1.1495, Loss 4.5333, Error 0.4159(best: 0.4116)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1555 | Time 73.7882(74.9191) | Bit/dim 3.9611(3.9676) | Xent 1.1948(1.2048) | Loss 4.5585(4.5700) | Error 0.4300(0.4312) Steps 802(802.96) | Grad Norm 0.7665(1.9512) | Total Time 14.00(14.00)\n",
      "Iter 1556 | Time 75.2716(74.9297) | Bit/dim 3.9660(3.9675) | Xent 1.2034(1.2047) | Loss 4.5677(4.5699) | Error 0.4236(0.4309) Steps 802(802.93) | Grad Norm 0.8023(1.9167) | Total Time 14.00(14.00)\n",
      "Iter 1557 | Time 75.4236(74.9445) | Bit/dim 3.9512(3.9671) | Xent 1.1640(1.2035) | Loss 4.5332(4.5688) | Error 0.4189(0.4306) Steps 802(802.90) | Grad Norm 0.8244(1.8839) | Total Time 14.00(14.00)\n",
      "Iter 1558 | Time 72.9261(74.8840) | Bit/dim 3.9592(3.9668) | Xent 1.1958(1.2033) | Loss 4.5571(4.5685) | Error 0.4311(0.4306) Steps 802(802.87) | Grad Norm 0.8452(1.8528) | Total Time 14.00(14.00)\n",
      "Iter 1559 | Time 76.7100(74.9388) | Bit/dim 3.9492(3.9663) | Xent 1.1945(1.2030) | Loss 4.5465(4.5678) | Error 0.4267(0.4305) Steps 802(802.85) | Grad Norm 1.0784(1.8296) | Total Time 14.00(14.00)\n",
      "Iter 1560 | Time 75.7974(74.9645) | Bit/dim 3.9560(3.9660) | Xent 1.1745(1.2022) | Loss 4.5432(4.5671) | Error 0.4153(0.4300) Steps 802(802.82) | Grad Norm 1.1793(1.8100) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 29.2642, Epoch Time 494.9243(486.3134), Bit/dim 3.9582(best: 3.9586), Xent 1.1463, Loss 4.5314, Error 0.4119(best: 0.4116)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1561 | Time 73.2660(74.9136) | Bit/dim 3.9452(3.9654) | Xent 1.1993(1.2021) | Loss 4.5449(4.5664) | Error 0.4217(0.4298) Steps 802(802.80) | Grad Norm 0.8839(1.7823) | Total Time 14.00(14.00)\n",
      "Iter 1562 | Time 73.5234(74.8719) | Bit/dim 3.9628(3.9653) | Xent 1.1860(1.2016) | Loss 4.5559(4.5661) | Error 0.4209(0.4295) Steps 802(802.77) | Grad Norm 0.6114(1.7471) | Total Time 14.00(14.00)\n",
      "Iter 1563 | Time 75.7799(74.8991) | Bit/dim 3.9700(3.9654) | Xent 1.1646(1.2005) | Loss 4.5523(4.5657) | Error 0.4201(0.4292) Steps 802(802.75) | Grad Norm 1.1997(1.7307) | Total Time 14.00(14.00)\n",
      "Iter 1564 | Time 73.2192(74.8487) | Bit/dim 3.9539(3.9651) | Xent 1.1812(1.1999) | Loss 4.5445(4.5650) | Error 0.4203(0.4289) Steps 802(802.73) | Grad Norm 1.1385(1.7129) | Total Time 14.00(14.00)\n",
      "Iter 1565 | Time 75.4675(74.8673) | Bit/dim 3.9606(3.9649) | Xent 1.1817(1.1994) | Loss 4.5514(4.5646) | Error 0.4169(0.4286) Steps 808(802.89) | Grad Norm 0.5979(1.6795) | Total Time 14.00(14.00)\n",
      "Iter 1566 | Time 74.1937(74.8471) | Bit/dim 3.9452(3.9643) | Xent 1.1840(1.1989) | Loss 4.5372(4.5638) | Error 0.4225(0.4284) Steps 802(802.86) | Grad Norm 0.8308(1.6540) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 29.1198, Epoch Time 490.2072(486.4303), Bit/dim 3.9578(best: 3.9582), Xent 1.1487, Loss 4.5321, Error 0.4150(best: 0.4116)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1567 | Time 75.2154(74.8581) | Bit/dim 3.9427(3.9637) | Xent 1.1773(1.1983) | Loss 4.5314(4.5628) | Error 0.4193(0.4281) Steps 808(803.01) | Grad Norm 0.6326(1.6234) | Total Time 14.00(14.00)\n",
      "Iter 1568 | Time 73.7133(74.8238) | Bit/dim 3.9564(3.9635) | Xent 1.1763(1.1976) | Loss 4.5445(4.5623) | Error 0.4239(0.4280) Steps 802(802.98) | Grad Norm 0.7820(1.5981) | Total Time 14.00(14.00)\n",
      "Iter 1569 | Time 76.7618(74.8819) | Bit/dim 3.9485(3.9630) | Xent 1.1693(1.1968) | Loss 4.5332(4.5614) | Error 0.4211(0.4278) Steps 802(802.95) | Grad Norm 0.8490(1.5757) | Total Time 14.00(14.00)\n",
      "Iter 1570 | Time 76.3251(74.9252) | Bit/dim 3.9595(3.9629) | Xent 1.1876(1.1965) | Loss 4.5532(4.5612) | Error 0.4210(0.4276) Steps 802(802.92) | Grad Norm 1.0951(1.5613) | Total Time 14.00(14.00)\n",
      "Iter 1571 | Time 74.6623(74.9173) | Bit/dim 3.9653(3.9630) | Xent 1.1737(1.1958) | Loss 4.5521(4.5609) | Error 0.4209(0.4274) Steps 802(802.90) | Grad Norm 0.9383(1.5426) | Total Time 14.00(14.00)\n",
      "Iter 1572 | Time 71.6350(74.8188) | Bit/dim 3.9638(3.9630) | Xent 1.1993(1.1959) | Loss 4.5634(4.5610) | Error 0.4223(0.4272) Steps 802(802.87) | Grad Norm 0.6233(1.5150) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 28.7544, Epoch Time 492.6203(486.6160), Bit/dim 3.9574(best: 3.9578), Xent 1.1443, Loss 4.5296, Error 0.4128(best: 0.4116)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1573 | Time 75.5513(74.8408) | Bit/dim 3.9591(3.9629) | Xent 1.1708(1.1951) | Loss 4.5445(4.5605) | Error 0.4171(0.4269) Steps 802(802.84) | Grad Norm 0.6638(1.4895) | Total Time 14.00(14.00)\n",
      "Iter 1574 | Time 75.2975(74.8545) | Bit/dim 3.9546(3.9627) | Xent 1.1548(1.1939) | Loss 4.5321(4.5596) | Error 0.4141(0.4265) Steps 802(802.82) | Grad Norm 0.9907(1.4745) | Total Time 14.00(14.00)\n",
      "Iter 1575 | Time 75.3923(74.8707) | Bit/dim 3.9617(3.9626) | Xent 1.1770(1.1934) | Loss 4.5502(4.5593) | Error 0.4250(0.4265) Steps 802(802.79) | Grad Norm 0.6155(1.4487) | Total Time 14.00(14.00)\n",
      "Iter 1576 | Time 76.0258(74.9053) | Bit/dim 3.9576(3.9625) | Xent 1.1955(1.1935) | Loss 4.5553(4.5592) | Error 0.4263(0.4265) Steps 802(802.77) | Grad Norm 0.6598(1.4251) | Total Time 14.00(14.00)\n",
      "Iter 1577 | Time 71.7924(74.8119) | Bit/dim 3.9501(3.9621) | Xent 1.2087(1.1939) | Loss 4.5545(4.5591) | Error 0.4353(0.4268) Steps 802(802.75) | Grad Norm 0.7826(1.4058) | Total Time 14.00(14.00)\n",
      "Iter 1578 | Time 73.3648(74.7685) | Bit/dim 3.9593(3.9620) | Xent 1.1855(1.1937) | Loss 4.5521(4.5589) | Error 0.4264(0.4267) Steps 802(802.72) | Grad Norm 0.7006(1.3846) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 29.4824, Epoch Time 492.6408(486.7967), Bit/dim 3.9574(best: 3.9574), Xent 1.1454, Loss 4.5301, Error 0.4140(best: 0.4116)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1579 | Time 75.0280(74.7763) | Bit/dim 3.9617(3.9620) | Xent 1.1923(1.1937) | Loss 4.5579(4.5588) | Error 0.4213(0.4266) Steps 802(802.70) | Grad Norm 0.7454(1.3654) | Total Time 14.00(14.00)\n",
      "Iter 1580 | Time 74.6051(74.7712) | Bit/dim 3.9471(3.9616) | Xent 1.1719(1.1930) | Loss 4.5331(4.5581) | Error 0.4166(0.4263) Steps 802(802.68) | Grad Norm 0.7978(1.3484) | Total Time 14.00(14.00)\n",
      "Iter 1581 | Time 76.6473(74.8274) | Bit/dim 3.9594(3.9615) | Xent 1.1772(1.1925) | Loss 4.5480(4.5578) | Error 0.4194(0.4261) Steps 802(802.66) | Grad Norm 0.5519(1.3245) | Total Time 14.00(14.00)\n",
      "Iter 1582 | Time 72.9225(74.7703) | Bit/dim 3.9446(3.9610) | Xent 1.1778(1.1921) | Loss 4.5334(4.5570) | Error 0.4147(0.4257) Steps 802(802.64) | Grad Norm 0.6161(1.3033) | Total Time 14.00(14.00)\n",
      "Iter 1583 | Time 72.2393(74.6944) | Bit/dim 3.9597(3.9610) | Xent 1.1816(1.1918) | Loss 4.5505(4.5568) | Error 0.4225(0.4256) Steps 802(802.62) | Grad Norm 0.8579(1.2899) | Total Time 14.00(14.00)\n",
      "Iter 1584 | Time 72.9886(74.6432) | Bit/dim 3.9563(3.9608) | Xent 1.1840(1.1915) | Loss 4.5483(4.5566) | Error 0.4215(0.4255) Steps 802(802.60) | Grad Norm 0.7366(1.2733) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 29.1189, Epoch Time 489.1842(486.8683), Bit/dim 3.9568(best: 3.9574), Xent 1.1446, Loss 4.5291, Error 0.4111(best: 0.4116)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1585 | Time 74.8244(74.6486) | Bit/dim 3.9584(3.9607) | Xent 1.1995(1.1918) | Loss 4.5581(4.5566) | Error 0.4207(0.4254) Steps 802(802.59) | Grad Norm 1.2146(1.2715) | Total Time 14.00(14.00)\n",
      "Iter 1586 | Time 73.2279(74.6060) | Bit/dim 3.9630(3.9608) | Xent 1.1751(1.1913) | Loss 4.5506(4.5564) | Error 0.4164(0.4251) Steps 802(802.57) | Grad Norm 1.0679(1.2654) | Total Time 14.00(14.00)\n",
      "Iter 1587 | Time 73.2167(74.5643) | Bit/dim 3.9547(3.9606) | Xent 1.1967(1.1914) | Loss 4.5530(4.5563) | Error 0.4259(0.4251) Steps 802(802.55) | Grad Norm 0.9048(1.2546) | Total Time 14.00(14.00)\n",
      "Iter 1588 | Time 71.7370(74.4795) | Bit/dim 3.9532(3.9604) | Xent 1.1902(1.1914) | Loss 4.5483(4.5561) | Error 0.4230(0.4251) Steps 802(802.53) | Grad Norm 0.5540(1.2336) | Total Time 14.00(14.00)\n",
      "Iter 1589 | Time 73.1019(74.4382) | Bit/dim 3.9584(3.9603) | Xent 1.1520(1.1902) | Loss 4.5344(4.5554) | Error 0.4116(0.4247) Steps 802(802.52) | Grad Norm 0.7213(1.2182) | Total Time 14.00(14.00)\n",
      "Iter 1590 | Time 73.2330(74.4020) | Bit/dim 3.9472(3.9599) | Xent 1.1827(1.1900) | Loss 4.5385(4.5549) | Error 0.4239(0.4246) Steps 802(802.50) | Grad Norm 1.2578(1.2194) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 29.2465, Epoch Time 484.3543(486.7929), Bit/dim 3.9561(best: 3.9568), Xent 1.1418, Loss 4.5270, Error 0.4115(best: 0.4111)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1591 | Time 73.6916(74.3807) | Bit/dim 3.9526(3.9597) | Xent 1.1870(1.1899) | Loss 4.5461(4.5547) | Error 0.4239(0.4246) Steps 802(802.49) | Grad Norm 0.8575(1.2086) | Total Time 14.00(14.00)\n",
      "Iter 1592 | Time 77.4177(74.4718) | Bit/dim 3.9528(3.9595) | Xent 1.1891(1.1899) | Loss 4.5474(4.5545) | Error 0.4313(0.4248) Steps 802(802.47) | Grad Norm 0.6873(1.1929) | Total Time 14.00(14.00)\n",
      "Iter 1593 | Time 75.3796(74.4991) | Bit/dim 3.9546(3.9594) | Xent 1.1872(1.1898) | Loss 4.5482(4.5543) | Error 0.4243(0.4248) Steps 802(802.46) | Grad Norm 0.5661(1.1741) | Total Time 14.00(14.00)\n",
      "Iter 1594 | Time 75.3892(74.5258) | Bit/dim 3.9701(3.9597) | Xent 1.1976(1.1900) | Loss 4.5689(4.5547) | Error 0.4224(0.4247) Steps 802(802.45) | Grad Norm 0.6696(1.1590) | Total Time 14.00(14.00)\n",
      "Iter 1595 | Time 76.4802(74.5844) | Bit/dim 3.9441(3.9592) | Xent 1.1720(1.1895) | Loss 4.5301(4.5540) | Error 0.4189(0.4245) Steps 802(802.43) | Grad Norm 0.5285(1.1401) | Total Time 14.00(14.00)\n",
      "Iter 1596 | Time 73.9657(74.5658) | Bit/dim 3.9500(3.9589) | Xent 1.1769(1.1891) | Loss 4.5384(4.5535) | Error 0.4237(0.4245) Steps 802(802.42) | Grad Norm 0.9601(1.1347) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 29.3758, Epoch Time 497.5441(487.1154), Bit/dim 3.9559(best: 3.9561), Xent 1.1435, Loss 4.5277, Error 0.4121(best: 0.4111)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1597 | Time 75.0277(74.5797) | Bit/dim 3.9551(3.9588) | Xent 1.1891(1.1891) | Loss 4.5496(4.5534) | Error 0.4229(0.4245) Steps 802(802.41) | Grad Norm 0.6359(1.1197) | Total Time 14.00(14.00)\n",
      "Iter 1598 | Time 74.8641(74.5882) | Bit/dim 3.9478(3.9585) | Xent 1.1908(1.1892) | Loss 4.5432(4.5531) | Error 0.4254(0.4245) Steps 802(802.39) | Grad Norm 0.5057(1.1013) | Total Time 14.00(14.00)\n",
      "Iter 1599 | Time 75.0424(74.6018) | Bit/dim 3.9584(3.9585) | Xent 1.1708(1.1886) | Loss 4.5438(4.5528) | Error 0.4191(0.4243) Steps 802(802.38) | Grad Norm 0.6236(1.0870) | Total Time 14.00(14.00)\n",
      "Iter 1600 | Time 74.0661(74.5858) | Bit/dim 3.9504(3.9583) | Xent 1.1573(1.1877) | Loss 4.5291(4.5521) | Error 0.4117(0.4240) Steps 802(802.37) | Grad Norm 0.5113(1.0697) | Total Time 14.00(14.00)\n",
      "Iter 1601 | Time 73.4273(74.5510) | Bit/dim 3.9626(3.9584) | Xent 1.1903(1.1878) | Loss 4.5577(4.5523) | Error 0.4200(0.4238) Steps 802(802.36) | Grad Norm 0.9727(1.0668) | Total Time 14.00(14.00)\n",
      "Iter 1602 | Time 76.0337(74.5955) | Bit/dim 3.9527(3.9582) | Xent 1.1608(1.1869) | Loss 4.5331(4.5517) | Error 0.4214(0.4238) Steps 808(802.53) | Grad Norm 0.9596(1.0636) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 29.5012, Epoch Time 493.3116(487.3013), Bit/dim 3.9554(best: 3.9559), Xent 1.1397, Loss 4.5253, Error 0.4103(best: 0.4111)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1603 | Time 72.9951(74.5475) | Bit/dim 3.9517(3.9580) | Xent 1.1829(1.1868) | Loss 4.5431(4.5514) | Error 0.4195(0.4236) Steps 802(802.51) | Grad Norm 0.7237(1.0534) | Total Time 14.00(14.00)\n",
      "Iter 1604 | Time 76.5991(74.6090) | Bit/dim 3.9479(3.9577) | Xent 1.1793(1.1866) | Loss 4.5375(4.5510) | Error 0.4179(0.4235) Steps 802(802.50) | Grad Norm 0.6114(1.0401) | Total Time 14.00(14.00)\n",
      "Iter 1605 | Time 74.0649(74.5927) | Bit/dim 3.9568(3.9577) | Xent 1.1871(1.1866) | Loss 4.5504(4.5510) | Error 0.4233(0.4235) Steps 802(802.48) | Grad Norm 1.0754(1.0412) | Total Time 14.00(14.00)\n",
      "Iter 1606 | Time 74.3283(74.5848) | Bit/dim 3.9478(3.9574) | Xent 1.1532(1.1856) | Loss 4.5244(4.5502) | Error 0.4126(0.4231) Steps 802(802.47) | Grad Norm 0.8057(1.0341) | Total Time 14.00(14.00)\n",
      "Iter 1607 | Time 74.1668(74.5722) | Bit/dim 3.9567(3.9574) | Xent 1.1803(1.1855) | Loss 4.5468(4.5501) | Error 0.4215(0.4231) Steps 802(802.45) | Grad Norm 1.4082(1.0453) | Total Time 14.00(14.00)\n",
      "Iter 1608 | Time 75.5626(74.6020) | Bit/dim 3.9640(3.9576) | Xent 1.1861(1.1855) | Loss 4.5571(4.5503) | Error 0.4260(0.4232) Steps 808(802.62) | Grad Norm 0.8726(1.0401) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 29.1981, Epoch Time 492.3349(487.4523), Bit/dim 3.9544(best: 3.9554), Xent 1.1406, Loss 4.5247, Error 0.4101(best: 0.4103)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1609 | Time 73.8014(74.5779) | Bit/dim 3.9663(3.9578) | Xent 1.1745(1.1851) | Loss 4.5536(4.5504) | Error 0.4161(0.4230) Steps 802(802.60) | Grad Norm 1.3047(1.0481) | Total Time 14.00(14.00)\n",
      "Iter 1610 | Time 74.3899(74.5723) | Bit/dim 3.9388(3.9573) | Xent 1.1690(1.1847) | Loss 4.5233(4.5496) | Error 0.4209(0.4229) Steps 802(802.58) | Grad Norm 0.7588(1.0394) | Total Time 14.00(14.00)\n",
      "Iter 1611 | Time 74.8205(74.5797) | Bit/dim 3.9435(3.9568) | Xent 1.1804(1.1845) | Loss 4.5337(4.5491) | Error 0.4204(0.4228) Steps 802(802.57) | Grad Norm 0.8492(1.0337) | Total Time 14.00(14.00)\n",
      "Iter 1612 | Time 75.1204(74.5960) | Bit/dim 3.9524(3.9567) | Xent 1.1612(1.1838) | Loss 4.5330(4.5486) | Error 0.4179(0.4227) Steps 802(802.55) | Grad Norm 0.6311(1.0216) | Total Time 14.00(14.00)\n",
      "Iter 1613 | Time 73.6359(74.5672) | Bit/dim 3.9671(3.9570) | Xent 1.1813(1.1838) | Loss 4.5577(4.5489) | Error 0.4195(0.4226) Steps 802(802.53) | Grad Norm 0.8418(1.0162) | Total Time 14.00(14.00)\n",
      "Iter 1614 | Time 75.4361(74.5932) | Bit/dim 3.9554(3.9570) | Xent 1.1705(1.1834) | Loss 4.5406(4.5487) | Error 0.4164(0.4224) Steps 808(802.70) | Grad Norm 0.6726(1.0059) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 29.3071, Epoch Time 491.9117(487.5861), Bit/dim 3.9542(best: 3.9544), Xent 1.1374, Loss 4.5229, Error 0.4085(best: 0.4101)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1615 | Time 74.3123(74.5848) | Bit/dim 3.9586(3.9570) | Xent 1.1981(1.1838) | Loss 4.5577(4.5489) | Error 0.4324(0.4227) Steps 808(802.86) | Grad Norm 0.6866(0.9963) | Total Time 14.00(14.00)\n",
      "Iter 1616 | Time 74.1789(74.5726) | Bit/dim 3.9539(3.9569) | Xent 1.1580(1.1830) | Loss 4.5329(4.5484) | Error 0.4125(0.4224) Steps 802(802.83) | Grad Norm 0.5777(0.9838) | Total Time 14.00(14.00)\n",
      "Iter 1617 | Time 73.7507(74.5480) | Bit/dim 3.9499(3.9567) | Xent 1.1610(1.1824) | Loss 4.5304(4.5479) | Error 0.4149(0.4222) Steps 808(802.99) | Grad Norm 0.8361(0.9793) | Total Time 14.00(14.00)\n",
      "Iter 1618 | Time 74.5112(74.5469) | Bit/dim 3.9491(3.9565) | Xent 1.1751(1.1821) | Loss 4.5366(4.5476) | Error 0.4240(0.4222) Steps 802(802.96) | Grad Norm 1.0417(0.9812) | Total Time 14.00(14.00)\n",
      "Iter 1619 | Time 75.0498(74.5619) | Bit/dim 3.9564(3.9565) | Xent 1.1674(1.1817) | Loss 4.5401(4.5473) | Error 0.4187(0.4221) Steps 802(802.93) | Grad Norm 0.7743(0.9750) | Total Time 14.00(14.00)\n",
      "Iter 1620 | Time 75.0906(74.5778) | Bit/dim 3.9525(3.9564) | Xent 1.1887(1.1819) | Loss 4.5469(4.5473) | Error 0.4265(0.4222) Steps 802(802.90) | Grad Norm 0.6649(0.9657) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 29.2361, Epoch Time 491.8512(487.7141), Bit/dim 3.9549(best: 3.9542), Xent 1.1383, Loss 4.5240, Error 0.4082(best: 0.4085)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1621 | Time 75.3519(74.6010) | Bit/dim 3.9610(3.9565) | Xent 1.1785(1.1818) | Loss 4.5502(4.5474) | Error 0.4239(0.4223) Steps 802(802.87) | Grad Norm 0.6839(0.9573) | Total Time 14.00(14.00)\n",
      "Iter 1622 | Time 72.7475(74.5454) | Bit/dim 3.9466(3.9562) | Xent 1.1790(1.1817) | Loss 4.5361(4.5471) | Error 0.4187(0.4222) Steps 808(803.03) | Grad Norm 0.7749(0.9518) | Total Time 14.00(14.00)\n",
      "Iter 1623 | Time 74.5974(74.5470) | Bit/dim 3.9530(3.9561) | Xent 1.1622(1.1811) | Loss 4.5341(4.5467) | Error 0.4137(0.4219) Steps 808(803.18) | Grad Norm 0.6269(0.9420) | Total Time 14.00(14.00)\n",
      "Iter 1624 | Time 73.3884(74.5122) | Bit/dim 3.9520(3.9560) | Xent 1.1629(1.1806) | Loss 4.5335(4.5463) | Error 0.4177(0.4218) Steps 808(803.32) | Grad Norm 0.6360(0.9329) | Total Time 14.00(14.00)\n",
      "Iter 1625 | Time 74.8950(74.5237) | Bit/dim 3.9565(3.9560) | Xent 1.1918(1.1809) | Loss 4.5524(4.5465) | Error 0.4209(0.4218) Steps 808(803.46) | Grad Norm 1.0193(0.9354) | Total Time 14.00(14.00)\n",
      "Iter 1626 | Time 76.2547(74.5756) | Bit/dim 3.9475(3.9558) | Xent 1.1600(1.1803) | Loss 4.5275(4.5459) | Error 0.4090(0.4214) Steps 808(803.60) | Grad Norm 0.7311(0.9293) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 29.4398, Epoch Time 492.1391(487.8468), Bit/dim 3.9539(best: 3.9542), Xent 1.1355, Loss 4.5216, Error 0.4062(best: 0.4082)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1627 | Time 73.9171(74.5559) | Bit/dim 3.9603(3.9559) | Xent 1.1747(1.1801) | Loss 4.5476(4.5460) | Error 0.4183(0.4213) Steps 802(803.55) | Grad Norm 0.6154(0.9199) | Total Time 14.00(14.00)\n",
      "Iter 1628 | Time 71.4696(74.4633) | Bit/dim 3.9571(3.9559) | Xent 1.1863(1.1803) | Loss 4.5503(4.5461) | Error 0.4289(0.4215) Steps 808(803.68) | Grad Norm 1.0210(0.9229) | Total Time 14.00(14.00)\n",
      "Iter 1629 | Time 74.8048(74.4735) | Bit/dim 3.9448(3.9556) | Xent 1.1645(1.1799) | Loss 4.5270(4.5455) | Error 0.4157(0.4214) Steps 808(803.81) | Grad Norm 0.7364(0.9173) | Total Time 14.00(14.00)\n",
      "Iter 1630 | Time 75.0790(74.4917) | Bit/dim 3.9589(3.9557) | Xent 1.1819(1.1799) | Loss 4.5499(4.5456) | Error 0.4187(0.4213) Steps 802(803.76) | Grad Norm 0.7420(0.9121) | Total Time 14.00(14.00)\n",
      "Iter 1631 | Time 71.5716(74.4041) | Bit/dim 3.9515(3.9556) | Xent 1.1673(1.1795) | Loss 4.5351(4.5453) | Error 0.4129(0.4210) Steps 802(803.70) | Grad Norm 0.9119(0.9121) | Total Time 14.00(14.00)\n",
      "Iter 1632 | Time 74.9432(74.4203) | Bit/dim 3.9503(3.9554) | Xent 1.1778(1.1795) | Loss 4.5392(4.5451) | Error 0.4261(0.4212) Steps 808(803.83) | Grad Norm 0.5870(0.9023) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 29.3966, Epoch Time 486.7242(487.8131), Bit/dim 3.9535(best: 3.9539), Xent 1.1361, Loss 4.5215, Error 0.4084(best: 0.4062)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1633 | Time 73.9312(74.4056) | Bit/dim 3.9570(3.9555) | Xent 1.1749(1.1793) | Loss 4.5445(4.5451) | Error 0.4177(0.4211) Steps 808(803.96) | Grad Norm 0.7777(0.8986) | Total Time 14.00(14.00)\n",
      "Iter 1634 | Time 74.4946(74.4083) | Bit/dim 3.9541(3.9554) | Xent 1.1621(1.1788) | Loss 4.5351(4.5448) | Error 0.4183(0.4210) Steps 802(803.90) | Grad Norm 0.5387(0.8878) | Total Time 14.00(14.00)\n",
      "Iter 1635 | Time 73.8264(74.3908) | Bit/dim 3.9561(3.9554) | Xent 1.1764(1.1788) | Loss 4.5443(4.5448) | Error 0.4203(0.4210) Steps 808(804.02) | Grad Norm 0.9846(0.8907) | Total Time 14.00(14.00)\n",
      "Iter 1636 | Time 74.4588(74.3929) | Bit/dim 3.9564(3.9555) | Xent 1.1601(1.1782) | Loss 4.5365(4.5446) | Error 0.4130(0.4207) Steps 808(804.14) | Grad Norm 0.8247(0.8887) | Total Time 14.00(14.00)\n",
      "Iter 1637 | Time 74.7631(74.4040) | Bit/dim 3.9476(3.9552) | Xent 1.1425(1.1771) | Loss 4.5189(4.5438) | Error 0.4044(0.4202) Steps 808(804.26) | Grad Norm 0.6481(0.8815) | Total Time 14.00(14.00)\n",
      "Iter 1638 | Time 74.8850(74.4184) | Bit/dim 3.9432(3.9549) | Xent 1.1732(1.1770) | Loss 4.5298(4.5434) | Error 0.4181(0.4202) Steps 802(804.19) | Grad Norm 0.5903(0.8728) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 29.1765, Epoch Time 490.9752(487.9080), Bit/dim 3.9534(best: 3.9535), Xent 1.1349, Loss 4.5209, Error 0.4090(best: 0.4062)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1639 | Time 73.9822(74.4053) | Bit/dim 3.9414(3.9545) | Xent 1.1648(1.1766) | Loss 4.5238(4.5428) | Error 0.4231(0.4203) Steps 802(804.12) | Grad Norm 0.9226(0.8742) | Total Time 14.00(14.00)\n",
      "Iter 1640 | Time 72.3628(74.3440) | Bit/dim 3.9469(3.9542) | Xent 1.1821(1.1768) | Loss 4.5380(4.5426) | Error 0.4181(0.4202) Steps 802(804.06) | Grad Norm 0.7669(0.8710) | Total Time 14.00(14.00)\n",
      "Iter 1641 | Time 74.7059(74.3549) | Bit/dim 3.9452(3.9540) | Xent 1.1711(1.1766) | Loss 4.5308(4.5423) | Error 0.4267(0.4204) Steps 802(804.00) | Grad Norm 0.6180(0.8634) | Total Time 14.00(14.00)\n",
      "Iter 1642 | Time 76.3461(74.4146) | Bit/dim 3.9618(3.9542) | Xent 1.1812(1.1768) | Loss 4.5524(4.5426) | Error 0.4183(0.4203) Steps 802(803.94) | Grad Norm 0.6702(0.8576) | Total Time 14.00(14.00)\n",
      "Iter 1643 | Time 73.8425(74.3975) | Bit/dim 3.9530(3.9542) | Xent 1.1478(1.1759) | Loss 4.5269(4.5421) | Error 0.4107(0.4200) Steps 808(804.06) | Grad Norm 0.7455(0.8543) | Total Time 14.00(14.00)\n",
      "Iter 1644 | Time 71.8844(74.3221) | Bit/dim 3.9572(3.9543) | Xent 1.1510(1.1752) | Loss 4.5328(4.5418) | Error 0.4167(0.4199) Steps 808(804.18) | Grad Norm 1.3570(0.8694) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 29.0506, Epoch Time 487.7851(487.9043), Bit/dim 3.9538(best: 3.9534), Xent 1.1340, Loss 4.5208, Error 0.4094(best: 0.4062)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1645 | Time 74.2298(74.3193) | Bit/dim 3.9539(3.9542) | Xent 1.1621(1.1748) | Loss 4.5350(4.5416) | Error 0.4183(0.4199) Steps 802(804.11) | Grad Norm 1.0974(0.8762) | Total Time 14.00(14.00)\n",
      "Iter 1646 | Time 74.3201(74.3193) | Bit/dim 3.9483(3.9541) | Xent 1.1841(1.1750) | Loss 4.5403(4.5416) | Error 0.4230(0.4200) Steps 802(804.05) | Grad Norm 0.6738(0.8701) | Total Time 14.00(14.00)\n",
      "Iter 1647 | Time 77.1517(74.4043) | Bit/dim 3.9506(3.9540) | Xent 1.1642(1.1747) | Loss 4.5328(4.5413) | Error 0.4187(0.4200) Steps 802(803.99) | Grad Norm 0.9640(0.8729) | Total Time 14.00(14.00)\n",
      "Iter 1648 | Time 74.9159(74.4197) | Bit/dim 3.9521(3.9539) | Xent 1.1669(1.1745) | Loss 4.5355(4.5411) | Error 0.4145(0.4198) Steps 802(803.93) | Grad Norm 0.5505(0.8633) | Total Time 14.00(14.00)\n",
      "Iter 1649 | Time 74.6392(74.4262) | Bit/dim 3.9530(3.9539) | Xent 1.1705(1.1744) | Loss 4.5383(4.5411) | Error 0.4091(0.4195) Steps 808(804.05) | Grad Norm 0.8126(0.8617) | Total Time 14.00(14.00)\n",
      "Iter 1650 | Time 74.1461(74.4178) | Bit/dim 3.9557(3.9539) | Xent 1.1715(1.1743) | Loss 4.5414(4.5411) | Error 0.4166(0.4194) Steps 802(803.99) | Grad Norm 0.9626(0.8648) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 29.2491, Epoch Time 494.0753(488.0895), Bit/dim 3.9538(best: 3.9534), Xent 1.1331, Loss 4.5204, Error 0.4088(best: 0.4062)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1651 | Time 75.6226(74.4540) | Bit/dim 3.9488(3.9538) | Xent 1.1585(1.1738) | Loss 4.5280(4.5407) | Error 0.4087(0.4191) Steps 808(804.11) | Grad Norm 0.7839(0.8623) | Total Time 14.00(14.00)\n",
      "Iter 1652 | Time 74.9737(74.4696) | Bit/dim 3.9437(3.9535) | Xent 1.1607(1.1734) | Loss 4.5241(4.5402) | Error 0.4114(0.4188) Steps 802(804.05) | Grad Norm 0.6676(0.8565) | Total Time 14.00(14.00)\n",
      "Iter 1653 | Time 74.9585(74.4842) | Bit/dim 3.9638(3.9538) | Xent 1.1661(1.1732) | Loss 4.5468(4.5404) | Error 0.4133(0.4187) Steps 802(803.99) | Grad Norm 0.7321(0.8528) | Total Time 14.00(14.00)\n",
      "Iter 1654 | Time 72.8336(74.4347) | Bit/dim 3.9488(3.9536) | Xent 1.1712(1.1731) | Loss 4.5344(4.5402) | Error 0.4210(0.4187) Steps 802(803.93) | Grad Norm 0.5730(0.8444) | Total Time 14.00(14.00)\n",
      "Iter 1655 | Time 71.4987(74.3466) | Bit/dim 3.9413(3.9533) | Xent 1.1465(1.1723) | Loss 4.5146(4.5394) | Error 0.4140(0.4186) Steps 808(804.05) | Grad Norm 0.7796(0.8424) | Total Time 14.00(14.00)\n",
      "Iter 1656 | Time 76.3537(74.4069) | Bit/dim 3.9666(3.9537) | Xent 1.1811(1.1726) | Loss 4.5571(4.5400) | Error 0.4240(0.4188) Steps 808(804.17) | Grad Norm 0.7010(0.8382) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 28.9741, Epoch Time 490.7385(488.1689), Bit/dim 3.9521(best: 3.9534), Xent 1.1324, Loss 4.5183, Error 0.4080(best: 0.4062)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1657 | Time 72.1455(74.3390) | Bit/dim 3.9554(3.9537) | Xent 1.1723(1.1726) | Loss 4.5416(4.5400) | Error 0.4266(0.4190) Steps 802(804.10) | Grad Norm 0.6424(0.8323) | Total Time 14.00(14.00)\n",
      "Iter 1658 | Time 73.3339(74.3089) | Bit/dim 3.9588(3.9539) | Xent 1.1594(1.1722) | Loss 4.5385(4.5400) | Error 0.4167(0.4189) Steps 808(804.22) | Grad Norm 0.5959(0.8252) | Total Time 14.00(14.00)\n",
      "Iter 1659 | Time 74.1340(74.3036) | Bit/dim 3.9397(3.9534) | Xent 1.1645(1.1720) | Loss 4.5220(4.5394) | Error 0.4100(0.4187) Steps 808(804.33) | Grad Norm 0.5028(0.8156) | Total Time 14.00(14.00)\n",
      "Iter 1660 | Time 72.6119(74.2529) | Bit/dim 3.9514(3.9534) | Xent 1.1596(1.1716) | Loss 4.5312(4.5392) | Error 0.4113(0.4184) Steps 808(804.44) | Grad Norm 0.6099(0.8094) | Total Time 14.00(14.00)\n",
      "Iter 1661 | Time 71.9858(74.1848) | Bit/dim 3.9561(3.9535) | Xent 1.1591(1.1712) | Loss 4.5357(4.5391) | Error 0.4146(0.4183) Steps 802(804.37) | Grad Norm 0.6489(0.8046) | Total Time 14.00(14.00)\n",
      "Iter 1662 | Time 77.1099(74.2726) | Bit/dim 3.9420(3.9531) | Xent 1.1691(1.1712) | Loss 4.5266(4.5387) | Error 0.4145(0.4182) Steps 802(804.30) | Grad Norm 0.6024(0.7985) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 29.0227, Epoch Time 486.0953(488.1067), Bit/dim 3.9511(best: 3.9521), Xent 1.1319, Loss 4.5171, Error 0.4115(best: 0.4062)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1663 | Time 74.9955(74.2943) | Bit/dim 3.9563(3.9532) | Xent 1.1548(1.1707) | Loss 4.5337(4.5386) | Error 0.4104(0.4180) Steps 808(804.41) | Grad Norm 0.7013(0.7956) | Total Time 14.00(14.00)\n",
      "Iter 1664 | Time 71.4812(74.2099) | Bit/dim 3.9566(3.9533) | Xent 1.1813(1.1710) | Loss 4.5473(4.5388) | Error 0.4225(0.4181) Steps 802(804.34) | Grad Norm 0.5906(0.7894) | Total Time 14.00(14.00)\n",
      "Iter 1665 | Time 74.8991(74.2306) | Bit/dim 3.9382(3.9529) | Xent 1.1664(1.1708) | Loss 4.5214(4.5383) | Error 0.4134(0.4180) Steps 802(804.27) | Grad Norm 0.6326(0.7847) | Total Time 14.00(14.00)\n",
      "Iter 1666 | Time 73.6554(74.2133) | Bit/dim 3.9447(3.9526) | Xent 1.1634(1.1706) | Loss 4.5264(4.5379) | Error 0.4154(0.4179) Steps 808(804.38) | Grad Norm 0.8286(0.7861) | Total Time 14.00(14.00)\n",
      "Iter 1667 | Time 75.1447(74.2413) | Bit/dim 3.9591(3.9528) | Xent 1.1608(1.1703) | Loss 4.5395(4.5380) | Error 0.4213(0.4180) Steps 802(804.31) | Grad Norm 0.6646(0.7824) | Total Time 14.00(14.00)\n",
      "Iter 1668 | Time 74.7420(74.2563) | Bit/dim 3.9465(3.9526) | Xent 1.1529(1.1698) | Loss 4.5229(4.5375) | Error 0.4094(0.4177) Steps 802(804.24) | Grad Norm 1.0064(0.7891) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 29.3788, Epoch Time 489.6687(488.1536), Bit/dim 3.9518(best: 3.9511), Xent 1.1298, Loss 4.5167, Error 0.4047(best: 0.4062)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1669 | Time 72.3986(74.2006) | Bit/dim 3.9579(3.9528) | Xent 1.1815(1.1702) | Loss 4.5486(4.5379) | Error 0.4229(0.4179) Steps 802(804.17) | Grad Norm 0.6103(0.7838) | Total Time 14.00(14.00)\n",
      "Iter 1670 | Time 74.7634(74.2174) | Bit/dim 3.9501(3.9527) | Xent 1.1540(1.1697) | Loss 4.5272(4.5375) | Error 0.4134(0.4177) Steps 802(804.11) | Grad Norm 0.7283(0.7821) | Total Time 14.00(14.00)\n",
      "Iter 1671 | Time 76.6683(74.2910) | Bit/dim 3.9527(3.9527) | Xent 1.1596(1.1694) | Loss 4.5325(4.5374) | Error 0.4161(0.4177) Steps 802(804.04) | Grad Norm 0.8309(0.7836) | Total Time 14.00(14.00)\n",
      "Iter 1672 | Time 74.0729(74.2844) | Bit/dim 3.9420(3.9524) | Xent 1.1548(1.1689) | Loss 4.5194(4.5369) | Error 0.4069(0.4174) Steps 802(803.98) | Grad Norm 0.8492(0.7855) | Total Time 14.00(14.00)\n",
      "Iter 1673 | Time 77.2978(74.3748) | Bit/dim 3.9494(3.9523) | Xent 1.1571(1.1686) | Loss 4.5279(4.5366) | Error 0.4086(0.4171) Steps 808(804.10) | Grad Norm 1.0777(0.7943) | Total Time 14.00(14.00)\n",
      "Iter 1674 | Time 75.3851(74.4051) | Bit/dim 3.9543(3.9524) | Xent 1.1706(1.1686) | Loss 4.5396(4.5367) | Error 0.4191(0.4172) Steps 808(804.22) | Grad Norm 0.7149(0.7919) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 29.1445, Epoch Time 495.1460(488.3633), Bit/dim 3.9514(best: 3.9511), Xent 1.1308, Loss 4.5168, Error 0.4096(best: 0.4047)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1675 | Time 75.1079(74.4262) | Bit/dim 3.9540(3.9524) | Xent 1.1803(1.1690) | Loss 4.5442(4.5369) | Error 0.4131(0.4171) Steps 808(804.33) | Grad Norm 0.5595(0.7849) | Total Time 14.00(14.00)\n",
      "Iter 1676 | Time 71.7330(74.3454) | Bit/dim 3.9536(3.9524) | Xent 1.1389(1.1681) | Loss 4.5230(4.5365) | Error 0.4034(0.4166) Steps 802(804.26) | Grad Norm 0.9316(0.7893) | Total Time 14.00(14.00)\n",
      "Iter 1677 | Time 74.7203(74.3567) | Bit/dim 3.9386(3.9520) | Xent 1.1549(1.1677) | Loss 4.5160(4.5359) | Error 0.4086(0.4164) Steps 802(804.19) | Grad Norm 0.9105(0.7930) | Total Time 14.00(14.00)\n",
      "Iter 1678 | Time 73.7564(74.3387) | Bit/dim 3.9566(3.9522) | Xent 1.1571(1.1674) | Loss 4.5352(4.5359) | Error 0.4079(0.4161) Steps 808(804.31) | Grad Norm 0.8390(0.7944) | Total Time 14.00(14.00)\n",
      "Iter 1679 | Time 74.0408(74.3297) | Bit/dim 3.9537(3.9522) | Xent 1.1574(1.1671) | Loss 4.5323(4.5357) | Error 0.4147(0.4161) Steps 808(804.42) | Grad Norm 0.6045(0.7887) | Total Time 14.00(14.00)\n",
      "Iter 1680 | Time 75.0371(74.3509) | Bit/dim 3.9445(3.9520) | Xent 1.1521(1.1666) | Loss 4.5206(4.5353) | Error 0.4180(0.4162) Steps 802(804.35) | Grad Norm 0.8863(0.7916) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 28.9248, Epoch Time 489.0431(488.3837), Bit/dim 3.9511(best: 3.9511), Xent 1.1279, Loss 4.5151, Error 0.4075(best: 0.4047)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1681 | Time 74.8895(74.3671) | Bit/dim 3.9565(3.9521) | Xent 1.1454(1.1660) | Loss 4.5292(4.5351) | Error 0.4019(0.4157) Steps 808(804.46) | Grad Norm 0.6887(0.7885) | Total Time 14.00(14.00)\n",
      "Iter 1682 | Time 75.6883(74.4067) | Bit/dim 3.9480(3.9520) | Xent 1.1578(1.1657) | Loss 4.5269(4.5349) | Error 0.4097(0.4156) Steps 802(804.38) | Grad Norm 1.3945(0.8067) | Total Time 14.00(14.00)\n",
      "Iter 1683 | Time 77.1648(74.4895) | Bit/dim 3.9388(3.9516) | Xent 1.1584(1.1655) | Loss 4.5180(4.5344) | Error 0.4205(0.4157) Steps 802(804.31) | Grad Norm 0.7959(0.8064) | Total Time 14.00(14.00)\n",
      "Iter 1684 | Time 74.3433(74.4851) | Bit/dim 3.9533(3.9516) | Xent 1.1634(1.1655) | Loss 4.5350(4.5344) | Error 0.4204(0.4158) Steps 802(804.24) | Grad Norm 1.0675(0.8142) | Total Time 14.00(14.00)\n",
      "Iter 1685 | Time 75.0668(74.5025) | Bit/dim 3.9507(3.9516) | Xent 1.1571(1.1652) | Loss 4.5293(4.5342) | Error 0.4101(0.4157) Steps 802(804.17) | Grad Norm 0.7624(0.8126) | Total Time 14.00(14.00)\n",
      "Iter 1686 | Time 73.7542(74.4801) | Bit/dim 3.9511(3.9516) | Xent 1.1654(1.1652) | Loss 4.5338(4.5342) | Error 0.4169(0.4157) Steps 802(804.11) | Grad Norm 1.1783(0.8236) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 29.2580, Epoch Time 495.5274(488.5980), Bit/dim 3.9497(best: 3.9511), Xent 1.1291, Loss 4.5143, Error 0.4077(best: 0.4047)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1687 | Time 73.9735(74.4649) | Bit/dim 3.9458(3.9514) | Xent 1.1443(1.1646) | Loss 4.5179(4.5337) | Error 0.4114(0.4156) Steps 808(804.23) | Grad Norm 0.5838(0.8164) | Total Time 14.00(14.00)\n",
      "Iter 1688 | Time 73.8350(74.4460) | Bit/dim 3.9605(3.9517) | Xent 1.1616(1.1645) | Loss 4.5413(4.5339) | Error 0.4216(0.4158) Steps 808(804.34) | Grad Norm 0.6828(0.8124) | Total Time 14.00(14.00)\n",
      "Iter 1689 | Time 73.1498(74.4071) | Bit/dim 3.9538(3.9518) | Xent 1.1512(1.1641) | Loss 4.5294(4.5338) | Error 0.4179(0.4158) Steps 808(804.45) | Grad Norm 0.6816(0.8085) | Total Time 14.00(14.00)\n",
      "Iter 1690 | Time 75.1230(74.4286) | Bit/dim 3.9494(3.9517) | Xent 1.1623(1.1640) | Loss 4.5305(4.5337) | Error 0.4199(0.4159) Steps 802(804.38) | Grad Norm 0.7371(0.8063) | Total Time 14.00(14.00)\n",
      "Iter 1691 | Time 73.5613(74.4026) | Bit/dim 3.9407(3.9514) | Xent 1.1683(1.1642) | Loss 4.5249(4.5334) | Error 0.4219(0.4161) Steps 802(804.30) | Grad Norm 1.0833(0.8147) | Total Time 14.00(14.00)\n",
      "Iter 1692 | Time 74.9361(74.4186) | Bit/dim 3.9498(3.9513) | Xent 1.2020(1.1653) | Loss 4.5508(4.5340) | Error 0.4259(0.4164) Steps 808(804.42) | Grad Norm 1.2040(0.8263) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 29.5174, Epoch Time 489.5396(488.6263), Bit/dim 3.9505(best: 3.9497), Xent 1.1260, Loss 4.5135, Error 0.4040(best: 0.4047)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1693 | Time 73.8290(74.4009) | Bit/dim 3.9536(3.9514) | Xent 1.1714(1.1655) | Loss 4.5393(4.5341) | Error 0.4156(0.4164) Steps 802(804.34) | Grad Norm 0.5533(0.8181) | Total Time 14.00(14.00)\n",
      "Iter 1694 | Time 74.8351(74.4139) | Bit/dim 3.9488(3.9513) | Xent 1.1486(1.1650) | Loss 4.5231(4.5338) | Error 0.4109(0.4162) Steps 808(804.45) | Grad Norm 0.9877(0.8232) | Total Time 14.00(14.00)\n",
      "Iter 1695 | Time 74.6845(74.4220) | Bit/dim 3.9494(3.9512) | Xent 1.1795(1.1654) | Loss 4.5391(4.5340) | Error 0.4230(0.4164) Steps 802(804.38) | Grad Norm 1.9747(0.8578) | Total Time 14.00(14.00)\n",
      "Iter 1696 | Time 74.7242(74.4311) | Bit/dim 3.9518(3.9513) | Xent 1.1519(1.1650) | Loss 4.5278(4.5338) | Error 0.4058(0.4161) Steps 802(804.31) | Grad Norm 0.9472(0.8605) | Total Time 14.00(14.00)\n",
      "Iter 1697 | Time 72.5891(74.3758) | Bit/dim 3.9534(3.9513) | Xent 1.1568(1.1648) | Loss 4.5318(4.5337) | Error 0.4131(0.4160) Steps 802(804.24) | Grad Norm 1.0135(0.8650) | Total Time 14.00(14.00)\n",
      "Iter 1698 | Time 77.9168(74.4821) | Bit/dim 3.9407(3.9510) | Xent 1.1704(1.1649) | Loss 4.5259(4.5335) | Error 0.4197(0.4161) Steps 802(804.17) | Grad Norm 0.9128(0.8665) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 28.9774, Epoch Time 493.0382(488.7587), Bit/dim 3.9507(best: 3.9497), Xent 1.1260, Loss 4.5137, Error 0.4029(best: 0.4040)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1699 | Time 76.2991(74.5366) | Bit/dim 3.9565(3.9512) | Xent 1.1725(1.1652) | Loss 4.5427(4.5338) | Error 0.4233(0.4163) Steps 802(804.11) | Grad Norm 0.9955(0.8704) | Total Time 14.00(14.00)\n",
      "Iter 1700 | Time 74.9440(74.5488) | Bit/dim 3.9515(3.9512) | Xent 1.1559(1.1649) | Loss 4.5295(4.5336) | Error 0.4084(0.4161) Steps 808(804.22) | Grad Norm 1.0002(0.8742) | Total Time 14.00(14.00)\n",
      "Iter 1701 | Time 75.6898(74.5830) | Bit/dim 3.9519(3.9512) | Xent 1.1424(1.1642) | Loss 4.5231(4.5333) | Error 0.4089(0.4159) Steps 808(804.34) | Grad Norm 1.3169(0.8875) | Total Time 14.00(14.00)\n",
      "Iter 1702 | Time 76.5067(74.6407) | Bit/dim 3.9481(3.9511) | Xent 1.1746(1.1645) | Loss 4.5354(4.5334) | Error 0.4177(0.4159) Steps 820(804.81) | Grad Norm 0.8294(0.8858) | Total Time 14.00(14.00)\n",
      "Iter 1703 | Time 76.4036(74.6936) | Bit/dim 3.9480(3.9510) | Xent 1.1782(1.1649) | Loss 4.5371(4.5335) | Error 0.4260(0.4162) Steps 802(804.72) | Grad Norm 1.0808(0.8916) | Total Time 14.00(14.00)\n",
      "Iter 1704 | Time 73.5224(74.6585) | Bit/dim 3.9447(3.9508) | Xent 1.1594(1.1648) | Loss 4.5244(4.5332) | Error 0.4125(0.4161) Steps 808(804.82) | Grad Norm 1.2789(0.9033) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 29.5445, Epoch Time 498.3544(489.0465), Bit/dim 3.9502(best: 3.9497), Xent 1.1280, Loss 4.5142, Error 0.4078(best: 0.4029)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1705 | Time 75.2851(74.6773) | Bit/dim 3.9491(3.9508) | Xent 1.1640(1.1647) | Loss 4.5311(4.5332) | Error 0.4097(0.4159) Steps 802(804.74) | Grad Norm 1.3821(0.9176) | Total Time 14.00(14.00)\n",
      "Iter 1706 | Time 73.9143(74.6544) | Bit/dim 3.9510(3.9508) | Xent 1.1598(1.1646) | Loss 4.5309(4.5331) | Error 0.4126(0.4158) Steps 802(804.65) | Grad Norm 1.1199(0.9237) | Total Time 14.00(14.00)\n",
      "Iter 1707 | Time 75.7368(74.6869) | Bit/dim 3.9413(3.9505) | Xent 1.1499(1.1642) | Loss 4.5162(4.5326) | Error 0.4096(0.4157) Steps 808(804.75) | Grad Norm 0.6783(0.9163) | Total Time 14.00(14.00)\n",
      "Iter 1708 | Time 72.7047(74.6274) | Bit/dim 3.9523(3.9506) | Xent 1.1713(1.1644) | Loss 4.5380(4.5327) | Error 0.4159(0.4157) Steps 808(804.85) | Grad Norm 0.6624(0.9087) | Total Time 14.00(14.00)\n",
      "Iter 1709 | Time 75.3970(74.6505) | Bit/dim 3.9540(3.9507) | Xent 1.1715(1.1646) | Loss 4.5398(4.5330) | Error 0.4189(0.4158) Steps 808(804.95) | Grad Norm 1.0378(0.9126) | Total Time 14.00(14.00)\n",
      "Iter 1710 | Time 72.2275(74.5778) | Bit/dim 3.9402(3.9503) | Xent 1.1634(1.1645) | Loss 4.5219(4.5326) | Error 0.4137(0.4157) Steps 808(805.04) | Grad Norm 0.7199(0.9068) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 29.4133, Epoch Time 489.9464(489.0735), Bit/dim 3.9497(best: 3.9497), Xent 1.1232, Loss 4.5113, Error 0.4026(best: 0.4029)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1711 | Time 72.7555(74.5231) | Bit/dim 3.9420(3.9501) | Xent 1.1652(1.1646) | Loss 4.5247(4.5324) | Error 0.4139(0.4156) Steps 802(804.95) | Grad Norm 1.2969(0.9185) | Total Time 14.00(14.00)\n",
      "Iter 1712 | Time 74.5334(74.5234) | Bit/dim 3.9441(3.9499) | Xent 1.1681(1.1647) | Loss 4.5281(4.5323) | Error 0.4159(0.4156) Steps 808(805.04) | Grad Norm 0.6654(0.9109) | Total Time 14.00(14.00)\n",
      "Iter 1713 | Time 74.2855(74.5163) | Bit/dim 3.9548(3.9501) | Xent 1.1631(1.1646) | Loss 4.5364(4.5324) | Error 0.4143(0.4156) Steps 808(805.13) | Grad Norm 0.9146(0.9110) | Total Time 14.00(14.00)\n",
      "Iter 1714 | Time 72.9485(74.4693) | Bit/dim 3.9528(3.9501) | Xent 1.1569(1.1644) | Loss 4.5312(4.5323) | Error 0.4153(0.4156) Steps 808(805.21) | Grad Norm 1.1065(0.9169) | Total Time 14.00(14.00)\n",
      "Iter 1715 | Time 74.0236(74.4559) | Bit/dim 3.9482(3.9501) | Xent 1.1608(1.1643) | Loss 4.5286(4.5322) | Error 0.4149(0.4156) Steps 802(805.12) | Grad Norm 0.8219(0.9140) | Total Time 14.00(14.00)\n",
      "Iter 1716 | Time 76.1946(74.5081) | Bit/dim 3.9486(3.9500) | Xent 1.1584(1.1641) | Loss 4.5278(4.5321) | Error 0.4129(0.4155) Steps 808(805.20) | Grad Norm 0.9831(0.9161) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 29.2069, Epoch Time 489.6865(489.0919), Bit/dim 3.9504(best: 3.9497), Xent 1.1218, Loss 4.5113, Error 0.4016(best: 0.4026)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1717 | Time 72.7508(74.4553) | Bit/dim 3.9566(3.9502) | Xent 1.1430(1.1635) | Loss 4.5281(4.5320) | Error 0.4052(0.4152) Steps 802(805.11) | Grad Norm 0.8006(0.9126) | Total Time 14.00(14.00)\n",
      "Iter 1718 | Time 74.4954(74.4565) | Bit/dim 3.9518(3.9503) | Xent 1.1642(1.1635) | Loss 4.5338(4.5320) | Error 0.4131(0.4151) Steps 802(805.01) | Grad Norm 1.4688(0.9293) | Total Time 14.00(14.00)\n",
      "Iter 1719 | Time 73.4651(74.4268) | Bit/dim 3.9420(3.9500) | Xent 1.1449(1.1629) | Loss 4.5144(4.5315) | Error 0.4100(0.4150) Steps 802(804.92) | Grad Norm 1.2320(0.9384) | Total Time 14.00(14.00)\n",
      "Iter 1720 | Time 72.8141(74.3784) | Bit/dim 3.9432(3.9498) | Xent 1.1713(1.1632) | Loss 4.5289(4.5314) | Error 0.4180(0.4151) Steps 802(804.84) | Grad Norm 0.6082(0.9285) | Total Time 14.00(14.00)\n",
      "Iter 1721 | Time 72.6497(74.3266) | Bit/dim 3.9503(3.9498) | Xent 1.1643(1.1632) | Loss 4.5324(4.5315) | Error 0.4164(0.4151) Steps 808(804.93) | Grad Norm 1.1425(0.9349) | Total Time 14.00(14.00)\n",
      "Iter 1722 | Time 75.7189(74.3683) | Bit/dim 3.9426(3.9496) | Xent 1.1484(1.1628) | Loss 4.5168(4.5310) | Error 0.4051(0.4148) Steps 808(805.02) | Grad Norm 0.9756(0.9361) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 29.6100, Epoch Time 487.2114(489.0355), Bit/dim 3.9493(best: 3.9497), Xent 1.1233, Loss 4.5109, Error 0.4039(best: 0.4016)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1723 | Time 73.8644(74.3532) | Bit/dim 3.9456(3.9495) | Xent 1.1706(1.1630) | Loss 4.5309(4.5310) | Error 0.4116(0.4147) Steps 802(804.93) | Grad Norm 1.4032(0.9501) | Total Time 14.00(14.00)\n",
      "Iter 1724 | Time 74.5906(74.3603) | Bit/dim 3.9509(3.9496) | Xent 1.1586(1.1629) | Loss 4.5302(4.5310) | Error 0.4175(0.4148) Steps 808(805.02) | Grad Norm 0.6907(0.9424) | Total Time 14.00(14.00)\n",
      "Iter 1725 | Time 75.2652(74.3875) | Bit/dim 3.9398(3.9493) | Xent 1.1665(1.1630) | Loss 4.5230(4.5308) | Error 0.4211(0.4150) Steps 808(805.11) | Grad Norm 0.6067(0.9323) | Total Time 14.00(14.00)\n",
      "Iter 1726 | Time 76.3026(74.4449) | Bit/dim 3.9529(3.9494) | Xent 1.1435(1.1624) | Loss 4.5246(4.5306) | Error 0.4085(0.4148) Steps 808(805.20) | Grad Norm 1.0103(0.9346) | Total Time 14.00(14.00)\n",
      "Iter 1727 | Time 74.9117(74.4589) | Bit/dim 3.9479(3.9493) | Xent 1.1548(1.1622) | Loss 4.5253(4.5304) | Error 0.4084(0.4146) Steps 808(805.28) | Grad Norm 1.6840(0.9571) | Total Time 14.00(14.00)\n",
      "Iter 1728 | Time 73.9466(74.4436) | Bit/dim 3.9505(3.9494) | Xent 1.1588(1.1621) | Loss 4.5299(4.5304) | Error 0.4074(0.4144) Steps 802(805.19) | Grad Norm 0.9476(0.9568) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 29.3977, Epoch Time 493.7045(489.1756), Bit/dim 3.9490(best: 3.9493), Xent 1.1208, Loss 4.5094, Error 0.4036(best: 0.4016)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1729 | Time 72.5510(74.3868) | Bit/dim 3.9444(3.9492) | Xent 1.1522(1.1618) | Loss 4.5205(4.5301) | Error 0.4077(0.4142) Steps 808(805.27) | Grad Norm 0.7673(0.9511) | Total Time 14.00(14.00)\n",
      "Iter 1730 | Time 72.6440(74.3345) | Bit/dim 3.9501(3.9492) | Xent 1.1559(1.1616) | Loss 4.5281(4.5300) | Error 0.4094(0.4140) Steps 808(805.35) | Grad Norm 1.4675(0.9666) | Total Time 14.00(14.00)\n",
      "Iter 1731 | Time 74.5132(74.3399) | Bit/dim 3.9475(3.9492) | Xent 1.1659(1.1617) | Loss 4.5305(4.5301) | Error 0.4150(0.4141) Steps 802(805.25) | Grad Norm 1.0254(0.9684) | Total Time 14.00(14.00)\n",
      "Iter 1732 | Time 77.5484(74.4361) | Bit/dim 3.9467(3.9491) | Xent 1.1535(1.1615) | Loss 4.5234(4.5299) | Error 0.4139(0.4141) Steps 802(805.15) | Grad Norm 0.9284(0.9672) | Total Time 14.00(14.00)\n",
      "Iter 1733 | Time 78.7289(74.5649) | Bit/dim 3.9470(3.9490) | Xent 1.1618(1.1615) | Loss 4.5279(4.5298) | Error 0.4145(0.4141) Steps 802(805.06) | Grad Norm 0.6416(0.9574) | Total Time 14.00(14.00)\n",
      "Iter 1734 | Time 74.9967(74.5779) | Bit/dim 3.9596(3.9494) | Xent 1.1417(1.1609) | Loss 4.5304(4.5298) | Error 0.4083(0.4139) Steps 808(805.15) | Grad Norm 1.1204(0.9623) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 29.5745, Epoch Time 496.1214(489.3839), Bit/dim 3.9495(best: 3.9490), Xent 1.1221, Loss 4.5105, Error 0.4039(best: 0.4016)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1735 | Time 73.5317(74.5465) | Bit/dim 3.9517(3.9494) | Xent 1.1717(1.1612) | Loss 4.5376(4.5300) | Error 0.4147(0.4139) Steps 802(805.05) | Grad Norm 2.0501(0.9950) | Total Time 14.00(14.00)\n",
      "Iter 1736 | Time 72.0690(74.4722) | Bit/dim 3.9484(3.9494) | Xent 1.1605(1.1612) | Loss 4.5286(4.5300) | Error 0.4136(0.4139) Steps 808(805.14) | Grad Norm 1.0120(0.9955) | Total Time 14.00(14.00)\n",
      "Iter 1737 | Time 76.9224(74.5457) | Bit/dim 3.9427(3.9492) | Xent 1.1387(1.1605) | Loss 4.5120(4.5295) | Error 0.4089(0.4138) Steps 808(805.23) | Grad Norm 0.9321(0.9936) | Total Time 14.00(14.00)\n",
      "Iter 1738 | Time 75.1969(74.5652) | Bit/dim 3.9451(3.9491) | Xent 1.1520(1.1603) | Loss 4.5211(4.5292) | Error 0.4091(0.4136) Steps 802(805.13) | Grad Norm 1.4765(1.0081) | Total Time 14.00(14.00)\n",
      "Iter 1739 | Time 76.2941(74.6171) | Bit/dim 3.9491(3.9491) | Xent 1.1674(1.1605) | Loss 4.5328(4.5293) | Error 0.4179(0.4138) Steps 808(805.22) | Grad Norm 1.1847(1.0134) | Total Time 14.00(14.00)\n",
      "Iter 1740 | Time 73.7155(74.5900) | Bit/dim 3.9471(3.9490) | Xent 1.1499(1.1602) | Loss 4.5221(4.5291) | Error 0.4123(0.4137) Steps 802(805.12) | Grad Norm 1.3799(1.0243) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 29.4109, Epoch Time 492.8479(489.4879), Bit/dim 3.9479(best: 3.9490), Xent 1.1200, Loss 4.5078, Error 0.4037(best: 0.4016)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1741 | Time 71.5878(74.4999) | Bit/dim 3.9456(3.9489) | Xent 1.1619(1.1602) | Loss 4.5265(4.5290) | Error 0.4151(0.4137) Steps 802(805.03) | Grad Norm 0.8572(1.0193) | Total Time 14.00(14.00)\n",
      "Iter 1742 | Time 74.9684(74.5140) | Bit/dim 3.9455(3.9488) | Xent 1.1623(1.1603) | Loss 4.5267(4.5290) | Error 0.4123(0.4137) Steps 802(804.94) | Grad Norm 1.0980(1.0217) | Total Time 14.00(14.00)\n",
      "Iter 1743 | Time 74.9748(74.5278) | Bit/dim 3.9432(3.9486) | Xent 1.1547(1.1601) | Loss 4.5205(4.5287) | Error 0.4149(0.4137) Steps 808(805.03) | Grad Norm 1.6483(1.0405) | Total Time 14.00(14.00)\n",
      "Iter 1744 | Time 73.5901(74.4997) | Bit/dim 3.9439(3.9485) | Xent 1.1499(1.1598) | Loss 4.5188(4.5284) | Error 0.4106(0.4136) Steps 808(805.12) | Grad Norm 1.3219(1.0489) | Total Time 14.00(14.00)\n",
      "Iter 1745 | Time 74.6455(74.5041) | Bit/dim 3.9510(3.9486) | Xent 1.1518(1.1596) | Loss 4.5269(4.5284) | Error 0.4103(0.4135) Steps 808(805.20) | Grad Norm 0.6388(1.0366) | Total Time 14.00(14.00)\n",
      "Iter 1746 | Time 76.3072(74.5582) | Bit/dim 3.9486(3.9486) | Xent 1.1775(1.1601) | Loss 4.5373(4.5286) | Error 0.4219(0.4138) Steps 808(805.29) | Grad Norm 1.1794(1.0409) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 29.3412, Epoch Time 491.0061(489.5334), Bit/dim 3.9480(best: 3.9479), Xent 1.1211, Loss 4.5085, Error 0.4055(best: 0.4016)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1747 | Time 74.6449(74.5608) | Bit/dim 3.9492(3.9486) | Xent 1.1494(1.1598) | Loss 4.5239(4.5285) | Error 0.4077(0.4136) Steps 808(805.37) | Grad Norm 1.3860(1.0513) | Total Time 14.00(14.00)\n",
      "Iter 1748 | Time 73.5669(74.5309) | Bit/dim 3.9617(3.9490) | Xent 1.1701(1.1601) | Loss 4.5467(4.5290) | Error 0.4166(0.4137) Steps 808(805.45) | Grad Norm 1.8103(1.0740) | Total Time 14.00(14.00)\n",
      "Iter 1749 | Time 76.7142(74.5964) | Bit/dim 3.9409(3.9487) | Xent 1.1575(1.1600) | Loss 4.5197(4.5288) | Error 0.4194(0.4139) Steps 808(805.52) | Grad Norm 0.7942(1.0656) | Total Time 14.00(14.00)\n",
      "Iter 1750 | Time 74.3644(74.5895) | Bit/dim 3.9395(3.9485) | Xent 1.1502(1.1597) | Loss 4.5146(4.5283) | Error 0.4185(0.4140) Steps 808(805.60) | Grad Norm 0.9208(1.0613) | Total Time 14.00(14.00)\n",
      "Iter 1751 | Time 74.7320(74.5938) | Bit/dim 3.9443(3.9483) | Xent 1.1432(1.1592) | Loss 4.5159(4.5280) | Error 0.4090(0.4139) Steps 802(805.49) | Grad Norm 1.9395(1.0876) | Total Time 14.00(14.00)\n",
      "Iter 1752 | Time 75.1685(74.6110) | Bit/dim 3.9440(3.9482) | Xent 1.1682(1.1595) | Loss 4.5281(4.5280) | Error 0.4193(0.4140) Steps 808(805.57) | Grad Norm 1.4808(1.0994) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 28.9313, Epoch Time 493.5778(489.6547), Bit/dim 3.9479(best: 3.9479), Xent 1.1192, Loss 4.5075, Error 0.4027(best: 0.4016)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1753 | Time 75.4674(74.6367) | Bit/dim 3.9552(3.9484) | Xent 1.1574(1.1594) | Loss 4.5339(4.5281) | Error 0.4115(0.4139) Steps 808(805.64) | Grad Norm 0.6418(1.0857) | Total Time 14.00(14.00)\n",
      "Iter 1754 | Time 73.7004(74.6086) | Bit/dim 3.9493(3.9484) | Xent 1.1624(1.1595) | Loss 4.5305(4.5282) | Error 0.4179(0.4141) Steps 802(805.53) | Grad Norm 0.8189(1.0777) | Total Time 14.00(14.00)\n",
      "Iter 1755 | Time 74.1157(74.5938) | Bit/dim 3.9444(3.9483) | Xent 1.1575(1.1595) | Loss 4.5231(4.5281) | Error 0.4151(0.4141) Steps 808(805.60) | Grad Norm 0.8704(1.0715) | Total Time 14.00(14.00)\n",
      "Iter 1756 | Time 75.0038(74.6061) | Bit/dim 3.9372(3.9480) | Xent 1.1431(1.1590) | Loss 4.5087(4.5275) | Error 0.4096(0.4140) Steps 808(805.68) | Grad Norm 1.6414(1.0886) | Total Time 14.00(14.00)\n",
      "Iter 1757 | Time 75.2161(74.6244) | Bit/dim 3.9467(3.9480) | Xent 1.1514(1.1587) | Loss 4.5224(4.5273) | Error 0.4076(0.4138) Steps 808(805.75) | Grad Norm 0.5872(1.0735) | Total Time 14.00(14.00)\n",
      "Iter 1758 | Time 76.3743(74.6769) | Bit/dim 3.9444(3.9478) | Xent 1.1588(1.1587) | Loss 4.5238(4.5272) | Error 0.4080(0.4136) Steps 808(805.81) | Grad Norm 0.7059(1.0625) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 29.2636, Epoch Time 494.6594(489.8049), Bit/dim 3.9477(best: 3.9479), Xent 1.1162, Loss 4.5058, Error 0.4012(best: 0.4016)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1759 | Time 74.2483(74.6640) | Bit/dim 3.9488(3.9479) | Xent 1.1537(1.1586) | Loss 4.5256(4.5272) | Error 0.4117(0.4135) Steps 808(805.88) | Grad Norm 0.7686(1.0537) | Total Time 14.00(14.00)\n",
      "Iter 1760 | Time 73.9422(74.6424) | Bit/dim 3.9465(3.9478) | Xent 1.1681(1.1589) | Loss 4.5305(4.5273) | Error 0.4103(0.4134) Steps 808(805.94) | Grad Norm 0.6674(1.0421) | Total Time 14.00(14.00)\n",
      "Iter 1761 | Time 76.5579(74.6999) | Bit/dim 3.9510(3.9479) | Xent 1.1512(1.1587) | Loss 4.5266(4.5272) | Error 0.4041(0.4132) Steps 808(806.00) | Grad Norm 0.8949(1.0377) | Total Time 14.00(14.00)\n",
      "Iter 1762 | Time 74.4922(74.6936) | Bit/dim 3.9475(3.9479) | Xent 1.1503(1.1584) | Loss 4.5227(4.5271) | Error 0.4137(0.4132) Steps 808(806.06) | Grad Norm 1.4119(1.0489) | Total Time 14.00(14.00)\n",
      "Iter 1763 | Time 75.6847(74.7234) | Bit/dim 3.9368(3.9476) | Xent 1.1608(1.1585) | Loss 4.5172(4.5268) | Error 0.4171(0.4133) Steps 802(805.94) | Grad Norm 0.8520(1.0430) | Total Time 14.00(14.00)\n",
      "Iter 1764 | Time 75.2900(74.7404) | Bit/dim 3.9525(3.9477) | Xent 1.1358(1.1578) | Loss 4.5204(4.5266) | Error 0.3998(0.4129) Steps 820(806.36) | Grad Norm 0.7330(1.0337) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 29.2770, Epoch Time 494.9299(489.9586), Bit/dim 3.9462(best: 3.9477), Xent 1.1184, Loss 4.5054, Error 0.4026(best: 0.4012)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1765 | Time 75.1435(74.7525) | Bit/dim 3.9456(3.9477) | Xent 1.1403(1.1573) | Loss 4.5157(4.5263) | Error 0.4000(0.4125) Steps 808(806.41) | Grad Norm 1.1896(1.0384) | Total Time 14.00(14.00)\n",
      "Iter 1766 | Time 73.3701(74.7110) | Bit/dim 3.9548(3.9479) | Xent 1.1665(1.1575) | Loss 4.5381(4.5266) | Error 0.4154(0.4126) Steps 808(806.46) | Grad Norm 1.1723(1.0424) | Total Time 14.00(14.00)\n",
      "Iter 1767 | Time 75.8356(74.7447) | Bit/dim 3.9461(3.9478) | Xent 1.1521(1.1574) | Loss 4.5221(4.5265) | Error 0.4175(0.4127) Steps 802(806.33) | Grad Norm 0.6617(1.0310) | Total Time 14.00(14.00)\n",
      "Iter 1768 | Time 74.2613(74.7302) | Bit/dim 3.9384(3.9475) | Xent 1.1456(1.1570) | Loss 4.5113(4.5261) | Error 0.4066(0.4126) Steps 802(806.20) | Grad Norm 0.5762(1.0173) | Total Time 14.00(14.00)\n",
      "Iter 1769 | Time 75.1000(74.7413) | Bit/dim 3.9512(3.9476) | Xent 1.1639(1.1572) | Loss 4.5332(4.5263) | Error 0.4166(0.4127) Steps 808(806.25) | Grad Norm 1.0584(1.0186) | Total Time 14.00(14.00)\n",
      "Iter 1770 | Time 74.5740(74.7363) | Bit/dim 3.9410(3.9475) | Xent 1.1540(1.1571) | Loss 4.5180(4.5260) | Error 0.4166(0.4128) Steps 808(806.30) | Grad Norm 0.7803(1.0114) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 29.4391, Epoch Time 493.2606(490.0577), Bit/dim 3.9471(best: 3.9462), Xent 1.1162, Loss 4.5052, Error 0.3997(best: 0.4012)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1771 | Time 71.9844(74.6537) | Bit/dim 3.9406(3.9472) | Xent 1.1534(1.1570) | Loss 4.5174(4.5258) | Error 0.4116(0.4128) Steps 808(806.35) | Grad Norm 0.8283(1.0059) | Total Time 14.00(14.00)\n",
      "Iter 1772 | Time 72.5801(74.5915) | Bit/dim 3.9418(3.9471) | Xent 1.1352(1.1564) | Loss 4.5094(4.5253) | Error 0.4019(0.4124) Steps 808(806.40) | Grad Norm 0.8508(1.0013) | Total Time 14.00(14.00)\n",
      "Iter 1773 | Time 73.3171(74.5533) | Bit/dim 3.9468(3.9471) | Xent 1.1732(1.1569) | Loss 4.5334(4.5255) | Error 0.4219(0.4127) Steps 808(806.45) | Grad Norm 0.7703(0.9943) | Total Time 14.00(14.00)\n",
      "Iter 1774 | Time 75.9632(74.5956) | Bit/dim 3.9513(3.9472) | Xent 1.1676(1.1572) | Loss 4.5352(4.5258) | Error 0.4204(0.4129) Steps 802(806.32) | Grad Norm 0.6883(0.9852) | Total Time 14.00(14.00)\n",
      "Iter 1775 | Time 72.7962(74.5416) | Bit/dim 3.9438(3.9471) | Xent 1.1685(1.1575) | Loss 4.5281(4.5259) | Error 0.4125(0.4129) Steps 808(806.37) | Grad Norm 0.7871(0.9792) | Total Time 14.00(14.00)\n",
      "Iter 1776 | Time 75.4639(74.5693) | Bit/dim 3.9499(3.9472) | Xent 1.1417(1.1571) | Loss 4.5207(4.5257) | Error 0.4094(0.4128) Steps 808(806.42) | Grad Norm 0.7354(0.9719) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 29.4510, Epoch Time 487.1568(489.9707), Bit/dim 3.9468(best: 3.9462), Xent 1.1157, Loss 4.5046, Error 0.4028(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1777 | Time 73.4499(74.5357) | Bit/dim 3.9558(3.9474) | Xent 1.1738(1.1576) | Loss 4.5427(4.5262) | Error 0.4167(0.4129) Steps 802(806.28) | Grad Norm 0.8970(0.9697) | Total Time 14.00(14.00)\n",
      "Iter 1778 | Time 76.5259(74.5954) | Bit/dim 3.9399(3.9472) | Xent 1.1507(1.1574) | Loss 4.5152(4.5259) | Error 0.4073(0.4128) Steps 808(806.34) | Grad Norm 0.8137(0.9650) | Total Time 14.00(14.00)\n",
      "Iter 1779 | Time 74.5188(74.5931) | Bit/dim 3.9510(3.9473) | Xent 1.1587(1.1574) | Loss 4.5304(4.5260) | Error 0.4166(0.4129) Steps 820(806.75) | Grad Norm 0.9984(0.9660) | Total Time 14.00(14.00)\n",
      "Iter 1780 | Time 77.1065(74.6685) | Bit/dim 3.9443(3.9472) | Xent 1.1629(1.1576) | Loss 4.5258(4.5260) | Error 0.4200(0.4131) Steps 802(806.60) | Grad Norm 0.6836(0.9575) | Total Time 14.00(14.00)\n",
      "Iter 1781 | Time 73.7617(74.6413) | Bit/dim 3.9412(3.9471) | Xent 1.1289(1.1567) | Loss 4.5056(4.5254) | Error 0.4054(0.4129) Steps 808(806.65) | Grad Norm 0.7664(0.9518) | Total Time 14.00(14.00)\n",
      "Iter 1782 | Time 73.4321(74.6050) | Bit/dim 3.9405(3.9469) | Xent 1.1320(1.1560) | Loss 4.5065(4.5248) | Error 0.4024(0.4126) Steps 808(806.69) | Grad Norm 0.6419(0.9425) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 29.7171, Epoch Time 493.9485(490.0900), Bit/dim 3.9462(best: 3.9462), Xent 1.1151, Loss 4.5038, Error 0.4002(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1783 | Time 75.7381(74.6390) | Bit/dim 3.9444(3.9468) | Xent 1.1473(1.1557) | Loss 4.5181(4.5246) | Error 0.4099(0.4125) Steps 808(806.73) | Grad Norm 0.9966(0.9441) | Total Time 14.00(14.00)\n",
      "Iter 1784 | Time 75.2375(74.6570) | Bit/dim 3.9362(3.9465) | Xent 1.1410(1.1553) | Loss 4.5067(4.5241) | Error 0.4085(0.4124) Steps 802(806.58) | Grad Norm 0.8637(0.9417) | Total Time 14.00(14.00)\n",
      "Iter 1785 | Time 74.1926(74.6430) | Bit/dim 3.9499(3.9466) | Xent 1.1558(1.1553) | Loss 4.5278(4.5242) | Error 0.4117(0.4123) Steps 808(806.63) | Grad Norm 1.0520(0.9450) | Total Time 14.00(14.00)\n",
      "Iter 1786 | Time 74.7420(74.6460) | Bit/dim 3.9502(3.9467) | Xent 1.1575(1.1553) | Loss 4.5289(4.5244) | Error 0.4121(0.4123) Steps 802(806.49) | Grad Norm 0.9584(0.9454) | Total Time 14.00(14.00)\n",
      "Iter 1787 | Time 74.9645(74.6556) | Bit/dim 3.9380(3.9464) | Xent 1.1539(1.1553) | Loss 4.5150(4.5241) | Error 0.4131(0.4124) Steps 802(806.35) | Grad Norm 0.7624(0.9399) | Total Time 14.00(14.00)\n",
      "Iter 1788 | Time 76.5502(74.7124) | Bit/dim 3.9463(3.9464) | Xent 1.1460(1.1550) | Loss 4.5193(4.5239) | Error 0.4100(0.4123) Steps 808(806.40) | Grad Norm 0.6841(0.9322) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 28.7882, Epoch Time 495.6746(490.2575), Bit/dim 3.9446(best: 3.9462), Xent 1.1150, Loss 4.5021, Error 0.4008(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1789 | Time 77.5808(74.7985) | Bit/dim 3.9457(3.9464) | Xent 1.1377(1.1545) | Loss 4.5146(4.5236) | Error 0.4030(0.4120) Steps 808(806.45) | Grad Norm 0.5443(0.9206) | Total Time 14.00(14.00)\n",
      "Iter 1790 | Time 76.9263(74.8623) | Bit/dim 3.9427(3.9463) | Xent 1.1586(1.1546) | Loss 4.5221(4.5236) | Error 0.4164(0.4121) Steps 814(806.68) | Grad Norm 0.6140(0.9114) | Total Time 14.00(14.00)\n",
      "Iter 1791 | Time 75.5685(74.8835) | Bit/dim 3.9445(3.9462) | Xent 1.1614(1.1548) | Loss 4.5252(4.5236) | Error 0.4127(0.4122) Steps 808(806.72) | Grad Norm 0.7759(0.9073) | Total Time 14.00(14.00)\n",
      "Iter 1792 | Time 74.4202(74.8696) | Bit/dim 3.9477(3.9463) | Xent 1.1357(1.1543) | Loss 4.5155(4.5234) | Error 0.4051(0.4119) Steps 802(806.57) | Grad Norm 0.7032(0.9012) | Total Time 14.00(14.00)\n",
      "Iter 1793 | Time 76.3780(74.9148) | Bit/dim 3.9414(3.9461) | Xent 1.1705(1.1547) | Loss 4.5266(4.5235) | Error 0.4119(0.4119) Steps 808(806.62) | Grad Norm 0.5853(0.8917) | Total Time 14.00(14.00)\n",
      "Iter 1794 | Time 72.4185(74.8399) | Bit/dim 3.9450(3.9461) | Xent 1.1632(1.1550) | Loss 4.5266(4.5236) | Error 0.4226(0.4123) Steps 802(806.48) | Grad Norm 0.7511(0.8875) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 29.4635, Epoch Time 498.0987(490.4928), Bit/dim 3.9462(best: 3.9446), Xent 1.1137, Loss 4.5030, Error 0.4031(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1795 | Time 75.6899(74.8654) | Bit/dim 3.9464(3.9461) | Xent 1.1434(1.1547) | Loss 4.5181(4.5234) | Error 0.4018(0.4119) Steps 808(806.52) | Grad Norm 0.7055(0.8821) | Total Time 14.00(14.00)\n",
      "Iter 1796 | Time 74.8956(74.8663) | Bit/dim 3.9359(3.9458) | Xent 1.1549(1.1547) | Loss 4.5133(4.5231) | Error 0.4137(0.4120) Steps 808(806.57) | Grad Norm 0.6888(0.8763) | Total Time 14.00(14.00)\n",
      "Iter 1797 | Time 75.1191(74.8739) | Bit/dim 3.9547(3.9461) | Xent 1.1354(1.1541) | Loss 4.5224(4.5231) | Error 0.4062(0.4118) Steps 808(806.61) | Grad Norm 0.9101(0.8773) | Total Time 14.00(14.00)\n",
      "Iter 1798 | Time 75.9665(74.9067) | Bit/dim 3.9453(3.9460) | Xent 1.1527(1.1540) | Loss 4.5216(4.5231) | Error 0.4061(0.4117) Steps 802(806.47) | Grad Norm 0.8989(0.8779) | Total Time 14.00(14.00)\n",
      "Iter 1799 | Time 75.2996(74.9185) | Bit/dim 3.9343(3.9457) | Xent 1.1610(1.1542) | Loss 4.5148(4.5228) | Error 0.4151(0.4118) Steps 808(806.52) | Grad Norm 0.8123(0.8760) | Total Time 14.00(14.00)\n",
      "Iter 1800 | Time 73.7179(74.8825) | Bit/dim 3.9510(3.9458) | Xent 1.1358(1.1537) | Loss 4.5189(4.5227) | Error 0.4069(0.4116) Steps 808(806.56) | Grad Norm 1.7798(0.9031) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 29.2551, Epoch Time 495.2696(490.6361), Bit/dim 3.9462(best: 3.9446), Xent 1.1146, Loss 4.5035, Error 0.4027(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1801 | Time 74.2345(74.8630) | Bit/dim 3.9469(3.9459) | Xent 1.1615(1.1539) | Loss 4.5276(4.5228) | Error 0.4113(0.4116) Steps 808(806.61) | Grad Norm 0.8697(0.9021) | Total Time 14.00(14.00)\n",
      "Iter 1802 | Time 75.4035(74.8793) | Bit/dim 3.9449(3.9458) | Xent 1.1647(1.1543) | Loss 4.5272(4.5230) | Error 0.4175(0.4118) Steps 802(806.47) | Grad Norm 1.1401(0.9092) | Total Time 14.00(14.00)\n",
      "Iter 1803 | Time 72.6205(74.8115) | Bit/dim 3.9496(3.9460) | Xent 1.1375(1.1537) | Loss 4.5184(4.5228) | Error 0.4009(0.4115) Steps 808(806.51) | Grad Norm 0.7934(0.9057) | Total Time 14.00(14.00)\n",
      "Iter 1804 | Time 77.5678(74.8942) | Bit/dim 3.9367(3.9457) | Xent 1.1316(1.1531) | Loss 4.5025(4.5222) | Error 0.4074(0.4113) Steps 820(806.92) | Grad Norm 1.6678(0.9286) | Total Time 14.00(14.00)\n",
      "Iter 1805 | Time 73.7609(74.8602) | Bit/dim 3.9377(3.9454) | Xent 1.1634(1.1534) | Loss 4.5194(4.5221) | Error 0.4239(0.4117) Steps 808(806.95) | Grad Norm 1.3023(0.9398) | Total Time 14.00(14.00)\n",
      "Iter 1806 | Time 75.6735(74.8846) | Bit/dim 3.9525(3.9457) | Xent 1.1370(1.1529) | Loss 4.5210(4.5221) | Error 0.4006(0.4114) Steps 808(806.98) | Grad Norm 1.0941(0.9444) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 29.4965, Epoch Time 494.2861(490.7456), Bit/dim 3.9451(best: 3.9446), Xent 1.1106, Loss 4.5004, Error 0.4023(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1807 | Time 76.5558(74.9347) | Bit/dim 3.9515(3.9458) | Xent 1.1556(1.1530) | Loss 4.5292(4.5223) | Error 0.4161(0.4115) Steps 808(807.01) | Grad Norm 1.1238(0.9498) | Total Time 14.00(14.00)\n",
      "Iter 1808 | Time 75.8707(74.9628) | Bit/dim 3.9424(3.9457) | Xent 1.1606(1.1532) | Loss 4.5227(4.5223) | Error 0.4120(0.4115) Steps 808(807.04) | Grad Norm 1.7739(0.9745) | Total Time 14.00(14.00)\n",
      "Iter 1809 | Time 75.5849(74.9815) | Bit/dim 3.9442(3.9457) | Xent 1.1431(1.1529) | Loss 4.5158(4.5221) | Error 0.4089(0.4115) Steps 808(807.07) | Grad Norm 1.7853(0.9989) | Total Time 14.00(14.00)\n",
      "Iter 1810 | Time 77.2073(75.0482) | Bit/dim 3.9397(3.9455) | Xent 1.1497(1.1528) | Loss 4.5145(4.5219) | Error 0.4062(0.4113) Steps 808(807.10) | Grad Norm 0.5824(0.9864) | Total Time 14.00(14.00)\n",
      "Iter 1811 | Time 74.3273(75.0266) | Bit/dim 3.9356(3.9452) | Xent 1.1421(1.1525) | Loss 4.5066(4.5214) | Error 0.4096(0.4112) Steps 808(807.13) | Grad Norm 1.2191(0.9934) | Total Time 14.00(14.00)\n",
      "Iter 1812 | Time 75.7156(75.0473) | Bit/dim 3.9509(3.9454) | Xent 1.1427(1.1522) | Loss 4.5223(4.5215) | Error 0.4120(0.4113) Steps 808(807.15) | Grad Norm 1.8223(1.0182) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 29.1841, Epoch Time 500.0724(491.0254), Bit/dim 3.9443(best: 3.9446), Xent 1.1112, Loss 4.4999, Error 0.4000(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1813 | Time 76.2836(75.0844) | Bit/dim 3.9405(3.9452) | Xent 1.1473(1.1521) | Loss 4.5142(4.5213) | Error 0.4095(0.4112) Steps 820(807.54) | Grad Norm 0.9732(1.0169) | Total Time 14.00(14.00)\n",
      "Iter 1814 | Time 74.9675(75.0809) | Bit/dim 3.9567(3.9456) | Xent 1.1459(1.1519) | Loss 4.5296(4.5215) | Error 0.4073(0.4111) Steps 802(807.37) | Grad Norm 0.7101(1.0077) | Total Time 14.00(14.00)\n",
      "Iter 1815 | Time 74.9774(75.0778) | Bit/dim 3.9393(3.9454) | Xent 1.1407(1.1515) | Loss 4.5097(4.5211) | Error 0.4099(0.4111) Steps 820(807.75) | Grad Norm 0.7509(1.0000) | Total Time 14.00(14.00)\n",
      "Iter 1816 | Time 75.7830(75.0989) | Bit/dim 3.9448(3.9454) | Xent 1.1519(1.1515) | Loss 4.5208(4.5211) | Error 0.4127(0.4111) Steps 808(807.76) | Grad Norm 1.2886(1.0086) | Total Time 14.00(14.00)\n",
      "Iter 1817 | Time 75.6146(75.1144) | Bit/dim 3.9401(3.9452) | Xent 1.1485(1.1515) | Loss 4.5144(4.5209) | Error 0.4095(0.4111) Steps 808(807.77) | Grad Norm 1.5643(1.0253) | Total Time 14.00(14.00)\n",
      "Iter 1818 | Time 75.5857(75.1285) | Bit/dim 3.9396(3.9450) | Xent 1.1383(1.1511) | Loss 4.5088(4.5206) | Error 0.4135(0.4111) Steps 802(807.59) | Grad Norm 0.8243(1.0193) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 29.3071, Epoch Time 497.9634(491.2335), Bit/dim 3.9440(best: 3.9443), Xent 1.1111, Loss 4.4996, Error 0.4024(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1819 | Time 76.9088(75.1819) | Bit/dim 3.9477(3.9451) | Xent 1.1625(1.1514) | Loss 4.5290(4.5208) | Error 0.4165(0.4113) Steps 808(807.61) | Grad Norm 0.9068(1.0159) | Total Time 14.00(14.00)\n",
      "Iter 1820 | Time 73.8864(75.1431) | Bit/dim 3.9515(3.9453) | Xent 1.1466(1.1513) | Loss 4.5248(4.5209) | Error 0.4096(0.4112) Steps 808(807.62) | Grad Norm 1.6444(1.0348) | Total Time 14.00(14.00)\n",
      "Iter 1821 | Time 75.3723(75.1499) | Bit/dim 3.9403(3.9452) | Xent 1.1182(1.1503) | Loss 4.4994(4.5203) | Error 0.4034(0.4110) Steps 808(807.63) | Grad Norm 1.3623(1.0446) | Total Time 14.00(14.00)\n",
      "Iter 1822 | Time 74.3655(75.1264) | Bit/dim 3.9384(3.9450) | Xent 1.1425(1.1500) | Loss 4.5096(4.5200) | Error 0.4077(0.4109) Steps 808(807.64) | Grad Norm 0.7189(1.0348) | Total Time 14.00(14.00)\n",
      "Iter 1823 | Time 77.6184(75.2012) | Bit/dim 3.9401(3.9448) | Xent 1.1501(1.1500) | Loss 4.5152(4.5198) | Error 0.4121(0.4109) Steps 808(807.65) | Grad Norm 0.9099(1.0311) | Total Time 14.00(14.00)\n",
      "Iter 1824 | Time 75.7334(75.2171) | Bit/dim 3.9414(3.9447) | Xent 1.1501(1.1500) | Loss 4.5164(4.5197) | Error 0.4110(0.4110) Steps 808(807.66) | Grad Norm 1.4614(1.0440) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 29.5086, Epoch Time 498.9991(491.4665), Bit/dim 3.9444(best: 3.9440), Xent 1.1101, Loss 4.4994, Error 0.4004(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1825 | Time 74.0092(75.1809) | Bit/dim 3.9419(3.9446) | Xent 1.1467(1.1499) | Loss 4.5152(4.5196) | Error 0.4065(0.4108) Steps 808(807.67) | Grad Norm 0.8521(1.0382) | Total Time 14.00(14.00)\n",
      "Iter 1826 | Time 77.6472(75.2549) | Bit/dim 3.9379(3.9444) | Xent 1.1492(1.1499) | Loss 4.5125(4.5194) | Error 0.4086(0.4108) Steps 802(807.50) | Grad Norm 0.9351(1.0351) | Total Time 14.00(14.00)\n",
      "Iter 1827 | Time 74.9582(75.2460) | Bit/dim 3.9491(3.9446) | Xent 1.1558(1.1501) | Loss 4.5270(4.5196) | Error 0.4123(0.4108) Steps 808(807.52) | Grad Norm 0.8420(1.0293) | Total Time 14.00(14.00)\n",
      "Iter 1828 | Time 76.7094(75.2899) | Bit/dim 3.9468(3.9446) | Xent 1.1307(1.1495) | Loss 4.5121(4.5194) | Error 0.4020(0.4105) Steps 802(807.35) | Grad Norm 0.7912(1.0222) | Total Time 14.00(14.00)\n",
      "Iter 1829 | Time 73.5978(75.2391) | Bit/dim 3.9417(3.9445) | Xent 1.1362(1.1491) | Loss 4.5098(4.5191) | Error 0.4058(0.4104) Steps 820(807.73) | Grad Norm 1.4240(1.0342) | Total Time 14.00(14.00)\n",
      "Iter 1830 | Time 75.6103(75.2503) | Bit/dim 3.9424(3.9445) | Xent 1.1451(1.1490) | Loss 4.5150(4.5190) | Error 0.4136(0.4105) Steps 814(807.92) | Grad Norm 0.5613(1.0201) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 29.3276, Epoch Time 497.2608(491.6403), Bit/dim 3.9444(best: 3.9440), Xent 1.1093, Loss 4.4991, Error 0.3981(best: 0.3997)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1831 | Time 76.6644(75.2927) | Bit/dim 3.9434(3.9444) | Xent 1.1522(1.1491) | Loss 4.5195(4.5190) | Error 0.4127(0.4106) Steps 826(808.46) | Grad Norm 0.9824(1.0189) | Total Time 14.00(14.00)\n",
      "Iter 1832 | Time 76.9981(75.3438) | Bit/dim 3.9437(3.9444) | Xent 1.1576(1.1493) | Loss 4.5224(4.5191) | Error 0.4115(0.4106) Steps 808(808.45) | Grad Norm 1.0479(1.0198) | Total Time 14.00(14.00)\n",
      "Iter 1833 | Time 77.3937(75.4053) | Bit/dim 3.9364(3.9442) | Xent 1.1434(1.1492) | Loss 4.5081(4.5188) | Error 0.4062(0.4105) Steps 808(808.43) | Grad Norm 1.2549(1.0268) | Total Time 14.00(14.00)\n",
      "Iter 1834 | Time 76.9650(75.4521) | Bit/dim 3.9422(3.9441) | Xent 1.1465(1.1491) | Loss 4.5155(4.5187) | Error 0.4081(0.4104) Steps 814(808.60) | Grad Norm 0.7667(1.0190) | Total Time 14.00(14.00)\n",
      "Iter 1835 | Time 77.2115(75.5049) | Bit/dim 3.9475(3.9442) | Xent 1.1293(1.1485) | Loss 4.5121(4.5185) | Error 0.3972(0.4100) Steps 820(808.94) | Grad Norm 0.8641(1.0144) | Total Time 14.00(14.00)\n",
      "Iter 1836 | Time 74.2938(75.4686) | Bit/dim 3.9404(3.9441) | Xent 1.1445(1.1484) | Loss 4.5127(4.5183) | Error 0.4136(0.4101) Steps 814(809.09) | Grad Norm 2.3808(1.0554) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 29.4257, Epoch Time 504.5409(492.0273), Bit/dim 3.9440(best: 3.9440), Xent 1.1074, Loss 4.4977, Error 0.4004(best: 0.3981)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1837 | Time 76.3999(75.4965) | Bit/dim 3.9416(3.9440) | Xent 1.1535(1.1485) | Loss 4.5183(4.5183) | Error 0.4115(0.4101) Steps 808(809.06) | Grad Norm 1.3899(1.0654) | Total Time 14.00(14.00)\n",
      "Iter 1838 | Time 76.5031(75.5267) | Bit/dim 3.9422(3.9440) | Xent 1.1343(1.1481) | Loss 4.5094(4.5180) | Error 0.4050(0.4100) Steps 808(809.03) | Grad Norm 1.1019(1.0665) | Total Time 14.00(14.00)\n",
      "Iter 1839 | Time 73.3098(75.4602) | Bit/dim 3.9457(3.9440) | Xent 1.1410(1.1479) | Loss 4.5162(4.5180) | Error 0.4031(0.4098) Steps 808(809.00) | Grad Norm 2.3708(1.1056) | Total Time 14.00(14.00)\n",
      "Iter 1840 | Time 74.9850(75.4460) | Bit/dim 3.9371(3.9438) | Xent 1.1322(1.1474) | Loss 4.5032(4.5175) | Error 0.4060(0.4097) Steps 808(808.97) | Grad Norm 1.6997(1.1235) | Total Time 14.00(14.00)\n",
      "Iter 1841 | Time 78.8143(75.5470) | Bit/dim 3.9348(3.9436) | Xent 1.1389(1.1472) | Loss 4.5042(4.5171) | Error 0.4131(0.4098) Steps 820(809.30) | Grad Norm 0.8128(1.1141) | Total Time 14.00(14.00)\n",
      "Iter 1842 | Time 76.4662(75.5746) | Bit/dim 3.9527(3.9438) | Xent 1.1646(1.1477) | Loss 4.5350(4.5177) | Error 0.4159(0.4100) Steps 814(809.44) | Grad Norm 1.2222(1.1174) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 29.2478, Epoch Time 501.0008(492.2965), Bit/dim 3.9436(best: 3.9440), Xent 1.1071, Loss 4.4971, Error 0.4004(best: 0.3981)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1843 | Time 73.6174(75.5159) | Bit/dim 3.9438(3.9438) | Xent 1.1496(1.1477) | Loss 4.5186(4.5177) | Error 0.4059(0.4098) Steps 808(809.40) | Grad Norm 1.4683(1.1279) | Total Time 14.00(14.00)\n",
      "Iter 1844 | Time 75.8420(75.5256) | Bit/dim 3.9434(3.9438) | Xent 1.1414(1.1475) | Loss 4.5141(4.5176) | Error 0.4065(0.4097) Steps 814(809.54) | Grad Norm 1.0383(1.1252) | Total Time 14.00(14.00)\n",
      "Iter 1845 | Time 72.9753(75.4491) | Bit/dim 3.9461(3.9439) | Xent 1.1485(1.1476) | Loss 4.5204(4.5177) | Error 0.4060(0.4096) Steps 808(809.49) | Grad Norm 0.7584(1.1142) | Total Time 14.00(14.00)\n",
      "Iter 1846 | Time 74.7207(75.4273) | Bit/dim 3.9474(3.9440) | Xent 1.1432(1.1474) | Loss 4.5190(4.5177) | Error 0.4114(0.4097) Steps 808(809.44) | Grad Norm 0.9323(1.1088) | Total Time 14.00(14.00)\n",
      "Iter 1847 | Time 75.2362(75.4215) | Bit/dim 3.9440(3.9440) | Xent 1.1326(1.1470) | Loss 4.5103(4.5175) | Error 0.4100(0.4097) Steps 808(809.40) | Grad Norm 1.2798(1.1139) | Total Time 14.00(14.00)\n",
      "Iter 1848 | Time 75.9811(75.4383) | Bit/dim 3.9305(3.9436) | Xent 1.1278(1.1464) | Loss 4.4944(4.5168) | Error 0.3989(0.4094) Steps 820(809.72) | Grad Norm 1.3848(1.1220) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 29.4610, Epoch Time 493.3095(492.3269), Bit/dim 3.9437(best: 3.9436), Xent 1.1071, Loss 4.4973, Error 0.3963(best: 0.3981)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1849 | Time 76.9842(75.4847) | Bit/dim 3.9474(3.9437) | Xent 1.1409(1.1463) | Loss 4.5178(4.5168) | Error 0.4064(0.4093) Steps 814(809.85) | Grad Norm 0.6599(1.1082) | Total Time 14.00(14.00)\n",
      "Iter 1850 | Time 75.6715(75.4903) | Bit/dim 3.9529(3.9440) | Xent 1.1297(1.1458) | Loss 4.5178(4.5169) | Error 0.4059(0.4092) Steps 802(809.61) | Grad Norm 1.0964(1.1078) | Total Time 14.00(14.00)\n",
      "Iter 1851 | Time 77.7937(75.5594) | Bit/dim 3.9230(3.9433) | Xent 1.1357(1.1455) | Loss 4.4908(4.5161) | Error 0.4038(0.4090) Steps 808(809.56) | Grad Norm 1.1785(1.1099) | Total Time 14.00(14.00)\n",
      "Iter 1852 | Time 75.2315(75.5496) | Bit/dim 3.9371(3.9432) | Xent 1.1467(1.1455) | Loss 4.5105(4.5159) | Error 0.4087(0.4090) Steps 808(809.52) | Grad Norm 1.2015(1.1127) | Total Time 14.00(14.00)\n",
      "Iter 1853 | Time 77.9368(75.6212) | Bit/dim 3.9374(3.9430) | Xent 1.1362(1.1452) | Loss 4.5055(4.5156) | Error 0.4048(0.4089) Steps 808(809.47) | Grad Norm 0.5660(1.0963) | Total Time 14.00(14.00)\n",
      "Iter 1854 | Time 75.2509(75.6101) | Bit/dim 3.9500(3.9432) | Xent 1.1522(1.1454) | Loss 4.5261(4.5159) | Error 0.4126(0.4090) Steps 808(809.43) | Grad Norm 0.8520(1.0889) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 29.4210, Epoch Time 503.8686(492.6732), Bit/dim 3.9436(best: 3.9436), Xent 1.1053, Loss 4.4962, Error 0.3966(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1855 | Time 74.6475(75.5812) | Bit/dim 3.9403(3.9431) | Xent 1.1380(1.1452) | Loss 4.5093(4.5157) | Error 0.4030(0.4088) Steps 808(809.38) | Grad Norm 1.2947(1.0951) | Total Time 14.00(14.00)\n",
      "Iter 1856 | Time 74.8501(75.5593) | Bit/dim 3.9354(3.9429) | Xent 1.1226(1.1445) | Loss 4.4967(4.5151) | Error 0.4031(0.4086) Steps 820(809.70) | Grad Norm 0.8927(1.0890) | Total Time 14.00(14.00)\n",
      "Iter 1857 | Time 76.4514(75.5860) | Bit/dim 3.9365(3.9427) | Xent 1.1194(1.1438) | Loss 4.4962(4.5146) | Error 0.4039(0.4085) Steps 808(809.65) | Grad Norm 0.5672(1.0734) | Total Time 14.00(14.00)\n",
      "Iter 1858 | Time 75.3575(75.5792) | Bit/dim 3.9433(3.9427) | Xent 1.1369(1.1436) | Loss 4.5117(4.5145) | Error 0.4026(0.4083) Steps 808(809.60) | Grad Norm 0.8831(1.0677) | Total Time 14.00(14.00)\n",
      "Iter 1859 | Time 75.9278(75.5896) | Bit/dim 3.9517(3.9430) | Xent 1.1566(1.1440) | Loss 4.5300(4.5150) | Error 0.4116(0.4084) Steps 808(809.55) | Grad Norm 1.0313(1.0666) | Total Time 14.00(14.00)\n",
      "Iter 1860 | Time 81.0953(75.7548) | Bit/dim 3.9412(3.9429) | Xent 1.1441(1.1440) | Loss 4.5132(4.5149) | Error 0.4026(0.4082) Steps 826(810.05) | Grad Norm 1.3116(1.0739) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 29.1701, Epoch Time 502.7274(492.9748), Bit/dim 3.9434(best: 3.9436), Xent 1.1054, Loss 4.4961, Error 0.3990(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1861 | Time 75.5520(75.7487) | Bit/dim 3.9467(3.9430) | Xent 1.1375(1.1438) | Loss 4.5155(4.5149) | Error 0.4061(0.4082) Steps 808(809.99) | Grad Norm 0.8167(1.0662) | Total Time 14.00(14.00)\n",
      "Iter 1862 | Time 79.4852(75.8608) | Bit/dim 3.9374(3.9429) | Xent 1.1366(1.1436) | Loss 4.5057(4.5146) | Error 0.4028(0.4080) Steps 808(809.93) | Grad Norm 1.1656(1.0692) | Total Time 14.00(14.00)\n",
      "Iter 1863 | Time 76.4431(75.8783) | Bit/dim 3.9480(3.9430) | Xent 1.1517(1.1438) | Loss 4.5239(4.5149) | Error 0.4129(0.4082) Steps 808(809.87) | Grad Norm 1.4422(1.0804) | Total Time 14.00(14.00)\n",
      "Iter 1864 | Time 75.2325(75.8589) | Bit/dim 3.9474(3.9432) | Xent 1.1477(1.1439) | Loss 4.5213(4.5151) | Error 0.4054(0.4081) Steps 820(810.17) | Grad Norm 0.5915(1.0657) | Total Time 14.00(14.00)\n",
      "Iter 1865 | Time 76.1585(75.8679) | Bit/dim 3.9390(3.9430) | Xent 1.1186(1.1432) | Loss 4.4983(4.5146) | Error 0.4060(0.4080) Steps 802(809.93) | Grad Norm 0.6979(1.0547) | Total Time 14.00(14.00)\n",
      "Iter 1866 | Time 78.1342(75.9359) | Bit/dim 3.9391(3.9429) | Xent 1.1503(1.1434) | Loss 4.5143(4.5146) | Error 0.4065(0.4080) Steps 820(810.23) | Grad Norm 0.7152(1.0445) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 29.1604, Epoch Time 505.6399(493.3548), Bit/dim 3.9417(best: 3.9434), Xent 1.1067, Loss 4.4950, Error 0.3982(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1867 | Time 74.7808(75.9012) | Bit/dim 3.9424(3.9429) | Xent 1.1328(1.1431) | Loss 4.5088(4.5144) | Error 0.4066(0.4079) Steps 820(810.52) | Grad Norm 0.6524(1.0327) | Total Time 14.00(14.00)\n",
      "Iter 1868 | Time 75.5242(75.8899) | Bit/dim 3.9427(3.9429) | Xent 1.1318(1.1427) | Loss 4.5086(4.5142) | Error 0.4051(0.4078) Steps 802(810.27) | Grad Norm 0.6881(1.0224) | Total Time 14.00(14.00)\n",
      "Iter 1869 | Time 74.5802(75.8506) | Bit/dim 3.9393(3.9428) | Xent 1.1489(1.1429) | Loss 4.5137(4.5142) | Error 0.4058(0.4078) Steps 808(810.20) | Grad Norm 0.9314(1.0197) | Total Time 14.00(14.00)\n",
      "Iter 1870 | Time 76.6863(75.8757) | Bit/dim 3.9415(3.9427) | Xent 1.1278(1.1424) | Loss 4.5054(4.5140) | Error 0.4029(0.4076) Steps 826(810.67) | Grad Norm 0.8011(1.0131) | Total Time 14.00(14.00)\n",
      "Iter 1871 | Time 73.4695(75.8035) | Bit/dim 3.9376(3.9426) | Xent 1.1569(1.1429) | Loss 4.5160(4.5140) | Error 0.4110(0.4077) Steps 820(810.95) | Grad Norm 0.6222(1.0014) | Total Time 14.00(14.00)\n",
      "Iter 1872 | Time 77.0372(75.8405) | Bit/dim 3.9432(3.9426) | Xent 1.1396(1.1428) | Loss 4.5130(4.5140) | Error 0.4123(0.4079) Steps 820(811.22) | Grad Norm 0.7576(0.9941) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 29.4220, Epoch Time 496.8265(493.4589), Bit/dim 3.9421(best: 3.9417), Xent 1.1050, Loss 4.4946, Error 0.3982(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1873 | Time 77.6730(75.8955) | Bit/dim 3.9397(3.9425) | Xent 1.1369(1.1426) | Loss 4.5082(4.5138) | Error 0.4009(0.4077) Steps 808(811.13) | Grad Norm 0.9162(0.9917) | Total Time 14.00(14.00)\n",
      "Iter 1874 | Time 76.6607(75.9185) | Bit/dim 3.9489(3.9427) | Xent 1.1454(1.1427) | Loss 4.5216(4.5141) | Error 0.4154(0.4079) Steps 826(811.57) | Grad Norm 0.9484(0.9904) | Total Time 14.00(14.00)\n",
      "Iter 1875 | Time 73.8824(75.8574) | Bit/dim 3.9412(3.9427) | Xent 1.1414(1.1427) | Loss 4.5119(4.5140) | Error 0.4044(0.4078) Steps 820(811.83) | Grad Norm 1.2927(0.9995) | Total Time 14.00(14.00)\n",
      "Iter 1876 | Time 77.8497(75.9171) | Bit/dim 3.9431(3.9427) | Xent 1.1310(1.1423) | Loss 4.5086(4.5138) | Error 0.4056(0.4077) Steps 808(811.71) | Grad Norm 0.8052(0.9937) | Total Time 14.00(14.00)\n",
      "Iter 1877 | Time 76.6721(75.9398) | Bit/dim 3.9333(3.9424) | Xent 1.1397(1.1422) | Loss 4.5032(4.5135) | Error 0.4025(0.4076) Steps 802(811.42) | Grad Norm 0.9009(0.9909) | Total Time 14.00(14.00)\n",
      "Iter 1878 | Time 74.7609(75.9044) | Bit/dim 3.9348(3.9422) | Xent 1.1312(1.1419) | Loss 4.5004(4.5131) | Error 0.4081(0.4076) Steps 802(811.14) | Grad Norm 1.3892(1.0028) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 29.4804, Epoch Time 502.5346(493.7312), Bit/dim 3.9411(best: 3.9417), Xent 1.1032, Loss 4.4927, Error 0.3951(best: 0.3963)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1879 | Time 76.0541(75.9089) | Bit/dim 3.9389(3.9421) | Xent 1.1402(1.1418) | Loss 4.5090(4.5130) | Error 0.4040(0.4075) Steps 808(811.04) | Grad Norm 1.0687(1.0048) | Total Time 14.00(14.00)\n",
      "Iter 1880 | Time 77.5981(75.9596) | Bit/dim 3.9440(3.9421) | Xent 1.1531(1.1422) | Loss 4.5205(4.5132) | Error 0.4080(0.4075) Steps 814(811.13) | Grad Norm 0.5680(0.9917) | Total Time 14.00(14.00)\n",
      "Iter 1881 | Time 78.7671(76.0438) | Bit/dim 3.9364(3.9420) | Xent 1.1406(1.1421) | Loss 4.5067(4.5130) | Error 0.4119(0.4076) Steps 820(811.40) | Grad Norm 0.7826(0.9854) | Total Time 14.00(14.00)\n",
      "Iter 1882 | Time 76.7584(76.0653) | Bit/dim 3.9335(3.9417) | Xent 1.1306(1.1418) | Loss 4.4988(4.5126) | Error 0.4039(0.4075) Steps 832(812.02) | Grad Norm 1.7311(1.0078) | Total Time 14.00(14.00)\n",
      "Iter 1883 | Time 77.1114(76.0966) | Bit/dim 3.9390(3.9416) | Xent 1.1380(1.1417) | Loss 4.5080(4.5125) | Error 0.4000(0.4073) Steps 826(812.44) | Grad Norm 1.8813(1.0340) | Total Time 14.00(14.00)\n",
      "Iter 1884 | Time 77.9285(76.1516) | Bit/dim 3.9517(3.9419) | Xent 1.1390(1.1416) | Loss 4.5212(4.5127) | Error 0.4061(0.4072) Steps 814(812.48) | Grad Norm 0.6658(1.0230) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 29.1608, Epoch Time 509.0223(494.1899), Bit/dim 3.9419(best: 3.9411), Xent 1.1020, Loss 4.4929, Error 0.3951(best: 0.3951)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1885 | Time 74.6309(76.1060) | Bit/dim 3.9492(3.9421) | Xent 1.1464(1.1417) | Loss 4.5223(4.5130) | Error 0.4141(0.4075) Steps 814(812.53) | Grad Norm 1.8630(1.0482) | Total Time 14.00(14.00)\n",
      "Iter 1886 | Time 75.3714(76.0839) | Bit/dim 3.9395(3.9421) | Xent 1.1489(1.1420) | Loss 4.5139(4.5130) | Error 0.4089(0.4075) Steps 814(812.57) | Grad Norm 0.9181(1.0443) | Total Time 14.00(14.00)\n",
      "Iter 1887 | Time 78.2761(76.1497) | Bit/dim 3.9430(3.9421) | Xent 1.1373(1.1418) | Loss 4.5117(4.5130) | Error 0.4009(0.4073) Steps 826(812.98) | Grad Norm 1.4891(1.0576) | Total Time 14.00(14.00)\n",
      "Iter 1888 | Time 77.1513(76.1798) | Bit/dim 3.9392(3.9420) | Xent 1.1204(1.1412) | Loss 4.4994(4.5126) | Error 0.3949(0.4069) Steps 814(813.01) | Grad Norm 1.1182(1.0594) | Total Time 14.00(14.00)\n",
      "Iter 1889 | Time 76.1854(76.1799) | Bit/dim 3.9320(3.9417) | Xent 1.1562(1.1416) | Loss 4.5101(4.5125) | Error 0.4149(0.4072) Steps 820(813.22) | Grad Norm 0.7996(1.0516) | Total Time 14.00(14.00)\n",
      "Iter 1890 | Time 76.3317(76.1845) | Bit/dim 3.9433(3.9417) | Xent 1.1194(1.1410) | Loss 4.5031(4.5122) | Error 0.3940(0.4068) Steps 826(813.60) | Grad Norm 0.8199(1.0447) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 29.1112, Epoch Time 502.7148(494.4457), Bit/dim 3.9416(best: 3.9411), Xent 1.1019, Loss 4.4926, Error 0.3977(best: 0.3951)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1891 | Time 77.4691(76.2230) | Bit/dim 3.9363(3.9416) | Xent 1.1332(1.1407) | Loss 4.5028(4.5119) | Error 0.4015(0.4066) Steps 814(813.61) | Grad Norm 1.4970(1.0582) | Total Time 14.00(14.00)\n",
      "Iter 1892 | Time 78.9413(76.3046) | Bit/dim 3.9498(3.9418) | Xent 1.1437(1.1408) | Loss 4.5217(4.5122) | Error 0.4020(0.4065) Steps 814(813.62) | Grad Norm 1.0059(1.0567) | Total Time 14.00(14.00)\n",
      "Iter 1893 | Time 78.2955(76.3643) | Bit/dim 3.9418(3.9418) | Xent 1.1119(1.1399) | Loss 4.4978(4.5118) | Error 0.3999(0.4063) Steps 832(814.17) | Grad Norm 0.8454(1.0503) | Total Time 14.00(14.00)\n",
      "Iter 1894 | Time 76.9644(76.3823) | Bit/dim 3.9419(3.9418) | Xent 1.1405(1.1400) | Loss 4.5121(4.5118) | Error 0.4064(0.4063) Steps 808(813.99) | Grad Norm 1.0304(1.0497) | Total Time 14.00(14.00)\n",
      "Iter 1895 | Time 76.3820(76.3823) | Bit/dim 3.9376(3.9417) | Xent 1.1333(1.1398) | Loss 4.5043(4.5116) | Error 0.4018(0.4061) Steps 820(814.17) | Grad Norm 1.0257(1.0490) | Total Time 14.00(14.00)\n",
      "Iter 1896 | Time 75.6964(76.3617) | Bit/dim 3.9365(3.9415) | Xent 1.1509(1.1401) | Loss 4.5119(4.5116) | Error 0.4101(0.4063) Steps 802(813.80) | Grad Norm 1.5118(1.0629) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 29.1761, Epoch Time 508.3773(494.8636), Bit/dim 3.9416(best: 3.9411), Xent 1.1001, Loss 4.4917, Error 0.3976(best: 0.3951)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1897 | Time 78.6185(76.4294) | Bit/dim 3.9356(3.9414) | Xent 1.1351(1.1399) | Loss 4.5031(4.5113) | Error 0.4095(0.4064) Steps 820(813.99) | Grad Norm 1.0771(1.0633) | Total Time 14.00(14.00)\n",
      "Iter 1898 | Time 78.2720(76.4847) | Bit/dim 3.9515(3.9417) | Xent 1.1354(1.1398) | Loss 4.5192(4.5116) | Error 0.4067(0.4064) Steps 808(813.81) | Grad Norm 1.1345(1.0655) | Total Time 14.00(14.00)\n",
      "Iter 1899 | Time 75.0247(76.4409) | Bit/dim 3.9411(3.9417) | Xent 1.1388(1.1398) | Loss 4.5105(4.5115) | Error 0.4085(0.4064) Steps 820(814.00) | Grad Norm 0.8080(1.0577) | Total Time 14.00(14.00)\n",
      "Iter 1900 | Time 76.9162(76.4551) | Bit/dim 3.9385(3.9416) | Xent 1.1252(1.1393) | Loss 4.5011(4.5112) | Error 0.4008(0.4063) Steps 814(814.00) | Grad Norm 1.4538(1.0696) | Total Time 14.00(14.00)\n",
      "Iter 1901 | Time 75.4527(76.4251) | Bit/dim 3.9398(3.9415) | Xent 1.1222(1.1388) | Loss 4.5009(4.5109) | Error 0.4021(0.4061) Steps 820(814.18) | Grad Norm 1.9215(1.0952) | Total Time 14.00(14.00)\n",
      "Iter 1902 | Time 78.3255(76.4821) | Bit/dim 3.9346(3.9413) | Xent 1.1243(1.1384) | Loss 4.4968(4.5105) | Error 0.4020(0.4060) Steps 808(813.99) | Grad Norm 0.6360(1.0814) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 29.3752, Epoch Time 507.4364(495.2408), Bit/dim 3.9406(best: 3.9411), Xent 1.1006, Loss 4.4909, Error 0.3979(best: 0.3951)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1903 | Time 75.3108(76.4469) | Bit/dim 3.9423(3.9413) | Xent 1.1221(1.1379) | Loss 4.5034(4.5103) | Error 0.3979(0.4058) Steps 814(813.99) | Grad Norm 1.8382(1.1041) | Total Time 14.00(14.00)\n",
      "Iter 1904 | Time 75.1891(76.4092) | Bit/dim 3.9412(3.9413) | Xent 1.1401(1.1380) | Loss 4.5112(4.5103) | Error 0.4010(0.4056) Steps 820(814.17) | Grad Norm 1.1802(1.1064) | Total Time 14.00(14.00)\n",
      "Iter 1905 | Time 81.2274(76.5538) | Bit/dim 3.9419(3.9413) | Xent 1.1342(1.1379) | Loss 4.5090(4.5103) | Error 0.4020(0.4055) Steps 808(813.99) | Grad Norm 1.7088(1.1245) | Total Time 14.00(14.00)\n",
      "Iter 1906 | Time 78.9271(76.6250) | Bit/dim 3.9302(3.9410) | Xent 1.1052(1.1369) | Loss 4.4829(4.5094) | Error 0.4020(0.4054) Steps 826(814.35) | Grad Norm 1.0228(1.1214) | Total Time 14.00(14.00)\n",
      "Iter 1907 | Time 79.8235(76.7209) | Bit/dim 3.9334(3.9408) | Xent 1.1469(1.1372) | Loss 4.5068(4.5094) | Error 0.4087(0.4055) Steps 808(814.16) | Grad Norm 1.5638(1.1347) | Total Time 14.00(14.00)\n",
      "Iter 1908 | Time 75.4908(76.6840) | Bit/dim 3.9511(3.9411) | Xent 1.1478(1.1375) | Loss 4.5250(4.5098) | Error 0.4134(0.4057) Steps 826(814.51) | Grad Norm 1.8346(1.1557) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 29.7352, Epoch Time 511.0776(495.7159), Bit/dim 3.9405(best: 3.9406), Xent 1.0992, Loss 4.4901, Error 0.3975(best: 0.3951)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1909 | Time 79.9747(76.7827) | Bit/dim 3.9464(3.9412) | Xent 1.1308(1.1373) | Loss 4.5118(4.5099) | Error 0.4036(0.4057) Steps 820(814.68) | Grad Norm 1.0735(1.1532) | Total Time 14.00(14.00)\n",
      "Iter 1910 | Time 79.2482(76.8567) | Bit/dim 3.9349(3.9411) | Xent 1.1457(1.1376) | Loss 4.5078(4.5098) | Error 0.4117(0.4059) Steps 814(814.66) | Grad Norm 0.6699(1.1387) | Total Time 14.00(14.00)\n",
      "Iter 1911 | Time 79.4580(76.9347) | Bit/dim 3.9383(3.9410) | Xent 1.1544(1.1381) | Loss 4.5155(4.5100) | Error 0.4071(0.4059) Steps 808(814.46) | Grad Norm 1.9888(1.1642) | Total Time 14.00(14.00)\n",
      "Iter 1912 | Time 74.4017(76.8587) | Bit/dim 3.9437(3.9411) | Xent 1.1557(1.1386) | Loss 4.5215(4.5104) | Error 0.4134(0.4061) Steps 808(814.26) | Grad Norm 1.5370(1.1754) | Total Time 14.00(14.00)\n",
      "Iter 1913 | Time 76.1672(76.8380) | Bit/dim 3.9308(3.9408) | Xent 1.1103(1.1377) | Loss 4.4860(4.5096) | Error 0.3948(0.4058) Steps 820(814.43) | Grad Norm 1.6478(1.1896) | Total Time 14.00(14.00)\n",
      "Iter 1914 | Time 76.6342(76.8319) | Bit/dim 3.9420(3.9408) | Xent 1.1214(1.1372) | Loss 4.5027(4.5094) | Error 0.4029(0.4057) Steps 826(814.78) | Grad Norm 1.8020(1.2080) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 29.3791, Epoch Time 510.8429(496.1697), Bit/dim 3.9405(best: 3.9405), Xent 1.1008, Loss 4.4909, Error 0.3974(best: 0.3951)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1915 | Time 77.3026(76.8460) | Bit/dim 3.9444(3.9409) | Xent 1.1239(1.1368) | Loss 4.5063(4.5093) | Error 0.3990(0.4055) Steps 820(814.94) | Grad Norm 2.0672(1.2337) | Total Time 14.00(14.00)\n",
      "Iter 1916 | Time 74.7110(76.7820) | Bit/dim 3.9266(3.9405) | Xent 1.1413(1.1370) | Loss 4.4972(4.5090) | Error 0.4095(0.4056) Steps 826(815.27) | Grad Norm 1.0330(1.2277) | Total Time 14.00(14.00)\n",
      "Iter 1917 | Time 79.2682(76.8565) | Bit/dim 3.9437(3.9406) | Xent 1.1432(1.1372) | Loss 4.5152(4.5091) | Error 0.4091(0.4057) Steps 820(815.41) | Grad Norm 0.8069(1.2151) | Total Time 14.00(14.00)\n",
      "Iter 1918 | Time 79.6315(76.9398) | Bit/dim 3.9425(3.9406) | Xent 1.1267(1.1368) | Loss 4.5058(4.5090) | Error 0.3968(0.4055) Steps 814(815.37) | Grad Norm 0.7755(1.2019) | Total Time 14.00(14.00)\n",
      "Iter 1919 | Time 78.4430(76.9849) | Bit/dim 3.9430(3.9407) | Xent 1.1435(1.1370) | Loss 4.5148(4.5092) | Error 0.4060(0.4055) Steps 814(815.33) | Grad Norm 1.2833(1.2043) | Total Time 14.00(14.00)\n",
      "Iter 1920 | Time 75.9751(76.9546) | Bit/dim 3.9383(3.9406) | Xent 1.1406(1.1372) | Loss 4.5086(4.5092) | Error 0.4048(0.4055) Steps 802(814.93) | Grad Norm 0.9439(1.1965) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 29.1927, Epoch Time 510.0290(496.5855), Bit/dim 3.9403(best: 3.9405), Xent 1.0977, Loss 4.4891, Error 0.3967(best: 0.3951)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1921 | Time 75.7106(76.9173) | Bit/dim 3.9411(3.9406) | Xent 1.1378(1.1372) | Loss 4.5100(4.5092) | Error 0.4089(0.4056) Steps 808(814.72) | Grad Norm 0.6716(1.1808) | Total Time 14.00(14.00)\n",
      "Iter 1922 | Time 74.9927(76.8595) | Bit/dim 3.9493(3.9409) | Xent 1.1233(1.1368) | Loss 4.5110(4.5093) | Error 0.4025(0.4055) Steps 814(814.70) | Grad Norm 1.2645(1.1833) | Total Time 14.00(14.00)\n",
      "Iter 1923 | Time 77.9251(76.8915) | Bit/dim 3.9401(3.9409) | Xent 1.1393(1.1368) | Loss 4.5098(4.5093) | Error 0.4040(0.4054) Steps 814(814.68) | Grad Norm 1.0027(1.1779) | Total Time 14.00(14.00)\n",
      "Iter 1924 | Time 78.3577(76.9355) | Bit/dim 3.9313(3.9406) | Xent 1.1429(1.1370) | Loss 4.5027(4.5091) | Error 0.4160(0.4057) Steps 814(814.66) | Grad Norm 0.7198(1.1641) | Total Time 14.00(14.00)\n",
      "Iter 1925 | Time 76.5231(76.9231) | Bit/dim 3.9459(3.9407) | Xent 1.1200(1.1365) | Loss 4.5059(4.5090) | Error 0.4000(0.4056) Steps 826(815.00) | Grad Norm 1.4385(1.1724) | Total Time 14.00(14.00)\n",
      "Iter 1926 | Time 76.0041(76.8955) | Bit/dim 3.9280(3.9404) | Xent 1.1293(1.1363) | Loss 4.4927(4.5085) | Error 0.4054(0.4056) Steps 814(814.97) | Grad Norm 0.8374(1.1623) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 29.8093, Epoch Time 504.8227(496.8326), Bit/dim 3.9398(best: 3.9403), Xent 1.0967, Loss 4.4881, Error 0.3938(best: 0.3951)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1927 | Time 76.2052(76.8748) | Bit/dim 3.9398(3.9403) | Xent 1.1454(1.1366) | Loss 4.5124(4.5086) | Error 0.4051(0.4055) Steps 826(815.30) | Grad Norm 1.2607(1.1653) | Total Time 14.00(14.00)\n",
      "Iter 1928 | Time 79.4583(76.9523) | Bit/dim 3.9402(3.9403) | Xent 1.1180(1.1360) | Loss 4.4992(4.5083) | Error 0.4012(0.4054) Steps 814(815.26) | Grad Norm 0.7402(1.1525) | Total Time 14.00(14.00)\n",
      "Iter 1929 | Time 77.8556(76.9794) | Bit/dim 3.9376(3.9403) | Xent 1.1304(1.1358) | Loss 4.5028(4.5082) | Error 0.3938(0.4051) Steps 820(815.40) | Grad Norm 0.6603(1.1377) | Total Time 14.00(14.00)\n",
      "Iter 1930 | Time 79.1086(77.0433) | Bit/dim 3.9324(3.9400) | Xent 1.1254(1.1355) | Loss 4.4950(4.5078) | Error 0.4026(0.4050) Steps 826(815.72) | Grad Norm 0.7592(1.1264) | Total Time 14.00(14.00)\n",
      "Iter 1931 | Time 77.0846(77.0445) | Bit/dim 3.9416(3.9401) | Xent 1.1420(1.1357) | Loss 4.5126(4.5079) | Error 0.4074(0.4051) Steps 802(815.31) | Grad Norm 0.8883(1.1192) | Total Time 14.00(14.00)\n",
      "Iter 1932 | Time 78.3040(77.0823) | Bit/dim 3.9410(3.9401) | Xent 1.1245(1.1354) | Loss 4.5033(4.5078) | Error 0.3958(0.4048) Steps 838(815.99) | Grad Norm 0.7564(1.1084) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 29.3658, Epoch Time 513.0070(497.3178), Bit/dim 3.9394(best: 3.9398), Xent 1.0962, Loss 4.4875, Error 0.3963(best: 0.3938)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1933 | Time 75.1790(77.0252) | Bit/dim 3.9367(3.9400) | Xent 1.1370(1.1354) | Loss 4.5052(4.5077) | Error 0.4070(0.4049) Steps 826(816.29) | Grad Norm 0.5867(1.0927) | Total Time 14.00(14.00)\n",
      "Iter 1934 | Time 80.7852(77.1380) | Bit/dim 3.9374(3.9399) | Xent 1.1308(1.1353) | Loss 4.5029(4.5076) | Error 0.3998(0.4047) Steps 826(816.58) | Grad Norm 1.1668(1.0949) | Total Time 14.00(14.00)\n",
      "Iter 1935 | Time 77.7459(77.1563) | Bit/dim 3.9381(3.9399) | Xent 1.1076(1.1345) | Loss 4.4919(4.5071) | Error 0.3981(0.4045) Steps 808(816.32) | Grad Norm 0.7646(1.0850) | Total Time 14.00(14.00)\n",
      "Iter 1936 | Time 76.0917(77.1243) | Bit/dim 3.9392(3.9398) | Xent 1.1136(1.1338) | Loss 4.4960(4.5068) | Error 0.3938(0.4042) Steps 808(816.07) | Grad Norm 0.8002(1.0765) | Total Time 14.00(14.00)\n",
      "Iter 1937 | Time 76.2005(77.0966) | Bit/dim 3.9391(3.9398) | Xent 1.1244(1.1335) | Loss 4.5013(4.5066) | Error 0.4018(0.4041) Steps 820(816.19) | Grad Norm 1.0651(1.0761) | Total Time 14.00(14.00)\n",
      "Iter 1938 | Time 79.5854(77.1713) | Bit/dim 3.9363(3.9397) | Xent 1.1193(1.1331) | Loss 4.4959(4.5063) | Error 0.4012(0.4040) Steps 820(816.31) | Grad Norm 1.1149(1.0773) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 29.1263, Epoch Time 510.3862(497.7099), Bit/dim 3.9397(best: 3.9394), Xent 1.0979, Loss 4.4887, Error 0.3962(best: 0.3938)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1939 | Time 77.4106(77.1785) | Bit/dim 3.9433(3.9398) | Xent 1.1440(1.1334) | Loss 4.5153(4.5065) | Error 0.4107(0.4042) Steps 808(816.06) | Grad Norm 0.8998(1.0720) | Total Time 14.00(14.00)\n",
      "Iter 1940 | Time 78.8953(77.2300) | Bit/dim 3.9254(3.9394) | Xent 1.1490(1.1339) | Loss 4.4998(4.5063) | Error 0.4090(0.4044) Steps 826(816.36) | Grad Norm 0.8963(1.0667) | Total Time 14.00(14.00)\n",
      "Iter 1941 | Time 80.3208(77.3227) | Bit/dim 3.9446(3.9395) | Xent 1.1167(1.1334) | Loss 4.5030(4.5062) | Error 0.3989(0.4042) Steps 832(816.82) | Grad Norm 0.7567(1.0574) | Total Time 14.00(14.00)\n",
      "Iter 1942 | Time 80.4824(77.4175) | Bit/dim 3.9325(3.9393) | Xent 1.1366(1.1335) | Loss 4.5008(4.5061) | Error 0.4059(0.4043) Steps 814(816.74) | Grad Norm 0.7863(1.0493) | Total Time 14.00(14.00)\n",
      "Iter 1943 | Time 77.3260(77.4147) | Bit/dim 3.9452(3.9395) | Xent 1.1134(1.1329) | Loss 4.5019(4.5060) | Error 0.3942(0.4040) Steps 808(816.48) | Grad Norm 0.6753(1.0381) | Total Time 14.00(14.00)\n",
      "Iter 1944 | Time 77.1211(77.4059) | Bit/dim 3.9378(3.9395) | Xent 1.1187(1.1325) | Loss 4.4972(4.5057) | Error 0.3955(0.4037) Steps 814(816.40) | Grad Norm 0.7736(1.0301) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 29.5251, Epoch Time 516.5141(498.2740), Bit/dim 3.9381(best: 3.9394), Xent 1.0956, Loss 4.4859, Error 0.3932(best: 0.3938)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1945 | Time 77.6725(77.4139) | Bit/dim 3.9299(3.9392) | Xent 1.1200(1.1321) | Loss 4.4899(4.5052) | Error 0.3995(0.4036) Steps 820(816.51) | Grad Norm 0.9622(1.0281) | Total Time 14.00(14.00)\n",
      "Iter 1946 | Time 78.8329(77.4565) | Bit/dim 3.9445(3.9393) | Xent 1.1359(1.1322) | Loss 4.5124(4.5054) | Error 0.4115(0.4038) Steps 808(816.26) | Grad Norm 1.1746(1.0325) | Total Time 14.00(14.00)\n",
      "Iter 1947 | Time 76.3265(77.4226) | Bit/dim 3.9511(3.9397) | Xent 1.1228(1.1319) | Loss 4.5125(4.5057) | Error 0.4012(0.4037) Steps 820(816.37) | Grad Norm 0.6799(1.0219) | Total Time 14.00(14.00)\n",
      "Iter 1948 | Time 73.9145(77.3173) | Bit/dim 3.9328(3.9395) | Xent 1.1336(1.1320) | Loss 4.4996(4.5055) | Error 0.4096(0.4039) Steps 820(816.48) | Grad Norm 1.4981(1.0362) | Total Time 14.00(14.00)\n",
      "Iter 1949 | Time 77.3127(77.3172) | Bit/dim 3.9402(3.9395) | Xent 1.1241(1.1317) | Loss 4.5023(4.5054) | Error 0.4022(0.4039) Steps 832(816.94) | Grad Norm 0.7654(1.0281) | Total Time 14.00(14.00)\n",
      "Iter 1950 | Time 78.6171(77.3562) | Bit/dim 3.9321(3.9393) | Xent 1.1227(1.1315) | Loss 4.4934(4.5050) | Error 0.4004(0.4038) Steps 820(817.03) | Grad Norm 1.3857(1.0388) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 29.3490, Epoch Time 507.6104(498.5541), Bit/dim 3.9386(best: 3.9381), Xent 1.0961, Loss 4.4867, Error 0.3916(best: 0.3932)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1951 | Time 77.3248(77.3553) | Bit/dim 3.9385(3.9393) | Xent 1.1208(1.1311) | Loss 4.4990(4.5048) | Error 0.3945(0.4035) Steps 808(816.76) | Grad Norm 1.4052(1.0498) | Total Time 14.00(14.00)\n",
      "Iter 1952 | Time 79.0831(77.4071) | Bit/dim 3.9371(3.9392) | Xent 1.1137(1.1306) | Loss 4.4939(4.5045) | Error 0.3951(0.4032) Steps 826(817.04) | Grad Norm 1.2502(1.0558) | Total Time 14.00(14.00)\n",
      "Iter 1953 | Time 75.5179(77.3504) | Bit/dim 3.9358(3.9391) | Xent 1.1274(1.1305) | Loss 4.4995(4.5044) | Error 0.3959(0.4030) Steps 826(817.31) | Grad Norm 1.5204(1.0697) | Total Time 14.00(14.00)\n",
      "Iter 1954 | Time 76.5797(77.3273) | Bit/dim 3.9314(3.9389) | Xent 1.1272(1.1304) | Loss 4.4950(4.5041) | Error 0.4075(0.4031) Steps 808(817.03) | Grad Norm 0.8827(1.0641) | Total Time 14.00(14.00)\n",
      "Iter 1955 | Time 77.3772(77.3288) | Bit/dim 3.9360(3.9388) | Xent 1.1471(1.1309) | Loss 4.5095(4.5042) | Error 0.4115(0.4034) Steps 808(816.76) | Grad Norm 1.6779(1.0825) | Total Time 14.00(14.00)\n",
      "Iter 1956 | Time 76.8208(77.3136) | Bit/dim 3.9467(3.9390) | Xent 1.1326(1.1310) | Loss 4.5130(4.5045) | Error 0.4036(0.4034) Steps 814(816.68) | Grad Norm 1.6580(1.0998) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 29.2813, Epoch Time 507.3033(498.8166), Bit/dim 3.9386(best: 3.9381), Xent 1.0928, Loss 4.4850, Error 0.3949(best: 0.3916)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1957 | Time 78.3820(77.3456) | Bit/dim 3.9349(3.9389) | Xent 1.1259(1.1308) | Loss 4.4978(4.5043) | Error 0.4020(0.4034) Steps 820(816.78) | Grad Norm 1.1497(1.1013) | Total Time 14.00(14.00)\n",
      "Iter 1958 | Time 77.2807(77.3437) | Bit/dim 3.9459(3.9391) | Xent 1.1312(1.1308) | Loss 4.5115(4.5045) | Error 0.4032(0.4034) Steps 808(816.51) | Grad Norm 1.2692(1.1063) | Total Time 14.00(14.00)\n",
      "Iter 1959 | Time 75.7601(77.2962) | Bit/dim 3.9367(3.9390) | Xent 1.1457(1.1313) | Loss 4.5096(4.5047) | Error 0.4061(0.4034) Steps 826(816.80) | Grad Norm 1.7740(1.1264) | Total Time 14.00(14.00)\n",
      "Iter 1960 | Time 78.2296(77.3242) | Bit/dim 3.9259(3.9386) | Xent 1.1357(1.1314) | Loss 4.4938(4.5043) | Error 0.4103(0.4036) Steps 826(817.07) | Grad Norm 1.4624(1.1365) | Total Time 14.00(14.00)\n",
      "Iter 1961 | Time 77.0487(77.3159) | Bit/dim 3.9415(3.9387) | Xent 1.1200(1.1311) | Loss 4.5015(4.5043) | Error 0.3974(0.4035) Steps 814(816.98) | Grad Norm 0.7368(1.1245) | Total Time 14.00(14.00)\n",
      "Iter 1962 | Time 77.9001(77.3334) | Bit/dim 3.9379(3.9387) | Xent 1.1169(1.1306) | Loss 4.4963(4.5040) | Error 0.4051(0.4035) Steps 826(817.25) | Grad Norm 1.1602(1.1255) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 29.5630, Epoch Time 509.6875(499.1427), Bit/dim 3.9378(best: 3.9381), Xent 1.0934, Loss 4.4845, Error 0.3925(best: 0.3916)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1963 | Time 80.8319(77.4384) | Bit/dim 3.9287(3.9384) | Xent 1.1278(1.1306) | Loss 4.4926(4.5037) | Error 0.4015(0.4034) Steps 832(817.69) | Grad Norm 1.9615(1.1506) | Total Time 14.00(14.00)\n",
      "Iter 1964 | Time 79.2746(77.4935) | Bit/dim 3.9415(3.9385) | Xent 1.1155(1.1301) | Loss 4.4992(4.5035) | Error 0.3962(0.4032) Steps 832(818.12) | Grad Norm 0.8059(1.1403) | Total Time 14.00(14.00)\n",
      "Iter 1965 | Time 78.7057(77.5298) | Bit/dim 3.9422(3.9386) | Xent 1.1139(1.1296) | Loss 4.4992(4.5034) | Error 0.3990(0.4031) Steps 814(818.00) | Grad Norm 1.4815(1.1505) | Total Time 14.00(14.00)\n",
      "Iter 1966 | Time 77.4459(77.5273) | Bit/dim 3.9285(3.9383) | Xent 1.1451(1.1301) | Loss 4.5011(4.5033) | Error 0.4069(0.4032) Steps 820(818.06) | Grad Norm 0.7573(1.1387) | Total Time 14.00(14.00)\n",
      "Iter 1967 | Time 78.7077(77.5627) | Bit/dim 3.9318(3.9381) | Xent 1.1200(1.1298) | Loss 4.4918(4.5030) | Error 0.3970(0.4030) Steps 820(818.12) | Grad Norm 1.0915(1.1373) | Total Time 14.00(14.00)\n",
      "Iter 1968 | Time 79.1944(77.6117) | Bit/dim 3.9465(3.9384) | Xent 1.1391(1.1301) | Loss 4.5160(4.5034) | Error 0.4034(0.4030) Steps 826(818.35) | Grad Norm 0.9079(1.1304) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 29.6572, Epoch Time 519.3521(499.7490), Bit/dim 3.9378(best: 3.9378), Xent 1.0919, Loss 4.4837, Error 0.3916(best: 0.3916)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1969 | Time 77.7125(77.6147) | Bit/dim 3.9309(3.9381) | Xent 1.1400(1.1304) | Loss 4.5009(4.5033) | Error 0.4095(0.4032) Steps 826(818.58) | Grad Norm 0.7054(1.1177) | Total Time 14.00(14.00)\n",
      "Iter 1970 | Time 79.6205(77.6749) | Bit/dim 3.9381(3.9381) | Xent 1.1052(1.1296) | Loss 4.4907(4.5029) | Error 0.3918(0.4029) Steps 808(818.27) | Grad Norm 0.8489(1.1096) | Total Time 14.00(14.00)\n",
      "Iter 1971 | Time 78.7670(77.7076) | Bit/dim 3.9239(3.9377) | Xent 1.1192(1.1293) | Loss 4.4835(4.5023) | Error 0.3955(0.4027) Steps 820(818.32) | Grad Norm 0.7835(1.0998) | Total Time 14.00(14.00)\n",
      "Iter 1972 | Time 77.2940(77.6952) | Bit/dim 3.9329(3.9376) | Xent 1.1410(1.1296) | Loss 4.5033(4.5024) | Error 0.4100(0.4029) Steps 832(818.73) | Grad Norm 0.7106(1.0881) | Total Time 14.00(14.00)\n",
      "Iter 1973 | Time 79.1174(77.7379) | Bit/dim 3.9468(3.9378) | Xent 1.1199(1.1294) | Loss 4.5068(4.5025) | Error 0.3991(0.4028) Steps 820(818.77) | Grad Norm 0.7833(1.0790) | Total Time 14.00(14.00)\n",
      "Iter 1974 | Time 78.6289(77.7646) | Bit/dim 3.9458(3.9381) | Xent 1.1272(1.1293) | Loss 4.5094(4.5027) | Error 0.3976(0.4026) Steps 820(818.80) | Grad Norm 1.2108(1.0829) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 29.1770, Epoch Time 516.4035(500.2486), Bit/dim 3.9376(best: 3.9378), Xent 1.0929, Loss 4.4840, Error 0.3898(best: 0.3916)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1975 | Time 76.8355(77.7367) | Bit/dim 3.9386(3.9381) | Xent 1.1199(1.1290) | Loss 4.4985(4.5026) | Error 0.4005(0.4026) Steps 820(818.84) | Grad Norm 0.7114(1.0718) | Total Time 14.00(14.00)\n",
      "Iter 1976 | Time 75.9326(77.6826) | Bit/dim 3.9321(3.9379) | Xent 1.1229(1.1288) | Loss 4.4936(4.5023) | Error 0.3976(0.4024) Steps 832(819.23) | Grad Norm 1.8598(1.0954) | Total Time 14.00(14.00)\n",
      "Iter 1977 | Time 77.6372(77.6813) | Bit/dim 3.9380(3.9379) | Xent 1.1347(1.1290) | Loss 4.5053(4.5024) | Error 0.4058(0.4025) Steps 832(819.62) | Grad Norm 1.2117(1.0989) | Total Time 14.00(14.00)\n",
      "Iter 1978 | Time 75.9100(77.6281) | Bit/dim 3.9470(3.9382) | Xent 1.1237(1.1288) | Loss 4.5088(4.5026) | Error 0.4022(0.4025) Steps 832(819.99) | Grad Norm 0.8224(1.0906) | Total Time 14.00(14.00)\n",
      "Iter 1979 | Time 78.2723(77.6474) | Bit/dim 3.9343(3.9381) | Xent 1.1228(1.1287) | Loss 4.4957(4.5024) | Error 0.3996(0.4024) Steps 820(819.99) | Grad Norm 1.9178(1.1154) | Total Time 14.00(14.00)\n",
      "Iter 1980 | Time 78.0840(77.6605) | Bit/dim 3.9318(3.9379) | Xent 1.1297(1.1287) | Loss 4.4966(4.5022) | Error 0.4054(0.4025) Steps 820(819.99) | Grad Norm 1.1250(1.1157) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 29.1918, Epoch Time 507.1977(500.4571), Bit/dim 3.9382(best: 3.9376), Xent 1.0915, Loss 4.4840, Error 0.3909(best: 0.3898)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1981 | Time 77.0127(77.6411) | Bit/dim 3.9406(3.9380) | Xent 1.1108(1.1282) | Loss 4.4960(4.5020) | Error 0.4005(0.4024) Steps 808(819.63) | Grad Norm 0.6005(1.1003) | Total Time 14.00(14.00)\n",
      "Iter 1982 | Time 76.7981(77.6158) | Bit/dim 3.9458(3.9382) | Xent 1.1370(1.1284) | Loss 4.5143(4.5024) | Error 0.4101(0.4027) Steps 820(819.64) | Grad Norm 0.7751(1.0905) | Total Time 14.00(14.00)\n",
      "Iter 1983 | Time 77.5993(77.6153) | Bit/dim 3.9215(3.9377) | Xent 1.1139(1.1280) | Loss 4.4785(4.5017) | Error 0.3988(0.4026) Steps 832(820.01) | Grad Norm 1.8121(1.1122) | Total Time 14.00(14.00)\n",
      "Iter 1984 | Time 78.5616(77.6437) | Bit/dim 3.9380(3.9377) | Xent 1.1260(1.1279) | Loss 4.5010(4.5017) | Error 0.4000(0.4025) Steps 826(820.19) | Grad Norm 0.7987(1.1028) | Total Time 14.00(14.00)\n",
      "Iter 1985 | Time 79.6048(77.7025) | Bit/dim 3.9322(3.9375) | Xent 1.1187(1.1276) | Loss 4.4916(4.5014) | Error 0.3960(0.4023) Steps 826(820.37) | Grad Norm 1.0032(1.0998) | Total Time 14.00(14.00)\n",
      "Iter 1986 | Time 77.8399(77.7067) | Bit/dim 3.9370(3.9375) | Xent 1.1399(1.1280) | Loss 4.5069(4.5015) | Error 0.4052(0.4024) Steps 826(820.53) | Grad Norm 1.4919(1.1115) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 29.2214, Epoch Time 512.2036(500.8095), Bit/dim 3.9377(best: 3.9376), Xent 1.0909, Loss 4.4832, Error 0.3924(best: 0.3898)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1987 | Time 80.8859(77.8020) | Bit/dim 3.9373(3.9375) | Xent 1.1332(1.1282) | Loss 4.5039(4.5016) | Error 0.4071(0.4025) Steps 826(820.70) | Grad Norm 1.7634(1.1311) | Total Time 14.00(14.00)\n",
      "Iter 1988 | Time 76.3445(77.7583) | Bit/dim 3.9425(3.9377) | Xent 1.1174(1.1278) | Loss 4.5012(4.5016) | Error 0.4028(0.4025) Steps 808(820.32) | Grad Norm 0.6793(1.1175) | Total Time 14.00(14.00)\n",
      "Iter 1989 | Time 75.3107(77.6849) | Bit/dim 3.9269(3.9373) | Xent 1.1295(1.1279) | Loss 4.4917(4.5013) | Error 0.4067(0.4026) Steps 832(820.67) | Grad Norm 1.1173(1.1175) | Total Time 14.00(14.00)\n",
      "Iter 1990 | Time 77.6352(77.6834) | Bit/dim 3.9404(3.9374) | Xent 1.1169(1.1276) | Loss 4.4989(4.5012) | Error 0.4040(0.4027) Steps 820(820.65) | Grad Norm 2.0489(1.1455) | Total Time 14.00(14.00)\n",
      "Iter 1991 | Time 79.7791(77.7463) | Bit/dim 3.9380(3.9375) | Xent 1.1464(1.1281) | Loss 4.5112(4.5015) | Error 0.4073(0.4028) Steps 838(821.17) | Grad Norm 1.1221(1.1448) | Total Time 14.00(14.00)\n",
      "Iter 1992 | Time 78.3062(77.7631) | Bit/dim 3.9337(3.9373) | Xent 1.1313(1.1282) | Loss 4.4994(4.5015) | Error 0.4044(0.4029) Steps 826(821.31) | Grad Norm 2.1553(1.1751) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 29.7987, Epoch Time 513.6418(501.1945), Bit/dim 3.9371(best: 3.9376), Xent 1.0900, Loss 4.4821, Error 0.3915(best: 0.3898)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1993 | Time 79.8011(77.8242) | Bit/dim 3.9358(3.9373) | Xent 1.1339(1.1284) | Loss 4.5027(4.5015) | Error 0.4041(0.4029) Steps 826(821.45) | Grad Norm 1.2110(1.1762) | Total Time 14.00(14.00)\n",
      "Iter 1994 | Time 77.5371(77.8156) | Bit/dim 3.9435(3.9375) | Xent 1.1092(1.1278) | Loss 4.4981(4.5014) | Error 0.3872(0.4024) Steps 826(821.59) | Grad Norm 0.9456(1.1693) | Total Time 14.00(14.00)\n",
      "Iter 1995 | Time 78.7405(77.8433) | Bit/dim 3.9350(3.9374) | Xent 1.1442(1.1283) | Loss 4.5072(4.5016) | Error 0.4123(0.4027) Steps 820(821.54) | Grad Norm 1.2881(1.1728) | Total Time 14.00(14.00)\n",
      "Iter 1996 | Time 79.1334(77.8820) | Bit/dim 3.9324(3.9373) | Xent 1.1201(1.1281) | Loss 4.4924(4.5013) | Error 0.4008(0.4027) Steps 826(821.68) | Grad Norm 1.1039(1.1707) | Total Time 14.00(14.00)\n",
      "Iter 1997 | Time 77.8990(77.8826) | Bit/dim 3.9284(3.9370) | Xent 1.1267(1.1280) | Loss 4.4917(4.5010) | Error 0.4040(0.4027) Steps 832(821.99) | Grad Norm 1.4028(1.1777) | Total Time 14.00(14.00)\n",
      "Iter 1998 | Time 79.6146(77.9345) | Bit/dim 3.9420(3.9371) | Xent 1.1025(1.1273) | Loss 4.4932(4.5008) | Error 0.3922(0.4024) Steps 832(822.29) | Grad Norm 1.3255(1.1821) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 29.5226, Epoch Time 517.9188(501.6962), Bit/dim 3.9376(best: 3.9371), Xent 1.0907, Loss 4.4829, Error 0.3904(best: 0.3898)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 1999 | Time 77.1027(77.9096) | Bit/dim 3.9391(3.9372) | Xent 1.1141(1.1269) | Loss 4.4961(4.5006) | Error 0.3972(0.4022) Steps 832(822.58) | Grad Norm 1.0037(1.1768) | Total Time 14.00(14.00)\n",
      "Iter 2000 | Time 76.8691(77.8783) | Bit/dim 3.9305(3.9370) | Xent 1.1268(1.1269) | Loss 4.4939(4.5004) | Error 0.4024(0.4023) Steps 820(822.50) | Grad Norm 1.0115(1.1718) | Total Time 14.00(14.00)\n",
      "Iter 2001 | Time 78.7961(77.9059) | Bit/dim 3.9254(3.9367) | Xent 1.1313(1.1270) | Loss 4.4911(4.5001) | Error 0.4009(0.4022) Steps 832(822.79) | Grad Norm 0.8272(1.1615) | Total Time 14.00(14.00)\n",
      "Iter 2002 | Time 78.2036(77.9148) | Bit/dim 3.9365(3.9366) | Xent 1.1166(1.1267) | Loss 4.4948(4.5000) | Error 0.4018(0.4022) Steps 826(822.88) | Grad Norm 1.2270(1.1635) | Total Time 14.00(14.00)\n",
      "Iter 2003 | Time 80.1027(77.9804) | Bit/dim 3.9447(3.9369) | Xent 1.1255(1.1267) | Loss 4.5074(4.5002) | Error 0.3892(0.4018) Steps 832(823.16) | Grad Norm 1.5922(1.1763) | Total Time 14.00(14.00)\n",
      "Iter 2004 | Time 77.6836(77.9715) | Bit/dim 3.9401(3.9370) | Xent 1.1300(1.1268) | Loss 4.5051(4.5004) | Error 0.4040(0.4019) Steps 832(823.42) | Grad Norm 0.9766(1.1703) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 28.9508, Epoch Time 513.1551(502.0400), Bit/dim 3.9359(best: 3.9371), Xent 1.0879, Loss 4.4799, Error 0.3920(best: 0.3898)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2005 | Time 78.9507(78.0009) | Bit/dim 3.9389(3.9370) | Xent 1.1550(1.1276) | Loss 4.5164(4.5008) | Error 0.4123(0.4022) Steps 832(823.68) | Grad Norm 1.4655(1.1792) | Total Time 14.00(14.00)\n",
      "Iter 2006 | Time 80.4910(78.0756) | Bit/dim 3.9302(3.9368) | Xent 1.1258(1.1275) | Loss 4.4931(4.5006) | Error 0.4022(0.4022) Steps 826(823.75) | Grad Norm 1.2679(1.1818) | Total Time 14.00(14.00)\n",
      "Iter 2007 | Time 77.5622(78.0602) | Bit/dim 3.9357(3.9368) | Xent 1.1163(1.1272) | Loss 4.4938(4.5004) | Error 0.3990(0.4021) Steps 832(824.00) | Grad Norm 0.7071(1.1676) | Total Time 14.00(14.00)\n",
      "Iter 2008 | Time 76.7692(78.0215) | Bit/dim 3.9347(3.9367) | Xent 1.1086(1.1266) | Loss 4.4890(4.5001) | Error 0.3910(0.4018) Steps 814(823.70) | Grad Norm 1.0930(1.1654) | Total Time 14.00(14.00)\n",
      "Iter 2009 | Time 79.4351(78.0639) | Bit/dim 3.9367(3.9367) | Xent 1.1101(1.1262) | Loss 4.4918(4.4998) | Error 0.3959(0.4016) Steps 820(823.58) | Grad Norm 0.7370(1.1525) | Total Time 14.00(14.00)\n",
      "Iter 2010 | Time 79.1352(78.0960) | Bit/dim 3.9320(3.9366) | Xent 1.1147(1.1258) | Loss 4.4893(4.4995) | Error 0.3932(0.4013) Steps 826(823.66) | Grad Norm 1.1323(1.1519) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 29.2737, Epoch Time 516.9623(502.4876), Bit/dim 3.9360(best: 3.9359), Xent 1.0874, Loss 4.4797, Error 0.3910(best: 0.3898)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2011 | Time 78.1962(78.0990) | Bit/dim 3.9358(3.9366) | Xent 1.1130(1.1254) | Loss 4.4924(4.4993) | Error 0.3938(0.4011) Steps 826(823.73) | Grad Norm 0.8894(1.1440) | Total Time 14.00(14.00)\n",
      "Iter 2012 | Time 77.3966(78.0780) | Bit/dim 3.9223(3.9361) | Xent 1.1285(1.1255) | Loss 4.4866(4.4989) | Error 0.4040(0.4012) Steps 802(823.08) | Grad Norm 0.9796(1.1391) | Total Time 14.00(14.00)\n",
      "Iter 2013 | Time 78.8737(78.1018) | Bit/dim 3.9405(3.9363) | Xent 1.1356(1.1258) | Loss 4.5083(4.4992) | Error 0.4042(0.4013) Steps 820(822.98) | Grad Norm 0.9237(1.1326) | Total Time 14.00(14.00)\n",
      "Iter 2014 | Time 75.0463(78.0102) | Bit/dim 3.9377(3.9363) | Xent 1.1083(1.1253) | Loss 4.4919(4.4990) | Error 0.4014(0.4013) Steps 832(823.25) | Grad Norm 1.9124(1.1560) | Total Time 14.00(14.00)\n",
      "Iter 2015 | Time 77.8563(78.0056) | Bit/dim 3.9355(3.9363) | Xent 1.1301(1.1254) | Loss 4.5006(4.4990) | Error 0.4011(0.4013) Steps 826(823.34) | Grad Norm 1.3788(1.1627) | Total Time 14.00(14.00)\n",
      "Iter 2016 | Time 80.4056(78.0776) | Bit/dim 3.9315(3.9362) | Xent 1.1154(1.1251) | Loss 4.4892(4.4987) | Error 0.3998(0.4012) Steps 826(823.42) | Grad Norm 1.0974(1.1607) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 29.5528, Epoch Time 513.0931(502.8058), Bit/dim 3.9361(best: 3.9359), Xent 1.0886, Loss 4.4804, Error 0.3918(best: 0.3898)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2017 | Time 77.4654(78.0592) | Bit/dim 3.9289(3.9359) | Xent 1.1119(1.1247) | Loss 4.4849(4.4983) | Error 0.3971(0.4011) Steps 814(823.13) | Grad Norm 1.8892(1.1826) | Total Time 14.00(14.00)\n",
      "Iter 2018 | Time 79.7805(78.1108) | Bit/dim 3.9429(3.9361) | Xent 1.1366(1.1251) | Loss 4.5112(4.4987) | Error 0.4090(0.4013) Steps 826(823.22) | Grad Norm 1.1264(1.1809) | Total Time 14.00(14.00)\n",
      "Iter 2019 | Time 76.3668(78.0585) | Bit/dim 3.9312(3.9360) | Xent 1.1114(1.1247) | Loss 4.4869(4.4983) | Error 0.4000(0.4013) Steps 826(823.30) | Grad Norm 0.7306(1.1674) | Total Time 14.00(14.00)\n",
      "Iter 2020 | Time 78.3551(78.0674) | Bit/dim 3.9322(3.9359) | Xent 1.1131(1.1243) | Loss 4.4888(4.4981) | Error 0.3914(0.4010) Steps 808(822.84) | Grad Norm 1.5721(1.1795) | Total Time 14.00(14.00)\n",
      "Iter 2021 | Time 78.8845(78.0919) | Bit/dim 3.9302(3.9357) | Xent 1.1323(1.1246) | Loss 4.4963(4.4980) | Error 0.4096(0.4013) Steps 820(822.76) | Grad Norm 1.3466(1.1846) | Total Time 14.00(14.00)\n",
      "Iter 2022 | Time 75.7370(78.0213) | Bit/dim 3.9449(3.9360) | Xent 1.1131(1.1242) | Loss 4.5015(4.4981) | Error 0.3998(0.4012) Steps 814(822.50) | Grad Norm 0.5981(1.1670) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 29.2620, Epoch Time 511.1142(503.0550), Bit/dim 3.9361(best: 3.9359), Xent 1.0869, Loss 4.4796, Error 0.3898(best: 0.3898)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2023 | Time 79.7382(78.0728) | Bit/dim 3.9346(3.9359) | Xent 1.1010(1.1235) | Loss 4.4851(4.4977) | Error 0.3936(0.4010) Steps 814(822.24) | Grad Norm 1.0917(1.1647) | Total Time 14.00(14.00)\n",
      "Iter 2024 | Time 78.6767(78.0909) | Bit/dim 3.9323(3.9358) | Xent 1.1109(1.1232) | Loss 4.4878(4.4974) | Error 0.4034(0.4011) Steps 820(822.17) | Grad Norm 1.0426(1.1610) | Total Time 14.00(14.00)\n",
      "Iter 2025 | Time 75.9435(78.0265) | Bit/dim 3.9363(3.9359) | Xent 1.1259(1.1232) | Loss 4.4993(4.4975) | Error 0.4004(0.4010) Steps 820(822.11) | Grad Norm 0.7253(1.1480) | Total Time 14.00(14.00)\n",
      "Iter 2026 | Time 76.6438(77.9850) | Bit/dim 3.9346(3.9358) | Xent 1.0995(1.1225) | Loss 4.4844(4.4971) | Error 0.3920(0.4008) Steps 820(822.05) | Grad Norm 1.0105(1.1438) | Total Time 14.00(14.00)\n",
      "Iter 2027 | Time 74.7914(77.8892) | Bit/dim 3.9311(3.9357) | Xent 1.1263(1.1226) | Loss 4.4942(4.4970) | Error 0.3996(0.4007) Steps 826(822.16) | Grad Norm 1.8094(1.1638) | Total Time 14.00(14.00)\n",
      "Iter 2028 | Time 80.8793(77.9789) | Bit/dim 3.9381(3.9357) | Xent 1.1172(1.1225) | Loss 4.4967(4.4970) | Error 0.3970(0.4006) Steps 808(821.74) | Grad Norm 1.2351(1.1660) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 28.8411, Epoch Time 511.2339(503.3004), Bit/dim 3.9352(best: 3.9359), Xent 1.0837, Loss 4.4771, Error 0.3875(best: 0.3898)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2029 | Time 79.8245(78.0343) | Bit/dim 3.9289(3.9355) | Xent 1.1136(1.1222) | Loss 4.4857(4.4966) | Error 0.3986(0.4006) Steps 820(821.69) | Grad Norm 1.0540(1.1626) | Total Time 14.00(14.00)\n",
      "Iter 2030 | Time 78.5192(78.0488) | Bit/dim 3.9274(3.9353) | Xent 1.1330(1.1225) | Loss 4.4939(4.4966) | Error 0.4030(0.4006) Steps 832(822.00) | Grad Norm 1.2370(1.1648) | Total Time 14.00(14.00)\n",
      "Iter 2031 | Time 78.7961(78.0712) | Bit/dim 3.9451(3.9356) | Xent 1.1347(1.1229) | Loss 4.5125(4.4970) | Error 0.4080(0.4009) Steps 814(821.76) | Grad Norm 1.2326(1.1669) | Total Time 14.00(14.00)\n",
      "Iter 2032 | Time 79.6314(78.1180) | Bit/dim 3.9441(3.9358) | Xent 1.1193(1.1228) | Loss 4.5037(4.4972) | Error 0.3996(0.4008) Steps 808(821.34) | Grad Norm 0.9472(1.1603) | Total Time 14.00(14.00)\n",
      "Iter 2033 | Time 77.0768(78.0868) | Bit/dim 3.9187(3.9353) | Xent 1.1295(1.1230) | Loss 4.4835(4.4968) | Error 0.4016(0.4008) Steps 820(821.30) | Grad Norm 1.1447(1.1598) | Total Time 14.00(14.00)\n",
      "Iter 2034 | Time 77.5568(78.0709) | Bit/dim 3.9385(3.9354) | Xent 1.1004(1.1223) | Loss 4.4887(4.4966) | Error 0.3952(0.4007) Steps 832(821.62) | Grad Norm 0.7935(1.1488) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 29.4284, Epoch Time 516.2213(503.6880), Bit/dim 3.9357(best: 3.9352), Xent 1.0847, Loss 4.4780, Error 0.3933(best: 0.3875)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2035 | Time 77.9009(78.0658) | Bit/dim 3.9236(3.9351) | Xent 1.1178(1.1222) | Loss 4.4825(4.4962) | Error 0.4083(0.4009) Steps 832(821.94) | Grad Norm 1.2311(1.1513) | Total Time 14.00(14.00)\n",
      "Iter 2036 | Time 80.1443(78.1282) | Bit/dim 3.9307(3.9349) | Xent 1.1156(1.1220) | Loss 4.4885(4.4959) | Error 0.3911(0.4006) Steps 826(822.06) | Grad Norm 1.5295(1.1626) | Total Time 14.00(14.00)\n",
      "Iter 2037 | Time 77.0243(78.0950) | Bit/dim 3.9362(3.9350) | Xent 1.1220(1.1220) | Loss 4.4972(4.4960) | Error 0.3954(0.4005) Steps 826(822.18) | Grad Norm 0.7406(1.1500) | Total Time 14.00(14.00)\n",
      "Iter 2038 | Time 80.0050(78.1523) | Bit/dim 3.9469(3.9353) | Xent 1.1141(1.1218) | Loss 4.5039(4.4962) | Error 0.4012(0.4005) Steps 802(821.57) | Grad Norm 0.8077(1.1397) | Total Time 14.00(14.00)\n",
      "Iter 2039 | Time 78.2720(78.1559) | Bit/dim 3.9321(3.9352) | Xent 1.1384(1.1222) | Loss 4.5012(4.4964) | Error 0.4067(0.4007) Steps 802(820.98) | Grad Norm 1.0884(1.1382) | Total Time 14.00(14.00)\n",
      "Iter 2040 | Time 79.6074(78.1995) | Bit/dim 3.9353(3.9352) | Xent 1.1141(1.1220) | Loss 4.4924(4.4962) | Error 0.3948(0.4005) Steps 814(820.77) | Grad Norm 0.9777(1.1333) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 29.4289, Epoch Time 517.9307(504.1153), Bit/dim 3.9348(best: 3.9352), Xent 1.0826, Loss 4.4761, Error 0.3865(best: 0.3875)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2041 | Time 77.3391(78.1737) | Bit/dim 3.9359(3.9353) | Xent 1.1167(1.1218) | Loss 4.4942(4.4962) | Error 0.3990(0.4004) Steps 832(821.11) | Grad Norm 1.5950(1.1472) | Total Time 14.00(14.00)\n",
      "Iter 2042 | Time 78.6248(78.1872) | Bit/dim 3.9179(3.9347) | Xent 1.1150(1.1216) | Loss 4.4755(4.4956) | Error 0.3979(0.4004) Steps 820(821.08) | Grad Norm 1.0730(1.1450) | Total Time 14.00(14.00)\n",
      "Iter 2043 | Time 80.3080(78.2508) | Bit/dim 3.9428(3.9350) | Xent 1.1266(1.1218) | Loss 4.5061(4.4959) | Error 0.4011(0.4004) Steps 820(821.05) | Grad Norm 0.9563(1.1393) | Total Time 14.00(14.00)\n",
      "Iter 2044 | Time 78.5861(78.2609) | Bit/dim 3.9279(3.9348) | Xent 1.1310(1.1221) | Loss 4.4933(4.4958) | Error 0.3974(0.4003) Steps 832(821.37) | Grad Norm 1.3199(1.1447) | Total Time 14.00(14.00)\n",
      "Iter 2045 | Time 79.7309(78.3050) | Bit/dim 3.9397(3.9349) | Xent 1.1170(1.1219) | Loss 4.4982(4.4959) | Error 0.3960(0.4002) Steps 820(821.33) | Grad Norm 0.9686(1.1394) | Total Time 14.00(14.00)\n",
      "Iter 2046 | Time 77.8178(78.2904) | Bit/dim 3.9328(3.9349) | Xent 1.1192(1.1218) | Loss 4.4924(4.4958) | Error 0.3985(0.4001) Steps 826(821.47) | Grad Norm 0.8216(1.1299) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 29.5910, Epoch Time 517.6763(504.5221), Bit/dim 3.9354(best: 3.9348), Xent 1.0849, Loss 4.4778, Error 0.3878(best: 0.3865)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2047 | Time 75.9854(78.2212) | Bit/dim 3.9344(3.9348) | Xent 1.1031(1.1213) | Loss 4.4859(4.4955) | Error 0.3899(0.3998) Steps 826(821.61) | Grad Norm 1.3520(1.1366) | Total Time 14.00(14.00)\n",
      "Iter 2048 | Time 79.2081(78.2508) | Bit/dim 3.9375(3.9349) | Xent 1.1275(1.1215) | Loss 4.5012(4.4956) | Error 0.3989(0.3998) Steps 832(821.92) | Grad Norm 1.1216(1.1361) | Total Time 14.00(14.00)\n",
      "Iter 2049 | Time 78.8992(78.2703) | Bit/dim 3.9297(3.9348) | Xent 1.1058(1.1210) | Loss 4.4826(4.4953) | Error 0.3932(0.3996) Steps 832(822.22) | Grad Norm 0.8460(1.1274) | Total Time 14.00(14.00)\n",
      "Iter 2050 | Time 79.5805(78.3096) | Bit/dim 3.9391(3.9349) | Xent 1.1198(1.1210) | Loss 4.4990(4.4954) | Error 0.3978(0.3995) Steps 814(821.98) | Grad Norm 0.9117(1.1209) | Total Time 14.00(14.00)\n",
      "Iter 2051 | Time 78.4423(78.3136) | Bit/dim 3.9334(3.9348) | Xent 1.1194(1.1209) | Loss 4.4931(4.4953) | Error 0.4014(0.3996) Steps 832(822.28) | Grad Norm 1.0666(1.1193) | Total Time 14.00(14.00)\n",
      "Iter 2052 | Time 80.2578(78.3719) | Bit/dim 3.9285(3.9347) | Xent 1.1084(1.1205) | Loss 4.4828(4.4949) | Error 0.3929(0.3994) Steps 832(822.57) | Grad Norm 0.9967(1.1156) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 29.3854, Epoch Time 517.2226(504.9032), Bit/dim 3.9341(best: 3.9348), Xent 1.0810, Loss 4.4746, Error 0.3851(best: 0.3865)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2053 | Time 80.8584(78.4465) | Bit/dim 3.9251(3.9344) | Xent 1.1108(1.1202) | Loss 4.4805(4.4945) | Error 0.4021(0.3995) Steps 832(822.85) | Grad Norm 1.1438(1.1165) | Total Time 14.00(14.00)\n",
      "Iter 2054 | Time 79.2998(78.4721) | Bit/dim 3.9320(3.9343) | Xent 1.1131(1.1200) | Loss 4.4885(4.4943) | Error 0.3971(0.3994) Steps 832(823.13) | Grad Norm 0.7860(1.1066) | Total Time 14.00(14.00)\n",
      "Iter 2055 | Time 78.3975(78.4698) | Bit/dim 3.9444(3.9346) | Xent 1.1153(1.1199) | Loss 4.5021(4.4945) | Error 0.3995(0.3994) Steps 826(823.21) | Grad Norm 1.3001(1.1124) | Total Time 14.00(14.00)\n",
      "Iter 2056 | Time 77.5549(78.4424) | Bit/dim 3.9358(3.9346) | Xent 1.1331(1.1203) | Loss 4.5023(4.4948) | Error 0.4026(0.3995) Steps 826(823.30) | Grad Norm 0.6469(1.0984) | Total Time 14.00(14.00)\n",
      "Iter 2057 | Time 78.8155(78.4536) | Bit/dim 3.9284(3.9345) | Xent 1.1241(1.1204) | Loss 4.4905(4.4947) | Error 0.4062(0.3997) Steps 832(823.56) | Grad Norm 1.0891(1.0981) | Total Time 14.00(14.00)\n",
      "Iter 2058 | Time 82.5965(78.5779) | Bit/dim 3.9307(3.9343) | Xent 1.1312(1.1207) | Loss 4.4963(4.4947) | Error 0.4073(0.3999) Steps 802(822.91) | Grad Norm 1.2231(1.1019) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 29.5083, Epoch Time 522.4437(505.4294), Bit/dim 3.9331(best: 3.9341), Xent 1.0809, Loss 4.4736, Error 0.3842(best: 0.3851)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2059 | Time 78.0177(78.5611) | Bit/dim 3.9217(3.9340) | Xent 1.1213(1.1207) | Loss 4.4824(4.4943) | Error 0.3959(0.3998) Steps 832(823.18) | Grad Norm 0.7617(1.0917) | Total Time 14.00(14.00)\n",
      "Iter 2060 | Time 77.3186(78.5238) | Bit/dim 3.9339(3.9340) | Xent 1.1333(1.1211) | Loss 4.5005(4.4945) | Error 0.4002(0.3998) Steps 832(823.45) | Grad Norm 1.0322(1.0899) | Total Time 14.00(14.00)\n",
      "Iter 2061 | Time 77.7420(78.5003) | Bit/dim 3.9192(3.9335) | Xent 1.0899(1.1202) | Loss 4.4641(4.4936) | Error 0.3880(0.3995) Steps 814(823.16) | Grad Norm 0.7757(1.0805) | Total Time 14.00(14.00)\n",
      "Iter 2062 | Time 79.1450(78.5197) | Bit/dim 3.9317(3.9335) | Xent 1.1115(1.1199) | Loss 4.4875(4.4934) | Error 0.3936(0.3993) Steps 832(823.43) | Grad Norm 1.3511(1.0886) | Total Time 14.00(14.00)\n",
      "Iter 2063 | Time 78.8742(78.5303) | Bit/dim 3.9477(3.9339) | Xent 1.1041(1.1194) | Loss 4.4997(4.4936) | Error 0.3971(0.3992) Steps 814(823.15) | Grad Norm 0.9154(1.0834) | Total Time 14.00(14.00)\n",
      "Iter 2064 | Time 80.6992(78.5954) | Bit/dim 3.9344(3.9339) | Xent 1.1249(1.1196) | Loss 4.4968(4.4937) | Error 0.4005(0.3993) Steps 832(823.41) | Grad Norm 1.0730(1.0831) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 29.2594, Epoch Time 516.7948(505.7703), Bit/dim 3.9329(best: 3.9331), Xent 1.0794, Loss 4.4726, Error 0.3859(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2065 | Time 80.0128(78.6379) | Bit/dim 3.9355(3.9340) | Xent 1.1169(1.1195) | Loss 4.4939(4.4937) | Error 0.3998(0.3993) Steps 832(823.67) | Grad Norm 0.6766(1.0709) | Total Time 14.00(14.00)\n",
      "Iter 2066 | Time 78.8964(78.6457) | Bit/dim 3.9245(3.9337) | Xent 1.1248(1.1197) | Loss 4.4869(4.4935) | Error 0.4051(0.3995) Steps 826(823.74) | Grad Norm 1.4425(1.0820) | Total Time 14.00(14.00)\n",
      "Iter 2067 | Time 76.2845(78.5748) | Bit/dim 3.9325(3.9336) | Xent 1.1037(1.1192) | Loss 4.4843(4.4932) | Error 0.3949(0.3993) Steps 832(823.99) | Grad Norm 0.9551(1.0782) | Total Time 14.00(14.00)\n",
      "Iter 2068 | Time 78.1568(78.5623) | Bit/dim 3.9376(3.9337) | Xent 1.1263(1.1194) | Loss 4.5008(4.4935) | Error 0.4024(0.3994) Steps 820(823.87) | Grad Norm 0.8833(1.0724) | Total Time 14.00(14.00)\n",
      "Iter 2069 | Time 80.3908(78.6171) | Bit/dim 3.9324(3.9337) | Xent 1.1072(1.1191) | Loss 4.4860(4.4932) | Error 0.3989(0.3994) Steps 832(824.11) | Grad Norm 0.9170(1.0677) | Total Time 14.00(14.00)\n",
      "Iter 2070 | Time 79.6567(78.6483) | Bit/dim 3.9304(3.9336) | Xent 1.1035(1.1186) | Loss 4.4821(4.4929) | Error 0.3924(0.3992) Steps 814(823.81) | Grad Norm 1.2647(1.0736) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 29.2334, Epoch Time 518.3599(506.1480), Bit/dim 3.9328(best: 3.9329), Xent 1.0809, Loss 4.4732, Error 0.3864(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2071 | Time 77.9397(78.6271) | Bit/dim 3.9333(3.9336) | Xent 1.1170(1.1185) | Loss 4.4918(4.4929) | Error 0.4042(0.3993) Steps 826(823.87) | Grad Norm 0.8241(1.0661) | Total Time 14.00(14.00)\n",
      "Iter 2072 | Time 78.8194(78.6328) | Bit/dim 3.9344(3.9336) | Xent 1.1075(1.1182) | Loss 4.4882(4.4927) | Error 0.3939(0.3992) Steps 808(823.40) | Grad Norm 1.6322(1.0831) | Total Time 14.00(14.00)\n",
      "Iter 2073 | Time 76.9522(78.5824) | Bit/dim 3.9313(3.9336) | Xent 1.1035(1.1178) | Loss 4.4830(4.4924) | Error 0.3982(0.3991) Steps 826(823.48) | Grad Norm 0.8473(1.0760) | Total Time 14.00(14.00)\n",
      "Iter 2074 | Time 75.9662(78.5039) | Bit/dim 3.9263(3.9333) | Xent 1.1178(1.1178) | Loss 4.4852(4.4922) | Error 0.3978(0.3991) Steps 826(823.55) | Grad Norm 0.9055(1.0709) | Total Time 14.00(14.00)\n",
      "Iter 2075 | Time 78.8559(78.5145) | Bit/dim 3.9383(3.9335) | Xent 1.1231(1.1179) | Loss 4.4999(4.4924) | Error 0.3995(0.3991) Steps 814(823.26) | Grad Norm 1.4148(1.0812) | Total Time 14.00(14.00)\n",
      "Iter 2076 | Time 79.8841(78.5556) | Bit/dim 3.9269(3.9333) | Xent 1.1154(1.1179) | Loss 4.4846(4.4922) | Error 0.3991(0.3991) Steps 808(822.81) | Grad Norm 1.1957(1.0847) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 29.1362, Epoch Time 512.9498(506.3521), Bit/dim 3.9328(best: 3.9328), Xent 1.0788, Loss 4.4722, Error 0.3850(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2077 | Time 78.0958(78.5418) | Bit/dim 3.9456(3.9337) | Xent 1.1238(1.1180) | Loss 4.5075(4.4927) | Error 0.4020(0.3992) Steps 826(822.90) | Grad Norm 0.8278(1.0770) | Total Time 14.00(14.00)\n",
      "Iter 2078 | Time 77.0119(78.4959) | Bit/dim 3.9250(3.9334) | Xent 1.1243(1.1182) | Loss 4.4871(4.4925) | Error 0.3981(0.3992) Steps 826(823.00) | Grad Norm 2.0384(1.1058) | Total Time 14.00(14.00)\n",
      "Iter 2079 | Time 78.6840(78.5015) | Bit/dim 3.9228(3.9331) | Xent 1.1061(1.1179) | Loss 4.4759(4.4920) | Error 0.4002(0.3992) Steps 814(822.73) | Grad Norm 1.7003(1.1237) | Total Time 14.00(14.00)\n",
      "Iter 2080 | Time 81.0946(78.5793) | Bit/dim 3.9331(3.9331) | Xent 1.1100(1.1176) | Loss 4.4881(4.4919) | Error 0.3888(0.3989) Steps 826(822.82) | Grad Norm 1.2155(1.1264) | Total Time 14.00(14.00)\n",
      "Iter 2081 | Time 76.8051(78.5261) | Bit/dim 3.9352(3.9331) | Xent 1.1129(1.1175) | Loss 4.4916(4.4919) | Error 0.3958(0.3988) Steps 832(823.10) | Grad Norm 1.8088(1.1469) | Total Time 14.00(14.00)\n",
      "Iter 2082 | Time 78.5871(78.5279) | Bit/dim 3.9351(3.9332) | Xent 1.1156(1.1174) | Loss 4.4929(4.4919) | Error 0.3976(0.3988) Steps 808(822.65) | Grad Norm 2.1185(1.1760) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 29.2633, Epoch Time 515.0773(506.6138), Bit/dim 3.9333(best: 3.9328), Xent 1.0783, Loss 4.4725, Error 0.3855(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2083 | Time 78.5886(78.5298) | Bit/dim 3.9357(3.9333) | Xent 1.1057(1.1171) | Loss 4.4886(4.4918) | Error 0.4000(0.3988) Steps 826(822.75) | Grad Norm 0.8160(1.1652) | Total Time 14.00(14.00)\n",
      "Iter 2084 | Time 79.5700(78.5610) | Bit/dim 3.9389(3.9334) | Xent 1.1233(1.1173) | Loss 4.5006(4.4921) | Error 0.4026(0.3989) Steps 832(823.02) | Grad Norm 2.0477(1.1917) | Total Time 14.00(14.00)\n",
      "Iter 2085 | Time 79.1274(78.5780) | Bit/dim 3.9255(3.9332) | Xent 1.1011(1.1168) | Loss 4.4760(4.4916) | Error 0.3915(0.3987) Steps 832(823.29) | Grad Norm 1.2892(1.1946) | Total Time 14.00(14.00)\n",
      "Iter 2086 | Time 79.0186(78.5912) | Bit/dim 3.9311(3.9331) | Xent 1.1275(1.1171) | Loss 4.4948(4.4917) | Error 0.4030(0.3988) Steps 826(823.37) | Grad Norm 1.4288(1.2017) | Total Time 14.00(14.00)\n",
      "Iter 2087 | Time 78.1641(78.5784) | Bit/dim 3.9302(3.9331) | Xent 1.1035(1.1167) | Loss 4.4820(4.4914) | Error 0.3891(0.3985) Steps 820(823.27) | Grad Norm 1.3947(1.2074) | Total Time 14.00(14.00)\n",
      "Iter 2088 | Time 81.7048(78.6722) | Bit/dim 3.9292(3.9329) | Xent 1.1208(1.1168) | Loss 4.4896(4.4913) | Error 0.4031(0.3987) Steps 808(822.82) | Grad Norm 1.2506(1.2087) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 29.3623, Epoch Time 520.9569(507.0441), Bit/dim 3.9327(best: 3.9328), Xent 1.0773, Loss 4.4713, Error 0.3870(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2089 | Time 77.5278(78.6378) | Bit/dim 3.9274(3.9328) | Xent 1.1096(1.1166) | Loss 4.4822(4.4911) | Error 0.3946(0.3985) Steps 826(822.91) | Grad Norm 0.8470(1.1979) | Total Time 14.00(14.00)\n",
      "Iter 2090 | Time 80.9426(78.7070) | Bit/dim 3.9272(3.9326) | Xent 1.1036(1.1162) | Loss 4.4790(4.4907) | Error 0.3910(0.3983) Steps 832(823.18) | Grad Norm 1.6543(1.2116) | Total Time 14.00(14.00)\n",
      "Iter 2091 | Time 78.9749(78.7150) | Bit/dim 3.9465(3.9330) | Xent 1.1059(1.1159) | Loss 4.4994(4.4910) | Error 0.3931(0.3982) Steps 814(822.91) | Grad Norm 1.2026(1.2113) | Total Time 14.00(14.00)\n",
      "Iter 2092 | Time 81.0883(78.7862) | Bit/dim 3.9304(3.9329) | Xent 1.1385(1.1166) | Loss 4.4996(4.4912) | Error 0.4040(0.3983) Steps 832(823.18) | Grad Norm 1.2707(1.2131) | Total Time 14.00(14.00)\n",
      "Iter 2093 | Time 79.2479(78.8001) | Bit/dim 3.9234(3.9327) | Xent 1.0987(1.1160) | Loss 4.4727(4.4907) | Error 0.3885(0.3980) Steps 826(823.27) | Grad Norm 1.1929(1.2125) | Total Time 14.00(14.00)\n",
      "Iter 2094 | Time 76.5730(78.7332) | Bit/dim 3.9329(3.9327) | Xent 1.1175(1.1161) | Loss 4.4916(4.4907) | Error 0.4032(0.3982) Steps 820(823.17) | Grad Norm 1.3636(1.2170) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 29.5145, Epoch Time 519.2418(507.4101), Bit/dim 3.9328(best: 3.9327), Xent 1.0781, Loss 4.4718, Error 0.3846(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2095 | Time 79.3928(78.7530) | Bit/dim 3.9307(3.9326) | Xent 1.1093(1.1159) | Loss 4.4853(4.4905) | Error 0.3921(0.3980) Steps 832(823.43) | Grad Norm 1.3586(1.2213) | Total Time 14.00(14.00)\n",
      "Iter 2096 | Time 81.3179(78.8300) | Bit/dim 3.9325(3.9326) | Xent 1.0815(1.1148) | Loss 4.4733(4.4900) | Error 0.3860(0.3977) Steps 826(823.51) | Grad Norm 0.9074(1.2118) | Total Time 14.00(14.00)\n",
      "Iter 2097 | Time 79.4405(78.8483) | Bit/dim 3.9253(3.9324) | Xent 1.1013(1.1144) | Loss 4.4759(4.4896) | Error 0.3909(0.3975) Steps 808(823.04) | Grad Norm 1.6992(1.2265) | Total Time 14.00(14.00)\n",
      "Iter 2098 | Time 79.3365(78.8629) | Bit/dim 3.9334(3.9324) | Xent 1.1242(1.1147) | Loss 4.4955(4.4898) | Error 0.4052(0.3977) Steps 832(823.31) | Grad Norm 2.8392(1.2749) | Total Time 14.00(14.00)\n",
      "Iter 2099 | Time 81.6931(78.9478) | Bit/dim 3.9376(3.9326) | Xent 1.1149(1.1147) | Loss 4.4950(4.4899) | Error 0.3979(0.3977) Steps 814(823.03) | Grad Norm 1.4711(1.2807) | Total Time 14.00(14.00)\n",
      "Iter 2100 | Time 77.3213(78.8990) | Bit/dim 3.9276(3.9324) | Xent 1.1152(1.1147) | Loss 4.4852(4.4898) | Error 0.4004(0.3978) Steps 826(823.12) | Grad Norm 2.6138(1.3207) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 29.5386, Epoch Time 523.5622(507.8946), Bit/dim 3.9325(best: 3.9327), Xent 1.0806, Loss 4.4729, Error 0.3843(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2101 | Time 77.0543(78.8437) | Bit/dim 3.9284(3.9323) | Xent 1.1158(1.1148) | Loss 4.4863(4.4897) | Error 0.4008(0.3979) Steps 826(823.21) | Grad Norm 2.4563(1.3548) | Total Time 14.00(14.00)\n",
      "Iter 2102 | Time 79.8403(78.8736) | Bit/dim 3.9286(3.9322) | Xent 1.0979(1.1143) | Loss 4.4775(4.4893) | Error 0.3935(0.3977) Steps 820(823.11) | Grad Norm 1.6123(1.3625) | Total Time 14.00(14.00)\n",
      "Iter 2103 | Time 79.9210(78.9050) | Bit/dim 3.9283(3.9321) | Xent 1.0984(1.1138) | Loss 4.4776(4.4890) | Error 0.3878(0.3974) Steps 826(823.20) | Grad Norm 1.4506(1.3652) | Total Time 14.00(14.00)\n",
      "Iter 2104 | Time 78.7009(78.8989) | Bit/dim 3.9471(3.9325) | Xent 1.1011(1.1134) | Loss 4.4977(4.4892) | Error 0.3909(0.3972) Steps 832(823.46) | Grad Norm 2.0104(1.3845) | Total Time 14.00(14.00)\n",
      "Iter 2105 | Time 80.8805(78.9583) | Bit/dim 3.9185(3.9321) | Xent 1.1216(1.1137) | Loss 4.4793(4.4889) | Error 0.4041(0.3974) Steps 814(823.18) | Grad Norm 2.3714(1.4141) | Total Time 14.00(14.00)\n",
      "Iter 2106 | Time 78.5200(78.9452) | Bit/dim 3.9331(3.9321) | Xent 1.1169(1.1138) | Loss 4.4915(4.4890) | Error 0.4019(0.3976) Steps 832(823.44) | Grad Norm 1.0988(1.4047) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 29.6346, Epoch Time 520.1307(508.2617), Bit/dim 3.9318(best: 3.9325), Xent 1.0771, Loss 4.4703, Error 0.3855(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2107 | Time 78.4911(78.9316) | Bit/dim 3.9360(3.9323) | Xent 1.1263(1.1141) | Loss 4.4992(4.4893) | Error 0.4020(0.3977) Steps 820(823.34) | Grad Norm 1.9309(1.4205) | Total Time 14.00(14.00)\n",
      "Iter 2108 | Time 75.5522(78.8302) | Bit/dim 3.9260(3.9321) | Xent 1.1127(1.1141) | Loss 4.4823(4.4891) | Error 0.3981(0.3977) Steps 826(823.42) | Grad Norm 2.0447(1.4392) | Total Time 14.00(14.00)\n",
      "Iter 2109 | Time 75.9077(78.7425) | Bit/dim 3.9272(3.9319) | Xent 1.0967(1.1136) | Loss 4.4755(4.4887) | Error 0.3886(0.3974) Steps 826(823.50) | Grad Norm 1.8573(1.4517) | Total Time 14.00(14.00)\n",
      "Iter 2110 | Time 78.8253(78.7450) | Bit/dim 3.9313(3.9319) | Xent 1.1028(1.1133) | Loss 4.4827(4.4885) | Error 0.3892(0.3972) Steps 808(823.03) | Grad Norm 1.0939(1.4410) | Total Time 14.00(14.00)\n",
      "Iter 2111 | Time 79.0743(78.7549) | Bit/dim 3.9258(3.9317) | Xent 1.1020(1.1129) | Loss 4.4768(4.4882) | Error 0.3970(0.3972) Steps 826(823.12) | Grad Norm 0.9744(1.4270) | Total Time 14.00(14.00)\n",
      "Iter 2112 | Time 79.2209(78.7689) | Bit/dim 3.9316(3.9317) | Xent 1.1151(1.1130) | Loss 4.4892(4.4882) | Error 0.3975(0.3972) Steps 832(823.39) | Grad Norm 1.1505(1.4187) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 29.2248, Epoch Time 511.8953(508.3707), Bit/dim 3.9309(best: 3.9318), Xent 1.0754, Loss 4.4685, Error 0.3844(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2113 | Time 77.2704(78.7239) | Bit/dim 3.9307(3.9317) | Xent 1.1251(1.1133) | Loss 4.4933(4.4884) | Error 0.3952(0.3971) Steps 832(823.65) | Grad Norm 1.0732(1.4083) | Total Time 14.00(14.00)\n",
      "Iter 2114 | Time 76.9683(78.6712) | Bit/dim 3.9374(3.9319) | Xent 1.1020(1.1130) | Loss 4.4884(4.4884) | Error 0.3914(0.3970) Steps 808(823.18) | Grad Norm 1.6801(1.4165) | Total Time 14.00(14.00)\n",
      "Iter 2115 | Time 79.5374(78.6972) | Bit/dim 3.9212(3.9315) | Xent 1.1158(1.1131) | Loss 4.4790(4.4881) | Error 0.3960(0.3969) Steps 820(823.08) | Grad Norm 0.9054(1.4012) | Total Time 14.00(14.00)\n",
      "Iter 2116 | Time 76.6137(78.6347) | Bit/dim 3.9314(3.9315) | Xent 1.0887(1.1124) | Loss 4.4758(4.4877) | Error 0.3899(0.3967) Steps 826(823.17) | Grad Norm 0.7362(1.3812) | Total Time 14.00(14.00)\n",
      "Iter 2117 | Time 78.5892(78.6334) | Bit/dim 3.9352(3.9316) | Xent 1.1078(1.1122) | Loss 4.4890(4.4877) | Error 0.3956(0.3967) Steps 820(823.07) | Grad Norm 1.1299(1.3737) | Total Time 14.00(14.00)\n",
      "Iter 2118 | Time 79.1864(78.6499) | Bit/dim 3.9216(3.9313) | Xent 1.0929(1.1116) | Loss 4.4681(4.4872) | Error 0.3908(0.3965) Steps 832(823.34) | Grad Norm 1.4293(1.3753) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 29.5771, Epoch Time 513.2208(508.5162), Bit/dim 3.9303(best: 3.9309), Xent 1.0739, Loss 4.4672, Error 0.3829(best: 0.3842)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2119 | Time 75.6646(78.5604) | Bit/dim 3.9341(3.9314) | Xent 1.1035(1.1114) | Loss 4.4859(4.4871) | Error 0.3906(0.3963) Steps 832(823.60) | Grad Norm 0.9229(1.3618) | Total Time 14.00(14.00)\n",
      "Iter 2120 | Time 78.1020(78.5466) | Bit/dim 3.9324(3.9315) | Xent 1.1173(1.1116) | Loss 4.4911(4.4872) | Error 0.3939(0.3963) Steps 808(823.13) | Grad Norm 0.9041(1.3480) | Total Time 14.00(14.00)\n",
      "Iter 2121 | Time 77.7649(78.5232) | Bit/dim 3.9307(3.9314) | Xent 1.1023(1.1113) | Loss 4.4818(4.4871) | Error 0.3922(0.3961) Steps 826(823.22) | Grad Norm 1.9299(1.3655) | Total Time 14.00(14.00)\n",
      "Iter 2122 | Time 80.2765(78.5758) | Bit/dim 3.9206(3.9311) | Xent 1.0934(1.1108) | Loss 4.4673(4.4865) | Error 0.3874(0.3959) Steps 832(823.48) | Grad Norm 1.1467(1.3589) | Total Time 14.00(14.00)\n",
      "Iter 2123 | Time 78.4267(78.5713) | Bit/dim 3.9267(3.9310) | Xent 1.1160(1.1109) | Loss 4.4847(4.4864) | Error 0.4012(0.3960) Steps 832(823.74) | Grad Norm 0.8571(1.3439) | Total Time 14.00(14.00)\n",
      "Iter 2124 | Time 76.9025(78.5212) | Bit/dim 3.9267(3.9308) | Xent 1.1092(1.1109) | Loss 4.4813(4.4863) | Error 0.3949(0.3960) Steps 808(823.27) | Grad Norm 1.4028(1.3456) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 29.2968, Epoch Time 511.8885(508.6174), Bit/dim 3.9306(best: 3.9303), Xent 1.0733, Loss 4.4673, Error 0.3799(best: 0.3829)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2125 | Time 78.5968(78.5235) | Bit/dim 3.9220(3.9306) | Xent 1.1107(1.1109) | Loss 4.4774(4.4860) | Error 0.3920(0.3959) Steps 808(822.81) | Grad Norm 1.7781(1.3586) | Total Time 14.00(14.00)\n",
      "Iter 2126 | Time 80.3774(78.5791) | Bit/dim 3.9257(3.9304) | Xent 1.1033(1.1106) | Loss 4.4773(4.4857) | Error 0.3931(0.3958) Steps 808(822.36) | Grad Norm 1.3701(1.3590) | Total Time 14.00(14.00)\n",
      "Iter 2127 | Time 77.1154(78.5352) | Bit/dim 3.9264(3.9303) | Xent 1.1019(1.1104) | Loss 4.4774(4.4855) | Error 0.3900(0.3956) Steps 826(822.47) | Grad Norm 1.7913(1.3719) | Total Time 14.00(14.00)\n",
      "Iter 2128 | Time 77.3509(78.4997) | Bit/dim 3.9348(3.9304) | Xent 1.0942(1.1099) | Loss 4.4819(4.4854) | Error 0.3884(0.3954) Steps 838(822.94) | Grad Norm 1.6678(1.3808) | Total Time 14.00(14.00)\n",
      "Iter 2129 | Time 79.7014(78.5357) | Bit/dim 3.9397(3.9307) | Xent 1.1069(1.1098) | Loss 4.4932(4.4856) | Error 0.3989(0.3955) Steps 808(822.49) | Grad Norm 1.3264(1.3792) | Total Time 14.00(14.00)\n",
      "Iter 2130 | Time 79.5743(78.5669) | Bit/dim 3.9249(3.9306) | Xent 1.1078(1.1097) | Loss 4.4788(4.4854) | Error 0.3981(0.3956) Steps 814(822.24) | Grad Norm 0.8894(1.3645) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 29.4363, Epoch Time 517.4530(508.8825), Bit/dim 3.9311(best: 3.9303), Xent 1.0719, Loss 4.4670, Error 0.3855(best: 0.3799)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2131 | Time 78.8967(78.5768) | Bit/dim 3.9224(3.9303) | Xent 1.0973(1.1094) | Loss 4.4711(4.4850) | Error 0.3974(0.3957) Steps 832(822.53) | Grad Norm 0.9931(1.3533) | Total Time 14.00(14.00)\n",
      "Iter 2132 | Time 77.9603(78.5583) | Bit/dim 3.9401(3.9306) | Xent 1.1156(1.1095) | Loss 4.4979(4.4854) | Error 0.3960(0.3957) Steps 820(822.45) | Grad Norm 1.5513(1.3593) | Total Time 14.00(14.00)\n",
      "Iter 2133 | Time 81.1270(78.6354) | Bit/dim 3.9322(3.9307) | Xent 1.0955(1.1091) | Loss 4.4799(4.4852) | Error 0.3849(0.3953) Steps 826(822.56) | Grad Norm 1.5436(1.3648) | Total Time 14.00(14.00)\n",
      "Iter 2134 | Time 78.6103(78.6346) | Bit/dim 3.9269(3.9305) | Xent 1.1152(1.1093) | Loss 4.4845(4.4852) | Error 0.3972(0.3954) Steps 826(822.66) | Grad Norm 0.9115(1.3512) | Total Time 14.00(14.00)\n",
      "Iter 2135 | Time 80.4212(78.6882) | Bit/dim 3.9309(3.9305) | Xent 1.0957(1.1089) | Loss 4.4787(4.4850) | Error 0.3906(0.3953) Steps 832(822.94) | Grad Norm 1.9445(1.3690) | Total Time 14.00(14.00)\n",
      "Iter 2136 | Time 82.1660(78.7925) | Bit/dim 3.9271(3.9304) | Xent 1.1254(1.1094) | Loss 4.4899(4.4851) | Error 0.3985(0.3953) Steps 808(822.49) | Grad Norm 1.8384(1.3831) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 29.4538, Epoch Time 524.0411(509.3372), Bit/dim 3.9301(best: 3.9303), Xent 1.0729, Loss 4.4665, Error 0.3857(best: 0.3799)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2137 | Time 77.6005(78.7568) | Bit/dim 3.9292(3.9304) | Xent 1.0914(1.1089) | Loss 4.4749(4.4848) | Error 0.3951(0.3953) Steps 802(821.88) | Grad Norm 0.9917(1.3713) | Total Time 14.00(14.00)\n",
      "Iter 2138 | Time 79.6512(78.7836) | Bit/dim 3.9362(3.9306) | Xent 1.1098(1.1089) | Loss 4.4910(4.4850) | Error 0.3914(0.3952) Steps 826(822.00) | Grad Norm 1.6389(1.3794) | Total Time 14.00(14.00)\n",
      "Iter 2139 | Time 78.8484(78.7855) | Bit/dim 3.9234(3.9304) | Xent 1.1287(1.1095) | Loss 4.4877(4.4851) | Error 0.4012(0.3954) Steps 826(822.12) | Grad Norm 2.0788(1.4004) | Total Time 14.00(14.00)\n",
      "Iter 2140 | Time 79.0652(78.7939) | Bit/dim 3.9164(3.9299) | Xent 1.1108(1.1095) | Loss 4.4718(4.4847) | Error 0.3956(0.3954) Steps 826(822.24) | Grad Norm 1.3271(1.3982) | Total Time 14.00(14.00)\n",
      "Iter 2141 | Time 74.7738(78.6733) | Bit/dim 3.9335(3.9301) | Xent 1.1144(1.1097) | Loss 4.4907(4.4849) | Error 0.3970(0.3955) Steps 820(822.17) | Grad Norm 1.1393(1.3904) | Total Time 14.00(14.00)\n",
      "Iter 2142 | Time 80.6195(78.7317) | Bit/dim 3.9329(3.9301) | Xent 1.0905(1.1091) | Loss 4.4782(4.4847) | Error 0.3868(0.3952) Steps 808(821.75) | Grad Norm 1.1866(1.3843) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 29.2204, Epoch Time 515.3478(509.5175), Bit/dim 3.9304(best: 3.9301), Xent 1.0716, Loss 4.4662, Error 0.3839(best: 0.3799)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2143 | Time 78.5943(78.7276) | Bit/dim 3.9303(3.9301) | Xent 1.1111(1.1091) | Loss 4.4858(4.4847) | Error 0.3964(0.3952) Steps 838(822.23) | Grad Norm 1.5539(1.3894) | Total Time 14.00(14.00)\n",
      "Iter 2144 | Time 78.6205(78.7244) | Bit/dim 3.9344(3.9303) | Xent 1.1047(1.1090) | Loss 4.4867(4.4848) | Error 0.3896(0.3951) Steps 832(822.53) | Grad Norm 0.8616(1.3735) | Total Time 14.00(14.00)\n",
      "Iter 2145 | Time 79.6487(78.7521) | Bit/dim 3.9298(3.9303) | Xent 1.0987(1.1087) | Loss 4.4792(4.4846) | Error 0.3880(0.3949) Steps 826(822.63) | Grad Norm 1.3454(1.3727) | Total Time 14.00(14.00)\n",
      "Iter 2146 | Time 80.3337(78.7996) | Bit/dim 3.9161(3.9298) | Xent 1.1144(1.1089) | Loss 4.4733(4.4843) | Error 0.3966(0.3949) Steps 808(822.19) | Grad Norm 1.8277(1.3863) | Total Time 14.00(14.00)\n",
      "Iter 2147 | Time 77.7216(78.7672) | Bit/dim 3.9297(3.9298) | Xent 1.1018(1.1087) | Loss 4.4806(4.4842) | Error 0.3999(0.3951) Steps 826(822.31) | Grad Norm 1.0665(1.3767) | Total Time 14.00(14.00)\n",
      "Iter 2148 | Time 78.7001(78.7652) | Bit/dim 3.9342(3.9300) | Xent 1.1099(1.1087) | Loss 4.4892(4.4843) | Error 0.3965(0.3951) Steps 808(821.88) | Grad Norm 0.7343(1.3575) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 29.3562, Epoch Time 518.3825(509.7835), Bit/dim 3.9296(best: 3.9301), Xent 1.0705, Loss 4.4648, Error 0.3819(best: 0.3799)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2149 | Time 78.5008(78.7573) | Bit/dim 3.9173(3.9296) | Xent 1.1099(1.1087) | Loss 4.4723(4.4840) | Error 0.3904(0.3950) Steps 808(821.46) | Grad Norm 1.1558(1.3514) | Total Time 14.00(14.00)\n",
      "Iter 2150 | Time 78.3699(78.7457) | Bit/dim 3.9183(3.9292) | Xent 1.1089(1.1087) | Loss 4.4728(4.4836) | Error 0.3958(0.3950) Steps 826(821.60) | Grad Norm 0.9441(1.3392) | Total Time 14.00(14.00)\n",
      "Iter 2151 | Time 79.5944(78.7711) | Bit/dim 3.9311(3.9293) | Xent 1.1020(1.1085) | Loss 4.4821(4.4836) | Error 0.3941(0.3950) Steps 832(821.91) | Grad Norm 1.4680(1.3431) | Total Time 14.00(14.00)\n",
      "Iter 2152 | Time 78.2312(78.7549) | Bit/dim 3.9356(3.9295) | Xent 1.1136(1.1087) | Loss 4.4924(4.4838) | Error 0.3936(0.3949) Steps 808(821.49) | Grad Norm 0.6443(1.3221) | Total Time 14.00(14.00)\n",
      "Iter 2153 | Time 77.8801(78.7287) | Bit/dim 3.9345(3.9296) | Xent 1.1011(1.1085) | Loss 4.4850(4.4839) | Error 0.3895(0.3948) Steps 826(821.63) | Grad Norm 1.4446(1.3258) | Total Time 14.00(14.00)\n",
      "Iter 2154 | Time 78.7556(78.7295) | Bit/dim 3.9272(3.9296) | Xent 1.0997(1.1082) | Loss 4.4771(4.4837) | Error 0.3980(0.3948) Steps 832(821.94) | Grad Norm 1.3047(1.3251) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 29.5172, Epoch Time 516.2607(509.9778), Bit/dim 3.9293(best: 3.9296), Xent 1.0684, Loss 4.4635, Error 0.3812(best: 0.3799)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2155 | Time 78.3673(78.7186) | Bit/dim 3.9332(3.9297) | Xent 1.0988(1.1079) | Loss 4.4825(4.4836) | Error 0.3906(0.3947) Steps 826(822.06) | Grad Norm 0.6238(1.3041) | Total Time 14.00(14.00)\n",
      "Iter 2156 | Time 77.6261(78.6858) | Bit/dim 3.9288(3.9296) | Xent 1.1050(1.1078) | Loss 4.4813(4.4836) | Error 0.3920(0.3946) Steps 826(822.18) | Grad Norm 0.7212(1.2866) | Total Time 14.00(14.00)\n",
      "Iter 2157 | Time 82.0177(78.7858) | Bit/dim 3.9281(3.9296) | Xent 1.1010(1.1076) | Loss 4.4787(4.4834) | Error 0.3956(0.3947) Steps 820(822.11) | Grad Norm 0.9354(1.2761) | Total Time 14.00(14.00)\n",
      "Iter 2158 | Time 80.8552(78.8479) | Bit/dim 3.9313(3.9297) | Xent 1.1040(1.1075) | Loss 4.4833(4.4834) | Error 0.3900(0.3945) Steps 832(822.41) | Grad Norm 1.3880(1.2794) | Total Time 14.00(14.00)\n",
      "Iter 2159 | Time 77.9893(78.8221) | Bit/dim 3.9195(3.9294) | Xent 1.1110(1.1076) | Loss 4.4750(4.4832) | Error 0.3956(0.3946) Steps 826(822.52) | Grad Norm 0.6891(1.2617) | Total Time 14.00(14.00)\n",
      "Iter 2160 | Time 80.3190(78.8670) | Bit/dim 3.9241(3.9292) | Xent 1.1015(1.1074) | Loss 4.4749(4.4829) | Error 0.3971(0.3946) Steps 826(822.62) | Grad Norm 0.8708(1.2500) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 29.5431, Epoch Time 522.2699(510.3466), Bit/dim 3.9285(best: 3.9293), Xent 1.0693, Loss 4.4632, Error 0.3812(best: 0.3799)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2161 | Time 78.7577(78.8637) | Bit/dim 3.9329(3.9293) | Xent 1.1071(1.1074) | Loss 4.4864(4.4830) | Error 0.3916(0.3945) Steps 826(822.72) | Grad Norm 1.6592(1.2623) | Total Time 14.00(14.00)\n",
      "Iter 2162 | Time 79.2841(78.8764) | Bit/dim 3.9220(3.9291) | Xent 1.0996(1.1072) | Loss 4.4718(4.4827) | Error 0.3866(0.3943) Steps 826(822.82) | Grad Norm 1.2358(1.2615) | Total Time 14.00(14.00)\n",
      "Iter 2163 | Time 76.8973(78.8170) | Bit/dim 3.9325(3.9292) | Xent 1.0918(1.1067) | Loss 4.4784(4.4826) | Error 0.3929(0.3943) Steps 808(822.38) | Grad Norm 1.1080(1.2569) | Total Time 14.00(14.00)\n",
      "Iter 2164 | Time 78.2200(78.7991) | Bit/dim 3.9289(3.9292) | Xent 1.1113(1.1069) | Loss 4.4845(4.4826) | Error 0.3916(0.3942) Steps 832(822.67) | Grad Norm 1.1105(1.2525) | Total Time 14.00(14.00)\n",
      "Iter 2165 | Time 77.9196(78.7727) | Bit/dim 3.9279(3.9291) | Xent 1.0959(1.1065) | Loss 4.4758(4.4824) | Error 0.3876(0.3940) Steps 826(822.77) | Grad Norm 1.4945(1.2597) | Total Time 14.00(14.00)\n",
      "Iter 2166 | Time 78.7518(78.7721) | Bit/dim 3.9199(3.9289) | Xent 1.0949(1.1062) | Loss 4.4674(4.4820) | Error 0.3912(0.3939) Steps 826(822.86) | Grad Norm 0.7577(1.2447) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 29.7578, Epoch Time 515.1212(510.4898), Bit/dim 3.9292(best: 3.9285), Xent 1.0693, Loss 4.4638, Error 0.3800(best: 0.3799)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2167 | Time 77.4539(78.7325) | Bit/dim 3.9197(3.9286) | Xent 1.1137(1.1064) | Loss 4.4765(4.4818) | Error 0.3974(0.3940) Steps 826(822.96) | Grad Norm 1.3998(1.2493) | Total Time 14.00(14.00)\n",
      "Iter 2168 | Time 76.6339(78.6696) | Bit/dim 3.9288(3.9286) | Xent 1.0918(1.1060) | Loss 4.4747(4.4816) | Error 0.3885(0.3938) Steps 826(823.05) | Grad Norm 1.6712(1.2620) | Total Time 14.00(14.00)\n",
      "Iter 2169 | Time 77.8673(78.6455) | Bit/dim 3.9264(3.9285) | Xent 1.0938(1.1056) | Loss 4.4733(4.4813) | Error 0.3858(0.3936) Steps 820(822.96) | Grad Norm 0.8266(1.2489) | Total Time 14.00(14.00)\n",
      "Iter 2170 | Time 76.2402(78.5733) | Bit/dim 3.9386(3.9288) | Xent 1.0935(1.1052) | Loss 4.4853(4.4815) | Error 0.3845(0.3933) Steps 826(823.05) | Grad Norm 0.9637(1.2404) | Total Time 14.00(14.00)\n",
      "Iter 2171 | Time 78.2674(78.5642) | Bit/dim 3.9212(3.9286) | Xent 1.1041(1.1052) | Loss 4.4732(4.4812) | Error 0.3928(0.3933) Steps 826(823.14) | Grad Norm 1.7962(1.2570) | Total Time 14.00(14.00)\n",
      "Iter 2172 | Time 79.2416(78.5845) | Bit/dim 3.9362(3.9288) | Xent 1.1331(1.1061) | Loss 4.5028(4.4819) | Error 0.4107(0.3938) Steps 832(823.40) | Grad Norm 1.2391(1.2565) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 29.5427, Epoch Time 511.1271(510.5089), Bit/dim 3.9289(best: 3.9285), Xent 1.0673, Loss 4.4626, Error 0.3817(best: 0.3799)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2173 | Time 76.6476(78.5264) | Bit/dim 3.9233(3.9287) | Xent 1.1051(1.1060) | Loss 4.4759(4.4817) | Error 0.3919(0.3938) Steps 826(823.48) | Grad Norm 0.7034(1.2399) | Total Time 14.00(14.00)\n",
      "Iter 2174 | Time 78.0038(78.5107) | Bit/dim 3.9228(3.9285) | Xent 1.0974(1.1058) | Loss 4.4716(4.4814) | Error 0.3878(0.3936) Steps 832(823.74) | Grad Norm 1.3880(1.2444) | Total Time 14.00(14.00)\n",
      "Iter 2175 | Time 79.9643(78.5543) | Bit/dim 3.9306(3.9286) | Xent 1.1206(1.1062) | Loss 4.4909(4.4817) | Error 0.3985(0.3937) Steps 832(823.98) | Grad Norm 1.1749(1.2423) | Total Time 14.00(14.00)\n",
      "Iter 2176 | Time 79.1334(78.5717) | Bit/dim 3.9285(3.9285) | Xent 1.1322(1.1070) | Loss 4.4946(4.4820) | Error 0.4026(0.3940) Steps 826(824.04) | Grad Norm 1.4352(1.2481) | Total Time 14.00(14.00)\n",
      "Iter 2177 | Time 77.5664(78.5415) | Bit/dim 3.9310(3.9286) | Xent 1.1038(1.1069) | Loss 4.4829(4.4821) | Error 0.3959(0.3941) Steps 826(824.10) | Grad Norm 1.2629(1.2485) | Total Time 14.00(14.00)\n",
      "Iter 2178 | Time 79.2663(78.5633) | Bit/dim 3.9248(3.9285) | Xent 1.0760(1.1060) | Loss 4.4628(4.4815) | Error 0.3832(0.3937) Steps 826(824.16) | Grad Norm 0.8152(1.2355) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 29.6284, Epoch Time 515.6547(510.6633), Bit/dim 3.9287(best: 3.9285), Xent 1.0666, Loss 4.4620, Error 0.3784(best: 0.3799)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2179 | Time 76.7897(78.5101) | Bit/dim 3.9209(3.9283) | Xent 1.1112(1.1061) | Loss 4.4764(4.4813) | Error 0.3999(0.3939) Steps 826(824.22) | Grad Norm 1.0081(1.2287) | Total Time 14.00(14.00)\n",
      "Iter 2180 | Time 77.1710(78.4699) | Bit/dim 3.9226(3.9281) | Xent 1.0960(1.1058) | Loss 4.4706(4.4810) | Error 0.3881(0.3938) Steps 820(824.09) | Grad Norm 0.8274(1.2166) | Total Time 14.00(14.00)\n",
      "Iter 2181 | Time 78.2344(78.4628) | Bit/dim 3.9305(3.9282) | Xent 1.1171(1.1062) | Loss 4.4891(4.4813) | Error 0.3940(0.3938) Steps 820(823.97) | Grad Norm 1.4558(1.2238) | Total Time 14.00(14.00)\n",
      "Iter 2182 | Time 76.8971(78.4158) | Bit/dim 3.9185(3.9279) | Xent 1.0904(1.1057) | Loss 4.4637(4.4807) | Error 0.3862(0.3935) Steps 826(824.03) | Grad Norm 0.8717(1.2133) | Total Time 14.00(14.00)\n",
      "Iter 2183 | Time 77.0423(78.3746) | Bit/dim 3.9381(3.9282) | Xent 1.0916(1.1053) | Loss 4.4839(4.4808) | Error 0.3864(0.3933) Steps 826(824.09) | Grad Norm 1.6970(1.2278) | Total Time 14.00(14.00)\n",
      "Iter 2184 | Time 78.6859(78.3840) | Bit/dim 3.9315(3.9283) | Xent 1.1066(1.1053) | Loss 4.4847(4.4809) | Error 0.3945(0.3934) Steps 826(824.14) | Grad Norm 1.8066(1.2451) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 29.5922, Epoch Time 510.3914(510.6551), Bit/dim 3.9277(best: 3.9285), Xent 1.0668, Loss 4.4611, Error 0.3809(best: 0.3784)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2185 | Time 80.5457(78.4488) | Bit/dim 3.9341(3.9285) | Xent 1.0871(1.1048) | Loss 4.4776(4.4808) | Error 0.3856(0.3931) Steps 826(824.20) | Grad Norm 0.7300(1.2297) | Total Time 14.00(14.00)\n",
      "Iter 2186 | Time 78.6919(78.4561) | Bit/dim 3.9307(3.9285) | Xent 1.1223(1.1053) | Loss 4.4919(4.4812) | Error 0.3996(0.3933) Steps 832(824.43) | Grad Norm 2.0122(1.2532) | Total Time 14.00(14.00)\n",
      "Iter 2187 | Time 75.5174(78.3680) | Bit/dim 3.9270(3.9285) | Xent 1.1023(1.1052) | Loss 4.4781(4.4811) | Error 0.3966(0.3934) Steps 826(824.48) | Grad Norm 1.7258(1.2673) | Total Time 14.00(14.00)\n",
      "Iter 2188 | Time 79.3200(78.3965) | Bit/dim 3.9266(3.9284) | Xent 1.1009(1.1051) | Loss 4.4770(4.4810) | Error 0.3931(0.3934) Steps 832(824.71) | Grad Norm 0.7596(1.2521) | Total Time 14.00(14.00)\n",
      "Iter 2189 | Time 77.2586(78.3624) | Bit/dim 3.9258(3.9284) | Xent 1.1133(1.1053) | Loss 4.4824(4.4810) | Error 0.3951(0.3935) Steps 826(824.74) | Grad Norm 1.8868(1.2711) | Total Time 14.00(14.00)\n",
      "Iter 2190 | Time 77.7395(78.3437) | Bit/dim 3.9182(3.9280) | Xent 1.0989(1.1051) | Loss 4.4676(4.4806) | Error 0.3908(0.3934) Steps 826(824.78) | Grad Norm 2.5424(1.3093) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 29.7647, Epoch Time 514.4106(510.7678), Bit/dim 3.9286(best: 3.9277), Xent 1.0652, Loss 4.4612, Error 0.3793(best: 0.3784)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2191 | Time 79.4151(78.3758) | Bit/dim 3.9239(3.9279) | Xent 1.1091(1.1052) | Loss 4.4784(4.4805) | Error 0.3919(0.3933) Steps 826(824.82) | Grad Norm 0.7640(1.2929) | Total Time 14.00(14.00)\n",
      "Iter 2192 | Time 79.7256(78.4163) | Bit/dim 3.9206(3.9277) | Xent 1.0963(1.1050) | Loss 4.4687(4.4802) | Error 0.3861(0.3931) Steps 814(824.49) | Grad Norm 2.8688(1.3402) | Total Time 14.00(14.00)\n",
      "Iter 2193 | Time 78.4919(78.4186) | Bit/dim 3.9234(3.9276) | Xent 1.1101(1.1051) | Loss 4.4785(4.4801) | Error 0.4009(0.3934) Steps 814(824.18) | Grad Norm 2.8734(1.3862) | Total Time 14.00(14.00)\n",
      "Iter 2194 | Time 76.6846(78.3666) | Bit/dim 3.9248(3.9275) | Xent 1.1018(1.1050) | Loss 4.4757(4.4800) | Error 0.3840(0.3931) Steps 826(824.23) | Grad Norm 1.3216(1.3843) | Total Time 14.00(14.00)\n",
      "Iter 2195 | Time 77.9403(78.3538) | Bit/dim 3.9310(3.9276) | Xent 1.1123(1.1052) | Loss 4.4872(4.4802) | Error 0.3954(0.3931) Steps 820(824.11) | Grad Norm 2.6018(1.4208) | Total Time 14.00(14.00)\n",
      "Iter 2196 | Time 79.2772(78.3815) | Bit/dim 3.9341(3.9278) | Xent 1.1024(1.1052) | Loss 4.4853(4.4804) | Error 0.3964(0.3932) Steps 832(824.34) | Grad Norm 2.4250(1.4509) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 29.3101, Epoch Time 516.1901(510.9305), Bit/dim 3.9275(best: 3.9277), Xent 1.0638, Loss 4.4594, Error 0.3790(best: 0.3784)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2197 | Time 78.9698(78.3991) | Bit/dim 3.9194(3.9275) | Xent 1.0975(1.1049) | Loss 4.4682(4.4800) | Error 0.3860(0.3930) Steps 826(824.39) | Grad Norm 0.8620(1.4332) | Total Time 14.00(14.00)\n",
      "Iter 2198 | Time 77.4906(78.3719) | Bit/dim 3.9263(3.9275) | Xent 1.0921(1.1045) | Loss 4.4723(4.4798) | Error 0.3901(0.3929) Steps 814(824.08) | Grad Norm 2.2072(1.4565) | Total Time 14.00(14.00)\n",
      "Iter 2199 | Time 78.8108(78.3851) | Bit/dim 3.9263(3.9275) | Xent 1.1165(1.1049) | Loss 4.4846(4.4799) | Error 0.4004(0.3932) Steps 820(823.96) | Grad Norm 1.8955(1.4696) | Total Time 14.00(14.00)\n",
      "Iter 2200 | Time 76.3814(78.3249) | Bit/dim 3.9294(3.9275) | Xent 1.0799(1.1042) | Loss 4.4693(4.4796) | Error 0.3819(0.3928) Steps 826(824.02) | Grad Norm 1.0861(1.4581) | Total Time 14.00(14.00)\n",
      "Iter 2201 | Time 77.4820(78.2997) | Bit/dim 3.9242(3.9274) | Xent 1.1105(1.1043) | Loss 4.4795(4.4796) | Error 0.3969(0.3929) Steps 826(824.08) | Grad Norm 1.0001(1.4444) | Total Time 14.00(14.00)\n",
      "Iter 2202 | Time 77.7899(78.2844) | Bit/dim 3.9321(3.9276) | Xent 1.0842(1.1037) | Loss 4.4742(4.4794) | Error 0.3881(0.3928) Steps 832(824.32) | Grad Norm 2.3868(1.4727) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 29.7319, Epoch Time 512.3442(510.9729), Bit/dim 3.9271(best: 3.9275), Xent 1.0634, Loss 4.4588, Error 0.3793(best: 0.3784)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2203 | Time 78.3686(78.2869) | Bit/dim 3.9257(3.9275) | Xent 1.1177(1.1042) | Loss 4.4845(4.4796) | Error 0.3964(0.3929) Steps 832(824.55) | Grad Norm 1.3050(1.4676) | Total Time 14.00(14.00)\n",
      "Iter 2204 | Time 77.8898(78.2750) | Bit/dim 3.9159(3.9272) | Xent 1.1025(1.1041) | Loss 4.4672(4.4792) | Error 0.3898(0.3928) Steps 820(824.41) | Grad Norm 1.3286(1.4635) | Total Time 14.00(14.00)\n",
      "Iter 2205 | Time 81.7905(78.3804) | Bit/dim 3.9310(3.9273) | Xent 1.0953(1.1038) | Loss 4.4787(4.4792) | Error 0.3881(0.3927) Steps 826(824.46) | Grad Norm 2.1809(1.4850) | Total Time 14.00(14.00)\n",
      "Iter 2206 | Time 79.6631(78.4189) | Bit/dim 3.9262(3.9272) | Xent 1.0902(1.1034) | Loss 4.4713(4.4790) | Error 0.3848(0.3924) Steps 826(824.51) | Grad Norm 2.0257(1.5012) | Total Time 14.00(14.00)\n",
      "Iter 2207 | Time 80.3598(78.4771) | Bit/dim 3.9240(3.9271) | Xent 1.0941(1.1032) | Loss 4.4710(4.4787) | Error 0.3918(0.3924) Steps 826(824.55) | Grad Norm 1.2707(1.4943) | Total Time 14.00(14.00)\n",
      "Iter 2208 | Time 79.1560(78.4975) | Bit/dim 3.9312(3.9273) | Xent 1.0822(1.1025) | Loss 4.4723(4.4785) | Error 0.3831(0.3921) Steps 826(824.59) | Grad Norm 2.8767(1.5358) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 29.2441, Epoch Time 522.1708(511.3088), Bit/dim 3.9269(best: 3.9271), Xent 1.0650, Loss 4.4594, Error 0.3791(best: 0.3784)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2209 | Time 80.9052(78.5697) | Bit/dim 3.9179(3.9270) | Xent 1.0874(1.1021) | Loss 4.4616(4.4780) | Error 0.3898(0.3921) Steps 826(824.64) | Grad Norm 1.2445(1.5270) | Total Time 14.00(14.00)\n",
      "Iter 2210 | Time 76.6646(78.5126) | Bit/dim 3.9192(3.9268) | Xent 1.1141(1.1024) | Loss 4.4763(4.4780) | Error 0.3979(0.3922) Steps 826(824.68) | Grad Norm 1.6387(1.5304) | Total Time 14.00(14.00)\n",
      "Iter 2211 | Time 78.2051(78.5034) | Bit/dim 3.9232(3.9267) | Xent 1.1015(1.1024) | Loss 4.4740(4.4779) | Error 0.3896(0.3922) Steps 826(824.72) | Grad Norm 2.0131(1.5449) | Total Time 14.00(14.00)\n",
      "Iter 2212 | Time 77.2094(78.4645) | Bit/dim 3.9315(3.9268) | Xent 1.1105(1.1026) | Loss 4.4868(4.4781) | Error 0.4021(0.3925) Steps 826(824.76) | Grad Norm 1.5471(1.5449) | Total Time 14.00(14.00)\n",
      "Iter 2213 | Time 77.6271(78.4394) | Bit/dim 3.9237(3.9267) | Xent 1.0915(1.1023) | Loss 4.4694(4.4779) | Error 0.3816(0.3921) Steps 826(824.79) | Grad Norm 1.4355(1.5416) | Total Time 14.00(14.00)\n",
      "Iter 2214 | Time 78.1073(78.4295) | Bit/dim 3.9356(3.9270) | Xent 1.0916(1.1020) | Loss 4.4814(4.4780) | Error 0.3832(0.3919) Steps 820(824.65) | Grad Norm 1.9083(1.5526) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 29.4242, Epoch Time 513.8016(511.3836), Bit/dim 3.9258(best: 3.9269), Xent 1.0645, Loss 4.4580, Error 0.3791(best: 0.3784)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2215 | Time 77.9626(78.4155) | Bit/dim 3.9243(3.9269) | Xent 1.0879(1.1016) | Loss 4.4682(4.4777) | Error 0.3852(0.3917) Steps 826(824.69) | Grad Norm 1.5481(1.5525) | Total Time 14.00(14.00)\n",
      "Iter 2216 | Time 78.2713(78.4111) | Bit/dim 3.9233(3.9268) | Xent 1.1149(1.1020) | Loss 4.4808(4.4778) | Error 0.3965(0.3918) Steps 826(824.73) | Grad Norm 1.5141(1.5513) | Total Time 14.00(14.00)\n",
      "Iter 2217 | Time 76.7930(78.3626) | Bit/dim 3.9251(3.9267) | Xent 1.0877(1.1015) | Loss 4.4689(4.4775) | Error 0.3902(0.3918) Steps 826(824.77) | Grad Norm 1.9057(1.5620) | Total Time 14.00(14.00)\n",
      "Iter 2218 | Time 78.4341(78.3647) | Bit/dim 3.9425(3.9272) | Xent 1.0863(1.1011) | Loss 4.4856(4.4777) | Error 0.3894(0.3917) Steps 826(824.80) | Grad Norm 1.6436(1.5644) | Total Time 14.00(14.00)\n",
      "Iter 2219 | Time 78.9180(78.3813) | Bit/dim 3.9169(3.9269) | Xent 1.1096(1.1013) | Loss 4.4717(4.4776) | Error 0.3971(0.3919) Steps 826(824.84) | Grad Norm 2.2997(1.5865) | Total Time 14.00(14.00)\n",
      "Iter 2220 | Time 76.8631(78.3358) | Bit/dim 3.9184(3.9266) | Xent 1.0815(1.1007) | Loss 4.4591(4.4770) | Error 0.3885(0.3918) Steps 808(824.33) | Grad Norm 1.0910(1.5716) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 29.3967, Epoch Time 512.3479(511.4125), Bit/dim 3.9260(best: 3.9258), Xent 1.0631, Loss 4.4575, Error 0.3800(best: 0.3784)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2221 | Time 79.5929(78.3735) | Bit/dim 3.9240(3.9266) | Xent 1.0920(1.1005) | Loss 4.4700(4.4768) | Error 0.3855(0.3916) Steps 826(824.38) | Grad Norm 1.4957(1.5693) | Total Time 14.00(14.00)\n",
      "Iter 2222 | Time 77.4176(78.3448) | Bit/dim 3.9175(3.9263) | Xent 1.0897(1.1002) | Loss 4.4623(4.4764) | Error 0.3869(0.3914) Steps 826(824.43) | Grad Norm 1.6009(1.5703) | Total Time 14.00(14.00)\n",
      "Iter 2223 | Time 78.4658(78.3484) | Bit/dim 3.9260(3.9263) | Xent 1.0812(1.0996) | Loss 4.4666(4.4761) | Error 0.3848(0.3912) Steps 820(824.30) | Grad Norm 1.0021(1.5532) | Total Time 14.00(14.00)\n",
      "Iter 2224 | Time 80.6232(78.4167) | Bit/dim 3.9296(3.9264) | Xent 1.1137(1.1000) | Loss 4.4864(4.4764) | Error 0.3981(0.3914) Steps 826(824.35) | Grad Norm 1.0342(1.5377) | Total Time 14.00(14.00)\n",
      "Iter 2225 | Time 78.8000(78.4282) | Bit/dim 3.9284(3.9264) | Xent 1.0915(1.0998) | Loss 4.4742(4.4763) | Error 0.3876(0.3913) Steps 826(824.40) | Grad Norm 1.1163(1.5250) | Total Time 14.00(14.00)\n",
      "Iter 2226 | Time 78.1353(78.4194) | Bit/dim 3.9238(3.9264) | Xent 1.0819(1.0992) | Loss 4.4648(4.4760) | Error 0.3822(0.3910) Steps 826(824.45) | Grad Norm 0.9897(1.5090) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 29.4491, Epoch Time 518.2823(511.6186), Bit/dim 3.9260(best: 3.9258), Xent 1.0592, Loss 4.4556, Error 0.3776(best: 0.3784)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2227 | Time 77.7519(78.3994) | Bit/dim 3.9342(3.9266) | Xent 1.0843(1.0988) | Loss 4.4763(4.4760) | Error 0.3792(0.3907) Steps 826(824.49) | Grad Norm 0.7768(1.4870) | Total Time 14.00(14.00)\n",
      "Iter 2228 | Time 76.3069(78.3366) | Bit/dim 3.9159(3.9263) | Xent 1.0881(1.0985) | Loss 4.4599(4.4755) | Error 0.3904(0.3907) Steps 808(824.00) | Grad Norm 1.6610(1.4922) | Total Time 14.00(14.00)\n",
      "Iter 2229 | Time 75.2679(78.2445) | Bit/dim 3.9242(3.9262) | Xent 1.0973(1.0984) | Loss 4.4729(4.4754) | Error 0.3928(0.3907) Steps 826(824.06) | Grad Norm 0.9632(1.4764) | Total Time 14.00(14.00)\n",
      "Iter 2230 | Time 79.1189(78.2708) | Bit/dim 3.9251(3.9262) | Xent 1.0873(1.0981) | Loss 4.4687(4.4752) | Error 0.3822(0.3905) Steps 826(824.12) | Grad Norm 1.4230(1.4748) | Total Time 14.00(14.00)\n",
      "Iter 2231 | Time 77.7492(78.2551) | Bit/dim 3.9217(3.9260) | Xent 1.0980(1.0981) | Loss 4.4707(4.4751) | Error 0.3909(0.3905) Steps 826(824.17) | Grad Norm 1.7137(1.4819) | Total Time 14.00(14.00)\n",
      "Iter 2232 | Time 77.8817(78.2439) | Bit/dim 3.9247(3.9260) | Xent 1.0812(1.0976) | Loss 4.4653(4.4748) | Error 0.3820(0.3902) Steps 826(824.23) | Grad Norm 0.9049(1.4646) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 29.3485, Epoch Time 509.0746(511.5423), Bit/dim 3.9257(best: 3.9258), Xent 1.0625, Loss 4.4569, Error 0.3777(best: 0.3776)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2233 | Time 79.2111(78.2729) | Bit/dim 3.9276(3.9261) | Xent 1.1000(1.0976) | Loss 4.4776(4.4749) | Error 0.3949(0.3904) Steps 826(824.28) | Grad Norm 1.0213(1.4513) | Total Time 14.00(14.00)\n",
      "Iter 2234 | Time 79.1282(78.2986) | Bit/dim 3.9258(3.9260) | Xent 1.0858(1.0973) | Loss 4.4687(4.4747) | Error 0.3899(0.3904) Steps 826(824.33) | Grad Norm 2.4571(1.4815) | Total Time 14.00(14.00)\n",
      "Iter 2235 | Time 78.1411(78.2939) | Bit/dim 3.9285(3.9261) | Xent 1.0971(1.0973) | Loss 4.4770(4.4748) | Error 0.3940(0.3905) Steps 826(824.38) | Grad Norm 0.7355(1.4591) | Total Time 14.00(14.00)\n",
      "Iter 2236 | Time 79.1057(78.3182) | Bit/dim 3.9206(3.9260) | Xent 1.0920(1.0971) | Loss 4.4666(4.4745) | Error 0.3828(0.3902) Steps 826(824.43) | Grad Norm 0.9421(1.4436) | Total Time 14.00(14.00)\n",
      "Iter 2237 | Time 77.3137(78.2881) | Bit/dim 3.9230(3.9259) | Xent 1.1076(1.0974) | Loss 4.4768(4.4746) | Error 0.3912(0.3903) Steps 826(824.48) | Grad Norm 1.5524(1.4469) | Total Time 14.00(14.00)\n",
      "Iter 2238 | Time 79.9571(78.3382) | Bit/dim 3.9202(3.9257) | Xent 1.0769(1.0968) | Loss 4.4587(4.4741) | Error 0.3818(0.3900) Steps 826(824.53) | Grad Norm 1.7390(1.4556) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 29.4097, Epoch Time 517.7695(511.7291), Bit/dim 3.9265(best: 3.9257), Xent 1.0593, Loss 4.4562, Error 0.3765(best: 0.3776)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2239 | Time 77.9729(78.3272) | Bit/dim 3.9373(3.9260) | Xent 1.0927(1.0967) | Loss 4.4837(4.4744) | Error 0.3871(0.3899) Steps 814(824.21) | Grad Norm 1.2289(1.4488) | Total Time 14.00(14.00)\n",
      "Iter 2240 | Time 79.0041(78.3475) | Bit/dim 3.9205(3.9259) | Xent 1.0998(1.0968) | Loss 4.4704(4.4743) | Error 0.3942(0.3901) Steps 796(823.36) | Grad Norm 1.1312(1.4393) | Total Time 14.00(14.00)\n",
      "Iter 2241 | Time 77.1300(78.3110) | Bit/dim 3.9193(3.9257) | Xent 1.0780(1.0962) | Loss 4.4583(4.4738) | Error 0.3852(0.3899) Steps 808(822.90) | Grad Norm 1.6347(1.4452) | Total Time 14.00(14.00)\n",
      "Iter 2242 | Time 78.7523(78.3242) | Bit/dim 3.9235(3.9256) | Xent 1.1005(1.0964) | Loss 4.4737(4.4738) | Error 0.3934(0.3900) Steps 820(822.82) | Grad Norm 1.7310(1.4537) | Total Time 14.00(14.00)\n",
      "Iter 2243 | Time 78.6848(78.3350) | Bit/dim 3.9241(3.9256) | Xent 1.1156(1.0969) | Loss 4.4819(4.4740) | Error 0.3958(0.3902) Steps 820(822.73) | Grad Norm 1.1029(1.4432) | Total Time 14.00(14.00)\n",
      "Iter 2244 | Time 78.2791(78.3334) | Bit/dim 3.9284(3.9257) | Xent 1.0813(1.0965) | Loss 4.4691(4.4739) | Error 0.3798(0.3899) Steps 814(822.47) | Grad Norm 1.3197(1.4395) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 29.2701, Epoch Time 514.4901(511.8120), Bit/dim 3.9258(best: 3.9257), Xent 1.0576, Loss 4.4547, Error 0.3753(best: 0.3765)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2245 | Time 77.2357(78.3004) | Bit/dim 3.9351(3.9259) | Xent 1.0929(1.0964) | Loss 4.4816(4.4741) | Error 0.3938(0.3900) Steps 826(822.57) | Grad Norm 0.6308(1.4152) | Total Time 14.00(14.00)\n",
      "Iter 2246 | Time 77.8234(78.2861) | Bit/dim 3.9268(3.9260) | Xent 1.0873(1.0961) | Loss 4.4705(4.4740) | Error 0.3890(0.3900) Steps 826(822.68) | Grad Norm 1.6871(1.4234) | Total Time 14.00(14.00)\n",
      "Iter 2247 | Time 77.3878(78.2592) | Bit/dim 3.9123(3.9256) | Xent 1.0632(1.0951) | Loss 4.4439(4.4731) | Error 0.3790(0.3896) Steps 820(822.60) | Grad Norm 1.9022(1.4378) | Total Time 14.00(14.00)\n",
      "Iter 2248 | Time 77.4876(78.2360) | Bit/dim 3.9262(3.9256) | Xent 1.0877(1.0949) | Loss 4.4700(4.4730) | Error 0.3882(0.3896) Steps 832(822.88) | Grad Norm 0.6373(1.4137) | Total Time 14.00(14.00)\n",
      "Iter 2249 | Time 77.2310(78.2059) | Bit/dim 3.9228(3.9255) | Xent 1.0893(1.0947) | Loss 4.4675(4.4728) | Error 0.3926(0.3897) Steps 826(822.97) | Grad Norm 2.2377(1.4385) | Total Time 14.00(14.00)\n",
      "Iter 2250 | Time 78.4378(78.2128) | Bit/dim 3.9214(3.9254) | Xent 1.1011(1.0949) | Loss 4.4719(4.4728) | Error 0.3914(0.3897) Steps 814(822.70) | Grad Norm 1.7141(1.4467) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 29.2605, Epoch Time 510.1647(511.7625), Bit/dim 3.9244(best: 3.9257), Xent 1.0583, Loss 4.4536, Error 0.3775(best: 0.3753)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2251 | Time 79.3397(78.2466) | Bit/dim 3.9289(3.9255) | Xent 1.0522(1.0936) | Loss 4.4549(4.4723) | Error 0.3741(0.3893) Steps 826(822.80) | Grad Norm 1.3168(1.4428) | Total Time 14.00(14.00)\n",
      "Iter 2252 | Time 77.7481(78.2317) | Bit/dim 3.9195(3.9253) | Xent 1.0941(1.0936) | Loss 4.4666(4.4721) | Error 0.3916(0.3893) Steps 826(822.90) | Grad Norm 1.2237(1.4363) | Total Time 14.00(14.00)\n",
      "Iter 2253 | Time 78.0567(78.2264) | Bit/dim 3.9301(3.9254) | Xent 1.0894(1.0935) | Loss 4.4748(4.4722) | Error 0.3890(0.3893) Steps 832(823.17) | Grad Norm 1.3057(1.4323) | Total Time 14.00(14.00)\n",
      "Iter 2254 | Time 78.2790(78.2280) | Bit/dim 3.9125(3.9250) | Xent 1.1027(1.0938) | Loss 4.4638(4.4719) | Error 0.3974(0.3896) Steps 826(823.26) | Grad Norm 0.8116(1.4137) | Total Time 14.00(14.00)\n",
      "Iter 2255 | Time 78.2119(78.2275) | Bit/dim 3.9212(3.9249) | Xent 1.1044(1.0941) | Loss 4.4734(4.4720) | Error 0.3968(0.3898) Steps 808(822.80) | Grad Norm 1.8782(1.4277) | Total Time 14.00(14.00)\n",
      "Iter 2256 | Time 79.4144(78.2631) | Bit/dim 3.9328(3.9252) | Xent 1.1028(1.0944) | Loss 4.4842(4.4724) | Error 0.3942(0.3899) Steps 826(822.89) | Grad Norm 1.7015(1.4359) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 29.6487, Epoch Time 516.0106(511.8900), Bit/dim 3.9244(best: 3.9244), Xent 1.0571, Loss 4.4529, Error 0.3757(best: 0.3753)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2257 | Time 76.5770(78.2125) | Bit/dim 3.9219(3.9251) | Xent 1.0800(1.0939) | Loss 4.4619(4.4720) | Error 0.3916(0.3900) Steps 832(823.17) | Grad Norm 1.1328(1.4268) | Total Time 14.00(14.00)\n",
      "Iter 2258 | Time 78.8064(78.2304) | Bit/dim 3.9180(3.9249) | Xent 1.0900(1.0938) | Loss 4.4630(4.4718) | Error 0.3889(0.3899) Steps 826(823.25) | Grad Norm 1.6451(1.4333) | Total Time 14.00(14.00)\n",
      "Iter 2259 | Time 80.8710(78.3096) | Bit/dim 3.9166(3.9246) | Xent 1.0949(1.0938) | Loss 4.4640(4.4715) | Error 0.3854(0.3898) Steps 826(823.34) | Grad Norm 0.8298(1.4152) | Total Time 14.00(14.00)\n",
      "Iter 2260 | Time 76.9372(78.2684) | Bit/dim 3.9372(3.9250) | Xent 1.0941(1.0939) | Loss 4.4843(4.4719) | Error 0.3884(0.3898) Steps 832(823.60) | Grad Norm 1.3893(1.4144) | Total Time 14.00(14.00)\n",
      "Iter 2261 | Time 75.9934(78.2002) | Bit/dim 3.9174(3.9248) | Xent 1.0802(1.0934) | Loss 4.4576(4.4715) | Error 0.3814(0.3895) Steps 826(823.67) | Grad Norm 0.9290(1.3999) | Total Time 14.00(14.00)\n",
      "Iter 2262 | Time 77.7165(78.1856) | Bit/dim 3.9326(3.9250) | Xent 1.0829(1.0931) | Loss 4.4740(4.4716) | Error 0.3841(0.3893) Steps 826(823.74) | Grad Norm 2.4218(1.4305) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 29.3049, Epoch Time 511.6152(511.8817), Bit/dim 3.9244(best: 3.9244), Xent 1.0557, Loss 4.4522, Error 0.3744(best: 0.3753)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2263 | Time 76.0554(78.1217) | Bit/dim 3.9229(3.9249) | Xent 1.1107(1.0937) | Loss 4.4783(4.4718) | Error 0.3952(0.3895) Steps 832(823.99) | Grad Norm 1.0909(1.4204) | Total Time 14.00(14.00)\n",
      "Iter 2264 | Time 78.2697(78.1262) | Bit/dim 3.9121(3.9246) | Xent 1.0648(1.0928) | Loss 4.4446(4.4709) | Error 0.3832(0.3893) Steps 814(823.69) | Grad Norm 0.5889(1.3954) | Total Time 14.00(14.00)\n",
      "Iter 2265 | Time 77.9962(78.1223) | Bit/dim 3.9244(3.9245) | Xent 1.0928(1.0928) | Loss 4.4708(4.4709) | Error 0.3904(0.3894) Steps 826(823.76) | Grad Norm 1.5009(1.3986) | Total Time 14.00(14.00)\n",
      "Iter 2266 | Time 79.1865(78.1542) | Bit/dim 3.9264(3.9246) | Xent 1.0951(1.0929) | Loss 4.4740(4.4710) | Error 0.3904(0.3894) Steps 826(823.82) | Grad Norm 1.0641(1.3885) | Total Time 14.00(14.00)\n",
      "Iter 2267 | Time 76.2608(78.0974) | Bit/dim 3.9204(3.9245) | Xent 1.0926(1.0929) | Loss 4.4667(4.4709) | Error 0.3908(0.3894) Steps 826(823.89) | Grad Norm 0.6117(1.3652) | Total Time 14.00(14.00)\n",
      "Iter 2268 | Time 76.0051(78.0346) | Bit/dim 3.9325(3.9247) | Xent 1.0741(1.0923) | Loss 4.4696(4.4709) | Error 0.3799(0.3892) Steps 826(823.95) | Grad Norm 1.3148(1.3637) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 29.5478, Epoch Time 508.8996(511.7923), Bit/dim 3.9243(best: 3.9244), Xent 1.0557, Loss 4.4522, Error 0.3732(best: 0.3744)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2269 | Time 81.3609(78.1344) | Bit/dim 3.9324(3.9249) | Xent 1.1155(1.0930) | Loss 4.4901(4.4714) | Error 0.3965(0.3894) Steps 826(824.01) | Grad Norm 0.9331(1.3508) | Total Time 14.00(14.00)\n",
      "Iter 2270 | Time 80.4185(78.2029) | Bit/dim 3.9201(3.9248) | Xent 1.0798(1.0926) | Loss 4.4600(4.4711) | Error 0.3915(0.3894) Steps 826(824.07) | Grad Norm 0.9027(1.3374) | Total Time 14.00(14.00)\n",
      "Iter 2271 | Time 77.6910(78.1876) | Bit/dim 3.9180(3.9246) | Xent 1.0818(1.0923) | Loss 4.4589(4.4707) | Error 0.3872(0.3894) Steps 826(824.13) | Grad Norm 1.1125(1.3306) | Total Time 14.00(14.00)\n",
      "Iter 2272 | Time 78.0274(78.1828) | Bit/dim 3.9260(3.9246) | Xent 1.0625(1.0914) | Loss 4.4573(4.4703) | Error 0.3858(0.3893) Steps 826(824.19) | Grad Norm 0.7645(1.3136) | Total Time 14.00(14.00)\n",
      "Iter 2273 | Time 77.9381(78.1754) | Bit/dim 3.9173(3.9244) | Xent 1.0790(1.0910) | Loss 4.4568(4.4699) | Error 0.3831(0.3891) Steps 826(824.24) | Grad Norm 0.9134(1.3016) | Total Time 14.00(14.00)\n",
      "Iter 2274 | Time 78.9325(78.1982) | Bit/dim 3.9215(3.9243) | Xent 1.0892(1.0910) | Loss 4.4661(4.4698) | Error 0.3836(0.3889) Steps 832(824.47) | Grad Norm 1.1378(1.2967) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 29.6272, Epoch Time 519.3404(512.0187), Bit/dim 3.9239(best: 3.9243), Xent 1.0555, Loss 4.4517, Error 0.3746(best: 0.3732)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2275 | Time 78.0186(78.1928) | Bit/dim 3.9218(3.9243) | Xent 1.0919(1.0910) | Loss 4.4677(4.4697) | Error 0.3910(0.3890) Steps 832(824.70) | Grad Norm 1.2481(1.2953) | Total Time 14.00(14.00)\n",
      "Iter 2276 | Time 79.2939(78.2258) | Bit/dim 3.9140(3.9239) | Xent 1.1042(1.0914) | Loss 4.4662(4.4696) | Error 0.3901(0.3890) Steps 826(824.74) | Grad Norm 2.0421(1.3177) | Total Time 14.00(14.00)\n",
      "Iter 2277 | Time 77.4228(78.2017) | Bit/dim 3.9215(3.9239) | Xent 1.0995(1.0916) | Loss 4.4713(4.4697) | Error 0.3909(0.3891) Steps 820(824.60) | Grad Norm 1.5149(1.3236) | Total Time 14.00(14.00)\n",
      "Iter 2278 | Time 78.5161(78.2111) | Bit/dim 3.9278(3.9240) | Xent 1.0636(1.0908) | Loss 4.4596(4.4694) | Error 0.3791(0.3888) Steps 826(824.64) | Grad Norm 1.2275(1.3207) | Total Time 14.00(14.00)\n",
      "Iter 2279 | Time 77.8512(78.2003) | Bit/dim 3.9236(3.9240) | Xent 1.1012(1.0911) | Loss 4.4742(4.4695) | Error 0.3894(0.3888) Steps 826(824.68) | Grad Norm 1.4117(1.3234) | Total Time 14.00(14.00)\n",
      "Iter 2280 | Time 77.5012(78.1794) | Bit/dim 3.9259(3.9240) | Xent 1.0700(1.0905) | Loss 4.4609(4.4693) | Error 0.3804(0.3885) Steps 826(824.72) | Grad Norm 0.8042(1.3078) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 29.3269, Epoch Time 513.2767(512.0565), Bit/dim 3.9230(best: 3.9239), Xent 1.0537, Loss 4.4498, Error 0.3744(best: 0.3732)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2281 | Time 79.7465(78.2264) | Bit/dim 3.9166(3.9238) | Xent 1.1022(1.0908) | Loss 4.4677(4.4692) | Error 0.3935(0.3887) Steps 832(824.94) | Grad Norm 1.6074(1.3168) | Total Time 14.00(14.00)\n",
      "Iter 2282 | Time 83.1604(78.3744) | Bit/dim 3.9247(3.9238) | Xent 1.0970(1.0910) | Loss 4.4732(4.4693) | Error 0.3919(0.3888) Steps 826(824.97) | Grad Norm 1.2493(1.3148) | Total Time 14.00(14.00)\n",
      "Iter 2283 | Time 78.0822(78.3656) | Bit/dim 3.9276(3.9240) | Xent 1.0850(1.0908) | Loss 4.4701(4.4694) | Error 0.3860(0.3887) Steps 826(825.00) | Grad Norm 1.3111(1.3147) | Total Time 14.00(14.00)\n",
      "Iter 2284 | Time 78.2687(78.3627) | Bit/dim 3.9191(3.9238) | Xent 1.0767(1.0904) | Loss 4.4574(4.4690) | Error 0.3850(0.3886) Steps 826(825.03) | Grad Norm 1.1945(1.3111) | Total Time 14.00(14.00)\n",
      "Iter 2285 | Time 78.1040(78.3550) | Bit/dim 3.9215(3.9237) | Xent 1.0715(1.0898) | Loss 4.4573(4.4687) | Error 0.3866(0.3885) Steps 826(825.06) | Grad Norm 1.0760(1.3040) | Total Time 14.00(14.00)\n",
      "Iter 2286 | Time 78.6026(78.3624) | Bit/dim 3.9220(3.9237) | Xent 1.0760(1.0894) | Loss 4.4600(4.4684) | Error 0.3794(0.3883) Steps 826(825.09) | Grad Norm 1.1205(1.2985) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 29.0341, Epoch Time 520.4012(512.3068), Bit/dim 3.9231(best: 3.9230), Xent 1.0537, Loss 4.4500, Error 0.3747(best: 0.3732)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2287 | Time 76.8799(78.3179) | Bit/dim 3.9230(3.9237) | Xent 1.0629(1.0886) | Loss 4.4545(4.4680) | Error 0.3724(0.3878) Steps 814(824.75) | Grad Norm 0.8518(1.2851) | Total Time 14.00(14.00)\n",
      "Iter 2288 | Time 75.4159(78.2309) | Bit/dim 3.9260(3.9237) | Xent 1.0972(1.0889) | Loss 4.4746(4.4682) | Error 0.3925(0.3879) Steps 826(824.79) | Grad Norm 1.0355(1.2776) | Total Time 14.00(14.00)\n",
      "Iter 2289 | Time 78.7850(78.2475) | Bit/dim 3.9275(3.9239) | Xent 1.1010(1.0892) | Loss 4.4780(4.4685) | Error 0.3866(0.3879) Steps 826(824.83) | Grad Norm 1.0851(1.2719) | Total Time 14.00(14.00)\n",
      "Iter 2290 | Time 78.6712(78.2602) | Bit/dim 3.9141(3.9236) | Xent 1.0966(1.0895) | Loss 4.4624(4.4683) | Error 0.3842(0.3878) Steps 826(824.86) | Grad Norm 0.9080(1.2609) | Total Time 14.00(14.00)\n",
      "Iter 2291 | Time 75.8733(78.1886) | Bit/dim 3.9161(3.9233) | Xent 1.0626(1.0887) | Loss 4.4474(4.4677) | Error 0.3751(0.3874) Steps 826(824.90) | Grad Norm 1.5623(1.2700) | Total Time 14.00(14.00)\n",
      "Iter 2292 | Time 77.8875(78.1796) | Bit/dim 3.9219(3.9233) | Xent 1.0959(1.0889) | Loss 4.4698(4.4677) | Error 0.3885(0.3874) Steps 826(824.93) | Grad Norm 1.1948(1.2677) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 29.7671, Epoch Time 508.5910(512.1953), Bit/dim 3.9234(best: 3.9230), Xent 1.0523, Loss 4.4495, Error 0.3747(best: 0.3732)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2293 | Time 77.9166(78.1717) | Bit/dim 3.9124(3.9230) | Xent 1.0754(1.0885) | Loss 4.4501(4.4672) | Error 0.3831(0.3873) Steps 826(824.96) | Grad Norm 1.5362(1.2758) | Total Time 14.00(14.00)\n",
      "Iter 2294 | Time 76.8494(78.1320) | Bit/dim 3.9227(3.9230) | Xent 1.0619(1.0877) | Loss 4.4537(4.4668) | Error 0.3764(0.3870) Steps 826(824.99) | Grad Norm 1.1748(1.2728) | Total Time 14.00(14.00)\n",
      "Iter 2295 | Time 80.1593(78.1928) | Bit/dim 3.9170(3.9228) | Xent 1.0963(1.0879) | Loss 4.4652(4.4667) | Error 0.3944(0.3872) Steps 826(825.02) | Grad Norm 1.0854(1.2671) | Total Time 14.00(14.00)\n",
      "Iter 2296 | Time 76.0095(78.1273) | Bit/dim 3.9309(3.9230) | Xent 1.0723(1.0875) | Loss 4.4671(4.4668) | Error 0.3844(0.3871) Steps 826(825.05) | Grad Norm 2.0925(1.2919) | Total Time 14.00(14.00)\n",
      "Iter 2297 | Time 79.1657(78.1585) | Bit/dim 3.9248(3.9231) | Xent 1.0814(1.0873) | Loss 4.4655(4.4667) | Error 0.3901(0.3872) Steps 826(825.08) | Grad Norm 1.4313(1.2961) | Total Time 14.00(14.00)\n",
      "Iter 2298 | Time 78.2966(78.1626) | Bit/dim 3.9216(3.9230) | Xent 1.1016(1.0877) | Loss 4.4724(4.4669) | Error 0.3849(0.3871) Steps 826(825.11) | Grad Norm 1.4614(1.3010) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 29.4596, Epoch Time 513.4833(512.2340), Bit/dim 3.9218(best: 3.9230), Xent 1.0521, Loss 4.4479, Error 0.3694(best: 0.3732)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2299 | Time 76.7172(78.1193) | Bit/dim 3.9182(3.9229) | Xent 1.0822(1.0875) | Loss 4.4593(4.4667) | Error 0.3860(0.3871) Steps 826(825.14) | Grad Norm 1.9206(1.3196) | Total Time 14.00(14.00)\n",
      "Iter 2300 | Time 76.2399(78.0629) | Bit/dim 3.9360(3.9233) | Xent 1.0900(1.0876) | Loss 4.4810(4.4671) | Error 0.3925(0.3873) Steps 826(825.16) | Grad Norm 1.2519(1.3176) | Total Time 14.00(14.00)\n",
      "Iter 2301 | Time 76.5343(78.0170) | Bit/dim 3.9181(3.9231) | Xent 1.0766(1.0873) | Loss 4.4564(4.4668) | Error 0.3821(0.3871) Steps 826(825.19) | Grad Norm 1.9625(1.3369) | Total Time 14.00(14.00)\n",
      "Iter 2302 | Time 77.3123(77.9959) | Bit/dim 3.9105(3.9227) | Xent 1.0793(1.0870) | Loss 4.4501(4.4663) | Error 0.3869(0.3871) Steps 820(825.03) | Grad Norm 1.4565(1.3405) | Total Time 14.00(14.00)\n",
      "Iter 2303 | Time 80.9407(78.0842) | Bit/dim 3.9222(3.9227) | Xent 1.0872(1.0871) | Loss 4.4658(4.4663) | Error 0.3918(0.3872) Steps 826(825.06) | Grad Norm 1.4586(1.3441) | Total Time 14.00(14.00)\n",
      "Iter 2304 | Time 76.0873(78.0243) | Bit/dim 3.9170(3.9226) | Xent 1.0766(1.0867) | Loss 4.4554(4.4659) | Error 0.3822(0.3871) Steps 826(825.09) | Grad Norm 1.1175(1.3373) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 29.1448, Epoch Time 508.5615(512.1238), Bit/dim 3.9232(best: 3.9218), Xent 1.0517, Loss 4.4490, Error 0.3750(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2305 | Time 76.4797(77.9780) | Bit/dim 3.9206(3.9225) | Xent 1.0923(1.0869) | Loss 4.4667(4.4660) | Error 0.3894(0.3872) Steps 826(825.12) | Grad Norm 1.1790(1.3325) | Total Time 14.00(14.00)\n",
      "Iter 2306 | Time 78.4789(77.9930) | Bit/dim 3.9116(3.9222) | Xent 1.0850(1.0869) | Loss 4.4541(4.4656) | Error 0.3762(0.3868) Steps 826(825.14) | Grad Norm 1.2547(1.3302) | Total Time 14.00(14.00)\n",
      "Iter 2307 | Time 77.9402(77.9914) | Bit/dim 3.9209(3.9221) | Xent 1.0934(1.0870) | Loss 4.4676(4.4657) | Error 0.3899(0.3869) Steps 826(825.17) | Grad Norm 1.1578(1.3250) | Total Time 14.00(14.00)\n",
      "Iter 2308 | Time 78.1979(77.9976) | Bit/dim 3.9311(3.9224) | Xent 1.0857(1.0870) | Loss 4.4739(4.4659) | Error 0.3952(0.3872) Steps 826(825.19) | Grad Norm 1.3653(1.3262) | Total Time 14.00(14.00)\n",
      "Iter 2309 | Time 76.7756(77.9609) | Bit/dim 3.9135(3.9221) | Xent 1.0581(1.0861) | Loss 4.4425(4.4652) | Error 0.3700(0.3867) Steps 826(825.22) | Grad Norm 1.4041(1.3286) | Total Time 14.00(14.00)\n",
      "Iter 2310 | Time 80.5770(78.0394) | Bit/dim 3.9275(3.9223) | Xent 1.0887(1.0862) | Loss 4.4718(4.4654) | Error 0.3891(0.3867) Steps 826(825.24) | Grad Norm 1.0887(1.3214) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 29.8592, Epoch Time 513.8322(512.1750), Bit/dim 3.9227(best: 3.9218), Xent 1.0501, Loss 4.4477, Error 0.3730(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2311 | Time 79.4975(78.0832) | Bit/dim 3.9305(3.9225) | Xent 1.1002(1.0866) | Loss 4.4806(4.4659) | Error 0.3906(0.3868) Steps 826(825.26) | Grad Norm 0.7817(1.3052) | Total Time 14.00(14.00)\n",
      "Iter 2312 | Time 76.4765(78.0350) | Bit/dim 3.9171(3.9224) | Xent 1.0731(1.0862) | Loss 4.4536(4.4655) | Error 0.3774(0.3866) Steps 826(825.29) | Grad Norm 1.0134(1.2964) | Total Time 14.00(14.00)\n",
      "Iter 2313 | Time 79.1433(78.0682) | Bit/dim 3.9267(3.9225) | Xent 1.1030(1.0867) | Loss 4.4782(4.4659) | Error 0.3944(0.3868) Steps 808(824.77) | Grad Norm 0.8157(1.2820) | Total Time 14.00(14.00)\n",
      "Iter 2314 | Time 75.8832(78.0027) | Bit/dim 3.9058(3.9220) | Xent 1.0865(1.0867) | Loss 4.4490(4.4654) | Error 0.3821(0.3867) Steps 826(824.80) | Grad Norm 0.7194(1.2651) | Total Time 14.00(14.00)\n",
      "Iter 2315 | Time 77.8210(77.9972) | Bit/dim 3.9269(3.9222) | Xent 1.0723(1.0863) | Loss 4.4631(4.4653) | Error 0.3818(0.3865) Steps 814(824.48) | Grad Norm 1.4385(1.2703) | Total Time 14.00(14.00)\n",
      "Iter 2316 | Time 77.3373(77.9774) | Bit/dim 3.9204(3.9221) | Xent 1.0640(1.0856) | Loss 4.4524(4.4649) | Error 0.3731(0.3861) Steps 820(824.35) | Grad Norm 0.9823(1.2617) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 29.4426, Epoch Time 511.5626(512.1567), Bit/dim 3.9215(best: 3.9218), Xent 1.0511, Loss 4.4471, Error 0.3746(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2317 | Time 80.0035(78.0382) | Bit/dim 3.9267(3.9222) | Xent 1.0802(1.0855) | Loss 4.4668(4.4650) | Error 0.3831(0.3860) Steps 826(824.40) | Grad Norm 1.0894(1.2565) | Total Time 14.00(14.00)\n",
      "Iter 2318 | Time 78.0578(78.0388) | Bit/dim 3.9160(3.9221) | Xent 1.0712(1.0850) | Loss 4.4515(4.4646) | Error 0.3810(0.3859) Steps 826(824.44) | Grad Norm 1.2170(1.2553) | Total Time 14.00(14.00)\n",
      "Iter 2319 | Time 76.6119(77.9960) | Bit/dim 3.9146(3.9218) | Xent 1.0791(1.0849) | Loss 4.4542(4.4643) | Error 0.3845(0.3858) Steps 826(824.49) | Grad Norm 0.8635(1.2436) | Total Time 14.00(14.00)\n",
      "Iter 2320 | Time 77.5627(77.9830) | Bit/dim 3.9260(3.9220) | Xent 1.0695(1.0844) | Loss 4.4607(4.4641) | Error 0.3820(0.3857) Steps 826(824.54) | Grad Norm 1.0105(1.2366) | Total Time 14.00(14.00)\n",
      "Iter 2321 | Time 79.2014(78.0195) | Bit/dim 3.9229(3.9220) | Xent 1.0963(1.0847) | Loss 4.4711(4.4644) | Error 0.3868(0.3857) Steps 832(824.76) | Grad Norm 1.2194(1.2361) | Total Time 14.00(14.00)\n",
      "Iter 2322 | Time 76.1273(77.9628) | Bit/dim 3.9230(3.9220) | Xent 1.0804(1.0846) | Loss 4.4632(4.4643) | Error 0.3845(0.3857) Steps 826(824.80) | Grad Norm 0.8917(1.2257) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 29.1903, Epoch Time 512.2078(512.1582), Bit/dim 3.9212(best: 3.9215), Xent 1.0485, Loss 4.4455, Error 0.3724(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2323 | Time 76.9485(77.9323) | Bit/dim 3.9277(3.9222) | Xent 1.0769(1.0844) | Loss 4.4662(4.4644) | Error 0.3836(0.3856) Steps 826(824.83) | Grad Norm 1.1030(1.2221) | Total Time 14.00(14.00)\n",
      "Iter 2324 | Time 77.3824(77.9158) | Bit/dim 3.9230(3.9222) | Xent 1.1013(1.0849) | Loss 4.4737(4.4647) | Error 0.3951(0.3859) Steps 820(824.69) | Grad Norm 1.6524(1.2350) | Total Time 14.00(14.00)\n",
      "Iter 2325 | Time 78.1774(77.9237) | Bit/dim 3.9204(3.9222) | Xent 1.0767(1.0846) | Loss 4.4587(4.4645) | Error 0.3828(0.3858) Steps 826(824.73) | Grad Norm 1.6534(1.2475) | Total Time 14.00(14.00)\n",
      "Iter 2326 | Time 77.0877(77.8986) | Bit/dim 3.9136(3.9219) | Xent 1.0764(1.0844) | Loss 4.4518(4.4641) | Error 0.3805(0.3857) Steps 826(824.77) | Grad Norm 0.8789(1.2365) | Total Time 14.00(14.00)\n",
      "Iter 2327 | Time 76.4257(77.8544) | Bit/dim 3.9176(3.9218) | Xent 1.0939(1.0847) | Loss 4.4646(4.4641) | Error 0.3889(0.3858) Steps 826(824.80) | Grad Norm 2.1621(1.2642) | Total Time 14.00(14.00)\n",
      "Iter 2328 | Time 79.3664(77.8998) | Bit/dim 3.9106(3.9214) | Xent 1.0815(1.0846) | Loss 4.4514(4.4637) | Error 0.3880(0.3858) Steps 826(824.84) | Grad Norm 2.2403(1.2935) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 29.4701, Epoch Time 510.0377(512.0946), Bit/dim 3.9207(best: 3.9212), Xent 1.0477, Loss 4.4445, Error 0.3719(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2329 | Time 76.9223(77.8705) | Bit/dim 3.9257(3.9216) | Xent 1.0702(1.0842) | Loss 4.4609(4.4636) | Error 0.3799(0.3857) Steps 832(825.05) | Grad Norm 0.8718(1.2809) | Total Time 14.00(14.00)\n",
      "Iter 2330 | Time 78.9540(77.9030) | Bit/dim 3.9268(3.9217) | Xent 1.0754(1.0839) | Loss 4.4645(4.4637) | Error 0.3814(0.3855) Steps 826(825.08) | Grad Norm 2.3927(1.3142) | Total Time 14.00(14.00)\n",
      "Iter 2331 | Time 78.2958(77.9148) | Bit/dim 3.9161(3.9216) | Xent 1.0832(1.0839) | Loss 4.4577(4.4635) | Error 0.3871(0.3856) Steps 832(825.29) | Grad Norm 2.0958(1.3377) | Total Time 14.00(14.00)\n",
      "Iter 2332 | Time 77.5228(77.9030) | Bit/dim 3.9184(3.9215) | Xent 1.0869(1.0840) | Loss 4.4619(4.4634) | Error 0.3851(0.3856) Steps 826(825.31) | Grad Norm 0.8286(1.3224) | Total Time 14.00(14.00)\n",
      "Iter 2333 | Time 78.3497(77.9164) | Bit/dim 3.9120(3.9212) | Xent 1.0967(1.0843) | Loss 4.4604(4.4633) | Error 0.3934(0.3858) Steps 826(825.33) | Grad Norm 3.2921(1.3815) | Total Time 14.00(14.00)\n",
      "Iter 2334 | Time 78.3133(77.9283) | Bit/dim 3.9165(3.9210) | Xent 1.0700(1.0839) | Loss 4.4515(4.4630) | Error 0.3801(0.3856) Steps 820(825.17) | Grad Norm 1.4406(1.3833) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 29.1817, Epoch Time 513.0807(512.1242), Bit/dim 3.9209(best: 3.9207), Xent 1.0501, Loss 4.4459, Error 0.3728(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2335 | Time 77.5754(77.9177) | Bit/dim 3.9199(3.9210) | Xent 1.0847(1.0839) | Loss 4.4623(4.4630) | Error 0.3862(0.3856) Steps 826(825.20) | Grad Norm 1.3877(1.3834) | Total Time 14.00(14.00)\n",
      "Iter 2336 | Time 77.8125(77.9146) | Bit/dim 3.9149(3.9208) | Xent 1.0686(1.0835) | Loss 4.4492(4.4626) | Error 0.3786(0.3854) Steps 826(825.22) | Grad Norm 3.2819(1.4403) | Total Time 14.00(14.00)\n",
      "Iter 2337 | Time 80.5640(77.9940) | Bit/dim 3.9173(3.9207) | Xent 1.0865(1.0836) | Loss 4.4606(4.4625) | Error 0.3889(0.3855) Steps 826(825.24) | Grad Norm 2.5532(1.4737) | Total Time 14.00(14.00)\n",
      "Iter 2338 | Time 78.4372(78.0073) | Bit/dim 3.9273(3.9209) | Xent 1.0787(1.0834) | Loss 4.4666(4.4626) | Error 0.3891(0.3856) Steps 820(825.09) | Grad Norm 2.3933(1.5013) | Total Time 14.00(14.00)\n",
      "Iter 2339 | Time 77.1791(77.9825) | Bit/dim 3.9207(3.9209) | Xent 1.0848(1.0835) | Loss 4.4631(4.4626) | Error 0.3864(0.3857) Steps 826(825.11) | Grad Norm 2.8893(1.5430) | Total Time 14.00(14.00)\n",
      "Iter 2340 | Time 80.8583(78.0688) | Bit/dim 3.9168(3.9208) | Xent 1.1010(1.0840) | Loss 4.4673(4.4628) | Error 0.3941(0.3859) Steps 826(825.14) | Grad Norm 3.0900(1.5894) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 29.5137, Epoch Time 517.4076(512.2827), Bit/dim 3.9203(best: 3.9207), Xent 1.0485, Loss 4.4446, Error 0.3744(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2341 | Time 80.3747(78.1379) | Bit/dim 3.9187(3.9207) | Xent 1.0801(1.0839) | Loss 4.4588(4.4627) | Error 0.3851(0.3859) Steps 814(824.81) | Grad Norm 2.1665(1.6067) | Total Time 14.00(14.00)\n",
      "Iter 2342 | Time 77.7327(78.1258) | Bit/dim 3.9146(3.9205) | Xent 1.0732(1.0836) | Loss 4.4512(4.4623) | Error 0.3848(0.3859) Steps 820(824.66) | Grad Norm 2.4583(1.6322) | Total Time 14.00(14.00)\n",
      "Iter 2343 | Time 77.3277(78.1018) | Bit/dim 3.9131(3.9203) | Xent 1.0697(1.0831) | Loss 4.4480(4.4619) | Error 0.3826(0.3858) Steps 826(824.70) | Grad Norm 1.5085(1.6285) | Total Time 14.00(14.00)\n",
      "Iter 2344 | Time 77.4672(78.0828) | Bit/dim 3.9247(3.9204) | Xent 1.0721(1.0828) | Loss 4.4607(4.4618) | Error 0.3869(0.3858) Steps 820(824.56) | Grad Norm 3.1040(1.6728) | Total Time 14.00(14.00)\n",
      "Iter 2345 | Time 76.3988(78.0323) | Bit/dim 3.9266(3.9206) | Xent 1.0718(1.0825) | Loss 4.4625(4.4619) | Error 0.3851(0.3858) Steps 826(824.60) | Grad Norm 2.2167(1.6891) | Total Time 14.00(14.00)\n",
      "Iter 2346 | Time 78.8929(78.0581) | Bit/dim 3.9176(3.9205) | Xent 1.1095(1.0833) | Loss 4.4724(4.4622) | Error 0.3960(0.3861) Steps 826(824.65) | Grad Norm 1.1813(1.6739) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 29.1738, Epoch Time 512.8444(512.2995), Bit/dim 3.9205(best: 3.9203), Xent 1.0461, Loss 4.4436, Error 0.3705(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2347 | Time 78.6224(78.0750) | Bit/dim 3.9213(3.9206) | Xent 1.0865(1.0834) | Loss 4.4646(4.4623) | Error 0.3859(0.3861) Steps 826(824.69) | Grad Norm 2.8208(1.7083) | Total Time 14.00(14.00)\n",
      "Iter 2348 | Time 78.3717(78.0839) | Bit/dim 3.9194(3.9205) | Xent 1.0679(1.0829) | Loss 4.4534(4.4620) | Error 0.3774(0.3858) Steps 814(824.37) | Grad Norm 1.5936(1.7048) | Total Time 14.00(14.00)\n",
      "Iter 2349 | Time 76.2210(78.0280) | Bit/dim 3.9150(3.9204) | Xent 1.0951(1.0833) | Loss 4.4626(4.4620) | Error 0.3866(0.3858) Steps 832(824.59) | Grad Norm 1.3057(1.6929) | Total Time 14.00(14.00)\n",
      "Iter 2350 | Time 77.1549(78.0018) | Bit/dim 3.9176(3.9203) | Xent 1.0837(1.0833) | Loss 4.4595(4.4619) | Error 0.3899(0.3860) Steps 808(824.10) | Grad Norm 1.8252(1.6968) | Total Time 14.00(14.00)\n",
      "Iter 2351 | Time 78.7759(78.0251) | Bit/dim 3.9242(3.9204) | Xent 1.0632(1.0827) | Loss 4.4558(4.4617) | Error 0.3710(0.3855) Steps 826(824.15) | Grad Norm 1.8645(1.7019) | Total Time 14.00(14.00)\n",
      "Iter 2352 | Time 75.5198(77.9499) | Bit/dim 3.9158(3.9203) | Xent 1.0718(1.0824) | Loss 4.4517(4.4614) | Error 0.3792(0.3853) Steps 826(824.21) | Grad Norm 1.0353(1.6819) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 29.3846, Epoch Time 509.4730(512.2147), Bit/dim 3.9199(best: 3.9203), Xent 1.0472, Loss 4.4435, Error 0.3714(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2353 | Time 77.8237(77.9461) | Bit/dim 3.9209(3.9203) | Xent 1.0666(1.0819) | Loss 4.4542(4.4612) | Error 0.3809(0.3852) Steps 820(824.08) | Grad Norm 2.0458(1.6928) | Total Time 14.00(14.00)\n",
      "Iter 2354 | Time 80.0905(78.0105) | Bit/dim 3.9153(3.9201) | Xent 1.0892(1.0821) | Loss 4.4599(4.4612) | Error 0.3861(0.3852) Steps 826(824.14) | Grad Norm 1.1201(1.6756) | Total Time 14.00(14.00)\n",
      "Iter 2355 | Time 75.7618(77.9430) | Bit/dim 3.9141(3.9200) | Xent 1.0659(1.0816) | Loss 4.4471(4.4608) | Error 0.3762(0.3850) Steps 826(824.20) | Grad Norm 1.1389(1.6595) | Total Time 14.00(14.00)\n",
      "Iter 2356 | Time 78.4402(77.9579) | Bit/dim 3.9210(3.9200) | Xent 1.0678(1.0812) | Loss 4.4549(4.4606) | Error 0.3835(0.3849) Steps 832(824.43) | Grad Norm 0.9794(1.6391) | Total Time 14.00(14.00)\n",
      "Iter 2357 | Time 77.9150(77.9566) | Bit/dim 3.9163(3.9199) | Xent 1.0782(1.0811) | Loss 4.4554(4.4604) | Error 0.3855(0.3849) Steps 826(824.48) | Grad Norm 1.4545(1.6336) | Total Time 14.00(14.00)\n",
      "Iter 2358 | Time 78.5977(77.9759) | Bit/dim 3.9267(3.9201) | Xent 1.0688(1.0807) | Loss 4.4611(4.4605) | Error 0.3801(0.3848) Steps 826(824.52) | Grad Norm 0.9609(1.6134) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 29.8236, Epoch Time 513.8934(512.2651), Bit/dim 3.9200(best: 3.9199), Xent 1.0465, Loss 4.4432, Error 0.3718(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2359 | Time 76.7546(77.9392) | Bit/dim 3.9126(3.9199) | Xent 1.0667(1.0803) | Loss 4.4459(4.4600) | Error 0.3831(0.3847) Steps 826(824.57) | Grad Norm 1.4195(1.6076) | Total Time 14.00(14.00)\n",
      "Iter 2360 | Time 75.5030(77.8661) | Bit/dim 3.9174(3.9198) | Xent 1.0831(1.0804) | Loss 4.4589(4.4600) | Error 0.3832(0.3847) Steps 826(824.61) | Grad Norm 1.1736(1.5945) | Total Time 14.00(14.00)\n",
      "Iter 2361 | Time 79.0210(77.9008) | Bit/dim 3.9198(3.9198) | Xent 1.0869(1.0806) | Loss 4.4633(4.4601) | Error 0.3834(0.3846) Steps 826(824.65) | Grad Norm 0.9135(1.5741) | Total Time 14.00(14.00)\n",
      "Iter 2362 | Time 80.3856(77.9753) | Bit/dim 3.9250(3.9199) | Xent 1.0725(1.0804) | Loss 4.4612(4.4601) | Error 0.3850(0.3847) Steps 826(824.69) | Grad Norm 0.7465(1.5493) | Total Time 14.00(14.00)\n",
      "Iter 2363 | Time 78.7508(77.9986) | Bit/dim 3.9127(3.9197) | Xent 1.1055(1.0811) | Loss 4.4654(4.4603) | Error 0.3939(0.3849) Steps 826(824.73) | Grad Norm 1.9256(1.5606) | Total Time 14.00(14.00)\n",
      "Iter 2364 | Time 78.0818(78.0011) | Bit/dim 3.9229(3.9198) | Xent 1.0678(1.0807) | Loss 4.4568(4.4602) | Error 0.3778(0.3847) Steps 814(824.41) | Grad Norm 0.8045(1.5379) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 29.2998, Epoch Time 513.4223(512.2998), Bit/dim 3.9193(best: 3.9199), Xent 1.0435, Loss 4.4411, Error 0.3717(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2365 | Time 77.9323(77.9990) | Bit/dim 3.9167(3.9197) | Xent 1.0659(1.0803) | Loss 4.4497(4.4599) | Error 0.3775(0.3845) Steps 826(824.46) | Grad Norm 1.1733(1.5270) | Total Time 14.00(14.00)\n",
      "Iter 2366 | Time 77.0123(77.9694) | Bit/dim 3.9131(3.9195) | Xent 1.0639(1.0798) | Loss 4.4450(4.4594) | Error 0.3731(0.3842) Steps 826(824.50) | Grad Norm 1.1934(1.5169) | Total Time 14.00(14.00)\n",
      "Iter 2367 | Time 77.3514(77.9509) | Bit/dim 3.9197(3.9195) | Xent 1.0839(1.0799) | Loss 4.4617(4.4595) | Error 0.3865(0.3842) Steps 832(824.73) | Grad Norm 1.3563(1.5121) | Total Time 14.00(14.00)\n",
      "Iter 2368 | Time 78.2411(77.9596) | Bit/dim 3.9171(3.9195) | Xent 1.0853(1.0801) | Loss 4.4598(4.4595) | Error 0.3859(0.3843) Steps 832(824.95) | Grad Norm 1.5635(1.5137) | Total Time 14.00(14.00)\n",
      "Iter 2369 | Time 76.2980(77.9097) | Bit/dim 3.9187(3.9194) | Xent 1.0863(1.0803) | Loss 4.4619(4.4596) | Error 0.3841(0.3843) Steps 826(824.98) | Grad Norm 1.4434(1.5116) | Total Time 14.00(14.00)\n",
      "Iter 2370 | Time 80.0618(77.9743) | Bit/dim 3.9222(3.9195) | Xent 1.0629(1.0797) | Loss 4.4537(4.4594) | Error 0.3839(0.3843) Steps 838(825.37) | Grad Norm 1.5998(1.5142) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 29.4899, Epoch Time 512.4304(512.3037), Bit/dim 3.9191(best: 3.9193), Xent 1.0420, Loss 4.4401, Error 0.3710(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2371 | Time 75.8080(77.9093) | Bit/dim 3.9156(3.9194) | Xent 1.0766(1.0796) | Loss 4.4539(4.4592) | Error 0.3809(0.3842) Steps 826(825.39) | Grad Norm 1.8467(1.5242) | Total Time 14.00(14.00)\n",
      "Iter 2372 | Time 75.3029(77.8311) | Bit/dim 3.9281(3.9197) | Xent 1.0752(1.0795) | Loss 4.4657(4.4594) | Error 0.3844(0.3842) Steps 826(825.41) | Grad Norm 2.4439(1.5518) | Total Time 14.00(14.00)\n",
      "Iter 2373 | Time 76.1938(77.7820) | Bit/dim 3.9291(3.9199) | Xent 1.0670(1.0791) | Loss 4.4625(4.4595) | Error 0.3829(0.3841) Steps 826(825.42) | Grad Norm 2.0335(1.5662) | Total Time 14.00(14.00)\n",
      "Iter 2374 | Time 77.2604(77.7664) | Bit/dim 3.9114(3.9197) | Xent 1.0851(1.0793) | Loss 4.4540(4.4593) | Error 0.3874(0.3842) Steps 832(825.62) | Grad Norm 1.8068(1.5734) | Total Time 14.00(14.00)\n",
      "Iter 2375 | Time 77.8081(77.7676) | Bit/dim 3.9022(3.9192) | Xent 1.0608(1.0788) | Loss 4.4326(4.4585) | Error 0.3804(0.3841) Steps 820(825.45) | Grad Norm 1.1670(1.5613) | Total Time 14.00(14.00)\n",
      "Iter 2376 | Time 76.1606(77.7194) | Bit/dim 3.9195(3.9192) | Xent 1.0768(1.0787) | Loss 4.4579(4.4585) | Error 0.3865(0.3842) Steps 826(825.47) | Grad Norm 1.2196(1.5510) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 29.6315, Epoch Time 503.6813(512.0451), Bit/dim 3.9178(best: 3.9191), Xent 1.0424, Loss 4.4390, Error 0.3703(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2377 | Time 75.3903(77.6495) | Bit/dim 3.9081(3.9188) | Xent 1.0735(1.0785) | Loss 4.4449(4.4581) | Error 0.3815(0.3841) Steps 826(825.49) | Grad Norm 1.4356(1.5475) | Total Time 14.00(14.00)\n",
      "Iter 2378 | Time 77.9782(77.6594) | Bit/dim 3.9144(3.9187) | Xent 1.0683(1.0782) | Loss 4.4485(4.4578) | Error 0.3834(0.3841) Steps 826(825.50) | Grad Norm 1.3364(1.5412) | Total Time 14.00(14.00)\n",
      "Iter 2379 | Time 78.5935(77.6874) | Bit/dim 3.9183(3.9187) | Xent 1.0858(1.0785) | Loss 4.4612(4.4579) | Error 0.3926(0.3843) Steps 814(825.16) | Grad Norm 1.6163(1.5435) | Total Time 14.00(14.00)\n",
      "Iter 2380 | Time 79.0526(77.7284) | Bit/dim 3.9269(3.9189) | Xent 1.0740(1.0783) | Loss 4.4639(4.4581) | Error 0.3851(0.3844) Steps 826(825.18) | Grad Norm 1.5126(1.5425) | Total Time 14.00(14.00)\n",
      "Iter 2381 | Time 77.4251(77.7193) | Bit/dim 3.9237(3.9191) | Xent 1.0644(1.0779) | Loss 4.4559(4.4580) | Error 0.3765(0.3841) Steps 826(825.21) | Grad Norm 2.5265(1.5721) | Total Time 14.00(14.00)\n",
      "Iter 2382 | Time 77.7375(77.7198) | Bit/dim 3.9162(3.9190) | Xent 1.0746(1.0778) | Loss 4.4535(4.4579) | Error 0.3829(0.3841) Steps 826(825.23) | Grad Norm 0.9227(1.5526) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 29.4084, Epoch Time 511.4877(512.0283), Bit/dim 3.9185(best: 3.9178), Xent 1.0437, Loss 4.4404, Error 0.3698(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2383 | Time 77.0897(77.7009) | Bit/dim 3.9163(3.9189) | Xent 1.0834(1.0780) | Loss 4.4580(4.4579) | Error 0.3861(0.3841) Steps 826(825.25) | Grad Norm 1.9566(1.5647) | Total Time 14.00(14.00)\n",
      "Iter 2384 | Time 77.6754(77.7001) | Bit/dim 3.9137(3.9188) | Xent 1.0723(1.0778) | Loss 4.4498(4.4577) | Error 0.3759(0.3839) Steps 814(824.91) | Grad Norm 1.9795(1.5771) | Total Time 14.00(14.00)\n",
      "Iter 2385 | Time 77.8723(77.7053) | Bit/dim 3.9175(3.9187) | Xent 1.0633(1.0774) | Loss 4.4491(4.4574) | Error 0.3739(0.3836) Steps 826(824.95) | Grad Norm 0.8730(1.5560) | Total Time 14.00(14.00)\n",
      "Iter 2386 | Time 77.8647(77.7101) | Bit/dim 3.9118(3.9185) | Xent 1.0702(1.0772) | Loss 4.4469(4.4571) | Error 0.3775(0.3834) Steps 826(824.98) | Grad Norm 2.3260(1.5791) | Total Time 14.00(14.00)\n",
      "Iter 2387 | Time 77.6097(77.7071) | Bit/dim 3.9217(3.9186) | Xent 1.0659(1.0768) | Loss 4.4546(4.4570) | Error 0.3805(0.3833) Steps 826(825.01) | Grad Norm 1.3883(1.5734) | Total Time 14.00(14.00)\n",
      "Iter 2388 | Time 78.9969(77.7458) | Bit/dim 3.9221(3.9187) | Xent 1.0707(1.0766) | Loss 4.4574(4.4570) | Error 0.3761(0.3831) Steps 826(825.04) | Grad Norm 1.6103(1.5745) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 29.5519, Epoch Time 512.2528(512.0351), Bit/dim 3.9186(best: 3.9178), Xent 1.0435, Loss 4.4404, Error 0.3695(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2389 | Time 78.3059(77.7626) | Bit/dim 3.9266(3.9189) | Xent 1.0846(1.0769) | Loss 4.4689(4.4574) | Error 0.3852(0.3832) Steps 832(825.25) | Grad Norm 2.5421(1.6035) | Total Time 14.00(14.00)\n",
      "Iter 2390 | Time 75.5011(77.6947) | Bit/dim 3.9191(3.9190) | Xent 1.0427(1.0758) | Loss 4.4405(4.4569) | Error 0.3749(0.3829) Steps 826(825.27) | Grad Norm 1.1410(1.5896) | Total Time 14.00(14.00)\n",
      "Iter 2391 | Time 76.1375(77.6480) | Bit/dim 3.9121(3.9187) | Xent 1.0591(1.0753) | Loss 4.4416(4.4564) | Error 0.3745(0.3827) Steps 826(825.29) | Grad Norm 2.3102(1.6113) | Total Time 14.00(14.00)\n",
      "Iter 2392 | Time 76.3200(77.6082) | Bit/dim 3.9141(3.9186) | Xent 1.1027(1.0762) | Loss 4.4654(4.4567) | Error 0.3922(0.3830) Steps 820(825.13) | Grad Norm 2.6028(1.6410) | Total Time 14.00(14.00)\n",
      "Iter 2393 | Time 79.8102(77.6742) | Bit/dim 3.9257(3.9188) | Xent 1.0898(1.0766) | Loss 4.4705(4.4571) | Error 0.3841(0.3830) Steps 826(825.16) | Grad Norm 1.3281(1.6316) | Total Time 14.00(14.00)\n",
      "Iter 2394 | Time 81.2122(77.7804) | Bit/dim 3.9093(3.9185) | Xent 1.0580(1.0760) | Loss 4.4383(4.4565) | Error 0.3798(0.3829) Steps 814(824.83) | Grad Norm 2.2447(1.6500) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 29.6239, Epoch Time 512.4374(512.0471), Bit/dim 3.9174(best: 3.9178), Xent 1.0397, Loss 4.4373, Error 0.3710(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2395 | Time 77.7350(77.7790) | Bit/dim 3.9155(3.9184) | Xent 1.0893(1.0764) | Loss 4.4602(4.4566) | Error 0.3891(0.3831) Steps 814(824.50) | Grad Norm 2.8641(1.6864) | Total Time 14.00(14.00)\n",
      "Iter 2396 | Time 77.5926(77.7734) | Bit/dim 3.9047(3.9180) | Xent 1.0699(1.0762) | Loss 4.4396(4.4561) | Error 0.3815(0.3830) Steps 832(824.73) | Grad Norm 1.3624(1.6767) | Total Time 14.00(14.00)\n",
      "Iter 2397 | Time 79.0212(77.8109) | Bit/dim 3.9169(3.9180) | Xent 1.0552(1.0756) | Loss 4.4445(4.4558) | Error 0.3771(0.3829) Steps 820(824.58) | Grad Norm 2.0537(1.6880) | Total Time 14.00(14.00)\n",
      "Iter 2398 | Time 76.9838(77.7860) | Bit/dim 3.9106(3.9178) | Xent 1.0640(1.0752) | Loss 4.4426(4.4554) | Error 0.3791(0.3827) Steps 826(824.63) | Grad Norm 1.4798(1.6818) | Total Time 14.00(14.00)\n",
      "Iter 2399 | Time 77.9286(77.7903) | Bit/dim 3.9273(3.9181) | Xent 1.0621(1.0748) | Loss 4.4583(4.4555) | Error 0.3794(0.3826) Steps 826(824.67) | Grad Norm 2.3707(1.7024) | Total Time 14.00(14.00)\n",
      "Iter 2400 | Time 76.6544(77.7562) | Bit/dim 3.9248(3.9183) | Xent 1.0819(1.0751) | Loss 4.4657(4.4558) | Error 0.3792(0.3825) Steps 826(824.71) | Grad Norm 1.1129(1.6848) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 29.3063, Epoch Time 510.7649(512.0087), Bit/dim 3.9174(best: 3.9174), Xent 1.0398, Loss 4.4373, Error 0.3713(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2401 | Time 78.0156(77.7640) | Bit/dim 3.9120(3.9181) | Xent 1.0622(1.0747) | Loss 4.4432(4.4554) | Error 0.3799(0.3825) Steps 808(824.21) | Grad Norm 1.5612(1.6811) | Total Time 14.00(14.00)\n",
      "Iter 2402 | Time 77.8039(77.7652) | Bit/dim 3.9266(3.9183) | Xent 1.0727(1.0746) | Loss 4.4629(4.4556) | Error 0.3845(0.3825) Steps 832(824.44) | Grad Norm 1.0414(1.6619) | Total Time 14.00(14.00)\n",
      "Iter 2403 | Time 78.7000(77.7933) | Bit/dim 3.9172(3.9183) | Xent 1.0759(1.0747) | Loss 4.4552(4.4556) | Error 0.3844(0.3826) Steps 826(824.49) | Grad Norm 1.4010(1.6540) | Total Time 14.00(14.00)\n",
      "Iter 2404 | Time 77.4273(77.7823) | Bit/dim 3.9151(3.9182) | Xent 1.0757(1.0747) | Loss 4.4529(4.4555) | Error 0.3885(0.3828) Steps 826(824.53) | Grad Norm 1.5326(1.6504) | Total Time 14.00(14.00)\n",
      "Iter 2405 | Time 77.8082(77.7831) | Bit/dim 3.9119(3.9180) | Xent 1.0537(1.0741) | Loss 4.4387(4.4550) | Error 0.3756(0.3825) Steps 826(824.58) | Grad Norm 1.3344(1.6409) | Total Time 14.00(14.00)\n",
      "Iter 2406 | Time 78.3615(77.8004) | Bit/dim 3.9112(3.9178) | Xent 1.0613(1.0737) | Loss 4.4419(4.4546) | Error 0.3729(0.3823) Steps 826(824.62) | Grad Norm 1.2278(1.6285) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 29.4434, Epoch Time 512.9626(512.0373), Bit/dim 3.9180(best: 3.9174), Xent 1.0393, Loss 4.4376, Error 0.3679(best: 0.3694)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2407 | Time 76.7557(77.7691) | Bit/dim 3.9145(3.9177) | Xent 1.0784(1.0738) | Loss 4.4537(4.4546) | Error 0.3846(0.3823) Steps 826(824.66) | Grad Norm 1.9211(1.6373) | Total Time 14.00(14.00)\n",
      "Iter 2408 | Time 79.1256(77.8098) | Bit/dim 3.9160(3.9177) | Xent 1.0680(1.0736) | Loss 4.4500(4.4545) | Error 0.3834(0.3824) Steps 826(824.70) | Grad Norm 1.3456(1.6285) | Total Time 14.00(14.00)\n",
      "Iter 2409 | Time 76.5139(77.7709) | Bit/dim 3.9110(3.9175) | Xent 1.0645(1.0734) | Loss 4.4433(4.4541) | Error 0.3841(0.3824) Steps 832(824.92) | Grad Norm 1.2524(1.6173) | Total Time 14.00(14.00)\n",
      "Iter 2410 | Time 77.9564(77.7765) | Bit/dim 3.9153(3.9174) | Xent 1.0721(1.0733) | Loss 4.4514(4.4541) | Error 0.3812(0.3824) Steps 832(825.13) | Grad Norm 1.8942(1.6256) | Total Time 14.00(14.00)\n",
      "Iter 2411 | Time 78.2019(77.7892) | Bit/dim 3.9250(3.9176) | Xent 1.0564(1.0728) | Loss 4.4532(4.4540) | Error 0.3748(0.3821) Steps 832(825.34) | Grad Norm 1.6620(1.6267) | Total Time 14.00(14.00)\n",
      "Iter 2412 | Time 77.6604(77.7854) | Bit/dim 3.9122(3.9175) | Xent 1.0638(1.0725) | Loss 4.4440(4.4537) | Error 0.3702(0.3818) Steps 826(825.36) | Grad Norm 1.8321(1.6328) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 29.5390, Epoch Time 511.2333(512.0132), Bit/dim 3.9169(best: 3.9174), Xent 1.0390, Loss 4.4364, Error 0.3676(best: 0.3679)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2413 | Time 78.1312(77.7957) | Bit/dim 3.9191(3.9175) | Xent 1.0589(1.0721) | Loss 4.4485(4.4536) | Error 0.3741(0.3816) Steps 814(825.02) | Grad Norm 1.7693(1.6369) | Total Time 14.00(14.00)\n",
      "Iter 2414 | Time 77.7874(77.7955) | Bit/dim 3.9126(3.9174) | Xent 1.0824(1.0724) | Loss 4.4538(4.4536) | Error 0.3825(0.3816) Steps 826(825.05) | Grad Norm 1.6214(1.6365) | Total Time 14.00(14.00)\n",
      "Iter 2415 | Time 77.0080(77.7719) | Bit/dim 3.9029(3.9169) | Xent 1.0510(1.0718) | Loss 4.4284(4.4528) | Error 0.3709(0.3813) Steps 814(824.72) | Grad Norm 2.4566(1.6611) | Total Time 14.00(14.00)\n",
      "Iter 2416 | Time 80.0531(77.8403) | Bit/dim 3.9093(3.9167) | Xent 1.0784(1.0720) | Loss 4.4485(4.4527) | Error 0.3868(0.3814) Steps 808(824.21) | Grad Norm 1.5412(1.6575) | Total Time 14.00(14.00)\n",
      "Iter 2417 | Time 79.1892(77.8808) | Bit/dim 3.9275(3.9170) | Xent 1.0728(1.0720) | Loss 4.4639(4.4530) | Error 0.3798(0.3814) Steps 832(824.45) | Grad Norm 2.3111(1.6771) | Total Time 14.00(14.00)\n",
      "Iter 2418 | Time 78.2277(77.8912) | Bit/dim 3.9224(3.9172) | Xent 1.0688(1.0719) | Loss 4.4568(4.4531) | Error 0.3825(0.3814) Steps 826(824.49) | Grad Norm 2.0138(1.6872) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 29.4107, Epoch Time 515.2894(512.1114), Bit/dim 3.9175(best: 3.9169), Xent 1.0395, Loss 4.4372, Error 0.3683(best: 0.3676)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2419 | Time 78.9828(77.9239) | Bit/dim 3.9147(3.9171) | Xent 1.0765(1.0721) | Loss 4.4530(4.4531) | Error 0.3801(0.3814) Steps 832(824.72) | Grad Norm 2.4720(1.7107) | Total Time 14.00(14.00)\n",
      "Iter 2420 | Time 78.3170(77.9357) | Bit/dim 3.9109(3.9169) | Xent 1.0799(1.0723) | Loss 4.4509(4.4531) | Error 0.3890(0.3816) Steps 826(824.76) | Grad Norm 1.5909(1.7071) | Total Time 14.00(14.00)\n",
      "Iter 2421 | Time 77.2826(77.9161) | Bit/dim 3.9259(3.9172) | Xent 1.0747(1.0724) | Loss 4.4633(4.4534) | Error 0.3799(0.3816) Steps 814(824.43) | Grad Norm 2.6001(1.7339) | Total Time 14.00(14.00)\n",
      "Iter 2422 | Time 78.4024(77.9307) | Bit/dim 3.9131(3.9171) | Xent 1.0706(1.0723) | Loss 4.4484(4.4532) | Error 0.3749(0.3814) Steps 814(824.12) | Grad Norm 2.1516(1.7464) | Total Time 14.00(14.00)\n",
      "Iter 2423 | Time 77.9469(77.9312) | Bit/dim 3.9107(3.9169) | Xent 1.0609(1.0720) | Loss 4.4412(4.4529) | Error 0.3776(0.3812) Steps 832(824.36) | Grad Norm 2.5064(1.7692) | Total Time 14.00(14.00)\n",
      "Iter 2424 | Time 79.6951(77.9841) | Bit/dim 3.9133(3.9168) | Xent 1.0589(1.0716) | Loss 4.4427(4.4526) | Error 0.3759(0.3811) Steps 826(824.41) | Grad Norm 2.1905(1.7819) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 29.5189, Epoch Time 515.5835(512.2156), Bit/dim 3.9170(best: 3.9169), Xent 1.0415, Loss 4.4378, Error 0.3692(best: 0.3676)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2425 | Time 76.6637(77.9445) | Bit/dim 3.9108(3.9166) | Xent 1.0718(1.0716) | Loss 4.4467(4.4524) | Error 0.3854(0.3812) Steps 826(824.46) | Grad Norm 2.0499(1.7899) | Total Time 14.00(14.00)\n",
      "Iter 2426 | Time 77.6318(77.9351) | Bit/dim 3.9173(3.9166) | Xent 1.0746(1.0717) | Loss 4.4546(4.4525) | Error 0.3748(0.3810) Steps 826(824.50) | Grad Norm 0.8942(1.7631) | Total Time 14.00(14.00)\n",
      "Iter 2427 | Time 77.0817(77.9095) | Bit/dim 3.9116(3.9165) | Xent 1.0648(1.0715) | Loss 4.4440(4.4522) | Error 0.3778(0.3809) Steps 826(824.55) | Grad Norm 3.3522(1.8107) | Total Time 14.00(14.00)\n",
      "Iter 2428 | Time 76.6953(77.8731) | Bit/dim 3.9177(3.9165) | Xent 1.0584(1.0711) | Loss 4.4469(4.4520) | Error 0.3676(0.3805) Steps 808(824.05) | Grad Norm 1.4246(1.7991) | Total Time 14.00(14.00)\n",
      "Iter 2429 | Time 78.3241(77.8866) | Bit/dim 3.9167(3.9165) | Xent 1.0521(1.0705) | Loss 4.4427(4.4518) | Error 0.3814(0.3805) Steps 820(823.93) | Grad Norm 2.1610(1.8100) | Total Time 14.00(14.00)\n",
      "Iter 2430 | Time 77.2633(77.8679) | Bit/dim 3.9191(3.9166) | Xent 1.0861(1.0710) | Loss 4.4622(4.4521) | Error 0.3825(0.3806) Steps 826(823.99) | Grad Norm 2.1337(1.8197) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 29.4302, Epoch Time 508.5304(512.1051), Bit/dim 3.9162(best: 3.9169), Xent 1.0355, Loss 4.4339, Error 0.3708(best: 0.3676)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2431 | Time 76.4123(77.8243) | Bit/dim 3.9180(3.9166) | Xent 1.0569(1.0706) | Loss 4.4464(4.4519) | Error 0.3764(0.3805) Steps 826(824.05) | Grad Norm 1.3715(1.8063) | Total Time 14.00(14.00)\n",
      "Iter 2432 | Time 79.9054(77.8867) | Bit/dim 3.9147(3.9166) | Xent 1.0580(1.0702) | Loss 4.4437(4.4517) | Error 0.3781(0.3804) Steps 826(824.11) | Grad Norm 1.7593(1.8049) | Total Time 14.00(14.00)\n",
      "Iter 2433 | Time 76.6947(77.8509) | Bit/dim 3.9141(3.9165) | Xent 1.0721(1.0702) | Loss 4.4501(4.4516) | Error 0.3816(0.3804) Steps 826(824.17) | Grad Norm 1.9360(1.8088) | Total Time 14.00(14.00)\n",
      "Iter 2434 | Time 79.3872(77.8970) | Bit/dim 3.9093(3.9163) | Xent 1.0676(1.0702) | Loss 4.4431(4.4514) | Error 0.3840(0.3805) Steps 826(824.22) | Grad Norm 1.3521(1.7951) | Total Time 14.00(14.00)\n",
      "Iter 2435 | Time 74.8991(77.8071) | Bit/dim 3.9126(3.9162) | Xent 1.0572(1.0698) | Loss 4.4412(4.4511) | Error 0.3795(0.3805) Steps 826(824.27) | Grad Norm 2.0906(1.8040) | Total Time 14.00(14.00)\n",
      "Iter 2436 | Time 75.3284(77.7327) | Bit/dim 3.9248(3.9164) | Xent 1.0632(1.0696) | Loss 4.4564(4.4512) | Error 0.3760(0.3804) Steps 826(824.33) | Grad Norm 2.0446(1.8112) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 29.5742, Epoch Time 513.6545(512.1515), Bit/dim 3.9159(best: 3.9162), Xent 1.0368, Loss 4.4342, Error 0.3690(best: 0.3676)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2437 | Time 75.0357(77.6518) | Bit/dim 3.9109(3.9163) | Xent 1.0609(1.0693) | Loss 4.4413(4.4509) | Error 0.3770(0.3803) Steps 826(824.38) | Grad Norm 1.1581(1.7916) | Total Time 14.00(14.00)\n",
      "Iter 2438 | Time 78.9610(77.6911) | Bit/dim 3.9190(3.9163) | Xent 1.0537(1.0688) | Loss 4.4458(4.4508) | Error 0.3711(0.3800) Steps 832(824.61) | Grad Norm 2.0235(1.7985) | Total Time 14.00(14.00)\n",
      "Iter 2439 | Time 74.8826(77.6068) | Bit/dim 3.9157(3.9163) | Xent 1.0681(1.0688) | Loss 4.4497(4.4507) | Error 0.3796(0.3800) Steps 826(824.65) | Grad Norm 2.0793(1.8070) | Total Time 14.00(14.00)\n",
      "Iter 2440 | Time 79.0854(77.6512) | Bit/dim 3.9198(3.9164) | Xent 1.0724(1.0689) | Loss 4.4560(4.4509) | Error 0.3805(0.3800) Steps 820(824.51) | Grad Norm 1.3533(1.7934) | Total Time 14.00(14.00)\n",
      "Iter 2441 | Time 77.2293(77.6385) | Bit/dim 3.9072(3.9162) | Xent 1.0696(1.0689) | Loss 4.4421(4.4506) | Error 0.3809(0.3800) Steps 826(824.55) | Grad Norm 2.2986(1.8085) | Total Time 14.00(14.00)\n",
      "Iter 2442 | Time 77.9276(77.6472) | Bit/dim 3.9139(3.9161) | Xent 1.0414(1.0681) | Loss 4.4346(4.4501) | Error 0.3698(0.3797) Steps 826(824.60) | Grad Norm 2.5805(1.8317) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 29.2476, Epoch Time 507.7675(512.0200), Bit/dim 3.9157(best: 3.9159), Xent 1.0346, Loss 4.4330, Error 0.3694(best: 0.3676)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2443 | Time 78.1963(77.6637) | Bit/dim 3.9146(3.9160) | Xent 1.0692(1.0682) | Loss 4.4492(4.4501) | Error 0.3829(0.3798) Steps 826(824.64) | Grad Norm 1.2652(1.8147) | Total Time 14.00(14.00)\n",
      "Iter 2444 | Time 80.0940(77.7366) | Bit/dim 3.9236(3.9163) | Xent 1.0685(1.0682) | Loss 4.4578(4.4503) | Error 0.3775(0.3798) Steps 832(824.86) | Grad Norm 2.6972(1.8411) | Total Time 14.00(14.00)\n",
      "Iter 2445 | Time 78.6938(77.7653) | Bit/dim 3.9181(3.9163) | Xent 1.0548(1.0678) | Loss 4.4455(4.4502) | Error 0.3754(0.3796) Steps 832(825.07) | Grad Norm 1.9572(1.8446) | Total Time 14.00(14.00)\n",
      "Iter 2446 | Time 76.9194(77.7399) | Bit/dim 3.9142(3.9163) | Xent 1.0675(1.0678) | Loss 4.4479(4.4501) | Error 0.3814(0.3797) Steps 826(825.10) | Grad Norm 1.3030(1.8284) | Total Time 14.00(14.00)\n",
      "Iter 2447 | Time 79.2610(77.7855) | Bit/dim 3.8953(3.9156) | Xent 1.0778(1.0681) | Loss 4.4342(4.4497) | Error 0.3845(0.3798) Steps 832(825.31) | Grad Norm 3.2413(1.8708) | Total Time 14.00(14.00)\n",
      "Iter 2448 | Time 76.8925(77.7588) | Bit/dim 3.9189(3.9157) | Xent 1.0434(1.0673) | Loss 4.4406(4.4494) | Error 0.3691(0.3795) Steps 826(825.33) | Grad Norm 1.1234(1.8483) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 29.3127, Epoch Time 514.7209(512.1010), Bit/dim 3.9147(best: 3.9157), Xent 1.0346, Loss 4.4320, Error 0.3670(best: 0.3676)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2449 | Time 77.3804(77.7474) | Bit/dim 3.9178(3.9158) | Xent 1.0492(1.0668) | Loss 4.4424(4.4492) | Error 0.3759(0.3794) Steps 814(824.99) | Grad Norm 1.7062(1.8441) | Total Time 14.00(14.00)\n",
      "Iter 2450 | Time 77.0566(77.7267) | Bit/dim 3.9264(3.9161) | Xent 1.0519(1.0663) | Loss 4.4524(4.4493) | Error 0.3671(0.3790) Steps 826(825.02) | Grad Norm 0.9141(1.8162) | Total Time 14.00(14.00)\n",
      "Iter 2451 | Time 76.4372(77.6880) | Bit/dim 3.9055(3.9158) | Xent 1.0576(1.0661) | Loss 4.4343(4.4488) | Error 0.3768(0.3790) Steps 832(825.23) | Grad Norm 1.8397(1.8169) | Total Time 14.00(14.00)\n",
      "Iter 2452 | Time 75.5000(77.6224) | Bit/dim 3.9142(3.9157) | Xent 1.0843(1.0666) | Loss 4.4563(4.4490) | Error 0.3808(0.3790) Steps 832(825.43) | Grad Norm 1.4225(1.8051) | Total Time 14.00(14.00)\n",
      "Iter 2453 | Time 78.8030(77.6578) | Bit/dim 3.9078(3.9155) | Xent 1.0704(1.0667) | Loss 4.4430(4.4489) | Error 0.3810(0.3791) Steps 826(825.45) | Grad Norm 2.1853(1.8165) | Total Time 14.00(14.00)\n",
      "Iter 2454 | Time 78.4673(77.6821) | Bit/dim 3.9098(3.9153) | Xent 1.0576(1.0665) | Loss 4.4386(4.4486) | Error 0.3748(0.3789) Steps 832(825.65) | Grad Norm 2.4116(1.8343) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 29.3152, Epoch Time 508.5041(511.9931), Bit/dim 3.9148(best: 3.9147), Xent 1.0310, Loss 4.4303, Error 0.3650(best: 0.3670)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2455 | Time 78.9597(77.7204) | Bit/dim 3.9098(3.9152) | Xent 1.0569(1.0662) | Loss 4.4383(4.4482) | Error 0.3710(0.3787) Steps 838(826.02) | Grad Norm 0.8081(1.8035) | Total Time 14.00(14.00)\n",
      "Iter 2456 | Time 78.4661(77.7428) | Bit/dim 3.9141(3.9151) | Xent 1.0932(1.0670) | Loss 4.4607(4.4486) | Error 0.3901(0.3790) Steps 832(826.20) | Grad Norm 2.9000(1.8364) | Total Time 14.00(14.00)\n",
      "Iter 2457 | Time 78.2575(77.7582) | Bit/dim 3.9208(3.9153) | Xent 1.0797(1.0674) | Loss 4.4606(4.4490) | Error 0.3858(0.3792) Steps 832(826.37) | Grad Norm 1.0548(1.8130) | Total Time 14.00(14.00)\n",
      "Iter 2458 | Time 78.6864(77.7860) | Bit/dim 3.9120(3.9152) | Xent 1.0657(1.0673) | Loss 4.4449(4.4489) | Error 0.3730(0.3791) Steps 826(826.36) | Grad Norm 1.0353(1.7896) | Total Time 14.00(14.00)\n",
      "Iter 2459 | Time 77.6825(77.7829) | Bit/dim 3.9115(3.9151) | Xent 1.0463(1.0667) | Loss 4.4347(4.4484) | Error 0.3754(0.3789) Steps 838(826.71) | Grad Norm 2.0591(1.7977) | Total Time 14.00(14.00)\n",
      "Iter 2460 | Time 78.1962(77.7953) | Bit/dim 3.9079(3.9149) | Xent 1.0481(1.0661) | Loss 4.4320(4.4479) | Error 0.3729(0.3788) Steps 832(826.87) | Grad Norm 1.3598(1.7846) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 29.4236, Epoch Time 522.5866(512.3109), Bit/dim 3.9149(best: 3.9147), Xent 1.0318, Loss 4.4308, Error 0.3664(best: 0.3650)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2461 | Time 77.1827(77.7770) | Bit/dim 3.9217(3.9151) | Xent 1.0623(1.0660) | Loss 4.4529(4.4481) | Error 0.3806(0.3788) Steps 838(827.20) | Grad Norm 0.9924(1.7608) | Total Time 14.00(14.00)\n",
      "Iter 2462 | Time 80.3842(77.8552) | Bit/dim 3.9149(3.9151) | Xent 1.0370(1.0651) | Loss 4.4334(4.4476) | Error 0.3666(0.3785) Steps 838(827.52) | Grad Norm 1.1678(1.7430) | Total Time 14.00(14.00)\n",
      "Iter 2463 | Time 80.1411(77.9238) | Bit/dim 3.9132(3.9150) | Xent 1.0598(1.0650) | Loss 4.4431(4.4475) | Error 0.3714(0.3782) Steps 832(827.66) | Grad Norm 1.3529(1.7313) | Total Time 14.00(14.00)\n",
      "Iter 2464 | Time 79.4207(77.9687) | Bit/dim 3.9141(3.9150) | Xent 1.0633(1.0649) | Loss 4.4457(4.4475) | Error 0.3790(0.3783) Steps 832(827.79) | Grad Norm 1.8613(1.7352) | Total Time 14.00(14.00)\n",
      "Iter 2465 | Time 76.7580(77.9323) | Bit/dim 3.9031(3.9146) | Xent 1.0643(1.0649) | Loss 4.4353(4.4471) | Error 0.3828(0.3784) Steps 844(828.28) | Grad Norm 0.6633(1.7031) | Total Time 14.00(14.00)\n",
      "Iter 2466 | Time 76.5169(77.8899) | Bit/dim 3.9133(3.9146) | Xent 1.0740(1.0652) | Loss 4.4503(4.4472) | Error 0.3799(0.3784) Steps 826(828.21) | Grad Norm 1.8583(1.7077) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 29.3847, Epoch Time 523.6955(512.6525), Bit/dim 3.9135(best: 3.9147), Xent 1.0323, Loss 4.4297, Error 0.3687(best: 0.3650)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2467 | Time 77.1627(77.8681) | Bit/dim 3.9255(3.9149) | Xent 1.0711(1.0654) | Loss 4.4611(4.4476) | Error 0.3862(0.3787) Steps 832(828.32) | Grad Norm 1.4913(1.7012) | Total Time 14.00(14.00)\n",
      "Iter 2468 | Time 78.8909(77.8988) | Bit/dim 3.9081(3.9147) | Xent 1.0630(1.0653) | Loss 4.4396(4.4474) | Error 0.3790(0.3787) Steps 826(828.25) | Grad Norm 1.2076(1.6864) | Total Time 14.00(14.00)\n",
      "Iter 2469 | Time 76.7927(77.8656) | Bit/dim 3.9156(3.9147) | Xent 1.0742(1.0656) | Loss 4.4527(4.4475) | Error 0.3811(0.3788) Steps 826(828.18) | Grad Norm 1.7945(1.6897) | Total Time 14.00(14.00)\n",
      "Iter 2470 | Time 77.6342(77.8586) | Bit/dim 3.9081(3.9146) | Xent 1.0452(1.0649) | Loss 4.4307(4.4470) | Error 0.3796(0.3788) Steps 826(828.12) | Grad Norm 2.0312(1.6999) | Total Time 14.00(14.00)\n",
      "Iter 2471 | Time 78.1849(77.8684) | Bit/dim 3.9231(3.9148) | Xent 1.0416(1.0642) | Loss 4.4439(4.4469) | Error 0.3688(0.3785) Steps 820(827.87) | Grad Norm 1.8401(1.7041) | Total Time 14.00(14.00)\n",
      "Iter 2472 | Time 78.3056(77.8815) | Bit/dim 3.8968(3.9143) | Xent 1.0632(1.0642) | Loss 4.4284(4.4464) | Error 0.3781(0.3785) Steps 838(828.18) | Grad Norm 2.1625(1.7179) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 29.8134, Epoch Time 519.0629(512.8448), Bit/dim 3.9129(best: 3.9135), Xent 1.0339, Loss 4.4298, Error 0.3682(best: 0.3650)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2473 | Time 78.1405(77.8893) | Bit/dim 3.9168(3.9143) | Xent 1.0695(1.0644) | Loss 4.4516(4.4465) | Error 0.3795(0.3785) Steps 838(828.47) | Grad Norm 2.3794(1.7377) | Total Time 14.00(14.00)\n",
      "Iter 2474 | Time 78.3531(77.9032) | Bit/dim 3.9205(3.9145) | Xent 1.0717(1.0646) | Loss 4.4563(4.4468) | Error 0.3830(0.3786) Steps 832(828.58) | Grad Norm 1.3512(1.7261) | Total Time 14.00(14.00)\n",
      "Iter 2475 | Time 77.1482(77.8806) | Bit/dim 3.9082(3.9143) | Xent 1.0516(1.0642) | Loss 4.4340(4.4464) | Error 0.3742(0.3785) Steps 838(828.86) | Grad Norm 1.8761(1.7306) | Total Time 14.00(14.00)\n",
      "Iter 2476 | Time 78.8939(77.9110) | Bit/dim 3.9056(3.9141) | Xent 1.0498(1.0638) | Loss 4.4305(4.4460) | Error 0.3779(0.3785) Steps 832(828.96) | Grad Norm 1.7570(1.7314) | Total Time 14.00(14.00)\n",
      "Iter 2477 | Time 76.6337(77.8727) | Bit/dim 3.9157(3.9141) | Xent 1.0724(1.0640) | Loss 4.4519(4.4461) | Error 0.3790(0.3785) Steps 844(829.41) | Grad Norm 2.5932(1.7573) | Total Time 14.00(14.00)\n",
      "Iter 2478 | Time 77.1679(77.8515) | Bit/dim 3.9147(3.9141) | Xent 1.0580(1.0638) | Loss 4.4437(4.4461) | Error 0.3722(0.3783) Steps 832(829.48) | Grad Norm 1.5596(1.7513) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 29.5827, Epoch Time 511.4861(512.8040), Bit/dim 3.9137(best: 3.9129), Xent 1.0313, Loss 4.4293, Error 0.3657(best: 0.3650)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2479 | Time 78.4681(77.8700) | Bit/dim 3.9194(3.9143) | Xent 1.0588(1.0637) | Loss 4.4488(4.4461) | Error 0.3706(0.3781) Steps 826(829.38) | Grad Norm 1.3456(1.7392) | Total Time 14.00(14.00)\n",
      "Iter 2480 | Time 78.1852(77.8795) | Bit/dim 3.9068(3.9141) | Xent 1.0683(1.0638) | Loss 4.4409(4.4460) | Error 0.3795(0.3781) Steps 832(829.46) | Grad Norm 2.0419(1.7483) | Total Time 14.00(14.00)\n",
      "Iter 2481 | Time 79.8500(77.9386) | Bit/dim 3.9158(3.9141) | Xent 1.0580(1.0637) | Loss 4.4448(4.4460) | Error 0.3895(0.3785) Steps 826(829.36) | Grad Norm 1.2241(1.7325) | Total Time 14.00(14.00)\n",
      "Iter 2482 | Time 76.4537(77.8940) | Bit/dim 3.9136(3.9141) | Xent 1.0742(1.0640) | Loss 4.4507(4.4461) | Error 0.3820(0.3786) Steps 832(829.43) | Grad Norm 2.3462(1.7509) | Total Time 14.00(14.00)\n",
      "Iter 2483 | Time 77.2154(77.8737) | Bit/dim 3.9054(3.9138) | Xent 1.0498(1.0636) | Loss 4.4303(4.4456) | Error 0.3782(0.3786) Steps 814(828.97) | Grad Norm 1.7460(1.7508) | Total Time 14.00(14.00)\n",
      "Iter 2484 | Time 78.9289(77.9053) | Bit/dim 3.9099(3.9137) | Xent 1.0591(1.0634) | Loss 4.4395(4.4454) | Error 0.3730(0.3784) Steps 832(829.06) | Grad Norm 1.2518(1.7358) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 29.8147, Epoch Time 514.5626(512.8568), Bit/dim 3.9141(best: 3.9129), Xent 1.0325, Loss 4.4304, Error 0.3647(best: 0.3650)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2485 | Time 78.4178(77.9207) | Bit/dim 3.9155(3.9138) | Xent 1.0682(1.0636) | Loss 4.4496(4.4456) | Error 0.3781(0.3784) Steps 826(828.97) | Grad Norm 2.3991(1.7557) | Total Time 14.00(14.00)\n",
      "Iter 2486 | Time 77.8011(77.9171) | Bit/dim 3.9026(3.9134) | Xent 1.0474(1.0631) | Loss 4.4263(4.4450) | Error 0.3704(0.3781) Steps 820(828.70) | Grad Norm 1.3600(1.7438) | Total Time 14.00(14.00)\n",
      "Iter 2487 | Time 79.4908(77.9643) | Bit/dim 3.9109(3.9134) | Xent 1.0654(1.0631) | Loss 4.4436(4.4449) | Error 0.3764(0.3781) Steps 838(828.98) | Grad Norm 2.0032(1.7516) | Total Time 14.00(14.00)\n",
      "Iter 2488 | Time 78.2785(77.9738) | Bit/dim 3.9175(3.9135) | Xent 1.0628(1.0631) | Loss 4.4489(4.4451) | Error 0.3760(0.3780) Steps 838(829.25) | Grad Norm 1.8365(1.7542) | Total Time 14.00(14.00)\n",
      "Iter 2489 | Time 77.9018(77.9716) | Bit/dim 3.9111(3.9134) | Xent 1.0652(1.0632) | Loss 4.4437(4.4450) | Error 0.3818(0.3781) Steps 838(829.51) | Grad Norm 1.5307(1.7475) | Total Time 14.00(14.00)\n",
      "Iter 2490 | Time 77.9101(77.9698) | Bit/dim 3.9136(3.9134) | Xent 1.0622(1.0632) | Loss 4.4447(4.4450) | Error 0.3726(0.3780) Steps 832(829.59) | Grad Norm 1.8541(1.7507) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 29.6740, Epoch Time 514.8815(512.9175), Bit/dim 3.9130(best: 3.9129), Xent 1.0311, Loss 4.4286, Error 0.3665(best: 0.3647)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2491 | Time 78.7816(77.9941) | Bit/dim 3.8948(3.9129) | Xent 1.0649(1.0632) | Loss 4.4273(4.4445) | Error 0.3784(0.3780) Steps 832(829.66) | Grad Norm 2.0184(1.7587) | Total Time 14.00(14.00)\n",
      "Iter 2492 | Time 78.9352(78.0223) | Bit/dim 3.9141(3.9129) | Xent 1.0562(1.0630) | Loss 4.4422(4.4444) | Error 0.3804(0.3781) Steps 826(829.55) | Grad Norm 1.0309(1.7369) | Total Time 14.00(14.00)\n",
      "Iter 2493 | Time 79.5250(78.0674) | Bit/dim 3.9098(3.9128) | Xent 1.0721(1.0633) | Loss 4.4459(4.4445) | Error 0.3842(0.3782) Steps 826(829.44) | Grad Norm 2.5280(1.7606) | Total Time 14.00(14.00)\n",
      "Iter 2494 | Time 78.5033(78.0805) | Bit/dim 3.9244(3.9132) | Xent 1.0455(1.0627) | Loss 4.4472(4.4445) | Error 0.3689(0.3780) Steps 820(829.16) | Grad Norm 1.7706(1.7609) | Total Time 14.00(14.00)\n",
      "Iter 2495 | Time 77.1878(78.0537) | Bit/dim 3.9179(3.9133) | Xent 1.0457(1.0622) | Loss 4.4408(4.4444) | Error 0.3790(0.3780) Steps 838(829.43) | Grad Norm 3.0773(1.8004) | Total Time 14.00(14.00)\n",
      "Iter 2496 | Time 78.0411(78.0533) | Bit/dim 3.9078(3.9131) | Xent 1.0524(1.0619) | Loss 4.4340(4.4441) | Error 0.3678(0.3777) Steps 832(829.50) | Grad Norm 1.9719(1.8055) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 29.5735, Epoch Time 516.0416(513.0112), Bit/dim 3.9114(best: 3.9129), Xent 1.0296, Loss 4.4262, Error 0.3654(best: 0.3647)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2497 | Time 78.4352(78.0648) | Bit/dim 3.9038(3.9129) | Xent 1.0524(1.0617) | Loss 4.4300(4.4437) | Error 0.3725(0.3775) Steps 832(829.58) | Grad Norm 1.5492(1.7978) | Total Time 14.00(14.00)\n",
      "Iter 2498 | Time 76.6995(78.0238) | Bit/dim 3.9068(3.9127) | Xent 1.0426(1.0611) | Loss 4.4281(4.4432) | Error 0.3704(0.3773) Steps 826(829.47) | Grad Norm 2.3493(1.8144) | Total Time 14.00(14.00)\n",
      "Iter 2499 | Time 79.3380(78.0633) | Bit/dim 3.9137(3.9127) | Xent 1.0698(1.0613) | Loss 4.4486(4.4434) | Error 0.3814(0.3774) Steps 832(829.55) | Grad Norm 1.5122(1.8053) | Total Time 14.00(14.00)\n",
      "Iter 2500 | Time 77.5550(78.0480) | Bit/dim 3.9166(3.9128) | Xent 1.0559(1.0612) | Loss 4.4445(4.4434) | Error 0.3771(0.3774) Steps 832(829.62) | Grad Norm 2.0918(1.8139) | Total Time 14.00(14.00)\n",
      "Iter 2501 | Time 77.9610(78.0454) | Bit/dim 3.9148(3.9129) | Xent 1.0498(1.0608) | Loss 4.4397(4.4433) | Error 0.3736(0.3773) Steps 838(829.87) | Grad Norm 2.1135(1.8229) | Total Time 14.00(14.00)\n",
      "Iter 2502 | Time 77.6267(78.0328) | Bit/dim 3.9062(3.9127) | Xent 1.0703(1.0611) | Loss 4.4414(4.4432) | Error 0.3832(0.3775) Steps 826(829.76) | Grad Norm 1.1633(1.8031) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 29.2725, Epoch Time 512.2560(512.9886), Bit/dim 3.9121(best: 3.9114), Xent 1.0331, Loss 4.4287, Error 0.3659(best: 0.3647)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2503 | Time 78.0554(78.0335) | Bit/dim 3.9025(3.9124) | Xent 1.0657(1.0613) | Loss 4.4353(4.4430) | Error 0.3845(0.3777) Steps 838(830.00) | Grad Norm 2.5671(1.8260) | Total Time 14.00(14.00)\n",
      "Iter 2504 | Time 78.2046(78.0387) | Bit/dim 3.9097(3.9123) | Xent 1.0619(1.0613) | Loss 4.4406(4.4429) | Error 0.3728(0.3776) Steps 826(829.88) | Grad Norm 1.6962(1.8221) | Total Time 14.00(14.00)\n",
      "Iter 2505 | Time 76.8825(78.0040) | Bit/dim 3.9151(3.9124) | Xent 1.0303(1.0603) | Loss 4.4302(4.4426) | Error 0.3638(0.3771) Steps 832(829.95) | Grad Norm 1.4033(1.8096) | Total Time 14.00(14.00)\n",
      "Iter 2506 | Time 76.9826(77.9733) | Bit/dim 3.9141(3.9124) | Xent 1.0636(1.0604) | Loss 4.4459(4.4427) | Error 0.3802(0.3772) Steps 832(830.01) | Grad Norm 2.6081(1.8335) | Total Time 14.00(14.00)\n",
      "Iter 2507 | Time 80.4162(78.0466) | Bit/dim 3.9200(3.9127) | Xent 1.0467(1.0600) | Loss 4.4433(4.4427) | Error 0.3745(0.3772) Steps 832(830.07) | Grad Norm 1.5571(1.8252) | Total Time 14.00(14.00)\n",
      "Iter 2508 | Time 79.0055(78.0754) | Bit/dim 3.9075(3.9125) | Xent 1.0690(1.0603) | Loss 4.4420(4.4427) | Error 0.3769(0.3771) Steps 838(830.31) | Grad Norm 2.1794(1.8359) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 29.5285, Epoch Time 518.9521(513.1675), Bit/dim 3.9120(best: 3.9114), Xent 1.0288, Loss 4.4264, Error 0.3655(best: 0.3647)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2509 | Time 78.0774(78.0754) | Bit/dim 3.9242(3.9129) | Xent 1.0406(1.0597) | Loss 4.4445(4.4427) | Error 0.3684(0.3769) Steps 832(830.36) | Grad Norm 1.2697(1.8189) | Total Time 14.00(14.00)\n",
      "Iter 2510 | Time 76.9588(78.0419) | Bit/dim 3.9115(3.9128) | Xent 1.0535(1.0595) | Loss 4.4383(4.4426) | Error 0.3735(0.3768) Steps 838(830.59) | Grad Norm 1.3010(1.8033) | Total Time 14.00(14.00)\n",
      "Iter 2511 | Time 79.4257(78.0835) | Bit/dim 3.9111(3.9128) | Xent 1.0530(1.0593) | Loss 4.4376(4.4424) | Error 0.3760(0.3768) Steps 826(830.45) | Grad Norm 1.6977(1.8002) | Total Time 14.00(14.00)\n",
      "Iter 2512 | Time 78.5639(78.0979) | Bit/dim 3.9102(3.9127) | Xent 1.0716(1.0597) | Loss 4.4460(4.4425) | Error 0.3848(0.3770) Steps 820(830.13) | Grad Norm 1.5930(1.7940) | Total Time 14.00(14.00)\n",
      "Iter 2513 | Time 77.7557(78.0876) | Bit/dim 3.9029(3.9124) | Xent 1.0544(1.0595) | Loss 4.4301(4.4422) | Error 0.3765(0.3770) Steps 838(830.37) | Grad Norm 2.6310(1.8191) | Total Time 14.00(14.00)\n",
      "Iter 2514 | Time 78.2370(78.0921) | Bit/dim 3.9071(3.9122) | Xent 1.0657(1.0597) | Loss 4.4400(4.4421) | Error 0.3820(0.3771) Steps 838(830.60) | Grad Norm 2.4970(1.8394) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 29.7340, Epoch Time 516.2250(513.2592), Bit/dim 3.9121(best: 3.9114), Xent 1.0259, Loss 4.4250, Error 0.3600(best: 0.3647)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2515 | Time 78.7907(78.1130) | Bit/dim 3.9185(3.9124) | Xent 1.0424(1.0592) | Loss 4.4397(4.4420) | Error 0.3739(0.3770) Steps 832(830.64) | Grad Norm 1.0900(1.8169) | Total Time 14.00(14.00)\n",
      "Iter 2516 | Time 79.0138(78.1401) | Bit/dim 3.9055(3.9122) | Xent 1.0338(1.0584) | Loss 4.4224(4.4414) | Error 0.3748(0.3770) Steps 832(830.68) | Grad Norm 2.9922(1.8522) | Total Time 14.00(14.00)\n",
      "Iter 2517 | Time 77.4818(78.1203) | Bit/dim 3.9059(3.9120) | Xent 1.0675(1.0587) | Loss 4.4397(4.4414) | Error 0.3800(0.3771) Steps 832(830.72) | Grad Norm 1.6780(1.8470) | Total Time 14.00(14.00)\n",
      "Iter 2518 | Time 79.3613(78.1576) | Bit/dim 3.9035(3.9118) | Xent 1.0735(1.0592) | Loss 4.4403(4.4413) | Error 0.3850(0.3773) Steps 838(830.94) | Grad Norm 1.7779(1.8449) | Total Time 14.00(14.00)\n",
      "Iter 2519 | Time 79.9700(78.2119) | Bit/dim 3.9074(3.9116) | Xent 1.0577(1.0591) | Loss 4.4363(4.4412) | Error 0.3790(0.3773) Steps 838(831.15) | Grad Norm 2.1725(1.8547) | Total Time 14.00(14.00)\n",
      "Iter 2520 | Time 80.0247(78.2663) | Bit/dim 3.9208(3.9119) | Xent 1.0647(1.0593) | Loss 4.4532(4.4416) | Error 0.3804(0.3774) Steps 838(831.36) | Grad Norm 1.0153(1.8295) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 29.5155, Epoch Time 519.5887(513.4491), Bit/dim 3.9119(best: 3.9114), Xent 1.0259, Loss 4.4248, Error 0.3633(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2521 | Time 76.4260(78.2111) | Bit/dim 3.9039(3.9117) | Xent 1.0609(1.0593) | Loss 4.4343(4.4413) | Error 0.3789(0.3775) Steps 826(831.20) | Grad Norm 1.7749(1.8279) | Total Time 14.00(14.00)\n",
      "Iter 2522 | Time 78.6712(78.2249) | Bit/dim 3.9059(3.9115) | Xent 1.0274(1.0584) | Loss 4.4196(4.4407) | Error 0.3674(0.3772) Steps 832(831.22) | Grad Norm 1.6248(1.8218) | Total Time 14.00(14.00)\n",
      "Iter 2523 | Time 76.9812(78.1876) | Bit/dim 3.9125(3.9115) | Xent 1.0353(1.0577) | Loss 4.4302(4.4404) | Error 0.3766(0.3772) Steps 832(831.24) | Grad Norm 1.4989(1.8121) | Total Time 14.00(14.00)\n",
      "Iter 2524 | Time 77.4187(78.1645) | Bit/dim 3.9127(3.9116) | Xent 1.0503(1.0575) | Loss 4.4379(4.4403) | Error 0.3789(0.3772) Steps 832(831.27) | Grad Norm 2.9063(1.8449) | Total Time 14.00(14.00)\n",
      "Iter 2525 | Time 77.2724(78.1378) | Bit/dim 3.9145(3.9117) | Xent 1.0623(1.0576) | Loss 4.4456(4.4405) | Error 0.3794(0.3773) Steps 838(831.47) | Grad Norm 2.3604(1.8604) | Total Time 14.00(14.00)\n",
      "Iter 2526 | Time 75.9804(78.0730) | Bit/dim 3.9103(3.9116) | Xent 1.0592(1.0577) | Loss 4.4399(4.4404) | Error 0.3780(0.3773) Steps 832(831.48) | Grad Norm 1.7018(1.8556) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 29.7167, Epoch Time 508.0963(513.2885), Bit/dim 3.9111(best: 3.9114), Xent 1.0298, Loss 4.4260, Error 0.3677(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2527 | Time 75.8179(78.0054) | Bit/dim 3.9050(3.9114) | Xent 1.0464(1.0573) | Loss 4.4282(4.4401) | Error 0.3776(0.3773) Steps 832(831.50) | Grad Norm 3.0087(1.8902) | Total Time 14.00(14.00)\n",
      "Iter 2528 | Time 78.0268(78.0060) | Bit/dim 3.9131(3.9115) | Xent 1.0449(1.0569) | Loss 4.4356(4.4399) | Error 0.3769(0.3773) Steps 832(831.52) | Grad Norm 1.6087(1.8818) | Total Time 14.00(14.00)\n",
      "Iter 2529 | Time 76.9296(77.9737) | Bit/dim 3.9110(3.9115) | Xent 1.0447(1.0566) | Loss 4.4334(4.4397) | Error 0.3688(0.3770) Steps 838(831.71) | Grad Norm 2.7772(1.9086) | Total Time 14.00(14.00)\n",
      "Iter 2530 | Time 76.7850(77.9381) | Bit/dim 3.9123(3.9115) | Xent 1.0648(1.0568) | Loss 4.4447(4.4399) | Error 0.3779(0.3771) Steps 826(831.54) | Grad Norm 1.6634(1.9013) | Total Time 14.00(14.00)\n",
      "Iter 2531 | Time 77.5255(77.9257) | Bit/dim 3.9144(3.9116) | Xent 1.0639(1.0570) | Loss 4.4463(4.4401) | Error 0.3756(0.3770) Steps 832(831.55) | Grad Norm 1.3576(1.8850) | Total Time 14.00(14.00)\n",
      "Iter 2532 | Time 80.1553(77.9926) | Bit/dim 3.9043(3.9113) | Xent 1.0308(1.0562) | Loss 4.4196(4.4395) | Error 0.3691(0.3768) Steps 832(831.57) | Grad Norm 1.8266(1.8832) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 29.8118, Epoch Time 510.7320(513.2118), Bit/dim 3.9101(best: 3.9111), Xent 1.0269, Loss 4.4235, Error 0.3650(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2533 | Time 79.9040(78.0499) | Bit/dim 3.9110(3.9113) | Xent 1.0749(1.0568) | Loss 4.4485(4.4397) | Error 0.3894(0.3772) Steps 820(831.22) | Grad Norm 2.1249(1.8905) | Total Time 14.00(14.00)\n",
      "Iter 2534 | Time 78.2233(78.0551) | Bit/dim 3.9114(3.9113) | Xent 1.0385(1.0563) | Loss 4.4307(4.4395) | Error 0.3602(0.3767) Steps 820(830.88) | Grad Norm 1.0934(1.8666) | Total Time 14.00(14.00)\n",
      "Iter 2535 | Time 74.7061(77.9547) | Bit/dim 3.9156(3.9115) | Xent 1.0457(1.0559) | Loss 4.4384(4.4394) | Error 0.3715(0.3765) Steps 844(831.28) | Grad Norm 3.3659(1.9115) | Total Time 14.00(14.00)\n",
      "Iter 2536 | Time 78.5023(77.9711) | Bit/dim 3.9089(3.9114) | Xent 1.0471(1.0557) | Loss 4.4324(4.4392) | Error 0.3686(0.3763) Steps 838(831.48) | Grad Norm 2.3424(1.9245) | Total Time 14.00(14.00)\n",
      "Iter 2537 | Time 76.2955(77.9208) | Bit/dim 3.9135(3.9115) | Xent 1.0590(1.0558) | Loss 4.4430(4.4393) | Error 0.3774(0.3763) Steps 832(831.49) | Grad Norm 1.8812(1.9232) | Total Time 14.00(14.00)\n",
      "Iter 2538 | Time 77.9365(77.9213) | Bit/dim 3.8993(3.9111) | Xent 1.0395(1.0553) | Loss 4.4191(4.4387) | Error 0.3710(0.3761) Steps 832(831.51) | Grad Norm 2.9420(1.9537) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 29.7633, Epoch Time 510.8329(513.1405), Bit/dim 3.9102(best: 3.9101), Xent 1.0260, Loss 4.4232, Error 0.3630(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2539 | Time 77.8235(77.9184) | Bit/dim 3.9069(3.9110) | Xent 1.0507(1.0552) | Loss 4.4323(4.4385) | Error 0.3709(0.3760) Steps 838(831.70) | Grad Norm 1.4430(1.9384) | Total Time 14.00(14.00)\n",
      "Iter 2540 | Time 79.6880(77.9714) | Bit/dim 3.9102(3.9109) | Xent 1.0590(1.0553) | Loss 4.4397(4.4386) | Error 0.3806(0.3761) Steps 844(832.07) | Grad Norm 1.9817(1.9397) | Total Time 14.00(14.00)\n",
      "Iter 2541 | Time 76.4929(77.9271) | Bit/dim 3.8952(3.9105) | Xent 1.0580(1.0553) | Loss 4.4242(4.4381) | Error 0.3759(0.3761) Steps 838(832.25) | Grad Norm 1.6427(1.9308) | Total Time 14.00(14.00)\n",
      "Iter 2542 | Time 76.8522(77.8948) | Bit/dim 3.9205(3.9108) | Xent 1.0430(1.0550) | Loss 4.4420(4.4383) | Error 0.3621(0.3757) Steps 820(831.88) | Grad Norm 1.6266(1.9217) | Total Time 14.00(14.00)\n",
      "Iter 2543 | Time 77.6079(77.8862) | Bit/dim 3.9108(3.9108) | Xent 1.0410(1.0546) | Loss 4.4313(4.4381) | Error 0.3686(0.3755) Steps 832(831.89) | Grad Norm 1.1129(1.8974) | Total Time 14.00(14.00)\n",
      "Iter 2544 | Time 78.8449(77.9150) | Bit/dim 3.9135(3.9109) | Xent 1.0507(1.0544) | Loss 4.4389(4.4381) | Error 0.3750(0.3755) Steps 826(831.71) | Grad Norm 2.3668(1.9115) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 29.8027, Epoch Time 512.4072(513.1185), Bit/dim 3.9102(best: 3.9101), Xent 1.0226, Loss 4.4215, Error 0.3616(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2545 | Time 78.0092(77.9178) | Bit/dim 3.9108(3.9109) | Xent 1.0481(1.0543) | Loss 4.4348(4.4380) | Error 0.3726(0.3754) Steps 838(831.90) | Grad Norm 1.1516(1.8887) | Total Time 14.00(14.00)\n",
      "Iter 2546 | Time 78.2135(77.9267) | Bit/dim 3.9072(3.9107) | Xent 1.0703(1.0547) | Loss 4.4423(4.4381) | Error 0.3819(0.3756) Steps 838(832.08) | Grad Norm 2.2601(1.8998) | Total Time 14.00(14.00)\n",
      "Iter 2547 | Time 77.0451(77.9002) | Bit/dim 3.8979(3.9104) | Xent 1.0504(1.0546) | Loss 4.4232(4.4377) | Error 0.3709(0.3754) Steps 844(832.44) | Grad Norm 1.8056(1.8970) | Total Time 14.00(14.00)\n",
      "Iter 2548 | Time 76.1951(77.8491) | Bit/dim 3.9198(3.9106) | Xent 1.0687(1.0550) | Loss 4.4542(4.4382) | Error 0.3830(0.3757) Steps 820(832.07) | Grad Norm 0.9378(1.8682) | Total Time 14.00(14.00)\n",
      "Iter 2549 | Time 75.4699(77.7777) | Bit/dim 3.9067(3.9105) | Xent 1.0443(1.0547) | Loss 4.4289(4.4379) | Error 0.3712(0.3755) Steps 832(832.06) | Grad Norm 3.1126(1.9056) | Total Time 14.00(14.00)\n",
      "Iter 2550 | Time 77.4722(77.7685) | Bit/dim 3.9111(3.9105) | Xent 1.0296(1.0540) | Loss 4.4259(4.4375) | Error 0.3634(0.3752) Steps 832(832.06) | Grad Norm 1.3250(1.8882) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 29.9150, Epoch Time 508.5445(512.9812), Bit/dim 3.9103(best: 3.9101), Xent 1.0267, Loss 4.4236, Error 0.3631(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2551 | Time 77.8742(77.7717) | Bit/dim 3.9166(3.9107) | Xent 1.0571(1.0540) | Loss 4.4452(4.4377) | Error 0.3752(0.3752) Steps 838(832.24) | Grad Norm 2.9559(1.9202) | Total Time 14.00(14.00)\n",
      "Iter 2552 | Time 78.4893(77.7932) | Bit/dim 3.9158(3.9109) | Xent 1.0334(1.0534) | Loss 4.4325(4.4376) | Error 0.3674(0.3749) Steps 826(832.05) | Grad Norm 2.2282(1.9294) | Total Time 14.00(14.00)\n",
      "Iter 2553 | Time 78.1568(77.8041) | Bit/dim 3.9068(3.9108) | Xent 1.0575(1.0536) | Loss 4.4355(4.4375) | Error 0.3749(0.3749) Steps 838(832.23) | Grad Norm 2.3817(1.9430) | Total Time 14.00(14.00)\n",
      "Iter 2554 | Time 75.1478(77.7245) | Bit/dim 3.8990(3.9104) | Xent 1.0438(1.0533) | Loss 4.4209(4.4370) | Error 0.3731(0.3749) Steps 838(832.40) | Grad Norm 2.0994(1.9477) | Total Time 14.00(14.00)\n",
      "Iter 2555 | Time 77.7207(77.7243) | Bit/dim 3.9087(3.9103) | Xent 1.0640(1.0536) | Loss 4.4407(4.4371) | Error 0.3809(0.3751) Steps 820(832.03) | Grad Norm 1.2268(1.9261) | Total Time 14.00(14.00)\n",
      "Iter 2556 | Time 78.0585(77.7344) | Bit/dim 3.9031(3.9101) | Xent 1.0562(1.0537) | Loss 4.4312(4.4370) | Error 0.3769(0.3751) Steps 838(832.21) | Grad Norm 2.6714(1.9484) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 29.6093, Epoch Time 510.6867(512.9124), Bit/dim 3.9102(best: 3.9101), Xent 1.0229, Loss 4.4217, Error 0.3625(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2557 | Time 77.0090(77.7126) | Bit/dim 3.9134(3.9102) | Xent 1.0350(1.0531) | Loss 4.4309(4.4368) | Error 0.3664(0.3749) Steps 826(832.02) | Grad Norm 2.2705(1.9581) | Total Time 14.00(14.00)\n",
      "Iter 2558 | Time 77.8030(77.7153) | Bit/dim 3.9017(3.9100) | Xent 1.0442(1.0528) | Loss 4.4238(4.4364) | Error 0.3750(0.3749) Steps 832(832.02) | Grad Norm 1.9208(1.9570) | Total Time 14.00(14.00)\n",
      "Iter 2559 | Time 80.3680(77.7949) | Bit/dim 3.9202(3.9103) | Xent 1.0431(1.0525) | Loss 4.4417(4.4366) | Error 0.3735(0.3748) Steps 826(831.84) | Grad Norm 2.9516(1.9868) | Total Time 14.00(14.00)\n",
      "Iter 2560 | Time 79.4998(77.8460) | Bit/dim 3.8995(3.9100) | Xent 1.0520(1.0525) | Loss 4.4255(4.4362) | Error 0.3750(0.3748) Steps 844(832.21) | Grad Norm 0.9965(1.9571) | Total Time 14.00(14.00)\n",
      "Iter 2561 | Time 78.3501(77.8612) | Bit/dim 3.9162(3.9101) | Xent 1.0650(1.0529) | Loss 4.4487(4.4366) | Error 0.3761(0.3749) Steps 826(832.02) | Grad Norm 2.6450(1.9777) | Total Time 14.00(14.00)\n",
      "Iter 2562 | Time 79.2287(77.9022) | Bit/dim 3.8981(3.9098) | Xent 1.0587(1.0531) | Loss 4.4274(4.4363) | Error 0.3815(0.3751) Steps 838(832.20) | Grad Norm 2.1930(1.9842) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 29.2372, Epoch Time 516.7625(513.0279), Bit/dim 3.9104(best: 3.9101), Xent 1.0227, Loss 4.4217, Error 0.3620(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2563 | Time 80.5642(77.9821) | Bit/dim 3.9027(3.9096) | Xent 1.0623(1.0533) | Loss 4.4339(4.4362) | Error 0.3708(0.3749) Steps 832(832.19) | Grad Norm 1.9393(1.9828) | Total Time 14.00(14.00)\n",
      "Iter 2564 | Time 83.4355(78.1457) | Bit/dim 3.9126(3.9097) | Xent 1.0479(1.0532) | Loss 4.4366(4.4363) | Error 0.3770(0.3750) Steps 820(831.83) | Grad Norm 2.3433(1.9937) | Total Time 14.00(14.00)\n",
      "Iter 2565 | Time 76.6635(78.1012) | Bit/dim 3.9217(3.9100) | Xent 1.0430(1.0529) | Loss 4.4432(4.4365) | Error 0.3688(0.3748) Steps 820(831.47) | Grad Norm 2.1979(1.9998) | Total Time 14.00(14.00)\n",
      "Iter 2566 | Time 79.2319(78.1351) | Bit/dim 3.9039(3.9098) | Xent 1.0264(1.0521) | Loss 4.4171(4.4359) | Error 0.3704(0.3747) Steps 838(831.67) | Grad Norm 1.0754(1.9721) | Total Time 14.00(14.00)\n",
      "Iter 2567 | Time 78.3825(78.1425) | Bit/dim 3.9059(3.9097) | Xent 1.0518(1.0521) | Loss 4.4318(4.4358) | Error 0.3685(0.3745) Steps 832(831.68) | Grad Norm 1.4942(1.9577) | Total Time 14.00(14.00)\n",
      "Iter 2568 | Time 79.4225(78.1809) | Bit/dim 3.9085(3.9097) | Xent 1.0552(1.0522) | Loss 4.4361(4.4358) | Error 0.3734(0.3745) Steps 832(831.69) | Grad Norm 1.5618(1.9458) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 29.8853, Epoch Time 524.3344(513.3671), Bit/dim 3.9086(best: 3.9101), Xent 1.0207, Loss 4.4189, Error 0.3648(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2569 | Time 78.4221(78.1882) | Bit/dim 3.9002(3.9094) | Xent 1.0702(1.0527) | Loss 4.4353(4.4358) | Error 0.3822(0.3747) Steps 814(831.16) | Grad Norm 1.7327(1.9394) | Total Time 14.00(14.00)\n",
      "Iter 2570 | Time 77.8295(78.1774) | Bit/dim 3.9118(3.9095) | Xent 1.0397(1.0523) | Loss 4.4316(4.4356) | Error 0.3744(0.3747) Steps 820(830.82) | Grad Norm 1.5889(1.9289) | Total Time 14.00(14.00)\n",
      "Iter 2571 | Time 79.1199(78.2057) | Bit/dim 3.9120(3.9096) | Xent 1.0509(1.0523) | Loss 4.4374(4.4357) | Error 0.3722(0.3746) Steps 814(830.32) | Grad Norm 1.8410(1.9263) | Total Time 14.00(14.00)\n",
      "Iter 2572 | Time 78.3407(78.2097) | Bit/dim 3.9002(3.9093) | Xent 1.0417(1.0520) | Loss 4.4210(4.4352) | Error 0.3756(0.3746) Steps 832(830.37) | Grad Norm 0.9120(1.8959) | Total Time 14.00(14.00)\n",
      "Iter 2573 | Time 78.1487(78.2079) | Bit/dim 3.9090(3.9093) | Xent 1.0390(1.0516) | Loss 4.4285(4.4350) | Error 0.3671(0.3744) Steps 838(830.60) | Grad Norm 1.7693(1.8921) | Total Time 14.00(14.00)\n",
      "Iter 2574 | Time 79.8138(78.2561) | Bit/dim 3.9124(3.9094) | Xent 1.0398(1.0512) | Loss 4.4323(4.4350) | Error 0.3745(0.3744) Steps 838(830.82) | Grad Norm 1.3451(1.8757) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 30.1721, Epoch Time 517.5618(513.4929), Bit/dim 3.9092(best: 3.9086), Xent 1.0218, Loss 4.4201, Error 0.3640(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2575 | Time 78.4249(78.2611) | Bit/dim 3.9008(3.9091) | Xent 1.0588(1.0514) | Loss 4.4302(4.4348) | Error 0.3785(0.3745) Steps 832(830.86) | Grad Norm 2.5850(1.8969) | Total Time 14.00(14.00)\n",
      "Iter 2576 | Time 77.5394(78.2395) | Bit/dim 3.9136(3.9092) | Xent 1.0323(1.0509) | Loss 4.4298(4.4347) | Error 0.3652(0.3743) Steps 838(831.07) | Grad Norm 1.6461(1.8894) | Total Time 14.00(14.00)\n",
      "Iter 2577 | Time 78.8742(78.2585) | Bit/dim 3.9152(3.9094) | Xent 1.0492(1.0508) | Loss 4.4398(4.4348) | Error 0.3748(0.3743) Steps 838(831.28) | Grad Norm 2.5368(1.9088) | Total Time 14.00(14.00)\n",
      "Iter 2578 | Time 78.6241(78.2695) | Bit/dim 3.9056(3.9093) | Xent 1.0553(1.0510) | Loss 4.4332(4.4348) | Error 0.3661(0.3740) Steps 820(830.94) | Grad Norm 1.7417(1.9038) | Total Time 14.00(14.00)\n",
      "Iter 2579 | Time 77.6279(78.2503) | Bit/dim 3.9037(3.9091) | Xent 1.0383(1.0506) | Loss 4.4229(4.4344) | Error 0.3646(0.3737) Steps 820(830.61) | Grad Norm 1.8340(1.9017) | Total Time 14.00(14.00)\n",
      "Iter 2580 | Time 76.7624(78.2056) | Bit/dim 3.9070(3.9091) | Xent 1.0434(1.0504) | Loss 4.4287(4.4342) | Error 0.3714(0.3737) Steps 844(831.01) | Grad Norm 2.7371(1.9268) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 29.6848, Epoch Time 513.0107(513.4785), Bit/dim 3.9087(best: 3.9086), Xent 1.0190, Loss 4.4182, Error 0.3599(best: 0.3600)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2581 | Time 77.4265(78.1822) | Bit/dim 3.9124(3.9092) | Xent 1.0626(1.0507) | Loss 4.4437(4.4345) | Error 0.3771(0.3738) Steps 832(831.04) | Grad Norm 2.5224(1.9447) | Total Time 14.00(14.00)\n",
      "Iter 2582 | Time 76.7280(78.1386) | Bit/dim 3.9059(3.9091) | Xent 1.0499(1.0507) | Loss 4.4308(4.4344) | Error 0.3772(0.3739) Steps 844(831.43) | Grad Norm 1.8199(1.9409) | Total Time 14.00(14.00)\n",
      "Iter 2583 | Time 76.1593(78.0792) | Bit/dim 3.9016(3.9088) | Xent 1.0430(1.0505) | Loss 4.4231(4.4341) | Error 0.3725(0.3738) Steps 832(831.45) | Grad Norm 1.7700(1.9358) | Total Time 14.00(14.00)\n",
      "Iter 2584 | Time 80.3472(78.1473) | Bit/dim 3.9013(3.9086) | Xent 1.0385(1.0501) | Loss 4.4205(4.4337) | Error 0.3715(0.3738) Steps 826(831.29) | Grad Norm 2.3741(1.9489) | Total Time 14.00(14.00)\n",
      "Iter 2585 | Time 77.4213(78.1255) | Bit/dim 3.9124(3.9087) | Xent 1.0453(1.0500) | Loss 4.4350(4.4337) | Error 0.3762(0.3738) Steps 832(831.31) | Grad Norm 1.6754(1.9407) | Total Time 14.00(14.00)\n",
      "Iter 2586 | Time 79.9836(78.1812) | Bit/dim 3.9074(3.9087) | Xent 1.0519(1.0500) | Loss 4.4333(4.4337) | Error 0.3755(0.3739) Steps 832(831.33) | Grad Norm 2.0048(1.9427) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 29.7182, Epoch Time 513.5937(513.4819), Bit/dim 3.9088(best: 3.9086), Xent 1.0186, Loss 4.4181, Error 0.3603(best: 0.3599)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2587 | Time 77.2722(78.1540) | Bit/dim 3.9006(3.9084) | Xent 1.0499(1.0500) | Loss 4.4256(4.4335) | Error 0.3716(0.3738) Steps 838(831.53) | Grad Norm 2.0185(1.9449) | Total Time 14.00(14.00)\n",
      "Iter 2588 | Time 80.3880(78.2210) | Bit/dim 3.9051(3.9083) | Xent 1.0508(1.0500) | Loss 4.4305(4.4334) | Error 0.3675(0.3736) Steps 838(831.72) | Grad Norm 1.3005(1.9256) | Total Time 14.00(14.00)\n",
      "Iter 2589 | Time 78.2406(78.2216) | Bit/dim 3.9098(3.9084) | Xent 1.0251(1.0493) | Loss 4.4224(4.4330) | Error 0.3654(0.3734) Steps 832(831.73) | Grad Norm 1.3086(1.9071) | Total Time 14.00(14.00)\n",
      "Iter 2590 | Time 77.5319(78.2009) | Bit/dim 3.9056(3.9083) | Xent 1.0372(1.0489) | Loss 4.4242(4.4328) | Error 0.3671(0.3732) Steps 814(831.20) | Grad Norm 1.5029(1.8950) | Total Time 14.00(14.00)\n",
      "Iter 2591 | Time 80.1666(78.2599) | Bit/dim 3.9083(3.9083) | Xent 1.0489(1.0489) | Loss 4.4327(4.4328) | Error 0.3729(0.3732) Steps 838(831.40) | Grad Norm 0.9699(1.8672) | Total Time 14.00(14.00)\n",
      "Iter 2592 | Time 80.2240(78.3188) | Bit/dim 3.9105(3.9084) | Xent 1.0472(1.0489) | Loss 4.4341(4.4328) | Error 0.3752(0.3733) Steps 832(831.42) | Grad Norm 1.4284(1.8540) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 29.2237, Epoch Time 518.6870(513.6381), Bit/dim 3.9087(best: 3.9086), Xent 1.0186, Loss 4.4180, Error 0.3612(best: 0.3599)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2593 | Time 79.1004(78.3422) | Bit/dim 3.9142(3.9085) | Xent 1.0513(1.0490) | Loss 4.4398(4.4330) | Error 0.3708(0.3732) Steps 820(831.08) | Grad Norm 2.2204(1.8650) | Total Time 14.00(14.00)\n",
      "Iter 2594 | Time 80.2373(78.3991) | Bit/dim 3.9094(3.9086) | Xent 1.0464(1.0489) | Loss 4.4327(4.4330) | Error 0.3685(0.3730) Steps 820(830.75) | Grad Norm 1.3447(1.8494) | Total Time 14.00(14.00)\n",
      "Iter 2595 | Time 76.2494(78.3346) | Bit/dim 3.9041(3.9084) | Xent 1.0501(1.0489) | Loss 4.4292(4.4329) | Error 0.3745(0.3731) Steps 808(830.06) | Grad Norm 2.1450(1.8583) | Total Time 14.00(14.00)\n",
      "Iter 2596 | Time 77.9759(78.3238) | Bit/dim 3.9145(3.9086) | Xent 1.0421(1.0487) | Loss 4.4355(4.4330) | Error 0.3701(0.3730) Steps 826(829.94) | Grad Norm 2.4531(1.8761) | Total Time 14.00(14.00)\n",
      "Iter 2597 | Time 78.0691(78.3162) | Bit/dim 3.8978(3.9083) | Xent 1.0145(1.0477) | Loss 4.4051(4.4321) | Error 0.3654(0.3728) Steps 832(830.00) | Grad Norm 1.7887(1.8735) | Total Time 14.00(14.00)\n",
      "Iter 2598 | Time 79.3231(78.3464) | Bit/dim 3.9022(3.9081) | Xent 1.0457(1.0476) | Loss 4.4250(4.4319) | Error 0.3720(0.3727) Steps 832(830.06) | Grad Norm 2.6238(1.8960) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 29.9370, Epoch Time 516.6105(513.7273), Bit/dim 3.9085(best: 3.9086), Xent 1.0177, Loss 4.4173, Error 0.3574(best: 0.3599)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2599 | Time 79.4476(78.3794) | Bit/dim 3.9230(3.9086) | Xent 1.0390(1.0474) | Loss 4.4425(4.4322) | Error 0.3714(0.3727) Steps 832(830.12) | Grad Norm 1.6017(1.8872) | Total Time 14.00(14.00)\n",
      "Iter 2600 | Time 78.3378(78.3782) | Bit/dim 3.9014(3.9083) | Xent 1.0493(1.0474) | Loss 4.4260(4.4321) | Error 0.3768(0.3728) Steps 838(830.36) | Grad Norm 2.5098(1.9059) | Total Time 14.00(14.00)\n",
      "Iter 2601 | Time 76.0525(78.3084) | Bit/dim 3.9072(3.9083) | Xent 1.0445(1.0473) | Loss 4.4295(4.4320) | Error 0.3701(0.3727) Steps 832(830.41) | Grad Norm 1.2907(1.8874) | Total Time 14.00(14.00)\n",
      "Iter 2602 | Time 79.4720(78.3433) | Bit/dim 3.9014(3.9081) | Xent 1.0374(1.0470) | Loss 4.4201(4.4316) | Error 0.3748(0.3728) Steps 832(830.45) | Grad Norm 2.8894(1.9175) | Total Time 14.00(14.00)\n",
      "Iter 2603 | Time 78.3518(78.3436) | Bit/dim 3.9009(3.9079) | Xent 1.0512(1.0472) | Loss 4.4266(4.4315) | Error 0.3795(0.3730) Steps 820(830.14) | Grad Norm 2.3141(1.9294) | Total Time 14.00(14.00)\n",
      "Iter 2604 | Time 78.2363(78.3404) | Bit/dim 3.9004(3.9077) | Xent 1.0425(1.0470) | Loss 4.4217(4.4312) | Error 0.3701(0.3729) Steps 838(830.38) | Grad Norm 2.6306(1.9504) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 29.6304, Epoch Time 515.1117(513.7688), Bit/dim 3.9077(best: 3.9085), Xent 1.0190, Loss 4.4172, Error 0.3612(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2605 | Time 79.4724(78.3743) | Bit/dim 3.9108(3.9078) | Xent 1.0583(1.0474) | Loss 4.4399(4.4314) | Error 0.3746(0.3730) Steps 820(830.07) | Grad Norm 2.5318(1.9679) | Total Time 14.00(14.00)\n",
      "Iter 2606 | Time 78.3646(78.3740) | Bit/dim 3.9147(3.9080) | Xent 1.0312(1.0469) | Loss 4.4303(4.4314) | Error 0.3714(0.3729) Steps 844(830.48) | Grad Norm 1.0861(1.9414) | Total Time 14.00(14.00)\n",
      "Iter 2607 | Time 75.5063(78.2880) | Bit/dim 3.9036(3.9078) | Xent 1.0234(1.0462) | Loss 4.4153(4.4309) | Error 0.3628(0.3726) Steps 838(830.71) | Grad Norm 1.9894(1.9428) | Total Time 14.00(14.00)\n",
      "Iter 2608 | Time 77.1680(78.2544) | Bit/dim 3.8997(3.9076) | Xent 1.0502(1.0463) | Loss 4.4248(4.4307) | Error 0.3681(0.3725) Steps 838(830.93) | Grad Norm 2.9538(1.9732) | Total Time 14.00(14.00)\n",
      "Iter 2609 | Time 78.3285(78.2566) | Bit/dim 3.9050(3.9075) | Xent 1.0338(1.0459) | Loss 4.4219(4.4305) | Error 0.3715(0.3724) Steps 832(830.96) | Grad Norm 2.0015(1.9740) | Total Time 14.00(14.00)\n",
      "Iter 2610 | Time 79.6909(78.2996) | Bit/dim 3.9016(3.9073) | Xent 1.0563(1.0462) | Loss 4.4298(4.4305) | Error 0.3832(0.3728) Steps 820(830.63) | Grad Norm 3.9000(2.0318) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 29.6540, Epoch Time 514.0538(513.7773), Bit/dim 3.9059(best: 3.9077), Xent 1.0158, Loss 4.4138, Error 0.3586(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2611 | Time 80.9775(78.3800) | Bit/dim 3.9044(3.9072) | Xent 1.0066(1.0450) | Loss 4.4077(4.4298) | Error 0.3604(0.3724) Steps 832(830.67) | Grad Norm 1.8558(2.0265) | Total Time 14.00(14.00)\n",
      "Iter 2612 | Time 78.5577(78.3853) | Bit/dim 3.8993(3.9070) | Xent 1.0523(1.0453) | Loss 4.4254(4.4296) | Error 0.3710(0.3724) Steps 832(830.71) | Grad Norm 4.4637(2.0996) | Total Time 14.00(14.00)\n",
      "Iter 2613 | Time 80.6807(78.4542) | Bit/dim 3.9069(3.9070) | Xent 1.0325(1.0449) | Loss 4.4232(4.4294) | Error 0.3691(0.3723) Steps 832(830.75) | Grad Norm 2.0878(2.0993) | Total Time 14.00(14.00)\n",
      "Iter 2614 | Time 80.8539(78.5262) | Bit/dim 3.9030(3.9069) | Xent 1.0529(1.0451) | Loss 4.4295(4.4294) | Error 0.3728(0.3723) Steps 844(831.15) | Grad Norm 3.0108(2.1266) | Total Time 14.00(14.00)\n",
      "Iter 2615 | Time 77.2624(78.4883) | Bit/dim 3.9110(3.9070) | Xent 1.0426(1.0450) | Loss 4.4323(4.4295) | Error 0.3626(0.3720) Steps 838(831.35) | Grad Norm 3.4196(2.1654) | Total Time 14.00(14.00)\n",
      "Iter 2616 | Time 76.2151(78.4201) | Bit/dim 3.9101(3.9071) | Xent 1.0517(1.0452) | Loss 4.4359(4.4297) | Error 0.3700(0.3719) Steps 832(831.37) | Grad Norm 1.9053(2.1576) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 29.8053, Epoch Time 520.1640(513.9689), Bit/dim 3.9067(best: 3.9059), Xent 1.0183, Loss 4.4159, Error 0.3625(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2617 | Time 78.5001(78.4225) | Bit/dim 3.9141(3.9073) | Xent 1.0341(1.0449) | Loss 4.4311(4.4298) | Error 0.3714(0.3719) Steps 838(831.57) | Grad Norm 2.7684(2.1759) | Total Time 14.00(14.00)\n",
      "Iter 2618 | Time 78.8434(78.4351) | Bit/dim 3.9109(3.9074) | Xent 1.0328(1.0446) | Loss 4.4274(4.4297) | Error 0.3660(0.3717) Steps 838(831.76) | Grad Norm 3.2146(2.2071) | Total Time 14.00(14.00)\n",
      "Iter 2619 | Time 79.6258(78.4708) | Bit/dim 3.8947(3.9070) | Xent 1.0515(1.0448) | Loss 4.4204(4.4294) | Error 0.3784(0.3719) Steps 850(832.31) | Grad Norm 1.5188(2.1864) | Total Time 14.00(14.00)\n",
      "Iter 2620 | Time 79.5936(78.5045) | Bit/dim 3.9089(3.9071) | Xent 1.0375(1.0445) | Loss 4.4277(4.4294) | Error 0.3646(0.3717) Steps 826(832.12) | Grad Norm 4.2422(2.2481) | Total Time 14.00(14.00)\n",
      "Iter 2621 | Time 76.7543(78.4520) | Bit/dim 3.9014(3.9069) | Xent 1.0301(1.0441) | Loss 4.4165(4.4290) | Error 0.3651(0.3715) Steps 832(832.12) | Grad Norm 1.2642(2.2186) | Total Time 14.00(14.00)\n",
      "Iter 2622 | Time 76.1003(78.3814) | Bit/dim 3.9070(3.9069) | Xent 1.0504(1.0443) | Loss 4.4322(4.4291) | Error 0.3682(0.3714) Steps 838(832.30) | Grad Norm 3.4853(2.2566) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 29.5902, Epoch Time 514.3987(513.9818), Bit/dim 3.9066(best: 3.9059), Xent 1.0198, Loss 4.4165, Error 0.3632(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2623 | Time 77.8598(78.3658) | Bit/dim 3.9035(3.9068) | Xent 1.0594(1.0447) | Loss 4.4332(4.4292) | Error 0.3782(0.3716) Steps 832(832.29) | Grad Norm 2.3004(2.2579) | Total Time 14.00(14.00)\n",
      "Iter 2624 | Time 77.8750(78.3511) | Bit/dim 3.9178(3.9072) | Xent 1.0331(1.0444) | Loss 4.4343(4.4294) | Error 0.3646(0.3714) Steps 838(832.46) | Grad Norm 1.5687(2.2372) | Total Time 14.00(14.00)\n",
      "Iter 2625 | Time 78.8608(78.3664) | Bit/dim 3.8965(3.9068) | Xent 1.0393(1.0442) | Loss 4.4162(4.4290) | Error 0.3649(0.3712) Steps 832(832.44) | Grad Norm 3.1664(2.2651) | Total Time 14.00(14.00)\n",
      "Iter 2626 | Time 77.1937(78.3312) | Bit/dim 3.9116(3.9070) | Xent 1.0463(1.0443) | Loss 4.4348(4.4291) | Error 0.3685(0.3711) Steps 838(832.61) | Grad Norm 1.0249(2.2279) | Total Time 14.00(14.00)\n",
      "Iter 2627 | Time 77.6052(78.3094) | Bit/dim 3.9018(3.9068) | Xent 1.0372(1.0441) | Loss 4.4204(4.4289) | Error 0.3678(0.3710) Steps 832(832.59) | Grad Norm 3.2106(2.2574) | Total Time 14.00(14.00)\n",
      "Iter 2628 | Time 78.9247(78.3279) | Bit/dim 3.8959(3.9065) | Xent 1.0523(1.0443) | Loss 4.4220(4.4287) | Error 0.3732(0.3711) Steps 820(832.21) | Grad Norm 1.9974(2.2496) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 29.6954, Epoch Time 513.9518(513.9809), Bit/dim 3.9061(best: 3.9059), Xent 1.0170, Loss 4.4145, Error 0.3608(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2629 | Time 77.8054(78.3122) | Bit/dim 3.9028(3.9064) | Xent 1.0511(1.0445) | Loss 4.4284(4.4287) | Error 0.3764(0.3713) Steps 820(831.85) | Grad Norm 1.7645(2.2350) | Total Time 14.00(14.00)\n",
      "Iter 2630 | Time 79.5187(78.3484) | Bit/dim 3.9109(3.9065) | Xent 1.0201(1.0438) | Loss 4.4210(4.4284) | Error 0.3628(0.3710) Steps 832(831.85) | Grad Norm 3.4034(2.2701) | Total Time 14.00(14.00)\n",
      "Iter 2631 | Time 77.7292(78.3298) | Bit/dim 3.9092(3.9066) | Xent 1.0470(1.0439) | Loss 4.4327(4.4286) | Error 0.3781(0.3712) Steps 826(831.68) | Grad Norm 1.4919(2.2467) | Total Time 14.00(14.00)\n",
      "Iter 2632 | Time 78.5009(78.3349) | Bit/dim 3.9076(3.9066) | Xent 1.0555(1.0443) | Loss 4.4353(4.4288) | Error 0.3746(0.3713) Steps 844(832.05) | Grad Norm 4.1842(2.3049) | Total Time 14.00(14.00)\n",
      "Iter 2633 | Time 78.3716(78.3360) | Bit/dim 3.9020(3.9065) | Xent 1.0489(1.0444) | Loss 4.4264(4.4287) | Error 0.3736(0.3714) Steps 838(832.23) | Grad Norm 2.0735(2.2979) | Total Time 14.00(14.00)\n",
      "Iter 2634 | Time 77.9555(78.3246) | Bit/dim 3.8998(3.9063) | Xent 1.0314(1.0440) | Loss 4.4155(4.4283) | Error 0.3664(0.3712) Steps 838(832.40) | Grad Norm 3.3771(2.3303) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 29.0381, Epoch Time 514.4045(513.9936), Bit/dim 3.9060(best: 3.9059), Xent 1.0186, Loss 4.4153, Error 0.3591(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2635 | Time 78.8326(78.3399) | Bit/dim 3.8984(3.9061) | Xent 1.0483(1.0441) | Loss 4.4225(4.4281) | Error 0.3720(0.3713) Steps 826(832.21) | Grad Norm 2.4053(2.3325) | Total Time 14.00(14.00)\n",
      "Iter 2636 | Time 77.3529(78.3103) | Bit/dim 3.9026(3.9059) | Xent 1.0605(1.0446) | Loss 4.4329(4.4283) | Error 0.3766(0.3714) Steps 826(832.02) | Grad Norm 1.9259(2.3204) | Total Time 14.00(14.00)\n",
      "Iter 2637 | Time 79.6716(78.3511) | Bit/dim 3.9055(3.9059) | Xent 1.0620(1.0451) | Loss 4.4365(4.4285) | Error 0.3785(0.3716) Steps 814(831.48) | Grad Norm 3.0388(2.3419) | Total Time 14.00(14.00)\n",
      "Iter 2638 | Time 77.1623(78.3154) | Bit/dim 3.9029(3.9058) | Xent 1.0435(1.0451) | Loss 4.4246(4.4284) | Error 0.3729(0.3717) Steps 838(831.68) | Grad Norm 1.6667(2.3217) | Total Time 14.00(14.00)\n",
      "Iter 2639 | Time 78.3244(78.3157) | Bit/dim 3.9153(3.9061) | Xent 1.0161(1.0442) | Loss 4.4233(4.4282) | Error 0.3622(0.3714) Steps 844(832.05) | Grad Norm 2.8683(2.3380) | Total Time 14.00(14.00)\n",
      "Iter 2640 | Time 78.7794(78.3296) | Bit/dim 3.9032(3.9060) | Xent 1.0223(1.0436) | Loss 4.4143(4.4278) | Error 0.3624(0.3711) Steps 838(832.22) | Grad Norm 2.5132(2.3433) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 29.6927, Epoch Time 515.1503(514.0283), Bit/dim 3.9061(best: 3.9059), Xent 1.0166, Loss 4.4145, Error 0.3601(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2641 | Time 76.8257(78.2845) | Bit/dim 3.9110(3.9062) | Xent 1.0648(1.0442) | Loss 4.4435(4.4283) | Error 0.3735(0.3712) Steps 838(832.40) | Grad Norm 1.8142(2.3274) | Total Time 14.00(14.00)\n",
      "Iter 2642 | Time 76.1346(78.2200) | Bit/dim 3.9119(3.9064) | Xent 1.0260(1.0437) | Loss 4.4249(4.4282) | Error 0.3690(0.3711) Steps 820(832.03) | Grad Norm 3.0952(2.3505) | Total Time 14.00(14.00)\n",
      "Iter 2643 | Time 77.8177(78.2079) | Bit/dim 3.8944(3.9060) | Xent 1.0262(1.0431) | Loss 4.4075(4.4276) | Error 0.3629(0.3709) Steps 844(832.38) | Grad Norm 0.8997(2.3069) | Total Time 14.00(14.00)\n",
      "Iter 2644 | Time 77.9171(78.1992) | Bit/dim 3.9125(3.9062) | Xent 1.0379(1.0430) | Loss 4.4314(4.4277) | Error 0.3674(0.3708) Steps 838(832.55) | Grad Norm 3.0931(2.3305) | Total Time 14.00(14.00)\n",
      "Iter 2645 | Time 76.8784(78.1596) | Bit/dim 3.9109(3.9063) | Xent 1.0265(1.0425) | Loss 4.4241(4.4276) | Error 0.3648(0.3706) Steps 844(832.90) | Grad Norm 1.3819(2.3021) | Total Time 14.00(14.00)\n",
      "Iter 2646 | Time 78.4596(78.1686) | Bit/dim 3.8889(3.9058) | Xent 1.0443(1.0425) | Loss 4.4111(4.4271) | Error 0.3771(0.3708) Steps 832(832.87) | Grad Norm 1.9747(2.2922) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 29.5684, Epoch Time 508.8503(513.8730), Bit/dim 3.9046(best: 3.9059), Xent 1.0171, Loss 4.4132, Error 0.3588(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2647 | Time 78.2985(78.1725) | Bit/dim 3.9076(3.9059) | Xent 1.0472(1.0427) | Loss 4.4312(4.4272) | Error 0.3748(0.3709) Steps 838(833.02) | Grad Norm 2.9617(2.3123) | Total Time 14.00(14.00)\n",
      "Iter 2648 | Time 78.0453(78.1687) | Bit/dim 3.8925(3.9055) | Xent 1.0331(1.0424) | Loss 4.4090(4.4267) | Error 0.3664(0.3708) Steps 826(832.81) | Grad Norm 1.4275(2.2858) | Total Time 14.00(14.00)\n",
      "Iter 2649 | Time 78.0813(78.1660) | Bit/dim 3.8974(3.9052) | Xent 1.0290(1.0420) | Loss 4.4119(4.4262) | Error 0.3658(0.3706) Steps 832(832.79) | Grad Norm 3.3909(2.3189) | Total Time 14.00(14.00)\n",
      "Iter 2650 | Time 77.7531(78.1537) | Bit/dim 3.9055(3.9052) | Xent 1.0315(1.0417) | Loss 4.4212(4.4261) | Error 0.3700(0.3706) Steps 838(832.94) | Grad Norm 1.1880(2.2850) | Total Time 14.00(14.00)\n",
      "Iter 2651 | Time 76.9352(78.1171) | Bit/dim 3.9121(3.9054) | Xent 1.0304(1.0413) | Loss 4.4273(4.4261) | Error 0.3689(0.3705) Steps 838(833.10) | Grad Norm 2.7902(2.3002) | Total Time 14.00(14.00)\n",
      "Iter 2652 | Time 79.6095(78.1619) | Bit/dim 3.9069(3.9055) | Xent 1.0535(1.0417) | Loss 4.4336(4.4263) | Error 0.3705(0.3705) Steps 826(832.88) | Grad Norm 3.2467(2.3286) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 29.7317, Epoch Time 513.7211(513.8684), Bit/dim 3.9049(best: 3.9046), Xent 1.0132, Loss 4.4115, Error 0.3597(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2653 | Time 80.1576(78.2217) | Bit/dim 3.9026(3.9054) | Xent 1.0158(1.0409) | Loss 4.4105(4.4259) | Error 0.3605(0.3702) Steps 838(833.04) | Grad Norm 2.2149(2.3252) | Total Time 14.00(14.00)\n",
      "Iter 2654 | Time 77.9301(78.2130) | Bit/dim 3.9045(3.9054) | Xent 1.0321(1.0407) | Loss 4.4206(4.4257) | Error 0.3656(0.3701) Steps 820(832.65) | Grad Norm 3.2574(2.3531) | Total Time 14.00(14.00)\n",
      "Iter 2655 | Time 77.1258(78.1804) | Bit/dim 3.9077(3.9054) | Xent 1.0304(1.0404) | Loss 4.4229(4.4256) | Error 0.3705(0.3701) Steps 826(832.45) | Grad Norm 1.1973(2.3184) | Total Time 14.00(14.00)\n",
      "Iter 2656 | Time 79.1264(78.2088) | Bit/dim 3.9062(3.9055) | Xent 1.0618(1.0410) | Loss 4.4371(4.4260) | Error 0.3732(0.3702) Steps 826(832.25) | Grad Norm 2.6551(2.3285) | Total Time 14.00(14.00)\n",
      "Iter 2657 | Time 77.9422(78.2008) | Bit/dim 3.8947(3.9051) | Xent 1.0391(1.0409) | Loss 4.4142(4.4256) | Error 0.3719(0.3703) Steps 832(832.25) | Grad Norm 1.7387(2.3108) | Total Time 14.00(14.00)\n",
      "Iter 2658 | Time 78.6413(78.2140) | Bit/dim 3.9030(3.9051) | Xent 1.0360(1.0408) | Loss 4.4210(4.4255) | Error 0.3685(0.3702) Steps 820(831.88) | Grad Norm 1.5502(2.2880) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 29.6650, Epoch Time 516.2401(513.9396), Bit/dim 3.9043(best: 3.9046), Xent 1.0134, Loss 4.4110, Error 0.3562(best: 0.3574)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2659 | Time 78.9834(78.2371) | Bit/dim 3.8997(3.9049) | Xent 1.0293(1.0405) | Loss 4.4143(4.4251) | Error 0.3645(0.3700) Steps 826(831.70) | Grad Norm 2.9656(2.3084) | Total Time 14.00(14.00)\n",
      "Iter 2660 | Time 77.5208(78.2156) | Bit/dim 3.8955(3.9046) | Xent 1.0147(1.0397) | Loss 4.4028(4.4245) | Error 0.3659(0.3699) Steps 838(831.89) | Grad Norm 0.9989(2.2691) | Total Time 14.00(14.00)\n",
      "Iter 2661 | Time 77.9816(78.2086) | Bit/dim 3.9065(3.9047) | Xent 1.0594(1.0403) | Loss 4.4361(4.4248) | Error 0.3726(0.3700) Steps 820(831.53) | Grad Norm 3.3528(2.3016) | Total Time 14.00(14.00)\n",
      "Iter 2662 | Time 80.0328(78.2633) | Bit/dim 3.9031(3.9046) | Xent 1.0523(1.0406) | Loss 4.4292(4.4250) | Error 0.3701(0.3700) Steps 820(831.19) | Grad Norm 1.1448(2.2669) | Total Time 14.00(14.00)\n",
      "Iter 2663 | Time 77.0288(78.2263) | Bit/dim 3.8990(3.9045) | Xent 1.0352(1.0405) | Loss 4.4166(4.4247) | Error 0.3730(0.3701) Steps 838(831.39) | Grad Norm 2.6486(2.2783) | Total Time 14.00(14.00)\n",
      "Iter 2664 | Time 78.2149(78.2259) | Bit/dim 3.9120(3.9047) | Xent 1.0328(1.0402) | Loss 4.4284(4.4248) | Error 0.3656(0.3700) Steps 838(831.59) | Grad Norm 1.4117(2.2523) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 29.6308, Epoch Time 514.8136(513.9658), Bit/dim 3.9042(best: 3.9043), Xent 1.0123, Loss 4.4103, Error 0.3574(best: 0.3562)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2665 | Time 78.4165(78.2316) | Bit/dim 3.9097(3.9048) | Xent 1.0287(1.0399) | Loss 4.4240(4.4248) | Error 0.3622(0.3697) Steps 826(831.42) | Grad Norm 1.6727(2.2349) | Total Time 14.00(14.00)\n",
      "Iter 2666 | Time 76.9069(78.1919) | Bit/dim 3.9007(3.9047) | Xent 1.0518(1.0402) | Loss 4.4266(4.4248) | Error 0.3765(0.3699) Steps 832(831.44) | Grad Norm 2.8693(2.2540) | Total Time 14.00(14.00)\n",
      "Iter 2667 | Time 78.6944(78.2070) | Bit/dim 3.9099(3.9049) | Xent 1.0433(1.0403) | Loss 4.4316(4.4250) | Error 0.3719(0.3700) Steps 826(831.28) | Grad Norm 1.8119(2.2407) | Total Time 14.00(14.00)\n",
      "Iter 2668 | Time 80.8001(78.2848) | Bit/dim 3.9056(3.9049) | Xent 1.0273(1.0400) | Loss 4.4193(4.4249) | Error 0.3629(0.3698) Steps 832(831.30) | Grad Norm 2.6680(2.2535) | Total Time 14.00(14.00)\n",
      "Iter 2669 | Time 77.9210(78.2738) | Bit/dim 3.8955(3.9046) | Xent 1.0491(1.0402) | Loss 4.4200(4.4247) | Error 0.3735(0.3699) Steps 832(831.32) | Grad Norm 1.3461(2.2263) | Total Time 14.00(14.00)\n",
      "Iter 2670 | Time 77.3976(78.2476) | Bit/dim 3.8919(3.9042) | Xent 1.0163(1.0395) | Loss 4.4000(4.4240) | Error 0.3564(0.3695) Steps 838(831.52) | Grad Norm 2.6997(2.2405) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 29.7409, Epoch Time 515.3384(514.0070), Bit/dim 3.9050(best: 3.9042), Xent 1.0132, Loss 4.4116, Error 0.3581(best: 0.3562)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2671 | Time 78.4647(78.2541) | Bit/dim 3.8977(3.9040) | Xent 1.0127(1.0387) | Loss 4.4040(4.4234) | Error 0.3655(0.3694) Steps 838(831.71) | Grad Norm 2.0541(2.2349) | Total Time 14.00(14.00)\n",
      "Iter 2672 | Time 77.8316(78.2414) | Bit/dim 3.8952(3.9038) | Xent 1.0174(1.0381) | Loss 4.4039(4.4228) | Error 0.3640(0.3692) Steps 832(831.72) | Grad Norm 1.9371(2.2260) | Total Time 14.00(14.00)\n",
      "Iter 2673 | Time 78.2842(78.2427) | Bit/dim 3.9105(3.9040) | Xent 1.0224(1.0376) | Loss 4.4217(4.4228) | Error 0.3692(0.3692) Steps 826(831.55) | Grad Norm 2.0783(2.2216) | Total Time 14.00(14.00)\n",
      "Iter 2674 | Time 74.3195(78.1250) | Bit/dim 3.9099(3.9041) | Xent 1.0450(1.0378) | Loss 4.4324(4.4231) | Error 0.3738(0.3693) Steps 832(831.56) | Grad Norm 1.4250(2.1977) | Total Time 14.00(14.00)\n",
      "Iter 2675 | Time 79.0142(78.1517) | Bit/dim 3.9057(3.9042) | Xent 1.0456(1.0381) | Loss 4.4285(4.4232) | Error 0.3659(0.3692) Steps 820(831.22) | Grad Norm 1.1724(2.1669) | Total Time 14.00(14.00)\n",
      "Iter 2676 | Time 79.3223(78.1868) | Bit/dim 3.8943(3.9039) | Xent 1.0412(1.0381) | Loss 4.4149(4.4230) | Error 0.3738(0.3694) Steps 832(831.24) | Grad Norm 2.1129(2.1653) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 29.4504, Epoch Time 512.1802(513.9522), Bit/dim 3.9039(best: 3.9042), Xent 1.0104, Loss 4.4091, Error 0.3536(best: 0.3562)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2677 | Time 77.1830(78.1567) | Bit/dim 3.8969(3.9037) | Xent 1.0330(1.0380) | Loss 4.4134(4.4227) | Error 0.3679(0.3693) Steps 844(831.62) | Grad Norm 1.2011(2.1364) | Total Time 14.00(14.00)\n",
      "Iter 2678 | Time 75.5994(78.0799) | Bit/dim 3.9082(3.9038) | Xent 1.0395(1.0380) | Loss 4.4279(4.4228) | Error 0.3708(0.3694) Steps 838(831.82) | Grad Norm 2.5432(2.1486) | Total Time 14.00(14.00)\n",
      "Iter 2679 | Time 79.3355(78.1176) | Bit/dim 3.9022(3.9038) | Xent 1.0274(1.0377) | Loss 4.4158(4.4226) | Error 0.3655(0.3693) Steps 838(832.00) | Grad Norm 1.2687(2.1222) | Total Time 14.00(14.00)\n",
      "Iter 2680 | Time 79.8351(78.1691) | Bit/dim 3.9003(3.9037) | Xent 1.0137(1.0370) | Loss 4.4072(4.4222) | Error 0.3605(0.3690) Steps 838(832.18) | Grad Norm 2.0984(2.1215) | Total Time 14.00(14.00)\n",
      "Iter 2681 | Time 77.2095(78.1403) | Bit/dim 3.9068(3.9038) | Xent 1.0493(1.0374) | Loss 4.4315(4.4224) | Error 0.3754(0.3692) Steps 832(832.18) | Grad Norm 1.3399(2.0980) | Total Time 14.00(14.00)\n",
      "Iter 2682 | Time 77.7774(78.1295) | Bit/dim 3.8941(3.9035) | Xent 1.0185(1.0368) | Loss 4.4033(4.4219) | Error 0.3705(0.3692) Steps 838(832.35) | Grad Norm 1.0316(2.0660) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 29.6606, Epoch Time 512.0114(513.8940), Bit/dim 3.9024(best: 3.9039), Xent 1.0088, Loss 4.4068, Error 0.3564(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2683 | Time 76.3443(78.0759) | Bit/dim 3.9062(3.9036) | Xent 1.0288(1.0366) | Loss 4.4206(4.4218) | Error 0.3672(0.3692) Steps 826(832.16) | Grad Norm 2.4396(2.0772) | Total Time 14.00(14.00)\n",
      "Iter 2684 | Time 77.7999(78.0676) | Bit/dim 3.8997(3.9034) | Xent 1.0352(1.0365) | Loss 4.4173(4.4217) | Error 0.3692(0.3692) Steps 838(832.33) | Grad Norm 0.9600(2.0437) | Total Time 14.00(14.00)\n",
      "Iter 2685 | Time 80.0861(78.1282) | Bit/dim 3.9048(3.9035) | Xent 1.0313(1.0364) | Loss 4.4205(4.4217) | Error 0.3686(0.3691) Steps 832(832.32) | Grad Norm 1.8102(2.0367) | Total Time 14.00(14.00)\n",
      "Iter 2686 | Time 77.5425(78.1106) | Bit/dim 3.9037(3.9035) | Xent 1.0273(1.0361) | Loss 4.4174(4.4215) | Error 0.3675(0.3691) Steps 844(832.68) | Grad Norm 1.0609(2.0074) | Total Time 14.00(14.00)\n",
      "Iter 2687 | Time 79.5203(78.1529) | Bit/dim 3.8937(3.9032) | Xent 1.0248(1.0358) | Loss 4.4061(4.4211) | Error 0.3634(0.3689) Steps 832(832.65) | Grad Norm 1.8767(2.0035) | Total Time 14.00(14.00)\n",
      "Iter 2688 | Time 77.8221(78.1430) | Bit/dim 3.9011(3.9031) | Xent 1.0310(1.0356) | Loss 4.4167(4.4209) | Error 0.3635(0.3688) Steps 838(832.82) | Grad Norm 1.2552(1.9811) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 29.3362, Epoch Time 515.0096(513.9274), Bit/dim 3.9032(best: 3.9024), Xent 1.0101, Loss 4.4083, Error 0.3578(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2689 | Time 77.8959(78.1356) | Bit/dim 3.8999(3.9030) | Xent 1.0601(1.0363) | Loss 4.4299(4.4212) | Error 0.3746(0.3689) Steps 832(832.79) | Grad Norm 1.5916(1.9694) | Total Time 14.00(14.00)\n",
      "Iter 2690 | Time 78.6998(78.1525) | Bit/dim 3.9032(3.9030) | Xent 1.0374(1.0364) | Loss 4.4219(4.4212) | Error 0.3705(0.3690) Steps 838(832.95) | Grad Norm 0.9954(1.9402) | Total Time 14.00(14.00)\n",
      "Iter 2691 | Time 77.2629(78.1258) | Bit/dim 3.8898(3.9026) | Xent 1.0505(1.0368) | Loss 4.4151(4.4210) | Error 0.3709(0.3690) Steps 838(833.10) | Grad Norm 0.7311(1.9039) | Total Time 14.00(14.00)\n",
      "Iter 2692 | Time 77.9465(78.1204) | Bit/dim 3.9093(3.9028) | Xent 1.0146(1.0361) | Loss 4.4166(4.4209) | Error 0.3608(0.3688) Steps 826(832.89) | Grad Norm 1.7928(1.9006) | Total Time 14.00(14.00)\n",
      "Iter 2693 | Time 77.6702(78.1069) | Bit/dim 3.9063(3.9029) | Xent 1.0344(1.0361) | Loss 4.4235(4.4210) | Error 0.3749(0.3690) Steps 826(832.68) | Grad Norm 1.3771(1.8848) | Total Time 14.00(14.00)\n",
      "Iter 2694 | Time 78.9137(78.1311) | Bit/dim 3.9047(3.9030) | Xent 1.0062(1.0352) | Loss 4.4078(4.4206) | Error 0.3651(0.3689) Steps 838(832.84) | Grad Norm 2.0626(1.8902) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 29.9373, Epoch Time 513.9382(513.9278), Bit/dim 3.9022(best: 3.9024), Xent 1.0094, Loss 4.4068, Error 0.3576(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2695 | Time 78.8110(78.1515) | Bit/dim 3.8986(3.9029) | Xent 1.0358(1.0352) | Loss 4.4165(4.4205) | Error 0.3656(0.3688) Steps 838(832.99) | Grad Norm 2.2385(1.9006) | Total Time 14.00(14.00)\n",
      "Iter 2696 | Time 77.1526(78.1215) | Bit/dim 3.9085(3.9030) | Xent 1.0399(1.0353) | Loss 4.4284(4.4207) | Error 0.3712(0.3688) Steps 838(833.14) | Grad Norm 1.5582(1.8904) | Total Time 14.00(14.00)\n",
      "Iter 2697 | Time 76.7258(78.0797) | Bit/dim 3.8996(3.9029) | Xent 1.0200(1.0349) | Loss 4.4097(4.4204) | Error 0.3665(0.3688) Steps 838(833.29) | Grad Norm 2.3416(1.9039) | Total Time 14.00(14.00)\n",
      "Iter 2698 | Time 78.3089(78.0866) | Bit/dim 3.8981(3.9028) | Xent 1.0356(1.0349) | Loss 4.4159(4.4202) | Error 0.3688(0.3688) Steps 832(833.25) | Grad Norm 1.0510(1.8783) | Total Time 14.00(14.00)\n",
      "Iter 2699 | Time 78.0241(78.0847) | Bit/dim 3.8984(3.9027) | Xent 1.0386(1.0350) | Loss 4.4177(4.4202) | Error 0.3629(0.3686) Steps 832(833.21) | Grad Norm 1.7185(1.8735) | Total Time 14.00(14.00)\n",
      "Iter 2700 | Time 77.3641(78.0631) | Bit/dim 3.9007(3.9026) | Xent 1.0253(1.0347) | Loss 4.4133(4.4200) | Error 0.3666(0.3685) Steps 826(833.00) | Grad Norm 1.2757(1.8556) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 29.7936, Epoch Time 511.6670(513.8599), Bit/dim 3.9020(best: 3.9022), Xent 1.0063, Loss 4.4052, Error 0.3570(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2701 | Time 76.8686(78.0272) | Bit/dim 3.9069(3.9027) | Xent 1.0398(1.0349) | Loss 4.4268(4.4202) | Error 0.3751(0.3687) Steps 826(832.79) | Grad Norm 0.7608(1.8227) | Total Time 14.00(14.00)\n",
      "Iter 2702 | Time 77.5403(78.0126) | Bit/dim 3.9030(3.9027) | Xent 1.0391(1.0350) | Loss 4.4226(4.4202) | Error 0.3678(0.3687) Steps 832(832.76) | Grad Norm 2.8094(1.8523) | Total Time 14.00(14.00)\n",
      "Iter 2703 | Time 79.8006(78.0663) | Bit/dim 3.8954(3.9025) | Xent 1.0133(1.0344) | Loss 4.4020(4.4197) | Error 0.3590(0.3684) Steps 838(832.92) | Grad Norm 1.2880(1.8354) | Total Time 14.00(14.00)\n",
      "Iter 2704 | Time 81.0458(78.1556) | Bit/dim 3.9040(3.9026) | Xent 1.0250(1.0341) | Loss 4.4165(4.4196) | Error 0.3690(0.3684) Steps 820(832.53) | Grad Norm 3.2690(1.8784) | Total Time 14.00(14.00)\n",
      "Iter 2705 | Time 77.8778(78.1473) | Bit/dim 3.8914(3.9022) | Xent 1.0150(1.0335) | Loss 4.3988(4.4190) | Error 0.3594(0.3682) Steps 838(832.70) | Grad Norm 1.8029(1.8761) | Total Time 14.00(14.00)\n",
      "Iter 2706 | Time 75.8377(78.0780) | Bit/dim 3.9032(3.9023) | Xent 1.0450(1.0338) | Loss 4.4257(4.4192) | Error 0.3791(0.3685) Steps 826(832.50) | Grad Norm 1.4353(1.8629) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 29.8434, Epoch Time 514.4849(513.8787), Bit/dim 3.9023(best: 3.9020), Xent 1.0083, Loss 4.4065, Error 0.3552(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2707 | Time 77.8765(78.0720) | Bit/dim 3.9064(3.9024) | Xent 1.0279(1.0337) | Loss 4.4204(4.4192) | Error 0.3650(0.3684) Steps 838(832.66) | Grad Norm 2.5901(1.8847) | Total Time 14.00(14.00)\n",
      "Iter 2708 | Time 77.4969(78.0547) | Bit/dim 3.9076(3.9025) | Xent 1.0198(1.0333) | Loss 4.4175(4.4192) | Error 0.3631(0.3682) Steps 826(832.46) | Grad Norm 1.3119(1.8676) | Total Time 14.00(14.00)\n",
      "Iter 2709 | Time 78.0803(78.0555) | Bit/dim 3.9028(3.9025) | Xent 1.0230(1.0329) | Loss 4.4143(4.4190) | Error 0.3606(0.3680) Steps 838(832.63) | Grad Norm 2.9121(1.8989) | Total Time 14.00(14.00)\n",
      "Iter 2710 | Time 79.4165(78.0963) | Bit/dim 3.8881(3.9021) | Xent 1.0347(1.0330) | Loss 4.4055(4.4186) | Error 0.3689(0.3680) Steps 832(832.61) | Grad Norm 2.8828(1.9284) | Total Time 14.00(14.00)\n",
      "Iter 2711 | Time 79.1258(78.1272) | Bit/dim 3.9027(3.9021) | Xent 1.0281(1.0329) | Loss 4.4168(4.4186) | Error 0.3699(0.3681) Steps 844(832.95) | Grad Norm 1.5250(1.9163) | Total Time 14.00(14.00)\n",
      "Iter 2712 | Time 78.4572(78.1371) | Bit/dim 3.8909(3.9018) | Xent 1.0142(1.0323) | Loss 4.3979(4.4179) | Error 0.3569(0.3677) Steps 844(833.28) | Grad Norm 3.7559(1.9715) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 28.9027, Epoch Time 514.8630(513.9082), Bit/dim 3.9019(best: 3.9020), Xent 1.0090, Loss 4.4064, Error 0.3553(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2713 | Time 76.6976(78.0939) | Bit/dim 3.8942(3.9016) | Xent 1.0309(1.0322) | Loss 4.4096(4.4177) | Error 0.3630(0.3676) Steps 832(833.24) | Grad Norm 2.8310(1.9973) | Total Time 14.00(14.00)\n",
      "Iter 2714 | Time 76.4497(78.0446) | Bit/dim 3.9049(3.9017) | Xent 1.0114(1.0316) | Loss 4.4106(4.4175) | Error 0.3632(0.3675) Steps 832(833.21) | Grad Norm 3.2130(2.0337) | Total Time 14.00(14.00)\n",
      "Iter 2715 | Time 80.0692(78.1053) | Bit/dim 3.9009(3.9016) | Xent 1.0302(1.0316) | Loss 4.4159(4.4174) | Error 0.3639(0.3674) Steps 832(833.17) | Grad Norm 4.6995(2.1137) | Total Time 14.00(14.00)\n",
      "Iter 2716 | Time 78.2998(78.1112) | Bit/dim 3.9038(3.9017) | Xent 1.0287(1.0315) | Loss 4.4182(4.4174) | Error 0.3646(0.3673) Steps 832(833.13) | Grad Norm 2.5580(2.1270) | Total Time 14.00(14.00)\n",
      "Iter 2717 | Time 78.2459(78.1152) | Bit/dim 3.9013(3.9017) | Xent 1.0328(1.0315) | Loss 4.4177(4.4175) | Error 0.3708(0.3674) Steps 838(833.28) | Grad Norm 3.1688(2.1583) | Total Time 14.00(14.00)\n",
      "Iter 2718 | Time 75.6626(78.0416) | Bit/dim 3.9011(3.9017) | Xent 1.0278(1.0314) | Loss 4.4150(4.4174) | Error 0.3672(0.3674) Steps 838(833.42) | Grad Norm 2.0658(2.1555) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 29.8919, Epoch Time 510.7778(513.8143), Bit/dim 3.9009(best: 3.9019), Xent 1.0084, Loss 4.4051, Error 0.3565(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2719 | Time 74.7837(77.9439) | Bit/dim 3.9058(3.9018) | Xent 1.0291(1.0314) | Loss 4.4204(4.4175) | Error 0.3568(0.3671) Steps 826(833.20) | Grad Norm 3.3431(2.1911) | Total Time 14.00(14.00)\n",
      "Iter 2720 | Time 77.2015(77.9216) | Bit/dim 3.9124(3.9021) | Xent 1.0343(1.0314) | Loss 4.4296(4.4178) | Error 0.3695(0.3671) Steps 826(832.98) | Grad Norm 2.8438(2.2107) | Total Time 14.00(14.00)\n",
      "Iter 2721 | Time 75.5940(77.8518) | Bit/dim 3.8919(3.9018) | Xent 1.0237(1.0312) | Loss 4.4037(4.4174) | Error 0.3668(0.3671) Steps 826(832.77) | Grad Norm 2.0150(2.2049) | Total Time 14.00(14.00)\n",
      "Iter 2722 | Time 77.6015(77.8443) | Bit/dim 3.8962(3.9016) | Xent 1.0471(1.0317) | Loss 4.4197(4.4175) | Error 0.3758(0.3674) Steps 826(832.57) | Grad Norm 2.4000(2.2107) | Total Time 14.00(14.00)\n",
      "Iter 2723 | Time 79.2939(77.8878) | Bit/dim 3.9008(3.9016) | Xent 1.0232(1.0314) | Loss 4.4124(4.4173) | Error 0.3664(0.3673) Steps 832(832.55) | Grad Norm 1.5390(2.1906) | Total Time 14.00(14.00)\n",
      "Iter 2724 | Time 77.4472(77.8746) | Bit/dim 3.8938(3.9014) | Xent 1.0256(1.0313) | Loss 4.4066(4.4170) | Error 0.3664(0.3673) Steps 820(832.18) | Grad Norm 2.0787(2.1872) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 29.9272, Epoch Time 507.5440(513.6262), Bit/dim 3.9014(best: 3.9009), Xent 1.0060, Loss 4.4044, Error 0.3548(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2725 | Time 77.1375(77.8524) | Bit/dim 3.8865(3.9009) | Xent 1.0499(1.0318) | Loss 4.4115(4.4168) | Error 0.3722(0.3675) Steps 838(832.35) | Grad Norm 2.4928(2.1964) | Total Time 14.00(14.00)\n",
      "Iter 2726 | Time 78.5917(77.8746) | Bit/dim 3.9033(3.9010) | Xent 1.0328(1.0318) | Loss 4.4197(4.4169) | Error 0.3681(0.3675) Steps 844(832.70) | Grad Norm 0.8770(2.1568) | Total Time 14.00(14.00)\n",
      "Iter 2727 | Time 78.2407(77.8856) | Bit/dim 3.9021(3.9010) | Xent 1.0224(1.0316) | Loss 4.4132(4.4168) | Error 0.3581(0.3672) Steps 832(832.68) | Grad Norm 2.0224(2.1528) | Total Time 14.00(14.00)\n",
      "Iter 2728 | Time 80.1391(77.9532) | Bit/dim 3.9001(3.9010) | Xent 1.0176(1.0311) | Loss 4.4089(4.4166) | Error 0.3674(0.3672) Steps 838(832.84) | Grad Norm 2.0601(2.1500) | Total Time 14.00(14.00)\n",
      "Iter 2729 | Time 78.0184(77.9552) | Bit/dim 3.8967(3.9009) | Xent 1.0292(1.0311) | Loss 4.4113(4.4164) | Error 0.3651(0.3671) Steps 826(832.63) | Grad Norm 1.6002(2.1335) | Total Time 14.00(14.00)\n",
      "Iter 2730 | Time 77.8019(77.9506) | Bit/dim 3.9011(3.9009) | Xent 1.0238(1.0309) | Loss 4.4130(4.4163) | Error 0.3638(0.3670) Steps 826(832.44) | Grad Norm 2.2840(2.1380) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 30.0036, Epoch Time 515.3407(513.6776), Bit/dim 3.8998(best: 3.9009), Xent 1.0041, Loss 4.4019, Error 0.3581(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2731 | Time 74.6539(77.8517) | Bit/dim 3.8935(3.9007) | Xent 1.0268(1.0307) | Loss 4.4069(4.4160) | Error 0.3599(0.3668) Steps 820(832.06) | Grad Norm 1.7427(2.1261) | Total Time 14.00(14.00)\n",
      "Iter 2732 | Time 76.3833(77.8076) | Bit/dim 3.9038(3.9008) | Xent 1.0320(1.0308) | Loss 4.4199(4.4162) | Error 0.3694(0.3669) Steps 826(831.88) | Grad Norm 2.5669(2.1394) | Total Time 14.00(14.00)\n",
      "Iter 2733 | Time 76.4665(77.7674) | Bit/dim 3.8972(3.9007) | Xent 1.0520(1.0314) | Loss 4.4232(4.4164) | Error 0.3709(0.3670) Steps 838(832.06) | Grad Norm 1.8032(2.1293) | Total Time 14.00(14.00)\n",
      "Iter 2734 | Time 78.4804(77.7888) | Bit/dim 3.8999(3.9006) | Xent 1.0219(1.0311) | Loss 4.4109(4.4162) | Error 0.3651(0.3670) Steps 832(832.06) | Grad Norm 2.7684(2.1485) | Total Time 14.00(14.00)\n",
      "Iter 2735 | Time 78.6962(77.8160) | Bit/dim 3.9032(3.9007) | Xent 1.0028(1.0303) | Loss 4.4046(4.4159) | Error 0.3568(0.3667) Steps 838(832.24) | Grad Norm 1.2084(2.1202) | Total Time 14.00(14.00)\n",
      "Iter 2736 | Time 78.0054(77.8217) | Bit/dim 3.9016(3.9007) | Xent 1.0178(1.0299) | Loss 4.4105(4.4157) | Error 0.3606(0.3665) Steps 838(832.41) | Grad Norm 1.8274(2.1115) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 29.6537, Epoch Time 514.4307(513.7002), Bit/dim 3.9005(best: 3.8998), Xent 1.0011, Loss 4.4011, Error 0.3561(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2737 | Time 76.5759(77.7843) | Bit/dim 3.9099(3.9010) | Xent 1.0199(1.0296) | Loss 4.4198(4.4158) | Error 0.3658(0.3665) Steps 832(832.40) | Grad Norm 1.2119(2.0845) | Total Time 14.00(14.00)\n",
      "Iter 2738 | Time 78.0174(77.7913) | Bit/dim 3.8957(3.9009) | Xent 1.0393(1.0299) | Loss 4.4154(4.4158) | Error 0.3630(0.3664) Steps 838(832.57) | Grad Norm 1.1246(2.0557) | Total Time 14.00(14.00)\n",
      "Iter 2739 | Time 76.5834(77.7551) | Bit/dim 3.9018(3.9009) | Xent 1.0234(1.0297) | Loss 4.4135(4.4157) | Error 0.3616(0.3662) Steps 832(832.55) | Grad Norm 1.9593(2.0528) | Total Time 14.00(14.00)\n",
      "Iter 2740 | Time 76.7009(77.7234) | Bit/dim 3.8897(3.9005) | Xent 1.0142(1.0292) | Loss 4.3968(4.4152) | Error 0.3592(0.3660) Steps 838(832.72) | Grad Norm 1.1657(2.0262) | Total Time 14.00(14.00)\n",
      "Iter 2741 | Time 77.8283(77.7266) | Bit/dim 3.9084(3.9008) | Xent 1.0347(1.0294) | Loss 4.4258(4.4155) | Error 0.3679(0.3661) Steps 832(832.69) | Grad Norm 1.2316(2.0023) | Total Time 14.00(14.00)\n",
      "Iter 2742 | Time 79.6797(77.7852) | Bit/dim 3.8937(3.9006) | Xent 1.0270(1.0293) | Loss 4.4072(4.4152) | Error 0.3689(0.3661) Steps 838(832.85) | Grad Norm 2.8357(2.0273) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 29.3247, Epoch Time 517.9408(513.8274), Bit/dim 3.9000(best: 3.8998), Xent 1.0039, Loss 4.4019, Error 0.3558(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2743 | Time 77.2999(77.7706) | Bit/dim 3.8888(3.9002) | Xent 1.0165(1.0289) | Loss 4.3970(4.4147) | Error 0.3630(0.3661) Steps 820(832.47) | Grad Norm 1.4880(2.0112) | Total Time 14.00(14.00)\n",
      "Iter 2744 | Time 74.2326(77.6645) | Bit/dim 3.9129(3.9006) | Xent 1.0420(1.0293) | Loss 4.4338(4.4153) | Error 0.3679(0.3661) Steps 832(832.45) | Grad Norm 2.8001(2.0348) | Total Time 14.00(14.00)\n",
      "Iter 2745 | Time 80.0972(77.7375) | Bit/dim 3.9077(3.9008) | Xent 1.0236(1.0292) | Loss 4.4195(4.4154) | Error 0.3672(0.3661) Steps 826(832.26) | Grad Norm 2.4824(2.0483) | Total Time 14.00(14.00)\n",
      "Iter 2746 | Time 78.1214(77.7490) | Bit/dim 3.8956(3.9007) | Xent 0.9989(1.0283) | Loss 4.3950(4.4148) | Error 0.3520(0.3657) Steps 826(832.07) | Grad Norm 1.7915(2.0406) | Total Time 14.00(14.00)\n",
      "Iter 2747 | Time 77.7955(77.7504) | Bit/dim 3.8987(3.9006) | Xent 1.0326(1.0284) | Loss 4.4150(4.4148) | Error 0.3701(0.3658) Steps 832(832.07) | Grad Norm 2.9247(2.0671) | Total Time 14.00(14.00)\n",
      "Iter 2748 | Time 80.7217(77.8395) | Bit/dim 3.8863(3.9002) | Xent 1.0282(1.0284) | Loss 4.4004(4.4144) | Error 0.3655(0.3658) Steps 826(831.89) | Grad Norm 1.2225(2.0417) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 29.7626, Epoch Time 513.6820(513.8231), Bit/dim 3.8998(best: 3.8998), Xent 1.0036, Loss 4.4016, Error 0.3538(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2749 | Time 79.2798(77.8827) | Bit/dim 3.9006(3.9002) | Xent 1.0348(1.0286) | Loss 4.4180(4.4145) | Error 0.3695(0.3659) Steps 820(831.53) | Grad Norm 2.2985(2.0494) | Total Time 14.00(14.00)\n",
      "Iter 2750 | Time 79.5355(77.9323) | Bit/dim 3.9077(3.9004) | Xent 1.0261(1.0285) | Loss 4.4208(4.4147) | Error 0.3639(0.3659) Steps 814(831.01) | Grad Norm 2.1853(2.0535) | Total Time 14.00(14.00)\n",
      "Iter 2751 | Time 79.9032(77.9914) | Bit/dim 3.8987(3.9004) | Xent 1.0158(1.0281) | Loss 4.4066(4.4144) | Error 0.3610(0.3657) Steps 844(831.39) | Grad Norm 1.6990(2.0429) | Total Time 14.00(14.00)\n",
      "Iter 2752 | Time 79.3949(78.0335) | Bit/dim 3.9032(3.9004) | Xent 1.0412(1.0285) | Loss 4.4238(4.4147) | Error 0.3761(0.3661) Steps 826(831.23) | Grad Norm 2.5634(2.0585) | Total Time 14.00(14.00)\n",
      "Iter 2753 | Time 79.8706(78.0886) | Bit/dim 3.8878(3.9001) | Xent 1.0247(1.0284) | Loss 4.4002(4.4143) | Error 0.3636(0.3660) Steps 838(831.44) | Grad Norm 2.1550(2.0614) | Total Time 14.00(14.00)\n",
      "Iter 2754 | Time 75.5606(78.0128) | Bit/dim 3.8946(3.8999) | Xent 1.0280(1.0284) | Loss 4.4086(4.4141) | Error 0.3700(0.3661) Steps 838(831.63) | Grad Norm 2.2556(2.0672) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 29.8254, Epoch Time 519.3079(513.9876), Bit/dim 3.8997(best: 3.8998), Xent 1.0048, Loss 4.4021, Error 0.3541(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2755 | Time 77.9333(78.0104) | Bit/dim 3.9091(3.9002) | Xent 1.0188(1.0281) | Loss 4.4185(4.4142) | Error 0.3600(0.3659) Steps 826(831.46) | Grad Norm 2.5967(2.0831) | Total Time 14.00(14.00)\n",
      "Iter 2756 | Time 76.6433(77.9694) | Bit/dim 3.8935(3.9000) | Xent 1.0230(1.0279) | Loss 4.4050(4.4139) | Error 0.3624(0.3658) Steps 838(831.66) | Grad Norm 1.8944(2.0774) | Total Time 14.00(14.00)\n",
      "Iter 2757 | Time 77.6025(77.9584) | Bit/dim 3.8957(3.8998) | Xent 1.0363(1.0282) | Loss 4.4139(4.4139) | Error 0.3681(0.3659) Steps 826(831.49) | Grad Norm 1.4448(2.0585) | Total Time 14.00(14.00)\n",
      "Iter 2758 | Time 78.4943(77.9745) | Bit/dim 3.8883(3.8995) | Xent 1.0247(1.0281) | Loss 4.4007(4.4135) | Error 0.3649(0.3658) Steps 826(831.33) | Grad Norm 1.8140(2.0511) | Total Time 14.00(14.00)\n",
      "Iter 2759 | Time 77.6874(77.9659) | Bit/dim 3.9020(3.8996) | Xent 1.0272(1.0281) | Loss 4.4156(4.4136) | Error 0.3614(0.3657) Steps 838(831.53) | Grad Norm 1.0865(2.0222) | Total Time 14.00(14.00)\n",
      "Iter 2760 | Time 77.5073(77.9521) | Bit/dim 3.9041(3.8997) | Xent 1.0232(1.0279) | Loss 4.4157(4.4137) | Error 0.3646(0.3657) Steps 838(831.72) | Grad Norm 1.6711(2.0117) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 29.8586, Epoch Time 515.5647(514.0349), Bit/dim 3.8994(best: 3.8997), Xent 1.0013, Loss 4.4001, Error 0.3523(best: 0.3536)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2761 | Time 80.5959(78.0314) | Bit/dim 3.8993(3.8997) | Xent 1.0334(1.0281) | Loss 4.4160(4.4137) | Error 0.3664(0.3657) Steps 826(831.55) | Grad Norm 1.3786(1.9927) | Total Time 14.00(14.00)\n",
      "Iter 2762 | Time 75.7314(77.9624) | Bit/dim 3.8997(3.8997) | Xent 1.0201(1.0278) | Loss 4.4098(4.4136) | Error 0.3675(0.3658) Steps 832(831.56) | Grad Norm 1.1588(1.9677) | Total Time 14.00(14.00)\n",
      "Iter 2763 | Time 78.5446(77.9799) | Bit/dim 3.9009(3.8997) | Xent 1.0121(1.0274) | Loss 4.4069(4.4134) | Error 0.3611(0.3656) Steps 826(831.40) | Grad Norm 1.5173(1.9541) | Total Time 14.00(14.00)\n",
      "Iter 2764 | Time 78.4739(77.9947) | Bit/dim 3.8951(3.8996) | Xent 1.0037(1.0267) | Loss 4.3970(4.4129) | Error 0.3560(0.3653) Steps 838(831.59) | Grad Norm 3.3125(1.9949) | Total Time 14.00(14.00)\n",
      "Iter 2765 | Time 77.4733(77.9791) | Bit/dim 3.8933(3.8994) | Xent 1.0374(1.0270) | Loss 4.4120(4.4129) | Error 0.3719(0.3655) Steps 832(831.61) | Grad Norm 2.2301(2.0019) | Total Time 14.00(14.00)\n",
      "Iter 2766 | Time 76.3377(77.9298) | Bit/dim 3.8965(3.8993) | Xent 1.0380(1.0273) | Loss 4.4155(4.4130) | Error 0.3658(0.3655) Steps 814(831.08) | Grad Norm 3.4920(2.0467) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 29.8616, Epoch Time 512.3531(513.9845), Bit/dim 3.8989(best: 3.8994), Xent 1.0019, Loss 4.3998, Error 0.3570(best: 0.3523)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2767 | Time 76.4585(77.8857) | Bit/dim 3.9043(3.8995) | Xent 1.0235(1.0272) | Loss 4.4161(4.4131) | Error 0.3680(0.3656) Steps 826(830.93) | Grad Norm 2.8529(2.0708) | Total Time 14.00(14.00)\n",
      "Iter 2768 | Time 77.6669(77.8791) | Bit/dim 3.9045(3.8996) | Xent 1.0173(1.0269) | Loss 4.4132(4.4131) | Error 0.3658(0.3656) Steps 838(831.14) | Grad Norm 2.8260(2.0935) | Total Time 14.00(14.00)\n",
      "Iter 2769 | Time 79.1105(77.9161) | Bit/dim 3.8915(3.8994) | Xent 1.0312(1.0270) | Loss 4.4071(4.4129) | Error 0.3638(0.3656) Steps 832(831.16) | Grad Norm 3.9070(2.1479) | Total Time 14.00(14.00)\n",
      "Iter 2770 | Time 76.9813(77.8880) | Bit/dim 3.8968(3.8993) | Xent 1.0447(1.0276) | Loss 4.4191(4.4131) | Error 0.3668(0.3656) Steps 838(831.37) | Grad Norm 2.5012(2.1585) | Total Time 14.00(14.00)\n",
      "Iter 2771 | Time 79.4784(77.9357) | Bit/dim 3.8950(3.8992) | Xent 1.0345(1.0278) | Loss 4.4123(4.4131) | Error 0.3686(0.3657) Steps 820(831.03) | Grad Norm 3.8401(2.2089) | Total Time 14.00(14.00)\n",
      "Iter 2772 | Time 78.8862(77.9642) | Bit/dim 3.8981(3.8991) | Xent 1.0345(1.0280) | Loss 4.4154(4.4131) | Error 0.3678(0.3657) Steps 826(830.88) | Grad Norm 1.9048(2.1998) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 29.8264, Epoch Time 513.8940(513.9818), Bit/dim 3.8990(best: 3.8989), Xent 0.9992, Loss 4.3986, Error 0.3526(best: 0.3523)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2773 | Time 77.5560(77.9520) | Bit/dim 3.9039(3.8993) | Xent 1.0283(1.0280) | Loss 4.4181(4.4133) | Error 0.3622(0.3656) Steps 844(831.27) | Grad Norm 3.0872(2.2264) | Total Time 14.00(14.00)\n",
      "Iter 2774 | Time 77.9505(77.9520) | Bit/dim 3.8887(3.8990) | Xent 1.0163(1.0276) | Loss 4.3968(4.4128) | Error 0.3646(0.3656) Steps 844(831.65) | Grad Norm 1.6589(2.2094) | Total Time 14.00(14.00)\n",
      "Iter 2775 | Time 75.2541(77.8710) | Bit/dim 3.8912(3.8987) | Xent 1.0445(1.0281) | Loss 4.4135(4.4128) | Error 0.3659(0.3656) Steps 820(831.30) | Grad Norm 1.9759(2.2024) | Total Time 14.00(14.00)\n",
      "Iter 2776 | Time 78.5839(77.8924) | Bit/dim 3.9063(3.8990) | Xent 0.9986(1.0273) | Loss 4.4055(4.4126) | Error 0.3500(0.3651) Steps 826(831.14) | Grad Norm 1.6142(2.1848) | Total Time 14.00(14.00)\n",
      "Iter 2777 | Time 75.6665(77.8256) | Bit/dim 3.9019(3.8990) | Xent 1.0133(1.0268) | Loss 4.4086(4.4125) | Error 0.3639(0.3651) Steps 826(830.99) | Grad Norm 1.2055(2.1554) | Total Time 14.00(14.00)\n",
      "Iter 2778 | Time 76.0258(77.7716) | Bit/dim 3.8886(3.8987) | Xent 1.0270(1.0268) | Loss 4.4021(4.4122) | Error 0.3686(0.3652) Steps 826(830.84) | Grad Norm 1.2588(2.1285) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 29.6124, Epoch Time 507.1282(513.7762), Bit/dim 3.8982(best: 3.8989), Xent 1.0022, Loss 4.3993, Error 0.3559(best: 0.3523)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2779 | Time 79.5529(77.8251) | Bit/dim 3.9012(3.8988) | Xent 1.0391(1.0272) | Loss 4.4207(4.4124) | Error 0.3736(0.3655) Steps 826(830.69) | Grad Norm 1.6589(2.1144) | Total Time 14.00(14.00)\n",
      "Iter 2780 | Time 76.4288(77.7832) | Bit/dim 3.8916(3.8986) | Xent 1.0244(1.0271) | Loss 4.4038(4.4122) | Error 0.3610(0.3653) Steps 826(830.55) | Grad Norm 1.4453(2.0943) | Total Time 14.00(14.00)\n",
      "Iter 2781 | Time 78.5527(77.8063) | Bit/dim 3.8960(3.8985) | Xent 1.0191(1.0269) | Loss 4.4055(4.4120) | Error 0.3622(0.3652) Steps 826(830.42) | Grad Norm 1.9610(2.0903) | Total Time 14.00(14.00)\n",
      "Iter 2782 | Time 79.0188(77.8426) | Bit/dim 3.9016(3.8986) | Xent 0.9977(1.0260) | Loss 4.4005(4.4116) | Error 0.3615(0.3651) Steps 838(830.64) | Grad Norm 1.0407(2.0588) | Total Time 14.00(14.00)\n",
      "Iter 2783 | Time 79.2989(77.8863) | Bit/dim 3.8926(3.8984) | Xent 1.0019(1.0253) | Loss 4.3935(4.4111) | Error 0.3619(0.3650) Steps 826(830.50) | Grad Norm 1.4241(2.0398) | Total Time 14.00(14.00)\n",
      "Iter 2784 | Time 79.1455(77.9241) | Bit/dim 3.9003(3.8985) | Xent 1.0302(1.0254) | Loss 4.4153(4.4112) | Error 0.3639(0.3650) Steps 826(830.37) | Grad Norm 1.4958(2.0235) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 29.8323, Epoch Time 518.9220(513.9305), Bit/dim 3.8976(best: 3.8982), Xent 0.9980, Loss 4.3966, Error 0.3529(best: 0.3523)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2785 | Time 78.3744(77.9376) | Bit/dim 3.8888(3.8982) | Xent 1.0026(1.0247) | Loss 4.3901(4.4106) | Error 0.3589(0.3648) Steps 826(830.24) | Grad Norm 1.0011(1.9928) | Total Time 14.00(14.00)\n",
      "Iter 2786 | Time 74.3918(77.8312) | Bit/dim 3.9030(3.8983) | Xent 1.0054(1.0242) | Loss 4.4057(4.4104) | Error 0.3602(0.3647) Steps 820(829.93) | Grad Norm 1.2525(1.9706) | Total Time 14.00(14.00)\n",
      "Iter 2787 | Time 78.3569(77.8470) | Bit/dim 3.8993(3.8984) | Xent 1.0322(1.0244) | Loss 4.4154(4.4106) | Error 0.3669(0.3647) Steps 826(829.81) | Grad Norm 3.1991(2.0074) | Total Time 14.00(14.00)\n",
      "Iter 2788 | Time 76.7541(77.8142) | Bit/dim 3.9018(3.8985) | Xent 1.0104(1.0240) | Loss 4.4070(4.4105) | Error 0.3629(0.3647) Steps 826(829.70) | Grad Norm 1.0904(1.9799) | Total Time 14.00(14.00)\n",
      "Iter 2789 | Time 75.1844(77.7353) | Bit/dim 3.8889(3.8982) | Xent 1.0059(1.0234) | Loss 4.3918(4.4099) | Error 0.3659(0.3647) Steps 832(829.77) | Grad Norm 2.3960(1.9924) | Total Time 14.00(14.00)\n",
      "Iter 2790 | Time 78.7412(77.7655) | Bit/dim 3.8950(3.8981) | Xent 1.0394(1.0239) | Loss 4.4147(4.4100) | Error 0.3615(0.3646) Steps 838(830.02) | Grad Norm 1.5102(1.9779) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 29.2964, Epoch Time 506.5168(513.7081), Bit/dim 3.8979(best: 3.8976), Xent 0.9990, Loss 4.3975, Error 0.3557(best: 0.3523)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2791 | Time 79.5392(77.8187) | Bit/dim 3.8899(3.8978) | Xent 1.0246(1.0239) | Loss 4.4022(4.4098) | Error 0.3570(0.3644) Steps 838(830.25) | Grad Norm 1.0054(1.9488) | Total Time 14.00(14.00)\n",
      "Iter 2792 | Time 77.1588(77.7989) | Bit/dim 3.9055(3.8981) | Xent 1.0079(1.0235) | Loss 4.4094(4.4098) | Error 0.3614(0.3643) Steps 832(830.31) | Grad Norm 2.3903(1.9620) | Total Time 14.00(14.00)\n",
      "Iter 2793 | Time 77.4723(77.7891) | Bit/dim 3.8949(3.8980) | Xent 1.0311(1.0237) | Loss 4.4105(4.4098) | Error 0.3648(0.3643) Steps 826(830.18) | Grad Norm 1.8899(1.9599) | Total Time 14.00(14.00)\n",
      "Iter 2794 | Time 77.2406(77.7727) | Bit/dim 3.8956(3.8979) | Xent 1.0179(1.0235) | Loss 4.4046(4.4097) | Error 0.3661(0.3644) Steps 838(830.41) | Grad Norm 2.8933(1.9879) | Total Time 14.00(14.00)\n",
      "Iter 2795 | Time 77.2262(77.7563) | Bit/dim 3.8922(3.8977) | Xent 1.0345(1.0238) | Loss 4.4094(4.4097) | Error 0.3634(0.3643) Steps 826(830.28) | Grad Norm 1.5750(1.9755) | Total Time 14.00(14.00)\n",
      "Iter 2796 | Time 77.1990(77.7396) | Bit/dim 3.8966(3.8977) | Xent 1.0103(1.0234) | Loss 4.4017(4.4094) | Error 0.3604(0.3642) Steps 838(830.51) | Grad Norm 2.2209(1.9828) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 29.8398, Epoch Time 511.2124(513.6332), Bit/dim 3.8973(best: 3.8976), Xent 0.9979, Loss 4.3963, Error 0.3505(best: 0.3523)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2797 | Time 78.2818(77.7558) | Bit/dim 3.8915(3.8975) | Xent 1.0426(1.0240) | Loss 4.4128(4.4095) | Error 0.3688(0.3644) Steps 826(830.38) | Grad Norm 2.2711(1.9915) | Total Time 14.00(14.00)\n",
      "Iter 2798 | Time 76.7017(77.7242) | Bit/dim 3.8966(3.8975) | Xent 1.0192(1.0239) | Loss 4.4062(4.4094) | Error 0.3598(0.3642) Steps 826(830.25) | Grad Norm 1.7988(1.9857) | Total Time 14.00(14.00)\n",
      "Iter 2799 | Time 74.9745(77.6417) | Bit/dim 3.8912(3.8973) | Xent 1.0262(1.0239) | Loss 4.4043(4.4093) | Error 0.3746(0.3645) Steps 814(829.76) | Grad Norm 3.3079(2.0254) | Total Time 14.00(14.00)\n",
      "Iter 2800 | Time 74.5614(77.5493) | Bit/dim 3.8970(3.8973) | Xent 1.0027(1.0233) | Loss 4.3984(4.4089) | Error 0.3529(0.3642) Steps 826(829.65) | Grad Norm 1.7487(2.0171) | Total Time 14.00(14.00)\n",
      "Iter 2801 | Time 80.3919(77.6346) | Bit/dim 3.8937(3.8972) | Xent 1.0274(1.0234) | Loss 4.4074(4.4089) | Error 0.3610(0.3641) Steps 826(829.54) | Grad Norm 3.6950(2.0674) | Total Time 14.00(14.00)\n",
      "Iter 2802 | Time 75.9132(77.5829) | Bit/dim 3.8991(3.8972) | Xent 1.0033(1.0228) | Loss 4.4007(4.4086) | Error 0.3511(0.3637) Steps 838(829.79) | Grad Norm 2.0396(2.0666) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 29.6763, Epoch Time 505.8647(513.4002), Bit/dim 3.8976(best: 3.8973), Xent 1.0026, Loss 4.3989, Error 0.3545(best: 0.3505)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2803 | Time 81.3345(77.6955) | Bit/dim 3.8972(3.8972) | Xent 1.0255(1.0229) | Loss 4.4100(4.4087) | Error 0.3662(0.3638) Steps 808(829.14) | Grad Norm 2.3715(2.0757) | Total Time 14.00(14.00)\n",
      "Iter 2804 | Time 78.3432(77.7149) | Bit/dim 3.8935(3.8971) | Xent 1.0318(1.0232) | Loss 4.4094(4.4087) | Error 0.3621(0.3637) Steps 826(829.04) | Grad Norm 2.2765(2.0817) | Total Time 14.00(14.00)\n",
      "Iter 2805 | Time 72.5878(77.5611) | Bit/dim 3.8926(3.8970) | Xent 1.0259(1.0233) | Loss 4.4055(4.4086) | Error 0.3702(0.3639) Steps 826(828.95) | Grad Norm 1.8736(2.0755) | Total Time 14.00(14.00)\n",
      "Iter 2806 | Time 75.3342(77.4943) | Bit/dim 3.9011(3.8971) | Xent 1.0031(1.0226) | Loss 4.4026(4.4084) | Error 0.3571(0.3637) Steps 826(828.86) | Grad Norm 2.1008(2.0763) | Total Time 14.00(14.00)\n",
      "Iter 2807 | Time 74.4952(77.4043) | Bit/dim 3.8955(3.8971) | Xent 1.0210(1.0226) | Loss 4.4060(4.4084) | Error 0.3641(0.3637) Steps 826(828.78) | Grad Norm 1.9439(2.0723) | Total Time 14.00(14.00)\n",
      "Iter 2808 | Time 79.3040(77.4613) | Bit/dim 3.8953(3.8970) | Xent 1.0202(1.0225) | Loss 4.4054(4.4083) | Error 0.3621(0.3637) Steps 838(829.05) | Grad Norm 1.7487(2.0626) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 29.8413, Epoch Time 506.6410(513.1974), Bit/dim 3.8978(best: 3.8973), Xent 0.9990, Loss 4.3973, Error 0.3524(best: 0.3505)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2809 | Time 80.2515(77.5450) | Bit/dim 3.8938(3.8969) | Xent 1.0311(1.0228) | Loss 4.4094(4.4083) | Error 0.3625(0.3636) Steps 826(828.96) | Grad Norm 2.7595(2.0835) | Total Time 14.00(14.00)\n",
      "Iter 2810 | Time 78.4702(77.5728) | Bit/dim 3.9057(3.8972) | Xent 1.0115(1.0224) | Loss 4.4115(4.4084) | Error 0.3606(0.3636) Steps 826(828.87) | Grad Norm 1.5261(2.0668) | Total Time 14.00(14.00)\n",
      "Iter 2811 | Time 78.8045(77.6097) | Bit/dim 3.8975(3.8972) | Xent 1.0105(1.0221) | Loss 4.4027(4.4082) | Error 0.3570(0.3634) Steps 832(828.97) | Grad Norm 2.6909(2.0855) | Total Time 14.00(14.00)\n",
      "Iter 2812 | Time 76.5060(77.5766) | Bit/dim 3.9036(3.8974) | Xent 1.0078(1.0217) | Loss 4.4075(4.4082) | Error 0.3608(0.3633) Steps 826(828.88) | Grad Norm 1.4629(2.0668) | Total Time 14.00(14.00)\n",
      "Iter 2813 | Time 74.7747(77.4926) | Bit/dim 3.8854(3.8970) | Xent 1.0343(1.0220) | Loss 4.4025(4.4080) | Error 0.3632(0.3633) Steps 838(829.15) | Grad Norm 2.4995(2.0798) | Total Time 14.00(14.00)\n",
      "Iter 2814 | Time 76.3265(77.4576) | Bit/dim 3.8885(3.8968) | Xent 1.0033(1.0215) | Loss 4.3901(4.4075) | Error 0.3581(0.3631) Steps 826(829.06) | Grad Norm 1.6937(2.0682) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 29.9317, Epoch Time 510.5921(513.1193), Bit/dim 3.8962(best: 3.8973), Xent 0.9978, Loss 4.3951, Error 0.3535(best: 0.3505)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2815 | Time 79.0595(77.5056) | Bit/dim 3.8996(3.8969) | Xent 1.0128(1.0212) | Loss 4.4060(4.4075) | Error 0.3631(0.3631) Steps 832(829.14) | Grad Norm 2.8943(2.0930) | Total Time 14.00(14.00)\n",
      "Iter 2816 | Time 76.4511(77.4740) | Bit/dim 3.8874(3.8966) | Xent 1.0337(1.0216) | Loss 4.4043(4.4074) | Error 0.3605(0.3630) Steps 820(828.87) | Grad Norm 1.4350(2.0733) | Total Time 14.00(14.00)\n",
      "Iter 2817 | Time 74.4720(77.3839) | Bit/dim 3.9012(3.8967) | Xent 1.0174(1.0215) | Loss 4.4099(4.4074) | Error 0.3588(0.3629) Steps 832(828.96) | Grad Norm 3.1630(2.1059) | Total Time 14.00(14.00)\n",
      "Iter 2818 | Time 77.0580(77.3742) | Bit/dim 3.8924(3.8966) | Xent 1.0225(1.0215) | Loss 4.4036(4.4073) | Error 0.3626(0.3629) Steps 838(829.24) | Grad Norm 1.2383(2.0799) | Total Time 14.00(14.00)\n",
      "Iter 2819 | Time 74.7708(77.2961) | Bit/dim 3.8949(3.8965) | Xent 1.0020(1.0209) | Loss 4.3959(4.4070) | Error 0.3579(0.3628) Steps 820(828.96) | Grad Norm 1.1535(2.0521) | Total Time 14.00(14.00)\n",
      "Iter 2820 | Time 76.6254(77.2759) | Bit/dim 3.8952(3.8965) | Xent 1.0243(1.0210) | Loss 4.4074(4.4070) | Error 0.3704(0.3630) Steps 826(828.87) | Grad Norm 1.4278(2.0334) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 29.3432, Epoch Time 503.5439(512.8320), Bit/dim 3.8963(best: 3.8962), Xent 0.9956, Loss 4.3941, Error 0.3517(best: 0.3505)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2821 | Time 75.8176(77.2322) | Bit/dim 3.8956(3.8965) | Xent 1.0246(1.0211) | Loss 4.4079(4.4070) | Error 0.3604(0.3629) Steps 820(828.60) | Grad Norm 1.0603(2.0042) | Total Time 14.00(14.00)\n",
      "Iter 2822 | Time 78.4124(77.2676) | Bit/dim 3.9017(3.8966) | Xent 1.0154(1.0209) | Loss 4.4094(4.4071) | Error 0.3701(0.3631) Steps 826(828.53) | Grad Norm 1.9414(2.0023) | Total Time 14.00(14.00)\n",
      "Iter 2823 | Time 79.1848(77.3251) | Bit/dim 3.8872(3.8963) | Xent 1.0002(1.0203) | Loss 4.3873(4.4065) | Error 0.3560(0.3629) Steps 838(828.81) | Grad Norm 1.5486(1.9887) | Total Time 14.00(14.00)\n",
      "Iter 2824 | Time 79.0743(77.3776) | Bit/dim 3.8971(3.8964) | Xent 0.9917(1.0195) | Loss 4.3930(4.4061) | Error 0.3519(0.3626) Steps 826(828.73) | Grad Norm 1.8302(1.9840) | Total Time 14.00(14.00)\n",
      "Iter 2825 | Time 78.5554(77.4129) | Bit/dim 3.8900(3.8962) | Xent 1.0419(1.0201) | Loss 4.4109(4.4062) | Error 0.3676(0.3627) Steps 820(828.46) | Grad Norm 2.3373(1.9946) | Total Time 14.00(14.00)\n",
      "Iter 2826 | Time 78.8945(77.4574) | Bit/dim 3.8918(3.8960) | Xent 1.0210(1.0202) | Loss 4.4023(4.4061) | Error 0.3646(0.3628) Steps 838(828.75) | Grad Norm 1.5338(1.9807) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 29.6341, Epoch Time 515.3092(512.9063), Bit/dim 3.8962(best: 3.8962), Xent 0.9978, Loss 4.3951, Error 0.3524(best: 0.3505)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2827 | Time 78.2203(77.4803) | Bit/dim 3.9012(3.8962) | Xent 1.0259(1.0203) | Loss 4.4142(4.4064) | Error 0.3661(0.3629) Steps 832(828.85) | Grad Norm 3.4250(2.0241) | Total Time 14.00(14.00)\n",
      "Iter 2828 | Time 77.8469(77.4913) | Bit/dim 3.8958(3.8962) | Xent 1.0133(1.0201) | Loss 4.4025(4.4062) | Error 0.3581(0.3627) Steps 832(828.94) | Grad Norm 1.8714(2.0195) | Total Time 14.00(14.00)\n",
      "Iter 2829 | Time 76.9870(77.4761) | Bit/dim 3.8817(3.8957) | Xent 1.0137(1.0199) | Loss 4.3885(4.4057) | Error 0.3670(0.3629) Steps 826(828.85) | Grad Norm 2.5079(2.0341) | Total Time 14.00(14.00)\n",
      "Iter 2830 | Time 77.6342(77.4809) | Bit/dim 3.8999(3.8959) | Xent 1.0286(1.0202) | Loss 4.4142(4.4060) | Error 0.3721(0.3632) Steps 826(828.77) | Grad Norm 2.0457(2.0345) | Total Time 14.00(14.00)\n",
      "Iter 2831 | Time 77.8146(77.4909) | Bit/dim 3.8893(3.8957) | Xent 1.0196(1.0202) | Loss 4.3991(4.4058) | Error 0.3670(0.3633) Steps 826(828.68) | Grad Norm 1.7720(2.0266) | Total Time 14.00(14.00)\n",
      "Iter 2832 | Time 78.0455(77.5075) | Bit/dim 3.8937(3.8956) | Xent 1.0025(1.0196) | Loss 4.3950(4.4054) | Error 0.3624(0.3632) Steps 826(828.60) | Grad Norm 1.4371(2.0089) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 29.6536, Epoch Time 511.8866(512.8757), Bit/dim 3.8948(best: 3.8962), Xent 0.9967, Loss 4.3931, Error 0.3518(best: 0.3505)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2833 | Time 78.7753(77.5456) | Bit/dim 3.8920(3.8955) | Xent 1.0090(1.0193) | Loss 4.3965(4.4052) | Error 0.3512(0.3629) Steps 838(828.89) | Grad Norm 2.4413(2.0219) | Total Time 14.00(14.00)\n",
      "Iter 2834 | Time 77.1016(77.5322) | Bit/dim 3.8884(3.8953) | Xent 1.0249(1.0195) | Loss 4.4008(4.4050) | Error 0.3674(0.3630) Steps 826(828.80) | Grad Norm 1.0231(1.9919) | Total Time 14.00(14.00)\n",
      "Iter 2835 | Time 78.8472(77.5717) | Bit/dim 3.8989(3.8954) | Xent 1.0180(1.0194) | Loss 4.4079(4.4051) | Error 0.3609(0.3630) Steps 838(829.08) | Grad Norm 1.2616(1.9700) | Total Time 14.00(14.00)\n",
      "Iter 2836 | Time 76.7964(77.5484) | Bit/dim 3.8904(3.8953) | Xent 0.9990(1.0188) | Loss 4.3899(4.4047) | Error 0.3599(0.3629) Steps 820(828.80) | Grad Norm 1.3334(1.9509) | Total Time 14.00(14.00)\n",
      "Iter 2837 | Time 72.2119(77.3883) | Bit/dim 3.9009(3.8954) | Xent 1.0251(1.0190) | Loss 4.4134(4.4049) | Error 0.3621(0.3628) Steps 826(828.72) | Grad Norm 1.2602(1.9302) | Total Time 14.00(14.00)\n",
      "Iter 2838 | Time 77.1478(77.3811) | Bit/dim 3.8938(3.8954) | Xent 1.0067(1.0187) | Loss 4.3971(4.4047) | Error 0.3604(0.3628) Steps 826(828.64) | Grad Norm 1.5195(1.9179) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 29.6448, Epoch Time 505.9629(512.6683), Bit/dim 3.8941(best: 3.8948), Xent 0.9931, Loss 4.3906, Error 0.3511(best: 0.3505)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2839 | Time 74.3195(77.2893) | Bit/dim 3.9035(3.8956) | Xent 1.0166(1.0186) | Loss 4.4118(4.4049) | Error 0.3592(0.3627) Steps 826(828.56) | Grad Norm 1.5779(1.9077) | Total Time 14.00(14.00)\n",
      "Iter 2840 | Time 76.5074(77.2658) | Bit/dim 3.8891(3.8954) | Xent 1.0226(1.0187) | Loss 4.4004(4.4048) | Error 0.3549(0.3624) Steps 832(828.66) | Grad Norm 1.2058(1.8866) | Total Time 14.00(14.00)\n",
      "Iter 2841 | Time 76.9041(77.2550) | Bit/dim 3.8864(3.8951) | Xent 1.0193(1.0187) | Loss 4.3961(4.4045) | Error 0.3659(0.3625) Steps 832(828.76) | Grad Norm 1.4787(1.8744) | Total Time 14.00(14.00)\n",
      "Iter 2842 | Time 79.4403(77.3205) | Bit/dim 3.9036(3.8954) | Xent 1.0047(1.0183) | Loss 4.4060(4.4046) | Error 0.3562(0.3623) Steps 826(828.68) | Grad Norm 1.3364(1.8582) | Total Time 14.00(14.00)\n",
      "Iter 2843 | Time 79.3544(77.3815) | Bit/dim 3.8942(3.8954) | Xent 0.9932(1.0176) | Loss 4.3908(4.4041) | Error 0.3540(0.3621) Steps 838(828.96) | Grad Norm 1.3118(1.8419) | Total Time 14.00(14.00)\n",
      "Iter 2844 | Time 75.6031(77.3282) | Bit/dim 3.8856(3.8951) | Xent 1.0128(1.0174) | Loss 4.3920(4.4038) | Error 0.3582(0.3620) Steps 838(829.23) | Grad Norm 1.8849(1.8431) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 30.1064, Epoch Time 507.8281(512.5231), Bit/dim 3.8942(best: 3.8941), Xent 0.9947, Loss 4.3916, Error 0.3519(best: 0.3505)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2845 | Time 72.7737(77.1915) | Bit/dim 3.8910(3.8950) | Xent 1.0282(1.0177) | Loss 4.4051(4.4038) | Error 0.3735(0.3623) Steps 820(828.95) | Grad Norm 1.5407(1.8341) | Total Time 14.00(14.00)\n",
      "Iter 2846 | Time 78.5355(77.2319) | Bit/dim 3.9012(3.8951) | Xent 1.0202(1.0178) | Loss 4.4113(4.4040) | Error 0.3559(0.3621) Steps 826(828.86) | Grad Norm 1.3267(1.8188) | Total Time 14.00(14.00)\n",
      "Iter 2847 | Time 77.7287(77.2468) | Bit/dim 3.8936(3.8951) | Xent 1.0050(1.0174) | Loss 4.3961(4.4038) | Error 0.3606(0.3621) Steps 820(828.60) | Grad Norm 1.7472(1.8167) | Total Time 14.00(14.00)\n",
      "Iter 2848 | Time 76.7877(77.2330) | Bit/dim 3.8949(3.8951) | Xent 1.0208(1.0175) | Loss 4.4053(4.4039) | Error 0.3608(0.3620) Steps 832(828.70) | Grad Norm 1.4744(1.8064) | Total Time 14.00(14.00)\n",
      "Iter 2849 | Time 77.7930(77.2498) | Bit/dim 3.8860(3.8948) | Xent 1.0168(1.0175) | Loss 4.3944(4.4036) | Error 0.3669(0.3622) Steps 820(828.44) | Grad Norm 1.2579(1.7900) | Total Time 14.00(14.00)\n",
      "Iter 2850 | Time 79.6434(77.3216) | Bit/dim 3.8923(3.8947) | Xent 0.9988(1.0169) | Loss 4.3917(4.4032) | Error 0.3501(0.3618) Steps 832(828.55) | Grad Norm 2.3193(1.8059) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 30.2179, Epoch Time 508.7275(512.4093), Bit/dim 3.8941(best: 3.8941), Xent 0.9924, Loss 4.3903, Error 0.3494(best: 0.3505)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2851 | Time 77.9949(77.3418) | Bit/dim 3.8888(3.8946) | Xent 1.0005(1.0164) | Loss 4.3891(4.4028) | Error 0.3551(0.3616) Steps 832(828.65) | Grad Norm 1.8200(1.8063) | Total Time 14.00(14.00)\n",
      "Iter 2852 | Time 76.6557(77.3212) | Bit/dim 3.8958(3.8946) | Xent 1.0057(1.0161) | Loss 4.3986(4.4027) | Error 0.3531(0.3614) Steps 832(828.75) | Grad Norm 1.7721(1.8053) | Total Time 14.00(14.00)\n",
      "Iter 2853 | Time 79.3239(77.3813) | Bit/dim 3.8846(3.8943) | Xent 1.0189(1.0162) | Loss 4.3941(4.4024) | Error 0.3636(0.3614) Steps 832(828.85) | Grad Norm 2.8884(1.8377) | Total Time 14.00(14.00)\n",
      "Iter 2854 | Time 74.9815(77.3093) | Bit/dim 3.8988(3.8944) | Xent 1.0257(1.0165) | Loss 4.4117(4.4027) | Error 0.3656(0.3616) Steps 826(828.76) | Grad Norm 1.8212(1.8373) | Total Time 14.00(14.00)\n",
      "Iter 2855 | Time 76.0758(77.2723) | Bit/dim 3.8950(3.8945) | Xent 0.9976(1.0159) | Loss 4.3938(4.4024) | Error 0.3590(0.3615) Steps 826(828.68) | Grad Norm 3.0990(1.8751) | Total Time 14.00(14.00)\n",
      "Iter 2856 | Time 79.5469(77.3405) | Bit/dim 3.8947(3.8945) | Xent 1.0291(1.0163) | Loss 4.4093(4.4026) | Error 0.3670(0.3617) Steps 838(828.96) | Grad Norm 1.4198(1.8614) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 29.8760, Epoch Time 509.8635(512.3329), Bit/dim 3.8944(best: 3.8941), Xent 0.9964, Loss 4.3926, Error 0.3507(best: 0.3494)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2857 | Time 77.9404(77.3585) | Bit/dim 3.8969(3.8945) | Xent 1.0064(1.0160) | Loss 4.4002(4.4025) | Error 0.3505(0.3613) Steps 838(829.23) | Grad Norm 2.2458(1.8730) | Total Time 14.00(14.00)\n",
      "Iter 2858 | Time 77.5091(77.3631) | Bit/dim 3.8916(3.8944) | Xent 1.0094(1.0158) | Loss 4.3963(4.4024) | Error 0.3584(0.3612) Steps 826(829.13) | Grad Norm 1.4299(1.8597) | Total Time 14.00(14.00)\n",
      "Iter 2859 | Time 76.4561(77.3358) | Bit/dim 3.8929(3.8944) | Xent 1.0171(1.0159) | Loss 4.4015(4.4023) | Error 0.3614(0.3612) Steps 832(829.22) | Grad Norm 2.9518(1.8924) | Total Time 14.00(14.00)\n",
      "Iter 2860 | Time 72.4179(77.1883) | Bit/dim 3.8956(3.8944) | Xent 1.0121(1.0158) | Loss 4.4017(4.4023) | Error 0.3636(0.3613) Steps 826(829.12) | Grad Norm 1.5340(1.8817) | Total Time 14.00(14.00)\n",
      "Iter 2861 | Time 76.3589(77.1634) | Bit/dim 3.8919(3.8944) | Xent 1.0100(1.0156) | Loss 4.3970(4.4022) | Error 0.3548(0.3611) Steps 844(829.57) | Grad Norm 1.8133(1.8796) | Total Time 14.00(14.00)\n",
      "Iter 2862 | Time 76.6850(77.1491) | Bit/dim 3.8930(3.8943) | Xent 1.0222(1.0158) | Loss 4.4041(4.4022) | Error 0.3659(0.3613) Steps 820(829.28) | Grad Norm 1.6296(1.8721) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 29.9475, Epoch Time 502.7932(512.0467), Bit/dim 3.8946(best: 3.8941), Xent 0.9918, Loss 4.3905, Error 0.3499(best: 0.3494)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2863 | Time 75.7816(77.1080) | Bit/dim 3.8793(3.8939) | Xent 1.0236(1.0160) | Loss 4.3911(4.4019) | Error 0.3634(0.3613) Steps 826(829.18) | Grad Norm 1.9004(1.8730) | Total Time 14.00(14.00)\n",
      "Iter 2864 | Time 75.2201(77.0514) | Bit/dim 3.9000(3.8941) | Xent 1.0095(1.0158) | Loss 4.4047(4.4020) | Error 0.3591(0.3612) Steps 832(829.27) | Grad Norm 1.3577(1.8575) | Total Time 14.00(14.00)\n",
      "Iter 2865 | Time 79.6219(77.1285) | Bit/dim 3.8953(3.8941) | Xent 1.0067(1.0155) | Loss 4.3986(4.4019) | Error 0.3552(0.3611) Steps 832(829.35) | Grad Norm 1.7613(1.8546) | Total Time 14.00(14.00)\n",
      "Iter 2866 | Time 75.9436(77.0930) | Bit/dim 3.8870(3.8939) | Xent 0.9968(1.0150) | Loss 4.3853(4.4014) | Error 0.3492(0.3607) Steps 832(829.43) | Grad Norm 1.7711(1.8521) | Total Time 14.00(14.00)\n",
      "Iter 2867 | Time 76.0622(77.0621) | Bit/dim 3.8978(3.8940) | Xent 1.0113(1.0149) | Loss 4.4035(4.4014) | Error 0.3545(0.3605) Steps 820(829.15) | Grad Norm 1.2406(1.8338) | Total Time 14.00(14.00)\n",
      "Iter 2868 | Time 80.0854(77.1528) | Bit/dim 3.8948(3.8940) | Xent 1.0163(1.0149) | Loss 4.4030(4.4015) | Error 0.3618(0.3606) Steps 820(828.87) | Grad Norm 1.7837(1.8323) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 29.5863, Epoch Time 507.9709(511.9244), Bit/dim 3.8924(best: 3.8941), Xent 0.9930, Loss 4.3889, Error 0.3519(best: 0.3494)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2869 | Time 75.9144(77.1156) | Bit/dim 3.8820(3.8937) | Xent 1.0102(1.0148) | Loss 4.3871(4.4010) | Error 0.3654(0.3607) Steps 838(829.15) | Grad Norm 1.2676(1.8153) | Total Time 14.00(14.00)\n",
      "Iter 2870 | Time 77.5510(77.1287) | Bit/dim 3.9033(3.8939) | Xent 1.0093(1.0146) | Loss 4.4079(4.4013) | Error 0.3590(0.3607) Steps 826(829.05) | Grad Norm 0.9132(1.7883) | Total Time 14.00(14.00)\n",
      "Iter 2871 | Time 75.9836(77.0943) | Bit/dim 3.8768(3.8934) | Xent 1.0140(1.0146) | Loss 4.3838(4.4007) | Error 0.3629(0.3607) Steps 826(828.96) | Grad Norm 1.4024(1.7767) | Total Time 14.00(14.00)\n",
      "Iter 2872 | Time 75.9342(77.0595) | Bit/dim 3.8868(3.8932) | Xent 1.0176(1.0147) | Loss 4.3956(4.4006) | Error 0.3665(0.3609) Steps 832(829.05) | Grad Norm 1.3774(1.7647) | Total Time 14.00(14.00)\n",
      "Iter 2873 | Time 76.1016(77.0308) | Bit/dim 3.8945(3.8933) | Xent 1.0175(1.0148) | Loss 4.4033(4.4007) | Error 0.3630(0.3610) Steps 838(829.32) | Grad Norm 1.6384(1.7609) | Total Time 14.00(14.00)\n",
      "Iter 2874 | Time 77.8595(77.0556) | Bit/dim 3.9069(3.8937) | Xent 0.9996(1.0143) | Loss 4.4067(4.4008) | Error 0.3605(0.3609) Steps 826(829.22) | Grad Norm 2.3764(1.7794) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 29.7921, Epoch Time 504.6475(511.7061), Bit/dim 3.8925(best: 3.8924), Xent 0.9927, Loss 4.3888, Error 0.3489(best: 0.3494)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2875 | Time 77.7958(77.0778) | Bit/dim 3.8983(3.8938) | Xent 1.0186(1.0144) | Loss 4.4076(4.4010) | Error 0.3632(0.3610) Steps 826(829.12) | Grad Norm 2.0782(1.7884) | Total Time 14.00(14.00)\n",
      "Iter 2876 | Time 78.3023(77.1146) | Bit/dim 3.8888(3.8937) | Xent 1.0074(1.0142) | Loss 4.3925(4.4008) | Error 0.3548(0.3608) Steps 826(829.03) | Grad Norm 1.8574(1.7904) | Total Time 14.00(14.00)\n",
      "Iter 2877 | Time 77.5196(77.1267) | Bit/dim 3.8837(3.8934) | Xent 1.0081(1.0140) | Loss 4.3878(4.4004) | Error 0.3582(0.3607) Steps 832(829.12) | Grad Norm 2.3384(1.8069) | Total Time 14.00(14.00)\n",
      "Iter 2878 | Time 77.3989(77.1349) | Bit/dim 3.8873(3.8932) | Xent 1.0013(1.0137) | Loss 4.3879(4.4000) | Error 0.3534(0.3605) Steps 838(829.39) | Grad Norm 1.9705(1.8118) | Total Time 14.00(14.00)\n",
      "Iter 2879 | Time 77.9792(77.1602) | Bit/dim 3.9001(3.8934) | Xent 1.0102(1.0136) | Loss 4.4052(4.4002) | Error 0.3620(0.3606) Steps 826(829.28) | Grad Norm 2.0231(1.8181) | Total Time 14.00(14.00)\n",
      "Iter 2880 | Time 78.9804(77.2148) | Bit/dim 3.8914(3.8933) | Xent 1.0162(1.0136) | Loss 4.3995(4.4002) | Error 0.3552(0.3604) Steps 826(829.19) | Grad Norm 2.7090(1.8448) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 30.0020, Epoch Time 513.5609(511.7618), Bit/dim 3.8936(best: 3.8924), Xent 0.9920, Loss 4.3896, Error 0.3507(best: 0.3489)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2881 | Time 77.2278(77.2152) | Bit/dim 3.8874(3.8932) | Xent 1.0153(1.0137) | Loss 4.3950(4.4000) | Error 0.3635(0.3605) Steps 826(829.09) | Grad Norm 1.2547(1.8271) | Total Time 14.00(14.00)\n",
      "Iter 2882 | Time 76.7890(77.2024) | Bit/dim 3.8991(3.8933) | Xent 1.0280(1.0141) | Loss 4.4131(4.4004) | Error 0.3615(0.3605) Steps 838(829.36) | Grad Norm 2.8823(1.8588) | Total Time 14.00(14.00)\n",
      "Iter 2883 | Time 77.2715(77.2045) | Bit/dim 3.8831(3.8930) | Xent 1.0237(1.0144) | Loss 4.3950(4.4002) | Error 0.3620(0.3606) Steps 838(829.62) | Grad Norm 1.7861(1.8566) | Total Time 14.00(14.00)\n",
      "Iter 2884 | Time 77.8372(77.2235) | Bit/dim 3.8953(3.8931) | Xent 1.0121(1.0143) | Loss 4.4013(4.4003) | Error 0.3490(0.3602) Steps 838(829.87) | Grad Norm 2.0856(1.8635) | Total Time 14.00(14.00)\n",
      "Iter 2885 | Time 73.8084(77.1210) | Bit/dim 3.8925(3.8931) | Xent 1.0058(1.0141) | Loss 4.3954(4.4001) | Error 0.3621(0.3603) Steps 826(829.75) | Grad Norm 2.3787(1.8789) | Total Time 14.00(14.00)\n",
      "Iter 2886 | Time 76.4941(77.1022) | Bit/dim 3.8889(3.8930) | Xent 0.9793(1.0130) | Loss 4.3785(4.3995) | Error 0.3551(0.3601) Steps 844(830.18) | Grad Norm 3.3586(1.9233) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 29.9175, Epoch Time 504.8935(511.5557), Bit/dim 3.8927(best: 3.8924), Xent 0.9939, Loss 4.3897, Error 0.3510(best: 0.3489)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2887 | Time 80.7432(77.2115) | Bit/dim 3.8861(3.8927) | Xent 0.9977(1.0126) | Loss 4.3850(4.3990) | Error 0.3550(0.3600) Steps 820(829.87) | Grad Norm 2.5860(1.9432) | Total Time 14.00(14.00)\n",
      "Iter 2888 | Time 78.2864(77.2437) | Bit/dim 3.8866(3.8926) | Xent 1.0266(1.0130) | Loss 4.3999(4.3991) | Error 0.3680(0.3602) Steps 826(829.76) | Grad Norm 2.1790(1.9503) | Total Time 14.00(14.00)\n",
      "Iter 2889 | Time 76.3391(77.2166) | Bit/dim 3.8940(3.8926) | Xent 1.0203(1.0132) | Loss 4.4042(4.3992) | Error 0.3671(0.3604) Steps 820(829.47) | Grad Norm 4.4340(2.0248) | Total Time 14.00(14.00)\n",
      "Iter 2890 | Time 72.9398(77.0883) | Bit/dim 3.8897(3.8925) | Xent 1.0025(1.0129) | Loss 4.3910(4.3990) | Error 0.3528(0.3602) Steps 826(829.36) | Grad Norm 1.5726(2.0112) | Total Time 14.00(14.00)\n",
      "Iter 2891 | Time 77.6536(77.1052) | Bit/dim 3.8888(3.8924) | Xent 0.9872(1.0121) | Loss 4.3824(4.3985) | Error 0.3474(0.3598) Steps 832(829.44) | Grad Norm 3.5552(2.0575) | Total Time 14.00(14.00)\n",
      "Iter 2892 | Time 77.1711(77.1072) | Bit/dim 3.8998(3.8926) | Xent 1.0116(1.0121) | Loss 4.4056(4.3987) | Error 0.3634(0.3599) Steps 832(829.52) | Grad Norm 1.6745(2.0461) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 30.0422, Epoch Time 508.6550(511.4687), Bit/dim 3.8925(best: 3.8924), Xent 0.9927, Loss 4.3889, Error 0.3498(best: 0.3489)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2893 | Time 76.3041(77.0831) | Bit/dim 3.8886(3.8925) | Xent 1.0354(1.0128) | Loss 4.4063(4.3989) | Error 0.3681(0.3602) Steps 838(829.77) | Grad Norm 4.0269(2.1055) | Total Time 14.00(14.00)\n",
      "Iter 2894 | Time 76.7475(77.0730) | Bit/dim 3.8928(3.8925) | Xent 1.0242(1.0131) | Loss 4.4049(4.3991) | Error 0.3569(0.3601) Steps 832(829.84) | Grad Norm 1.2511(2.0799) | Total Time 14.00(14.00)\n",
      "Iter 2895 | Time 75.1423(77.0151) | Bit/dim 3.8970(3.8927) | Xent 1.0141(1.0132) | Loss 4.4041(4.3992) | Error 0.3585(0.3600) Steps 826(829.72) | Grad Norm 4.1086(2.1407) | Total Time 14.00(14.00)\n",
      "Iter 2896 | Time 76.0446(76.9860) | Bit/dim 3.8894(3.8926) | Xent 0.9987(1.0127) | Loss 4.3887(4.3989) | Error 0.3535(0.3598) Steps 826(829.61) | Grad Norm 1.5943(2.1243) | Total Time 14.00(14.00)\n",
      "Iter 2897 | Time 79.1606(77.0512) | Bit/dim 3.8923(3.8925) | Xent 1.0036(1.0125) | Loss 4.3941(4.3988) | Error 0.3526(0.3596) Steps 808(828.96) | Grad Norm 3.8063(2.1748) | Total Time 14.00(14.00)\n",
      "Iter 2898 | Time 78.5101(77.0950) | Bit/dim 3.8907(3.8925) | Xent 0.9866(1.0117) | Loss 4.3840(4.3983) | Error 0.3486(0.3593) Steps 832(829.05) | Grad Norm 2.2129(2.1759) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 29.7039, Epoch Time 507.6089(511.3529), Bit/dim 3.8923(best: 3.8924), Xent 0.9954, Loss 4.3900, Error 0.3520(best: 0.3489)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2899 | Time 75.7869(77.0558) | Bit/dim 3.8934(3.8925) | Xent 1.0279(1.0122) | Loss 4.4074(4.3986) | Error 0.3661(0.3595) Steps 844(829.50) | Grad Norm 2.3922(2.1824) | Total Time 14.00(14.00)\n",
      "Iter 2900 | Time 80.3354(77.1541) | Bit/dim 3.8909(3.8925) | Xent 1.0179(1.0123) | Loss 4.3998(4.3986) | Error 0.3651(0.3597) Steps 826(829.40) | Grad Norm 1.8486(2.1724) | Total Time 14.00(14.00)\n",
      "Iter 2901 | Time 77.0054(77.1497) | Bit/dim 3.8811(3.8921) | Xent 0.9922(1.0117) | Loss 4.3771(4.3980) | Error 0.3542(0.3595) Steps 838(829.66) | Grad Norm 1.4871(2.1518) | Total Time 14.00(14.00)\n",
      "Iter 2902 | Time 73.6515(77.0447) | Bit/dim 3.8967(3.8923) | Xent 1.0316(1.0123) | Loss 4.4125(4.3984) | Error 0.3689(0.3598) Steps 826(829.55) | Grad Norm 1.7229(2.1390) | Total Time 14.00(14.00)\n",
      "Iter 2903 | Time 74.5948(76.9712) | Bit/dim 3.8942(3.8923) | Xent 1.0153(1.0124) | Loss 4.4019(4.3985) | Error 0.3632(0.3599) Steps 832(829.62) | Grad Norm 1.8799(2.1312) | Total Time 14.00(14.00)\n",
      "Iter 2904 | Time 74.6853(76.9027) | Bit/dim 3.8876(3.8922) | Xent 1.0190(1.0126) | Loss 4.3971(4.3985) | Error 0.3551(0.3597) Steps 832(829.69) | Grad Norm 2.2734(2.1355) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 30.0547, Epoch Time 501.6993(511.0633), Bit/dim 3.8925(best: 3.8923), Xent 0.9880, Loss 4.3865, Error 0.3507(best: 0.3489)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2905 | Time 77.3164(76.9151) | Bit/dim 3.8903(3.8921) | Xent 1.0290(1.0131) | Loss 4.4048(4.3987) | Error 0.3688(0.3600) Steps 820(829.40) | Grad Norm 1.8790(2.1278) | Total Time 14.00(14.00)\n",
      "Iter 2906 | Time 79.0809(76.9800) | Bit/dim 3.8907(3.8921) | Xent 1.0055(1.0129) | Loss 4.3934(4.3985) | Error 0.3602(0.3600) Steps 826(829.30) | Grad Norm 2.4643(2.1379) | Total Time 14.00(14.00)\n",
      "Iter 2907 | Time 78.1901(77.0163) | Bit/dim 3.8861(3.8919) | Xent 1.0015(1.0125) | Loss 4.3868(4.3982) | Error 0.3508(0.3597) Steps 820(829.02) | Grad Norm 2.1150(2.1372) | Total Time 14.00(14.00)\n",
      "Iter 2908 | Time 79.1421(77.0801) | Bit/dim 3.8983(3.8921) | Xent 1.0063(1.0124) | Loss 4.4014(4.3983) | Error 0.3552(0.3596) Steps 826(828.93) | Grad Norm 1.2631(2.1110) | Total Time 14.00(14.00)\n",
      "Iter 2909 | Time 75.8051(77.0419) | Bit/dim 3.8991(3.8923) | Xent 0.9846(1.0115) | Loss 4.3914(4.3981) | Error 0.3480(0.3593) Steps 832(829.02) | Grad Norm 2.3145(2.1171) | Total Time 14.00(14.00)\n",
      "Iter 2910 | Time 77.1588(77.0454) | Bit/dim 3.8794(3.8919) | Xent 0.9985(1.0111) | Loss 4.3787(4.3975) | Error 0.3525(0.3590) Steps 826(828.93) | Grad Norm 2.4716(2.1277) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 29.5832, Epoch Time 514.8547(511.1770), Bit/dim 3.8910(best: 3.8923), Xent 0.9882, Loss 4.3851, Error 0.3485(best: 0.3489)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2911 | Time 73.7637(76.9469) | Bit/dim 3.8903(3.8919) | Xent 1.0223(1.0115) | Loss 4.4014(4.3976) | Error 0.3644(0.3592) Steps 826(828.84) | Grad Norm 2.2457(2.1312) | Total Time 14.00(14.00)\n",
      "Iter 2912 | Time 80.6914(77.0593) | Bit/dim 3.8968(3.8920) | Xent 1.0099(1.0114) | Loss 4.4017(4.3977) | Error 0.3546(0.3591) Steps 838(829.12) | Grad Norm 2.5749(2.1445) | Total Time 14.00(14.00)\n",
      "Iter 2913 | Time 76.9139(77.0549) | Bit/dim 3.8855(3.8918) | Xent 1.0077(1.0113) | Loss 4.3894(4.3975) | Error 0.3632(0.3592) Steps 826(829.02) | Grad Norm 2.2099(2.1465) | Total Time 14.00(14.00)\n",
      "Iter 2914 | Time 78.5712(77.1004) | Bit/dim 3.8940(3.8919) | Xent 1.0044(1.0111) | Loss 4.3962(4.3974) | Error 0.3542(0.3590) Steps 826(828.93) | Grad Norm 2.6382(2.1613) | Total Time 14.00(14.00)\n",
      "Iter 2915 | Time 76.7053(77.0885) | Bit/dim 3.8781(3.8915) | Xent 1.0002(1.0108) | Loss 4.3781(4.3969) | Error 0.3568(0.3590) Steps 820(828.66) | Grad Norm 2.2615(2.1643) | Total Time 14.00(14.00)\n",
      "Iter 2916 | Time 75.0549(77.0275) | Bit/dim 3.8944(3.8916) | Xent 0.9990(1.0104) | Loss 4.3939(4.3968) | Error 0.3586(0.3590) Steps 826(828.58) | Grad Norm 3.4996(2.2043) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 29.8770, Epoch Time 507.1246(511.0555), Bit/dim 3.8898(best: 3.8910), Xent 0.9934, Loss 4.3865, Error 0.3527(best: 0.3485)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2917 | Time 75.5839(76.9842) | Bit/dim 3.8822(3.8913) | Xent 1.0007(1.0101) | Loss 4.3826(4.3963) | Error 0.3495(0.3587) Steps 832(828.69) | Grad Norm 2.3980(2.2101) | Total Time 14.00(14.00)\n",
      "Iter 2918 | Time 79.5241(77.0604) | Bit/dim 3.8874(3.8912) | Xent 1.0179(1.0104) | Loss 4.3964(4.3963) | Error 0.3599(0.3587) Steps 826(828.61) | Grad Norm 1.8636(2.1997) | Total Time 14.00(14.00)\n",
      "Iter 2919 | Time 79.1410(77.1228) | Bit/dim 3.8849(3.8910) | Xent 1.0121(1.0104) | Loss 4.3909(4.3962) | Error 0.3591(0.3587) Steps 826(828.53) | Grad Norm 3.3895(2.2354) | Total Time 14.00(14.00)\n",
      "Iter 2920 | Time 74.4292(77.0420) | Bit/dim 3.8936(3.8911) | Xent 1.0265(1.0109) | Loss 4.4069(4.3965) | Error 0.3669(0.3590) Steps 826(828.45) | Grad Norm 2.7314(2.2503) | Total Time 14.00(14.00)\n",
      "Iter 2921 | Time 74.4040(76.9629) | Bit/dim 3.8874(3.8909) | Xent 1.0193(1.0112) | Loss 4.3970(4.3965) | Error 0.3665(0.3592) Steps 826(828.38) | Grad Norm 3.8632(2.2987) | Total Time 14.00(14.00)\n",
      "Iter 2922 | Time 76.7126(76.9554) | Bit/dim 3.8951(3.8911) | Xent 0.9944(1.0107) | Loss 4.3923(4.3964) | Error 0.3502(0.3589) Steps 826(828.31) | Grad Norm 2.4288(2.3026) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 29.5837, Epoch Time 504.9975(510.8737), Bit/dim 3.8917(best: 3.8898), Xent 0.9973, Loss 4.3904, Error 0.3515(best: 0.3485)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2923 | Time 74.8354(76.8918) | Bit/dim 3.8879(3.8910) | Xent 1.0271(1.0111) | Loss 4.4015(4.3965) | Error 0.3721(0.3593) Steps 826(828.24) | Grad Norm 4.5247(2.3693) | Total Time 14.00(14.00)\n",
      "Iter 2924 | Time 72.6708(76.7651) | Bit/dim 3.8890(3.8909) | Xent 1.0097(1.0111) | Loss 4.3939(4.3965) | Error 0.3479(0.3590) Steps 826(828.17) | Grad Norm 1.9535(2.3568) | Total Time 14.00(14.00)\n",
      "Iter 2925 | Time 74.9455(76.7106) | Bit/dim 3.8831(3.8907) | Xent 1.0121(1.0111) | Loss 4.3892(4.3962) | Error 0.3626(0.3591) Steps 826(828.11) | Grad Norm 3.0838(2.3786) | Total Time 14.00(14.00)\n",
      "Iter 2926 | Time 76.8647(76.7152) | Bit/dim 3.8842(3.8905) | Xent 1.0283(1.0116) | Loss 4.3983(4.3963) | Error 0.3685(0.3594) Steps 832(828.22) | Grad Norm 2.4596(2.3810) | Total Time 14.00(14.00)\n",
      "Iter 2927 | Time 78.4504(76.7672) | Bit/dim 3.8945(3.8906) | Xent 1.0054(1.0115) | Loss 4.3972(4.3963) | Error 0.3588(0.3594) Steps 820(827.98) | Grad Norm 3.0344(2.4006) | Total Time 14.00(14.00)\n",
      "Iter 2928 | Time 78.4209(76.8168) | Bit/dim 3.8963(3.8908) | Xent 1.0124(1.0115) | Loss 4.4025(4.3965) | Error 0.3602(0.3594) Steps 838(828.28) | Grad Norm 4.3121(2.4580) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 30.0747, Epoch Time 501.9373(510.6056), Bit/dim 3.8900(best: 3.8898), Xent 0.9882, Loss 4.3841, Error 0.3500(best: 0.3485)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2929 | Time 77.6959(76.8432) | Bit/dim 3.8857(3.8906) | Xent 0.9952(1.0110) | Loss 4.3833(4.3961) | Error 0.3591(0.3594) Steps 826(828.21) | Grad Norm 1.8817(2.4407) | Total Time 14.00(14.00)\n",
      "Iter 2930 | Time 76.1525(76.8225) | Bit/dim 3.8885(3.8906) | Xent 1.0168(1.0112) | Loss 4.3968(4.3961) | Error 0.3628(0.3595) Steps 808(827.60) | Grad Norm 4.7397(2.5097) | Total Time 14.00(14.00)\n",
      "Iter 2931 | Time 77.5618(76.8447) | Bit/dim 3.8974(3.8908) | Xent 1.0062(1.0110) | Loss 4.4005(4.3963) | Error 0.3615(0.3595) Steps 832(827.73) | Grad Norm 2.0902(2.4971) | Total Time 14.00(14.00)\n",
      "Iter 2932 | Time 75.6270(76.8081) | Bit/dim 3.8828(3.8905) | Xent 1.0130(1.0111) | Loss 4.3893(4.3961) | Error 0.3599(0.3595) Steps 826(827.68) | Grad Norm 3.2010(2.5182) | Total Time 14.00(14.00)\n",
      "Iter 2933 | Time 77.2598(76.8217) | Bit/dim 3.8963(3.8907) | Xent 1.0074(1.0110) | Loss 4.4000(4.3962) | Error 0.3562(0.3595) Steps 826(827.63) | Grad Norm 3.8861(2.5592) | Total Time 14.00(14.00)\n",
      "Iter 2934 | Time 78.5098(76.8723) | Bit/dim 3.8808(3.8904) | Xent 0.9975(1.0106) | Loss 4.3795(4.3957) | Error 0.3525(0.3592) Steps 826(827.58) | Grad Norm 1.8954(2.5393) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 29.3446, Epoch Time 507.6370(510.5166), Bit/dim 3.8894(best: 3.8898), Xent 0.9909, Loss 4.3848, Error 0.3491(best: 0.3485)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2935 | Time 79.8163(76.9607) | Bit/dim 3.8834(3.8902) | Xent 1.0244(1.0110) | Loss 4.3956(4.3957) | Error 0.3619(0.3593) Steps 838(827.90) | Grad Norm 3.9607(2.5820) | Total Time 14.00(14.00)\n",
      "Iter 2936 | Time 77.8991(76.9888) | Bit/dim 3.8923(3.8903) | Xent 1.0114(1.0110) | Loss 4.3980(4.3958) | Error 0.3652(0.3595) Steps 838(828.20) | Grad Norm 2.2763(2.5728) | Total Time 14.00(14.00)\n",
      "Iter 2937 | Time 76.0841(76.9617) | Bit/dim 3.8853(3.8901) | Xent 1.0226(1.0113) | Loss 4.3967(4.3958) | Error 0.3671(0.3597) Steps 832(828.31) | Grad Norm 3.6309(2.6045) | Total Time 14.00(14.00)\n",
      "Iter 2938 | Time 77.2030(76.9689) | Bit/dim 3.8835(3.8899) | Xent 1.0080(1.0112) | Loss 4.3875(4.3955) | Error 0.3619(0.3598) Steps 832(828.42) | Grad Norm 2.8534(2.6120) | Total Time 14.00(14.00)\n",
      "Iter 2939 | Time 73.2869(76.8584) | Bit/dim 3.8942(3.8900) | Xent 1.0042(1.0110) | Loss 4.3963(4.3956) | Error 0.3589(0.3598) Steps 826(828.35) | Grad Norm 3.2450(2.6310) | Total Time 14.00(14.00)\n",
      "Iter 2940 | Time 75.7732(76.8259) | Bit/dim 3.8879(3.8900) | Xent 0.9866(1.0103) | Loss 4.3812(4.3951) | Error 0.3500(0.3595) Steps 820(828.10) | Grad Norm 3.9689(2.6711) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 29.8511, Epoch Time 505.2703(510.3592), Bit/dim 3.8894(best: 3.8894), Xent 0.9885, Loss 4.3836, Error 0.3511(best: 0.3485)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2941 | Time 77.2679(76.8392) | Bit/dim 3.8896(3.8900) | Xent 0.9994(1.0100) | Loss 4.3893(4.3949) | Error 0.3544(0.3593) Steps 820(827.86) | Grad Norm 2.0052(2.6511) | Total Time 14.00(14.00)\n",
      "Iter 2942 | Time 75.6761(76.8043) | Bit/dim 3.8843(3.8898) | Xent 1.0059(1.0099) | Loss 4.3873(4.3947) | Error 0.3572(0.3593) Steps 826(827.80) | Grad Norm 4.7414(2.7139) | Total Time 14.00(14.00)\n",
      "Iter 2943 | Time 74.0623(76.7220) | Bit/dim 3.8950(3.8900) | Xent 1.0052(1.0097) | Loss 4.3976(4.3948) | Error 0.3608(0.3593) Steps 826(827.75) | Grad Norm 2.6168(2.7109) | Total Time 14.00(14.00)\n",
      "Iter 2944 | Time 75.6587(76.6901) | Bit/dim 3.8947(3.8901) | Xent 1.0190(1.0100) | Loss 4.4041(4.3951) | Error 0.3582(0.3593) Steps 826(827.69) | Grad Norm 4.3118(2.7590) | Total Time 14.00(14.00)\n",
      "Iter 2945 | Time 78.5604(76.7462) | Bit/dim 3.8887(3.8901) | Xent 0.9934(1.0095) | Loss 4.3854(4.3948) | Error 0.3506(0.3590) Steps 826(827.64) | Grad Norm 2.3845(2.7477) | Total Time 14.00(14.00)\n",
      "Iter 2946 | Time 76.8302(76.7487) | Bit/dim 3.8791(3.8897) | Xent 1.0084(1.0095) | Loss 4.3833(4.3945) | Error 0.3539(0.3589) Steps 826(827.59) | Grad Norm 1.6631(2.7152) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 29.9553, Epoch Time 503.4338(510.1514), Bit/dim 3.8902(best: 3.8894), Xent 0.9894, Loss 4.3849, Error 0.3462(best: 0.3485)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2947 | Time 77.4711(76.7704) | Bit/dim 3.8883(3.8897) | Xent 1.0056(1.0093) | Loss 4.3911(4.3944) | Error 0.3610(0.3589) Steps 838(827.91) | Grad Norm 3.2160(2.7302) | Total Time 14.00(14.00)\n",
      "Iter 2948 | Time 77.8334(76.8023) | Bit/dim 3.8861(3.8896) | Xent 0.9840(1.0086) | Loss 4.3782(4.3939) | Error 0.3449(0.3585) Steps 826(827.85) | Grad Norm 1.6804(2.6987) | Total Time 14.00(14.00)\n",
      "Iter 2949 | Time 75.8295(76.7731) | Bit/dim 3.8941(3.8897) | Xent 1.0093(1.0086) | Loss 4.3987(4.3940) | Error 0.3628(0.3586) Steps 820(827.61) | Grad Norm 3.6867(2.7284) | Total Time 14.00(14.00)\n",
      "Iter 2950 | Time 71.7422(76.6222) | Bit/dim 3.8783(3.8894) | Xent 1.0231(1.0090) | Loss 4.3898(4.3939) | Error 0.3644(0.3588) Steps 826(827.57) | Grad Norm 3.0531(2.7381) | Total Time 14.00(14.00)\n",
      "Iter 2951 | Time 75.4022(76.5856) | Bit/dim 3.8844(3.8892) | Xent 1.0335(1.0098) | Loss 4.4012(4.3941) | Error 0.3666(0.3590) Steps 820(827.34) | Grad Norm 4.7691(2.7990) | Total Time 14.00(14.00)\n",
      "Iter 2952 | Time 73.5885(76.4957) | Bit/dim 3.8953(3.8894) | Xent 1.0107(1.0098) | Loss 4.4007(4.3943) | Error 0.3600(0.3591) Steps 826(827.30) | Grad Norm 3.1205(2.8087) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 29.6045, Epoch Time 496.9167(509.7544), Bit/dim 3.8885(best: 3.8894), Xent 0.9879, Loss 4.3824, Error 0.3516(best: 0.3462)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2953 | Time 75.0616(76.4526) | Bit/dim 3.8968(3.8896) | Xent 0.9829(1.0090) | Loss 4.3882(4.3941) | Error 0.3486(0.3588) Steps 832(827.44) | Grad Norm 3.5642(2.8313) | Total Time 14.00(14.00)\n",
      "Iter 2954 | Time 74.8573(76.4048) | Bit/dim 3.8876(3.8896) | Xent 1.0167(1.0092) | Loss 4.3960(4.3942) | Error 0.3619(0.3588) Steps 808(826.86) | Grad Norm 4.0013(2.8664) | Total Time 14.00(14.00)\n",
      "Iter 2955 | Time 77.2053(76.4288) | Bit/dim 3.8825(3.8894) | Xent 1.0059(1.0091) | Loss 4.3855(4.3939) | Error 0.3594(0.3589) Steps 826(826.83) | Grad Norm 3.5513(2.8870) | Total Time 14.00(14.00)\n",
      "Iter 2956 | Time 74.7388(76.3781) | Bit/dim 3.8792(3.8890) | Xent 1.0154(1.0093) | Loss 4.3869(4.3937) | Error 0.3630(0.3590) Steps 832(826.99) | Grad Norm 4.8798(2.9468) | Total Time 14.00(14.00)\n",
      "Iter 2957 | Time 76.5632(76.3837) | Bit/dim 3.8810(3.8888) | Xent 1.0257(1.0098) | Loss 4.3938(4.3937) | Error 0.3675(0.3592) Steps 820(826.78) | Grad Norm 3.4955(2.9632) | Total Time 14.00(14.00)\n",
      "Iter 2958 | Time 80.9210(76.5198) | Bit/dim 3.8971(3.8891) | Xent 1.0162(1.0100) | Loss 4.4052(4.3941) | Error 0.3666(0.3595) Steps 826(826.75) | Grad Norm 4.0452(2.9957) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 29.6088, Epoch Time 504.5181(509.5973), Bit/dim 3.8889(best: 3.8885), Xent 0.9949, Loss 4.3864, Error 0.3521(best: 0.3462)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2959 | Time 79.1999(76.6002) | Bit/dim 3.8884(3.8890) | Xent 1.0056(1.0099) | Loss 4.3912(4.3940) | Error 0.3565(0.3594) Steps 826(826.73) | Grad Norm 3.5228(3.0115) | Total Time 14.00(14.00)\n",
      "Iter 2960 | Time 75.8093(76.5765) | Bit/dim 3.8935(3.8892) | Xent 1.0033(1.0097) | Loss 4.3952(4.3940) | Error 0.3499(0.3591) Steps 826(826.71) | Grad Norm 3.0104(3.0115) | Total Time 14.00(14.00)\n",
      "Iter 2961 | Time 74.8241(76.5239) | Bit/dim 3.8909(3.8892) | Xent 1.0154(1.0098) | Loss 4.3986(4.3941) | Error 0.3595(0.3591) Steps 808(826.15) | Grad Norm 4.4752(3.0554) | Total Time 14.00(14.00)\n",
      "Iter 2962 | Time 79.1343(76.6022) | Bit/dim 3.8811(3.8890) | Xent 0.9894(1.0092) | Loss 4.3758(4.3936) | Error 0.3518(0.3589) Steps 826(826.14) | Grad Norm 2.4440(3.0370) | Total Time 14.00(14.00)\n",
      "Iter 2963 | Time 78.3833(76.6556) | Bit/dim 3.8943(3.8891) | Xent 1.0098(1.0092) | Loss 4.3992(4.3938) | Error 0.3642(0.3590) Steps 826(826.14) | Grad Norm 4.3392(3.0761) | Total Time 14.00(14.00)\n",
      "Iter 2964 | Time 74.5914(76.5937) | Bit/dim 3.8778(3.8888) | Xent 1.0153(1.0094) | Loss 4.3854(4.3935) | Error 0.3625(0.3591) Steps 826(826.13) | Grad Norm 1.3883(3.0255) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 30.0390, Epoch Time 507.4884(509.5340), Bit/dim 3.8880(best: 3.8885), Xent 0.9887, Loss 4.3823, Error 0.3496(best: 0.3462)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2965 | Time 72.8849(76.4824) | Bit/dim 3.8963(3.8890) | Xent 1.0188(1.0097) | Loss 4.4057(4.3939) | Error 0.3559(0.3590) Steps 820(825.95) | Grad Norm 4.2627(3.0626) | Total Time 14.00(14.00)\n",
      "Iter 2966 | Time 78.3027(76.5370) | Bit/dim 3.8851(3.8889) | Xent 1.0114(1.0098) | Loss 4.3908(4.3938) | Error 0.3552(0.3589) Steps 814(825.59) | Grad Norm 2.4906(3.0454) | Total Time 14.00(14.00)\n",
      "Iter 2967 | Time 77.2146(76.5574) | Bit/dim 3.8870(3.8888) | Xent 1.0069(1.0097) | Loss 4.3905(4.3937) | Error 0.3578(0.3589) Steps 826(825.60) | Grad Norm 2.6439(3.0334) | Total Time 14.00(14.00)\n",
      "Iter 2968 | Time 74.0155(76.4811) | Bit/dim 3.8896(3.8889) | Xent 1.0073(1.0096) | Loss 4.3932(4.3937) | Error 0.3528(0.3587) Steps 808(825.08) | Grad Norm 2.6818(3.0228) | Total Time 14.00(14.00)\n",
      "Iter 2969 | Time 74.2638(76.4146) | Bit/dim 3.8777(3.8885) | Xent 1.0213(1.0100) | Loss 4.3884(4.3935) | Error 0.3698(0.3590) Steps 826(825.10) | Grad Norm 2.4468(3.0056) | Total Time 14.00(14.00)\n",
      "Iter 2970 | Time 73.4668(76.3262) | Bit/dim 3.8904(3.8886) | Xent 0.9863(1.0092) | Loss 4.3835(4.3932) | Error 0.3486(0.3587) Steps 826(825.13) | Grad Norm 2.3238(2.9851) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 30.2120, Epoch Time 496.0435(509.1293), Bit/dim 3.8878(best: 3.8880), Xent 0.9836, Loss 4.3795, Error 0.3471(best: 0.3462)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2971 | Time 78.6830(76.3969) | Bit/dim 3.8923(3.8887) | Xent 0.9969(1.0089) | Loss 4.3908(4.3931) | Error 0.3479(0.3584) Steps 844(825.70) | Grad Norm 2.0603(2.9574) | Total Time 14.00(14.00)\n",
      "Iter 2972 | Time 76.0295(76.3858) | Bit/dim 3.8853(3.8886) | Xent 0.9945(1.0084) | Loss 4.3826(4.3928) | Error 0.3534(0.3583) Steps 826(825.71) | Grad Norm 1.2821(2.9071) | Total Time 14.00(14.00)\n",
      "Iter 2973 | Time 75.4520(76.3578) | Bit/dim 3.8888(3.8886) | Xent 1.0022(1.0083) | Loss 4.3899(4.3927) | Error 0.3559(0.3582) Steps 826(825.71) | Grad Norm 1.8535(2.8755) | Total Time 14.00(14.00)\n",
      "Iter 2974 | Time 78.7528(76.4297) | Bit/dim 3.8741(3.8882) | Xent 0.9962(1.0079) | Loss 4.3722(4.3921) | Error 0.3609(0.3583) Steps 826(825.72) | Grad Norm 2.1685(2.8543) | Total Time 14.00(14.00)\n",
      "Iter 2975 | Time 78.1628(76.4817) | Bit/dim 3.8807(3.8879) | Xent 1.0147(1.0081) | Loss 4.3880(4.3920) | Error 0.3602(0.3583) Steps 826(825.73) | Grad Norm 2.1484(2.8331) | Total Time 14.00(14.00)\n",
      "Iter 2976 | Time 73.1886(76.3829) | Bit/dim 3.8941(3.8881) | Xent 1.0113(1.0082) | Loss 4.3997(4.3922) | Error 0.3564(0.3583) Steps 820(825.56) | Grad Norm 1.7073(2.7993) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 30.1219, Epoch Time 505.9362(509.0335), Bit/dim 3.8869(best: 3.8878), Xent 0.9885, Loss 4.3811, Error 0.3507(best: 0.3462)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2977 | Time 73.7200(76.3030) | Bit/dim 3.8846(3.8880) | Xent 1.0070(1.0082) | Loss 4.3881(4.3921) | Error 0.3552(0.3582) Steps 832(825.75) | Grad Norm 1.9775(2.7747) | Total Time 14.00(14.00)\n",
      "Iter 2978 | Time 78.5430(76.3702) | Bit/dim 3.8962(3.8883) | Xent 1.0097(1.0082) | Loss 4.4010(4.3924) | Error 0.3572(0.3581) Steps 814(825.40) | Grad Norm 2.1808(2.7569) | Total Time 14.00(14.00)\n",
      "Iter 2979 | Time 76.9986(76.3890) | Bit/dim 3.8790(3.8880) | Xent 1.0015(1.0080) | Loss 4.3797(4.3920) | Error 0.3586(0.3582) Steps 826(825.42) | Grad Norm 1.7589(2.7269) | Total Time 14.00(14.00)\n",
      "Iter 2980 | Time 76.4484(76.3908) | Bit/dim 3.8835(3.8879) | Xent 1.0097(1.0081) | Loss 4.3884(4.3919) | Error 0.3578(0.3581) Steps 808(824.90) | Grad Norm 2.0289(2.7060) | Total Time 14.00(14.00)\n",
      "Iter 2981 | Time 79.4606(76.4829) | Bit/dim 3.8783(3.8876) | Xent 0.9972(1.0077) | Loss 4.3769(4.3914) | Error 0.3549(0.3581) Steps 838(825.29) | Grad Norm 1.5154(2.6703) | Total Time 14.00(14.00)\n",
      "Iter 2982 | Time 78.8342(76.5535) | Bit/dim 3.8912(3.8877) | Xent 0.9917(1.0073) | Loss 4.3870(4.3913) | Error 0.3514(0.3579) Steps 826(825.31) | Grad Norm 2.3217(2.6598) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 29.9246, Epoch Time 509.4326(509.0455), Bit/dim 3.8872(best: 3.8869), Xent 0.9831, Loss 4.3788, Error 0.3451(best: 0.3462)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2983 | Time 76.5188(76.5524) | Bit/dim 3.8934(3.8878) | Xent 0.9952(1.0069) | Loss 4.3910(4.3913) | Error 0.3559(0.3578) Steps 838(825.69) | Grad Norm 1.3360(2.6201) | Total Time 14.00(14.00)\n",
      "Iter 2984 | Time 75.2708(76.5140) | Bit/dim 3.8836(3.8877) | Xent 1.0211(1.0073) | Loss 4.3942(4.3914) | Error 0.3670(0.3581) Steps 820(825.52) | Grad Norm 1.4914(2.5862) | Total Time 14.00(14.00)\n",
      "Iter 2985 | Time 76.0095(76.4988) | Bit/dim 3.8900(3.8878) | Xent 0.9875(1.0067) | Loss 4.3837(4.3911) | Error 0.3476(0.3578) Steps 826(825.53) | Grad Norm 2.5282(2.5845) | Total Time 14.00(14.00)\n",
      "Iter 2986 | Time 78.4113(76.5562) | Bit/dim 3.8755(3.8874) | Xent 0.9976(1.0064) | Loss 4.3743(4.3906) | Error 0.3569(0.3577) Steps 820(825.37) | Grad Norm 1.2789(2.5453) | Total Time 14.00(14.00)\n",
      "Iter 2987 | Time 78.4302(76.6124) | Bit/dim 3.8844(3.8873) | Xent 1.0016(1.0063) | Loss 4.3852(4.3905) | Error 0.3605(0.3578) Steps 832(825.57) | Grad Norm 2.5943(2.5468) | Total Time 14.00(14.00)\n",
      "Iter 2988 | Time 74.7564(76.5567) | Bit/dim 3.8837(3.8872) | Xent 1.0046(1.0063) | Loss 4.3861(4.3903) | Error 0.3484(0.3575) Steps 826(825.58) | Grad Norm 1.8016(2.5244) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 29.9086, Epoch Time 505.3143(508.9335), Bit/dim 3.8866(best: 3.8869), Xent 0.9842, Loss 4.3787, Error 0.3471(best: 0.3451)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2989 | Time 79.1476(76.6345) | Bit/dim 3.8823(3.8871) | Xent 1.0089(1.0063) | Loss 4.3868(4.3902) | Error 0.3515(0.3573) Steps 826(825.59) | Grad Norm 2.6345(2.5277) | Total Time 14.00(14.00)\n",
      "Iter 2990 | Time 76.5027(76.6305) | Bit/dim 3.8839(3.8870) | Xent 1.0157(1.0066) | Loss 4.3918(4.3903) | Error 0.3638(0.3575) Steps 832(825.79) | Grad Norm 2.5332(2.5279) | Total Time 14.00(14.00)\n",
      "Iter 2991 | Time 74.3813(76.5630) | Bit/dim 3.8715(3.8865) | Xent 1.0097(1.0067) | Loss 4.3764(4.3899) | Error 0.3594(0.3576) Steps 826(825.79) | Grad Norm 3.1612(2.5469) | Total Time 14.00(14.00)\n",
      "Iter 2992 | Time 74.9391(76.5143) | Bit/dim 3.9017(3.8870) | Xent 0.9877(1.0061) | Loss 4.3956(4.3900) | Error 0.3510(0.3574) Steps 832(825.98) | Grad Norm 2.3285(2.5404) | Total Time 14.00(14.00)\n",
      "Iter 2993 | Time 71.0566(76.3506) | Bit/dim 3.8814(3.8868) | Xent 0.9947(1.0058) | Loss 4.3787(4.3897) | Error 0.3530(0.3573) Steps 820(825.80) | Grad Norm 4.5707(2.6013) | Total Time 14.00(14.00)\n",
      "Iter 2994 | Time 76.2195(76.3467) | Bit/dim 3.8884(3.8869) | Xent 0.9966(1.0055) | Loss 4.3867(4.3896) | Error 0.3458(0.3569) Steps 826(825.80) | Grad Norm 2.3640(2.5941) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 29.9532, Epoch Time 497.8386(508.6007), Bit/dim 3.8878(best: 3.8866), Xent 0.9814, Loss 4.3785, Error 0.3488(best: 0.3451)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 2995 | Time 75.6241(76.3250) | Bit/dim 3.8869(3.8869) | Xent 0.9791(1.0047) | Loss 4.3765(4.3892) | Error 0.3510(0.3567) Steps 826(825.81) | Grad Norm 3.2540(2.6139) | Total Time 14.00(14.00)\n",
      "Iter 2996 | Time 73.6344(76.2443) | Bit/dim 3.8777(3.8866) | Xent 0.9902(1.0043) | Loss 4.3728(4.3887) | Error 0.3578(0.3568) Steps 832(826.00) | Grad Norm 3.2577(2.6333) | Total Time 14.00(14.00)\n",
      "Iter 2997 | Time 74.9603(76.2058) | Bit/dim 3.8821(3.8864) | Xent 1.0130(1.0046) | Loss 4.3886(4.3887) | Error 0.3551(0.3567) Steps 832(826.18) | Grad Norm 3.3138(2.6537) | Total Time 14.00(14.00)\n",
      "Iter 2998 | Time 78.4618(76.2734) | Bit/dim 3.8921(3.8866) | Xent 0.9984(1.0044) | Loss 4.3913(4.3888) | Error 0.3552(0.3567) Steps 832(826.35) | Grad Norm 3.6647(2.6840) | Total Time 14.00(14.00)\n",
      "Iter 2999 | Time 72.4991(76.1602) | Bit/dim 3.8852(3.8866) | Xent 1.0147(1.0047) | Loss 4.3926(4.3889) | Error 0.3595(0.3568) Steps 808(825.80) | Grad Norm 2.9150(2.6909) | Total Time 14.00(14.00)\n",
      "Iter 3000 | Time 73.6346(76.0844) | Bit/dim 3.8878(3.8866) | Xent 1.0319(1.0055) | Loss 4.4037(4.3894) | Error 0.3712(0.3572) Steps 832(825.99) | Grad Norm 3.3847(2.7117) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 29.7991, Epoch Time 494.5068(508.1779), Bit/dim 3.8865(best: 3.8866), Xent 0.9833, Loss 4.3781, Error 0.3475(best: 0.3451)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3001 | Time 77.1734(76.1171) | Bit/dim 3.8851(3.8866) | Xent 1.0006(1.0053) | Loss 4.3854(4.3892) | Error 0.3614(0.3573) Steps 820(825.81) | Grad Norm 1.8508(2.6859) | Total Time 14.00(14.00)\n",
      "Iter 3002 | Time 76.3510(76.1241) | Bit/dim 3.8823(3.8864) | Xent 0.9888(1.0048) | Loss 4.3767(4.3889) | Error 0.3529(0.3572) Steps 838(826.17) | Grad Norm 3.7038(2.7164) | Total Time 14.00(14.00)\n",
      "Iter 3003 | Time 76.7579(76.1431) | Bit/dim 3.8740(3.8861) | Xent 0.9979(1.0046) | Loss 4.3729(4.3884) | Error 0.3541(0.3571) Steps 826(826.17) | Grad Norm 3.1893(2.7306) | Total Time 14.00(14.00)\n",
      "Iter 3004 | Time 77.7890(76.1925) | Bit/dim 3.8893(3.8862) | Xent 1.0019(1.0046) | Loss 4.3903(4.3884) | Error 0.3516(0.3569) Steps 820(825.98) | Grad Norm 3.6845(2.7593) | Total Time 14.00(14.00)\n",
      "Iter 3005 | Time 76.7338(76.2087) | Bit/dim 3.9009(3.8866) | Xent 1.0087(1.0047) | Loss 4.4052(4.3889) | Error 0.3565(0.3569) Steps 832(826.16) | Grad Norm 2.8324(2.7614) | Total Time 14.00(14.00)\n",
      "Iter 3006 | Time 76.8534(76.2281) | Bit/dim 3.8822(3.8865) | Xent 1.0137(1.0050) | Loss 4.3891(4.3889) | Error 0.3541(0.3568) Steps 826(826.16) | Grad Norm 3.3846(2.7801) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0501 | Time 29.9261, Epoch Time 507.0881(508.1452), Bit/dim 3.8854(best: 3.8865), Xent 0.9848, Loss 4.3778, Error 0.3493(best: 0.3451)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3007 | Time 72.7841(76.1248) | Bit/dim 3.8822(3.8863) | Xent 1.0131(1.0052) | Loss 4.3887(4.3889) | Error 0.3649(0.3571) Steps 826(826.15) | Grad Norm 2.8553(2.7824) | Total Time 14.00(14.00)\n",
      "Iter 3008 | Time 73.6833(76.0515) | Bit/dim 3.8877(3.8864) | Xent 1.0001(1.0050) | Loss 4.3878(4.3889) | Error 0.3549(0.3570) Steps 826(826.15) | Grad Norm 3.6441(2.8082) | Total Time 14.00(14.00)\n",
      "Iter 3009 | Time 77.4728(76.0942) | Bit/dim 3.8870(3.8864) | Xent 0.9862(1.0045) | Loss 4.3801(4.3886) | Error 0.3509(0.3568) Steps 832(826.32) | Grad Norm 2.9899(2.8137) | Total Time 14.00(14.00)\n",
      "Iter 3010 | Time 78.2834(76.1598) | Bit/dim 3.8788(3.8862) | Xent 1.0080(1.0046) | Loss 4.3828(4.3885) | Error 0.3588(0.3569) Steps 838(826.67) | Grad Norm 4.7939(2.8731) | Total Time 14.00(14.00)\n",
      "Iter 3011 | Time 78.2375(76.2222) | Bit/dim 3.8752(3.8858) | Xent 0.9868(1.0041) | Loss 4.3686(4.3879) | Error 0.3524(0.3567) Steps 832(826.83) | Grad Norm 2.3269(2.8567) | Total Time 14.00(14.00)\n",
      "Iter 3012 | Time 75.9761(76.2148) | Bit/dim 3.8975(3.8862) | Xent 1.0101(1.0042) | Loss 4.4026(4.3883) | Error 0.3619(0.3569) Steps 826(826.81) | Grad Norm 3.5314(2.8770) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0502 | Time 30.1762, Epoch Time 502.0750(507.9631), Bit/dim 3.8848(best: 3.8854), Xent 0.9835, Loss 4.3765, Error 0.3453(best: 0.3451)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3013 | Time 71.4225(76.0710) | Bit/dim 3.8849(3.8862) | Xent 1.0009(1.0041) | Loss 4.3854(4.3882) | Error 0.3566(0.3569) Steps 826(826.78) | Grad Norm 3.3139(2.8901) | Total Time 14.00(14.00)\n",
      "Iter 3014 | Time 76.4730(76.0831) | Bit/dim 3.8809(3.8860) | Xent 0.9980(1.0040) | Loss 4.3799(4.3880) | Error 0.3515(0.3567) Steps 826(826.76) | Grad Norm 3.6764(2.9137) | Total Time 14.00(14.00)\n",
      "Iter 3015 | Time 75.2191(76.0572) | Bit/dim 3.8797(3.8858) | Xent 0.9861(1.0034) | Loss 4.3727(4.3875) | Error 0.3454(0.3564) Steps 826(826.74) | Grad Norm 3.3012(2.9253) | Total Time 14.00(14.00)\n",
      "Iter 3016 | Time 77.4605(76.0993) | Bit/dim 3.8743(3.8855) | Xent 0.9972(1.0032) | Loss 4.3728(4.3871) | Error 0.3560(0.3564) Steps 820(826.54) | Grad Norm 2.3209(2.9071) | Total Time 14.00(14.00)\n",
      "Iter 3017 | Time 75.4696(76.0804) | Bit/dim 3.8914(3.8856) | Xent 1.0126(1.0035) | Loss 4.3977(4.3874) | Error 0.3602(0.3565) Steps 826(826.52) | Grad Norm 3.0919(2.9127) | Total Time 14.00(14.00)\n",
      "Iter 3018 | Time 76.3195(76.0875) | Bit/dim 3.8889(3.8857) | Xent 1.0023(1.0035) | Loss 4.3900(4.3875) | Error 0.3560(0.3565) Steps 832(826.68) | Grad Norm 1.7438(2.8776) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0503 | Time 29.2732, Epoch Time 496.9713(507.6333), Bit/dim 3.8846(best: 3.8848), Xent 0.9812, Loss 4.3752, Error 0.3481(best: 0.3451)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3019 | Time 72.9225(75.9926) | Bit/dim 3.8892(3.8858) | Xent 0.9973(1.0033) | Loss 4.3878(4.3875) | Error 0.3494(0.3563) Steps 826(826.66) | Grad Norm 2.0656(2.8533) | Total Time 14.00(14.00)\n",
      "Iter 3020 | Time 73.2117(75.9092) | Bit/dim 3.8816(3.8857) | Xent 1.0066(1.0034) | Loss 4.3849(4.3874) | Error 0.3535(0.3562) Steps 826(826.64) | Grad Norm 1.7626(2.8205) | Total Time 14.00(14.00)\n",
      "Iter 3021 | Time 73.9691(75.8510) | Bit/dim 3.8883(3.8858) | Xent 0.9984(1.0032) | Loss 4.3875(4.3874) | Error 0.3525(0.3561) Steps 826(826.62) | Grad Norm 1.4384(2.7791) | Total Time 14.00(14.00)\n",
      "Iter 3022 | Time 77.8404(75.9106) | Bit/dim 3.8822(3.8857) | Xent 0.9903(1.0028) | Loss 4.3773(4.3871) | Error 0.3579(0.3561) Steps 808(826.07) | Grad Norm 1.8833(2.7522) | Total Time 14.00(14.00)\n",
      "Iter 3023 | Time 79.0173(76.0038) | Bit/dim 3.8855(3.8857) | Xent 0.9997(1.0028) | Loss 4.3853(4.3870) | Error 0.3552(0.3561) Steps 838(826.42) | Grad Norm 1.7968(2.7235) | Total Time 14.00(14.00)\n",
      "Iter 3024 | Time 81.3958(76.1656) | Bit/dim 3.8772(3.8854) | Xent 0.9999(1.0027) | Loss 4.3771(4.3868) | Error 0.3579(0.3562) Steps 832(826.59) | Grad Norm 1.8532(2.6974) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0504 | Time 29.6522, Epoch Time 503.4847(507.5089), Bit/dim 3.8848(best: 3.8846), Xent 0.9794, Loss 4.3745, Error 0.3454(best: 0.3451)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3025 | Time 74.6815(76.1211) | Bit/dim 3.8660(3.8848) | Xent 0.9739(1.0018) | Loss 4.3529(4.3857) | Error 0.3486(0.3559) Steps 820(826.39) | Grad Norm 2.3782(2.6879) | Total Time 14.00(14.00)\n",
      "Iter 3026 | Time 73.8608(76.0533) | Bit/dim 3.8767(3.8846) | Xent 0.9859(1.0013) | Loss 4.3696(4.3853) | Error 0.3499(0.3557) Steps 826(826.38) | Grad Norm 1.7364(2.6593) | Total Time 14.00(14.00)\n",
      "Iter 3027 | Time 74.2798(76.0001) | Bit/dim 3.8938(3.8849) | Xent 1.0094(1.0016) | Loss 4.3986(4.3857) | Error 0.3619(0.3559) Steps 826(826.37) | Grad Norm 2.0680(2.6416) | Total Time 14.00(14.00)\n",
      "Iter 3028 | Time 71.9478(75.8785) | Bit/dim 3.8841(3.8848) | Xent 0.9910(1.0013) | Loss 4.3796(4.3855) | Error 0.3501(0.3558) Steps 820(826.18) | Grad Norm 1.3990(2.6043) | Total Time 14.00(14.00)\n",
      "Iter 3029 | Time 73.4672(75.8062) | Bit/dim 3.8886(3.8850) | Xent 0.9995(1.0012) | Loss 4.3883(4.3856) | Error 0.3512(0.3556) Steps 826(826.17) | Grad Norm 1.7359(2.5782) | Total Time 14.00(14.00)\n",
      "Iter 3030 | Time 74.9873(75.7816) | Bit/dim 3.8891(3.8851) | Xent 0.9927(1.0009) | Loss 4.3854(4.3856) | Error 0.3542(0.3556) Steps 826(826.17) | Grad Norm 2.5079(2.5761) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0505 | Time 29.9210, Epoch Time 488.6096(506.9419), Bit/dim 3.8848(best: 3.8846), Xent 0.9799, Loss 4.3748, Error 0.3448(best: 0.3451)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3031 | Time 76.7769(75.8115) | Bit/dim 3.8799(3.8849) | Xent 0.9961(1.0008) | Loss 4.3779(4.3853) | Error 0.3569(0.3556) Steps 826(826.16) | Grad Norm 1.0377(2.5300) | Total Time 14.00(14.00)\n",
      "Iter 3032 | Time 72.4112(75.7094) | Bit/dim 3.8815(3.8848) | Xent 1.0298(1.0017) | Loss 4.3964(4.3857) | Error 0.3656(0.3559) Steps 826(826.16) | Grad Norm 3.4807(2.5585) | Total Time 14.00(14.00)\n",
      "Iter 3033 | Time 73.9053(75.6553) | Bit/dim 3.8861(3.8849) | Xent 1.0101(1.0019) | Loss 4.3912(4.3858) | Error 0.3570(0.3560) Steps 826(826.15) | Grad Norm 1.7382(2.5339) | Total Time 14.00(14.00)\n",
      "Iter 3034 | Time 76.1030(75.6688) | Bit/dim 3.8821(3.8848) | Xent 1.0055(1.0020) | Loss 4.3849(4.3858) | Error 0.3561(0.3560) Steps 832(826.33) | Grad Norm 3.6878(2.5685) | Total Time 14.00(14.00)\n",
      "Iter 3035 | Time 77.0739(75.7109) | Bit/dim 3.8769(3.8845) | Xent 0.9882(1.0016) | Loss 4.3710(4.3853) | Error 0.3528(0.3559) Steps 820(826.14) | Grad Norm 1.2665(2.5294) | Total Time 14.00(14.00)\n",
      "Iter 3036 | Time 76.8638(75.7455) | Bit/dim 3.8902(3.8847) | Xent 0.9819(1.0010) | Loss 4.3812(4.3852) | Error 0.3485(0.3556) Steps 826(826.14) | Grad Norm 3.4803(2.5580) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0506 | Time 29.9088, Epoch Time 498.7598(506.6964), Bit/dim 3.8854(best: 3.8846), Xent 0.9776, Loss 4.3742, Error 0.3431(best: 0.3448)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3037 | Time 79.1681(75.8482) | Bit/dim 3.8892(3.8848) | Xent 0.9998(1.0010) | Loss 4.3891(4.3853) | Error 0.3572(0.3557) Steps 832(826.31) | Grad Norm 1.0269(2.5120) | Total Time 14.00(14.00)\n",
      "Iter 3038 | Time 76.1083(75.8560) | Bit/dim 3.8788(3.8847) | Xent 0.9913(1.0007) | Loss 4.3744(4.3850) | Error 0.3542(0.3556) Steps 826(826.30) | Grad Norm 2.1411(2.5009) | Total Time 14.00(14.00)\n",
      "Iter 3039 | Time 73.7056(75.7915) | Bit/dim 3.8824(3.8846) | Xent 0.9918(1.0004) | Loss 4.3783(4.3848) | Error 0.3509(0.3555) Steps 832(826.47) | Grad Norm 2.0278(2.4867) | Total Time 14.00(14.00)\n",
      "Iter 3040 | Time 74.1318(75.7417) | Bit/dim 3.8815(3.8845) | Xent 0.9990(1.0004) | Loss 4.3810(4.3847) | Error 0.3548(0.3555) Steps 826(826.46) | Grad Norm 1.6420(2.4614) | Total Time 14.00(14.00)\n",
      "Iter 3041 | Time 75.2590(75.7272) | Bit/dim 3.8854(3.8845) | Xent 1.0028(1.0005) | Loss 4.3868(4.3848) | Error 0.3582(0.3556) Steps 826(826.44) | Grad Norm 2.5367(2.4636) | Total Time 14.00(14.00)\n",
      "Iter 3042 | Time 76.4339(75.7484) | Bit/dim 3.8786(3.8844) | Xent 0.9924(1.0002) | Loss 4.3748(4.3845) | Error 0.3508(0.3554) Steps 826(826.43) | Grad Norm 2.0829(2.4522) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0507 | Time 29.3472, Epoch Time 499.9144(506.4930), Bit/dim 3.8832(best: 3.8846), Xent 0.9791, Loss 4.3728, Error 0.3420(best: 0.3431)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3043 | Time 76.4960(75.7708) | Bit/dim 3.8839(3.8843) | Xent 1.0128(1.0006) | Loss 4.3903(4.3846) | Error 0.3564(0.3554) Steps 820(826.24) | Grad Norm 1.7258(2.4304) | Total Time 14.00(14.00)\n",
      "Iter 3044 | Time 74.6641(75.7376) | Bit/dim 3.8818(3.8843) | Xent 1.0113(1.0009) | Loss 4.3875(4.3847) | Error 0.3631(0.3557) Steps 826(826.23) | Grad Norm 2.1049(2.4207) | Total Time 14.00(14.00)\n",
      "Iter 3045 | Time 74.3950(75.6973) | Bit/dim 3.8750(3.8840) | Xent 0.9852(1.0004) | Loss 4.3676(4.3842) | Error 0.3489(0.3555) Steps 826(826.22) | Grad Norm 1.7011(2.3991) | Total Time 14.00(14.00)\n",
      "Iter 3046 | Time 80.2367(75.8335) | Bit/dim 3.8911(3.8842) | Xent 0.9915(1.0002) | Loss 4.3868(4.3843) | Error 0.3556(0.3555) Steps 826(826.22) | Grad Norm 2.4149(2.3995) | Total Time 14.00(14.00)\n",
      "Iter 3047 | Time 72.9272(75.7463) | Bit/dim 3.8823(3.8841) | Xent 0.9738(0.9994) | Loss 4.3692(4.3838) | Error 0.3501(0.3553) Steps 826(826.21) | Grad Norm 1.3636(2.3685) | Total Time 14.00(14.00)\n",
      "Iter 3048 | Time 74.0052(75.6941) | Bit/dim 3.8778(3.8840) | Xent 1.0103(0.9997) | Loss 4.3829(4.3838) | Error 0.3564(0.3553) Steps 826(826.20) | Grad Norm 1.7846(2.3509) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0508 | Time 29.7445, Epoch Time 497.9243(506.2359), Bit/dim 3.8836(best: 3.8832), Xent 0.9793, Loss 4.3732, Error 0.3445(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3049 | Time 76.2445(75.7106) | Bit/dim 3.8737(3.8836) | Xent 1.0072(0.9999) | Loss 4.3773(4.3836) | Error 0.3589(0.3555) Steps 832(826.38) | Grad Norm 1.0549(2.3121) | Total Time 14.00(14.00)\n",
      "Iter 3050 | Time 76.6614(75.7391) | Bit/dim 3.8824(3.8836) | Xent 0.9923(0.9997) | Loss 4.3785(4.3835) | Error 0.3526(0.3554) Steps 832(826.55) | Grad Norm 1.5498(2.2892) | Total Time 14.00(14.00)\n",
      "Iter 3051 | Time 78.4804(75.8214) | Bit/dim 3.8810(3.8835) | Xent 1.0093(1.0000) | Loss 4.3856(4.3835) | Error 0.3586(0.3555) Steps 826(826.53) | Grad Norm 1.6372(2.2696) | Total Time 14.00(14.00)\n",
      "Iter 3052 | Time 76.0832(75.8292) | Bit/dim 3.8786(3.8834) | Xent 0.9982(0.9999) | Loss 4.3777(4.3833) | Error 0.3528(0.3554) Steps 832(826.70) | Grad Norm 2.3193(2.2711) | Total Time 14.00(14.00)\n",
      "Iter 3053 | Time 73.7205(75.7660) | Bit/dim 3.8813(3.8833) | Xent 0.9978(0.9999) | Loss 4.3802(4.3833) | Error 0.3610(0.3556) Steps 826(826.67) | Grad Norm 2.0399(2.2642) | Total Time 14.00(14.00)\n",
      "Iter 3054 | Time 73.5223(75.6987) | Bit/dim 3.8915(3.8836) | Xent 0.9838(0.9994) | Loss 4.3834(4.3833) | Error 0.3490(0.3554) Steps 808(826.11) | Grad Norm 2.9132(2.2837) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0509 | Time 29.6592, Epoch Time 500.3014(506.0579), Bit/dim 3.8834(best: 3.8832), Xent 0.9784, Loss 4.3726, Error 0.3461(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3055 | Time 74.9792(75.6771) | Bit/dim 3.8811(3.8835) | Xent 0.9858(0.9990) | Loss 4.3740(4.3830) | Error 0.3468(0.3551) Steps 808(825.57) | Grad Norm 1.7307(2.2671) | Total Time 14.00(14.00)\n",
      "Iter 3056 | Time 73.1097(75.6000) | Bit/dim 3.8689(3.8830) | Xent 1.0027(0.9991) | Loss 4.3702(4.3826) | Error 0.3502(0.3550) Steps 832(825.76) | Grad Norm 3.0818(2.2915) | Total Time 14.00(14.00)\n",
      "Iter 3057 | Time 75.1940(75.5879) | Bit/dim 3.8860(3.8831) | Xent 1.0058(0.9993) | Loss 4.3889(4.3828) | Error 0.3544(0.3549) Steps 826(825.77) | Grad Norm 1.4573(2.2665) | Total Time 14.00(14.00)\n",
      "Iter 3058 | Time 73.7769(75.5335) | Bit/dim 3.8894(3.8833) | Xent 1.0080(0.9996) | Loss 4.3934(4.3831) | Error 0.3620(0.3551) Steps 814(825.42) | Grad Norm 3.1634(2.2934) | Total Time 14.00(14.00)\n",
      "Iter 3059 | Time 74.5905(75.5052) | Bit/dim 3.8824(3.8833) | Xent 0.9903(0.9993) | Loss 4.3775(4.3829) | Error 0.3566(0.3552) Steps 826(825.43) | Grad Norm 1.0496(2.2561) | Total Time 14.00(14.00)\n",
      "Iter 3060 | Time 75.5624(75.5070) | Bit/dim 3.8857(3.8834) | Xent 0.9895(0.9990) | Loss 4.3804(4.3829) | Error 0.3568(0.3552) Steps 832(825.63) | Grad Norm 2.2586(2.2562) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0510 | Time 29.9332, Epoch Time 492.8741(505.6624), Bit/dim 3.8826(best: 3.8832), Xent 0.9800, Loss 4.3725, Error 0.3457(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3061 | Time 76.4925(75.5365) | Bit/dim 3.8750(3.8831) | Xent 0.9832(0.9985) | Loss 4.3667(4.3824) | Error 0.3476(0.3550) Steps 826(825.64) | Grad Norm 1.9633(2.2474) | Total Time 14.00(14.00)\n",
      "Iter 3062 | Time 76.5016(75.5655) | Bit/dim 3.8851(3.8832) | Xent 0.9930(0.9983) | Loss 4.3817(4.3824) | Error 0.3580(0.3551) Steps 808(825.11) | Grad Norm 2.0657(2.2419) | Total Time 14.00(14.00)\n",
      "Iter 3063 | Time 73.3258(75.4983) | Bit/dim 3.8755(3.8829) | Xent 0.9928(0.9982) | Loss 4.3719(4.3820) | Error 0.3541(0.3551) Steps 820(824.96) | Grad Norm 1.7344(2.2267) | Total Time 14.00(14.00)\n",
      "Iter 3064 | Time 78.5156(75.5888) | Bit/dim 3.8908(3.8832) | Xent 0.9925(0.9980) | Loss 4.3870(4.3822) | Error 0.3541(0.3550) Steps 826(824.99) | Grad Norm 1.5098(2.2052) | Total Time 14.00(14.00)\n",
      "Iter 3065 | Time 71.4024(75.4632) | Bit/dim 3.8925(3.8835) | Xent 1.0065(0.9983) | Loss 4.3957(4.3826) | Error 0.3566(0.3551) Steps 826(825.02) | Grad Norm 2.6014(2.2171) | Total Time 14.00(14.00)\n",
      "Iter 3066 | Time 76.3418(75.4896) | Bit/dim 3.8734(3.8832) | Xent 0.9992(0.9983) | Loss 4.3731(4.3823) | Error 0.3582(0.3552) Steps 808(824.51) | Grad Norm 2.2449(2.2179) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0511 | Time 29.9146, Epoch Time 497.7124(505.4239), Bit/dim 3.8821(best: 3.8826), Xent 0.9760, Loss 4.3701, Error 0.3439(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3067 | Time 76.4522(75.5185) | Bit/dim 3.8804(3.8831) | Xent 0.9986(0.9983) | Loss 4.3797(4.3822) | Error 0.3534(0.3551) Steps 832(824.74) | Grad Norm 3.0489(2.2428) | Total Time 14.00(14.00)\n",
      "Iter 3068 | Time 77.4251(75.5757) | Bit/dim 3.8823(3.8831) | Xent 0.9932(0.9981) | Loss 4.3789(4.3821) | Error 0.3480(0.3549) Steps 844(825.31) | Grad Norm 1.6532(2.2251) | Total Time 14.00(14.00)\n",
      "Iter 3069 | Time 73.0109(75.4987) | Bit/dim 3.8835(3.8831) | Xent 0.9935(0.9980) | Loss 4.3803(4.3821) | Error 0.3575(0.3550) Steps 826(825.33) | Grad Norm 2.7260(2.2402) | Total Time 14.00(14.00)\n",
      "Iter 3070 | Time 73.8083(75.4480) | Bit/dim 3.8782(3.8829) | Xent 0.9760(0.9974) | Loss 4.3662(4.3816) | Error 0.3526(0.3549) Steps 820(825.17) | Grad Norm 1.4405(2.2162) | Total Time 14.00(14.00)\n",
      "Iter 3071 | Time 79.2067(75.5608) | Bit/dim 3.8773(3.8828) | Xent 0.9902(0.9971) | Loss 4.3724(4.3813) | Error 0.3515(0.3548) Steps 826(825.20) | Grad Norm 2.6788(2.2301) | Total Time 14.00(14.00)\n",
      "Iter 3072 | Time 74.8846(75.5405) | Bit/dim 3.8795(3.8827) | Xent 0.9881(0.9969) | Loss 4.3735(4.3811) | Error 0.3555(0.3548) Steps 826(825.22) | Grad Norm 1.6041(2.2113) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0512 | Time 29.9837, Epoch Time 500.1822(505.2666), Bit/dim 3.8809(best: 3.8821), Xent 0.9769, Loss 4.3693, Error 0.3468(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3073 | Time 76.9333(75.5823) | Bit/dim 3.8793(3.8826) | Xent 1.0062(0.9971) | Loss 4.3824(4.3811) | Error 0.3582(0.3549) Steps 820(825.07) | Grad Norm 1.2494(2.1824) | Total Time 14.00(14.00)\n",
      "Iter 3074 | Time 77.5903(75.6425) | Bit/dim 3.8823(3.8825) | Xent 0.9988(0.9972) | Loss 4.3817(4.3811) | Error 0.3552(0.3550) Steps 826(825.09) | Grad Norm 1.9831(2.1764) | Total Time 14.00(14.00)\n",
      "Iter 3075 | Time 78.2660(75.7212) | Bit/dim 3.8839(3.8826) | Xent 1.0089(0.9975) | Loss 4.3883(4.3814) | Error 0.3609(0.3551) Steps 826(825.12) | Grad Norm 1.3576(2.1519) | Total Time 14.00(14.00)\n",
      "Iter 3076 | Time 76.8039(75.7537) | Bit/dim 3.8820(3.8826) | Xent 0.9854(0.9972) | Loss 4.3747(4.3812) | Error 0.3546(0.3551) Steps 844(825.69) | Grad Norm 2.1851(2.1529) | Total Time 14.00(14.00)\n",
      "Iter 3077 | Time 72.0338(75.6421) | Bit/dim 3.8812(3.8825) | Xent 0.9864(0.9969) | Loss 4.3744(4.3810) | Error 0.3492(0.3549) Steps 826(825.70) | Grad Norm 1.7215(2.1399) | Total Time 14.00(14.00)\n",
      "Iter 3078 | Time 74.9825(75.6223) | Bit/dim 3.8817(3.8825) | Xent 0.9883(0.9966) | Loss 4.3759(4.3808) | Error 0.3574(0.3550) Steps 820(825.53) | Grad Norm 2.0570(2.1374) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0513 | Time 29.4910, Epoch Time 501.3829(505.1501), Bit/dim 3.8818(best: 3.8809), Xent 0.9750, Loss 4.3693, Error 0.3427(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3079 | Time 71.5487(75.5001) | Bit/dim 3.8773(3.8823) | Xent 0.9622(0.9956) | Loss 4.3584(4.3801) | Error 0.3456(0.3547) Steps 820(825.36) | Grad Norm 1.8773(2.1296) | Total Time 14.00(14.00)\n",
      "Iter 3080 | Time 77.0289(75.5460) | Bit/dim 3.8773(3.8822) | Xent 1.0020(0.9958) | Loss 4.3783(4.3801) | Error 0.3600(0.3549) Steps 820(825.20) | Grad Norm 0.9675(2.0948) | Total Time 14.00(14.00)\n",
      "Iter 3081 | Time 79.1313(75.6535) | Bit/dim 3.8802(3.8821) | Xent 1.0232(0.9966) | Loss 4.3917(4.3804) | Error 0.3651(0.3552) Steps 826(825.22) | Grad Norm 2.0874(2.0946) | Total Time 14.00(14.00)\n",
      "Iter 3082 | Time 77.7134(75.7153) | Bit/dim 3.8835(3.8822) | Xent 0.9879(0.9963) | Loss 4.3774(4.3803) | Error 0.3534(0.3551) Steps 826(825.25) | Grad Norm 1.3933(2.0735) | Total Time 14.00(14.00)\n",
      "Iter 3083 | Time 75.0497(75.6953) | Bit/dim 3.8802(3.8821) | Xent 0.9958(0.9963) | Loss 4.3781(4.3803) | Error 0.3540(0.3551) Steps 832(825.45) | Grad Norm 1.9566(2.0700) | Total Time 14.00(14.00)\n",
      "Iter 3084 | Time 79.2414(75.8017) | Bit/dim 3.8871(3.8823) | Xent 0.9975(0.9963) | Loss 4.3858(4.3804) | Error 0.3551(0.3551) Steps 826(825.47) | Grad Norm 1.5639(2.0548) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0514 | Time 29.7265, Epoch Time 504.8842(505.1421), Bit/dim 3.8825(best: 3.8809), Xent 0.9747, Loss 4.3699, Error 0.3434(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3085 | Time 73.9867(75.7473) | Bit/dim 3.8808(3.8822) | Xent 0.9756(0.9957) | Loss 4.3686(4.3801) | Error 0.3500(0.3550) Steps 826(825.48) | Grad Norm 2.0362(2.0543) | Total Time 14.00(14.00)\n",
      "Iter 3086 | Time 76.0198(75.7555) | Bit/dim 3.8884(3.8824) | Xent 0.9978(0.9958) | Loss 4.3873(4.3803) | Error 0.3500(0.3548) Steps 820(825.32) | Grad Norm 2.0340(2.0537) | Total Time 14.00(14.00)\n",
      "Iter 3087 | Time 77.6107(75.8111) | Bit/dim 3.8838(3.8824) | Xent 0.9978(0.9958) | Loss 4.3827(4.3804) | Error 0.3550(0.3548) Steps 826(825.34) | Grad Norm 1.4875(2.0367) | Total Time 14.00(14.00)\n",
      "Iter 3088 | Time 73.2389(75.7339) | Bit/dim 3.8805(3.8824) | Xent 0.9912(0.9957) | Loss 4.3761(4.3802) | Error 0.3529(0.3548) Steps 826(825.36) | Grad Norm 1.5169(2.0211) | Total Time 14.00(14.00)\n",
      "Iter 3089 | Time 76.7532(75.7645) | Bit/dim 3.8759(3.8822) | Xent 1.0041(0.9960) | Loss 4.3779(4.3802) | Error 0.3585(0.3549) Steps 832(825.56) | Grad Norm 1.1738(1.9957) | Total Time 14.00(14.00)\n",
      "Iter 3090 | Time 73.7190(75.7032) | Bit/dim 3.8770(3.8820) | Xent 0.9832(0.9956) | Loss 4.3686(4.3798) | Error 0.3540(0.3548) Steps 826(825.57) | Grad Norm 1.7220(1.9875) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0515 | Time 30.1449, Epoch Time 497.2746(504.9061), Bit/dim 3.8818(best: 3.8809), Xent 0.9774, Loss 4.3705, Error 0.3433(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3091 | Time 77.4799(75.7565) | Bit/dim 3.8817(3.8820) | Xent 0.9848(0.9953) | Loss 4.3741(4.3797) | Error 0.3478(0.3546) Steps 826(825.58) | Grad Norm 1.3032(1.9669) | Total Time 14.00(14.00)\n",
      "Iter 3092 | Time 76.6783(75.7841) | Bit/dim 3.8855(3.8821) | Xent 0.9820(0.9949) | Loss 4.3765(4.3796) | Error 0.3540(0.3546) Steps 832(825.78) | Grad Norm 2.1024(1.9710) | Total Time 14.00(14.00)\n",
      "Iter 3093 | Time 76.1970(75.7965) | Bit/dim 3.8685(3.8817) | Xent 0.9857(0.9946) | Loss 4.3614(4.3790) | Error 0.3498(0.3545) Steps 820(825.60) | Grad Norm 2.2078(1.9781) | Total Time 14.00(14.00)\n",
      "Iter 3094 | Time 78.1936(75.8684) | Bit/dim 3.8878(3.8819) | Xent 0.9859(0.9943) | Loss 4.3807(4.3791) | Error 0.3518(0.3544) Steps 826(825.61) | Grad Norm 2.2494(1.9862) | Total Time 14.00(14.00)\n",
      "Iter 3095 | Time 74.1609(75.8172) | Bit/dim 3.8758(3.8817) | Xent 0.9883(0.9941) | Loss 4.3699(4.3788) | Error 0.3505(0.3543) Steps 820(825.45) | Grad Norm 2.2586(1.9944) | Total Time 14.00(14.00)\n",
      "Iter 3096 | Time 73.5572(75.7494) | Bit/dim 3.8790(3.8816) | Xent 1.0052(0.9945) | Loss 4.3816(4.3789) | Error 0.3561(0.3543) Steps 820(825.28) | Grad Norm 2.3047(2.0037) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0516 | Time 29.6366, Epoch Time 501.2363(504.7960), Bit/dim 3.8794(best: 3.8809), Xent 0.9777, Loss 4.3683, Error 0.3461(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3097 | Time 74.8064(75.7211) | Bit/dim 3.8833(3.8817) | Xent 0.9714(0.9938) | Loss 4.3690(4.3786) | Error 0.3450(0.3540) Steps 832(825.48) | Grad Norm 2.3722(2.0148) | Total Time 14.00(14.00)\n",
      "Iter 3098 | Time 75.7839(75.7230) | Bit/dim 3.8766(3.8815) | Xent 0.9987(0.9939) | Loss 4.3760(4.3785) | Error 0.3461(0.3538) Steps 820(825.32) | Grad Norm 2.0584(2.0161) | Total Time 14.00(14.00)\n",
      "Iter 3099 | Time 78.4075(75.8035) | Bit/dim 3.8788(3.8815) | Xent 0.9889(0.9938) | Loss 4.3732(4.3783) | Error 0.3511(0.3537) Steps 826(825.34) | Grad Norm 2.3475(2.0260) | Total Time 14.00(14.00)\n",
      "Iter 3100 | Time 75.6691(75.7995) | Bit/dim 3.8768(3.8813) | Xent 1.0023(0.9940) | Loss 4.3780(4.3783) | Error 0.3586(0.3539) Steps 820(825.18) | Grad Norm 1.1638(2.0002) | Total Time 14.00(14.00)\n",
      "Iter 3101 | Time 75.2712(75.7836) | Bit/dim 3.8742(3.8811) | Xent 0.9981(0.9942) | Loss 4.3733(4.3782) | Error 0.3516(0.3538) Steps 826(825.20) | Grad Norm 1.4726(1.9843) | Total Time 14.00(14.00)\n",
      "Iter 3102 | Time 73.7070(75.7213) | Bit/dim 3.8847(3.8812) | Xent 1.0069(0.9945) | Loss 4.3881(4.3785) | Error 0.3639(0.3541) Steps 826(825.23) | Grad Norm 2.5538(2.0014) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0517 | Time 29.8081, Epoch Time 499.0820(504.6246), Bit/dim 3.8810(best: 3.8794), Xent 0.9758, Loss 4.3689, Error 0.3426(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3103 | Time 76.0801(75.7321) | Bit/dim 3.8713(3.8809) | Xent 0.9926(0.9945) | Loss 4.3677(4.3782) | Error 0.3522(0.3540) Steps 826(825.25) | Grad Norm 1.6727(1.9916) | Total Time 14.00(14.00)\n",
      "Iter 3104 | Time 72.2819(75.6286) | Bit/dim 3.8719(3.8806) | Xent 0.9881(0.9943) | Loss 4.3660(4.3778) | Error 0.3542(0.3541) Steps 826(825.27) | Grad Norm 2.4089(2.0041) | Total Time 14.00(14.00)\n",
      "Iter 3105 | Time 73.5799(75.5671) | Bit/dim 3.8772(3.8805) | Xent 0.9824(0.9939) | Loss 4.3683(4.3775) | Error 0.3496(0.3539) Steps 820(825.12) | Grad Norm 1.6183(1.9925) | Total Time 14.00(14.00)\n",
      "Iter 3106 | Time 74.4720(75.5343) | Bit/dim 3.8929(3.8809) | Xent 1.0135(0.9945) | Loss 4.3996(4.3782) | Error 0.3588(0.3541) Steps 820(824.96) | Grad Norm 1.8174(1.9872) | Total Time 14.00(14.00)\n",
      "Iter 3107 | Time 78.1712(75.6134) | Bit/dim 3.8889(3.8812) | Xent 0.9959(0.9946) | Loss 4.3869(4.3784) | Error 0.3532(0.3540) Steps 838(825.35) | Grad Norm 1.4986(1.9726) | Total Time 14.00(14.00)\n",
      "Iter 3108 | Time 74.9701(75.5941) | Bit/dim 3.8750(3.8810) | Xent 0.9774(0.9940) | Loss 4.3637(4.3780) | Error 0.3502(0.3539) Steps 820(825.19) | Grad Norm 2.6002(1.9914) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0518 | Time 29.9640, Epoch Time 494.9324(504.3338), Bit/dim 3.8814(best: 3.8794), Xent 0.9747, Loss 4.3688, Error 0.3423(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3109 | Time 78.1112(75.6696) | Bit/dim 3.8743(3.8808) | Xent 1.0203(0.9948) | Loss 4.3844(4.3782) | Error 0.3614(0.3542) Steps 826(825.22) | Grad Norm 1.8260(1.9865) | Total Time 14.00(14.00)\n",
      "Iter 3110 | Time 75.9412(75.6777) | Bit/dim 3.8925(3.8811) | Xent 0.9623(0.9939) | Loss 4.3736(4.3780) | Error 0.3419(0.3538) Steps 826(825.24) | Grad Norm 1.9312(1.9848) | Total Time 14.00(14.00)\n",
      "Iter 3111 | Time 75.8562(75.6831) | Bit/dim 3.8734(3.8809) | Xent 0.9907(0.9938) | Loss 4.3688(4.3778) | Error 0.3482(0.3536) Steps 820(825.08) | Grad Norm 2.3458(1.9956) | Total Time 14.00(14.00)\n",
      "Iter 3112 | Time 73.1966(75.6085) | Bit/dim 3.8766(3.8808) | Xent 0.9877(0.9936) | Loss 4.3705(4.3775) | Error 0.3521(0.3536) Steps 820(824.93) | Grad Norm 1.7895(1.9894) | Total Time 14.00(14.00)\n",
      "Iter 3113 | Time 72.6261(75.5190) | Bit/dim 3.8804(3.8808) | Xent 0.9980(0.9937) | Loss 4.3794(4.3776) | Error 0.3574(0.3537) Steps 826(824.96) | Grad Norm 2.6415(2.0090) | Total Time 14.00(14.00)\n",
      "Iter 3114 | Time 75.9106(75.5308) | Bit/dim 3.8767(3.8806) | Xent 0.9820(0.9934) | Loss 4.3677(4.3773) | Error 0.3495(0.3536) Steps 832(825.17) | Grad Norm 1.1531(1.9833) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0519 | Time 29.8906, Epoch Time 497.0110(504.1141), Bit/dim 3.8798(best: 3.8794), Xent 0.9791, Loss 4.3693, Error 0.3458(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3115 | Time 78.6954(75.6257) | Bit/dim 3.8852(3.8808) | Xent 0.9990(0.9935) | Loss 4.3847(4.3775) | Error 0.3504(0.3535) Steps 820(825.02) | Grad Norm 3.0203(2.0144) | Total Time 14.00(14.00)\n",
      "Iter 3116 | Time 76.2737(75.6452) | Bit/dim 3.8737(3.8806) | Xent 1.0030(0.9938) | Loss 4.3752(4.3775) | Error 0.3542(0.3535) Steps 826(825.05) | Grad Norm 1.9115(2.0113) | Total Time 14.00(14.00)\n",
      "Iter 3117 | Time 74.5047(75.6109) | Bit/dim 3.8725(3.8803) | Xent 1.0042(0.9941) | Loss 4.3746(4.3774) | Error 0.3596(0.3537) Steps 826(825.08) | Grad Norm 2.2584(2.0188) | Total Time 14.00(14.00)\n",
      "Iter 3118 | Time 71.7405(75.4948) | Bit/dim 3.8901(3.8806) | Xent 0.9776(0.9936) | Loss 4.3790(4.3774) | Error 0.3429(0.3533) Steps 826(825.10) | Grad Norm 3.0926(2.0510) | Total Time 14.00(14.00)\n",
      "Iter 3119 | Time 73.1982(75.4259) | Bit/dim 3.8773(3.8805) | Xent 0.9790(0.9932) | Loss 4.3668(4.3771) | Error 0.3461(0.3531) Steps 826(825.13) | Grad Norm 2.5772(2.0668) | Total Time 14.00(14.00)\n",
      "Iter 3120 | Time 74.2864(75.3917) | Bit/dim 3.8757(3.8804) | Xent 0.9814(0.9928) | Loss 4.3664(4.3768) | Error 0.3578(0.3533) Steps 826(825.16) | Grad Norm 2.3160(2.0742) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0520 | Time 29.8795, Epoch Time 494.0383(503.8119), Bit/dim 3.8799(best: 3.8794), Xent 0.9737, Loss 4.3668, Error 0.3422(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3121 | Time 76.2586(75.4178) | Bit/dim 3.8776(3.8803) | Xent 0.9629(0.9919) | Loss 4.3591(4.3762) | Error 0.3499(0.3532) Steps 832(825.36) | Grad Norm 1.1746(2.0472) | Total Time 14.00(14.00)\n",
      "Iter 3122 | Time 75.8444(75.4306) | Bit/dim 3.8739(3.8801) | Xent 1.0018(0.9922) | Loss 4.3747(4.3762) | Error 0.3494(0.3531) Steps 820(825.20) | Grad Norm 2.3376(2.0560) | Total Time 14.00(14.00)\n",
      "Iter 3123 | Time 77.3767(75.4889) | Bit/dim 3.8722(3.8799) | Xent 1.0060(0.9926) | Loss 4.3752(4.3762) | Error 0.3565(0.3532) Steps 820(825.05) | Grad Norm 1.9286(2.0521) | Total Time 14.00(14.00)\n",
      "Iter 3124 | Time 77.3609(75.5451) | Bit/dim 3.8853(3.8800) | Xent 0.9811(0.9923) | Loss 4.3758(4.3762) | Error 0.3458(0.3529) Steps 826(825.07) | Grad Norm 2.2523(2.0581) | Total Time 14.00(14.00)\n",
      "Iter 3125 | Time 72.5383(75.4549) | Bit/dim 3.8743(3.8798) | Xent 0.9817(0.9920) | Loss 4.3651(4.3758) | Error 0.3481(0.3528) Steps 826(825.10) | Grad Norm 1.9078(2.0536) | Total Time 14.00(14.00)\n",
      "Iter 3126 | Time 74.0167(75.4117) | Bit/dim 3.8841(3.8800) | Xent 0.9876(0.9918) | Loss 4.3779(4.3759) | Error 0.3556(0.3529) Steps 820(824.95) | Grad Norm 2.3819(2.0635) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0521 | Time 29.8985, Epoch Time 498.9122(503.6649), Bit/dim 3.8803(best: 3.8794), Xent 0.9792, Loss 4.3699, Error 0.3449(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3127 | Time 73.5789(75.3568) | Bit/dim 3.8810(3.8800) | Xent 0.9784(0.9914) | Loss 4.3702(4.3757) | Error 0.3492(0.3528) Steps 826(824.98) | Grad Norm 3.1324(2.0955) | Total Time 14.00(14.00)\n",
      "Iter 3128 | Time 76.7092(75.3973) | Bit/dim 3.8845(3.8801) | Xent 0.9877(0.9913) | Loss 4.3784(4.3758) | Error 0.3489(0.3527) Steps 820(824.83) | Grad Norm 2.4778(2.1070) | Total Time 14.00(14.00)\n",
      "Iter 3129 | Time 75.0822(75.3879) | Bit/dim 3.8789(3.8801) | Xent 0.9692(0.9907) | Loss 4.3635(4.3754) | Error 0.3411(0.3523) Steps 832(825.05) | Grad Norm 2.7486(2.1263) | Total Time 14.00(14.00)\n",
      "Iter 3130 | Time 73.7812(75.3397) | Bit/dim 3.8804(3.8801) | Xent 1.0011(0.9910) | Loss 4.3810(4.3756) | Error 0.3545(0.3524) Steps 832(825.25) | Grad Norm 2.7082(2.1437) | Total Time 14.00(14.00)\n",
      "Iter 3131 | Time 76.3612(75.3703) | Bit/dim 3.8761(3.8800) | Xent 0.9852(0.9908) | Loss 4.3687(4.3754) | Error 0.3455(0.3522) Steps 820(825.10) | Grad Norm 4.3384(2.2096) | Total Time 14.00(14.00)\n",
      "Iter 3132 | Time 75.8500(75.3847) | Bit/dim 3.8745(3.8798) | Xent 1.0002(0.9911) | Loss 4.3746(4.3754) | Error 0.3555(0.3523) Steps 832(825.30) | Grad Norm 2.5857(2.2208) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0522 | Time 29.9625, Epoch Time 496.7678(503.4580), Bit/dim 3.8797(best: 3.8794), Xent 0.9720, Loss 4.3657, Error 0.3445(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3133 | Time 73.8108(75.3375) | Bit/dim 3.8733(3.8796) | Xent 0.9867(0.9910) | Loss 4.3666(4.3751) | Error 0.3490(0.3522) Steps 820(825.15) | Grad Norm 2.8836(2.2407) | Total Time 14.00(14.00)\n",
      "Iter 3134 | Time 74.9120(75.3247) | Bit/dim 3.8823(3.8797) | Xent 0.9897(0.9909) | Loss 4.3772(4.3752) | Error 0.3471(0.3520) Steps 832(825.35) | Grad Norm 2.3645(2.2444) | Total Time 14.00(14.00)\n",
      "Iter 3135 | Time 72.1620(75.2298) | Bit/dim 3.8896(3.8800) | Xent 0.9933(0.9910) | Loss 4.3862(4.3755) | Error 0.3585(0.3522) Steps 826(825.37) | Grad Norm 2.1971(2.2430) | Total Time 14.00(14.00)\n",
      "Iter 3136 | Time 74.6405(75.2122) | Bit/dim 3.8741(3.8798) | Xent 0.9940(0.9911) | Loss 4.3711(4.3754) | Error 0.3561(0.3523) Steps 844(825.93) | Grad Norm 1.6725(2.2259) | Total Time 14.00(14.00)\n",
      "Iter 3137 | Time 74.4801(75.1902) | Bit/dim 3.8729(3.8796) | Xent 0.9739(0.9906) | Loss 4.3599(4.3749) | Error 0.3462(0.3521) Steps 826(825.93) | Grad Norm 1.4755(2.2034) | Total Time 14.00(14.00)\n",
      "Iter 3138 | Time 76.4263(75.2273) | Bit/dim 3.8708(3.8794) | Xent 0.9794(0.9902) | Loss 4.3605(4.3745) | Error 0.3423(0.3518) Steps 826(825.93) | Grad Norm 2.9447(2.2256) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0523 | Time 29.8319, Epoch Time 491.7768(503.1075), Bit/dim 3.8797(best: 3.8794), Xent 0.9736, Loss 4.3666, Error 0.3432(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3139 | Time 71.1729(75.1057) | Bit/dim 3.8794(3.8794) | Xent 0.9751(0.9898) | Loss 4.3670(4.3742) | Error 0.3448(0.3516) Steps 832(826.12) | Grad Norm 2.1287(2.2227) | Total Time 14.00(14.00)\n",
      "Iter 3140 | Time 78.4534(75.2061) | Bit/dim 3.8717(3.8791) | Xent 1.0007(0.9901) | Loss 4.3721(4.3742) | Error 0.3524(0.3517) Steps 832(826.29) | Grad Norm 3.5043(2.2612) | Total Time 14.00(14.00)\n",
      "Iter 3141 | Time 74.6349(75.1890) | Bit/dim 3.8794(3.8791) | Xent 0.9752(0.9897) | Loss 4.3670(4.3740) | Error 0.3451(0.3515) Steps 832(826.46) | Grad Norm 2.5868(2.2709) | Total Time 14.00(14.00)\n",
      "Iter 3142 | Time 73.7264(75.1451) | Bit/dim 3.8844(3.8793) | Xent 0.9986(0.9899) | Loss 4.3837(4.3743) | Error 0.3556(0.3516) Steps 820(826.27) | Grad Norm 3.1614(2.2977) | Total Time 14.00(14.00)\n",
      "Iter 3143 | Time 74.6203(75.1293) | Bit/dim 3.8651(3.8789) | Xent 0.9934(0.9900) | Loss 4.3618(4.3739) | Error 0.3545(0.3517) Steps 826(826.26) | Grad Norm 3.0921(2.3215) | Total Time 14.00(14.00)\n",
      "Iter 3144 | Time 75.0004(75.1255) | Bit/dim 3.8836(3.8790) | Xent 0.9852(0.9899) | Loss 4.3762(4.3740) | Error 0.3475(0.3515) Steps 826(826.25) | Grad Norm 2.9772(2.3412) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0524 | Time 29.8736, Epoch Time 493.1914(502.8100), Bit/dim 3.8772(best: 3.8794), Xent 0.9756, Loss 4.3650, Error 0.3427(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3145 | Time 73.1040(75.0648) | Bit/dim 3.8743(3.8789) | Xent 0.9792(0.9896) | Loss 4.3640(4.3737) | Error 0.3512(0.3515) Steps 832(826.43) | Grad Norm 4.2851(2.3995) | Total Time 14.00(14.00)\n",
      "Iter 3146 | Time 78.0760(75.1552) | Bit/dim 3.8796(3.8789) | Xent 0.9927(0.9897) | Loss 4.3759(4.3737) | Error 0.3608(0.3518) Steps 826(826.41) | Grad Norm 2.2110(2.3938) | Total Time 14.00(14.00)\n",
      "Iter 3147 | Time 73.6272(75.1093) | Bit/dim 3.8758(3.8788) | Xent 0.9993(0.9900) | Loss 4.3755(4.3738) | Error 0.3546(0.3519) Steps 826(826.40) | Grad Norm 5.9539(2.5006) | Total Time 14.00(14.00)\n",
      "Iter 3148 | Time 71.1770(74.9913) | Bit/dim 3.8782(3.8788) | Xent 0.9915(0.9900) | Loss 4.3740(4.3738) | Error 0.3506(0.3519) Steps 832(826.57) | Grad Norm 2.6074(2.5038) | Total Time 14.00(14.00)\n",
      "Iter 3149 | Time 74.6051(74.9798) | Bit/dim 3.8829(3.8789) | Xent 0.9931(0.9901) | Loss 4.3795(4.3740) | Error 0.3508(0.3518) Steps 826(826.55) | Grad Norm 5.9995(2.6087) | Total Time 14.00(14.00)\n",
      "Iter 3150 | Time 74.4840(74.9649) | Bit/dim 3.8730(3.8787) | Xent 0.9866(0.9900) | Loss 4.3663(4.3737) | Error 0.3461(0.3517) Steps 832(826.71) | Grad Norm 2.9815(2.6199) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0525 | Time 29.8252, Epoch Time 490.3665(502.4367), Bit/dim 3.8785(best: 3.8772), Xent 0.9758, Loss 4.3664, Error 0.3407(best: 0.3420)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3151 | Time 75.6597(74.9857) | Bit/dim 3.8863(3.8790) | Xent 0.9937(0.9901) | Loss 4.3832(4.3740) | Error 0.3575(0.3518) Steps 826(826.69) | Grad Norm 4.6319(2.6802) | Total Time 14.00(14.00)\n",
      "Iter 3152 | Time 72.8066(74.9204) | Bit/dim 3.8751(3.8788) | Xent 0.9922(0.9902) | Loss 4.3712(4.3739) | Error 0.3489(0.3517) Steps 826(826.67) | Grad Norm 4.1815(2.7253) | Total Time 14.00(14.00)\n",
      "Iter 3153 | Time 75.2154(74.9292) | Bit/dim 3.8834(3.8790) | Xent 0.9797(0.9898) | Loss 4.3732(4.3739) | Error 0.3472(0.3516) Steps 826(826.65) | Grad Norm 2.4970(2.7184) | Total Time 14.00(14.00)\n",
      "Iter 3154 | Time 74.3407(74.9116) | Bit/dim 3.8756(3.8789) | Xent 1.0140(0.9906) | Loss 4.3827(4.3742) | Error 0.3569(0.3518) Steps 820(826.45) | Grad Norm 4.6957(2.7777) | Total Time 14.00(14.00)\n",
      "Iter 3155 | Time 73.9952(74.8841) | Bit/dim 3.8744(3.8787) | Xent 0.9772(0.9902) | Loss 4.3630(4.3738) | Error 0.3496(0.3517) Steps 826(826.44) | Grad Norm 2.4303(2.7673) | Total Time 14.00(14.00)\n",
      "Iter 3156 | Time 74.7960(74.8814) | Bit/dim 3.8686(3.8784) | Xent 0.9947(0.9903) | Loss 4.3660(4.3736) | Error 0.3586(0.3519) Steps 832(826.61) | Grad Norm 3.2724(2.7825) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0526 | Time 29.8173, Epoch Time 492.0904(502.1263), Bit/dim 3.8769(best: 3.8772), Xent 0.9721, Loss 4.3629, Error 0.3406(best: 0.3407)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3157 | Time 72.5678(74.8120) | Bit/dim 3.8754(3.8783) | Xent 0.9982(0.9905) | Loss 4.3746(4.3736) | Error 0.3565(0.3520) Steps 826(826.59) | Grad Norm 1.8854(2.7556) | Total Time 14.00(14.00)\n",
      "Iter 3158 | Time 76.7720(74.8708) | Bit/dim 3.8854(3.8786) | Xent 0.9652(0.9898) | Loss 4.3680(4.3735) | Error 0.3455(0.3519) Steps 826(826.57) | Grad Norm 5.5730(2.8401) | Total Time 14.00(14.00)\n",
      "Iter 3159 | Time 76.3462(74.9151) | Bit/dim 3.8748(3.8784) | Xent 0.9971(0.9900) | Loss 4.3733(4.3734) | Error 0.3548(0.3519) Steps 826(826.55) | Grad Norm 1.9529(2.8135) | Total Time 14.00(14.00)\n",
      "Iter 3160 | Time 72.7605(74.8504) | Bit/dim 3.8775(3.8784) | Xent 0.9693(0.9894) | Loss 4.3621(4.3731) | Error 0.3401(0.3516) Steps 832(826.72) | Grad Norm 4.4120(2.8614) | Total Time 14.00(14.00)\n",
      "Iter 3161 | Time 73.3147(74.8044) | Bit/dim 3.8663(3.8780) | Xent 0.9967(0.9896) | Loss 4.3646(4.3729) | Error 0.3602(0.3518) Steps 820(826.52) | Grad Norm 2.5518(2.8521) | Total Time 14.00(14.00)\n",
      "Iter 3162 | Time 77.1903(74.8759) | Bit/dim 3.8793(3.8781) | Xent 0.9839(0.9894) | Loss 4.3712(4.3728) | Error 0.3515(0.3518) Steps 820(826.32) | Grad Norm 3.2506(2.8641) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0527 | Time 29.6675, Epoch Time 494.0296(501.8834), Bit/dim 3.8772(best: 3.8769), Xent 0.9711, Loss 4.3628, Error 0.3409(best: 0.3406)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3163 | Time 74.2665(74.8577) | Bit/dim 3.8721(3.8779) | Xent 1.0122(0.9901) | Loss 4.3782(4.3730) | Error 0.3574(0.3520) Steps 826(826.31) | Grad Norm 1.9897(2.8379) | Total Time 14.00(14.00)\n",
      "Iter 3164 | Time 74.5950(74.8498) | Bit/dim 3.8855(3.8781) | Xent 0.9634(0.9893) | Loss 4.3673(4.3728) | Error 0.3403(0.3516) Steps 826(826.30) | Grad Norm 1.5440(2.7990) | Total Time 14.00(14.00)\n",
      "Iter 3165 | Time 73.8327(74.8193) | Bit/dim 3.8783(3.8781) | Xent 0.9821(0.9891) | Loss 4.3694(4.3727) | Error 0.3496(0.3516) Steps 826(826.29) | Grad Norm 2.2379(2.7822) | Total Time 14.00(14.00)\n",
      "Iter 3166 | Time 77.8976(74.9116) | Bit/dim 3.8740(3.8780) | Xent 0.9908(0.9892) | Loss 4.3694(4.3726) | Error 0.3562(0.3517) Steps 820(826.10) | Grad Norm 1.1968(2.7346) | Total Time 14.00(14.00)\n",
      "Iter 3167 | Time 76.3454(74.9546) | Bit/dim 3.8707(3.8778) | Xent 0.9939(0.9893) | Loss 4.3676(4.3724) | Error 0.3560(0.3519) Steps 832(826.28) | Grad Norm 2.8037(2.7367) | Total Time 14.00(14.00)\n",
      "Iter 3168 | Time 74.6079(74.9442) | Bit/dim 3.8736(3.8777) | Xent 0.9856(0.9892) | Loss 4.3664(4.3723) | Error 0.3425(0.3516) Steps 826(826.27) | Grad Norm 1.8670(2.7106) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0528 | Time 29.4427, Epoch Time 496.4817(501.7214), Bit/dim 3.8776(best: 3.8769), Xent 0.9711, Loss 4.3631, Error 0.3415(best: 0.3406)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3169 | Time 72.1513(74.8604) | Bit/dim 3.8817(3.8778) | Xent 0.9987(0.9895) | Loss 4.3810(4.3725) | Error 0.3540(0.3516) Steps 814(825.90) | Grad Norm 2.2416(2.6966) | Total Time 14.00(14.00)\n",
      "Iter 3170 | Time 78.3984(74.9666) | Bit/dim 3.8762(3.8777) | Xent 0.9868(0.9894) | Loss 4.3696(4.3724) | Error 0.3551(0.3518) Steps 820(825.73) | Grad Norm 2.7668(2.6987) | Total Time 14.00(14.00)\n",
      "Iter 3171 | Time 72.5620(74.8944) | Bit/dim 3.8615(3.8773) | Xent 0.9838(0.9892) | Loss 4.3534(4.3719) | Error 0.3569(0.3519) Steps 826(825.73) | Grad Norm 1.3395(2.6579) | Total Time 14.00(14.00)\n",
      "Iter 3172 | Time 76.1617(74.9325) | Bit/dim 3.8725(3.8771) | Xent 0.9776(0.9889) | Loss 4.3613(4.3715) | Error 0.3461(0.3517) Steps 826(825.74) | Grad Norm 2.7932(2.6619) | Total Time 14.00(14.00)\n",
      "Iter 3173 | Time 73.0575(74.8762) | Bit/dim 3.8784(3.8771) | Xent 0.9806(0.9886) | Loss 4.3687(4.3715) | Error 0.3494(0.3517) Steps 820(825.57) | Grad Norm 3.7928(2.6959) | Total Time 14.00(14.00)\n",
      "Iter 3174 | Time 74.5841(74.8674) | Bit/dim 3.8834(3.8773) | Xent 0.9873(0.9886) | Loss 4.3770(4.3716) | Error 0.3511(0.3516) Steps 826(825.58) | Grad Norm 4.1002(2.7380) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0529 | Time 29.7958, Epoch Time 492.1245(501.4335), Bit/dim 3.8783(best: 3.8769), Xent 0.9706, Loss 4.3636, Error 0.3405(best: 0.3406)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3175 | Time 78.5284(74.9773) | Bit/dim 3.8646(3.8770) | Xent 0.9864(0.9885) | Loss 4.3578(4.3712) | Error 0.3490(0.3516) Steps 826(825.60) | Grad Norm 3.2468(2.7533) | Total Time 14.00(14.00)\n",
      "Iter 3176 | Time 74.3815(74.9594) | Bit/dim 3.8766(3.8769) | Xent 0.9855(0.9884) | Loss 4.3694(4.3712) | Error 0.3529(0.3516) Steps 820(825.43) | Grad Norm 3.4266(2.7735) | Total Time 14.00(14.00)\n",
      "Iter 3177 | Time 74.7792(74.9540) | Bit/dim 3.8822(3.8771) | Xent 0.9778(0.9881) | Loss 4.3711(4.3712) | Error 0.3531(0.3517) Steps 820(825.26) | Grad Norm 2.2746(2.7585) | Total Time 14.00(14.00)\n",
      "Iter 3178 | Time 75.3063(74.9646) | Bit/dim 3.8705(3.8769) | Xent 0.9796(0.9879) | Loss 4.3603(4.3708) | Error 0.3466(0.3515) Steps 820(825.11) | Grad Norm 1.6875(2.7264) | Total Time 14.00(14.00)\n",
      "Iter 3179 | Time 73.7128(74.9270) | Bit/dim 3.8781(3.8769) | Xent 0.9897(0.9879) | Loss 4.3729(4.3709) | Error 0.3548(0.3516) Steps 826(825.13) | Grad Norm 3.3371(2.7447) | Total Time 14.00(14.00)\n",
      "Iter 3180 | Time 74.8966(74.9261) | Bit/dim 3.8784(3.8770) | Xent 0.9822(0.9877) | Loss 4.3695(4.3709) | Error 0.3556(0.3517) Steps 826(825.16) | Grad Norm 1.5169(2.7079) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0530 | Time 29.9718, Epoch Time 496.8786(501.2968), Bit/dim 3.8767(best: 3.8769), Xent 0.9731, Loss 4.3632, Error 0.3433(best: 0.3405)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3181 | Time 75.5874(74.9459) | Bit/dim 3.8702(3.8768) | Xent 0.9818(0.9876) | Loss 4.3611(4.3706) | Error 0.3445(0.3515) Steps 832(825.36) | Grad Norm 2.4151(2.6991) | Total Time 14.00(14.00)\n",
      "Iter 3182 | Time 77.7769(75.0309) | Bit/dim 3.8737(3.8767) | Xent 0.9961(0.9878) | Loss 4.3718(4.3706) | Error 0.3508(0.3515) Steps 820(825.20) | Grad Norm 3.1622(2.7130) | Total Time 14.00(14.00)\n",
      "Iter 3183 | Time 74.0635(75.0018) | Bit/dim 3.8840(3.8769) | Xent 0.9700(0.9873) | Loss 4.3690(4.3705) | Error 0.3426(0.3512) Steps 826(825.23) | Grad Norm 3.7166(2.7431) | Total Time 14.00(14.00)\n",
      "Iter 3184 | Time 74.4838(74.9863) | Bit/dim 3.8732(3.8768) | Xent 1.0053(0.9878) | Loss 4.3758(4.3707) | Error 0.3545(0.3513) Steps 826(825.25) | Grad Norm 2.3142(2.7302) | Total Time 14.00(14.00)\n",
      "Iter 3185 | Time 76.0981(75.0197) | Bit/dim 3.8767(3.8768) | Xent 0.9776(0.9875) | Loss 4.3655(4.3706) | Error 0.3520(0.3513) Steps 826(825.27) | Grad Norm 3.2450(2.7457) | Total Time 14.00(14.00)\n",
      "Iter 3186 | Time 78.0634(75.1110) | Bit/dim 3.8783(3.8768) | Xent 0.9730(0.9871) | Loss 4.3648(4.3704) | Error 0.3424(0.3511) Steps 820(825.12) | Grad Norm 3.1250(2.7570) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0531 | Time 29.9744, Epoch Time 501.5783(501.3053), Bit/dim 3.8771(best: 3.8767), Xent 0.9686, Loss 4.3614, Error 0.3394(best: 0.3405)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3187 | Time 76.9313(75.1656) | Bit/dim 3.8733(3.8767) | Xent 0.9824(0.9869) | Loss 4.3645(4.3702) | Error 0.3501(0.3510) Steps 820(824.96) | Grad Norm 2.8786(2.7607) | Total Time 14.00(14.00)\n",
      "Iter 3188 | Time 79.2847(75.2892) | Bit/dim 3.8895(3.8771) | Xent 0.9836(0.9868) | Loss 4.3813(4.3705) | Error 0.3464(0.3509) Steps 820(824.81) | Grad Norm 1.7057(2.7290) | Total Time 14.00(14.00)\n",
      "Iter 3189 | Time 74.9366(75.2786) | Bit/dim 3.8745(3.8770) | Xent 1.0056(0.9874) | Loss 4.3773(4.3707) | Error 0.3594(0.3512) Steps 820(824.67) | Grad Norm 2.6237(2.7259) | Total Time 14.00(14.00)\n",
      "Iter 3190 | Time 72.4494(75.1937) | Bit/dim 3.8607(3.8765) | Xent 0.9651(0.9867) | Loss 4.3432(4.3699) | Error 0.3459(0.3510) Steps 820(824.53) | Grad Norm 3.1312(2.7380) | Total Time 14.00(14.00)\n",
      "Iter 3191 | Time 71.9558(75.0966) | Bit/dim 3.8856(3.8768) | Xent 0.9914(0.9869) | Loss 4.3812(4.3703) | Error 0.3485(0.3509) Steps 814(824.21) | Grad Norm 3.4269(2.7587) | Total Time 14.00(14.00)\n",
      "Iter 3192 | Time 73.7792(75.0570) | Bit/dim 3.8633(3.8764) | Xent 0.9857(0.9868) | Loss 4.3562(4.3698) | Error 0.3494(0.3509) Steps 820(824.09) | Grad Norm 3.4733(2.7801) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0532 | Time 29.8426, Epoch Time 494.5887(501.1038), Bit/dim 3.8763(best: 3.8767), Xent 0.9733, Loss 4.3629, Error 0.3427(best: 0.3394)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3193 | Time 72.8639(74.9913) | Bit/dim 3.8664(3.8761) | Xent 1.0010(0.9873) | Loss 4.3669(4.3697) | Error 0.3610(0.3512) Steps 826(824.14) | Grad Norm 2.3441(2.7671) | Total Time 14.00(14.00)\n",
      "Iter 3194 | Time 72.1405(74.9057) | Bit/dim 3.8688(3.8759) | Xent 0.9714(0.9868) | Loss 4.3544(4.3693) | Error 0.3516(0.3512) Steps 814(823.84) | Grad Norm 3.5571(2.7908) | Total Time 14.00(14.00)\n",
      "Iter 3195 | Time 77.2018(74.9746) | Bit/dim 3.8839(3.8761) | Xent 0.9819(0.9866) | Loss 4.3748(4.3695) | Error 0.3514(0.3512) Steps 838(824.26) | Grad Norm 2.0391(2.7682) | Total Time 14.00(14.00)\n",
      "Iter 3196 | Time 76.6620(75.0252) | Bit/dim 3.8692(3.8759) | Xent 0.9832(0.9865) | Loss 4.3609(4.3692) | Error 0.3484(0.3511) Steps 838(824.68) | Grad Norm 2.0880(2.7478) | Total Time 14.00(14.00)\n",
      "Iter 3197 | Time 74.2163(75.0010) | Bit/dim 3.8827(3.8761) | Xent 0.9751(0.9862) | Loss 4.3703(4.3692) | Error 0.3479(0.3510) Steps 826(824.72) | Grad Norm 2.2156(2.7318) | Total Time 14.00(14.00)\n",
      "Iter 3198 | Time 74.0877(74.9736) | Bit/dim 3.8703(3.8760) | Xent 0.9846(0.9861) | Loss 4.3626(4.3690) | Error 0.3498(0.3510) Steps 832(824.93) | Grad Norm 1.9222(2.7075) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0533 | Time 29.6285, Epoch Time 492.3862(500.8422), Bit/dim 3.8762(best: 3.8763), Xent 0.9687, Loss 4.3606, Error 0.3397(best: 0.3394)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3199 | Time 75.4405(74.9876) | Bit/dim 3.8791(3.8760) | Xent 0.9847(0.9861) | Loss 4.3715(4.3691) | Error 0.3535(0.3511) Steps 826(824.97) | Grad Norm 1.9414(2.6846) | Total Time 14.00(14.00)\n",
      "Iter 3200 | Time 76.6012(75.0360) | Bit/dim 3.8753(3.8760) | Xent 0.9836(0.9860) | Loss 4.3671(4.3690) | Error 0.3440(0.3508) Steps 820(824.82) | Grad Norm 2.0980(2.6670) | Total Time 14.00(14.00)\n",
      "Iter 3201 | Time 74.1765(75.0102) | Bit/dim 3.8743(3.8760) | Xent 0.9980(0.9864) | Loss 4.3733(4.3692) | Error 0.3550(0.3510) Steps 826(824.85) | Grad Norm 2.6528(2.6665) | Total Time 14.00(14.00)\n",
      "Iter 3202 | Time 72.1620(74.9247) | Bit/dim 3.8773(3.8760) | Xent 0.9729(0.9860) | Loss 4.3638(4.3690) | Error 0.3479(0.3509) Steps 820(824.71) | Grad Norm 2.4251(2.6593) | Total Time 14.00(14.00)\n",
      "Iter 3203 | Time 73.6159(74.8855) | Bit/dim 3.8687(3.8758) | Xent 0.9837(0.9859) | Loss 4.3605(4.3688) | Error 0.3535(0.3509) Steps 820(824.57) | Grad Norm 3.8796(2.6959) | Total Time 14.00(14.00)\n",
      "Iter 3204 | Time 74.3051(74.8681) | Bit/dim 3.8702(3.8756) | Xent 0.9758(0.9856) | Loss 4.3581(4.3684) | Error 0.3542(0.3510) Steps 808(824.07) | Grad Norm 2.3272(2.6848) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0534 | Time 29.5674, Epoch Time 491.6278(500.5658), Bit/dim 3.8756(best: 3.8762), Xent 0.9745, Loss 4.3629, Error 0.3423(best: 0.3394)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3205 | Time 73.3260(74.8218) | Bit/dim 3.8683(3.8754) | Xent 0.9846(0.9856) | Loss 4.3606(4.3682) | Error 0.3516(0.3511) Steps 814(823.77) | Grad Norm 3.7481(2.7167) | Total Time 14.00(14.00)\n",
      "Iter 3206 | Time 76.7054(74.8783) | Bit/dim 3.8780(3.8755) | Xent 0.9806(0.9854) | Loss 4.3683(4.3682) | Error 0.3491(0.3510) Steps 814(823.47) | Grad Norm 2.3511(2.7058) | Total Time 14.00(14.00)\n",
      "Iter 3207 | Time 75.3238(74.8917) | Bit/dim 3.8778(3.8756) | Xent 0.9878(0.9855) | Loss 4.3717(4.3683) | Error 0.3466(0.3509) Steps 820(823.37) | Grad Norm 3.6864(2.7352) | Total Time 14.00(14.00)\n",
      "Iter 3208 | Time 75.0989(74.8979) | Bit/dim 3.8736(3.8755) | Xent 0.9857(0.9855) | Loss 4.3664(4.3683) | Error 0.3548(0.3510) Steps 814(823.09) | Grad Norm 2.8150(2.7376) | Total Time 14.00(14.00)\n",
      "Iter 3209 | Time 75.3768(74.9123) | Bit/dim 3.8652(3.8752) | Xent 0.9764(0.9852) | Loss 4.3534(4.3678) | Error 0.3500(0.3510) Steps 820(823.00) | Grad Norm 3.2015(2.7515) | Total Time 14.00(14.00)\n",
      "Iter 3210 | Time 74.5707(74.9020) | Bit/dim 3.8783(3.8753) | Xent 0.9663(0.9847) | Loss 4.3615(4.3676) | Error 0.3465(0.3508) Steps 820(822.91) | Grad Norm 3.1427(2.7632) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0535 | Time 29.8054, Epoch Time 495.6535(500.4184), Bit/dim 3.8750(best: 3.8756), Xent 0.9705, Loss 4.3603, Error 0.3415(best: 0.3394)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3211 | Time 72.0822(74.8174) | Bit/dim 3.8734(3.8752) | Xent 0.9852(0.9847) | Loss 4.3660(4.3676) | Error 0.3434(0.3506) Steps 808(822.46) | Grad Norm 3.0652(2.7723) | Total Time 14.00(14.00)\n",
      "Iter 3212 | Time 76.6312(74.8718) | Bit/dim 3.8580(3.8747) | Xent 0.9806(0.9846) | Loss 4.3484(4.3670) | Error 0.3425(0.3504) Steps 838(822.93) | Grad Norm 3.8984(2.8061) | Total Time 14.00(14.00)\n",
      "Iter 3213 | Time 76.8342(74.9307) | Bit/dim 3.8793(3.8748) | Xent 1.0079(0.9853) | Loss 4.3832(4.3675) | Error 0.3632(0.3507) Steps 820(822.84) | Grad Norm 4.0518(2.8434) | Total Time 14.00(14.00)\n",
      "Iter 3214 | Time 76.4363(74.9759) | Bit/dim 3.8661(3.8746) | Xent 0.9837(0.9852) | Loss 4.3580(4.3672) | Error 0.3496(0.3507) Steps 814(822.57) | Grad Norm 3.1538(2.8528) | Total Time 14.00(14.00)\n",
      "Iter 3215 | Time 74.4534(74.9602) | Bit/dim 3.8782(3.8747) | Xent 0.9740(0.9849) | Loss 4.3652(4.3671) | Error 0.3401(0.3504) Steps 820(822.50) | Grad Norm 2.4143(2.8396) | Total Time 14.00(14.00)\n",
      "Iter 3216 | Time 70.7550(74.8340) | Bit/dim 3.8814(3.8749) | Xent 0.9860(0.9849) | Loss 4.3744(4.3674) | Error 0.3494(0.3504) Steps 826(822.60) | Grad Norm 1.9531(2.8130) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0536 | Time 29.8039, Epoch Time 492.3872(500.1775), Bit/dim 3.8752(best: 3.8750), Xent 0.9673, Loss 4.3588, Error 0.3388(best: 0.3394)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3217 | Time 74.1264(74.8128) | Bit/dim 3.8798(3.8750) | Xent 0.9768(0.9847) | Loss 4.3682(4.3674) | Error 0.3470(0.3503) Steps 820(822.52) | Grad Norm 2.0124(2.7890) | Total Time 14.00(14.00)\n",
      "Iter 3218 | Time 72.2659(74.7364) | Bit/dim 3.8726(3.8750) | Xent 0.9856(0.9847) | Loss 4.3654(4.3673) | Error 0.3479(0.3502) Steps 820(822.45) | Grad Norm 2.6761(2.7856) | Total Time 14.00(14.00)\n",
      "Iter 3219 | Time 73.7545(74.7069) | Bit/dim 3.8784(3.8751) | Xent 0.9790(0.9845) | Loss 4.3679(4.3673) | Error 0.3485(0.3501) Steps 826(822.55) | Grad Norm 1.7733(2.7552) | Total Time 14.00(14.00)\n",
      "Iter 3220 | Time 73.4636(74.6696) | Bit/dim 3.8738(3.8750) | Xent 0.9563(0.9837) | Loss 4.3520(4.3669) | Error 0.3442(0.3500) Steps 820(822.48) | Grad Norm 2.0857(2.7352) | Total Time 14.00(14.00)\n",
      "Iter 3221 | Time 71.9958(74.5894) | Bit/dim 3.8644(3.8747) | Xent 0.9861(0.9838) | Loss 4.3575(4.3666) | Error 0.3546(0.3501) Steps 814(822.22) | Grad Norm 2.8372(2.7382) | Total Time 14.00(14.00)\n",
      "Iter 3222 | Time 78.1735(74.6970) | Bit/dim 3.8823(3.8749) | Xent 0.9841(0.9838) | Loss 4.3743(4.3668) | Error 0.3511(0.3501) Steps 820(822.16) | Grad Norm 3.9487(2.7745) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0537 | Time 29.5944, Epoch Time 488.9031(499.8393), Bit/dim 3.8743(best: 3.8750), Xent 0.9653, Loss 4.3570, Error 0.3397(best: 0.3388)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3223 | Time 78.6630(74.8159) | Bit/dim 3.8694(3.8748) | Xent 0.9992(0.9842) | Loss 4.3690(4.3669) | Error 0.3600(0.3504) Steps 820(822.09) | Grad Norm 1.8179(2.7458) | Total Time 14.00(14.00)\n",
      "Iter 3224 | Time 74.3046(74.8006) | Bit/dim 3.8779(3.8749) | Xent 0.9871(0.9843) | Loss 4.3715(4.3670) | Error 0.3495(0.3504) Steps 826(822.21) | Grad Norm 4.1283(2.7873) | Total Time 14.00(14.00)\n",
      "Iter 3225 | Time 78.1961(74.9025) | Bit/dim 3.8759(3.8749) | Xent 0.9854(0.9843) | Loss 4.3686(4.3671) | Error 0.3561(0.3506) Steps 826(822.32) | Grad Norm 1.2361(2.7408) | Total Time 14.00(14.00)\n",
      "Iter 3226 | Time 78.6575(75.0151) | Bit/dim 3.8716(3.8748) | Xent 0.9827(0.9843) | Loss 4.3630(4.3670) | Error 0.3452(0.3504) Steps 820(822.25) | Grad Norm 4.3426(2.7888) | Total Time 14.00(14.00)\n",
      "Iter 3227 | Time 75.1061(75.0178) | Bit/dim 3.8672(3.8746) | Xent 0.9687(0.9838) | Loss 4.3516(4.3665) | Error 0.3433(0.3502) Steps 820(822.18) | Grad Norm 1.7778(2.7585) | Total Time 14.00(14.00)\n",
      "Iter 3228 | Time 74.5962(75.0052) | Bit/dim 3.8741(3.8746) | Xent 0.9869(0.9839) | Loss 4.3676(4.3665) | Error 0.3550(0.3503) Steps 820(822.12) | Grad Norm 2.8961(2.7626) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0538 | Time 29.7815, Epoch Time 504.5693(499.9812), Bit/dim 3.8746(best: 3.8743), Xent 0.9671, Loss 4.3581, Error 0.3406(best: 0.3388)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3229 | Time 77.1649(75.0700) | Bit/dim 3.8703(3.8744) | Xent 0.9651(0.9834) | Loss 4.3529(4.3661) | Error 0.3450(0.3502) Steps 814(821.88) | Grad Norm 1.3336(2.7197) | Total Time 14.00(14.00)\n",
      "Iter 3230 | Time 75.9947(75.0977) | Bit/dim 3.8733(3.8744) | Xent 0.9820(0.9833) | Loss 4.3643(4.3661) | Error 0.3521(0.3502) Steps 802(821.28) | Grad Norm 3.2829(2.7366) | Total Time 14.00(14.00)\n",
      "Iter 3231 | Time 72.6706(75.0249) | Bit/dim 3.8676(3.8742) | Xent 0.9942(0.9836) | Loss 4.3647(4.3660) | Error 0.3515(0.3503) Steps 820(821.24) | Grad Norm 2.3243(2.7243) | Total Time 14.00(14.00)\n",
      "Iter 3232 | Time 74.7739(75.0174) | Bit/dim 3.8750(3.8742) | Xent 0.9824(0.9836) | Loss 4.3662(4.3660) | Error 0.3501(0.3503) Steps 820(821.20) | Grad Norm 3.2475(2.7400) | Total Time 14.00(14.00)\n",
      "Iter 3233 | Time 74.4490(75.0003) | Bit/dim 3.8749(3.8742) | Xent 0.9769(0.9834) | Loss 4.3634(4.3659) | Error 0.3415(0.3500) Steps 820(821.17) | Grad Norm 2.0641(2.7197) | Total Time 14.00(14.00)\n",
      "Iter 3234 | Time 74.5644(74.9873) | Bit/dim 3.8751(3.8743) | Xent 0.9817(0.9834) | Loss 4.3660(4.3659) | Error 0.3529(0.3501) Steps 820(821.13) | Grad Norm 2.9708(2.7272) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0539 | Time 29.6295, Epoch Time 494.8017(499.8258), Bit/dim 3.8741(best: 3.8743), Xent 0.9649, Loss 4.3565, Error 0.3387(best: 0.3388)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3235 | Time 77.0144(75.0481) | Bit/dim 3.8708(3.8742) | Xent 1.0013(0.9839) | Loss 4.3715(4.3661) | Error 0.3576(0.3503) Steps 820(821.10) | Grad Norm 2.5943(2.7232) | Total Time 14.00(14.00)\n",
      "Iter 3236 | Time 73.6543(75.0063) | Bit/dim 3.8766(3.8742) | Xent 0.9911(0.9841) | Loss 4.3721(4.3663) | Error 0.3499(0.3503) Steps 814(820.89) | Grad Norm 2.1038(2.7047) | Total Time 14.00(14.00)\n",
      "Iter 3237 | Time 74.2925(74.9848) | Bit/dim 3.8719(3.8742) | Xent 0.9941(0.9844) | Loss 4.3690(4.3664) | Error 0.3572(0.3505) Steps 820(820.86) | Grad Norm 1.7352(2.6756) | Total Time 14.00(14.00)\n",
      "Iter 3238 | Time 74.1912(74.9610) | Bit/dim 3.8746(3.8742) | Xent 0.9676(0.9839) | Loss 4.3584(4.3661) | Error 0.3410(0.3502) Steps 820(820.83) | Grad Norm 1.7751(2.6486) | Total Time 14.00(14.00)\n",
      "Iter 3239 | Time 74.1820(74.9377) | Bit/dim 3.8611(3.8738) | Xent 0.9642(0.9833) | Loss 4.3432(4.3654) | Error 0.3471(0.3501) Steps 820(820.81) | Grad Norm 2.7184(2.6506) | Total Time 14.00(14.00)\n",
      "Iter 3240 | Time 74.1692(74.9146) | Bit/dim 3.8723(3.8737) | Xent 0.9836(0.9833) | Loss 4.3641(4.3654) | Error 0.3532(0.3502) Steps 820(820.78) | Grad Norm 1.5279(2.6170) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0540 | Time 29.8140, Epoch Time 492.5485(499.6075), Bit/dim 3.8733(best: 3.8741), Xent 0.9700, Loss 4.3584, Error 0.3417(best: 0.3387)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3241 | Time 74.7429(74.9095) | Bit/dim 3.8746(3.8738) | Xent 0.9973(0.9837) | Loss 4.3732(4.3656) | Error 0.3521(0.3503) Steps 820(820.76) | Grad Norm 3.7328(2.6504) | Total Time 14.00(14.00)\n",
      "Iter 3242 | Time 74.9515(74.9107) | Bit/dim 3.8677(3.8736) | Xent 0.9785(0.9836) | Loss 4.3569(4.3654) | Error 0.3500(0.3503) Steps 826(820.92) | Grad Norm 1.7813(2.6244) | Total Time 14.00(14.00)\n",
      "Iter 3243 | Time 76.6393(74.9626) | Bit/dim 3.8728(3.8736) | Xent 1.0049(0.9842) | Loss 4.3752(4.3657) | Error 0.3608(0.3506) Steps 820(820.89) | Grad Norm 2.3419(2.6159) | Total Time 14.00(14.00)\n",
      "Iter 3244 | Time 74.0074(74.9339) | Bit/dim 3.8629(3.8732) | Xent 0.9721(0.9839) | Loss 4.3490(4.3652) | Error 0.3425(0.3504) Steps 820(820.86) | Grad Norm 1.3254(2.5772) | Total Time 14.00(14.00)\n",
      "Iter 3245 | Time 71.6006(74.8339) | Bit/dim 3.8679(3.8731) | Xent 0.9535(0.9830) | Loss 4.3446(4.3646) | Error 0.3409(0.3501) Steps 814(820.66) | Grad Norm 3.3931(2.6017) | Total Time 14.00(14.00)\n",
      "Iter 3246 | Time 72.9349(74.7770) | Bit/dim 3.8801(3.8733) | Xent 0.9828(0.9829) | Loss 4.3715(4.3648) | Error 0.3506(0.3501) Steps 820(820.64) | Grad Norm 1.9469(2.5820) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0541 | Time 30.2992, Epoch Time 490.5714(499.3364), Bit/dim 3.8734(best: 3.8733), Xent 0.9709, Loss 4.3589, Error 0.3429(best: 0.3387)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3247 | Time 74.6858(74.7742) | Bit/dim 3.8728(3.8733) | Xent 0.9847(0.9830) | Loss 4.3652(4.3648) | Error 0.3560(0.3503) Steps 814(820.44) | Grad Norm 3.7552(2.6172) | Total Time 14.00(14.00)\n",
      "Iter 3248 | Time 74.5855(74.7686) | Bit/dim 3.8707(3.8732) | Xent 0.9836(0.9830) | Loss 4.3625(4.3647) | Error 0.3456(0.3501) Steps 802(819.89) | Grad Norm 3.5873(2.6463) | Total Time 14.00(14.00)\n",
      "Iter 3249 | Time 75.8534(74.8011) | Bit/dim 3.8718(3.8732) | Xent 0.9736(0.9827) | Loss 4.3586(4.3645) | Error 0.3508(0.3501) Steps 820(819.89) | Grad Norm 2.6576(2.6466) | Total Time 14.00(14.00)\n",
      "Iter 3250 | Time 75.4744(74.8213) | Bit/dim 3.8664(3.8730) | Xent 0.9862(0.9828) | Loss 4.3595(4.3644) | Error 0.3526(0.3502) Steps 814(819.71) | Grad Norm 4.0257(2.6880) | Total Time 14.00(14.00)\n",
      "Iter 3251 | Time 73.6632(74.7866) | Bit/dim 3.8785(3.8731) | Xent 0.9798(0.9828) | Loss 4.3684(4.3645) | Error 0.3459(0.3501) Steps 814(819.54) | Grad Norm 2.2273(2.6742) | Total Time 14.00(14.00)\n",
      "Iter 3252 | Time 72.8124(74.7273) | Bit/dim 3.8676(3.8730) | Xent 0.9754(0.9825) | Loss 4.3554(4.3642) | Error 0.3445(0.3499) Steps 820(819.55) | Grad Norm 3.1426(2.6883) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0542 | Time 29.6019, Epoch Time 492.3143(499.1257), Bit/dim 3.8716(best: 3.8733), Xent 0.9669, Loss 4.3551, Error 0.3432(best: 0.3387)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3253 | Time 74.0916(74.7083) | Bit/dim 3.8613(3.8726) | Xent 0.9896(0.9827) | Loss 4.3561(4.3640) | Error 0.3530(0.3500) Steps 814(819.39) | Grad Norm 1.7763(2.6609) | Total Time 14.00(14.00)\n",
      "Iter 3254 | Time 73.9218(74.6847) | Bit/dim 3.8702(3.8725) | Xent 0.9679(0.9823) | Loss 4.3541(4.3637) | Error 0.3430(0.3498) Steps 814(819.23) | Grad Norm 2.5925(2.6588) | Total Time 14.00(14.00)\n",
      "Iter 3255 | Time 75.3180(74.7037) | Bit/dim 3.8707(3.8725) | Xent 0.9771(0.9821) | Loss 4.3593(4.3635) | Error 0.3561(0.3500) Steps 820(819.25) | Grad Norm 2.1421(2.6433) | Total Time 14.00(14.00)\n",
      "Iter 3256 | Time 72.5807(74.6400) | Bit/dim 3.8733(3.8725) | Xent 0.9659(0.9817) | Loss 4.3563(4.3633) | Error 0.3373(0.3496) Steps 826(819.45) | Grad Norm 2.1057(2.6272) | Total Time 14.00(14.00)\n",
      "Iter 3257 | Time 74.4951(74.6356) | Bit/dim 3.8666(3.8723) | Xent 0.9906(0.9819) | Loss 4.3618(4.3633) | Error 0.3534(0.3497) Steps 814(819.29) | Grad Norm 1.9678(2.6074) | Total Time 14.00(14.00)\n",
      "Iter 3258 | Time 74.3242(74.6263) | Bit/dim 3.8780(3.8725) | Xent 0.9673(0.9815) | Loss 4.3616(4.3632) | Error 0.3438(0.3495) Steps 820(819.31) | Grad Norm 2.0843(2.5917) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0543 | Time 29.8919, Epoch Time 490.1050(498.8551), Bit/dim 3.8725(best: 3.8716), Xent 0.9646, Loss 4.3547, Error 0.3367(best: 0.3387)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3259 | Time 75.2619(74.6454) | Bit/dim 3.8665(3.8723) | Xent 0.9721(0.9812) | Loss 4.3526(4.3629) | Error 0.3474(0.3495) Steps 820(819.33) | Grad Norm 1.7508(2.5665) | Total Time 14.00(14.00)\n",
      "Iter 3260 | Time 76.2521(74.6936) | Bit/dim 3.8664(3.8721) | Xent 0.9587(0.9805) | Loss 4.3458(4.3624) | Error 0.3399(0.3492) Steps 832(819.71) | Grad Norm 2.4604(2.5633) | Total Time 14.00(14.00)\n",
      "Iter 3261 | Time 74.3500(74.6833) | Bit/dim 3.8673(3.8720) | Xent 0.9775(0.9804) | Loss 4.3561(4.3622) | Error 0.3509(0.3492) Steps 820(819.72) | Grad Norm 2.8682(2.5725) | Total Time 14.00(14.00)\n",
      "Iter 3262 | Time 75.2870(74.7014) | Bit/dim 3.8794(3.8722) | Xent 0.9972(0.9809) | Loss 4.3780(4.3627) | Error 0.3531(0.3494) Steps 820(819.73) | Grad Norm 3.6280(2.6041) | Total Time 14.00(14.00)\n",
      "Iter 3263 | Time 74.7739(74.7035) | Bit/dim 3.8673(3.8721) | Xent 0.9858(0.9811) | Loss 4.3602(4.3626) | Error 0.3481(0.3493) Steps 820(819.74) | Grad Norm 1.7350(2.5781) | Total Time 14.00(14.00)\n",
      "Iter 3264 | Time 72.9930(74.6522) | Bit/dim 3.8795(3.8723) | Xent 0.9661(0.9806) | Loss 4.3625(4.3626) | Error 0.3394(0.3490) Steps 814(819.56) | Grad Norm 2.5850(2.5783) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0544 | Time 30.0519, Epoch Time 494.3558(498.7201), Bit/dim 3.8727(best: 3.8716), Xent 0.9633, Loss 4.3544, Error 0.3396(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3265 | Time 73.8943(74.6295) | Bit/dim 3.8575(3.8718) | Xent 0.9668(0.9802) | Loss 4.3410(4.3620) | Error 0.3395(0.3487) Steps 820(819.58) | Grad Norm 1.6148(2.5494) | Total Time 14.00(14.00)\n",
      "Iter 3266 | Time 73.7274(74.6024) | Bit/dim 3.8708(3.8718) | Xent 0.9782(0.9802) | Loss 4.3599(4.3619) | Error 0.3529(0.3489) Steps 820(819.59) | Grad Norm 3.0896(2.5656) | Total Time 14.00(14.00)\n",
      "Iter 3267 | Time 74.0358(74.5854) | Bit/dim 3.8736(3.8719) | Xent 0.9850(0.9803) | Loss 4.3661(4.3620) | Error 0.3519(0.3490) Steps 820(819.60) | Grad Norm 2.2102(2.5549) | Total Time 14.00(14.00)\n",
      "Iter 3268 | Time 75.7808(74.6213) | Bit/dim 3.8711(3.8718) | Xent 0.9834(0.9804) | Loss 4.3628(4.3620) | Error 0.3468(0.3489) Steps 820(819.61) | Grad Norm 3.9464(2.5967) | Total Time 14.00(14.00)\n",
      "Iter 3269 | Time 75.5316(74.6486) | Bit/dim 3.8794(3.8721) | Xent 0.9800(0.9804) | Loss 4.3694(4.3623) | Error 0.3486(0.3489) Steps 820(819.63) | Grad Norm 3.5781(2.6261) | Total Time 14.00(14.00)\n",
      "Iter 3270 | Time 74.4605(74.6430) | Bit/dim 3.8702(3.8720) | Xent 0.9810(0.9804) | Loss 4.3607(4.3622) | Error 0.3436(0.3487) Steps 814(819.46) | Grad Norm 3.4057(2.6495) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0545 | Time 29.4004, Epoch Time 492.3813(498.5300), Bit/dim 3.8729(best: 3.8716), Xent 0.9612, Loss 4.3535, Error 0.3387(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3271 | Time 75.2488(74.6611) | Bit/dim 3.8824(3.8723) | Xent 0.9671(0.9800) | Loss 4.3659(4.3623) | Error 0.3429(0.3485) Steps 820(819.47) | Grad Norm 2.4829(2.6445) | Total Time 14.00(14.00)\n",
      "Iter 3272 | Time 73.3028(74.6204) | Bit/dim 3.8700(3.8723) | Xent 0.9805(0.9800) | Loss 4.3602(4.3623) | Error 0.3495(0.3486) Steps 820(819.49) | Grad Norm 0.9870(2.5948) | Total Time 14.00(14.00)\n",
      "Iter 3273 | Time 74.8444(74.6271) | Bit/dim 3.8738(3.8723) | Xent 1.0001(0.9806) | Loss 4.3738(4.3626) | Error 0.3524(0.3487) Steps 820(819.50) | Grad Norm 4.9068(2.6641) | Total Time 14.00(14.00)\n",
      "Iter 3274 | Time 77.1937(74.7041) | Bit/dim 3.8607(3.8720) | Xent 0.9500(0.9797) | Loss 4.3357(4.3618) | Error 0.3375(0.3484) Steps 814(819.34) | Grad Norm 1.3649(2.6252) | Total Time 14.00(14.00)\n",
      "Iter 3275 | Time 77.1904(74.7787) | Bit/dim 3.8699(3.8719) | Xent 0.9698(0.9794) | Loss 4.3549(4.3616) | Error 0.3413(0.3481) Steps 820(819.36) | Grad Norm 5.0837(2.6989) | Total Time 14.00(14.00)\n",
      "Iter 3276 | Time 73.0041(74.7254) | Bit/dim 3.8604(3.8716) | Xent 0.9831(0.9795) | Loss 4.3520(4.3613) | Error 0.3534(0.3483) Steps 826(819.56) | Grad Norm 1.7389(2.6701) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0546 | Time 29.9766, Epoch Time 496.2952(498.4629), Bit/dim 3.8714(best: 3.8716), Xent 0.9709, Loss 4.3568, Error 0.3425(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3277 | Time 74.7356(74.7258) | Bit/dim 3.8677(3.8714) | Xent 0.9766(0.9794) | Loss 4.3560(4.3612) | Error 0.3452(0.3482) Steps 820(819.57) | Grad Norm 4.3177(2.7195) | Total Time 14.00(14.00)\n",
      "Iter 3278 | Time 75.2044(74.7401) | Bit/dim 3.8691(3.8714) | Xent 0.9754(0.9793) | Loss 4.3568(4.3610) | Error 0.3472(0.3482) Steps 826(819.76) | Grad Norm 3.1143(2.7314) | Total Time 14.00(14.00)\n",
      "Iter 3279 | Time 77.5230(74.8236) | Bit/dim 3.8612(3.8711) | Xent 0.9634(0.9788) | Loss 4.3429(4.3605) | Error 0.3436(0.3480) Steps 832(820.13) | Grad Norm 6.5025(2.8445) | Total Time 14.00(14.00)\n",
      "Iter 3280 | Time 73.6692(74.7890) | Bit/dim 3.8784(3.8713) | Xent 0.9992(0.9794) | Loss 4.3780(4.3610) | Error 0.3561(0.3483) Steps 814(819.95) | Grad Norm 1.6870(2.8098) | Total Time 14.00(14.00)\n",
      "Iter 3281 | Time 72.5225(74.7210) | Bit/dim 3.8647(3.8711) | Xent 0.9776(0.9794) | Loss 4.3534(4.3608) | Error 0.3462(0.3482) Steps 820(819.95) | Grad Norm 4.1808(2.8509) | Total Time 14.00(14.00)\n",
      "Iter 3282 | Time 77.3128(74.7987) | Bit/dim 3.8751(3.8712) | Xent 0.9858(0.9796) | Loss 4.3680(4.3610) | Error 0.3545(0.3484) Steps 820(819.95) | Grad Norm 3.3730(2.8666) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0547 | Time 29.8102, Epoch Time 496.2043(498.3952), Bit/dim 3.8716(best: 3.8714), Xent 0.9655, Loss 4.3543, Error 0.3402(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3283 | Time 75.9330(74.8328) | Bit/dim 3.8694(3.8711) | Xent 0.9889(0.9799) | Loss 4.3639(4.3611) | Error 0.3506(0.3485) Steps 820(819.95) | Grad Norm 3.5956(2.8884) | Total Time 14.00(14.00)\n",
      "Iter 3284 | Time 75.7179(74.8593) | Bit/dim 3.8567(3.8707) | Xent 0.9676(0.9795) | Loss 4.3405(4.3605) | Error 0.3386(0.3482) Steps 814(819.77) | Grad Norm 4.4277(2.9346) | Total Time 14.00(14.00)\n",
      "Iter 3285 | Time 75.2633(74.8714) | Bit/dim 3.8729(3.8708) | Xent 0.9833(0.9796) | Loss 4.3645(4.3606) | Error 0.3530(0.3483) Steps 814(819.60) | Grad Norm 3.2399(2.9438) | Total Time 14.00(14.00)\n",
      "Iter 3286 | Time 74.9962(74.8752) | Bit/dim 3.8724(3.8708) | Xent 0.9771(0.9795) | Loss 4.3610(4.3606) | Error 0.3470(0.3483) Steps 820(819.61) | Grad Norm 5.2983(3.0144) | Total Time 14.00(14.00)\n",
      "Iter 3287 | Time 77.0879(74.9416) | Bit/dim 3.8728(3.8709) | Xent 0.9722(0.9793) | Loss 4.3589(4.3605) | Error 0.3458(0.3482) Steps 814(819.44) | Grad Norm 4.1591(3.0488) | Total Time 14.00(14.00)\n",
      "Iter 3288 | Time 74.0046(74.9134) | Bit/dim 3.8744(3.8710) | Xent 0.9934(0.9797) | Loss 4.3711(4.3609) | Error 0.3531(0.3484) Steps 814(819.28) | Grad Norm 5.1580(3.1120) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0548 | Time 29.5985, Epoch Time 497.8239(498.3780), Bit/dim 3.8710(best: 3.8714), Xent 0.9800, Loss 4.3610, Error 0.3505(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3289 | Time 72.9059(74.8532) | Bit/dim 3.8657(3.8708) | Xent 1.0015(0.9804) | Loss 4.3664(4.3610) | Error 0.3556(0.3486) Steps 820(819.30) | Grad Norm 4.6124(3.1570) | Total Time 14.00(14.00)\n",
      "Iter 3290 | Time 75.1500(74.8621) | Bit/dim 3.8650(3.8707) | Xent 0.9977(0.9809) | Loss 4.3638(4.3611) | Error 0.3558(0.3488) Steps 820(819.32) | Grad Norm 4.4320(3.1953) | Total Time 14.00(14.00)\n",
      "Iter 3291 | Time 76.2010(74.9023) | Bit/dim 3.8754(3.8708) | Xent 0.9811(0.9809) | Loss 4.3659(4.3613) | Error 0.3476(0.3488) Steps 820(819.34) | Grad Norm 4.3546(3.2301) | Total Time 14.00(14.00)\n",
      "Iter 3292 | Time 73.4651(74.8592) | Bit/dim 3.8741(3.8709) | Xent 0.9632(0.9804) | Loss 4.3557(4.3611) | Error 0.3479(0.3487) Steps 820(819.36) | Grad Norm 4.2394(3.2604) | Total Time 14.00(14.00)\n",
      "Iter 3293 | Time 72.4742(74.7876) | Bit/dim 3.8635(3.8707) | Xent 0.9864(0.9806) | Loss 4.3566(4.3610) | Error 0.3546(0.3489) Steps 820(819.38) | Grad Norm 4.0183(3.2831) | Total Time 14.00(14.00)\n",
      "Iter 3294 | Time 74.3173(74.7735) | Bit/dim 3.8738(3.8708) | Xent 0.9825(0.9806) | Loss 4.3651(4.3611) | Error 0.3542(0.3491) Steps 820(819.40) | Grad Norm 2.7370(3.2667) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0549 | Time 29.5952, Epoch Time 489.5690(498.1138), Bit/dim 3.8716(best: 3.8710), Xent 0.9644, Loss 4.3538, Error 0.3385(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3295 | Time 76.8371(74.8354) | Bit/dim 3.8700(3.8707) | Xent 0.9701(0.9803) | Loss 4.3550(4.3609) | Error 0.3454(0.3490) Steps 826(819.60) | Grad Norm 2.9612(3.2575) | Total Time 14.00(14.00)\n",
      "Iter 3296 | Time 74.2954(74.8192) | Bit/dim 3.8723(3.8708) | Xent 0.9879(0.9805) | Loss 4.3663(4.3611) | Error 0.3499(0.3490) Steps 820(819.61) | Grad Norm 2.2172(3.2263) | Total Time 14.00(14.00)\n",
      "Iter 3297 | Time 73.5066(74.7798) | Bit/dim 3.8699(3.8708) | Xent 0.9670(0.9801) | Loss 4.3534(4.3608) | Error 0.3442(0.3488) Steps 814(819.44) | Grad Norm 2.7182(3.2111) | Total Time 14.00(14.00)\n",
      "Iter 3298 | Time 72.4426(74.7097) | Bit/dim 3.8687(3.8707) | Xent 0.9984(0.9807) | Loss 4.3679(4.3610) | Error 0.3526(0.3490) Steps 826(819.64) | Grad Norm 2.3627(3.1856) | Total Time 14.00(14.00)\n",
      "Iter 3299 | Time 74.4297(74.7013) | Bit/dim 3.8600(3.8704) | Xent 0.9767(0.9805) | Loss 4.3483(4.3607) | Error 0.3420(0.3487) Steps 820(819.65) | Grad Norm 2.5586(3.1668) | Total Time 14.00(14.00)\n",
      "Iter 3300 | Time 72.6566(74.6400) | Bit/dim 3.8746(3.8705) | Xent 0.9754(0.9804) | Loss 4.3623(4.3607) | Error 0.3472(0.3487) Steps 814(819.48) | Grad Norm 2.4687(3.1459) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0550 | Time 29.9354, Epoch Time 489.6491(497.8598), Bit/dim 3.8702(best: 3.8710), Xent 0.9677, Loss 4.3540, Error 0.3413(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3301 | Time 73.5932(74.6086) | Bit/dim 3.8758(3.8707) | Xent 0.9636(0.9799) | Loss 4.3576(4.3606) | Error 0.3365(0.3483) Steps 820(819.50) | Grad Norm 3.2927(3.1503) | Total Time 14.00(14.00)\n",
      "Iter 3302 | Time 74.6788(74.6107) | Bit/dim 3.8722(3.8707) | Xent 0.9713(0.9796) | Loss 4.3579(4.3605) | Error 0.3495(0.3484) Steps 802(818.97) | Grad Norm 1.7976(3.1097) | Total Time 14.00(14.00)\n",
      "Iter 3303 | Time 74.0913(74.5951) | Bit/dim 3.8721(3.8708) | Xent 0.9686(0.9793) | Loss 4.3564(4.3604) | Error 0.3399(0.3481) Steps 820(819.00) | Grad Norm 2.6690(3.0965) | Total Time 14.00(14.00)\n",
      "Iter 3304 | Time 76.3248(74.6470) | Bit/dim 3.8661(3.8706) | Xent 0.9926(0.9797) | Loss 4.3624(4.3605) | Error 0.3468(0.3481) Steps 820(819.03) | Grad Norm 2.2595(3.0714) | Total Time 14.00(14.00)\n",
      "Iter 3305 | Time 72.2483(74.5750) | Bit/dim 3.8706(3.8706) | Xent 0.9708(0.9794) | Loss 4.3560(4.3603) | Error 0.3410(0.3479) Steps 820(819.06) | Grad Norm 1.9577(3.0380) | Total Time 14.00(14.00)\n",
      "Iter 3306 | Time 73.1846(74.5333) | Bit/dim 3.8561(3.8702) | Xent 0.9695(0.9791) | Loss 4.3409(4.3597) | Error 0.3459(0.3478) Steps 814(818.91) | Grad Norm 1.6516(2.9964) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0551 | Time 29.9517, Epoch Time 489.6591(497.6138), Bit/dim 3.8709(best: 3.8702), Xent 0.9636, Loss 4.3527, Error 0.3390(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3307 | Time 73.9201(74.5149) | Bit/dim 3.8619(3.8699) | Xent 0.9586(0.9785) | Loss 4.3412(4.3592) | Error 0.3423(0.3476) Steps 820(818.94) | Grad Norm 3.3256(3.0063) | Total Time 14.00(14.00)\n",
      "Iter 3308 | Time 75.4798(74.5439) | Bit/dim 3.8632(3.8697) | Xent 0.9792(0.9785) | Loss 4.3528(4.3590) | Error 0.3476(0.3476) Steps 820(818.97) | Grad Norm 2.0739(2.9783) | Total Time 14.00(14.00)\n",
      "Iter 3309 | Time 74.6788(74.5479) | Bit/dim 3.8685(3.8697) | Xent 0.9814(0.9786) | Loss 4.3592(4.3590) | Error 0.3532(0.3478) Steps 820(819.00) | Grad Norm 5.1299(3.0428) | Total Time 14.00(14.00)\n",
      "Iter 3310 | Time 73.7436(74.5238) | Bit/dim 3.8730(3.8698) | Xent 0.9701(0.9784) | Loss 4.3581(4.3590) | Error 0.3405(0.3476) Steps 820(819.03) | Grad Norm 2.2358(3.0186) | Total Time 14.00(14.00)\n",
      "Iter 3311 | Time 76.1792(74.5735) | Bit/dim 3.8647(3.8696) | Xent 0.9748(0.9783) | Loss 4.3521(4.3588) | Error 0.3515(0.3477) Steps 820(819.06) | Grad Norm 4.2314(3.0550) | Total Time 14.00(14.00)\n",
      "Iter 3312 | Time 77.3029(74.6553) | Bit/dim 3.8789(3.8699) | Xent 0.9707(0.9780) | Loss 4.3642(4.3589) | Error 0.3471(0.3477) Steps 826(819.27) | Grad Norm 2.7410(3.0456) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0552 | Time 29.6667, Epoch Time 496.6567(497.5851), Bit/dim 3.8697(best: 3.8702), Xent 0.9631, Loss 4.3513, Error 0.3370(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3313 | Time 72.8726(74.6019) | Bit/dim 3.8696(3.8699) | Xent 0.9865(0.9783) | Loss 4.3629(4.3591) | Error 0.3484(0.3477) Steps 820(819.29) | Grad Norm 4.6429(3.0935) | Total Time 14.00(14.00)\n",
      "Iter 3314 | Time 74.1274(74.5876) | Bit/dim 3.8791(3.8702) | Xent 0.9766(0.9782) | Loss 4.3674(4.3593) | Error 0.3476(0.3477) Steps 820(819.31) | Grad Norm 2.2285(3.0676) | Total Time 14.00(14.00)\n",
      "Iter 3315 | Time 75.8987(74.6270) | Bit/dim 3.8694(3.8702) | Xent 0.9863(0.9785) | Loss 4.3626(4.3594) | Error 0.3480(0.3477) Steps 820(819.34) | Grad Norm 4.2363(3.1026) | Total Time 14.00(14.00)\n",
      "Iter 3316 | Time 72.1147(74.5516) | Bit/dim 3.8661(3.8700) | Xent 0.9820(0.9786) | Loss 4.3571(4.3593) | Error 0.3482(0.3477) Steps 814(819.17) | Grad Norm 4.7869(3.1531) | Total Time 14.00(14.00)\n",
      "Iter 3317 | Time 75.2487(74.5725) | Bit/dim 3.8644(3.8699) | Xent 0.9637(0.9781) | Loss 4.3463(4.3589) | Error 0.3480(0.3477) Steps 814(819.02) | Grad Norm 2.3410(3.1288) | Total Time 14.00(14.00)\n",
      "Iter 3318 | Time 73.7654(74.5483) | Bit/dim 3.8589(3.8695) | Xent 0.9705(0.9779) | Loss 4.3441(4.3585) | Error 0.3442(0.3476) Steps 820(819.05) | Grad Norm 3.8004(3.1489) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0553 | Time 29.8868, Epoch Time 489.4635(497.3414), Bit/dim 3.8692(best: 3.8697), Xent 0.9624, Loss 4.3504, Error 0.3364(best: 0.3367)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3319 | Time 74.3191(74.5414) | Bit/dim 3.8643(3.8694) | Xent 0.9568(0.9773) | Loss 4.3427(4.3580) | Error 0.3384(0.3474) Steps 802(818.54) | Grad Norm 2.8493(3.1399) | Total Time 14.00(14.00)\n",
      "Iter 3320 | Time 74.1072(74.5284) | Bit/dim 3.8735(3.8695) | Xent 0.9692(0.9770) | Loss 4.3581(4.3580) | Error 0.3424(0.3472) Steps 820(818.58) | Grad Norm 4.3884(3.1774) | Total Time 14.00(14.00)\n",
      "Iter 3321 | Time 74.6387(74.5317) | Bit/dim 3.8725(3.8696) | Xent 0.9816(0.9772) | Loss 4.3633(4.3582) | Error 0.3565(0.3475) Steps 802(818.08) | Grad Norm 4.1271(3.2059) | Total Time 14.00(14.00)\n",
      "Iter 3322 | Time 74.5630(74.5326) | Bit/dim 3.8607(3.8693) | Xent 0.9801(0.9773) | Loss 4.3508(4.3580) | Error 0.3461(0.3474) Steps 820(818.14) | Grad Norm 3.7450(3.2221) | Total Time 14.00(14.00)\n",
      "Iter 3323 | Time 73.9188(74.5142) | Bit/dim 3.8715(3.8694) | Xent 0.9980(0.9779) | Loss 4.3705(4.3583) | Error 0.3548(0.3477) Steps 820(818.20) | Grad Norm 4.6466(3.2648) | Total Time 14.00(14.00)\n",
      "Iter 3324 | Time 76.0024(74.5589) | Bit/dim 3.8650(3.8693) | Xent 0.9719(0.9777) | Loss 4.3509(4.3581) | Error 0.3452(0.3476) Steps 820(818.25) | Grad Norm 2.3273(3.2367) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0554 | Time 29.8556, Epoch Time 492.9758(497.2105), Bit/dim 3.8694(best: 3.8692), Xent 0.9692, Loss 4.3539, Error 0.3432(best: 0.3364)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3325 | Time 73.3885(74.5238) | Bit/dim 3.8644(3.8691) | Xent 0.9830(0.9779) | Loss 4.3559(4.3581) | Error 0.3479(0.3476) Steps 820(818.30) | Grad Norm 4.3171(3.2691) | Total Time 14.00(14.00)\n",
      "Iter 3326 | Time 76.4546(74.5817) | Bit/dim 3.8583(3.8688) | Xent 0.9689(0.9776) | Loss 4.3428(4.3576) | Error 0.3462(0.3476) Steps 820(818.35) | Grad Norm 2.2065(3.2372) | Total Time 14.00(14.00)\n",
      "Iter 3327 | Time 71.7736(74.4974) | Bit/dim 3.8591(3.8685) | Xent 0.9641(0.9772) | Loss 4.3412(4.3571) | Error 0.3471(0.3475) Steps 820(818.40) | Grad Norm 2.8109(3.2244) | Total Time 14.00(14.00)\n",
      "Iter 3328 | Time 72.9264(74.4503) | Bit/dim 3.8732(3.8686) | Xent 0.9749(0.9771) | Loss 4.3606(4.3572) | Error 0.3430(0.3474) Steps 820(818.45) | Grad Norm 1.4999(3.1727) | Total Time 14.00(14.00)\n",
      "Iter 3329 | Time 73.2525(74.4144) | Bit/dim 3.8649(3.8685) | Xent 0.9746(0.9770) | Loss 4.3522(4.3571) | Error 0.3454(0.3473) Steps 820(818.50) | Grad Norm 2.7001(3.1585) | Total Time 14.00(14.00)\n",
      "Iter 3330 | Time 75.8430(74.4572) | Bit/dim 3.8801(3.8689) | Xent 0.9906(0.9774) | Loss 4.3754(4.3576) | Error 0.3535(0.3475) Steps 820(818.54) | Grad Norm 1.6445(3.1131) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0555 | Time 29.7050, Epoch Time 488.7319(496.9561), Bit/dim 3.8681(best: 3.8692), Xent 0.9599, Loss 4.3480, Error 0.3392(best: 0.3364)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3331 | Time 73.2131(74.4199) | Bit/dim 3.8572(3.8685) | Xent 0.9764(0.9774) | Loss 4.3454(4.3572) | Error 0.3440(0.3474) Steps 820(818.59) | Grad Norm 3.5604(3.1265) | Total Time 14.00(14.00)\n",
      "Iter 3332 | Time 73.7742(74.4005) | Bit/dim 3.8701(3.8686) | Xent 0.9625(0.9770) | Loss 4.3514(4.3571) | Error 0.3401(0.3472) Steps 826(818.81) | Grad Norm 2.8011(3.1167) | Total Time 14.00(14.00)\n",
      "Iter 3333 | Time 72.5090(74.3438) | Bit/dim 3.8709(3.8686) | Xent 0.9800(0.9771) | Loss 4.3609(4.3572) | Error 0.3491(0.3473) Steps 820(818.85) | Grad Norm 4.7609(3.1661) | Total Time 14.00(14.00)\n",
      "Iter 3334 | Time 75.2620(74.3713) | Bit/dim 3.8682(3.8686) | Xent 0.9743(0.9770) | Loss 4.3553(4.3571) | Error 0.3520(0.3474) Steps 814(818.70) | Grad Norm 2.5100(3.1464) | Total Time 14.00(14.00)\n",
      "Iter 3335 | Time 75.0510(74.3917) | Bit/dim 3.8644(3.8685) | Xent 0.9937(0.9775) | Loss 4.3612(4.3572) | Error 0.3550(0.3476) Steps 820(818.74) | Grad Norm 3.8075(3.1662) | Total Time 14.00(14.00)\n",
      "Iter 3336 | Time 74.0030(74.3801) | Bit/dim 3.8666(3.8684) | Xent 0.9602(0.9770) | Loss 4.3466(4.3569) | Error 0.3420(0.3475) Steps 814(818.60) | Grad Norm 4.2855(3.1998) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0556 | Time 29.3158, Epoch Time 488.6225(496.7061), Bit/dim 3.8687(best: 3.8681), Xent 0.9584, Loss 4.3478, Error 0.3371(best: 0.3364)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3337 | Time 73.6564(74.3584) | Bit/dim 3.8705(3.8685) | Xent 0.9752(0.9769) | Loss 4.3581(4.3570) | Error 0.3430(0.3473) Steps 820(818.64) | Grad Norm 2.6925(3.1846) | Total Time 14.00(14.00)\n",
      "Iter 3338 | Time 72.7564(74.3103) | Bit/dim 3.8732(3.8686) | Xent 0.9780(0.9769) | Loss 4.3622(4.3571) | Error 0.3471(0.3473) Steps 814(818.50) | Grad Norm 2.5706(3.1662) | Total Time 14.00(14.00)\n",
      "Iter 3339 | Time 72.2610(74.2488) | Bit/dim 3.8561(3.8683) | Xent 0.9748(0.9769) | Loss 4.3435(4.3567) | Error 0.3449(0.3473) Steps 820(818.54) | Grad Norm 2.0166(3.1317) | Total Time 14.00(14.00)\n",
      "Iter 3340 | Time 75.1490(74.2758) | Bit/dim 3.8586(3.8680) | Xent 0.9632(0.9765) | Loss 4.3402(4.3562) | Error 0.3406(0.3471) Steps 820(818.59) | Grad Norm 2.4497(3.1112) | Total Time 14.00(14.00)\n",
      "Iter 3341 | Time 75.4627(74.3114) | Bit/dim 3.8729(3.8681) | Xent 0.9813(0.9766) | Loss 4.3635(4.3564) | Error 0.3514(0.3472) Steps 820(818.63) | Grad Norm 1.5812(3.0653) | Total Time 14.00(14.00)\n",
      "Iter 3342 | Time 76.9379(74.3902) | Bit/dim 3.8681(3.8681) | Xent 0.9540(0.9759) | Loss 4.3452(4.3561) | Error 0.3379(0.3469) Steps 802(818.13) | Grad Norm 2.2178(3.0399) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0557 | Time 29.6182, Epoch Time 491.4040(496.5470), Bit/dim 3.8671(best: 3.8681), Xent 0.9597, Loss 4.3470, Error 0.3386(best: 0.3364)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3343 | Time 72.7324(74.3405) | Bit/dim 3.8820(3.8685) | Xent 0.9564(0.9753) | Loss 4.3602(4.3562) | Error 0.3400(0.3467) Steps 820(818.19) | Grad Norm 1.5324(2.9947) | Total Time 14.00(14.00)\n",
      "Iter 3344 | Time 75.2985(74.3692) | Bit/dim 3.8715(3.8686) | Xent 0.9722(0.9753) | Loss 4.3576(4.3563) | Error 0.3426(0.3466) Steps 820(818.24) | Grad Norm 2.5782(2.9822) | Total Time 14.00(14.00)\n",
      "Iter 3345 | Time 75.0661(74.3901) | Bit/dim 3.8582(3.8683) | Xent 0.9585(0.9748) | Loss 4.3375(4.3557) | Error 0.3431(0.3465) Steps 802(817.75) | Grad Norm 1.9392(2.9509) | Total Time 14.00(14.00)\n",
      "Iter 3346 | Time 73.1604(74.3532) | Bit/dim 3.8564(3.8680) | Xent 0.9631(0.9744) | Loss 4.3380(4.3552) | Error 0.3458(0.3464) Steps 820(817.82) | Grad Norm 2.6019(2.9404) | Total Time 14.00(14.00)\n",
      "Iter 3347 | Time 72.2093(74.2889) | Bit/dim 3.8600(3.8677) | Xent 0.9725(0.9743) | Loss 4.3462(4.3549) | Error 0.3441(0.3464) Steps 820(817.89) | Grad Norm 1.5264(2.8980) | Total Time 14.00(14.00)\n",
      "Iter 3348 | Time 72.2732(74.2285) | Bit/dim 3.8696(3.8678) | Xent 1.0041(0.9752) | Loss 4.3717(4.3554) | Error 0.3556(0.3467) Steps 820(817.95) | Grad Norm 4.6388(2.9502) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0558 | Time 29.6530, Epoch Time 485.7220(496.2223), Bit/dim 3.8669(best: 3.8671), Xent 0.9596, Loss 4.3467, Error 0.3392(best: 0.3364)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3349 | Time 71.3847(74.1431) | Bit/dim 3.8633(3.8676) | Xent 0.9623(0.9748) | Loss 4.3445(4.3551) | Error 0.3431(0.3466) Steps 814(817.83) | Grad Norm 2.9130(2.9491) | Total Time 14.00(14.00)\n",
      "Iter 3350 | Time 74.3253(74.1486) | Bit/dim 3.8719(3.8678) | Xent 0.9868(0.9752) | Loss 4.3653(4.3554) | Error 0.3492(0.3466) Steps 814(817.72) | Grad Norm 4.3615(2.9915) | Total Time 14.00(14.00)\n",
      "Iter 3351 | Time 74.0467(74.1455) | Bit/dim 3.8645(3.8677) | Xent 0.9897(0.9756) | Loss 4.3593(4.3555) | Error 0.3574(0.3470) Steps 802(817.25) | Grad Norm 2.8157(2.9862) | Total Time 14.00(14.00)\n",
      "Iter 3352 | Time 74.6978(74.1621) | Bit/dim 3.8665(3.8676) | Xent 0.9664(0.9754) | Loss 4.3497(4.3553) | Error 0.3400(0.3467) Steps 802(816.79) | Grad Norm 3.0482(2.9881) | Total Time 14.00(14.00)\n",
      "Iter 3353 | Time 74.3298(74.1671) | Bit/dim 3.8603(3.8674) | Xent 0.9766(0.9754) | Loss 4.3486(4.3551) | Error 0.3488(0.3468) Steps 826(817.06) | Grad Norm 1.3907(2.9401) | Total Time 14.00(14.00)\n",
      "Iter 3354 | Time 75.1031(74.1952) | Bit/dim 3.8687(3.8675) | Xent 0.9730(0.9753) | Loss 4.3552(4.3551) | Error 0.3498(0.3469) Steps 802(816.61) | Grad Norm 2.2281(2.9188) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0559 | Time 29.6953, Epoch Time 489.0534(496.0072), Bit/dim 3.8671(best: 3.8669), Xent 0.9623, Loss 4.3482, Error 0.3381(best: 0.3364)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3355 | Time 73.3324(74.1693) | Bit/dim 3.8679(3.8675) | Xent 0.9610(0.9749) | Loss 4.3484(4.3549) | Error 0.3406(0.3467) Steps 820(816.71) | Grad Norm 2.9288(2.9191) | Total Time 14.00(14.00)\n",
      "Iter 3356 | Time 74.8758(74.1905) | Bit/dim 3.8786(3.8678) | Xent 0.9661(0.9746) | Loss 4.3617(4.3551) | Error 0.3401(0.3465) Steps 820(816.81) | Grad Norm 3.0485(2.9230) | Total Time 14.00(14.00)\n",
      "Iter 3357 | Time 73.3034(74.1639) | Bit/dim 3.8710(3.8679) | Xent 0.9662(0.9744) | Loss 4.3541(4.3551) | Error 0.3508(0.3466) Steps 814(816.73) | Grad Norm 3.1154(2.9287) | Total Time 14.00(14.00)\n",
      "Iter 3358 | Time 75.2805(74.1974) | Bit/dim 3.8584(3.8676) | Xent 0.9859(0.9747) | Loss 4.3514(4.3550) | Error 0.3535(0.3468) Steps 826(817.01) | Grad Norm 2.2154(2.9073) | Total Time 14.00(14.00)\n",
      "Iter 3359 | Time 75.7170(74.2430) | Bit/dim 3.8630(3.8675) | Xent 0.9782(0.9748) | Loss 4.3521(4.3549) | Error 0.3441(0.3468) Steps 820(817.10) | Grad Norm 4.4894(2.9548) | Total Time 14.00(14.00)\n",
      "Iter 3360 | Time 72.9090(74.2030) | Bit/dim 3.8566(3.8672) | Xent 0.9780(0.9749) | Loss 4.3456(4.3546) | Error 0.3491(0.3468) Steps 814(817.00) | Grad Norm 2.8920(2.9529) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0560 | Time 29.6459, Epoch Time 490.4833(495.8415), Bit/dim 3.8671(best: 3.8669), Xent 0.9592, Loss 4.3467, Error 0.3376(best: 0.3364)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3361 | Time 71.8948(74.1337) | Bit/dim 3.8633(3.8670) | Xent 0.9783(0.9750) | Loss 4.3525(4.3546) | Error 0.3454(0.3468) Steps 826(817.27) | Grad Norm 3.2292(2.9612) | Total Time 14.00(14.00)\n",
      "Iter 3362 | Time 75.5921(74.1775) | Bit/dim 3.8591(3.8668) | Xent 0.9806(0.9752) | Loss 4.3494(4.3544) | Error 0.3431(0.3467) Steps 826(817.54) | Grad Norm 3.3074(2.9716) | Total Time 14.00(14.00)\n",
      "Iter 3363 | Time 71.7921(74.1059) | Bit/dim 3.8724(3.8670) | Xent 0.9467(0.9743) | Loss 4.3458(4.3541) | Error 0.3340(0.3463) Steps 820(817.61) | Grad Norm 3.0064(2.9726) | Total Time 14.00(14.00)\n",
      "Iter 3364 | Time 74.2875(74.1114) | Bit/dim 3.8597(3.8667) | Xent 0.9707(0.9742) | Loss 4.3451(4.3539) | Error 0.3436(0.3462) Steps 820(817.68) | Grad Norm 3.2130(2.9798) | Total Time 14.00(14.00)\n",
      "Iter 3365 | Time 74.9787(74.1374) | Bit/dim 3.8700(3.8668) | Xent 0.9708(0.9741) | Loss 4.3554(4.3539) | Error 0.3449(0.3462) Steps 820(817.75) | Grad Norm 3.1512(2.9850) | Total Time 14.00(14.00)\n",
      "Iter 3366 | Time 74.3724(74.1444) | Bit/dim 3.8704(3.8670) | Xent 0.9723(0.9741) | Loss 4.3565(4.3540) | Error 0.3438(0.3461) Steps 820(817.82) | Grad Norm 2.2386(2.9626) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0561 | Time 29.7852, Epoch Time 488.0676(495.6083), Bit/dim 3.8668(best: 3.8669), Xent 0.9601, Loss 4.3469, Error 0.3348(best: 0.3364)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3367 | Time 73.5309(74.1260) | Bit/dim 3.8612(3.8668) | Xent 0.9698(0.9739) | Loss 4.3460(4.3538) | Error 0.3450(0.3461) Steps 820(817.88) | Grad Norm 3.8038(2.9878) | Total Time 14.00(14.00)\n",
      "Iter 3368 | Time 75.1670(74.1573) | Bit/dim 3.8732(3.8670) | Xent 0.9627(0.9736) | Loss 4.3545(4.3538) | Error 0.3440(0.3460) Steps 814(817.77) | Grad Norm 1.3899(2.9399) | Total Time 14.00(14.00)\n",
      "Iter 3369 | Time 74.1227(74.1562) | Bit/dim 3.8703(3.8671) | Xent 0.9903(0.9741) | Loss 4.3654(4.3541) | Error 0.3539(0.3462) Steps 820(817.83) | Grad Norm 3.5063(2.9569) | Total Time 14.00(14.00)\n",
      "Iter 3370 | Time 72.0197(74.0921) | Bit/dim 3.8603(3.8669) | Xent 0.9729(0.9741) | Loss 4.3468(4.3539) | Error 0.3433(0.3462) Steps 826(818.08) | Grad Norm 2.5884(2.9458) | Total Time 14.00(14.00)\n",
      "Iter 3371 | Time 75.0079(74.1196) | Bit/dim 3.8578(3.8666) | Xent 0.9692(0.9739) | Loss 4.3424(4.3536) | Error 0.3492(0.3462) Steps 826(818.32) | Grad Norm 3.4030(2.9595) | Total Time 14.00(14.00)\n",
      "Iter 3372 | Time 70.5897(74.0137) | Bit/dim 3.8743(3.8668) | Xent 0.9809(0.9741) | Loss 4.3647(4.3539) | Error 0.3469(0.3463) Steps 826(818.55) | Grad Norm 3.0430(2.9620) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0562 | Time 29.5070, Epoch Time 485.3335(495.3000), Bit/dim 3.8671(best: 3.8668), Xent 0.9596, Loss 4.3469, Error 0.3341(best: 0.3348)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3373 | Time 71.7656(73.9463) | Bit/dim 3.8582(3.8666) | Xent 0.9574(0.9736) | Loss 4.3369(4.3534) | Error 0.3423(0.3461) Steps 820(818.59) | Grad Norm 2.3440(2.9435) | Total Time 14.00(14.00)\n",
      "Iter 3374 | Time 71.5034(73.8730) | Bit/dim 3.8728(3.8668) | Xent 0.9674(0.9734) | Loss 4.3565(4.3535) | Error 0.3465(0.3462) Steps 820(818.63) | Grad Norm 2.1841(2.9207) | Total Time 14.00(14.00)\n",
      "Iter 3375 | Time 75.4091(73.9191) | Bit/dim 3.8699(3.8669) | Xent 0.9601(0.9730) | Loss 4.3500(4.3534) | Error 0.3403(0.3460) Steps 820(818.67) | Grad Norm 1.5386(2.8793) | Total Time 14.00(14.00)\n",
      "Iter 3376 | Time 74.9061(73.9487) | Bit/dim 3.8601(3.8667) | Xent 1.0027(0.9739) | Loss 4.3615(4.3536) | Error 0.3555(0.3463) Steps 820(818.71) | Grad Norm 3.6520(2.9024) | Total Time 14.00(14.00)\n",
      "Iter 3377 | Time 73.5158(73.9357) | Bit/dim 3.8617(3.8665) | Xent 0.9620(0.9736) | Loss 4.3427(4.3533) | Error 0.3350(0.3459) Steps 820(818.75) | Grad Norm 1.0435(2.8467) | Total Time 14.00(14.00)\n",
      "Iter 3378 | Time 75.7339(73.9896) | Bit/dim 3.8668(3.8665) | Xent 0.9656(0.9733) | Loss 4.3496(4.3532) | Error 0.3452(0.3459) Steps 826(818.97) | Grad Norm 2.9783(2.8506) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0563 | Time 29.1015, Epoch Time 487.6148(495.0695), Bit/dim 3.8661(best: 3.8668), Xent 0.9550, Loss 4.3436, Error 0.3361(best: 0.3341)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3379 | Time 75.4348(74.0330) | Bit/dim 3.8637(3.8664) | Xent 0.9628(0.9730) | Loss 4.3451(4.3529) | Error 0.3441(0.3459) Steps 820(819.00) | Grad Norm 2.0955(2.8280) | Total Time 14.00(14.00)\n",
      "Iter 3380 | Time 75.3318(74.0720) | Bit/dim 3.8712(3.8666) | Xent 0.9868(0.9734) | Loss 4.3646(4.3533) | Error 0.3518(0.3460) Steps 820(819.03) | Grad Norm 2.5824(2.8206) | Total Time 14.00(14.00)\n",
      "Iter 3381 | Time 75.4538(74.1134) | Bit/dim 3.8600(3.8664) | Xent 0.9759(0.9735) | Loss 4.3480(4.3531) | Error 0.3469(0.3461) Steps 820(819.06) | Grad Norm 2.7953(2.8198) | Total Time 14.00(14.00)\n",
      "Iter 3382 | Time 74.9304(74.1379) | Bit/dim 3.8654(3.8663) | Xent 0.9547(0.9729) | Loss 4.3427(4.3528) | Error 0.3425(0.3459) Steps 814(818.91) | Grad Norm 1.9413(2.7935) | Total Time 14.00(14.00)\n",
      "Iter 3383 | Time 75.9896(74.1935) | Bit/dim 3.8639(3.8663) | Xent 0.9646(0.9727) | Loss 4.3462(4.3526) | Error 0.3439(0.3459) Steps 820(818.94) | Grad Norm 4.0045(2.8298) | Total Time 14.00(14.00)\n",
      "Iter 3384 | Time 74.1493(74.1921) | Bit/dim 3.8645(3.8662) | Xent 0.9776(0.9728) | Loss 4.3533(4.3526) | Error 0.3448(0.3459) Steps 814(818.79) | Grad Norm 1.3558(2.7856) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0564 | Time 29.4225, Epoch Time 496.0235(495.0981), Bit/dim 3.8663(best: 3.8661), Xent 0.9564, Loss 4.3446, Error 0.3343(best: 0.3341)\n",
      "===> Using batch size 8000. Total 6 iterations/epoch.\n",
      "Iter 3385 | Time 73.6547(74.1760) | Bit/dim 3.8676(3.8663) | Xent 0.9568(0.9724) | Loss 4.3460(4.3524) | Error 0.3371(0.3456) Steps 820(818.83) | Grad Norm 1.9751(2.7613) | Total Time 14.00(14.00)\n",
      "Iter 3386 | Time 74.2958(74.1796) | Bit/dim 3.8705(3.8664) | Xent 0.9663(0.9722) | Loss 4.3537(4.3525) | Error 0.3357(0.3453) Steps 814(818.68) | Grad Norm 3.2917(2.7772) | Total Time 14.00(14.00)\n",
      "Iter 3387 | Time 74.9074(74.2014) | Bit/dim 3.8712(3.8665) | Xent 0.9710(0.9721) | Loss 4.3567(4.3526) | Error 0.3470(0.3453) Steps 820(818.72) | Grad Norm 1.5825(2.7413) | Total Time 14.00(14.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs8K_sratio_0_5_drop_0_5_baseline_run1_post --load_dir ../experiments_published/cnf_conditional_disentangle_cifar10_bs8K_sratio_0_5_drop_0_5_baseline_run1 --seed 1 --conditional True --controlled_tol False --train_mode semisup --lr 0.001 --warmup_iters 1000 --atol 1e-5  --rtol 1e-5 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
