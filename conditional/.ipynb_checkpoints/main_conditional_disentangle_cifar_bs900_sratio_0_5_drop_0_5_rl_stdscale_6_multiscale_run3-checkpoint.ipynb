{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl_multiscale.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['figure.dpi'] = 300\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"colormnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl_multiscale as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z_sup, z_unsup, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    z_sup = torch.cat(z_sup, 1)\n",
      "    z_unsup = torch.cat(z_unsup, 1)\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z_sup).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z_unsup).view(z_unsup.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z_sup = model.module.dropout(z_sup)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z_sup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            dim_unsup = np.prod(data_shape) - np.prod(fixed_z_sup.shape[1:])\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            \n",
      "            a_sup = fixed_z_sup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            a_unsup = fixed_z_unsup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            \n",
      "            fixed_z = []\n",
      "            start_sup = 0; start_unsup = 0\n",
      "            for ns in range(model.module.n_scale, 1, -1):\n",
      "                end_sup = start_sup + (2**(ns-2))*a_sup\n",
      "                end_unsup = start_unsup + (2**(ns-2))*a_unsup\n",
      "                \n",
      "                fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "                fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "                \n",
      "                start_sup = end_sup; start_unsup = end_unsup\n",
      "            \n",
      "            end_sup = start_sup + a_sup\n",
      "            end_unsup = start_unsup + a_unsup\n",
      "            \n",
      "            fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "            fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "            \n",
      "            # for i_z in range(len(fixed_z)): print(fixed_z[i_z].shape)\n",
      "            \n",
      "            fixed_z = torch.cat(fixed_z,1)\n",
      "            \n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            if args.data == \"colormnist\":\n",
      "                y = y[0]\n",
      "            \n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "            \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if args.data == \"colormnist\":\n",
      "                        y = y[0]\n",
      "                        \n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                    \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=False, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume=None, rl_weight=0.01, rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run3', scale=1.0, scale_fac=1.0, scale_std=6.0, seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 0010 | Time 12.9121(32.0162) | Bit/dim 8.9017(9.0693) | Xent 2.2843(2.3007) | Loss 22.0007(22.6004) | Error 0.7567(0.8721) Steps 490(491.82) | Grad Norm 21.3869(30.9785) | Total Time 0.00(0.00)\n",
      "Iter 0020 | Time 13.1869(26.9522) | Bit/dim 8.5311(8.9468) | Xent 2.2564(2.2916) | Loss 21.3951(22.3005) | Error 0.7633(0.8423) Steps 538(495.56) | Grad Norm 9.4943(26.1328) | Total Time 0.00(0.00)\n",
      "Iter 0030 | Time 12.8482(23.1354) | Bit/dim 8.3451(8.8027) | Xent 2.2076(2.2738) | Loss 20.7861(21.9430) | Error 0.7522(0.8193) Steps 502(497.34) | Grad Norm 7.8768(21.5702) | Total Time 0.00(0.00)\n",
      "Iter 0040 | Time 13.3774(20.3845) | Bit/dim 8.1211(8.6446) | Xent 2.1549(2.2507) | Loss 20.4896(21.5807) | Error 0.7256(0.7980) Steps 484(495.73) | Grad Norm 6.8152(17.6229) | Total Time 0.00(0.00)\n",
      "Iter 0050 | Time 12.7871(18.3781) | Bit/dim 7.8697(8.4706) | Xent 2.1266(2.2246) | Loss 19.9756(21.1938) | Error 0.6822(0.7756) Steps 532(498.62) | Grad Norm 5.8948(14.5576) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 75.9732, Epoch Time 819.5396(819.5396), Bit/dim 7.7102(best: inf), Xent 2.1188, Loss 8.7696, Error 0.6936(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 12.6248(16.9151) | Bit/dim 7.5670(8.2754) | Xent 2.0956(2.1972) | Loss 19.2554(21.3177) | Error 0.6678(0.7539) Steps 526(498.23) | Grad Norm 5.1186(12.1991) | Total Time 0.00(0.00)\n",
      "Iter 0070 | Time 13.9619(15.9482) | Bit/dim 7.3314(8.0567) | Xent 2.0974(2.1735) | Loss 18.5636(20.7012) | Error 0.6744(0.7339) Steps 526(503.16) | Grad Norm 4.1385(10.2533) | Total Time 0.00(0.00)\n",
      "Iter 0080 | Time 13.7841(15.2400) | Bit/dim 7.1464(7.8367) | Xent 2.1134(2.1579) | Loss 18.5116(20.1388) | Error 0.6589(0.7199) Steps 544(509.58) | Grad Norm 2.8887(8.4502) | Total Time 0.00(0.00)\n",
      "Iter 0090 | Time 12.6936(14.7291) | Bit/dim 7.0773(7.6445) | Xent 2.1328(2.1499) | Loss 18.1699(19.6516) | Error 0.7078(0.7113) Steps 514(512.71) | Grad Norm 3.4141(6.9639) | Total Time 0.00(0.00)\n",
      "Iter 0100 | Time 13.4160(14.2931) | Bit/dim 7.0383(7.4880) | Xent 2.1217(2.1432) | Loss 18.2000(19.2524) | Error 0.7022(0.7071) Steps 562(517.45) | Grad Norm 3.3509(5.8678) | Total Time 0.00(0.00)\n",
      "Iter 0110 | Time 13.3947(14.0317) | Bit/dim 6.9898(7.3627) | Xent 2.1047(2.1352) | Loss 17.9286(18.9316) | Error 0.6956(0.7036) Steps 520(521.61) | Grad Norm 2.8913(5.0608) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 76.3020, Epoch Time 822.9252(819.6412), Bit/dim 6.9938(best: 7.7102), Xent 2.1010, Loss 8.0443, Error 0.6875(best: 0.6936)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 13.1970(13.8114) | Bit/dim 6.9535(7.2613) | Xent 2.0819(2.1244) | Loss 17.6817(19.1910) | Error 0.6767(0.6994) Steps 514(524.01) | Grad Norm 2.6572(4.3665) | Total Time 0.00(0.00)\n",
      "Iter 0130 | Time 13.1869(13.6943) | Bit/dim 6.9339(7.1760) | Xent 2.0660(2.1112) | Loss 17.6201(18.8244) | Error 0.6944(0.6973) Steps 496(523.43) | Grad Norm 2.5360(4.0475) | Total Time 0.00(0.00)\n",
      "Iter 0140 | Time 13.0191(13.5909) | Bit/dim 6.8808(7.1040) | Xent 2.0526(2.1014) | Loss 17.7623(18.5604) | Error 0.6822(0.6970) Steps 526(525.17) | Grad Norm 1.9486(4.1923) | Total Time 0.00(0.00)\n",
      "Iter 0150 | Time 13.6567(13.6132) | Bit/dim 6.7970(7.0335) | Xent 2.0444(2.0870) | Loss 17.3199(18.2975) | Error 0.6989(0.6956) Steps 514(527.20) | Grad Norm 6.0031(4.3938) | Total Time 0.00(0.00)\n",
      "Iter 0160 | Time 13.8272(13.6945) | Bit/dim 6.7336(6.9626) | Xent 2.0901(2.0783) | Loss 17.4869(18.0863) | Error 0.7600(0.7015) Steps 538(531.35) | Grad Norm 27.4665(8.0784) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 76.4137, Epoch Time 841.3356(820.2920), Bit/dim 6.6755(best: 6.9938), Xent 2.0846, Loss 7.7178, Error 0.7480(best: 0.6875)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 13.3225(13.7021) | Bit/dim 6.6053(6.8861) | Xent 2.0087(2.0710) | Loss 16.9492(18.4729) | Error 0.6567(0.7021) Steps 532(533.76) | Grad Norm 20.3890(12.7153) | Total Time 0.00(0.00)\n",
      "Iter 0180 | Time 14.0393(13.7169) | Bit/dim 6.4714(6.7937) | Xent 2.0335(2.0592) | Loss 16.9001(18.0825) | Error 0.7189(0.7022) Steps 556(536.95) | Grad Norm 30.2337(17.1755) | Total Time 0.00(0.00)\n",
      "Iter 0190 | Time 13.1508(13.6833) | Bit/dim 6.2917(6.6825) | Xent 2.2056(2.0593) | Loss 16.5072(17.6881) | Error 0.8156(0.7090) Steps 550(538.53) | Grad Norm 86.6964(24.3680) | Total Time 0.00(0.00)\n",
      "Iter 0200 | Time 13.8300(13.8052) | Bit/dim 6.2181(6.5764) | Xent 2.0778(2.0762) | Loss 16.5387(17.4043) | Error 0.7189(0.7191) Steps 550(541.08) | Grad Norm 68.4455(42.1905) | Total Time 0.00(0.00)\n",
      "Iter 0210 | Time 12.9987(13.7853) | Bit/dim 5.9902(6.4407) | Xent 2.0742(2.0627) | Loss 16.1108(17.0390) | Error 0.7289(0.7112) Steps 574(539.94) | Grad Norm 67.1442(41.8666) | Total Time 0.00(0.00)\n",
      "Iter 0220 | Time 13.0504(13.8304) | Bit/dim 5.8579(6.3015) | Xent 2.0003(2.0698) | Loss 15.4685(16.7143) | Error 0.6722(0.7196) Steps 538(542.03) | Grad Norm 58.3958(48.9091) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 77.5243, Epoch Time 857.2871(821.4019), Bit/dim 5.8359(best: 6.6755), Xent 2.0059, Loss 6.8388, Error 0.6599(best: 0.6875)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 13.9950(13.7413) | Bit/dim 5.7193(6.1696) | Xent 2.0326(2.0554) | Loss 15.4036(16.9038) | Error 0.6967(0.7093) Steps 526(542.00) | Grad Norm 16.4156(43.2916) | Total Time 0.00(0.00)\n",
      "Iter 0240 | Time 13.3203(13.7183) | Bit/dim 5.6403(6.0458) | Xent 1.9800(2.0371) | Loss 15.0263(16.4483) | Error 0.6844(0.6988) Steps 538(541.20) | Grad Norm 31.4351(36.6208) | Total Time 0.00(0.00)\n",
      "Iter 0250 | Time 13.9328(13.6792) | Bit/dim 5.7717(5.9863) | Xent 2.0212(2.0580) | Loss 15.2508(16.2036) | Error 0.7189(0.7079) Steps 562(541.50) | Grad Norm 45.3222(54.6220) | Total Time 0.00(0.00)\n",
      "Iter 0260 | Time 13.7428(13.6287) | Bit/dim 5.6513(5.9132) | Xent 2.0736(2.0538) | Loss 15.1685(15.9499) | Error 0.7544(0.7099) Steps 562(541.88) | Grad Norm 53.4991(49.3772) | Total Time 0.00(0.00)\n",
      "Iter 0270 | Time 13.3075(13.5517) | Bit/dim 5.6204(5.8401) | Xent 2.0278(2.0465) | Loss 14.9519(15.7110) | Error 0.7211(0.7093) Steps 532(540.67) | Grad Norm 51.7184(47.6649) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 77.1219, Epoch Time 838.8811(821.9262), Bit/dim 5.6112(best: 5.8359), Xent 2.1081, Loss 6.6653, Error 0.7871(best: 0.6599)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 13.4957(13.4950) | Bit/dim 5.5808(5.7827) | Xent 2.0013(2.0502) | Loss 15.0361(16.1663) | Error 0.6822(0.7145) Steps 538(539.64) | Grad Norm 16.2483(49.1434) | Total Time 0.00(0.00)\n",
      "Iter 0290 | Time 14.0171(13.4978) | Bit/dim 5.5047(5.7250) | Xent 2.0078(2.0413) | Loss 14.8215(15.8478) | Error 0.6989(0.7105) Steps 520(537.82) | Grad Norm 17.1523(42.2482) | Total Time 0.00(0.00)\n",
      "Iter 0300 | Time 13.7471(13.4944) | Bit/dim 5.5366(5.6779) | Xent 1.9547(2.0292) | Loss 14.6850(15.5841) | Error 0.6689(0.7036) Steps 538(535.21) | Grad Norm 8.5921(34.2971) | Total Time 0.00(0.00)\n",
      "Iter 0310 | Time 13.6310(13.4880) | Bit/dim 5.5127(5.6350) | Xent 1.9998(2.0123) | Loss 14.9916(15.3734) | Error 0.6711(0.6939) Steps 556(535.39) | Grad Norm 7.7952(27.4350) | Total Time 0.00(0.00)\n",
      "Iter 0320 | Time 13.3851(13.4815) | Bit/dim 5.4520(5.5998) | Xent 1.9240(1.9939) | Loss 14.5329(15.1854) | Error 0.6278(0.6832) Steps 532(535.18) | Grad Norm 5.0917(23.0667) | Total Time 0.00(0.00)\n",
      "Iter 0330 | Time 13.3243(13.5106) | Bit/dim 5.4382(5.5619) | Xent 1.8833(1.9763) | Loss 14.5718(15.0302) | Error 0.6422(0.6775) Steps 550(535.61) | Grad Norm 14.2675(22.4119) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 76.8018, Epoch Time 838.4262(822.4212), Bit/dim 5.4461(best: 5.6112), Xent 1.9019, Loss 6.3970, Error 0.6391(best: 0.6599)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 13.1974(13.5667) | Bit/dim 5.4366(5.5275) | Xent 1.9123(1.9573) | Loss 14.6442(15.4221) | Error 0.6578(0.6727) Steps 538(536.35) | Grad Norm 5.6193(22.5969) | Total Time 0.00(0.00)\n",
      "Iter 0350 | Time 14.0713(13.6398) | Bit/dim 5.3493(5.4935) | Xent 1.8980(1.9474) | Loss 14.2513(15.1588) | Error 0.6489(0.6711) Steps 544(539.12) | Grad Norm 40.6606(28.3475) | Total Time 0.00(0.00)\n",
      "Iter 0360 | Time 13.8421(13.7136) | Bit/dim 5.3898(5.4600) | Xent 1.9388(1.9411) | Loss 14.4463(14.9689) | Error 0.6822(0.6682) Steps 574(540.92) | Grad Norm 33.7548(29.3214) | Total Time 0.00(0.00)\n",
      "Iter 0370 | Time 13.5210(13.8388) | Bit/dim 5.3055(5.4224) | Xent 1.8843(1.9340) | Loss 14.3624(14.7974) | Error 0.6556(0.6667) Steps 538(540.05) | Grad Norm 29.9412(28.0805) | Total Time 0.00(0.00)\n",
      "Iter 0380 | Time 14.9640(13.9118) | Bit/dim 5.2836(5.3888) | Xent 1.9048(1.9389) | Loss 14.3379(14.6734) | Error 0.6833(0.6726) Steps 586(545.99) | Grad Norm 33.6177(32.4890) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 78.4024, Epoch Time 866.3802(823.7400), Bit/dim 5.2613(best: 5.4461), Xent 1.8815, Loss 6.2021, Error 0.6455(best: 0.6391)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 14.3436(13.9400) | Bit/dim 5.2723(5.3613) | Xent 1.8895(1.9325) | Loss 14.3981(15.1755) | Error 0.6489(0.6695) Steps 538(545.80) | Grad Norm 8.4327(30.0282) | Total Time 0.00(0.00)\n",
      "Iter 0400 | Time 14.1781(14.0188) | Bit/dim 5.2252(5.3283) | Xent 1.9241(1.9204) | Loss 14.0293(14.9107) | Error 0.6656(0.6634) Steps 562(549.35) | Grad Norm 28.0390(26.9699) | Total Time 0.00(0.00)\n",
      "Iter 0410 | Time 14.4346(14.0325) | Bit/dim 5.1961(5.2943) | Xent 1.8852(1.9095) | Loss 14.0535(14.6632) | Error 0.6567(0.6604) Steps 544(547.66) | Grad Norm 18.4172(24.8686) | Total Time 0.00(0.00)\n",
      "Iter 0420 | Time 13.7863(14.0432) | Bit/dim 5.1694(5.2670) | Xent 1.8662(1.9009) | Loss 13.9143(14.4915) | Error 0.6189(0.6574) Steps 550(548.67) | Grad Norm 26.5077(26.9177) | Total Time 0.00(0.00)\n",
      "Iter 0430 | Time 13.8714(14.0948) | Bit/dim 5.1924(5.2387) | Xent 2.0096(1.9027) | Loss 14.1921(14.3566) | Error 0.6767(0.6591) Steps 574(551.45) | Grad Norm 68.2298(30.3035) | Total Time 0.00(0.00)\n",
      "Iter 0440 | Time 14.2559(14.0941) | Bit/dim 5.1253(5.2164) | Xent 1.9396(1.9145) | Loss 13.9953(14.2611) | Error 0.7022(0.6673) Steps 544(549.46) | Grad Norm 17.3142(34.4679) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 78.3949, Epoch Time 876.2792(825.3162), Bit/dim 5.1186(best: 5.2613), Xent 1.8870, Loss 6.0621, Error 0.6535(best: 0.6391)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 14.6444(14.2296) | Bit/dim 5.0622(5.1907) | Xent 1.9162(1.9098) | Loss 13.8228(14.6639) | Error 0.6922(0.6670) Steps 556(548.40) | Grad Norm 23.6432(30.6817) | Total Time 0.00(0.00)\n",
      "Iter 0460 | Time 14.5583(14.2622) | Bit/dim 5.0384(5.1655) | Xent 1.8245(1.8992) | Loss 13.6103(14.4304) | Error 0.6389(0.6620) Steps 562(549.40) | Grad Norm 8.5536(25.6831) | Total Time 0.00(0.00)\n",
      "Iter 0470 | Time 14.5040(14.2591) | Bit/dim 5.0558(5.1361) | Xent 1.8667(1.8902) | Loss 13.6931(14.2284) | Error 0.6833(0.6590) Steps 538(546.15) | Grad Norm 32.4880(23.9465) | Total Time 0.00(0.00)\n",
      "Iter 0480 | Time 14.5123(14.2869) | Bit/dim 4.9988(5.1029) | Xent 1.8408(1.8790) | Loss 13.4486(14.0489) | Error 0.6600(0.6563) Steps 550(547.57) | Grad Norm 12.7889(23.2379) | Total Time 0.00(0.00)\n",
      "Iter 0490 | Time 14.6004(14.3121) | Bit/dim 4.9622(5.0748) | Xent 1.8911(1.8697) | Loss 13.3617(13.9094) | Error 0.6656(0.6524) Steps 526(547.35) | Grad Norm 21.4108(23.7895) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 78.5269, Epoch Time 889.9359(827.2548), Bit/dim 5.0237(best: 5.1186), Xent 1.8852, Loss 5.9663, Error 0.6667(best: 0.6391)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 14.4865(14.4035) | Bit/dim 4.9812(5.0525) | Xent 1.9026(1.8704) | Loss 13.6789(14.4339) | Error 0.6767(0.6516) Steps 562(550.75) | Grad Norm 36.4328(29.0727) | Total Time 0.00(0.00)\n",
      "Iter 0510 | Time 15.4761(14.4722) | Bit/dim 4.8861(5.0232) | Xent 1.8316(1.8678) | Loss 13.2509(14.1669) | Error 0.6444(0.6527) Steps 526(551.60) | Grad Norm 13.7086(27.8355) | Total Time 0.00(0.00)\n",
      "Iter 0520 | Time 14.8439(14.5340) | Bit/dim 4.9011(4.9912) | Xent 1.8545(1.8494) | Loss 13.3521(13.9263) | Error 0.6378(0.6481) Steps 556(552.28) | Grad Norm 40.7649(25.7383) | Total Time 0.00(0.00)\n",
      "Iter 0530 | Time 14.5626(14.5734) | Bit/dim 4.8495(4.9636) | Xent 1.7876(1.8343) | Loss 13.2093(13.7529) | Error 0.6200(0.6434) Steps 592(554.06) | Grad Norm 29.8110(26.4901) | Total Time 0.00(0.00)\n",
      "Iter 0540 | Time 14.2159(14.6122) | Bit/dim 5.0396(4.9602) | Xent 2.7195(1.8776) | Loss 14.3818(13.6848) | Error 0.8256(0.6552) Steps 568(558.53) | Grad Norm 134.7001(36.8871) | Total Time 0.00(0.00)\n",
      "Iter 0550 | Time 14.8305(14.6976) | Bit/dim 4.8959(4.9601) | Xent 1.9895(1.9208) | Loss 13.4197(13.6797) | Error 0.7144(0.6744) Steps 592(562.96) | Grad Norm 16.5162(33.5764) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 82.0502, Epoch Time 912.3889(829.8088), Bit/dim 4.8973(best: 5.0237), Xent 1.9220, Loss 5.8582, Error 0.6832(best: 0.6391)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 15.1972(14.7351) | Bit/dim 4.8253(4.9356) | Xent 1.8608(1.9169) | Loss 13.1428(14.0945) | Error 0.6556(0.6744) Steps 556(564.98) | Grad Norm 11.6941(28.0078) | Total Time 0.00(0.00)\n",
      "Iter 0570 | Time 14.8435(14.8280) | Bit/dim 4.8310(4.9079) | Xent 1.8657(1.9017) | Loss 13.3018(13.8608) | Error 0.6667(0.6701) Steps 550(564.37) | Grad Norm 8.4308(24.5490) | Total Time 0.00(0.00)\n",
      "Iter 0580 | Time 15.2749(14.9428) | Bit/dim 4.7896(4.8802) | Xent 1.8398(1.8867) | Loss 13.0863(13.6660) | Error 0.6644(0.6666) Steps 556(567.12) | Grad Norm 25.7784(25.5127) | Total Time 0.00(0.00)\n",
      "Iter 0590 | Time 15.2534(15.0152) | Bit/dim 4.7846(4.8573) | Xent 1.8228(1.8816) | Loss 12.9700(13.5192) | Error 0.6489(0.6665) Steps 574(568.50) | Grad Norm 18.9802(27.7125) | Total Time 0.00(0.00)\n",
      "Iter 0600 | Time 15.6003(15.1124) | Bit/dim 4.7449(4.8387) | Xent 1.8131(1.8681) | Loss 13.0184(13.4176) | Error 0.6111(0.6599) Steps 574(573.32) | Grad Norm 28.3404(28.2412) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 80.9629, Epoch Time 936.2191(833.0011), Bit/dim 4.7661(best: 4.8973), Xent 1.7457, Loss 5.6390, Error 0.6123(best: 0.6391)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 15.5779(15.1771) | Bit/dim 4.7398(4.8168) | Xent 1.7457(1.8439) | Loss 12.8586(13.9014) | Error 0.6144(0.6513) Steps 544(573.24) | Grad Norm 22.3546(26.1720) | Total Time 0.00(0.00)\n",
      "Iter 0620 | Time 15.9420(15.2488) | Bit/dim 4.7437(4.7972) | Xent 1.6688(1.8161) | Loss 12.9783(13.6330) | Error 0.5878(0.6417) Steps 592(577.67) | Grad Norm 5.9252(22.6467) | Total Time 0.00(0.00)\n",
      "Iter 0630 | Time 15.0815(15.2821) | Bit/dim 4.6956(4.7745) | Xent 1.7037(1.7868) | Loss 12.8129(13.4259) | Error 0.5967(0.6311) Steps 592(579.30) | Grad Norm 21.7751(20.9109) | Total Time 0.00(0.00)\n",
      "Iter 0640 | Time 15.1360(15.3184) | Bit/dim 4.7413(4.7698) | Xent 1.7874(1.7812) | Loss 12.9733(13.3034) | Error 0.6500(0.6306) Steps 586(582.44) | Grad Norm 34.0308(24.8905) | Total Time 0.00(0.00)\n",
      "Iter 0650 | Time 15.9182(15.3693) | Bit/dim 4.6694(4.7550) | Xent 1.7370(1.7759) | Loss 12.7907(13.1962) | Error 0.6178(0.6310) Steps 586(584.06) | Grad Norm 13.8529(24.7348) | Total Time 0.00(0.00)\n",
      "Iter 0660 | Time 16.3207(15.4915) | Bit/dim 4.7312(4.7402) | Xent 1.7230(1.7658) | Loss 12.8464(13.0992) | Error 0.6156(0.6267) Steps 616(586.85) | Grad Norm 15.1714(24.6797) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 84.6009, Epoch Time 957.1992(836.7271), Bit/dim 4.6824(best: 4.7661), Xent 1.6487, Loss 5.5067, Error 0.5800(best: 0.6123)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 14.7467(15.4898) | Bit/dim 4.6671(4.7240) | Xent 1.6988(1.7456) | Loss 12.5914(13.5279) | Error 0.5878(0.6224) Steps 568(587.17) | Grad Norm 26.5317(23.5046) | Total Time 0.00(0.00)\n",
      "Iter 0680 | Time 16.2691(15.5410) | Bit/dim 4.6674(4.7074) | Xent 1.7583(1.7359) | Loss 12.9098(13.3060) | Error 0.6289(0.6170) Steps 640(588.73) | Grad Norm 41.0007(24.4469) | Total Time 0.00(0.00)\n",
      "Iter 0690 | Time 15.4599(15.5462) | Bit/dim 4.7095(4.7085) | Xent 1.6934(1.7483) | Loss 12.7012(13.1896) | Error 0.6289(0.6212) Steps 598(589.97) | Grad Norm 22.2417(28.9598) | Total Time 0.00(0.00)\n",
      "Iter 0700 | Time 16.0853(15.5157) | Bit/dim 4.6309(4.6993) | Xent 1.7426(1.7475) | Loss 12.7842(13.0819) | Error 0.6167(0.6195) Steps 622(594.24) | Grad Norm 15.3965(26.7327) | Total Time 0.00(0.00)\n",
      "Iter 0710 | Time 15.2416(15.4928) | Bit/dim 4.6421(4.6861) | Xent 1.6351(1.7309) | Loss 12.5821(12.9552) | Error 0.5722(0.6136) Steps 592(594.66) | Grad Norm 10.4612(24.1102) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 83.6093, Epoch Time 957.5374(840.3514), Bit/dim 4.7626(best: 4.6824), Xent 1.9517, Loss 5.7385, Error 0.6793(best: 0.5800)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 15.4999(15.5304) | Bit/dim 4.6884(4.6857) | Xent 1.7509(1.7450) | Loss 12.8447(13.5401) | Error 0.6411(0.6175) Steps 592(594.53) | Grad Norm 26.5920(28.0657) | Total Time 0.00(0.00)\n",
      "Iter 0730 | Time 15.8568(15.4952) | Bit/dim 4.6565(4.6778) | Xent 1.6541(1.7405) | Loss 12.5581(13.3048) | Error 0.5700(0.6168) Steps 610(594.12) | Grad Norm 8.3592(25.4783) | Total Time 0.00(0.00)\n",
      "Iter 0740 | Time 15.5397(15.5225) | Bit/dim 4.6810(4.6688) | Xent 1.6585(1.7172) | Loss 12.6378(13.1294) | Error 0.5800(0.6095) Steps 580(593.73) | Grad Norm 29.7932(23.5948) | Total Time 0.00(0.00)\n",
      "Iter 0750 | Time 15.6799(15.5737) | Bit/dim 4.5976(4.6536) | Xent 1.6326(1.6937) | Loss 12.5261(12.9655) | Error 0.5667(0.6038) Steps 562(594.18) | Grad Norm 14.2876(20.6282) | Total Time 0.00(0.00)\n",
      "Iter 0760 | Time 16.4671(15.5967) | Bit/dim 4.5898(4.6369) | Xent 1.5715(1.6737) | Loss 12.4106(12.8384) | Error 0.5544(0.5983) Steps 598(597.36) | Grad Norm 14.1368(18.8748) | Total Time 0.00(0.00)\n",
      "Iter 0770 | Time 15.2122(15.5918) | Bit/dim 4.6282(4.6205) | Xent 1.7287(1.6674) | Loss 12.5543(12.7328) | Error 0.6311(0.5959) Steps 598(599.96) | Grad Norm 33.9428(19.2204) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 85.7707, Epoch Time 963.4332(844.0438), Bit/dim 4.5774(best: 4.6824), Xent 1.5955, Loss 5.3751, Error 0.5690(best: 0.5800)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 16.1257(15.6918) | Bit/dim 4.5255(4.6061) | Xent 1.5962(1.6549) | Loss 12.3332(13.1955) | Error 0.5600(0.5904) Steps 628(602.04) | Grad Norm 6.1337(20.3244) | Total Time 0.00(0.00)\n",
      "Iter 0790 | Time 15.9032(15.7536) | Bit/dim 4.5390(4.5970) | Xent 1.6376(1.6438) | Loss 12.4612(13.0042) | Error 0.5656(0.5862) Steps 598(604.32) | Grad Norm 23.1977(20.7276) | Total Time 0.00(0.00)\n",
      "Iter 0800 | Time 15.6761(15.7960) | Bit/dim 4.5624(4.5895) | Xent 1.6006(1.6368) | Loss 12.4389(12.8568) | Error 0.5567(0.5822) Steps 610(606.94) | Grad Norm 32.0051(22.0686) | Total Time 0.00(0.00)\n",
      "Iter 0810 | Time 15.7793(15.7813) | Bit/dim 4.5425(4.5781) | Xent 1.6230(1.6357) | Loss 12.5035(12.7484) | Error 0.5856(0.5846) Steps 628(609.67) | Grad Norm 16.3321(20.9297) | Total Time 0.00(0.00)\n",
      "Iter 0820 | Time 16.4432(15.8570) | Bit/dim 4.5339(4.5638) | Xent 1.6257(1.6224) | Loss 12.3118(12.6325) | Error 0.5956(0.5827) Steps 616(607.48) | Grad Norm 28.7441(19.5853) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 86.1416, Epoch Time 981.0988(848.1555), Bit/dim 4.5267(best: 4.5774), Xent 1.5250, Loss 5.2892, Error 0.5452(best: 0.5690)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 16.5767(15.8765) | Bit/dim 4.5602(4.5625) | Xent 1.5790(1.6237) | Loss 12.5133(13.2616) | Error 0.5622(0.5836) Steps 592(611.27) | Grad Norm 20.2870(23.0775) | Total Time 0.00(0.00)\n",
      "Iter 0840 | Time 15.4461(15.9191) | Bit/dim 4.5135(4.5499) | Xent 1.5366(1.6136) | Loss 12.3229(13.0239) | Error 0.5467(0.5803) Steps 616(616.45) | Grad Norm 13.4646(20.6129) | Total Time 0.00(0.00)\n",
      "Iter 0850 | Time 15.6531(15.8996) | Bit/dim 4.5300(4.5432) | Xent 1.6508(1.6015) | Loss 12.4289(12.8459) | Error 0.5900(0.5767) Steps 616(616.40) | Grad Norm 42.0815(19.7494) | Total Time 0.00(0.00)\n",
      "Iter 0860 | Time 16.4226(15.8904) | Bit/dim 4.5030(4.5345) | Xent 1.6355(1.5928) | Loss 12.3724(12.7047) | Error 0.5900(0.5730) Steps 628(616.73) | Grad Norm 6.9019(19.8382) | Total Time 0.00(0.00)\n",
      "Iter 0870 | Time 15.4858(15.8463) | Bit/dim 4.5885(4.5323) | Xent 1.6153(1.5957) | Loss 12.2233(12.6052) | Error 0.5611(0.5753) Steps 610(615.90) | Grad Norm 23.8468(21.6474) | Total Time 0.00(0.00)\n",
      "Iter 0880 | Time 16.1652(15.8941) | Bit/dim 4.5015(4.5247) | Xent 1.5851(1.6108) | Loss 12.4872(12.5708) | Error 0.5600(0.5794) Steps 652(619.08) | Grad Norm 22.6812(20.5694) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 88.6750, Epoch Time 984.1333(852.2348), Bit/dim 4.4840(best: 4.5267), Xent 1.5345, Loss 5.2512, Error 0.5502(best: 0.5452)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 16.7595(15.9458) | Bit/dim 4.4537(4.5132) | Xent 1.5642(1.5970) | Loss 12.2357(13.0815) | Error 0.5678(0.5739) Steps 670(621.44) | Grad Norm 13.3700(18.2409) | Total Time 0.00(0.00)\n",
      "Iter 0900 | Time 15.4949(15.9480) | Bit/dim 4.4367(4.4985) | Xent 1.4602(1.5758) | Loss 12.0964(12.8474) | Error 0.5344(0.5676) Steps 622(622.16) | Grad Norm 6.5430(16.1488) | Total Time 0.00(0.00)\n",
      "Iter 0910 | Time 15.3748(15.9499) | Bit/dim 4.4533(4.4852) | Xent 1.5480(1.5560) | Loss 12.0412(12.6463) | Error 0.5789(0.5599) Steps 592(621.25) | Grad Norm 22.4204(15.8548) | Total Time 0.00(0.00)\n",
      "Iter 0920 | Time 15.9640(15.9880) | Bit/dim 4.5863(4.5087) | Xent 1.6965(1.6199) | Loss 12.7239(12.6601) | Error 0.5956(0.5778) Steps 646(622.83) | Grad Norm 20.0251(22.1736) | Total Time 0.00(0.00)\n",
      "Iter 0930 | Time 16.9383(16.1968) | Bit/dim 4.4829(4.5079) | Xent 1.6866(1.6339) | Loss 12.4257(12.6119) | Error 0.6100(0.5836) Steps 622(631.68) | Grad Norm 14.3724(21.1635) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 88.0998, Epoch Time 999.2690(856.6458), Bit/dim 4.4661(best: 4.4840), Xent 1.5124, Loss 5.2223, Error 0.5415(best: 0.5452)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 16.8412(16.2576) | Bit/dim 4.4541(4.4971) | Xent 1.5389(1.6187) | Loss 12.2318(13.1794) | Error 0.5567(0.5785) Steps 628(633.03) | Grad Norm 15.5170(18.9359) | Total Time 0.00(0.00)\n",
      "Iter 0950 | Time 15.7552(16.3077) | Bit/dim 4.4456(4.4803) | Xent 1.5175(1.5975) | Loss 12.1123(12.9220) | Error 0.5556(0.5710) Steps 640(637.17) | Grad Norm 5.0599(16.1951) | Total Time 0.00(0.00)\n",
      "Iter 0960 | Time 16.7739(16.3539) | Bit/dim 4.3947(4.4620) | Xent 1.4782(1.5666) | Loss 12.0012(12.6988) | Error 0.5367(0.5620) Steps 646(635.51) | Grad Norm 8.2248(14.1553) | Total Time 0.00(0.00)\n",
      "Iter 0970 | Time 16.3742(16.3764) | Bit/dim 4.4256(4.4491) | Xent 1.5204(1.5526) | Loss 12.0969(12.5459) | Error 0.5467(0.5585) Steps 628(633.86) | Grad Norm 16.5817(15.2206) | Total Time 0.00(0.00)\n",
      "Iter 0980 | Time 16.2778(16.3194) | Bit/dim 4.3962(4.4321) | Xent 1.4336(1.5403) | Loss 12.0304(12.3976) | Error 0.5089(0.5532) Steps 628(631.93) | Grad Norm 12.5273(15.1323) | Total Time 0.00(0.00)\n",
      "Iter 0990 | Time 15.6743(16.2987) | Bit/dim 4.3902(4.4199) | Xent 1.5097(1.5290) | Loss 12.0379(12.2871) | Error 0.5544(0.5497) Steps 604(629.34) | Grad Norm 21.9699(15.8354) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 90.5848, Epoch Time 1010.2397(861.2536), Bit/dim 4.3787(best: 4.4661), Xent 1.4080, Loss 5.0827, Error 0.5077(best: 0.5415)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 15.6954(16.3216) | Bit/dim 4.4048(4.4087) | Xent 1.4511(1.5077) | Loss 11.9147(12.7983) | Error 0.5300(0.5434) Steps 634(632.05) | Grad Norm 20.9280(15.6480) | Total Time 0.00(0.00)\n",
      "Iter 1010 | Time 16.0474(16.3097) | Bit/dim 4.3440(4.3985) | Xent 1.4921(1.5009) | Loss 11.8077(12.5833) | Error 0.5189(0.5397) Steps 592(632.60) | Grad Norm 21.2099(17.5032) | Total Time 0.00(0.00)\n",
      "Iter 1020 | Time 17.3380(16.3293) | Bit/dim 4.3368(4.3855) | Xent 1.4669(1.4926) | Loss 11.9930(12.4153) | Error 0.5189(0.5357) Steps 688(633.38) | Grad Norm 16.3091(17.8608) | Total Time 0.00(0.00)\n",
      "Iter 1030 | Time 16.7423(16.4496) | Bit/dim 4.3630(4.3794) | Xent 1.4512(1.4925) | Loss 12.0173(12.2992) | Error 0.5111(0.5364) Steps 628(634.73) | Grad Norm 31.9046(18.8244) | Total Time 0.00(0.00)\n",
      "Iter 1040 | Time 16.7741(16.3400) | Bit/dim 4.3724(4.3768) | Xent 1.4475(1.4931) | Loss 11.9445(12.2160) | Error 0.5344(0.5372) Steps 598(631.30) | Grad Norm 11.3752(18.7827) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 87.8340, Epoch Time 1009.1713(865.6912), Bit/dim 4.3333(best: 4.3787), Xent 1.4650, Loss 5.0657, Error 0.5320(best: 0.5077)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 16.6368(16.3981) | Bit/dim 4.3053(4.3652) | Xent 1.3902(1.4881) | Loss 11.7888(12.7807) | Error 0.4900(0.5354) Steps 640(631.23) | Grad Norm 18.1353(17.4708) | Total Time 0.00(0.00)\n",
      "Iter 1060 | Time 17.4415(16.5234) | Bit/dim 4.3444(4.3519) | Xent 1.4382(1.4682) | Loss 11.8944(12.5138) | Error 0.5111(0.5269) Steps 634(632.08) | Grad Norm 17.2567(16.0028) | Total Time 0.00(0.00)\n",
      "Iter 1070 | Time 16.2430(16.6228) | Bit/dim 4.6394(4.3531) | Xent 1.7500(1.4641) | Loss 12.7804(12.3623) | Error 0.6256(0.5272) Steps 670(637.35) | Grad Norm 54.1138(18.2122) | Total Time 0.00(0.00)\n",
      "Iter 1080 | Time 16.8720(16.6869) | Bit/dim 4.3687(4.3717) | Xent 1.5936(1.5271) | Loss 12.0007(12.3691) | Error 0.5744(0.5470) Steps 622(642.91) | Grad Norm 9.9736(20.5841) | Total Time 0.00(0.00)\n",
      "Iter 1090 | Time 17.9737(16.8562) | Bit/dim 4.3175(4.3645) | Xent 1.4430(1.5222) | Loss 11.9629(12.2800) | Error 0.5400(0.5457) Steps 694(649.40) | Grad Norm 7.7882(17.4395) | Total Time 0.00(0.00)\n",
      "Iter 1100 | Time 16.3120(16.8916) | Bit/dim 4.3186(4.3519) | Xent 1.3746(1.5067) | Loss 11.8479(12.1870) | Error 0.5056(0.5418) Steps 622(653.47) | Grad Norm 10.1646(14.9073) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 89.8448, Epoch Time 1041.7305(870.9724), Bit/dim 4.2899(best: 4.3333), Xent 1.3699, Loss 4.9749, Error 0.4947(best: 0.5077)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 17.0253(16.8550) | Bit/dim 4.2930(4.3348) | Xent 1.4223(1.4804) | Loss 11.6887(12.6697) | Error 0.5211(0.5322) Steps 652(654.05) | Grad Norm 5.6948(13.5309) | Total Time 0.00(0.00)\n",
      "Iter 1120 | Time 17.0731(16.9600) | Bit/dim 4.2351(4.3159) | Xent 1.3530(1.4563) | Loss 11.6419(12.4175) | Error 0.5078(0.5252) Steps 694(658.64) | Grad Norm 9.6340(12.1260) | Total Time 0.00(0.00)\n",
      "Iter 1130 | Time 16.9829(16.8958) | Bit/dim 4.2784(4.3092) | Xent 1.4279(1.4456) | Loss 11.7963(12.2616) | Error 0.5400(0.5212) Steps 670(659.16) | Grad Norm 16.8623(14.3764) | Total Time 0.00(0.00)\n",
      "Iter 1140 | Time 16.0172(16.8002) | Bit/dim 4.2458(4.2959) | Xent 1.3198(1.4315) | Loss 11.5608(12.1047) | Error 0.4833(0.5171) Steps 640(653.34) | Grad Norm 7.1836(14.2687) | Total Time 0.00(0.00)\n",
      "Iter 1150 | Time 17.1270(16.8734) | Bit/dim 4.2396(4.2800) | Xent 1.3748(1.4207) | Loss 11.7301(11.9868) | Error 0.5033(0.5116) Steps 694(654.02) | Grad Norm 9.8209(14.1084) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 90.3050, Epoch Time 1038.0251(875.9839), Bit/dim 4.2259(best: 4.2899), Xent 1.3442, Loss 4.8980, Error 0.4873(best: 0.4947)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 16.6804(16.9174) | Bit/dim 4.2508(4.2702) | Xent 1.3914(1.4058) | Loss 11.8683(12.6208) | Error 0.5111(0.5083) Steps 676(656.82) | Grad Norm 25.5460(14.4215) | Total Time 0.00(0.00)\n",
      "Iter 1170 | Time 17.4768(16.9122) | Bit/dim 4.2577(4.2596) | Xent 1.3984(1.3929) | Loss 11.4741(12.3417) | Error 0.5022(0.5031) Steps 694(659.63) | Grad Norm 25.1256(15.0647) | Total Time 0.00(0.00)\n",
      "Iter 1180 | Time 16.6254(16.9534) | Bit/dim 4.1769(4.2474) | Xent 1.3984(1.3967) | Loss 11.6281(12.1555) | Error 0.5067(0.5029) Steps 634(658.70) | Grad Norm 18.4437(16.6520) | Total Time 0.00(0.00)\n",
      "Iter 1190 | Time 17.3291(16.9924) | Bit/dim 4.2220(4.2395) | Xent 1.3930(1.3967) | Loss 11.5207(12.0078) | Error 0.5156(0.5034) Steps 652(659.73) | Grad Norm 26.3667(17.1947) | Total Time 0.00(0.00)\n",
      "Iter 1200 | Time 17.9846(17.0188) | Bit/dim 4.2020(4.2309) | Xent 1.4250(1.3955) | Loss 11.6325(11.8961) | Error 0.5022(0.5002) Steps 682(659.37) | Grad Norm 21.5886(17.3516) | Total Time 0.00(0.00)\n",
      "Iter 1210 | Time 17.4421(17.0264) | Bit/dim 4.2191(4.2202) | Xent 1.4234(1.3852) | Loss 11.6542(11.8028) | Error 0.5000(0.4980) Steps 640(658.59) | Grad Norm 27.3028(17.3661) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 88.4133, Epoch Time 1046.3868(881.0960), Bit/dim 4.2132(best: 4.2259), Xent 1.3241, Loss 4.8753, Error 0.4734(best: 0.4873)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 16.9842(16.9965) | Bit/dim 4.1888(4.2117) | Xent 1.3570(1.3755) | Loss 11.4624(12.2980) | Error 0.4633(0.4926) Steps 664(657.26) | Grad Norm 17.1745(17.6028) | Total Time 0.00(0.00)\n",
      "Iter 1230 | Time 17.0410(16.9038) | Bit/dim 4.3149(4.2226) | Xent 1.5195(1.3964) | Loss 11.9762(12.1538) | Error 0.5511(0.4980) Steps 640(652.75) | Grad Norm 20.9421(20.6268) | Total Time 0.00(0.00)\n",
      "Iter 1240 | Time 17.2146(16.9591) | Bit/dim 4.2542(4.2401) | Xent 1.5982(1.4312) | Loss 11.9101(12.0914) | Error 0.6033(0.5124) Steps 682(660.51) | Grad Norm 23.5739(19.7467) | Total Time 0.00(0.00)\n",
      "Iter 1250 | Time 17.5197(17.1691) | Bit/dim 4.1943(4.2327) | Xent 1.4722(1.4318) | Loss 11.7120(11.9863) | Error 0.5556(0.5135) Steps 676(662.12) | Grad Norm 9.1202(17.2648) | Total Time 0.00(0.00)\n",
      "Iter 1260 | Time 16.5620(17.2274) | Bit/dim 4.1943(4.2204) | Xent 1.4678(1.4249) | Loss 11.7159(11.8794) | Error 0.5378(0.5133) Steps 676(666.00) | Grad Norm 14.5416(15.8082) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 91.4655, Epoch Time 1057.3728(886.3843), Bit/dim 4.1551(best: 4.2132), Xent 1.3157, Loss 4.8129, Error 0.4801(best: 0.4734)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 18.2709(17.2781) | Bit/dim 4.1406(4.2017) | Xent 1.3515(1.4072) | Loss 11.5457(12.4950) | Error 0.4800(0.5059) Steps 712(668.70) | Grad Norm 10.3535(14.6624) | Total Time 0.00(0.00)\n",
      "Iter 1280 | Time 18.1766(17.3870) | Bit/dim 4.1209(4.1842) | Xent 1.3385(1.3935) | Loss 11.4577(12.2235) | Error 0.4889(0.5012) Steps 646(673.95) | Grad Norm 12.2185(14.0207) | Total Time 0.00(0.00)\n",
      "Iter 1290 | Time 16.6370(17.3726) | Bit/dim 4.1620(4.1770) | Xent 1.3066(1.3742) | Loss 11.5155(12.0216) | Error 0.4467(0.4954) Steps 676(673.43) | Grad Norm 18.1182(13.5463) | Total Time 0.00(0.00)\n",
      "Iter 1300 | Time 17.9299(17.4098) | Bit/dim 4.1546(4.1691) | Xent 1.3375(1.3628) | Loss 11.4316(11.8503) | Error 0.4678(0.4905) Steps 670(672.14) | Grad Norm 14.7366(14.0862) | Total Time 0.00(0.00)\n",
      "Iter 1310 | Time 16.8514(17.4700) | Bit/dim 4.1697(4.1625) | Xent 1.2836(1.3536) | Loss 11.3523(11.7237) | Error 0.4722(0.4883) Steps 676(673.14) | Grad Norm 23.4459(15.7788) | Total Time 0.00(0.00)\n",
      "Iter 1320 | Time 16.8516(17.5607) | Bit/dim 4.1381(4.1546) | Xent 1.2767(1.3463) | Loss 11.4176(11.6486) | Error 0.4656(0.4842) Steps 700(680.44) | Grad Norm 5.8888(15.0434) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 92.1895, Epoch Time 1079.6008(892.1808), Bit/dim 4.1344(best: 4.1551), Xent 1.2535, Loss 4.7612, Error 0.4559(best: 0.4734)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 17.1181(17.5396) | Bit/dim 4.1912(4.1472) | Xent 1.2252(1.3239) | Loss 11.3909(12.1956) | Error 0.4367(0.4758) Steps 688(678.95) | Grad Norm 31.4871(15.1828) | Total Time 0.00(0.00)\n",
      "Iter 1340 | Time 17.0437(17.5203) | Bit/dim 4.0857(4.1487) | Xent 1.2712(1.3168) | Loss 11.1269(11.9844) | Error 0.4611(0.4734) Steps 670(680.21) | Grad Norm 13.0852(16.4336) | Total Time 0.00(0.00)\n",
      "Iter 1350 | Time 17.2412(17.5825) | Bit/dim 4.1013(4.1407) | Xent 1.2844(1.2992) | Loss 11.2692(11.7974) | Error 0.4456(0.4662) Steps 694(678.63) | Grad Norm 10.0804(15.7656) | Total Time 0.00(0.00)\n",
      "Iter 1360 | Time 17.8858(17.5639) | Bit/dim 4.1019(4.1338) | Xent 1.2381(1.2935) | Loss 11.3714(11.6778) | Error 0.4433(0.4646) Steps 700(680.35) | Grad Norm 9.4004(15.2202) | Total Time 0.00(0.00)\n",
      "Iter 1370 | Time 16.9205(17.5052) | Bit/dim 4.0734(4.1251) | Xent 1.3175(1.2850) | Loss 11.1632(11.5770) | Error 0.4633(0.4606) Steps 664(680.83) | Grad Norm 8.2811(14.1785) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 91.2892, Epoch Time 1073.7779(897.6287), Bit/dim 4.0922(best: 4.1344), Xent 1.2328, Loss 4.7086, Error 0.4445(best: 0.4559)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 17.3787(17.4688) | Bit/dim 4.0993(4.1201) | Xent 1.1664(1.2731) | Loss 11.1470(12.2272) | Error 0.4133(0.4565) Steps 640(680.33) | Grad Norm 17.3182(13.9012) | Total Time 0.00(0.00)\n",
      "Iter 1390 | Time 17.9195(17.4309) | Bit/dim 4.0860(4.1122) | Xent 1.2306(1.2673) | Loss 11.3219(11.9688) | Error 0.4544(0.4545) Steps 718(678.67) | Grad Norm 9.9623(14.4265) | Total Time 0.00(0.00)\n",
      "Iter 1400 | Time 17.2235(17.3432) | Bit/dim 4.0790(4.1066) | Xent 1.2559(1.2626) | Loss 11.2064(11.7698) | Error 0.4544(0.4519) Steps 670(675.00) | Grad Norm 20.9471(15.7713) | Total Time 0.00(0.00)\n",
      "Iter 1410 | Time 17.0247(17.2342) | Bit/dim 4.1021(4.0994) | Xent 1.2550(1.2533) | Loss 11.2587(11.6119) | Error 0.4489(0.4482) Steps 652(670.73) | Grad Norm 10.9243(15.2895) | Total Time 0.00(0.00)\n",
      "Iter 1420 | Time 17.3246(17.1834) | Bit/dim 4.0515(4.0944) | Xent 1.1989(1.2441) | Loss 11.0922(11.4875) | Error 0.4289(0.4451) Steps 700(670.17) | Grad Norm 12.7442(16.0284) | Total Time 0.00(0.00)\n",
      "Iter 1430 | Time 16.5970(17.1472) | Bit/dim 4.0856(4.0906) | Xent 1.2126(1.2329) | Loss 11.0211(11.3898) | Error 0.4300(0.4419) Steps 634(665.76) | Grad Norm 19.0067(14.7988) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 91.8516, Epoch Time 1053.4548(902.3035), Bit/dim 4.0699(best: 4.0922), Xent 1.1752, Loss 4.6575, Error 0.4213(best: 0.4445)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 17.0071(17.1186) | Bit/dim 4.1014(4.0862) | Xent 1.2091(1.2156) | Loss 11.0383(11.9310) | Error 0.4267(0.4339) Steps 670(664.49) | Grad Norm 16.1312(14.0961) | Total Time 0.00(0.00)\n",
      "Iter 1450 | Time 17.9917(17.0691) | Bit/dim 4.0548(4.0813) | Xent 1.2456(1.2090) | Loss 10.9959(11.7012) | Error 0.4544(0.4310) Steps 658(659.65) | Grad Norm 14.4325(15.5058) | Total Time 0.00(0.00)\n",
      "Iter 1460 | Time 17.3339(17.0655) | Bit/dim 4.0520(4.0772) | Xent 1.1690(1.2066) | Loss 11.1439(11.5563) | Error 0.4122(0.4299) Steps 682(664.72) | Grad Norm 9.5358(15.2506) | Total Time 0.00(0.00)\n",
      "Iter 1470 | Time 16.3755(17.0844) | Bit/dim 4.0422(4.0743) | Xent 1.1854(1.2035) | Loss 11.0862(11.4441) | Error 0.4222(0.4287) Steps 682(664.43) | Grad Norm 13.0510(16.0117) | Total Time 0.00(0.00)\n",
      "Iter 1480 | Time 17.1044(17.0356) | Bit/dim 4.0500(4.0674) | Xent 1.1837(1.2026) | Loss 11.0279(11.3421) | Error 0.4256(0.4289) Steps 676(662.83) | Grad Norm 12.9786(15.1217) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 90.7449, Epoch Time 1045.3027(906.5935), Bit/dim 4.0482(best: 4.0699), Xent 1.1264, Loss 4.6113, Error 0.4060(best: 0.4213)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 17.9574(16.9947) | Bit/dim 4.0298(4.0618) | Xent 1.0871(1.1835) | Loss 10.6766(11.9260) | Error 0.4044(0.4223) Steps 640(654.69) | Grad Norm 7.1485(14.0408) | Total Time 0.00(0.00)\n",
      "Iter 1500 | Time 18.5481(17.0088) | Bit/dim 4.0393(4.0599) | Xent 1.1004(1.1720) | Loss 10.8108(11.6622) | Error 0.3944(0.4197) Steps 652(651.43) | Grad Norm 10.3398(14.3976) | Total Time 0.00(0.00)\n",
      "Iter 1510 | Time 16.3208(16.9754) | Bit/dim 4.0792(4.0611) | Xent 1.1910(1.1688) | Loss 11.1090(11.5088) | Error 0.4144(0.4169) Steps 658(650.97) | Grad Norm 23.0832(14.9239) | Total Time 0.00(0.00)\n",
      "Iter 1520 | Time 17.1331(16.9338) | Bit/dim 4.0635(4.0567) | Xent 1.0888(1.1584) | Loss 10.9944(11.3678) | Error 0.3911(0.4149) Steps 688(651.75) | Grad Norm 9.7275(14.1538) | Total Time 0.00(0.00)\n",
      "Iter 1530 | Time 17.8893(16.9250) | Bit/dim 4.0155(4.0496) | Xent 1.1489(1.1574) | Loss 10.9500(11.2543) | Error 0.3989(0.4137) Steps 646(651.22) | Grad Norm 13.3562(14.9616) | Total Time 0.00(0.00)\n",
      "Iter 1540 | Time 17.3236(16.8295) | Bit/dim 4.0387(4.0528) | Xent 1.1488(1.1829) | Loss 10.9800(11.2190) | Error 0.4156(0.4217) Steps 610(645.35) | Grad Norm 7.7328(16.9985) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 88.0132, Epoch Time 1035.0710(910.4478), Bit/dim 4.0555(best: 4.0482), Xent 1.2131, Loss 4.6620, Error 0.4326(best: 0.4060)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 17.6407(16.8179) | Bit/dim 4.0540(4.0517) | Xent 1.0862(1.1673) | Loss 10.9847(11.7425) | Error 0.3956(0.4178) Steps 694(646.29) | Grad Norm 9.9007(15.7807) | Total Time 0.00(0.00)\n",
      "Iter 1560 | Time 16.5631(16.8256) | Bit/dim 4.0050(4.0448) | Xent 1.1159(1.1508) | Loss 10.7576(11.5070) | Error 0.3900(0.4102) Steps 616(644.72) | Grad Norm 5.6629(14.5542) | Total Time 0.00(0.00)\n",
      "Iter 1570 | Time 17.2122(16.7900) | Bit/dim 4.0297(4.0375) | Xent 1.1241(1.1353) | Loss 11.0132(11.3439) | Error 0.3856(0.4038) Steps 658(642.96) | Grad Norm 15.2943(13.7829) | Total Time 0.00(0.00)\n",
      "Iter 1580 | Time 17.2294(16.8670) | Bit/dim 4.0354(4.0336) | Xent 1.0738(1.1281) | Loss 10.8544(11.2232) | Error 0.3989(0.4013) Steps 622(645.30) | Grad Norm 17.8398(14.4927) | Total Time 0.00(0.00)\n",
      "Iter 1590 | Time 15.9087(16.8078) | Bit/dim 4.0156(4.0298) | Xent 1.1220(1.1251) | Loss 10.8457(11.1283) | Error 0.4233(0.4008) Steps 592(642.53) | Grad Norm 8.1909(13.5024) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 89.0619, Epoch Time 1032.5713(914.1115), Bit/dim 4.0204(best: 4.0482), Xent 1.1535, Loss 4.5972, Error 0.4166(best: 0.4060)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 17.0869(16.7339) | Bit/dim 4.0021(4.0249) | Xent 1.0673(1.1184) | Loss 10.7770(11.7194) | Error 0.3967(0.3997) Steps 622(639.46) | Grad Norm 12.3974(13.8486) | Total Time 0.00(0.00)\n",
      "Iter 1610 | Time 16.8782(16.7133) | Bit/dim 4.0514(4.0233) | Xent 1.0269(1.1056) | Loss 10.5771(11.4803) | Error 0.3700(0.3947) Steps 640(640.53) | Grad Norm 7.5901(13.8769) | Total Time 0.00(0.00)\n",
      "Iter 1620 | Time 17.2335(16.6392) | Bit/dim 3.9909(4.0190) | Xent 1.0333(1.0949) | Loss 10.6606(11.2861) | Error 0.3556(0.3911) Steps 670(640.22) | Grad Norm 14.7436(13.4887) | Total Time 0.00(0.00)\n",
      "Iter 1630 | Time 16.5975(16.6677) | Bit/dim 3.9859(4.0150) | Xent 1.1267(1.0939) | Loss 10.7043(11.1501) | Error 0.3844(0.3895) Steps 610(635.82) | Grad Norm 20.5994(15.0662) | Total Time 0.00(0.00)\n",
      "Iter 1640 | Time 16.2995(16.5875) | Bit/dim 3.9932(4.0114) | Xent 1.0639(1.1041) | Loss 10.7747(11.0738) | Error 0.3833(0.3942) Steps 628(636.01) | Grad Norm 7.9316(15.5262) | Total Time 0.00(0.00)\n",
      "Iter 1650 | Time 17.1695(16.6972) | Bit/dim 4.0079(4.0082) | Xent 1.1099(1.0983) | Loss 10.8364(10.9980) | Error 0.3878(0.3935) Steps 676(639.75) | Grad Norm 16.2788(15.1073) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 90.5245, Epoch Time 1025.2926(917.4470), Bit/dim 4.0007(best: 4.0204), Xent 1.0978, Loss 4.5496, Error 0.3922(best: 0.4060)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 16.1514(16.7166) | Bit/dim 3.9630(4.0031) | Xent 1.0503(1.0834) | Loss 10.6633(11.5430) | Error 0.3844(0.3872) Steps 646(641.47) | Grad Norm 12.0194(14.4119) | Total Time 0.00(0.00)\n",
      "Iter 1670 | Time 16.9394(16.7772) | Bit/dim 3.9759(4.0006) | Xent 1.0428(1.0734) | Loss 10.7057(11.3483) | Error 0.3956(0.3839) Steps 634(643.83) | Grad Norm 13.8864(13.8677) | Total Time 0.00(0.00)\n",
      "Iter 1680 | Time 16.6136(16.6399) | Bit/dim 3.9637(3.9953) | Xent 1.0401(1.0578) | Loss 10.7092(11.1708) | Error 0.3778(0.3778) Steps 634(639.14) | Grad Norm 7.4610(13.2415) | Total Time 0.00(0.00)\n",
      "Iter 1690 | Time 16.0323(16.5968) | Bit/dim 4.0189(3.9916) | Xent 0.9600(1.0482) | Loss 10.5935(11.0307) | Error 0.3422(0.3749) Steps 616(635.72) | Grad Norm 8.1376(12.8234) | Total Time 0.00(0.00)\n",
      "Iter 1700 | Time 15.4848(16.4814) | Bit/dim 3.9877(3.9894) | Xent 1.1105(1.0439) | Loss 10.8212(10.9349) | Error 0.4122(0.3738) Steps 640(633.74) | Grad Norm 25.6415(12.8408) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 89.6184, Epoch Time 1017.6582(920.4533), Bit/dim 3.9861(best: 4.0007), Xent 1.1285, Loss 4.5503, Error 0.4106(best: 0.3922)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 15.8615(16.4029) | Bit/dim 3.9824(3.9894) | Xent 1.0533(1.0476) | Loss 10.6915(11.5999) | Error 0.3911(0.3766) Steps 634(634.20) | Grad Norm 14.8053(14.4842) | Total Time 0.00(0.00)\n",
      "Iter 1720 | Time 16.1970(16.4027) | Bit/dim 3.9715(3.9893) | Xent 1.0179(1.0422) | Loss 10.7364(11.3693) | Error 0.3589(0.3730) Steps 640(632.88) | Grad Norm 14.6092(14.6315) | Total Time 0.00(0.00)\n",
      "Iter 1730 | Time 17.1333(16.5240) | Bit/dim 3.9783(3.9848) | Xent 0.9976(1.0279) | Loss 10.8079(11.1838) | Error 0.3578(0.3670) Steps 664(635.28) | Grad Norm 11.8025(13.7510) | Total Time 0.00(0.00)\n",
      "Iter 1740 | Time 16.6691(16.4688) | Bit/dim 3.9569(3.9814) | Xent 1.0066(1.0241) | Loss 10.6714(11.0291) | Error 0.3733(0.3658) Steps 616(631.38) | Grad Norm 19.5954(13.6487) | Total Time 0.00(0.00)\n",
      "Iter 1750 | Time 16.9061(16.5057) | Bit/dim 3.9811(3.9790) | Xent 0.9788(1.0311) | Loss 10.7834(10.9527) | Error 0.3200(0.3672) Steps 676(630.79) | Grad Norm 7.9540(14.5211) | Total Time 0.00(0.00)\n",
      "Iter 1760 | Time 16.8380(16.4578) | Bit/dim 3.9501(3.9754) | Xent 0.9850(1.0349) | Loss 10.6462(10.8775) | Error 0.3444(0.3675) Steps 640(629.23) | Grad Norm 9.4366(13.8190) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 87.0395, Epoch Time 1013.2395(923.2369), Bit/dim 3.9709(best: 3.9861), Xent 1.0560, Loss 4.4989, Error 0.3794(best: 0.3922)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 16.0797(16.4259) | Bit/dim 3.9301(3.9714) | Xent 0.9076(1.0157) | Loss 10.5057(11.3935) | Error 0.3489(0.3615) Steps 646(630.51) | Grad Norm 7.2421(12.8000) | Total Time 0.00(0.00)\n",
      "Iter 1780 | Time 16.6091(16.4074) | Bit/dim 3.9472(3.9680) | Xent 0.9651(0.9971) | Loss 10.5061(11.1750) | Error 0.3589(0.3564) Steps 616(629.81) | Grad Norm 7.0009(12.0555) | Total Time 0.00(0.00)\n",
      "Iter 1790 | Time 15.3869(16.3739) | Bit/dim 3.9659(3.9667) | Xent 1.0196(0.9978) | Loss 10.5735(11.0194) | Error 0.3778(0.3558) Steps 622(628.74) | Grad Norm 21.1439(13.7003) | Total Time 0.00(0.00)\n",
      "Iter 1800 | Time 16.0727(16.3657) | Bit/dim 3.9377(3.9621) | Xent 1.0297(0.9957) | Loss 10.4878(10.8935) | Error 0.3667(0.3554) Steps 610(622.66) | Grad Norm 10.2463(13.2592) | Total Time 0.00(0.00)\n",
      "Iter 1810 | Time 15.8038(16.3367) | Bit/dim 3.9475(3.9624) | Xent 1.0250(1.0031) | Loss 10.3279(10.8108) | Error 0.3433(0.3568) Steps 580(621.84) | Grad Norm 10.3382(14.0120) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 86.8057, Epoch Time 1006.6412(925.7390), Bit/dim 3.9417(best: 3.9709), Xent 1.0352, Loss 4.4592, Error 0.3713(best: 0.3794)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 15.7836(16.3790) | Bit/dim 3.9321(3.9582) | Xent 0.9624(0.9909) | Loss 10.5007(11.4068) | Error 0.3533(0.3531) Steps 616(622.87) | Grad Norm 13.4683(13.4088) | Total Time 0.00(0.00)\n",
      "Iter 1830 | Time 17.2283(16.4127) | Bit/dim 3.9590(3.9548) | Xent 0.9457(0.9752) | Loss 10.5165(11.1578) | Error 0.3289(0.3477) Steps 676(625.99) | Grad Norm 9.8792(12.5033) | Total Time 0.00(0.00)\n",
      "Iter 1840 | Time 16.9024(16.5258) | Bit/dim 3.9804(3.9548) | Xent 0.8881(0.9638) | Loss 10.6200(11.0009) | Error 0.3100(0.3436) Steps 598(626.15) | Grad Norm 23.1178(13.0206) | Total Time 0.00(0.00)\n",
      "Iter 1850 | Time 16.5927(16.5399) | Bit/dim 3.9225(3.9519) | Xent 0.9379(0.9666) | Loss 10.5422(10.8793) | Error 0.3389(0.3456) Steps 652(628.87) | Grad Norm 11.4348(13.0399) | Total Time 0.00(0.00)\n",
      "Iter 1860 | Time 16.4738(16.5450) | Bit/dim 3.9544(3.9486) | Xent 1.0005(0.9650) | Loss 10.5938(10.7831) | Error 0.3444(0.3449) Steps 646(627.93) | Grad Norm 8.2283(12.5107) | Total Time 0.00(0.00)\n",
      "Iter 1870 | Time 16.3457(16.5162) | Bit/dim 3.9016(3.9435) | Xent 0.9909(0.9648) | Loss 10.5616(10.7187) | Error 0.3600(0.3443) Steps 622(630.23) | Grad Norm 13.1675(13.6067) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 88.6189, Epoch Time 1019.5768(928.5541), Bit/dim 3.9574(best: 3.9417), Xent 1.0788, Loss 4.4968, Error 0.3824(best: 0.3713)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 15.5903(16.4096) | Bit/dim 3.9089(3.9422) | Xent 0.9102(0.9606) | Loss 10.3519(11.2414) | Error 0.3333(0.3430) Steps 610(629.00) | Grad Norm 16.8005(13.6458) | Total Time 0.00(0.00)\n",
      "Iter 1890 | Time 16.1563(16.3462) | Bit/dim 3.9440(3.9428) | Xent 0.9703(0.9498) | Loss 10.5000(11.0349) | Error 0.3411(0.3385) Steps 616(626.89) | Grad Norm 15.4073(13.3295) | Total Time 0.00(0.00)\n",
      "Iter 1900 | Time 16.8785(16.3967) | Bit/dim 3.9276(3.9382) | Xent 0.8786(0.9385) | Loss 10.3823(10.8615) | Error 0.3211(0.3357) Steps 616(627.66) | Grad Norm 6.7717(12.7432) | Total Time 0.00(0.00)\n",
      "Iter 1910 | Time 17.0344(16.4949) | Bit/dim 3.9094(3.9311) | Xent 0.9008(0.9266) | Loss 10.5166(10.7474) | Error 0.3056(0.3309) Steps 652(630.12) | Grad Norm 7.2551(12.2071) | Total Time 0.00(0.00)\n",
      "Iter 1920 | Time 15.8112(16.4713) | Bit/dim 3.9317(3.9264) | Xent 0.9398(0.9235) | Loss 10.4582(10.6416) | Error 0.3367(0.3288) Steps 628(630.08) | Grad Norm 21.9017(12.3228) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 87.8195, Epoch Time 1009.3041(930.9766), Bit/dim 3.9129(best: 3.9417), Xent 0.9775, Loss 4.4017, Error 0.3474(best: 0.3713)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 15.7211(16.4337) | Bit/dim 3.9234(3.9236) | Xent 0.8742(0.9133) | Loss 10.3546(11.2638) | Error 0.3000(0.3260) Steps 622(628.40) | Grad Norm 9.8756(12.0503) | Total Time 0.00(0.00)\n",
      "Iter 1940 | Time 16.7288(16.4342) | Bit/dim 3.9466(3.9200) | Xent 0.8523(0.9058) | Loss 10.5093(11.0338) | Error 0.3011(0.3231) Steps 670(626.16) | Grad Norm 24.2850(12.0070) | Total Time 0.00(0.00)\n",
      "Iter 1950 | Time 15.8689(16.4058) | Bit/dim 3.8957(3.9193) | Xent 0.9111(0.8980) | Loss 10.3487(10.8580) | Error 0.3211(0.3204) Steps 616(624.09) | Grad Norm 13.0237(11.9120) | Total Time 0.00(0.00)\n",
      "Iter 1960 | Time 16.5474(16.3334) | Bit/dim 3.8912(3.9150) | Xent 0.8739(0.8907) | Loss 10.3780(10.7151) | Error 0.3111(0.3170) Steps 646(626.13) | Grad Norm 9.2551(11.1217) | Total Time 0.00(0.00)\n",
      "Iter 1970 | Time 17.4081(16.4501) | Bit/dim 3.9000(3.9141) | Xent 0.8437(0.8949) | Loss 10.3583(10.6467) | Error 0.3011(0.3179) Steps 652(629.75) | Grad Norm 12.3505(12.7873) | Total Time 0.00(0.00)\n",
      "Iter 1980 | Time 16.4005(16.4399) | Bit/dim 3.8990(3.9140) | Xent 0.8768(0.8891) | Loss 10.3331(10.5665) | Error 0.3200(0.3167) Steps 604(625.08) | Grad Norm 13.4704(12.8729) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 88.9145, Epoch Time 1012.3915(933.4191), Bit/dim 3.9043(best: 3.9129), Xent 0.9870, Loss 4.3978, Error 0.3460(best: 0.3474)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 16.8342(16.4365) | Bit/dim 3.8882(3.9119) | Xent 0.8235(0.8736) | Loss 10.1352(11.0784) | Error 0.2867(0.3108) Steps 622(627.36) | Grad Norm 9.2539(12.7095) | Total Time 0.00(0.00)\n",
      "Iter 2000 | Time 15.9336(16.4394) | Bit/dim 3.9135(3.9093) | Xent 0.8624(0.8665) | Loss 10.3304(10.8707) | Error 0.3167(0.3079) Steps 604(629.13) | Grad Norm 8.5683(12.3938) | Total Time 0.00(0.00)\n",
      "Iter 2010 | Time 16.2765(16.4386) | Bit/dim 3.8947(3.9082) | Xent 0.8334(0.8644) | Loss 10.2537(10.7316) | Error 0.2856(0.3069) Steps 616(630.31) | Grad Norm 7.9410(12.5489) | Total Time 0.00(0.00)\n",
      "Iter 2020 | Time 15.9313(16.4726) | Bit/dim 3.9038(3.9047) | Xent 0.8472(0.8601) | Loss 10.3515(10.6201) | Error 0.3089(0.3058) Steps 628(631.44) | Grad Norm 11.8885(12.5695) | Total Time 0.00(0.00)\n",
      "Iter 2030 | Time 16.9262(16.4784) | Bit/dim 3.8830(3.9027) | Xent 0.9841(0.8699) | Loss 10.4371(10.5468) | Error 0.3367(0.3087) Steps 616(628.97) | Grad Norm 11.9073(12.1039) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 87.6385, Epoch Time 1013.3631(935.8174), Bit/dim 3.8979(best: 3.9043), Xent 0.9771, Loss 4.3864, Error 0.3437(best: 0.3460)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 16.4392(16.4596) | Bit/dim 3.9276(3.8997) | Xent 0.7801(0.8661) | Loss 10.3447(11.1660) | Error 0.2889(0.3082) Steps 628(630.14) | Grad Norm 9.2510(11.9062) | Total Time 0.00(0.00)\n",
      "Iter 2050 | Time 16.2178(16.4376) | Bit/dim 3.8958(3.8967) | Xent 0.9816(0.8559) | Loss 10.4649(10.9311) | Error 0.3489(0.3047) Steps 598(627.87) | Grad Norm 19.4477(11.3269) | Total Time 0.00(0.00)\n",
      "Iter 2060 | Time 15.8188(16.4493) | Bit/dim 3.8744(3.9010) | Xent 0.9334(0.8812) | Loss 10.2158(10.7942) | Error 0.3344(0.3137) Steps 610(626.16) | Grad Norm 11.0759(13.2163) | Total Time 0.00(0.00)\n",
      "Iter 2070 | Time 16.4364(16.4873) | Bit/dim 3.8953(3.9058) | Xent 0.8549(0.8748) | Loss 10.2199(10.6740) | Error 0.3000(0.3109) Steps 598(624.40) | Grad Norm 7.2857(12.4381) | Total Time 0.00(0.00)\n",
      "Iter 2080 | Time 15.7343(16.5019) | Bit/dim 3.8965(3.9007) | Xent 0.8200(0.8653) | Loss 10.2247(10.5672) | Error 0.2856(0.3070) Steps 616(625.39) | Grad Norm 10.0829(11.5322) | Total Time 0.00(0.00)\n",
      "Iter 2090 | Time 15.5928(16.4651) | Bit/dim 3.8230(3.8949) | Xent 0.7699(0.8555) | Loss 9.9631(10.4703) | Error 0.2611(0.3046) Steps 604(624.96) | Grad Norm 9.7959(11.8253) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 88.1891, Epoch Time 1015.1692(938.1980), Bit/dim 3.9073(best: 3.8979), Xent 0.9874, Loss 4.4010, Error 0.3406(best: 0.3437)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 16.3653(16.5094) | Bit/dim 3.8701(3.8927) | Xent 0.8578(0.8434) | Loss 10.2169(10.9840) | Error 0.2989(0.2997) Steps 646(626.35) | Grad Norm 11.4626(11.2932) | Total Time 0.00(0.00)\n",
      "Iter 2110 | Time 16.7222(16.5085) | Bit/dim 3.8766(3.8900) | Xent 0.8277(0.8339) | Loss 10.2154(10.7759) | Error 0.2833(0.2954) Steps 658(625.20) | Grad Norm 17.2841(10.7690) | Total Time 0.00(0.00)\n",
      "Iter 2120 | Time 15.8882(16.4247) | Bit/dim 3.8892(3.8862) | Xent 0.8419(0.8323) | Loss 10.2279(10.6296) | Error 0.2978(0.2969) Steps 640(623.53) | Grad Norm 21.1645(11.6184) | Total Time 0.00(0.00)\n",
      "Iter 2130 | Time 15.9300(16.3739) | Bit/dim 3.8703(3.8850) | Xent 0.8228(0.8333) | Loss 10.1743(10.5290) | Error 0.2989(0.2966) Steps 628(625.26) | Grad Norm 11.4616(11.7827) | Total Time 0.00(0.00)\n",
      "Iter 2140 | Time 17.0156(16.4437) | Bit/dim 3.8415(3.8807) | Xent 0.8733(0.8308) | Loss 10.2068(10.4462) | Error 0.3244(0.2965) Steps 616(626.09) | Grad Norm 22.9390(13.0054) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 89.2044, Epoch Time 1014.3467(940.4824), Bit/dim 3.8879(best: 3.8979), Xent 0.9736, Loss 4.3747, Error 0.3361(best: 0.3406)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 17.3935(16.5035) | Bit/dim 3.8714(3.8817) | Xent 0.7811(0.8222) | Loss 10.2324(11.1022) | Error 0.2744(0.2938) Steps 598(627.04) | Grad Norm 9.4040(13.0109) | Total Time 0.00(0.00)\n",
      "Iter 2160 | Time 15.6020(16.5479) | Bit/dim 3.8795(3.8801) | Xent 0.7719(0.8119) | Loss 10.1859(10.8648) | Error 0.2811(0.2887) Steps 604(626.63) | Grad Norm 12.1128(12.4701) | Total Time 0.00(0.00)\n",
      "Iter 2170 | Time 16.9665(16.5506) | Bit/dim 3.8862(3.8807) | Xent 0.8301(0.8043) | Loss 10.2130(10.6874) | Error 0.2967(0.2857) Steps 640(630.75) | Grad Norm 10.2369(11.6248) | Total Time 0.00(0.00)\n",
      "Iter 2180 | Time 16.3240(16.5970) | Bit/dim 3.8616(3.8778) | Xent 0.7859(0.7994) | Loss 10.1639(10.5508) | Error 0.2767(0.2836) Steps 634(628.56) | Grad Norm 9.4093(10.8333) | Total Time 0.00(0.00)\n",
      "Iter 2190 | Time 16.4353(16.5982) | Bit/dim 3.8450(3.8731) | Xent 0.7911(0.7931) | Loss 10.1621(10.4280) | Error 0.2833(0.2813) Steps 604(628.51) | Grad Norm 12.1441(10.4203) | Total Time 0.00(0.00)\n",
      "Iter 2200 | Time 16.1915(16.6568) | Bit/dim 3.8480(3.8684) | Xent 0.7389(0.7889) | Loss 10.1986(10.3648) | Error 0.2844(0.2805) Steps 646(630.09) | Grad Norm 15.5768(10.5699) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 86.8460, Epoch Time 1025.4984(943.0329), Bit/dim 3.8703(best: 3.8879), Xent 0.9362, Loss 4.3384, Error 0.3288(best: 0.3361)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 16.9591(16.6207) | Bit/dim 3.8539(3.8648) | Xent 0.7739(0.7733) | Loss 10.1819(10.8572) | Error 0.2733(0.2754) Steps 646(630.50) | Grad Norm 8.3620(10.7953) | Total Time 0.00(0.00)\n",
      "Iter 2220 | Time 17.1387(16.7384) | Bit/dim 3.8730(3.8647) | Xent 0.7617(0.7612) | Loss 10.3249(10.6692) | Error 0.2711(0.2705) Steps 670(633.72) | Grad Norm 11.0013(10.5395) | Total Time 0.00(0.00)\n",
      "Iter 2230 | Time 16.5366(16.6328) | Bit/dim 3.8389(3.8635) | Xent 0.7616(0.7630) | Loss 10.1873(10.5318) | Error 0.2722(0.2713) Steps 628(632.08) | Grad Norm 23.3152(11.8707) | Total Time 0.00(0.00)\n",
      "Iter 2240 | Time 16.1909(16.7288) | Bit/dim 3.8279(3.8635) | Xent 0.6811(0.7617) | Loss 9.9479(10.4168) | Error 0.2367(0.2709) Steps 658(630.58) | Grad Norm 14.5214(12.2699) | Total Time 0.00(0.00)\n",
      "Iter 2250 | Time 16.4181(16.7450) | Bit/dim 3.8556(3.8593) | Xent 0.7513(0.7615) | Loss 10.2012(10.3263) | Error 0.2678(0.2705) Steps 634(630.06) | Grad Norm 8.4972(11.5775) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 87.5408, Epoch Time 1028.0649(945.5839), Bit/dim 3.8617(best: 3.8703), Xent 1.0253, Loss 4.3744, Error 0.3431(best: 0.3288)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 16.2584(16.6974) | Bit/dim 3.8455(3.8590) | Xent 0.6820(0.7571) | Loss 10.0715(10.9674) | Error 0.2444(0.2693) Steps 640(631.94) | Grad Norm 7.5150(11.8198) | Total Time 0.00(0.00)\n",
      "Iter 2270 | Time 16.6464(16.7049) | Bit/dim 3.9018(3.8626) | Xent 0.7413(0.7531) | Loss 10.1262(10.7415) | Error 0.2567(0.2668) Steps 604(630.10) | Grad Norm 21.7801(12.9805) | Total Time 0.00(0.00)\n",
      "Iter 2280 | Time 17.6274(16.8373) | Bit/dim 3.8417(3.8605) | Xent 0.7098(0.7427) | Loss 9.9562(10.5662) | Error 0.2422(0.2625) Steps 580(629.91) | Grad Norm 10.5313(12.1172) | Total Time 0.00(0.00)\n",
      "Iter 2290 | Time 17.1174(16.7917) | Bit/dim 3.8433(3.8570) | Xent 0.6949(0.7395) | Loss 10.0800(10.4364) | Error 0.2456(0.2615) Steps 640(629.96) | Grad Norm 9.1576(11.6541) | Total Time 0.00(0.00)\n",
      "Iter 2300 | Time 16.4189(16.7864) | Bit/dim 3.8334(3.8543) | Xent 0.6855(0.7419) | Loss 9.9969(10.3397) | Error 0.2633(0.2633) Steps 634(631.89) | Grad Norm 8.6126(12.7554) | Total Time 0.00(0.00)\n",
      "Iter 2310 | Time 16.7463(16.7216) | Bit/dim 3.8829(3.8557) | Xent 0.7084(0.7477) | Loss 10.0783(10.2827) | Error 0.2467(0.2636) Steps 622(630.73) | Grad Norm 9.0240(12.3060) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 88.8357, Epoch Time 1031.2283(948.1532), Bit/dim 3.8544(best: 3.8617), Xent 0.9590, Loss 4.3339, Error 0.3291(best: 0.3288)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 17.9997(16.7979) | Bit/dim 3.8444(3.8516) | Xent 0.6587(0.7358) | Loss 10.0104(10.8042) | Error 0.2411(0.2598) Steps 700(633.84) | Grad Norm 12.3147(11.8201) | Total Time 0.00(0.00)\n",
      "Iter 2330 | Time 16.5612(16.8322) | Bit/dim 3.8543(3.8508) | Xent 0.6986(0.7283) | Loss 10.1286(10.6095) | Error 0.2422(0.2579) Steps 640(635.14) | Grad Norm 6.5167(11.5672) | Total Time 0.00(0.00)\n",
      "Iter 2340 | Time 17.9158(16.8071) | Bit/dim 3.8198(3.8492) | Xent 0.6956(0.7216) | Loss 9.9288(10.4488) | Error 0.2478(0.2550) Steps 676(634.10) | Grad Norm 5.6617(11.0277) | Total Time 0.00(0.00)\n",
      "Iter 2350 | Time 16.5066(16.7870) | Bit/dim 3.8613(3.8490) | Xent 0.7182(0.7162) | Loss 9.9493(10.3423) | Error 0.2489(0.2524) Steps 610(632.75) | Grad Norm 10.5896(10.8993) | Total Time 0.00(0.00)\n",
      "Iter 2360 | Time 16.5387(16.8491) | Bit/dim 3.8530(3.8463) | Xent 0.6941(0.7177) | Loss 10.1478(10.2738) | Error 0.2511(0.2524) Steps 628(635.11) | Grad Norm 11.5496(11.2583) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 87.3867, Epoch Time 1034.1680(950.7336), Bit/dim 3.8452(best: 3.8544), Xent 0.9414, Loss 4.3159, Error 0.3224(best: 0.3288)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 17.2659(16.7898) | Bit/dim 3.8326(3.8426) | Xent 0.6754(0.7106) | Loss 10.0723(10.9065) | Error 0.2389(0.2506) Steps 610(631.22) | Grad Norm 11.9391(10.8876) | Total Time 0.00(0.00)\n",
      "Iter 2380 | Time 16.4692(16.7875) | Bit/dim 3.8846(3.8438) | Xent 0.7075(0.7062) | Loss 9.9981(10.6763) | Error 0.2678(0.2499) Steps 652(635.24) | Grad Norm 11.6852(10.7148) | Total Time 0.00(0.00)\n",
      "Iter 2390 | Time 16.6392(16.7240) | Bit/dim 3.8309(3.8390) | Xent 0.7146(0.6992) | Loss 10.0435(10.4885) | Error 0.2444(0.2473) Steps 634(636.11) | Grad Norm 6.6293(10.2111) | Total Time 0.00(0.00)\n",
      "Iter 2400 | Time 17.0856(16.7808) | Bit/dim 3.8480(3.8390) | Xent 0.6596(0.6914) | Loss 9.8252(10.3500) | Error 0.2344(0.2452) Steps 646(637.79) | Grad Norm 11.2747(10.0918) | Total Time 0.00(0.00)\n",
      "Iter 2410 | Time 17.2807(16.7634) | Bit/dim 3.8585(3.8377) | Xent 0.6760(0.6964) | Loss 10.1304(10.2785) | Error 0.2411(0.2468) Steps 670(641.73) | Grad Norm 11.9353(10.9585) | Total Time 0.00(0.00)\n",
      "Iter 2420 | Time 16.0044(16.7563) | Bit/dim 3.8146(3.8383) | Xent 0.6889(0.6930) | Loss 9.9080(10.2034) | Error 0.2467(0.2442) Steps 634(639.82) | Grad Norm 8.5446(10.9453) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 87.0505, Epoch Time 1028.6288(953.0705), Bit/dim 3.8299(best: 3.8452), Xent 0.9360, Loss 4.2978, Error 0.3189(best: 0.3224)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 16.4431(16.7421) | Bit/dim 3.8388(3.8389) | Xent 0.6900(0.6806) | Loss 10.0837(10.7416) | Error 0.2567(0.2408) Steps 634(638.53) | Grad Norm 8.8303(10.9286) | Total Time 0.00(0.00)\n",
      "Iter 2440 | Time 16.1498(16.7201) | Bit/dim 3.8297(3.8340) | Xent 0.6760(0.6807) | Loss 9.9848(10.5460) | Error 0.2500(0.2410) Steps 652(640.80) | Grad Norm 10.0112(11.7463) | Total Time 0.00(0.00)\n",
      "Iter 2450 | Time 17.4953(16.8144) | Bit/dim 3.8464(3.8340) | Xent 0.6861(0.6734) | Loss 10.0299(10.3925) | Error 0.2644(0.2402) Steps 646(638.59) | Grad Norm 5.8246(11.2415) | Total Time 0.00(0.00)\n",
      "Iter 2460 | Time 16.7166(16.8530) | Bit/dim 3.8643(3.8353) | Xent 0.6670(0.6711) | Loss 10.0982(10.2927) | Error 0.2333(0.2394) Steps 658(639.57) | Grad Norm 17.2424(12.0719) | Total Time 0.00(0.00)\n",
      "Iter 2470 | Time 16.6537(16.7949) | Bit/dim 3.8397(3.8334) | Xent 0.6895(0.6733) | Loss 10.0341(10.2232) | Error 0.2456(0.2408) Steps 640(638.04) | Grad Norm 12.3124(11.7920) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 85.5355, Epoch Time 1030.9639(955.4073), Bit/dim 3.8298(best: 3.8299), Xent 0.9449, Loss 4.3023, Error 0.3181(best: 0.3189)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 17.0511(16.8561) | Bit/dim 3.8201(3.8293) | Xent 0.6038(0.6571) | Loss 9.8686(10.8414) | Error 0.2133(0.2347) Steps 646(639.09) | Grad Norm 8.8252(10.9645) | Total Time 0.00(0.00)\n",
      "Iter 2490 | Time 16.8655(16.7688) | Bit/dim 3.8493(3.8285) | Xent 0.7134(0.6547) | Loss 10.0548(10.5953) | Error 0.2444(0.2325) Steps 634(637.82) | Grad Norm 13.2864(11.8098) | Total Time 0.00(0.00)\n",
      "Iter 2500 | Time 17.8526(16.8014) | Bit/dim 3.8295(3.8299) | Xent 0.6582(0.6612) | Loss 9.9639(10.4326) | Error 0.2422(0.2354) Steps 628(636.79) | Grad Norm 10.3752(12.4145) | Total Time 0.00(0.00)\n",
      "Iter 2510 | Time 16.5370(16.7554) | Bit/dim 3.8328(3.8293) | Xent 0.6335(0.6627) | Loss 10.0409(10.3114) | Error 0.2422(0.2359) Steps 628(636.21) | Grad Norm 8.1798(13.1331) | Total Time 0.00(0.00)\n",
      "Iter 2520 | Time 15.8188(16.7046) | Bit/dim 3.8283(3.8293) | Xent 0.5881(0.6572) | Loss 9.9546(10.2169) | Error 0.1944(0.2336) Steps 646(635.55) | Grad Norm 8.3922(12.4439) | Total Time 0.00(0.00)\n",
      "Iter 2530 | Time 16.6303(16.7447) | Bit/dim 3.8072(3.8266) | Xent 0.7483(0.6516) | Loss 10.0278(10.1371) | Error 0.2589(0.2311) Steps 628(637.15) | Grad Norm 13.2182(12.0715) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 86.4634, Epoch Time 1026.9039(957.5522), Bit/dim 3.8242(best: 3.8298), Xent 1.0177, Loss 4.3331, Error 0.3367(best: 0.3181)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 17.5113(16.7745) | Bit/dim 3.8202(3.8239) | Xent 0.5605(0.6510) | Loss 9.7572(10.6574) | Error 0.2011(0.2298) Steps 616(635.92) | Grad Norm 15.5273(12.2905) | Total Time 0.00(0.00)\n",
      "Iter 2550 | Time 17.5379(16.8749) | Bit/dim 3.8153(3.8231) | Xent 0.6707(0.6442) | Loss 10.0687(10.4663) | Error 0.2356(0.2278) Steps 652(641.42) | Grad Norm 13.1047(12.6158) | Total Time 0.00(0.00)\n",
      "Iter 2560 | Time 17.3954(16.9042) | Bit/dim 3.8210(3.8243) | Xent 0.6004(0.6345) | Loss 9.8198(10.3155) | Error 0.2178(0.2235) Steps 640(640.38) | Grad Norm 20.0633(12.6173) | Total Time 0.00(0.00)\n",
      "Iter 2570 | Time 16.3349(16.8714) | Bit/dim 3.8050(3.8217) | Xent 0.6349(0.6235) | Loss 9.8695(10.1877) | Error 0.2189(0.2205) Steps 652(639.76) | Grad Norm 7.9378(11.6200) | Total Time 0.00(0.00)\n",
      "Iter 2580 | Time 17.4976(16.9550) | Bit/dim 3.8009(3.8196) | Xent 0.6652(0.6217) | Loss 10.0083(10.1090) | Error 0.2256(0.2189) Steps 610(637.42) | Grad Norm 7.7322(10.7996) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 88.2917, Epoch Time 1044.3451(960.1560), Bit/dim 3.8157(best: 3.8242), Xent 0.9687, Loss 4.3000, Error 0.3229(best: 0.3181)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 16.6257(16.9403) | Bit/dim 3.7932(3.8194) | Xent 0.6022(0.6218) | Loss 9.7948(10.7198) | Error 0.1978(0.2182) Steps 640(638.41) | Grad Norm 10.4451(11.2652) | Total Time 0.00(0.00)\n",
      "Iter 2600 | Time 16.6110(16.9204) | Bit/dim 3.8708(3.8187) | Xent 0.6541(0.6233) | Loss 10.0048(10.5117) | Error 0.2133(0.2200) Steps 580(639.12) | Grad Norm 12.9774(12.2793) | Total Time 0.00(0.00)\n",
      "Iter 2610 | Time 16.9180(16.8563) | Bit/dim 3.8211(3.8222) | Xent 0.5798(0.6231) | Loss 9.8636(10.3629) | Error 0.2133(0.2202) Steps 658(639.15) | Grad Norm 9.3350(11.5061) | Total Time 0.00(0.00)\n",
      "Iter 2620 | Time 17.7877(16.9551) | Bit/dim 3.8165(3.8193) | Xent 0.5750(0.6094) | Loss 9.9889(10.2172) | Error 0.2056(0.2160) Steps 658(644.07) | Grad Norm 5.6629(10.6451) | Total Time 0.00(0.00)\n",
      "Iter 2630 | Time 16.9544(17.0088) | Bit/dim 3.8226(3.8178) | Xent 0.5534(0.6039) | Loss 9.7975(10.1254) | Error 0.2044(0.2133) Steps 658(647.59) | Grad Norm 6.4444(10.5816) | Total Time 0.00(0.00)\n",
      "Iter 2640 | Time 17.0460(17.0662) | Bit/dim 3.8063(3.8129) | Xent 0.5904(0.6036) | Loss 9.7850(10.0575) | Error 0.2022(0.2133) Steps 670(648.25) | Grad Norm 11.9775(10.7976) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 88.3331, Epoch Time 1043.4413(962.6545), Bit/dim 3.8136(best: 3.8157), Xent 1.0073, Loss 4.3172, Error 0.3289(best: 0.3181)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 16.2583(17.0676) | Bit/dim 3.8246(3.8102) | Xent 0.5197(0.5883) | Loss 9.7955(10.5793) | Error 0.1867(0.2086) Steps 670(649.89) | Grad Norm 6.6330(10.0396) | Total Time 0.00(0.00)\n",
      "Iter 2660 | Time 16.3344(17.0734) | Bit/dim 3.8246(3.8106) | Xent 0.5706(0.5827) | Loss 9.7923(10.3773) | Error 0.2033(0.2079) Steps 628(646.56) | Grad Norm 7.8557(9.5909) | Total Time 0.00(0.00)\n",
      "Iter 2670 | Time 17.6553(17.0583) | Bit/dim 3.7916(3.8117) | Xent 0.4591(0.5769) | Loss 9.7627(10.2461) | Error 0.1567(0.2052) Steps 634(644.11) | Grad Norm 16.6852(10.2234) | Total Time 0.00(0.00)\n",
      "Iter 2680 | Time 17.0699(17.0628) | Bit/dim 3.8056(3.8111) | Xent 0.5503(0.5730) | Loss 9.7098(10.1353) | Error 0.1956(0.2035) Steps 598(644.96) | Grad Norm 7.3554(10.0601) | Total Time 0.00(0.00)\n",
      "Iter 2690 | Time 16.5202(17.0396) | Bit/dim 3.7959(3.8105) | Xent 0.6617(0.5813) | Loss 9.9476(10.0581) | Error 0.2278(0.2055) Steps 652(645.10) | Grad Norm 9.5171(11.6747) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 88.0335, Epoch Time 1043.9176(965.0924), Bit/dim 3.8106(best: 3.8136), Xent 1.0021, Loss 4.3117, Error 0.3287(best: 0.3181)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 16.8687(16.9219) | Bit/dim 3.7986(3.8080) | Xent 0.5949(0.5839) | Loss 9.7166(10.6748) | Error 0.2033(0.2062) Steps 640(644.52) | Grad Norm 9.1832(11.7990) | Total Time 0.00(0.00)\n",
      "Iter 2710 | Time 17.5428(16.9474) | Bit/dim 3.8089(3.8057) | Xent 0.5450(0.5673) | Loss 9.7572(10.4267) | Error 0.1867(0.2012) Steps 676(645.82) | Grad Norm 13.2888(11.0297) | Total Time 0.00(0.00)\n",
      "Iter 2720 | Time 17.0755(17.0132) | Bit/dim 3.7936(3.8035) | Xent 0.5010(0.5611) | Loss 9.7938(10.2554) | Error 0.1656(0.1982) Steps 664(647.97) | Grad Norm 11.0082(10.9989) | Total Time 0.00(0.00)\n",
      "Iter 2730 | Time 16.3491(17.0079) | Bit/dim 3.7872(3.8009) | Xent 0.5096(0.5471) | Loss 9.7396(10.1208) | Error 0.1756(0.1926) Steps 658(649.15) | Grad Norm 6.0435(10.0241) | Total Time 0.00(0.00)\n",
      "Iter 2740 | Time 16.9693(17.0526) | Bit/dim 3.7976(3.8030) | Xent 0.6462(0.5529) | Loss 9.8389(10.0413) | Error 0.2200(0.1951) Steps 652(648.99) | Grad Norm 22.6087(11.5493) | Total Time 0.00(0.00)\n",
      "Iter 2750 | Time 17.7692(17.1065) | Bit/dim 3.7664(3.8031) | Xent 0.5760(0.5571) | Loss 9.7091(9.9801) | Error 0.1967(0.1955) Steps 700(646.70) | Grad Norm 6.1591(11.0631) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 89.4602, Epoch Time 1049.2465(967.6171), Bit/dim 3.8086(best: 3.8106), Xent 0.9766, Loss 4.2969, Error 0.3141(best: 0.3181)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 17.1227(17.0821) | Bit/dim 3.7968(3.8013) | Xent 0.4897(0.5363) | Loss 9.8535(10.5088) | Error 0.1733(0.1882) Steps 646(647.00) | Grad Norm 9.6058(10.3275) | Total Time 0.00(0.00)\n",
      "Iter 2770 | Time 17.5817(17.0547) | Bit/dim 3.8228(3.8009) | Xent 0.5094(0.5342) | Loss 9.8795(10.3162) | Error 0.1822(0.1874) Steps 670(648.04) | Grad Norm 11.3048(11.4337) | Total Time 0.00(0.00)\n",
      "Iter 2780 | Time 16.6222(17.0395) | Bit/dim 3.7756(3.8005) | Xent 0.5080(0.5321) | Loss 9.6252(10.1689) | Error 0.1944(0.1868) Steps 634(646.16) | Grad Norm 8.1656(10.9548) | Total Time 0.00(0.00)\n",
      "Iter 2790 | Time 18.3179(17.0698) | Bit/dim 3.8020(3.8036) | Xent 0.5503(0.5377) | Loss 9.9263(10.0803) | Error 0.1900(0.1893) Steps 622(645.09) | Grad Norm 6.4608(11.6665) | Total Time 0.00(0.00)\n",
      "Iter 2800 | Time 16.6468(17.0244) | Bit/dim 3.8452(3.8030) | Xent 0.5415(0.5436) | Loss 9.7613(9.9921) | Error 0.1889(0.1922) Steps 640(644.09) | Grad Norm 9.4301(11.4472) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 88.8493, Epoch Time 1044.0061(969.9087), Bit/dim 3.7995(best: 3.8086), Xent 0.9930, Loss 4.2960, Error 0.3217(best: 0.3141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 16.6394(16.9903) | Bit/dim 3.7829(3.8011) | Xent 0.4324(0.5400) | Loss 9.5619(10.6199) | Error 0.1611(0.1913) Steps 640(646.69) | Grad Norm 9.7452(11.3272) | Total Time 0.00(0.00)\n",
      "Iter 2820 | Time 16.6211(16.9108) | Bit/dim 3.8158(3.7991) | Xent 0.4830(0.5268) | Loss 9.8020(10.3793) | Error 0.1644(0.1866) Steps 658(646.82) | Grad Norm 5.9028(10.5671) | Total Time 0.00(0.00)\n",
      "Iter 2830 | Time 16.6290(16.9852) | Bit/dim 3.7712(3.7973) | Xent 0.5709(0.5241) | Loss 9.6694(10.2068) | Error 0.2100(0.1855) Steps 616(643.98) | Grad Norm 19.2245(10.7021) | Total Time 0.00(0.00)\n",
      "Iter 2840 | Time 17.1878(16.9364) | Bit/dim 3.8009(3.7951) | Xent 0.5167(0.5286) | Loss 9.7870(10.0854) | Error 0.1667(0.1862) Steps 652(646.25) | Grad Norm 9.1843(11.5234) | Total Time 0.00(0.00)\n",
      "Iter 2850 | Time 17.0407(17.0119) | Bit/dim 3.7637(3.7913) | Xent 0.4929(0.5281) | Loss 9.7170(10.0061) | Error 0.1811(0.1866) Steps 664(647.56) | Grad Norm 7.8683(10.9470) | Total Time 0.00(0.00)\n",
      "Iter 2860 | Time 17.3509(16.9838) | Bit/dim 3.8218(3.7962) | Xent 0.5158(0.5277) | Loss 9.7646(9.9487) | Error 0.1900(0.1859) Steps 640(648.05) | Grad Norm 12.5206(11.3568) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 88.7266, Epoch Time 1042.3139(972.0809), Bit/dim 3.7966(best: 3.7995), Xent 1.0116, Loss 4.3024, Error 0.3225(best: 0.3141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 16.3805(16.9022) | Bit/dim 3.7777(3.7964) | Xent 0.5233(0.5171) | Loss 9.7452(10.4906) | Error 0.1822(0.1822) Steps 646(647.70) | Grad Norm 12.3685(11.2070) | Total Time 0.00(0.00)\n",
      "Iter 2880 | Time 17.0988(16.8931) | Bit/dim 3.7948(3.7946) | Xent 0.4680(0.5066) | Loss 9.6683(10.2812) | Error 0.1756(0.1778) Steps 652(647.69) | Grad Norm 9.1919(10.6773) | Total Time 0.00(0.00)\n",
      "Iter 2890 | Time 18.1180(16.9323) | Bit/dim 3.7976(3.7935) | Xent 0.4932(0.4965) | Loss 9.7656(10.1170) | Error 0.1756(0.1748) Steps 688(649.14) | Grad Norm 8.9267(10.4387) | Total Time 0.00(0.00)\n",
      "Iter 2900 | Time 16.4701(16.9397) | Bit/dim 3.7931(3.7904) | Xent 0.4799(0.4896) | Loss 9.7823(9.9992) | Error 0.1656(0.1733) Steps 664(648.54) | Grad Norm 12.6175(10.5223) | Total Time 0.00(0.00)\n",
      "Iter 2910 | Time 16.7922(16.9147) | Bit/dim 3.8145(3.7886) | Xent 0.5114(0.4926) | Loss 9.8478(9.9211) | Error 0.1911(0.1758) Steps 664(647.17) | Grad Norm 10.4445(10.7729) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 87.8735, Epoch Time 1037.8968(974.0554), Bit/dim 3.7893(best: 3.7966), Xent 1.0089, Loss 4.2938, Error 0.3088(best: 0.3141)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 16.8182(16.9129) | Bit/dim 3.7643(3.7860) | Xent 0.3522(0.4800) | Loss 9.4973(10.5368) | Error 0.1200(0.1710) Steps 658(648.14) | Grad Norm 5.0934(10.4678) | Total Time 0.00(0.00)\n",
      "Iter 2930 | Time 17.3983(16.9253) | Bit/dim 3.8139(3.7918) | Xent 0.5727(0.4740) | Loss 9.9782(10.3289) | Error 0.2033(0.1694) Steps 682(648.51) | Grad Norm 18.0268(10.9756) | Total Time 0.00(0.00)\n",
      "Iter 2940 | Time 17.0168(17.0344) | Bit/dim 3.7841(3.7920) | Xent 0.5425(0.4819) | Loss 9.8083(10.1730) | Error 0.1789(0.1715) Steps 670(650.70) | Grad Norm 20.4722(12.5276) | Total Time 0.00(0.00)\n",
      "Iter 2950 | Time 16.3762(17.0392) | Bit/dim 3.7630(3.7915) | Xent 0.4981(0.4870) | Loss 9.5884(10.0526) | Error 0.1678(0.1720) Steps 646(647.19) | Grad Norm 11.3171(12.5742) | Total Time 0.00(0.00)\n",
      "Iter 2960 | Time 17.0823(16.9920) | Bit/dim 3.7993(3.7882) | Xent 0.4724(0.4846) | Loss 9.7487(9.9603) | Error 0.1722(0.1713) Steps 634(648.18) | Grad Norm 11.5069(11.7825) | Total Time 0.00(0.00)\n",
      "Iter 2970 | Time 17.9027(17.0378) | Bit/dim 3.7547(3.7853) | Xent 0.5140(0.4807) | Loss 9.6021(9.8741) | Error 0.1778(0.1692) Steps 694(648.44) | Grad Norm 11.9897(11.4719) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 87.6476, Epoch Time 1045.5886(976.2014), Bit/dim 3.7824(best: 3.7893), Xent 1.0085, Loss 4.2866, Error 0.3138(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 17.3631(16.9880) | Bit/dim 3.8058(3.7838) | Xent 0.3773(0.4702) | Loss 9.6733(10.4195) | Error 0.1356(0.1648) Steps 634(645.69) | Grad Norm 8.3436(10.9386) | Total Time 0.00(0.00)\n",
      "Iter 2990 | Time 16.1707(16.9320) | Bit/dim 3.7875(3.7818) | Xent 0.3943(0.4536) | Loss 9.5062(10.1991) | Error 0.1422(0.1593) Steps 634(644.25) | Grad Norm 9.7411(10.2875) | Total Time 0.00(0.00)\n",
      "Iter 3000 | Time 16.9103(17.0109) | Bit/dim 3.7440(3.7796) | Xent 0.4287(0.4486) | Loss 9.6560(10.0528) | Error 0.1756(0.1577) Steps 658(647.98) | Grad Norm 7.7364(10.3762) | Total Time 0.00(0.00)\n",
      "Iter 3010 | Time 17.7804(16.9302) | Bit/dim 3.7636(3.7773) | Xent 0.5956(0.4521) | Loss 9.6845(9.9431) | Error 0.2044(0.1589) Steps 676(648.22) | Grad Norm 22.4517(10.4890) | Total Time 0.00(0.00)\n",
      "Iter 3020 | Time 16.5494(16.8768) | Bit/dim 3.7853(3.7778) | Xent 0.4698(0.4632) | Loss 9.7060(9.8701) | Error 0.1533(0.1631) Steps 628(645.48) | Grad Norm 7.6404(10.9365) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 88.4160, Epoch Time 1038.3366(978.0654), Bit/dim 3.7859(best: 3.7824), Xent 1.0771, Loss 4.3244, Error 0.3231(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 17.0040(16.8970) | Bit/dim 3.7959(3.7810) | Xent 0.4104(0.4622) | Loss 9.6351(10.5097) | Error 0.1522(0.1631) Steps 628(645.21) | Grad Norm 7.3850(10.4737) | Total Time 0.00(0.00)\n",
      "Iter 3040 | Time 16.8345(16.9185) | Bit/dim 3.7425(3.7793) | Xent 0.4194(0.4491) | Loss 9.6176(10.2794) | Error 0.1511(0.1579) Steps 670(650.10) | Grad Norm 7.9329(9.9661) | Total Time 0.00(0.00)\n",
      "Iter 3050 | Time 17.0173(16.8704) | Bit/dim 3.7893(3.7781) | Xent 0.4088(0.4406) | Loss 9.5824(10.1081) | Error 0.1500(0.1550) Steps 664(650.85) | Grad Norm 10.3933(9.9961) | Total Time 0.00(0.00)\n",
      "Iter 3060 | Time 16.3949(16.8558) | Bit/dim 3.7536(3.7779) | Xent 0.4078(0.4351) | Loss 9.4787(9.9817) | Error 0.1322(0.1523) Steps 646(649.74) | Grad Norm 7.4524(10.1727) | Total Time 0.00(0.00)\n",
      "Iter 3070 | Time 18.0372(16.8855) | Bit/dim 3.7994(3.7774) | Xent 0.4338(0.4401) | Loss 9.7569(9.8940) | Error 0.1389(0.1549) Steps 640(649.44) | Grad Norm 9.5588(10.6002) | Total Time 0.00(0.00)\n",
      "Iter 3080 | Time 17.0900(16.8954) | Bit/dim 3.7756(3.7780) | Xent 0.3985(0.4488) | Loss 9.6294(9.8371) | Error 0.1378(0.1584) Steps 646(651.74) | Grad Norm 8.0880(11.4436) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 87.3608, Epoch Time 1035.2714(979.7816), Bit/dim 3.7850(best: 3.7824), Xent 1.0738, Loss 4.3219, Error 0.3228(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 17.4122(16.8760) | Bit/dim 3.7836(3.7766) | Xent 0.3855(0.4321) | Loss 9.5767(10.3459) | Error 0.1378(0.1535) Steps 634(649.18) | Grad Norm 11.3541(10.6632) | Total Time 0.00(0.00)\n",
      "Iter 3100 | Time 16.5438(16.8601) | Bit/dim 3.7797(3.7764) | Xent 0.3640(0.4151) | Loss 9.5446(10.1393) | Error 0.1289(0.1476) Steps 670(648.89) | Grad Norm 8.6141(10.0670) | Total Time 0.00(0.00)\n",
      "Iter 3110 | Time 17.2073(16.8602) | Bit/dim 3.7669(3.7743) | Xent 0.4963(0.4089) | Loss 9.6817(9.9887) | Error 0.1633(0.1446) Steps 688(648.90) | Grad Norm 11.2955(10.3677) | Total Time 0.00(0.00)\n",
      "Iter 3120 | Time 16.4965(16.8709) | Bit/dim 3.7518(3.7731) | Xent 0.4381(0.4112) | Loss 9.5774(9.8791) | Error 0.1611(0.1462) Steps 652(649.88) | Grad Norm 7.3233(9.9936) | Total Time 0.00(0.00)\n",
      "Iter 3130 | Time 17.4604(16.9333) | Bit/dim 3.7427(3.7710) | Xent 0.4297(0.4172) | Loss 9.5657(9.8159) | Error 0.1656(0.1492) Steps 688(651.15) | Grad Norm 7.7262(9.9169) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 88.3535, Epoch Time 1036.7104(981.4895), Bit/dim 3.7814(best: 3.7824), Xent 1.0729, Loss 4.3178, Error 0.3184(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 16.5178(16.8838) | Bit/dim 3.7604(3.7710) | Xent 0.3199(0.4133) | Loss 9.4496(10.4414) | Error 0.1178(0.1477) Steps 634(647.99) | Grad Norm 9.7825(10.0727) | Total Time 0.00(0.00)\n",
      "Iter 3150 | Time 15.6713(16.8223) | Bit/dim 3.7738(3.7729) | Xent 0.3854(0.3998) | Loss 9.4954(10.1976) | Error 0.1411(0.1431) Steps 646(650.36) | Grad Norm 12.6943(9.4957) | Total Time 0.00(0.00)\n",
      "Iter 3160 | Time 17.0320(16.8408) | Bit/dim 3.7536(3.7686) | Xent 0.3335(0.3903) | Loss 9.5164(10.0219) | Error 0.1211(0.1391) Steps 658(651.00) | Grad Norm 7.4097(9.2928) | Total Time 0.00(0.00)\n",
      "Iter 3170 | Time 16.6022(16.8344) | Bit/dim 3.7514(3.7702) | Xent 0.4699(0.3908) | Loss 9.5459(9.9069) | Error 0.1744(0.1393) Steps 646(653.53) | Grad Norm 19.6468(9.8887) | Total Time 0.00(0.00)\n",
      "Iter 3180 | Time 16.2642(16.8055) | Bit/dim 3.7917(3.7712) | Xent 0.4580(0.3975) | Loss 9.7594(9.8274) | Error 0.1533(0.1400) Steps 634(649.69) | Grad Norm 16.0884(10.6061) | Total Time 0.00(0.00)\n",
      "Iter 3190 | Time 16.7687(16.7987) | Bit/dim 3.7741(3.7726) | Xent 0.3335(0.3948) | Loss 9.5204(9.7682) | Error 0.1211(0.1394) Steps 664(650.76) | Grad Norm 5.7710(10.1770) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 88.4014, Epoch Time 1032.4836(983.0193), Bit/dim 3.7752(best: 3.7814), Xent 1.1503, Loss 4.3503, Error 0.3204(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 17.6658(16.8335) | Bit/dim 3.7723(3.7703) | Xent 0.3561(0.3819) | Loss 9.5367(10.3132) | Error 0.1200(0.1342) Steps 646(650.98) | Grad Norm 9.1765(9.7135) | Total Time 0.00(0.00)\n",
      "Iter 3210 | Time 16.2142(16.8124) | Bit/dim 3.7355(3.7683) | Xent 0.3349(0.3741) | Loss 9.5218(10.0974) | Error 0.1189(0.1325) Steps 658(649.35) | Grad Norm 9.7369(10.1167) | Total Time 0.00(0.00)\n",
      "Iter 3220 | Time 17.2346(16.8206) | Bit/dim 3.7326(3.7656) | Xent 0.4228(0.3712) | Loss 9.5281(9.9341) | Error 0.1522(0.1319) Steps 682(650.65) | Grad Norm 9.7941(10.3186) | Total Time 0.00(0.00)\n",
      "Iter 3230 | Time 17.1392(16.8403) | Bit/dim 3.7395(3.7659) | Xent 0.4246(0.3754) | Loss 9.6136(9.8350) | Error 0.1478(0.1330) Steps 616(651.71) | Grad Norm 14.1117(10.2948) | Total Time 0.00(0.00)\n",
      "Iter 3240 | Time 16.8823(16.8606) | Bit/dim 3.7883(3.7651) | Xent 0.4481(0.3893) | Loss 9.7719(9.7756) | Error 0.1456(0.1377) Steps 658(655.91) | Grad Norm 9.8805(10.9420) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 89.3166, Epoch Time 1034.5979(984.5666), Bit/dim 3.7759(best: 3.7752), Xent 1.1424, Loss 4.3471, Error 0.3203(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 17.3758(16.8246) | Bit/dim 3.7922(3.7665) | Xent 0.2947(0.3821) | Loss 9.5569(10.3918) | Error 0.1044(0.1342) Steps 634(653.81) | Grad Norm 12.6394(10.5988) | Total Time 0.00(0.00)\n",
      "Iter 3260 | Time 16.9982(16.8180) | Bit/dim 3.7507(3.7668) | Xent 0.4075(0.3687) | Loss 9.5146(10.1658) | Error 0.1389(0.1298) Steps 682(654.48) | Grad Norm 16.4728(10.9786) | Total Time 0.00(0.00)\n",
      "Iter 3270 | Time 17.8102(16.8992) | Bit/dim 3.7556(3.7633) | Xent 0.2996(0.3583) | Loss 9.5153(9.9842) | Error 0.1033(0.1257) Steps 652(652.27) | Grad Norm 8.8930(10.8070) | Total Time 0.00(0.00)\n",
      "Iter 3280 | Time 16.7439(16.9299) | Bit/dim 3.7798(3.7630) | Xent 0.3220(0.3559) | Loss 9.4720(9.8624) | Error 0.1122(0.1247) Steps 622(655.16) | Grad Norm 11.3100(10.7940) | Total Time 0.00(0.00)\n",
      "Iter 3290 | Time 17.1051(16.8971) | Bit/dim 3.7615(3.7653) | Xent 0.3092(0.3520) | Loss 9.5695(9.7706) | Error 0.1122(0.1228) Steps 670(656.41) | Grad Norm 11.4561(10.6893) | Total Time 0.00(0.00)\n",
      "Iter 3300 | Time 16.5017(16.8949) | Bit/dim 3.7358(3.7611) | Xent 0.4117(0.3610) | Loss 9.4830(9.7129) | Error 0.1544(0.1259) Steps 670(655.40) | Grad Norm 18.5338(11.2106) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 89.4980, Epoch Time 1041.8185(986.2842), Bit/dim 3.7615(best: 3.7752), Xent 1.1209, Loss 4.3220, Error 0.3165(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 16.8013(16.9097) | Bit/dim 3.7675(3.7637) | Xent 0.3766(0.3584) | Loss 9.5457(10.2977) | Error 0.1289(0.1247) Steps 628(654.28) | Grad Norm 13.3231(11.9060) | Total Time 0.00(0.00)\n",
      "Iter 3320 | Time 16.9044(16.8758) | Bit/dim 3.7603(3.7642) | Xent 0.3704(0.3568) | Loss 9.5139(10.0947) | Error 0.1311(0.1239) Steps 640(652.42) | Grad Norm 9.4464(11.7194) | Total Time 0.00(0.00)\n",
      "Iter 3330 | Time 16.9520(16.8877) | Bit/dim 3.7553(3.7626) | Xent 0.3536(0.3479) | Loss 9.4604(9.9389) | Error 0.1311(0.1218) Steps 682(655.42) | Grad Norm 16.9586(11.7908) | Total Time 0.00(0.00)\n",
      "Iter 3340 | Time 16.8530(16.9152) | Bit/dim 3.7895(3.7584) | Xent 0.3531(0.3425) | Loss 9.5772(9.8165) | Error 0.1322(0.1195) Steps 652(656.11) | Grad Norm 11.9754(11.5004) | Total Time 0.00(0.00)\n",
      "Iter 3350 | Time 17.0591(16.9529) | Bit/dim 3.7523(3.7580) | Xent 0.3133(0.3398) | Loss 9.4465(9.7279) | Error 0.1111(0.1180) Steps 628(655.78) | Grad Norm 12.2558(11.1197) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 87.8030, Epoch Time 1040.8244(987.9204), Bit/dim 3.7729(best: 3.7615), Xent 1.2377, Loss 4.3918, Error 0.3270(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 17.3193(16.9642) | Bit/dim 3.7452(3.7612) | Xent 0.2927(0.3378) | Loss 9.3626(10.3661) | Error 0.1056(0.1180) Steps 670(653.91) | Grad Norm 7.3769(11.2522) | Total Time 0.00(0.00)\n",
      "Iter 3370 | Time 17.3031(16.9556) | Bit/dim 3.7632(3.7582) | Xent 0.3259(0.3301) | Loss 9.4330(10.1139) | Error 0.1056(0.1153) Steps 652(653.91) | Grad Norm 11.6351(10.3887) | Total Time 0.00(0.00)\n",
      "Iter 3380 | Time 16.9894(16.9057) | Bit/dim 3.7650(3.7561) | Xent 0.2999(0.3293) | Loss 9.3974(9.9416) | Error 0.1056(0.1146) Steps 664(653.18) | Grad Norm 6.5830(10.0762) | Total Time 0.00(0.00)\n",
      "Iter 3390 | Time 17.1697(16.8985) | Bit/dim 3.7382(3.7574) | Xent 0.2927(0.3286) | Loss 9.4252(9.8220) | Error 0.1067(0.1144) Steps 664(653.97) | Grad Norm 7.1725(9.7670) | Total Time 0.00(0.00)\n",
      "Iter 3400 | Time 16.8372(16.8847) | Bit/dim 3.7696(3.7560) | Xent 0.3390(0.3320) | Loss 9.6152(9.7406) | Error 0.1156(0.1157) Steps 682(653.28) | Grad Norm 10.9861(9.8127) | Total Time 0.00(0.00)\n",
      "Iter 3410 | Time 17.0618(16.9007) | Bit/dim 3.7106(3.7572) | Xent 0.2754(0.3322) | Loss 9.3366(9.6786) | Error 0.0978(0.1152) Steps 676(656.07) | Grad Norm 8.2004(9.9323) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 88.2491, Epoch Time 1042.9245(989.5705), Bit/dim 3.7697(best: 3.7615), Xent 1.2072, Loss 4.3734, Error 0.3208(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 16.4922(16.9011) | Bit/dim 3.7656(3.7569) | Xent 0.2952(0.3250) | Loss 9.2943(10.2164) | Error 0.0889(0.1118) Steps 640(656.20) | Grad Norm 14.0957(10.3341) | Total Time 0.00(0.00)\n",
      "Iter 3430 | Time 17.2316(16.8463) | Bit/dim 3.7409(3.7561) | Xent 0.3300(0.3209) | Loss 9.4887(10.0114) | Error 0.1122(0.1111) Steps 664(654.14) | Grad Norm 9.2079(10.5178) | Total Time 0.00(0.00)\n",
      "Iter 3440 | Time 17.5163(16.8476) | Bit/dim 3.7035(3.7545) | Xent 0.2704(0.3159) | Loss 9.3002(9.8640) | Error 0.0989(0.1093) Steps 646(650.23) | Grad Norm 7.3221(9.9451) | Total Time 0.00(0.00)\n",
      "Iter 3450 | Time 16.6068(16.8469) | Bit/dim 3.7558(3.7534) | Xent 0.3682(0.3117) | Loss 9.5318(9.7463) | Error 0.1378(0.1082) Steps 676(652.90) | Grad Norm 15.6835(10.1616) | Total Time 0.00(0.00)\n",
      "Iter 3460 | Time 16.9530(16.8795) | Bit/dim 3.7609(3.7526) | Xent 0.3307(0.3186) | Loss 9.4842(9.6737) | Error 0.1144(0.1110) Steps 664(653.90) | Grad Norm 10.7292(10.7177) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 89.0512, Epoch Time 1037.4897(991.0081), Bit/dim 3.7761(best: 3.7615), Xent 1.2604, Loss 4.4063, Error 0.3309(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 16.8424(16.9063) | Bit/dim 3.7545(3.7529) | Xent 0.3317(0.3231) | Loss 9.4216(10.3583) | Error 0.1089(0.1124) Steps 610(654.30) | Grad Norm 16.8218(11.5901) | Total Time 0.00(0.00)\n",
      "Iter 3480 | Time 17.7741(16.9501) | Bit/dim 3.7140(3.7528) | Xent 0.2721(0.3104) | Loss 9.3622(10.1181) | Error 0.1056(0.1086) Steps 682(656.07) | Grad Norm 9.8401(11.1315) | Total Time 0.00(0.00)\n",
      "Iter 3490 | Time 16.9605(16.9428) | Bit/dim 3.7699(3.7529) | Xent 0.2821(0.3031) | Loss 9.4235(9.9231) | Error 0.1000(0.1062) Steps 652(654.09) | Grad Norm 5.8432(10.2497) | Total Time 0.00(0.00)\n",
      "Iter 3500 | Time 16.4948(16.9434) | Bit/dim 3.7304(3.7494) | Xent 0.2931(0.2986) | Loss 9.3602(9.7778) | Error 0.0944(0.1045) Steps 658(653.03) | Grad Norm 7.8290(10.0326) | Total Time 0.00(0.00)\n",
      "Iter 3510 | Time 17.2042(16.9338) | Bit/dim 3.7406(3.7481) | Xent 0.2672(0.2976) | Loss 9.5327(9.7003) | Error 0.0878(0.1037) Steps 682(657.74) | Grad Norm 11.9503(10.5080) | Total Time 0.00(0.00)\n",
      "Iter 3520 | Time 17.4953(17.0586) | Bit/dim 3.7542(3.7491) | Xent 0.2910(0.3019) | Loss 9.3596(9.6344) | Error 0.1033(0.1049) Steps 604(655.85) | Grad Norm 6.5524(10.6247) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 89.0176, Epoch Time 1046.5238(992.6736), Bit/dim 3.7681(best: 3.7615), Xent 1.2498, Loss 4.3930, Error 0.3217(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 16.7215(17.0628) | Bit/dim 3.7465(3.7482) | Xent 0.2571(0.2901) | Loss 9.4449(10.1887) | Error 0.0856(0.1011) Steps 640(656.23) | Grad Norm 13.1332(10.3641) | Total Time 0.00(0.00)\n",
      "Iter 3540 | Time 17.7863(17.0398) | Bit/dim 3.7628(3.7498) | Xent 0.2618(0.2924) | Loss 9.4155(10.0077) | Error 0.0856(0.1016) Steps 658(656.52) | Grad Norm 6.7897(10.6617) | Total Time 0.00(0.00)\n",
      "Iter 3550 | Time 17.4272(17.0473) | Bit/dim 3.7446(3.7488) | Xent 0.3000(0.2918) | Loss 9.3946(9.8572) | Error 0.1056(0.1012) Steps 664(654.66) | Grad Norm 14.9626(10.6924) | Total Time 0.00(0.00)\n",
      "Iter 3560 | Time 17.2890(17.0272) | Bit/dim 3.7245(3.7480) | Xent 0.3126(0.2927) | Loss 9.4065(9.7503) | Error 0.1100(0.1012) Steps 688(658.84) | Grad Norm 13.9296(10.9850) | Total Time 0.00(0.00)\n",
      "Iter 3570 | Time 17.5931(17.0194) | Bit/dim 3.7527(3.7492) | Xent 0.2495(0.2896) | Loss 9.4848(9.6765) | Error 0.0844(0.0997) Steps 682(660.70) | Grad Norm 6.5124(10.6956) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 87.7958, Epoch Time 1043.6863(994.2040), Bit/dim 3.7656(best: 3.7615), Xent 1.2086, Loss 4.3698, Error 0.3203(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 16.8600(16.9638) | Bit/dim 3.7793(3.7470) | Xent 0.2680(0.2885) | Loss 9.4898(10.3197) | Error 0.0867(0.0993) Steps 670(660.61) | Grad Norm 13.6592(10.7797) | Total Time 0.00(0.00)\n",
      "Iter 3590 | Time 16.7614(16.9324) | Bit/dim 3.7134(3.7472) | Xent 0.2249(0.2751) | Loss 9.3038(10.0688) | Error 0.0844(0.0949) Steps 670(655.76) | Grad Norm 7.7582(10.2331) | Total Time 0.00(0.00)\n",
      "Iter 3600 | Time 17.9403(17.0062) | Bit/dim 3.7273(3.7455) | Xent 0.2620(0.2689) | Loss 9.4166(9.8814) | Error 0.1022(0.0933) Steps 622(653.36) | Grad Norm 12.4939(9.8842) | Total Time 0.00(0.00)\n",
      "Iter 3610 | Time 17.2072(17.0279) | Bit/dim 3.7099(3.7440) | Xent 0.2694(0.2689) | Loss 9.2819(9.7497) | Error 0.0967(0.0929) Steps 676(652.60) | Grad Norm 7.6977(9.7717) | Total Time 0.00(0.00)\n",
      "Iter 3620 | Time 17.5187(17.0710) | Bit/dim 3.7314(3.7436) | Xent 0.2736(0.2693) | Loss 9.3466(9.6645) | Error 0.0800(0.0931) Steps 622(652.62) | Grad Norm 14.5821(10.3757) | Total Time 0.00(0.00)\n",
      "Iter 3630 | Time 16.5263(16.9480) | Bit/dim 3.7265(3.7419) | Xent 0.2593(0.2695) | Loss 9.3428(9.5900) | Error 0.0878(0.0937) Steps 670(652.13) | Grad Norm 9.7945(10.1115) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 89.7440, Epoch Time 1043.6389(995.6870), Bit/dim 3.7571(best: 3.7615), Xent 1.2565, Loss 4.3853, Error 0.3116(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 16.8113(16.9167) | Bit/dim 3.7139(3.7413) | Xent 0.2665(0.2624) | Loss 9.4831(10.1636) | Error 0.1056(0.0912) Steps 688(651.68) | Grad Norm 9.1664(10.0864) | Total Time 0.00(0.00)\n",
      "Iter 3650 | Time 18.3046(17.0086) | Bit/dim 3.7855(3.7382) | Xent 0.2883(0.2625) | Loss 9.5122(9.9579) | Error 0.1022(0.0914) Steps 634(655.07) | Grad Norm 9.2828(9.4941) | Total Time 0.00(0.00)\n",
      "Iter 3660 | Time 17.0579(17.0166) | Bit/dim 3.7346(3.7396) | Xent 0.2252(0.2591) | Loss 9.4684(9.8108) | Error 0.0778(0.0906) Steps 658(655.08) | Grad Norm 6.9843(9.2662) | Total Time 0.00(0.00)\n",
      "Iter 3670 | Time 17.4473(16.9793) | Bit/dim 3.7172(3.7363) | Xent 0.2528(0.2537) | Loss 9.3105(9.6868) | Error 0.0889(0.0889) Steps 646(656.73) | Grad Norm 6.9102(9.1881) | Total Time 0.00(0.00)\n",
      "Iter 3680 | Time 19.2135(17.0294) | Bit/dim 3.7454(3.7399) | Xent 0.2874(0.2581) | Loss 9.5041(9.6142) | Error 0.0944(0.0885) Steps 682(657.43) | Grad Norm 9.1096(9.6913) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 89.2967, Epoch Time 1048.3914(997.2681), Bit/dim 3.7428(best: 3.7571), Xent 1.2832, Loss 4.3844, Error 0.3345(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 17.3116(17.0906) | Bit/dim 3.7768(3.7410) | Xent 0.2887(0.2602) | Loss 9.5725(10.2436) | Error 0.0911(0.0892) Steps 670(658.54) | Grad Norm 13.0664(9.7428) | Total Time 0.00(0.00)\n",
      "Iter 3700 | Time 17.3489(17.0733) | Bit/dim 3.7313(3.7405) | Xent 0.2153(0.2546) | Loss 9.3346(10.0035) | Error 0.0667(0.0862) Steps 664(658.22) | Grad Norm 11.4016(9.8820) | Total Time 0.00(0.00)\n",
      "Iter 3710 | Time 16.7460(16.9999) | Bit/dim 3.7531(3.7412) | Xent 0.2456(0.2576) | Loss 9.3825(9.8419) | Error 0.0822(0.0881) Steps 616(657.81) | Grad Norm 6.1719(9.7994) | Total Time 0.00(0.00)\n",
      "Iter 3720 | Time 16.5433(16.8963) | Bit/dim 3.7204(3.7440) | Xent 0.1990(0.2520) | Loss 9.2381(9.7095) | Error 0.0756(0.0869) Steps 652(655.65) | Grad Norm 6.2947(9.1474) | Total Time 0.00(0.00)\n",
      "Iter 3730 | Time 17.7667(16.9414) | Bit/dim 3.7474(3.7402) | Xent 0.2236(0.2511) | Loss 9.3933(9.6075) | Error 0.0689(0.0864) Steps 682(653.73) | Grad Norm 11.7064(9.2223) | Total Time 0.00(0.00)\n",
      "Iter 3740 | Time 17.7260(16.9500) | Bit/dim 3.7388(3.7378) | Xent 0.3236(0.2535) | Loss 9.5487(9.5501) | Error 0.1111(0.0880) Steps 640(655.97) | Grad Norm 15.8885(9.7343) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 89.3067, Epoch Time 1039.6096(998.5384), Bit/dim 3.7431(best: 3.7428), Xent 1.3542, Loss 4.4202, Error 0.3265(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 17.9371(16.9978) | Bit/dim 3.7151(3.7374) | Xent 0.2096(0.2454) | Loss 9.2865(10.0967) | Error 0.0689(0.0851) Steps 694(657.86) | Grad Norm 13.2813(10.2512) | Total Time 0.00(0.00)\n",
      "Iter 3760 | Time 16.2863(16.9434) | Bit/dim 3.7493(3.7371) | Xent 0.3308(0.2431) | Loss 9.3597(9.8978) | Error 0.1156(0.0835) Steps 628(658.25) | Grad Norm 15.2769(9.9621) | Total Time 0.00(0.00)\n",
      "Iter 3770 | Time 16.7675(16.9046) | Bit/dim 3.7331(3.7344) | Xent 0.2487(0.2472) | Loss 9.4354(9.7570) | Error 0.0844(0.0846) Steps 652(657.28) | Grad Norm 8.9040(9.7931) | Total Time 0.00(0.00)\n",
      "Iter 3780 | Time 16.1796(16.9793) | Bit/dim 3.7501(3.7371) | Xent 0.2369(0.2465) | Loss 9.3806(9.6570) | Error 0.0878(0.0849) Steps 622(657.32) | Grad Norm 6.8321(9.6492) | Total Time 0.00(0.00)\n",
      "Iter 3790 | Time 17.6756(17.0015) | Bit/dim 3.7167(3.7377) | Xent 0.1884(0.2408) | Loss 9.4197(9.5818) | Error 0.0700(0.0831) Steps 658(657.01) | Grad Norm 6.1772(9.1687) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 89.2284, Epoch Time 1042.9729(999.8714), Bit/dim 3.7431(best: 3.7428), Xent 1.3650, Loss 4.4256, Error 0.3241(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 16.5123(16.9296) | Bit/dim 3.7623(3.7381) | Xent 0.2137(0.2283) | Loss 9.3305(10.2042) | Error 0.0778(0.0778) Steps 640(654.94) | Grad Norm 9.6451(8.6614) | Total Time 0.00(0.00)\n",
      "Iter 3810 | Time 15.8917(16.8922) | Bit/dim 3.7239(3.7342) | Xent 0.1995(0.2224) | Loss 9.3139(9.9707) | Error 0.0611(0.0759) Steps 628(655.02) | Grad Norm 7.7993(8.8500) | Total Time 0.00(0.00)\n",
      "Iter 3820 | Time 16.2676(16.9202) | Bit/dim 3.7490(3.7333) | Xent 0.2184(0.2249) | Loss 9.3695(9.8065) | Error 0.0778(0.0760) Steps 634(655.20) | Grad Norm 8.1117(9.3411) | Total Time 0.00(0.00)\n",
      "Iter 3830 | Time 16.6750(16.9228) | Bit/dim 3.7357(3.7337) | Xent 0.2378(0.2247) | Loss 9.3880(9.6832) | Error 0.0733(0.0757) Steps 658(655.94) | Grad Norm 7.2839(9.1170) | Total Time 0.00(0.00)\n",
      "Iter 3840 | Time 17.4812(16.9696) | Bit/dim 3.7366(3.7331) | Xent 0.2466(0.2299) | Loss 9.3462(9.5981) | Error 0.0856(0.0778) Steps 652(658.35) | Grad Norm 13.6935(9.5851) | Total Time 0.00(0.00)\n",
      "Iter 3850 | Time 17.2476(16.9344) | Bit/dim 3.7315(3.7334) | Xent 0.1698(0.2298) | Loss 9.3824(9.5372) | Error 0.0633(0.0778) Steps 652(659.21) | Grad Norm 9.0767(9.8348) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 89.5598, Epoch Time 1040.4789(1001.0896), Bit/dim 3.7434(best: 3.7428), Xent 1.3841, Loss 4.4354, Error 0.3267(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 17.3217(16.8904) | Bit/dim 3.7626(3.7362) | Xent 0.3017(0.2244) | Loss 9.4798(10.1145) | Error 0.1078(0.0758) Steps 640(660.45) | Grad Norm 14.0608(9.9595) | Total Time 0.00(0.00)\n",
      "Iter 3870 | Time 17.0285(16.9543) | Bit/dim 3.7566(3.7363) | Xent 0.1875(0.2262) | Loss 9.3222(9.9169) | Error 0.0578(0.0760) Steps 676(663.20) | Grad Norm 8.4050(10.6146) | Total Time 0.00(0.00)\n",
      "Iter 3880 | Time 16.7029(16.9962) | Bit/dim 3.7654(3.7366) | Xent 0.2145(0.2239) | Loss 9.3859(9.7755) | Error 0.0756(0.0750) Steps 670(664.73) | Grad Norm 12.5158(10.9795) | Total Time 0.00(0.00)\n",
      "Iter 3890 | Time 16.7204(16.9851) | Bit/dim 3.6447(3.7316) | Xent 0.2433(0.2277) | Loss 9.1744(9.6520) | Error 0.0833(0.0765) Steps 634(660.72) | Grad Norm 6.7292(11.0183) | Total Time 0.00(0.00)\n",
      "Iter 3900 | Time 17.7604(16.9652) | Bit/dim 3.7355(3.7318) | Xent 0.1979(0.2189) | Loss 9.2921(9.5545) | Error 0.0711(0.0736) Steps 676(661.16) | Grad Norm 5.5449(9.8755) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 89.4049, Epoch Time 1043.0868(1002.3496), Bit/dim 3.7367(best: 3.7428), Xent 1.3488, Loss 4.4111, Error 0.3236(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 16.6212(16.9696) | Bit/dim 3.7272(3.7309) | Xent 0.1941(0.2133) | Loss 9.2801(10.1980) | Error 0.0678(0.0717) Steps 634(659.29) | Grad Norm 10.3845(9.7870) | Total Time 0.00(0.00)\n",
      "Iter 3920 | Time 17.1513(16.9797) | Bit/dim 3.7225(3.7313) | Xent 0.1615(0.2039) | Loss 9.2980(9.9628) | Error 0.0478(0.0683) Steps 652(659.04) | Grad Norm 6.4458(9.3069) | Total Time 0.00(0.00)\n",
      "Iter 3930 | Time 18.4869(17.0444) | Bit/dim 3.7192(3.7279) | Xent 0.2697(0.2081) | Loss 9.3215(9.7892) | Error 0.0844(0.0693) Steps 676(662.10) | Grad Norm 10.9931(9.2649) | Total Time 0.00(0.00)\n",
      "Iter 3940 | Time 17.5316(17.0781) | Bit/dim 3.7538(3.7330) | Xent 0.2590(0.2251) | Loss 9.3377(9.6928) | Error 0.0989(0.0758) Steps 682(664.21) | Grad Norm 6.8996(10.6552) | Total Time 0.00(0.00)\n",
      "Iter 3950 | Time 17.1151(17.1495) | Bit/dim 3.7268(3.7330) | Xent 0.2321(0.2264) | Loss 9.3931(9.6039) | Error 0.0800(0.0771) Steps 652(663.41) | Grad Norm 10.4686(10.6350) | Total Time 0.00(0.00)\n",
      "Iter 3960 | Time 18.5371(17.1623) | Bit/dim 3.7164(3.7339) | Xent 0.2234(0.2323) | Loss 9.3526(9.5483) | Error 0.0767(0.0783) Steps 676(662.14) | Grad Norm 9.0534(10.5425) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 89.4465, Epoch Time 1054.5475(1003.9155), Bit/dim 3.7410(best: 3.7367), Xent 1.3418, Loss 4.4119, Error 0.3291(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 16.6202(17.0238) | Bit/dim 3.7094(3.7351) | Xent 0.1841(0.2260) | Loss 9.1211(10.1020) | Error 0.0689(0.0764) Steps 652(657.46) | Grad Norm 11.2106(10.3417) | Total Time 0.00(0.00)\n",
      "Iter 3980 | Time 16.6427(17.0019) | Bit/dim 3.7185(3.7305) | Xent 0.1802(0.2160) | Loss 9.2504(9.8850) | Error 0.0544(0.0726) Steps 664(657.87) | Grad Norm 6.0170(9.4541) | Total Time 0.00(0.00)\n",
      "Iter 3990 | Time 16.7561(17.0487) | Bit/dim 3.7177(3.7304) | Xent 0.1634(0.2109) | Loss 9.1434(9.7288) | Error 0.0511(0.0714) Steps 646(658.07) | Grad Norm 4.8861(9.8528) | Total Time 0.00(0.00)\n",
      "Iter 4000 | Time 16.1947(17.0262) | Bit/dim 3.7343(3.7308) | Xent 0.3355(0.2193) | Loss 9.3258(9.6298) | Error 0.1011(0.0735) Steps 652(658.45) | Grad Norm 15.7863(9.9618) | Total Time 0.00(0.00)\n",
      "Iter 4010 | Time 16.8666(17.0119) | Bit/dim 3.7112(3.7306) | Xent 0.2515(0.2189) | Loss 9.3258(9.5530) | Error 0.0933(0.0744) Steps 652(657.64) | Grad Norm 12.3571(9.6733) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 89.0732, Epoch Time 1041.1152(1005.0315), Bit/dim 3.7404(best: 3.7367), Xent 1.3566, Loss 4.4187, Error 0.3346(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 16.6930(17.0769) | Bit/dim 3.6953(3.7272) | Xent 0.1917(0.2138) | Loss 9.2918(10.1973) | Error 0.0722(0.0724) Steps 640(659.96) | Grad Norm 16.6532(10.4670) | Total Time 0.00(0.00)\n",
      "Iter 4030 | Time 17.5027(17.0717) | Bit/dim 3.7212(3.7245) | Xent 0.1744(0.2109) | Loss 9.4414(9.9582) | Error 0.0556(0.0717) Steps 652(658.41) | Grad Norm 9.2538(10.3829) | Total Time 0.00(0.00)\n",
      "Iter 4040 | Time 16.9256(17.0644) | Bit/dim 3.7148(3.7243) | Xent 0.1841(0.2082) | Loss 9.3286(9.7865) | Error 0.0556(0.0706) Steps 688(660.91) | Grad Norm 9.5593(9.7377) | Total Time 0.00(0.00)\n",
      "Iter 4050 | Time 16.3425(17.1603) | Bit/dim 3.7544(3.7259) | Xent 0.1890(0.2053) | Loss 9.4088(9.6665) | Error 0.0700(0.0697) Steps 646(661.83) | Grad Norm 5.6327(9.0835) | Total Time 0.00(0.00)\n",
      "Iter 4060 | Time 17.7514(17.2850) | Bit/dim 3.6915(3.7266) | Xent 0.1585(0.2001) | Loss 9.2383(9.5646) | Error 0.0556(0.0678) Steps 688(658.43) | Grad Norm 5.9329(8.9930) | Total Time 0.00(0.00)\n",
      "Iter 4070 | Time 17.1175(17.2731) | Bit/dim 3.7267(3.7286) | Xent 0.2559(0.1972) | Loss 9.2091(9.4880) | Error 0.0789(0.0665) Steps 622(656.85) | Grad Norm 15.7071(9.5317) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 89.3963, Epoch Time 1061.6515(1006.7301), Bit/dim 3.7382(best: 3.7367), Xent 1.4206, Loss 4.4485, Error 0.3210(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 16.8493(17.2019) | Bit/dim 3.7268(3.7266) | Xent 0.1369(0.1897) | Loss 9.2463(10.0225) | Error 0.0467(0.0639) Steps 652(658.80) | Grad Norm 6.0094(9.3246) | Total Time 0.00(0.00)\n",
      "Iter 4090 | Time 16.6216(17.2319) | Bit/dim 3.7285(3.7251) | Xent 0.1990(0.1855) | Loss 9.1811(9.8236) | Error 0.0622(0.0622) Steps 670(663.19) | Grad Norm 7.9950(9.1070) | Total Time 0.00(0.00)\n",
      "Iter 4100 | Time 16.1288(17.2029) | Bit/dim 3.7138(3.7228) | Xent 0.1438(0.1805) | Loss 9.0863(9.6586) | Error 0.0456(0.0609) Steps 634(662.13) | Grad Norm 6.7811(8.7582) | Total Time 0.00(0.00)\n",
      "Iter 4110 | Time 16.7592(17.1269) | Bit/dim 3.7226(3.7201) | Xent 0.1660(0.1805) | Loss 9.2775(9.5469) | Error 0.0644(0.0613) Steps 670(659.00) | Grad Norm 11.4064(8.7740) | Total Time 0.00(0.00)\n",
      "Iter 4120 | Time 16.8047(17.1209) | Bit/dim 3.7408(3.7204) | Xent 0.1736(0.1825) | Loss 9.1413(9.4658) | Error 0.0556(0.0618) Steps 670(660.21) | Grad Norm 9.0661(9.1126) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 88.4425, Epoch Time 1050.4284(1008.0410), Bit/dim 3.7323(best: 3.7367), Xent 1.4693, Loss 4.4669, Error 0.3180(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 17.2418(17.1124) | Bit/dim 3.7172(3.7224) | Xent 0.1835(0.1806) | Loss 9.2545(10.1282) | Error 0.0633(0.0618) Steps 634(660.03) | Grad Norm 8.6153(8.6363) | Total Time 0.00(0.00)\n",
      "Iter 4140 | Time 17.4335(17.1146) | Bit/dim 3.6901(3.7205) | Xent 0.1743(0.1742) | Loss 9.3146(9.8995) | Error 0.0500(0.0593) Steps 628(656.38) | Grad Norm 9.6755(8.5822) | Total Time 0.00(0.00)\n",
      "Iter 4150 | Time 17.6550(17.1347) | Bit/dim 3.7064(3.7179) | Xent 0.1807(0.1723) | Loss 9.2181(9.7174) | Error 0.0600(0.0587) Steps 694(655.33) | Grad Norm 7.6318(8.4284) | Total Time 0.00(0.00)\n",
      "Iter 4160 | Time 17.0799(17.2443) | Bit/dim 3.7098(3.7168) | Xent 0.2162(0.1750) | Loss 9.3279(9.6095) | Error 0.0744(0.0595) Steps 682(657.24) | Grad Norm 16.6666(9.0109) | Total Time 0.00(0.00)\n",
      "Iter 4170 | Time 17.8700(17.2927) | Bit/dim 3.7273(3.7193) | Xent 0.1978(0.1773) | Loss 9.2516(9.5176) | Error 0.0644(0.0598) Steps 640(657.89) | Grad Norm 6.2461(8.9848) | Total Time 0.00(0.00)\n",
      "Iter 4180 | Time 17.2825(17.1598) | Bit/dim 3.7133(3.7186) | Xent 0.2291(0.1786) | Loss 9.2543(9.4361) | Error 0.0744(0.0605) Steps 670(655.85) | Grad Norm 17.6481(9.5213) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 89.4886, Epoch Time 1055.1781(1009.4551), Bit/dim 3.7288(best: 3.7323), Xent 1.4774, Loss 4.4675, Error 0.3260(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 17.5472(17.2497) | Bit/dim 3.7288(3.7171) | Xent 0.1549(0.1776) | Loss 9.1211(9.9875) | Error 0.0433(0.0600) Steps 676(655.96) | Grad Norm 7.0170(9.5112) | Total Time 0.00(0.00)\n",
      "Iter 4200 | Time 16.9183(17.2196) | Bit/dim 3.7364(3.7164) | Xent 0.1405(0.1696) | Loss 9.2501(9.7845) | Error 0.0522(0.0566) Steps 646(654.57) | Grad Norm 8.3216(9.2401) | Total Time 0.00(0.00)\n",
      "Iter 4210 | Time 16.9333(17.1752) | Bit/dim 3.7146(3.7192) | Xent 0.1704(0.1682) | Loss 9.2269(9.6448) | Error 0.0578(0.0554) Steps 658(657.00) | Grad Norm 7.1114(9.4677) | Total Time 0.00(0.00)\n",
      "Iter 4220 | Time 17.2464(17.1523) | Bit/dim 3.7013(3.7172) | Xent 0.2126(0.1731) | Loss 9.2644(9.5386) | Error 0.0667(0.0574) Steps 658(659.60) | Grad Norm 6.4184(9.8517) | Total Time 0.00(0.00)\n",
      "Iter 4230 | Time 16.9458(17.1334) | Bit/dim 3.6769(3.7172) | Xent 0.1581(0.1714) | Loss 9.1257(9.4542) | Error 0.0522(0.0576) Steps 652(659.84) | Grad Norm 6.9102(9.1922) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 89.6117, Epoch Time 1055.7514(1010.8440), Bit/dim 3.7214(best: 3.7288), Xent 1.5283, Loss 4.4855, Error 0.3240(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 17.0985(17.1834) | Bit/dim 3.6880(3.7148) | Xent 0.1277(0.1673) | Loss 9.0166(10.1486) | Error 0.0389(0.0566) Steps 634(661.80) | Grad Norm 9.5205(9.0092) | Total Time 0.00(0.00)\n",
      "Iter 4250 | Time 17.2188(17.1800) | Bit/dim 3.6928(3.7162) | Xent 0.1529(0.1683) | Loss 9.1891(9.9124) | Error 0.0567(0.0573) Steps 658(658.92) | Grad Norm 7.2341(10.3036) | Total Time 0.00(0.00)\n",
      "Iter 4260 | Time 17.1856(17.1983) | Bit/dim 3.7105(3.7184) | Xent 0.1802(0.1694) | Loss 9.3137(9.7474) | Error 0.0656(0.0581) Steps 670(657.29) | Grad Norm 7.3414(9.6881) | Total Time 0.00(0.00)\n",
      "Iter 4270 | Time 17.0610(17.2158) | Bit/dim 3.7337(3.7156) | Xent 0.2160(0.1716) | Loss 9.3790(9.6170) | Error 0.0700(0.0582) Steps 676(660.08) | Grad Norm 10.8007(9.6150) | Total Time 0.00(0.00)\n",
      "Iter 4280 | Time 17.0702(17.2426) | Bit/dim 3.7157(3.7157) | Xent 0.1613(0.1724) | Loss 9.1494(9.5201) | Error 0.0567(0.0588) Steps 646(662.97) | Grad Norm 8.6669(9.5291) | Total Time 0.00(0.00)\n",
      "Iter 4290 | Time 16.5648(17.2616) | Bit/dim 3.7070(3.7150) | Xent 0.1448(0.1690) | Loss 9.1197(9.4334) | Error 0.0500(0.0579) Steps 658(664.52) | Grad Norm 6.9625(8.9999) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 89.0853, Epoch Time 1059.5897(1012.3064), Bit/dim 3.7219(best: 3.7214), Xent 1.5304, Loss 4.4871, Error 0.3328(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 17.5999(17.2666) | Bit/dim 3.7019(3.7144) | Xent 0.1365(0.1638) | Loss 9.1442(10.0053) | Error 0.0378(0.0551) Steps 694(666.16) | Grad Norm 13.2180(8.8850) | Total Time 0.00(0.00)\n",
      "Iter 4310 | Time 17.4426(17.2430) | Bit/dim 3.6987(3.7121) | Xent 0.1512(0.1604) | Loss 9.1673(9.8027) | Error 0.0467(0.0539) Steps 682(667.23) | Grad Norm 8.2860(8.7566) | Total Time 0.00(0.00)\n",
      "Iter 4320 | Time 16.9798(17.2220) | Bit/dim 3.7315(3.7124) | Xent 0.2259(0.1653) | Loss 9.2670(9.6551) | Error 0.0700(0.0550) Steps 676(668.78) | Grad Norm 17.9185(9.4402) | Total Time 0.00(0.00)\n",
      "Iter 4330 | Time 17.0454(17.1653) | Bit/dim 3.7074(3.7131) | Xent 0.1711(0.1783) | Loss 9.2346(9.5520) | Error 0.0578(0.0594) Steps 646(665.46) | Grad Norm 8.9943(9.8764) | Total Time 0.00(0.00)\n",
      "Iter 4340 | Time 17.3589(17.2452) | Bit/dim 3.6755(3.7120) | Xent 0.1486(0.1769) | Loss 9.1845(9.4711) | Error 0.0522(0.0595) Steps 688(665.11) | Grad Norm 7.4628(9.5316) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 91.3397, Epoch Time 1060.9238(1013.7649), Bit/dim 3.7257(best: 3.7214), Xent 1.5377, Loss 4.4946, Error 0.3293(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 16.9596(17.2767) | Bit/dim 3.7435(3.7133) | Xent 0.1473(0.1762) | Loss 9.2610(10.1362) | Error 0.0522(0.0599) Steps 658(662.90) | Grad Norm 11.2637(9.5822) | Total Time 0.00(0.00)\n",
      "Iter 4360 | Time 16.4501(17.2627) | Bit/dim 3.6949(3.7109) | Xent 0.0973(0.1642) | Loss 8.9786(9.8846) | Error 0.0267(0.0553) Steps 646(663.64) | Grad Norm 5.2006(9.1002) | Total Time 0.00(0.00)\n",
      "Iter 4370 | Time 16.4652(17.3146) | Bit/dim 3.7187(3.7101) | Xent 0.1278(0.1602) | Loss 9.2937(9.7136) | Error 0.0456(0.0538) Steps 676(664.55) | Grad Norm 7.7343(8.8755) | Total Time 0.00(0.00)\n",
      "Iter 4380 | Time 16.5880(17.2605) | Bit/dim 3.7426(3.7099) | Xent 0.1959(0.1552) | Loss 9.3539(9.5914) | Error 0.0667(0.0522) Steps 646(661.78) | Grad Norm 16.6213(9.0259) | Total Time 0.00(0.00)\n",
      "Iter 4390 | Time 17.4619(17.2437) | Bit/dim 3.7249(3.7104) | Xent 0.1248(0.1578) | Loss 9.2267(9.5050) | Error 0.0444(0.0530) Steps 700(662.69) | Grad Norm 4.3101(9.3192) | Total Time 0.00(0.00)\n",
      "Iter 4400 | Time 18.0832(17.2050) | Bit/dim 3.6743(3.7084) | Xent 0.1301(0.1540) | Loss 9.1436(9.4295) | Error 0.0478(0.0516) Steps 640(662.73) | Grad Norm 6.0525(8.7373) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 90.3555, Epoch Time 1059.9925(1015.1518), Bit/dim 3.7206(best: 3.7214), Xent 1.5893, Loss 4.5152, Error 0.3283(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 16.7829(17.1193) | Bit/dim 3.6971(3.7089) | Xent 0.1671(0.1484) | Loss 9.2166(9.9666) | Error 0.0567(0.0496) Steps 664(664.13) | Grad Norm 8.7202(8.2436) | Total Time 0.00(0.00)\n",
      "Iter 4420 | Time 17.5047(17.1842) | Bit/dim 3.7000(3.7036) | Xent 0.1027(0.1471) | Loss 9.2390(9.7586) | Error 0.0356(0.0492) Steps 682(665.66) | Grad Norm 6.6240(8.1959) | Total Time 0.00(0.00)\n",
      "Iter 4430 | Time 17.1834(17.2495) | Bit/dim 3.6953(3.7076) | Xent 0.1811(0.1491) | Loss 9.1986(9.6357) | Error 0.0544(0.0502) Steps 658(665.00) | Grad Norm 13.0685(8.8866) | Total Time 0.00(0.00)\n",
      "Iter 4440 | Time 18.1835(17.2859) | Bit/dim 3.7145(3.7094) | Xent 0.1341(0.1501) | Loss 9.2298(9.5314) | Error 0.0478(0.0507) Steps 682(664.68) | Grad Norm 13.9625(9.4517) | Total Time 0.00(0.00)\n",
      "Iter 4450 | Time 17.2197(17.2601) | Bit/dim 3.6801(3.7092) | Xent 0.2086(0.1572) | Loss 9.2856(9.4599) | Error 0.0667(0.0532) Steps 682(667.79) | Grad Norm 11.9757(10.2340) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 90.8288, Epoch Time 1066.7103(1016.6985), Bit/dim 3.7231(best: 3.7206), Xent 1.4908, Loss 4.4685, Error 0.3315(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 17.3926(17.3140) | Bit/dim 3.7292(3.7106) | Xent 0.1444(0.1562) | Loss 9.3460(10.1288) | Error 0.0489(0.0523) Steps 616(669.37) | Grad Norm 6.8911(9.8205) | Total Time 0.00(0.00)\n",
      "Iter 4470 | Time 16.4322(17.3190) | Bit/dim 3.7038(3.7093) | Xent 0.1620(0.1504) | Loss 9.2322(9.8882) | Error 0.0589(0.0506) Steps 646(666.40) | Grad Norm 10.7538(9.2132) | Total Time 0.00(0.00)\n",
      "Iter 4480 | Time 17.4828(17.3175) | Bit/dim 3.6602(3.7070) | Xent 0.1144(0.1457) | Loss 9.0582(9.6968) | Error 0.0422(0.0494) Steps 682(663.79) | Grad Norm 7.4201(8.9703) | Total Time 0.00(0.00)\n",
      "Iter 4490 | Time 17.8561(17.3061) | Bit/dim 3.7186(3.7090) | Xent 0.1426(0.1473) | Loss 9.2052(9.5818) | Error 0.0522(0.0495) Steps 658(665.07) | Grad Norm 9.3648(8.8285) | Total Time 0.00(0.00)\n",
      "Iter 4500 | Time 17.9099(17.2741) | Bit/dim 3.6634(3.7080) | Xent 0.1257(0.1430) | Loss 9.1461(9.4707) | Error 0.0411(0.0479) Steps 712(663.99) | Grad Norm 5.0674(8.3019) | Total Time 0.00(0.00)\n",
      "Iter 4510 | Time 17.8144(17.4096) | Bit/dim 3.7001(3.7059) | Xent 0.1684(0.1406) | Loss 9.2374(9.3932) | Error 0.0467(0.0476) Steps 670(664.13) | Grad Norm 10.9568(8.0951) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 90.7598, Epoch Time 1070.4905(1018.3123), Bit/dim 3.7156(best: 3.7206), Xent 1.6578, Loss 4.5445, Error 0.3280(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 16.8757(17.3017) | Bit/dim 3.7292(3.7052) | Xent 0.1092(0.1364) | Loss 9.2551(9.9453) | Error 0.0400(0.0459) Steps 664(664.30) | Grad Norm 6.4073(7.7711) | Total Time 0.00(0.00)\n",
      "Iter 4530 | Time 16.9943(17.2614) | Bit/dim 3.7126(3.7035) | Xent 0.1646(0.1402) | Loss 9.1702(9.7474) | Error 0.0533(0.0468) Steps 646(664.81) | Grad Norm 16.6461(8.9460) | Total Time 0.00(0.00)\n",
      "Iter 4540 | Time 18.0013(17.2904) | Bit/dim 3.7137(3.7050) | Xent 0.1620(0.1461) | Loss 9.3019(9.6148) | Error 0.0600(0.0487) Steps 652(663.07) | Grad Norm 11.9684(9.5562) | Total Time 0.00(0.00)\n",
      "Iter 4550 | Time 16.7370(17.2739) | Bit/dim 3.7223(3.7049) | Xent 0.1272(0.1530) | Loss 9.1347(9.5157) | Error 0.0422(0.0505) Steps 658(662.67) | Grad Norm 6.8405(9.7785) | Total Time 0.00(0.00)\n",
      "Iter 4560 | Time 17.8280(17.3188) | Bit/dim 3.7018(3.7086) | Xent 0.1788(0.1529) | Loss 9.2079(9.4491) | Error 0.0567(0.0506) Steps 700(664.85) | Grad Norm 10.5975(9.8187) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 89.6006, Epoch Time 1062.0343(1019.6239), Bit/dim 3.7168(best: 3.7156), Xent 1.6667, Loss 4.5501, Error 0.3358(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 17.7575(17.3949) | Bit/dim 3.6990(3.7073) | Xent 0.1494(0.1509) | Loss 9.2262(10.1024) | Error 0.0522(0.0500) Steps 682(668.13) | Grad Norm 5.9270(9.6752) | Total Time 0.00(0.00)\n",
      "Iter 4580 | Time 16.9644(17.3860) | Bit/dim 3.6586(3.7083) | Xent 0.1003(0.1430) | Loss 8.9147(9.8556) | Error 0.0333(0.0470) Steps 664(665.15) | Grad Norm 7.8137(9.0307) | Total Time 0.00(0.00)\n",
      "Iter 4590 | Time 17.3955(17.4698) | Bit/dim 3.7017(3.7069) | Xent 0.1261(0.1383) | Loss 9.1988(9.6802) | Error 0.0467(0.0457) Steps 652(667.63) | Grad Norm 7.0339(8.5319) | Total Time 0.00(0.00)\n",
      "Iter 4600 | Time 17.0647(17.4473) | Bit/dim 3.7084(3.7037) | Xent 0.1611(0.1376) | Loss 9.1416(9.5390) | Error 0.0467(0.0451) Steps 640(666.10) | Grad Norm 6.8432(7.9881) | Total Time 0.00(0.00)\n",
      "Iter 4610 | Time 17.0567(17.4064) | Bit/dim 3.7349(3.7031) | Xent 0.1989(0.1446) | Loss 9.2517(9.4564) | Error 0.0667(0.0468) Steps 628(664.58) | Grad Norm 9.6812(8.5194) | Total Time 0.00(0.00)\n",
      "Iter 4620 | Time 16.7636(17.2993) | Bit/dim 3.7456(3.7007) | Xent 0.1336(0.1466) | Loss 9.3011(9.3840) | Error 0.0422(0.0475) Steps 646(662.82) | Grad Norm 16.8279(9.1159) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 90.0554, Epoch Time 1069.0623(1021.1071), Bit/dim 3.7141(best: 3.7156), Xent 1.5718, Loss 4.5000, Error 0.3313(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 17.0466(17.3026) | Bit/dim 3.6987(3.7025) | Xent 0.1170(0.1420) | Loss 9.1858(9.9569) | Error 0.0289(0.0458) Steps 664(662.91) | Grad Norm 6.9727(9.3230) | Total Time 0.00(0.00)\n",
      "Iter 4640 | Time 17.4766(17.2370) | Bit/dim 3.6738(3.7014) | Xent 0.0989(0.1354) | Loss 9.0544(9.7457) | Error 0.0356(0.0441) Steps 682(662.54) | Grad Norm 5.7986(8.8678) | Total Time 0.00(0.00)\n",
      "Iter 4650 | Time 17.1969(17.2539) | Bit/dim 3.7002(3.6987) | Xent 0.1448(0.1360) | Loss 9.1778(9.5974) | Error 0.0467(0.0451) Steps 664(665.80) | Grad Norm 7.1285(8.8318) | Total Time 0.00(0.00)\n",
      "Iter 4660 | Time 17.0656(17.2484) | Bit/dim 3.6907(3.6988) | Xent 0.1633(0.1387) | Loss 9.2846(9.4815) | Error 0.0500(0.0454) Steps 670(665.58) | Grad Norm 8.7679(8.8165) | Total Time 0.00(0.00)\n",
      "Iter 4670 | Time 17.9713(17.2702) | Bit/dim 3.7103(3.6989) | Xent 0.1351(0.1430) | Loss 9.3118(9.4125) | Error 0.0500(0.0468) Steps 694(667.30) | Grad Norm 7.3241(8.8106) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 91.3458, Epoch Time 1059.9100(1022.2712), Bit/dim 3.7215(best: 3.7141), Xent 1.6213, Loss 4.5321, Error 0.3390(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 17.3273(17.2562) | Bit/dim 3.6999(3.7004) | Xent 0.1442(0.1519) | Loss 9.1805(10.0892) | Error 0.0511(0.0503) Steps 664(667.93) | Grad Norm 10.3999(9.4240) | Total Time 0.00(0.00)\n",
      "Iter 4690 | Time 16.7287(17.3240) | Bit/dim 3.6900(3.7016) | Xent 0.1599(0.1454) | Loss 9.2230(9.8631) | Error 0.0600(0.0485) Steps 652(668.33) | Grad Norm 8.0980(8.9415) | Total Time 0.00(0.00)\n",
      "Iter 4700 | Time 17.3495(17.3152) | Bit/dim 3.7006(3.7009) | Xent 0.1073(0.1438) | Loss 9.2002(9.6860) | Error 0.0311(0.0477) Steps 676(665.79) | Grad Norm 5.1231(8.7087) | Total Time 0.00(0.00)\n",
      "Iter 4710 | Time 17.3790(17.3575) | Bit/dim 3.7175(3.6998) | Xent 0.1362(0.1379) | Loss 9.2550(9.5551) | Error 0.0433(0.0460) Steps 658(664.60) | Grad Norm 6.9791(8.4162) | Total Time 0.00(0.00)\n",
      "Iter 4720 | Time 17.4648(17.3308) | Bit/dim 3.6715(3.6967) | Xent 0.1366(0.1361) | Loss 9.0881(9.4453) | Error 0.0489(0.0453) Steps 652(664.13) | Grad Norm 12.8434(8.7559) | Total Time 0.00(0.00)\n",
      "Iter 4730 | Time 15.9121(17.2082) | Bit/dim 3.7265(3.6994) | Xent 0.1319(0.1396) | Loss 9.1902(9.3879) | Error 0.0411(0.0466) Steps 658(663.51) | Grad Norm 6.2150(9.0901) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 90.7137, Epoch Time 1061.9338(1023.4611), Bit/dim 3.7185(best: 3.7141), Xent 1.6606, Loss 4.5488, Error 0.3434(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 17.0655(17.2390) | Bit/dim 3.6762(3.7002) | Xent 0.0966(0.1356) | Loss 9.0856(9.9397) | Error 0.0344(0.0454) Steps 658(663.79) | Grad Norm 5.7156(8.7431) | Total Time 0.00(0.00)\n",
      "Iter 4750 | Time 17.0429(17.2797) | Bit/dim 3.6798(3.6986) | Xent 0.1081(0.1319) | Loss 9.0757(9.7327) | Error 0.0378(0.0438) Steps 676(666.03) | Grad Norm 6.6603(8.6335) | Total Time 0.00(0.00)\n",
      "Iter 4760 | Time 17.5236(17.3265) | Bit/dim 3.6756(3.6967) | Xent 0.0970(0.1269) | Loss 9.0231(9.5734) | Error 0.0311(0.0420) Steps 658(667.63) | Grad Norm 8.7754(8.2071) | Total Time 0.00(0.00)\n",
      "Iter 4770 | Time 17.6564(17.3291) | Bit/dim 3.6968(3.6968) | Xent 0.1115(0.1243) | Loss 9.1902(9.4735) | Error 0.0389(0.0412) Steps 682(665.77) | Grad Norm 8.8160(8.0734) | Total Time 0.00(0.00)\n",
      "Iter 4780 | Time 17.3651(17.3676) | Bit/dim 3.7003(3.6952) | Xent 0.1815(0.1248) | Loss 9.1778(9.3891) | Error 0.0689(0.0421) Steps 670(664.49) | Grad Norm 15.2416(8.4499) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 90.2371, Epoch Time 1067.7713(1024.7904), Bit/dim 3.7163(best: 3.7141), Xent 1.5470, Loss 4.4898, Error 0.3271(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 17.2492(17.3485) | Bit/dim 3.7129(3.7001) | Xent 0.1145(0.1342) | Loss 9.1731(10.0668) | Error 0.0433(0.0449) Steps 682(667.06) | Grad Norm 11.2081(9.1815) | Total Time 0.00(0.00)\n",
      "Iter 4800 | Time 17.9510(17.3821) | Bit/dim 3.7302(3.7044) | Xent 0.1194(0.1374) | Loss 9.2343(9.8509) | Error 0.0344(0.0455) Steps 682(671.14) | Grad Norm 7.8574(9.0915) | Total Time 0.00(0.00)\n",
      "Iter 4810 | Time 17.8634(17.3467) | Bit/dim 3.6777(3.7028) | Xent 0.1207(0.1351) | Loss 9.1895(9.6699) | Error 0.0367(0.0449) Steps 676(670.97) | Grad Norm 9.7491(9.3817) | Total Time 0.00(0.00)\n",
      "Iter 4820 | Time 17.6981(17.3268) | Bit/dim 3.6560(3.6988) | Xent 0.1376(0.1325) | Loss 9.2335(9.5426) | Error 0.0456(0.0442) Steps 700(672.26) | Grad Norm 6.9447(9.1291) | Total Time 0.00(0.00)\n",
      "Iter 4830 | Time 17.5564(17.3049) | Bit/dim 3.6902(3.6977) | Xent 0.1403(0.1278) | Loss 9.2103(9.4411) | Error 0.0422(0.0426) Steps 676(670.04) | Grad Norm 8.1813(8.8852) | Total Time 0.00(0.00)\n",
      "Iter 4840 | Time 17.3786(17.3433) | Bit/dim 3.7033(3.6960) | Xent 0.1512(0.1327) | Loss 9.1928(9.3746) | Error 0.0544(0.0448) Steps 688(671.61) | Grad Norm 5.9306(9.0781) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 90.5811, Epoch Time 1065.0035(1025.9968), Bit/dim 3.7128(best: 3.7141), Xent 1.5782, Loss 4.5019, Error 0.3269(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 17.6550(17.4645) | Bit/dim 3.7421(3.6954) | Xent 0.1443(0.1303) | Loss 9.1655(9.9628) | Error 0.0433(0.0440) Steps 640(669.60) | Grad Norm 12.0144(8.8841) | Total Time 0.00(0.00)\n",
      "Iter 4860 | Time 17.6287(17.4105) | Bit/dim 3.6973(3.6937) | Xent 0.0913(0.1265) | Loss 9.1269(9.7382) | Error 0.0267(0.0425) Steps 676(669.99) | Grad Norm 5.7600(8.6659) | Total Time 0.00(0.00)\n",
      "Iter 4870 | Time 17.4991(17.3968) | Bit/dim 3.7001(3.6924) | Xent 0.1294(0.1267) | Loss 9.2202(9.5824) | Error 0.0422(0.0421) Steps 664(664.25) | Grad Norm 7.0364(8.8101) | Total Time 0.00(0.00)\n",
      "Iter 4880 | Time 16.7149(17.3858) | Bit/dim 3.6802(3.6915) | Xent 0.1096(0.1255) | Loss 9.0169(9.4653) | Error 0.0378(0.0420) Steps 652(664.24) | Grad Norm 9.8729(8.5833) | Total Time 0.00(0.00)\n",
      "Iter 4890 | Time 17.4804(17.3848) | Bit/dim 3.6741(3.6892) | Xent 0.1340(0.1257) | Loss 9.1798(9.3817) | Error 0.0444(0.0412) Steps 676(665.97) | Grad Norm 6.7757(8.2966) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 90.7140, Epoch Time 1068.6066(1027.2750), Bit/dim 3.7023(best: 3.7128), Xent 1.6120, Loss 4.5083, Error 0.3222(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 17.5581(17.3561) | Bit/dim 3.6905(3.6904) | Xent 0.1079(0.1296) | Loss 9.1570(10.0537) | Error 0.0389(0.0426) Steps 664(667.17) | Grad Norm 5.0655(8.8153) | Total Time 0.00(0.00)\n",
      "Iter 4910 | Time 16.9913(17.3721) | Bit/dim 3.6939(3.6922) | Xent 0.1904(0.1413) | Loss 9.2439(9.8341) | Error 0.0756(0.0468) Steps 658(667.64) | Grad Norm 13.2022(9.4118) | Total Time 0.00(0.00)\n",
      "Iter 4920 | Time 17.2940(17.3316) | Bit/dim 3.7344(3.6955) | Xent 0.1755(0.1425) | Loss 9.3528(9.6615) | Error 0.0544(0.0469) Steps 688(665.67) | Grad Norm 11.6531(9.4367) | Total Time 0.00(0.00)\n",
      "Iter 4930 | Time 17.5586(17.2890) | Bit/dim 3.7095(3.6972) | Xent 0.1532(0.1469) | Loss 9.2452(9.5466) | Error 0.0544(0.0492) Steps 676(666.25) | Grad Norm 13.6711(9.7716) | Total Time 0.00(0.00)\n",
      "Iter 4940 | Time 16.6258(17.3005) | Bit/dim 3.7132(3.6974) | Xent 0.1061(0.1433) | Loss 9.0345(9.4439) | Error 0.0333(0.0477) Steps 676(665.49) | Grad Norm 6.9217(9.6771) | Total Time 0.00(0.00)\n",
      "Iter 4950 | Time 17.2515(17.2215) | Bit/dim 3.6733(3.6946) | Xent 0.1381(0.1439) | Loss 9.1720(9.3690) | Error 0.0433(0.0469) Steps 664(664.24) | Grad Norm 8.4508(9.6208) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 89.9324, Epoch Time 1061.7700(1028.3099), Bit/dim 3.7092(best: 3.7023), Xent 1.5445, Loss 4.4815, Error 0.3252(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 16.6653(17.2433) | Bit/dim 3.7157(3.6957) | Xent 0.0622(0.1334) | Loss 9.0902(9.9293) | Error 0.0156(0.0434) Steps 670(666.26) | Grad Norm 4.2354(8.7851) | Total Time 0.00(0.00)\n",
      "Iter 4970 | Time 18.0745(17.3674) | Bit/dim 3.6878(3.6933) | Xent 0.1100(0.1247) | Loss 9.1297(9.7190) | Error 0.0322(0.0407) Steps 682(665.83) | Grad Norm 7.9233(8.2215) | Total Time 0.00(0.00)\n",
      "Iter 4980 | Time 18.5107(17.4120) | Bit/dim 3.6722(3.6907) | Xent 0.0834(0.1167) | Loss 9.1972(9.5576) | Error 0.0333(0.0386) Steps 652(664.81) | Grad Norm 6.4608(7.7601) | Total Time 0.00(0.00)\n",
      "Iter 4990 | Time 16.7429(17.3738) | Bit/dim 3.6743(3.6870) | Xent 0.1014(0.1122) | Loss 9.1079(9.4375) | Error 0.0367(0.0370) Steps 670(662.63) | Grad Norm 7.1722(7.1341) | Total Time 0.00(0.00)\n",
      "Iter 5000 | Time 17.4898(17.3962) | Bit/dim 3.6804(3.6846) | Xent 0.1175(0.1062) | Loss 9.1405(9.3411) | Error 0.0422(0.0347) Steps 670(661.48) | Grad Norm 8.8952(7.0452) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 91.5549, Epoch Time 1071.8696(1029.6167), Bit/dim 3.7007(best: 3.7023), Xent 1.6976, Loss 4.5495, Error 0.3303(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 17.1274(17.3723) | Bit/dim 3.7228(3.6822) | Xent 0.1011(0.1026) | Loss 9.2482(10.0058) | Error 0.0344(0.0333) Steps 676(659.17) | Grad Norm 7.2496(6.9111) | Total Time 0.00(0.00)\n",
      "Iter 5020 | Time 16.8579(17.4037) | Bit/dim 3.6844(3.6821) | Xent 0.0700(0.0986) | Loss 9.0756(9.7723) | Error 0.0211(0.0324) Steps 676(660.93) | Grad Norm 6.0614(7.1376) | Total Time 0.00(0.00)\n",
      "Iter 5030 | Time 16.7076(17.3904) | Bit/dim 3.6521(3.6830) | Xent 0.1193(0.0977) | Loss 9.0094(9.5941) | Error 0.0467(0.0319) Steps 658(661.07) | Grad Norm 6.2308(6.9061) | Total Time 0.00(0.00)\n",
      "Iter 5040 | Time 17.2716(17.3842) | Bit/dim 3.6751(3.6836) | Xent 0.0825(0.0998) | Loss 9.1695(9.4710) | Error 0.0289(0.0323) Steps 670(662.74) | Grad Norm 4.8847(7.0814) | Total Time 0.00(0.00)\n",
      "Iter 5050 | Time 18.4588(17.4253) | Bit/dim 3.6840(3.6834) | Xent 0.1334(0.1054) | Loss 9.0825(9.3739) | Error 0.0500(0.0343) Steps 688(662.44) | Grad Norm 13.0406(7.8968) | Total Time 0.00(0.00)\n",
      "Iter 5060 | Time 18.0670(17.5176) | Bit/dim 3.6981(3.6839) | Xent 0.1010(0.1146) | Loss 9.1364(9.3143) | Error 0.0333(0.0373) Steps 640(661.56) | Grad Norm 8.2439(8.6891) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 89.8937, Epoch Time 1074.9506(1030.9767), Bit/dim 3.7066(best: 3.7007), Xent 1.6187, Loss 4.5160, Error 0.3287(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 16.8644(17.4394) | Bit/dim 3.6944(3.6832) | Xent 0.1065(0.1127) | Loss 9.0490(9.8672) | Error 0.0278(0.0365) Steps 676(662.89) | Grad Norm 7.3233(8.1627) | Total Time 0.00(0.00)\n",
      "Iter 5080 | Time 17.2197(17.4861) | Bit/dim 3.6807(3.6834) | Xent 0.1010(0.1120) | Loss 9.1379(9.6831) | Error 0.0344(0.0365) Steps 676(664.13) | Grad Norm 8.7903(7.9865) | Total Time 0.00(0.00)\n",
      "Iter 5090 | Time 16.8285(17.3539) | Bit/dim 3.6392(3.6832) | Xent 0.0935(0.1125) | Loss 9.0072(9.5380) | Error 0.0311(0.0366) Steps 676(662.00) | Grad Norm 5.0488(8.0008) | Total Time 0.00(0.00)\n",
      "Iter 5100 | Time 17.1051(17.3316) | Bit/dim 3.7011(3.6872) | Xent 0.1130(0.1102) | Loss 9.0113(9.4325) | Error 0.0467(0.0358) Steps 634(662.13) | Grad Norm 7.3774(8.0125) | Total Time 0.00(0.00)\n",
      "Iter 5110 | Time 17.4667(17.2807) | Bit/dim 3.6883(3.6827) | Xent 0.1227(0.1116) | Loss 9.0803(9.3405) | Error 0.0344(0.0356) Steps 664(662.48) | Grad Norm 8.5044(7.9618) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 90.3814, Epoch Time 1063.1995(1031.9434), Bit/dim 3.6968(best: 3.7007), Xent 1.5584, Loss 4.4760, Error 0.3321(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 18.0219(17.3306) | Bit/dim 3.6952(3.6843) | Xent 0.0771(0.1098) | Loss 9.1279(9.9881) | Error 0.0256(0.0355) Steps 682(663.81) | Grad Norm 4.5532(7.6614) | Total Time 0.00(0.00)\n",
      "Iter 5130 | Time 18.1306(17.4177) | Bit/dim 3.7086(3.6856) | Xent 0.1345(0.1043) | Loss 9.2567(9.7714) | Error 0.0433(0.0336) Steps 664(664.30) | Grad Norm 8.0280(7.2146) | Total Time 0.00(0.00)\n",
      "Iter 5140 | Time 17.8634(17.4649) | Bit/dim 3.7042(3.6844) | Xent 0.1666(0.1072) | Loss 9.3110(9.6128) | Error 0.0511(0.0346) Steps 688(668.18) | Grad Norm 16.7078(7.5647) | Total Time 0.00(0.00)\n",
      "Iter 5150 | Time 17.5344(17.5269) | Bit/dim 3.6932(3.6844) | Xent 0.1103(0.1111) | Loss 9.2648(9.4932) | Error 0.0400(0.0359) Steps 694(671.02) | Grad Norm 6.0020(7.8655) | Total Time 0.00(0.00)\n",
      "Iter 5160 | Time 17.6580(17.5297) | Bit/dim 3.6823(3.6837) | Xent 0.1089(0.1061) | Loss 9.0644(9.3891) | Error 0.0344(0.0345) Steps 682(675.19) | Grad Norm 7.1306(7.5056) | Total Time 0.00(0.00)\n",
      "Iter 5170 | Time 17.2872(17.4955) | Bit/dim 3.6832(3.6801) | Xent 0.1044(0.1075) | Loss 9.0268(9.3170) | Error 0.0322(0.0348) Steps 664(672.89) | Grad Norm 6.7164(7.4929) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 90.8590, Epoch Time 1078.4669(1033.3391), Bit/dim 3.6917(best: 3.6968), Xent 1.6919, Loss 4.5376, Error 0.3316(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 17.9459(17.4652) | Bit/dim 3.6835(3.6803) | Xent 0.0692(0.1030) | Loss 9.1278(9.8702) | Error 0.0211(0.0331) Steps 676(673.61) | Grad Norm 7.6638(7.4815) | Total Time 0.00(0.00)\n",
      "Iter 5190 | Time 17.1185(17.5587) | Bit/dim 3.6866(3.6817) | Xent 0.0782(0.0993) | Loss 9.0159(9.6755) | Error 0.0244(0.0317) Steps 688(673.96) | Grad Norm 9.1888(7.6384) | Total Time 0.00(0.00)\n",
      "Iter 5200 | Time 16.4557(17.4547) | Bit/dim 3.7022(3.6809) | Xent 0.1112(0.0983) | Loss 9.1388(9.5227) | Error 0.0400(0.0319) Steps 652(673.11) | Grad Norm 8.4912(7.7909) | Total Time 0.00(0.00)\n",
      "Iter 5210 | Time 16.9218(17.4945) | Bit/dim 3.6861(3.6799) | Xent 0.1089(0.1051) | Loss 9.2051(9.4225) | Error 0.0367(0.0339) Steps 658(673.09) | Grad Norm 7.6066(8.4698) | Total Time 0.00(0.00)\n",
      "Iter 5220 | Time 16.3611(17.4230) | Bit/dim 3.6845(3.6776) | Xent 0.0951(0.1081) | Loss 9.0136(9.3428) | Error 0.0367(0.0352) Steps 652(671.98) | Grad Norm 5.8203(8.0764) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 89.4144, Epoch Time 1076.5078(1034.6342), Bit/dim 3.6947(best: 3.6917), Xent 1.6948, Loss 4.5421, Error 0.3343(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 16.7285(17.3749) | Bit/dim 3.7036(3.6799) | Xent 0.0745(0.1051) | Loss 8.8388(9.9907) | Error 0.0267(0.0345) Steps 670(667.91) | Grad Norm 9.1627(7.5835) | Total Time 0.00(0.00)\n",
      "Iter 5240 | Time 17.2927(17.3487) | Bit/dim 3.7072(3.6822) | Xent 0.0909(0.1043) | Loss 9.2616(9.7767) | Error 0.0289(0.0336) Steps 640(665.50) | Grad Norm 6.9030(7.6327) | Total Time 0.00(0.00)\n",
      "Iter 5250 | Time 16.9970(17.3633) | Bit/dim 3.6509(3.6771) | Xent 0.0630(0.1001) | Loss 8.9112(9.5863) | Error 0.0178(0.0318) Steps 670(664.23) | Grad Norm 5.0147(7.3685) | Total Time 0.00(0.00)\n",
      "Iter 5260 | Time 18.0008(17.4362) | Bit/dim 3.6920(3.6765) | Xent 0.0514(0.0959) | Loss 9.0841(9.4518) | Error 0.0144(0.0305) Steps 628(666.07) | Grad Norm 3.3681(6.9957) | Total Time 0.00(0.00)\n",
      "Iter 5270 | Time 17.0465(17.3820) | Bit/dim 3.6702(3.6760) | Xent 0.0834(0.0922) | Loss 9.1554(9.3519) | Error 0.0278(0.0291) Steps 676(667.78) | Grad Norm 8.9178(6.8977) | Total Time 0.00(0.00)\n",
      "Iter 5280 | Time 17.7774(17.3859) | Bit/dim 3.6244(3.6731) | Xent 0.0831(0.0926) | Loss 9.0189(9.2776) | Error 0.0344(0.0300) Steps 616(666.25) | Grad Norm 9.8859(6.9182) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 90.2020, Epoch Time 1067.8088(1035.6294), Bit/dim 3.6902(best: 3.6917), Xent 1.6884, Loss 4.5344, Error 0.3235(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 17.3847(17.4311) | Bit/dim 3.6452(3.6721) | Xent 0.1212(0.0955) | Loss 9.0333(9.8418) | Error 0.0400(0.0310) Steps 670(668.97) | Grad Norm 7.2225(7.3786) | Total Time 0.00(0.00)\n",
      "Iter 5300 | Time 16.2687(17.4617) | Bit/dim 3.6737(3.6763) | Xent 0.1029(0.0969) | Loss 9.1343(9.6516) | Error 0.0300(0.0309) Steps 646(668.93) | Grad Norm 10.3445(7.7393) | Total Time 0.00(0.00)\n",
      "Iter 5310 | Time 18.0275(17.4733) | Bit/dim 3.6689(3.6749) | Xent 0.1024(0.1025) | Loss 9.1092(9.5061) | Error 0.0300(0.0333) Steps 676(670.44) | Grad Norm 10.3931(8.0992) | Total Time 0.00(0.00)\n",
      "Iter 5320 | Time 17.2894(17.5082) | Bit/dim 3.6752(3.6796) | Xent 0.1153(0.1087) | Loss 9.1287(9.4215) | Error 0.0400(0.0350) Steps 664(672.83) | Grad Norm 10.6312(9.0641) | Total Time 0.00(0.00)\n",
      "Iter 5330 | Time 17.7948(17.4882) | Bit/dim 3.6974(3.6839) | Xent 0.1011(0.1134) | Loss 9.2990(9.3562) | Error 0.0333(0.0366) Steps 700(674.17) | Grad Norm 8.9243(9.0264) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 93.7411, Epoch Time 1082.4397(1037.0337), Bit/dim 3.6951(best: 3.6902), Xent 1.6007, Loss 4.4954, Error 0.3246(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 16.9673(17.4653) | Bit/dim 3.7169(3.6817) | Xent 0.0870(0.1137) | Loss 9.1857(10.0143) | Error 0.0289(0.0367) Steps 658(675.16) | Grad Norm 7.9267(8.9337) | Total Time 0.00(0.00)\n",
      "Iter 5350 | Time 18.0739(17.4332) | Bit/dim 3.6746(3.6799) | Xent 0.0789(0.1075) | Loss 9.0042(9.7702) | Error 0.0222(0.0351) Steps 676(672.67) | Grad Norm 7.6859(8.4235) | Total Time 0.00(0.00)\n",
      "Iter 5360 | Time 17.7545(17.4187) | Bit/dim 3.7218(3.6787) | Xent 0.1090(0.1091) | Loss 9.1769(9.6009) | Error 0.0256(0.0352) Steps 664(672.85) | Grad Norm 5.7458(8.1887) | Total Time 0.00(0.00)\n",
      "Iter 5370 | Time 17.7384(17.4986) | Bit/dim 3.6646(3.6786) | Xent 0.1117(0.1100) | Loss 8.9745(9.4657) | Error 0.0411(0.0362) Steps 670(671.24) | Grad Norm 6.5851(7.9781) | Total Time 0.00(0.00)\n",
      "Iter 5380 | Time 17.9710(17.5926) | Bit/dim 3.6944(3.6782) | Xent 0.1038(0.1112) | Loss 9.1406(9.3746) | Error 0.0333(0.0363) Steps 670(671.86) | Grad Norm 11.5212(8.5086) | Total Time 0.00(0.00)\n",
      "Iter 5390 | Time 17.0790(17.5520) | Bit/dim 3.6706(3.6766) | Xent 0.0992(0.1073) | Loss 9.1180(9.3028) | Error 0.0300(0.0354) Steps 646(667.35) | Grad Norm 7.2099(8.1876) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 90.2655, Epoch Time 1077.9996(1038.2627), Bit/dim 3.6901(best: 3.6902), Xent 1.6917, Loss 4.5360, Error 0.3253(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 17.4298(17.5542) | Bit/dim 3.6960(3.6783) | Xent 0.1080(0.1055) | Loss 9.1925(9.8541) | Error 0.0378(0.0350) Steps 688(670.26) | Grad Norm 12.6374(8.5889) | Total Time 0.00(0.00)\n",
      "Iter 5410 | Time 18.0248(17.6098) | Bit/dim 3.6830(3.6785) | Xent 0.1225(0.1069) | Loss 9.1561(9.6639) | Error 0.0400(0.0349) Steps 694(671.05) | Grad Norm 8.2412(8.4762) | Total Time 0.00(0.00)\n",
      "Iter 5420 | Time 17.8779(17.5883) | Bit/dim 3.6642(3.6758) | Xent 0.0733(0.1014) | Loss 8.9761(9.5059) | Error 0.0256(0.0333) Steps 640(669.87) | Grad Norm 6.3382(8.0048) | Total Time 0.00(0.00)\n",
      "Iter 5430 | Time 17.3334(17.5290) | Bit/dim 3.6515(3.6727) | Xent 0.0561(0.0995) | Loss 8.9914(9.3855) | Error 0.0156(0.0325) Steps 676(668.55) | Grad Norm 5.4882(7.8240) | Total Time 0.00(0.00)\n",
      "Iter 5440 | Time 16.9637(17.5713) | Bit/dim 3.6511(3.6728) | Xent 0.1123(0.1029) | Loss 8.9479(9.3161) | Error 0.0344(0.0337) Steps 664(672.80) | Grad Norm 8.0706(7.9742) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 91.4674, Epoch Time 1081.7125(1039.5662), Bit/dim 3.6895(best: 3.6901), Xent 1.6669, Loss 4.5229, Error 0.3281(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 17.4844(17.5884) | Bit/dim 3.6996(3.6746) | Xent 0.0968(0.1053) | Loss 9.2035(9.9852) | Error 0.0289(0.0339) Steps 664(674.64) | Grad Norm 7.0519(7.9167) | Total Time 0.00(0.00)\n",
      "Iter 5460 | Time 18.4140(17.6295) | Bit/dim 3.6819(3.6717) | Xent 0.1517(0.1071) | Loss 9.1674(9.7611) | Error 0.0500(0.0344) Steps 664(672.55) | Grad Norm 8.4708(7.8358) | Total Time 0.00(0.00)\n",
      "Iter 5470 | Time 16.6118(17.5498) | Bit/dim 3.6897(3.6698) | Xent 0.0783(0.1055) | Loss 9.1005(9.5763) | Error 0.0267(0.0342) Steps 670(674.09) | Grad Norm 5.9864(7.6710) | Total Time 0.00(0.00)\n",
      "Iter 5480 | Time 16.8156(17.5136) | Bit/dim 3.6292(3.6702) | Xent 0.1356(0.1053) | Loss 8.9904(9.4499) | Error 0.0433(0.0342) Steps 658(673.85) | Grad Norm 8.0708(7.3691) | Total Time 0.00(0.00)\n",
      "Iter 5490 | Time 16.7478(17.5340) | Bit/dim 3.6723(3.6690) | Xent 0.1438(0.1057) | Loss 9.1281(9.3556) | Error 0.0478(0.0345) Steps 676(673.61) | Grad Norm 8.3607(7.5033) | Total Time 0.00(0.00)\n",
      "Iter 5500 | Time 17.9970(17.5412) | Bit/dim 3.6661(3.6713) | Xent 0.0593(0.1010) | Loss 8.9859(9.2816) | Error 0.0200(0.0330) Steps 700(676.26) | Grad Norm 5.9429(7.0981) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 91.6685, Epoch Time 1077.5328(1040.7052), Bit/dim 3.6827(best: 3.6895), Xent 1.7813, Loss 4.5734, Error 0.3244(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 18.3040(17.5687) | Bit/dim 3.6350(3.6678) | Xent 0.0638(0.0925) | Loss 8.9908(9.8450) | Error 0.0222(0.0302) Steps 688(679.94) | Grad Norm 6.0704(6.8297) | Total Time 0.00(0.00)\n",
      "Iter 5520 | Time 17.9100(17.6291) | Bit/dim 3.6377(3.6648) | Xent 0.0803(0.0851) | Loss 9.0116(9.6256) | Error 0.0267(0.0276) Steps 688(679.29) | Grad Norm 5.8025(6.4297) | Total Time 0.00(0.00)\n",
      "Iter 5530 | Time 17.8345(17.5909) | Bit/dim 3.6663(3.6676) | Xent 0.0729(0.0873) | Loss 9.1056(9.4876) | Error 0.0222(0.0283) Steps 688(676.00) | Grad Norm 4.4955(6.6928) | Total Time 0.00(0.00)\n",
      "Iter 5540 | Time 18.2755(17.5884) | Bit/dim 3.6412(3.6675) | Xent 0.0824(0.0900) | Loss 9.0207(9.3750) | Error 0.0311(0.0295) Steps 712(677.16) | Grad Norm 10.5704(7.3069) | Total Time 0.00(0.00)\n",
      "Iter 5550 | Time 18.4426(17.6438) | Bit/dim 3.6284(3.6670) | Xent 0.0850(0.0922) | Loss 9.0513(9.2944) | Error 0.0256(0.0299) Steps 682(677.83) | Grad Norm 5.1752(7.1854) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 92.1085, Epoch Time 1083.9566(1042.0027), Bit/dim 3.6884(best: 3.6827), Xent 1.8870, Loss 4.6319, Error 0.3416(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 17.3750(17.6168) | Bit/dim 3.6327(3.6674) | Xent 0.0849(0.0914) | Loss 9.0401(9.9709) | Error 0.0244(0.0289) Steps 664(679.14) | Grad Norm 7.9086(7.3956) | Total Time 0.00(0.00)\n",
      "Iter 5570 | Time 17.5411(17.6133) | Bit/dim 3.6708(3.6691) | Xent 0.0846(0.0900) | Loss 9.2122(9.7346) | Error 0.0267(0.0284) Steps 694(676.49) | Grad Norm 5.8484(7.6871) | Total Time 0.00(0.00)\n",
      "Iter 5580 | Time 16.9974(17.6398) | Bit/dim 3.6350(3.6672) | Xent 0.1069(0.0894) | Loss 8.9780(9.5612) | Error 0.0300(0.0286) Steps 682(680.41) | Grad Norm 5.9818(7.5714) | Total Time 0.00(0.00)\n",
      "Iter 5590 | Time 17.2542(17.5576) | Bit/dim 3.6714(3.6684) | Xent 0.0583(0.0849) | Loss 9.1097(9.4279) | Error 0.0200(0.0275) Steps 646(678.10) | Grad Norm 4.7734(6.9926) | Total Time 0.00(0.00)\n",
      "Iter 5600 | Time 18.1275(17.5487) | Bit/dim 3.6529(3.6653) | Xent 0.1090(0.0868) | Loss 9.0668(9.3285) | Error 0.0333(0.0282) Steps 670(675.02) | Grad Norm 9.0157(7.0770) | Total Time 0.00(0.00)\n",
      "Iter 5610 | Time 17.5250(17.5271) | Bit/dim 3.6574(3.6645) | Xent 0.1213(0.0896) | Loss 9.0678(9.2612) | Error 0.0433(0.0291) Steps 682(675.24) | Grad Norm 8.4712(7.1834) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 90.7511, Epoch Time 1083.3050(1043.2418), Bit/dim 3.6865(best: 3.6827), Xent 1.7391, Loss 4.5561, Error 0.3324(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 17.6938(17.5358) | Bit/dim 3.6738(3.6658) | Xent 0.0914(0.0900) | Loss 9.1245(9.8477) | Error 0.0289(0.0293) Steps 664(676.34) | Grad Norm 6.1751(7.2683) | Total Time 0.00(0.00)\n",
      "Iter 5630 | Time 17.8740(17.4816) | Bit/dim 3.7033(3.6659) | Xent 0.0562(0.0897) | Loss 9.1681(9.6443) | Error 0.0167(0.0287) Steps 712(677.44) | Grad Norm 4.2711(7.3937) | Total Time 0.00(0.00)\n",
      "Iter 5640 | Time 17.2074(17.4683) | Bit/dim 3.6608(3.6635) | Xent 0.0667(0.0867) | Loss 9.0723(9.4820) | Error 0.0211(0.0277) Steps 664(674.85) | Grad Norm 6.5601(6.9740) | Total Time 0.00(0.00)\n",
      "Iter 5650 | Time 17.1994(17.4378) | Bit/dim 3.6520(3.6600) | Xent 0.0604(0.0837) | Loss 8.8694(9.3524) | Error 0.0178(0.0265) Steps 658(671.80) | Grad Norm 10.0958(6.9048) | Total Time 0.00(0.00)\n",
      "Iter 5660 | Time 16.5834(17.5573) | Bit/dim 3.6287(3.6613) | Xent 0.0911(0.0884) | Loss 8.8914(9.2841) | Error 0.0278(0.0278) Steps 652(675.80) | Grad Norm 8.7765(7.2582) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 90.8365, Epoch Time 1075.0611(1044.1964), Bit/dim 3.6812(best: 3.6827), Xent 1.7483, Loss 4.5554, Error 0.3357(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 16.5884(17.5289) | Bit/dim 3.6626(3.6635) | Xent 0.0813(0.0888) | Loss 9.0627(9.9545) | Error 0.0300(0.0288) Steps 640(670.44) | Grad Norm 4.7694(7.1793) | Total Time 0.00(0.00)\n",
      "Iter 5680 | Time 17.7453(17.4946) | Bit/dim 3.6832(3.6650) | Xent 0.1043(0.0884) | Loss 9.1761(9.7260) | Error 0.0322(0.0287) Steps 682(670.98) | Grad Norm 11.8296(7.2330) | Total Time 0.00(0.00)\n",
      "Iter 5690 | Time 17.7289(17.4731) | Bit/dim 3.6497(3.6640) | Xent 0.1092(0.0931) | Loss 9.1225(9.5647) | Error 0.0311(0.0299) Steps 676(671.99) | Grad Norm 5.7873(7.2648) | Total Time 0.00(0.00)\n",
      "Iter 5700 | Time 17.4137(17.5255) | Bit/dim 3.6833(3.6645) | Xent 0.1388(0.0977) | Loss 9.1847(9.4442) | Error 0.0411(0.0314) Steps 646(672.43) | Grad Norm 8.9805(7.4535) | Total Time 0.00(0.00)\n",
      "Iter 5710 | Time 17.0200(17.5382) | Bit/dim 3.7008(3.6655) | Xent 0.1477(0.1109) | Loss 9.0775(9.3733) | Error 0.0411(0.0350) Steps 676(674.84) | Grad Norm 10.1734(8.7656) | Total Time 0.00(0.00)\n",
      "Iter 5720 | Time 17.5125(17.5826) | Bit/dim 3.7329(3.6698) | Xent 0.2597(0.1311) | Loss 9.3836(9.3372) | Error 0.0844(0.0421) Steps 682(676.92) | Grad Norm 13.0830(9.9460) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 92.4540, Epoch Time 1077.6478(1045.1999), Bit/dim 3.6877(best: 3.6812), Xent 1.5537, Loss 4.4646, Error 0.3393(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 17.5255(17.5067) | Bit/dim 3.6740(3.6690) | Xent 0.1137(0.1264) | Loss 9.1576(9.9013) | Error 0.0344(0.0412) Steps 664(674.78) | Grad Norm 5.9455(9.3076) | Total Time 0.00(0.00)\n",
      "Iter 5740 | Time 17.9865(17.4942) | Bit/dim 3.6857(3.6689) | Xent 0.1424(0.1238) | Loss 9.2313(9.7028) | Error 0.0467(0.0400) Steps 712(675.92) | Grad Norm 12.8428(9.2441) | Total Time 0.00(0.00)\n",
      "Iter 5750 | Time 17.8494(17.5614) | Bit/dim 3.6458(3.6681) | Xent 0.0657(0.1130) | Loss 9.1135(9.5440) | Error 0.0244(0.0368) Steps 694(679.16) | Grad Norm 4.4627(8.1844) | Total Time 0.00(0.00)\n",
      "Iter 5760 | Time 17.5652(17.6039) | Bit/dim 3.6810(3.6658) | Xent 0.0680(0.1036) | Loss 9.2855(9.4203) | Error 0.0233(0.0335) Steps 688(678.24) | Grad Norm 5.8244(7.5376) | Total Time 0.00(0.00)\n",
      "Iter 5770 | Time 17.5523(17.6121) | Bit/dim 3.6916(3.6672) | Xent 0.1195(0.1000) | Loss 9.1957(9.3368) | Error 0.0367(0.0324) Steps 706(679.29) | Grad Norm 12.4327(8.2200) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 90.9341, Epoch Time 1082.6562(1046.3236), Bit/dim 3.6770(best: 3.6812), Xent 1.7697, Loss 4.5618, Error 0.3343(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 18.0821(17.6354) | Bit/dim 3.6957(3.6671) | Xent 0.0717(0.0983) | Loss 9.1202(9.9812) | Error 0.0244(0.0321) Steps 664(676.76) | Grad Norm 6.1063(8.6020) | Total Time 0.00(0.00)\n",
      "Iter 5790 | Time 17.9120(17.6117) | Bit/dim 3.6790(3.6687) | Xent 0.1570(0.1012) | Loss 9.1352(9.7427) | Error 0.0467(0.0326) Steps 700(677.16) | Grad Norm 15.1217(8.7498) | Total Time 0.00(0.00)\n",
      "Iter 5800 | Time 17.7879(17.6996) | Bit/dim 3.6996(3.6694) | Xent 0.0900(0.1018) | Loss 9.1899(9.5813) | Error 0.0311(0.0329) Steps 688(680.05) | Grad Norm 6.0922(8.8389) | Total Time 0.00(0.00)\n",
      "Iter 5810 | Time 18.3224(17.7250) | Bit/dim 3.6388(3.6672) | Xent 0.1158(0.1003) | Loss 9.2084(9.4613) | Error 0.0433(0.0325) Steps 688(678.43) | Grad Norm 14.1454(8.6359) | Total Time 0.00(0.00)\n",
      "Iter 5820 | Time 17.9547(17.6652) | Bit/dim 3.6315(3.6663) | Xent 0.0948(0.0996) | Loss 9.0353(9.3620) | Error 0.0300(0.0318) Steps 700(674.78) | Grad Norm 5.4939(8.2593) | Total Time 0.00(0.00)\n",
      "Iter 5830 | Time 17.7176(17.6653) | Bit/dim 3.6486(3.6654) | Xent 0.1206(0.0967) | Loss 9.1628(9.2872) | Error 0.0333(0.0303) Steps 694(673.11) | Grad Norm 4.9162(7.8990) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 91.1616, Epoch Time 1084.9579(1047.4826), Bit/dim 3.6718(best: 3.6770), Xent 1.6747, Loss 4.5091, Error 0.3235(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 17.3878(17.6634) | Bit/dim 3.6697(3.6637) | Xent 0.0992(0.0895) | Loss 9.1195(9.8632) | Error 0.0300(0.0281) Steps 682(673.51) | Grad Norm 10.9693(7.5155) | Total Time 0.00(0.00)\n",
      "Iter 5850 | Time 17.6228(17.6180) | Bit/dim 3.6212(3.6581) | Xent 0.1116(0.0867) | Loss 8.8911(9.6397) | Error 0.0322(0.0277) Steps 670(675.10) | Grad Norm 7.2958(7.1191) | Total Time 0.00(0.00)\n",
      "Iter 5860 | Time 17.4944(17.6506) | Bit/dim 3.6367(3.6582) | Xent 0.1001(0.0872) | Loss 9.1241(9.4942) | Error 0.0333(0.0278) Steps 682(675.12) | Grad Norm 9.5632(7.0700) | Total Time 0.00(0.00)\n",
      "Iter 5870 | Time 17.2863(17.6358) | Bit/dim 3.6565(3.6577) | Xent 0.0984(0.0923) | Loss 9.0833(9.3899) | Error 0.0267(0.0296) Steps 700(677.44) | Grad Norm 7.9939(8.0593) | Total Time 0.00(0.00)\n",
      "Iter 5880 | Time 18.4196(17.6945) | Bit/dim 3.6535(3.6595) | Xent 0.0771(0.0941) | Loss 9.0905(9.3029) | Error 0.0233(0.0300) Steps 688(679.40) | Grad Norm 7.4400(7.9258) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 91.6959, Epoch Time 1085.4851(1048.6227), Bit/dim 3.6773(best: 3.6718), Xent 1.7741, Loss 4.5644, Error 0.3253(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 18.2529(17.7305) | Bit/dim 3.6417(3.6587) | Xent 0.0564(0.0922) | Loss 9.1058(9.9797) | Error 0.0233(0.0293) Steps 730(684.95) | Grad Norm 5.9392(7.7726) | Total Time 0.00(0.00)\n",
      "Iter 5900 | Time 17.3495(17.6848) | Bit/dim 3.6553(3.6565) | Xent 0.0619(0.0891) | Loss 9.0889(9.7333) | Error 0.0178(0.0276) Steps 682(685.98) | Grad Norm 5.7233(7.4774) | Total Time 0.00(0.00)\n",
      "Iter 5910 | Time 18.5413(17.7047) | Bit/dim 3.6911(3.6561) | Xent 0.1048(0.0869) | Loss 9.2720(9.5537) | Error 0.0322(0.0271) Steps 664(683.20) | Grad Norm 7.5433(7.1795) | Total Time 0.00(0.00)\n",
      "Iter 5920 | Time 17.2369(17.7235) | Bit/dim 3.6812(3.6571) | Xent 0.0731(0.0831) | Loss 9.1804(9.4279) | Error 0.0256(0.0263) Steps 694(681.93) | Grad Norm 7.2797(7.1958) | Total Time 0.00(0.00)\n",
      "Iter 5930 | Time 17.1045(17.7080) | Bit/dim 3.6361(3.6552) | Xent 0.0649(0.0805) | Loss 8.9882(9.3273) | Error 0.0189(0.0254) Steps 676(681.19) | Grad Norm 5.7833(6.9114) | Total Time 0.00(0.00)\n",
      "Iter 5940 | Time 16.9045(17.6677) | Bit/dim 3.6587(3.6551) | Xent 0.0841(0.0821) | Loss 9.0845(9.2605) | Error 0.0233(0.0258) Steps 664(679.98) | Grad Norm 7.0347(6.9057) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 90.8086, Epoch Time 1084.0580(1049.6858), Bit/dim 3.6738(best: 3.6718), Xent 1.7508, Loss 4.5493, Error 0.3261(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 18.5776(17.7093) | Bit/dim 3.6541(3.6559) | Xent 0.1135(0.0827) | Loss 9.1545(9.8257) | Error 0.0378(0.0259) Steps 706(679.26) | Grad Norm 10.3911(7.2574) | Total Time 0.00(0.00)\n",
      "Iter 5960 | Time 18.4583(17.7487) | Bit/dim 3.6408(3.6558) | Xent 0.1214(0.0837) | Loss 9.1482(9.6260) | Error 0.0400(0.0262) Steps 712(681.49) | Grad Norm 7.0892(7.5973) | Total Time 0.00(0.00)\n",
      "Iter 5970 | Time 17.6211(17.7395) | Bit/dim 3.6542(3.6524) | Xent 0.0657(0.0833) | Loss 8.9786(9.4687) | Error 0.0222(0.0259) Steps 676(681.22) | Grad Norm 6.3204(7.3861) | Total Time 0.00(0.00)\n",
      "Iter 5980 | Time 18.6877(17.7622) | Bit/dim 3.6692(3.6529) | Xent 0.0666(0.0797) | Loss 9.0932(9.3615) | Error 0.0178(0.0248) Steps 706(683.56) | Grad Norm 5.0792(6.7497) | Total Time 0.00(0.00)\n",
      "Iter 5990 | Time 18.1526(17.7561) | Bit/dim 3.6824(3.6532) | Xent 0.1015(0.0845) | Loss 9.0154(9.2721) | Error 0.0278(0.0266) Steps 652(680.09) | Grad Norm 14.0171(7.3855) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 91.5671, Epoch Time 1093.6194(1051.0038), Bit/dim 3.6705(best: 3.6718), Xent 1.7477, Loss 4.5444, Error 0.3234(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 17.3434(17.7278) | Bit/dim 3.6718(3.6559) | Xent 0.0933(0.0857) | Loss 9.1458(9.9434) | Error 0.0311(0.0274) Steps 664(678.16) | Grad Norm 6.3689(7.6272) | Total Time 0.00(0.00)\n",
      "Iter 6010 | Time 17.7818(17.7207) | Bit/dim 3.6624(3.6576) | Xent 0.0809(0.0837) | Loss 9.0974(9.7098) | Error 0.0244(0.0268) Steps 688(679.23) | Grad Norm 10.4327(7.4636) | Total Time 0.00(0.00)\n",
      "Iter 6020 | Time 17.9039(17.7781) | Bit/dim 3.6471(3.6562) | Xent 0.0536(0.0822) | Loss 9.1550(9.5436) | Error 0.0144(0.0265) Steps 682(682.24) | Grad Norm 8.8619(7.5857) | Total Time 0.00(0.00)\n",
      "Iter 6030 | Time 17.6731(17.7536) | Bit/dim 3.6126(3.6519) | Xent 0.0444(0.0771) | Loss 8.9530(9.4044) | Error 0.0167(0.0249) Steps 700(683.24) | Grad Norm 7.1079(7.4967) | Total Time 0.00(0.00)\n",
      "Iter 6040 | Time 17.6820(17.7250) | Bit/dim 3.6279(3.6500) | Xent 0.0767(0.0767) | Loss 8.9146(9.3059) | Error 0.0244(0.0250) Steps 664(682.37) | Grad Norm 8.0691(7.6243) | Total Time 0.00(0.00)\n",
      "Iter 6050 | Time 17.0565(17.7722) | Bit/dim 3.6408(3.6537) | Xent 0.0794(0.0779) | Loss 9.0786(9.2501) | Error 0.0244(0.0256) Steps 658(683.87) | Grad Norm 7.3199(7.7922) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 92.3566, Epoch Time 1088.3799(1052.1251), Bit/dim 3.6765(best: 3.6705), Xent 1.7568, Loss 4.5549, Error 0.3282(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 18.4285(17.8064) | Bit/dim 3.6349(3.6533) | Xent 0.0714(0.0779) | Loss 9.0597(9.8443) | Error 0.0233(0.0253) Steps 694(685.79) | Grad Norm 5.8900(7.3429) | Total Time 0.00(0.00)\n",
      "Iter 6070 | Time 17.4996(17.7591) | Bit/dim 3.6678(3.6544) | Xent 0.0653(0.0773) | Loss 9.1205(9.6354) | Error 0.0167(0.0249) Steps 706(682.21) | Grad Norm 4.3322(7.1249) | Total Time 0.00(0.00)\n",
      "Iter 6080 | Time 17.4484(17.6524) | Bit/dim 3.6460(3.6547) | Xent 0.0526(0.0735) | Loss 9.0572(9.4772) | Error 0.0167(0.0232) Steps 646(679.38) | Grad Norm 3.8357(6.4722) | Total Time 0.00(0.00)\n",
      "Iter 6090 | Time 16.9914(17.6556) | Bit/dim 3.6437(3.6524) | Xent 0.0872(0.0764) | Loss 9.0791(9.3545) | Error 0.0278(0.0241) Steps 646(678.13) | Grad Norm 6.3050(6.5184) | Total Time 0.00(0.00)\n",
      "Iter 6100 | Time 18.4516(17.6482) | Bit/dim 3.6741(3.6501) | Xent 0.0864(0.0774) | Loss 9.1536(9.2672) | Error 0.0278(0.0242) Steps 700(677.34) | Grad Norm 7.5008(6.6245) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 90.3948, Epoch Time 1081.6332(1053.0103), Bit/dim 3.6611(best: 3.6705), Xent 1.7665, Loss 4.5444, Error 0.3268(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 17.6121(17.6769) | Bit/dim 3.6157(3.6479) | Xent 0.0511(0.0729) | Loss 8.9831(9.9413) | Error 0.0178(0.0232) Steps 694(677.59) | Grad Norm 3.9336(6.4286) | Total Time 0.00(0.00)\n",
      "Iter 6120 | Time 18.6179(17.7307) | Bit/dim 3.6339(3.6475) | Xent 0.0530(0.0725) | Loss 9.0671(9.6991) | Error 0.0167(0.0232) Steps 682(678.63) | Grad Norm 5.5978(6.6701) | Total Time 0.00(0.00)\n",
      "Iter 6130 | Time 17.2733(17.6671) | Bit/dim 3.6597(3.6484) | Xent 0.0559(0.0746) | Loss 8.9991(9.5270) | Error 0.0211(0.0240) Steps 670(678.26) | Grad Norm 7.0020(6.7355) | Total Time 0.00(0.00)\n",
      "Iter 6140 | Time 16.8782(17.6008) | Bit/dim 3.6870(3.6520) | Xent 0.0676(0.0773) | Loss 9.0583(9.4029) | Error 0.0211(0.0248) Steps 682(675.96) | Grad Norm 8.3858(7.2877) | Total Time 0.00(0.00)\n",
      "Iter 6150 | Time 18.6835(17.6391) | Bit/dim 3.6477(3.6533) | Xent 0.1730(0.0954) | Loss 9.2091(9.3385) | Error 0.0511(0.0304) Steps 712(682.06) | Grad Norm 8.5280(8.4618) | Total Time 0.00(0.00)\n",
      "Iter 6160 | Time 18.0527(17.6013) | Bit/dim 3.6515(3.6558) | Xent 0.0798(0.1001) | Loss 9.0590(9.2717) | Error 0.0267(0.0319) Steps 670(684.58) | Grad Norm 4.5856(8.2612) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 91.0749, Epoch Time 1081.4552(1053.8636), Bit/dim 3.6740(best: 3.6611), Xent 1.7786, Loss 4.5633, Error 0.3407(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 17.2987(17.6850) | Bit/dim 3.6805(3.6599) | Xent 0.0824(0.0973) | Loss 9.0750(9.8428) | Error 0.0256(0.0311) Steps 694(686.81) | Grad Norm 6.0163(7.9906) | Total Time 0.00(0.00)\n",
      "Iter 6180 | Time 17.9873(17.6509) | Bit/dim 3.6412(3.6551) | Xent 0.1039(0.0946) | Loss 9.0350(9.6241) | Error 0.0289(0.0304) Steps 694(684.51) | Grad Norm 10.6257(8.0543) | Total Time 0.00(0.00)\n",
      "Iter 6190 | Time 19.1594(17.6865) | Bit/dim 3.6353(3.6523) | Xent 0.0965(0.0909) | Loss 9.0750(9.4774) | Error 0.0267(0.0289) Steps 688(683.66) | Grad Norm 8.1094(7.5948) | Total Time 0.00(0.00)\n",
      "Iter 6200 | Time 17.2382(17.6924) | Bit/dim 3.6365(3.6539) | Xent 0.1023(0.0881) | Loss 9.0580(9.3812) | Error 0.0322(0.0279) Steps 694(684.95) | Grad Norm 7.6474(7.6905) | Total Time 0.00(0.00)\n",
      "Iter 6210 | Time 18.1291(17.6538) | Bit/dim 3.6538(3.6502) | Xent 0.0545(0.0839) | Loss 8.9894(9.2771) | Error 0.0156(0.0261) Steps 646(681.42) | Grad Norm 3.8648(7.2634) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 91.6669, Epoch Time 1090.5394(1054.9639), Bit/dim 3.6635(best: 3.6611), Xent 1.8457, Loss 4.5864, Error 0.3311(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 17.5773(17.6644) | Bit/dim 3.6304(3.6518) | Xent 0.0712(0.0802) | Loss 8.8034(9.9331) | Error 0.0233(0.0250) Steps 640(679.32) | Grad Norm 5.1622(7.2288) | Total Time 0.00(0.00)\n",
      "Iter 6230 | Time 18.7323(17.7420) | Bit/dim 3.6734(3.6505) | Xent 0.0650(0.0760) | Loss 9.0564(9.6966) | Error 0.0178(0.0239) Steps 688(679.98) | Grad Norm 5.2064(7.1081) | Total Time 0.00(0.00)\n",
      "Iter 6240 | Time 18.0666(17.7289) | Bit/dim 3.6386(3.6497) | Xent 0.0746(0.0749) | Loss 9.0162(9.5225) | Error 0.0256(0.0238) Steps 676(677.85) | Grad Norm 4.5902(7.0875) | Total Time 0.00(0.00)\n",
      "Iter 6250 | Time 17.7386(17.7783) | Bit/dim 3.6260(3.6495) | Xent 0.0760(0.0779) | Loss 8.9357(9.3986) | Error 0.0233(0.0248) Steps 658(679.60) | Grad Norm 8.7774(7.4187) | Total Time 0.00(0.00)\n",
      "Iter 6260 | Time 17.8444(17.7856) | Bit/dim 3.6276(3.6485) | Xent 0.1267(0.0828) | Loss 9.1054(9.3117) | Error 0.0378(0.0259) Steps 682(680.26) | Grad Norm 10.1696(7.5754) | Total Time 0.00(0.00)\n",
      "Iter 6270 | Time 18.5130(17.8769) | Bit/dim 3.6531(3.6482) | Xent 0.0922(0.0848) | Loss 9.0718(9.2453) | Error 0.0289(0.0265) Steps 718(685.71) | Grad Norm 7.1015(7.4189) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 92.8558, Epoch Time 1096.4786(1056.2094), Bit/dim 3.6645(best: 3.6611), Xent 1.8389, Loss 4.5840, Error 0.3405(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 17.6660(17.8620) | Bit/dim 3.6537(3.6481) | Xent 0.0716(0.0866) | Loss 9.0902(9.8272) | Error 0.0222(0.0271) Steps 676(685.43) | Grad Norm 5.5078(7.3587) | Total Time 0.00(0.00)\n",
      "Iter 6290 | Time 18.9203(17.8287) | Bit/dim 3.6215(3.6454) | Xent 0.0698(0.0822) | Loss 8.9032(9.6060) | Error 0.0200(0.0258) Steps 634(683.40) | Grad Norm 5.5498(6.9245) | Total Time 0.00(0.00)\n",
      "Iter 6300 | Time 17.0653(17.7910) | Bit/dim 3.6590(3.6457) | Xent 0.0629(0.0779) | Loss 8.9160(9.4593) | Error 0.0211(0.0246) Steps 694(684.85) | Grad Norm 5.8054(7.0180) | Total Time 0.00(0.00)\n",
      "Iter 6310 | Time 17.3937(17.7681) | Bit/dim 3.6602(3.6439) | Xent 0.1360(0.0819) | Loss 9.1149(9.3505) | Error 0.0411(0.0260) Steps 658(685.94) | Grad Norm 13.4393(7.4858) | Total Time 0.00(0.00)\n",
      "Iter 6320 | Time 17.6443(17.7473) | Bit/dim 3.6772(3.6482) | Xent 0.0775(0.0835) | Loss 9.1217(9.2794) | Error 0.0189(0.0266) Steps 706(685.74) | Grad Norm 6.7525(7.6140) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 91.7371, Epoch Time 1090.3765(1057.2344), Bit/dim 3.6607(best: 3.6611), Xent 1.8457, Loss 4.5836, Error 0.3227(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 17.8553(17.8133) | Bit/dim 3.6397(3.6496) | Xent 0.0981(0.0850) | Loss 9.0942(9.9641) | Error 0.0244(0.0270) Steps 676(685.59) | Grad Norm 5.2621(7.4632) | Total Time 0.00(0.00)\n",
      "Iter 6340 | Time 17.5534(17.7910) | Bit/dim 3.6633(3.6479) | Xent 0.0709(0.0860) | Loss 8.9813(9.7206) | Error 0.0222(0.0272) Steps 700(688.05) | Grad Norm 6.4205(7.4046) | Total Time 0.00(0.00)\n",
      "Iter 6350 | Time 17.0675(17.7813) | Bit/dim 3.6720(3.6500) | Xent 0.0649(0.0865) | Loss 9.0426(9.5482) | Error 0.0233(0.0275) Steps 682(686.38) | Grad Norm 5.0539(7.5608) | Total Time 0.00(0.00)\n",
      "Iter 6360 | Time 17.3275(17.7617) | Bit/dim 3.6447(3.6504) | Xent 0.1176(0.0858) | Loss 9.0883(9.4225) | Error 0.0400(0.0273) Steps 688(687.59) | Grad Norm 7.8661(7.3495) | Total Time 0.00(0.00)\n",
      "Iter 6370 | Time 18.0147(17.7295) | Bit/dim 3.6313(3.6461) | Xent 0.0532(0.0816) | Loss 8.9191(9.3136) | Error 0.0189(0.0258) Steps 676(688.61) | Grad Norm 3.7468(6.8203) | Total Time 0.00(0.00)\n",
      "Iter 6380 | Time 18.1043(17.7936) | Bit/dim 3.6530(3.6458) | Xent 0.0724(0.0795) | Loss 9.1561(9.2465) | Error 0.0211(0.0251) Steps 670(689.25) | Grad Norm 7.6109(6.5712) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 92.4715, Epoch Time 1091.2569(1058.2550), Bit/dim 3.6585(best: 3.6607), Xent 1.8944, Loss 4.6057, Error 0.3362(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 17.5790(17.7583) | Bit/dim 3.6251(3.6420) | Xent 0.0491(0.0740) | Loss 8.9366(9.7918) | Error 0.0122(0.0234) Steps 670(687.63) | Grad Norm 7.3353(6.3166) | Total Time 0.00(0.00)\n",
      "Iter 6400 | Time 18.4379(17.7663) | Bit/dim 3.6633(3.6410) | Xent 0.0827(0.0703) | Loss 9.0855(9.5843) | Error 0.0211(0.0222) Steps 670(682.73) | Grad Norm 5.3997(6.0713) | Total Time 0.00(0.00)\n",
      "Iter 6410 | Time 17.9477(17.8312) | Bit/dim 3.6701(3.6401) | Xent 0.0733(0.0689) | Loss 9.0379(9.4377) | Error 0.0267(0.0219) Steps 682(686.71) | Grad Norm 7.4336(5.9601) | Total Time 0.00(0.00)\n",
      "Iter 6420 | Time 17.3431(17.9116) | Bit/dim 3.6729(3.6381) | Xent 0.0578(0.0675) | Loss 8.9416(9.3215) | Error 0.0189(0.0216) Steps 670(686.43) | Grad Norm 5.0316(5.9199) | Total Time 0.00(0.00)\n",
      "Iter 6430 | Time 18.6658(17.8882) | Bit/dim 3.6490(3.6399) | Xent 0.0900(0.0724) | Loss 9.0998(9.2456) | Error 0.0233(0.0229) Steps 676(684.91) | Grad Norm 6.5645(6.3461) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 92.8337, Epoch Time 1096.2131(1059.3938), Bit/dim 3.6697(best: 3.6585), Xent 1.9030, Loss 4.6212, Error 0.3424(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 17.3553(17.8374) | Bit/dim 3.6926(3.6470) | Xent 0.0796(0.0762) | Loss 9.1179(9.9170) | Error 0.0289(0.0244) Steps 676(684.19) | Grad Norm 8.5524(6.6531) | Total Time 0.00(0.00)\n",
      "Iter 6450 | Time 17.5278(17.8203) | Bit/dim 3.6446(3.6467) | Xent 0.1103(0.0788) | Loss 8.8994(9.6820) | Error 0.0344(0.0253) Steps 664(681.99) | Grad Norm 6.9004(6.8380) | Total Time 0.00(0.00)\n",
      "Iter 6460 | Time 18.0398(17.8368) | Bit/dim 3.6508(3.6462) | Xent 0.0740(0.0817) | Loss 8.9453(9.5018) | Error 0.0233(0.0262) Steps 700(681.83) | Grad Norm 7.0158(7.0285) | Total Time 0.00(0.00)\n",
      "Iter 6470 | Time 17.7521(17.8449) | Bit/dim 3.6043(3.6427) | Xent 0.0521(0.0797) | Loss 9.0367(9.3776) | Error 0.0211(0.0258) Steps 700(684.99) | Grad Norm 5.1344(6.9169) | Total Time 0.00(0.00)\n",
      "Iter 6480 | Time 17.6310(17.9107) | Bit/dim 3.6445(3.6434) | Xent 0.0795(0.0787) | Loss 9.1183(9.2928) | Error 0.0222(0.0254) Steps 712(686.86) | Grad Norm 8.0059(6.8764) | Total Time 0.00(0.00)\n",
      "Iter 6490 | Time 18.1755(17.8797) | Bit/dim 3.6812(3.6432) | Xent 0.0608(0.0776) | Loss 9.1027(9.2251) | Error 0.0189(0.0249) Steps 712(686.49) | Grad Norm 3.4041(6.8611) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 92.3536, Epoch Time 1095.2860(1060.4706), Bit/dim 3.6588(best: 3.6585), Xent 1.7307, Loss 4.5241, Error 0.3264(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 17.6654(17.8469) | Bit/dim 3.6718(3.6434) | Xent 0.0459(0.0730) | Loss 9.0874(9.8000) | Error 0.0189(0.0234) Steps 724(686.23) | Grad Norm 5.5879(6.5413) | Total Time 0.00(0.00)\n",
      "Iter 6510 | Time 18.4431(17.8084) | Bit/dim 3.6440(3.6413) | Xent 0.0504(0.0705) | Loss 9.0798(9.5930) | Error 0.0156(0.0225) Steps 700(688.40) | Grad Norm 6.9676(6.3653) | Total Time 0.00(0.00)\n",
      "Iter 6520 | Time 17.7843(17.8290) | Bit/dim 3.6218(3.6419) | Xent 0.0953(0.0777) | Loss 8.9517(9.4540) | Error 0.0367(0.0251) Steps 652(687.16) | Grad Norm 10.0312(7.1819) | Total Time 0.00(0.00)\n",
      "Iter 6530 | Time 17.8991(17.8245) | Bit/dim 3.6238(3.6424) | Xent 0.0739(0.0844) | Loss 9.0875(9.3515) | Error 0.0222(0.0274) Steps 730(685.65) | Grad Norm 5.6782(7.5228) | Total Time 0.00(0.00)\n",
      "Iter 6540 | Time 17.9045(17.8728) | Bit/dim 3.6409(3.6430) | Xent 0.0960(0.0861) | Loss 9.0797(9.2769) | Error 0.0311(0.0279) Steps 712(686.13) | Grad Norm 13.0037(7.9649) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 91.7662, Epoch Time 1096.3436(1061.5467), Bit/dim 3.6685(best: 3.6585), Xent 1.8405, Loss 4.5888, Error 0.3307(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 18.5319(17.9328) | Bit/dim 3.6740(3.6481) | Xent 0.0916(0.0864) | Loss 9.2107(9.9613) | Error 0.0356(0.0285) Steps 706(686.15) | Grad Norm 15.4027(8.3790) | Total Time 0.00(0.00)\n",
      "Iter 6560 | Time 18.1078(17.8591) | Bit/dim 3.6440(3.6442) | Xent 0.0847(0.0858) | Loss 8.9446(9.7120) | Error 0.0233(0.0281) Steps 700(687.47) | Grad Norm 4.9222(7.8063) | Total Time 0.00(0.00)\n",
      "Iter 6570 | Time 17.4638(17.9041) | Bit/dim 3.6671(3.6441) | Xent 0.0473(0.0841) | Loss 9.1022(9.5368) | Error 0.0133(0.0271) Steps 724(688.81) | Grad Norm 6.9809(7.2874) | Total Time 0.00(0.00)\n",
      "Iter 6580 | Time 17.5680(17.7655) | Bit/dim 3.6397(3.6426) | Xent 0.0752(0.0804) | Loss 9.0971(9.3988) | Error 0.0244(0.0258) Steps 706(687.68) | Grad Norm 7.7523(7.2757) | Total Time 0.00(0.00)\n",
      "Iter 6590 | Time 16.9784(17.7959) | Bit/dim 3.6426(3.6428) | Xent 0.0760(0.0792) | Loss 8.9471(9.3000) | Error 0.0222(0.0254) Steps 664(690.07) | Grad Norm 5.2730(7.3457) | Total Time 0.00(0.00)\n",
      "Iter 6600 | Time 17.3495(17.7879) | Bit/dim 3.6471(3.6445) | Xent 0.1350(0.0846) | Loss 9.0639(9.2409) | Error 0.0389(0.0271) Steps 694(689.74) | Grad Norm 12.0390(7.9492) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 91.9717, Epoch Time 1090.3506(1062.4109), Bit/dim 3.6660(best: 3.6585), Xent 1.7273, Loss 4.5296, Error 0.3282(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 18.3684(17.8388) | Bit/dim 3.6291(3.6465) | Xent 0.0590(0.0807) | Loss 8.8447(9.8467) | Error 0.0144(0.0262) Steps 700(691.43) | Grad Norm 3.8565(7.3173) | Total Time 0.00(0.00)\n",
      "Iter 6620 | Time 16.8884(17.8841) | Bit/dim 3.6104(3.6444) | Xent 0.0390(0.0756) | Loss 8.8983(9.6245) | Error 0.0156(0.0245) Steps 664(692.15) | Grad Norm 6.8121(7.1943) | Total Time 0.00(0.00)\n",
      "Iter 6630 | Time 18.0871(17.9210) | Bit/dim 3.6058(3.6424) | Xent 0.0659(0.0734) | Loss 8.9041(9.4582) | Error 0.0200(0.0235) Steps 688(689.73) | Grad Norm 5.7908(6.8340) | Total Time 0.00(0.00)\n",
      "Iter 6640 | Time 17.7518(17.9163) | Bit/dim 3.6605(3.6384) | Xent 0.0946(0.0749) | Loss 9.1429(9.3300) | Error 0.0278(0.0238) Steps 706(691.26) | Grad Norm 9.1272(7.0257) | Total Time 0.00(0.00)\n",
      "Iter 6650 | Time 18.1392(17.9420) | Bit/dim 3.5972(3.6352) | Xent 0.0899(0.0745) | Loss 8.9223(9.2388) | Error 0.0278(0.0234) Steps 670(692.41) | Grad Norm 6.8699(6.7892) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 91.1494, Epoch Time 1103.4563(1063.6422), Bit/dim 3.6488(best: 3.6585), Xent 1.7921, Loss 4.5448, Error 0.3239(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 17.7026(17.8754) | Bit/dim 3.6289(3.6353) | Xent 0.0660(0.0716) | Loss 9.0348(9.9068) | Error 0.0178(0.0227) Steps 694(693.53) | Grad Norm 4.9172(6.3551) | Total Time 0.00(0.00)\n",
      "Iter 6670 | Time 17.2197(17.8790) | Bit/dim 3.6230(3.6340) | Xent 0.0917(0.0710) | Loss 8.9536(9.6670) | Error 0.0278(0.0229) Steps 682(693.45) | Grad Norm 8.8474(6.2738) | Total Time 0.00(0.00)\n",
      "Iter 6680 | Time 17.4480(17.8378) | Bit/dim 3.6496(3.6372) | Xent 0.0834(0.0716) | Loss 9.0022(9.4964) | Error 0.0256(0.0232) Steps 694(690.98) | Grad Norm 7.5764(6.6106) | Total Time 0.00(0.00)\n",
      "Iter 6690 | Time 18.0932(17.8768) | Bit/dim 3.6416(3.6387) | Xent 0.0670(0.0719) | Loss 8.9491(9.3721) | Error 0.0211(0.0231) Steps 700(692.76) | Grad Norm 7.8908(6.7149) | Total Time 0.00(0.00)\n",
      "Iter 6700 | Time 17.8889(17.9058) | Bit/dim 3.6356(3.6384) | Xent 0.0707(0.0761) | Loss 9.0052(9.2742) | Error 0.0222(0.0243) Steps 694(690.67) | Grad Norm 7.9352(6.8860) | Total Time 0.00(0.00)\n",
      "Iter 6710 | Time 18.0072(17.9697) | Bit/dim 3.6280(3.6391) | Xent 0.1132(0.0769) | Loss 8.8782(9.2171) | Error 0.0389(0.0249) Steps 658(695.25) | Grad Norm 9.0777(6.9417) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 92.4090, Epoch Time 1101.9759(1064.7922), Bit/dim 3.6548(best: 3.6488), Xent 1.9057, Loss 4.6076, Error 0.3273(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 17.7322(18.0762) | Bit/dim 3.6472(3.6392) | Xent 0.0686(0.0771) | Loss 9.1117(9.7998) | Error 0.0189(0.0248) Steps 724(697.43) | Grad Norm 5.0424(6.7512) | Total Time 0.00(0.00)\n",
      "Iter 6730 | Time 17.5138(18.0089) | Bit/dim 3.6335(3.6376) | Xent 0.0732(0.0793) | Loss 8.9182(9.5836) | Error 0.0244(0.0253) Steps 700(695.23) | Grad Norm 9.3798(6.8111) | Total Time 0.00(0.00)\n",
      "Iter 6740 | Time 17.5881(18.0129) | Bit/dim 3.6304(3.6377) | Xent 0.0638(0.0809) | Loss 9.1169(9.4531) | Error 0.0222(0.0256) Steps 712(694.61) | Grad Norm 5.4156(7.1599) | Total Time 0.00(0.00)\n",
      "Iter 6750 | Time 17.4271(18.0157) | Bit/dim 3.6297(3.6392) | Xent 0.0779(0.0803) | Loss 9.0166(9.3368) | Error 0.0278(0.0251) Steps 694(695.72) | Grad Norm 6.8810(7.0232) | Total Time 0.00(0.00)\n",
      "Iter 6760 | Time 18.0558(18.0330) | Bit/dim 3.6583(3.6407) | Xent 0.0666(0.0783) | Loss 8.9959(9.2517) | Error 0.0178(0.0245) Steps 676(694.57) | Grad Norm 5.2986(6.8943) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 92.4310, Epoch Time 1113.6972(1066.2594), Bit/dim 3.6585(best: 3.6488), Xent 1.8647, Loss 4.5908, Error 0.3227(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 18.7645(18.1503) | Bit/dim 3.6191(3.6387) | Xent 0.0635(0.0765) | Loss 9.0590(9.9346) | Error 0.0256(0.0239) Steps 724(699.61) | Grad Norm 4.9934(6.9359) | Total Time 0.00(0.00)\n",
      "Iter 6780 | Time 17.6026(18.1737) | Bit/dim 3.6427(3.6391) | Xent 0.0611(0.0747) | Loss 9.0660(9.6940) | Error 0.0144(0.0235) Steps 664(699.12) | Grad Norm 4.2936(6.6593) | Total Time 0.00(0.00)\n",
      "Iter 6790 | Time 17.3925(18.1180) | Bit/dim 3.6313(3.6390) | Xent 0.0945(0.0837) | Loss 9.1464(9.5297) | Error 0.0278(0.0258) Steps 700(699.20) | Grad Norm 11.2379(7.4984) | Total Time 0.00(0.00)\n",
      "Iter 6800 | Time 17.8560(18.0862) | Bit/dim 3.6165(3.6407) | Xent 0.0810(0.0852) | Loss 8.9717(9.3970) | Error 0.0311(0.0267) Steps 700(696.52) | Grad Norm 7.9512(7.7474) | Total Time 0.00(0.00)\n",
      "Iter 6810 | Time 19.5433(18.1151) | Bit/dim 3.6725(3.6397) | Xent 0.0739(0.0844) | Loss 9.1677(9.3032) | Error 0.0267(0.0263) Steps 742(698.64) | Grad Norm 7.3880(7.6230) | Total Time 0.00(0.00)\n",
      "Iter 6820 | Time 18.1354(18.2001) | Bit/dim 3.6277(3.6366) | Xent 0.1309(0.0867) | Loss 9.0419(9.2315) | Error 0.0389(0.0269) Steps 700(700.40) | Grad Norm 9.4071(7.9428) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 92.0122, Epoch Time 1114.2514(1067.6991), Bit/dim 3.6495(best: 3.6488), Xent 1.8389, Loss 4.5690, Error 0.3230(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 18.5069(18.1079) | Bit/dim 3.6368(3.6371) | Xent 0.0794(0.0832) | Loss 8.9704(9.7945) | Error 0.0311(0.0261) Steps 646(695.16) | Grad Norm 5.3639(7.2972) | Total Time 0.00(0.00)\n",
      "Iter 6840 | Time 17.6712(18.0515) | Bit/dim 3.6584(3.6352) | Xent 0.0794(0.0795) | Loss 8.8948(9.5722) | Error 0.0278(0.0248) Steps 676(692.87) | Grad Norm 5.1876(6.8120) | Total Time 0.00(0.00)\n",
      "Iter 6850 | Time 18.4141(18.0106) | Bit/dim 3.6587(3.6347) | Xent 0.0514(0.0738) | Loss 8.9901(9.4248) | Error 0.0156(0.0234) Steps 682(691.82) | Grad Norm 5.4257(6.4115) | Total Time 0.00(0.00)\n",
      "Iter 6860 | Time 17.3365(17.9742) | Bit/dim 3.6133(3.6350) | Xent 0.0593(0.0717) | Loss 8.9130(9.3118) | Error 0.0189(0.0229) Steps 706(692.71) | Grad Norm 6.2836(6.4302) | Total Time 0.00(0.00)\n",
      "Iter 6870 | Time 17.7724(17.9425) | Bit/dim 3.6298(3.6361) | Xent 0.0711(0.0708) | Loss 8.9722(9.2288) | Error 0.0256(0.0229) Steps 640(689.26) | Grad Norm 5.7950(6.6387) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 90.9849, Epoch Time 1097.1967(1068.5841), Bit/dim 3.6572(best: 3.6488), Xent 1.9657, Loss 4.6400, Error 0.3336(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 18.5601(18.0454) | Bit/dim 3.6255(3.6361) | Xent 0.0654(0.0732) | Loss 8.9703(9.9127) | Error 0.0189(0.0237) Steps 706(694.85) | Grad Norm 8.3924(7.0976) | Total Time 0.00(0.00)\n",
      "Iter 6890 | Time 17.1910(18.0037) | Bit/dim 3.6145(3.6355) | Xent 0.0751(0.0784) | Loss 8.9195(9.6740) | Error 0.0233(0.0251) Steps 706(694.82) | Grad Norm 5.0541(7.2907) | Total Time 0.00(0.00)\n",
      "Iter 6900 | Time 17.7908(18.0535) | Bit/dim 3.6404(3.6340) | Xent 0.0443(0.0801) | Loss 8.9590(9.4977) | Error 0.0156(0.0254) Steps 718(696.62) | Grad Norm 5.7121(6.8803) | Total Time 0.00(0.00)\n",
      "Iter 6910 | Time 18.4341(18.1227) | Bit/dim 3.6288(3.6355) | Xent 0.0503(0.0806) | Loss 9.0365(9.3760) | Error 0.0178(0.0259) Steps 736(695.98) | Grad Norm 4.6962(6.8503) | Total Time 0.00(0.00)\n",
      "Iter 6920 | Time 18.6136(18.2089) | Bit/dim 3.6221(3.6382) | Xent 0.0822(0.0798) | Loss 9.0744(9.2908) | Error 0.0278(0.0256) Steps 736(700.32) | Grad Norm 5.5327(6.7236) | Total Time 0.00(0.00)\n",
      "Iter 6930 | Time 18.1586(18.1592) | Bit/dim 3.6540(3.6373) | Xent 0.0833(0.0794) | Loss 9.1067(9.2211) | Error 0.0300(0.0252) Steps 730(703.98) | Grad Norm 5.3013(6.5967) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 93.3792, Epoch Time 1115.3588(1069.9873), Bit/dim 3.6496(best: 3.6488), Xent 1.8447, Loss 4.5719, Error 0.3326(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 17.6603(18.1584) | Bit/dim 3.6291(3.6374) | Xent 0.0887(0.0759) | Loss 9.0512(9.7855) | Error 0.0322(0.0243) Steps 706(704.92) | Grad Norm 8.5181(6.5217) | Total Time 0.00(0.00)\n",
      "Iter 6950 | Time 18.6399(18.1965) | Bit/dim 3.5971(3.6340) | Xent 0.0806(0.0732) | Loss 8.8882(9.5780) | Error 0.0300(0.0235) Steps 712(707.52) | Grad Norm 12.1456(6.9218) | Total Time 0.00(0.00)\n",
      "Iter 6960 | Time 17.5135(18.2227) | Bit/dim 3.6234(3.6351) | Xent 0.0582(0.0731) | Loss 8.9282(9.4358) | Error 0.0233(0.0232) Steps 700(706.43) | Grad Norm 5.1498(6.7912) | Total Time 0.00(0.00)\n",
      "Iter 6970 | Time 18.4039(18.2312) | Bit/dim 3.6705(3.6338) | Xent 0.0727(0.0730) | Loss 9.1035(9.3214) | Error 0.0211(0.0230) Steps 730(704.68) | Grad Norm 6.9852(6.7221) | Total Time 0.00(0.00)\n",
      "Iter 6980 | Time 18.8905(18.2590) | Bit/dim 3.6483(3.6336) | Xent 0.0737(0.0753) | Loss 8.9926(9.2360) | Error 0.0222(0.0238) Steps 718(703.83) | Grad Norm 5.9163(6.7569) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 92.4819, Epoch Time 1120.5095(1071.5030), Bit/dim 3.6548(best: 3.6488), Xent 1.8547, Loss 4.5822, Error 0.3338(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 18.4665(18.2720) | Bit/dim 3.6517(3.6347) | Xent 0.0526(0.0721) | Loss 9.0524(9.9232) | Error 0.0167(0.0228) Steps 682(701.99) | Grad Norm 4.7028(6.6098) | Total Time 0.00(0.00)\n",
      "Iter 7000 | Time 18.9522(18.3542) | Bit/dim 3.6615(3.6366) | Xent 0.0751(0.0686) | Loss 9.2119(9.6955) | Error 0.0233(0.0213) Steps 742(704.29) | Grad Norm 5.4527(6.2132) | Total Time 0.00(0.00)\n",
      "Iter 7010 | Time 17.0414(18.2246) | Bit/dim 3.6251(3.6340) | Xent 0.0933(0.0709) | Loss 8.9590(9.5067) | Error 0.0333(0.0224) Steps 676(700.17) | Grad Norm 5.5441(6.5755) | Total Time 0.00(0.00)\n",
      "Iter 7020 | Time 18.5605(18.1725) | Bit/dim 3.6568(3.6338) | Xent 0.0965(0.0720) | Loss 9.1809(9.3766) | Error 0.0356(0.0227) Steps 724(697.97) | Grad Norm 9.2286(6.6225) | Total Time 0.00(0.00)\n",
      "Iter 7030 | Time 17.9945(18.1618) | Bit/dim 3.6415(3.6343) | Xent 0.0483(0.0698) | Loss 9.0257(9.2732) | Error 0.0167(0.0220) Steps 634(695.98) | Grad Norm 6.2345(6.6603) | Total Time 0.00(0.00)\n",
      "Iter 7040 | Time 17.7529(18.1418) | Bit/dim 3.6443(3.6295) | Xent 0.0920(0.0711) | Loss 9.1461(9.2027) | Error 0.0256(0.0229) Steps 712(696.32) | Grad Norm 7.3930(6.7957) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 92.4367, Epoch Time 1113.3638(1072.7588), Bit/dim 3.6434(best: 3.6488), Xent 1.8376, Loss 4.5623, Error 0.3245(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 18.5583(18.1368) | Bit/dim 3.5898(3.6273) | Xent 0.0493(0.0691) | Loss 9.0057(9.7659) | Error 0.0156(0.0222) Steps 718(696.68) | Grad Norm 5.4160(6.5117) | Total Time 0.00(0.00)\n",
      "Iter 7060 | Time 18.2451(18.1165) | Bit/dim 3.6334(3.6282) | Xent 0.0951(0.0711) | Loss 8.9256(9.5567) | Error 0.0211(0.0225) Steps 688(691.10) | Grad Norm 9.3379(6.8829) | Total Time 0.00(0.00)\n",
      "Iter 7070 | Time 18.2618(18.0352) | Bit/dim 3.6294(3.6290) | Xent 0.0643(0.0680) | Loss 8.9585(9.4065) | Error 0.0189(0.0217) Steps 688(690.32) | Grad Norm 6.0390(7.1473) | Total Time 0.00(0.00)\n",
      "Iter 7080 | Time 18.0288(18.1312) | Bit/dim 3.6396(3.6292) | Xent 0.0702(0.0708) | Loss 9.1091(9.3042) | Error 0.0211(0.0225) Steps 706(691.81) | Grad Norm 8.3958(7.7590) | Total Time 0.00(0.00)\n",
      "Iter 7090 | Time 17.7683(18.0922) | Bit/dim 3.6319(3.6304) | Xent 0.0412(0.0748) | Loss 9.0415(9.2279) | Error 0.0122(0.0235) Steps 706(692.11) | Grad Norm 4.1368(7.7962) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 91.7865, Epoch Time 1106.2831(1073.7645), Bit/dim 3.6431(best: 3.6434), Xent 1.8125, Loss 4.5494, Error 0.3284(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 18.6374(18.1042) | Bit/dim 3.6226(3.6290) | Xent 0.0500(0.0728) | Loss 8.9604(9.9144) | Error 0.0122(0.0227) Steps 694(696.77) | Grad Norm 5.0030(7.1209) | Total Time 0.00(0.00)\n",
      "Iter 7110 | Time 17.7861(18.1572) | Bit/dim 3.6469(3.6329) | Xent 0.1004(0.0711) | Loss 9.2238(9.6818) | Error 0.0233(0.0219) Steps 700(694.37) | Grad Norm 6.9744(6.7411) | Total Time 0.00(0.00)\n",
      "Iter 7120 | Time 18.6331(18.0899) | Bit/dim 3.6476(3.6324) | Xent 0.0608(0.0719) | Loss 8.9340(9.4977) | Error 0.0222(0.0223) Steps 688(691.64) | Grad Norm 5.2451(6.7104) | Total Time 0.00(0.00)\n",
      "Iter 7130 | Time 18.2175(18.0200) | Bit/dim 3.6019(3.6297) | Xent 0.0428(0.0734) | Loss 8.9777(9.3663) | Error 0.0122(0.0227) Steps 712(692.20) | Grad Norm 3.9769(6.4361) | Total Time 0.00(0.00)\n",
      "Iter 7140 | Time 17.6800(18.0337) | Bit/dim 3.6268(3.6307) | Xent 0.0927(0.0719) | Loss 8.9084(9.2655) | Error 0.0278(0.0223) Steps 700(693.11) | Grad Norm 7.1247(6.1956) | Total Time 0.00(0.00)\n",
      "Iter 7150 | Time 17.4691(18.0523) | Bit/dim 3.6362(3.6279) | Xent 0.0529(0.0710) | Loss 8.9873(9.2000) | Error 0.0178(0.0222) Steps 670(692.72) | Grad Norm 3.6193(6.2228) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 92.4490, Epoch Time 1108.9366(1074.8197), Bit/dim 3.6486(best: 3.6431), Xent 1.8085, Loss 4.5529, Error 0.3267(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 17.2496(18.0186) | Bit/dim 3.6179(3.6243) | Xent 0.0668(0.0687) | Loss 8.9225(9.7638) | Error 0.0233(0.0217) Steps 694(693.36) | Grad Norm 7.7433(6.0425) | Total Time 0.00(0.00)\n",
      "Iter 7170 | Time 17.4179(17.9791) | Bit/dim 3.6440(3.6255) | Xent 0.0722(0.0671) | Loss 8.9632(9.5554) | Error 0.0178(0.0210) Steps 670(694.51) | Grad Norm 4.8955(5.9238) | Total Time 0.00(0.00)\n",
      "Iter 7180 | Time 18.7037(18.0295) | Bit/dim 3.6364(3.6279) | Xent 0.0931(0.0691) | Loss 9.1881(9.4129) | Error 0.0222(0.0214) Steps 700(693.92) | Grad Norm 8.8823(6.0058) | Total Time 0.00(0.00)\n",
      "Iter 7190 | Time 18.5827(18.0701) | Bit/dim 3.6529(3.6266) | Xent 0.0526(0.0685) | Loss 9.1336(9.3057) | Error 0.0178(0.0212) Steps 718(698.42) | Grad Norm 5.0872(6.0027) | Total Time 0.00(0.00)\n",
      "Iter 7200 | Time 19.1724(18.1536) | Bit/dim 3.6344(3.6271) | Xent 0.1016(0.0746) | Loss 9.0682(9.2363) | Error 0.0333(0.0231) Steps 688(700.44) | Grad Norm 10.2919(6.5156) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 92.9961, Epoch Time 1110.3433(1075.8854), Bit/dim 3.6430(best: 3.6431), Xent 1.7789, Loss 4.5325, Error 0.3264(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 18.8109(18.1933) | Bit/dim 3.6205(3.6305) | Xent 0.0346(0.0723) | Loss 8.9702(9.9174) | Error 0.0178(0.0229) Steps 736(702.54) | Grad Norm 5.4562(6.3698) | Total Time 0.00(0.00)\n",
      "Iter 7220 | Time 17.5904(18.1861) | Bit/dim 3.6174(3.6268) | Xent 0.0723(0.0716) | Loss 8.9741(9.6743) | Error 0.0133(0.0227) Steps 718(704.60) | Grad Norm 7.9364(6.4942) | Total Time 0.00(0.00)\n",
      "Iter 7230 | Time 18.6846(18.2077) | Bit/dim 3.6346(3.6293) | Xent 0.0822(0.0769) | Loss 9.0263(9.5067) | Error 0.0278(0.0245) Steps 718(702.23) | Grad Norm 7.0250(7.0537) | Total Time 0.00(0.00)\n",
      "Iter 7240 | Time 18.3535(18.2313) | Bit/dim 3.6015(3.6283) | Xent 0.0864(0.0782) | Loss 8.9467(9.3825) | Error 0.0244(0.0247) Steps 706(702.54) | Grad Norm 7.0572(6.8897) | Total Time 0.00(0.00)\n",
      "Iter 7250 | Time 18.6733(18.2472) | Bit/dim 3.6268(3.6271) | Xent 0.0757(0.0771) | Loss 9.0477(9.2817) | Error 0.0222(0.0244) Steps 712(704.51) | Grad Norm 7.4421(6.5766) | Total Time 0.00(0.00)\n",
      "Iter 7260 | Time 18.0184(18.1433) | Bit/dim 3.6606(3.6290) | Xent 0.0458(0.0742) | Loss 9.1015(9.2094) | Error 0.0156(0.0235) Steps 670(701.90) | Grad Norm 7.9116(6.6710) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 91.6102, Epoch Time 1112.9024(1076.9959), Bit/dim 3.6424(best: 3.6430), Xent 1.8209, Loss 4.5529, Error 0.3332(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7270 | Time 18.9222(18.1546) | Bit/dim 3.5901(3.6260) | Xent 0.0585(0.0676) | Loss 9.0362(9.7802) | Error 0.0178(0.0213) Steps 724(703.37) | Grad Norm 4.6296(6.2920) | Total Time 0.00(0.00)\n",
      "Iter 7280 | Time 17.9159(18.1063) | Bit/dim 3.5949(3.6235) | Xent 0.0530(0.0688) | Loss 8.8222(9.5558) | Error 0.0156(0.0212) Steps 712(699.18) | Grad Norm 6.9633(6.7028) | Total Time 0.00(0.00)\n",
      "Iter 7290 | Time 17.7120(18.0255) | Bit/dim 3.6283(3.6278) | Xent 0.0527(0.0707) | Loss 9.0042(9.4124) | Error 0.0189(0.0220) Steps 706(696.95) | Grad Norm 6.2021(6.9881) | Total Time 0.00(0.00)\n",
      "Iter 7300 | Time 18.0707(18.0037) | Bit/dim 3.6248(3.6286) | Xent 0.0874(0.0693) | Loss 8.8957(9.3035) | Error 0.0278(0.0214) Steps 682(696.28) | Grad Norm 7.0402(6.7077) | Total Time 0.00(0.00)\n",
      "Iter 7310 | Time 17.4224(18.0082) | Bit/dim 3.6135(3.6252) | Xent 0.0618(0.0706) | Loss 8.9025(9.2100) | Error 0.0189(0.0217) Steps 700(697.87) | Grad Norm 4.3827(6.4930) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 94.4537, Epoch Time 1103.7950(1077.7999), Bit/dim 3.6477(best: 3.6424), Xent 1.8987, Loss 4.5971, Error 0.3376(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7320 | Time 18.0180(17.9577) | Bit/dim 3.6215(3.6272) | Xent 0.0779(0.0729) | Loss 8.9531(9.8756) | Error 0.0289(0.0232) Steps 706(696.94) | Grad Norm 7.5222(7.2810) | Total Time 0.00(0.00)\n",
      "Iter 7330 | Time 18.1807(18.0306) | Bit/dim 3.6297(3.6275) | Xent 0.0751(0.0767) | Loss 9.0390(9.6523) | Error 0.0222(0.0242) Steps 706(700.91) | Grad Norm 5.7674(7.3446) | Total Time 0.00(0.00)\n",
      "Iter 7340 | Time 18.0853(18.0887) | Bit/dim 3.6217(3.6298) | Xent 0.0584(0.0777) | Loss 8.9309(9.4912) | Error 0.0200(0.0249) Steps 730(702.75) | Grad Norm 5.1748(7.0492) | Total Time 0.00(0.00)\n",
      "Iter 7350 | Time 18.2157(18.1233) | Bit/dim 3.6245(3.6314) | Xent 0.0352(0.0743) | Loss 8.9776(9.3602) | Error 0.0122(0.0240) Steps 724(701.88) | Grad Norm 5.3270(6.8780) | Total Time 0.00(0.00)\n",
      "Iter 7360 | Time 18.1026(18.1038) | Bit/dim 3.6487(3.6292) | Xent 0.0874(0.0743) | Loss 9.0885(9.2693) | Error 0.0344(0.0239) Steps 718(706.25) | Grad Norm 7.3387(6.5385) | Total Time 0.00(0.00)\n",
      "Iter 7370 | Time 18.3867(18.1657) | Bit/dim 3.6396(3.6300) | Xent 0.0697(0.0747) | Loss 8.9807(9.1981) | Error 0.0256(0.0238) Steps 664(702.27) | Grad Norm 5.1074(6.4237) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 91.0668, Epoch Time 1112.4261(1078.8387), Bit/dim 3.6418(best: 3.6424), Xent 1.8674, Loss 4.5755, Error 0.3266(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7380 | Time 18.5384(18.1616) | Bit/dim 3.6132(3.6285) | Xent 0.0717(0.0702) | Loss 8.9517(9.7609) | Error 0.0256(0.0223) Steps 682(698.02) | Grad Norm 6.2184(6.0498) | Total Time 0.00(0.00)\n",
      "Iter 7390 | Time 16.8913(18.1242) | Bit/dim 3.6390(3.6265) | Xent 0.0943(0.0707) | Loss 8.8553(9.5620) | Error 0.0222(0.0220) Steps 682(697.76) | Grad Norm 4.8662(6.0475) | Total Time 0.00(0.00)\n",
      "Iter 7400 | Time 17.8633(18.1302) | Bit/dim 3.6677(3.6252) | Xent 0.0524(0.0692) | Loss 8.8421(9.4022) | Error 0.0178(0.0217) Steps 652(695.27) | Grad Norm 5.5713(6.0791) | Total Time 0.00(0.00)\n",
      "Iter 7410 | Time 17.3754(18.0920) | Bit/dim 3.6468(3.6248) | Xent 0.0446(0.0664) | Loss 9.0493(9.2878) | Error 0.0156(0.0207) Steps 706(696.68) | Grad Norm 4.5867(5.7659) | Total Time 0.00(0.00)\n",
      "Iter 7420 | Time 19.4078(18.1671) | Bit/dim 3.6232(3.6261) | Xent 0.0837(0.0661) | Loss 9.0683(9.2123) | Error 0.0222(0.0207) Steps 742(696.20) | Grad Norm 12.1674(6.1060) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 90.9810, Epoch Time 1107.9125(1079.7109), Bit/dim 3.6374(best: 3.6418), Xent 1.8637, Loss 4.5692, Error 0.3304(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7430 | Time 17.7824(18.1052) | Bit/dim 3.6156(3.6223) | Xent 0.0309(0.0632) | Loss 8.9509(9.8682) | Error 0.0089(0.0199) Steps 700(696.59) | Grad Norm 3.4740(5.8406) | Total Time 0.00(0.00)\n",
      "Iter 7440 | Time 18.0391(18.0453) | Bit/dim 3.5826(3.6216) | Xent 0.0907(0.0611) | Loss 8.9950(9.6246) | Error 0.0300(0.0189) Steps 706(696.28) | Grad Norm 5.0756(5.5901) | Total Time 0.00(0.00)\n",
      "Iter 7450 | Time 18.0836(18.0298) | Bit/dim 3.6133(3.6198) | Xent 0.0947(0.0616) | Loss 9.0445(9.4606) | Error 0.0233(0.0183) Steps 676(694.71) | Grad Norm 9.7822(5.8439) | Total Time 0.00(0.00)\n",
      "Iter 7460 | Time 17.4707(18.0443) | Bit/dim 3.6752(3.6193) | Xent 0.0683(0.0605) | Loss 9.1193(9.3256) | Error 0.0256(0.0180) Steps 718(694.93) | Grad Norm 8.8050(6.0663) | Total Time 0.00(0.00)\n",
      "Iter 7470 | Time 17.6666(18.0955) | Bit/dim 3.6330(3.6185) | Xent 0.0668(0.0582) | Loss 8.9031(9.2188) | Error 0.0233(0.0176) Steps 682(694.43) | Grad Norm 4.5785(5.6412) | Total Time 0.00(0.00)\n",
      "Iter 7480 | Time 18.4244(18.0709) | Bit/dim 3.6100(3.6184) | Xent 0.0747(0.0596) | Loss 8.9879(9.1539) | Error 0.0222(0.0181) Steps 670(692.70) | Grad Norm 9.0152(5.6739) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 91.2004, Epoch Time 1103.7978(1080.4335), Bit/dim 3.6364(best: 3.6374), Xent 1.9089, Loss 4.5908, Error 0.3291(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7490 | Time 18.6495(18.1342) | Bit/dim 3.6339(3.6190) | Xent 0.0830(0.0599) | Loss 9.0090(9.7340) | Error 0.0244(0.0184) Steps 712(693.44) | Grad Norm 7.2950(5.7996) | Total Time 0.00(0.00)\n",
      "Iter 7500 | Time 19.1974(18.2118) | Bit/dim 3.6489(3.6182) | Xent 0.1161(0.0627) | Loss 9.0756(9.5384) | Error 0.0356(0.0192) Steps 700(694.38) | Grad Norm 9.0014(5.8531) | Total Time 0.00(0.00)\n",
      "Iter 7510 | Time 18.6405(18.2086) | Bit/dim 3.5988(3.6198) | Xent 0.0621(0.0654) | Loss 8.9263(9.3902) | Error 0.0156(0.0199) Steps 742(699.55) | Grad Norm 4.8713(6.3480) | Total Time 0.00(0.00)\n",
      "Iter 7520 | Time 18.3881(18.2654) | Bit/dim 3.6219(3.6218) | Xent 0.0857(0.0680) | Loss 8.9825(9.2974) | Error 0.0278(0.0205) Steps 724(701.67) | Grad Norm 8.8420(6.4666) | Total Time 0.00(0.00)\n",
      "Iter 7530 | Time 18.2945(18.3604) | Bit/dim 3.6639(3.6227) | Xent 0.1002(0.0745) | Loss 9.1411(9.2260) | Error 0.0256(0.0226) Steps 706(705.99) | Grad Norm 8.2925(6.7244) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 93.5275, Epoch Time 1124.6830(1081.7610), Bit/dim 3.6441(best: 3.6364), Xent 1.7593, Loss 4.5237, Error 0.3305(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7540 | Time 18.4673(18.2822) | Bit/dim 3.6573(3.6287) | Xent 0.0970(0.0826) | Loss 9.0936(9.9181) | Error 0.0300(0.0251) Steps 712(704.76) | Grad Norm 13.0600(7.3629) | Total Time 0.00(0.00)\n",
      "Iter 7550 | Time 18.4289(18.3077) | Bit/dim 3.6189(3.6275) | Xent 0.0707(0.0788) | Loss 9.0253(9.6755) | Error 0.0200(0.0242) Steps 718(704.15) | Grad Norm 8.1425(7.6597) | Total Time 0.00(0.00)\n",
      "Iter 7560 | Time 17.9155(18.2755) | Bit/dim 3.6180(3.6261) | Xent 0.1066(0.0800) | Loss 8.9862(9.4968) | Error 0.0300(0.0244) Steps 706(704.56) | Grad Norm 9.5632(7.6918) | Total Time 0.00(0.00)\n",
      "Iter 7570 | Time 17.7100(18.1746) | Bit/dim 3.6307(3.6252) | Xent 0.1098(0.0795) | Loss 9.1056(9.3695) | Error 0.0278(0.0246) Steps 682(700.82) | Grad Norm 7.3697(7.2992) | Total Time 0.00(0.00)\n",
      "Iter 7580 | Time 18.6744(18.2236) | Bit/dim 3.6331(3.6228) | Xent 0.0918(0.0858) | Loss 8.9346(9.2792) | Error 0.0333(0.0263) Steps 694(703.21) | Grad Norm 7.9575(7.4841) | Total Time 0.00(0.00)\n",
      "Iter 7590 | Time 18.2035(18.2293) | Bit/dim 3.6305(3.6267) | Xent 0.0797(0.0857) | Loss 9.1064(9.2010) | Error 0.0200(0.0259) Steps 712(705.30) | Grad Norm 4.0570(7.3459) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 93.3201, Epoch Time 1116.3284(1082.7980), Bit/dim 3.6405(best: 3.6364), Xent 1.7558, Loss 4.5184, Error 0.3334(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7600 | Time 17.5323(18.1450) | Bit/dim 3.6118(3.6258) | Xent 0.0561(0.0763) | Loss 8.7818(9.7545) | Error 0.0144(0.0230) Steps 688(706.53) | Grad Norm 6.4143(7.1120) | Total Time 0.00(0.00)\n",
      "Iter 7610 | Time 17.6242(18.0709) | Bit/dim 3.6131(3.6219) | Xent 0.0543(0.0718) | Loss 8.9610(9.5368) | Error 0.0178(0.0218) Steps 664(701.85) | Grad Norm 4.3623(6.9082) | Total Time 0.00(0.00)\n",
      "Iter 7620 | Time 17.7192(17.9638) | Bit/dim 3.5944(3.6196) | Xent 0.0640(0.0726) | Loss 8.8623(9.3810) | Error 0.0200(0.0221) Steps 682(695.03) | Grad Norm 6.0205(7.0721) | Total Time 0.00(0.00)\n",
      "Iter 7630 | Time 18.0005(18.0465) | Bit/dim 3.6180(3.6221) | Xent 0.0574(0.0700) | Loss 9.0042(9.2820) | Error 0.0189(0.0216) Steps 706(698.16) | Grad Norm 4.6611(6.8292) | Total Time 0.00(0.00)\n",
      "Iter 7640 | Time 17.7207(18.0856) | Bit/dim 3.6144(3.6255) | Xent 0.0864(0.0687) | Loss 8.9513(9.2053) | Error 0.0256(0.0214) Steps 694(698.66) | Grad Norm 6.8193(6.7514) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 94.2004, Epoch Time 1106.1726(1083.4992), Bit/dim 3.6453(best: 3.6364), Xent 1.9154, Loss 4.6030, Error 0.3324(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7650 | Time 19.4488(18.1711) | Bit/dim 3.6353(3.6269) | Xent 0.0725(0.0692) | Loss 9.1550(9.9125) | Error 0.0256(0.0217) Steps 736(701.89) | Grad Norm 7.9104(7.0707) | Total Time 0.00(0.00)\n",
      "Iter 7660 | Time 17.7661(18.1969) | Bit/dim 3.6170(3.6234) | Xent 0.0638(0.0666) | Loss 9.0702(9.6694) | Error 0.0200(0.0210) Steps 688(703.81) | Grad Norm 6.1740(6.8613) | Total Time 0.00(0.00)\n",
      "Iter 7670 | Time 18.1191(18.2016) | Bit/dim 3.6042(3.6206) | Xent 0.0715(0.0639) | Loss 8.8948(9.4846) | Error 0.0244(0.0201) Steps 706(707.17) | Grad Norm 10.3700(6.7215) | Total Time 0.00(0.00)\n",
      "Iter 7680 | Time 18.8161(18.2865) | Bit/dim 3.6435(3.6207) | Xent 0.0545(0.0628) | Loss 9.1278(9.3563) | Error 0.0167(0.0195) Steps 760(709.71) | Grad Norm 5.9688(6.5174) | Total Time 0.00(0.00)\n",
      "Iter 7690 | Time 19.0286(18.2484) | Bit/dim 3.6285(3.6192) | Xent 0.1002(0.0658) | Loss 9.0520(9.2544) | Error 0.0378(0.0208) Steps 682(704.50) | Grad Norm 6.4629(6.3366) | Total Time 0.00(0.00)\n",
      "Iter 7700 | Time 19.2115(18.2952) | Bit/dim 3.6480(3.6190) | Xent 0.0968(0.0705) | Loss 9.0541(9.1807) | Error 0.0244(0.0222) Steps 754(706.96) | Grad Norm 8.0105(6.3747) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 92.8911, Epoch Time 1121.7287(1084.6461), Bit/dim 3.6396(best: 3.6364), Xent 1.8146, Loss 4.5469, Error 0.3264(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7710 | Time 18.1641(18.3046) | Bit/dim 3.6556(3.6188) | Xent 0.0470(0.0671) | Loss 9.1002(9.7398) | Error 0.0122(0.0212) Steps 724(709.69) | Grad Norm 3.7696(5.9897) | Total Time 0.00(0.00)\n",
      "Iter 7720 | Time 19.0905(18.5126) | Bit/dim 3.5869(3.6183) | Xent 0.0806(0.0661) | Loss 8.8607(9.5417) | Error 0.0222(0.0206) Steps 712(713.84) | Grad Norm 5.4019(6.0776) | Total Time 0.00(0.00)\n",
      "Iter 7730 | Time 18.3116(18.5460) | Bit/dim 3.6506(3.6193) | Xent 0.1304(0.0700) | Loss 9.0996(9.4027) | Error 0.0344(0.0215) Steps 700(714.53) | Grad Norm 8.1113(6.2280) | Total Time 0.00(0.00)\n",
      "Iter 7740 | Time 19.6796(18.6089) | Bit/dim 3.6331(3.6215) | Xent 0.1311(0.0782) | Loss 9.2268(9.3231) | Error 0.0444(0.0245) Steps 754(715.28) | Grad Norm 15.4002(7.2805) | Total Time 0.00(0.00)\n",
      "Iter 7750 | Time 18.1747(18.6140) | Bit/dim 3.6473(3.6246) | Xent 0.1000(0.0885) | Loss 9.0535(9.2626) | Error 0.0378(0.0280) Steps 700(713.71) | Grad Norm 6.9413(8.0564) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 92.7479, Epoch Time 1143.5320(1086.4127), Bit/dim 3.6414(best: 3.6364), Xent 1.7533, Loss 4.5180, Error 0.3330(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7760 | Time 17.7942(18.5568) | Bit/dim 3.6115(3.6249) | Xent 0.0720(0.0858) | Loss 8.9795(9.9384) | Error 0.0222(0.0272) Steps 724(710.12) | Grad Norm 7.8791(7.7273) | Total Time 0.00(0.00)\n",
      "Iter 7770 | Time 18.7748(18.4723) | Bit/dim 3.6270(3.6247) | Xent 0.1419(0.0867) | Loss 9.1253(9.6966) | Error 0.0378(0.0273) Steps 742(711.51) | Grad Norm 11.6207(7.6019) | Total Time 0.00(0.00)\n",
      "Iter 7780 | Time 17.9674(18.4337) | Bit/dim 3.6406(3.6266) | Xent 0.0591(0.0827) | Loss 9.1268(9.5176) | Error 0.0167(0.0262) Steps 706(708.56) | Grad Norm 4.7025(7.2111) | Total Time 0.00(0.00)\n",
      "Iter 7790 | Time 18.0416(18.3660) | Bit/dim 3.6222(3.6218) | Xent 0.0777(0.0790) | Loss 9.0248(9.3686) | Error 0.0256(0.0246) Steps 736(709.43) | Grad Norm 7.6068(6.8330) | Total Time 0.00(0.00)\n",
      "Iter 7800 | Time 17.9082(18.3298) | Bit/dim 3.6611(3.6198) | Xent 0.0631(0.0730) | Loss 8.9232(9.2667) | Error 0.0211(0.0228) Steps 682(708.97) | Grad Norm 4.9245(6.3987) | Total Time 0.00(0.00)\n",
      "Iter 7810 | Time 18.7029(18.3212) | Bit/dim 3.6279(3.6198) | Xent 0.0877(0.0678) | Loss 9.1119(9.1954) | Error 0.0211(0.0208) Steps 742(709.36) | Grad Norm 5.3030(5.9106) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 93.3615, Epoch Time 1118.1092(1087.3636), Bit/dim 3.6278(best: 3.6364), Xent 1.8380, Loss 4.5468, Error 0.3200(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7820 | Time 18.3224(18.3135) | Bit/dim 3.6347(3.6188) | Xent 0.0561(0.0623) | Loss 8.9754(9.7491) | Error 0.0167(0.0192) Steps 694(708.47) | Grad Norm 4.3007(5.5169) | Total Time 0.00(0.00)\n",
      "Iter 7830 | Time 18.0661(18.2871) | Bit/dim 3.6312(3.6148) | Xent 0.0482(0.0607) | Loss 8.8605(9.5387) | Error 0.0122(0.0186) Steps 742(711.46) | Grad Norm 3.6213(5.3269) | Total Time 0.00(0.00)\n",
      "Iter 7840 | Time 17.9190(18.3271) | Bit/dim 3.5845(3.6136) | Xent 0.0472(0.0615) | Loss 8.8601(9.3951) | Error 0.0111(0.0188) Steps 682(711.28) | Grad Norm 5.1125(5.4180) | Total Time 0.00(0.00)\n",
      "Iter 7850 | Time 18.5989(18.4001) | Bit/dim 3.6078(3.6152) | Xent 0.0373(0.0572) | Loss 9.0289(9.2917) | Error 0.0144(0.0180) Steps 712(713.77) | Grad Norm 5.7283(5.4458) | Total Time 0.00(0.00)\n",
      "Iter 7860 | Time 18.3754(18.4497) | Bit/dim 3.6072(3.6129) | Xent 0.0462(0.0581) | Loss 9.1016(9.2088) | Error 0.0133(0.0182) Steps 718(711.00) | Grad Norm 5.6850(5.7085) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 93.3629, Epoch Time 1128.3637(1088.5936), Bit/dim 3.6376(best: 3.6278), Xent 1.9336, Loss 4.6044, Error 0.3314(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7870 | Time 18.8823(18.5152) | Bit/dim 3.5980(3.6141) | Xent 0.0440(0.0587) | Loss 8.9259(9.9074) | Error 0.0122(0.0183) Steps 670(711.08) | Grad Norm 4.4974(5.8619) | Total Time 0.00(0.00)\n",
      "Iter 7880 | Time 17.9784(18.4706) | Bit/dim 3.6374(3.6139) | Xent 0.0505(0.0592) | Loss 9.0712(9.6683) | Error 0.0233(0.0190) Steps 730(714.39) | Grad Norm 4.9419(5.6125) | Total Time 0.00(0.00)\n",
      "Iter 7890 | Time 18.2627(18.4563) | Bit/dim 3.6024(3.6121) | Xent 0.0905(0.0597) | Loss 8.9680(9.4802) | Error 0.0244(0.0190) Steps 706(716.14) | Grad Norm 6.2442(5.4167) | Total Time 0.00(0.00)\n",
      "Iter 7900 | Time 19.1223(18.4360) | Bit/dim 3.6467(3.6131) | Xent 0.1036(0.0634) | Loss 9.0126(9.3555) | Error 0.0289(0.0199) Steps 730(716.75) | Grad Norm 11.1250(5.8865) | Total Time 0.00(0.00)\n",
      "Iter 7910 | Time 18.4271(18.4039) | Bit/dim 3.6201(3.6138) | Xent 0.0579(0.0622) | Loss 9.0166(9.2635) | Error 0.0167(0.0194) Steps 724(717.37) | Grad Norm 5.1567(5.5882) | Total Time 0.00(0.00)\n",
      "Iter 7920 | Time 18.0744(18.4074) | Bit/dim 3.6568(3.6143) | Xent 0.0629(0.0652) | Loss 9.0864(9.1895) | Error 0.0211(0.0205) Steps 700(714.07) | Grad Norm 5.2742(5.9053) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 93.2065, Epoch Time 1127.6955(1089.7667), Bit/dim 3.6365(best: 3.6278), Xent 1.7733, Loss 4.5232, Error 0.3298(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7930 | Time 18.4210(18.3748) | Bit/dim 3.6128(3.6180) | Xent 0.0643(0.0647) | Loss 9.0480(9.7845) | Error 0.0167(0.0199) Steps 730(715.78) | Grad Norm 4.9237(6.1960) | Total Time 0.00(0.00)\n",
      "Iter 7940 | Time 18.2764(18.3403) | Bit/dim 3.6044(3.6174) | Xent 0.0375(0.0651) | Loss 8.8410(9.5604) | Error 0.0144(0.0198) Steps 682(710.15) | Grad Norm 4.6110(6.6133) | Total Time 0.00(0.00)\n",
      "Iter 7950 | Time 17.5057(18.3005) | Bit/dim 3.5901(3.6119) | Xent 0.0560(0.0646) | Loss 8.7580(9.3844) | Error 0.0189(0.0198) Steps 700(708.38) | Grad Norm 6.6136(6.6025) | Total Time 0.00(0.00)\n",
      "Iter 7960 | Time 17.7156(18.3010) | Bit/dim 3.6217(3.6134) | Xent 0.0471(0.0602) | Loss 8.9598(9.2797) | Error 0.0156(0.0185) Steps 682(706.95) | Grad Norm 3.8197(6.1450) | Total Time 0.00(0.00)\n",
      "Iter 7970 | Time 18.5300(18.2588) | Bit/dim 3.6271(3.6120) | Xent 0.0556(0.0610) | Loss 9.1582(9.2046) | Error 0.0189(0.0184) Steps 712(704.89) | Grad Norm 6.2261(5.9566) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 92.6639, Epoch Time 1120.8172(1090.6982), Bit/dim 3.6333(best: 3.6278), Xent 1.9282, Loss 4.5974, Error 0.3385(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7980 | Time 18.2179(18.2966) | Bit/dim 3.6326(3.6111) | Xent 0.1019(0.0625) | Loss 9.0855(9.8628) | Error 0.0300(0.0189) Steps 718(702.52) | Grad Norm 6.3155(6.0379) | Total Time 0.00(0.00)\n",
      "Iter 7990 | Time 19.0604(18.3457) | Bit/dim 3.6168(3.6093) | Xent 0.0687(0.0625) | Loss 9.0292(9.6329) | Error 0.0222(0.0190) Steps 688(705.30) | Grad Norm 9.1571(6.2608) | Total Time 0.00(0.00)\n",
      "Iter 8000 | Time 17.8812(18.3089) | Bit/dim 3.6377(3.6130) | Xent 0.0570(0.0626) | Loss 9.0384(9.4778) | Error 0.0178(0.0189) Steps 724(705.25) | Grad Norm 5.1740(6.3009) | Total Time 0.00(0.00)\n",
      "Iter 8010 | Time 19.0411(18.3087) | Bit/dim 3.5952(3.6141) | Xent 0.0553(0.0604) | Loss 8.9814(9.3453) | Error 0.0178(0.0184) Steps 706(703.58) | Grad Norm 5.0636(5.9559) | Total Time 0.00(0.00)\n",
      "Iter 8020 | Time 17.8802(18.3377) | Bit/dim 3.6170(3.6132) | Xent 0.0724(0.0611) | Loss 9.0764(9.2624) | Error 0.0211(0.0184) Steps 712(706.00) | Grad Norm 6.4265(6.0704) | Total Time 0.00(0.00)\n",
      "Iter 8030 | Time 19.0604(18.3923) | Bit/dim 3.6017(3.6135) | Xent 0.0378(0.0646) | Loss 9.0209(9.1830) | Error 0.0122(0.0197) Steps 736(707.24) | Grad Norm 6.0990(6.1356) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 93.6432, Epoch Time 1126.4512(1091.7708), Bit/dim 3.6321(best: 3.6278), Xent 1.8237, Loss 4.5440, Error 0.3300(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8040 | Time 17.9814(18.4367) | Bit/dim 3.5939(3.6122) | Xent 0.0466(0.0611) | Loss 8.8594(9.7775) | Error 0.0144(0.0191) Steps 724(709.79) | Grad Norm 4.9533(5.7935) | Total Time 0.00(0.00)\n",
      "Iter 8050 | Time 18.2355(18.3506) | Bit/dim 3.6180(3.6144) | Xent 0.0734(0.0610) | Loss 9.0000(9.5703) | Error 0.0244(0.0188) Steps 700(709.68) | Grad Norm 9.1419(6.1533) | Total Time 0.00(0.00)\n",
      "Iter 8060 | Time 19.3052(18.3632) | Bit/dim 3.6190(3.6144) | Xent 0.0696(0.0621) | Loss 8.9671(9.4228) | Error 0.0211(0.0192) Steps 724(710.82) | Grad Norm 5.6456(6.3058) | Total Time 0.00(0.00)\n",
      "Iter 8070 | Time 17.5927(18.3473) | Bit/dim 3.6597(3.6142) | Xent 0.0771(0.0624) | Loss 9.0659(9.3103) | Error 0.0256(0.0199) Steps 694(711.73) | Grad Norm 9.8774(6.5339) | Total Time 0.00(0.00)\n",
      "Iter 8080 | Time 18.4115(18.4119) | Bit/dim 3.6119(3.6147) | Xent 0.0437(0.0622) | Loss 8.9562(9.2234) | Error 0.0122(0.0197) Steps 724(711.65) | Grad Norm 5.7667(6.4534) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0147 | Time 92.5697, Epoch Time 1125.9112(1092.7950), Bit/dim 3.6344(best: 3.6278), Xent 1.8825, Loss 4.5757, Error 0.3330(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8090 | Time 18.0497(18.3689) | Bit/dim 3.5887(3.6149) | Xent 0.0804(0.0670) | Loss 8.9641(9.9102) | Error 0.0211(0.0207) Steps 700(710.40) | Grad Norm 9.7393(7.2044) | Total Time 0.00(0.00)\n",
      "Iter 8100 | Time 17.8291(18.3738) | Bit/dim 3.6049(3.6139) | Xent 0.0739(0.0697) | Loss 8.8493(9.6725) | Error 0.0256(0.0216) Steps 670(710.65) | Grad Norm 6.7601(7.0858) | Total Time 0.00(0.00)\n",
      "Iter 8110 | Time 17.7391(18.3619) | Bit/dim 3.5733(3.6123) | Xent 0.0471(0.0672) | Loss 8.8184(9.4831) | Error 0.0144(0.0207) Steps 706(709.71) | Grad Norm 5.1322(6.5860) | Total Time 0.00(0.00)\n",
      "Iter 8120 | Time 18.7201(18.3655) | Bit/dim 3.5986(3.6101) | Xent 0.0372(0.0613) | Loss 8.9219(9.3530) | Error 0.0100(0.0186) Steps 700(710.34) | Grad Norm 2.7781(5.9344) | Total Time 0.00(0.00)\n",
      "Iter 8130 | Time 18.4538(18.3101) | Bit/dim 3.5899(3.6070) | Xent 0.0572(0.0593) | Loss 8.9146(9.2287) | Error 0.0144(0.0179) Steps 700(708.24) | Grad Norm 5.9507(5.6667) | Total Time 0.00(0.00)\n",
      "Iter 8140 | Time 18.8062(18.3613) | Bit/dim 3.6022(3.6085) | Xent 0.0351(0.0559) | Loss 8.9352(9.1607) | Error 0.0111(0.0172) Steps 730(710.46) | Grad Norm 4.8346(5.4713) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 92.6805, Epoch Time 1124.3502(1093.7416), Bit/dim 3.6183(best: 3.6278), Xent 1.9199, Loss 4.5782, Error 0.3234(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8150 | Time 18.2903(18.4120) | Bit/dim 3.6091(3.6097) | Xent 0.0860(0.0579) | Loss 8.9425(9.7578) | Error 0.0244(0.0174) Steps 724(713.80) | Grad Norm 9.0996(5.6632) | Total Time 0.00(0.00)\n",
      "Iter 8160 | Time 18.9113(18.4361) | Bit/dim 3.6141(3.6106) | Xent 0.0752(0.0584) | Loss 8.9913(9.5482) | Error 0.0267(0.0180) Steps 766(713.36) | Grad Norm 5.8390(6.2242) | Total Time 0.00(0.00)\n",
      "Iter 8170 | Time 18.5803(18.4829) | Bit/dim 3.5958(3.6097) | Xent 0.0490(0.0608) | Loss 8.9512(9.4016) | Error 0.0156(0.0191) Steps 730(716.99) | Grad Norm 7.0519(6.4020) | Total Time 0.00(0.00)\n",
      "Iter 8180 | Time 18.2206(18.4641) | Bit/dim 3.6529(3.6116) | Xent 0.0329(0.0613) | Loss 8.9824(9.2988) | Error 0.0111(0.0190) Steps 718(717.99) | Grad Norm 8.2127(6.9657) | Total Time 0.00(0.00)\n",
      "Iter 8190 | Time 17.9425(18.4680) | Bit/dim 3.6032(3.6087) | Xent 0.0931(0.0597) | Loss 8.9056(9.2031) | Error 0.0278(0.0189) Steps 718(715.02) | Grad Norm 7.9544(6.7137) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 92.8185, Epoch Time 1131.0205(1094.8600), Bit/dim 3.6216(best: 3.6183), Xent 1.9481, Loss 4.5956, Error 0.3321(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8200 | Time 17.9043(18.4534) | Bit/dim 3.6051(3.6093) | Xent 0.0482(0.0600) | Loss 8.8612(9.8584) | Error 0.0167(0.0192) Steps 724(714.36) | Grad Norm 6.7300(6.5402) | Total Time 0.00(0.00)\n",
      "Iter 8210 | Time 18.3621(18.4321) | Bit/dim 3.6204(3.6072) | Xent 0.0522(0.0558) | Loss 8.9952(9.6169) | Error 0.0156(0.0178) Steps 718(713.09) | Grad Norm 4.8049(6.2010) | Total Time 0.00(0.00)\n",
      "Iter 8220 | Time 18.3346(18.3565) | Bit/dim 3.6328(3.6075) | Xent 0.0643(0.0582) | Loss 8.9828(9.4353) | Error 0.0167(0.0179) Steps 742(713.80) | Grad Norm 4.4405(6.2259) | Total Time 0.00(0.00)\n",
      "Iter 8230 | Time 18.7830(18.4369) | Bit/dim 3.5803(3.6050) | Xent 0.0650(0.0614) | Loss 8.8745(9.3081) | Error 0.0233(0.0189) Steps 676(713.59) | Grad Norm 7.0723(6.1851) | Total Time 0.00(0.00)\n",
      "Iter 8240 | Time 18.6385(18.3953) | Bit/dim 3.6354(3.6076) | Xent 0.0534(0.0658) | Loss 9.0534(9.2232) | Error 0.0144(0.0201) Steps 730(715.32) | Grad Norm 4.8196(6.4119) | Total Time 0.00(0.00)\n",
      "Iter 8250 | Time 18.0150(18.3652) | Bit/dim 3.6186(3.6087) | Xent 0.0888(0.0705) | Loss 8.8858(9.1602) | Error 0.0267(0.0217) Steps 706(714.90) | Grad Norm 4.9781(6.7876) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 92.7488, Epoch Time 1123.6856(1095.7248), Bit/dim 3.6283(best: 3.6183), Xent 1.9066, Loss 4.5817, Error 0.3312(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8260 | Time 17.9989(18.3537) | Bit/dim 3.6468(3.6130) | Xent 0.0927(0.0744) | Loss 9.1060(9.7627) | Error 0.0311(0.0234) Steps 724(718.29) | Grad Norm 5.5942(6.9222) | Total Time 0.00(0.00)\n",
      "Iter 8270 | Time 17.6147(18.3056) | Bit/dim 3.6049(3.6142) | Xent 0.0634(0.0724) | Loss 8.8288(9.5616) | Error 0.0211(0.0228) Steps 688(717.42) | Grad Norm 6.1613(6.7372) | Total Time 0.00(0.00)\n",
      "Iter 8280 | Time 18.3593(18.3786) | Bit/dim 3.6140(3.6146) | Xent 0.0706(0.0724) | Loss 8.9835(9.4156) | Error 0.0211(0.0222) Steps 676(713.75) | Grad Norm 5.0876(6.7184) | Total Time 0.00(0.00)\n",
      "Iter 8290 | Time 19.1734(18.3969) | Bit/dim 3.6010(3.6116) | Xent 0.0578(0.0713) | Loss 8.9111(9.2999) | Error 0.0144(0.0220) Steps 676(713.88) | Grad Norm 3.4660(6.2843) | Total Time 0.00(0.00)\n",
      "Iter 8300 | Time 18.0820(18.2912) | Bit/dim 3.5562(3.6081) | Xent 0.0681(0.0675) | Loss 8.8232(9.1951) | Error 0.0200(0.0213) Steps 694(709.25) | Grad Norm 6.1845(6.0890) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0151 | Time 94.0910, Epoch Time 1122.5686(1096.5301), Bit/dim 3.6213(best: 3.6183), Xent 1.8274, Loss 4.5350, Error 0.3273(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8310 | Time 18.7128(18.3277) | Bit/dim 3.6269(3.6090) | Xent 0.0500(0.0670) | Loss 9.0098(9.8871) | Error 0.0156(0.0212) Steps 730(711.25) | Grad Norm 4.5214(6.1113) | Total Time 0.00(0.00)\n",
      "Iter 8320 | Time 18.8343(18.3967) | Bit/dim 3.6086(3.6098) | Xent 0.0406(0.0663) | Loss 8.9216(9.6459) | Error 0.0078(0.0205) Steps 688(712.87) | Grad Norm 4.5681(6.1383) | Total Time 0.00(0.00)\n",
      "Iter 8330 | Time 19.1808(18.4061) | Bit/dim 3.5939(3.6082) | Xent 0.0664(0.0657) | Loss 8.8898(9.4637) | Error 0.0233(0.0208) Steps 730(714.45) | Grad Norm 8.4967(6.0993) | Total Time 0.00(0.00)\n",
      "Iter 8340 | Time 18.3167(18.3327) | Bit/dim 3.5990(3.6061) | Xent 0.0893(0.0647) | Loss 9.0886(9.3362) | Error 0.0244(0.0205) Steps 724(716.17) | Grad Norm 3.8883(5.9854) | Total Time 0.00(0.00)\n",
      "Iter 8350 | Time 17.8714(18.2915) | Bit/dim 3.5864(3.6043) | Xent 0.0657(0.0616) | Loss 8.8350(9.2223) | Error 0.0233(0.0195) Steps 700(716.28) | Grad Norm 7.1035(5.6330) | Total Time 0.00(0.00)\n",
      "Iter 8360 | Time 18.1416(18.3157) | Bit/dim 3.6071(3.6043) | Xent 0.0479(0.0585) | Loss 8.9773(9.1561) | Error 0.0144(0.0185) Steps 682(712.40) | Grad Norm 4.8989(5.5222) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0152 | Time 92.3771, Epoch Time 1122.7971(1097.3181), Bit/dim 3.6222(best: 3.6183), Xent 1.9735, Loss 4.6089, Error 0.3336(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8370 | Time 18.1355(18.2963) | Bit/dim 3.6253(3.6048) | Xent 0.0475(0.0583) | Loss 9.1028(9.7644) | Error 0.0156(0.0182) Steps 724(713.09) | Grad Norm 5.2313(5.8523) | Total Time 0.00(0.00)\n",
      "Iter 8380 | Time 17.8656(18.2591) | Bit/dim 3.6121(3.6064) | Xent 0.0437(0.0602) | Loss 9.0541(9.5606) | Error 0.0100(0.0186) Steps 724(710.88) | Grad Norm 4.7739(6.0981) | Total Time 0.00(0.00)\n",
      "Iter 8390 | Time 18.6978(18.3015) | Bit/dim 3.6432(3.6062) | Xent 0.0749(0.0639) | Loss 9.0836(9.4054) | Error 0.0233(0.0197) Steps 736(713.43) | Grad Norm 5.3160(6.3920) | Total Time 0.00(0.00)\n",
      "Iter 8400 | Time 18.5499(18.3548) | Bit/dim 3.6396(3.6070) | Xent 0.0509(0.0616) | Loss 9.0679(9.2911) | Error 0.0211(0.0191) Steps 724(714.22) | Grad Norm 5.0182(6.3058) | Total Time 0.00(0.00)\n",
      "Iter 8410 | Time 18.4782(18.3635) | Bit/dim 3.6016(3.6054) | Xent 0.0728(0.0629) | Loss 8.9254(9.2055) | Error 0.0178(0.0195) Steps 706(716.95) | Grad Norm 5.4574(6.1491) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0153 | Time 93.0260, Epoch Time 1124.6439(1098.1379), Bit/dim 3.6366(best: 3.6183), Xent 1.8566, Loss 4.5649, Error 0.3353(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8420 | Time 18.7411(18.3670) | Bit/dim 3.6072(3.6085) | Xent 0.0622(0.0641) | Loss 9.0392(9.8924) | Error 0.0189(0.0198) Steps 718(717.40) | Grad Norm 7.3461(6.3419) | Total Time 0.00(0.00)\n",
      "Iter 8430 | Time 17.5640(18.3579) | Bit/dim 3.6270(3.6065) | Xent 0.0663(0.0651) | Loss 8.9840(9.6428) | Error 0.0189(0.0204) Steps 712(715.36) | Grad Norm 5.1894(6.5152) | Total Time 0.00(0.00)\n",
      "Iter 8440 | Time 17.8959(18.3454) | Bit/dim 3.5929(3.6045) | Xent 0.0713(0.0621) | Loss 8.6601(9.4425) | Error 0.0167(0.0196) Steps 694(710.09) | Grad Norm 5.8555(6.3845) | Total Time 0.00(0.00)\n",
      "Iter 8450 | Time 17.9643(18.2670) | Bit/dim 3.6282(3.6071) | Xent 0.0997(0.0610) | Loss 9.0618(9.3139) | Error 0.0322(0.0190) Steps 718(708.54) | Grad Norm 7.4347(6.1144) | Total Time 0.00(0.00)\n",
      "Iter 8460 | Time 17.6002(18.2359) | Bit/dim 3.6249(3.6071) | Xent 0.1254(0.0707) | Loss 9.0065(9.2210) | Error 0.0411(0.0218) Steps 706(706.64) | Grad Norm 7.6654(6.3898) | Total Time 0.00(0.00)\n",
      "Iter 8470 | Time 18.2614(18.2969) | Bit/dim 3.6202(3.6118) | Xent 0.0890(0.0783) | Loss 9.1168(9.1770) | Error 0.0289(0.0238) Steps 712(709.55) | Grad Norm 5.2250(6.2694) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0154 | Time 92.7762, Epoch Time 1121.2079(1098.8300), Bit/dim 3.6364(best: 3.6183), Xent 1.8220, Loss 4.5474, Error 0.3376(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8480 | Time 18.8699(18.3479) | Bit/dim 3.5668(3.6123) | Xent 0.0524(0.0748) | Loss 8.7790(9.7732) | Error 0.0156(0.0223) Steps 736(714.35) | Grad Norm 4.2917(6.0892) | Total Time 0.00(0.00)\n",
      "Iter 8490 | Time 18.7310(18.3430) | Bit/dim 3.6126(3.6116) | Xent 0.0483(0.0710) | Loss 8.9981(9.5703) | Error 0.0144(0.0211) Steps 736(716.08) | Grad Norm 4.3053(5.8748) | Total Time 0.00(0.00)\n",
      "Iter 8500 | Time 18.5203(18.3801) | Bit/dim 3.6032(3.6079) | Xent 0.0858(0.0709) | Loss 9.0886(9.4126) | Error 0.0222(0.0207) Steps 742(717.16) | Grad Norm 8.0185(5.9486) | Total Time 0.00(0.00)\n",
      "Iter 8510 | Time 18.9273(18.4775) | Bit/dim 3.6177(3.6093) | Xent 0.1128(0.0724) | Loss 9.1206(9.3085) | Error 0.0344(0.0217) Steps 736(719.01) | Grad Norm 11.2266(6.3852) | Total Time 0.00(0.00)\n",
      "Iter 8520 | Time 18.9196(18.4854) | Bit/dim 3.6161(3.6067) | Xent 0.0474(0.0745) | Loss 9.0226(9.2304) | Error 0.0189(0.0223) Steps 724(718.51) | Grad Norm 4.6322(6.3079) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0155 | Time 92.2264, Epoch Time 1130.9375(1099.7932), Bit/dim 3.6199(best: 3.6183), Xent 1.8565, Loss 4.5482, Error 0.3323(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8530 | Time 19.7785(18.5580) | Bit/dim 3.6022(3.6070) | Xent 0.0421(0.0692) | Loss 9.0249(9.9159) | Error 0.0144(0.0211) Steps 730(718.15) | Grad Norm 4.4642(5.8219) | Total Time 0.00(0.00)\n",
      "Iter 8540 | Time 18.3998(18.4924) | Bit/dim 3.6073(3.6061) | Xent 0.0426(0.0656) | Loss 8.8533(9.6600) | Error 0.0133(0.0202) Steps 712(717.91) | Grad Norm 6.7046(5.8101) | Total Time 0.00(0.00)\n",
      "Iter 8550 | Time 19.1234(18.4874) | Bit/dim 3.5974(3.6061) | Xent 0.0678(0.0688) | Loss 9.0354(9.4842) | Error 0.0178(0.0210) Steps 712(718.06) | Grad Norm 6.1852(5.9825) | Total Time 0.00(0.00)\n",
      "Iter 8560 | Time 17.1536(18.4431) | Bit/dim 3.6039(3.6067) | Xent 0.0480(0.0706) | Loss 8.8129(9.3557) | Error 0.0144(0.0217) Steps 712(715.94) | Grad Norm 7.7820(6.1722) | Total Time 0.00(0.00)\n",
      "Iter 8570 | Time 17.8551(18.4885) | Bit/dim 3.6124(3.6071) | Xent 0.0739(0.0703) | Loss 8.9386(9.2520) | Error 0.0244(0.0219) Steps 700(714.74) | Grad Norm 4.6112(6.1077) | Total Time 0.00(0.00)\n",
      "Iter 8580 | Time 18.6534(18.5099) | Bit/dim 3.5979(3.6063) | Xent 0.0722(0.0673) | Loss 8.7737(9.1739) | Error 0.0200(0.0210) Steps 682(712.70) | Grad Norm 5.1838(5.9501) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0156 | Time 91.7578, Epoch Time 1130.3753(1100.7107), Bit/dim 3.6210(best: 3.6183), Xent 1.8167, Loss 4.5294, Error 0.3237(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8590 | Time 18.1370(18.5614) | Bit/dim 3.5885(3.6060) | Xent 0.0466(0.0638) | Loss 8.8345(9.7616) | Error 0.0178(0.0201) Steps 682(711.44) | Grad Norm 4.9752(5.8812) | Total Time 0.00(0.00)\n",
      "Iter 8600 | Time 19.1796(18.4974) | Bit/dim 3.5773(3.6018) | Xent 0.0421(0.0569) | Loss 8.8257(9.5224) | Error 0.0156(0.0176) Steps 718(708.12) | Grad Norm 6.2046(5.4886) | Total Time 0.00(0.00)\n",
      "Iter 8610 | Time 18.4725(18.4175) | Bit/dim 3.6080(3.6019) | Xent 0.0626(0.0521) | Loss 8.9908(9.3665) | Error 0.0189(0.0161) Steps 688(709.72) | Grad Norm 7.6485(5.4527) | Total Time 0.00(0.00)\n",
      "Iter 8620 | Time 18.1044(18.4388) | Bit/dim 3.5848(3.6016) | Xent 0.0618(0.0565) | Loss 8.8846(9.2599) | Error 0.0189(0.0170) Steps 688(707.25) | Grad Norm 5.2149(5.9913) | Total Time 0.00(0.00)\n",
      "Iter 8630 | Time 18.5210(18.4498) | Bit/dim 3.6150(3.6009) | Xent 0.0857(0.0614) | Loss 9.0652(9.1850) | Error 0.0189(0.0185) Steps 736(707.21) | Grad Norm 5.0968(6.2111) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0157 | Time 92.8750, Epoch Time 1130.3737(1101.6005), Bit/dim 3.6256(best: 3.6183), Xent 1.9446, Loss 4.5979, Error 0.3401(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8640 | Time 19.1982(18.5336) | Bit/dim 3.6212(3.6017) | Xent 0.0710(0.0643) | Loss 8.9861(9.8911) | Error 0.0256(0.0194) Steps 712(713.73) | Grad Norm 5.3245(6.3182) | Total Time 0.00(0.00)\n",
      "Iter 8650 | Time 18.5693(18.5839) | Bit/dim 3.6038(3.6013) | Xent 0.0513(0.0650) | Loss 8.8892(9.6504) | Error 0.0156(0.0202) Steps 730(716.90) | Grad Norm 6.4210(6.6790) | Total Time 0.00(0.00)\n",
      "Iter 8660 | Time 18.8349(18.6102) | Bit/dim 3.5732(3.6031) | Xent 0.0844(0.0637) | Loss 8.9994(9.4748) | Error 0.0289(0.0197) Steps 742(717.37) | Grad Norm 9.5943(7.0255) | Total Time 0.00(0.00)\n",
      "Iter 8670 | Time 18.3223(18.5948) | Bit/dim 3.5827(3.6021) | Xent 0.0557(0.0636) | Loss 8.9789(9.3382) | Error 0.0167(0.0199) Steps 706(715.25) | Grad Norm 7.5693(6.7576) | Total Time 0.00(0.00)\n",
      "Iter 8680 | Time 18.0096(18.4769) | Bit/dim 3.6066(3.6027) | Xent 0.1065(0.0678) | Loss 9.0290(9.2358) | Error 0.0289(0.0212) Steps 724(714.65) | Grad Norm 7.2452(6.6179) | Total Time 0.00(0.00)\n",
      "Iter 8690 | Time 18.4375(18.4846) | Bit/dim 3.6309(3.6066) | Xent 0.0746(0.0702) | Loss 8.9653(9.1707) | Error 0.0278(0.0219) Steps 694(711.98) | Grad Norm 7.2138(6.5389) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0158 | Time 93.5574, Epoch Time 1133.4745(1102.5568), Bit/dim 3.6254(best: 3.6183), Xent 1.7894, Loss 4.5201, Error 0.3298(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8700 | Time 18.5261(18.4658) | Bit/dim 3.6085(3.6052) | Xent 0.0473(0.0666) | Loss 9.0688(9.7486) | Error 0.0122(0.0205) Steps 742(714.41) | Grad Norm 3.8326(6.1040) | Total Time 0.00(0.00)\n",
      "Iter 8710 | Time 18.8676(18.4182) | Bit/dim 3.5983(3.6028) | Xent 0.0448(0.0620) | Loss 8.8428(9.5229) | Error 0.0133(0.0192) Steps 742(711.08) | Grad Norm 3.7144(5.6899) | Total Time 0.00(0.00)\n",
      "Iter 8720 | Time 18.9910(18.4247) | Bit/dim 3.6137(3.5998) | Xent 0.0578(0.0583) | Loss 9.0379(9.3578) | Error 0.0178(0.0184) Steps 742(712.05) | Grad Norm 4.7339(5.2557) | Total Time 0.00(0.00)\n",
      "Iter 8730 | Time 19.5743(18.4292) | Bit/dim 3.6077(3.5995) | Xent 0.0725(0.0609) | Loss 8.9855(9.2437) | Error 0.0267(0.0191) Steps 748(711.66) | Grad Norm 7.4882(5.4716) | Total Time 0.00(0.00)\n",
      "Iter 8740 | Time 18.9652(18.4974) | Bit/dim 3.5701(3.6010) | Xent 0.0719(0.0611) | Loss 8.9328(9.1660) | Error 0.0256(0.0191) Steps 730(713.10) | Grad Norm 6.2176(5.8232) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0159 | Time 94.0089, Epoch Time 1131.0730(1103.4123), Bit/dim 3.6177(best: 3.6183), Xent 1.9322, Loss 4.5838, Error 0.3316(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8750 | Time 18.3667(18.4754) | Bit/dim 3.6192(3.5994) | Xent 0.0524(0.0597) | Loss 9.0315(9.8611) | Error 0.0122(0.0185) Steps 706(714.26) | Grad Norm 5.1503(5.4825) | Total Time 0.00(0.00)\n",
      "Iter 8760 | Time 18.5983(18.4485) | Bit/dim 3.6108(3.5995) | Xent 0.0629(0.0572) | Loss 9.0016(9.6128) | Error 0.0200(0.0180) Steps 718(714.63) | Grad Norm 6.9394(5.3192) | Total Time 0.00(0.00)\n",
      "Iter 8770 | Time 17.7772(18.3741) | Bit/dim 3.6432(3.5999) | Xent 0.0385(0.0540) | Loss 8.9365(9.4296) | Error 0.0100(0.0167) Steps 706(714.36) | Grad Norm 4.2934(5.2877) | Total Time 0.00(0.00)\n",
      "Iter 8780 | Time 18.5804(18.4356) | Bit/dim 3.6095(3.5994) | Xent 0.0624(0.0541) | Loss 8.9027(9.2922) | Error 0.0178(0.0168) Steps 718(714.82) | Grad Norm 5.6146(5.5096) | Total Time 0.00(0.00)\n",
      "Iter 8790 | Time 17.8858(18.3537) | Bit/dim 3.6228(3.6014) | Xent 0.0545(0.0540) | Loss 9.0613(9.1964) | Error 0.0178(0.0167) Steps 730(713.56) | Grad Norm 4.5007(5.3157) | Total Time 0.00(0.00)\n",
      "Iter 8800 | Time 18.7311(18.4219) | Bit/dim 3.6226(3.5995) | Xent 0.0914(0.0551) | Loss 8.9943(9.1244) | Error 0.0278(0.0171) Steps 688(713.17) | Grad Norm 10.1270(5.5831) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0160 | Time 93.4974, Epoch Time 1126.8868(1104.1165), Bit/dim 3.6216(best: 3.6177), Xent 1.9424, Loss 4.5928, Error 0.3308(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8810 | Time 19.6400(18.4403) | Bit/dim 3.6131(3.6013) | Xent 0.1064(0.0568) | Loss 9.1024(9.7396) | Error 0.0256(0.0173) Steps 700(713.06) | Grad Norm 10.1216(5.8838) | Total Time 0.00(0.00)\n",
      "Iter 8820 | Time 18.4307(18.4474) | Bit/dim 3.5821(3.5991) | Xent 0.0531(0.0567) | Loss 8.8930(9.5221) | Error 0.0167(0.0173) Steps 712(715.12) | Grad Norm 4.8881(5.7587) | Total Time 0.00(0.00)\n",
      "Iter 8830 | Time 18.8277(18.4119) | Bit/dim 3.5820(3.5993) | Xent 0.0536(0.0549) | Loss 8.8553(9.3691) | Error 0.0167(0.0172) Steps 742(714.91) | Grad Norm 4.9866(5.4613) | Total Time 0.00(0.00)\n",
      "Iter 8840 | Time 17.8715(18.4180) | Bit/dim 3.6238(3.6017) | Xent 0.0579(0.0543) | Loss 9.0471(9.2615) | Error 0.0189(0.0172) Steps 718(714.55) | Grad Norm 5.0870(5.3545) | Total Time 0.00(0.00)\n",
      "Iter 8850 | Time 18.5161(18.3873) | Bit/dim 3.5801(3.5985) | Xent 0.0515(0.0592) | Loss 8.8364(9.1761) | Error 0.0167(0.0186) Steps 682(712.16) | Grad Norm 5.0707(5.9222) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0161 | Time 95.2372, Epoch Time 1129.9284(1104.8908), Bit/dim 3.6267(best: 3.6177), Xent 1.9725, Loss 4.6129, Error 0.3459(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8860 | Time 18.4297(18.4135) | Bit/dim 3.6368(3.6026) | Xent 0.0857(0.0652) | Loss 8.8837(9.9076) | Error 0.0256(0.0200) Steps 718(710.79) | Grad Norm 9.0901(6.3865) | Total Time 0.00(0.00)\n",
      "Iter 8870 | Time 19.1311(18.4939) | Bit/dim 3.6135(3.6045) | Xent 0.0481(0.0661) | Loss 9.0783(9.6750) | Error 0.0156(0.0204) Steps 748(716.70) | Grad Norm 4.6663(6.4540) | Total Time 0.00(0.00)\n",
      "Iter 8880 | Time 18.0941(18.4612) | Bit/dim 3.5817(3.5995) | Xent 0.0488(0.0640) | Loss 8.8520(9.4751) | Error 0.0178(0.0199) Steps 682(717.18) | Grad Norm 5.0429(6.1514) | Total Time 0.00(0.00)\n",
      "Iter 8890 | Time 18.5859(18.4742) | Bit/dim 3.5942(3.5995) | Xent 0.0526(0.0598) | Loss 9.0284(9.3383) | Error 0.0133(0.0181) Steps 730(719.90) | Grad Norm 4.9189(5.9037) | Total Time 0.00(0.00)\n",
      "Iter 8900 | Time 18.2226(18.4614) | Bit/dim 3.6065(3.6018) | Xent 0.0762(0.0607) | Loss 8.9372(9.2443) | Error 0.0222(0.0180) Steps 706(718.65) | Grad Norm 4.6058(5.8957) | Total Time 0.00(0.00)\n",
      "Iter 8910 | Time 18.4044(18.5156) | Bit/dim 3.6236(3.6017) | Xent 0.0315(0.0591) | Loss 8.9278(9.1660) | Error 0.0111(0.0179) Steps 724(719.46) | Grad Norm 4.4330(5.7372) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0162 | Time 94.9565, Epoch Time 1134.2423(1105.7714), Bit/dim 3.6239(best: 3.6177), Xent 1.9169, Loss 4.5823, Error 0.3258(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8920 | Time 18.2898(18.5534) | Bit/dim 3.5768(3.5998) | Xent 0.0561(0.0580) | Loss 8.8656(9.7364) | Error 0.0222(0.0178) Steps 712(715.85) | Grad Norm 7.5197(5.8038) | Total Time 0.00(0.00)\n",
      "Iter 8930 | Time 19.5628(18.6802) | Bit/dim 3.5622(3.5988) | Xent 0.0663(0.0586) | Loss 8.8255(9.5386) | Error 0.0189(0.0181) Steps 730(716.64) | Grad Norm 5.2455(5.6725) | Total Time 0.00(0.00)\n",
      "Iter 8940 | Time 19.0681(18.6317) | Bit/dim 3.6157(3.5995) | Xent 0.0439(0.0601) | Loss 9.0104(9.3872) | Error 0.0122(0.0186) Steps 712(718.80) | Grad Norm 3.4524(5.7562) | Total Time 0.00(0.00)\n",
      "Iter 8950 | Time 18.4899(18.5927) | Bit/dim 3.5745(3.5986) | Xent 0.0771(0.0580) | Loss 8.9195(9.2624) | Error 0.0189(0.0179) Steps 730(719.02) | Grad Norm 6.9273(5.5541) | Total Time 0.00(0.00)\n",
      "Iter 8960 | Time 18.8065(18.5627) | Bit/dim 3.5766(3.5991) | Xent 0.0724(0.0579) | Loss 8.8921(9.1673) | Error 0.0233(0.0180) Steps 700(719.00) | Grad Norm 7.0735(5.9492) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0163 | Time 94.6860, Epoch Time 1142.3114(1106.8676), Bit/dim 3.6205(best: 3.6177), Xent 1.8782, Loss 4.5596, Error 0.3276(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8970 | Time 18.4148(18.6008) | Bit/dim 3.5657(3.5983) | Xent 0.0329(0.0584) | Loss 8.7238(9.8284) | Error 0.0100(0.0182) Steps 712(717.98) | Grad Norm 3.8320(5.8833) | Total Time 0.00(0.00)\n",
      "Iter 8980 | Time 18.5446(18.6161) | Bit/dim 3.5775(3.5991) | Xent 0.0408(0.0536) | Loss 8.8555(9.5932) | Error 0.0100(0.0169) Steps 748(719.80) | Grad Norm 4.1132(5.4231) | Total Time 0.00(0.00)\n",
      "Iter 8990 | Time 18.5613(18.6063) | Bit/dim 3.6258(3.5998) | Xent 0.0634(0.0544) | Loss 8.9674(9.4329) | Error 0.0144(0.0169) Steps 724(718.73) | Grad Norm 3.7834(5.2701) | Total Time 0.00(0.00)\n",
      "Iter 9000 | Time 18.1165(18.5671) | Bit/dim 3.5926(3.6002) | Xent 0.0566(0.0544) | Loss 8.9858(9.3021) | Error 0.0144(0.0166) Steps 742(718.62) | Grad Norm 4.5328(5.3062) | Total Time 0.00(0.00)\n",
      "Iter 9010 | Time 19.0725(18.5479) | Bit/dim 3.5916(3.5978) | Xent 0.0405(0.0524) | Loss 8.8569(9.1935) | Error 0.0144(0.0162) Steps 706(717.24) | Grad Norm 5.6332(5.3026) | Total Time 0.00(0.00)\n",
      "Iter 9020 | Time 19.2371(18.5971) | Bit/dim 3.5996(3.5956) | Xent 0.0406(0.0503) | Loss 9.0092(9.1159) | Error 0.0122(0.0153) Steps 694(715.75) | Grad Norm 4.0648(4.9928) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0164 | Time 95.2181, Epoch Time 1137.7266(1107.7934), Bit/dim 3.6058(best: 3.6177), Xent 1.9277, Loss 4.5697, Error 0.3287(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9030 | Time 18.6636(18.5069) | Bit/dim 3.5644(3.5940) | Xent 0.0498(0.0501) | Loss 8.8579(9.7150) | Error 0.0100(0.0148) Steps 712(717.98) | Grad Norm 4.7475(5.2659) | Total Time 0.00(0.00)\n",
      "Iter 9040 | Time 18.7668(18.5718) | Bit/dim 3.5973(3.5943) | Xent 0.0513(0.0491) | Loss 8.9693(9.5061) | Error 0.0156(0.0145) Steps 742(718.81) | Grad Norm 4.0929(5.2566) | Total Time 0.00(0.00)\n",
      "Iter 9050 | Time 18.1385(18.4894) | Bit/dim 3.6086(3.5913) | Xent 0.0545(0.0493) | Loss 8.8814(9.3524) | Error 0.0156(0.0147) Steps 718(718.36) | Grad Norm 4.2716(4.9993) | Total Time 0.00(0.00)\n",
      "Iter 9060 | Time 18.7826(18.5274) | Bit/dim 3.5819(3.5915) | Xent 0.0660(0.0508) | Loss 8.9100(9.2362) | Error 0.0200(0.0153) Steps 736(717.61) | Grad Norm 5.1117(5.0246) | Total Time 0.00(0.00)\n",
      "Iter 9070 | Time 18.7141(18.4825) | Bit/dim 3.5647(3.5914) | Xent 0.0464(0.0514) | Loss 8.9050(9.1542) | Error 0.0133(0.0154) Steps 700(716.42) | Grad Norm 4.8513(5.1685) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0165 | Time 93.1392, Epoch Time 1130.1902(1108.4653), Bit/dim 3.6123(best: 3.6058), Xent 1.7987, Loss 4.5116, Error 0.3241(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9080 | Time 18.2342(18.4439) | Bit/dim 3.5495(3.5919) | Xent 0.0555(0.0551) | Loss 8.8344(9.8649) | Error 0.0178(0.0164) Steps 700(716.76) | Grad Norm 7.9692(5.3765) | Total Time 0.00(0.00)\n",
      "Iter 9090 | Time 18.4861(18.5156) | Bit/dim 3.5875(3.5939) | Xent 0.0664(0.0565) | Loss 8.8482(9.6250) | Error 0.0167(0.0168) Steps 706(717.15) | Grad Norm 4.4235(5.3897) | Total Time 0.00(0.00)\n",
      "Iter 9100 | Time 17.8238(18.4771) | Bit/dim 3.6252(3.5946) | Xent 0.0520(0.0578) | Loss 8.9074(9.4498) | Error 0.0133(0.0171) Steps 712(717.58) | Grad Norm 5.1377(5.5530) | Total Time 0.00(0.00)\n",
      "Iter 9110 | Time 18.7400(18.4991) | Bit/dim 3.6187(3.5960) | Xent 0.0672(0.0611) | Loss 8.9454(9.3247) | Error 0.0178(0.0184) Steps 700(717.96) | Grad Norm 6.1637(6.0703) | Total Time 0.00(0.00)\n",
      "Iter 9120 | Time 18.3314(18.4854) | Bit/dim 3.5818(3.5986) | Xent 0.0770(0.0635) | Loss 8.7818(9.2268) | Error 0.0211(0.0191) Steps 682(715.48) | Grad Norm 7.1347(6.7367) | Total Time 0.00(0.00)\n",
      "Iter 9130 | Time 18.1033(18.4962) | Bit/dim 3.6087(3.5994) | Xent 0.0652(0.0646) | Loss 9.0130(9.1621) | Error 0.0189(0.0198) Steps 742(716.06) | Grad Norm 6.1144(6.4840) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0166 | Time 92.6517, Epoch Time 1134.9555(1109.2600), Bit/dim 3.6147(best: 3.6058), Xent 1.8893, Loss 4.5594, Error 0.3366(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9140 | Time 18.4123(18.5106) | Bit/dim 3.6053(3.5989) | Xent 0.0536(0.0629) | Loss 8.8648(9.7504) | Error 0.0144(0.0192) Steps 712(712.83) | Grad Norm 5.0707(6.1988) | Total Time 0.00(0.00)\n",
      "Iter 9150 | Time 18.9983(18.5028) | Bit/dim 3.5869(3.5981) | Xent 0.0546(0.0595) | Loss 8.8854(9.5357) | Error 0.0189(0.0183) Steps 724(712.52) | Grad Norm 5.9080(5.9510) | Total Time 0.00(0.00)\n",
      "Iter 9160 | Time 18.5434(18.5045) | Bit/dim 3.5868(3.5967) | Xent 0.0500(0.0586) | Loss 8.9696(9.3807) | Error 0.0178(0.0179) Steps 706(714.81) | Grad Norm 6.9554(5.9000) | Total Time 0.00(0.00)\n",
      "Iter 9170 | Time 19.2898(18.5444) | Bit/dim 3.6304(3.5971) | Xent 0.0271(0.0592) | Loss 8.8651(9.2715) | Error 0.0056(0.0178) Steps 730(716.78) | Grad Norm 2.6319(5.8961) | Total Time 0.00(0.00)\n",
      "Iter 9180 | Time 18.6485(18.5706) | Bit/dim 3.5636(3.5957) | Xent 0.0637(0.0617) | Loss 8.8887(9.1962) | Error 0.0144(0.0184) Steps 718(722.00) | Grad Norm 4.8425(6.1703) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0167 | Time 94.3266, Epoch Time 1137.4197(1110.1048), Bit/dim 3.6140(best: 3.6058), Xent 1.9159, Loss 4.5720, Error 0.3327(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9190 | Time 18.6351(18.6241) | Bit/dim 3.6050(3.5957) | Xent 0.0620(0.0616) | Loss 9.1153(9.9076) | Error 0.0211(0.0187) Steps 754(724.14) | Grad Norm 5.1915(5.9847) | Total Time 0.00(0.00)\n",
      "Iter 9200 | Time 18.1138(18.6479) | Bit/dim 3.5767(3.5937) | Xent 0.0561(0.0618) | Loss 8.8836(9.6515) | Error 0.0156(0.0183) Steps 724(725.77) | Grad Norm 3.9941(5.7799) | Total Time 0.00(0.00)\n",
      "Iter 9210 | Time 18.6007(18.6314) | Bit/dim 3.5837(3.5931) | Xent 0.0275(0.0596) | Loss 9.0709(9.4722) | Error 0.0089(0.0177) Steps 748(725.09) | Grad Norm 3.9072(5.4569) | Total Time 0.00(0.00)\n",
      "Iter 9220 | Time 18.8927(18.6185) | Bit/dim 3.5863(3.5939) | Xent 0.0638(0.0602) | Loss 8.9143(9.3374) | Error 0.0200(0.0184) Steps 724(725.51) | Grad Norm 4.9178(5.4976) | Total Time 0.00(0.00)\n",
      "Iter 9230 | Time 18.8541(18.5539) | Bit/dim 3.6344(3.5950) | Xent 0.0476(0.0578) | Loss 8.9772(9.2275) | Error 0.0167(0.0179) Steps 742(724.51) | Grad Norm 4.7632(5.4133) | Total Time 0.00(0.00)\n",
      "Iter 9240 | Time 17.8990(18.5319) | Bit/dim 3.5910(3.5942) | Xent 0.0563(0.0579) | Loss 8.8191(9.1613) | Error 0.0189(0.0179) Steps 736(725.22) | Grad Norm 4.8086(5.2520) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0168 | Time 93.4231, Epoch Time 1135.7818(1110.8751), Bit/dim 3.6105(best: 3.6058), Xent 1.8569, Loss 4.5390, Error 0.3346(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9250 | Time 19.2061(18.5180) | Bit/dim 3.5914(3.5914) | Xent 0.0769(0.0541) | Loss 9.1434(9.7505) | Error 0.0211(0.0169) Steps 730(722.32) | Grad Norm 5.8619(5.0666) | Total Time 0.00(0.00)\n",
      "Iter 9260 | Time 18.4334(18.5609) | Bit/dim 3.5882(3.5889) | Xent 0.0254(0.0514) | Loss 8.9061(9.5268) | Error 0.0078(0.0162) Steps 748(725.74) | Grad Norm 7.6304(5.0889) | Total Time 0.00(0.00)\n",
      "Iter 9270 | Time 19.2593(18.6110) | Bit/dim 3.6331(3.5928) | Xent 0.0506(0.0515) | Loss 9.0503(9.3923) | Error 0.0167(0.0159) Steps 706(728.33) | Grad Norm 6.9974(5.3015) | Total Time 0.00(0.00)\n",
      "Iter 9280 | Time 18.1608(18.5430) | Bit/dim 3.6233(3.5927) | Xent 0.0981(0.0539) | Loss 9.0331(9.2621) | Error 0.0289(0.0166) Steps 706(724.88) | Grad Norm 7.9739(5.2534) | Total Time 0.00(0.00)\n",
      "Iter 9290 | Time 18.0631(18.5150) | Bit/dim 3.6126(3.5941) | Xent 0.1427(0.0599) | Loss 8.9782(9.1848) | Error 0.0456(0.0184) Steps 712(723.63) | Grad Norm 7.2739(5.8391) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0169 | Time 93.5393, Epoch Time 1133.4252(1111.5516), Bit/dim 3.6251(best: 3.6058), Xent 1.8189, Loss 4.5345, Error 0.3275(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9300 | Time 19.0914(18.5284) | Bit/dim 3.6199(3.5947) | Xent 0.0440(0.0627) | Loss 8.8561(9.8714) | Error 0.0122(0.0188) Steps 712(720.69) | Grad Norm 4.3434(5.8319) | Total Time 0.00(0.00)\n",
      "Iter 9310 | Time 17.9010(18.5109) | Bit/dim 3.5779(3.5922) | Xent 0.0430(0.0616) | Loss 8.8333(9.6212) | Error 0.0133(0.0188) Steps 688(719.45) | Grad Norm 4.3474(5.7288) | Total Time 0.00(0.00)\n",
      "Iter 9320 | Time 19.0572(18.4818) | Bit/dim 3.5762(3.5906) | Xent 0.0533(0.0588) | Loss 8.9102(9.4401) | Error 0.0167(0.0178) Steps 724(717.18) | Grad Norm 7.9329(5.5923) | Total Time 0.00(0.00)\n",
      "Iter 9330 | Time 18.4672(18.5737) | Bit/dim 3.5566(3.5932) | Xent 0.0647(0.0580) | Loss 8.8273(9.3106) | Error 0.0244(0.0178) Steps 754(719.79) | Grad Norm 7.2875(5.6103) | Total Time 0.00(0.00)\n",
      "Iter 9340 | Time 17.6055(18.4874) | Bit/dim 3.5994(3.5928) | Xent 0.0626(0.0567) | Loss 8.7777(9.2034) | Error 0.0189(0.0173) Steps 688(718.34) | Grad Norm 7.0157(5.5635) | Total Time 0.00(0.00)\n",
      "Iter 9350 | Time 17.9546(18.5197) | Bit/dim 3.6323(3.5936) | Xent 0.0462(0.0547) | Loss 8.8557(9.1193) | Error 0.0156(0.0168) Steps 718(719.04) | Grad Norm 4.3519(5.1999) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0170 | Time 93.3112, Epoch Time 1133.2240(1112.2018), Bit/dim 3.6041(best: 3.6058), Xent 1.9040, Loss 4.5560, Error 0.3233(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9360 | Time 19.2597(18.5607) | Bit/dim 3.6131(3.5942) | Xent 0.0424(0.0509) | Loss 8.8481(9.7129) | Error 0.0144(0.0154) Steps 694(720.44) | Grad Norm 6.4324(5.0709) | Total Time 0.00(0.00)\n",
      "Iter 9370 | Time 17.7261(18.5022) | Bit/dim 3.6150(3.5912) | Xent 0.0563(0.0509) | Loss 8.9932(9.5056) | Error 0.0144(0.0150) Steps 718(722.96) | Grad Norm 5.0246(5.1238) | Total Time 0.00(0.00)\n",
      "Iter 9380 | Time 18.2772(18.5218) | Bit/dim 3.6139(3.5871) | Xent 0.0937(0.0548) | Loss 9.0232(9.3476) | Error 0.0344(0.0163) Steps 718(721.96) | Grad Norm 10.4705(5.5533) | Total Time 0.00(0.00)\n",
      "Iter 9390 | Time 18.2801(18.4951) | Bit/dim 3.5876(3.5909) | Xent 0.0346(0.0545) | Loss 8.8595(9.2486) | Error 0.0100(0.0163) Steps 730(721.27) | Grad Norm 6.2549(5.6251) | Total Time 0.00(0.00)\n",
      "Iter 9400 | Time 18.0161(18.4730) | Bit/dim 3.5983(3.5917) | Xent 0.0386(0.0558) | Loss 9.0631(9.1737) | Error 0.0156(0.0170) Steps 712(720.22) | Grad Norm 6.9811(6.1682) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0171 | Time 94.8296, Epoch Time 1131.3929(1112.7775), Bit/dim 3.6130(best: 3.6041), Xent 1.9035, Loss 4.5648, Error 0.3305(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9410 | Time 18.5699(18.4820) | Bit/dim 3.6051(3.5918) | Xent 0.0822(0.0548) | Loss 9.0463(9.8478) | Error 0.0256(0.0165) Steps 676(717.28) | Grad Norm 8.3243(6.1449) | Total Time 0.00(0.00)\n",
      "Iter 9420 | Time 18.3127(18.4501) | Bit/dim 3.5975(3.5894) | Xent 0.0363(0.0564) | Loss 8.8326(9.5995) | Error 0.0111(0.0169) Steps 712(716.07) | Grad Norm 4.2996(6.0596) | Total Time 0.00(0.00)\n",
      "Iter 9430 | Time 19.7433(18.5411) | Bit/dim 3.5955(3.5899) | Xent 0.0434(0.0539) | Loss 8.8748(9.4184) | Error 0.0133(0.0163) Steps 754(717.75) | Grad Norm 5.0179(5.7940) | Total Time 0.00(0.00)\n",
      "Iter 9440 | Time 18.9164(18.4766) | Bit/dim 3.5736(3.5890) | Xent 0.0249(0.0559) | Loss 8.7899(9.2870) | Error 0.0067(0.0168) Steps 682(716.49) | Grad Norm 3.6011(5.8553) | Total Time 0.00(0.00)\n",
      "Iter 9450 | Time 18.4787(18.4021) | Bit/dim 3.5832(3.5907) | Xent 0.0570(0.0545) | Loss 8.8939(9.1802) | Error 0.0122(0.0162) Steps 724(715.74) | Grad Norm 5.2574(5.7084) | Total Time 0.00(0.00)\n",
      "Iter 9460 | Time 18.6527(18.4162) | Bit/dim 3.6170(3.5928) | Xent 0.0493(0.0561) | Loss 8.9173(9.1185) | Error 0.0156(0.0169) Steps 676(715.21) | Grad Norm 4.7685(5.4609) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0172 | Time 94.5840, Epoch Time 1129.4127(1113.2765), Bit/dim 3.6130(best: 3.6041), Xent 1.8798, Loss 4.5529, Error 0.3286(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9470 | Time 18.1507(18.4218) | Bit/dim 3.5869(3.5901) | Xent 0.0501(0.0571) | Loss 8.8723(9.7319) | Error 0.0200(0.0174) Steps 700(715.74) | Grad Norm 6.0832(5.4937) | Total Time 0.00(0.00)\n",
      "Iter 9480 | Time 17.9483(18.3900) | Bit/dim 3.5297(3.5899) | Xent 0.0497(0.0585) | Loss 8.7554(9.5300) | Error 0.0144(0.0181) Steps 694(716.83) | Grad Norm 4.8988(5.5139) | Total Time 0.00(0.00)\n",
      "Iter 9490 | Time 19.1140(18.4361) | Bit/dim 3.5905(3.5899) | Xent 0.0766(0.0588) | Loss 8.9955(9.3720) | Error 0.0233(0.0179) Steps 712(718.99) | Grad Norm 8.5935(5.6216) | Total Time 0.00(0.00)\n",
      "Iter 9500 | Time 18.6958(18.4679) | Bit/dim 3.5693(3.5892) | Xent 0.0451(0.0561) | Loss 8.9611(9.2546) | Error 0.0122(0.0172) Steps 748(717.46) | Grad Norm 4.6558(5.6992) | Total Time 0.00(0.00)\n",
      "Iter 9510 | Time 19.3837(18.6708) | Bit/dim 3.6234(3.5900) | Xent 0.0534(0.0530) | Loss 9.1182(9.1818) | Error 0.0178(0.0163) Steps 760(719.00) | Grad Norm 6.5925(5.5704) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0173 | Time 93.6128, Epoch Time 1140.4665(1114.0922), Bit/dim 3.6081(best: 3.6041), Xent 1.9315, Loss 4.5739, Error 0.3200(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9520 | Time 18.4117(18.6586) | Bit/dim 3.5683(3.5898) | Xent 0.0704(0.0559) | Loss 8.8446(9.8744) | Error 0.0189(0.0170) Steps 688(719.54) | Grad Norm 7.0275(5.7255) | Total Time 0.00(0.00)\n",
      "Iter 9530 | Time 18.9518(18.6817) | Bit/dim 3.6008(3.5919) | Xent 0.0592(0.0569) | Loss 9.0358(9.6299) | Error 0.0156(0.0171) Steps 736(718.92) | Grad Norm 7.4268(6.1682) | Total Time 0.00(0.00)\n",
      "Iter 9540 | Time 18.8959(18.7662) | Bit/dim 3.6052(3.5917) | Xent 0.0678(0.0607) | Loss 8.9948(9.4604) | Error 0.0167(0.0180) Steps 730(721.30) | Grad Norm 8.7041(6.8106) | Total Time 0.00(0.00)\n",
      "Iter 9550 | Time 19.6316(18.7656) | Bit/dim 3.5954(3.5935) | Xent 0.0540(0.0600) | Loss 9.0703(9.3356) | Error 0.0156(0.0178) Steps 778(722.46) | Grad Norm 5.7732(6.5444) | Total Time 0.00(0.00)\n",
      "Iter 9560 | Time 18.4811(18.6899) | Bit/dim 3.5719(3.5926) | Xent 0.0404(0.0564) | Loss 8.9417(9.2383) | Error 0.0144(0.0169) Steps 736(724.46) | Grad Norm 5.1871(5.9917) | Total Time 0.00(0.00)\n",
      "Iter 9570 | Time 18.7394(18.6601) | Bit/dim 3.5882(3.5934) | Xent 0.0693(0.0573) | Loss 8.9979(9.1562) | Error 0.0167(0.0171) Steps 724(724.94) | Grad Norm 8.1770(6.0241) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0174 | Time 94.2006, Epoch Time 1143.5592(1114.9763), Bit/dim 3.6089(best: 3.6041), Xent 1.9500, Loss 4.5839, Error 0.3387(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9580 | Time 18.0503(18.6588) | Bit/dim 3.5845(3.5913) | Xent 0.0442(0.0565) | Loss 8.9353(9.7439) | Error 0.0156(0.0168) Steps 736(726.82) | Grad Norm 3.6003(5.6782) | Total Time 0.00(0.00)\n",
      "Iter 9590 | Time 19.2375(18.7273) | Bit/dim 3.5922(3.5908) | Xent 0.0723(0.0537) | Loss 9.0712(9.5374) | Error 0.0178(0.0157) Steps 754(729.34) | Grad Norm 5.3756(5.3968) | Total Time 0.00(0.00)\n",
      "Iter 9600 | Time 19.4300(18.7965) | Bit/dim 3.5493(3.5896) | Xent 0.0737(0.0554) | Loss 8.7879(9.3728) | Error 0.0222(0.0166) Steps 748(730.67) | Grad Norm 5.6655(5.5159) | Total Time 0.00(0.00)\n",
      "Iter 9610 | Time 18.5810(18.8077) | Bit/dim 3.6060(3.5919) | Xent 0.0325(0.0521) | Loss 8.9416(9.2567) | Error 0.0111(0.0157) Steps 724(727.21) | Grad Norm 3.7344(5.3870) | Total Time 0.00(0.00)\n",
      "Iter 9620 | Time 19.1396(18.8802) | Bit/dim 3.5523(3.5896) | Xent 0.0622(0.0529) | Loss 8.9051(9.1786) | Error 0.0178(0.0161) Steps 700(729.14) | Grad Norm 5.7367(5.4074) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0175 | Time 94.0152, Epoch Time 1154.6239(1116.1657), Bit/dim 3.6204(best: 3.6041), Xent 2.0373, Loss 4.6390, Error 0.3510(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9630 | Time 18.9327(18.8376) | Bit/dim 3.6021(3.5887) | Xent 0.0885(0.0592) | Loss 8.9929(9.9015) | Error 0.0233(0.0181) Steps 724(728.53) | Grad Norm 5.4869(5.7263) | Total Time 0.00(0.00)\n",
      "Iter 9640 | Time 19.5507(18.8546) | Bit/dim 3.5726(3.5935) | Xent 0.0598(0.0600) | Loss 8.9405(9.6615) | Error 0.0189(0.0182) Steps 754(731.20) | Grad Norm 6.0181(5.6067) | Total Time 0.00(0.00)\n",
      "Iter 9650 | Time 19.6290(18.8463) | Bit/dim 3.5858(3.5906) | Xent 0.0682(0.0598) | Loss 9.0035(9.4676) | Error 0.0256(0.0181) Steps 712(729.88) | Grad Norm 5.1368(5.4372) | Total Time 0.00(0.00)\n",
      "Iter 9660 | Time 18.5659(18.8322) | Bit/dim 3.5874(3.5891) | Xent 0.0231(0.0548) | Loss 8.8585(9.3176) | Error 0.0056(0.0166) Steps 724(729.21) | Grad Norm 4.2062(5.0035) | Total Time 0.00(0.00)\n",
      "Iter 9670 | Time 17.6587(18.8398) | Bit/dim 3.5842(3.5891) | Xent 0.0349(0.0537) | Loss 8.8524(9.2117) | Error 0.0089(0.0166) Steps 718(731.11) | Grad Norm 3.7663(4.8737) | Total Time 0.00(0.00)\n",
      "Iter 9680 | Time 18.6181(18.7994) | Bit/dim 3.5972(3.5854) | Xent 0.0559(0.0541) | Loss 8.9461(9.1402) | Error 0.0178(0.0163) Steps 694(729.19) | Grad Norm 5.5635(4.8867) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0176 | Time 95.1100, Epoch Time 1149.6507(1117.1702), Bit/dim 3.6072(best: 3.6041), Xent 1.9102, Loss 4.5623, Error 0.3308(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9690 | Time 18.8170(18.8152) | Bit/dim 3.5452(3.5857) | Xent 0.0525(0.0549) | Loss 8.8395(9.7551) | Error 0.0200(0.0165) Steps 736(731.47) | Grad Norm 5.6784(4.8249) | Total Time 0.00(0.00)\n",
      "Iter 9700 | Time 19.2668(18.9184) | Bit/dim 3.5887(3.5869) | Xent 0.1115(0.0575) | Loss 8.9068(9.5435) | Error 0.0300(0.0174) Steps 718(731.70) | Grad Norm 7.8568(5.1197) | Total Time 0.00(0.00)\n",
      "Iter 9710 | Time 18.9820(18.8462) | Bit/dim 3.5771(3.5906) | Xent 0.0606(0.0655) | Loss 8.9699(9.4117) | Error 0.0200(0.0203) Steps 754(732.56) | Grad Norm 7.6761(5.5602) | Total Time 0.00(0.00)\n",
      "Iter 9720 | Time 17.8070(18.8505) | Bit/dim 3.5843(3.5934) | Xent 0.0579(0.0681) | Loss 8.9521(9.3110) | Error 0.0167(0.0210) Steps 730(733.82) | Grad Norm 7.6254(5.6711) | Total Time 0.00(0.00)\n",
      "Iter 9730 | Time 18.8975(18.7999) | Bit/dim 3.5810(3.5933) | Xent 0.0531(0.0689) | Loss 8.8817(9.2185) | Error 0.0167(0.0211) Steps 724(734.33) | Grad Norm 4.7785(5.8699) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0177 | Time 95.7824, Epoch Time 1156.3965(1118.3470), Bit/dim 3.6023(best: 3.6041), Xent 1.8590, Loss 4.5318, Error 0.3301(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9740 | Time 19.6786(18.8775) | Bit/dim 3.6067(3.5944) | Xent 0.0648(0.0667) | Loss 8.9622(9.9238) | Error 0.0144(0.0201) Steps 712(734.99) | Grad Norm 5.9855(5.5122) | Total Time 0.00(0.00)\n",
      "Iter 9750 | Time 20.1817(18.9552) | Bit/dim 3.6174(3.5944) | Xent 0.0270(0.0626) | Loss 9.0094(9.6778) | Error 0.0067(0.0190) Steps 718(736.18) | Grad Norm 5.1100(5.5534) | Total Time 0.00(0.00)\n",
      "Iter 9760 | Time 19.8728(18.9489) | Bit/dim 3.5732(3.5909) | Xent 0.0438(0.0588) | Loss 8.9757(9.4738) | Error 0.0100(0.0182) Steps 694(732.33) | Grad Norm 3.5062(5.7621) | Total Time 0.00(0.00)\n",
      "Iter 9770 | Time 19.0018(18.9243) | Bit/dim 3.5922(3.5891) | Xent 0.0621(0.0574) | Loss 8.9105(9.3372) | Error 0.0178(0.0176) Steps 742(731.94) | Grad Norm 6.4009(5.9221) | Total Time 0.00(0.00)\n",
      "Iter 9780 | Time 19.4038(18.8766) | Bit/dim 3.5966(3.5905) | Xent 0.0642(0.0603) | Loss 8.9099(9.2430) | Error 0.0211(0.0187) Steps 700(729.21) | Grad Norm 6.2761(6.1451) | Total Time 0.00(0.00)\n",
      "Iter 9790 | Time 18.3569(18.8513) | Bit/dim 3.5803(3.5901) | Xent 0.0817(0.0612) | Loss 8.8004(9.1738) | Error 0.0256(0.0189) Steps 724(727.92) | Grad Norm 10.9673(6.3948) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0178 | Time 95.5869, Epoch Time 1156.6335(1119.4956), Bit/dim 3.6097(best: 3.6023), Xent 1.8869, Loss 4.5531, Error 0.3386(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9800 | Time 18.8415(18.8319) | Bit/dim 3.5896(3.5943) | Xent 0.0595(0.0708) | Loss 9.0229(9.8183) | Error 0.0156(0.0215) Steps 760(727.88) | Grad Norm 3.9153(6.9895) | Total Time 0.00(0.00)\n",
      "Iter 9810 | Time 18.7447(18.7675) | Bit/dim 3.5674(3.5967) | Xent 0.0634(0.0706) | Loss 8.9388(9.6026) | Error 0.0200(0.0210) Steps 724(729.27) | Grad Norm 4.0206(6.6385) | Total Time 0.00(0.00)\n",
      "Iter 9820 | Time 18.1826(18.7922) | Bit/dim 3.5794(3.5948) | Xent 0.0409(0.0683) | Loss 9.0115(9.4420) | Error 0.0133(0.0204) Steps 736(728.22) | Grad Norm 4.7418(6.2691) | Total Time 0.00(0.00)\n",
      "Iter 9830 | Time 18.8240(18.8074) | Bit/dim 3.5999(3.5910) | Xent 0.0598(0.0636) | Loss 9.0161(9.3217) | Error 0.0200(0.0192) Steps 748(731.52) | Grad Norm 5.4953(5.9675) | Total Time 0.00(0.00)\n",
      "Iter 9840 | Time 18.6695(18.7520) | Bit/dim 3.5954(3.5880) | Xent 0.0476(0.0612) | Loss 8.9565(9.2215) | Error 0.0189(0.0187) Steps 730(734.03) | Grad Norm 5.4810(5.8471) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0179 | Time 96.0428, Epoch Time 1149.5515(1120.3973), Bit/dim 3.6112(best: 3.6023), Xent 1.8680, Loss 4.5452, Error 0.3259(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9850 | Time 18.9403(18.7724) | Bit/dim 3.5956(3.5908) | Xent 0.0803(0.0641) | Loss 9.0626(9.9350) | Error 0.0222(0.0199) Steps 730(731.28) | Grad Norm 6.5202(6.4380) | Total Time 0.00(0.00)\n",
      "Iter 9860 | Time 19.3821(18.8725) | Bit/dim 3.6099(3.5900) | Xent 0.0668(0.0663) | Loss 9.0566(9.6869) | Error 0.0233(0.0201) Steps 784(734.72) | Grad Norm 5.9533(6.2310) | Total Time 0.00(0.00)\n",
      "Iter 9870 | Time 18.3218(18.8457) | Bit/dim 3.6011(3.5921) | Xent 0.0383(0.0640) | Loss 8.9369(9.4961) | Error 0.0100(0.0198) Steps 730(733.33) | Grad Norm 3.9438(6.1638) | Total Time 0.00(0.00)\n",
      "Iter 9880 | Time 18.2342(18.8394) | Bit/dim 3.5886(3.5887) | Xent 0.1171(0.0618) | Loss 8.8932(9.3425) | Error 0.0322(0.0189) Steps 718(731.01) | Grad Norm 7.5620(5.8076) | Total Time 0.00(0.00)\n",
      "Iter 9890 | Time 18.6091(18.9362) | Bit/dim 3.5719(3.5870) | Xent 0.0235(0.0601) | Loss 8.8006(9.2365) | Error 0.0067(0.0183) Steps 700(732.60) | Grad Norm 3.0833(5.3926) | Total Time 0.00(0.00)\n",
      "Iter 9900 | Time 18.1897(18.9239) | Bit/dim 3.5556(3.5869) | Xent 0.0270(0.0563) | Loss 8.8263(9.1505) | Error 0.0100(0.0175) Steps 718(730.04) | Grad Norm 2.5561(4.9978) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0180 | Time 94.6618, Epoch Time 1157.9581(1121.5241), Bit/dim 3.6027(best: 3.6023), Xent 1.9043, Loss 4.5549, Error 0.3292(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9910 | Time 18.9648(18.8847) | Bit/dim 3.5903(3.5847) | Xent 0.0354(0.0513) | Loss 8.9596(9.7604) | Error 0.0100(0.0160) Steps 736(731.31) | Grad Norm 7.0752(4.7770) | Total Time 0.00(0.00)\n",
      "Iter 9920 | Time 18.3446(18.7612) | Bit/dim 3.5623(3.5843) | Xent 0.0511(0.0512) | Loss 8.8304(9.5383) | Error 0.0156(0.0159) Steps 724(729.90) | Grad Norm 4.9736(4.9093) | Total Time 0.00(0.00)\n",
      "Iter 9930 | Time 19.1506(18.8277) | Bit/dim 3.5343(3.5813) | Xent 0.0437(0.0488) | Loss 8.8176(9.3790) | Error 0.0122(0.0154) Steps 706(730.86) | Grad Norm 5.8703(4.7744) | Total Time 0.00(0.00)\n",
      "Iter 9940 | Time 19.2686(18.8144) | Bit/dim 3.6009(3.5807) | Xent 0.0573(0.0471) | Loss 8.9582(9.2560) | Error 0.0156(0.0147) Steps 748(732.45) | Grad Norm 5.5290(4.7413) | Total Time 0.00(0.00)\n",
      "Iter 9950 | Time 19.5738(18.8183) | Bit/dim 3.5623(3.5806) | Xent 0.0475(0.0443) | Loss 8.8739(9.1573) | Error 0.0178(0.0138) Steps 712(733.25) | Grad Norm 3.4722(4.5128) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0181 | Time 95.0871, Epoch Time 1149.6407(1122.3676), Bit/dim 3.5965(best: 3.6023), Xent 1.9500, Loss 4.5715, Error 0.3263(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9960 | Time 18.9498(18.8348) | Bit/dim 3.5936(3.5789) | Xent 0.0392(0.0448) | Loss 9.0081(9.8468) | Error 0.0111(0.0139) Steps 724(731.90) | Grad Norm 4.7649(4.4038) | Total Time 0.00(0.00)\n",
      "Iter 9970 | Time 19.4396(18.8088) | Bit/dim 3.6043(3.5811) | Xent 0.0358(0.0481) | Loss 9.0641(9.6166) | Error 0.0144(0.0147) Steps 760(734.68) | Grad Norm 6.8740(4.9668) | Total Time 0.00(0.00)\n",
      "Iter 9980 | Time 18.4334(18.8729) | Bit/dim 3.5612(3.5807) | Xent 0.0477(0.0487) | Loss 8.9333(9.4492) | Error 0.0133(0.0149) Steps 730(734.74) | Grad Norm 5.0020(5.0134) | Total Time 0.00(0.00)\n",
      "Iter 9990 | Time 19.5198(18.8540) | Bit/dim 3.5626(3.5823) | Xent 0.0787(0.0516) | Loss 9.0262(9.3357) | Error 0.0211(0.0152) Steps 712(739.18) | Grad Norm 10.8063(5.1021) | Total Time 0.00(0.00)\n",
      "Iter 10000 | Time 18.7545(18.9178) | Bit/dim 3.5479(3.5823) | Xent 0.0385(0.0545) | Loss 8.9287(9.2314) | Error 0.0144(0.0165) Steps 736(737.69) | Grad Norm 6.8607(5.3176) | Total Time 0.00(0.00)\n",
      "Iter 10010 | Time 19.5568(18.9273) | Bit/dim 3.6094(3.5858) | Xent 0.0583(0.0598) | Loss 9.0407(9.1630) | Error 0.0133(0.0182) Steps 730(736.16) | Grad Norm 6.6329(5.6617) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0182 | Time 94.5871, Epoch Time 1158.0658(1123.4386), Bit/dim 3.6241(best: 3.5965), Xent 2.0022, Loss 4.6252, Error 0.3464(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10020 | Time 18.7157(18.8222) | Bit/dim 3.6141(3.5900) | Xent 0.0811(0.0669) | Loss 9.0090(9.7616) | Error 0.0189(0.0201) Steps 766(733.25) | Grad Norm 6.7481(6.3717) | Total Time 0.00(0.00)\n",
      "Iter 10030 | Time 19.6490(18.8595) | Bit/dim 3.5963(3.5903) | Xent 0.0845(0.0668) | Loss 8.9506(9.5529) | Error 0.0200(0.0199) Steps 784(733.67) | Grad Norm 7.5681(6.5170) | Total Time 0.00(0.00)\n",
      "Iter 10040 | Time 18.8449(18.8954) | Bit/dim 3.6006(3.5914) | Xent 0.0991(0.0633) | Loss 9.0598(9.4029) | Error 0.0278(0.0188) Steps 736(731.58) | Grad Norm 8.9263(6.4882) | Total Time 0.00(0.00)\n",
      "Iter 10050 | Time 19.5469(18.9141) | Bit/dim 3.5898(3.5911) | Xent 0.0246(0.0573) | Loss 8.9249(9.2849) | Error 0.0078(0.0174) Steps 754(735.55) | Grad Norm 4.3354(6.2327) | Total Time 0.00(0.00)\n",
      "Iter 10060 | Time 19.7512(18.9333) | Bit/dim 3.5412(3.5885) | Xent 0.0587(0.0544) | Loss 8.8411(9.1932) | Error 0.0211(0.0168) Steps 778(734.52) | Grad Norm 4.3641(5.8213) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0183 | Time 95.9591, Epoch Time 1155.1134(1124.3888), Bit/dim 3.5978(best: 3.5965), Xent 1.8604, Loss 4.5280, Error 0.3237(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10070 | Time 18.0509(18.9359) | Bit/dim 3.6284(3.5884) | Xent 0.0484(0.0548) | Loss 9.0940(9.9157) | Error 0.0122(0.0170) Steps 742(732.73) | Grad Norm 4.1584(5.5649) | Total Time 0.00(0.00)\n",
      "Iter 10080 | Time 20.2580(19.0384) | Bit/dim 3.5815(3.5837) | Xent 0.0479(0.0524) | Loss 8.9119(9.6544) | Error 0.0122(0.0165) Steps 742(735.81) | Grad Norm 4.0121(5.1237) | Total Time 0.00(0.00)\n",
      "Iter 10090 | Time 18.0414(19.0114) | Bit/dim 3.5549(3.5795) | Xent 0.0325(0.0484) | Loss 8.9056(9.4578) | Error 0.0122(0.0153) Steps 748(735.33) | Grad Norm 5.3740(4.8099) | Total Time 0.00(0.00)\n",
      "Iter 10100 | Time 18.6275(19.0285) | Bit/dim 3.6000(3.5790) | Xent 0.0496(0.0481) | Loss 9.0312(9.3293) | Error 0.0156(0.0149) Steps 730(738.35) | Grad Norm 5.2634(5.0289) | Total Time 0.00(0.00)\n",
      "Iter 10110 | Time 18.8293(18.9945) | Bit/dim 3.5794(3.5808) | Xent 0.0254(0.0485) | Loss 8.8865(9.2372) | Error 0.0078(0.0149) Steps 736(737.66) | Grad Norm 5.7690(4.9807) | Total Time 0.00(0.00)\n",
      "Iter 10120 | Time 19.1282(18.9265) | Bit/dim 3.5821(3.5834) | Xent 0.0978(0.0554) | Loss 9.0523(9.1787) | Error 0.0311(0.0173) Steps 760(737.67) | Grad Norm 8.3307(5.7738) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0184 | Time 95.5425, Epoch Time 1163.3873(1125.5588), Bit/dim 3.6101(best: 3.5965), Xent 1.9597, Loss 4.5900, Error 0.3365(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10130 | Time 18.5670(18.8837) | Bit/dim 3.5730(3.5852) | Xent 0.0525(0.0574) | Loss 8.8094(9.8066) | Error 0.0189(0.0180) Steps 742(736.82) | Grad Norm 6.6838(5.9469) | Total Time 0.00(0.00)\n",
      "Iter 10140 | Time 19.2765(18.8511) | Bit/dim 3.5827(3.5870) | Xent 0.0682(0.0584) | Loss 9.0148(9.5938) | Error 0.0156(0.0178) Steps 748(735.07) | Grad Norm 5.9630(6.0065) | Total Time 0.00(0.00)\n",
      "Iter 10150 | Time 18.9281(18.9255) | Bit/dim 3.5731(3.5877) | Xent 0.0467(0.0563) | Loss 8.9574(9.4266) | Error 0.0156(0.0172) Steps 754(738.30) | Grad Norm 4.3352(6.0452) | Total Time 0.00(0.00)\n",
      "Iter 10160 | Time 19.1250(18.9002) | Bit/dim 3.5646(3.5856) | Xent 0.0194(0.0551) | Loss 8.9230(9.2909) | Error 0.0078(0.0169) Steps 748(734.33) | Grad Norm 3.6403(5.8829) | Total Time 0.00(0.00)\n",
      "Iter 10170 | Time 18.7594(18.8723) | Bit/dim 3.5831(3.5845) | Xent 0.0271(0.0535) | Loss 8.8650(9.1949) | Error 0.0089(0.0166) Steps 754(733.20) | Grad Norm 3.1156(5.6913) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0185 | Time 95.2857, Epoch Time 1154.5100(1126.4273), Bit/dim 3.6036(best: 3.5965), Xent 1.8703, Loss 4.5387, Error 0.3281(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10180 | Time 17.9095(18.7981) | Bit/dim 3.6093(3.5830) | Xent 0.0504(0.0536) | Loss 8.9752(9.8925) | Error 0.0111(0.0165) Steps 718(730.45) | Grad Norm 3.0083(5.3762) | Total Time 0.00(0.00)\n",
      "Iter 10190 | Time 18.4396(18.7802) | Bit/dim 3.5751(3.5834) | Xent 0.0624(0.0531) | Loss 8.8775(9.6437) | Error 0.0178(0.0162) Steps 706(730.33) | Grad Norm 4.4950(4.9976) | Total Time 0.00(0.00)\n",
      "Iter 10200 | Time 18.7726(18.7318) | Bit/dim 3.5559(3.5810) | Xent 0.0607(0.0512) | Loss 8.9410(9.4576) | Error 0.0167(0.0158) Steps 718(730.84) | Grad Norm 5.9684(4.8876) | Total Time 0.00(0.00)\n",
      "Iter 10210 | Time 18.3134(18.7686) | Bit/dim 3.5856(3.5806) | Xent 0.0480(0.0491) | Loss 8.9040(9.3299) | Error 0.0144(0.0150) Steps 724(734.84) | Grad Norm 6.0177(4.8105) | Total Time 0.00(0.00)\n",
      "Iter 10220 | Time 20.1348(18.9039) | Bit/dim 3.6064(3.5811) | Xent 0.0503(0.0497) | Loss 8.9904(9.2259) | Error 0.0156(0.0152) Steps 718(734.54) | Grad Norm 3.6758(4.5981) | Total Time 0.00(0.00)\n",
      "Iter 10230 | Time 19.6558(18.9991) | Bit/dim 3.5560(3.5778) | Xent 0.0508(0.0485) | Loss 8.8975(9.1343) | Error 0.0178(0.0147) Steps 718(735.39) | Grad Norm 4.6800(4.5364) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0186 | Time 95.7564, Epoch Time 1156.4897(1127.3292), Bit/dim 3.5899(best: 3.5965), Xent 1.8803, Loss 4.5301, Error 0.3320(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10240 | Time 18.6483(19.0455) | Bit/dim 3.5683(3.5766) | Xent 0.0376(0.0486) | Loss 8.8042(9.7590) | Error 0.0133(0.0147) Steps 712(734.56) | Grad Norm 6.1389(4.6809) | Total Time 0.00(0.00)\n",
      "Iter 10250 | Time 18.5002(19.0715) | Bit/dim 3.5882(3.5753) | Xent 0.0547(0.0478) | Loss 9.0490(9.5375) | Error 0.0078(0.0138) Steps 724(736.53) | Grad Norm 4.3196(4.6356) | Total Time 0.00(0.00)\n",
      "Iter 10260 | Time 18.5780(19.0660) | Bit/dim 3.5615(3.5750) | Xent 0.0525(0.0482) | Loss 8.9481(9.3731) | Error 0.0178(0.0141) Steps 754(735.82) | Grad Norm 3.9373(4.5981) | Total Time 0.00(0.00)\n",
      "Iter 10270 | Time 19.1074(18.9925) | Bit/dim 3.5305(3.5748) | Xent 0.0520(0.0481) | Loss 8.8102(9.2497) | Error 0.0133(0.0141) Steps 748(733.80) | Grad Norm 4.1660(4.5611) | Total Time 0.00(0.00)\n",
      "Iter 10280 | Time 18.5099(18.9943) | Bit/dim 3.5943(3.5767) | Xent 0.0558(0.0485) | Loss 9.0016(9.1591) | Error 0.0122(0.0142) Steps 730(736.55) | Grad Norm 4.8248(4.6573) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0187 | Time 95.6655, Epoch Time 1167.3756(1128.5306), Bit/dim 3.5992(best: 3.5899), Xent 1.9254, Loss 4.5619, Error 0.3264(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10290 | Time 17.9985(18.9693) | Bit/dim 3.6138(3.5790) | Xent 0.0421(0.0483) | Loss 8.9727(9.9014) | Error 0.0144(0.0141) Steps 742(737.16) | Grad Norm 3.8716(4.6789) | Total Time 0.00(0.00)\n",
      "Iter 10300 | Time 18.8387(18.9190) | Bit/dim 3.5841(3.5808) | Xent 0.0464(0.0458) | Loss 8.9847(9.6375) | Error 0.0156(0.0135) Steps 766(735.01) | Grad Norm 3.9713(4.5020) | Total Time 0.00(0.00)\n",
      "Iter 10310 | Time 19.6207(19.0258) | Bit/dim 3.5925(3.5797) | Xent 0.0210(0.0432) | Loss 8.9506(9.4316) | Error 0.0067(0.0131) Steps 760(737.88) | Grad Norm 3.2230(4.3840) | Total Time 0.00(0.00)\n",
      "Iter 10320 | Time 19.3943(19.0103) | Bit/dim 3.5674(3.5741) | Xent 0.0569(0.0445) | Loss 8.8403(9.2935) | Error 0.0189(0.0137) Steps 736(738.03) | Grad Norm 5.8012(4.6270) | Total Time 0.00(0.00)\n",
      "Iter 10330 | Time 19.1723(18.9973) | Bit/dim 3.5441(3.5737) | Xent 0.0601(0.0467) | Loss 8.8264(9.1958) | Error 0.0200(0.0143) Steps 748(738.63) | Grad Norm 7.0217(4.8834) | Total Time 0.00(0.00)\n",
      "Iter 10340 | Time 18.0939(18.9474) | Bit/dim 3.6136(3.5780) | Xent 0.0473(0.0471) | Loss 8.9583(9.1209) | Error 0.0189(0.0144) Steps 742(736.50) | Grad Norm 4.9510(4.9598) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0188 | Time 93.6826, Epoch Time 1156.8041(1129.3788), Bit/dim 3.6061(best: 3.5899), Xent 1.9103, Loss 4.5612, Error 0.3255(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10350 | Time 19.0823(18.9069) | Bit/dim 3.5823(3.5811) | Xent 0.0330(0.0449) | Loss 8.9223(9.7299) | Error 0.0067(0.0138) Steps 748(737.05) | Grad Norm 4.3987(4.9666) | Total Time 0.00(0.00)\n",
      "Iter 10360 | Time 19.4150(18.9228) | Bit/dim 3.5470(3.5787) | Xent 0.0748(0.0454) | Loss 8.7597(9.5073) | Error 0.0200(0.0139) Steps 754(737.87) | Grad Norm 6.3843(4.9605) | Total Time 0.00(0.00)\n",
      "Iter 10370 | Time 18.5202(18.9550) | Bit/dim 3.5814(3.5779) | Xent 0.0500(0.0460) | Loss 8.9783(9.3588) | Error 0.0200(0.0139) Steps 760(741.10) | Grad Norm 5.4131(4.8870) | Total Time 0.00(0.00)\n",
      "Iter 10380 | Time 19.5820(19.0210) | Bit/dim 3.5660(3.5745) | Xent 0.0313(0.0444) | Loss 8.8408(9.2388) | Error 0.0100(0.0134) Steps 754(745.47) | Grad Norm 3.5270(4.6948) | Total Time 0.00(0.00)\n",
      "Iter 10390 | Time 18.7768(18.9852) | Bit/dim 3.5487(3.5739) | Xent 0.0581(0.0453) | Loss 8.9650(9.1532) | Error 0.0144(0.0132) Steps 754(746.16) | Grad Norm 4.6499(4.7287) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0189 | Time 93.3280, Epoch Time 1158.3851(1130.2490), Bit/dim 3.6054(best: 3.5899), Xent 1.9818, Loss 4.5963, Error 0.3445(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10400 | Time 18.5595(19.0127) | Bit/dim 3.5636(3.5753) | Xent 0.0475(0.0485) | Loss 8.8642(9.8430) | Error 0.0122(0.0142) Steps 742(743.79) | Grad Norm 3.9390(5.1351) | Total Time 0.00(0.00)\n",
      "Iter 10410 | Time 18.9662(18.9264) | Bit/dim 3.5966(3.5788) | Xent 0.0612(0.0507) | Loss 8.9985(9.6135) | Error 0.0167(0.0149) Steps 730(739.33) | Grad Norm 6.9161(5.6454) | Total Time 0.00(0.00)\n",
      "Iter 10420 | Time 18.8566(18.9657) | Bit/dim 3.6010(3.5794) | Xent 0.0407(0.0495) | Loss 8.9612(9.4342) | Error 0.0111(0.0146) Steps 754(740.77) | Grad Norm 7.0138(5.7617) | Total Time 0.00(0.00)\n",
      "Iter 10430 | Time 18.9874(19.0066) | Bit/dim 3.5892(3.5821) | Xent 0.0759(0.0527) | Loss 9.0034(9.3080) | Error 0.0278(0.0156) Steps 730(740.12) | Grad Norm 6.1551(5.6990) | Total Time 0.00(0.00)\n",
      "Iter 10440 | Time 19.2916(19.0196) | Bit/dim 3.5591(3.5808) | Xent 0.0439(0.0506) | Loss 8.9266(9.2053) | Error 0.0133(0.0148) Steps 718(741.37) | Grad Norm 3.8849(5.5455) | Total Time 0.00(0.00)\n",
      "Iter 10450 | Time 18.8953(19.0651) | Bit/dim 3.5527(3.5785) | Xent 0.0581(0.0497) | Loss 9.0044(9.1468) | Error 0.0189(0.0147) Steps 772(744.39) | Grad Norm 6.1618(5.3956) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0190 | Time 93.9129, Epoch Time 1162.5577(1131.2182), Bit/dim 3.5958(best: 3.5899), Xent 1.9207, Loss 4.5561, Error 0.3253(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10460 | Time 19.0783(19.1008) | Bit/dim 3.5572(3.5734) | Xent 0.0987(0.0502) | Loss 8.9712(9.7433) | Error 0.0300(0.0149) Steps 754(743.25) | Grad Norm 9.4056(5.4012) | Total Time 0.00(0.00)\n",
      "Iter 10470 | Time 18.7689(19.1046) | Bit/dim 3.6321(3.5799) | Xent 0.0915(0.0573) | Loss 9.0671(9.5608) | Error 0.0244(0.0168) Steps 736(746.00) | Grad Norm 11.3870(5.8957) | Total Time 0.00(0.00)\n",
      "Iter 10480 | Time 18.5406(19.0837) | Bit/dim 3.5808(3.5836) | Xent 0.0682(0.0655) | Loss 8.9222(9.4288) | Error 0.0233(0.0196) Steps 736(749.06) | Grad Norm 5.3012(6.2625) | Total Time 0.00(0.00)\n",
      "Iter 10490 | Time 19.2065(19.1173) | Bit/dim 3.5639(3.5841) | Xent 0.0766(0.0698) | Loss 8.9765(9.3108) | Error 0.0200(0.0207) Steps 772(747.30) | Grad Norm 6.5087(6.1647) | Total Time 0.00(0.00)\n",
      "Iter 10500 | Time 19.7085(19.1614) | Bit/dim 3.5888(3.5870) | Xent 0.0592(0.0653) | Loss 9.0114(9.2297) | Error 0.0178(0.0196) Steps 796(749.73) | Grad Norm 4.2222(5.7822) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0191 | Time 98.4115, Epoch Time 1172.5221(1132.4573), Bit/dim 3.5937(best: 3.5899), Xent 1.9666, Loss 4.5770, Error 0.3373(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10510 | Time 19.4875(19.0870) | Bit/dim 3.5606(3.5824) | Xent 0.0591(0.0619) | Loss 8.9889(9.8984) | Error 0.0156(0.0186) Steps 730(745.87) | Grad Norm 3.6618(5.3544) | Total Time 0.00(0.00)\n",
      "Iter 10520 | Time 19.0505(19.0901) | Bit/dim 3.5838(3.5827) | Xent 0.0282(0.0567) | Loss 9.0010(9.6527) | Error 0.0089(0.0172) Steps 748(743.92) | Grad Norm 3.6386(5.2036) | Total Time 0.00(0.00)\n",
      "Iter 10530 | Time 19.0421(19.1774) | Bit/dim 3.5901(3.5807) | Xent 0.0289(0.0545) | Loss 8.9294(9.4594) | Error 0.0067(0.0164) Steps 766(741.82) | Grad Norm 4.1958(5.0573) | Total Time 0.00(0.00)\n",
      "Iter 10540 | Time 19.0091(19.1771) | Bit/dim 3.5661(3.5799) | Xent 0.0360(0.0551) | Loss 8.9121(9.3174) | Error 0.0100(0.0169) Steps 724(739.12) | Grad Norm 3.6463(5.1036) | Total Time 0.00(0.00)\n",
      "Iter 10550 | Time 18.6061(19.1019) | Bit/dim 3.5620(3.5803) | Xent 0.0609(0.0532) | Loss 8.9133(9.2248) | Error 0.0144(0.0162) Steps 730(739.09) | Grad Norm 7.3971(5.2188) | Total Time 0.00(0.00)\n",
      "Iter 10560 | Time 18.6827(19.0428) | Bit/dim 3.5638(3.5796) | Xent 0.0415(0.0542) | Loss 8.7983(9.1495) | Error 0.0156(0.0165) Steps 718(737.17) | Grad Norm 4.0943(5.1019) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0192 | Time 95.3780, Epoch Time 1169.1751(1133.5589), Bit/dim 3.5981(best: 3.5899), Xent 1.8417, Loss 4.5190, Error 0.3181(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10570 | Time 18.3712(18.8435) | Bit/dim 3.5590(3.5780) | Xent 0.0544(0.0544) | Loss 8.7799(9.7462) | Error 0.0167(0.0163) Steps 724(733.37) | Grad Norm 5.8025(5.0768) | Total Time 0.00(0.00)\n",
      "Iter 10580 | Time 19.3774(18.9008) | Bit/dim 3.5488(3.5771) | Xent 0.0433(0.0528) | Loss 8.7037(9.5139) | Error 0.0133(0.0158) Steps 760(733.63) | Grad Norm 8.3470(5.2562) | Total Time 0.00(0.00)\n",
      "Iter 10590 | Time 18.7016(18.9917) | Bit/dim 3.6021(3.5804) | Xent 0.0627(0.0555) | Loss 8.9344(9.3657) | Error 0.0189(0.0167) Steps 724(736.42) | Grad Norm 5.7245(5.5087) | Total Time 0.00(0.00)\n",
      "Iter 10600 | Time 18.6916(19.0095) | Bit/dim 3.5883(3.5809) | Xent 0.0475(0.0532) | Loss 8.9569(9.2485) | Error 0.0144(0.0160) Steps 754(738.73) | Grad Norm 3.1274(5.2120) | Total Time 0.00(0.00)\n",
      "Iter 10610 | Time 18.4512(19.0335) | Bit/dim 3.5695(3.5804) | Xent 0.0486(0.0503) | Loss 8.9644(9.1729) | Error 0.0122(0.0154) Steps 724(739.08) | Grad Norm 3.9552(4.8625) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0193 | Time 97.5185, Epoch Time 1161.4362(1134.3952), Bit/dim 3.5942(best: 3.5899), Xent 1.9613, Loss 4.5748, Error 0.3285(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10620 | Time 19.3106(19.1027) | Bit/dim 3.5552(3.5800) | Xent 0.0619(0.0495) | Loss 9.0106(9.9222) | Error 0.0200(0.0154) Steps 748(738.69) | Grad Norm 5.9905(4.8770) | Total Time 0.00(0.00)\n",
      "Iter 10630 | Time 18.0032(19.0687) | Bit/dim 3.5787(3.5826) | Xent 0.0773(0.0545) | Loss 8.9064(9.6699) | Error 0.0200(0.0166) Steps 742(738.09) | Grad Norm 5.4265(5.2464) | Total Time 0.00(0.00)\n",
      "Iter 10640 | Time 18.7116(19.1094) | Bit/dim 3.5762(3.5810) | Xent 0.0543(0.0551) | Loss 8.8734(9.4808) | Error 0.0200(0.0170) Steps 748(740.73) | Grad Norm 5.4682(5.3393) | Total Time 0.00(0.00)\n",
      "Iter 10650 | Time 18.3021(19.1326) | Bit/dim 3.5618(3.5813) | Xent 0.0491(0.0574) | Loss 8.8586(9.3482) | Error 0.0189(0.0177) Steps 748(742.29) | Grad Norm 5.5593(5.4140) | Total Time 0.00(0.00)\n",
      "Iter 10660 | Time 19.3382(19.2180) | Bit/dim 3.5819(3.5820) | Xent 0.0525(0.0576) | Loss 9.0185(9.2464) | Error 0.0200(0.0178) Steps 760(745.37) | Grad Norm 4.6220(5.4049) | Total Time 0.00(0.00)\n",
      "Iter 10670 | Time 19.0557(19.2023) | Bit/dim 3.5554(3.5797) | Xent 0.0417(0.0559) | Loss 8.9367(9.1620) | Error 0.0122(0.0170) Steps 760(746.49) | Grad Norm 4.4856(5.1809) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0194 | Time 95.4341, Epoch Time 1173.9477(1135.5818), Bit/dim 3.5931(best: 3.5899), Xent 1.8805, Loss 4.5333, Error 0.3397(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10680 | Time 19.2382(19.1186) | Bit/dim 3.5340(3.5766) | Xent 0.0388(0.0545) | Loss 8.7421(9.7438) | Error 0.0156(0.0165) Steps 676(741.60) | Grad Norm 3.7284(4.9610) | Total Time 0.00(0.00)\n",
      "Iter 10690 | Time 18.4972(19.0276) | Bit/dim 3.5357(3.5763) | Xent 0.0648(0.0543) | Loss 8.8331(9.5256) | Error 0.0211(0.0163) Steps 742(738.96) | Grad Norm 4.4927(4.7012) | Total Time 0.00(0.00)\n",
      "Iter 10700 | Time 19.9853(19.0777) | Bit/dim 3.5580(3.5752) | Xent 0.0993(0.0526) | Loss 8.9792(9.3615) | Error 0.0278(0.0158) Steps 790(739.60) | Grad Norm 9.0974(4.6369) | Total Time 0.00(0.00)\n",
      "Iter 10710 | Time 19.9647(18.9990) | Bit/dim 3.5681(3.5779) | Xent 0.0837(0.0538) | Loss 8.9337(9.2364) | Error 0.0244(0.0163) Steps 742(739.52) | Grad Norm 10.6156(5.4153) | Total Time 0.00(0.00)\n",
      "Iter 10720 | Time 17.9820(18.9140) | Bit/dim 3.5620(3.5750) | Xent 0.0455(0.0530) | Loss 8.7970(9.1428) | Error 0.0156(0.0159) Steps 712(739.55) | Grad Norm 4.1053(5.3674) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0195 | Time 95.4216, Epoch Time 1156.1286(1136.1982), Bit/dim 3.5907(best: 3.5899), Xent 1.9708, Loss 4.5761, Error 0.3293(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10730 | Time 18.8186(18.9601) | Bit/dim 3.6024(3.5758) | Xent 0.0380(0.0512) | Loss 8.9367(9.8446) | Error 0.0144(0.0154) Steps 724(741.28) | Grad Norm 5.1730(5.1703) | Total Time 0.00(0.00)\n",
      "Iter 10740 | Time 18.0538(18.9501) | Bit/dim 3.5904(3.5737) | Xent 0.0466(0.0502) | Loss 8.9829(9.5982) | Error 0.0144(0.0154) Steps 736(741.19) | Grad Norm 3.6607(4.9456) | Total Time 0.00(0.00)\n",
      "Iter 10750 | Time 18.0070(19.0292) | Bit/dim 3.5471(3.5724) | Xent 0.0488(0.0472) | Loss 8.8333(9.4143) | Error 0.0156(0.0144) Steps 736(741.01) | Grad Norm 3.8031(4.8869) | Total Time 0.00(0.00)\n",
      "Iter 10760 | Time 18.9404(19.0291) | Bit/dim 3.5767(3.5718) | Xent 0.0265(0.0449) | Loss 8.8753(9.2813) | Error 0.0089(0.0136) Steps 712(742.76) | Grad Norm 6.2188(4.8956) | Total Time 0.00(0.00)\n",
      "Iter 10770 | Time 19.7101(19.1720) | Bit/dim 3.5603(3.5725) | Xent 0.0363(0.0457) | Loss 8.9154(9.1968) | Error 0.0100(0.0135) Steps 754(744.95) | Grad Norm 3.4142(5.0465) | Total Time 0.00(0.00)\n",
      "Iter 10780 | Time 20.1067(19.2360) | Bit/dim 3.6278(3.5781) | Xent 0.0613(0.0525) | Loss 9.0356(9.1499) | Error 0.0211(0.0156) Steps 742(743.90) | Grad Norm 3.8190(5.4649) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0196 | Time 95.9835, Epoch Time 1174.1006(1137.3352), Bit/dim 3.6028(best: 3.5899), Xent 1.9661, Loss 4.5858, Error 0.3350(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10790 | Time 18.8314(19.2412) | Bit/dim 3.5754(3.5804) | Xent 0.0690(0.0571) | Loss 8.9648(9.7474) | Error 0.0200(0.0167) Steps 688(744.07) | Grad Norm 4.9610(5.7182) | Total Time 0.00(0.00)\n",
      "Iter 10800 | Time 18.7964(19.2017) | Bit/dim 3.6314(3.5826) | Xent 0.0576(0.0568) | Loss 9.0709(9.5544) | Error 0.0211(0.0170) Steps 694(740.85) | Grad Norm 4.6351(5.4476) | Total Time 0.00(0.00)\n",
      "Iter 10810 | Time 18.8765(19.1048) | Bit/dim 3.5643(3.5802) | Xent 0.0881(0.0573) | Loss 8.9229(9.3940) | Error 0.0278(0.0171) Steps 730(741.00) | Grad Norm 5.6322(5.3795) | Total Time 0.00(0.00)\n",
      "Iter 10820 | Time 19.4620(19.0800) | Bit/dim 3.5562(3.5796) | Xent 0.0573(0.0561) | Loss 8.8028(9.2701) | Error 0.0211(0.0174) Steps 766(744.13) | Grad Norm 6.4577(5.6433) | Total Time 0.00(0.00)\n",
      "Iter 10830 | Time 18.8704(19.0136) | Bit/dim 3.5833(3.5807) | Xent 0.0567(0.0553) | Loss 8.9401(9.1811) | Error 0.0167(0.0173) Steps 760(742.78) | Grad Norm 4.5834(5.4425) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0197 | Time 95.4095, Epoch Time 1160.7977(1138.0391), Bit/dim 3.5976(best: 3.5899), Xent 1.9209, Loss 4.5580, Error 0.3293(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10840 | Time 18.8899(18.9693) | Bit/dim 3.5749(3.5784) | Xent 0.0332(0.0534) | Loss 8.8701(9.8967) | Error 0.0122(0.0168) Steps 718(741.35) | Grad Norm 4.6250(5.3038) | Total Time 0.00(0.00)\n",
      "Iter 10850 | Time 18.6656(19.0091) | Bit/dim 3.5966(3.5789) | Xent 0.0594(0.0514) | Loss 8.9593(9.6462) | Error 0.0233(0.0164) Steps 754(741.62) | Grad Norm 4.6387(4.9567) | Total Time 0.00(0.00)\n",
      "Iter 10860 | Time 18.9015(19.0091) | Bit/dim 3.5465(3.5768) | Xent 0.0241(0.0472) | Loss 8.7557(9.4439) | Error 0.0089(0.0150) Steps 700(740.88) | Grad Norm 3.3429(4.8482) | Total Time 0.00(0.00)\n",
      "Iter 10870 | Time 18.4622(19.0295) | Bit/dim 3.6246(3.5782) | Xent 0.0333(0.0459) | Loss 8.9771(9.3116) | Error 0.0111(0.0144) Steps 700(742.58) | Grad Norm 5.8764(5.0057) | Total Time 0.00(0.00)\n",
      "Iter 10880 | Time 20.7816(19.2163) | Bit/dim 3.5799(3.5745) | Xent 0.0617(0.0487) | Loss 9.0582(9.2147) | Error 0.0111(0.0150) Steps 754(742.54) | Grad Norm 5.4472(5.4742) | Total Time 0.00(0.00)\n",
      "Iter 10890 | Time 19.0903(19.2333) | Bit/dim 3.5405(3.5752) | Xent 0.0598(0.0494) | Loss 8.9698(9.1449) | Error 0.0200(0.0151) Steps 784(744.46) | Grad Norm 4.6981(5.4265) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0198 | Time 96.0570, Epoch Time 1173.6938(1139.1088), Bit/dim 3.5950(best: 3.5899), Xent 1.9586, Loss 4.5743, Error 0.3349(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10900 | Time 19.4702(19.2087) | Bit/dim 3.6014(3.5765) | Xent 0.0793(0.0479) | Loss 9.0837(9.7946) | Error 0.0222(0.0148) Steps 748(746.06) | Grad Norm 4.9753(5.1947) | Total Time 0.00(0.00)\n",
      "Iter 10910 | Time 18.6805(19.2225) | Bit/dim 3.5752(3.5763) | Xent 0.0708(0.0514) | Loss 9.0350(9.5776) | Error 0.0200(0.0160) Steps 736(744.74) | Grad Norm 6.1401(5.4943) | Total Time 0.00(0.00)\n",
      "Iter 10920 | Time 19.4465(19.2538) | Bit/dim 3.6030(3.5752) | Xent 0.0556(0.0525) | Loss 9.0354(9.4154) | Error 0.0156(0.0163) Steps 742(743.74) | Grad Norm 4.0538(5.2344) | Total Time 0.00(0.00)\n",
      "Iter 10930 | Time 19.0195(19.2064) | Bit/dim 3.5375(3.5734) | Xent 0.0734(0.0547) | Loss 9.0080(9.2870) | Error 0.0222(0.0167) Steps 772(743.85) | Grad Norm 5.2688(5.1494) | Total Time 0.00(0.00)\n",
      "Iter 10940 | Time 19.0424(19.2101) | Bit/dim 3.5454(3.5747) | Xent 0.0717(0.0551) | Loss 8.9206(9.1992) | Error 0.0200(0.0165) Steps 730(744.42) | Grad Norm 7.4491(5.1991) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0199 | Time 97.5175, Epoch Time 1174.6076(1140.1737), Bit/dim 3.5852(best: 3.5899), Xent 1.8298, Loss 4.5001, Error 0.3328(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10950 | Time 19.8958(19.2449) | Bit/dim 3.5851(3.5754) | Xent 0.0416(0.0542) | Loss 9.1338(9.9312) | Error 0.0111(0.0162) Steps 772(746.64) | Grad Norm 4.8184(5.0527) | Total Time 0.00(0.00)\n",
      "Iter 10960 | Time 19.3835(19.2229) | Bit/dim 3.5572(3.5768) | Xent 0.0355(0.0490) | Loss 9.0227(9.6737) | Error 0.0144(0.0149) Steps 790(746.45) | Grad Norm 3.5444(4.6997) | Total Time 0.00(0.00)\n",
      "Iter 10970 | Time 18.8175(19.2374) | Bit/dim 3.5753(3.5726) | Xent 0.0236(0.0444) | Loss 8.9560(9.4799) | Error 0.0078(0.0134) Steps 778(747.78) | Grad Norm 3.5631(4.3468) | Total Time 0.00(0.00)\n",
      "Iter 10980 | Time 18.5435(19.1491) | Bit/dim 3.6221(3.5725) | Xent 0.0496(0.0431) | Loss 9.1135(9.3392) | Error 0.0156(0.0131) Steps 742(747.43) | Grad Norm 5.6602(4.4995) | Total Time 0.00(0.00)\n",
      "Iter 10990 | Time 18.9407(19.1271) | Bit/dim 3.5558(3.5717) | Xent 0.0328(0.0424) | Loss 8.8697(9.2232) | Error 0.0111(0.0128) Steps 730(744.49) | Grad Norm 4.2641(4.6783) | Total Time 0.00(0.00)\n",
      "Iter 11000 | Time 18.8713(19.1500) | Bit/dim 3.5638(3.5704) | Xent 0.0635(0.0432) | Loss 9.0225(9.1458) | Error 0.0167(0.0130) Steps 748(746.96) | Grad Norm 3.6597(4.5904) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0200 | Time 95.4571, Epoch Time 1170.4759(1141.0828), Bit/dim 3.5946(best: 3.5852), Xent 2.0547, Loss 4.6219, Error 0.3296(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11010 | Time 19.0624(19.1721) | Bit/dim 3.5718(3.5710) | Xent 0.0524(0.0458) | Loss 8.9289(9.7695) | Error 0.0189(0.0136) Steps 682(744.96) | Grad Norm 4.4153(4.7760) | Total Time 0.00(0.00)\n",
      "Iter 11020 | Time 19.3930(19.1747) | Bit/dim 3.5497(3.5708) | Xent 0.0493(0.0476) | Loss 8.9045(9.5443) | Error 0.0122(0.0140) Steps 760(741.38) | Grad Norm 5.0749(4.7758) | Total Time 0.00(0.00)\n",
      "Iter 11030 | Time 18.2111(19.0951) | Bit/dim 3.5678(3.5697) | Xent 0.0582(0.0480) | Loss 8.9767(9.3882) | Error 0.0167(0.0145) Steps 712(743.09) | Grad Norm 5.6696(5.0023) | Total Time 0.00(0.00)\n",
      "Iter 11040 | Time 18.4773(19.0803) | Bit/dim 3.5722(3.5741) | Xent 0.0220(0.0516) | Loss 8.7763(9.2730) | Error 0.0056(0.0153) Steps 724(741.85) | Grad Norm 2.8030(5.7405) | Total Time 0.00(0.00)\n",
      "Iter 11050 | Time 19.1292(19.1167) | Bit/dim 3.5862(3.5779) | Xent 0.0472(0.0528) | Loss 9.0212(9.1807) | Error 0.0156(0.0161) Steps 748(740.93) | Grad Norm 2.9488(5.6636) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0201 | Time 96.1504, Epoch Time 1167.4996(1141.8753), Bit/dim 3.5940(best: 3.5852), Xent 1.8786, Loss 4.5333, Error 0.3250(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11060 | Time 19.3667(19.1080) | Bit/dim 3.5837(3.5764) | Xent 0.0332(0.0521) | Loss 8.9625(9.8977) | Error 0.0078(0.0152) Steps 760(743.62) | Grad Norm 4.0058(5.3388) | Total Time 0.00(0.00)\n",
      "Iter 11070 | Time 19.6010(19.1050) | Bit/dim 3.5689(3.5750) | Xent 0.0240(0.0507) | Loss 8.7871(9.6322) | Error 0.0067(0.0149) Steps 760(744.61) | Grad Norm 3.0565(5.1363) | Total Time 0.00(0.00)\n",
      "Iter 11080 | Time 18.7172(19.1402) | Bit/dim 3.5959(3.5758) | Xent 0.0493(0.0490) | Loss 8.9730(9.4487) | Error 0.0167(0.0143) Steps 748(745.18) | Grad Norm 3.7219(5.0092) | Total Time 0.00(0.00)\n",
      "Iter 11090 | Time 20.3260(19.2110) | Bit/dim 3.5654(3.5741) | Xent 0.0400(0.0453) | Loss 8.8224(9.3069) | Error 0.0133(0.0135) Steps 724(742.88) | Grad Norm 3.4651(4.7009) | Total Time 0.00(0.00)\n",
      "Iter 11100 | Time 19.4689(19.2178) | Bit/dim 3.5702(3.5703) | Xent 0.0552(0.0421) | Loss 8.8654(9.1875) | Error 0.0156(0.0126) Steps 760(744.32) | Grad Norm 4.6000(4.4189) | Total Time 0.00(0.00)\n",
      "Iter 11110 | Time 19.3742(19.2479) | Bit/dim 3.5861(3.5684) | Xent 0.1068(0.0440) | Loss 9.0297(9.1090) | Error 0.0267(0.0128) Steps 754(746.46) | Grad Norm 7.8009(4.5258) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0202 | Time 96.5696, Epoch Time 1176.8498(1142.9245), Bit/dim 3.5905(best: 3.5852), Xent 2.0369, Loss 4.6089, Error 0.3374(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11120 | Time 18.7449(19.2315) | Bit/dim 3.5582(3.5712) | Xent 0.0584(0.0466) | Loss 8.9632(9.7259) | Error 0.0122(0.0132) Steps 778(749.24) | Grad Norm 6.7350(4.7934) | Total Time 0.00(0.00)\n",
      "Iter 11130 | Time 19.9851(19.3305) | Bit/dim 3.5836(3.5731) | Xent 0.0936(0.0523) | Loss 9.1005(9.5349) | Error 0.0222(0.0150) Steps 766(750.24) | Grad Norm 6.5392(5.2381) | Total Time 0.00(0.00)\n",
      "Iter 11140 | Time 19.7018(19.4248) | Bit/dim 3.5985(3.5767) | Xent 0.0427(0.0562) | Loss 8.9501(9.3934) | Error 0.0133(0.0161) Steps 778(753.50) | Grad Norm 6.1945(5.5814) | Total Time 0.00(0.00)\n",
      "Iter 11150 | Time 19.3550(19.4337) | Bit/dim 3.5714(3.5773) | Xent 0.0449(0.0543) | Loss 8.8165(9.2691) | Error 0.0122(0.0159) Steps 772(756.26) | Grad Norm 6.1705(5.6532) | Total Time 0.00(0.00)\n",
      "Iter 11160 | Time 19.1481(19.4065) | Bit/dim 3.5409(3.5733) | Xent 0.0290(0.0506) | Loss 8.7918(9.1783) | Error 0.0067(0.0149) Steps 772(754.47) | Grad Norm 3.3388(5.2415) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0203 | Time 97.9946, Epoch Time 1189.2949(1144.3156), Bit/dim 3.5922(best: 3.5852), Xent 1.9473, Loss 4.5658, Error 0.3281(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11170 | Time 19.8025(19.4268) | Bit/dim 3.5718(3.5711) | Xent 0.0490(0.0481) | Loss 8.9487(9.9498) | Error 0.0167(0.0142) Steps 760(755.03) | Grad Norm 3.7268(4.9479) | Total Time 0.00(0.00)\n",
      "Iter 11180 | Time 19.3280(19.5324) | Bit/dim 3.5347(3.5693) | Xent 0.0328(0.0480) | Loss 8.7519(9.6764) | Error 0.0133(0.0143) Steps 718(755.73) | Grad Norm 4.5679(4.7266) | Total Time 0.00(0.00)\n",
      "Iter 11190 | Time 20.3929(19.5999) | Bit/dim 3.5441(3.5692) | Xent 0.0282(0.0481) | Loss 8.9560(9.4755) | Error 0.0067(0.0143) Steps 724(755.48) | Grad Norm 3.0722(4.6822) | Total Time 0.00(0.00)\n",
      "Iter 11200 | Time 19.4198(19.4662) | Bit/dim 3.5758(3.5694) | Xent 0.0611(0.0474) | Loss 8.8041(9.3149) | Error 0.0144(0.0137) Steps 724(753.60) | Grad Norm 3.9466(4.4409) | Total Time 0.00(0.00)\n",
      "Iter 11210 | Time 20.2481(19.6047) | Bit/dim 3.5998(3.5693) | Xent 0.0484(0.0464) | Loss 9.1504(9.2176) | Error 0.0133(0.0136) Steps 790(756.23) | Grad Norm 5.9331(4.4398) | Total Time 0.00(0.00)\n",
      "Iter 11220 | Time 19.5628(19.5393) | Bit/dim 3.5688(3.5682) | Xent 0.0584(0.0492) | Loss 8.9368(9.1326) | Error 0.0144(0.0148) Steps 748(753.56) | Grad Norm 6.0228(4.8718) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0204 | Time 96.2961, Epoch Time 1194.9513(1145.8347), Bit/dim 3.5910(best: 3.5852), Xent 1.9499, Loss 4.5659, Error 0.3296(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11230 | Time 19.4221(19.5450) | Bit/dim 3.5724(3.5663) | Xent 0.0707(0.0474) | Loss 8.9785(9.7504) | Error 0.0189(0.0141) Steps 754(756.27) | Grad Norm 8.9386(4.8850) | Total Time 0.00(0.00)\n",
      "Iter 11240 | Time 19.6800(19.5796) | Bit/dim 3.5528(3.5654) | Xent 0.0311(0.0455) | Loss 8.8688(9.5347) | Error 0.0089(0.0134) Steps 754(754.65) | Grad Norm 3.5554(4.5088) | Total Time 0.00(0.00)\n",
      "Iter 11250 | Time 19.7020(19.6000) | Bit/dim 3.5632(3.5658) | Xent 0.0723(0.0471) | Loss 8.9910(9.3803) | Error 0.0189(0.0137) Steps 772(755.19) | Grad Norm 4.1836(4.4215) | Total Time 0.00(0.00)\n",
      "Iter 11260 | Time 20.5147(19.6639) | Bit/dim 3.5785(3.5660) | Xent 0.0422(0.0467) | Loss 8.8761(9.2494) | Error 0.0167(0.0137) Steps 736(754.27) | Grad Norm 4.6836(4.2201) | Total Time 0.00(0.00)\n",
      "Iter 11270 | Time 18.4953(19.6073) | Bit/dim 3.6087(3.5672) | Xent 0.0287(0.0495) | Loss 8.9634(9.1673) | Error 0.0056(0.0148) Steps 778(756.70) | Grad Norm 3.6889(4.4339) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0205 | Time 96.3326, Epoch Time 1198.2171(1147.4062), Bit/dim 3.5940(best: 3.5852), Xent 1.8751, Loss 4.5315, Error 0.3286(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11280 | Time 20.6484(19.6004) | Bit/dim 3.5692(3.5673) | Xent 0.0494(0.0494) | Loss 8.9843(9.9049) | Error 0.0222(0.0150) Steps 730(752.03) | Grad Norm 6.0039(4.6875) | Total Time 0.00(0.00)\n",
      "Iter 11290 | Time 19.2250(19.5821) | Bit/dim 3.5962(3.5718) | Xent 0.0603(0.0508) | Loss 9.0854(9.6662) | Error 0.0156(0.0151) Steps 748(755.26) | Grad Norm 4.2744(4.7288) | Total Time 0.00(0.00)\n",
      "Iter 11300 | Time 19.7049(19.4986) | Bit/dim 3.5342(3.5714) | Xent 0.0394(0.0492) | Loss 8.8596(9.4727) | Error 0.0133(0.0145) Steps 754(754.72) | Grad Norm 5.4991(4.7853) | Total Time 0.00(0.00)\n",
      "Iter 11310 | Time 18.6431(19.5161) | Bit/dim 3.5722(3.5720) | Xent 0.0386(0.0482) | Loss 8.9820(9.3330) | Error 0.0111(0.0143) Steps 748(757.46) | Grad Norm 4.2434(4.9886) | Total Time 0.00(0.00)\n",
      "Iter 11320 | Time 20.3474(19.5563) | Bit/dim 3.5896(3.5706) | Xent 0.0799(0.0535) | Loss 9.0765(9.2389) | Error 0.0222(0.0160) Steps 760(756.11) | Grad Norm 5.1064(5.2056) | Total Time 0.00(0.00)\n",
      "Iter 11330 | Time 20.4215(19.6031) | Bit/dim 3.5268(3.5699) | Xent 0.0725(0.0579) | Loss 8.8095(9.1607) | Error 0.0156(0.0174) Steps 778(759.43) | Grad Norm 5.9165(5.3930) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0206 | Time 97.0157, Epoch Time 1193.6211(1148.7926), Bit/dim 3.5964(best: 3.5852), Xent 1.9205, Loss 4.5567, Error 0.3261(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11340 | Time 19.3283(19.5713) | Bit/dim 3.5490(3.5714) | Xent 0.0523(0.0576) | Loss 8.9361(9.7435) | Error 0.0167(0.0171) Steps 748(757.66) | Grad Norm 3.7496(5.3953) | Total Time 0.00(0.00)\n",
      "Iter 11350 | Time 19.3478(19.5194) | Bit/dim 3.5902(3.5735) | Xent 0.0464(0.0561) | Loss 9.0270(9.5334) | Error 0.0122(0.0164) Steps 778(755.46) | Grad Norm 6.7111(5.3872) | Total Time 0.00(0.00)\n",
      "Iter 11360 | Time 20.7776(19.6474) | Bit/dim 3.5384(3.5689) | Xent 0.0418(0.0542) | Loss 8.8585(9.3691) | Error 0.0111(0.0161) Steps 808(760.42) | Grad Norm 4.7049(5.1177) | Total Time 0.00(0.00)\n",
      "Iter 11370 | Time 19.3124(19.6656) | Bit/dim 3.5423(3.5700) | Xent 0.0759(0.0538) | Loss 8.9666(9.2641) | Error 0.0244(0.0159) Steps 748(759.18) | Grad Norm 5.7848(5.1559) | Total Time 0.00(0.00)\n",
      "Iter 11380 | Time 19.9823(19.6915) | Bit/dim 3.5654(3.5732) | Xent 0.0412(0.0574) | Loss 8.8674(9.1812) | Error 0.0133(0.0170) Steps 760(759.41) | Grad Norm 3.5994(5.7911) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0207 | Time 98.0638, Epoch Time 1201.4241(1150.3716), Bit/dim 3.5878(best: 3.5852), Xent 1.8233, Loss 4.4994, Error 0.3263(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11390 | Time 20.8789(19.7288) | Bit/dim 3.5409(3.5712) | Xent 0.0320(0.0543) | Loss 8.9553(9.9215) | Error 0.0089(0.0159) Steps 814(759.12) | Grad Norm 4.2712(5.3914) | Total Time 0.00(0.00)\n",
      "Iter 11400 | Time 20.0517(19.8220) | Bit/dim 3.5508(3.5685) | Xent 0.0473(0.0512) | Loss 8.9683(9.6602) | Error 0.0100(0.0152) Steps 772(763.43) | Grad Norm 3.3199(5.1025) | Total Time 0.00(0.00)\n",
      "Iter 11410 | Time 19.8785(19.7786) | Bit/dim 3.5578(3.5665) | Xent 0.0378(0.0502) | Loss 8.8247(9.4564) | Error 0.0133(0.0148) Steps 754(765.39) | Grad Norm 5.2364(5.0299) | Total Time 0.00(0.00)\n",
      "Iter 11420 | Time 19.4565(19.7761) | Bit/dim 3.5738(3.5676) | Xent 0.0285(0.0490) | Loss 9.0206(9.3312) | Error 0.0078(0.0146) Steps 760(764.78) | Grad Norm 2.7993(4.8750) | Total Time 0.00(0.00)\n",
      "Iter 11430 | Time 19.1505(19.7648) | Bit/dim 3.5743(3.5679) | Xent 0.0547(0.0490) | Loss 8.8916(9.2279) | Error 0.0167(0.0147) Steps 748(765.52) | Grad Norm 5.0699(4.6863) | Total Time 0.00(0.00)\n",
      "Iter 11440 | Time 19.5410(19.7440) | Bit/dim 3.5654(3.5677) | Xent 0.0580(0.0462) | Loss 8.8636(9.1425) | Error 0.0200(0.0140) Steps 748(767.54) | Grad Norm 6.8964(4.5061) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0208 | Time 98.2954, Epoch Time 1207.9547(1152.0991), Bit/dim 3.5833(best: 3.5852), Xent 1.9279, Loss 4.5473, Error 0.3285(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11450 | Time 19.0807(19.7014) | Bit/dim 3.6044(3.5677) | Xent 0.0415(0.0454) | Loss 8.9614(9.7758) | Error 0.0122(0.0139) Steps 742(764.40) | Grad Norm 5.3823(4.5661) | Total Time 0.00(0.00)\n",
      "Iter 11460 | Time 19.6844(19.7258) | Bit/dim 3.6072(3.5669) | Xent 0.0497(0.0441) | Loss 9.0494(9.5524) | Error 0.0144(0.0133) Steps 772(764.81) | Grad Norm 4.4439(4.4656) | Total Time 0.00(0.00)\n",
      "Iter 11470 | Time 20.0192(19.7537) | Bit/dim 3.5797(3.5681) | Xent 0.0806(0.0463) | Loss 8.8357(9.3935) | Error 0.0222(0.0140) Steps 760(760.75) | Grad Norm 6.1255(4.6064) | Total Time 0.00(0.00)\n",
      "Iter 11480 | Time 20.0150(19.7658) | Bit/dim 3.5930(3.5698) | Xent 0.0545(0.0532) | Loss 9.0051(9.2871) | Error 0.0189(0.0162) Steps 736(762.15) | Grad Norm 5.6565(5.0946) | Total Time 0.00(0.00)\n",
      "Iter 11490 | Time 20.2884(19.7376) | Bit/dim 3.5343(3.5725) | Xent 0.0378(0.0563) | Loss 8.9082(9.2102) | Error 0.0111(0.0172) Steps 766(765.78) | Grad Norm 5.6092(5.5023) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0209 | Time 97.2580, Epoch Time 1204.6899(1153.6768), Bit/dim 3.5994(best: 3.5833), Xent 1.9266, Loss 4.5627, Error 0.3224(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11500 | Time 19.5982(19.7828) | Bit/dim 3.6131(3.5737) | Xent 0.0533(0.0563) | Loss 9.0291(9.9717) | Error 0.0167(0.0173) Steps 742(767.32) | Grad Norm 5.4988(5.7107) | Total Time 0.00(0.00)\n",
      "Iter 11510 | Time 19.4182(19.8558) | Bit/dim 3.5641(3.5748) | Xent 0.0423(0.0534) | Loss 8.9136(9.7091) | Error 0.0144(0.0166) Steps 766(769.78) | Grad Norm 4.0752(5.3866) | Total Time 0.00(0.00)\n",
      "Iter 11520 | Time 19.8418(19.8242) | Bit/dim 3.5546(3.5715) | Xent 0.0385(0.0498) | Loss 8.9589(9.5063) | Error 0.0122(0.0155) Steps 790(773.04) | Grad Norm 4.3497(5.2176) | Total Time 0.00(0.00)\n",
      "Iter 11530 | Time 19.0546(19.8330) | Bit/dim 3.5787(3.5730) | Xent 0.0656(0.0502) | Loss 8.9596(9.3721) | Error 0.0200(0.0150) Steps 766(773.21) | Grad Norm 4.2336(4.9093) | Total Time 0.00(0.00)\n",
      "Iter 11540 | Time 20.1507(19.7933) | Bit/dim 3.5273(3.5689) | Xent 0.0456(0.0499) | Loss 8.8028(9.2502) | Error 0.0133(0.0148) Steps 754(768.67) | Grad Norm 7.7176(5.0434) | Total Time 0.00(0.00)\n",
      "Iter 11550 | Time 19.3878(19.8583) | Bit/dim 3.5784(3.5686) | Xent 0.0577(0.0505) | Loss 8.9165(9.1779) | Error 0.0189(0.0151) Steps 772(771.61) | Grad Norm 5.0820(5.3688) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0210 | Time 98.1101, Epoch Time 1215.3936(1155.5283), Bit/dim 3.5904(best: 3.5833), Xent 1.8691, Loss 4.5250, Error 0.3244(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11560 | Time 20.3190(19.9392) | Bit/dim 3.5497(3.5684) | Xent 0.0351(0.0487) | Loss 8.8749(9.8315) | Error 0.0111(0.0148) Steps 808(774.27) | Grad Norm 3.6673(5.2332) | Total Time 0.00(0.00)\n",
      "Iter 11570 | Time 20.4452(20.0075) | Bit/dim 3.6010(3.5663) | Xent 0.0317(0.0476) | Loss 9.0153(9.6058) | Error 0.0089(0.0142) Steps 784(780.10) | Grad Norm 4.2834(4.8336) | Total Time 0.00(0.00)\n",
      "Iter 11580 | Time 19.5706(20.0015) | Bit/dim 3.5964(3.5685) | Xent 0.0355(0.0454) | Loss 9.0220(9.4373) | Error 0.0111(0.0135) Steps 790(781.37) | Grad Norm 2.9289(4.4988) | Total Time 0.00(0.00)\n",
      "Iter 11590 | Time 19.3710(19.9698) | Bit/dim 3.5802(3.5681) | Xent 0.0621(0.0445) | Loss 9.0191(9.3004) | Error 0.0189(0.0134) Steps 742(773.25) | Grad Norm 4.7814(4.4764) | Total Time 0.00(0.00)\n",
      "Iter 11600 | Time 20.5936(19.9213) | Bit/dim 3.6197(3.5678) | Xent 0.0508(0.0456) | Loss 9.0102(9.2060) | Error 0.0122(0.0135) Steps 790(770.10) | Grad Norm 5.7608(4.8407) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0211 | Time 97.3183, Epoch Time 1217.4115(1157.3848), Bit/dim 3.5886(best: 3.5833), Xent 1.9111, Loss 4.5442, Error 0.3229(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11610 | Time 19.2075(19.8957) | Bit/dim 3.5316(3.5657) | Xent 0.0396(0.0444) | Loss 8.7239(9.9154) | Error 0.0111(0.0130) Steps 760(768.14) | Grad Norm 3.7312(4.8369) | Total Time 0.00(0.00)\n",
      "Iter 11620 | Time 19.0650(19.7993) | Bit/dim 3.5574(3.5653) | Xent 0.0447(0.0453) | Loss 8.8511(9.6570) | Error 0.0122(0.0132) Steps 772(767.99) | Grad Norm 5.1076(5.0771) | Total Time 0.00(0.00)\n",
      "Iter 11630 | Time 19.7243(19.7270) | Bit/dim 3.5610(3.5709) | Xent 0.1062(0.0628) | Loss 8.9635(9.4961) | Error 0.0267(0.0181) Steps 784(767.92) | Grad Norm 7.3955(6.1594) | Total Time 0.00(0.00)\n",
      "Iter 11640 | Time 20.5832(19.7978) | Bit/dim 3.5812(3.5733) | Xent 0.0786(0.0710) | Loss 8.9717(9.3763) | Error 0.0267(0.0210) Steps 772(770.46) | Grad Norm 4.0009(6.1895) | Total Time 0.00(0.00)\n",
      "Iter 11650 | Time 18.8656(19.7450) | Bit/dim 3.5844(3.5762) | Xent 0.0685(0.0679) | Loss 8.9193(9.2720) | Error 0.0256(0.0205) Steps 742(770.06) | Grad Norm 8.2005(6.0564) | Total Time 0.00(0.00)\n",
      "Iter 11660 | Time 19.5615(19.6564) | Bit/dim 3.5717(3.5729) | Xent 0.0511(0.0640) | Loss 8.9143(9.1817) | Error 0.0133(0.0195) Steps 790(769.30) | Grad Norm 3.8340(5.6355) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0212 | Time 96.1931, Epoch Time 1196.7571(1158.5660), Bit/dim 3.5893(best: 3.5833), Xent 1.9459, Loss 4.5622, Error 0.3310(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11670 | Time 19.4902(19.7137) | Bit/dim 3.5313(3.5734) | Xent 0.0611(0.0581) | Loss 8.7632(9.8033) | Error 0.0156(0.0175) Steps 760(767.41) | Grad Norm 4.5411(5.2749) | Total Time 0.00(0.00)\n",
      "Iter 11680 | Time 18.2692(19.6359) | Bit/dim 3.6006(3.5722) | Xent 0.0453(0.0547) | Loss 8.8964(9.5720) | Error 0.0111(0.0165) Steps 736(765.22) | Grad Norm 5.2168(4.9216) | Total Time 0.00(0.00)\n",
      "Iter 11690 | Time 19.7017(19.6149) | Bit/dim 3.5442(3.5691) | Xent 0.0296(0.0542) | Loss 8.8161(9.4079) | Error 0.0122(0.0163) Steps 790(765.28) | Grad Norm 3.6729(4.7937) | Total Time 0.00(0.00)\n",
      "Iter 11700 | Time 19.6199(19.6700) | Bit/dim 3.5763(3.5684) | Xent 0.0593(0.0524) | Loss 8.9135(9.2825) | Error 0.0122(0.0154) Steps 760(764.25) | Grad Norm 5.2640(4.8161) | Total Time 0.00(0.00)\n",
      "Iter 11710 | Time 20.1418(19.7020) | Bit/dim 3.5697(3.5669) | Xent 0.0398(0.0504) | Loss 9.0848(9.2003) | Error 0.0122(0.0147) Steps 802(767.34) | Grad Norm 4.5506(4.7755) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0213 | Time 99.3837, Epoch Time 1205.8359(1159.9841), Bit/dim 3.5922(best: 3.5833), Xent 1.9035, Loss 4.5439, Error 0.3262(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11720 | Time 19.3946(19.7123) | Bit/dim 3.5784(3.5666) | Xent 0.0555(0.0512) | Loss 8.9829(9.9545) | Error 0.0144(0.0149) Steps 748(767.08) | Grad Norm 3.7547(4.9124) | Total Time 0.00(0.00)\n",
      "Iter 11730 | Time 19.8120(19.7261) | Bit/dim 3.5455(3.5652) | Xent 0.0427(0.0492) | Loss 8.9186(9.6735) | Error 0.0156(0.0143) Steps 760(765.28) | Grad Norm 4.3608(4.7331) | Total Time 0.00(0.00)\n",
      "Iter 11740 | Time 19.6744(19.7458) | Bit/dim 3.5516(3.5642) | Xent 0.0564(0.0484) | Loss 9.0412(9.4705) | Error 0.0189(0.0140) Steps 784(768.21) | Grad Norm 5.5674(4.6665) | Total Time 0.00(0.00)\n",
      "Iter 11750 | Time 20.1528(19.8321) | Bit/dim 3.5662(3.5643) | Xent 0.0662(0.0470) | Loss 8.9039(9.3337) | Error 0.0133(0.0136) Steps 766(770.12) | Grad Norm 3.9264(4.4703) | Total Time 0.00(0.00)\n",
      "Iter 11760 | Time 20.1360(19.8558) | Bit/dim 3.5952(3.5665) | Xent 0.0245(0.0461) | Loss 8.9958(9.2281) | Error 0.0056(0.0137) Steps 778(772.36) | Grad Norm 4.2921(4.6076) | Total Time 0.00(0.00)\n",
      "Iter 11770 | Time 19.9719(20.0229) | Bit/dim 3.5750(3.5682) | Xent 0.0497(0.0439) | Loss 9.0212(9.1517) | Error 0.0144(0.0130) Steps 790(771.86) | Grad Norm 5.2100(4.6069) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0214 | Time 97.1437, Epoch Time 1217.9354(1161.7226), Bit/dim 3.5811(best: 3.5833), Xent 1.9299, Loss 4.5461, Error 0.3296(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11780 | Time 20.6457(19.9826) | Bit/dim 3.5599(3.5644) | Xent 0.0480(0.0408) | Loss 8.9302(9.7570) | Error 0.0167(0.0125) Steps 766(772.10) | Grad Norm 5.2592(4.3123) | Total Time 0.00(0.00)\n",
      "Iter 11790 | Time 21.0785(19.9685) | Bit/dim 3.5374(3.5640) | Xent 0.0417(0.0408) | Loss 8.9219(9.5438) | Error 0.0133(0.0124) Steps 820(773.28) | Grad Norm 3.3857(4.1775) | Total Time 0.00(0.00)\n",
      "Iter 11800 | Time 19.6404(19.9845) | Bit/dim 3.5458(3.5638) | Xent 0.0388(0.0423) | Loss 9.0311(9.4033) | Error 0.0111(0.0125) Steps 784(773.17) | Grad Norm 2.6651(4.2890) | Total Time 0.00(0.00)\n",
      "Iter 11810 | Time 19.8498(20.0301) | Bit/dim 3.5349(3.5616) | Xent 0.0498(0.0413) | Loss 8.8695(9.2790) | Error 0.0200(0.0124) Steps 796(773.85) | Grad Norm 5.1128(4.3000) | Total Time 0.00(0.00)\n",
      "Iter 11820 | Time 19.9539(20.0810) | Bit/dim 3.5649(3.5615) | Xent 0.0338(0.0429) | Loss 8.9373(9.2025) | Error 0.0111(0.0132) Steps 772(777.18) | Grad Norm 3.5399(4.4472) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0215 | Time 101.7860, Epoch Time 1226.0071(1163.6511), Bit/dim 3.5922(best: 3.5811), Xent 1.9831, Loss 4.5837, Error 0.3335(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11830 | Time 19.4329(20.1680) | Bit/dim 3.5740(3.5626) | Xent 0.0480(0.0439) | Loss 8.9707(9.9776) | Error 0.0167(0.0137) Steps 790(783.84) | Grad Norm 5.3943(4.4983) | Total Time 0.00(0.00)\n",
      "Iter 11840 | Time 19.8001(20.1832) | Bit/dim 3.5500(3.5635) | Xent 0.0355(0.0436) | Loss 8.8427(9.7185) | Error 0.0133(0.0135) Steps 778(784.88) | Grad Norm 4.4187(4.3337) | Total Time 0.00(0.00)\n",
      "Iter 11850 | Time 20.0811(20.2083) | Bit/dim 3.5782(3.5642) | Xent 0.0496(0.0422) | Loss 9.0184(9.5203) | Error 0.0167(0.0132) Steps 790(784.73) | Grad Norm 4.6489(4.3379) | Total Time 0.00(0.00)\n",
      "Iter 11860 | Time 20.0881(20.1818) | Bit/dim 3.5666(3.5636) | Xent 0.0495(0.0430) | Loss 8.9078(9.3719) | Error 0.0156(0.0132) Steps 766(779.04) | Grad Norm 4.2902(4.2971) | Total Time 0.00(0.00)\n",
      "Iter 11870 | Time 19.7920(20.1469) | Bit/dim 3.5714(3.5631) | Xent 0.0486(0.0451) | Loss 9.0291(9.2643) | Error 0.0133(0.0138) Steps 754(776.66) | Grad Norm 4.0959(4.3207) | Total Time 0.00(0.00)\n",
      "Iter 11880 | Time 19.6990(20.1794) | Bit/dim 3.5618(3.5630) | Xent 0.0493(0.0451) | Loss 8.9054(9.1872) | Error 0.0167(0.0137) Steps 784(780.72) | Grad Norm 6.1857(4.4568) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0216 | Time 99.2603, Epoch Time 1235.6018(1165.8097), Bit/dim 3.5749(best: 3.5811), Xent 1.9005, Loss 4.5252, Error 0.3270(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11890 | Time 18.9298(20.1043) | Bit/dim 3.5692(3.5634) | Xent 0.0325(0.0443) | Loss 8.9526(9.7963) | Error 0.0067(0.0133) Steps 754(777.99) | Grad Norm 5.0003(4.5819) | Total Time 0.00(0.00)\n",
      "Iter 11900 | Time 19.5392(20.0675) | Bit/dim 3.5514(3.5638) | Xent 0.0450(0.0463) | Loss 8.8432(9.5678) | Error 0.0111(0.0135) Steps 742(771.77) | Grad Norm 4.3183(4.8255) | Total Time 0.00(0.00)\n",
      "Iter 11910 | Time 20.4948(20.0864) | Bit/dim 3.5423(3.5635) | Xent 0.0262(0.0426) | Loss 8.8898(9.3945) | Error 0.0067(0.0123) Steps 820(770.91) | Grad Norm 3.6354(4.5965) | Total Time 0.00(0.00)\n",
      "Iter 11920 | Time 19.6327(20.1693) | Bit/dim 3.5626(3.5642) | Xent 0.0373(0.0429) | Loss 8.7749(9.2726) | Error 0.0144(0.0127) Steps 754(773.23) | Grad Norm 4.1332(4.8095) | Total Time 0.00(0.00)\n",
      "Iter 11930 | Time 20.6471(20.0961) | Bit/dim 3.5618(3.5610) | Xent 0.0358(0.0411) | Loss 9.0137(9.1692) | Error 0.0078(0.0119) Steps 790(771.44) | Grad Norm 3.4901(4.6041) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0217 | Time 95.8890, Epoch Time 1220.3704(1167.4465), Bit/dim 3.5798(best: 3.5749), Xent 1.9371, Loss 4.5484, Error 0.3199(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11940 | Time 20.5022(20.0222) | Bit/dim 3.5713(3.5602) | Xent 0.0243(0.0394) | Loss 8.9622(9.8837) | Error 0.0089(0.0115) Steps 760(770.06) | Grad Norm 2.9197(4.2857) | Total Time 0.00(0.00)\n",
      "Iter 11950 | Time 20.5787(20.0938) | Bit/dim 3.5756(3.5606) | Xent 0.0392(0.0417) | Loss 9.0014(9.6360) | Error 0.0100(0.0119) Steps 778(771.13) | Grad Norm 4.8309(4.3278) | Total Time 0.00(0.00)\n",
      "Iter 11960 | Time 19.5428(20.0941) | Bit/dim 3.5553(3.5615) | Xent 0.0467(0.0413) | Loss 8.9480(9.4478) | Error 0.0133(0.0118) Steps 790(773.13) | Grad Norm 6.1887(4.4126) | Total Time 0.00(0.00)\n",
      "Iter 11970 | Time 19.5154(19.9165) | Bit/dim 3.5633(3.5597) | Xent 0.0606(0.0417) | Loss 9.0507(9.2987) | Error 0.0244(0.0124) Steps 772(771.43) | Grad Norm 7.0044(4.4097) | Total Time 0.00(0.00)\n",
      "Iter 11980 | Time 19.6426(19.9696) | Bit/dim 3.5649(3.5597) | Xent 0.0408(0.0409) | Loss 8.9563(9.2122) | Error 0.0100(0.0121) Steps 778(774.38) | Grad Norm 3.7861(4.3565) | Total Time 0.00(0.00)\n",
      "Iter 11990 | Time 19.7012(19.9085) | Bit/dim 3.5593(3.5597) | Xent 0.0272(0.0439) | Loss 8.8844(9.1377) | Error 0.0122(0.0128) Steps 778(778.06) | Grad Norm 4.6874(4.5200) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0218 | Time 99.3709, Epoch Time 1215.4083(1168.8853), Bit/dim 3.5848(best: 3.5749), Xent 1.9151, Loss 4.5424, Error 0.3230(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12000 | Time 20.2732(19.9362) | Bit/dim 3.5447(3.5600) | Xent 0.0388(0.0444) | Loss 8.8285(9.7737) | Error 0.0133(0.0132) Steps 808(778.62) | Grad Norm 5.1114(4.5671) | Total Time 0.00(0.00)\n",
      "Iter 12010 | Time 19.9534(19.9449) | Bit/dim 3.5832(3.5631) | Xent 0.0716(0.0442) | Loss 8.9576(9.5650) | Error 0.0256(0.0135) Steps 784(778.63) | Grad Norm 6.4949(4.6604) | Total Time 0.00(0.00)\n",
      "Iter 12020 | Time 19.9639(19.9953) | Bit/dim 3.5954(3.5622) | Xent 0.0360(0.0440) | Loss 9.1201(9.4139) | Error 0.0100(0.0132) Steps 754(778.44) | Grad Norm 4.2455(4.6246) | Total Time 0.00(0.00)\n",
      "Iter 12030 | Time 19.4124(19.9738) | Bit/dim 3.5580(3.5616) | Xent 0.0457(0.0458) | Loss 8.8406(9.2864) | Error 0.0144(0.0138) Steps 766(776.09) | Grad Norm 4.1926(4.6484) | Total Time 0.00(0.00)\n",
      "Iter 12040 | Time 20.0375(20.0570) | Bit/dim 3.5590(3.5602) | Xent 0.0594(0.0497) | Loss 8.8690(9.1875) | Error 0.0144(0.0145) Steps 760(774.68) | Grad Norm 5.3441(4.7737) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0219 | Time 100.7099, Epoch Time 1226.3573(1170.6095), Bit/dim 3.5785(best: 3.5749), Xent 1.8319, Loss 4.4945, Error 0.3247(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12050 | Time 21.0174(20.1308) | Bit/dim 3.5388(3.5619) | Xent 0.0341(0.0477) | Loss 8.9830(9.9190) | Error 0.0111(0.0140) Steps 802(776.95) | Grad Norm 4.3655(4.6330) | Total Time 0.00(0.00)\n",
      "Iter 12060 | Time 19.9628(20.1778) | Bit/dim 3.5537(3.5623) | Xent 0.0454(0.0477) | Loss 8.9112(9.6680) | Error 0.0133(0.0141) Steps 802(781.45) | Grad Norm 4.4917(4.6200) | Total Time 0.00(0.00)\n",
      "Iter 12070 | Time 20.1023(20.1518) | Bit/dim 3.5548(3.5623) | Xent 0.0411(0.0468) | Loss 8.9413(9.4787) | Error 0.0133(0.0138) Steps 778(782.08) | Grad Norm 3.2163(4.4692) | Total Time 0.00(0.00)\n",
      "Iter 12080 | Time 19.0784(20.0944) | Bit/dim 3.5527(3.5601) | Xent 0.0449(0.0447) | Loss 8.8773(9.3390) | Error 0.0144(0.0132) Steps 736(779.65) | Grad Norm 3.5508(4.4705) | Total Time 0.00(0.00)\n",
      "Iter 12090 | Time 20.5701(20.0935) | Bit/dim 3.5416(3.5600) | Xent 0.0500(0.0433) | Loss 8.8988(9.2304) | Error 0.0144(0.0129) Steps 796(777.20) | Grad Norm 5.7819(4.5690) | Total Time 0.00(0.00)\n",
      "Iter 12100 | Time 19.7199(20.1353) | Bit/dim 3.5749(3.5627) | Xent 0.0482(0.0441) | Loss 8.8547(9.1482) | Error 0.0133(0.0130) Steps 778(776.97) | Grad Norm 6.2798(4.9314) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0220 | Time 97.2853, Epoch Time 1229.3223(1172.3709), Bit/dim 3.5845(best: 3.5749), Xent 1.9070, Loss 4.5380, Error 0.3187(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12110 | Time 19.7087(20.0925) | Bit/dim 3.5706(3.5639) | Xent 0.0296(0.0431) | Loss 8.9439(9.7779) | Error 0.0089(0.0131) Steps 754(776.36) | Grad Norm 3.7098(4.9290) | Total Time 0.00(0.00)\n",
      "Iter 12120 | Time 20.1610(20.1392) | Bit/dim 3.5623(3.5623) | Xent 0.0610(0.0458) | Loss 8.8149(9.5618) | Error 0.0178(0.0134) Steps 766(774.34) | Grad Norm 5.6821(4.9502) | Total Time 0.00(0.00)\n",
      "Iter 12130 | Time 20.6948(20.0340) | Bit/dim 3.5583(3.5624) | Xent 0.0528(0.0453) | Loss 9.0029(9.4004) | Error 0.0189(0.0134) Steps 784(773.53) | Grad Norm 5.7707(4.7000) | Total Time 0.00(0.00)\n",
      "Iter 12140 | Time 19.5472(19.9535) | Bit/dim 3.5706(3.5626) | Xent 0.0248(0.0499) | Loss 8.8549(9.2817) | Error 0.0089(0.0150) Steps 754(771.66) | Grad Norm 6.2215(4.8611) | Total Time 0.00(0.00)\n",
      "Iter 12150 | Time 20.6484(19.9530) | Bit/dim 3.5959(3.5697) | Xent 0.0386(0.0515) | Loss 9.0402(9.2168) | Error 0.0133(0.0155) Steps 742(768.62) | Grad Norm 4.6266(5.0771) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0221 | Time 98.6133, Epoch Time 1217.9758(1173.7390), Bit/dim 3.5873(best: 3.5749), Xent 1.8999, Loss 4.5373, Error 0.3318(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12160 | Time 20.0808(19.9929) | Bit/dim 3.5646(3.5689) | Xent 0.0308(0.0522) | Loss 8.9597(9.9720) | Error 0.0100(0.0157) Steps 796(773.82) | Grad Norm 3.4236(5.2540) | Total Time 0.00(0.00)\n",
      "Iter 12170 | Time 20.2994(20.1570) | Bit/dim 3.5213(3.5668) | Xent 0.0471(0.0507) | Loss 8.9367(9.7039) | Error 0.0144(0.0152) Steps 772(776.00) | Grad Norm 5.2533(5.1653) | Total Time 0.00(0.00)\n",
      "Iter 12180 | Time 19.3187(20.1200) | Bit/dim 3.5469(3.5642) | Xent 0.0391(0.0489) | Loss 8.7125(9.4937) | Error 0.0144(0.0147) Steps 772(776.67) | Grad Norm 6.4531(5.1408) | Total Time 0.00(0.00)\n",
      "Iter 12190 | Time 20.7513(20.1697) | Bit/dim 3.5947(3.5660) | Xent 0.0622(0.0522) | Loss 8.9902(9.3516) | Error 0.0222(0.0158) Steps 748(776.66) | Grad Norm 4.8885(5.4738) | Total Time 0.00(0.00)\n",
      "Iter 12200 | Time 20.6100(20.2050) | Bit/dim 3.5723(3.5673) | Xent 0.0356(0.0512) | Loss 8.9737(9.2562) | Error 0.0089(0.0156) Steps 760(776.56) | Grad Norm 3.8587(5.3702) | Total Time 0.00(0.00)\n",
      "Iter 12210 | Time 20.0782(20.2219) | Bit/dim 3.6028(3.5660) | Xent 0.0347(0.0476) | Loss 8.9038(9.1668) | Error 0.0100(0.0146) Steps 772(777.56) | Grad Norm 2.9544(5.0270) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0222 | Time 98.3560, Epoch Time 1234.1163(1175.5503), Bit/dim 3.5779(best: 3.5749), Xent 1.9765, Loss 4.5662, Error 0.3312(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12220 | Time 20.8827(20.1466) | Bit/dim 3.5660(3.5648) | Xent 0.0540(0.0458) | Loss 9.0849(9.7805) | Error 0.0167(0.0141) Steps 808(778.01) | Grad Norm 3.8168(4.6082) | Total Time 0.00(0.00)\n",
      "Iter 12230 | Time 20.1862(20.1211) | Bit/dim 3.5493(3.5628) | Xent 0.0368(0.0446) | Loss 8.8181(9.5413) | Error 0.0133(0.0138) Steps 802(776.81) | Grad Norm 3.2247(4.3944) | Total Time 0.00(0.00)\n",
      "Iter 12240 | Time 20.5179(20.1792) | Bit/dim 3.5833(3.5601) | Xent 0.0464(0.0421) | Loss 8.9220(9.3610) | Error 0.0133(0.0130) Steps 748(773.40) | Grad Norm 3.3736(4.2615) | Total Time 0.00(0.00)\n",
      "Iter 12250 | Time 19.7098(20.1526) | Bit/dim 3.5735(3.5602) | Xent 0.0959(0.0471) | Loss 9.0650(9.2555) | Error 0.0278(0.0142) Steps 778(772.61) | Grad Norm 7.7367(4.7544) | Total Time 0.00(0.00)\n",
      "Iter 12260 | Time 19.9233(20.1450) | Bit/dim 3.5576(3.5619) | Xent 0.0603(0.0488) | Loss 8.9430(9.1705) | Error 0.0167(0.0147) Steps 772(776.20) | Grad Norm 7.3584(4.8005) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0223 | Time 99.4118, Epoch Time 1225.0380(1177.0350), Bit/dim 3.5784(best: 3.5749), Xent 1.9098, Loss 4.5333, Error 0.3240(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12270 | Time 19.4189(20.0787) | Bit/dim 3.5757(3.5619) | Xent 0.0333(0.0471) | Loss 8.9337(9.9174) | Error 0.0100(0.0141) Steps 784(778.52) | Grad Norm 3.7050(4.7744) | Total Time 0.00(0.00)\n",
      "Iter 12280 | Time 19.9879(20.0595) | Bit/dim 3.5714(3.5613) | Xent 0.0362(0.0459) | Loss 8.9159(9.6616) | Error 0.0078(0.0136) Steps 796(778.57) | Grad Norm 3.7303(4.8520) | Total Time 0.00(0.00)\n",
      "Iter 12290 | Time 20.6650(20.0889) | Bit/dim 3.5475(3.5596) | Xent 0.0269(0.0434) | Loss 8.9707(9.4666) | Error 0.0044(0.0129) Steps 778(774.92) | Grad Norm 4.4957(4.6322) | Total Time 0.00(0.00)\n",
      "Iter 12300 | Time 20.3842(20.1464) | Bit/dim 3.5637(3.5603) | Xent 0.0447(0.0425) | Loss 8.8587(9.3234) | Error 0.0122(0.0127) Steps 742(777.18) | Grad Norm 4.1071(4.5007) | Total Time 0.00(0.00)\n",
      "Iter 12310 | Time 21.3995(20.2691) | Bit/dim 3.5607(3.5602) | Xent 0.0440(0.0409) | Loss 8.8812(9.2201) | Error 0.0133(0.0122) Steps 826(779.04) | Grad Norm 5.8907(4.4497) | Total Time 0.00(0.00)\n",
      "Iter 12320 | Time 19.6557(20.2891) | Bit/dim 3.5625(3.5621) | Xent 0.0474(0.0398) | Loss 8.9432(9.1433) | Error 0.0178(0.0118) Steps 760(778.57) | Grad Norm 4.8229(4.2887) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0224 | Time 99.5821, Epoch Time 1234.8148(1178.7684), Bit/dim 3.5811(best: 3.5749), Xent 2.0113, Loss 4.5868, Error 0.3260(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12330 | Time 19.8328(20.3083) | Bit/dim 3.5578(3.5598) | Xent 0.0382(0.0415) | Loss 8.9465(9.7806) | Error 0.0122(0.0121) Steps 790(780.02) | Grad Norm 3.5947(4.2297) | Total Time 0.00(0.00)\n",
      "Iter 12340 | Time 21.5133(20.3509) | Bit/dim 3.5758(3.5635) | Xent 0.0208(0.0405) | Loss 8.9356(9.5668) | Error 0.0056(0.0117) Steps 820(782.99) | Grad Norm 4.1454(4.2475) | Total Time 0.00(0.00)\n",
      "Iter 12350 | Time 20.3090(20.3398) | Bit/dim 3.5306(3.5614) | Xent 0.0530(0.0409) | Loss 8.8952(9.3959) | Error 0.0144(0.0118) Steps 796(782.60) | Grad Norm 3.9373(4.1965) | Total Time 0.00(0.00)\n",
      "Iter 12360 | Time 20.2030(20.2676) | Bit/dim 3.5523(3.5592) | Xent 0.1032(0.0444) | Loss 8.9963(9.2745) | Error 0.0289(0.0132) Steps 772(778.70) | Grad Norm 7.1944(4.3426) | Total Time 0.00(0.00)\n",
      "Iter 12370 | Time 20.9033(20.2945) | Bit/dim 3.5500(3.5590) | Xent 0.0912(0.0481) | Loss 8.9489(9.1918) | Error 0.0233(0.0140) Steps 760(777.77) | Grad Norm 6.9965(4.7890) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0225 | Time 99.9472, Epoch Time 1238.8215(1180.5700), Bit/dim 3.5872(best: 3.5749), Xent 1.9165, Loss 4.5454, Error 0.3251(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12380 | Time 19.7179(20.3019) | Bit/dim 3.5383(3.5605) | Xent 0.0757(0.0505) | Loss 8.8381(9.9502) | Error 0.0211(0.0149) Steps 778(776.60) | Grad Norm 5.0348(4.9877) | Total Time 0.00(0.00)\n",
      "Iter 12390 | Time 20.7548(20.2754) | Bit/dim 3.5423(3.5629) | Xent 0.0285(0.0491) | Loss 8.8108(9.6855) | Error 0.0067(0.0144) Steps 808(779.05) | Grad Norm 3.8371(4.9136) | Total Time 0.00(0.00)\n",
      "Iter 12400 | Time 20.4278(20.2570) | Bit/dim 3.5749(3.5637) | Xent 0.0719(0.0519) | Loss 8.9682(9.4912) | Error 0.0133(0.0152) Steps 796(780.16) | Grad Norm 5.6155(5.0353) | Total Time 0.00(0.00)\n",
      "Iter 12410 | Time 20.9888(20.2789) | Bit/dim 3.5607(3.5642) | Xent 0.0363(0.0513) | Loss 9.0499(9.3485) | Error 0.0078(0.0150) Steps 742(780.13) | Grad Norm 2.7506(4.7720) | Total Time 0.00(0.00)\n",
      "Iter 12420 | Time 20.6672(20.3256) | Bit/dim 3.5589(3.5646) | Xent 0.0812(0.0514) | Loss 9.0851(9.2522) | Error 0.0289(0.0151) Steps 814(781.68) | Grad Norm 5.1072(4.5927) | Total Time 0.00(0.00)\n",
      "Iter 12430 | Time 21.1940(20.3188) | Bit/dim 3.5618(3.5631) | Xent 0.0557(0.0508) | Loss 8.9954(9.1706) | Error 0.0189(0.0154) Steps 814(784.97) | Grad Norm 6.2563(4.8027) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0226 | Time 100.4174, Epoch Time 1236.9303(1182.2608), Bit/dim 3.5809(best: 3.5749), Xent 1.8678, Loss 4.5148, Error 0.3248(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12440 | Time 21.1868(20.3910) | Bit/dim 3.5857(3.5628) | Xent 0.0356(0.0489) | Loss 8.9839(9.8282) | Error 0.0111(0.0147) Steps 802(785.48) | Grad Norm 5.1081(4.9232) | Total Time 0.00(0.00)\n",
      "Iter 12450 | Time 20.3606(20.3311) | Bit/dim 3.5804(3.5596) | Xent 0.0455(0.0467) | Loss 9.0562(9.5932) | Error 0.0133(0.0143) Steps 814(783.71) | Grad Norm 3.1097(4.7793) | Total Time 0.00(0.00)\n",
      "Iter 12460 | Time 20.5807(20.3023) | Bit/dim 3.5549(3.5584) | Xent 0.0580(0.0462) | Loss 8.8869(9.4216) | Error 0.0133(0.0138) Steps 748(780.31) | Grad Norm 4.0246(4.6164) | Total Time 0.00(0.00)\n",
      "Iter 12470 | Time 19.5510(20.3057) | Bit/dim 3.5457(3.5589) | Xent 0.0430(0.0452) | Loss 8.9566(9.2909) | Error 0.0156(0.0135) Steps 784(782.63) | Grad Norm 3.5562(4.3552) | Total Time 0.00(0.00)\n",
      "Iter 12480 | Time 20.5311(20.2733) | Bit/dim 3.5585(3.5617) | Xent 0.0469(0.0491) | Loss 8.9226(9.2029) | Error 0.0144(0.0150) Steps 802(783.76) | Grad Norm 7.9636(5.0584) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0227 | Time 99.1604, Epoch Time 1237.9349(1183.9310), Bit/dim 3.5867(best: 3.5749), Xent 1.9312, Loss 4.5523, Error 0.3245(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12490 | Time 20.0127(20.2146) | Bit/dim 3.6083(3.5643) | Xent 0.0393(0.0505) | Loss 9.0471(9.9611) | Error 0.0111(0.0154) Steps 808(783.37) | Grad Norm 5.0287(5.1697) | Total Time 0.00(0.00)\n",
      "Iter 12500 | Time 20.5996(20.2462) | Bit/dim 3.5504(3.5654) | Xent 0.0494(0.0522) | Loss 8.9468(9.6993) | Error 0.0167(0.0159) Steps 784(782.86) | Grad Norm 5.1925(5.2053) | Total Time 0.00(0.00)\n",
      "Iter 12510 | Time 20.0222(20.2067) | Bit/dim 3.5969(3.5647) | Xent 0.0671(0.0526) | Loss 9.0320(9.5076) | Error 0.0167(0.0161) Steps 784(783.70) | Grad Norm 6.4914(5.2030) | Total Time 0.00(0.00)\n",
      "Iter 12520 | Time 20.5796(20.2468) | Bit/dim 3.5766(3.5647) | Xent 0.0547(0.0580) | Loss 8.9330(9.3750) | Error 0.0178(0.0175) Steps 790(786.95) | Grad Norm 5.3973(5.6898) | Total Time 0.00(0.00)\n",
      "Iter 12530 | Time 19.7237(20.1891) | Bit/dim 3.6133(3.5704) | Xent 0.0683(0.0649) | Loss 9.1254(9.2952) | Error 0.0200(0.0195) Steps 754(783.43) | Grad Norm 5.8624(5.9316) | Total Time 0.00(0.00)\n",
      "Iter 12540 | Time 20.3656(20.2731) | Bit/dim 3.5867(3.5718) | Xent 0.0452(0.0661) | Loss 8.8528(9.2245) | Error 0.0167(0.0200) Steps 718(783.10) | Grad Norm 4.2127(5.6828) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0228 | Time 99.0468, Epoch Time 1233.1012(1185.4061), Bit/dim 3.5889(best: 3.5749), Xent 1.8522, Loss 4.5150, Error 0.3286(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12550 | Time 20.4761(20.3139) | Bit/dim 3.5628(3.5708) | Xent 0.0698(0.0619) | Loss 8.9291(9.8646) | Error 0.0200(0.0187) Steps 766(782.29) | Grad Norm 4.2621(5.4001) | Total Time 0.00(0.00)\n",
      "Iter 12560 | Time 20.7474(20.3610) | Bit/dim 3.5873(3.5666) | Xent 0.0578(0.0569) | Loss 8.9479(9.6124) | Error 0.0156(0.0171) Steps 730(784.68) | Grad Norm 3.0712(5.1304) | Total Time 0.00(0.00)\n",
      "Iter 12570 | Time 20.9195(20.4222) | Bit/dim 3.5990(3.5638) | Xent 0.0311(0.0527) | Loss 8.9970(9.4383) | Error 0.0111(0.0159) Steps 820(785.42) | Grad Norm 3.2656(4.8093) | Total Time 0.00(0.00)\n",
      "Iter 12580 | Time 20.6311(20.4443) | Bit/dim 3.5424(3.5609) | Xent 0.0231(0.0469) | Loss 9.0024(9.3044) | Error 0.0078(0.0143) Steps 808(786.14) | Grad Norm 2.8564(4.3524) | Total Time 0.00(0.00)\n",
      "Iter 12590 | Time 20.3165(20.3801) | Bit/dim 3.5491(3.5579) | Xent 0.0287(0.0429) | Loss 8.9298(9.1912) | Error 0.0089(0.0129) Steps 742(782.32) | Grad Norm 3.2943(3.9827) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0229 | Time 98.8368, Epoch Time 1240.7211(1187.0655), Bit/dim 3.5709(best: 3.5749), Xent 2.0541, Loss 4.5980, Error 0.3263(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12600 | Time 20.1034(20.2474) | Bit/dim 3.5701(3.5551) | Xent 0.0240(0.0396) | Loss 8.8149(9.9199) | Error 0.0100(0.0121) Steps 754(779.23) | Grad Norm 2.9152(3.8289) | Total Time 0.00(0.00)\n",
      "Iter 12610 | Time 20.0539(20.2630) | Bit/dim 3.5577(3.5546) | Xent 0.0222(0.0373) | Loss 8.8966(9.6522) | Error 0.0044(0.0110) Steps 760(779.58) | Grad Norm 2.3861(3.5970) | Total Time 0.00(0.00)\n",
      "Iter 12620 | Time 20.5851(20.3149) | Bit/dim 3.5493(3.5532) | Xent 0.0160(0.0349) | Loss 8.8283(9.4570) | Error 0.0033(0.0104) Steps 760(781.89) | Grad Norm 2.7874(3.4689) | Total Time 0.00(0.00)\n",
      "Iter 12630 | Time 20.5655(20.2726) | Bit/dim 3.5361(3.5513) | Xent 0.0219(0.0330) | Loss 8.9403(9.3073) | Error 0.0067(0.0098) Steps 778(781.81) | Grad Norm 3.9321(3.5166) | Total Time 0.00(0.00)\n",
      "Iter 12640 | Time 20.2262(20.3319) | Bit/dim 3.5719(3.5519) | Xent 0.0893(0.0392) | Loss 9.0758(9.2152) | Error 0.0222(0.0112) Steps 766(784.97) | Grad Norm 6.7330(3.7970) | Total Time 0.00(0.00)\n",
      "Iter 12650 | Time 20.2652(20.2547) | Bit/dim 3.5644(3.5555) | Xent 0.0358(0.0393) | Loss 8.9428(9.1430) | Error 0.0100(0.0116) Steps 790(785.43) | Grad Norm 3.3121(3.7393) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0230 | Time 98.0202, Epoch Time 1233.7564(1188.4663), Bit/dim 3.5763(best: 3.5709), Xent 1.9345, Loss 4.5435, Error 0.3313(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12660 | Time 19.0930(20.1470) | Bit/dim 3.5730(3.5561) | Xent 0.0099(0.0370) | Loss 8.8961(9.7870) | Error 0.0022(0.0106) Steps 766(781.05) | Grad Norm 2.4482(3.5337) | Total Time 0.00(0.00)\n",
      "Iter 12670 | Time 21.1094(20.1538) | Bit/dim 3.5354(3.5516) | Xent 0.0397(0.0375) | Loss 8.9345(9.5586) | Error 0.0122(0.0107) Steps 760(783.12) | Grad Norm 4.2247(3.6482) | Total Time 0.00(0.00)\n",
      "Iter 12680 | Time 20.2123(20.1709) | Bit/dim 3.5881(3.5541) | Xent 0.0668(0.0414) | Loss 9.1105(9.4001) | Error 0.0178(0.0120) Steps 766(781.06) | Grad Norm 9.7265(4.4617) | Total Time 0.00(0.00)\n",
      "Iter 12690 | Time 20.6478(20.2108) | Bit/dim 3.5379(3.5550) | Xent 0.0442(0.0444) | Loss 8.9499(9.2767) | Error 0.0133(0.0130) Steps 826(780.26) | Grad Norm 4.3732(4.8633) | Total Time 0.00(0.00)\n",
      "Iter 12700 | Time 20.6513(20.1878) | Bit/dim 3.5553(3.5563) | Xent 0.0848(0.0535) | Loss 9.0536(9.1990) | Error 0.0244(0.0158) Steps 784(779.56) | Grad Norm 6.2097(5.6017) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0231 | Time 96.7176, Epoch Time 1226.1109(1189.5956), Bit/dim 3.5834(best: 3.5709), Xent 1.8647, Loss 4.5157, Error 0.3414(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12710 | Time 19.7488(20.1768) | Bit/dim 3.5448(3.5595) | Xent 0.0595(0.0560) | Loss 8.7051(9.9302) | Error 0.0167(0.0162) Steps 754(777.82) | Grad Norm 3.2214(5.1296) | Total Time 0.00(0.00)\n",
      "Iter 12720 | Time 19.8631(20.1288) | Bit/dim 3.5780(3.5578) | Xent 0.0358(0.0511) | Loss 8.9958(9.6503) | Error 0.0100(0.0149) Steps 802(774.29) | Grad Norm 3.8420(4.8934) | Total Time 0.00(0.00)\n",
      "Iter 12730 | Time 20.5954(20.1013) | Bit/dim 3.5635(3.5588) | Xent 0.0554(0.0479) | Loss 8.9373(9.4546) | Error 0.0133(0.0139) Steps 808(775.34) | Grad Norm 4.7633(4.7879) | Total Time 0.00(0.00)\n",
      "Iter 12740 | Time 21.3171(20.2420) | Bit/dim 3.5467(3.5596) | Xent 0.0488(0.0463) | Loss 8.9192(9.3164) | Error 0.0144(0.0135) Steps 760(774.15) | Grad Norm 4.0646(4.6618) | Total Time 0.00(0.00)\n",
      "Iter 12750 | Time 20.0326(20.2455) | Bit/dim 3.5594(3.5606) | Xent 0.0403(0.0428) | Loss 8.8976(9.2106) | Error 0.0122(0.0126) Steps 754(775.98) | Grad Norm 3.0476(4.4611) | Total Time 0.00(0.00)\n",
      "Iter 12760 | Time 20.8373(20.2796) | Bit/dim 3.5863(3.5575) | Xent 0.0495(0.0423) | Loss 8.8243(9.1264) | Error 0.0156(0.0127) Steps 778(775.79) | Grad Norm 3.3811(4.1923) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0232 | Time 98.7634, Epoch Time 1232.5365(1190.8838), Bit/dim 3.5756(best: 3.5709), Xent 1.9803, Loss 4.5657, Error 0.3304(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12770 | Time 20.0757(20.2590) | Bit/dim 3.5133(3.5567) | Xent 0.0292(0.0384) | Loss 8.8345(9.7744) | Error 0.0044(0.0116) Steps 808(776.32) | Grad Norm 2.4678(3.9339) | Total Time 0.00(0.00)\n",
      "Iter 12780 | Time 21.7894(20.3186) | Bit/dim 3.5962(3.5554) | Xent 0.0836(0.0411) | Loss 9.0775(9.5544) | Error 0.0211(0.0122) Steps 850(780.31) | Grad Norm 7.1906(4.0893) | Total Time 0.00(0.00)\n",
      "Iter 12790 | Time 21.2945(20.4348) | Bit/dim 3.5859(3.5564) | Xent 0.0511(0.0430) | Loss 9.0387(9.3960) | Error 0.0167(0.0128) Steps 784(781.86) | Grad Norm 4.2804(4.2301) | Total Time 0.00(0.00)\n",
      "Iter 12800 | Time 20.9906(20.4337) | Bit/dim 3.5638(3.5565) | Xent 0.0450(0.0416) | Loss 9.0204(9.2715) | Error 0.0111(0.0126) Steps 802(785.41) | Grad Norm 3.6069(4.2627) | Total Time 0.00(0.00)\n",
      "Iter 12810 | Time 21.3467(20.4755) | Bit/dim 3.6032(3.5589) | Xent 0.0553(0.0452) | Loss 9.0102(9.1919) | Error 0.0178(0.0132) Steps 784(786.31) | Grad Norm 5.6608(4.6412) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0233 | Time 98.1914, Epoch Time 1247.0951(1192.5702), Bit/dim 3.5823(best: 3.5709), Xent 1.8631, Loss 4.5139, Error 0.3382(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12820 | Time 20.2925(20.4848) | Bit/dim 3.5548(3.5566) | Xent 0.0477(0.0476) | Loss 8.8362(9.9404) | Error 0.0144(0.0139) Steps 778(785.42) | Grad Norm 4.6319(4.7414) | Total Time 0.00(0.00)\n",
      "Iter 12830 | Time 20.3061(20.4529) | Bit/dim 3.5704(3.5586) | Xent 0.0520(0.0463) | Loss 8.8693(9.6772) | Error 0.0178(0.0136) Steps 748(784.95) | Grad Norm 5.4961(4.7080) | Total Time 0.00(0.00)\n",
      "Iter 12840 | Time 20.8914(20.4849) | Bit/dim 3.5668(3.5567) | Xent 0.0318(0.0446) | Loss 9.0072(9.4862) | Error 0.0078(0.0130) Steps 790(787.65) | Grad Norm 3.6726(4.5344) | Total Time 0.00(0.00)\n",
      "Iter 12850 | Time 20.0300(20.4608) | Bit/dim 3.5675(3.5590) | Xent 0.0483(0.0465) | Loss 8.9781(9.3460) | Error 0.0156(0.0136) Steps 778(784.58) | Grad Norm 5.7073(4.7580) | Total Time 0.00(0.00)\n",
      "Iter 12860 | Time 19.8108(20.3742) | Bit/dim 3.5452(3.5593) | Xent 0.0403(0.0485) | Loss 8.8861(9.2378) | Error 0.0133(0.0143) Steps 772(784.49) | Grad Norm 5.5327(4.8748) | Total Time 0.00(0.00)\n",
      "Iter 12870 | Time 20.1784(20.3344) | Bit/dim 3.5680(3.5613) | Xent 0.0529(0.0505) | Loss 8.8630(9.1584) | Error 0.0156(0.0147) Steps 790(785.12) | Grad Norm 6.0843(4.9303) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0234 | Time 98.7409, Epoch Time 1238.4281(1193.9459), Bit/dim 3.5802(best: 3.5709), Xent 1.8547, Loss 4.5076, Error 0.3336(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12880 | Time 20.2132(20.4480) | Bit/dim 3.5312(3.5596) | Xent 0.0517(0.0495) | Loss 8.8775(9.8061) | Error 0.0178(0.0147) Steps 784(788.49) | Grad Norm 5.6976(4.7363) | Total Time 0.00(0.00)\n",
      "Iter 12890 | Time 20.8481(20.5040) | Bit/dim 3.5363(3.5576) | Xent 0.0527(0.0485) | Loss 8.9907(9.5765) | Error 0.0156(0.0141) Steps 814(790.99) | Grad Norm 3.8032(4.7206) | Total Time 0.00(0.00)\n",
      "Iter 12900 | Time 20.1755(20.5291) | Bit/dim 3.5868(3.5590) | Xent 0.0500(0.0479) | Loss 8.8542(9.4048) | Error 0.0133(0.0138) Steps 760(788.36) | Grad Norm 3.9675(4.5457) | Total Time 0.00(0.00)\n",
      "Iter 12910 | Time 21.2459(20.5900) | Bit/dim 3.5523(3.5571) | Xent 0.0264(0.0473) | Loss 8.9130(9.2781) | Error 0.0067(0.0134) Steps 772(786.07) | Grad Norm 5.4258(4.6453) | Total Time 0.00(0.00)\n",
      "Iter 12920 | Time 20.1135(20.4916) | Bit/dim 3.5605(3.5574) | Xent 0.0220(0.0452) | Loss 8.9095(9.1798) | Error 0.0078(0.0130) Steps 778(786.03) | Grad Norm 3.0372(4.4154) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0235 | Time 100.3037, Epoch Time 1254.0410(1195.7488), Bit/dim 3.5725(best: 3.5709), Xent 1.9823, Loss 4.5637, Error 0.3321(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12930 | Time 20.7816(20.4905) | Bit/dim 3.5419(3.5580) | Xent 0.0481(0.0437) | Loss 8.8835(9.9376) | Error 0.0178(0.0124) Steps 814(788.13) | Grad Norm 4.8753(4.1971) | Total Time 0.00(0.00)\n",
      "Iter 12940 | Time 21.3061(20.4424) | Bit/dim 3.5344(3.5542) | Xent 0.0429(0.0396) | Loss 8.9035(9.6637) | Error 0.0122(0.0114) Steps 838(787.73) | Grad Norm 4.4960(3.9794) | Total Time 0.00(0.00)\n",
      "Iter 12950 | Time 20.6078(20.4501) | Bit/dim 3.5654(3.5548) | Xent 0.0259(0.0364) | Loss 8.9874(9.4745) | Error 0.0100(0.0107) Steps 754(786.37) | Grad Norm 3.2180(3.9083) | Total Time 0.00(0.00)\n",
      "Iter 12960 | Time 20.8776(20.6407) | Bit/dim 3.5423(3.5544) | Xent 0.0528(0.0385) | Loss 9.0552(9.3332) | Error 0.0133(0.0115) Steps 790(790.81) | Grad Norm 4.1837(3.9956) | Total Time 0.00(0.00)\n",
      "Iter 12970 | Time 20.2814(20.5916) | Bit/dim 3.5335(3.5510) | Xent 0.0395(0.0364) | Loss 8.9448(9.2201) | Error 0.0133(0.0109) Steps 796(791.70) | Grad Norm 4.3915(3.8820) | Total Time 0.00(0.00)\n",
      "Iter 12980 | Time 21.2965(20.5565) | Bit/dim 3.5782(3.5531) | Xent 0.0349(0.0392) | Loss 8.9816(9.1386) | Error 0.0122(0.0119) Steps 766(790.93) | Grad Norm 3.8065(4.0954) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0236 | Time 100.2664, Epoch Time 1252.7658(1197.4593), Bit/dim 3.5828(best: 3.5709), Xent 2.0195, Loss 4.5925, Error 0.3293(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12990 | Time 20.4621(20.5330) | Bit/dim 3.5600(3.5581) | Xent 0.0395(0.0388) | Loss 8.9817(9.8165) | Error 0.0122(0.0116) Steps 838(793.18) | Grad Norm 3.1146(4.0761) | Total Time 0.00(0.00)\n",
      "Iter 13000 | Time 20.7838(20.5735) | Bit/dim 3.4999(3.5560) | Xent 0.0480(0.0387) | Loss 8.7939(9.5837) | Error 0.0133(0.0115) Steps 814(791.96) | Grad Norm 4.9005(4.1684) | Total Time 0.00(0.00)\n",
      "Iter 13010 | Time 22.2404(20.6057) | Bit/dim 3.5741(3.5560) | Xent 0.0309(0.0386) | Loss 9.0329(9.4106) | Error 0.0089(0.0117) Steps 844(792.14) | Grad Norm 3.4639(4.1041) | Total Time 0.00(0.00)\n",
      "Iter 13020 | Time 21.0277(20.6414) | Bit/dim 3.5542(3.5555) | Xent 0.0965(0.0423) | Loss 8.9751(9.2863) | Error 0.0311(0.0126) Steps 784(792.40) | Grad Norm 8.0311(4.4377) | Total Time 0.00(0.00)\n",
      "Iter 13030 | Time 21.6682(20.7004) | Bit/dim 3.5610(3.5580) | Xent 0.1034(0.0480) | Loss 9.0827(9.2089) | Error 0.0244(0.0142) Steps 844(794.08) | Grad Norm 10.2966(4.9551) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0237 | Time 101.7626, Epoch Time 1262.3793(1199.4069), Bit/dim 3.5840(best: 3.5709), Xent 1.9348, Loss 4.5514, Error 0.3338(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13040 | Time 21.1437(20.7445) | Bit/dim 3.5551(3.5615) | Xent 0.0459(0.0504) | Loss 9.0391(9.9878) | Error 0.0167(0.0149) Steps 802(798.00) | Grad Norm 5.8936(4.9840) | Total Time 0.00(0.00)\n",
      "Iter 13050 | Time 21.7549(20.7154) | Bit/dim 3.5810(3.5651) | Xent 0.0629(0.0516) | Loss 9.0489(9.7293) | Error 0.0178(0.0156) Steps 820(799.19) | Grad Norm 3.2982(4.9586) | Total Time 0.00(0.00)\n",
      "Iter 13060 | Time 21.0480(20.7263) | Bit/dim 3.5726(3.5628) | Xent 0.0525(0.0526) | Loss 9.0970(9.5316) | Error 0.0144(0.0161) Steps 790(798.59) | Grad Norm 4.2897(4.8941) | Total Time 0.00(0.00)\n",
      "Iter 13070 | Time 21.4796(20.8019) | Bit/dim 3.5474(3.5618) | Xent 0.0470(0.0522) | Loss 8.9269(9.3735) | Error 0.0122(0.0159) Steps 778(798.19) | Grad Norm 4.7905(4.8821) | Total Time 0.00(0.00)\n",
      "Iter 13080 | Time 20.9102(20.7844) | Bit/dim 3.5537(3.5612) | Xent 0.0473(0.0509) | Loss 9.0402(9.2555) | Error 0.0156(0.0155) Steps 808(796.94) | Grad Norm 5.2547(5.1701) | Total Time 0.00(0.00)\n",
      "Iter 13090 | Time 20.6878(20.7770) | Bit/dim 3.5414(3.5604) | Xent 0.0645(0.0532) | Loss 8.9564(9.1675) | Error 0.0189(0.0156) Steps 814(797.86) | Grad Norm 3.7864(5.3207) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0238 | Time 99.3804, Epoch Time 1262.7492(1201.3072), Bit/dim 3.5854(best: 3.5709), Xent 1.9143, Loss 4.5426, Error 0.3344(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13100 | Time 21.2778(20.7285) | Bit/dim 3.5206(3.5598) | Xent 0.0885(0.0551) | Loss 8.9183(9.8439) | Error 0.0256(0.0161) Steps 802(797.13) | Grad Norm 7.8247(5.3440) | Total Time 0.00(0.00)\n",
      "Iter 13110 | Time 22.3807(20.8496) | Bit/dim 3.5787(3.5625) | Xent 0.0768(0.0615) | Loss 9.0607(9.6254) | Error 0.0233(0.0176) Steps 832(800.15) | Grad Norm 5.9690(5.5272) | Total Time 0.00(0.00)\n",
      "Iter 13120 | Time 20.9193(20.9931) | Bit/dim 3.5354(3.5597) | Xent 0.0451(0.0596) | Loss 9.0037(9.4629) | Error 0.0133(0.0170) Steps 802(803.41) | Grad Norm 3.5794(5.1282) | Total Time 0.00(0.00)\n",
      "Iter 13130 | Time 20.9071(20.9194) | Bit/dim 3.5536(3.5595) | Xent 0.0384(0.0564) | Loss 8.9268(9.3394) | Error 0.0122(0.0163) Steps 790(802.73) | Grad Norm 2.9396(4.7017) | Total Time 0.00(0.00)\n",
      "Iter 13140 | Time 21.1885(20.9080) | Bit/dim 3.5510(3.5593) | Xent 0.0302(0.0505) | Loss 9.0193(9.2379) | Error 0.0122(0.0150) Steps 820(804.17) | Grad Norm 4.3854(4.5000) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0239 | Time 100.7604, Epoch Time 1276.1084(1203.5512), Bit/dim 3.5728(best: 3.5709), Xent 1.9471, Loss 4.5464, Error 0.3204(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13150 | Time 21.5646(20.9952) | Bit/dim 3.5686(3.5580) | Xent 0.0343(0.0464) | Loss 9.1212(9.9924) | Error 0.0089(0.0136) Steps 814(803.98) | Grad Norm 4.1608(4.2881) | Total Time 0.00(0.00)\n",
      "Iter 13160 | Time 21.3004(21.0280) | Bit/dim 3.5548(3.5558) | Xent 0.0417(0.0446) | Loss 8.9120(9.7089) | Error 0.0100(0.0130) Steps 832(804.89) | Grad Norm 3.3638(4.0424) | Total Time 0.00(0.00)\n",
      "Iter 13170 | Time 20.9041(21.0705) | Bit/dim 3.5487(3.5562) | Xent 0.0741(0.0448) | Loss 8.9571(9.5104) | Error 0.0211(0.0131) Steps 814(802.67) | Grad Norm 3.8922(3.9210) | Total Time 0.00(0.00)\n",
      "Iter 13180 | Time 20.4820(21.0651) | Bit/dim 3.5491(3.5580) | Xent 0.0528(0.0439) | Loss 8.9169(9.3684) | Error 0.0111(0.0125) Steps 790(802.89) | Grad Norm 3.7785(3.8393) | Total Time 0.00(0.00)\n",
      "Iter 13190 | Time 20.5060(21.0928) | Bit/dim 3.5293(3.5557) | Xent 0.0750(0.0446) | Loss 8.9703(9.2606) | Error 0.0211(0.0127) Steps 814(806.55) | Grad Norm 7.9958(4.0887) | Total Time 0.00(0.00)\n",
      "Iter 13200 | Time 20.9394(21.1072) | Bit/dim 3.5709(3.5554) | Xent 0.0569(0.0462) | Loss 8.9868(9.1777) | Error 0.0133(0.0133) Steps 814(803.75) | Grad Norm 5.5527(4.3600) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0240 | Time 100.4895, Epoch Time 1284.3833(1205.9762), Bit/dim 3.5818(best: 3.5709), Xent 1.9186, Loss 4.5411, Error 0.3284(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13210 | Time 20.2992(21.0099) | Bit/dim 3.5464(3.5575) | Xent 0.0278(0.0435) | Loss 8.8986(9.7841) | Error 0.0078(0.0127) Steps 796(799.64) | Grad Norm 3.7128(4.3911) | Total Time 0.00(0.00)\n",
      "Iter 13220 | Time 22.0282(20.9773) | Bit/dim 3.5423(3.5546) | Xent 0.0301(0.0422) | Loss 8.8313(9.5496) | Error 0.0078(0.0122) Steps 784(798.01) | Grad Norm 4.1325(4.2453) | Total Time 0.00(0.00)\n",
      "Iter 13230 | Time 21.1211(20.9240) | Bit/dim 3.5547(3.5550) | Xent 0.0582(0.0388) | Loss 9.0029(9.3900) | Error 0.0156(0.0115) Steps 808(799.09) | Grad Norm 6.7362(4.2723) | Total Time 0.00(0.00)\n",
      "Iter 13240 | Time 20.6860(20.9797) | Bit/dim 3.5423(3.5574) | Xent 0.0487(0.0417) | Loss 8.8122(9.2772) | Error 0.0144(0.0121) Steps 784(797.81) | Grad Norm 4.7112(4.4174) | Total Time 0.00(0.00)\n",
      "Iter 13250 | Time 21.9472(21.0807) | Bit/dim 3.5676(3.5550) | Xent 0.0597(0.0446) | Loss 9.0182(9.1947) | Error 0.0178(0.0130) Steps 820(800.10) | Grad Norm 5.4708(4.4608) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0241 | Time 100.8278, Epoch Time 1277.6824(1208.1273), Bit/dim 3.5719(best: 3.5709), Xent 1.8859, Loss 4.5148, Error 0.3257(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13260 | Time 20.5916(21.1050) | Bit/dim 3.5675(3.5553) | Xent 0.0221(0.0405) | Loss 8.8534(9.9462) | Error 0.0078(0.0121) Steps 772(801.16) | Grad Norm 3.1238(4.0994) | Total Time 0.00(0.00)\n",
      "Iter 13270 | Time 22.0940(21.2039) | Bit/dim 3.5652(3.5574) | Xent 0.0515(0.0392) | Loss 8.9330(9.6847) | Error 0.0133(0.0116) Steps 820(802.99) | Grad Norm 3.9428(4.0152) | Total Time 0.00(0.00)\n",
      "Iter 13280 | Time 21.9738(21.2738) | Bit/dim 3.5738(3.5543) | Xent 0.0487(0.0379) | Loss 9.0135(9.4688) | Error 0.0111(0.0112) Steps 760(802.62) | Grad Norm 3.0229(3.9050) | Total Time 0.00(0.00)\n",
      "Iter 13290 | Time 20.5101(21.2900) | Bit/dim 3.5627(3.5545) | Xent 0.0282(0.0391) | Loss 8.8462(9.3293) | Error 0.0100(0.0116) Steps 766(799.48) | Grad Norm 4.7832(4.1072) | Total Time 0.00(0.00)\n",
      "Iter 13300 | Time 22.1548(21.3057) | Bit/dim 3.5571(3.5529) | Xent 0.0569(0.0416) | Loss 8.9929(9.2276) | Error 0.0211(0.0124) Steps 796(800.64) | Grad Norm 4.1971(4.2306) | Total Time 0.00(0.00)\n",
      "Iter 13310 | Time 22.3876(21.3679) | Bit/dim 3.5483(3.5531) | Xent 0.0374(0.0447) | Loss 8.9537(9.1529) | Error 0.0100(0.0131) Steps 832(803.46) | Grad Norm 3.1021(4.2725) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0242 | Time 101.0202, Epoch Time 1299.4939(1210.8683), Bit/dim 3.5756(best: 3.5709), Xent 1.8060, Loss 4.4786, Error 0.3233(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13320 | Time 21.0061(21.3551) | Bit/dim 3.5540(3.5520) | Xent 0.0496(0.0425) | Loss 9.0207(9.8248) | Error 0.0122(0.0123) Steps 826(806.35) | Grad Norm 4.2906(4.2154) | Total Time 0.00(0.00)\n",
      "Iter 13330 | Time 20.3341(21.3010) | Bit/dim 3.5739(3.5534) | Xent 0.0370(0.0415) | Loss 9.0077(9.5928) | Error 0.0111(0.0121) Steps 814(807.96) | Grad Norm 5.4763(4.1661) | Total Time 0.00(0.00)\n",
      "Iter 13340 | Time 20.7794(21.3338) | Bit/dim 3.5544(3.5517) | Xent 0.0522(0.0411) | Loss 8.9776(9.4071) | Error 0.0133(0.0123) Steps 772(806.01) | Grad Norm 4.0328(4.3125) | Total Time 0.00(0.00)\n",
      "Iter 13350 | Time 20.5266(21.3417) | Bit/dim 3.6003(3.5531) | Xent 0.0724(0.0425) | Loss 8.8946(9.2923) | Error 0.0222(0.0128) Steps 808(805.34) | Grad Norm 6.8722(4.3837) | Total Time 0.00(0.00)\n",
      "Iter 13360 | Time 22.0610(21.2918) | Bit/dim 3.5477(3.5561) | Xent 0.0310(0.0443) | Loss 8.8751(9.2028) | Error 0.0100(0.0130) Steps 796(803.56) | Grad Norm 3.1232(4.4867) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0243 | Time 99.2693, Epoch Time 1290.1057(1213.2455), Bit/dim 3.5803(best: 3.5709), Xent 1.9208, Loss 4.5407, Error 0.3343(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13370 | Time 20.7538(21.2802) | Bit/dim 3.5394(3.5555) | Xent 0.0406(0.0431) | Loss 8.7931(9.9720) | Error 0.0111(0.0129) Steps 790(803.86) | Grad Norm 3.3387(4.5540) | Total Time 0.00(0.00)\n",
      "Iter 13380 | Time 20.9917(21.2253) | Bit/dim 3.5500(3.5573) | Xent 0.0480(0.0425) | Loss 8.8315(9.6971) | Error 0.0144(0.0127) Steps 784(801.36) | Grad Norm 4.7886(4.5665) | Total Time 0.00(0.00)\n",
      "Iter 13390 | Time 21.5653(21.2374) | Bit/dim 3.5850(3.5566) | Xent 0.0467(0.0448) | Loss 8.9777(9.5028) | Error 0.0122(0.0136) Steps 790(803.59) | Grad Norm 3.1571(4.4804) | Total Time 0.00(0.00)\n",
      "Iter 13400 | Time 21.5270(21.2343) | Bit/dim 3.5630(3.5548) | Xent 0.0453(0.0448) | Loss 8.9259(9.3533) | Error 0.0156(0.0135) Steps 784(803.07) | Grad Norm 5.9927(4.3862) | Total Time 0.00(0.00)\n",
      "Iter 13410 | Time 22.0939(21.2773) | Bit/dim 3.5559(3.5559) | Xent 0.0408(0.0445) | Loss 9.0461(9.2533) | Error 0.0111(0.0133) Steps 826(804.53) | Grad Norm 4.7348(4.4729) | Total Time 0.00(0.00)\n",
      "Iter 13420 | Time 21.6731(21.3602) | Bit/dim 3.5527(3.5574) | Xent 0.0336(0.0468) | Loss 8.9447(9.1832) | Error 0.0122(0.0142) Steps 844(808.52) | Grad Norm 4.4961(4.6424) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0244 | Time 102.1796, Epoch Time 1295.8063(1215.7223), Bit/dim 3.5790(best: 3.5709), Xent 1.9329, Loss 4.5455, Error 0.3260(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13430 | Time 21.8238(21.3766) | Bit/dim 3.5631(3.5597) | Xent 0.0395(0.0455) | Loss 8.9948(9.8580) | Error 0.0089(0.0137) Steps 832(808.25) | Grad Norm 4.2237(4.7926) | Total Time 0.00(0.00)\n",
      "Iter 13440 | Time 21.2101(21.3566) | Bit/dim 3.5655(3.5595) | Xent 0.0164(0.0438) | Loss 8.9815(9.6212) | Error 0.0056(0.0131) Steps 796(808.78) | Grad Norm 4.0477(4.6962) | Total Time 0.00(0.00)\n",
      "Iter 13450 | Time 21.4242(21.3381) | Bit/dim 3.4988(3.5539) | Xent 0.0307(0.0405) | Loss 8.7517(9.4332) | Error 0.0067(0.0120) Steps 826(810.00) | Grad Norm 4.0494(4.4325) | Total Time 0.00(0.00)\n",
      "Iter 13460 | Time 21.7098(21.3870) | Bit/dim 3.5488(3.5525) | Xent 0.0357(0.0395) | Loss 8.9429(9.3030) | Error 0.0078(0.0117) Steps 814(809.71) | Grad Norm 4.6490(4.6082) | Total Time 0.00(0.00)\n",
      "Iter 13470 | Time 21.0777(21.4421) | Bit/dim 3.5300(3.5522) | Xent 0.0498(0.0410) | Loss 8.9046(9.2113) | Error 0.0189(0.0122) Steps 808(813.01) | Grad Norm 4.9542(4.4584) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0245 | Time 101.8723, Epoch Time 1303.1274(1218.3444), Bit/dim 3.5718(best: 3.5709), Xent 1.9256, Loss 4.5345, Error 0.3269(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13480 | Time 21.3198(21.4663) | Bit/dim 3.5371(3.5520) | Xent 0.0404(0.0452) | Loss 8.8570(9.9943) | Error 0.0144(0.0132) Steps 826(813.20) | Grad Norm 3.5134(4.4843) | Total Time 0.00(0.00)\n",
      "Iter 13490 | Time 22.1176(21.4824) | Bit/dim 3.5515(3.5565) | Xent 0.0565(0.0516) | Loss 9.0336(9.7383) | Error 0.0156(0.0149) Steps 796(811.04) | Grad Norm 4.1845(5.2027) | Total Time 0.00(0.00)\n",
      "Iter 13500 | Time 20.8782(21.4356) | Bit/dim 3.5540(3.5580) | Xent 0.0383(0.0541) | Loss 8.9146(9.5261) | Error 0.0089(0.0154) Steps 790(809.82) | Grad Norm 2.8930(5.1257) | Total Time 0.00(0.00)\n",
      "Iter 13510 | Time 21.4338(21.4706) | Bit/dim 3.5855(3.5561) | Xent 0.0613(0.0520) | Loss 8.9070(9.3616) | Error 0.0222(0.0148) Steps 808(808.71) | Grad Norm 4.8268(4.8481) | Total Time 0.00(0.00)\n",
      "Iter 13520 | Time 22.0159(21.4757) | Bit/dim 3.5531(3.5571) | Xent 0.0706(0.0526) | Loss 9.0119(9.2603) | Error 0.0167(0.0150) Steps 790(806.61) | Grad Norm 5.5536(4.8388) | Total Time 0.00(0.00)\n",
      "Iter 13530 | Time 21.7243(21.5125) | Bit/dim 3.5698(3.5579) | Xent 0.0465(0.0507) | Loss 8.8749(9.1715) | Error 0.0144(0.0148) Steps 808(805.63) | Grad Norm 2.9420(4.6479) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0246 | Time 101.6434, Epoch Time 1306.2826(1220.9826), Bit/dim 3.5717(best: 3.5709), Xent 1.8247, Loss 4.4841, Error 0.3254(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13540 | Time 21.4801(21.4115) | Bit/dim 3.5465(3.5594) | Xent 0.0232(0.0472) | Loss 8.7835(9.8109) | Error 0.0056(0.0135) Steps 820(806.35) | Grad Norm 2.6706(4.2971) | Total Time 0.00(0.00)\n",
      "Iter 13550 | Time 21.6117(21.4443) | Bit/dim 3.5251(3.5553) | Xent 0.0208(0.0436) | Loss 8.9086(9.5793) | Error 0.0044(0.0126) Steps 808(807.81) | Grad Norm 3.0392(4.2333) | Total Time 0.00(0.00)\n",
      "Iter 13560 | Time 21.8482(21.3908) | Bit/dim 3.5606(3.5550) | Xent 0.0324(0.0413) | Loss 8.8445(9.4001) | Error 0.0067(0.0120) Steps 826(808.58) | Grad Norm 4.2428(4.1045) | Total Time 0.00(0.00)\n",
      "Iter 13570 | Time 21.5520(21.3278) | Bit/dim 3.5145(3.5543) | Xent 0.0393(0.0420) | Loss 8.8838(9.2745) | Error 0.0144(0.0124) Steps 802(808.51) | Grad Norm 3.5957(4.1934) | Total Time 0.00(0.00)\n",
      "Iter 13580 | Time 21.6140(21.3303) | Bit/dim 3.5517(3.5510) | Xent 0.0420(0.0405) | Loss 9.0345(9.1703) | Error 0.0122(0.0121) Steps 808(808.00) | Grad Norm 4.5604(4.3118) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0247 | Time 101.5749, Epoch Time 1295.3416(1223.2133), Bit/dim 3.5725(best: 3.5709), Xent 1.9765, Loss 4.5608, Error 0.3327(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13590 | Time 22.0851(21.4469) | Bit/dim 3.5589(3.5534) | Xent 0.0178(0.0397) | Loss 8.9467(9.9382) | Error 0.0056(0.0119) Steps 820(810.58) | Grad Norm 4.3941(4.5188) | Total Time 0.00(0.00)\n",
      "Iter 13600 | Time 21.6151(21.3833) | Bit/dim 3.5771(3.5545) | Xent 0.0592(0.0388) | Loss 8.8511(9.6716) | Error 0.0156(0.0117) Steps 790(810.50) | Grad Norm 5.6589(4.4584) | Total Time 0.00(0.00)\n",
      "Iter 13610 | Time 21.0893(21.3516) | Bit/dim 3.5541(3.5524) | Xent 0.0477(0.0385) | Loss 8.9060(9.4737) | Error 0.0144(0.0114) Steps 820(809.44) | Grad Norm 4.2609(4.2576) | Total Time 0.00(0.00)\n",
      "Iter 13620 | Time 22.6364(21.4392) | Bit/dim 3.5521(3.5507) | Xent 0.0698(0.0414) | Loss 8.9942(9.3356) | Error 0.0167(0.0120) Steps 862(813.70) | Grad Norm 6.3332(4.2389) | Total Time 0.00(0.00)\n",
      "Iter 13630 | Time 21.9649(21.5553) | Bit/dim 3.5541(3.5509) | Xent 0.0407(0.0408) | Loss 8.9109(9.2317) | Error 0.0122(0.0117) Steps 820(817.66) | Grad Norm 2.9468(4.0709) | Total Time 0.00(0.00)\n",
      "Iter 13640 | Time 21.5035(21.5630) | Bit/dim 3.5268(3.5505) | Xent 0.0270(0.0402) | Loss 8.8059(9.1507) | Error 0.0078(0.0112) Steps 832(816.58) | Grad Norm 3.9236(3.8771) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0248 | Time 101.1797, Epoch Time 1307.0246(1225.7277), Bit/dim 3.5672(best: 3.5709), Xent 1.8061, Loss 4.4703, Error 0.3220(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13650 | Time 21.7358(21.5327) | Bit/dim 3.5608(3.5512) | Xent 0.0584(0.0389) | Loss 8.9079(9.7868) | Error 0.0167(0.0111) Steps 796(815.31) | Grad Norm 4.0948(3.7588) | Total Time 0.00(0.00)\n",
      "Iter 13660 | Time 21.3069(21.5779) | Bit/dim 3.5727(3.5491) | Xent 0.0334(0.0369) | Loss 8.8573(9.5534) | Error 0.0078(0.0102) Steps 802(815.05) | Grad Norm 4.4035(3.7135) | Total Time 0.00(0.00)\n",
      "Iter 13670 | Time 21.4738(21.5299) | Bit/dim 3.6008(3.5501) | Xent 0.0340(0.0377) | Loss 9.0610(9.3864) | Error 0.0100(0.0103) Steps 826(811.07) | Grad Norm 3.0768(3.7195) | Total Time 0.00(0.00)\n",
      "Iter 13680 | Time 22.4438(21.5546) | Bit/dim 3.5577(3.5511) | Xent 0.0381(0.0389) | Loss 8.9911(9.2744) | Error 0.0133(0.0112) Steps 844(811.68) | Grad Norm 3.2388(3.9944) | Total Time 0.00(0.00)\n",
      "Iter 13690 | Time 21.0031(21.5237) | Bit/dim 3.5611(3.5516) | Xent 0.0571(0.0434) | Loss 8.8916(9.1922) | Error 0.0133(0.0126) Steps 820(810.29) | Grad Norm 5.5749(4.3966) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0249 | Time 102.2470, Epoch Time 1306.5741(1228.1531), Bit/dim 3.5700(best: 3.5672), Xent 1.8811, Loss 4.5105, Error 0.3249(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13700 | Time 21.2310(21.5300) | Bit/dim 3.5355(3.5502) | Xent 0.0246(0.0413) | Loss 8.7329(9.9455) | Error 0.0100(0.0122) Steps 826(807.23) | Grad Norm 2.3574(4.1880) | Total Time 0.00(0.00)\n",
      "Iter 13710 | Time 22.7623(21.5122) | Bit/dim 3.5185(3.5482) | Xent 0.0343(0.0405) | Loss 8.9520(9.6848) | Error 0.0111(0.0122) Steps 826(810.03) | Grad Norm 3.0355(3.9439) | Total Time 0.00(0.00)\n",
      "Iter 13720 | Time 20.2728(21.4595) | Bit/dim 3.5825(3.5466) | Xent 0.0291(0.0379) | Loss 8.9325(9.4736) | Error 0.0089(0.0112) Steps 766(811.60) | Grad Norm 4.6883(3.9220) | Total Time 0.00(0.00)\n",
      "Iter 13730 | Time 20.7926(21.4114) | Bit/dim 3.5524(3.5445) | Xent 0.0203(0.0353) | Loss 8.8316(9.3197) | Error 0.0044(0.0103) Steps 778(811.44) | Grad Norm 3.1946(3.8081) | Total Time 0.00(0.00)\n",
      "Iter 13740 | Time 21.5385(21.4035) | Bit/dim 3.5368(3.5447) | Xent 0.0330(0.0341) | Loss 8.8474(9.2007) | Error 0.0111(0.0099) Steps 826(810.74) | Grad Norm 3.5026(3.7241) | Total Time 0.00(0.00)\n",
      "Iter 13750 | Time 21.7621(21.4044) | Bit/dim 3.5573(3.5463) | Xent 0.0374(0.0345) | Loss 9.0096(9.1290) | Error 0.0078(0.0099) Steps 802(810.66) | Grad Norm 3.3527(3.8270) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0250 | Time 103.8337, Epoch Time 1301.3378(1230.3486), Bit/dim 3.5715(best: 3.5672), Xent 2.0617, Loss 4.6023, Error 0.3299(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13760 | Time 21.7075(21.5195) | Bit/dim 3.5146(3.5457) | Xent 0.0318(0.0334) | Loss 8.8666(9.8159) | Error 0.0078(0.0097) Steps 778(813.24) | Grad Norm 4.6398(3.9092) | Total Time 0.00(0.00)\n",
      "Iter 13770 | Time 22.4685(21.5441) | Bit/dim 3.5475(3.5476) | Xent 0.0310(0.0359) | Loss 8.9220(9.5869) | Error 0.0089(0.0103) Steps 808(815.33) | Grad Norm 4.7430(4.4994) | Total Time 0.00(0.00)\n",
      "Iter 13780 | Time 21.9432(21.5985) | Bit/dim 3.5886(3.5518) | Xent 0.0185(0.0383) | Loss 8.9309(9.4292) | Error 0.0078(0.0110) Steps 832(817.57) | Grad Norm 2.7152(4.7234) | Total Time 0.00(0.00)\n",
      "Iter 13790 | Time 21.3418(21.6162) | Bit/dim 3.5296(3.5493) | Xent 0.0318(0.0421) | Loss 8.8222(9.2954) | Error 0.0111(0.0118) Steps 784(816.15) | Grad Norm 5.5778(4.5868) | Total Time 0.00(0.00)\n",
      "Iter 13800 | Time 21.3594(21.6209) | Bit/dim 3.5660(3.5527) | Xent 0.1302(0.0537) | Loss 9.1083(9.2199) | Error 0.0311(0.0149) Steps 808(816.02) | Grad Norm 13.5183(5.3184) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 103.0708, Epoch Time 1318.3736(1232.9894), Bit/dim 3.5901(best: 3.5672), Xent 1.7681, Loss 4.4742, Error 0.3221(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13810 | Time 22.3579(21.7722) | Bit/dim 3.5509(3.5568) | Xent 0.0746(0.0636) | Loss 8.9885(10.0407) | Error 0.0200(0.0183) Steps 808(815.79) | Grad Norm 6.6193(5.7565) | Total Time 0.00(0.00)\n",
      "Iter 13820 | Time 21.3512(21.7724) | Bit/dim 3.5416(3.5557) | Xent 0.0449(0.0596) | Loss 8.8644(9.7647) | Error 0.0111(0.0176) Steps 814(816.81) | Grad Norm 3.3981(5.2503) | Total Time 0.00(0.00)\n",
      "Iter 13830 | Time 21.4849(21.7877) | Bit/dim 3.5837(3.5578) | Xent 0.0668(0.0556) | Loss 8.9524(9.5593) | Error 0.0189(0.0167) Steps 796(817.85) | Grad Norm 5.1962(5.2051) | Total Time 0.00(0.00)\n",
      "Iter 13840 | Time 21.2925(21.7379) | Bit/dim 3.5607(3.5575) | Xent 0.0749(0.0539) | Loss 8.9841(9.4082) | Error 0.0222(0.0163) Steps 790(816.99) | Grad Norm 7.3566(5.2978) | Total Time 0.00(0.00)\n",
      "Iter 13850 | Time 21.8726(21.7752) | Bit/dim 3.5542(3.5574) | Xent 0.0295(0.0535) | Loss 8.8589(9.2903) | Error 0.0111(0.0163) Steps 832(818.94) | Grad Norm 3.3383(5.1874) | Total Time 0.00(0.00)\n",
      "Iter 13860 | Time 21.5934(21.6845) | Bit/dim 3.5631(3.5544) | Xent 0.0308(0.0489) | Loss 8.8292(9.1990) | Error 0.0067(0.0149) Steps 808(819.33) | Grad Norm 2.8450(4.8109) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 101.9118, Epoch Time 1320.5620(1235.6166), Bit/dim 3.5744(best: 3.5672), Xent 2.0321, Loss 4.5904, Error 0.3400(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13870 | Time 21.5158(21.6321) | Bit/dim 3.5468(3.5531) | Xent 0.0346(0.0472) | Loss 9.0240(9.8410) | Error 0.0100(0.0143) Steps 832(816.23) | Grad Norm 5.2701(4.5863) | Total Time 0.00(0.00)\n",
      "Iter 13880 | Time 21.3185(21.6195) | Bit/dim 3.5587(3.5550) | Xent 0.0322(0.0446) | Loss 8.9189(9.6151) | Error 0.0078(0.0134) Steps 814(816.29) | Grad Norm 3.7781(4.3251) | Total Time 0.00(0.00)\n",
      "Iter 13890 | Time 21.8488(21.5925) | Bit/dim 3.5663(3.5524) | Xent 0.0751(0.0427) | Loss 8.9280(9.4292) | Error 0.0244(0.0126) Steps 826(813.51) | Grad Norm 4.1235(4.0838) | Total Time 0.00(0.00)\n",
      "Iter 13900 | Time 21.9685(21.5768) | Bit/dim 3.5469(3.5481) | Xent 0.0503(0.0427) | Loss 8.9875(9.2812) | Error 0.0133(0.0127) Steps 838(813.48) | Grad Norm 7.2993(4.2695) | Total Time 0.00(0.00)\n",
      "Iter 13910 | Time 21.7995(21.6589) | Bit/dim 3.5644(3.5507) | Xent 0.0871(0.0449) | Loss 9.0093(9.2068) | Error 0.0244(0.0130) Steps 844(818.01) | Grad Norm 7.7869(4.5431) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 105.0382, Epoch Time 1317.3623(1238.0689), Bit/dim 3.5729(best: 3.5672), Xent 1.9465, Loss 4.5461, Error 0.3342(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13920 | Time 21.2995(21.8171) | Bit/dim 3.5453(3.5520) | Xent 0.0456(0.0451) | Loss 9.0551(9.9930) | Error 0.0122(0.0129) Steps 832(819.49) | Grad Norm 4.2330(4.6013) | Total Time 0.00(0.00)\n",
      "Iter 13930 | Time 21.7155(21.7506) | Bit/dim 3.5485(3.5535) | Xent 0.0616(0.0447) | Loss 8.9809(9.7288) | Error 0.0167(0.0128) Steps 796(818.60) | Grad Norm 5.1922(4.4868) | Total Time 0.00(0.00)\n",
      "Iter 13940 | Time 21.2027(21.7337) | Bit/dim 3.5322(3.5504) | Xent 0.0357(0.0424) | Loss 8.8096(9.5188) | Error 0.0122(0.0122) Steps 790(818.33) | Grad Norm 3.2940(4.2106) | Total Time 0.00(0.00)\n",
      "Iter 13950 | Time 21.9050(21.7981) | Bit/dim 3.5557(3.5486) | Xent 0.0281(0.0381) | Loss 9.0030(9.3604) | Error 0.0067(0.0111) Steps 838(818.94) | Grad Norm 3.1013(3.9701) | Total Time 0.00(0.00)\n",
      "Iter 13960 | Time 21.2540(21.7245) | Bit/dim 3.5435(3.5463) | Xent 0.0439(0.0381) | Loss 8.8699(9.2453) | Error 0.0122(0.0110) Steps 808(818.66) | Grad Norm 4.2823(3.9273) | Total Time 0.00(0.00)\n",
      "Iter 13970 | Time 21.7099(21.6969) | Bit/dim 3.5782(3.5488) | Xent 0.0672(0.0426) | Loss 9.0274(9.1728) | Error 0.0167(0.0123) Steps 814(817.64) | Grad Norm 4.3360(4.3224) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 102.4059, Epoch Time 1319.2368(1240.5040), Bit/dim 3.5738(best: 3.5672), Xent 1.9832, Loss 4.5654, Error 0.3338(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13980 | Time 22.0434(21.6892) | Bit/dim 3.5698(3.5506) | Xent 0.0277(0.0432) | Loss 8.9239(9.8291) | Error 0.0089(0.0127) Steps 808(819.56) | Grad Norm 4.7595(4.3306) | Total Time 0.00(0.00)\n",
      "Iter 13990 | Time 22.1246(21.7610) | Bit/dim 3.5503(3.5524) | Xent 0.0404(0.0438) | Loss 8.9923(9.6052) | Error 0.0111(0.0126) Steps 832(822.43) | Grad Norm 3.1179(4.3440) | Total Time 0.00(0.00)\n",
      "Iter 14000 | Time 22.2182(21.9465) | Bit/dim 3.5361(3.5530) | Xent 0.0437(0.0434) | Loss 9.0468(9.4472) | Error 0.0133(0.0128) Steps 844(827.45) | Grad Norm 3.6107(4.3497) | Total Time 0.00(0.00)\n",
      "Iter 14010 | Time 22.2086(21.9395) | Bit/dim 3.5543(3.5531) | Xent 0.0481(0.0440) | Loss 8.9386(9.3219) | Error 0.0111(0.0129) Steps 844(830.40) | Grad Norm 3.5599(4.3063) | Total Time 0.00(0.00)\n",
      "Iter 14020 | Time 21.4484(21.8242) | Bit/dim 3.5566(3.5521) | Xent 0.0416(0.0428) | Loss 8.9527(9.2122) | Error 0.0156(0.0129) Steps 814(825.20) | Grad Norm 4.3087(4.0043) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 102.8645, Epoch Time 1328.8501(1243.1543), Bit/dim 3.5677(best: 3.5672), Xent 1.9686, Loss 4.5520, Error 0.3275(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14030 | Time 22.3617(21.8844) | Bit/dim 3.5555(3.5506) | Xent 0.0173(0.0407) | Loss 8.9615(9.9813) | Error 0.0067(0.0127) Steps 808(824.81) | Grad Norm 4.8603(3.9306) | Total Time 0.00(0.00)\n",
      "Iter 14040 | Time 21.5782(21.8423) | Bit/dim 3.5793(3.5513) | Xent 0.0539(0.0402) | Loss 8.8792(9.7062) | Error 0.0133(0.0121) Steps 808(824.76) | Grad Norm 4.7825(3.9111) | Total Time 0.00(0.00)\n",
      "Iter 14050 | Time 22.0935(21.9144) | Bit/dim 3.5492(3.5500) | Xent 0.0367(0.0403) | Loss 8.7628(9.4968) | Error 0.0133(0.0123) Steps 826(826.68) | Grad Norm 4.0894(3.9731) | Total Time 0.00(0.00)\n",
      "Iter 14060 | Time 20.6940(21.8273) | Bit/dim 3.5593(3.5478) | Xent 0.0416(0.0423) | Loss 8.9099(9.3547) | Error 0.0100(0.0125) Steps 826(828.20) | Grad Norm 4.2782(4.0484) | Total Time 0.00(0.00)\n",
      "Iter 14070 | Time 21.9835(21.8108) | Bit/dim 3.5895(3.5505) | Xent 0.0511(0.0438) | Loss 9.1227(9.2551) | Error 0.0122(0.0131) Steps 832(827.96) | Grad Norm 3.9804(4.2120) | Total Time 0.00(0.00)\n",
      "Iter 14080 | Time 22.0481(21.7599) | Bit/dim 3.5265(3.5514) | Xent 0.0589(0.0432) | Loss 8.9139(9.1777) | Error 0.0178(0.0126) Steps 844(826.98) | Grad Norm 4.2212(4.1120) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 102.0200, Epoch Time 1321.7302(1245.5116), Bit/dim 3.5665(best: 3.5672), Xent 1.8576, Loss 4.4953, Error 0.3202(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14090 | Time 22.5526(21.6991) | Bit/dim 3.5102(3.5489) | Xent 0.0540(0.0400) | Loss 8.8706(9.8315) | Error 0.0133(0.0116) Steps 802(824.28) | Grad Norm 4.4525(3.8616) | Total Time 0.00(0.00)\n",
      "Iter 14100 | Time 22.3473(21.7198) | Bit/dim 3.5497(3.5464) | Xent 0.0450(0.0393) | Loss 8.9812(9.5968) | Error 0.0167(0.0112) Steps 820(823.05) | Grad Norm 5.4198(3.7812) | Total Time 0.00(0.00)\n",
      "Iter 14110 | Time 21.4789(21.6520) | Bit/dim 3.5552(3.5455) | Xent 0.0483(0.0396) | Loss 8.8551(9.4199) | Error 0.0144(0.0113) Steps 796(822.15) | Grad Norm 3.6224(3.7978) | Total Time 0.00(0.00)\n",
      "Iter 14120 | Time 21.9233(21.6695) | Bit/dim 3.5534(3.5480) | Xent 0.0487(0.0406) | Loss 8.9854(9.3072) | Error 0.0111(0.0116) Steps 796(821.12) | Grad Norm 5.6889(3.8536) | Total Time 0.00(0.00)\n",
      "Iter 14130 | Time 22.3781(21.6377) | Bit/dim 3.5394(3.5477) | Xent 0.0810(0.0426) | Loss 9.0254(9.2079) | Error 0.0267(0.0123) Steps 796(819.21) | Grad Norm 5.7776(4.0825) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 102.0511, Epoch Time 1313.5410(1247.5525), Bit/dim 3.5753(best: 3.5665), Xent 1.8677, Loss 4.5092, Error 0.3180(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14140 | Time 23.0155(21.6855) | Bit/dim 3.5165(3.5487) | Xent 0.0342(0.0455) | Loss 8.8817(9.9556) | Error 0.0089(0.0131) Steps 826(818.19) | Grad Norm 3.6422(4.1236) | Total Time 0.00(0.00)\n",
      "Iter 14150 | Time 22.1438(21.5977) | Bit/dim 3.5570(3.5516) | Xent 0.0341(0.0467) | Loss 8.9440(9.6937) | Error 0.0056(0.0137) Steps 826(817.32) | Grad Norm 4.8241(4.1763) | Total Time 0.00(0.00)\n",
      "Iter 14160 | Time 21.1533(21.6603) | Bit/dim 3.5431(3.5496) | Xent 0.0222(0.0453) | Loss 8.8750(9.5009) | Error 0.0078(0.0135) Steps 826(821.57) | Grad Norm 3.5971(4.2093) | Total Time 0.00(0.00)\n",
      "Iter 14170 | Time 21.5492(21.6330) | Bit/dim 3.5825(3.5479) | Xent 0.0209(0.0424) | Loss 8.8272(9.3406) | Error 0.0067(0.0126) Steps 808(820.56) | Grad Norm 2.4114(3.8899) | Total Time 0.00(0.00)\n",
      "Iter 14180 | Time 20.9531(21.7584) | Bit/dim 3.5504(3.5456) | Xent 0.0337(0.0403) | Loss 8.9047(9.2293) | Error 0.0078(0.0117) Steps 790(818.11) | Grad Norm 3.9911(3.8412) | Total Time 0.00(0.00)\n",
      "Iter 14190 | Time 21.0606(21.7661) | Bit/dim 3.5531(3.5451) | Xent 0.0736(0.0408) | Loss 8.9167(9.1470) | Error 0.0244(0.0120) Steps 802(816.68) | Grad Norm 8.3024(4.1686) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 101.2296, Epoch Time 1317.2833(1249.6444), Bit/dim 3.5657(best: 3.5665), Xent 1.9252, Loss 4.5283, Error 0.3241(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14200 | Time 22.1373(21.7592) | Bit/dim 3.5474(3.5447) | Xent 0.0615(0.0397) | Loss 9.0245(9.7714) | Error 0.0122(0.0113) Steps 808(814.68) | Grad Norm 3.6393(4.0969) | Total Time 0.00(0.00)\n",
      "Iter 14210 | Time 22.5132(21.7992) | Bit/dim 3.5789(3.5458) | Xent 0.0362(0.0362) | Loss 9.0009(9.5490) | Error 0.0122(0.0107) Steps 874(821.66) | Grad Norm 3.6793(3.9728) | Total Time 0.00(0.00)\n",
      "Iter 14220 | Time 22.1315(21.8030) | Bit/dim 3.5289(3.5435) | Xent 0.0385(0.0361) | Loss 8.9899(9.3890) | Error 0.0111(0.0109) Steps 850(824.40) | Grad Norm 4.8359(3.8807) | Total Time 0.00(0.00)\n",
      "Iter 14230 | Time 22.3584(21.8133) | Bit/dim 3.5834(3.5415) | Xent 0.0527(0.0390) | Loss 9.0750(9.2585) | Error 0.0111(0.0112) Steps 808(824.72) | Grad Norm 3.5133(3.8346) | Total Time 0.00(0.00)\n",
      "Iter 14240 | Time 22.8783(21.8424) | Bit/dim 3.5995(3.5464) | Xent 0.0522(0.0421) | Loss 9.0606(9.1787) | Error 0.0167(0.0121) Steps 808(824.30) | Grad Norm 4.0398(3.8860) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 103.0254, Epoch Time 1323.8845(1251.8716), Bit/dim 3.5680(best: 3.5657), Xent 1.9361, Loss 4.5361, Error 0.3256(best: 0.3088)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14250 | Time 22.4580(21.8830) | Bit/dim 3.5512(3.5487) | Xent 0.0114(0.0393) | Loss 8.8871(9.9394) | Error 0.0011(0.0112) Steps 832(825.01) | Grad Norm 3.6180(3.7946) | Total Time 0.00(0.00)\n",
      "Iter 14260 | Time 21.6865(21.8906) | Bit/dim 3.5361(3.5469) | Xent 0.0185(0.0384) | Loss 8.8056(9.6678) | Error 0.0067(0.0110) Steps 820(825.77) | Grad Norm 2.6332(3.8261) | Total Time 0.00(0.00)\n",
      "Iter 14270 | Time 21.5430(21.8648) | Bit/dim 3.5243(3.5452) | Xent 0.0380(0.0376) | Loss 8.8509(9.4730) | Error 0.0100(0.0109) Steps 856(828.66) | Grad Norm 4.2167(3.7480) | Total Time 0.00(0.00)\n",
      "Iter 14280 | Time 22.4093(21.9042) | Bit/dim 3.5283(3.5455) | Xent 0.0573(0.0372) | Loss 8.9892(9.3349) | Error 0.0144(0.0108) Steps 868(831.25) | Grad Norm 3.9926(3.6513) | Total Time 0.00(0.00)\n",
      "Iter 14290 | Time 21.6448(21.9037) | Bit/dim 3.5585(3.5436) | Xent 0.0752(0.0384) | Loss 8.9640(9.2324) | Error 0.0200(0.0111) Steps 808(827.74) | Grad Norm 5.7045(3.7545) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl_multiscale.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run3 --resume ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run3/epoch_250_checkpt.pth --seed 3 --lr 0.0001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --scale_std 6.0\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
