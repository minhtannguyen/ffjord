{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=0.0001, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=True, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume=None, rtol=0.0001, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_tunetol_run1', seed=1, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000.0, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1414198\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 0010 | Time 12.7541(29.9921) | Bit/dim 9.0577(9.2272) | Xent 2.2768(2.3000) | Loss 10.1961(10.3772) | Error 0.7533(0.8723) Steps 550(550.00) | Grad Norm 13.0513(17.3663) | Total Time 14.00(14.00)\n",
      "Iter 0020 | Time 13.1771(25.4953) | Bit/dim 8.5459(9.1016) | Xent 2.2224(2.2870) | Loss 9.6571(10.2451) | Error 0.7356(0.8410) Steps 550(550.00) | Grad Norm 5.3168(15.0113) | Total Time 14.00(14.00)\n",
      "Iter 0030 | Time 13.0598(22.2196) | Bit/dim 8.3426(8.9325) | Xent 2.1874(2.2636) | Loss 9.4363(10.0643) | Error 0.7589(0.8189) Steps 562(551.65) | Grad Norm 4.3691(12.1928) | Total Time 14.00(14.00)\n",
      "Iter 0040 | Time 12.8432(19.8034) | Bit/dim 8.1914(8.7629) | Xent 2.1320(2.2333) | Loss 9.2574(9.8795) | Error 0.7267(0.7980) Steps 550(552.84) | Grad Norm 3.2842(9.9281) | Total Time 14.00(14.00)\n",
      "Iter 0050 | Time 13.2021(17.9275) | Bit/dim 7.9111(8.5810) | Xent 2.1081(2.2030) | Loss 8.9652(9.6825) | Error 0.7122(0.7764) Steps 544(551.43) | Grad Norm 2.6059(8.1486) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0001 | Time 79.8738, Epoch Time 831.6393(831.6393), Bit/dim 7.7967(best: inf), Xent 2.0827, Loss 8.8381, Error 0.6986(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0060 | Time 12.6670(16.6428) | Bit/dim 7.6737(8.3790) | Xent 2.0972(2.1732) | Loss 8.7223(9.4656) | Error 0.7111(0.7583) Steps 562(552.25) | Grad Norm 2.6978(6.7789) | Total Time 14.00(14.00)\n",
      "Iter 0070 | Time 12.8817(15.7139) | Bit/dim 7.3791(8.1500) | Xent 2.0612(2.1474) | Loss 8.4097(9.2237) | Error 0.6911(0.7417) Steps 562(554.81) | Grad Norm 2.3017(5.6552) | Total Time 14.00(14.00)\n",
      "Iter 0080 | Time 13.1322(15.0324) | Bit/dim 7.1767(7.9152) | Xent 2.0998(2.1311) | Loss 8.2267(8.9808) | Error 0.6822(0.7274) Steps 562(556.70) | Grad Norm 1.6010(4.6678) | Total Time 14.00(14.00)\n",
      "Iter 0090 | Time 13.4198(14.5217) | Bit/dim 7.0655(7.7048) | Xent 2.0985(2.1236) | Loss 8.1148(8.7667) | Error 0.7211(0.7216) Steps 562(558.09) | Grad Norm 1.1660(3.8517) | Total Time 14.00(14.00)\n",
      "Iter 0100 | Time 13.4275(14.2125) | Bit/dim 7.0315(7.5321) | Xent 2.0769(2.1153) | Loss 8.0699(8.5898) | Error 0.7267(0.7181) Steps 568(560.12) | Grad Norm 1.8625(3.2967) | Total Time 14.00(14.00)\n",
      "Iter 0110 | Time 13.4450(13.9967) | Bit/dim 7.0061(7.3943) | Xent 2.0795(2.1059) | Loss 8.0459(8.4472) | Error 0.7100(0.7149) Steps 568(562.19) | Grad Norm 4.1818(2.9327) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0002 | Time 73.8254, Epoch Time 818.7723(831.2533), Bit/dim 6.9903(best: 7.7967), Xent 2.0600, Loss 8.0203, Error 0.6908(best: 0.6986)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0120 | Time 13.5061(13.8279) | Bit/dim 6.9560(7.2827) | Xent 2.0762(2.0968) | Loss 7.9941(8.3311) | Error 0.7122(0.7135) Steps 568(563.71) | Grad Norm 6.0021(3.0719) | Total Time 14.00(14.00)\n",
      "Iter 0130 | Time 13.4696(13.7723) | Bit/dim 6.8969(7.1921) | Xent 2.0562(2.0908) | Loss 7.9250(8.2375) | Error 0.7167(0.7151) Steps 574(565.54) | Grad Norm 2.2209(3.8372) | Total Time 14.00(14.00)\n",
      "Iter 0140 | Time 14.7776(13.8795) | Bit/dim 6.8683(7.1147) | Xent 2.1081(2.0847) | Loss 7.9223(8.1571) | Error 0.7400(0.7147) Steps 592(570.72) | Grad Norm 10.8927(4.7895) | Total Time 14.00(14.00)\n",
      "Iter 0150 | Time 14.3910(14.0226) | Bit/dim 6.8382(7.0485) | Xent 2.0413(2.0732) | Loss 7.8588(8.0852) | Error 0.6800(0.7095) Steps 592(576.50) | Grad Norm 2.5348(4.3689) | Total Time 14.00(14.00)\n",
      "Iter 0160 | Time 13.9129(14.0281) | Bit/dim 6.7934(6.9835) | Xent 2.0369(2.0607) | Loss 7.8118(8.0139) | Error 0.6822(0.7014) Steps 592(580.57) | Grad Norm 5.3925(4.2741) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0003 | Time 78.6609, Epoch Time 862.2887(832.1843), Bit/dim 6.7218(best: 6.9903), Xent 2.0506, Loss 7.7471, Error 0.7284(best: 0.6908)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0170 | Time 14.6899(14.0256) | Bit/dim 6.6629(6.9131) | Xent 2.0207(2.0544) | Loss 7.6732(7.9402) | Error 0.7022(0.7020) Steps 592(583.57) | Grad Norm 7.9598(5.8283) | Total Time 14.00(14.00)\n",
      "Iter 0180 | Time 13.8105(13.9660) | Bit/dim 6.5700(6.8325) | Xent 2.1847(2.0560) | Loss 7.6623(7.8605) | Error 0.7944(0.7093) Steps 586(584.95) | Grad Norm 44.4866(10.0417) | Total Time 14.00(14.00)\n",
      "Iter 0190 | Time 13.6434(13.9632) | Bit/dim 6.4169(6.7414) | Xent 2.0099(2.0558) | Loss 7.4218(7.7693) | Error 0.6900(0.7117) Steps 586(585.05) | Grad Norm 14.7868(14.2407) | Total Time 14.00(14.00)\n",
      "Iter 0200 | Time 14.0971(13.9636) | Bit/dim 6.2271(6.6328) | Xent 2.0968(2.0568) | Loss 7.2756(7.6611) | Error 0.7844(0.7168) Steps 592(585.38) | Grad Norm 35.4964(17.9619) | Total Time 14.00(14.00)\n",
      "Iter 0210 | Time 14.1576(14.0833) | Bit/dim 6.1114(6.5118) | Xent 2.1136(2.0681) | Loss 7.1682(7.5459) | Error 0.7700(0.7257) Steps 592(587.28) | Grad Norm 47.2701(22.3731) | Total Time 14.00(14.00)\n",
      "Iter 0220 | Time 14.1770(14.1934) | Bit/dim 5.9952(6.3889) | Xent 2.0066(2.0617) | Loss 6.9985(7.4197) | Error 0.6900(0.7232) Steps 592(589.00) | Grad Norm 19.0002(22.7147) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0004 | Time 78.1099, Epoch Time 872.5112(833.3941), Bit/dim 5.9634(best: 6.7218), Xent 2.0085, Loss 6.9676, Error 0.6708(best: 0.6908)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0230 | Time 13.9966(14.1791) | Bit/dim 5.9476(6.2693) | Xent 2.0280(2.0583) | Loss 6.9616(7.2985) | Error 0.7511(0.7223) Steps 592(590.29) | Grad Norm 56.6389(24.5355) | Total Time 14.00(14.00)\n",
      "Iter 0240 | Time 14.3949(14.2164) | Bit/dim 5.7974(6.1557) | Xent 2.0450(2.0532) | Loss 6.8199(7.1823) | Error 0.6644(0.7154) Steps 598(592.02) | Grad Norm 14.2427(23.9368) | Total Time 14.00(14.00)\n",
      "Iter 0250 | Time 14.1193(14.2021) | Bit/dim 5.7087(6.0526) | Xent 1.9877(2.0444) | Loss 6.7026(7.0748) | Error 0.6633(0.7091) Steps 598(593.49) | Grad Norm 11.5817(22.9421) | Total Time 14.00(14.00)\n",
      "Iter 0260 | Time 14.5644(14.2027) | Bit/dim 5.6842(5.9636) | Xent 2.0202(2.0355) | Loss 6.6943(6.9813) | Error 0.7000(0.7049) Steps 604(594.88) | Grad Norm 23.7654(23.1058) | Total Time 14.00(14.00)\n",
      "Iter 0270 | Time 14.0710(14.1833) | Bit/dim 5.6857(5.8888) | Xent 2.0172(2.0258) | Loss 6.6944(6.9017) | Error 0.7000(0.6980) Steps 598(596.15) | Grad Norm 18.1931(21.3338) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0005 | Time 78.5249, Epoch Time 876.5227(834.6880), Bit/dim 5.6319(best: 5.9634), Xent 1.9515, Loss 6.6077, Error 0.6372(best: 0.6708)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0280 | Time 14.5113(14.1667) | Bit/dim 5.6699(5.8270) | Xent 1.9877(2.0143) | Loss 6.6637(6.8341) | Error 0.6889(0.6912) Steps 598(597.37) | Grad Norm 46.6790(21.6563) | Total Time 14.00(14.00)\n",
      "Iter 0290 | Time 14.0069(14.1744) | Bit/dim 5.5848(5.7728) | Xent 1.9535(2.0021) | Loss 6.5616(6.7739) | Error 0.6811(0.6857) Steps 616(599.80) | Grad Norm 9.6243(20.1595) | Total Time 14.00(14.00)\n",
      "Iter 0300 | Time 14.4410(14.2610) | Bit/dim 5.6222(5.7426) | Xent 2.0161(2.0434) | Loss 6.6303(6.7643) | Error 0.7122(0.7034) Steps 604(600.92) | Grad Norm 9.5173(24.3477) | Total Time 14.00(14.00)\n",
      "Iter 0310 | Time 13.7647(14.2700) | Bit/dim 5.5327(5.7074) | Xent 2.0391(2.0461) | Loss 6.5522(6.7305) | Error 0.7189(0.7061) Steps 592(599.48) | Grad Norm 12.6095(20.1418) | Total Time 14.00(14.00)\n",
      "Iter 0320 | Time 14.4628(14.2883) | Bit/dim 5.5565(5.6722) | Xent 2.0303(2.0430) | Loss 6.5717(6.6937) | Error 0.7033(0.7069) Steps 598(599.42) | Grad Norm 25.4879(17.0649) | Total Time 14.00(14.00)\n",
      "Iter 0330 | Time 13.9218(14.2536) | Bit/dim 5.5491(5.6433) | Xent 2.0541(2.0470) | Loss 6.5762(6.6667) | Error 0.7278(0.7103) Steps 592(598.87) | Grad Norm 20.5312(17.7539) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0006 | Time 77.1407, Epoch Time 880.6058(836.0655), Bit/dim 5.5409(best: 5.6319), Xent 2.0032, Loss 6.5426, Error 0.6799(best: 0.6372)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0340 | Time 14.3798(14.1595) | Bit/dim 5.5409(5.6153) | Xent 1.9896(2.0420) | Loss 6.5357(6.6363) | Error 0.6722(0.7069) Steps 598(598.34) | Grad Norm 6.8780(18.0767) | Total Time 14.00(14.00)\n",
      "Iter 0350 | Time 14.6904(14.1657) | Bit/dim 5.5449(5.5903) | Xent 2.0510(2.0332) | Loss 6.5704(6.6069) | Error 0.7211(0.7034) Steps 598(598.25) | Grad Norm 22.6090(17.8597) | Total Time 14.00(14.00)\n",
      "Iter 0360 | Time 14.0893(14.1893) | Bit/dim 5.4851(5.5639) | Xent 2.0279(2.0260) | Loss 6.4990(6.5769) | Error 0.7000(0.6999) Steps 598(598.19) | Grad Norm 3.1567(15.6816) | Total Time 14.00(14.00)\n",
      "Iter 0370 | Time 14.0279(14.2266) | Bit/dim 5.4464(5.5386) | Xent 1.9494(2.0163) | Loss 6.4211(6.5468) | Error 0.6722(0.6941) Steps 604(598.32) | Grad Norm 7.9099(13.3443) | Total Time 14.00(14.00)\n",
      "Iter 0380 | Time 14.0787(14.2308) | Bit/dim 5.4701(5.5178) | Xent 1.9465(2.0015) | Loss 6.4434(6.5185) | Error 0.6644(0.6879) Steps 604(599.66) | Grad Norm 29.8845(12.9461) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0007 | Time 77.7185, Epoch Time 876.5924(837.2813), Bit/dim 5.4224(best: 5.5409), Xent 1.9537, Loss 6.3993, Error 0.6615(best: 0.6372)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0390 | Time 14.0312(14.2307) | Bit/dim 5.4231(5.4981) | Xent 1.8794(1.9970) | Loss 6.3628(6.4966) | Error 0.6156(0.6876) Steps 598(599.52) | Grad Norm 5.0441(15.4416) | Total Time 14.00(14.00)\n",
      "Iter 0400 | Time 13.9942(14.2031) | Bit/dim 5.4032(5.4691) | Xent 2.0060(1.9871) | Loss 6.4062(6.4626) | Error 0.7200(0.6861) Steps 604(600.56) | Grad Norm 20.2735(14.0345) | Total Time 14.00(14.00)\n",
      "Iter 0410 | Time 14.4108(14.2460) | Bit/dim 5.3726(5.4446) | Xent 1.9699(1.9759) | Loss 6.3576(6.4326) | Error 0.7100(0.6817) Steps 604(601.78) | Grad Norm 19.6485(13.0804) | Total Time 14.00(14.00)\n",
      "Iter 0420 | Time 14.8401(14.3089) | Bit/dim 5.2871(5.4083) | Xent 1.9153(1.9633) | Loss 6.2447(6.3900) | Error 0.6456(0.6765) Steps 616(604.20) | Grad Norm 7.4786(12.2354) | Total Time 14.00(14.00)\n",
      "Iter 0430 | Time 14.2923(14.3390) | Bit/dim 5.2432(5.3684) | Xent 2.0046(1.9574) | Loss 6.2455(6.3471) | Error 0.7300(0.6755) Steps 610(606.72) | Grad Norm 33.9687(13.3146) | Total Time 14.00(14.00)\n",
      "Iter 0440 | Time 13.9819(14.3261) | Bit/dim 5.2043(5.3394) | Xent 1.9630(1.9645) | Loss 6.1858(6.3217) | Error 0.6600(0.6793) Steps 610(608.18) | Grad Norm 9.1241(15.0383) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0008 | Time 81.2764, Epoch Time 886.5992(838.7609), Bit/dim 5.2337(best: 5.4224), Xent 1.9411, Loss 6.2043, Error 0.6704(best: 0.6372)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0450 | Time 14.0455(14.3045) | Bit/dim 5.1927(5.3118) | Xent 1.9270(1.9552) | Loss 6.1562(6.2894) | Error 0.6811(0.6761) Steps 610(608.95) | Grad Norm 6.4759(14.4821) | Total Time 14.00(14.00)\n",
      "Iter 0460 | Time 14.4536(14.2802) | Bit/dim 5.1124(5.2719) | Xent 1.9182(1.9414) | Loss 6.0715(6.2426) | Error 0.6567(0.6716) Steps 610(609.23) | Grad Norm 4.6690(12.6706) | Total Time 14.00(14.00)\n",
      "Iter 0470 | Time 14.1586(14.2851) | Bit/dim 5.0605(5.2340) | Xent 1.8877(1.9283) | Loss 6.0043(6.1981) | Error 0.6644(0.6682) Steps 604(608.58) | Grad Norm 7.7442(11.9664) | Total Time 14.00(14.00)\n",
      "Iter 0480 | Time 13.6600(14.2226) | Bit/dim 5.1691(5.2034) | Xent 1.9296(1.9195) | Loss 6.1339(6.1631) | Error 0.6633(0.6673) Steps 604(607.55) | Grad Norm 31.9964(13.4081) | Total Time 14.00(14.00)\n",
      "Iter 0490 | Time 14.1031(14.1907) | Bit/dim 5.1084(5.1755) | Xent 1.8657(1.9168) | Loss 6.0413(6.1340) | Error 0.6511(0.6669) Steps 604(606.45) | Grad Norm 9.9741(13.0661) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0009 | Time 82.0218, Epoch Time 879.6185(839.9866), Bit/dim 5.0518(best: 5.2337), Xent 1.8691, Loss 5.9864, Error 0.6634(best: 0.6372)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0500 | Time 14.0824(14.1548) | Bit/dim 5.0728(5.1495) | Xent 1.8559(1.9097) | Loss 6.0008(6.1043) | Error 0.6422(0.6655) Steps 604(606.12) | Grad Norm 8.5008(12.4052) | Total Time 14.00(14.00)\n",
      "Iter 0510 | Time 14.3033(14.1554) | Bit/dim 5.0317(5.1164) | Xent 1.8302(1.8953) | Loss 5.9468(6.0641) | Error 0.6244(0.6598) Steps 610(606.81) | Grad Norm 6.9780(10.8037) | Total Time 14.00(14.00)\n",
      "Iter 0520 | Time 13.9641(14.1455) | Bit/dim 4.9811(5.0976) | Xent 1.9168(1.9130) | Loss 5.9395(6.0541) | Error 0.6844(0.6686) Steps 604(607.14) | Grad Norm 13.7202(13.7202) | Total Time 14.00(14.00)\n",
      "Iter 0530 | Time 14.6432(14.1741) | Bit/dim 4.9894(5.0820) | Xent 1.9433(1.9327) | Loss 5.9610(6.0484) | Error 0.6778(0.6780) Steps 610(607.61) | Grad Norm 14.0850(16.0462) | Total Time 14.00(14.00)\n",
      "Iter 0540 | Time 14.4237(14.1616) | Bit/dim 4.9296(5.0558) | Xent 1.9541(1.9373) | Loss 5.9067(6.0244) | Error 0.6867(0.6800) Steps 604(608.06) | Grad Norm 3.5566(14.1114) | Total Time 14.00(14.00)\n",
      "Iter 0550 | Time 14.3697(14.2364) | Bit/dim 4.9508(5.0285) | Xent 1.9037(1.9316) | Loss 5.9027(5.9943) | Error 0.6600(0.6775) Steps 604(609.11) | Grad Norm 2.8994(11.7056) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0010 | Time 79.8242, Epoch Time 878.6045(841.1451), Bit/dim 4.9072(best: 5.0518), Xent 1.8275, Loss 5.8210, Error 0.6184(best: 0.6372)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0560 | Time 14.0199(14.3103) | Bit/dim 4.9252(4.9916) | Xent 1.8885(1.9097) | Loss 5.8694(5.9464) | Error 0.6644(0.6697) Steps 592(608.78) | Grad Norm 7.8018(10.0938) | Total Time 14.00(14.00)\n",
      "Iter 0570 | Time 14.3522(14.3239) | Bit/dim 4.8543(4.9606) | Xent 1.7941(1.8868) | Loss 5.7514(5.9040) | Error 0.6456(0.6612) Steps 598(606.42) | Grad Norm 11.0358(9.5008) | Total Time 14.00(14.00)\n",
      "Iter 0580 | Time 15.4913(14.4210) | Bit/dim 4.8674(4.9350) | Xent 1.8544(1.8777) | Loss 5.7946(5.8739) | Error 0.6433(0.6594) Steps 604(605.58) | Grad Norm 15.8556(11.5777) | Total Time 14.00(14.00)\n",
      "Iter 0590 | Time 15.3044(14.5002) | Bit/dim 4.8309(4.9106) | Xent 1.8226(1.8701) | Loss 5.7423(5.8456) | Error 0.6333(0.6565) Steps 622(606.06) | Grad Norm 17.0440(12.0257) | Total Time 14.00(14.00)\n",
      "Iter 0600 | Time 14.5326(14.6093) | Bit/dim 4.8073(4.8800) | Xent 1.8079(1.8574) | Loss 5.7112(5.8087) | Error 0.6233(0.6526) Steps 616(608.40) | Grad Norm 10.9981(11.4620) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0011 | Time 81.0221, Epoch Time 905.8851(843.0873), Bit/dim 4.7995(best: 4.9072), Xent 1.7330, Loss 5.6660, Error 0.5901(best: 0.6184)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0610 | Time 14.6894(14.6761) | Bit/dim 4.7660(4.8568) | Xent 1.7562(1.8370) | Loss 5.6441(5.7753) | Error 0.6211(0.6455) Steps 616(610.85) | Grad Norm 4.1179(11.6406) | Total Time 14.00(14.00)\n",
      "Iter 0620 | Time 15.2369(14.7786) | Bit/dim 4.7334(4.8349) | Xent 1.8640(1.8275) | Loss 5.6654(5.7487) | Error 0.6700(0.6425) Steps 634(614.01) | Grad Norm 27.2306(13.0429) | Total Time 14.00(14.00)\n",
      "Iter 0630 | Time 14.9548(14.8874) | Bit/dim 4.7467(4.8118) | Xent 1.7571(1.8165) | Loss 5.6253(5.7200) | Error 0.6133(0.6389) Steps 628(616.22) | Grad Norm 13.0979(13.1292) | Total Time 14.00(14.00)\n",
      "Iter 0640 | Time 15.3266(14.9462) | Bit/dim 4.8308(4.7952) | Xent 1.8435(1.8011) | Loss 5.7526(5.6958) | Error 0.6578(0.6338) Steps 616(617.65) | Grad Norm 30.4482(13.5912) | Total Time 14.00(14.00)\n",
      "Iter 0650 | Time 15.6928(15.1342) | Bit/dim 4.7239(4.7815) | Xent 1.8391(1.8234) | Loss 5.6434(5.6931) | Error 0.6767(0.6449) Steps 628(619.73) | Grad Norm 6.2074(14.3060) | Total Time 14.00(14.00)\n",
      "Iter 0660 | Time 14.9937(15.1422) | Bit/dim 4.6775(4.7594) | Xent 1.7351(1.8229) | Loss 5.5450(5.6709) | Error 0.6244(0.6461) Steps 622(621.23) | Grad Norm 6.5394(12.6986) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0012 | Time 82.1992, Epoch Time 935.5482(845.8612), Bit/dim 4.6969(best: 4.7995), Xent 1.7154, Loss 5.5546, Error 0.6036(best: 0.5901)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0670 | Time 14.4726(15.0852) | Bit/dim 4.6691(4.7431) | Xent 1.7731(1.8054) | Loss 5.5557(5.6458) | Error 0.6422(0.6379) Steps 616(620.57) | Grad Norm 14.3189(12.6330) | Total Time 14.00(14.00)\n",
      "Iter 0680 | Time 14.7591(15.0140) | Bit/dim 4.6911(4.7261) | Xent 1.7248(1.7814) | Loss 5.5535(5.6168) | Error 0.6089(0.6286) Steps 616(618.97) | Grad Norm 12.0696(11.6756) | Total Time 14.00(14.00)\n",
      "Iter 0690 | Time 14.8713(14.9507) | Bit/dim 4.6370(4.7038) | Xent 1.7085(1.7650) | Loss 5.4913(5.5863) | Error 0.6233(0.6245) Steps 616(618.33) | Grad Norm 9.4568(11.8636) | Total Time 14.00(14.00)\n",
      "Iter 0700 | Time 15.0308(14.9259) | Bit/dim 4.8632(4.7371) | Xent 1.9450(1.7755) | Loss 5.8357(5.6248) | Error 0.6478(0.6281) Steps 616(619.39) | Grad Norm 19.3048(13.3812) | Total Time 14.00(14.00)\n",
      "Iter 0710 | Time 14.8534(14.8846) | Bit/dim 4.7488(4.7605) | Xent 1.8999(1.7932) | Loss 5.6987(5.6571) | Error 0.6767(0.6341) Steps 610(616.63) | Grad Norm 17.7164(14.1261) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0013 | Time 80.6023, Epoch Time 913.4619(847.8892), Bit/dim 4.6872(best: 4.6969), Xent 1.7269, Loss 5.5507, Error 0.6077(best: 0.5901)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0720 | Time 14.7772(14.8449) | Bit/dim 4.6390(4.7487) | Xent 1.7125(1.7951) | Loss 5.4952(5.6463) | Error 0.6267(0.6371) Steps 604(613.33) | Grad Norm 4.0063(12.3128) | Total Time 14.00(14.00)\n",
      "Iter 0730 | Time 14.3677(14.7951) | Bit/dim 4.6438(4.7233) | Xent 1.7011(1.7677) | Loss 5.4944(5.6071) | Error 0.6011(0.6277) Steps 604(611.02) | Grad Norm 4.1187(10.9380) | Total Time 14.00(14.00)\n",
      "Iter 0740 | Time 14.5126(14.7126) | Bit/dim 4.5933(4.6942) | Xent 1.6232(1.7437) | Loss 5.4049(5.5661) | Error 0.5900(0.6196) Steps 610(609.54) | Grad Norm 3.7871(9.8287) | Total Time 14.00(14.00)\n",
      "Iter 0750 | Time 14.3171(14.6342) | Bit/dim 4.6304(4.6730) | Xent 1.8445(1.7477) | Loss 5.5527(5.5468) | Error 0.6600(0.6219) Steps 616(609.29) | Grad Norm 12.9650(11.3331) | Total Time 14.00(14.00)\n",
      "Iter 0760 | Time 14.8574(14.6971) | Bit/dim 4.5601(4.6510) | Xent 1.7625(1.7450) | Loss 5.4414(5.5235) | Error 0.6211(0.6216) Steps 622(611.69) | Grad Norm 9.0626(10.9903) | Total Time 14.00(14.00)\n",
      "Iter 0770 | Time 14.8272(14.7184) | Bit/dim 4.5557(4.6325) | Xent 1.6447(1.7295) | Loss 5.3781(5.4972) | Error 0.5822(0.6162) Steps 610(613.40) | Grad Norm 6.4768(10.1942) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0014 | Time 78.2680, Epoch Time 901.7345(849.5045), Bit/dim 4.5711(best: 4.6872), Xent 1.6165, Loss 5.3793, Error 0.5755(best: 0.5901)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0780 | Time 15.1537(14.8084) | Bit/dim 4.6587(4.6164) | Xent 1.6484(1.7060) | Loss 5.4829(5.4694) | Error 0.5667(0.6080) Steps 634(616.30) | Grad Norm 16.0061(10.4778) | Total Time 14.00(14.00)\n",
      "Iter 0790 | Time 15.0302(14.9027) | Bit/dim 4.5839(4.6169) | Xent 1.6528(1.6942) | Loss 5.4103(5.4640) | Error 0.6000(0.6048) Steps 634(619.92) | Grad Norm 12.7481(11.0384) | Total Time 14.00(14.00)\n",
      "Iter 0800 | Time 15.3801(14.9462) | Bit/dim 4.5681(4.6016) | Xent 1.6450(1.6889) | Loss 5.3906(5.4460) | Error 0.5944(0.6038) Steps 634(623.30) | Grad Norm 15.7140(10.5695) | Total Time 14.00(14.00)\n",
      "Iter 0810 | Time 15.1280(15.0587) | Bit/dim 4.5226(4.5829) | Xent 1.7047(1.6834) | Loss 5.3750(5.4245) | Error 0.6089(0.6029) Steps 640(627.41) | Grad Norm 9.3550(10.9336) | Total Time 14.00(14.00)\n",
      "Iter 0820 | Time 15.4539(15.0614) | Bit/dim 4.5246(4.5644) | Xent 1.6155(1.6740) | Loss 5.3323(5.4014) | Error 0.5900(0.6002) Steps 640(629.01) | Grad Norm 8.5497(10.3169) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0015 | Time 80.1592, Epoch Time 930.7117(851.9408), Bit/dim 4.4967(best: 4.5711), Xent 1.5338, Loss 5.2636, Error 0.5470(best: 0.5755)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0830 | Time 14.5735(15.0291) | Bit/dim 4.4990(4.5472) | Xent 1.6041(1.6602) | Loss 5.3011(5.3773) | Error 0.5933(0.5978) Steps 640(629.48) | Grad Norm 14.6304(10.0295) | Total Time 14.00(14.00)\n",
      "Iter 0840 | Time 15.5864(15.0789) | Bit/dim 4.4523(4.5333) | Xent 1.5267(1.6428) | Loss 5.2157(5.3547) | Error 0.5511(0.5915) Steps 646(632.60) | Grad Norm 6.4415(10.1197) | Total Time 14.00(14.00)\n",
      "Iter 0850 | Time 15.0556(15.1477) | Bit/dim 4.4629(4.5178) | Xent 1.5869(1.6331) | Loss 5.2564(5.3343) | Error 0.5967(0.5910) Steps 640(634.50) | Grad Norm 7.3550(9.0551) | Total Time 14.00(14.00)\n",
      "Iter 0860 | Time 15.2636(15.1392) | Bit/dim 4.4674(4.5009) | Xent 1.6463(1.6199) | Loss 5.2906(5.3109) | Error 0.5889(0.5868) Steps 646(635.23) | Grad Norm 9.6016(8.0659) | Total Time 14.00(14.00)\n",
      "Iter 0870 | Time 14.9230(15.1837) | Bit/dim 4.4953(4.4942) | Xent 1.6886(1.6251) | Loss 5.3396(5.3068) | Error 0.5911(0.5882) Steps 658(640.47) | Grad Norm 19.4293(9.0582) | Total Time 14.00(14.00)\n",
      "Iter 0880 | Time 15.2296(15.2389) | Bit/dim 4.4602(4.4836) | Xent 1.7004(1.6255) | Loss 5.3104(5.2963) | Error 0.6011(0.5868) Steps 634(639.75) | Grad Norm 5.3804(9.5185) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0016 | Time 81.1070, Epoch Time 936.6986(854.4835), Bit/dim 4.4361(best: 4.4967), Xent 1.5643, Loss 5.2182, Error 0.5575(best: 0.5470)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0890 | Time 15.9077(15.2919) | Bit/dim 4.4187(4.4683) | Xent 1.5806(1.6146) | Loss 5.2090(5.2756) | Error 0.5656(0.5829) Steps 646(640.42) | Grad Norm 8.9904(9.5903) | Total Time 14.00(14.00)\n",
      "Iter 0900 | Time 15.4907(15.2806) | Bit/dim 4.4089(4.4539) | Xent 1.6347(1.6040) | Loss 5.2263(5.2559) | Error 0.5789(0.5786) Steps 640(640.81) | Grad Norm 8.7197(8.7273) | Total Time 14.00(14.00)\n",
      "Iter 0910 | Time 14.4248(15.2935) | Bit/dim 4.4374(4.4562) | Xent 1.5786(1.6038) | Loss 5.2267(5.2581) | Error 0.5700(0.5782) Steps 634(640.02) | Grad Norm 9.0105(9.7454) | Total Time 14.00(14.00)\n",
      "Iter 0920 | Time 15.7325(15.2366) | Bit/dim 4.4012(4.4457) | Xent 1.6081(1.6032) | Loss 5.2053(5.2473) | Error 0.5878(0.5781) Steps 634(637.16) | Grad Norm 4.7372(9.0677) | Total Time 14.00(14.00)\n",
      "Iter 0930 | Time 15.2161(15.2692) | Bit/dim 4.4038(4.4325) | Xent 1.7151(1.6040) | Loss 5.2614(5.2345) | Error 0.6422(0.5796) Steps 658(640.13) | Grad Norm 27.7341(9.4093) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0017 | Time 83.5958, Epoch Time 943.5240(857.1547), Bit/dim 4.3898(best: 4.4361), Xent 1.5369, Loss 5.1582, Error 0.5596(best: 0.5470)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 0940 | Time 15.1393(15.2813) | Bit/dim 4.3711(4.4244) | Xent 1.5644(1.6073) | Loss 5.1533(5.2280) | Error 0.5933(0.5823) Steps 640(640.67) | Grad Norm 6.6579(9.3158) | Total Time 14.00(14.00)\n",
      "Iter 0950 | Time 15.9297(15.3658) | Bit/dim 4.3968(4.4125) | Xent 1.5615(1.5973) | Loss 5.1775(5.2112) | Error 0.5833(0.5785) Steps 652(641.14) | Grad Norm 13.8083(9.0720) | Total Time 14.00(14.00)\n",
      "Iter 0960 | Time 15.5377(15.4096) | Bit/dim 4.3542(4.4039) | Xent 1.4861(1.5878) | Loss 5.0973(5.1978) | Error 0.5567(0.5757) Steps 640(641.37) | Grad Norm 7.3969(9.3041) | Total Time 14.00(14.00)\n",
      "Iter 0970 | Time 15.0563(15.3445) | Bit/dim 4.3232(4.3853) | Xent 1.5353(1.5739) | Loss 5.0908(5.1722) | Error 0.5689(0.5734) Steps 640(638.25) | Grad Norm 8.3499(8.1157) | Total Time 14.00(14.00)\n",
      "Iter 0980 | Time 14.9451(15.2844) | Bit/dim 4.3516(4.3710) | Xent 1.5160(1.5689) | Loss 5.1097(5.1555) | Error 0.5356(0.5685) Steps 622(637.50) | Grad Norm 10.3892(8.4827) | Total Time 14.00(14.00)\n",
      "Iter 0990 | Time 14.6341(15.1602) | Bit/dim 4.3375(4.3585) | Xent 1.5893(1.5649) | Loss 5.1321(5.1410) | Error 0.5633(0.5665) Steps 628(632.66) | Grad Norm 8.6580(7.8529) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0018 | Time 80.8014, Epoch Time 936.2825(859.5285), Bit/dim 4.3115(best: 4.3898), Xent 1.4469, Loss 5.0350, Error 0.5231(best: 0.5470)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1000 | Time 15.4179(15.2542) | Bit/dim 4.2901(4.3441) | Xent 1.4832(1.5493) | Loss 5.0317(5.1187) | Error 0.5389(0.5595) Steps 646(634.74) | Grad Norm 8.8880(7.7208) | Total Time 14.00(14.00)\n",
      "Iter 1010 | Time 15.3640(15.2934) | Bit/dim 4.3157(4.3366) | Xent 1.5117(1.5319) | Loss 5.0716(5.1026) | Error 0.5322(0.5550) Steps 640(638.21) | Grad Norm 12.6185(7.6631) | Total Time 14.00(14.00)\n",
      "Iter 1020 | Time 14.7164(15.1747) | Bit/dim 4.2882(4.3258) | Xent 1.4618(1.5304) | Loss 5.0191(5.0910) | Error 0.5322(0.5549) Steps 628(635.02) | Grad Norm 5.0870(7.9680) | Total Time 14.00(14.00)\n",
      "Iter 1030 | Time 15.4716(15.2184) | Bit/dim 4.2500(4.3136) | Xent 1.5749(1.5358) | Loss 5.0375(5.0815) | Error 0.5511(0.5553) Steps 646(637.50) | Grad Norm 11.3127(8.6341) | Total Time 14.00(14.00)\n",
      "Iter 1040 | Time 14.8435(15.2025) | Bit/dim 4.2544(4.3001) | Xent 1.5387(1.5352) | Loss 5.0238(5.0677) | Error 0.5500(0.5538) Steps 646(640.50) | Grad Norm 5.0825(7.9514) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0019 | Time 84.0195, Epoch Time 941.1314(861.9766), Bit/dim 4.2593(best: 4.3115), Xent 1.4096, Loss 4.9641, Error 0.5102(best: 0.5231)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1050 | Time 15.4593(15.2202) | Bit/dim 4.2234(4.2885) | Xent 1.4279(1.5181) | Loss 4.9374(5.0475) | Error 0.5289(0.5485) Steps 628(640.25) | Grad Norm 4.3700(7.2046) | Total Time 14.00(14.00)\n",
      "Iter 1060 | Time 15.8673(15.2906) | Bit/dim 4.2724(4.2770) | Xent 1.5215(1.5037) | Loss 5.0331(5.0289) | Error 0.5267(0.5439) Steps 634(640.75) | Grad Norm 7.0745(7.1120) | Total Time 14.00(14.00)\n",
      "Iter 1070 | Time 15.0454(15.3475) | Bit/dim 4.3088(4.2754) | Xent 1.5287(1.5241) | Loss 5.0732(5.0374) | Error 0.5311(0.5495) Steps 634(642.08) | Grad Norm 7.7131(8.2312) | Total Time 14.00(14.00)\n",
      "Iter 1080 | Time 14.9950(15.3558) | Bit/dim 4.2817(4.2724) | Xent 1.4884(1.5306) | Loss 5.0259(5.0377) | Error 0.5356(0.5519) Steps 628(640.85) | Grad Norm 6.5046(8.3608) | Total Time 14.00(14.00)\n",
      "Iter 1090 | Time 15.0962(15.2609) | Bit/dim 4.2128(4.2636) | Xent 1.4839(1.5175) | Loss 4.9548(5.0224) | Error 0.5267(0.5478) Steps 634(634.75) | Grad Norm 6.8888(7.6913) | Total Time 14.00(14.00)\n",
      "Iter 1100 | Time 15.7157(15.2886) | Bit/dim 4.2360(4.2529) | Xent 1.4832(1.4981) | Loss 4.9776(5.0019) | Error 0.5333(0.5416) Steps 634(634.72) | Grad Norm 6.1386(7.4467) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0020 | Time 83.0845, Epoch Time 944.1034(864.4404), Bit/dim 4.2191(best: 4.2593), Xent 1.3740, Loss 4.9061, Error 0.4987(best: 0.5102)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1110 | Time 15.0197(15.2849) | Bit/dim 4.1997(4.2411) | Xent 1.4758(1.4773) | Loss 4.9376(4.9798) | Error 0.5500(0.5359) Steps 640(636.22) | Grad Norm 7.9437(6.8690) | Total Time 14.00(14.00)\n",
      "Iter 1120 | Time 15.0513(15.2522) | Bit/dim 4.2003(4.2306) | Xent 1.3863(1.4700) | Loss 4.8935(4.9656) | Error 0.5022(0.5327) Steps 640(637.54) | Grad Norm 5.8038(7.3445) | Total Time 14.00(14.00)\n",
      "Iter 1130 | Time 14.4933(15.1896) | Bit/dim 4.2026(4.2197) | Xent 1.4083(1.4560) | Loss 4.9067(4.9477) | Error 0.5089(0.5268) Steps 640(636.38) | Grad Norm 8.0980(7.4188) | Total Time 14.00(14.00)\n",
      "Iter 1140 | Time 15.7119(15.1312) | Bit/dim 4.1691(4.2087) | Xent 1.4840(1.4529) | Loss 4.9111(4.9352) | Error 0.5233(0.5254) Steps 652(636.15) | Grad Norm 14.1291(7.3312) | Total Time 14.00(14.00)\n",
      "Iter 1150 | Time 14.8229(15.1326) | Bit/dim 4.1785(4.1999) | Xent 1.4784(1.4504) | Loss 4.9177(4.9252) | Error 0.5300(0.5234) Steps 634(636.83) | Grad Norm 7.8357(7.3939) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0021 | Time 82.1381, Epoch Time 931.2310(866.4441), Bit/dim 4.1673(best: 4.2191), Xent 1.3431, Loss 4.8388, Error 0.4828(best: 0.4987)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1160 | Time 14.9491(15.1075) | Bit/dim 4.1640(4.1933) | Xent 1.3706(1.4359) | Loss 4.8494(4.9112) | Error 0.4911(0.5172) Steps 622(635.70) | Grad Norm 4.9061(7.3398) | Total Time 14.00(14.00)\n",
      "Iter 1170 | Time 15.1418(15.0666) | Bit/dim 4.1199(4.1816) | Xent 1.3831(1.4232) | Loss 4.8115(4.8932) | Error 0.4722(0.5115) Steps 622(631.37) | Grad Norm 3.9312(6.6069) | Total Time 14.00(14.00)\n",
      "Iter 1180 | Time 14.6247(15.0023) | Bit/dim 4.1663(4.1738) | Xent 1.4321(1.4215) | Loss 4.8823(4.8846) | Error 0.5444(0.5118) Steps 616(627.47) | Grad Norm 13.9209(7.1798) | Total Time 14.00(14.00)\n",
      "Iter 1190 | Time 15.4319(15.0402) | Bit/dim 4.1374(4.1681) | Xent 1.4497(1.4235) | Loss 4.8623(4.8798) | Error 0.4989(0.5105) Steps 646(628.39) | Grad Norm 8.4890(7.7203) | Total Time 14.00(14.00)\n",
      "Iter 1200 | Time 15.5891(15.0657) | Bit/dim 4.1470(4.1642) | Xent 1.4519(1.4237) | Loss 4.8730(4.8761) | Error 0.5011(0.5115) Steps 616(627.57) | Grad Norm 6.5522(7.4166) | Total Time 14.00(14.00)\n",
      "Iter 1210 | Time 15.0898(15.0642) | Bit/dim 4.1022(4.1564) | Xent 1.4170(1.4209) | Loss 4.8108(4.8669) | Error 0.5078(0.5120) Steps 610(624.11) | Grad Norm 7.1479(7.2038) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0022 | Time 79.3533, Epoch Time 923.7905(868.1645), Bit/dim 4.1259(best: 4.1673), Xent 1.3115, Loss 4.7817, Error 0.4756(best: 0.4828)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1220 | Time 14.0476(14.9931) | Bit/dim 4.1024(4.1468) | Xent 1.3422(1.4065) | Loss 4.7735(4.8501) | Error 0.4956(0.5066) Steps 598(618.92) | Grad Norm 4.9167(6.6522) | Total Time 14.00(14.00)\n",
      "Iter 1230 | Time 14.3285(14.9810) | Bit/dim 4.1051(4.1388) | Xent 1.3573(1.3975) | Loss 4.7838(4.8376) | Error 0.4967(0.5054) Steps 616(618.69) | Grad Norm 5.1195(6.8883) | Total Time 14.00(14.00)\n",
      "Iter 1240 | Time 15.1842(15.0362) | Bit/dim 4.1046(4.1300) | Xent 1.3419(1.3888) | Loss 4.7755(4.8244) | Error 0.4756(0.5007) Steps 628(620.40) | Grad Norm 3.7102(6.4015) | Total Time 14.00(14.00)\n",
      "Iter 1250 | Time 14.8268(15.0510) | Bit/dim 4.1029(4.1203) | Xent 1.3332(1.3759) | Loss 4.7695(4.8082) | Error 0.4889(0.4982) Steps 628(619.96) | Grad Norm 4.6923(5.8847) | Total Time 14.00(14.00)\n",
      "Iter 1260 | Time 14.9472(15.0072) | Bit/dim 4.1038(4.1134) | Xent 1.4611(1.3854) | Loss 4.8344(4.8061) | Error 0.5356(0.4998) Steps 622(619.33) | Grad Norm 9.1806(6.6919) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0023 | Time 80.6539, Epoch Time 923.1872(869.8152), Bit/dim 4.0931(best: 4.1259), Xent 1.3075, Loss 4.7469, Error 0.4781(best: 0.4756)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1270 | Time 14.0259(15.0016) | Bit/dim 4.0866(4.1101) | Xent 1.2912(1.3813) | Loss 4.7323(4.8007) | Error 0.4667(0.4972) Steps 604(617.42) | Grad Norm 5.5536(6.8887) | Total Time 14.00(14.00)\n",
      "Iter 1280 | Time 14.8366(14.9686) | Bit/dim 4.0496(4.1028) | Xent 1.2929(1.3742) | Loss 4.6960(4.7899) | Error 0.4511(0.4952) Steps 616(615.49) | Grad Norm 5.4728(7.0385) | Total Time 14.00(14.00)\n",
      "Iter 1290 | Time 15.1196(14.9596) | Bit/dim 4.0615(4.0987) | Xent 1.3501(1.3681) | Loss 4.7366(4.7827) | Error 0.4867(0.4932) Steps 622(613.01) | Grad Norm 4.6829(7.0217) | Total Time 14.00(14.00)\n",
      "Iter 1300 | Time 15.3902(14.9727) | Bit/dim 4.0870(4.0897) | Xent 1.3332(1.3597) | Loss 4.7536(4.7695) | Error 0.4689(0.4918) Steps 598(610.20) | Grad Norm 10.3094(6.6048) | Total Time 14.00(14.00)\n",
      "Iter 1310 | Time 15.0553(14.9472) | Bit/dim 4.0723(4.0838) | Xent 1.3150(1.3588) | Loss 4.7299(4.7632) | Error 0.4989(0.4920) Steps 604(610.04) | Grad Norm 5.0466(6.3059) | Total Time 14.00(14.00)\n",
      "Iter 1320 | Time 15.5465(15.0103) | Bit/dim 4.0735(4.0764) | Xent 1.3081(1.3486) | Loss 4.7276(4.7506) | Error 0.4589(0.4869) Steps 622(609.88) | Grad Norm 6.0753(6.1010) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0024 | Time 80.2530, Epoch Time 921.0806(871.3532), Bit/dim 4.0530(best: 4.0931), Xent 1.2382, Loss 4.6721, Error 0.4482(best: 0.4756)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1330 | Time 14.6608(15.0065) | Bit/dim 4.0625(4.0685) | Xent 1.5055(1.3549) | Loss 4.8152(4.7460) | Error 0.5289(0.4880) Steps 598(609.88) | Grad Norm 9.4118(6.7139) | Total Time 14.00(14.00)\n",
      "Iter 1340 | Time 14.6592(15.0479) | Bit/dim 4.0752(4.0670) | Xent 1.3509(1.3570) | Loss 4.7506(4.7455) | Error 0.4911(0.4886) Steps 598(609.65) | Grad Norm 4.3107(7.1855) | Total Time 14.00(14.00)\n",
      "Iter 1350 | Time 15.4780(15.1170) | Bit/dim 4.0639(4.0625) | Xent 1.2822(1.3448) | Loss 4.7050(4.7348) | Error 0.4644(0.4851) Steps 622(609.00) | Grad Norm 5.4097(6.8475) | Total Time 14.00(14.00)\n",
      "Iter 1360 | Time 15.1798(15.1320) | Bit/dim 4.0526(4.0556) | Xent 1.3009(1.3337) | Loss 4.7031(4.7225) | Error 0.4822(0.4806) Steps 598(607.64) | Grad Norm 3.9435(6.4534) | Total Time 14.00(14.00)\n",
      "Iter 1370 | Time 15.4946(15.0780) | Bit/dim 4.0123(4.0506) | Xent 1.2791(1.3314) | Loss 4.6519(4.7163) | Error 0.4689(0.4795) Steps 610(607.77) | Grad Norm 4.5279(6.5590) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0025 | Time 78.4903, Epoch Time 926.2210(872.9992), Bit/dim 4.0291(best: 4.0530), Xent 1.2369, Loss 4.6476, Error 0.4484(best: 0.4482)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1380 | Time 15.3749(15.0660) | Bit/dim 4.0504(4.0471) | Xent 1.2740(1.3258) | Loss 4.6874(4.7100) | Error 0.4711(0.4778) Steps 598(606.94) | Grad Norm 4.3042(6.7584) | Total Time 14.00(14.00)\n",
      "Iter 1390 | Time 14.4445(14.9633) | Bit/dim 4.0513(4.0429) | Xent 1.3496(1.3220) | Loss 4.7261(4.7039) | Error 0.4867(0.4770) Steps 598(606.02) | Grad Norm 4.1415(6.2752) | Total Time 14.00(14.00)\n",
      "Iter 1400 | Time 14.6296(14.9927) | Bit/dim 4.0322(4.0400) | Xent 1.2853(1.3141) | Loss 4.6749(4.6970) | Error 0.4411(0.4744) Steps 598(605.21) | Grad Norm 8.5538(6.2719) | Total Time 14.00(14.00)\n",
      "Iter 1410 | Time 14.7450(14.9297) | Bit/dim 4.0009(4.0339) | Xent 1.2833(1.3079) | Loss 4.6425(4.6878) | Error 0.4567(0.4708) Steps 616(603.66) | Grad Norm 5.7294(6.3443) | Total Time 14.00(14.00)\n",
      "Iter 1420 | Time 15.0828(14.9353) | Bit/dim 3.9693(4.0254) | Xent 1.3254(1.3063) | Loss 4.6320(4.6786) | Error 0.4900(0.4720) Steps 580(601.35) | Grad Norm 2.1374(6.0749) | Total Time 14.00(14.00)\n",
      "Iter 1430 | Time 14.4135(14.9141) | Bit/dim 3.9782(4.0201) | Xent 1.2560(1.2981) | Loss 4.6062(4.6691) | Error 0.4589(0.4695) Steps 592(599.26) | Grad Norm 3.3370(6.3244) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0026 | Time 79.1264, Epoch Time 916.3595(874.3000), Bit/dim 4.0114(best: 4.0291), Xent 1.2421, Loss 4.6324, Error 0.4513(best: 0.4482)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1440 | Time 14.6761(14.9168) | Bit/dim 4.0039(4.0141) | Xent 1.2908(1.2868) | Loss 4.6493(4.6575) | Error 0.4778(0.4640) Steps 592(598.36) | Grad Norm 3.5452(5.9589) | Total Time 14.00(14.00)\n",
      "Iter 1450 | Time 15.4787(14.8844) | Bit/dim 4.0095(4.0103) | Xent 1.2781(1.2776) | Loss 4.6486(4.6491) | Error 0.4700(0.4605) Steps 592(596.54) | Grad Norm 9.8433(5.6659) | Total Time 14.00(14.00)\n",
      "Iter 1460 | Time 15.0984(14.9296) | Bit/dim 3.9885(4.0057) | Xent 1.3395(1.2854) | Loss 4.6582(4.6483) | Error 0.4833(0.4627) Steps 604(599.14) | Grad Norm 8.3380(6.5239) | Total Time 14.00(14.00)\n",
      "Iter 1470 | Time 14.6796(14.9124) | Bit/dim 3.9912(4.0055) | Xent 1.3081(1.2873) | Loss 4.6452(4.6491) | Error 0.4744(0.4632) Steps 592(597.60) | Grad Norm 4.9067(6.4119) | Total Time 14.00(14.00)\n",
      "Iter 1480 | Time 14.6244(14.9298) | Bit/dim 3.9872(4.0009) | Xent 1.2225(1.2792) | Loss 4.5984(4.6405) | Error 0.4589(0.4626) Steps 604(597.90) | Grad Norm 5.6148(5.9339) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0027 | Time 78.6427, Epoch Time 917.1915(875.5868), Bit/dim 3.9831(best: 4.0114), Xent 1.2158, Loss 4.5910, Error 0.4431(best: 0.4482)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1490 | Time 14.4048(14.9037) | Bit/dim 3.9955(3.9977) | Xent 1.2180(1.2775) | Loss 4.6045(4.6365) | Error 0.4367(0.4617) Steps 598(598.66) | Grad Norm 4.5337(6.3206) | Total Time 14.00(14.00)\n",
      "Iter 1500 | Time 14.7133(14.8371) | Bit/dim 4.0049(3.9965) | Xent 1.2538(1.2673) | Loss 4.6318(4.6302) | Error 0.4456(0.4573) Steps 580(598.38) | Grad Norm 5.3626(6.3332) | Total Time 14.00(14.00)\n",
      "Iter 1510 | Time 14.9381(14.8074) | Bit/dim 3.9832(3.9900) | Xent 1.2559(1.2559) | Loss 4.6111(4.6180) | Error 0.4411(0.4519) Steps 598(596.99) | Grad Norm 4.5203(5.8208) | Total Time 14.00(14.00)\n",
      "Iter 1520 | Time 14.8843(14.7286) | Bit/dim 3.9662(3.9874) | Xent 1.2540(1.2513) | Loss 4.5932(4.6131) | Error 0.4422(0.4500) Steps 598(594.92) | Grad Norm 11.3487(5.7894) | Total Time 14.00(14.00)\n",
      "Iter 1530 | Time 15.1587(14.7196) | Bit/dim 3.9649(3.9820) | Xent 1.2482(1.2562) | Loss 4.5890(4.6101) | Error 0.4422(0.4511) Steps 598(594.89) | Grad Norm 9.1954(6.2614) | Total Time 14.00(14.00)\n",
      "Iter 1540 | Time 14.5558(14.6968) | Bit/dim 3.9448(3.9759) | Xent 1.2322(1.2580) | Loss 4.5609(4.6048) | Error 0.4544(0.4506) Steps 604(594.02) | Grad Norm 4.7838(6.4084) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0028 | Time 79.1222, Epoch Time 902.7142(876.4006), Bit/dim 3.9650(best: 3.9831), Xent 1.2464, Loss 4.5882, Error 0.4494(best: 0.4431)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1550 | Time 14.2490(14.6944) | Bit/dim 3.9982(3.9758) | Xent 1.2553(1.2588) | Loss 4.6258(4.6052) | Error 0.4789(0.4524) Steps 592(594.39) | Grad Norm 3.5663(6.7990) | Total Time 14.00(14.00)\n",
      "Iter 1560 | Time 14.3737(14.7045) | Bit/dim 3.9737(3.9740) | Xent 1.1879(1.2461) | Loss 4.5677(4.5971) | Error 0.4300(0.4471) Steps 598(595.14) | Grad Norm 5.3745(6.6347) | Total Time 14.00(14.00)\n",
      "Iter 1570 | Time 15.0485(14.7349) | Bit/dim 3.9577(3.9689) | Xent 1.1673(1.2411) | Loss 4.5413(4.5895) | Error 0.4278(0.4452) Steps 580(594.36) | Grad Norm 4.5783(6.2724) | Total Time 14.00(14.00)\n",
      "Iter 1580 | Time 14.8247(14.7698) | Bit/dim 3.9715(3.9662) | Xent 1.2088(1.2377) | Loss 4.5759(4.5851) | Error 0.4533(0.4440) Steps 586(593.82) | Grad Norm 5.8498(6.6405) | Total Time 14.00(14.00)\n",
      "Iter 1590 | Time 14.9481(14.8013) | Bit/dim 3.9363(3.9638) | Xent 1.2188(1.2409) | Loss 4.5457(4.5843) | Error 0.4422(0.4452) Steps 586(592.37) | Grad Norm 4.7738(6.9686) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0029 | Time 76.7511, Epoch Time 909.1998(877.3846), Bit/dim 3.9521(best: 3.9650), Xent 1.1758, Loss 4.5400, Error 0.4227(best: 0.4431)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1600 | Time 14.3717(14.7844) | Bit/dim 3.9595(3.9615) | Xent 1.2008(1.2371) | Loss 4.5599(4.5801) | Error 0.4567(0.4434) Steps 592(591.83) | Grad Norm 8.6225(6.7643) | Total Time 14.00(14.00)\n",
      "Iter 1610 | Time 15.1490(14.7204) | Bit/dim 3.9782(3.9602) | Xent 1.2370(1.2293) | Loss 4.5967(4.5748) | Error 0.4444(0.4408) Steps 598(592.80) | Grad Norm 6.3904(6.4915) | Total Time 14.00(14.00)\n",
      "Iter 1620 | Time 14.2932(14.7220) | Bit/dim 3.9646(3.9559) | Xent 1.1980(1.2201) | Loss 4.5636(4.5659) | Error 0.4378(0.4364) Steps 598(593.68) | Grad Norm 7.8809(6.2534) | Total Time 14.00(14.00)\n",
      "Iter 1630 | Time 14.4523(14.6834) | Bit/dim 3.9377(3.9503) | Xent 1.1562(1.2105) | Loss 4.5158(4.5556) | Error 0.4233(0.4342) Steps 604(595.07) | Grad Norm 5.0835(5.8615) | Total Time 14.00(14.00)\n",
      "Iter 1640 | Time 14.1485(14.7277) | Bit/dim 3.9676(3.9486) | Xent 1.2647(1.2121) | Loss 4.5999(4.5547) | Error 0.4567(0.4322) Steps 592(597.34) | Grad Norm 8.3429(6.5334) | Total Time 14.00(14.00)\n",
      "Iter 1650 | Time 14.1140(14.7247) | Bit/dim 3.9243(3.9458) | Xent 1.1495(1.2088) | Loss 4.4990(4.5502) | Error 0.4267(0.4318) Steps 598(597.01) | Grad Norm 4.6874(6.4442) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0030 | Time 78.3815, Epoch Time 903.5806(878.1704), Bit/dim 3.9335(best: 3.9521), Xent 1.1299, Loss 4.4984, Error 0.4096(best: 0.4227)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1660 | Time 14.5067(14.7364) | Bit/dim 3.9294(3.9423) | Xent 1.1502(1.2005) | Loss 4.5045(4.5425) | Error 0.3989(0.4286) Steps 580(596.85) | Grad Norm 6.3918(6.2705) | Total Time 14.00(14.00)\n",
      "Iter 1670 | Time 14.3613(14.7392) | Bit/dim 3.9444(3.9431) | Xent 1.2243(1.2001) | Loss 4.5566(4.5431) | Error 0.4289(0.4304) Steps 598(596.99) | Grad Norm 7.2097(6.3253) | Total Time 14.00(14.00)\n",
      "Iter 1680 | Time 14.6434(14.6951) | Bit/dim 3.9310(3.9405) | Xent 1.1401(1.1911) | Loss 4.5010(4.5360) | Error 0.4189(0.4288) Steps 580(595.86) | Grad Norm 3.7359(6.1619) | Total Time 14.00(14.00)\n",
      "Iter 1690 | Time 14.2044(14.6998) | Bit/dim 3.8905(3.9352) | Xent 1.1394(1.1909) | Loss 4.4603(4.5306) | Error 0.4267(0.4289) Steps 598(595.11) | Grad Norm 4.6791(6.3123) | Total Time 14.00(14.00)\n",
      "Iter 1700 | Time 14.5582(14.6984) | Bit/dim 3.9250(3.9297) | Xent 1.1137(1.1804) | Loss 4.4819(4.5199) | Error 0.3933(0.4238) Steps 592(594.56) | Grad Norm 4.3372(6.2172) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0031 | Time 79.1887, Epoch Time 906.8301(879.0302), Bit/dim 3.9238(best: 3.9335), Xent 1.1356, Loss 4.4916, Error 0.4115(best: 0.4096)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1710 | Time 14.7457(14.7500) | Bit/dim 3.9344(3.9300) | Xent 1.1639(1.1822) | Loss 4.5163(4.5211) | Error 0.4189(0.4244) Steps 574(594.58) | Grad Norm 5.0821(6.3032) | Total Time 14.00(14.00)\n",
      "Iter 1720 | Time 14.4916(14.7121) | Bit/dim 3.9063(3.9266) | Xent 1.1569(1.1764) | Loss 4.4847(4.5148) | Error 0.4222(0.4207) Steps 586(594.68) | Grad Norm 5.8967(6.3023) | Total Time 14.00(14.00)\n",
      "Iter 1730 | Time 14.6956(14.7305) | Bit/dim 3.9579(3.9257) | Xent 1.1703(1.1783) | Loss 4.5431(4.5149) | Error 0.4200(0.4214) Steps 616(595.82) | Grad Norm 5.6427(6.2318) | Total Time 14.00(14.00)\n",
      "Iter 1740 | Time 14.1672(14.7280) | Bit/dim 3.9044(3.9234) | Xent 1.1293(1.1743) | Loss 4.4690(4.5105) | Error 0.4100(0.4204) Steps 592(595.79) | Grad Norm 5.5606(6.4250) | Total Time 14.00(14.00)\n",
      "Iter 1750 | Time 14.2747(14.7115) | Bit/dim 3.9316(3.9223) | Xent 1.1209(1.1634) | Loss 4.4920(4.5040) | Error 0.3911(0.4161) Steps 598(594.76) | Grad Norm 4.8047(6.2189) | Total Time 14.00(14.00)\n",
      "Iter 1760 | Time 14.8336(14.7317) | Bit/dim 3.8772(3.9164) | Xent 1.1319(1.1563) | Loss 4.4432(4.4945) | Error 0.4178(0.4150) Steps 604(593.89) | Grad Norm 5.4786(5.9479) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0032 | Time 79.9826, Epoch Time 908.3612(879.9102), Bit/dim 3.9095(best: 3.9238), Xent 1.1136, Loss 4.4662, Error 0.4054(best: 0.4096)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1770 | Time 14.9047(14.7553) | Bit/dim 3.8910(3.9125) | Xent 1.2034(1.1512) | Loss 4.4927(4.4881) | Error 0.4300(0.4133) Steps 586(594.31) | Grad Norm 3.6238(5.6899) | Total Time 14.00(14.00)\n",
      "Iter 1780 | Time 14.2875(14.7178) | Bit/dim 3.8946(3.9077) | Xent 1.1001(1.1357) | Loss 4.4447(4.4755) | Error 0.3833(0.4074) Steps 592(595.23) | Grad Norm 4.2493(5.4082) | Total Time 14.00(14.00)\n",
      "Iter 1790 | Time 14.6795(14.7370) | Bit/dim 3.8992(3.9040) | Xent 1.2033(1.1405) | Loss 4.5009(4.4742) | Error 0.4467(0.4099) Steps 592(595.37) | Grad Norm 8.6104(5.7492) | Total Time 14.00(14.00)\n",
      "Iter 1800 | Time 14.9326(14.7119) | Bit/dim 3.8863(3.9032) | Xent 1.1458(1.1407) | Loss 4.4592(4.4736) | Error 0.4044(0.4090) Steps 592(595.50) | Grad Norm 5.2793(6.1358) | Total Time 14.00(14.00)\n",
      "Iter 1810 | Time 15.2451(14.7461) | Bit/dim 3.9261(3.9055) | Xent 1.2841(1.1433) | Loss 4.5682(4.4771) | Error 0.4256(0.4080) Steps 616(595.32) | Grad Norm 7.8326(6.1131) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0033 | Time 76.2136, Epoch Time 903.8007(880.6269), Bit/dim 3.9037(best: 3.9095), Xent 1.0909, Loss 4.4492, Error 0.3868(best: 0.4054)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1820 | Time 14.2872(14.7080) | Bit/dim 3.9293(3.9037) | Xent 1.0198(1.1339) | Loss 4.4392(4.4706) | Error 0.3478(0.4050) Steps 580(594.71) | Grad Norm 6.2645(6.0319) | Total Time 14.00(14.00)\n",
      "Iter 1830 | Time 13.8573(14.6809) | Bit/dim 3.9062(3.9017) | Xent 1.1507(1.1315) | Loss 4.4815(4.4674) | Error 0.4022(0.4036) Steps 592(595.52) | Grad Norm 6.2455(5.8253) | Total Time 14.00(14.00)\n",
      "Iter 1840 | Time 14.8699(14.6906) | Bit/dim 3.9000(3.9018) | Xent 1.1546(1.1310) | Loss 4.4773(4.4673) | Error 0.4022(0.4030) Steps 592(595.34) | Grad Norm 7.0306(6.6040) | Total Time 14.00(14.00)\n",
      "Iter 1850 | Time 14.5166(14.7615) | Bit/dim 3.8874(3.9009) | Xent 1.0775(1.1205) | Loss 4.4262(4.4611) | Error 0.4044(0.3979) Steps 598(595.00) | Grad Norm 5.3312(6.1852) | Total Time 14.00(14.00)\n",
      "Iter 1860 | Time 15.2810(14.7799) | Bit/dim 3.8882(3.8969) | Xent 1.0967(1.1134) | Loss 4.4365(4.4536) | Error 0.3756(0.3943) Steps 598(594.91) | Grad Norm 3.2109(5.6088) | Total Time 14.00(14.00)\n",
      "Iter 1870 | Time 14.4475(14.7413) | Bit/dim 3.8707(3.8926) | Xent 1.1063(1.1035) | Loss 4.4239(4.4444) | Error 0.3878(0.3908) Steps 592(594.12) | Grad Norm 4.4105(5.4870) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0034 | Time 77.2592, Epoch Time 905.6023(881.3761), Bit/dim 3.8828(best: 3.9037), Xent 1.0623, Loss 4.4139, Error 0.3763(best: 0.3868)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1880 | Time 14.6744(14.7062) | Bit/dim 3.9182(3.8898) | Xent 1.1419(1.1001) | Loss 4.4891(4.4398) | Error 0.3833(0.3897) Steps 592(593.73) | Grad Norm 7.1194(5.8897) | Total Time 14.00(14.00)\n",
      "Iter 1890 | Time 14.4297(14.6913) | Bit/dim 3.8878(3.8892) | Xent 1.0553(1.1015) | Loss 4.4154(4.4399) | Error 0.3800(0.3905) Steps 592(594.30) | Grad Norm 4.4393(5.8414) | Total Time 14.00(14.00)\n",
      "Iter 1900 | Time 14.3974(14.6558) | Bit/dim 3.8773(3.8870) | Xent 1.0981(1.0974) | Loss 4.4263(4.4357) | Error 0.3922(0.3901) Steps 598(595.39) | Grad Norm 4.7167(6.0064) | Total Time 14.00(14.00)\n",
      "Iter 1910 | Time 14.5613(14.7353) | Bit/dim 3.8757(3.8848) | Xent 1.1630(1.0968) | Loss 4.4572(4.4332) | Error 0.4133(0.3901) Steps 592(595.30) | Grad Norm 7.2885(6.1941) | Total Time 14.00(14.00)\n",
      "Iter 1920 | Time 15.1327(14.8308) | Bit/dim 3.8902(3.8843) | Xent 1.0924(1.1039) | Loss 4.4364(4.4362) | Error 0.3878(0.3930) Steps 598(596.27) | Grad Norm 8.0564(6.2171) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0035 | Time 79.2714, Epoch Time 911.3742(882.2761), Bit/dim 3.8785(best: 3.8828), Xent 1.0348, Loss 4.3959, Error 0.3724(best: 0.3763)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1930 | Time 14.9443(14.8643) | Bit/dim 3.9028(3.8812) | Xent 1.1320(1.1021) | Loss 4.4688(4.4323) | Error 0.4189(0.3940) Steps 592(597.24) | Grad Norm 6.8663(6.2459) | Total Time 14.00(14.00)\n",
      "Iter 1940 | Time 14.8203(14.8187) | Bit/dim 3.8782(3.8762) | Xent 1.0866(1.0906) | Loss 4.4215(4.4215) | Error 0.3767(0.3903) Steps 592(597.51) | Grad Norm 3.6246(5.7971) | Total Time 14.00(14.00)\n",
      "Iter 1950 | Time 14.4415(14.7722) | Bit/dim 3.8881(3.8755) | Xent 1.0210(1.0778) | Loss 4.3986(4.4144) | Error 0.3567(0.3850) Steps 592(597.44) | Grad Norm 6.0538(5.6207) | Total Time 14.00(14.00)\n",
      "Iter 1960 | Time 14.4556(14.7445) | Bit/dim 3.8906(3.8744) | Xent 1.1144(1.0723) | Loss 4.4478(4.4105) | Error 0.3933(0.3820) Steps 592(596.46) | Grad Norm 6.8368(5.6243) | Total Time 14.00(14.00)\n",
      "Iter 1970 | Time 15.0472(14.7751) | Bit/dim 3.8472(3.8699) | Xent 1.1264(1.0808) | Loss 4.4103(4.4103) | Error 0.4067(0.3861) Steps 598(597.35) | Grad Norm 6.9641(5.8757) | Total Time 14.00(14.00)\n",
      "Iter 1980 | Time 14.5188(14.7461) | Bit/dim 3.9031(3.8694) | Xent 1.1011(1.0798) | Loss 4.4537(4.4093) | Error 0.4111(0.3853) Steps 598(597.09) | Grad Norm 6.9391(5.9145) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0036 | Time 80.6226, Epoch Time 908.2967(883.0567), Bit/dim 3.8663(best: 3.8785), Xent 0.9926, Loss 4.3626, Error 0.3576(best: 0.3724)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 1990 | Time 15.2198(14.8171) | Bit/dim 3.8285(3.8676) | Xent 1.0812(1.0728) | Loss 4.3691(4.4040) | Error 0.3800(0.3818) Steps 604(597.37) | Grad Norm 7.4761(5.8657) | Total Time 14.00(14.00)\n",
      "Iter 2000 | Time 14.8719(14.7861) | Bit/dim 3.8632(3.8665) | Xent 1.0496(1.0668) | Loss 4.3880(4.3999) | Error 0.3878(0.3794) Steps 598(597.34) | Grad Norm 4.4355(5.7039) | Total Time 14.00(14.00)\n",
      "Iter 2010 | Time 14.5079(14.7916) | Bit/dim 3.8618(3.8637) | Xent 1.1406(1.0658) | Loss 4.4321(4.3966) | Error 0.4033(0.3801) Steps 592(597.68) | Grad Norm 5.8797(6.1569) | Total Time 14.00(14.00)\n",
      "Iter 2020 | Time 14.8988(14.8216) | Bit/dim 3.8206(3.8604) | Xent 1.0761(1.0735) | Loss 4.3587(4.3971) | Error 0.3756(0.3825) Steps 598(597.80) | Grad Norm 6.3294(6.1076) | Total Time 14.00(14.00)\n",
      "Iter 2030 | Time 15.1377(14.7984) | Bit/dim 3.8471(3.8597) | Xent 1.0125(1.0637) | Loss 4.3533(4.3916) | Error 0.3711(0.3793) Steps 598(597.67) | Grad Norm 5.5079(5.7021) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0037 | Time 78.6411, Epoch Time 912.1832(883.9305), Bit/dim 3.8566(best: 3.8663), Xent 0.9876, Loss 4.3504, Error 0.3544(best: 0.3576)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2040 | Time 14.9293(14.8113) | Bit/dim 3.8605(3.8598) | Xent 1.0547(1.0588) | Loss 4.3878(4.3892) | Error 0.3867(0.3782) Steps 592(597.76) | Grad Norm 6.9533(5.6161) | Total Time 14.00(14.00)\n",
      "Iter 2050 | Time 14.6048(14.8064) | Bit/dim 3.8902(3.8598) | Xent 1.1122(1.0526) | Loss 4.4464(4.3860) | Error 0.3789(0.3737) Steps 604(597.39) | Grad Norm 10.7881(5.6219) | Total Time 14.00(14.00)\n",
      "Iter 2060 | Time 14.6830(14.7521) | Bit/dim 3.8704(3.8596) | Xent 1.1130(1.0526) | Loss 4.4269(4.3859) | Error 0.4056(0.3759) Steps 592(596.74) | Grad Norm 5.6847(5.8921) | Total Time 14.00(14.00)\n",
      "Iter 2070 | Time 15.0380(14.7708) | Bit/dim 3.8127(3.8560) | Xent 1.0333(1.0528) | Loss 4.3294(4.3824) | Error 0.3767(0.3749) Steps 598(597.21) | Grad Norm 4.3863(5.9839) | Total Time 14.00(14.00)\n",
      "Iter 2080 | Time 15.3335(14.7573) | Bit/dim 3.8360(3.8538) | Xent 1.0572(1.0547) | Loss 4.3646(4.3812) | Error 0.3933(0.3761) Steps 598(597.44) | Grad Norm 3.6083(6.0602) | Total Time 14.00(14.00)\n",
      "Iter 2090 | Time 15.3028(14.8189) | Bit/dim 3.8330(3.8492) | Xent 1.0572(1.0515) | Loss 4.3616(4.3750) | Error 0.3833(0.3759) Steps 598(597.44) | Grad Norm 7.9229(5.5810) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0038 | Time 77.9650, Epoch Time 909.7996(884.7066), Bit/dim 3.8485(best: 3.8566), Xent 0.9708, Loss 4.3339, Error 0.3470(best: 0.3544)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2100 | Time 14.2730(14.7494) | Bit/dim 3.8656(3.8495) | Xent 1.0495(1.0465) | Loss 4.3903(4.3728) | Error 0.3911(0.3746) Steps 598(597.27) | Grad Norm 5.9258(5.8733) | Total Time 14.00(14.00)\n",
      "Iter 2110 | Time 14.6219(14.7060) | Bit/dim 3.8726(3.8508) | Xent 1.0623(1.0405) | Loss 4.4038(4.3711) | Error 0.3633(0.3712) Steps 598(597.31) | Grad Norm 8.4041(6.3141) | Total Time 14.00(14.00)\n",
      "Iter 2120 | Time 14.2638(14.7166) | Bit/dim 3.8807(3.8533) | Xent 1.0795(1.0479) | Loss 4.4204(4.3772) | Error 0.3956(0.3742) Steps 604(596.73) | Grad Norm 6.9486(6.7088) | Total Time 14.00(14.00)\n",
      "Iter 2130 | Time 14.5365(14.7182) | Bit/dim 3.8447(3.8502) | Xent 1.0213(1.0450) | Loss 4.3553(4.3727) | Error 0.3733(0.3724) Steps 598(597.09) | Grad Norm 5.5884(6.2883) | Total Time 14.00(14.00)\n",
      "Iter 2140 | Time 15.3072(14.7466) | Bit/dim 3.8390(3.8463) | Xent 0.9890(1.0424) | Loss 4.3335(4.3675) | Error 0.3467(0.3716) Steps 610(597.42) | Grad Norm 4.6364(5.9596) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0039 | Time 77.7996, Epoch Time 904.1930(885.2912), Bit/dim 3.8411(best: 3.8485), Xent 0.9786, Loss 4.3304, Error 0.3484(best: 0.3470)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2150 | Time 15.0024(14.7514) | Bit/dim 3.8400(3.8433) | Xent 0.9300(1.0338) | Loss 4.3050(4.3602) | Error 0.3400(0.3697) Steps 598(597.23) | Grad Norm 3.4703(5.6874) | Total Time 14.00(14.00)\n",
      "Iter 2160 | Time 15.0827(14.7642) | Bit/dim 3.8485(3.8408) | Xent 0.9599(1.0260) | Loss 4.3284(4.3538) | Error 0.3356(0.3653) Steps 592(596.78) | Grad Norm 6.0312(5.4145) | Total Time 14.00(14.00)\n",
      "Iter 2170 | Time 14.2858(14.7305) | Bit/dim 3.8457(3.8426) | Xent 1.0627(1.0469) | Loss 4.3770(4.3661) | Error 0.3789(0.3715) Steps 592(596.02) | Grad Norm 6.2292(6.6923) | Total Time 14.00(14.00)\n",
      "Iter 2180 | Time 14.9268(14.8228) | Bit/dim 3.8459(3.8416) | Xent 0.9995(1.0564) | Loss 4.3457(4.3698) | Error 0.3478(0.3759) Steps 598(597.48) | Grad Norm 4.7599(6.5060) | Total Time 14.00(14.00)\n",
      "Iter 2190 | Time 15.4075(14.8329) | Bit/dim 3.8161(3.8411) | Xent 1.0409(1.0521) | Loss 4.3366(4.3672) | Error 0.3511(0.3733) Steps 592(597.16) | Grad Norm 8.7056(6.0628) | Total Time 14.00(14.00)\n",
      "Iter 2200 | Time 15.0360(14.8503) | Bit/dim 3.8329(3.8393) | Xent 1.1508(1.0463) | Loss 4.4083(4.3624) | Error 0.3889(0.3697) Steps 592(596.73) | Grad Norm 14.0689(6.2124) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0040 | Time 77.6868, Epoch Time 912.0260(886.0932), Bit/dim 3.8478(best: 3.8411), Xent 1.0568, Loss 4.3761, Error 0.3782(best: 0.3470)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2210 | Time 14.6441(14.7689) | Bit/dim 3.8085(3.8375) | Xent 0.9986(1.0452) | Loss 4.3078(4.3601) | Error 0.3444(0.3695) Steps 592(595.49) | Grad Norm 3.5153(6.2625) | Total Time 14.00(14.00)\n",
      "Iter 2220 | Time 14.5390(14.7413) | Bit/dim 3.8433(3.8401) | Xent 1.0388(1.0466) | Loss 4.3627(4.3634) | Error 0.3822(0.3704) Steps 592(594.87) | Grad Norm 9.3502(6.6480) | Total Time 14.00(14.00)\n",
      "Iter 2230 | Time 14.5168(14.7666) | Bit/dim 3.8109(3.8359) | Xent 0.9672(1.0358) | Loss 4.2945(4.3538) | Error 0.3533(0.3680) Steps 580(593.07) | Grad Norm 5.4961(6.3061) | Total Time 14.00(14.00)\n",
      "Iter 2240 | Time 14.5541(14.7121) | Bit/dim 3.8240(3.8329) | Xent 1.0607(1.0235) | Loss 4.3543(4.3446) | Error 0.4078(0.3659) Steps 592(591.61) | Grad Norm 6.5907(6.1078) | Total Time 14.00(14.00)\n",
      "Iter 2250 | Time 14.3187(14.7364) | Bit/dim 3.8450(3.8307) | Xent 1.0123(1.0272) | Loss 4.3511(4.3443) | Error 0.3533(0.3662) Steps 580(592.08) | Grad Norm 3.5134(5.8116) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0041 | Time 78.4318, Epoch Time 904.1827(886.6359), Bit/dim 3.8302(best: 3.8411), Xent 0.9797, Loss 4.3200, Error 0.3538(best: 0.3470)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2260 | Time 14.7400(14.7182) | Bit/dim 3.8033(3.8274) | Xent 0.9733(1.0172) | Loss 4.2899(4.3360) | Error 0.3467(0.3623) Steps 598(592.56) | Grad Norm 8.0710(5.7458) | Total Time 14.00(14.00)\n",
      "Iter 2270 | Time 14.3355(14.6792) | Bit/dim 3.8444(3.8255) | Xent 0.9619(1.0063) | Loss 4.3254(4.3287) | Error 0.3422(0.3586) Steps 586(592.86) | Grad Norm 5.0292(5.7439) | Total Time 14.00(14.00)\n",
      "Iter 2280 | Time 14.3095(14.6029) | Bit/dim 3.8257(3.8252) | Xent 0.9858(1.0107) | Loss 4.3186(4.3306) | Error 0.3478(0.3609) Steps 598(592.83) | Grad Norm 4.1667(6.1143) | Total Time 14.00(14.00)\n",
      "Iter 2290 | Time 14.7834(14.5996) | Bit/dim 3.8076(3.8224) | Xent 0.9837(1.0098) | Loss 4.2994(4.3273) | Error 0.3322(0.3583) Steps 592(592.67) | Grad Norm 3.8154(5.8018) | Total Time 14.00(14.00)\n",
      "Iter 2300 | Time 14.3616(14.6036) | Bit/dim 3.8231(3.8225) | Xent 1.0553(1.0044) | Loss 4.3508(4.3247) | Error 0.3756(0.3563) Steps 592(593.48) | Grad Norm 4.5529(5.4218) | Total Time 14.00(14.00)\n",
      "Iter 2310 | Time 14.8334(14.6417) | Bit/dim 3.8391(3.8207) | Xent 0.9944(1.0101) | Loss 4.3363(4.3257) | Error 0.3544(0.3600) Steps 580(591.51) | Grad Norm 6.1221(5.5901) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0042 | Time 77.7657, Epoch Time 897.5299(886.9627), Bit/dim 3.8235(best: 3.8302), Xent 0.9473, Loss 4.2972, Error 0.3378(best: 0.3470)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2320 | Time 14.6130(14.6604) | Bit/dim 3.7987(3.8188) | Xent 0.9839(1.0063) | Loss 4.2906(4.3219) | Error 0.3300(0.3585) Steps 586(591.29) | Grad Norm 3.7542(5.7279) | Total Time 14.00(14.00)\n",
      "Iter 2330 | Time 14.3221(14.6934) | Bit/dim 3.7821(3.8173) | Xent 1.1045(1.0008) | Loss 4.3343(4.3177) | Error 0.3956(0.3574) Steps 580(591.72) | Grad Norm 8.5510(5.9709) | Total Time 14.00(14.00)\n",
      "Iter 2340 | Time 14.7797(14.6750) | Bit/dim 3.8178(3.8176) | Xent 1.0229(1.0031) | Loss 4.3293(4.3191) | Error 0.3500(0.3568) Steps 586(591.91) | Grad Norm 5.9578(5.9028) | Total Time 14.00(14.00)\n",
      "Iter 2350 | Time 14.5116(14.7152) | Bit/dim 3.8030(3.8174) | Xent 0.9581(0.9970) | Loss 4.2821(4.3159) | Error 0.3622(0.3544) Steps 592(591.85) | Grad Norm 4.0839(5.4726) | Total Time 14.00(14.00)\n",
      "Iter 2360 | Time 15.0935(14.7246) | Bit/dim 3.8086(3.8163) | Xent 0.9871(0.9918) | Loss 4.3022(4.3123) | Error 0.3500(0.3535) Steps 604(591.96) | Grad Norm 4.7725(5.4212) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0043 | Time 77.6215, Epoch Time 905.9027(887.5309), Bit/dim 3.8030(best: 3.8235), Xent 0.9332, Loss 4.2696, Error 0.3331(best: 0.3378)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2370 | Time 14.2642(14.6730) | Bit/dim 3.7820(3.8153) | Xent 0.9352(0.9830) | Loss 4.2497(4.3068) | Error 0.3289(0.3496) Steps 592(591.02) | Grad Norm 3.3883(5.1592) | Total Time 14.00(14.00)\n",
      "Iter 2380 | Time 14.4172(14.6279) | Bit/dim 3.7917(3.8096) | Xent 0.9837(0.9812) | Loss 4.2836(4.3001) | Error 0.3433(0.3484) Steps 586(588.80) | Grad Norm 4.4964(4.7670) | Total Time 14.00(14.00)\n",
      "Iter 2390 | Time 14.6866(14.5509) | Bit/dim 3.7909(3.8094) | Xent 0.9491(0.9709) | Loss 4.2654(4.2949) | Error 0.3433(0.3451) Steps 580(588.61) | Grad Norm 3.3358(4.6174) | Total Time 14.00(14.00)\n",
      "Iter 2400 | Time 14.3345(14.5578) | Bit/dim 3.7957(3.8056) | Xent 0.9340(0.9671) | Loss 4.2626(4.2892) | Error 0.3367(0.3447) Steps 604(589.61) | Grad Norm 4.7521(4.6407) | Total Time 14.00(14.00)\n",
      "Iter 2410 | Time 14.7885(14.5461) | Bit/dim 3.7761(3.8034) | Xent 0.9682(0.9601) | Loss 4.2602(4.2834) | Error 0.3556(0.3420) Steps 604(590.58) | Grad Norm 5.4831(4.7218) | Total Time 14.00(14.00)\n",
      "Iter 2420 | Time 14.1145(14.5186) | Bit/dim 3.7968(3.7997) | Xent 0.9187(0.9693) | Loss 4.2561(4.2843) | Error 0.3256(0.3458) Steps 592(590.29) | Grad Norm 4.9594(4.9417) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0044 | Time 77.5448, Epoch Time 891.6960(887.6559), Bit/dim 3.7975(best: 3.8030), Xent 0.9282, Loss 4.2616, Error 0.3307(best: 0.3331)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2430 | Time 14.3750(14.4829) | Bit/dim 3.8227(3.8028) | Xent 1.0154(0.9678) | Loss 4.3305(4.2867) | Error 0.3433(0.3444) Steps 592(588.74) | Grad Norm 5.5415(5.2432) | Total Time 14.00(14.00)\n",
      "Iter 2440 | Time 14.2112(14.4635) | Bit/dim 3.7895(3.8017) | Xent 1.0180(0.9665) | Loss 4.2985(4.2849) | Error 0.3800(0.3440) Steps 586(587.96) | Grad Norm 7.2891(5.4836) | Total Time 14.00(14.00)\n",
      "Iter 2450 | Time 14.2613(14.4254) | Bit/dim 3.8352(3.8000) | Xent 1.0057(0.9803) | Loss 4.3381(4.2901) | Error 0.3489(0.3488) Steps 586(587.97) | Grad Norm 5.4344(5.6755) | Total Time 14.00(14.00)\n",
      "Iter 2460 | Time 14.9574(14.4701) | Bit/dim 3.7750(3.7990) | Xent 1.0160(0.9794) | Loss 4.2830(4.2887) | Error 0.3733(0.3494) Steps 592(587.35) | Grad Norm 5.1439(5.6424) | Total Time 14.00(14.00)\n",
      "Iter 2470 | Time 14.6154(14.4840) | Bit/dim 3.7729(3.7995) | Xent 0.9871(0.9822) | Loss 4.2664(4.2906) | Error 0.3556(0.3511) Steps 592(588.02) | Grad Norm 3.4428(5.7256) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0045 | Time 77.3866, Epoch Time 888.6485(887.6856), Bit/dim 3.7944(best: 3.7975), Xent 0.9001, Loss 4.2445, Error 0.3181(best: 0.3307)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2480 | Time 14.2199(14.4336) | Bit/dim 3.8021(3.7967) | Xent 1.0346(0.9754) | Loss 4.3194(4.2844) | Error 0.3878(0.3495) Steps 580(585.70) | Grad Norm 5.6874(5.4979) | Total Time 14.00(14.00)\n",
      "Iter 2490 | Time 14.5115(14.4872) | Bit/dim 3.8180(3.7964) | Xent 0.9611(0.9761) | Loss 4.2986(4.2844) | Error 0.3422(0.3497) Steps 580(586.33) | Grad Norm 4.8950(5.6746) | Total Time 14.00(14.00)\n",
      "Iter 2500 | Time 13.8729(14.4763) | Bit/dim 3.8104(3.7961) | Xent 0.9467(0.9693) | Loss 4.2838(4.2807) | Error 0.3522(0.3469) Steps 574(584.24) | Grad Norm 4.1967(5.6538) | Total Time 14.00(14.00)\n",
      "Iter 2510 | Time 14.2798(14.4207) | Bit/dim 3.7898(3.7925) | Xent 0.9223(0.9556) | Loss 4.2510(4.2702) | Error 0.3311(0.3431) Steps 580(583.56) | Grad Norm 3.6071(5.4569) | Total Time 14.00(14.00)\n",
      "Iter 2520 | Time 14.0548(14.4582) | Bit/dim 3.7911(3.7933) | Xent 0.9698(0.9522) | Loss 4.2760(4.2694) | Error 0.3356(0.3416) Steps 580(583.63) | Grad Norm 8.1313(5.5631) | Total Time 14.00(14.00)\n",
      "Iter 2530 | Time 13.8438(14.4211) | Bit/dim 3.7649(3.7904) | Xent 0.9031(0.9503) | Loss 4.2165(4.2655) | Error 0.3200(0.3405) Steps 574(582.23) | Grad Norm 3.2408(5.3643) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0046 | Time 76.9860, Epoch Time 888.9921(887.7248), Bit/dim 3.7882(best: 3.7944), Xent 0.9217, Loss 4.2491, Error 0.3279(best: 0.3181)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2540 | Time 14.6067(14.4436) | Bit/dim 3.7842(3.7842) | Xent 0.9039(0.9457) | Loss 4.2362(4.2571) | Error 0.3311(0.3390) Steps 580(583.06) | Grad Norm 3.8123(5.1912) | Total Time 14.00(14.00)\n",
      "Iter 2550 | Time 14.6647(14.4289) | Bit/dim 3.7935(3.7886) | Xent 1.0368(0.9496) | Loss 4.3119(4.2634) | Error 0.3656(0.3403) Steps 580(582.87) | Grad Norm 6.6153(5.6511) | Total Time 14.00(14.00)\n",
      "Iter 2560 | Time 15.2804(14.4511) | Bit/dim 3.7992(3.7913) | Xent 0.9265(0.9534) | Loss 4.2624(4.2680) | Error 0.3156(0.3398) Steps 586(582.98) | Grad Norm 5.9596(6.1051) | Total Time 14.00(14.00)\n",
      "Iter 2570 | Time 14.2494(14.4694) | Bit/dim 3.7866(3.7890) | Xent 0.9142(0.9530) | Loss 4.2437(4.2655) | Error 0.3289(0.3396) Steps 586(584.42) | Grad Norm 3.3856(5.7912) | Total Time 14.00(14.00)\n",
      "Iter 2580 | Time 14.6339(14.4224) | Bit/dim 3.7897(3.7882) | Xent 0.9253(0.9561) | Loss 4.2523(4.2662) | Error 0.3256(0.3406) Steps 586(584.00) | Grad Norm 6.0323(5.9622) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0047 | Time 78.5893, Epoch Time 890.5140(887.8085), Bit/dim 3.7861(best: 3.7882), Xent 0.9047, Loss 4.2385, Error 0.3240(best: 0.3181)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2590 | Time 14.5473(14.4326) | Bit/dim 3.7515(3.7859) | Xent 0.9134(0.9471) | Loss 4.2082(4.2594) | Error 0.3300(0.3371) Steps 592(582.17) | Grad Norm 5.1530(5.4539) | Total Time 14.00(14.00)\n",
      "Iter 2600 | Time 14.0984(14.3580) | Bit/dim 3.7728(3.7847) | Xent 0.9175(0.9367) | Loss 4.2315(4.2531) | Error 0.3256(0.3333) Steps 568(580.49) | Grad Norm 7.4693(5.4504) | Total Time 14.00(14.00)\n",
      "Iter 2610 | Time 13.8796(14.3435) | Bit/dim 3.7863(3.7848) | Xent 0.9694(0.9429) | Loss 4.2710(4.2563) | Error 0.3344(0.3354) Steps 568(578.30) | Grad Norm 3.8373(5.5802) | Total Time 14.00(14.00)\n",
      "Iter 2620 | Time 13.8673(14.3157) | Bit/dim 3.7722(3.7832) | Xent 0.9624(0.9373) | Loss 4.2534(4.2518) | Error 0.3456(0.3336) Steps 574(577.04) | Grad Norm 6.7962(5.4337) | Total Time 14.00(14.00)\n",
      "Iter 2630 | Time 14.4718(14.2401) | Bit/dim 3.7578(3.7802) | Xent 0.8610(0.9353) | Loss 4.1883(4.2479) | Error 0.3178(0.3339) Steps 574(575.27) | Grad Norm 3.5989(5.3356) | Total Time 14.00(14.00)\n",
      "Iter 2640 | Time 14.3734(14.2401) | Bit/dim 3.7639(3.7800) | Xent 1.0129(0.9393) | Loss 4.2703(4.2496) | Error 0.3478(0.3337) Steps 574(574.16) | Grad Norm 7.9610(5.5685) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0048 | Time 75.8035, Epoch Time 876.0476(887.4557), Bit/dim 3.7898(best: 3.7861), Xent 0.9586, Loss 4.2692, Error 0.3379(best: 0.3181)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2650 | Time 14.3147(14.2265) | Bit/dim 3.7697(3.7798) | Xent 0.8910(0.9394) | Loss 4.2152(4.2495) | Error 0.2956(0.3312) Steps 574(573.92) | Grad Norm 4.3862(6.0682) | Total Time 14.00(14.00)\n",
      "Iter 2660 | Time 14.4213(14.2194) | Bit/dim 3.8227(3.7815) | Xent 0.9939(0.9365) | Loss 4.3196(4.2497) | Error 0.3544(0.3317) Steps 574(574.11) | Grad Norm 6.9007(6.0050) | Total Time 14.00(14.00)\n",
      "Iter 2670 | Time 13.8888(14.1582) | Bit/dim 3.7948(3.7791) | Xent 0.9466(0.9399) | Loss 4.2681(4.2490) | Error 0.3300(0.3334) Steps 568(573.28) | Grad Norm 5.7134(5.8874) | Total Time 14.00(14.00)\n",
      "Iter 2680 | Time 14.1587(14.2073) | Bit/dim 3.7729(3.7770) | Xent 0.9311(0.9326) | Loss 4.2385(4.2433) | Error 0.3656(0.3328) Steps 574(571.62) | Grad Norm 2.4403(5.4282) | Total Time 14.00(14.00)\n",
      "Iter 2690 | Time 14.6394(14.2813) | Bit/dim 3.7670(3.7742) | Xent 0.8486(0.9221) | Loss 4.1913(4.2353) | Error 0.3011(0.3284) Steps 568(570.34) | Grad Norm 6.7074(5.4245) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0049 | Time 76.8844, Epoch Time 877.0972(887.1449), Bit/dim 3.7748(best: 3.7861), Xent 0.8925, Loss 4.2210, Error 0.3128(best: 0.3181)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2700 | Time 14.2288(14.2238) | Bit/dim 3.7857(3.7723) | Xent 0.8907(0.9208) | Loss 4.2311(4.2327) | Error 0.3156(0.3287) Steps 568(571.14) | Grad Norm 6.4167(5.3838) | Total Time 14.00(14.00)\n",
      "Iter 2710 | Time 14.1925(14.1879) | Bit/dim 3.7170(3.7712) | Xent 0.9021(0.9125) | Loss 4.1681(4.2274) | Error 0.3256(0.3261) Steps 580(571.49) | Grad Norm 4.7224(5.3530) | Total Time 14.00(14.00)\n",
      "Iter 2720 | Time 14.0996(14.1417) | Bit/dim 3.7573(3.7689) | Xent 0.9943(0.9101) | Loss 4.2544(4.2240) | Error 0.3444(0.3255) Steps 580(571.71) | Grad Norm 11.0628(5.4802) | Total Time 14.00(14.00)\n",
      "Iter 2730 | Time 13.8957(14.1221) | Bit/dim 3.7656(3.7711) | Xent 0.9996(0.9262) | Loss 4.2654(4.2342) | Error 0.3533(0.3309) Steps 580(571.70) | Grad Norm 5.5878(5.7747) | Total Time 14.00(14.00)\n",
      "Iter 2740 | Time 13.7237(14.1322) | Bit/dim 3.7775(3.7740) | Xent 0.8689(0.9258) | Loss 4.2119(4.2370) | Error 0.3244(0.3329) Steps 568(570.89) | Grad Norm 5.5832(5.6013) | Total Time 14.00(14.00)\n",
      "Iter 2750 | Time 13.9736(14.0782) | Bit/dim 3.7869(3.7729) | Xent 0.8809(0.9283) | Loss 4.2274(4.2371) | Error 0.3022(0.3311) Steps 568(570.30) | Grad Norm 4.7929(5.5936) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0050 | Time 75.1261, Epoch Time 866.0664(886.5126), Bit/dim 3.7658(best: 3.7748), Xent 0.8782, Loss 4.2049, Error 0.3102(best: 0.3128)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2760 | Time 13.9948(14.0623) | Bit/dim 3.7522(3.7708) | Xent 0.9484(0.9229) | Loss 4.2264(4.2322) | Error 0.3367(0.3291) Steps 574(570.70) | Grad Norm 3.4627(5.4336) | Total Time 14.00(14.00)\n",
      "Iter 2770 | Time 14.0278(14.1363) | Bit/dim 3.7425(3.7703) | Xent 0.8650(0.9195) | Loss 4.1750(4.2301) | Error 0.3167(0.3279) Steps 568(571.52) | Grad Norm 5.2282(5.3217) | Total Time 14.00(14.00)\n",
      "Iter 2780 | Time 14.3049(14.1889) | Bit/dim 3.8066(3.7677) | Xent 0.9105(0.9271) | Loss 4.2619(4.2313) | Error 0.3322(0.3314) Steps 574(571.88) | Grad Norm 8.0495(5.9113) | Total Time 14.00(14.00)\n",
      "Iter 2790 | Time 14.1342(14.1636) | Bit/dim 3.7716(3.7702) | Xent 0.9041(0.9243) | Loss 4.2237(4.2324) | Error 0.3333(0.3315) Steps 568(571.56) | Grad Norm 4.5129(5.9105) | Total Time 14.00(14.00)\n",
      "Iter 2800 | Time 14.4314(14.1552) | Bit/dim 3.7428(3.7687) | Xent 0.9948(0.9220) | Loss 4.2402(4.2297) | Error 0.3400(0.3295) Steps 562(570.32) | Grad Norm 5.7216(5.4818) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0051 | Time 76.5657, Epoch Time 875.1694(886.1723), Bit/dim 3.7640(best: 3.7658), Xent 0.8777, Loss 4.2028, Error 0.3094(best: 0.3102)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2810 | Time 13.7333(14.1120) | Bit/dim 3.7326(3.7662) | Xent 0.9075(0.9132) | Loss 4.1863(4.2228) | Error 0.3189(0.3253) Steps 562(569.19) | Grad Norm 3.0252(5.1035) | Total Time 14.00(14.00)\n",
      "Iter 2820 | Time 14.3893(14.1370) | Bit/dim 3.7717(3.7636) | Xent 0.7802(0.8924) | Loss 4.1618(4.2098) | Error 0.2744(0.3188) Steps 562(569.15) | Grad Norm 4.3697(4.8323) | Total Time 14.00(14.00)\n",
      "Iter 2830 | Time 14.1190(14.1542) | Bit/dim 3.7292(3.7623) | Xent 0.8809(0.8956) | Loss 4.1696(4.2101) | Error 0.3322(0.3199) Steps 574(569.23) | Grad Norm 9.0421(5.1853) | Total Time 14.00(14.00)\n",
      "Iter 2840 | Time 13.7124(14.1231) | Bit/dim 3.7461(3.7624) | Xent 0.9303(0.9026) | Loss 4.2113(4.2137) | Error 0.3300(0.3224) Steps 568(569.09) | Grad Norm 4.5474(5.5781) | Total Time 14.00(14.00)\n",
      "Iter 2850 | Time 13.9357(14.1625) | Bit/dim 3.7485(3.7625) | Xent 0.8990(0.9074) | Loss 4.1980(4.2162) | Error 0.3178(0.3221) Steps 568(569.43) | Grad Norm 6.6791(5.8093) | Total Time 14.00(14.00)\n",
      "Iter 2860 | Time 14.7731(14.1329) | Bit/dim 3.7546(3.7634) | Xent 0.8764(0.9023) | Loss 4.1928(4.2145) | Error 0.3211(0.3214) Steps 568(568.43) | Grad Norm 5.4311(5.5258) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0052 | Time 75.4394, Epoch Time 870.0498(885.6886), Bit/dim 3.7539(best: 3.7640), Xent 0.8549, Loss 4.1814, Error 0.2973(best: 0.3094)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2870 | Time 14.4455(14.1302) | Bit/dim 3.7672(3.7612) | Xent 0.8472(0.8958) | Loss 4.1908(4.2091) | Error 0.3022(0.3200) Steps 574(568.35) | Grad Norm 7.1512(5.1506) | Total Time 14.00(14.00)\n",
      "Iter 2880 | Time 14.0925(14.1521) | Bit/dim 3.7657(3.7593) | Xent 0.9118(0.9003) | Loss 4.2216(4.2095) | Error 0.3289(0.3216) Steps 568(568.29) | Grad Norm 8.0801(6.0613) | Total Time 14.00(14.00)\n",
      "Iter 2890 | Time 14.5099(14.1888) | Bit/dim 3.7566(3.7605) | Xent 0.9516(0.9014) | Loss 4.2324(4.2112) | Error 0.3233(0.3218) Steps 574(569.35) | Grad Norm 4.5425(6.1105) | Total Time 14.00(14.00)\n",
      "Iter 2900 | Time 13.6893(14.1401) | Bit/dim 3.7481(3.7591) | Xent 0.8758(0.8971) | Loss 4.1860(4.2077) | Error 0.3167(0.3212) Steps 574(569.85) | Grad Norm 5.0927(5.4772) | Total Time 14.00(14.00)\n",
      "Iter 2910 | Time 14.4599(14.1274) | Bit/dim 3.7633(3.7580) | Xent 0.9335(0.8921) | Loss 4.2301(4.2041) | Error 0.3300(0.3195) Steps 562(568.26) | Grad Norm 4.3722(5.2258) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0053 | Time 75.5764, Epoch Time 871.0416(885.2492), Bit/dim 3.7541(best: 3.7539), Xent 0.8561, Loss 4.1821, Error 0.2998(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2920 | Time 13.8459(14.1094) | Bit/dim 3.7580(3.7542) | Xent 0.9341(0.8871) | Loss 4.2251(4.1977) | Error 0.3322(0.3171) Steps 562(567.25) | Grad Norm 3.1857(4.9449) | Total Time 14.00(14.00)\n",
      "Iter 2930 | Time 13.7117(14.0749) | Bit/dim 3.7523(3.7554) | Xent 0.8427(0.8842) | Loss 4.1737(4.1975) | Error 0.2878(0.3156) Steps 562(566.78) | Grad Norm 5.4918(4.9692) | Total Time 14.00(14.00)\n",
      "Iter 2940 | Time 13.8156(14.0112) | Bit/dim 3.7261(3.7543) | Xent 0.8937(0.8780) | Loss 4.1730(4.1933) | Error 0.3156(0.3112) Steps 562(566.70) | Grad Norm 6.2342(4.9865) | Total Time 14.00(14.00)\n",
      "Iter 2950 | Time 14.4866(14.0372) | Bit/dim 3.7268(3.7543) | Xent 0.9345(0.8811) | Loss 4.1941(4.1948) | Error 0.3344(0.3118) Steps 562(566.43) | Grad Norm 4.8170(5.2292) | Total Time 14.00(14.00)\n",
      "Iter 2960 | Time 14.3870(14.0401) | Bit/dim 3.7534(3.7506) | Xent 0.8908(0.8895) | Loss 4.1988(4.1953) | Error 0.3211(0.3157) Steps 580(567.51) | Grad Norm 4.7566(5.5341) | Total Time 14.00(14.00)\n",
      "Iter 2970 | Time 14.2486(14.0860) | Bit/dim 3.7655(3.7511) | Xent 0.8765(0.8875) | Loss 4.2038(4.1948) | Error 0.2989(0.3153) Steps 562(567.17) | Grad Norm 6.3279(5.7344) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0054 | Time 76.3056, Epoch Time 866.3313(884.6817), Bit/dim 3.7578(best: 3.7539), Xent 0.8658, Loss 4.1907, Error 0.3003(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 2980 | Time 14.7951(14.0800) | Bit/dim 3.7194(3.7483) | Xent 0.8479(0.8796) | Loss 4.1434(4.1881) | Error 0.3022(0.3141) Steps 568(566.81) | Grad Norm 4.9390(5.4983) | Total Time 14.00(14.00)\n",
      "Iter 2990 | Time 13.8180(14.0262) | Bit/dim 3.7121(3.7466) | Xent 0.8471(0.8844) | Loss 4.1357(4.1888) | Error 0.3178(0.3162) Steps 562(567.01) | Grad Norm 3.4944(5.6307) | Total Time 14.00(14.00)\n",
      "Iter 3000 | Time 13.7827(14.0347) | Bit/dim 3.7498(3.7473) | Xent 0.8765(0.8868) | Loss 4.1881(4.1907) | Error 0.3144(0.3169) Steps 568(566.81) | Grad Norm 6.3061(5.6972) | Total Time 14.00(14.00)\n",
      "Iter 3010 | Time 13.7184(14.0159) | Bit/dim 3.7785(3.7516) | Xent 0.8340(0.8847) | Loss 4.1955(4.1939) | Error 0.2867(0.3156) Steps 562(567.13) | Grad Norm 5.9646(5.6293) | Total Time 14.00(14.00)\n",
      "Iter 3020 | Time 13.5531(14.0420) | Bit/dim 3.7475(3.7493) | Xent 0.8410(0.8764) | Loss 4.1680(4.1875) | Error 0.3078(0.3132) Steps 562(566.23) | Grad Norm 5.4300(5.2745) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0055 | Time 76.6220, Epoch Time 866.0054(884.1214), Bit/dim 3.7419(best: 3.7539), Xent 0.8521, Loss 4.1680, Error 0.2984(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3030 | Time 14.0609(14.0689) | Bit/dim 3.7689(3.7484) | Xent 0.9552(0.8758) | Loss 4.2466(4.1862) | Error 0.3289(0.3139) Steps 562(566.88) | Grad Norm 2.8678(4.9576) | Total Time 14.00(14.00)\n",
      "Iter 3040 | Time 14.0483(14.1007) | Bit/dim 3.7344(3.7454) | Xent 0.9275(0.8748) | Loss 4.1981(4.1828) | Error 0.3378(0.3130) Steps 562(566.69) | Grad Norm 4.2335(4.9291) | Total Time 14.00(14.00)\n",
      "Iter 3050 | Time 14.4161(14.1179) | Bit/dim 3.7630(3.7459) | Xent 0.8682(0.8740) | Loss 4.1971(4.1829) | Error 0.3111(0.3133) Steps 574(567.49) | Grad Norm 5.1626(5.1106) | Total Time 14.00(14.00)\n",
      "Iter 3060 | Time 13.6652(14.0620) | Bit/dim 3.7102(3.7424) | Xent 0.8693(0.8628) | Loss 4.1449(4.1738) | Error 0.3144(0.3097) Steps 562(566.61) | Grad Norm 4.8253(4.9113) | Total Time 14.00(14.00)\n",
      "Iter 3070 | Time 14.0745(14.0784) | Bit/dim 3.7323(3.7403) | Xent 0.9250(0.8691) | Loss 4.1949(4.1748) | Error 0.3278(0.3116) Steps 562(566.89) | Grad Norm 3.7791(5.0874) | Total Time 14.00(14.00)\n",
      "Iter 3080 | Time 14.1854(14.1179) | Bit/dim 3.7581(3.7408) | Xent 0.8790(0.8716) | Loss 4.1976(4.1765) | Error 0.3011(0.3114) Steps 562(566.67) | Grad Norm 5.7465(5.0675) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0056 | Time 76.3046, Epoch Time 871.4843(883.7423), Bit/dim 3.7367(best: 3.7419), Xent 0.8543, Loss 4.1638, Error 0.2975(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3090 | Time 14.4915(14.1344) | Bit/dim 3.6783(3.7389) | Xent 0.8260(0.8650) | Loss 4.0913(4.1713) | Error 0.3067(0.3098) Steps 562(566.71) | Grad Norm 7.3430(5.0104) | Total Time 14.00(14.00)\n",
      "Iter 3100 | Time 14.3564(14.1628) | Bit/dim 3.7375(3.7384) | Xent 0.9077(0.8588) | Loss 4.1914(4.1679) | Error 0.3233(0.3065) Steps 568(566.10) | Grad Norm 5.4252(4.8603) | Total Time 14.00(14.00)\n",
      "Iter 3110 | Time 13.7196(14.0902) | Bit/dim 3.7515(3.7391) | Xent 0.8312(0.8525) | Loss 4.1672(4.1653) | Error 0.2956(0.3042) Steps 562(565.91) | Grad Norm 4.3013(4.7779) | Total Time 14.00(14.00)\n",
      "Iter 3120 | Time 13.7578(14.0674) | Bit/dim 3.7763(3.7392) | Xent 0.8363(0.8473) | Loss 4.1944(4.1629) | Error 0.3100(0.3013) Steps 568(566.45) | Grad Norm 10.3229(4.8811) | Total Time 14.00(14.00)\n",
      "Iter 3130 | Time 13.9857(14.0824) | Bit/dim 3.7183(3.7370) | Xent 0.9194(0.8540) | Loss 4.1780(4.1640) | Error 0.3389(0.3050) Steps 568(566.39) | Grad Norm 9.6400(5.1794) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0057 | Time 76.0372, Epoch Time 870.0063(883.3302), Bit/dim 3.7448(best: 3.7367), Xent 0.9630, Loss 4.2263, Error 0.3414(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3140 | Time 14.1544(14.1455) | Bit/dim 3.7683(3.7409) | Xent 0.8105(0.8619) | Loss 4.1736(4.1718) | Error 0.2978(0.3082) Steps 574(566.70) | Grad Norm 5.8463(5.6179) | Total Time 14.00(14.00)\n",
      "Iter 3150 | Time 14.0368(14.1880) | Bit/dim 3.7359(3.7445) | Xent 0.7978(0.8535) | Loss 4.1348(4.1712) | Error 0.2856(0.3052) Steps 568(567.78) | Grad Norm 4.2354(5.4899) | Total Time 14.00(14.00)\n",
      "Iter 3160 | Time 14.0782(14.2494) | Bit/dim 3.7467(3.7415) | Xent 0.8602(0.8534) | Loss 4.1767(4.1682) | Error 0.2944(0.3037) Steps 574(568.33) | Grad Norm 4.3653(5.0941) | Total Time 14.00(14.00)\n",
      "Iter 3170 | Time 14.0896(14.2656) | Bit/dim 3.6932(3.7378) | Xent 0.8703(0.8543) | Loss 4.1283(4.1650) | Error 0.3000(0.3026) Steps 562(567.59) | Grad Norm 6.6082(5.1979) | Total Time 14.00(14.00)\n",
      "Iter 3180 | Time 13.8366(14.2190) | Bit/dim 3.6995(3.7353) | Xent 0.8670(0.8564) | Loss 4.1330(4.1635) | Error 0.3067(0.3036) Steps 568(567.23) | Grad Norm 6.0992(5.0032) | Total Time 14.00(14.00)\n",
      "Iter 3190 | Time 13.9153(14.2273) | Bit/dim 3.7204(3.7342) | Xent 0.7647(0.8514) | Loss 4.1028(4.1599) | Error 0.2789(0.3028) Steps 568(568.81) | Grad Norm 2.9048(4.9721) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0058 | Time 76.3938, Epoch Time 879.6390(883.2194), Bit/dim 3.7298(best: 3.7367), Xent 0.8372, Loss 4.1484, Error 0.2989(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3200 | Time 14.3755(14.2199) | Bit/dim 3.7155(3.7325) | Xent 0.8108(0.8411) | Loss 4.1209(4.1531) | Error 0.2922(0.2990) Steps 562(568.78) | Grad Norm 4.7887(5.0337) | Total Time 14.00(14.00)\n",
      "Iter 3210 | Time 14.3765(14.1979) | Bit/dim 3.7326(3.7320) | Xent 0.8493(0.8385) | Loss 4.1573(4.1513) | Error 0.3167(0.2987) Steps 562(567.83) | Grad Norm 4.8947(5.2252) | Total Time 14.00(14.00)\n",
      "Iter 3220 | Time 13.5950(14.1332) | Bit/dim 3.7068(3.7320) | Xent 0.8080(0.8408) | Loss 4.1108(4.1523) | Error 0.2889(0.2984) Steps 568(567.58) | Grad Norm 4.5077(4.9232) | Total Time 14.00(14.00)\n",
      "Iter 3230 | Time 14.4133(14.1385) | Bit/dim 3.6938(3.7300) | Xent 0.8845(0.8418) | Loss 4.1361(4.1509) | Error 0.3156(0.3002) Steps 574(567.83) | Grad Norm 6.1171(5.0862) | Total Time 14.00(14.00)\n",
      "Iter 3240 | Time 14.8676(14.1325) | Bit/dim 3.7162(3.7305) | Xent 0.8009(0.8451) | Loss 4.1167(4.1531) | Error 0.2956(0.3025) Steps 568(567.42) | Grad Norm 4.5797(5.2396) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0059 | Time 78.4600, Epoch Time 873.3439(882.9232), Bit/dim 3.7319(best: 3.7298), Xent 0.8487, Loss 4.1563, Error 0.2986(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3250 | Time 14.7570(14.1934) | Bit/dim 3.7390(3.7326) | Xent 0.8934(0.8550) | Loss 4.1857(4.1601) | Error 0.2989(0.3064) Steps 580(568.21) | Grad Norm 6.5783(5.5771) | Total Time 14.00(14.00)\n",
      "Iter 3260 | Time 13.9973(14.2667) | Bit/dim 3.7398(3.7321) | Xent 0.8983(0.8508) | Loss 4.1889(4.1575) | Error 0.3256(0.3048) Steps 556(569.18) | Grad Norm 5.9877(5.5557) | Total Time 14.00(14.00)\n",
      "Iter 3270 | Time 14.5056(14.3168) | Bit/dim 3.7674(3.7310) | Xent 0.8984(0.8498) | Loss 4.2166(4.1559) | Error 0.3244(0.3035) Steps 580(570.46) | Grad Norm 6.2985(5.4689) | Total Time 14.00(14.00)\n",
      "Iter 3280 | Time 13.9630(14.3049) | Bit/dim 3.7024(3.7307) | Xent 0.9128(0.8465) | Loss 4.1588(4.1540) | Error 0.3300(0.3031) Steps 568(569.94) | Grad Norm 4.5048(5.1218) | Total Time 14.00(14.00)\n",
      "Iter 3290 | Time 13.9639(14.2759) | Bit/dim 3.7400(3.7304) | Xent 0.7745(0.8343) | Loss 4.1273(4.1475) | Error 0.2744(0.2983) Steps 568(570.30) | Grad Norm 5.8261(5.0324) | Total Time 14.00(14.00)\n",
      "Iter 3300 | Time 14.4193(14.2701) | Bit/dim 3.7325(3.7296) | Xent 0.8671(0.8361) | Loss 4.1660(4.1477) | Error 0.2933(0.2993) Steps 562(569.78) | Grad Norm 5.1971(5.0487) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0060 | Time 75.8079, Epoch Time 882.2314(882.9024), Bit/dim 3.7305(best: 3.7298), Xent 0.8275, Loss 4.1443, Error 0.2880(best: 0.2973)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3310 | Time 13.9835(14.2456) | Bit/dim 3.7010(3.7301) | Xent 0.8402(0.8337) | Loss 4.1211(4.1470) | Error 0.2856(0.2971) Steps 574(570.49) | Grad Norm 4.5881(5.3037) | Total Time 14.00(14.00)\n",
      "Iter 3320 | Time 14.0761(14.2180) | Bit/dim 3.7521(3.7316) | Xent 0.8305(0.8380) | Loss 4.1673(4.1506) | Error 0.3022(0.2987) Steps 574(570.53) | Grad Norm 5.8123(5.5053) | Total Time 14.00(14.00)\n",
      "Iter 3330 | Time 13.9669(14.2512) | Bit/dim 3.7102(3.7309) | Xent 0.8214(0.8332) | Loss 4.1208(4.1475) | Error 0.2978(0.2968) Steps 574(570.48) | Grad Norm 4.0578(5.3613) | Total Time 14.00(14.00)\n",
      "Iter 3340 | Time 13.9449(14.2239) | Bit/dim 3.7448(3.7291) | Xent 0.7976(0.8307) | Loss 4.1436(4.1445) | Error 0.2744(0.2951) Steps 568(570.16) | Grad Norm 5.1573(5.2773) | Total Time 14.00(14.00)\n",
      "Iter 3350 | Time 13.9894(14.2172) | Bit/dim 3.6910(3.7259) | Xent 0.8523(0.8330) | Loss 4.1171(4.1424) | Error 0.2967(0.2958) Steps 568(570.20) | Grad Norm 3.1801(5.2067) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0061 | Time 76.7674, Epoch Time 875.4426(882.6786), Bit/dim 3.7228(best: 3.7298), Xent 0.8055, Loss 4.1255, Error 0.2852(best: 0.2880)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3360 | Time 14.1701(14.1760) | Bit/dim 3.7025(3.7229) | Xent 0.7541(0.8244) | Loss 4.0795(4.1351) | Error 0.2578(0.2941) Steps 580(570.45) | Grad Norm 4.9352(4.9529) | Total Time 14.00(14.00)\n",
      "Iter 3370 | Time 13.7204(14.1508) | Bit/dim 3.7211(3.7219) | Xent 0.7738(0.8117) | Loss 4.1080(4.1278) | Error 0.2956(0.2910) Steps 568(570.41) | Grad Norm 4.2037(4.8724) | Total Time 14.00(14.00)\n",
      "Iter 3380 | Time 14.4434(14.1728) | Bit/dim 3.7176(3.7220) | Xent 0.8963(0.8146) | Loss 4.1657(4.1292) | Error 0.3078(0.2914) Steps 568(570.71) | Grad Norm 6.7687(5.0894) | Total Time 14.00(14.00)\n",
      "Iter 3390 | Time 13.8938(14.1990) | Bit/dim 3.7110(3.7199) | Xent 0.8257(0.8193) | Loss 4.1239(4.1296) | Error 0.2944(0.2941) Steps 568(570.75) | Grad Norm 7.0845(5.1444) | Total Time 14.00(14.00)\n",
      "Iter 3400 | Time 14.4632(14.1476) | Bit/dim 3.7290(3.7228) | Xent 0.8817(0.8271) | Loss 4.1699(4.1363) | Error 0.3222(0.2969) Steps 568(570.53) | Grad Norm 7.3929(5.2159) | Total Time 14.00(14.00)\n",
      "Iter 3410 | Time 14.4739(14.1848) | Bit/dim 3.7441(3.7241) | Xent 0.8152(0.8305) | Loss 4.1517(4.1394) | Error 0.2911(0.2975) Steps 568(570.19) | Grad Norm 5.9582(5.1470) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0062 | Time 76.8068, Epoch Time 873.3959(882.4002), Bit/dim 3.7269(best: 3.7228), Xent 0.8078, Loss 4.1308, Error 0.2803(best: 0.2852)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3420 | Time 13.8491(14.1645) | Bit/dim 3.7218(3.7221) | Xent 0.9260(0.8258) | Loss 4.1847(4.1350) | Error 0.3211(0.2937) Steps 568(569.76) | Grad Norm 9.8176(5.4344) | Total Time 14.00(14.00)\n",
      "Iter 3430 | Time 14.7715(14.1895) | Bit/dim 3.7092(3.7227) | Xent 0.8285(0.8396) | Loss 4.1235(4.1425) | Error 0.2922(0.2993) Steps 580(571.48) | Grad Norm 6.2007(5.9097) | Total Time 14.00(14.00)\n",
      "Iter 3440 | Time 13.7423(14.2029) | Bit/dim 3.7542(3.7274) | Xent 0.8418(0.8384) | Loss 4.1750(4.1466) | Error 0.3000(0.3000) Steps 574(572.44) | Grad Norm 4.4477(5.6935) | Total Time 14.00(14.00)\n",
      "Iter 3450 | Time 14.3072(14.2072) | Bit/dim 3.7377(3.7251) | Xent 0.8347(0.8337) | Loss 4.1551(4.1420) | Error 0.3111(0.2991) Steps 568(571.71) | Grad Norm 3.6902(5.3060) | Total Time 14.00(14.00)\n",
      "Iter 3460 | Time 13.9483(14.1481) | Bit/dim 3.7182(3.7217) | Xent 0.8137(0.8280) | Loss 4.1250(4.1356) | Error 0.2978(0.2982) Steps 568(571.04) | Grad Norm 4.4170(5.1255) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0063 | Time 76.6557, Epoch Time 873.6688(882.1382), Bit/dim 3.7129(best: 3.7228), Xent 0.8075, Loss 4.1166, Error 0.2840(best: 0.2803)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3470 | Time 13.7810(14.1831) | Bit/dim 3.6857(3.7189) | Xent 0.8481(0.8248) | Loss 4.1097(4.1313) | Error 0.3322(0.2965) Steps 568(571.37) | Grad Norm 7.4030(4.8732) | Total Time 14.00(14.00)\n",
      "Iter 3480 | Time 13.9108(14.1704) | Bit/dim 3.7190(3.7164) | Xent 0.8275(0.8140) | Loss 4.1328(4.1234) | Error 0.2811(0.2919) Steps 568(571.25) | Grad Norm 4.8757(4.5021) | Total Time 14.00(14.00)\n",
      "Iter 3490 | Time 13.6891(14.2085) | Bit/dim 3.7258(3.7166) | Xent 0.7806(0.8076) | Loss 4.1161(4.1203) | Error 0.2856(0.2893) Steps 568(572.25) | Grad Norm 3.5676(4.1958) | Total Time 14.00(14.00)\n",
      "Iter 3500 | Time 14.7839(14.2560) | Bit/dim 3.7104(3.7164) | Xent 0.9003(0.8047) | Loss 4.1606(4.1187) | Error 0.3156(0.2880) Steps 580(572.73) | Grad Norm 6.9056(4.2468) | Total Time 14.00(14.00)\n",
      "Iter 3510 | Time 13.7752(14.2594) | Bit/dim 3.7173(3.7151) | Xent 0.9013(0.8234) | Loss 4.1680(4.1268) | Error 0.3178(0.2943) Steps 568(572.41) | Grad Norm 4.9282(4.9155) | Total Time 14.00(14.00)\n",
      "Iter 3520 | Time 13.8544(14.2476) | Bit/dim 3.7261(3.7183) | Xent 0.7958(0.8290) | Loss 4.1240(4.1328) | Error 0.2844(0.2960) Steps 568(572.57) | Grad Norm 3.9881(4.8963) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0064 | Time 76.7494, Epoch Time 879.3629(882.0550), Bit/dim 3.7167(best: 3.7129), Xent 0.8006, Loss 4.1170, Error 0.2834(best: 0.2803)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3530 | Time 14.1154(14.2182) | Bit/dim 3.7434(3.7188) | Xent 0.8563(0.8194) | Loss 4.1716(4.1285) | Error 0.2867(0.2918) Steps 574(572.47) | Grad Norm 4.0157(4.7613) | Total Time 14.00(14.00)\n",
      "Iter 3540 | Time 13.8260(14.2035) | Bit/dim 3.7311(3.7183) | Xent 0.8133(0.8133) | Loss 4.1378(4.1250) | Error 0.3056(0.2904) Steps 568(572.24) | Grad Norm 5.4885(4.8191) | Total Time 14.00(14.00)\n",
      "Iter 3550 | Time 13.9995(14.2139) | Bit/dim 3.7355(3.7162) | Xent 0.8035(0.8088) | Loss 4.1373(4.1206) | Error 0.2756(0.2884) Steps 586(573.08) | Grad Norm 3.3576(4.9519) | Total Time 14.00(14.00)\n",
      "Iter 3560 | Time 14.5548(14.2785) | Bit/dim 3.7038(3.7145) | Xent 0.8049(0.8041) | Loss 4.1063(4.1166) | Error 0.2800(0.2861) Steps 574(573.21) | Grad Norm 4.1912(5.0396) | Total Time 14.00(14.00)\n",
      "Iter 3570 | Time 14.2819(14.2617) | Bit/dim 3.7240(3.7168) | Xent 0.9032(0.8098) | Loss 4.1756(4.1217) | Error 0.3433(0.2881) Steps 574(573.46) | Grad Norm 5.6256(5.2544) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0065 | Time 77.2028, Epoch Time 879.0885(881.9660), Bit/dim 3.7155(best: 3.7129), Xent 0.8466, Loss 4.1388, Error 0.2979(best: 0.2803)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3580 | Time 13.6500(14.2208) | Bit/dim 3.7189(3.7158) | Xent 0.8340(0.8155) | Loss 4.1359(4.1236) | Error 0.2922(0.2917) Steps 568(573.26) | Grad Norm 8.7921(5.5067) | Total Time 14.00(14.00)\n",
      "Iter 3590 | Time 14.1568(14.2460) | Bit/dim 3.6852(3.7142) | Xent 0.7244(0.8105) | Loss 4.0474(4.1194) | Error 0.2856(0.2905) Steps 580(573.68) | Grad Norm 4.3287(5.4264) | Total Time 14.00(14.00)\n",
      "Iter 3600 | Time 13.9476(14.1997) | Bit/dim 3.7082(3.7166) | Xent 0.8035(0.8018) | Loss 4.1100(4.1175) | Error 0.3044(0.2868) Steps 574(572.66) | Grad Norm 5.2660(5.1895) | Total Time 14.00(14.00)\n",
      "Iter 3610 | Time 14.4200(14.2309) | Bit/dim 3.6971(3.7127) | Xent 0.7731(0.8013) | Loss 4.0836(4.1133) | Error 0.2611(0.2841) Steps 568(572.50) | Grad Norm 3.5192(4.9079) | Total Time 14.00(14.00)\n",
      "Iter 3620 | Time 14.3111(14.2488) | Bit/dim 3.7369(3.7150) | Xent 0.8157(0.7982) | Loss 4.1447(4.1141) | Error 0.2922(0.2834) Steps 568(572.61) | Grad Norm 6.8193(4.7402) | Total Time 14.00(14.00)\n",
      "Iter 3630 | Time 14.0021(14.2580) | Bit/dim 3.6861(3.7140) | Xent 0.8002(0.7994) | Loss 4.0861(4.1137) | Error 0.2789(0.2842) Steps 580(573.42) | Grad Norm 4.7531(4.9614) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0066 | Time 77.2645, Epoch Time 877.3506(881.8275), Bit/dim 3.7030(best: 3.7129), Xent 0.7972, Loss 4.1016, Error 0.2796(best: 0.2803)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3640 | Time 14.2186(14.2286) | Bit/dim 3.7262(3.7137) | Xent 0.8506(0.7983) | Loss 4.1515(4.1128) | Error 0.2989(0.2843) Steps 574(573.98) | Grad Norm 9.7866(5.2375) | Total Time 14.00(14.00)\n",
      "Iter 3650 | Time 14.5873(14.2562) | Bit/dim 3.7310(3.7125) | Xent 0.7962(0.7976) | Loss 4.1292(4.1113) | Error 0.2833(0.2833) Steps 592(574.54) | Grad Norm 5.2165(5.3481) | Total Time 14.00(14.00)\n",
      "Iter 3660 | Time 14.4814(14.2877) | Bit/dim 3.7230(3.7104) | Xent 0.7527(0.7970) | Loss 4.0994(4.1089) | Error 0.2656(0.2826) Steps 568(574.08) | Grad Norm 5.2272(5.1938) | Total Time 14.00(14.00)\n",
      "Iter 3670 | Time 14.4205(14.2929) | Bit/dim 3.6808(3.7098) | Xent 0.8133(0.7952) | Loss 4.0874(4.1074) | Error 0.2922(0.2837) Steps 568(573.97) | Grad Norm 9.0557(5.0029) | Total Time 14.00(14.00)\n",
      "Iter 3680 | Time 14.2261(14.3198) | Bit/dim 3.7030(3.7070) | Xent 0.7811(0.7952) | Loss 4.0936(4.1047) | Error 0.2733(0.2825) Steps 580(574.40) | Grad Norm 2.6514(4.8082) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0067 | Time 77.5227, Epoch Time 880.5111(881.7880), Bit/dim 3.7069(best: 3.7030), Xent 0.8274, Loss 4.1207, Error 0.2868(best: 0.2796)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3690 | Time 14.5331(14.2650) | Bit/dim 3.7152(3.7081) | Xent 0.8042(0.7887) | Loss 4.1173(4.1024) | Error 0.2811(0.2812) Steps 568(574.60) | Grad Norm 5.4590(4.6867) | Total Time 14.00(14.00)\n",
      "Iter 3700 | Time 14.2912(14.2423) | Bit/dim 3.7176(3.7072) | Xent 0.8057(0.7817) | Loss 4.1204(4.0981) | Error 0.2622(0.2789) Steps 568(574.11) | Grad Norm 6.9622(4.7338) | Total Time 14.00(14.00)\n",
      "Iter 3710 | Time 14.7911(14.2502) | Bit/dim 3.7414(3.7059) | Xent 0.7677(0.7838) | Loss 4.1253(4.0978) | Error 0.2822(0.2796) Steps 568(573.89) | Grad Norm 5.0595(5.2355) | Total Time 14.00(14.00)\n",
      "Iter 3720 | Time 13.6678(14.2448) | Bit/dim 3.6620(3.7048) | Xent 0.8250(0.7881) | Loss 4.0745(4.0989) | Error 0.3178(0.2824) Steps 568(573.90) | Grad Norm 5.6127(5.1371) | Total Time 14.00(14.00)\n",
      "Iter 3730 | Time 13.9981(14.2772) | Bit/dim 3.6938(3.7061) | Xent 0.7955(0.7897) | Loss 4.0916(4.1009) | Error 0.2822(0.2821) Steps 574(574.27) | Grad Norm 7.0311(5.5454) | Total Time 14.00(14.00)\n",
      "Iter 3740 | Time 14.3946(14.3164) | Bit/dim 3.7238(3.7054) | Xent 0.8509(0.7934) | Loss 4.1492(4.1022) | Error 0.3100(0.2834) Steps 574(574.79) | Grad Norm 5.5162(5.3144) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0068 | Time 78.3470, Epoch Time 882.3363(881.8045), Bit/dim 3.7102(best: 3.7030), Xent 0.7936, Loss 4.1070, Error 0.2816(best: 0.2796)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3750 | Time 14.3685(14.3577) | Bit/dim 3.6956(3.7045) | Xent 0.7696(0.7831) | Loss 4.0804(4.0961) | Error 0.2767(0.2790) Steps 580(575.35) | Grad Norm 5.1885(5.0149) | Total Time 14.00(14.00)\n",
      "Iter 3760 | Time 14.4173(14.3235) | Bit/dim 3.7082(3.7042) | Xent 0.7040(0.7781) | Loss 4.0602(4.0932) | Error 0.2611(0.2777) Steps 568(575.99) | Grad Norm 3.0660(4.9508) | Total Time 14.00(14.00)\n",
      "Iter 3770 | Time 14.7011(14.3387) | Bit/dim 3.6930(3.7024) | Xent 0.8031(0.7763) | Loss 4.0946(4.0906) | Error 0.2889(0.2773) Steps 568(575.01) | Grad Norm 5.5676(4.9734) | Total Time 14.00(14.00)\n",
      "Iter 3780 | Time 13.9147(14.2963) | Bit/dim 3.6826(3.7009) | Xent 0.7595(0.7808) | Loss 4.0624(4.0913) | Error 0.2711(0.2791) Steps 568(574.67) | Grad Norm 2.6753(4.6947) | Total Time 14.00(14.00)\n",
      "Iter 3790 | Time 14.2803(14.3034) | Bit/dim 3.6972(3.7009) | Xent 0.7888(0.7792) | Loss 4.0915(4.0905) | Error 0.2800(0.2795) Steps 568(574.16) | Grad Norm 3.7557(4.3300) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0069 | Time 77.1318, Epoch Time 881.8630(881.8062), Bit/dim 3.7001(best: 3.7030), Xent 0.7698, Loss 4.0850, Error 0.2722(best: 0.2796)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3800 | Time 13.8185(14.3091) | Bit/dim 3.7039(3.7003) | Xent 0.7220(0.7756) | Loss 4.0649(4.0881) | Error 0.2578(0.2783) Steps 574(573.66) | Grad Norm 5.1511(4.5098) | Total Time 14.00(14.00)\n",
      "Iter 3810 | Time 13.9481(14.3110) | Bit/dim 3.6662(3.6998) | Xent 0.8025(0.7730) | Loss 4.0674(4.0864) | Error 0.3000(0.2763) Steps 568(573.11) | Grad Norm 4.9889(4.5763) | Total Time 14.00(14.00)\n",
      "Iter 3820 | Time 14.1766(14.2863) | Bit/dim 3.6666(3.6996) | Xent 0.7446(0.7695) | Loss 4.0388(4.0843) | Error 0.2622(0.2746) Steps 580(573.30) | Grad Norm 5.8131(4.6780) | Total Time 14.00(14.00)\n",
      "Iter 3830 | Time 13.8479(14.2758) | Bit/dim 3.6967(3.6984) | Xent 0.8960(0.7764) | Loss 4.1447(4.0866) | Error 0.3322(0.2793) Steps 568(573.67) | Grad Norm 9.0712(4.9739) | Total Time 14.00(14.00)\n",
      "Iter 3840 | Time 14.4256(14.3307) | Bit/dim 3.7061(3.7008) | Xent 0.7482(0.7840) | Loss 4.0802(4.0928) | Error 0.2589(0.2812) Steps 574(573.30) | Grad Norm 4.7487(5.2028) | Total Time 14.00(14.00)\n",
      "Iter 3850 | Time 14.8596(14.3758) | Bit/dim 3.6721(3.6983) | Xent 0.7688(0.7801) | Loss 4.0565(4.0883) | Error 0.2744(0.2793) Steps 580(573.36) | Grad Norm 3.5840(4.7525) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0070 | Time 78.7768, Epoch Time 886.6760(881.9523), Bit/dim 3.6967(best: 3.7001), Xent 0.7840, Loss 4.0887, Error 0.2765(best: 0.2722)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3860 | Time 14.4944(14.3986) | Bit/dim 3.6986(3.6981) | Xent 0.7479(0.7752) | Loss 4.0725(4.0858) | Error 0.2578(0.2787) Steps 574(573.18) | Grad Norm 3.7021(4.7955) | Total Time 14.00(14.00)\n",
      "Iter 3870 | Time 14.5547(14.3950) | Bit/dim 3.7724(3.7001) | Xent 0.7350(0.7730) | Loss 4.1399(4.0866) | Error 0.2600(0.2767) Steps 574(573.12) | Grad Norm 4.5234(4.7542) | Total Time 14.00(14.00)\n",
      "Iter 3880 | Time 14.8345(14.4808) | Bit/dim 3.6708(3.6995) | Xent 0.7791(0.7735) | Loss 4.0603(4.0863) | Error 0.2800(0.2767) Steps 574(573.66) | Grad Norm 6.2658(4.8942) | Total Time 14.00(14.00)\n",
      "Iter 3890 | Time 14.4684(14.4757) | Bit/dim 3.6894(3.7002) | Xent 0.7741(0.7677) | Loss 4.0764(4.0841) | Error 0.2778(0.2740) Steps 568(574.01) | Grad Norm 4.2463(4.6593) | Total Time 14.00(14.00)\n",
      "Iter 3900 | Time 14.5619(14.4775) | Bit/dim 3.6860(3.7001) | Xent 0.7976(0.7757) | Loss 4.0848(4.0880) | Error 0.2900(0.2785) Steps 568(574.29) | Grad Norm 2.9748(4.9910) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0071 | Time 78.1718, Epoch Time 892.2686(882.2618), Bit/dim 3.7106(best: 3.6967), Xent 0.7743, Loss 4.0978, Error 0.2733(best: 0.2722)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3910 | Time 14.2256(14.4177) | Bit/dim 3.6868(3.6978) | Xent 0.7738(0.7769) | Loss 4.0736(4.0862) | Error 0.2911(0.2788) Steps 574(574.23) | Grad Norm 2.6514(4.7648) | Total Time 14.00(14.00)\n",
      "Iter 3920 | Time 14.5684(14.3750) | Bit/dim 3.7130(3.7002) | Xent 0.7270(0.7651) | Loss 4.0765(4.0827) | Error 0.2711(0.2754) Steps 586(575.06) | Grad Norm 2.2895(4.3449) | Total Time 14.00(14.00)\n",
      "Iter 3930 | Time 14.4683(14.4067) | Bit/dim 3.7098(3.6973) | Xent 0.7195(0.7543) | Loss 4.0696(4.0744) | Error 0.2533(0.2705) Steps 574(575.91) | Grad Norm 4.5961(4.4358) | Total Time 14.00(14.00)\n",
      "Iter 3940 | Time 13.9455(14.3860) | Bit/dim 3.6993(3.6969) | Xent 0.7824(0.7516) | Loss 4.0905(4.0727) | Error 0.2744(0.2680) Steps 574(576.30) | Grad Norm 6.2285(4.5224) | Total Time 14.00(14.00)\n",
      "Iter 3950 | Time 13.9214(14.3590) | Bit/dim 3.6920(3.6951) | Xent 0.7525(0.7538) | Loss 4.0683(4.0720) | Error 0.2811(0.2703) Steps 568(575.98) | Grad Norm 3.1548(4.5478) | Total Time 14.00(14.00)\n",
      "Iter 3960 | Time 14.5155(14.3519) | Bit/dim 3.6628(3.6930) | Xent 0.7925(0.7536) | Loss 4.0590(4.0698) | Error 0.2822(0.2703) Steps 574(574.82) | Grad Norm 3.1013(4.2881) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0072 | Time 77.1108, Epoch Time 883.0619(882.2858), Bit/dim 3.6929(best: 3.6967), Xent 0.7579, Loss 4.0718, Error 0.2645(best: 0.2722)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 3970 | Time 14.4771(14.3590) | Bit/dim 3.7214(3.6943) | Xent 0.7178(0.7471) | Loss 4.0803(4.0679) | Error 0.2622(0.2681) Steps 586(574.98) | Grad Norm 4.9500(4.2481) | Total Time 14.00(14.00)\n",
      "Iter 3980 | Time 13.9812(14.3294) | Bit/dim 3.7048(3.6903) | Xent 0.7526(0.7503) | Loss 4.0811(4.0654) | Error 0.2578(0.2690) Steps 580(575.34) | Grad Norm 6.5650(4.3284) | Total Time 14.00(14.00)\n",
      "Iter 3990 | Time 14.0915(14.2879) | Bit/dim 3.6989(3.6898) | Xent 0.8508(0.7485) | Loss 4.1243(4.0641) | Error 0.2944(0.2684) Steps 574(575.77) | Grad Norm 8.8867(4.5749) | Total Time 14.00(14.00)\n",
      "Iter 4000 | Time 13.6687(14.3094) | Bit/dim 3.7023(3.6874) | Xent 0.7933(0.7532) | Loss 4.0990(4.0639) | Error 0.2922(0.2712) Steps 568(576.42) | Grad Norm 4.0235(4.7291) | Total Time 14.00(14.00)\n",
      "Iter 4010 | Time 13.9629(14.2902) | Bit/dim 3.7131(3.6918) | Xent 0.7477(0.7503) | Loss 4.0870(4.0669) | Error 0.2722(0.2700) Steps 574(575.95) | Grad Norm 3.7792(4.5845) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0073 | Time 78.2438, Epoch Time 881.3837(882.2587), Bit/dim 3.6927(best: 3.6929), Xent 0.8414, Loss 4.1134, Error 0.2995(best: 0.2645)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4020 | Time 14.7962(14.3008) | Bit/dim 3.6985(3.6948) | Xent 0.7487(0.7527) | Loss 4.0728(4.0712) | Error 0.2744(0.2699) Steps 574(576.06) | Grad Norm 8.4650(5.1636) | Total Time 14.00(14.00)\n",
      "Iter 4030 | Time 13.8129(14.3230) | Bit/dim 3.6826(3.6970) | Xent 0.7198(0.7493) | Loss 4.0425(4.0717) | Error 0.2556(0.2683) Steps 568(575.84) | Grad Norm 4.9186(5.0273) | Total Time 14.00(14.00)\n",
      "Iter 4040 | Time 14.6333(14.2721) | Bit/dim 3.6924(3.6946) | Xent 0.7549(0.7590) | Loss 4.0699(4.0741) | Error 0.2756(0.2728) Steps 574(575.24) | Grad Norm 7.1126(5.4526) | Total Time 14.00(14.00)\n",
      "Iter 4050 | Time 14.6540(14.2646) | Bit/dim 3.6773(3.6974) | Xent 0.7582(0.7612) | Loss 4.0564(4.0780) | Error 0.2656(0.2744) Steps 574(575.06) | Grad Norm 6.6932(5.4353) | Total Time 14.00(14.00)\n",
      "Iter 4060 | Time 14.1533(14.2597) | Bit/dim 3.6760(3.6939) | Xent 0.7485(0.7544) | Loss 4.0502(4.0711) | Error 0.2756(0.2721) Steps 586(575.29) | Grad Norm 6.4924(5.1993) | Total Time 14.00(14.00)\n",
      "Iter 4070 | Time 14.1770(14.2994) | Bit/dim 3.6901(3.6926) | Xent 0.8498(0.7629) | Loss 4.1150(4.0740) | Error 0.3000(0.2737) Steps 574(575.99) | Grad Norm 6.5342(5.2482) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0074 | Time 77.0975, Epoch Time 881.4828(882.2355), Bit/dim 3.6966(best: 3.6927), Xent 0.7850, Loss 4.0891, Error 0.2758(best: 0.2645)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4080 | Time 14.6916(14.3690) | Bit/dim 3.6875(3.6932) | Xent 0.7342(0.7555) | Loss 4.0546(4.0709) | Error 0.2644(0.2716) Steps 580(576.49) | Grad Norm 3.6370(5.2103) | Total Time 14.00(14.00)\n",
      "Iter 4090 | Time 14.4454(14.3507) | Bit/dim 3.6953(3.6902) | Xent 0.7790(0.7502) | Loss 4.0849(4.0653) | Error 0.2722(0.2679) Steps 574(576.15) | Grad Norm 5.5756(5.1165) | Total Time 14.00(14.00)\n",
      "Iter 4100 | Time 14.3543(14.3346) | Bit/dim 3.6728(3.6909) | Xent 0.6892(0.7445) | Loss 4.0174(4.0631) | Error 0.2367(0.2652) Steps 574(576.32) | Grad Norm 3.4830(4.9181) | Total Time 14.00(14.00)\n",
      "Iter 4110 | Time 14.1891(14.3146) | Bit/dim 3.7171(3.6901) | Xent 0.7123(0.7397) | Loss 4.0732(4.0600) | Error 0.2411(0.2629) Steps 574(576.58) | Grad Norm 6.2462(4.9056) | Total Time 14.00(14.00)\n",
      "Iter 4120 | Time 13.9970(14.3531) | Bit/dim 3.6874(3.6917) | Xent 0.6454(0.7363) | Loss 4.0101(4.0599) | Error 0.2367(0.2625) Steps 574(576.20) | Grad Norm 2.8171(4.8531) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0075 | Time 76.9740, Epoch Time 886.0058(882.3486), Bit/dim 3.6870(best: 3.6927), Xent 0.7614, Loss 4.0677, Error 0.2662(best: 0.2645)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4130 | Time 14.6452(14.3346) | Bit/dim 3.6646(3.6892) | Xent 0.6927(0.7311) | Loss 4.0109(4.0548) | Error 0.2478(0.2597) Steps 568(576.26) | Grad Norm 3.8824(4.7563) | Total Time 14.00(14.00)\n",
      "Iter 4140 | Time 13.7230(14.2755) | Bit/dim 3.7249(3.6891) | Xent 0.7142(0.7308) | Loss 4.0820(4.0545) | Error 0.2533(0.2594) Steps 568(574.85) | Grad Norm 3.9914(4.6078) | Total Time 14.00(14.00)\n",
      "Iter 4150 | Time 14.0381(14.2641) | Bit/dim 3.6472(3.6872) | Xent 0.6794(0.7237) | Loss 3.9870(4.0490) | Error 0.2400(0.2571) Steps 568(575.90) | Grad Norm 3.0590(4.5801) | Total Time 14.00(14.00)\n",
      "Iter 4160 | Time 14.0572(14.2473) | Bit/dim 3.6853(3.6869) | Xent 0.6745(0.7210) | Loss 4.0226(4.0473) | Error 0.2556(0.2579) Steps 574(575.67) | Grad Norm 4.2143(4.5191) | Total Time 14.00(14.00)\n",
      "Iter 4170 | Time 14.1413(14.2397) | Bit/dim 3.7103(3.6863) | Xent 0.6838(0.7239) | Loss 4.0522(4.0482) | Error 0.2433(0.2576) Steps 574(575.85) | Grad Norm 2.8758(4.5668) | Total Time 14.00(14.00)\n",
      "Iter 4180 | Time 14.1147(14.2848) | Bit/dim 3.6918(3.6877) | Xent 0.7261(0.7286) | Loss 4.0549(4.0520) | Error 0.2456(0.2598) Steps 580(575.99) | Grad Norm 5.4339(4.6287) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0076 | Time 78.4515, Epoch Time 878.6379(882.2372), Bit/dim 3.6943(best: 3.6870), Xent 0.7860, Loss 4.0874, Error 0.2767(best: 0.2645)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4190 | Time 14.1269(14.2644) | Bit/dim 3.7005(3.6876) | Xent 0.6723(0.7203) | Loss 4.0366(4.0478) | Error 0.2478(0.2569) Steps 580(576.63) | Grad Norm 4.9822(4.6937) | Total Time 14.00(14.00)\n",
      "Iter 4200 | Time 14.1799(14.2383) | Bit/dim 3.6954(3.6881) | Xent 0.7767(0.7304) | Loss 4.0838(4.0534) | Error 0.2756(0.2599) Steps 586(577.82) | Grad Norm 6.4307(5.0774) | Total Time 14.00(14.00)\n",
      "Iter 4210 | Time 14.3694(14.2471) | Bit/dim 3.6876(3.6886) | Xent 0.7359(0.7334) | Loss 4.0555(4.0553) | Error 0.2678(0.2633) Steps 574(578.06) | Grad Norm 4.5120(4.9302) | Total Time 14.00(14.00)\n",
      "Iter 4220 | Time 13.9673(14.2261) | Bit/dim 3.6508(3.6868) | Xent 0.6966(0.7293) | Loss 3.9991(4.0515) | Error 0.2400(0.2609) Steps 580(577.81) | Grad Norm 3.2591(4.6574) | Total Time 14.00(14.00)\n",
      "Iter 4230 | Time 13.8096(14.1969) | Bit/dim 3.6807(3.6860) | Xent 0.7077(0.7235) | Loss 4.0345(4.0478) | Error 0.2589(0.2578) Steps 574(577.24) | Grad Norm 3.8116(4.5134) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0077 | Time 77.4728, Epoch Time 875.5156(882.0356), Bit/dim 3.6831(best: 3.6870), Xent 0.7583, Loss 4.0623, Error 0.2686(best: 0.2645)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4240 | Time 14.7609(14.2179) | Bit/dim 3.6945(3.6858) | Xent 0.7166(0.7205) | Loss 4.0528(4.0460) | Error 0.2500(0.2568) Steps 574(576.25) | Grad Norm 3.4819(4.3522) | Total Time 14.00(14.00)\n",
      "Iter 4250 | Time 14.4422(14.2062) | Bit/dim 3.7062(3.6844) | Xent 0.7153(0.7202) | Loss 4.0638(4.0445) | Error 0.2667(0.2571) Steps 580(576.51) | Grad Norm 4.0102(4.4849) | Total Time 14.00(14.00)\n",
      "Iter 4260 | Time 14.7255(14.2594) | Bit/dim 3.6563(3.6808) | Xent 0.7923(0.7261) | Loss 4.0525(4.0438) | Error 0.2744(0.2585) Steps 568(575.65) | Grad Norm 10.1950(4.7867) | Total Time 14.00(14.00)\n",
      "Iter 4270 | Time 14.2925(14.2760) | Bit/dim 3.6790(3.6836) | Xent 0.6857(0.7255) | Loss 4.0218(4.0464) | Error 0.2467(0.2584) Steps 580(576.00) | Grad Norm 3.7663(4.8962) | Total Time 14.00(14.00)\n",
      "Iter 4280 | Time 14.3445(14.2907) | Bit/dim 3.6944(3.6847) | Xent 0.6807(0.7246) | Loss 4.0347(4.0470) | Error 0.2444(0.2584) Steps 586(576.21) | Grad Norm 6.1371(5.1163) | Total Time 14.00(14.00)\n",
      "Iter 4290 | Time 14.5068(14.3082) | Bit/dim 3.6859(3.6832) | Xent 0.6820(0.7188) | Loss 4.0269(4.0425) | Error 0.2389(0.2561) Steps 586(576.80) | Grad Norm 3.1371(4.7661) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0078 | Time 79.0286, Epoch Time 884.7945(882.1184), Bit/dim 3.6823(best: 3.6831), Xent 0.7405, Loss 4.0525, Error 0.2595(best: 0.2645)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4300 | Time 14.4624(14.3026) | Bit/dim 3.6770(3.6808) | Xent 0.7181(0.7091) | Loss 4.0360(4.0353) | Error 0.2467(0.2536) Steps 574(577.58) | Grad Norm 4.0651(4.4817) | Total Time 14.00(14.00)\n",
      "Iter 4310 | Time 14.1905(14.2882) | Bit/dim 3.6679(3.6779) | Xent 0.7268(0.7071) | Loss 4.0313(4.0315) | Error 0.2522(0.2517) Steps 580(577.30) | Grad Norm 2.7519(4.4008) | Total Time 14.00(14.00)\n",
      "Iter 4320 | Time 14.4935(14.3236) | Bit/dim 3.6754(3.6818) | Xent 0.8126(0.7180) | Loss 4.0817(4.0408) | Error 0.2667(0.2558) Steps 574(577.23) | Grad Norm 9.3182(4.9463) | Total Time 14.00(14.00)\n",
      "Iter 4330 | Time 14.2952(14.3139) | Bit/dim 3.6954(3.6842) | Xent 0.7280(0.7219) | Loss 4.0594(4.0452) | Error 0.2478(0.2581) Steps 568(577.65) | Grad Norm 5.2388(5.0438) | Total Time 14.00(14.00)\n",
      "Iter 4340 | Time 14.2747(14.3273) | Bit/dim 3.6891(3.6862) | Xent 0.7003(0.7211) | Loss 4.0393(4.0467) | Error 0.2478(0.2587) Steps 574(578.21) | Grad Norm 5.3584(5.3161) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0079 | Time 79.4653, Epoch Time 884.0347(882.1759), Bit/dim 3.6874(best: 3.6823), Xent 0.7539, Loss 4.0644, Error 0.2622(best: 0.2595)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4350 | Time 14.0240(14.3237) | Bit/dim 3.6829(3.6858) | Xent 0.6945(0.7150) | Loss 4.0302(4.0434) | Error 0.2467(0.2576) Steps 580(579.63) | Grad Norm 3.2875(5.0883) | Total Time 14.00(14.00)\n",
      "Iter 4360 | Time 13.8592(14.3181) | Bit/dim 3.6854(3.6849) | Xent 0.6480(0.7086) | Loss 4.0094(4.0391) | Error 0.2278(0.2544) Steps 574(579.57) | Grad Norm 3.6961(4.6839) | Total Time 14.00(14.00)\n",
      "Iter 4370 | Time 14.2397(14.3151) | Bit/dim 3.6618(3.6814) | Xent 0.6467(0.7056) | Loss 3.9852(4.0342) | Error 0.2289(0.2535) Steps 586(578.84) | Grad Norm 3.3516(4.6022) | Total Time 14.00(14.00)\n",
      "Iter 4380 | Time 14.2326(14.3393) | Bit/dim 3.7098(3.6803) | Xent 0.7207(0.7104) | Loss 4.0701(4.0355) | Error 0.2633(0.2540) Steps 586(578.21) | Grad Norm 5.4475(4.8532) | Total Time 14.00(14.00)\n",
      "Iter 4390 | Time 13.9367(14.2871) | Bit/dim 3.6560(3.6785) | Xent 0.6867(0.7128) | Loss 3.9994(4.0349) | Error 0.2478(0.2553) Steps 568(577.23) | Grad Norm 3.6804(4.5975) | Total Time 14.00(14.00)\n",
      "Iter 4400 | Time 14.1105(14.2974) | Bit/dim 3.7234(3.6836) | Xent 0.7282(0.7191) | Loss 4.0875(4.0432) | Error 0.2478(0.2563) Steps 574(577.37) | Grad Norm 5.6586(4.7392) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0080 | Time 78.5092, Epoch Time 883.4887(882.2152), Bit/dim 3.6888(best: 3.6823), Xent 0.7504, Loss 4.0639, Error 0.2622(best: 0.2595)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4410 | Time 14.2108(14.3060) | Bit/dim 3.6504(3.6824) | Xent 0.6650(0.7096) | Loss 3.9829(4.0372) | Error 0.2478(0.2537) Steps 580(578.89) | Grad Norm 7.3442(4.7867) | Total Time 14.00(14.00)\n",
      "Iter 4420 | Time 14.0480(14.2893) | Bit/dim 3.6631(3.6816) | Xent 0.6677(0.7087) | Loss 3.9969(4.0360) | Error 0.2444(0.2539) Steps 586(578.62) | Grad Norm 4.1209(4.7632) | Total Time 14.00(14.00)\n",
      "Iter 4430 | Time 13.9886(14.2662) | Bit/dim 3.6583(3.6776) | Xent 0.7207(0.7046) | Loss 4.0186(4.0299) | Error 0.2489(0.2520) Steps 580(578.98) | Grad Norm 5.7209(4.4427) | Total Time 14.00(14.00)\n",
      "Iter 4440 | Time 14.6730(14.2467) | Bit/dim 3.7016(3.6777) | Xent 0.7805(0.7082) | Loss 4.0919(4.0318) | Error 0.2733(0.2526) Steps 574(579.18) | Grad Norm 8.8410(4.8498) | Total Time 14.00(14.00)\n",
      "Iter 4450 | Time 14.1416(14.2421) | Bit/dim 3.6520(3.6799) | Xent 0.6983(0.7137) | Loss 4.0012(4.0367) | Error 0.2478(0.2544) Steps 580(579.38) | Grad Norm 4.4771(4.8277) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0081 | Time 78.1586, Epoch Time 879.2051(882.1249), Bit/dim 3.6799(best: 3.6823), Xent 0.7545, Loss 4.0571, Error 0.2637(best: 0.2595)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4460 | Time 14.0768(14.2545) | Bit/dim 3.6890(3.6828) | Xent 0.6404(0.7078) | Loss 4.0092(4.0367) | Error 0.2333(0.2537) Steps 580(580.57) | Grad Norm 4.6098(4.9019) | Total Time 14.00(14.00)\n",
      "Iter 4470 | Time 14.4027(14.2407) | Bit/dim 3.6859(3.6835) | Xent 0.6952(0.7148) | Loss 4.0334(4.0409) | Error 0.2522(0.2559) Steps 586(581.20) | Grad Norm 4.3856(5.1447) | Total Time 14.00(14.00)\n",
      "Iter 4480 | Time 14.6695(14.2636) | Bit/dim 3.7134(3.6836) | Xent 0.6903(0.7079) | Loss 4.0585(4.0376) | Error 0.2433(0.2528) Steps 586(581.26) | Grad Norm 3.7255(4.9343) | Total Time 14.00(14.00)\n",
      "Iter 4490 | Time 15.2814(14.3060) | Bit/dim 3.6677(3.6794) | Xent 0.6615(0.7044) | Loss 3.9984(4.0316) | Error 0.2422(0.2510) Steps 580(581.68) | Grad Norm 6.3569(4.7830) | Total Time 14.00(14.00)\n",
      "Iter 4500 | Time 14.1308(14.3262) | Bit/dim 3.6785(3.6774) | Xent 0.6805(0.6954) | Loss 4.0187(4.0251) | Error 0.2656(0.2488) Steps 580(580.95) | Grad Norm 3.6032(4.4620) | Total Time 14.00(14.00)\n",
      "Iter 4510 | Time 13.8781(14.3013) | Bit/dim 3.6477(3.6742) | Xent 0.6885(0.7020) | Loss 3.9920(4.0251) | Error 0.2200(0.2496) Steps 580(580.00) | Grad Norm 4.7539(4.6316) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0082 | Time 78.3570, Epoch Time 883.4416(882.1644), Bit/dim 3.6770(best: 3.6799), Xent 0.7813, Loss 4.0677, Error 0.2752(best: 0.2595)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4520 | Time 14.0033(14.2767) | Bit/dim 3.6714(3.6744) | Xent 0.7026(0.7029) | Loss 4.0227(4.0258) | Error 0.2589(0.2497) Steps 574(579.88) | Grad Norm 4.5260(4.8036) | Total Time 14.00(14.00)\n",
      "Iter 4530 | Time 14.5058(14.2562) | Bit/dim 3.6672(3.6754) | Xent 0.6970(0.6925) | Loss 4.0157(4.0217) | Error 0.2578(0.2466) Steps 580(579.77) | Grad Norm 4.1554(4.5341) | Total Time 14.00(14.00)\n",
      "Iter 4540 | Time 15.0500(14.2727) | Bit/dim 3.6526(3.6736) | Xent 0.7390(0.6894) | Loss 4.0221(4.0183) | Error 0.2600(0.2451) Steps 580(580.10) | Grad Norm 7.9665(4.6956) | Total Time 14.00(14.00)\n",
      "Iter 4550 | Time 14.6015(14.3145) | Bit/dim 3.6830(3.6719) | Xent 0.6729(0.6926) | Loss 4.0194(4.0182) | Error 0.2311(0.2464) Steps 592(580.99) | Grad Norm 4.0232(4.5231) | Total Time 14.00(14.00)\n",
      "Iter 4560 | Time 13.8637(14.2987) | Bit/dim 3.6684(3.6725) | Xent 0.6998(0.6890) | Loss 4.0183(4.0170) | Error 0.2444(0.2434) Steps 592(581.56) | Grad Norm 2.1925(4.1951) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0083 | Time 78.0816, Epoch Time 881.8247(882.1542), Bit/dim 3.6723(best: 3.6770), Xent 0.7256, Loss 4.0351, Error 0.2539(best: 0.2595)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4570 | Time 13.8091(14.2801) | Bit/dim 3.6482(3.6718) | Xent 0.6583(0.6851) | Loss 3.9773(4.0143) | Error 0.2278(0.2432) Steps 568(580.47) | Grad Norm 2.8409(3.9559) | Total Time 14.00(14.00)\n",
      "Iter 4580 | Time 14.7135(14.2770) | Bit/dim 3.6914(3.6728) | Xent 0.6608(0.6800) | Loss 4.0218(4.0128) | Error 0.2333(0.2417) Steps 574(580.08) | Grad Norm 4.2367(3.8899) | Total Time 14.00(14.00)\n",
      "Iter 4590 | Time 14.6947(14.3083) | Bit/dim 3.6531(3.6730) | Xent 0.6441(0.6756) | Loss 3.9752(4.0108) | Error 0.2311(0.2403) Steps 574(580.35) | Grad Norm 3.9020(4.0986) | Total Time 14.00(14.00)\n",
      "Iter 4600 | Time 13.7742(14.2611) | Bit/dim 3.6356(3.6714) | Xent 0.6816(0.6767) | Loss 3.9765(4.0097) | Error 0.2589(0.2416) Steps 574(579.87) | Grad Norm 3.1353(4.1374) | Total Time 14.00(14.00)\n",
      "Iter 4610 | Time 14.8288(14.2775) | Bit/dim 3.6735(3.6701) | Xent 0.6865(0.6764) | Loss 4.0167(4.0083) | Error 0.2333(0.2405) Steps 586(579.47) | Grad Norm 5.7343(4.3374) | Total Time 14.00(14.00)\n",
      "Iter 4620 | Time 14.1776(14.2878) | Bit/dim 3.6768(3.6707) | Xent 0.7016(0.6852) | Loss 4.0276(4.0133) | Error 0.2467(0.2429) Steps 580(579.35) | Grad Norm 4.6721(4.8371) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0084 | Time 79.0132, Epoch Time 881.3797(882.1310), Bit/dim 3.6766(best: 3.6723), Xent 0.7315, Loss 4.0423, Error 0.2541(best: 0.2539)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4630 | Time 14.2569(14.3045) | Bit/dim 3.6675(3.6715) | Xent 0.6420(0.6789) | Loss 3.9885(4.0110) | Error 0.2289(0.2408) Steps 586(580.50) | Grad Norm 3.7390(4.7130) | Total Time 14.00(14.00)\n",
      "Iter 4640 | Time 14.1159(14.3136) | Bit/dim 3.6512(3.6696) | Xent 0.6558(0.6760) | Loss 3.9792(4.0076) | Error 0.2344(0.2395) Steps 574(580.17) | Grad Norm 4.9270(4.6246) | Total Time 14.00(14.00)\n",
      "Iter 4650 | Time 13.8270(14.2670) | Bit/dim 3.6403(3.6685) | Xent 0.6793(0.6767) | Loss 3.9799(4.0068) | Error 0.2533(0.2406) Steps 574(579.34) | Grad Norm 4.7114(4.6406) | Total Time 14.00(14.00)\n",
      "Iter 4660 | Time 14.4192(14.2642) | Bit/dim 3.6453(3.6664) | Xent 0.7323(0.6770) | Loss 4.0114(4.0049) | Error 0.2622(0.2397) Steps 592(580.09) | Grad Norm 3.1644(4.4870) | Total Time 14.00(14.00)\n",
      "Iter 4670 | Time 14.4738(14.3026) | Bit/dim 3.6877(3.6689) | Xent 0.7227(0.6770) | Loss 4.0491(4.0074) | Error 0.2544(0.2406) Steps 568(579.45) | Grad Norm 4.2256(4.3452) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0085 | Time 80.6299, Epoch Time 886.0068(882.2473), Bit/dim 3.6666(best: 3.6723), Xent 0.7269, Loss 4.0300, Error 0.2535(best: 0.2539)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4680 | Time 14.7064(14.3352) | Bit/dim 3.6849(3.6735) | Xent 0.7200(0.6763) | Loss 4.0449(4.0116) | Error 0.2478(0.2405) Steps 574(579.54) | Grad Norm 5.7598(4.3476) | Total Time 14.00(14.00)\n",
      "Iter 4690 | Time 14.2721(14.3619) | Bit/dim 3.6667(3.6717) | Xent 0.7149(0.6788) | Loss 4.0241(4.0111) | Error 0.2589(0.2411) Steps 586(580.02) | Grad Norm 5.4529(4.3786) | Total Time 14.00(14.00)\n",
      "Iter 4700 | Time 14.8291(14.3856) | Bit/dim 3.6712(3.6708) | Xent 0.5979(0.6715) | Loss 3.9702(4.0065) | Error 0.2167(0.2395) Steps 592(581.81) | Grad Norm 3.7290(4.5555) | Total Time 14.00(14.00)\n",
      "Iter 4710 | Time 14.6015(14.3607) | Bit/dim 3.6666(3.6696) | Xent 0.7832(0.6793) | Loss 4.0582(4.0093) | Error 0.2867(0.2415) Steps 586(582.48) | Grad Norm 6.3876(4.6245) | Total Time 14.00(14.00)\n",
      "Iter 4720 | Time 13.8712(14.3609) | Bit/dim 3.6587(3.6685) | Xent 0.6963(0.6775) | Loss 4.0068(4.0073) | Error 0.2567(0.2405) Steps 592(583.65) | Grad Norm 4.5674(4.7299) | Total Time 14.00(14.00)\n",
      "Iter 4730 | Time 14.3851(14.3539) | Bit/dim 3.6483(3.6703) | Xent 0.6323(0.6815) | Loss 3.9644(4.0110) | Error 0.2133(0.2414) Steps 592(584.77) | Grad Norm 3.7271(4.9566) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0086 | Time 79.5846, Epoch Time 888.0401(882.4211), Bit/dim 3.6814(best: 3.6666), Xent 0.7256, Loss 4.0442, Error 0.2589(best: 0.2535)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4740 | Time 14.7328(14.3369) | Bit/dim 3.6834(3.6689) | Xent 0.6919(0.6750) | Loss 4.0294(4.0064) | Error 0.2522(0.2388) Steps 586(584.33) | Grad Norm 4.3477(4.9764) | Total Time 14.00(14.00)\n",
      "Iter 4750 | Time 14.3332(14.3415) | Bit/dim 3.6579(3.6674) | Xent 0.6403(0.6702) | Loss 3.9781(4.0025) | Error 0.2311(0.2382) Steps 574(582.78) | Grad Norm 4.8209(4.7212) | Total Time 14.00(14.00)\n",
      "Iter 4760 | Time 14.0932(14.3327) | Bit/dim 3.6693(3.6697) | Xent 0.6325(0.6702) | Loss 3.9856(4.0048) | Error 0.2211(0.2389) Steps 568(582.79) | Grad Norm 3.0674(4.5654) | Total Time 14.00(14.00)\n",
      "Iter 4770 | Time 14.2253(14.3149) | Bit/dim 3.6881(3.6709) | Xent 0.6160(0.6690) | Loss 3.9961(4.0053) | Error 0.2133(0.2383) Steps 574(580.76) | Grad Norm 4.5541(4.5091) | Total Time 14.00(14.00)\n",
      "Iter 4780 | Time 14.0662(14.3526) | Bit/dim 3.6725(3.6682) | Xent 0.6844(0.6722) | Loss 4.0147(4.0043) | Error 0.2456(0.2394) Steps 592(580.58) | Grad Norm 6.6691(4.8732) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0087 | Time 79.7397, Epoch Time 886.1421(882.5327), Bit/dim 3.6657(best: 3.6666), Xent 0.7403, Loss 4.0359, Error 0.2573(best: 0.2535)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4790 | Time 14.3066(14.3506) | Bit/dim 3.6898(3.6681) | Xent 0.6556(0.6668) | Loss 4.0176(4.0015) | Error 0.2089(0.2379) Steps 592(582.34) | Grad Norm 5.1579(4.7420) | Total Time 14.00(14.00)\n",
      "Iter 4800 | Time 14.3496(14.3202) | Bit/dim 3.6608(3.6679) | Xent 0.6156(0.6621) | Loss 3.9686(3.9989) | Error 0.2378(0.2377) Steps 592(583.54) | Grad Norm 2.9517(4.6474) | Total Time 14.00(14.00)\n",
      "Iter 4810 | Time 15.3965(14.3448) | Bit/dim 3.6777(3.6650) | Xent 0.7160(0.6562) | Loss 4.0357(3.9931) | Error 0.2511(0.2350) Steps 604(584.27) | Grad Norm 4.4000(4.5442) | Total Time 14.00(14.00)\n",
      "Iter 4820 | Time 13.7660(14.3767) | Bit/dim 3.6645(3.6651) | Xent 0.6283(0.6627) | Loss 3.9787(3.9965) | Error 0.2200(0.2365) Steps 574(584.16) | Grad Norm 5.7034(4.6742) | Total Time 14.00(14.00)\n",
      "Iter 4830 | Time 14.2862(14.3395) | Bit/dim 3.6904(3.6675) | Xent 0.6550(0.6664) | Loss 4.0179(4.0007) | Error 0.2289(0.2388) Steps 580(583.30) | Grad Norm 5.9353(4.7246) | Total Time 14.00(14.00)\n",
      "Iter 4840 | Time 14.3053(14.2680) | Bit/dim 3.6605(3.6661) | Xent 0.7145(0.6728) | Loss 4.0177(4.0025) | Error 0.2500(0.2404) Steps 568(582.99) | Grad Norm 4.3903(4.8421) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0088 | Time 77.6658, Epoch Time 880.8326(882.4817), Bit/dim 3.6620(best: 3.6657), Xent 0.7356, Loss 4.0298, Error 0.2588(best: 0.2535)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4850 | Time 14.2203(14.2910) | Bit/dim 3.6620(3.6662) | Xent 0.7038(0.6662) | Loss 4.0139(3.9993) | Error 0.2500(0.2397) Steps 580(582.68) | Grad Norm 5.0728(4.5207) | Total Time 14.00(14.00)\n",
      "Iter 4860 | Time 13.9239(14.2908) | Bit/dim 3.6979(3.6664) | Xent 0.5762(0.6597) | Loss 3.9860(3.9962) | Error 0.1989(0.2375) Steps 580(582.18) | Grad Norm 3.5410(4.4374) | Total Time 14.00(14.00)\n",
      "Iter 4870 | Time 14.0159(14.2865) | Bit/dim 3.6843(3.6660) | Xent 0.6230(0.6566) | Loss 3.9958(3.9943) | Error 0.2167(0.2346) Steps 592(583.92) | Grad Norm 3.1873(4.2524) | Total Time 14.00(14.00)\n",
      "Iter 4880 | Time 14.0623(14.2968) | Bit/dim 3.6537(3.6647) | Xent 0.6681(0.6572) | Loss 3.9878(3.9933) | Error 0.2433(0.2348) Steps 580(583.07) | Grad Norm 3.3392(4.0684) | Total Time 14.00(14.00)\n",
      "Iter 4890 | Time 14.2117(14.2993) | Bit/dim 3.7021(3.6622) | Xent 0.7061(0.6583) | Loss 4.0551(3.9914) | Error 0.2600(0.2346) Steps 586(583.17) | Grad Norm 6.0922(4.3202) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0089 | Time 78.5301, Epoch Time 883.7583(882.5200), Bit/dim 3.6617(best: 3.6620), Xent 0.7166, Loss 4.0200, Error 0.2515(best: 0.2535)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4900 | Time 13.9429(14.3175) | Bit/dim 3.6600(3.6624) | Xent 0.6933(0.6570) | Loss 4.0067(3.9909) | Error 0.2478(0.2343) Steps 592(583.47) | Grad Norm 4.5613(4.3908) | Total Time 14.00(14.00)\n",
      "Iter 4910 | Time 14.0164(14.3158) | Bit/dim 3.6409(3.6608) | Xent 0.6130(0.6510) | Loss 3.9473(3.9863) | Error 0.2133(0.2324) Steps 580(582.40) | Grad Norm 4.9846(4.4872) | Total Time 14.00(14.00)\n",
      "Iter 4920 | Time 14.3549(14.3579) | Bit/dim 3.6367(3.6618) | Xent 0.7297(0.6508) | Loss 4.0016(3.9872) | Error 0.2478(0.2317) Steps 586(582.32) | Grad Norm 7.1935(4.4522) | Total Time 14.00(14.00)\n",
      "Iter 4930 | Time 14.0402(14.3243) | Bit/dim 3.6898(3.6627) | Xent 0.6974(0.6535) | Loss 4.0385(3.9894) | Error 0.2356(0.2320) Steps 580(582.35) | Grad Norm 4.0890(4.5260) | Total Time 14.00(14.00)\n",
      "Iter 4940 | Time 14.3989(14.3513) | Bit/dim 3.6587(3.6613) | Xent 0.6712(0.6516) | Loss 3.9943(3.9871) | Error 0.2556(0.2319) Steps 586(583.01) | Grad Norm 5.9070(4.5893) | Total Time 14.00(14.00)\n",
      "Iter 4950 | Time 14.1912(14.3509) | Bit/dim 3.6317(3.6647) | Xent 0.6353(0.6565) | Loss 3.9494(3.9929) | Error 0.2233(0.2336) Steps 586(584.15) | Grad Norm 3.4433(4.5701) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0090 | Time 77.9614, Epoch Time 885.3994(882.6064), Bit/dim 3.6667(best: 3.6617), Xent 0.7523, Loss 4.0428, Error 0.2677(best: 0.2515)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 4960 | Time 14.4730(14.3863) | Bit/dim 3.6095(3.6614) | Xent 0.6602(0.6523) | Loss 3.9396(3.9875) | Error 0.2289(0.2313) Steps 586(584.51) | Grad Norm 5.5888(4.5135) | Total Time 14.00(14.00)\n",
      "Iter 4970 | Time 14.1267(14.3143) | Bit/dim 3.6776(3.6611) | Xent 0.6294(0.6509) | Loss 3.9923(3.9865) | Error 0.2156(0.2313) Steps 574(583.78) | Grad Norm 5.0859(4.3870) | Total Time 14.00(14.00)\n",
      "Iter 4980 | Time 14.4856(14.3113) | Bit/dim 3.6275(3.6612) | Xent 0.6785(0.6531) | Loss 3.9668(3.9878) | Error 0.2367(0.2330) Steps 592(584.77) | Grad Norm 3.4384(4.4968) | Total Time 14.00(14.00)\n",
      "Iter 4990 | Time 14.4791(14.3265) | Bit/dim 3.6255(3.6606) | Xent 0.7223(0.6574) | Loss 3.9867(3.9892) | Error 0.2478(0.2337) Steps 586(584.81) | Grad Norm 4.0070(4.4727) | Total Time 14.00(14.00)\n",
      "Iter 5000 | Time 14.8839(14.3737) | Bit/dim 3.7110(3.6626) | Xent 0.7101(0.6558) | Loss 4.0661(3.9905) | Error 0.2544(0.2324) Steps 592(584.39) | Grad Norm 6.3643(4.5350) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0091 | Time 76.9725, Epoch Time 883.9391(882.6464), Bit/dim 3.6580(best: 3.6617), Xent 0.6969, Loss 4.0064, Error 0.2489(best: 0.2515)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5010 | Time 13.8811(14.3622) | Bit/dim 3.6344(3.6620) | Xent 0.7288(0.6553) | Loss 3.9988(3.9897) | Error 0.2756(0.2340) Steps 586(584.83) | Grad Norm 4.5029(4.4337) | Total Time 14.00(14.00)\n",
      "Iter 5020 | Time 14.2347(14.3507) | Bit/dim 3.6455(3.6629) | Xent 0.6812(0.6502) | Loss 3.9861(3.9880) | Error 0.2489(0.2320) Steps 586(585.29) | Grad Norm 4.9491(4.5243) | Total Time 14.00(14.00)\n",
      "Iter 5030 | Time 14.7905(14.3254) | Bit/dim 3.6501(3.6617) | Xent 0.6299(0.6559) | Loss 3.9651(3.9896) | Error 0.2122(0.2330) Steps 592(585.59) | Grad Norm 3.9947(4.9902) | Total Time 14.00(14.00)\n",
      "Iter 5040 | Time 14.3214(14.3580) | Bit/dim 3.6303(3.6593) | Xent 0.6100(0.6544) | Loss 3.9353(3.9866) | Error 0.2256(0.2334) Steps 592(585.00) | Grad Norm 2.6022(4.5747) | Total Time 14.00(14.00)\n",
      "Iter 5050 | Time 13.8485(14.4073) | Bit/dim 3.7065(3.6620) | Xent 0.6024(0.6488) | Loss 4.0077(3.9864) | Error 0.2189(0.2319) Steps 592(586.51) | Grad Norm 5.2545(4.3843) | Total Time 14.00(14.00)\n",
      "Iter 5060 | Time 14.1461(14.4478) | Bit/dim 3.6760(3.6619) | Xent 0.6384(0.6520) | Loss 3.9952(3.9879) | Error 0.2367(0.2322) Steps 592(586.92) | Grad Norm 1.9917(4.3092) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0092 | Time 81.4500, Epoch Time 892.0908(882.9297), Bit/dim 3.6612(best: 3.6580), Xent 0.7210, Loss 4.0217, Error 0.2545(best: 0.2489)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5070 | Time 14.5719(14.5074) | Bit/dim 3.6281(3.6588) | Xent 0.6130(0.6492) | Loss 3.9345(3.9834) | Error 0.2200(0.2307) Steps 586(588.28) | Grad Norm 2.8001(4.2195) | Total Time 14.00(14.00)\n",
      "Iter 5080 | Time 14.1478(14.5509) | Bit/dim 3.6718(3.6578) | Xent 0.5994(0.6430) | Loss 3.9715(3.9793) | Error 0.2333(0.2289) Steps 592(590.47) | Grad Norm 2.8038(4.1886) | Total Time 14.00(14.00)\n",
      "Iter 5090 | Time 14.8822(14.5207) | Bit/dim 3.6683(3.6588) | Xent 0.6530(0.6388) | Loss 3.9947(3.9781) | Error 0.2367(0.2280) Steps 604(589.91) | Grad Norm 4.4074(4.1829) | Total Time 14.00(14.00)\n",
      "Iter 5100 | Time 14.1983(14.4635) | Bit/dim 3.6665(3.6576) | Xent 0.6403(0.6457) | Loss 3.9867(3.9805) | Error 0.2256(0.2314) Steps 580(589.74) | Grad Norm 3.2088(4.1502) | Total Time 14.00(14.00)\n",
      "Iter 5110 | Time 14.0252(14.4383) | Bit/dim 3.6879(3.6578) | Xent 0.6654(0.6394) | Loss 4.0206(3.9775) | Error 0.2356(0.2283) Steps 592(589.16) | Grad Norm 3.8533(4.1344) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0093 | Time 80.6386, Epoch Time 896.1605(883.3266), Bit/dim 3.6588(best: 3.6580), Xent 0.7082, Loss 4.0129, Error 0.2452(best: 0.2489)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5120 | Time 14.4282(14.4508) | Bit/dim 3.6709(3.6600) | Xent 0.6626(0.6311) | Loss 4.0022(3.9756) | Error 0.2500(0.2260) Steps 586(588.82) | Grad Norm 3.6552(4.2594) | Total Time 14.00(14.00)\n",
      "Iter 5130 | Time 14.8941(14.4853) | Bit/dim 3.6577(3.6563) | Xent 0.5818(0.6250) | Loss 3.9486(3.9688) | Error 0.2078(0.2231) Steps 592(589.71) | Grad Norm 3.8620(4.1527) | Total Time 14.00(14.00)\n",
      "Iter 5140 | Time 14.6919(14.5069) | Bit/dim 3.6437(3.6561) | Xent 0.5485(0.6194) | Loss 3.9179(3.9657) | Error 0.2000(0.2205) Steps 586(590.29) | Grad Norm 2.7417(4.3572) | Total Time 14.00(14.00)\n",
      "Iter 5150 | Time 14.1805(14.5000) | Bit/dim 3.6688(3.6577) | Xent 0.5502(0.6201) | Loss 3.9439(3.9677) | Error 0.1989(0.2204) Steps 586(590.19) | Grad Norm 4.8099(4.4289) | Total Time 14.00(14.00)\n",
      "Iter 5160 | Time 15.4259(14.5138) | Bit/dim 3.6659(3.6548) | Xent 0.5224(0.6151) | Loss 3.9271(3.9623) | Error 0.2078(0.2196) Steps 604(590.10) | Grad Norm 3.8756(4.2379) | Total Time 14.00(14.00)\n",
      "Iter 5170 | Time 14.7664(14.5624) | Bit/dim 3.6754(3.6572) | Xent 0.6691(0.6205) | Loss 4.0099(3.9675) | Error 0.2444(0.2218) Steps 586(589.58) | Grad Norm 5.7803(4.2772) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0094 | Time 79.7604, Epoch Time 898.7480(883.7893), Bit/dim 3.6542(best: 3.6580), Xent 0.7451, Loss 4.0267, Error 0.2566(best: 0.2452)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5180 | Time 15.0320(14.5975) | Bit/dim 3.6367(3.6594) | Xent 0.5864(0.6130) | Loss 3.9299(3.9659) | Error 0.2078(0.2189) Steps 592(590.66) | Grad Norm 3.8806(4.1747) | Total Time 14.00(14.00)\n",
      "Iter 5190 | Time 14.6053(14.6026) | Bit/dim 3.6267(3.6593) | Xent 0.6934(0.6257) | Loss 3.9734(3.9722) | Error 0.2356(0.2231) Steps 592(590.29) | Grad Norm 4.6041(4.4466) | Total Time 14.00(14.00)\n",
      "Iter 5200 | Time 14.6784(14.6565) | Bit/dim 3.6741(3.6557) | Xent 0.6007(0.6267) | Loss 3.9745(3.9691) | Error 0.2078(0.2225) Steps 586(590.24) | Grad Norm 2.9400(4.3341) | Total Time 14.00(14.00)\n",
      "Iter 5210 | Time 15.0542(14.6566) | Bit/dim 3.6561(3.6578) | Xent 0.6587(0.6235) | Loss 3.9855(3.9696) | Error 0.2367(0.2216) Steps 592(591.69) | Grad Norm 4.5823(4.2271) | Total Time 14.00(14.00)\n",
      "Iter 5220 | Time 14.6014(14.6601) | Bit/dim 3.6865(3.6569) | Xent 0.5883(0.6236) | Loss 3.9807(3.9687) | Error 0.2067(0.2217) Steps 580(590.84) | Grad Norm 5.2071(4.2870) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0095 | Time 82.7493, Epoch Time 907.6018(884.5036), Bit/dim 3.6583(best: 3.6542), Xent 0.7259, Loss 4.0213, Error 0.2528(best: 0.2452)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5230 | Time 15.2078(14.6619) | Bit/dim 3.6384(3.6528) | Xent 0.5758(0.6221) | Loss 3.9263(3.9638) | Error 0.2067(0.2204) Steps 580(589.85) | Grad Norm 2.3440(4.1721) | Total Time 14.00(14.00)\n",
      "Iter 5240 | Time 14.1665(14.6465) | Bit/dim 3.6524(3.6543) | Xent 0.6010(0.6127) | Loss 3.9529(3.9607) | Error 0.2211(0.2173) Steps 592(588.47) | Grad Norm 2.5815(4.0532) | Total Time 14.00(14.00)\n",
      "Iter 5250 | Time 14.7894(14.6964) | Bit/dim 3.6457(3.6542) | Xent 0.6485(0.6144) | Loss 3.9699(3.9614) | Error 0.2300(0.2185) Steps 592(588.74) | Grad Norm 4.8209(4.1067) | Total Time 14.00(14.00)\n",
      "Iter 5260 | Time 15.1831(14.7375) | Bit/dim 3.6470(3.6532) | Xent 0.5633(0.6108) | Loss 3.9287(3.9587) | Error 0.1900(0.2171) Steps 610(591.77) | Grad Norm 2.5438(3.9959) | Total Time 14.00(14.00)\n",
      "Iter 5270 | Time 14.6391(14.7125) | Bit/dim 3.6363(3.6527) | Xent 0.6739(0.6132) | Loss 3.9733(3.9593) | Error 0.2400(0.2178) Steps 604(592.87) | Grad Norm 5.2560(4.0679) | Total Time 14.00(14.00)\n",
      "Iter 5280 | Time 14.7134(14.7242) | Bit/dim 3.6507(3.6525) | Xent 0.5849(0.6103) | Loss 3.9431(3.9577) | Error 0.2100(0.2177) Steps 592(593.28) | Grad Norm 4.6207(4.1433) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0096 | Time 79.4135, Epoch Time 908.1647(885.2135), Bit/dim 3.6552(best: 3.6542), Xent 0.7295, Loss 4.0200, Error 0.2547(best: 0.2452)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5290 | Time 14.8985(14.7610) | Bit/dim 3.6708(3.6530) | Xent 0.6000(0.6063) | Loss 3.9708(3.9562) | Error 0.2211(0.2166) Steps 604(594.15) | Grad Norm 3.3201(4.0596) | Total Time 14.00(14.00)\n",
      "Iter 5300 | Time 15.5095(14.7462) | Bit/dim 3.6616(3.6536) | Xent 0.6428(0.5994) | Loss 3.9830(3.9533) | Error 0.2244(0.2137) Steps 586(594.01) | Grad Norm 5.9308(4.0345) | Total Time 14.00(14.00)\n",
      "Iter 5310 | Time 14.3331(14.7425) | Bit/dim 3.6532(3.6522) | Xent 0.6439(0.6091) | Loss 3.9752(3.9567) | Error 0.2144(0.2166) Steps 598(594.12) | Grad Norm 4.1182(4.4166) | Total Time 14.00(14.00)\n",
      "Iter 5320 | Time 14.2929(14.7308) | Bit/dim 3.6485(3.6561) | Xent 0.5960(0.6195) | Loss 3.9464(3.9658) | Error 0.2233(0.2207) Steps 586(595.35) | Grad Norm 3.9390(4.4061) | Total Time 14.00(14.00)\n",
      "Iter 5330 | Time 13.8107(14.6541) | Bit/dim 3.6514(3.6548) | Xent 0.6720(0.6192) | Loss 3.9874(3.9644) | Error 0.2322(0.2196) Steps 586(594.61) | Grad Norm 4.5886(4.5252) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0097 | Time 79.6855, Epoch Time 905.5863(885.8247), Bit/dim 3.6541(best: 3.6542), Xent 0.6957, Loss 4.0019, Error 0.2444(best: 0.2452)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5340 | Time 15.1001(14.6612) | Bit/dim 3.6267(3.6525) | Xent 0.6291(0.6200) | Loss 3.9413(3.9626) | Error 0.2122(0.2193) Steps 598(594.13) | Grad Norm 4.2759(4.4029) | Total Time 14.00(14.00)\n",
      "Iter 5350 | Time 14.9190(14.6877) | Bit/dim 3.6114(3.6536) | Xent 0.6481(0.6156) | Loss 3.9354(3.9614) | Error 0.2300(0.2188) Steps 610(594.67) | Grad Norm 6.6516(4.2375) | Total Time 14.00(14.00)\n",
      "Iter 5360 | Time 14.9332(14.7264) | Bit/dim 3.6562(3.6534) | Xent 0.6554(0.6152) | Loss 3.9839(3.9610) | Error 0.2489(0.2195) Steps 592(595.11) | Grad Norm 3.8084(4.3124) | Total Time 14.00(14.00)\n",
      "Iter 5370 | Time 15.0253(14.7547) | Bit/dim 3.6453(3.6528) | Xent 0.6048(0.6157) | Loss 3.9477(3.9606) | Error 0.2233(0.2205) Steps 616(596.68) | Grad Norm 2.4045(4.2135) | Total Time 14.00(14.00)\n",
      "Iter 5380 | Time 15.0708(14.8095) | Bit/dim 3.6496(3.6508) | Xent 0.5819(0.6151) | Loss 3.9406(3.9583) | Error 0.2067(0.2207) Steps 604(598.60) | Grad Norm 5.7617(4.2657) | Total Time 14.00(14.00)\n",
      "Iter 5390 | Time 14.8049(14.7745) | Bit/dim 3.6411(3.6502) | Xent 0.5886(0.6113) | Loss 3.9355(3.9559) | Error 0.1978(0.2191) Steps 604(598.36) | Grad Norm 4.8381(4.3536) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0098 | Time 82.1256, Epoch Time 913.6381(886.6591), Bit/dim 3.6495(best: 3.6541), Xent 0.7061, Loss 4.0026, Error 0.2463(best: 0.2444)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5400 | Time 14.4910(14.7749) | Bit/dim 3.6714(3.6541) | Xent 0.5888(0.6104) | Loss 3.9658(3.9593) | Error 0.2044(0.2194) Steps 604(597.85) | Grad Norm 3.8347(4.5106) | Total Time 14.00(14.00)\n",
      "Iter 5410 | Time 14.5099(14.7800) | Bit/dim 3.6792(3.6530) | Xent 0.6231(0.6132) | Loss 3.9908(3.9596) | Error 0.2222(0.2192) Steps 592(597.71) | Grad Norm 3.3652(4.5351) | Total Time 14.00(14.00)\n",
      "Iter 5420 | Time 14.0981(14.7227) | Bit/dim 3.6280(3.6511) | Xent 0.5826(0.6087) | Loss 3.9193(3.9555) | Error 0.1944(0.2169) Steps 592(597.73) | Grad Norm 3.2759(4.3259) | Total Time 14.00(14.00)\n",
      "Iter 5430 | Time 14.9249(14.7735) | Bit/dim 3.6554(3.6494) | Xent 0.5869(0.6070) | Loss 3.9488(3.9529) | Error 0.2122(0.2158) Steps 586(597.91) | Grad Norm 5.3867(4.3855) | Total Time 14.00(14.00)\n",
      "Iter 5440 | Time 14.5284(14.8102) | Bit/dim 3.6264(3.6496) | Xent 0.5842(0.6085) | Loss 3.9185(3.9538) | Error 0.2067(0.2174) Steps 610(597.81) | Grad Norm 2.9205(4.4830) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0099 | Time 82.5666, Epoch Time 914.8424(887.5046), Bit/dim 3.6514(best: 3.6495), Xent 0.7174, Loss 4.0100, Error 0.2488(best: 0.2444)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5450 | Time 14.4932(14.8114) | Bit/dim 3.6518(3.6497) | Xent 0.6286(0.6075) | Loss 3.9661(3.9535) | Error 0.2189(0.2162) Steps 604(598.12) | Grad Norm 5.6675(4.5856) | Total Time 14.00(14.00)\n",
      "Iter 5460 | Time 14.9058(14.8860) | Bit/dim 3.6337(3.6476) | Xent 0.6241(0.6048) | Loss 3.9458(3.9500) | Error 0.2044(0.2139) Steps 604(599.39) | Grad Norm 6.1676(4.6486) | Total Time 14.00(14.00)\n",
      "Iter 5470 | Time 14.6709(14.8627) | Bit/dim 3.6637(3.6510) | Xent 0.5836(0.6124) | Loss 3.9555(3.9572) | Error 0.2111(0.2171) Steps 604(600.24) | Grad Norm 5.1218(4.9652) | Total Time 14.00(14.00)\n",
      "Iter 5480 | Time 14.5588(14.8487) | Bit/dim 3.6512(3.6528) | Xent 0.5783(0.6058) | Loss 3.9403(3.9557) | Error 0.2178(0.2164) Steps 604(600.22) | Grad Norm 5.6317(4.6032) | Total Time 14.00(14.00)\n",
      "Iter 5490 | Time 15.1757(14.8494) | Bit/dim 3.6354(3.6527) | Xent 0.6023(0.6063) | Loss 3.9365(3.9559) | Error 0.2122(0.2163) Steps 616(601.79) | Grad Norm 2.2008(4.2874) | Total Time 14.00(14.00)\n",
      "Iter 5500 | Time 14.9033(14.8698) | Bit/dim 3.6205(3.6495) | Xent 0.6114(0.6028) | Loss 3.9262(3.9509) | Error 0.2189(0.2149) Steps 610(603.19) | Grad Norm 4.4779(4.2464) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0100 | Time 81.7397, Epoch Time 918.0499(888.4209), Bit/dim 3.6545(best: 3.6495), Xent 0.6959, Loss 4.0024, Error 0.2411(best: 0.2444)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5510 | Time 14.6273(14.8306) | Bit/dim 3.6539(3.6521) | Xent 0.5937(0.5941) | Loss 3.9508(3.9492) | Error 0.2122(0.2122) Steps 610(603.34) | Grad Norm 4.3429(4.2842) | Total Time 14.00(14.00)\n",
      "Iter 5520 | Time 14.5396(14.8085) | Bit/dim 3.6706(3.6491) | Xent 0.6018(0.5927) | Loss 3.9715(3.9454) | Error 0.2067(0.2111) Steps 604(603.82) | Grad Norm 3.5554(4.2034) | Total Time 14.00(14.00)\n",
      "Iter 5530 | Time 15.1158(14.7726) | Bit/dim 3.6529(3.6496) | Xent 0.5452(0.5903) | Loss 3.9255(3.9448) | Error 0.1933(0.2096) Steps 604(603.05) | Grad Norm 2.9446(3.9962) | Total Time 14.00(14.00)\n",
      "Iter 5540 | Time 14.9436(14.8335) | Bit/dim 3.6213(3.6438) | Xent 0.5418(0.5827) | Loss 3.8921(3.9351) | Error 0.1800(0.2072) Steps 616(604.45) | Grad Norm 3.1912(4.0016) | Total Time 14.00(14.00)\n",
      "Iter 5550 | Time 14.6868(14.8081) | Bit/dim 3.6123(3.6439) | Xent 0.7042(0.5951) | Loss 3.9644(3.9414) | Error 0.2389(0.2110) Steps 604(603.67) | Grad Norm 6.9264(4.1530) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0101 | Time 80.3135, Epoch Time 912.2584(889.1360), Bit/dim 3.6588(best: 3.6495), Xent 0.7258, Loss 4.0217, Error 0.2526(best: 0.2411)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5560 | Time 14.7746(14.8195) | Bit/dim 3.6506(3.6447) | Xent 0.5476(0.5958) | Loss 3.9244(3.9426) | Error 0.1889(0.2106) Steps 616(603.48) | Grad Norm 3.6581(4.2787) | Total Time 14.00(14.00)\n",
      "Iter 5570 | Time 15.1953(14.8429) | Bit/dim 3.6743(3.6441) | Xent 0.5408(0.5869) | Loss 3.9447(3.9376) | Error 0.1933(0.2081) Steps 598(604.29) | Grad Norm 4.7233(4.1280) | Total Time 14.00(14.00)\n",
      "Iter 5580 | Time 15.3601(14.8208) | Bit/dim 3.6390(3.6417) | Xent 0.5292(0.5866) | Loss 3.9036(3.9350) | Error 0.1756(0.2088) Steps 616(604.56) | Grad Norm 4.4833(4.1172) | Total Time 14.00(14.00)\n",
      "Iter 5590 | Time 15.0672(14.8704) | Bit/dim 3.6779(3.6457) | Xent 0.6234(0.5880) | Loss 3.9896(3.9397) | Error 0.2144(0.2101) Steps 604(604.39) | Grad Norm 8.0864(4.2576) | Total Time 14.00(14.00)\n",
      "Iter 5600 | Time 14.4430(14.8658) | Bit/dim 3.6248(3.6507) | Xent 0.5696(0.5895) | Loss 3.9096(3.9454) | Error 0.2022(0.2095) Steps 586(603.39) | Grad Norm 2.7631(4.2506) | Total Time 14.00(14.00)\n",
      "Iter 5610 | Time 15.0978(14.8660) | Bit/dim 3.6823(3.6476) | Xent 0.6073(0.5917) | Loss 3.9859(3.9435) | Error 0.1922(0.2091) Steps 610(603.35) | Grad Norm 4.7933(4.1923) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0102 | Time 81.3270, Epoch Time 916.5328(889.9579), Bit/dim 3.6467(best: 3.6495), Xent 0.6866, Loss 3.9900, Error 0.2376(best: 0.2411)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5620 | Time 15.2146(14.9072) | Bit/dim 3.6563(3.6477) | Xent 0.5484(0.5867) | Loss 3.9305(3.9410) | Error 0.2078(0.2077) Steps 610(603.23) | Grad Norm 3.0860(4.1991) | Total Time 14.00(14.00)\n",
      "Iter 5630 | Time 14.5374(14.8683) | Bit/dim 3.6516(3.6460) | Xent 0.5736(0.5764) | Loss 3.9384(3.9342) | Error 0.2067(0.2047) Steps 616(604.27) | Grad Norm 4.4027(4.0066) | Total Time 14.00(14.00)\n",
      "Iter 5640 | Time 14.4632(14.8269) | Bit/dim 3.6657(3.6474) | Xent 0.6086(0.5745) | Loss 3.9701(3.9347) | Error 0.2178(0.2053) Steps 598(603.69) | Grad Norm 6.2278(4.0240) | Total Time 14.00(14.00)\n",
      "Iter 5650 | Time 14.3888(14.8395) | Bit/dim 3.6523(3.6478) | Xent 0.6459(0.5928) | Loss 3.9752(3.9442) | Error 0.2244(0.2104) Steps 610(602.31) | Grad Norm 5.5228(4.5323) | Total Time 14.00(14.00)\n",
      "Iter 5660 | Time 14.9271(14.8690) | Bit/dim 3.6523(3.6452) | Xent 0.6304(0.5951) | Loss 3.9675(3.9428) | Error 0.2267(0.2119) Steps 604(601.52) | Grad Norm 3.6121(4.3712) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0103 | Time 82.3081, Epoch Time 918.4748(890.8134), Bit/dim 3.6384(best: 3.6467), Xent 0.7057, Loss 3.9912, Error 0.2471(best: 0.2376)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5670 | Time 14.5185(14.8548) | Bit/dim 3.6256(3.6463) | Xent 0.5550(0.5916) | Loss 3.9031(3.9421) | Error 0.1933(0.2114) Steps 610(602.81) | Grad Norm 3.1673(4.2325) | Total Time 14.00(14.00)\n",
      "Iter 5680 | Time 14.9304(14.8557) | Bit/dim 3.6522(3.6456) | Xent 0.5626(0.5849) | Loss 3.9335(3.9380) | Error 0.1889(0.2077) Steps 604(603.72) | Grad Norm 4.3147(4.1797) | Total Time 14.00(14.00)\n",
      "Iter 5690 | Time 14.5547(14.8415) | Bit/dim 3.6021(3.6443) | Xent 0.6303(0.5832) | Loss 3.9173(3.9360) | Error 0.2267(0.2084) Steps 616(603.79) | Grad Norm 3.7797(4.1264) | Total Time 14.00(14.00)\n",
      "Iter 5700 | Time 14.7099(14.8636) | Bit/dim 3.6212(3.6439) | Xent 0.5442(0.5737) | Loss 3.8933(3.9308) | Error 0.1989(0.2047) Steps 604(605.24) | Grad Norm 3.7040(3.9464) | Total Time 14.00(14.00)\n",
      "Iter 5710 | Time 15.1665(14.8556) | Bit/dim 3.6586(3.6432) | Xent 0.5903(0.5784) | Loss 3.9537(3.9324) | Error 0.2100(0.2063) Steps 622(606.56) | Grad Norm 2.6035(4.0417) | Total Time 14.00(14.00)\n",
      "Iter 5720 | Time 14.4976(14.8780) | Bit/dim 3.6727(3.6441) | Xent 0.6177(0.5779) | Loss 3.9815(3.9330) | Error 0.2256(0.2054) Steps 604(607.60) | Grad Norm 5.6584(4.0651) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0104 | Time 82.8084, Epoch Time 917.8300(891.6239), Bit/dim 3.6462(best: 3.6384), Xent 0.6980, Loss 3.9952, Error 0.2409(best: 0.2376)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5730 | Time 14.6453(14.7791) | Bit/dim 3.6780(3.6442) | Xent 0.5474(0.5768) | Loss 3.9517(3.9326) | Error 0.1933(0.2052) Steps 610(606.60) | Grad Norm 4.6647(4.0994) | Total Time 14.00(14.00)\n",
      "Iter 5740 | Time 14.4036(14.7826) | Bit/dim 3.6047(3.6415) | Xent 0.6020(0.5730) | Loss 3.9057(3.9280) | Error 0.2133(0.2040) Steps 610(606.52) | Grad Norm 3.9051(4.1405) | Total Time 14.00(14.00)\n",
      "Iter 5750 | Time 15.0453(14.7766) | Bit/dim 3.6225(3.6403) | Xent 0.5473(0.5742) | Loss 3.8961(3.9274) | Error 0.1922(0.2036) Steps 592(606.92) | Grad Norm 2.1944(4.2290) | Total Time 14.00(14.00)\n",
      "Iter 5760 | Time 14.7228(14.7268) | Bit/dim 3.6498(3.6425) | Xent 0.5667(0.5770) | Loss 3.9331(3.9310) | Error 0.1911(0.2039) Steps 592(604.93) | Grad Norm 6.5725(4.2472) | Total Time 14.00(14.00)\n",
      "Iter 5770 | Time 14.9403(14.7362) | Bit/dim 3.6325(3.6416) | Xent 0.5901(0.5750) | Loss 3.9276(3.9291) | Error 0.2256(0.2048) Steps 598(605.11) | Grad Norm 4.1394(4.2324) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0105 | Time 80.8889, Epoch Time 907.4949(892.1001), Bit/dim 3.6420(best: 3.6384), Xent 0.6898, Loss 3.9869, Error 0.2385(best: 0.2376)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5780 | Time 14.7056(14.7714) | Bit/dim 3.6612(3.6437) | Xent 0.5435(0.5723) | Loss 3.9330(3.9298) | Error 0.1967(0.2044) Steps 616(606.61) | Grad Norm 3.6255(4.4335) | Total Time 14.00(14.00)\n",
      "Iter 5790 | Time 14.4079(14.8045) | Bit/dim 3.6357(3.6441) | Xent 0.5492(0.5845) | Loss 3.9103(3.9363) | Error 0.2000(0.2090) Steps 610(607.19) | Grad Norm 3.3336(4.8113) | Total Time 14.00(14.00)\n",
      "Iter 5800 | Time 14.6068(14.7794) | Bit/dim 3.6366(3.6456) | Xent 0.6146(0.5939) | Loss 3.9439(3.9426) | Error 0.2122(0.2128) Steps 616(607.60) | Grad Norm 5.1076(4.8337) | Total Time 14.00(14.00)\n",
      "Iter 5810 | Time 14.6286(14.8282) | Bit/dim 3.6367(3.6464) | Xent 0.5291(0.5825) | Loss 3.9013(3.9376) | Error 0.1833(0.2082) Steps 604(608.08) | Grad Norm 3.1276(4.7172) | Total Time 14.00(14.00)\n",
      "Iter 5820 | Time 15.2080(14.8549) | Bit/dim 3.6357(3.6440) | Xent 0.6912(0.5861) | Loss 3.9813(3.9371) | Error 0.2322(0.2080) Steps 616(607.65) | Grad Norm 8.4641(4.7931) | Total Time 14.00(14.00)\n",
      "Iter 5830 | Time 14.4786(14.8633) | Bit/dim 3.6506(3.6435) | Xent 0.6043(0.5987) | Loss 3.9528(3.9428) | Error 0.2067(0.2107) Steps 604(608.23) | Grad Norm 3.6499(5.0171) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0106 | Time 82.2316, Epoch Time 917.8582(892.8728), Bit/dim 3.6436(best: 3.6384), Xent 0.7369, Loss 4.0120, Error 0.2545(best: 0.2376)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5840 | Time 15.3766(14.9280) | Bit/dim 3.6831(3.6447) | Xent 0.5944(0.5948) | Loss 3.9803(3.9421) | Error 0.1989(0.2088) Steps 616(609.04) | Grad Norm 5.5274(4.9366) | Total Time 14.00(14.00)\n",
      "Iter 5850 | Time 15.3180(14.9561) | Bit/dim 3.6852(3.6442) | Xent 0.5628(0.5947) | Loss 3.9666(3.9415) | Error 0.1956(0.2108) Steps 622(608.41) | Grad Norm 5.4001(5.0209) | Total Time 14.00(14.00)\n",
      "Iter 5860 | Time 14.8613(14.8964) | Bit/dim 3.6722(3.6463) | Xent 0.5564(0.5862) | Loss 3.9504(3.9394) | Error 0.1900(0.2081) Steps 610(608.47) | Grad Norm 6.1403(4.7027) | Total Time 14.00(14.00)\n",
      "Iter 5870 | Time 14.8349(14.8799) | Bit/dim 3.6229(3.6448) | Xent 0.5798(0.5754) | Loss 3.9128(3.9325) | Error 0.2078(0.2061) Steps 598(608.25) | Grad Norm 3.4001(4.4960) | Total Time 14.00(14.00)\n",
      "Iter 5880 | Time 15.0276(14.8992) | Bit/dim 3.6711(3.6430) | Xent 0.5906(0.5723) | Loss 3.9665(3.9291) | Error 0.2156(0.2044) Steps 610(607.58) | Grad Norm 3.9664(4.2685) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0107 | Time 81.7855, Epoch Time 922.0159(893.7471), Bit/dim 3.6366(best: 3.6384), Xent 0.6823, Loss 3.9778, Error 0.2380(best: 0.2376)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5890 | Time 14.4964(14.9022) | Bit/dim 3.6503(3.6428) | Xent 0.5838(0.5715) | Loss 3.9422(3.9285) | Error 0.2033(0.2027) Steps 610(607.82) | Grad Norm 5.7833(4.2958) | Total Time 14.00(14.00)\n",
      "Iter 5900 | Time 15.3268(14.9083) | Bit/dim 3.6215(3.6402) | Xent 0.5676(0.5620) | Loss 3.9053(3.9212) | Error 0.2044(0.1998) Steps 610(609.87) | Grad Norm 4.1808(4.3406) | Total Time 14.00(14.00)\n",
      "Iter 5910 | Time 14.2419(14.8429) | Bit/dim 3.6418(3.6415) | Xent 0.6973(0.5705) | Loss 3.9904(3.9268) | Error 0.2511(0.2022) Steps 604(609.56) | Grad Norm 8.4034(4.5313) | Total Time 14.00(14.00)\n",
      "Iter 5920 | Time 15.0265(14.8640) | Bit/dim 3.6643(3.6409) | Xent 0.5914(0.5806) | Loss 3.9600(3.9313) | Error 0.2211(0.2055) Steps 610(609.41) | Grad Norm 4.5425(4.8285) | Total Time 14.00(14.00)\n",
      "Iter 5930 | Time 14.5235(14.8437) | Bit/dim 3.6474(3.6427) | Xent 0.6070(0.5797) | Loss 3.9509(3.9325) | Error 0.2156(0.2059) Steps 604(608.76) | Grad Norm 3.4203(4.7770) | Total Time 14.00(14.00)\n",
      "Iter 5940 | Time 14.4988(14.8162) | Bit/dim 3.6349(3.6434) | Xent 0.6006(0.5770) | Loss 3.9352(3.9319) | Error 0.2200(0.2047) Steps 604(608.53) | Grad Norm 4.8478(4.5019) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0108 | Time 82.8104, Epoch Time 914.5480(894.3711), Bit/dim 3.6401(best: 3.6366), Xent 0.6867, Loss 3.9834, Error 0.2377(best: 0.2376)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 5950 | Time 14.3937(14.8000) | Bit/dim 3.6382(3.6429) | Xent 0.5136(0.5638) | Loss 3.8950(3.9248) | Error 0.1711(0.1995) Steps 598(607.75) | Grad Norm 2.2581(4.2214) | Total Time 14.00(14.00)\n",
      "Iter 5960 | Time 14.6910(14.7787) | Bit/dim 3.6495(3.6416) | Xent 0.4791(0.5540) | Loss 3.8891(3.9186) | Error 0.1667(0.1961) Steps 616(608.11) | Grad Norm 3.6155(4.0178) | Total Time 14.00(14.00)\n",
      "Iter 5970 | Time 14.3906(14.7714) | Bit/dim 3.6374(3.6393) | Xent 0.5978(0.5564) | Loss 3.9363(3.9175) | Error 0.2122(0.1974) Steps 604(608.54) | Grad Norm 3.2711(4.3345) | Total Time 14.00(14.00)\n",
      "Iter 5980 | Time 15.3397(14.8235) | Bit/dim 3.6733(3.6403) | Xent 0.5984(0.5573) | Loss 3.9725(3.9189) | Error 0.2022(0.1987) Steps 610(608.24) | Grad Norm 3.7865(4.1244) | Total Time 14.00(14.00)\n",
      "Iter 5990 | Time 14.6363(14.8768) | Bit/dim 3.6260(3.6412) | Xent 0.5134(0.5519) | Loss 3.8827(3.9172) | Error 0.1800(0.1973) Steps 604(610.18) | Grad Norm 4.3090(3.9859) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0109 | Time 81.5576, Epoch Time 917.2559(895.0577), Bit/dim 3.6417(best: 3.6366), Xent 0.7458, Loss 4.0146, Error 0.2552(best: 0.2376)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6000 | Time 15.2169(14.9387) | Bit/dim 3.6418(3.6406) | Xent 0.5519(0.5610) | Loss 3.9178(3.9211) | Error 0.2078(0.2007) Steps 610(610.53) | Grad Norm 4.7695(4.3126) | Total Time 14.00(14.00)\n",
      "Iter 6010 | Time 14.4254(14.9140) | Bit/dim 3.6545(3.6383) | Xent 0.5465(0.5609) | Loss 3.9277(3.9187) | Error 0.2011(0.2004) Steps 604(609.80) | Grad Norm 4.1167(4.3375) | Total Time 14.00(14.00)\n",
      "Iter 6020 | Time 14.4977(14.9168) | Bit/dim 3.5997(3.6356) | Xent 0.5774(0.5592) | Loss 3.8884(3.9152) | Error 0.2089(0.1997) Steps 610(611.21) | Grad Norm 3.7375(4.1791) | Total Time 14.00(14.00)\n",
      "Iter 6030 | Time 14.7687(14.8834) | Bit/dim 3.6347(3.6359) | Xent 0.5937(0.5579) | Loss 3.9315(3.9149) | Error 0.2144(0.2004) Steps 610(611.10) | Grad Norm 3.6245(4.2787) | Total Time 14.00(14.00)\n",
      "Iter 6040 | Time 14.8308(14.8972) | Bit/dim 3.6298(3.6369) | Xent 0.5540(0.5600) | Loss 3.9067(3.9169) | Error 0.1767(0.2000) Steps 616(610.28) | Grad Norm 4.2509(4.2168) | Total Time 14.00(14.00)\n",
      "Iter 6050 | Time 14.9542(14.8837) | Bit/dim 3.6746(3.6404) | Xent 0.5703(0.5644) | Loss 3.9597(3.9226) | Error 0.2022(0.2021) Steps 610(609.92) | Grad Norm 3.1565(4.3279) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0110 | Time 84.7103, Epoch Time 921.4426(895.8492), Bit/dim 3.6448(best: 3.6366), Xent 0.7474, Loss 4.0185, Error 0.2503(best: 0.2376)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6060 | Time 14.5089(14.8511) | Bit/dim 3.6890(3.6408) | Xent 0.5809(0.5631) | Loss 3.9795(3.9224) | Error 0.2133(0.2019) Steps 610(609.85) | Grad Norm 4.7614(4.5581) | Total Time 14.00(14.00)\n",
      "Iter 6070 | Time 14.7230(14.8249) | Bit/dim 3.6446(3.6429) | Xent 0.5677(0.5600) | Loss 3.9285(3.9229) | Error 0.2011(0.2006) Steps 592(610.00) | Grad Norm 5.3922(4.5862) | Total Time 14.00(14.00)\n",
      "Iter 6080 | Time 15.0991(14.8792) | Bit/dim 3.6095(3.6403) | Xent 0.4974(0.5546) | Loss 3.8582(3.9175) | Error 0.1744(0.1985) Steps 616(609.96) | Grad Norm 3.1809(4.4092) | Total Time 14.00(14.00)\n",
      "Iter 6090 | Time 14.9416(14.8673) | Bit/dim 3.6387(3.6374) | Xent 0.5399(0.5490) | Loss 3.9086(3.9119) | Error 0.1800(0.1960) Steps 610(609.95) | Grad Norm 3.8618(4.1884) | Total Time 14.00(14.00)\n",
      "Iter 6100 | Time 14.6349(14.8634) | Bit/dim 3.6528(3.6366) | Xent 0.5336(0.5510) | Loss 3.9195(3.9121) | Error 0.1756(0.1970) Steps 610(610.15) | Grad Norm 2.8221(4.1466) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0111 | Time 82.8981, Epoch Time 917.9738(896.5130), Bit/dim 3.6390(best: 3.6366), Xent 0.6866, Loss 3.9823, Error 0.2359(best: 0.2376)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6110 | Time 14.5180(14.8342) | Bit/dim 3.6291(3.6375) | Xent 0.4987(0.5493) | Loss 3.8785(3.9122) | Error 0.1800(0.1965) Steps 604(610.12) | Grad Norm 3.0171(4.0754) | Total Time 14.00(14.00)\n",
      "Iter 6120 | Time 15.1885(14.8710) | Bit/dim 3.6282(3.6382) | Xent 0.5368(0.5454) | Loss 3.8966(3.9109) | Error 0.1856(0.1941) Steps 622(609.77) | Grad Norm 5.2848(4.0879) | Total Time 14.00(14.00)\n",
      "Iter 6130 | Time 14.4287(14.8704) | Bit/dim 3.6432(3.6375) | Xent 0.5651(0.5550) | Loss 3.9258(3.9150) | Error 0.2044(0.1976) Steps 604(609.05) | Grad Norm 5.6612(4.6893) | Total Time 14.00(14.00)\n",
      "Iter 6140 | Time 14.4959(14.8762) | Bit/dim 3.6299(3.6390) | Xent 0.4891(0.5516) | Loss 3.8745(3.9147) | Error 0.1667(0.1965) Steps 610(610.36) | Grad Norm 3.0923(4.6095) | Total Time 14.00(14.00)\n",
      "Iter 6150 | Time 14.7499(14.8836) | Bit/dim 3.6367(3.6376) | Xent 0.5397(0.5500) | Loss 3.9065(3.9127) | Error 0.1978(0.1966) Steps 616(610.41) | Grad Norm 5.7282(4.4181) | Total Time 14.00(14.00)\n",
      "Iter 6160 | Time 15.0160(14.8665) | Bit/dim 3.6640(3.6401) | Xent 0.5682(0.5544) | Loss 3.9481(3.9173) | Error 0.2111(0.1982) Steps 604(610.10) | Grad Norm 4.3321(4.3671) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0112 | Time 82.4166, Epoch Time 917.5972(897.1455), Bit/dim 3.6388(best: 3.6366), Xent 0.7004, Loss 3.9890, Error 0.2390(best: 0.2359)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6170 | Time 15.2516(14.9171) | Bit/dim 3.6383(3.6389) | Xent 0.5490(0.5469) | Loss 3.9128(3.9124) | Error 0.2000(0.1955) Steps 610(609.15) | Grad Norm 7.7636(4.2911) | Total Time 14.00(14.00)\n",
      "Iter 6180 | Time 15.2247(14.9316) | Bit/dim 3.6206(3.6370) | Xent 0.4695(0.5407) | Loss 3.8554(3.9073) | Error 0.1678(0.1924) Steps 610(610.93) | Grad Norm 2.1212(4.1027) | Total Time 14.00(14.00)\n",
      "Iter 6190 | Time 15.1943(14.8987) | Bit/dim 3.5871(3.6341) | Xent 0.5609(0.5337) | Loss 3.8675(3.9010) | Error 0.2122(0.1898) Steps 604(609.59) | Grad Norm 3.0891(3.8360) | Total Time 14.00(14.00)\n",
      "Iter 6200 | Time 14.5623(14.8517) | Bit/dim 3.6522(3.6365) | Xent 0.5376(0.5379) | Loss 3.9210(3.9054) | Error 0.1956(0.1918) Steps 610(609.87) | Grad Norm 3.0288(4.0376) | Total Time 14.00(14.00)\n",
      "Iter 6210 | Time 15.2238(14.8971) | Bit/dim 3.6354(3.6345) | Xent 0.5894(0.5451) | Loss 3.9301(3.9071) | Error 0.2133(0.1956) Steps 610(609.84) | Grad Norm 5.9090(4.0918) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0113 | Time 81.7216, Epoch Time 920.0132(897.8315), Bit/dim 3.6408(best: 3.6366), Xent 0.7106, Loss 3.9961, Error 0.2368(best: 0.2359)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6220 | Time 14.3874(14.8762) | Bit/dim 3.6120(3.6350) | Xent 0.5378(0.5437) | Loss 3.8808(3.9068) | Error 0.1889(0.1939) Steps 610(609.72) | Grad Norm 5.0315(4.1550) | Total Time 14.00(14.00)\n",
      "Iter 6230 | Time 14.4617(14.8717) | Bit/dim 3.6572(3.6358) | Xent 0.4723(0.5353) | Loss 3.8933(3.9035) | Error 0.1822(0.1918) Steps 616(609.99) | Grad Norm 5.0051(4.3078) | Total Time 14.00(14.00)\n",
      "Iter 6240 | Time 15.2770(14.9283) | Bit/dim 3.6565(3.6373) | Xent 0.5508(0.5328) | Loss 3.9319(3.9037) | Error 0.2089(0.1907) Steps 616(610.67) | Grad Norm 7.2621(4.2743) | Total Time 14.00(14.00)\n",
      "Iter 6250 | Time 14.6990(14.8760) | Bit/dim 3.6312(3.6358) | Xent 0.6237(0.5410) | Loss 3.9430(3.9063) | Error 0.2078(0.1943) Steps 616(610.73) | Grad Norm 4.5804(4.3133) | Total Time 14.00(14.00)\n",
      "Iter 6260 | Time 14.6314(14.8528) | Bit/dim 3.6371(3.6366) | Xent 0.5678(0.5434) | Loss 3.9210(3.9082) | Error 0.2122(0.1946) Steps 616(611.62) | Grad Norm 4.3440(4.4135) | Total Time 14.00(14.00)\n",
      "Iter 6270 | Time 14.9924(14.8298) | Bit/dim 3.6087(3.6372) | Xent 0.6548(0.5495) | Loss 3.9361(3.9120) | Error 0.2356(0.1969) Steps 616(611.42) | Grad Norm 8.1489(4.4500) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0114 | Time 84.2096, Epoch Time 918.1484(898.4410), Bit/dim 3.6399(best: 3.6366), Xent 0.6586, Loss 3.9692, Error 0.2269(best: 0.2359)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6280 | Time 14.3733(14.8137) | Bit/dim 3.6215(3.6392) | Xent 0.4882(0.5418) | Loss 3.8656(3.9101) | Error 0.1833(0.1934) Steps 604(611.76) | Grad Norm 2.7717(4.2557) | Total Time 14.00(14.00)\n",
      "Iter 6290 | Time 14.5564(14.8673) | Bit/dim 3.6174(3.6350) | Xent 0.5176(0.5382) | Loss 3.8762(3.9041) | Error 0.1756(0.1903) Steps 604(612.95) | Grad Norm 3.6530(4.0980) | Total Time 14.00(14.00)\n",
      "Iter 6300 | Time 14.4858(14.8541) | Bit/dim 3.6358(3.6363) | Xent 0.5139(0.5346) | Loss 3.8928(3.9036) | Error 0.1944(0.1913) Steps 610(612.18) | Grad Norm 2.6295(4.0624) | Total Time 14.00(14.00)\n",
      "Iter 6310 | Time 14.9047(14.8211) | Bit/dim 3.6506(3.6351) | Xent 0.5409(0.5321) | Loss 3.9211(3.9011) | Error 0.1900(0.1902) Steps 610(611.89) | Grad Norm 4.9554(3.9693) | Total Time 14.00(14.00)\n",
      "Iter 6320 | Time 15.0135(14.8124) | Bit/dim 3.6404(3.6333) | Xent 0.6328(0.5489) | Loss 3.9568(3.9078) | Error 0.2333(0.1955) Steps 610(611.12) | Grad Norm 5.2683(4.3298) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0115 | Time 81.7122, Epoch Time 915.7272(898.9596), Bit/dim 3.6560(best: 3.6366), Xent 0.7192, Loss 4.0155, Error 0.2496(best: 0.2269)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6330 | Time 14.8958(14.8362) | Bit/dim 3.6558(3.6373) | Xent 0.5401(0.5544) | Loss 3.9258(3.9145) | Error 0.1956(0.1976) Steps 628(612.11) | Grad Norm 6.3219(4.6792) | Total Time 14.00(14.00)\n",
      "Iter 6340 | Time 14.7171(14.8423) | Bit/dim 3.6466(3.6387) | Xent 0.5404(0.5498) | Loss 3.9168(3.9136) | Error 0.1933(0.1961) Steps 610(611.85) | Grad Norm 4.2051(4.4831) | Total Time 14.00(14.00)\n",
      "Iter 6350 | Time 15.1386(14.9057) | Bit/dim 3.6269(3.6380) | Xent 0.5474(0.5493) | Loss 3.9006(3.9127) | Error 0.1989(0.1962) Steps 610(612.75) | Grad Norm 5.1307(4.6505) | Total Time 14.00(14.00)\n",
      "Iter 6360 | Time 15.3423(14.9145) | Bit/dim 3.6451(3.6354) | Xent 0.5983(0.5488) | Loss 3.9443(3.9098) | Error 0.2167(0.1966) Steps 622(613.68) | Grad Norm 4.9044(4.3965) | Total Time 14.00(14.00)\n",
      "Iter 6370 | Time 14.7424(14.8835) | Bit/dim 3.6521(3.6354) | Xent 0.5453(0.5443) | Loss 3.9247(3.9076) | Error 0.1978(0.1951) Steps 622(613.03) | Grad Norm 3.8943(4.2742) | Total Time 14.00(14.00)\n",
      "Iter 6380 | Time 15.1675(14.9328) | Bit/dim 3.6197(3.6328) | Xent 0.5624(0.5400) | Loss 3.9009(3.9029) | Error 0.2033(0.1935) Steps 604(611.66) | Grad Norm 4.5730(4.1586) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0116 | Time 82.2901, Epoch Time 922.1523(899.6554), Bit/dim 3.6287(best: 3.6366), Xent 0.6616, Loss 3.9595, Error 0.2257(best: 0.2269)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6390 | Time 14.8799(14.9266) | Bit/dim 3.6319(3.6338) | Xent 0.5343(0.5323) | Loss 3.8991(3.8999) | Error 0.1900(0.1908) Steps 604(611.36) | Grad Norm 4.4430(4.0724) | Total Time 14.00(14.00)\n",
      "Iter 6400 | Time 15.2241(14.9485) | Bit/dim 3.6207(3.6329) | Xent 0.4986(0.5331) | Loss 3.8700(3.8995) | Error 0.1833(0.1917) Steps 610(611.22) | Grad Norm 3.8501(4.2009) | Total Time 14.00(14.00)\n",
      "Iter 6410 | Time 15.2115(14.9305) | Bit/dim 3.5937(3.6314) | Xent 0.5204(0.5303) | Loss 3.8539(3.8965) | Error 0.1900(0.1891) Steps 610(611.84) | Grad Norm 2.3825(3.8733) | Total Time 14.00(14.00)\n",
      "Iter 6420 | Time 14.7106(14.8986) | Bit/dim 3.6570(3.6304) | Xent 0.4417(0.5246) | Loss 3.8778(3.8927) | Error 0.1567(0.1873) Steps 616(611.14) | Grad Norm 3.0186(3.7414) | Total Time 14.00(14.00)\n",
      "Iter 6430 | Time 15.2613(14.9380) | Bit/dim 3.6178(3.6302) | Xent 0.5089(0.5210) | Loss 3.8722(3.8908) | Error 0.1756(0.1867) Steps 622(611.48) | Grad Norm 6.0187(3.8299) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0117 | Time 83.2183, Epoch Time 921.7453(900.3181), Bit/dim 3.6360(best: 3.6287), Xent 0.6904, Loss 3.9812, Error 0.2311(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6440 | Time 15.1673(14.9574) | Bit/dim 3.6558(3.6328) | Xent 0.4757(0.5183) | Loss 3.8936(3.8919) | Error 0.1533(0.1852) Steps 622(613.53) | Grad Norm 2.4293(3.9311) | Total Time 14.00(14.00)\n",
      "Iter 6450 | Time 15.2564(14.9866) | Bit/dim 3.6154(3.6306) | Xent 0.4776(0.5156) | Loss 3.8543(3.8884) | Error 0.1722(0.1844) Steps 604(612.85) | Grad Norm 2.8536(4.1147) | Total Time 14.00(14.00)\n",
      "Iter 6460 | Time 15.1337(14.9926) | Bit/dim 3.6136(3.6305) | Xent 0.5247(0.5166) | Loss 3.8759(3.8889) | Error 0.1911(0.1837) Steps 610(613.86) | Grad Norm 5.4095(4.1277) | Total Time 14.00(14.00)\n",
      "Iter 6470 | Time 14.7443(14.9695) | Bit/dim 3.6875(3.6310) | Xent 0.4721(0.5147) | Loss 3.9235(3.8884) | Error 0.1700(0.1831) Steps 616(615.10) | Grad Norm 5.1274(4.1473) | Total Time 14.00(14.00)\n",
      "Iter 6480 | Time 14.9771(15.0571) | Bit/dim 3.6168(3.6309) | Xent 0.5156(0.5154) | Loss 3.8746(3.8886) | Error 0.1900(0.1834) Steps 622(615.29) | Grad Norm 4.3948(4.1510) | Total Time 14.00(14.00)\n",
      "Iter 6490 | Time 14.9162(15.0366) | Bit/dim 3.6070(3.6302) | Xent 0.5181(0.5210) | Loss 3.8660(3.8907) | Error 0.1800(0.1845) Steps 610(614.85) | Grad Norm 4.4929(4.1173) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0118 | Time 85.0217, Epoch Time 931.4591(901.2523), Bit/dim 3.6306(best: 3.6287), Xent 0.7145, Loss 3.9879, Error 0.2411(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6500 | Time 14.7095(15.0841) | Bit/dim 3.6448(3.6281) | Xent 0.4701(0.5122) | Loss 3.8799(3.8842) | Error 0.1722(0.1823) Steps 604(615.26) | Grad Norm 2.5187(4.0294) | Total Time 14.00(14.00)\n",
      "Iter 6510 | Time 15.7072(15.1107) | Bit/dim 3.6136(3.6282) | Xent 0.5376(0.5106) | Loss 3.8823(3.8835) | Error 0.1833(0.1806) Steps 616(615.18) | Grad Norm 4.3610(3.8318) | Total Time 14.00(14.00)\n",
      "Iter 6520 | Time 14.4851(15.0563) | Bit/dim 3.6341(3.6284) | Xent 0.5554(0.5097) | Loss 3.9118(3.8833) | Error 0.1933(0.1798) Steps 610(614.45) | Grad Norm 5.2373(3.8040) | Total Time 14.00(14.00)\n",
      "Iter 6530 | Time 14.8289(15.0181) | Bit/dim 3.6208(3.6293) | Xent 0.5006(0.5127) | Loss 3.8711(3.8857) | Error 0.1811(0.1819) Steps 616(615.98) | Grad Norm 4.0101(3.9178) | Total Time 14.00(14.00)\n",
      "Iter 6540 | Time 14.3971(14.9873) | Bit/dim 3.6248(3.6282) | Xent 0.5129(0.5089) | Loss 3.8812(3.8826) | Error 0.1878(0.1798) Steps 604(614.91) | Grad Norm 3.0531(3.7868) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0119 | Time 82.0203, Epoch Time 925.3361(901.9748), Bit/dim 3.6282(best: 3.6287), Xent 0.6726, Loss 3.9645, Error 0.2301(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6550 | Time 15.0746(14.9681) | Bit/dim 3.6194(3.6275) | Xent 0.4892(0.5039) | Loss 3.8640(3.8794) | Error 0.1689(0.1785) Steps 628(615.59) | Grad Norm 4.6062(3.6977) | Total Time 14.00(14.00)\n",
      "Iter 6560 | Time 14.6266(14.9675) | Bit/dim 3.6155(3.6263) | Xent 0.5034(0.4993) | Loss 3.8672(3.8760) | Error 0.1856(0.1781) Steps 622(616.80) | Grad Norm 3.9426(3.6205) | Total Time 14.00(14.00)\n",
      "Iter 6570 | Time 15.0083(15.0243) | Bit/dim 3.6239(3.6278) | Xent 0.5225(0.4977) | Loss 3.8852(3.8767) | Error 0.1856(0.1775) Steps 610(616.87) | Grad Norm 5.0803(3.7539) | Total Time 14.00(14.00)\n",
      "Iter 6580 | Time 15.5818(15.0596) | Bit/dim 3.6439(3.6247) | Xent 0.4862(0.5086) | Loss 3.8871(3.8790) | Error 0.1678(0.1809) Steps 622(617.50) | Grad Norm 5.2958(3.9132) | Total Time 14.00(14.00)\n",
      "Iter 6590 | Time 14.6439(14.9972) | Bit/dim 3.6483(3.6270) | Xent 0.5456(0.5122) | Loss 3.9211(3.8831) | Error 0.1900(0.1812) Steps 616(617.13) | Grad Norm 4.5506(3.9345) | Total Time 14.00(14.00)\n",
      "Iter 6600 | Time 14.7870(14.9886) | Bit/dim 3.6332(3.6294) | Xent 0.5425(0.5167) | Loss 3.9045(3.8878) | Error 0.1933(0.1828) Steps 610(616.83) | Grad Norm 6.5774(4.2505) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0120 | Time 84.4645, Epoch Time 928.1883(902.7612), Bit/dim 3.6330(best: 3.6282), Xent 0.7200, Loss 3.9931, Error 0.2404(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6610 | Time 15.2931(14.9936) | Bit/dim 3.6045(3.6297) | Xent 0.4629(0.5192) | Loss 3.8359(3.8893) | Error 0.1633(0.1834) Steps 610(614.66) | Grad Norm 4.0293(4.2899) | Total Time 14.00(14.00)\n",
      "Iter 6620 | Time 15.3569(15.0020) | Bit/dim 3.6768(3.6303) | Xent 0.4508(0.5094) | Loss 3.9022(3.8850) | Error 0.1600(0.1808) Steps 628(616.16) | Grad Norm 4.1263(4.2224) | Total Time 14.00(14.00)\n",
      "Iter 6630 | Time 15.0033(14.9701) | Bit/dim 3.6274(3.6280) | Xent 0.4505(0.5102) | Loss 3.8526(3.8831) | Error 0.1644(0.1827) Steps 610(615.68) | Grad Norm 3.7655(4.2606) | Total Time 14.00(14.00)\n",
      "Iter 6640 | Time 14.6183(14.9657) | Bit/dim 3.6589(3.6295) | Xent 0.5243(0.5163) | Loss 3.9210(3.8877) | Error 0.1933(0.1846) Steps 622(615.51) | Grad Norm 4.6783(4.2474) | Total Time 14.00(14.00)\n",
      "Iter 6650 | Time 15.3047(14.9616) | Bit/dim 3.6406(3.6299) | Xent 0.5165(0.5126) | Loss 3.8988(3.8862) | Error 0.1844(0.1835) Steps 628(615.98) | Grad Norm 4.1548(4.2079) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0121 | Time 84.8040, Epoch Time 924.3525(903.4090), Bit/dim 3.6349(best: 3.6282), Xent 0.6815, Loss 3.9756, Error 0.2343(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6660 | Time 14.5011(14.9186) | Bit/dim 3.6688(3.6287) | Xent 0.5221(0.5127) | Loss 3.9299(3.8851) | Error 0.1822(0.1830) Steps 610(615.42) | Grad Norm 5.4766(4.3619) | Total Time 14.00(14.00)\n",
      "Iter 6670 | Time 14.7564(14.9456) | Bit/dim 3.6035(3.6299) | Xent 0.5242(0.5084) | Loss 3.8656(3.8841) | Error 0.1867(0.1811) Steps 628(615.93) | Grad Norm 3.3425(4.3052) | Total Time 14.00(14.00)\n",
      "Iter 6680 | Time 14.7708(14.9567) | Bit/dim 3.6194(3.6281) | Xent 0.5187(0.5057) | Loss 3.8788(3.8809) | Error 0.2033(0.1815) Steps 610(616.22) | Grad Norm 3.3542(4.1700) | Total Time 14.00(14.00)\n",
      "Iter 6690 | Time 15.4796(14.9898) | Bit/dim 3.6206(3.6269) | Xent 0.4693(0.5040) | Loss 3.8553(3.8789) | Error 0.1578(0.1806) Steps 616(616.31) | Grad Norm 3.0174(4.1010) | Total Time 14.00(14.00)\n",
      "Iter 6700 | Time 14.7622(15.0348) | Bit/dim 3.5993(3.6255) | Xent 0.4803(0.5090) | Loss 3.8395(3.8801) | Error 0.1644(0.1819) Steps 622(617.49) | Grad Norm 2.7026(4.0443) | Total Time 14.00(14.00)\n",
      "Iter 6710 | Time 14.9237(15.0005) | Bit/dim 3.6199(3.6264) | Xent 0.5684(0.5027) | Loss 3.9041(3.8778) | Error 0.1989(0.1800) Steps 610(617.53) | Grad Norm 6.2060(4.1016) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0122 | Time 86.1938, Epoch Time 929.6673(904.1967), Bit/dim 3.6274(best: 3.6282), Xent 0.6881, Loss 3.9714, Error 0.2325(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6720 | Time 14.9406(15.0475) | Bit/dim 3.6230(3.6247) | Xent 0.4535(0.4962) | Loss 3.8498(3.8728) | Error 0.1678(0.1784) Steps 622(617.96) | Grad Norm 3.3270(3.9077) | Total Time 14.00(14.00)\n",
      "Iter 6730 | Time 15.2365(15.0911) | Bit/dim 3.6466(3.6262) | Xent 0.4250(0.4893) | Loss 3.8591(3.8709) | Error 0.1589(0.1754) Steps 622(618.36) | Grad Norm 3.3777(3.7992) | Total Time 14.00(14.00)\n",
      "Iter 6740 | Time 14.9445(15.1346) | Bit/dim 3.6277(3.6277) | Xent 0.4385(0.4921) | Loss 3.8469(3.8738) | Error 0.1556(0.1752) Steps 622(619.14) | Grad Norm 2.5450(3.7831) | Total Time 14.00(14.00)\n",
      "Iter 6750 | Time 15.3470(15.1335) | Bit/dim 3.6180(3.6275) | Xent 0.4557(0.4893) | Loss 3.8459(3.8722) | Error 0.1600(0.1742) Steps 622(619.23) | Grad Norm 4.2949(3.7514) | Total Time 14.00(14.00)\n",
      "Iter 6760 | Time 15.8936(15.1334) | Bit/dim 3.5983(3.6254) | Xent 0.4811(0.4898) | Loss 3.8389(3.8703) | Error 0.1767(0.1733) Steps 628(619.49) | Grad Norm 3.8183(3.8031) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0123 | Time 83.6378, Epoch Time 934.5341(905.1068), Bit/dim 3.6244(best: 3.6274), Xent 0.7297, Loss 3.9893, Error 0.2453(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6770 | Time 15.0377(15.0784) | Bit/dim 3.6305(3.6254) | Xent 0.5224(0.4937) | Loss 3.8917(3.8722) | Error 0.1822(0.1753) Steps 628(618.80) | Grad Norm 7.7132(4.0662) | Total Time 14.00(14.00)\n",
      "Iter 6780 | Time 14.5789(14.9736) | Bit/dim 3.6129(3.6241) | Xent 0.4859(0.4902) | Loss 3.8558(3.8692) | Error 0.1689(0.1732) Steps 616(618.97) | Grad Norm 4.6246(4.0661) | Total Time 14.00(14.00)\n",
      "Iter 6790 | Time 15.3984(14.9764) | Bit/dim 3.6311(3.6221) | Xent 0.4843(0.4906) | Loss 3.8733(3.8673) | Error 0.1667(0.1737) Steps 616(619.39) | Grad Norm 3.3912(4.0080) | Total Time 14.00(14.00)\n",
      "Iter 6800 | Time 14.6196(14.9662) | Bit/dim 3.6099(3.6223) | Xent 0.5151(0.4923) | Loss 3.8674(3.8685) | Error 0.1867(0.1745) Steps 628(619.97) | Grad Norm 3.5127(4.1140) | Total Time 14.00(14.00)\n",
      "Iter 6810 | Time 15.6282(14.9793) | Bit/dim 3.6444(3.6250) | Xent 0.5245(0.4991) | Loss 3.9067(3.8746) | Error 0.1856(0.1765) Steps 616(619.86) | Grad Norm 3.8765(4.0701) | Total Time 14.00(14.00)\n",
      "Iter 6820 | Time 14.7072(14.9370) | Bit/dim 3.6211(3.6261) | Xent 0.4860(0.5040) | Loss 3.8641(3.8781) | Error 0.1656(0.1785) Steps 616(619.35) | Grad Norm 4.7204(4.1785) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0124 | Time 84.9207, Epoch Time 922.2651(905.6216), Bit/dim 3.6205(best: 3.6244), Xent 0.6885, Loss 3.9647, Error 0.2336(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6830 | Time 14.7300(14.9528) | Bit/dim 3.6120(3.6236) | Xent 0.5169(0.4961) | Loss 3.8705(3.8716) | Error 0.1789(0.1761) Steps 616(619.56) | Grad Norm 3.8724(4.0837) | Total Time 14.00(14.00)\n",
      "Iter 6840 | Time 14.8205(14.9385) | Bit/dim 3.6390(3.6249) | Xent 0.4687(0.4941) | Loss 3.8733(3.8720) | Error 0.1722(0.1755) Steps 616(620.02) | Grad Norm 6.8420(4.0087) | Total Time 14.00(14.00)\n",
      "Iter 6850 | Time 14.6887(14.9646) | Bit/dim 3.6249(3.6242) | Xent 0.6007(0.5016) | Loss 3.9253(3.8751) | Error 0.2089(0.1776) Steps 616(620.05) | Grad Norm 6.6176(4.2686) | Total Time 14.00(14.00)\n",
      "Iter 6860 | Time 14.7522(14.9250) | Bit/dim 3.6236(3.6238) | Xent 0.5011(0.5042) | Loss 3.8742(3.8759) | Error 0.1744(0.1775) Steps 622(619.15) | Grad Norm 3.8470(4.2280) | Total Time 14.00(14.00)\n",
      "Iter 6870 | Time 14.9017(14.9640) | Bit/dim 3.6478(3.6264) | Xent 0.5400(0.5045) | Loss 3.9178(3.8786) | Error 0.1967(0.1795) Steps 616(620.04) | Grad Norm 5.0983(4.1577) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0125 | Time 86.3025, Epoch Time 928.8016(906.3170), Bit/dim 3.6297(best: 3.6205), Xent 0.7255, Loss 3.9925, Error 0.2456(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6880 | Time 15.5407(15.0317) | Bit/dim 3.6774(3.6285) | Xent 0.5054(0.5102) | Loss 3.9301(3.8835) | Error 0.1722(0.1810) Steps 622(619.01) | Grad Norm 6.7778(4.5592) | Total Time 14.00(14.00)\n",
      "Iter 6890 | Time 15.5630(15.0320) | Bit/dim 3.6259(3.6286) | Xent 0.5957(0.5151) | Loss 3.9237(3.8861) | Error 0.2089(0.1834) Steps 610(618.35) | Grad Norm 6.0047(4.6643) | Total Time 14.00(14.00)\n",
      "Iter 6900 | Time 14.6996(15.0299) | Bit/dim 3.6561(3.6276) | Xent 0.5145(0.5120) | Loss 3.9133(3.8836) | Error 0.1900(0.1829) Steps 616(618.02) | Grad Norm 4.2384(4.5494) | Total Time 14.00(14.00)\n",
      "Iter 6910 | Time 14.9762(15.0558) | Bit/dim 3.6457(3.6302) | Xent 0.5261(0.5035) | Loss 3.9087(3.8819) | Error 0.1811(0.1798) Steps 616(617.95) | Grad Norm 2.9426(4.3412) | Total Time 14.00(14.00)\n",
      "Iter 6920 | Time 15.0586(15.0478) | Bit/dim 3.6177(3.6305) | Xent 0.5300(0.5040) | Loss 3.8827(3.8825) | Error 0.1889(0.1798) Steps 610(618.13) | Grad Norm 2.7629(4.2410) | Total Time 14.00(14.00)\n",
      "Iter 6930 | Time 15.0980(15.0851) | Bit/dim 3.6408(3.6278) | Xent 0.5075(0.5058) | Loss 3.8945(3.8807) | Error 0.1722(0.1799) Steps 622(618.09) | Grad Norm 5.3238(4.3439) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0126 | Time 85.7179, Epoch Time 933.4818(907.1319), Bit/dim 3.6333(best: 3.6205), Xent 0.6800, Loss 3.9734, Error 0.2300(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6940 | Time 15.2708(15.0862) | Bit/dim 3.6044(3.6253) | Xent 0.5214(0.5036) | Loss 3.8651(3.8771) | Error 0.1656(0.1788) Steps 610(617.98) | Grad Norm 4.8391(4.2986) | Total Time 14.00(14.00)\n",
      "Iter 6950 | Time 15.4537(15.1346) | Bit/dim 3.6330(3.6251) | Xent 0.3981(0.4904) | Loss 3.8320(3.8704) | Error 0.1400(0.1736) Steps 622(617.96) | Grad Norm 2.2289(3.8697) | Total Time 14.00(14.00)\n",
      "Iter 6960 | Time 14.6220(15.1325) | Bit/dim 3.6245(3.6214) | Xent 0.4851(0.4808) | Loss 3.8671(3.8618) | Error 0.1756(0.1707) Steps 616(617.89) | Grad Norm 2.4282(3.6220) | Total Time 14.00(14.00)\n",
      "Iter 6970 | Time 15.6942(15.1670) | Bit/dim 3.6438(3.6226) | Xent 0.4396(0.4782) | Loss 3.8636(3.8617) | Error 0.1578(0.1693) Steps 622(618.65) | Grad Norm 2.7812(3.6342) | Total Time 14.00(14.00)\n",
      "Iter 6980 | Time 15.3967(15.1408) | Bit/dim 3.6115(3.6230) | Xent 0.4726(0.4731) | Loss 3.8478(3.8595) | Error 0.1611(0.1675) Steps 622(619.24) | Grad Norm 2.7756(3.6672) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0127 | Time 86.0894, Epoch Time 936.7923(908.0218), Bit/dim 3.6257(best: 3.6205), Xent 0.6856, Loss 3.9685, Error 0.2311(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 6990 | Time 15.6697(15.1376) | Bit/dim 3.5919(3.6200) | Xent 0.4576(0.4764) | Loss 3.8207(3.8582) | Error 0.1711(0.1693) Steps 634(620.24) | Grad Norm 3.5041(3.6495) | Total Time 14.00(14.00)\n",
      "Iter 7000 | Time 15.2262(15.1093) | Bit/dim 3.6173(3.6201) | Xent 0.5109(0.4815) | Loss 3.8727(3.8609) | Error 0.1822(0.1708) Steps 616(620.66) | Grad Norm 3.5929(3.8979) | Total Time 14.00(14.00)\n",
      "Iter 7010 | Time 15.1229(15.1096) | Bit/dim 3.6295(3.6235) | Xent 0.5157(0.4813) | Loss 3.8874(3.8642) | Error 0.1722(0.1709) Steps 616(620.34) | Grad Norm 3.8624(3.9410) | Total Time 14.00(14.00)\n",
      "Iter 7020 | Time 15.3153(15.1359) | Bit/dim 3.6061(3.6227) | Xent 0.4700(0.4798) | Loss 3.8411(3.8627) | Error 0.1700(0.1702) Steps 616(620.92) | Grad Norm 2.6250(3.8301) | Total Time 14.00(14.00)\n",
      "Iter 7030 | Time 15.0692(15.1205) | Bit/dim 3.6336(3.6227) | Xent 0.4709(0.4757) | Loss 3.8691(3.8606) | Error 0.1611(0.1695) Steps 622(621.37) | Grad Norm 2.4762(3.5960) | Total Time 14.00(14.00)\n",
      "Iter 7040 | Time 14.7453(15.1205) | Bit/dim 3.6167(3.6239) | Xent 0.4778(0.4743) | Loss 3.8556(3.8611) | Error 0.1811(0.1692) Steps 616(621.50) | Grad Norm 5.3737(3.6761) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0128 | Time 86.1022, Epoch Time 935.8364(908.8562), Bit/dim 3.6223(best: 3.6205), Xent 0.6623, Loss 3.9534, Error 0.2249(best: 0.2257)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7050 | Time 15.1812(15.0945) | Bit/dim 3.6112(3.6219) | Xent 0.4572(0.4740) | Loss 3.8398(3.8589) | Error 0.1611(0.1685) Steps 616(620.63) | Grad Norm 3.7173(3.8071) | Total Time 14.00(14.00)\n",
      "Iter 7060 | Time 15.0337(15.1030) | Bit/dim 3.6446(3.6252) | Xent 0.4841(0.4846) | Loss 3.8867(3.8675) | Error 0.1811(0.1711) Steps 616(619.87) | Grad Norm 3.6793(4.1148) | Total Time 14.00(14.00)\n",
      "Iter 7070 | Time 14.7339(15.0466) | Bit/dim 3.6486(3.6272) | Xent 0.5036(0.4871) | Loss 3.9004(3.8708) | Error 0.1800(0.1722) Steps 622(620.72) | Grad Norm 3.9398(4.0158) | Total Time 14.00(14.00)\n",
      "Iter 7080 | Time 14.6148(15.0250) | Bit/dim 3.6070(3.6248) | Xent 0.4914(0.4917) | Loss 3.8527(3.8707) | Error 0.1900(0.1743) Steps 616(620.78) | Grad Norm 4.5834(4.2405) | Total Time 14.00(14.00)\n",
      "Iter 7090 | Time 14.6666(15.0615) | Bit/dim 3.6404(3.6256) | Xent 0.4484(0.4951) | Loss 3.8647(3.8732) | Error 0.1578(0.1761) Steps 622(621.61) | Grad Norm 4.5112(4.3048) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0129 | Time 85.8846, Epoch Time 929.5548(909.4771), Bit/dim 3.6258(best: 3.6205), Xent 0.6711, Loss 3.9613, Error 0.2271(best: 0.2249)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7100 | Time 14.7832(15.0081) | Bit/dim 3.6306(3.6244) | Xent 0.4285(0.4875) | Loss 3.8448(3.8681) | Error 0.1667(0.1739) Steps 622(621.41) | Grad Norm 2.3348(4.1404) | Total Time 14.00(14.00)\n",
      "Iter 7110 | Time 15.5766(15.0522) | Bit/dim 3.6214(3.6258) | Xent 0.4650(0.4829) | Loss 3.8540(3.8672) | Error 0.1800(0.1723) Steps 622(621.91) | Grad Norm 2.9490(4.1206) | Total Time 14.00(14.00)\n",
      "Iter 7120 | Time 14.7335(15.0811) | Bit/dim 3.6092(3.6254) | Xent 0.5121(0.4820) | Loss 3.8653(3.8664) | Error 0.1800(0.1718) Steps 622(622.39) | Grad Norm 5.7730(4.2272) | Total Time 14.00(14.00)\n",
      "Iter 7130 | Time 15.4994(15.1050) | Bit/dim 3.6210(3.6222) | Xent 0.5040(0.4797) | Loss 3.8730(3.8621) | Error 0.1756(0.1711) Steps 634(622.81) | Grad Norm 4.6007(4.2541) | Total Time 14.00(14.00)\n",
      "Iter 7140 | Time 15.1767(15.1604) | Bit/dim 3.6197(3.6232) | Xent 0.4923(0.4815) | Loss 3.8659(3.8639) | Error 0.1778(0.1714) Steps 622(623.82) | Grad Norm 3.6337(4.3216) | Total Time 14.00(14.00)\n",
      "Iter 7150 | Time 15.5580(15.1997) | Bit/dim 3.6111(3.6246) | Xent 0.4491(0.4820) | Loss 3.8356(3.8656) | Error 0.1611(0.1711) Steps 622(623.77) | Grad Norm 4.6492(4.0576) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0130 | Time 85.6961, Epoch Time 939.4228(910.3755), Bit/dim 3.6247(best: 3.6205), Xent 0.6736, Loss 3.9615, Error 0.2190(best: 0.2249)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7160 | Time 14.7858(15.1930) | Bit/dim 3.6375(3.6221) | Xent 0.4489(0.4719) | Loss 3.8620(3.8580) | Error 0.1578(0.1683) Steps 616(622.95) | Grad Norm 2.7185(3.7515) | Total Time 14.00(14.00)\n",
      "Iter 7170 | Time 14.6150(15.1887) | Bit/dim 3.6211(3.6211) | Xent 0.5211(0.4665) | Loss 3.8816(3.8543) | Error 0.1778(0.1658) Steps 616(622.80) | Grad Norm 6.8231(3.7882) | Total Time 14.00(14.00)\n",
      "Iter 7180 | Time 15.5868(15.1595) | Bit/dim 3.6405(3.6219) | Xent 0.4066(0.4723) | Loss 3.8438(3.8581) | Error 0.1433(0.1686) Steps 628(623.25) | Grad Norm 1.8088(3.8141) | Total Time 14.00(14.00)\n",
      "Iter 7190 | Time 15.6527(15.2347) | Bit/dim 3.6574(3.6245) | Xent 0.4638(0.4776) | Loss 3.8893(3.8633) | Error 0.1656(0.1702) Steps 628(623.73) | Grad Norm 2.9064(3.8004) | Total Time 14.00(14.00)\n",
      "Iter 7200 | Time 15.4956(15.2708) | Bit/dim 3.6422(3.6240) | Xent 0.4216(0.4790) | Loss 3.8530(3.8635) | Error 0.1578(0.1704) Steps 634(624.09) | Grad Norm 3.0660(3.9332) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0131 | Time 85.8093, Epoch Time 942.4636(911.3382), Bit/dim 3.6296(best: 3.6205), Xent 0.6990, Loss 3.9791, Error 0.2271(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7210 | Time 15.9255(15.2807) | Bit/dim 3.5947(3.6217) | Xent 0.4936(0.4772) | Loss 3.8415(3.8602) | Error 0.1700(0.1690) Steps 622(624.29) | Grad Norm 2.6913(3.8969) | Total Time 14.00(14.00)\n",
      "Iter 7220 | Time 16.0971(15.3352) | Bit/dim 3.6277(3.6206) | Xent 0.5432(0.4764) | Loss 3.8993(3.8588) | Error 0.1944(0.1681) Steps 628(625.16) | Grad Norm 5.8184(4.0120) | Total Time 14.00(14.00)\n",
      "Iter 7230 | Time 15.8202(15.3433) | Bit/dim 3.6289(3.6200) | Xent 0.4412(0.4705) | Loss 3.8494(3.8553) | Error 0.1611(0.1664) Steps 622(625.26) | Grad Norm 3.7336(4.0553) | Total Time 14.00(14.00)\n",
      "Iter 7240 | Time 15.6541(15.3636) | Bit/dim 3.6407(3.6219) | Xent 0.4739(0.4736) | Loss 3.8776(3.8587) | Error 0.1689(0.1683) Steps 622(625.90) | Grad Norm 3.7391(4.1148) | Total Time 14.00(14.00)\n",
      "Iter 7250 | Time 15.7750(15.3876) | Bit/dim 3.6107(3.6248) | Xent 0.4740(0.4723) | Loss 3.8477(3.8610) | Error 0.1622(0.1670) Steps 634(626.16) | Grad Norm 3.2780(4.2128) | Total Time 14.00(14.00)\n",
      "Iter 7260 | Time 15.6220(15.3834) | Bit/dim 3.5947(3.6241) | Xent 0.4535(0.4775) | Loss 3.8215(3.8628) | Error 0.1700(0.1693) Steps 634(626.66) | Grad Norm 3.5307(4.1690) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0132 | Time 86.4599, Epoch Time 952.4683(912.5721), Bit/dim 3.6333(best: 3.6205), Xent 0.7073, Loss 3.9869, Error 0.2322(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7270 | Time 15.0999(15.3846) | Bit/dim 3.5901(3.6224) | Xent 0.4817(0.4723) | Loss 3.8309(3.8585) | Error 0.1711(0.1679) Steps 628(627.28) | Grad Norm 3.5148(4.0885) | Total Time 14.00(14.00)\n",
      "Iter 7280 | Time 15.5901(15.3979) | Bit/dim 3.6411(3.6213) | Xent 0.4471(0.4653) | Loss 3.8647(3.8540) | Error 0.1644(0.1653) Steps 634(626.81) | Grad Norm 2.2240(3.9838) | Total Time 14.00(14.00)\n",
      "Iter 7290 | Time 15.7029(15.4314) | Bit/dim 3.6038(3.6215) | Xent 0.4324(0.4605) | Loss 3.8200(3.8518) | Error 0.1489(0.1637) Steps 628(627.30) | Grad Norm 3.1971(3.8797) | Total Time 14.00(14.00)\n",
      "Iter 7300 | Time 14.9375(15.3839) | Bit/dim 3.6134(3.6186) | Xent 0.4607(0.4590) | Loss 3.8437(3.8481) | Error 0.1756(0.1639) Steps 628(626.71) | Grad Norm 5.7878(3.9476) | Total Time 14.00(14.00)\n",
      "Iter 7310 | Time 14.9801(15.3618) | Bit/dim 3.6530(3.6210) | Xent 0.4551(0.4582) | Loss 3.8805(3.8501) | Error 0.1600(0.1633) Steps 628(627.00) | Grad Norm 3.7882(3.9249) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0133 | Time 86.4868, Epoch Time 951.4172(913.7374), Bit/dim 3.6262(best: 3.6205), Xent 0.6864, Loss 3.9694, Error 0.2265(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7320 | Time 15.0567(15.3988) | Bit/dim 3.6346(3.6223) | Xent 0.5296(0.4637) | Loss 3.8994(3.8541) | Error 0.1978(0.1650) Steps 622(627.24) | Grad Norm 6.1404(4.1216) | Total Time 14.00(14.00)\n",
      "Iter 7330 | Time 15.4670(15.4440) | Bit/dim 3.6199(3.6195) | Xent 0.4132(0.4643) | Loss 3.8265(3.8517) | Error 0.1411(0.1647) Steps 628(627.74) | Grad Norm 5.1166(4.0786) | Total Time 14.00(14.00)\n",
      "Iter 7340 | Time 16.0991(15.4943) | Bit/dim 3.6500(3.6221) | Xent 0.4997(0.4621) | Loss 3.8998(3.8531) | Error 0.1722(0.1639) Steps 634(627.84) | Grad Norm 4.3109(3.9478) | Total Time 14.00(14.00)\n",
      "Iter 7350 | Time 15.9763(15.5382) | Bit/dim 3.5964(3.6211) | Xent 0.4712(0.4619) | Loss 3.8320(3.8520) | Error 0.1767(0.1654) Steps 634(627.91) | Grad Norm 4.3775(3.8991) | Total Time 14.00(14.00)\n",
      "Iter 7360 | Time 15.6910(15.5476) | Bit/dim 3.5850(3.6226) | Xent 0.4796(0.4634) | Loss 3.8248(3.8543) | Error 0.1678(0.1661) Steps 628(626.79) | Grad Norm 2.6774(3.7753) | Total Time 14.00(14.00)\n",
      "Iter 7370 | Time 15.2564(15.5595) | Bit/dim 3.5935(3.6182) | Xent 0.4220(0.4619) | Loss 3.8045(3.8491) | Error 0.1600(0.1672) Steps 628(626.85) | Grad Norm 2.7957(3.8097) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0134 | Time 85.7144, Epoch Time 961.0548(915.1569), Bit/dim 3.6262(best: 3.6205), Xent 0.7002, Loss 3.9763, Error 0.2361(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7380 | Time 15.6405(15.5312) | Bit/dim 3.6190(3.6168) | Xent 0.4904(0.4555) | Loss 3.8642(3.8446) | Error 0.1667(0.1636) Steps 634(627.49) | Grad Norm 7.4405(3.9802) | Total Time 14.00(14.00)\n",
      "Iter 7390 | Time 15.7969(15.4977) | Bit/dim 3.6149(3.6167) | Xent 0.4773(0.4637) | Loss 3.8535(3.8486) | Error 0.1589(0.1655) Steps 634(627.82) | Grad Norm 3.4069(4.3205) | Total Time 14.00(14.00)\n",
      "Iter 7400 | Time 14.9386(15.4800) | Bit/dim 3.6022(3.6190) | Xent 0.4695(0.4576) | Loss 3.8369(3.8478) | Error 0.1833(0.1643) Steps 634(628.34) | Grad Norm 4.5665(4.2692) | Total Time 14.00(14.00)\n",
      "Iter 7410 | Time 15.7935(15.4684) | Bit/dim 3.5887(3.6189) | Xent 0.4375(0.4552) | Loss 3.8074(3.8465) | Error 0.1544(0.1628) Steps 634(627.49) | Grad Norm 4.5851(4.1264) | Total Time 14.00(14.00)\n",
      "Iter 7420 | Time 15.2884(15.4754) | Bit/dim 3.6322(3.6207) | Xent 0.4131(0.4584) | Loss 3.8387(3.8498) | Error 0.1356(0.1636) Steps 628(628.12) | Grad Norm 4.4587(4.2302) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0135 | Time 86.9721, Epoch Time 955.1070(916.3554), Bit/dim 3.6216(best: 3.6205), Xent 0.6905, Loss 3.9669, Error 0.2295(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7430 | Time 15.9348(15.4690) | Bit/dim 3.5998(3.6220) | Xent 0.3850(0.4555) | Loss 3.7923(3.8497) | Error 0.1444(0.1628) Steps 628(627.73) | Grad Norm 3.2719(4.1196) | Total Time 14.00(14.00)\n",
      "Iter 7440 | Time 15.7901(15.5032) | Bit/dim 3.6463(3.6227) | Xent 0.3930(0.4540) | Loss 3.8429(3.8498) | Error 0.1444(0.1617) Steps 628(627.95) | Grad Norm 3.3995(3.9958) | Total Time 14.00(14.00)\n",
      "Iter 7450 | Time 15.8482(15.5159) | Bit/dim 3.6168(3.6220) | Xent 0.4796(0.4511) | Loss 3.8566(3.8475) | Error 0.1800(0.1605) Steps 622(627.92) | Grad Norm 4.1124(3.8915) | Total Time 14.00(14.00)\n",
      "Iter 7460 | Time 15.0607(15.4943) | Bit/dim 3.6359(3.6218) | Xent 0.4614(0.4512) | Loss 3.8666(3.8474) | Error 0.1656(0.1612) Steps 628(627.78) | Grad Norm 4.1901(4.1069) | Total Time 14.00(14.00)\n",
      "Iter 7470 | Time 15.5188(15.4996) | Bit/dim 3.6065(3.6198) | Xent 0.4296(0.4560) | Loss 3.8213(3.8478) | Error 0.1600(0.1626) Steps 634(628.50) | Grad Norm 3.4139(4.3060) | Total Time 14.00(14.00)\n",
      "Iter 7480 | Time 16.2980(15.5131) | Bit/dim 3.6232(3.6174) | Xent 0.4452(0.4616) | Loss 3.8458(3.8482) | Error 0.1611(0.1643) Steps 628(628.35) | Grad Norm 3.9463(4.4270) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0136 | Time 86.8291, Epoch Time 957.4954(917.5896), Bit/dim 3.6153(best: 3.6205), Xent 0.6862, Loss 3.9584, Error 0.2258(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7490 | Time 15.0724(15.5375) | Bit/dim 3.6229(3.6165) | Xent 0.4340(0.4574) | Loss 3.8399(3.8452) | Error 0.1433(0.1624) Steps 628(628.40) | Grad Norm 4.4700(4.3328) | Total Time 14.00(14.00)\n",
      "Iter 7500 | Time 15.8421(15.5466) | Bit/dim 3.6223(3.6165) | Xent 0.4507(0.4558) | Loss 3.8477(3.8444) | Error 0.1578(0.1617) Steps 634(628.50) | Grad Norm 3.5905(4.1913) | Total Time 14.00(14.00)\n",
      "Iter 7510 | Time 15.2254(15.5359) | Bit/dim 3.6395(3.6145) | Xent 0.4020(0.4488) | Loss 3.8404(3.8389) | Error 0.1422(0.1585) Steps 628(628.96) | Grad Norm 2.2624(3.9537) | Total Time 14.00(14.00)\n",
      "Iter 7520 | Time 15.6379(15.6059) | Bit/dim 3.6605(3.6133) | Xent 0.4377(0.4441) | Loss 3.8793(3.8353) | Error 0.1567(0.1564) Steps 628(629.02) | Grad Norm 2.4462(3.7329) | Total Time 14.00(14.00)\n",
      "Iter 7530 | Time 15.9976(15.6303) | Bit/dim 3.6446(3.6140) | Xent 0.4402(0.4449) | Loss 3.8647(3.8365) | Error 0.1656(0.1581) Steps 640(629.73) | Grad Norm 3.1806(3.7910) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0137 | Time 86.3850, Epoch Time 962.2168(918.9285), Bit/dim 3.6165(best: 3.6153), Xent 0.7169, Loss 3.9749, Error 0.2325(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7540 | Time 15.7337(15.5734) | Bit/dim 3.6238(3.6136) | Xent 0.4285(0.4438) | Loss 3.8380(3.8355) | Error 0.1422(0.1571) Steps 634(629.81) | Grad Norm 3.1478(3.7303) | Total Time 14.00(14.00)\n",
      "Iter 7550 | Time 15.2934(15.5465) | Bit/dim 3.6092(3.6141) | Xent 0.4207(0.4360) | Loss 3.8195(3.8321) | Error 0.1511(0.1543) Steps 628(629.78) | Grad Norm 2.6727(3.5152) | Total Time 14.00(14.00)\n",
      "Iter 7560 | Time 15.9714(15.5551) | Bit/dim 3.6328(3.6133) | Xent 0.4056(0.4288) | Loss 3.8357(3.8277) | Error 0.1300(0.1513) Steps 634(630.25) | Grad Norm 2.2562(3.3267) | Total Time 14.00(14.00)\n",
      "Iter 7570 | Time 15.2997(15.5958) | Bit/dim 3.6193(3.6162) | Xent 0.4625(0.4390) | Loss 3.8506(3.8356) | Error 0.1711(0.1560) Steps 628(630.12) | Grad Norm 4.3553(3.6754) | Total Time 14.00(14.00)\n",
      "Iter 7580 | Time 15.3114(15.5842) | Bit/dim 3.6104(3.6162) | Xent 0.4769(0.4554) | Loss 3.8489(3.8439) | Error 0.1756(0.1614) Steps 622(629.13) | Grad Norm 4.0866(4.0168) | Total Time 14.00(14.00)\n",
      "Iter 7590 | Time 15.3494(15.5587) | Bit/dim 3.5991(3.6144) | Xent 0.4692(0.4610) | Loss 3.8337(3.8449) | Error 0.1689(0.1636) Steps 628(629.64) | Grad Norm 5.4021(4.1969) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0138 | Time 85.5895, Epoch Time 959.2499(920.1381), Bit/dim 3.6290(best: 3.6153), Xent 0.7216, Loss 3.9899, Error 0.2367(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7600 | Time 15.5940(15.5953) | Bit/dim 3.6039(3.6139) | Xent 0.4444(0.4540) | Loss 3.8261(3.8410) | Error 0.1556(0.1611) Steps 628(629.52) | Grad Norm 3.4267(4.0052) | Total Time 14.00(14.00)\n",
      "Iter 7610 | Time 15.9397(15.6312) | Bit/dim 3.5912(3.6123) | Xent 0.4673(0.4464) | Loss 3.8249(3.8355) | Error 0.1633(0.1576) Steps 628(630.06) | Grad Norm 4.7468(3.9313) | Total Time 14.00(14.00)\n",
      "Iter 7620 | Time 14.9841(15.6245) | Bit/dim 3.6388(3.6135) | Xent 0.3897(0.4443) | Loss 3.8336(3.8357) | Error 0.1333(0.1564) Steps 628(630.15) | Grad Norm 3.1169(4.0237) | Total Time 14.00(14.00)\n",
      "Iter 7630 | Time 15.6513(15.5972) | Bit/dim 3.6131(3.6159) | Xent 0.4774(0.4408) | Loss 3.8518(3.8362) | Error 0.1744(0.1562) Steps 628(629.75) | Grad Norm 2.8206(3.8813) | Total Time 14.00(14.00)\n",
      "Iter 7640 | Time 15.2610(15.5750) | Bit/dim 3.6140(3.6160) | Xent 0.3986(0.4364) | Loss 3.8132(3.8342) | Error 0.1300(0.1548) Steps 628(629.55) | Grad Norm 4.0554(3.7205) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0139 | Time 85.9975, Epoch Time 961.8817(921.3904), Bit/dim 3.6169(best: 3.6153), Xent 0.7120, Loss 3.9729, Error 0.2391(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7650 | Time 15.6164(15.5498) | Bit/dim 3.5960(3.6152) | Xent 0.3943(0.4363) | Loss 3.7931(3.8333) | Error 0.1467(0.1566) Steps 634(629.79) | Grad Norm 2.7774(3.7677) | Total Time 14.00(14.00)\n",
      "Iter 7660 | Time 15.4000(15.5463) | Bit/dim 3.6096(3.6152) | Xent 0.3569(0.4319) | Loss 3.7881(3.8312) | Error 0.1300(0.1557) Steps 628(630.42) | Grad Norm 2.8002(3.8239) | Total Time 14.00(14.00)\n",
      "Iter 7670 | Time 15.2500(15.5542) | Bit/dim 3.6392(3.6169) | Xent 0.4385(0.4289) | Loss 3.8585(3.8314) | Error 0.1489(0.1539) Steps 628(630.86) | Grad Norm 3.5504(3.5839) | Total Time 14.00(14.00)\n",
      "Iter 7680 | Time 15.8579(15.5668) | Bit/dim 3.6145(3.6139) | Xent 0.3692(0.4269) | Loss 3.7991(3.8273) | Error 0.1400(0.1527) Steps 628(630.55) | Grad Norm 3.2257(3.5440) | Total Time 14.00(14.00)\n",
      "Iter 7690 | Time 16.0833(15.6499) | Bit/dim 3.6111(3.6137) | Xent 0.4437(0.4265) | Loss 3.8329(3.8270) | Error 0.1556(0.1521) Steps 628(632.48) | Grad Norm 4.9527(3.4896) | Total Time 14.00(14.00)\n",
      "Iter 7700 | Time 15.7569(15.6793) | Bit/dim 3.6567(3.6131) | Xent 0.4191(0.4359) | Loss 3.8662(3.8311) | Error 0.1500(0.1545) Steps 640(632.00) | Grad Norm 5.6070(3.8653) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0140 | Time 86.6545, Epoch Time 965.9891(922.7284), Bit/dim 3.6138(best: 3.6153), Xent 0.6808, Loss 3.9542, Error 0.2280(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7710 | Time 15.3983(15.6470) | Bit/dim 3.6117(3.6134) | Xent 0.4257(0.4331) | Loss 3.8245(3.8300) | Error 0.1600(0.1539) Steps 628(630.80) | Grad Norm 3.2099(3.8281) | Total Time 14.00(14.00)\n",
      "Iter 7720 | Time 16.8119(15.6552) | Bit/dim 3.6008(3.6114) | Xent 0.4086(0.4277) | Loss 3.8051(3.8252) | Error 0.1578(0.1535) Steps 634(630.90) | Grad Norm 4.4885(3.8151) | Total Time 14.00(14.00)\n",
      "Iter 7730 | Time 15.0032(15.6489) | Bit/dim 3.5821(3.6126) | Xent 0.4520(0.4293) | Loss 3.8081(3.8273) | Error 0.1689(0.1540) Steps 628(630.92) | Grad Norm 6.2963(3.8434) | Total Time 14.00(14.00)\n",
      "Iter 7740 | Time 15.6897(15.6244) | Bit/dim 3.6077(3.6119) | Xent 0.4241(0.4306) | Loss 3.8198(3.8271) | Error 0.1578(0.1544) Steps 634(630.65) | Grad Norm 3.5485(3.8752) | Total Time 14.00(14.00)\n",
      "Iter 7750 | Time 16.1899(15.6222) | Bit/dim 3.6090(3.6147) | Xent 0.3999(0.4329) | Loss 3.8089(3.8311) | Error 0.1411(0.1548) Steps 628(630.75) | Grad Norm 3.3939(4.0230) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0141 | Time 86.9890, Epoch Time 964.3221(923.9762), Bit/dim 3.6190(best: 3.6138), Xent 0.6609, Loss 3.9494, Error 0.2204(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7760 | Time 15.9799(15.6263) | Bit/dim 3.5952(3.6147) | Xent 0.4326(0.4255) | Loss 3.8115(3.8275) | Error 0.1622(0.1523) Steps 628(631.24) | Grad Norm 3.3750(3.7507) | Total Time 14.00(14.00)\n",
      "Iter 7770 | Time 15.2241(15.6244) | Bit/dim 3.5912(3.6143) | Xent 0.3788(0.4151) | Loss 3.7806(3.8219) | Error 0.1344(0.1490) Steps 628(630.70) | Grad Norm 3.9192(3.5650) | Total Time 14.00(14.00)\n",
      "Iter 7780 | Time 15.7167(15.6494) | Bit/dim 3.6471(3.6131) | Xent 0.4189(0.4129) | Loss 3.8565(3.8196) | Error 0.1578(0.1481) Steps 634(630.39) | Grad Norm 5.0519(3.6182) | Total Time 14.00(14.00)\n",
      "Iter 7790 | Time 15.8755(15.6503) | Bit/dim 3.5909(3.6125) | Xent 0.4815(0.4271) | Loss 3.8317(3.8261) | Error 0.1633(0.1516) Steps 634(630.92) | Grad Norm 4.3986(4.1380) | Total Time 14.00(14.00)\n",
      "Iter 7800 | Time 15.6400(15.6680) | Bit/dim 3.6060(3.6136) | Xent 0.4134(0.4334) | Loss 3.8127(3.8302) | Error 0.1444(0.1540) Steps 628(631.55) | Grad Norm 3.0495(4.2356) | Total Time 14.00(14.00)\n",
      "Iter 7810 | Time 15.8862(15.6878) | Bit/dim 3.6055(3.6125) | Xent 0.4447(0.4333) | Loss 3.8279(3.8292) | Error 0.1600(0.1550) Steps 628(631.60) | Grad Norm 3.8406(4.1634) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0142 | Time 86.8233, Epoch Time 965.8921(925.2337), Bit/dim 3.6224(best: 3.6138), Xent 0.6672, Loss 3.9559, Error 0.2177(best: 0.2190)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7820 | Time 15.6905(15.7218) | Bit/dim 3.6306(3.6146) | Xent 0.4129(0.4321) | Loss 3.8370(3.8307) | Error 0.1467(0.1549) Steps 622(632.14) | Grad Norm 3.3355(4.1501) | Total Time 14.00(14.00)\n",
      "Iter 7830 | Time 15.4601(15.7132) | Bit/dim 3.6331(3.6127) | Xent 0.4746(0.4365) | Loss 3.8704(3.8309) | Error 0.1700(0.1552) Steps 628(633.41) | Grad Norm 4.4662(4.2704) | Total Time 14.00(14.00)\n",
      "Iter 7840 | Time 15.2572(15.7305) | Bit/dim 3.6463(3.6136) | Xent 0.3773(0.4381) | Loss 3.8350(3.8326) | Error 0.1256(0.1555) Steps 628(633.79) | Grad Norm 3.6314(4.2418) | Total Time 14.00(14.00)\n",
      "Iter 7850 | Time 15.3818(15.7275) | Bit/dim 3.5964(3.6157) | Xent 0.4332(0.4337) | Loss 3.8130(3.8326) | Error 0.1700(0.1551) Steps 634(633.59) | Grad Norm 3.0159(4.1308) | Total Time 14.00(14.00)\n",
      "Iter 7860 | Time 14.8386(15.7086) | Bit/dim 3.6258(3.6162) | Xent 0.4424(0.4284) | Loss 3.8470(3.8304) | Error 0.1589(0.1529) Steps 628(634.11) | Grad Norm 3.1976(4.1243) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0143 | Time 85.5494, Epoch Time 967.8283(926.5115), Bit/dim 3.6231(best: 3.6138), Xent 0.7202, Loss 3.9832, Error 0.2357(best: 0.2177)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7870 | Time 16.3143(15.6828) | Bit/dim 3.6376(3.6165) | Xent 0.3604(0.4265) | Loss 3.8178(3.8297) | Error 0.1200(0.1513) Steps 640(634.66) | Grad Norm 2.8930(4.2075) | Total Time 14.00(14.00)\n",
      "Iter 7880 | Time 15.6763(15.7262) | Bit/dim 3.6142(3.6142) | Xent 0.4762(0.4276) | Loss 3.8523(3.8280) | Error 0.1778(0.1517) Steps 634(634.98) | Grad Norm 4.3428(4.1841) | Total Time 14.00(14.00)\n",
      "Iter 7890 | Time 16.0038(15.7648) | Bit/dim 3.6010(3.6158) | Xent 0.5517(0.4364) | Loss 3.8768(3.8340) | Error 0.1822(0.1535) Steps 640(635.80) | Grad Norm 7.1723(4.3898) | Total Time 14.00(14.00)\n",
      "Iter 7900 | Time 15.6446(15.7958) | Bit/dim 3.6080(3.6157) | Xent 0.5530(0.4585) | Loss 3.8845(3.8449) | Error 0.1911(0.1612) Steps 646(637.12) | Grad Norm 6.7242(4.7518) | Total Time 14.00(14.00)\n",
      "Iter 7910 | Time 15.8736(15.8086) | Bit/dim 3.6170(3.6165) | Xent 0.4477(0.4558) | Loss 3.8408(3.8444) | Error 0.1556(0.1603) Steps 640(637.47) | Grad Norm 4.2451(4.5671) | Total Time 14.00(14.00)\n",
      "Iter 7920 | Time 15.7169(15.8066) | Bit/dim 3.5926(3.6149) | Xent 0.4115(0.4460) | Loss 3.7983(3.8379) | Error 0.1544(0.1572) Steps 640(638.11) | Grad Norm 2.2834(4.2171) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0144 | Time 86.2118, Epoch Time 974.9168(927.9637), Bit/dim 3.6163(best: 3.6138), Xent 0.6626, Loss 3.9477, Error 0.2175(best: 0.2177)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7930 | Time 16.2307(15.9168) | Bit/dim 3.5986(3.6134) | Xent 0.3897(0.4356) | Loss 3.7935(3.8312) | Error 0.1478(0.1524) Steps 646(639.23) | Grad Norm 4.4246(4.0713) | Total Time 14.00(14.00)\n",
      "Iter 7940 | Time 15.3573(15.9039) | Bit/dim 3.5989(3.6106) | Xent 0.4153(0.4380) | Loss 3.8066(3.8296) | Error 0.1522(0.1541) Steps 634(638.53) | Grad Norm 4.3040(4.3638) | Total Time 14.00(14.00)\n",
      "Iter 7950 | Time 16.0172(15.9015) | Bit/dim 3.5932(3.6117) | Xent 0.3764(0.4328) | Loss 3.7814(3.8281) | Error 0.1267(0.1529) Steps 640(638.28) | Grad Norm 2.3710(4.1686) | Total Time 14.00(14.00)\n",
      "Iter 7960 | Time 15.5558(15.9238) | Bit/dim 3.5935(3.6103) | Xent 0.3948(0.4219) | Loss 3.7910(3.8212) | Error 0.1322(0.1491) Steps 640(639.29) | Grad Norm 3.6260(4.0186) | Total Time 14.00(14.00)\n",
      "Iter 7970 | Time 16.8921(15.9953) | Bit/dim 3.6139(3.6100) | Xent 0.3918(0.4199) | Loss 3.8098(3.8200) | Error 0.1278(0.1484) Steps 652(641.04) | Grad Norm 3.0793(4.0263) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0145 | Time 86.7996, Epoch Time 987.4120(929.7471), Bit/dim 3.6135(best: 3.6138), Xent 0.6777, Loss 3.9523, Error 0.2211(best: 0.2175)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 7980 | Time 16.6333(16.0208) | Bit/dim 3.6095(3.6130) | Xent 0.3789(0.4131) | Loss 3.7990(3.8195) | Error 0.1322(0.1465) Steps 652(641.87) | Grad Norm 5.1805(3.8100) | Total Time 14.00(14.00)\n",
      "Iter 7990 | Time 15.7764(15.9765) | Bit/dim 3.6060(3.6127) | Xent 0.3979(0.4030) | Loss 3.8050(3.8142) | Error 0.1444(0.1429) Steps 658(642.43) | Grad Norm 3.1624(3.6217) | Total Time 14.00(14.00)\n",
      "Iter 8000 | Time 16.0199(15.9589) | Bit/dim 3.6235(3.6109) | Xent 0.4116(0.4011) | Loss 3.8293(3.8115) | Error 0.1578(0.1425) Steps 640(641.83) | Grad Norm 3.0757(3.5415) | Total Time 14.00(14.00)\n",
      "Iter 8010 | Time 16.3782(16.0546) | Bit/dim 3.6296(3.6103) | Xent 0.4321(0.4184) | Loss 3.8456(3.8195) | Error 0.1622(0.1484) Steps 640(642.16) | Grad Norm 4.7279(3.9736) | Total Time 14.00(14.00)\n",
      "Iter 8020 | Time 15.9031(16.0769) | Bit/dim 3.6015(3.6111) | Xent 0.4586(0.4223) | Loss 3.8308(3.8222) | Error 0.1689(0.1500) Steps 640(643.20) | Grad Norm 4.9043(4.0156) | Total Time 14.00(14.00)\n",
      "Iter 8030 | Time 16.7234(16.0943) | Bit/dim 3.6412(3.6138) | Xent 0.5335(0.4296) | Loss 3.9080(3.8286) | Error 0.1978(0.1532) Steps 634(643.63) | Grad Norm 6.1102(4.1303) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0146 | Time 86.2349, Epoch Time 987.6564(931.4844), Bit/dim 3.6122(best: 3.6135), Xent 0.6652, Loss 3.9448, Error 0.2192(best: 0.2175)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8040 | Time 15.6545(16.1052) | Bit/dim 3.6304(3.6153) | Xent 0.4255(0.4221) | Loss 3.8431(3.8263) | Error 0.1544(0.1494) Steps 640(643.79) | Grad Norm 4.2694(3.8884) | Total Time 14.00(14.00)\n",
      "Iter 8050 | Time 16.3481(16.1116) | Bit/dim 3.5840(3.6134) | Xent 0.4133(0.4159) | Loss 3.7907(3.8214) | Error 0.1367(0.1480) Steps 658(644.03) | Grad Norm 3.6452(3.9976) | Total Time 14.00(14.00)\n",
      "Iter 8060 | Time 16.1252(16.1365) | Bit/dim 3.6178(3.6119) | Xent 0.4306(0.4138) | Loss 3.8331(3.8188) | Error 0.1633(0.1479) Steps 652(644.87) | Grad Norm 3.1264(3.8281) | Total Time 14.00(14.00)\n",
      "Iter 8070 | Time 16.9936(16.0810) | Bit/dim 3.6375(3.6132) | Xent 0.3754(0.4083) | Loss 3.8252(3.8174) | Error 0.1367(0.1451) Steps 652(645.12) | Grad Norm 3.7680(3.6282) | Total Time 14.00(14.00)\n",
      "Iter 8080 | Time 16.8590(16.1780) | Bit/dim 3.5910(3.6091) | Xent 0.3998(0.4107) | Loss 3.7909(3.8145) | Error 0.1411(0.1460) Steps 670(646.71) | Grad Norm 2.7027(3.5751) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0147 | Time 86.7923, Epoch Time 995.1469(933.3943), Bit/dim 3.6097(best: 3.6122), Xent 0.6999, Loss 3.9597, Error 0.2237(best: 0.2175)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8090 | Time 15.8596(16.2215) | Bit/dim 3.6000(3.6065) | Xent 0.3589(0.4052) | Loss 3.7794(3.8091) | Error 0.1211(0.1436) Steps 646(649.30) | Grad Norm 3.0617(3.4868) | Total Time 14.00(14.00)\n",
      "Iter 8100 | Time 16.8604(16.3215) | Bit/dim 3.5692(3.6043) | Xent 0.4210(0.4045) | Loss 3.7797(3.8065) | Error 0.1511(0.1434) Steps 646(650.66) | Grad Norm 3.2168(3.6974) | Total Time 14.00(14.00)\n",
      "Iter 8110 | Time 16.8772(16.3119) | Bit/dim 3.6223(3.6089) | Xent 0.4106(0.4142) | Loss 3.8276(3.8159) | Error 0.1389(0.1468) Steps 652(650.26) | Grad Norm 4.2224(4.0410) | Total Time 14.00(14.00)\n",
      "Iter 8120 | Time 16.1982(16.3410) | Bit/dim 3.6131(3.6098) | Xent 0.4272(0.4263) | Loss 3.8267(3.8230) | Error 0.1522(0.1515) Steps 658(652.53) | Grad Norm 3.6245(4.2371) | Total Time 14.00(14.00)\n",
      "Iter 8130 | Time 16.5517(16.3517) | Bit/dim 3.6246(3.6123) | Xent 0.4121(0.4232) | Loss 3.8307(3.8240) | Error 0.1500(0.1501) Steps 646(651.62) | Grad Norm 3.2118(3.9886) | Total Time 14.00(14.00)\n",
      "Iter 8140 | Time 16.7188(16.3978) | Bit/dim 3.6288(3.6117) | Xent 0.4176(0.4271) | Loss 3.8376(3.8252) | Error 0.1644(0.1533) Steps 658(652.84) | Grad Norm 2.9835(3.8857) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0148 | Time 87.1550, Epoch Time 1009.3219(935.6721), Bit/dim 3.6144(best: 3.6097), Xent 0.6753, Loss 3.9520, Error 0.2188(best: 0.2175)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8150 | Time 16.8898(16.4356) | Bit/dim 3.6438(3.6130) | Xent 0.3947(0.4153) | Loss 3.8411(3.8206) | Error 0.1444(0.1486) Steps 658(654.14) | Grad Norm 3.8319(3.6907) | Total Time 14.00(14.00)\n",
      "Iter 8160 | Time 16.8827(16.4509) | Bit/dim 3.6095(3.6119) | Xent 0.4131(0.4113) | Loss 3.8161(3.8176) | Error 0.1578(0.1477) Steps 682(655.05) | Grad Norm 5.4162(3.9147) | Total Time 14.00(14.00)\n",
      "Iter 8170 | Time 17.8208(16.5380) | Bit/dim 3.6271(3.6140) | Xent 0.3591(0.4084) | Loss 3.8067(3.8181) | Error 0.1278(0.1454) Steps 652(658.86) | Grad Norm 3.1850(3.7271) | Total Time 14.00(14.00)\n",
      "Iter 8180 | Time 16.6057(16.5126) | Bit/dim 3.5733(3.6110) | Xent 0.4131(0.4072) | Loss 3.7798(3.8146) | Error 0.1478(0.1454) Steps 682(658.61) | Grad Norm 3.1589(3.5635) | Total Time 14.00(14.00)\n",
      "Iter 8190 | Time 16.0706(16.4672) | Bit/dim 3.5923(3.6075) | Xent 0.4724(0.4095) | Loss 3.8285(3.8123) | Error 0.1689(0.1464) Steps 676(660.07) | Grad Norm 6.0595(3.6299) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0149 | Time 85.1481, Epoch Time 1010.0990(937.9049), Bit/dim 3.6123(best: 3.6097), Xent 0.6634, Loss 3.9439, Error 0.2166(best: 0.2175)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8200 | Time 17.4415(16.4653) | Bit/dim 3.6290(3.6087) | Xent 0.3960(0.4052) | Loss 3.8271(3.8113) | Error 0.1322(0.1458) Steps 670(658.48) | Grad Norm 3.7508(3.6603) | Total Time 14.00(14.00)\n",
      "Iter 8210 | Time 17.2956(16.5465) | Bit/dim 3.5999(3.6095) | Xent 0.4342(0.4123) | Loss 3.8170(3.8156) | Error 0.1567(0.1475) Steps 670(661.46) | Grad Norm 5.0004(4.0778) | Total Time 14.00(14.00)\n",
      "Iter 8220 | Time 16.6151(16.5846) | Bit/dim 3.5791(3.6094) | Xent 0.4127(0.4082) | Loss 3.7855(3.8135) | Error 0.1489(0.1458) Steps 640(662.43) | Grad Norm 3.5068(3.7818) | Total Time 14.00(14.00)\n",
      "Iter 8230 | Time 17.1576(16.6172) | Bit/dim 3.6091(3.6078) | Xent 0.4087(0.4011) | Loss 3.8135(3.8084) | Error 0.1389(0.1431) Steps 676(664.97) | Grad Norm 4.8640(3.8388) | Total Time 14.00(14.00)\n",
      "Iter 8240 | Time 16.1328(16.6037) | Bit/dim 3.5743(3.6070) | Xent 0.4391(0.4049) | Loss 3.7938(3.8095) | Error 0.1467(0.1439) Steps 670(661.32) | Grad Norm 4.5111(3.9337) | Total Time 14.00(14.00)\n",
      "Iter 8250 | Time 15.8399(16.6126) | Bit/dim 3.6135(3.6072) | Xent 0.5080(0.4121) | Loss 3.8675(3.8133) | Error 0.1744(0.1467) Steps 670(663.89) | Grad Norm 4.9896(3.8470) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0150 | Time 86.3665, Epoch Time 1021.2290(940.4046), Bit/dim 3.6064(best: 3.6097), Xent 0.6775, Loss 3.9451, Error 0.2270(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8260 | Time 17.2991(16.6246) | Bit/dim 3.6089(3.6081) | Xent 0.4184(0.4076) | Loss 3.8181(3.8119) | Error 0.1478(0.1450) Steps 676(663.69) | Grad Norm 4.2286(3.8551) | Total Time 14.00(14.00)\n",
      "Iter 8270 | Time 16.9733(16.6448) | Bit/dim 3.6212(3.6085) | Xent 0.3710(0.4040) | Loss 3.8067(3.8104) | Error 0.1300(0.1431) Steps 664(665.64) | Grad Norm 3.5149(3.8134) | Total Time 14.00(14.00)\n",
      "Iter 8280 | Time 16.8868(16.5957) | Bit/dim 3.5999(3.6080) | Xent 0.4347(0.3987) | Loss 3.8173(3.8073) | Error 0.1522(0.1414) Steps 676(664.44) | Grad Norm 5.7806(3.8774) | Total Time 14.00(14.00)\n",
      "Iter 8290 | Time 16.1496(16.5690) | Bit/dim 3.6273(3.6080) | Xent 0.4160(0.4005) | Loss 3.8353(3.8083) | Error 0.1422(0.1421) Steps 670(666.67) | Grad Norm 5.3732(3.9313) | Total Time 14.00(14.00)\n",
      "Iter 8300 | Time 16.6312(16.6246) | Bit/dim 3.6109(3.6078) | Xent 0.3255(0.4015) | Loss 3.7737(3.8086) | Error 0.1144(0.1430) Steps 670(667.77) | Grad Norm 3.5171(3.8910) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0151 | Time 85.9461, Epoch Time 1016.0385(942.6736), Bit/dim 3.6109(best: 3.6064), Xent 0.7046, Loss 3.9632, Error 0.2216(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8310 | Time 16.3521(16.5386) | Bit/dim 3.6155(3.6090) | Xent 0.3655(0.3946) | Loss 3.7982(3.8063) | Error 0.1300(0.1401) Steps 652(666.14) | Grad Norm 2.3111(3.7569) | Total Time 14.00(14.00)\n",
      "Iter 8320 | Time 17.0070(16.6416) | Bit/dim 3.5739(3.6066) | Xent 0.3683(0.3957) | Loss 3.7580(3.8044) | Error 0.1200(0.1399) Steps 646(666.28) | Grad Norm 4.0356(3.8266) | Total Time 14.00(14.00)\n",
      "Iter 8330 | Time 16.3929(16.6329) | Bit/dim 3.6077(3.6063) | Xent 0.3922(0.3942) | Loss 3.8038(3.8034) | Error 0.1356(0.1393) Steps 652(666.38) | Grad Norm 4.5251(3.8211) | Total Time 14.00(14.00)\n",
      "Iter 8340 | Time 17.3135(16.6259) | Bit/dim 3.6357(3.6090) | Xent 0.4434(0.4077) | Loss 3.8574(3.8129) | Error 0.1667(0.1437) Steps 670(666.47) | Grad Norm 4.0705(4.0477) | Total Time 14.00(14.00)\n",
      "Iter 8350 | Time 17.0382(16.6627) | Bit/dim 3.5945(3.6102) | Xent 0.4590(0.4064) | Loss 3.8240(3.8134) | Error 0.1567(0.1438) Steps 682(667.33) | Grad Norm 4.9687(3.8949) | Total Time 14.00(14.00)\n",
      "Iter 8360 | Time 16.4298(16.6863) | Bit/dim 3.6105(3.6097) | Xent 0.4214(0.4090) | Loss 3.8212(3.8142) | Error 0.1556(0.1454) Steps 634(665.96) | Grad Norm 3.6724(3.8957) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0152 | Time 85.6147, Epoch Time 1021.1034(945.0265), Bit/dim 3.6117(best: 3.6064), Xent 0.6961, Loss 3.9597, Error 0.2292(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8370 | Time 17.2209(16.6760) | Bit/dim 3.5681(3.6094) | Xent 0.4235(0.4028) | Loss 3.7798(3.8108) | Error 0.1500(0.1422) Steps 682(667.60) | Grad Norm 5.8609(4.0052) | Total Time 14.00(14.00)\n",
      "Iter 8380 | Time 16.2346(16.6320) | Bit/dim 3.6023(3.6059) | Xent 0.4279(0.4005) | Loss 3.8163(3.8061) | Error 0.1400(0.1424) Steps 682(666.91) | Grad Norm 4.1929(4.1229) | Total Time 14.00(14.00)\n",
      "Iter 8390 | Time 16.7695(16.6982) | Bit/dim 3.6080(3.6094) | Xent 0.4456(0.4035) | Loss 3.8309(3.8112) | Error 0.1778(0.1441) Steps 670(668.84) | Grad Norm 4.9366(4.2201) | Total Time 14.00(14.00)\n",
      "Iter 8400 | Time 15.1205(16.6239) | Bit/dim 3.6197(3.6087) | Xent 0.3624(0.4038) | Loss 3.8009(3.8106) | Error 0.1278(0.1434) Steps 640(664.99) | Grad Norm 2.3454(4.0897) | Total Time 14.00(14.00)\n",
      "Iter 8410 | Time 17.5139(16.6259) | Bit/dim 3.6064(3.6128) | Xent 0.4174(0.4010) | Loss 3.8151(3.8133) | Error 0.1411(0.1429) Steps 682(664.69) | Grad Norm 3.4495(4.3119) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0153 | Time 85.5721, Epoch Time 1016.0082(947.1560), Bit/dim 3.6037(best: 3.6064), Xent 0.6850, Loss 3.9462, Error 0.2262(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8420 | Time 16.7742(16.6004) | Bit/dim 3.5907(3.6097) | Xent 0.3966(0.4016) | Loss 3.7890(3.8105) | Error 0.1322(0.1430) Steps 670(666.00) | Grad Norm 2.6907(3.9415) | Total Time 14.00(14.00)\n",
      "Iter 8430 | Time 16.3783(16.5541) | Bit/dim 3.6006(3.6109) | Xent 0.3716(0.3947) | Loss 3.7864(3.8082) | Error 0.1233(0.1394) Steps 670(666.99) | Grad Norm 4.0480(3.7254) | Total Time 14.00(14.00)\n",
      "Iter 8440 | Time 17.1029(16.6447) | Bit/dim 3.6409(3.6090) | Xent 0.3192(0.3873) | Loss 3.8005(3.8027) | Error 0.1178(0.1379) Steps 682(666.11) | Grad Norm 2.3793(3.5188) | Total Time 14.00(14.00)\n",
      "Iter 8450 | Time 17.4505(16.6800) | Bit/dim 3.6107(3.6053) | Xent 0.4182(0.3809) | Loss 3.8198(3.7958) | Error 0.1433(0.1361) Steps 670(668.52) | Grad Norm 4.6428(3.3965) | Total Time 14.00(14.00)\n",
      "Iter 8460 | Time 17.0473(16.6741) | Bit/dim 3.6439(3.6061) | Xent 0.3535(0.3832) | Loss 3.8207(3.7977) | Error 0.1211(0.1364) Steps 670(668.53) | Grad Norm 3.3030(3.5426) | Total Time 14.00(14.00)\n",
      "Iter 8470 | Time 16.9049(16.7085) | Bit/dim 3.6320(3.6063) | Xent 0.3837(0.3836) | Loss 3.8239(3.7981) | Error 0.1244(0.1362) Steps 658(669.92) | Grad Norm 4.1233(3.5765) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0154 | Time 85.2547, Epoch Time 1022.2235(949.4080), Bit/dim 3.6123(best: 3.6037), Xent 0.6925, Loss 3.9586, Error 0.2179(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8480 | Time 17.1935(16.7571) | Bit/dim 3.5840(3.6041) | Xent 0.3617(0.3769) | Loss 3.7648(3.7926) | Error 0.1289(0.1331) Steps 688(668.22) | Grad Norm 2.7239(3.4914) | Total Time 14.00(14.00)\n",
      "Iter 8490 | Time 16.0851(16.6973) | Bit/dim 3.6386(3.6036) | Xent 0.3704(0.3806) | Loss 3.8238(3.7939) | Error 0.1356(0.1342) Steps 646(667.86) | Grad Norm 5.7476(3.7874) | Total Time 14.00(14.00)\n",
      "Iter 8500 | Time 16.9837(16.7380) | Bit/dim 3.5867(3.6037) | Xent 0.4137(0.3942) | Loss 3.7936(3.8008) | Error 0.1433(0.1394) Steps 682(669.78) | Grad Norm 5.1023(4.1767) | Total Time 14.00(14.00)\n",
      "Iter 8510 | Time 17.1649(16.8213) | Bit/dim 3.6463(3.6066) | Xent 0.4194(0.3942) | Loss 3.8560(3.8037) | Error 0.1511(0.1403) Steps 664(670.70) | Grad Norm 4.5945(4.0520) | Total Time 14.00(14.00)\n",
      "Iter 8520 | Time 16.5796(16.7977) | Bit/dim 3.6224(3.6073) | Xent 0.3885(0.3942) | Loss 3.8166(3.8044) | Error 0.1344(0.1399) Steps 646(668.90) | Grad Norm 4.5333(4.0370) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0155 | Time 85.6039, Epoch Time 1029.4568(951.8095), Bit/dim 3.6180(best: 3.6037), Xent 0.7527, Loss 3.9943, Error 0.2350(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8530 | Time 16.4541(16.7902) | Bit/dim 3.5904(3.6067) | Xent 0.3269(0.3954) | Loss 3.7538(3.8044) | Error 0.1167(0.1403) Steps 646(668.59) | Grad Norm 4.1034(4.0433) | Total Time 14.00(14.00)\n",
      "Iter 8540 | Time 17.5081(16.9144) | Bit/dim 3.6151(3.6084) | Xent 0.3376(0.3934) | Loss 3.7839(3.8051) | Error 0.1078(0.1398) Steps 682(671.15) | Grad Norm 2.6621(3.9078) | Total Time 14.00(14.00)\n",
      "Iter 8550 | Time 17.2842(17.0396) | Bit/dim 3.5773(3.6060) | Xent 0.3845(0.3930) | Loss 3.7696(3.8025) | Error 0.1389(0.1391) Steps 670(672.57) | Grad Norm 2.5249(3.8102) | Total Time 14.00(14.00)\n",
      "Iter 8560 | Time 17.5585(17.1511) | Bit/dim 3.5507(3.6073) | Xent 0.3850(0.3923) | Loss 3.7432(3.8034) | Error 0.1356(0.1393) Steps 706(675.33) | Grad Norm 4.5400(3.9089) | Total Time 14.00(14.00)\n",
      "Iter 8570 | Time 17.3784(17.1858) | Bit/dim 3.5996(3.6046) | Xent 0.3567(0.3855) | Loss 3.7780(3.7974) | Error 0.1333(0.1374) Steps 700(676.94) | Grad Norm 2.0029(3.6248) | Total Time 14.00(14.00)\n",
      "Iter 8580 | Time 16.9017(17.1965) | Bit/dim 3.6282(3.6060) | Xent 0.3962(0.3815) | Loss 3.8263(3.7967) | Error 0.1378(0.1359) Steps 652(676.61) | Grad Norm 4.5287(3.5352) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0156 | Time 85.9748, Epoch Time 1052.5495(954.8317), Bit/dim 3.6152(best: 3.6037), Xent 0.6970, Loss 3.9637, Error 0.2202(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8590 | Time 17.6231(17.3199) | Bit/dim 3.6150(3.6043) | Xent 0.3594(0.3823) | Loss 3.7947(3.7954) | Error 0.1367(0.1367) Steps 688(680.42) | Grad Norm 3.4077(3.6449) | Total Time 14.00(14.00)\n",
      "Iter 8600 | Time 17.2782(17.3568) | Bit/dim 3.5806(3.6037) | Xent 0.4163(0.3833) | Loss 3.7888(3.7954) | Error 0.1411(0.1383) Steps 694(681.18) | Grad Norm 4.0516(3.8565) | Total Time 14.00(14.00)\n",
      "Iter 8610 | Time 17.3532(17.3064) | Bit/dim 3.5724(3.6050) | Xent 0.3306(0.3811) | Loss 3.7377(3.7955) | Error 0.1144(0.1359) Steps 682(679.99) | Grad Norm 4.7345(3.9188) | Total Time 14.00(14.00)\n",
      "Iter 8620 | Time 17.8790(17.3662) | Bit/dim 3.6173(3.6032) | Xent 0.4016(0.3858) | Loss 3.8181(3.7961) | Error 0.1444(0.1376) Steps 676(680.11) | Grad Norm 3.4865(3.8227) | Total Time 14.00(14.00)\n",
      "Iter 8630 | Time 17.6052(17.3405) | Bit/dim 3.6258(3.6055) | Xent 0.3894(0.3822) | Loss 3.8205(3.7966) | Error 0.1411(0.1365) Steps 694(678.90) | Grad Norm 2.9393(3.6341) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0157 | Time 85.4091, Epoch Time 1060.4116(957.9991), Bit/dim 3.6046(best: 3.6037), Xent 0.7673, Loss 3.9882, Error 0.2385(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8640 | Time 17.3499(17.3194) | Bit/dim 3.6290(3.6062) | Xent 0.3971(0.3863) | Loss 3.8276(3.7994) | Error 0.1200(0.1372) Steps 676(680.44) | Grad Norm 3.4789(3.9507) | Total Time 14.00(14.00)\n",
      "Iter 8650 | Time 17.2449(17.3082) | Bit/dim 3.5801(3.6049) | Xent 0.3509(0.3848) | Loss 3.7556(3.7973) | Error 0.1200(0.1368) Steps 664(678.53) | Grad Norm 2.5913(3.9734) | Total Time 14.00(14.00)\n",
      "Iter 8660 | Time 16.9911(17.2996) | Bit/dim 3.5963(3.6075) | Xent 0.3694(0.3794) | Loss 3.7810(3.7972) | Error 0.1289(0.1349) Steps 688(680.09) | Grad Norm 4.6568(3.9569) | Total Time 14.00(14.00)\n",
      "Iter 8670 | Time 17.3545(17.3065) | Bit/dim 3.6339(3.6043) | Xent 0.4023(0.3837) | Loss 3.8351(3.7961) | Error 0.1411(0.1362) Steps 670(680.60) | Grad Norm 4.2026(4.1681) | Total Time 14.00(14.00)\n",
      "Iter 8680 | Time 17.1220(17.3177) | Bit/dim 3.6051(3.6025) | Xent 0.3661(0.3855) | Loss 3.7882(3.7953) | Error 0.1244(0.1361) Steps 694(682.24) | Grad Norm 2.6280(4.1080) | Total Time 14.00(14.00)\n",
      "Iter 8690 | Time 17.0371(17.3685) | Bit/dim 3.6038(3.6040) | Xent 0.3937(0.3839) | Loss 3.8007(3.7960) | Error 0.1511(0.1360) Steps 682(683.77) | Grad Norm 2.1935(3.7730) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0158 | Time 87.0442, Epoch Time 1059.0116(961.0294), Bit/dim 3.6036(best: 3.6037), Xent 0.6782, Loss 3.9427, Error 0.2193(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8700 | Time 17.0263(17.3665) | Bit/dim 3.6067(3.6023) | Xent 0.3556(0.3769) | Loss 3.7845(3.7907) | Error 0.1200(0.1345) Steps 700(685.17) | Grad Norm 3.4690(3.7957) | Total Time 14.00(14.00)\n",
      "Iter 8710 | Time 17.3172(17.3856) | Bit/dim 3.6407(3.6026) | Xent 0.3497(0.3794) | Loss 3.8156(3.7923) | Error 0.1278(0.1354) Steps 694(690.57) | Grad Norm 4.6608(3.8933) | Total Time 14.00(14.00)\n",
      "Iter 8720 | Time 17.0961(17.4155) | Bit/dim 3.5846(3.6033) | Xent 0.3961(0.3729) | Loss 3.7827(3.7898) | Error 0.1367(0.1330) Steps 700(691.14) | Grad Norm 3.2170(3.6344) | Total Time 14.00(14.00)\n",
      "Iter 8730 | Time 18.0673(17.4585) | Bit/dim 3.5562(3.6007) | Xent 0.3646(0.3716) | Loss 3.7385(3.7865) | Error 0.1333(0.1321) Steps 712(691.70) | Grad Norm 4.5421(3.6764) | Total Time 14.00(14.00)\n",
      "Iter 8740 | Time 17.0421(17.4173) | Bit/dim 3.6081(3.6009) | Xent 0.4549(0.3807) | Loss 3.8355(3.7913) | Error 0.1578(0.1362) Steps 676(690.61) | Grad Norm 5.9970(3.8628) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0159 | Time 86.8985, Epoch Time 1064.6895(964.1392), Bit/dim 3.6147(best: 3.6036), Xent 0.7719, Loss 4.0007, Error 0.2393(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8750 | Time 17.7442(17.4781) | Bit/dim 3.5873(3.6020) | Xent 0.4177(0.3903) | Loss 3.7962(3.7971) | Error 0.1478(0.1390) Steps 700(692.45) | Grad Norm 4.2105(3.9197) | Total Time 14.00(14.00)\n",
      "Iter 8760 | Time 16.8758(17.4175) | Bit/dim 3.5926(3.6072) | Xent 0.3280(0.3845) | Loss 3.7566(3.7995) | Error 0.1211(0.1370) Steps 688(690.30) | Grad Norm 2.5454(4.0145) | Total Time 14.00(14.00)\n",
      "Iter 8770 | Time 18.4344(17.4491) | Bit/dim 3.6054(3.6038) | Xent 0.4592(0.3877) | Loss 3.8350(3.7977) | Error 0.1544(0.1379) Steps 700(690.88) | Grad Norm 7.2684(4.3157) | Total Time 14.00(14.00)\n",
      "Iter 8780 | Time 17.1063(17.5046) | Bit/dim 3.5998(3.6044) | Xent 0.3622(0.3824) | Loss 3.7810(3.7956) | Error 0.1178(0.1354) Steps 682(690.80) | Grad Norm 5.0306(4.1719) | Total Time 14.00(14.00)\n",
      "Iter 8790 | Time 17.7135(17.5507) | Bit/dim 3.6072(3.6067) | Xent 0.4301(0.3842) | Loss 3.8222(3.7988) | Error 0.1533(0.1366) Steps 712(691.72) | Grad Norm 4.3658(4.2166) | Total Time 14.00(14.00)\n",
      "Iter 8800 | Time 18.0023(17.5658) | Bit/dim 3.6165(3.6060) | Xent 0.4052(0.3827) | Loss 3.8191(3.7973) | Error 0.1489(0.1361) Steps 706(691.80) | Grad Norm 3.2238(4.0962) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0160 | Time 86.9561, Epoch Time 1070.0740(967.3173), Bit/dim 3.6047(best: 3.6036), Xent 0.6985, Loss 3.9539, Error 0.2187(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8810 | Time 18.2460(17.6302) | Bit/dim 3.5884(3.6020) | Xent 0.3797(0.3750) | Loss 3.7782(3.7895) | Error 0.1389(0.1336) Steps 718(694.60) | Grad Norm 3.1385(3.9225) | Total Time 14.00(14.00)\n",
      "Iter 8820 | Time 16.9389(17.6418) | Bit/dim 3.5850(3.6002) | Xent 0.3726(0.3717) | Loss 3.7713(3.7861) | Error 0.1422(0.1318) Steps 700(696.69) | Grad Norm 4.8221(3.9867) | Total Time 14.00(14.00)\n",
      "Iter 8830 | Time 17.9539(17.6401) | Bit/dim 3.6174(3.6020) | Xent 0.3335(0.3680) | Loss 3.7842(3.7860) | Error 0.1233(0.1306) Steps 700(696.44) | Grad Norm 2.7544(3.8092) | Total Time 14.00(14.00)\n",
      "Iter 8840 | Time 18.0232(17.6732) | Bit/dim 3.6563(3.6036) | Xent 0.3444(0.3727) | Loss 3.8285(3.7899) | Error 0.1122(0.1322) Steps 706(697.36) | Grad Norm 3.0143(3.9408) | Total Time 14.00(14.00)\n",
      "Iter 8850 | Time 18.3024(17.7848) | Bit/dim 3.6056(3.6022) | Xent 0.3594(0.3783) | Loss 3.7853(3.7914) | Error 0.1411(0.1341) Steps 700(700.15) | Grad Norm 2.6609(4.1346) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0161 | Time 87.9281, Epoch Time 1083.8410(970.8130), Bit/dim 3.6058(best: 3.6036), Xent 0.7195, Loss 3.9655, Error 0.2294(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8860 | Time 17.9400(17.8085) | Bit/dim 3.6152(3.6035) | Xent 0.3713(0.3730) | Loss 3.8008(3.7899) | Error 0.1311(0.1325) Steps 694(699.04) | Grad Norm 2.8040(3.8995) | Total Time 14.00(14.00)\n",
      "Iter 8870 | Time 17.6836(17.7405) | Bit/dim 3.6399(3.6045) | Xent 0.3344(0.3690) | Loss 3.8072(3.7890) | Error 0.1233(0.1309) Steps 700(698.69) | Grad Norm 2.6936(3.7516) | Total Time 14.00(14.00)\n",
      "Iter 8880 | Time 17.7682(17.7325) | Bit/dim 3.5818(3.6024) | Xent 0.3595(0.3681) | Loss 3.7615(3.7864) | Error 0.1200(0.1300) Steps 700(697.83) | Grad Norm 3.6063(3.8052) | Total Time 14.00(14.00)\n",
      "Iter 8890 | Time 18.6071(17.7673) | Bit/dim 3.6457(3.6029) | Xent 0.3312(0.3636) | Loss 3.8113(3.7847) | Error 0.1111(0.1279) Steps 718(701.86) | Grad Norm 2.8940(3.6119) | Total Time 14.00(14.00)\n",
      "Iter 8900 | Time 17.9035(17.7663) | Bit/dim 3.6285(3.6023) | Xent 0.3576(0.3619) | Loss 3.8073(3.7832) | Error 0.1244(0.1279) Steps 700(702.24) | Grad Norm 3.9190(3.4256) | Total Time 14.00(14.00)\n",
      "Iter 8910 | Time 18.2464(17.7992) | Bit/dim 3.5937(3.6010) | Xent 0.3746(0.3603) | Loss 3.7810(3.7812) | Error 0.1422(0.1279) Steps 712(704.02) | Grad Norm 2.7310(3.5609) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0162 | Time 87.4354, Epoch Time 1083.0272(974.1794), Bit/dim 3.6083(best: 3.6036), Xent 0.7292, Loss 3.9729, Error 0.2283(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8920 | Time 18.3669(17.8105) | Bit/dim 3.6394(3.6008) | Xent 0.3345(0.3560) | Loss 3.8067(3.7788) | Error 0.1200(0.1260) Steps 706(704.22) | Grad Norm 2.2613(3.5715) | Total Time 14.00(14.00)\n",
      "Iter 8930 | Time 17.8128(17.8026) | Bit/dim 3.6242(3.6022) | Xent 0.4513(0.3624) | Loss 3.8499(3.7834) | Error 0.1611(0.1290) Steps 712(706.84) | Grad Norm 5.0229(3.8863) | Total Time 14.00(14.00)\n",
      "Iter 8940 | Time 18.5238(17.8279) | Bit/dim 3.6270(3.6054) | Xent 0.3836(0.3720) | Loss 3.8188(3.7913) | Error 0.1300(0.1319) Steps 688(706.73) | Grad Norm 4.5918(4.1888) | Total Time 14.00(14.00)\n",
      "Iter 8950 | Time 18.3123(17.8086) | Bit/dim 3.6071(3.6036) | Xent 0.4261(0.3714) | Loss 3.8202(3.7893) | Error 0.1544(0.1314) Steps 712(705.68) | Grad Norm 3.6335(4.1798) | Total Time 14.00(14.00)\n",
      "Iter 8960 | Time 18.1798(17.8596) | Bit/dim 3.5847(3.6051) | Xent 0.3913(0.3714) | Loss 3.7803(3.7908) | Error 0.1322(0.1319) Steps 718(708.66) | Grad Norm 3.9923(4.1166) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0163 | Time 87.7521, Epoch Time 1087.2900(977.5727), Bit/dim 3.6105(best: 3.6036), Xent 0.7581, Loss 3.9895, Error 0.2298(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 8970 | Time 18.1586(17.8648) | Bit/dim 3.6257(3.6070) | Xent 0.3726(0.3717) | Loss 3.8120(3.7929) | Error 0.1256(0.1312) Steps 718(709.12) | Grad Norm 4.2670(4.2094) | Total Time 14.00(14.00)\n",
      "Iter 8980 | Time 17.9163(17.8725) | Bit/dim 3.6013(3.6049) | Xent 0.3683(0.3666) | Loss 3.7854(3.7882) | Error 0.1433(0.1301) Steps 694(707.32) | Grad Norm 2.1985(3.8642) | Total Time 14.00(14.00)\n",
      "Iter 8990 | Time 18.0191(17.8725) | Bit/dim 3.5797(3.6002) | Xent 0.3777(0.3605) | Loss 3.7685(3.7805) | Error 0.1411(0.1274) Steps 718(709.21) | Grad Norm 4.1891(3.7536) | Total Time 14.00(14.00)\n",
      "Iter 9000 | Time 17.8681(17.8586) | Bit/dim 3.6202(3.6013) | Xent 0.3496(0.3573) | Loss 3.7950(3.7799) | Error 0.1278(0.1262) Steps 718(711.14) | Grad Norm 4.3349(3.8168) | Total Time 14.00(14.00)\n",
      "Iter 9010 | Time 17.7215(17.8548) | Bit/dim 3.6191(3.6015) | Xent 0.3470(0.3520) | Loss 3.7926(3.7775) | Error 0.1311(0.1246) Steps 712(711.02) | Grad Norm 6.2302(3.8325) | Total Time 14.00(14.00)\n",
      "Iter 9020 | Time 18.0283(17.8301) | Bit/dim 3.6032(3.6042) | Xent 0.4318(0.3698) | Loss 3.8191(3.7891) | Error 0.1633(0.1312) Steps 712(710.38) | Grad Norm 5.1217(4.1211) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0164 | Time 87.2887, Epoch Time 1086.2472(980.8330), Bit/dim 3.6079(best: 3.6036), Xent 0.7059, Loss 3.9609, Error 0.2228(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9030 | Time 17.7260(17.8837) | Bit/dim 3.5737(3.6049) | Xent 0.3712(0.3685) | Loss 3.7593(3.7891) | Error 0.1378(0.1312) Steps 724(710.46) | Grad Norm 4.5813(4.1338) | Total Time 14.00(14.00)\n",
      "Iter 9040 | Time 18.3265(17.9326) | Bit/dim 3.5508(3.6035) | Xent 0.4041(0.3684) | Loss 3.7528(3.7877) | Error 0.1433(0.1309) Steps 718(711.95) | Grad Norm 3.9284(4.2275) | Total Time 14.00(14.00)\n",
      "Iter 9050 | Time 17.2131(17.9616) | Bit/dim 3.5733(3.6011) | Xent 0.3450(0.3655) | Loss 3.7458(3.7838) | Error 0.1244(0.1297) Steps 700(711.51) | Grad Norm 3.3403(4.1850) | Total Time 14.00(14.00)\n",
      "Iter 9060 | Time 17.6350(17.9090) | Bit/dim 3.5874(3.6020) | Xent 0.3236(0.3588) | Loss 3.7492(3.7814) | Error 0.1089(0.1266) Steps 712(709.06) | Grad Norm 3.0265(3.9049) | Total Time 14.00(14.00)\n",
      "Iter 9070 | Time 16.7596(17.8688) | Bit/dim 3.5681(3.6026) | Xent 0.4388(0.3533) | Loss 3.7875(3.7792) | Error 0.1667(0.1251) Steps 706(709.24) | Grad Norm 5.9523(3.7074) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0165 | Time 88.0760, Epoch Time 1090.8197(984.1326), Bit/dim 3.6009(best: 3.6036), Xent 0.6988, Loss 3.9503, Error 0.2168(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9080 | Time 17.8612(17.8478) | Bit/dim 3.6401(3.6039) | Xent 0.4309(0.3666) | Loss 3.8555(3.7872) | Error 0.1589(0.1302) Steps 700(710.28) | Grad Norm 6.3004(4.3910) | Total Time 14.00(14.00)\n",
      "Iter 9090 | Time 17.2319(17.7574) | Bit/dim 3.5848(3.6055) | Xent 0.3364(0.3695) | Loss 3.7530(3.7903) | Error 0.1344(0.1318) Steps 712(710.37) | Grad Norm 3.2619(4.4405) | Total Time 14.00(14.00)\n",
      "Iter 9100 | Time 17.4883(17.7366) | Bit/dim 3.5811(3.6018) | Xent 0.3349(0.3678) | Loss 3.7485(3.7857) | Error 0.1089(0.1299) Steps 682(709.89) | Grad Norm 3.5463(4.3435) | Total Time 14.00(14.00)\n",
      "Iter 9110 | Time 17.8520(17.7729) | Bit/dim 3.6037(3.6020) | Xent 0.3625(0.3642) | Loss 3.7849(3.7841) | Error 0.1256(0.1281) Steps 712(709.35) | Grad Norm 2.8625(4.0479) | Total Time 14.00(14.00)\n",
      "Iter 9120 | Time 18.1760(17.8249) | Bit/dim 3.5869(3.6020) | Xent 0.3073(0.3617) | Loss 3.7406(3.7828) | Error 0.1133(0.1282) Steps 718(709.89) | Grad Norm 3.7956(3.9530) | Total Time 14.00(14.00)\n",
      "Iter 9130 | Time 17.7275(17.8296) | Bit/dim 3.5992(3.6018) | Xent 0.3910(0.3669) | Loss 3.7947(3.7853) | Error 0.1433(0.1301) Steps 712(710.28) | Grad Norm 3.8779(3.9261) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0166 | Time 87.3441, Epoch Time 1083.7431(987.1209), Bit/dim 3.6085(best: 3.6009), Xent 0.7372, Loss 3.9771, Error 0.2322(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9140 | Time 17.8277(17.8236) | Bit/dim 3.6392(3.6037) | Xent 0.3768(0.3705) | Loss 3.8276(3.7889) | Error 0.1356(0.1316) Steps 712(710.37) | Grad Norm 5.4101(4.1380) | Total Time 14.00(14.00)\n",
      "Iter 9150 | Time 17.3558(17.8407) | Bit/dim 3.5883(3.6029) | Xent 0.3404(0.3669) | Loss 3.7585(3.7863) | Error 0.1189(0.1309) Steps 712(709.73) | Grad Norm 3.1868(3.9957) | Total Time 14.00(14.00)\n",
      "Iter 9160 | Time 18.1329(17.9209) | Bit/dim 3.5826(3.6000) | Xent 0.3261(0.3556) | Loss 3.7456(3.7778) | Error 0.1178(0.1274) Steps 712(710.62) | Grad Norm 3.9025(3.8453) | Total Time 14.00(14.00)\n",
      "Iter 9170 | Time 17.7861(17.9004) | Bit/dim 3.5839(3.5989) | Xent 0.3746(0.3501) | Loss 3.7712(3.7740) | Error 0.1311(0.1257) Steps 712(708.84) | Grad Norm 4.1581(3.5957) | Total Time 14.00(14.00)\n",
      "Iter 9180 | Time 18.1220(17.8130) | Bit/dim 3.6206(3.5998) | Xent 0.3274(0.3489) | Loss 3.7843(3.7742) | Error 0.1067(0.1251) Steps 718(711.07) | Grad Norm 3.0879(3.7657) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0167 | Time 89.1780, Epoch Time 1088.2197(990.1539), Bit/dim 3.6030(best: 3.6009), Xent 0.7370, Loss 3.9715, Error 0.2203(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9190 | Time 17.7468(17.8037) | Bit/dim 3.5920(3.5986) | Xent 0.3423(0.3443) | Loss 3.7631(3.7707) | Error 0.1211(0.1238) Steps 694(711.35) | Grad Norm 3.8447(3.5769) | Total Time 14.00(14.00)\n",
      "Iter 9200 | Time 18.3808(17.8033) | Bit/dim 3.6165(3.5999) | Xent 0.3858(0.3420) | Loss 3.8094(3.7709) | Error 0.1289(0.1221) Steps 718(712.13) | Grad Norm 4.1595(3.5152) | Total Time 14.00(14.00)\n",
      "Iter 9210 | Time 17.8949(17.8018) | Bit/dim 3.6003(3.6005) | Xent 0.3409(0.3429) | Loss 3.7707(3.7719) | Error 0.1244(0.1223) Steps 718(712.12) | Grad Norm 2.9231(3.6266) | Total Time 14.00(14.00)\n",
      "Iter 9220 | Time 18.1956(17.8616) | Bit/dim 3.6042(3.5990) | Xent 0.3694(0.3456) | Loss 3.7889(3.7718) | Error 0.1367(0.1235) Steps 712(713.98) | Grad Norm 4.3063(3.7245) | Total Time 14.00(14.00)\n",
      "Iter 9230 | Time 17.7214(17.8810) | Bit/dim 3.6032(3.5979) | Xent 0.3760(0.3476) | Loss 3.7912(3.7717) | Error 0.1367(0.1239) Steps 706(713.02) | Grad Norm 4.8479(3.8011) | Total Time 14.00(14.00)\n",
      "Iter 9240 | Time 18.2109(17.8966) | Bit/dim 3.6036(3.5971) | Xent 0.3451(0.3495) | Loss 3.7762(3.7718) | Error 0.1422(0.1251) Steps 706(713.44) | Grad Norm 4.6644(3.8334) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0168 | Time 90.4993, Epoch Time 1092.1168(993.2127), Bit/dim 3.6151(best: 3.6009), Xent 0.7461, Loss 3.9881, Error 0.2214(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9250 | Time 17.8704(17.8942) | Bit/dim 3.6128(3.5987) | Xent 0.4177(0.3485) | Loss 3.8217(3.7729) | Error 0.1511(0.1245) Steps 700(714.04) | Grad Norm 5.7463(4.0484) | Total Time 14.00(14.00)\n",
      "Iter 9260 | Time 17.4799(17.8598) | Bit/dim 3.6204(3.5989) | Xent 0.3028(0.3467) | Loss 3.7718(3.7722) | Error 0.1067(0.1240) Steps 730(715.11) | Grad Norm 2.6700(3.9806) | Total Time 14.00(14.00)\n",
      "Iter 9270 | Time 18.4214(17.9164) | Bit/dim 3.6020(3.5975) | Xent 0.2954(0.3410) | Loss 3.7497(3.7680) | Error 0.1078(0.1222) Steps 718(714.97) | Grad Norm 2.6080(3.8935) | Total Time 14.00(14.00)\n",
      "Iter 9280 | Time 17.6262(17.8458) | Bit/dim 3.6111(3.5974) | Xent 0.3415(0.3412) | Loss 3.7818(3.7680) | Error 0.1267(0.1223) Steps 706(715.86) | Grad Norm 3.6274(3.8653) | Total Time 14.00(14.00)\n",
      "Iter 9290 | Time 18.1228(17.8562) | Bit/dim 3.5972(3.5954) | Xent 0.3677(0.3527) | Loss 3.7810(3.7718) | Error 0.1444(0.1261) Steps 718(715.66) | Grad Norm 3.4870(3.9205) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0169 | Time 90.0330, Epoch Time 1090.0915(996.1191), Bit/dim 3.6013(best: 3.6009), Xent 0.7074, Loss 3.9550, Error 0.2175(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9300 | Time 18.0889(17.8457) | Bit/dim 3.5961(3.5976) | Xent 0.3883(0.3538) | Loss 3.7902(3.7745) | Error 0.1467(0.1269) Steps 718(716.20) | Grad Norm 8.0901(4.0196) | Total Time 14.00(14.00)\n",
      "Iter 9310 | Time 17.9932(17.8830) | Bit/dim 3.6243(3.5967) | Xent 0.3643(0.3486) | Loss 3.8064(3.7710) | Error 0.1233(0.1237) Steps 724(717.25) | Grad Norm 3.1661(3.7882) | Total Time 14.00(14.00)\n",
      "Iter 9320 | Time 17.7306(17.8404) | Bit/dim 3.5865(3.5973) | Xent 0.3207(0.3404) | Loss 3.7469(3.7674) | Error 0.1056(0.1224) Steps 706(716.30) | Grad Norm 3.4879(3.6419) | Total Time 14.00(14.00)\n",
      "Iter 9330 | Time 17.8220(17.7698) | Bit/dim 3.6287(3.6017) | Xent 0.3533(0.3374) | Loss 3.8053(3.7704) | Error 0.1267(0.1209) Steps 718(716.29) | Grad Norm 4.6985(3.8566) | Total Time 14.00(14.00)\n",
      "Iter 9340 | Time 18.1721(17.7916) | Bit/dim 3.6014(3.5999) | Xent 0.3701(0.3362) | Loss 3.7864(3.7680) | Error 0.1356(0.1195) Steps 724(715.78) | Grad Norm 4.0171(3.6468) | Total Time 14.00(14.00)\n",
      "Iter 9350 | Time 18.1072(17.8551) | Bit/dim 3.5656(3.5978) | Xent 0.3552(0.3362) | Loss 3.7433(3.7660) | Error 0.1367(0.1193) Steps 718(715.62) | Grad Norm 4.0907(3.6842) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0170 | Time 88.0700, Epoch Time 1085.7296(998.8074), Bit/dim 3.6016(best: 3.6009), Xent 0.7207, Loss 3.9620, Error 0.2208(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9360 | Time 17.2670(17.8584) | Bit/dim 3.6259(3.5981) | Xent 0.3990(0.3377) | Loss 3.8254(3.7670) | Error 0.1456(0.1209) Steps 700(714.88) | Grad Norm 5.7862(3.8295) | Total Time 14.00(14.00)\n",
      "Iter 9370 | Time 18.3326(17.8556) | Bit/dim 3.5947(3.5983) | Xent 0.3949(0.3441) | Loss 3.7921(3.7703) | Error 0.1489(0.1234) Steps 724(712.98) | Grad Norm 5.1898(3.8549) | Total Time 14.00(14.00)\n",
      "Iter 9380 | Time 17.7858(17.8563) | Bit/dim 3.5473(3.5990) | Xent 0.3862(0.3500) | Loss 3.7404(3.7740) | Error 0.1389(0.1259) Steps 718(713.14) | Grad Norm 2.9693(4.1152) | Total Time 14.00(14.00)\n",
      "Iter 9390 | Time 18.8055(17.9363) | Bit/dim 3.6107(3.6009) | Xent 0.3278(0.3458) | Loss 3.7747(3.7739) | Error 0.1089(0.1235) Steps 724(713.76) | Grad Norm 2.3949(3.9425) | Total Time 14.00(14.00)\n",
      "Iter 9400 | Time 17.9374(17.9448) | Bit/dim 3.5869(3.5982) | Xent 0.3470(0.3440) | Loss 3.7604(3.7702) | Error 0.1144(0.1224) Steps 712(715.78) | Grad Norm 3.7894(3.7574) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0171 | Time 88.7355, Epoch Time 1092.8912(1001.6299), Bit/dim 3.6062(best: 3.6009), Xent 0.7574, Loss 3.9849, Error 0.2358(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9410 | Time 18.2085(17.9294) | Bit/dim 3.5891(3.5999) | Xent 0.3424(0.3489) | Loss 3.7603(3.7743) | Error 0.1156(0.1244) Steps 712(714.33) | Grad Norm 5.1197(4.1524) | Total Time 14.00(14.00)\n",
      "Iter 9420 | Time 17.9594(17.9326) | Bit/dim 3.6045(3.5986) | Xent 0.3088(0.3414) | Loss 3.7589(3.7693) | Error 0.1111(0.1229) Steps 712(713.53) | Grad Norm 3.2920(3.9241) | Total Time 14.00(14.00)\n",
      "Iter 9430 | Time 17.8998(17.9423) | Bit/dim 3.5474(3.5985) | Xent 0.3438(0.3340) | Loss 3.7193(3.7655) | Error 0.1133(0.1197) Steps 724(714.35) | Grad Norm 4.3286(3.7335) | Total Time 14.00(14.00)\n",
      "Iter 9440 | Time 18.1456(17.9774) | Bit/dim 3.6167(3.5981) | Xent 0.3278(0.3274) | Loss 3.7806(3.7618) | Error 0.1167(0.1166) Steps 718(715.03) | Grad Norm 4.0177(3.4944) | Total Time 14.00(14.00)\n",
      "Iter 9450 | Time 18.3044(17.9691) | Bit/dim 3.5846(3.5990) | Xent 0.3506(0.3298) | Loss 3.7599(3.7639) | Error 0.1289(0.1174) Steps 718(715.02) | Grad Norm 4.7581(3.7432) | Total Time 14.00(14.00)\n",
      "Iter 9460 | Time 17.9412(17.9379) | Bit/dim 3.5869(3.5960) | Xent 0.3006(0.3418) | Loss 3.7372(3.7669) | Error 0.1156(0.1220) Steps 724(715.92) | Grad Norm 2.7259(3.9520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0172 | Time 89.6884, Epoch Time 1095.4639(1004.4450), Bit/dim 3.5984(best: 3.6009), Xent 0.7480, Loss 3.9724, Error 0.2268(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9470 | Time 18.0473(17.9347) | Bit/dim 3.5695(3.5935) | Xent 0.3491(0.3376) | Loss 3.7440(3.7623) | Error 0.1111(0.1207) Steps 712(714.91) | Grad Norm 3.6270(3.9151) | Total Time 14.00(14.00)\n",
      "Iter 9480 | Time 18.1689(17.9680) | Bit/dim 3.6670(3.5949) | Xent 0.3180(0.3318) | Loss 3.8260(3.7608) | Error 0.1144(0.1183) Steps 736(718.08) | Grad Norm 3.7702(3.7317) | Total Time 14.00(14.00)\n",
      "Iter 9490 | Time 18.5076(18.0007) | Bit/dim 3.6060(3.5976) | Xent 0.3883(0.3344) | Loss 3.8002(3.7648) | Error 0.1344(0.1186) Steps 724(719.79) | Grad Norm 6.7741(3.8941) | Total Time 14.00(14.00)\n",
      "Iter 9500 | Time 17.8634(17.9468) | Bit/dim 3.5584(3.5963) | Xent 0.3493(0.3376) | Loss 3.7331(3.7651) | Error 0.1178(0.1202) Steps 718(720.32) | Grad Norm 2.7242(3.8730) | Total Time 14.00(14.00)\n",
      "Iter 9510 | Time 18.2951(17.9699) | Bit/dim 3.6058(3.5983) | Xent 0.4427(0.3364) | Loss 3.8271(3.7665) | Error 0.1611(0.1200) Steps 724(719.47) | Grad Norm 8.8093(3.9637) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0173 | Time 89.9562, Epoch Time 1097.1986(1007.2276), Bit/dim 3.6059(best: 3.5984), Xent 0.7697, Loss 3.9907, Error 0.2290(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9520 | Time 18.0964(17.9826) | Bit/dim 3.6011(3.5970) | Xent 0.3427(0.3443) | Loss 3.7725(3.7691) | Error 0.1222(0.1234) Steps 718(719.65) | Grad Norm 3.7463(4.0861) | Total Time 14.00(14.00)\n",
      "Iter 9530 | Time 17.8717(17.9071) | Bit/dim 3.6168(3.5977) | Xent 0.2948(0.3364) | Loss 3.7642(3.7659) | Error 0.1022(0.1204) Steps 712(718.67) | Grad Norm 2.5372(3.9315) | Total Time 14.00(14.00)\n",
      "Iter 9540 | Time 17.6700(17.9186) | Bit/dim 3.6001(3.5954) | Xent 0.3969(0.3372) | Loss 3.7985(3.7640) | Error 0.1533(0.1216) Steps 718(717.17) | Grad Norm 3.1199(3.8222) | Total Time 14.00(14.00)\n",
      "Iter 9550 | Time 17.5416(17.9502) | Bit/dim 3.5917(3.5963) | Xent 0.3064(0.3329) | Loss 3.7449(3.7628) | Error 0.1178(0.1208) Steps 706(717.45) | Grad Norm 2.3904(3.8603) | Total Time 14.00(14.00)\n",
      "Iter 9560 | Time 18.0190(17.9825) | Bit/dim 3.5738(3.5973) | Xent 0.3106(0.3335) | Loss 3.7291(3.7641) | Error 0.1044(0.1201) Steps 724(717.08) | Grad Norm 2.8551(3.7383) | Total Time 14.00(14.00)\n",
      "Iter 9570 | Time 17.6907(18.0463) | Bit/dim 3.6336(3.5955) | Xent 0.2914(0.3315) | Loss 3.7793(3.7612) | Error 0.0967(0.1193) Steps 706(719.01) | Grad Norm 2.6625(3.6433) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0174 | Time 88.2453, Epoch Time 1095.4787(1009.8751), Bit/dim 3.6024(best: 3.5984), Xent 0.7653, Loss 3.9851, Error 0.2253(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9580 | Time 17.0141(18.0551) | Bit/dim 3.6221(3.5971) | Xent 0.4589(0.3327) | Loss 3.8516(3.7634) | Error 0.1678(0.1194) Steps 724(720.25) | Grad Norm 6.9840(3.8218) | Total Time 14.00(14.00)\n",
      "Iter 9590 | Time 17.8879(18.0172) | Bit/dim 3.6002(3.5972) | Xent 0.3406(0.3347) | Loss 3.7705(3.7645) | Error 0.1211(0.1208) Steps 718(720.51) | Grad Norm 3.9778(3.7815) | Total Time 14.00(14.00)\n",
      "Iter 9600 | Time 18.5454(18.0565) | Bit/dim 3.5836(3.5974) | Xent 0.3322(0.3360) | Loss 3.7497(3.7654) | Error 0.1111(0.1199) Steps 712(721.06) | Grad Norm 3.0826(3.6685) | Total Time 14.00(14.00)\n",
      "Iter 9610 | Time 17.6143(18.0612) | Bit/dim 3.5810(3.5950) | Xent 0.3680(0.3420) | Loss 3.7650(3.7660) | Error 0.1411(0.1226) Steps 712(721.19) | Grad Norm 6.4725(4.0238) | Total Time 14.00(14.00)\n",
      "Iter 9620 | Time 17.8456(18.0245) | Bit/dim 3.5764(3.5967) | Xent 0.3434(0.3444) | Loss 3.7480(3.7689) | Error 0.1333(0.1234) Steps 724(720.33) | Grad Norm 3.5280(4.0381) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0175 | Time 91.2984, Epoch Time 1099.7700(1012.5720), Bit/dim 3.6219(best: 3.5984), Xent 0.9228, Loss 4.0832, Error 0.2508(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9630 | Time 17.3913(17.9813) | Bit/dim 3.6427(3.5999) | Xent 0.3676(0.3614) | Loss 3.8265(3.7805) | Error 0.1222(0.1287) Steps 718(720.37) | Grad Norm 5.3703(4.4682) | Total Time 14.00(14.00)\n",
      "Iter 9640 | Time 17.5141(17.9514) | Bit/dim 3.6084(3.6044) | Xent 0.4068(0.3672) | Loss 3.8118(3.7880) | Error 0.1400(0.1312) Steps 718(721.21) | Grad Norm 3.4456(4.4933) | Total Time 14.00(14.00)\n",
      "Iter 9650 | Time 17.9008(17.9742) | Bit/dim 3.5901(3.6010) | Xent 0.3049(0.3604) | Loss 3.7426(3.7812) | Error 0.1133(0.1295) Steps 730(721.79) | Grad Norm 2.7726(4.2402) | Total Time 14.00(14.00)\n",
      "Iter 9660 | Time 18.3908(18.0019) | Bit/dim 3.6166(3.5996) | Xent 0.3567(0.3515) | Loss 3.7949(3.7754) | Error 0.1300(0.1260) Steps 724(723.46) | Grad Norm 2.7837(3.8527) | Total Time 14.00(14.00)\n",
      "Iter 9670 | Time 17.0752(17.9297) | Bit/dim 3.5837(3.6011) | Xent 0.3298(0.3437) | Loss 3.7486(3.7730) | Error 0.1189(0.1235) Steps 712(723.71) | Grad Norm 5.4962(3.7744) | Total Time 14.00(14.00)\n",
      "Iter 9680 | Time 17.9209(17.9721) | Bit/dim 3.5741(3.5982) | Xent 0.3353(0.3355) | Loss 3.7418(3.7660) | Error 0.1067(0.1202) Steps 730(722.46) | Grad Norm 3.5858(3.5465) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0176 | Time 90.1668, Epoch Time 1096.0040(1015.0749), Bit/dim 3.5995(best: 3.5984), Xent 0.7495, Loss 3.9743, Error 0.2242(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9690 | Time 17.9483(18.0269) | Bit/dim 3.6181(3.5991) | Xent 0.2727(0.3313) | Loss 3.7545(3.7647) | Error 0.0989(0.1184) Steps 712(723.67) | Grad Norm 3.9548(3.5452) | Total Time 14.00(14.00)\n",
      "Iter 9700 | Time 17.8958(18.0576) | Bit/dim 3.5899(3.5960) | Xent 0.3073(0.3290) | Loss 3.7435(3.7606) | Error 0.1111(0.1173) Steps 730(723.80) | Grad Norm 6.0381(3.7063) | Total Time 14.00(14.00)\n",
      "Iter 9710 | Time 18.4371(18.0787) | Bit/dim 3.6123(3.5978) | Xent 0.4108(0.3308) | Loss 3.8178(3.7632) | Error 0.1356(0.1171) Steps 712(722.40) | Grad Norm 5.1322(3.8065) | Total Time 14.00(14.00)\n",
      "Iter 9720 | Time 18.5202(18.1037) | Bit/dim 3.5822(3.5944) | Xent 0.3186(0.3272) | Loss 3.7415(3.7580) | Error 0.1122(0.1163) Steps 718(722.79) | Grad Norm 2.7921(3.6492) | Total Time 14.00(14.00)\n",
      "Iter 9730 | Time 17.4168(18.1147) | Bit/dim 3.5966(3.5941) | Xent 0.3659(0.3269) | Loss 3.7796(3.7576) | Error 0.1233(0.1162) Steps 724(723.86) | Grad Norm 6.2729(3.7090) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0177 | Time 91.9007, Epoch Time 1106.4427(1017.8159), Bit/dim 3.6047(best: 3.5984), Xent 0.7510, Loss 3.9802, Error 0.2230(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9740 | Time 17.8742(18.0160) | Bit/dim 3.5999(3.5977) | Xent 0.2942(0.3252) | Loss 3.7470(3.7604) | Error 0.0967(0.1165) Steps 718(723.36) | Grad Norm 3.0861(3.8194) | Total Time 14.00(14.00)\n",
      "Iter 9750 | Time 17.3439(18.0729) | Bit/dim 3.5949(3.5978) | Xent 0.3202(0.3213) | Loss 3.7550(3.7585) | Error 0.1200(0.1153) Steps 718(721.96) | Grad Norm 3.6425(3.7391) | Total Time 14.00(14.00)\n",
      "Iter 9760 | Time 18.1449(18.0768) | Bit/dim 3.6187(3.5975) | Xent 0.3389(0.3258) | Loss 3.7881(3.7604) | Error 0.1278(0.1170) Steps 718(723.46) | Grad Norm 5.0968(4.0994) | Total Time 14.00(14.00)\n",
      "Iter 9770 | Time 17.8998(18.0705) | Bit/dim 3.5748(3.5967) | Xent 0.2898(0.3250) | Loss 3.7197(3.7592) | Error 0.1100(0.1165) Steps 736(725.14) | Grad Norm 2.6939(4.0856) | Total Time 14.00(14.00)\n",
      "Iter 9780 | Time 18.0528(18.0950) | Bit/dim 3.6063(3.5978) | Xent 0.3547(0.3227) | Loss 3.7836(3.7591) | Error 0.1256(0.1162) Steps 718(724.18) | Grad Norm 2.5373(3.7687) | Total Time 14.00(14.00)\n",
      "Iter 9790 | Time 18.2389(18.0905) | Bit/dim 3.5996(3.5975) | Xent 0.3091(0.3218) | Loss 3.7542(3.7584) | Error 0.1078(0.1154) Steps 736(725.45) | Grad Norm 4.3931(3.6069) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0178 | Time 88.8698, Epoch Time 1100.9784(1020.3108), Bit/dim 3.6033(best: 3.5984), Xent 0.7729, Loss 3.9897, Error 0.2250(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9800 | Time 18.3962(18.0916) | Bit/dim 3.6433(3.5979) | Xent 0.3334(0.3187) | Loss 3.8100(3.7573) | Error 0.1222(0.1137) Steps 736(725.33) | Grad Norm 6.3554(3.8842) | Total Time 14.00(14.00)\n",
      "Iter 9810 | Time 17.8511(18.0905) | Bit/dim 3.6277(3.6009) | Xent 0.3272(0.3208) | Loss 3.7913(3.7613) | Error 0.1200(0.1140) Steps 718(725.86) | Grad Norm 5.1299(4.1149) | Total Time 14.00(14.00)\n",
      "Iter 9820 | Time 18.0404(18.0936) | Bit/dim 3.6079(3.5998) | Xent 0.3141(0.3222) | Loss 3.7650(3.7609) | Error 0.1156(0.1150) Steps 748(727.10) | Grad Norm 2.9464(4.0925) | Total Time 14.00(14.00)\n",
      "Iter 9830 | Time 18.4056(18.0708) | Bit/dim 3.6423(3.6008) | Xent 0.3870(0.3409) | Loss 3.8358(3.7713) | Error 0.1333(0.1219) Steps 724(727.40) | Grad Norm 4.6631(4.6782) | Total Time 14.00(14.00)\n",
      "Iter 9840 | Time 17.6577(17.9963) | Bit/dim 3.5692(3.5997) | Xent 0.3118(0.3435) | Loss 3.7251(3.7715) | Error 0.1144(0.1224) Steps 730(727.07) | Grad Norm 2.5209(4.3695) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0179 | Time 90.2352, Epoch Time 1100.5439(1022.7178), Bit/dim 3.6052(best: 3.5984), Xent 0.7199, Loss 3.9651, Error 0.2171(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9850 | Time 18.1042(18.0388) | Bit/dim 3.6007(3.6013) | Xent 0.2978(0.3322) | Loss 3.7496(3.7674) | Error 0.1144(0.1192) Steps 736(728.59) | Grad Norm 3.1718(4.0622) | Total Time 14.00(14.00)\n",
      "Iter 9860 | Time 18.2427(18.0974) | Bit/dim 3.5867(3.5974) | Xent 0.3456(0.3277) | Loss 3.7595(3.7612) | Error 0.1211(0.1179) Steps 736(728.21) | Grad Norm 4.1617(3.9578) | Total Time 14.00(14.00)\n",
      "Iter 9870 | Time 18.1199(18.0515) | Bit/dim 3.6276(3.5970) | Xent 0.3204(0.3279) | Loss 3.7878(3.7610) | Error 0.1111(0.1176) Steps 718(726.43) | Grad Norm 3.0380(4.1124) | Total Time 14.00(14.00)\n",
      "Iter 9880 | Time 18.1039(18.0124) | Bit/dim 3.5956(3.5978) | Xent 0.2858(0.3217) | Loss 3.7385(3.7586) | Error 0.1056(0.1145) Steps 724(726.26) | Grad Norm 2.7579(3.8516) | Total Time 14.00(14.00)\n",
      "Iter 9890 | Time 18.1467(18.0024) | Bit/dim 3.5844(3.5953) | Xent 0.2729(0.3144) | Loss 3.7209(3.7525) | Error 0.0978(0.1123) Steps 736(726.24) | Grad Norm 3.0913(3.6388) | Total Time 14.00(14.00)\n",
      "Iter 9900 | Time 18.3601(18.0215) | Bit/dim 3.5951(3.5949) | Xent 0.3641(0.3230) | Loss 3.7771(3.7564) | Error 0.1311(0.1151) Steps 754(725.49) | Grad Norm 4.8786(3.9297) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0180 | Time 91.2642, Epoch Time 1099.9211(1025.0339), Bit/dim 3.5939(best: 3.5984), Xent 0.7570, Loss 3.9724, Error 0.2240(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9910 | Time 18.0789(18.0717) | Bit/dim 3.5656(3.5946) | Xent 0.3137(0.3208) | Loss 3.7224(3.7550) | Error 0.1089(0.1139) Steps 724(726.97) | Grad Norm 3.4479(3.8656) | Total Time 14.00(14.00)\n",
      "Iter 9920 | Time 18.3168(18.0488) | Bit/dim 3.5661(3.5963) | Xent 0.3155(0.3248) | Loss 3.7239(3.7587) | Error 0.1289(0.1161) Steps 742(725.11) | Grad Norm 4.7550(4.0577) | Total Time 14.00(14.00)\n",
      "Iter 9930 | Time 18.5873(18.0275) | Bit/dim 3.6059(3.5986) | Xent 0.3404(0.3203) | Loss 3.7761(3.7587) | Error 0.1289(0.1152) Steps 736(725.59) | Grad Norm 3.6343(3.9166) | Total Time 14.00(14.00)\n",
      "Iter 9940 | Time 18.7370(18.1024) | Bit/dim 3.6034(3.5944) | Xent 0.3144(0.3220) | Loss 3.7606(3.7554) | Error 0.1078(0.1155) Steps 736(727.66) | Grad Norm 5.8717(3.9023) | Total Time 14.00(14.00)\n",
      "Iter 9950 | Time 18.0289(18.0930) | Bit/dim 3.5655(3.5933) | Xent 0.2996(0.3198) | Loss 3.7153(3.7531) | Error 0.1067(0.1147) Steps 730(726.86) | Grad Norm 2.1982(3.8131) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0181 | Time 91.7621, Epoch Time 1105.3855(1027.4445), Bit/dim 3.6002(best: 3.5939), Xent 0.7686, Loss 3.9845, Error 0.2270(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 9960 | Time 17.8918(18.0974) | Bit/dim 3.5822(3.5929) | Xent 0.3316(0.3162) | Loss 3.7480(3.7510) | Error 0.1122(0.1134) Steps 730(728.46) | Grad Norm 3.4153(3.6570) | Total Time 14.00(14.00)\n",
      "Iter 9970 | Time 17.7776(18.0378) | Bit/dim 3.5737(3.5916) | Xent 0.3611(0.3159) | Loss 3.7542(3.7495) | Error 0.1278(0.1138) Steps 730(728.77) | Grad Norm 4.9689(3.8002) | Total Time 14.00(14.00)\n",
      "Iter 9980 | Time 17.3925(18.0286) | Bit/dim 3.6012(3.5912) | Xent 0.3373(0.3204) | Loss 3.7699(3.7514) | Error 0.1178(0.1156) Steps 718(729.22) | Grad Norm 3.8196(3.9774) | Total Time 14.00(14.00)\n",
      "Iter 9990 | Time 17.8859(17.9804) | Bit/dim 3.5960(3.5932) | Xent 0.3392(0.3194) | Loss 3.7655(3.7529) | Error 0.1244(0.1145) Steps 730(727.96) | Grad Norm 5.0833(3.8587) | Total Time 14.00(14.00)\n",
      "Iter 10000 | Time 17.6619(18.0008) | Bit/dim 3.5871(3.5929) | Xent 0.3651(0.3205) | Loss 3.7697(3.7532) | Error 0.1333(0.1147) Steps 736(727.29) | Grad Norm 5.1145(3.7863) | Total Time 14.00(14.00)\n",
      "Iter 10010 | Time 17.5729(17.9624) | Bit/dim 3.6262(3.5977) | Xent 0.4035(0.3288) | Loss 3.8280(3.7620) | Error 0.1478(0.1178) Steps 736(726.94) | Grad Norm 3.8433(3.9395) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0182 | Time 89.3476, Epoch Time 1094.8900(1029.4678), Bit/dim 3.5963(best: 3.5939), Xent 0.7500, Loss 3.9713, Error 0.2269(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10020 | Time 18.1400(18.0423) | Bit/dim 3.5620(3.5947) | Xent 0.3082(0.3210) | Loss 3.7161(3.7552) | Error 0.1089(0.1146) Steps 718(729.23) | Grad Norm 4.1242(3.9492) | Total Time 14.00(14.00)\n",
      "Iter 10030 | Time 18.2159(18.0563) | Bit/dim 3.6081(3.5928) | Xent 0.2803(0.3138) | Loss 3.7482(3.7497) | Error 0.1056(0.1126) Steps 742(730.54) | Grad Norm 2.9176(3.8187) | Total Time 14.00(14.00)\n",
      "Iter 10040 | Time 18.4179(18.0955) | Bit/dim 3.5904(3.5931) | Xent 0.3386(0.3100) | Loss 3.7597(3.7481) | Error 0.1311(0.1111) Steps 724(729.94) | Grad Norm 4.0104(3.6689) | Total Time 14.00(14.00)\n",
      "Iter 10050 | Time 18.2173(18.1281) | Bit/dim 3.5772(3.5942) | Xent 0.2752(0.3067) | Loss 3.7148(3.7476) | Error 0.0922(0.1108) Steps 724(731.20) | Grad Norm 3.3640(3.4649) | Total Time 14.00(14.00)\n",
      "Iter 10060 | Time 18.3270(18.2063) | Bit/dim 3.5771(3.5940) | Xent 0.3275(0.3072) | Loss 3.7409(3.7476) | Error 0.1211(0.1102) Steps 736(731.68) | Grad Norm 4.0808(3.5329) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0183 | Time 90.2843, Epoch Time 1112.3885(1031.9554), Bit/dim 3.5964(best: 3.5939), Xent 0.7607, Loss 3.9768, Error 0.2227(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10070 | Time 18.2450(18.2537) | Bit/dim 3.5868(3.5930) | Xent 0.3105(0.3079) | Loss 3.7421(3.7469) | Error 0.1167(0.1112) Steps 730(732.64) | Grad Norm 3.8799(3.5137) | Total Time 14.00(14.00)\n",
      "Iter 10080 | Time 18.2221(18.2478) | Bit/dim 3.5826(3.5936) | Xent 0.3884(0.3090) | Loss 3.7768(3.7481) | Error 0.1456(0.1125) Steps 754(735.61) | Grad Norm 4.5732(3.8080) | Total Time 14.00(14.00)\n",
      "Iter 10090 | Time 18.1538(18.2056) | Bit/dim 3.5652(3.5923) | Xent 0.3198(0.3073) | Loss 3.7251(3.7459) | Error 0.1156(0.1113) Steps 730(734.25) | Grad Norm 5.4636(3.8283) | Total Time 14.00(14.00)\n",
      "Iter 10100 | Time 18.4635(18.1502) | Bit/dim 3.5850(3.5919) | Xent 0.2719(0.3021) | Loss 3.7209(3.7430) | Error 0.0911(0.1088) Steps 742(734.24) | Grad Norm 3.3030(3.6475) | Total Time 14.00(14.00)\n",
      "Iter 10110 | Time 17.7993(18.1261) | Bit/dim 3.5745(3.5899) | Xent 0.3441(0.3050) | Loss 3.7465(3.7423) | Error 0.1100(0.1092) Steps 724(732.62) | Grad Norm 2.6021(3.5704) | Total Time 14.00(14.00)\n",
      "Iter 10120 | Time 18.2365(18.1602) | Bit/dim 3.6330(3.5909) | Xent 0.3080(0.3045) | Loss 3.7870(3.7432) | Error 0.1033(0.1087) Steps 730(733.69) | Grad Norm 5.5873(3.5616) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0184 | Time 89.5619, Epoch Time 1105.0165(1034.1473), Bit/dim 3.5976(best: 3.5939), Xent 0.7587, Loss 3.9770, Error 0.2254(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10130 | Time 18.4234(18.1295) | Bit/dim 3.5889(3.5899) | Xent 0.2972(0.3051) | Loss 3.7375(3.7424) | Error 0.1100(0.1094) Steps 754(734.26) | Grad Norm 3.6704(3.5509) | Total Time 14.00(14.00)\n",
      "Iter 10140 | Time 18.5785(18.1148) | Bit/dim 3.5570(3.5913) | Xent 0.2996(0.3105) | Loss 3.7068(3.7465) | Error 0.1056(0.1119) Steps 730(731.78) | Grad Norm 4.0049(4.0459) | Total Time 14.00(14.00)\n",
      "Iter 10150 | Time 17.7589(18.1399) | Bit/dim 3.6088(3.5919) | Xent 0.3536(0.3125) | Loss 3.7856(3.7482) | Error 0.1211(0.1124) Steps 736(733.44) | Grad Norm 6.3796(4.2113) | Total Time 14.00(14.00)\n",
      "Iter 10160 | Time 17.7460(18.1398) | Bit/dim 3.6012(3.5935) | Xent 0.2992(0.3147) | Loss 3.7508(3.7508) | Error 0.1033(0.1123) Steps 742(734.20) | Grad Norm 1.7205(4.0573) | Total Time 14.00(14.00)\n",
      "Iter 10170 | Time 18.5279(18.1126) | Bit/dim 3.5823(3.5932) | Xent 0.2872(0.3086) | Loss 3.7259(3.7475) | Error 0.1022(0.1101) Steps 736(734.18) | Grad Norm 2.9743(3.8684) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0185 | Time 90.9804, Epoch Time 1104.5109(1036.2582), Bit/dim 3.5985(best: 3.5939), Xent 0.7822, Loss 3.9896, Error 0.2195(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10180 | Time 19.1189(18.2098) | Bit/dim 3.6124(3.5927) | Xent 0.2669(0.3006) | Loss 3.7458(3.7430) | Error 0.0900(0.1070) Steps 724(734.82) | Grad Norm 3.8509(3.7471) | Total Time 14.00(14.00)\n",
      "Iter 10190 | Time 18.5220(18.2251) | Bit/dim 3.6241(3.5927) | Xent 0.3137(0.2991) | Loss 3.7810(3.7422) | Error 0.1156(0.1067) Steps 724(733.48) | Grad Norm 3.6126(3.5327) | Total Time 14.00(14.00)\n",
      "Iter 10200 | Time 18.9783(18.2318) | Bit/dim 3.6190(3.5914) | Xent 0.2992(0.3030) | Loss 3.7686(3.7429) | Error 0.1022(0.1086) Steps 748(732.92) | Grad Norm 5.8534(3.6952) | Total Time 14.00(14.00)\n",
      "Iter 10210 | Time 18.0686(18.2576) | Bit/dim 3.5908(3.5894) | Xent 0.2424(0.2998) | Loss 3.7120(3.7393) | Error 0.0778(0.1081) Steps 742(734.90) | Grad Norm 2.3697(3.6867) | Total Time 14.00(14.00)\n",
      "Iter 10220 | Time 17.8270(18.2618) | Bit/dim 3.6096(3.5939) | Xent 0.3176(0.3059) | Loss 3.7684(3.7468) | Error 0.1100(0.1095) Steps 748(735.89) | Grad Norm 3.6371(3.8732) | Total Time 14.00(14.00)\n",
      "Iter 10230 | Time 17.9909(18.1855) | Bit/dim 3.5833(3.5950) | Xent 0.3567(0.3111) | Loss 3.7617(3.7506) | Error 0.1167(0.1115) Steps 736(734.79) | Grad Norm 3.4143(4.0022) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0186 | Time 89.9844, Epoch Time 1112.7840(1038.5540), Bit/dim 3.6016(best: 3.5939), Xent 0.7947, Loss 3.9990, Error 0.2335(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10240 | Time 18.3400(18.2437) | Bit/dim 3.6085(3.5939) | Xent 0.2674(0.3030) | Loss 3.7422(3.7454) | Error 0.0978(0.1088) Steps 718(736.30) | Grad Norm 2.7673(3.7678) | Total Time 14.00(14.00)\n",
      "Iter 10250 | Time 18.1481(18.2718) | Bit/dim 3.5893(3.5935) | Xent 0.2601(0.2970) | Loss 3.7193(3.7420) | Error 0.1089(0.1065) Steps 742(736.85) | Grad Norm 2.3241(3.4020) | Total Time 14.00(14.00)\n",
      "Iter 10260 | Time 18.3172(18.2743) | Bit/dim 3.6021(3.5899) | Xent 0.2778(0.2960) | Loss 3.7410(3.7379) | Error 0.1022(0.1066) Steps 748(738.34) | Grad Norm 3.2653(3.4625) | Total Time 14.00(14.00)\n",
      "Iter 10270 | Time 18.2728(18.3223) | Bit/dim 3.6049(3.5903) | Xent 0.3291(0.2965) | Loss 3.7695(3.7385) | Error 0.1233(0.1066) Steps 766(740.56) | Grad Norm 5.0533(3.5292) | Total Time 14.00(14.00)\n",
      "Iter 10280 | Time 18.3603(18.2993) | Bit/dim 3.6010(3.5903) | Xent 0.2982(0.2966) | Loss 3.7501(3.7386) | Error 0.0944(0.1051) Steps 766(742.33) | Grad Norm 3.2927(3.5199) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0187 | Time 89.7267, Epoch Time 1115.9617(1040.8762), Bit/dim 3.5933(best: 3.5939), Xent 0.7784, Loss 3.9825, Error 0.2260(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10290 | Time 18.3595(18.3039) | Bit/dim 3.5595(3.5909) | Xent 0.2822(0.2958) | Loss 3.7006(3.7388) | Error 0.1056(0.1051) Steps 742(742.52) | Grad Norm 3.1698(3.6718) | Total Time 14.00(14.00)\n",
      "Iter 10300 | Time 18.0582(18.2936) | Bit/dim 3.6115(3.5914) | Xent 0.2684(0.2882) | Loss 3.7456(3.7355) | Error 0.0944(0.1030) Steps 754(744.13) | Grad Norm 4.2829(3.6064) | Total Time 14.00(14.00)\n",
      "Iter 10310 | Time 17.9363(18.3106) | Bit/dim 3.5798(3.5901) | Xent 0.2366(0.2821) | Loss 3.6981(3.7311) | Error 0.0933(0.1000) Steps 736(747.16) | Grad Norm 2.1848(3.4419) | Total Time 14.00(14.00)\n",
      "Iter 10320 | Time 17.6605(18.3289) | Bit/dim 3.5968(3.5894) | Xent 0.2652(0.2838) | Loss 3.7294(3.7313) | Error 0.0878(0.0995) Steps 736(746.55) | Grad Norm 2.6486(3.4865) | Total Time 14.00(14.00)\n",
      "Iter 10330 | Time 18.5536(18.2980) | Bit/dim 3.6038(3.5904) | Xent 0.3152(0.2911) | Loss 3.7614(3.7360) | Error 0.1111(0.1023) Steps 748(745.48) | Grad Norm 4.3818(3.7657) | Total Time 14.00(14.00)\n",
      "Iter 10340 | Time 18.8090(18.3123) | Bit/dim 3.5836(3.5891) | Xent 0.2676(0.2933) | Loss 3.7174(3.7358) | Error 0.1011(0.1041) Steps 748(746.96) | Grad Norm 2.9153(3.7344) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0188 | Time 91.5511, Epoch Time 1116.5632(1043.1468), Bit/dim 3.5958(best: 3.5933), Xent 0.8055, Loss 3.9985, Error 0.2298(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10350 | Time 18.7374(18.3547) | Bit/dim 3.6189(3.5931) | Xent 0.3384(0.2877) | Loss 3.7881(3.7369) | Error 0.1133(0.1018) Steps 742(747.33) | Grad Norm 3.9330(3.5881) | Total Time 14.00(14.00)\n",
      "Iter 10360 | Time 18.6246(18.3484) | Bit/dim 3.5851(3.5927) | Xent 0.2929(0.2845) | Loss 3.7316(3.7349) | Error 0.1056(0.1006) Steps 754(745.91) | Grad Norm 3.7271(3.5320) | Total Time 14.00(14.00)\n",
      "Iter 10370 | Time 18.5921(18.3501) | Bit/dim 3.5873(3.5918) | Xent 0.2991(0.2924) | Loss 3.7368(3.7380) | Error 0.1211(0.1038) Steps 742(744.86) | Grad Norm 4.3945(3.7361) | Total Time 14.00(14.00)\n",
      "Iter 10380 | Time 18.3170(18.3771) | Bit/dim 3.5728(3.5907) | Xent 0.2846(0.2933) | Loss 3.7151(3.7373) | Error 0.1067(0.1043) Steps 742(745.33) | Grad Norm 3.6181(3.7221) | Total Time 14.00(14.00)\n",
      "Iter 10390 | Time 18.7705(18.3828) | Bit/dim 3.6221(3.5915) | Xent 0.2646(0.2956) | Loss 3.7544(3.7393) | Error 0.0956(0.1048) Steps 760(745.46) | Grad Norm 2.3782(3.6287) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0189 | Time 92.2011, Epoch Time 1123.5222(1045.5581), Bit/dim 3.5936(best: 3.5933), Xent 0.7704, Loss 3.9788, Error 0.2240(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10400 | Time 18.6556(18.4555) | Bit/dim 3.5773(3.5878) | Xent 0.3022(0.2930) | Loss 3.7284(3.7343) | Error 0.1089(0.1044) Steps 760(747.89) | Grad Norm 5.0962(3.5140) | Total Time 14.00(14.00)\n",
      "Iter 10410 | Time 18.7250(18.4489) | Bit/dim 3.6093(3.5878) | Xent 0.2822(0.2893) | Loss 3.7504(3.7325) | Error 0.0911(0.1037) Steps 742(747.12) | Grad Norm 2.4374(3.6189) | Total Time 14.00(14.00)\n",
      "Iter 10420 | Time 18.5732(18.4160) | Bit/dim 3.6093(3.5887) | Xent 0.3559(0.2910) | Loss 3.7873(3.7342) | Error 0.1322(0.1043) Steps 748(748.05) | Grad Norm 4.1252(3.7349) | Total Time 14.00(14.00)\n",
      "Iter 10430 | Time 18.1489(18.4070) | Bit/dim 3.5754(3.5874) | Xent 0.2953(0.3003) | Loss 3.7231(3.7375) | Error 0.1000(0.1071) Steps 748(749.23) | Grad Norm 2.5295(3.9467) | Total Time 14.00(14.00)\n",
      "Iter 10440 | Time 18.6887(18.4332) | Bit/dim 3.6046(3.5932) | Xent 0.3057(0.3059) | Loss 3.7574(3.7462) | Error 0.1122(0.1085) Steps 736(749.03) | Grad Norm 3.4863(4.0255) | Total Time 14.00(14.00)\n",
      "Iter 10450 | Time 18.0465(18.3772) | Bit/dim 3.5790(3.5953) | Xent 0.2929(0.3045) | Loss 3.7254(3.7475) | Error 0.1011(0.1083) Steps 736(747.30) | Grad Norm 2.1558(3.7979) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0190 | Time 91.2326, Epoch Time 1120.6780(1047.8117), Bit/dim 3.5959(best: 3.5933), Xent 0.7457, Loss 3.9688, Error 0.2191(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10460 | Time 18.3426(18.3509) | Bit/dim 3.5941(3.5934) | Xent 0.2953(0.3012) | Loss 3.7418(3.7441) | Error 0.1133(0.1076) Steps 748(746.17) | Grad Norm 4.2199(3.8882) | Total Time 14.00(14.00)\n",
      "Iter 10470 | Time 18.7192(18.3379) | Bit/dim 3.5839(3.5937) | Xent 0.2983(0.3030) | Loss 3.7330(3.7452) | Error 0.1067(0.1088) Steps 748(745.84) | Grad Norm 3.5477(4.0641) | Total Time 14.00(14.00)\n",
      "Iter 10480 | Time 18.9797(18.4555) | Bit/dim 3.6020(3.5945) | Xent 0.2350(0.2961) | Loss 3.7195(3.7425) | Error 0.0878(0.1058) Steps 742(745.79) | Grad Norm 2.4415(3.9439) | Total Time 14.00(14.00)\n",
      "Iter 10490 | Time 18.9919(18.5119) | Bit/dim 3.6267(3.5941) | Xent 0.2659(0.2920) | Loss 3.7596(3.7401) | Error 0.0922(0.1046) Steps 742(745.43) | Grad Norm 2.6335(3.7625) | Total Time 14.00(14.00)\n",
      "Iter 10500 | Time 19.0708(18.5442) | Bit/dim 3.5936(3.5916) | Xent 0.3017(0.2959) | Loss 3.7445(3.7395) | Error 0.1033(0.1052) Steps 748(746.37) | Grad Norm 4.1497(3.8279) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0191 | Time 92.3291, Epoch Time 1129.2650(1050.2553), Bit/dim 3.5961(best: 3.5933), Xent 0.8206, Loss 4.0064, Error 0.2329(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10510 | Time 18.3479(18.5644) | Bit/dim 3.5481(3.5910) | Xent 0.3519(0.3060) | Loss 3.7241(3.7440) | Error 0.1244(0.1087) Steps 742(746.64) | Grad Norm 4.2568(3.9287) | Total Time 14.00(14.00)\n",
      "Iter 10520 | Time 18.8183(18.5220) | Bit/dim 3.5503(3.5900) | Xent 0.2926(0.2998) | Loss 3.6966(3.7399) | Error 0.1044(0.1064) Steps 766(747.81) | Grad Norm 2.2569(3.6463) | Total Time 14.00(14.00)\n",
      "Iter 10530 | Time 18.5690(18.4925) | Bit/dim 3.5834(3.5910) | Xent 0.2739(0.2907) | Loss 3.7203(3.7363) | Error 0.1011(0.1031) Steps 754(748.22) | Grad Norm 3.3440(3.5667) | Total Time 14.00(14.00)\n",
      "Iter 10540 | Time 18.8626(18.4435) | Bit/dim 3.5862(3.5877) | Xent 0.3070(0.2847) | Loss 3.7397(3.7300) | Error 0.1100(0.1008) Steps 742(746.86) | Grad Norm 4.3895(3.5602) | Total Time 14.00(14.00)\n",
      "Iter 10550 | Time 17.9155(18.3978) | Bit/dim 3.5546(3.5861) | Xent 0.2754(0.2889) | Loss 3.6924(3.7305) | Error 0.0978(0.1021) Steps 760(746.60) | Grad Norm 3.3534(3.6936) | Total Time 14.00(14.00)\n",
      "Iter 10560 | Time 18.2741(18.3855) | Bit/dim 3.6140(3.5884) | Xent 0.3052(0.2922) | Loss 3.7666(3.7345) | Error 0.1156(0.1044) Steps 742(746.85) | Grad Norm 4.1147(3.8509) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0192 | Time 91.3051, Epoch Time 1120.5739(1052.3648), Bit/dim 3.5895(best: 3.5933), Xent 0.8038, Loss 3.9914, Error 0.2349(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10570 | Time 17.9434(18.3411) | Bit/dim 3.6023(3.5877) | Xent 0.2963(0.2935) | Loss 3.7505(3.7344) | Error 0.1000(0.1042) Steps 748(747.51) | Grad Norm 3.9199(3.8270) | Total Time 14.00(14.00)\n",
      "Iter 10580 | Time 18.3125(18.3590) | Bit/dim 3.5776(3.5876) | Xent 0.2735(0.2980) | Loss 3.7143(3.7366) | Error 0.1022(0.1073) Steps 730(748.47) | Grad Norm 4.2567(3.7431) | Total Time 14.00(14.00)\n",
      "Iter 10590 | Time 18.2257(18.3537) | Bit/dim 3.5834(3.5904) | Xent 0.2845(0.2951) | Loss 3.7257(3.7380) | Error 0.1000(0.1065) Steps 748(747.68) | Grad Norm 4.1796(3.6641) | Total Time 14.00(14.00)\n",
      "Iter 10600 | Time 18.3916(18.4672) | Bit/dim 3.5754(3.5905) | Xent 0.2909(0.2916) | Loss 3.7209(3.7363) | Error 0.1000(0.1047) Steps 772(750.05) | Grad Norm 5.1280(3.6192) | Total Time 14.00(14.00)\n",
      "Iter 10610 | Time 18.7176(18.5181) | Bit/dim 3.5681(3.5894) | Xent 0.3218(0.2930) | Loss 3.7290(3.7359) | Error 0.1222(0.1050) Steps 748(749.13) | Grad Norm 3.3385(3.8224) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0193 | Time 92.2344, Epoch Time 1126.3762(1054.5852), Bit/dim 3.5977(best: 3.5895), Xent 0.7809, Loss 3.9882, Error 0.2206(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10620 | Time 18.5609(18.5138) | Bit/dim 3.5863(3.5882) | Xent 0.2948(0.2930) | Loss 3.7336(3.7347) | Error 0.1022(0.1048) Steps 736(748.07) | Grad Norm 4.8054(3.8139) | Total Time 14.00(14.00)\n",
      "Iter 10630 | Time 18.2354(18.4705) | Bit/dim 3.5854(3.5897) | Xent 0.2642(0.2872) | Loss 3.7175(3.7334) | Error 0.1000(0.1035) Steps 736(748.56) | Grad Norm 3.4594(3.8366) | Total Time 14.00(14.00)\n",
      "Iter 10640 | Time 18.8065(18.4567) | Bit/dim 3.5617(3.5885) | Xent 0.2928(0.2913) | Loss 3.7081(3.7342) | Error 0.1000(0.1051) Steps 748(748.81) | Grad Norm 4.5259(3.8929) | Total Time 14.00(14.00)\n",
      "Iter 10650 | Time 18.5374(18.4822) | Bit/dim 3.5665(3.5891) | Xent 0.2196(0.2844) | Loss 3.6763(3.7313) | Error 0.0756(0.1023) Steps 754(749.86) | Grad Norm 2.6465(3.6856) | Total Time 14.00(14.00)\n",
      "Iter 10660 | Time 19.0797(18.5790) | Bit/dim 3.6097(3.5902) | Xent 0.2674(0.2836) | Loss 3.7434(3.7320) | Error 0.1011(0.1018) Steps 766(752.66) | Grad Norm 2.9804(3.6332) | Total Time 14.00(14.00)\n",
      "Iter 10670 | Time 18.5167(18.6190) | Bit/dim 3.5550(3.5862) | Xent 0.3174(0.2889) | Loss 3.7137(3.7306) | Error 0.1111(0.1031) Steps 748(755.10) | Grad Norm 2.9834(3.7686) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0194 | Time 92.4662, Epoch Time 1132.6708(1056.9277), Bit/dim 3.5976(best: 3.5895), Xent 0.8147, Loss 4.0049, Error 0.2291(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10680 | Time 18.3806(18.5758) | Bit/dim 3.5494(3.5850) | Xent 0.2860(0.2964) | Loss 3.6924(3.7332) | Error 0.0989(0.1059) Steps 772(755.84) | Grad Norm 3.7366(3.9610) | Total Time 14.00(14.00)\n",
      "Iter 10690 | Time 18.2047(18.5509) | Bit/dim 3.5600(3.5870) | Xent 0.3303(0.3103) | Loss 3.7252(3.7421) | Error 0.1200(0.1111) Steps 754(754.74) | Grad Norm 5.1615(4.3448) | Total Time 14.00(14.00)\n",
      "Iter 10700 | Time 18.5796(18.6286) | Bit/dim 3.5775(3.5882) | Xent 0.2945(0.3070) | Loss 3.7247(3.7417) | Error 0.1067(0.1098) Steps 760(757.28) | Grad Norm 3.0228(4.1268) | Total Time 14.00(14.00)\n",
      "Iter 10710 | Time 17.8832(18.6277) | Bit/dim 3.6027(3.5895) | Xent 0.2606(0.3004) | Loss 3.7330(3.7397) | Error 0.1011(0.1074) Steps 748(755.71) | Grad Norm 2.4694(3.9095) | Total Time 14.00(14.00)\n",
      "Iter 10720 | Time 18.5223(18.5710) | Bit/dim 3.5971(3.5902) | Xent 0.2673(0.2902) | Loss 3.7308(3.7353) | Error 0.1000(0.1042) Steps 772(755.88) | Grad Norm 2.8240(3.6688) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0195 | Time 93.3907, Epoch Time 1134.0788(1059.2423), Bit/dim 3.5873(best: 3.5895), Xent 0.7917, Loss 3.9832, Error 0.2352(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10730 | Time 18.5786(18.6232) | Bit/dim 3.5695(3.5888) | Xent 0.3204(0.2886) | Loss 3.7297(3.7331) | Error 0.1222(0.1043) Steps 766(759.03) | Grad Norm 3.9653(3.6785) | Total Time 14.00(14.00)\n",
      "Iter 10740 | Time 18.6182(18.5887) | Bit/dim 3.6071(3.5917) | Xent 0.3129(0.2896) | Loss 3.7636(3.7365) | Error 0.1200(0.1051) Steps 766(756.70) | Grad Norm 6.0851(3.7261) | Total Time 14.00(14.00)\n",
      "Iter 10750 | Time 18.1919(18.6391) | Bit/dim 3.5646(3.5871) | Xent 0.2660(0.2856) | Loss 3.6976(3.7299) | Error 0.0922(0.1029) Steps 748(757.50) | Grad Norm 2.6166(3.6953) | Total Time 14.00(14.00)\n",
      "Iter 10760 | Time 18.3653(18.6425) | Bit/dim 3.5754(3.5896) | Xent 0.2912(0.2907) | Loss 3.7210(3.7349) | Error 0.1122(0.1049) Steps 742(756.75) | Grad Norm 2.9855(3.8355) | Total Time 14.00(14.00)\n",
      "Iter 10770 | Time 18.8336(18.6634) | Bit/dim 3.5866(3.5913) | Xent 0.2806(0.2913) | Loss 3.7270(3.7370) | Error 0.0989(0.1047) Steps 766(758.88) | Grad Norm 5.5395(3.8199) | Total Time 14.00(14.00)\n",
      "Iter 10780 | Time 18.0226(18.6600) | Bit/dim 3.5988(3.5918) | Xent 0.2661(0.2868) | Loss 3.7319(3.7352) | Error 0.0900(0.1029) Steps 754(758.97) | Grad Norm 3.4827(3.8058) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0196 | Time 91.6637, Epoch Time 1136.2126(1061.5514), Bit/dim 3.5982(best: 3.5873), Xent 0.7622, Loss 3.9793, Error 0.2210(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10790 | Time 18.9077(18.7230) | Bit/dim 3.6178(3.5912) | Xent 0.2843(0.2801) | Loss 3.7600(3.7313) | Error 0.1067(0.1011) Steps 772(759.20) | Grad Norm 4.3164(3.6072) | Total Time 14.00(14.00)\n",
      "Iter 10800 | Time 19.0351(18.7283) | Bit/dim 3.5789(3.5888) | Xent 0.2697(0.2726) | Loss 3.7137(3.7251) | Error 0.0944(0.0980) Steps 778(759.51) | Grad Norm 2.8322(3.4729) | Total Time 14.00(14.00)\n",
      "Iter 10810 | Time 18.8716(18.7872) | Bit/dim 3.5939(3.5872) | Xent 0.2402(0.2637) | Loss 3.7140(3.7190) | Error 0.0900(0.0947) Steps 772(762.24) | Grad Norm 2.4351(3.2433) | Total Time 14.00(14.00)\n",
      "Iter 10820 | Time 18.7203(18.7961) | Bit/dim 3.5770(3.5885) | Xent 0.2900(0.2717) | Loss 3.7220(3.7244) | Error 0.1100(0.0976) Steps 760(762.10) | Grad Norm 3.1354(3.3797) | Total Time 14.00(14.00)\n",
      "Iter 10830 | Time 18.2756(18.7376) | Bit/dim 3.5998(3.5878) | Xent 0.4084(0.2902) | Loss 3.8039(3.7329) | Error 0.1389(0.1034) Steps 748(760.58) | Grad Norm 7.8412(3.7358) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0197 | Time 92.3327, Epoch Time 1144.2504(1064.0323), Bit/dim 3.5995(best: 3.5873), Xent 0.7955, Loss 3.9972, Error 0.2286(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10840 | Time 17.9609(18.6796) | Bit/dim 3.5820(3.5890) | Xent 0.2697(0.2858) | Loss 3.7169(3.7319) | Error 0.0911(0.1021) Steps 748(759.71) | Grad Norm 3.2645(3.7183) | Total Time 14.00(14.00)\n",
      "Iter 10850 | Time 18.7624(18.6510) | Bit/dim 3.5892(3.5890) | Xent 0.3300(0.2906) | Loss 3.7541(3.7343) | Error 0.1200(0.1037) Steps 772(758.84) | Grad Norm 5.2376(3.7216) | Total Time 14.00(14.00)\n",
      "Iter 10860 | Time 18.5160(18.6633) | Bit/dim 3.6157(3.5913) | Xent 0.3123(0.2868) | Loss 3.7719(3.7347) | Error 0.1133(0.1021) Steps 754(760.10) | Grad Norm 4.1356(3.7449) | Total Time 14.00(14.00)\n",
      "Iter 10870 | Time 19.4134(18.6782) | Bit/dim 3.5577(3.5880) | Xent 0.2302(0.2852) | Loss 3.6728(3.7306) | Error 0.0822(0.1015) Steps 736(759.82) | Grad Norm 2.7597(3.5747) | Total Time 14.00(14.00)\n",
      "Iter 10880 | Time 18.4408(18.7154) | Bit/dim 3.5678(3.5870) | Xent 0.2464(0.2800) | Loss 3.6910(3.7270) | Error 0.0911(0.0995) Steps 760(760.79) | Grad Norm 1.6805(3.4751) | Total Time 14.00(14.00)\n",
      "Iter 10890 | Time 17.9289(18.6718) | Bit/dim 3.5838(3.5872) | Xent 0.2803(0.2776) | Loss 3.7240(3.7260) | Error 0.0944(0.0986) Steps 754(760.73) | Grad Norm 3.4410(3.5139) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0198 | Time 91.7201, Epoch Time 1134.2459(1066.1388), Bit/dim 3.5930(best: 3.5873), Xent 0.8026, Loss 3.9943, Error 0.2289(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10900 | Time 18.2321(18.6451) | Bit/dim 3.5700(3.5885) | Xent 0.2630(0.2718) | Loss 3.7015(3.7244) | Error 0.0922(0.0966) Steps 766(762.03) | Grad Norm 3.8152(3.6336) | Total Time 14.00(14.00)\n",
      "Iter 10910 | Time 19.0403(18.6567) | Bit/dim 3.5984(3.5857) | Xent 0.3701(0.2753) | Loss 3.7835(3.7234) | Error 0.1211(0.0973) Steps 754(761.82) | Grad Norm 7.9337(3.9304) | Total Time 14.00(14.00)\n",
      "Iter 10920 | Time 18.8805(18.6654) | Bit/dim 3.5829(3.5897) | Xent 0.3711(0.3018) | Loss 3.7684(3.7406) | Error 0.1267(0.1067) Steps 766(762.86) | Grad Norm 5.1653(4.4562) | Total Time 14.00(14.00)\n",
      "Iter 10930 | Time 19.1162(18.6670) | Bit/dim 3.5862(3.5925) | Xent 0.2855(0.3110) | Loss 3.7289(3.7480) | Error 0.1089(0.1109) Steps 772(763.39) | Grad Norm 2.9877(4.5981) | Total Time 14.00(14.00)\n",
      "Iter 10940 | Time 18.7789(18.7135) | Bit/dim 3.5858(3.5931) | Xent 0.3461(0.3073) | Loss 3.7588(3.7467) | Error 0.1167(0.1088) Steps 790(764.58) | Grad Norm 4.1628(4.3209) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0199 | Time 91.6914, Epoch Time 1138.1177(1068.2981), Bit/dim 3.5904(best: 3.5873), Xent 0.7386, Loss 3.9597, Error 0.2207(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 10950 | Time 18.0531(18.7171) | Bit/dim 3.5755(3.5913) | Xent 0.2551(0.2948) | Loss 3.7031(3.7387) | Error 0.0978(0.1050) Steps 760(762.83) | Grad Norm 3.2363(3.9945) | Total Time 14.00(14.00)\n",
      "Iter 10960 | Time 19.2222(18.7379) | Bit/dim 3.5584(3.5913) | Xent 0.2527(0.2871) | Loss 3.6848(3.7348) | Error 0.0878(0.1030) Steps 754(762.15) | Grad Norm 3.6519(3.9680) | Total Time 14.00(14.00)\n",
      "Iter 10970 | Time 19.3184(18.7944) | Bit/dim 3.5724(3.5889) | Xent 0.2311(0.2781) | Loss 3.6879(3.7279) | Error 0.0844(0.0999) Steps 784(764.32) | Grad Norm 2.1668(3.7993) | Total Time 14.00(14.00)\n",
      "Iter 10980 | Time 19.0679(18.8192) | Bit/dim 3.5773(3.5881) | Xent 0.2296(0.2687) | Loss 3.6921(3.7225) | Error 0.0811(0.0956) Steps 766(763.72) | Grad Norm 3.0351(3.5933) | Total Time 14.00(14.00)\n",
      "Iter 10990 | Time 18.9807(18.8166) | Bit/dim 3.5645(3.5852) | Xent 0.2819(0.2715) | Loss 3.7055(3.7209) | Error 0.1044(0.0963) Steps 778(763.98) | Grad Norm 3.9329(3.5880) | Total Time 14.00(14.00)\n",
      "Iter 11000 | Time 18.6905(18.8432) | Bit/dim 3.6028(3.5871) | Xent 0.2828(0.2716) | Loss 3.7442(3.7230) | Error 0.1022(0.0967) Steps 760(764.57) | Grad Norm 4.7530(3.5740) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0200 | Time 93.6968, Epoch Time 1148.0948(1070.6920), Bit/dim 3.5936(best: 3.5873), Xent 0.7979, Loss 3.9926, Error 0.2173(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11010 | Time 19.3228(18.8823) | Bit/dim 3.5727(3.5904) | Xent 0.2705(0.2656) | Loss 3.7079(3.7231) | Error 0.0900(0.0952) Steps 766(763.71) | Grad Norm 3.8635(3.5579) | Total Time 14.00(14.00)\n",
      "Iter 11020 | Time 18.7839(18.9125) | Bit/dim 3.5829(3.5875) | Xent 0.2466(0.2602) | Loss 3.7062(3.7175) | Error 0.0833(0.0925) Steps 778(765.18) | Grad Norm 3.4596(3.4372) | Total Time 14.00(14.00)\n",
      "Iter 11030 | Time 18.7889(18.9046) | Bit/dim 3.5663(3.5858) | Xent 0.2292(0.2583) | Loss 3.6809(3.7150) | Error 0.0789(0.0920) Steps 736(763.99) | Grad Norm 2.2025(3.4133) | Total Time 14.00(14.00)\n",
      "Iter 11040 | Time 18.7362(18.9564) | Bit/dim 3.5855(3.5831) | Xent 0.2995(0.2600) | Loss 3.7352(3.7131) | Error 0.1100(0.0931) Steps 778(764.43) | Grad Norm 3.6424(3.3515) | Total Time 14.00(14.00)\n",
      "Iter 11050 | Time 18.5063(18.9574) | Bit/dim 3.6060(3.5862) | Xent 0.2339(0.2655) | Loss 3.7230(3.7189) | Error 0.0878(0.0952) Steps 766(765.44) | Grad Norm 3.2876(3.5557) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0201 | Time 93.4306, Epoch Time 1153.5196(1073.1768), Bit/dim 3.5912(best: 3.5873), Xent 0.7820, Loss 3.9822, Error 0.2192(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11060 | Time 18.7431(18.8801) | Bit/dim 3.5585(3.5855) | Xent 0.3137(0.2678) | Loss 3.7154(3.7194) | Error 0.1156(0.0953) Steps 754(764.14) | Grad Norm 6.8129(3.6252) | Total Time 14.00(14.00)\n",
      "Iter 11070 | Time 19.3464(18.8777) | Bit/dim 3.6021(3.5855) | Xent 0.2316(0.2696) | Loss 3.7179(3.7203) | Error 0.0822(0.0960) Steps 772(764.52) | Grad Norm 2.2103(3.6856) | Total Time 14.00(14.00)\n",
      "Iter 11080 | Time 19.5633(18.8510) | Bit/dim 3.6081(3.5877) | Xent 0.2312(0.2632) | Loss 3.7237(3.7193) | Error 0.0856(0.0940) Steps 778(763.68) | Grad Norm 2.3197(3.4276) | Total Time 14.00(14.00)\n",
      "Iter 11090 | Time 19.1659(18.9263) | Bit/dim 3.5685(3.5854) | Xent 0.2498(0.2577) | Loss 3.6934(3.7143) | Error 0.0867(0.0922) Steps 766(764.58) | Grad Norm 2.1631(3.3018) | Total Time 14.00(14.00)\n",
      "Iter 11100 | Time 18.4521(18.8854) | Bit/dim 3.6091(3.5868) | Xent 0.3516(0.2778) | Loss 3.7849(3.7257) | Error 0.1300(0.0992) Steps 748(766.31) | Grad Norm 4.1110(3.9025) | Total Time 14.00(14.00)\n",
      "Iter 11110 | Time 20.5221(18.9775) | Bit/dim 3.5974(3.5893) | Xent 0.2890(0.2870) | Loss 3.7419(3.7328) | Error 0.1056(0.1030) Steps 784(768.69) | Grad Norm 2.6757(4.0011) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0202 | Time 92.3066, Epoch Time 1150.9626(1075.5104), Bit/dim 3.5948(best: 3.5873), Xent 0.8149, Loss 4.0023, Error 0.2267(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11120 | Time 19.1226(18.9731) | Bit/dim 3.5741(3.5897) | Xent 0.2290(0.2810) | Loss 3.6886(3.7302) | Error 0.0833(0.1006) Steps 772(769.56) | Grad Norm 3.5886(3.9812) | Total Time 14.00(14.00)\n",
      "Iter 11130 | Time 19.3600(18.9510) | Bit/dim 3.5825(3.5895) | Xent 0.2733(0.2754) | Loss 3.7192(3.7272) | Error 0.0844(0.0984) Steps 766(766.45) | Grad Norm 2.3558(3.7141) | Total Time 14.00(14.00)\n",
      "Iter 11140 | Time 18.8973(18.8925) | Bit/dim 3.6042(3.5907) | Xent 0.3037(0.2822) | Loss 3.7561(3.7318) | Error 0.1256(0.1019) Steps 778(766.45) | Grad Norm 3.8683(3.7886) | Total Time 14.00(14.00)\n",
      "Iter 11150 | Time 20.0102(18.9576) | Bit/dim 3.5618(3.5875) | Xent 0.3550(0.2881) | Loss 3.7393(3.7316) | Error 0.1222(0.1036) Steps 760(766.07) | Grad Norm 5.3343(3.9742) | Total Time 14.00(14.00)\n",
      "Iter 11160 | Time 19.6777(18.9740) | Bit/dim 3.6157(3.5895) | Xent 0.3348(0.3077) | Loss 3.7831(3.7433) | Error 0.1122(0.1112) Steps 796(766.72) | Grad Norm 4.8257(4.6019) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0203 | Time 92.2593, Epoch Time 1149.9888(1077.7448), Bit/dim 3.6075(best: 3.5873), Xent 0.8329, Loss 4.0240, Error 0.2388(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11170 | Time 18.8283(18.9486) | Bit/dim 3.5905(3.5907) | Xent 0.2548(0.3077) | Loss 3.7179(3.7446) | Error 0.0867(0.1113) Steps 784(766.81) | Grad Norm 2.9390(4.3986) | Total Time 14.00(14.00)\n",
      "Iter 11180 | Time 18.4982(18.9632) | Bit/dim 3.5971(3.5929) | Xent 0.3054(0.3002) | Loss 3.7498(3.7431) | Error 0.1133(0.1085) Steps 760(770.14) | Grad Norm 3.8418(4.3077) | Total Time 14.00(14.00)\n",
      "Iter 11190 | Time 18.9361(18.9101) | Bit/dim 3.5659(3.5904) | Xent 0.2737(0.2905) | Loss 3.7028(3.7357) | Error 0.0989(0.1044) Steps 760(771.92) | Grad Norm 3.0835(3.9940) | Total Time 14.00(14.00)\n",
      "Iter 11200 | Time 19.4953(18.9679) | Bit/dim 3.6077(3.5880) | Xent 0.2197(0.2818) | Loss 3.7175(3.7289) | Error 0.0756(0.1008) Steps 784(772.90) | Grad Norm 2.0448(3.7379) | Total Time 14.00(14.00)\n",
      "Iter 11210 | Time 19.3288(19.0707) | Bit/dim 3.5611(3.5868) | Xent 0.2435(0.2700) | Loss 3.6828(3.7217) | Error 0.0767(0.0959) Steps 760(774.30) | Grad Norm 2.4071(3.5017) | Total Time 14.00(14.00)\n",
      "Iter 11220 | Time 19.3823(19.1340) | Bit/dim 3.6042(3.5862) | Xent 0.2667(0.2657) | Loss 3.7376(3.7190) | Error 0.0900(0.0955) Steps 784(776.22) | Grad Norm 3.3927(3.3850) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0204 | Time 93.8362, Epoch Time 1162.9775(1080.3018), Bit/dim 3.5875(best: 3.5873), Xent 0.7722, Loss 3.9735, Error 0.2157(best: 0.2166)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11230 | Time 18.8662(19.1725) | Bit/dim 3.5591(3.5859) | Xent 0.2232(0.2560) | Loss 3.6707(3.7139) | Error 0.0778(0.0912) Steps 784(778.97) | Grad Norm 2.4318(3.1535) | Total Time 14.00(14.00)\n",
      "Iter 11240 | Time 19.1135(19.1979) | Bit/dim 3.5907(3.5859) | Xent 0.2850(0.2518) | Loss 3.7332(3.7118) | Error 0.1033(0.0900) Steps 784(778.27) | Grad Norm 3.5550(3.1572) | Total Time 14.00(14.00)\n",
      "Iter 11250 | Time 19.2088(19.2300) | Bit/dim 3.5572(3.5834) | Xent 0.2268(0.2490) | Loss 3.6705(3.7079) | Error 0.0789(0.0887) Steps 754(777.50) | Grad Norm 3.7135(3.1650) | Total Time 14.00(14.00)\n",
      "Iter 11260 | Time 18.9605(19.2415) | Bit/dim 3.5664(3.5830) | Xent 0.2176(0.2523) | Loss 3.6752(3.7091) | Error 0.0833(0.0899) Steps 790(779.40) | Grad Norm 3.0902(3.2671) | Total Time 14.00(14.00)\n",
      "Iter 11270 | Time 19.3057(19.2991) | Bit/dim 3.5847(3.5862) | Xent 0.2506(0.2514) | Loss 3.7100(3.7118) | Error 0.0889(0.0895) Steps 772(779.11) | Grad Norm 3.3863(3.5571) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0205 | Time 90.5172, Epoch Time 1170.6529(1083.0123), Bit/dim 3.5921(best: 3.5873), Xent 0.7998, Loss 3.9920, Error 0.2247(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11280 | Time 20.0713(19.2780) | Bit/dim 3.6001(3.5868) | Xent 0.2700(0.2509) | Loss 3.7351(3.7122) | Error 0.0878(0.0893) Steps 790(778.52) | Grad Norm 4.0684(3.6168) | Total Time 14.00(14.00)\n",
      "Iter 11290 | Time 20.0626(19.3345) | Bit/dim 3.6119(3.5836) | Xent 0.3158(0.2582) | Loss 3.7698(3.7127) | Error 0.1044(0.0922) Steps 790(780.05) | Grad Norm 5.6202(4.0213) | Total Time 14.00(14.00)\n",
      "Iter 11300 | Time 19.5989(19.3445) | Bit/dim 3.5756(3.5875) | Xent 0.2283(0.2579) | Loss 3.6897(3.7164) | Error 0.0867(0.0920) Steps 796(780.90) | Grad Norm 4.0936(3.9547) | Total Time 14.00(14.00)\n",
      "Iter 11310 | Time 19.8231(19.3234) | Bit/dim 3.5976(3.5874) | Xent 0.2650(0.2597) | Loss 3.7301(3.7172) | Error 0.0922(0.0926) Steps 772(782.36) | Grad Norm 4.2369(3.8280) | Total Time 14.00(14.00)\n",
      "Iter 11320 | Time 19.6895(19.3557) | Bit/dim 3.6020(3.5861) | Xent 0.2683(0.2604) | Loss 3.7361(3.7163) | Error 0.1000(0.0931) Steps 784(784.30) | Grad Norm 2.8871(3.7648) | Total Time 14.00(14.00)\n",
      "Iter 11330 | Time 19.1171(19.2819) | Bit/dim 3.5906(3.5848) | Xent 0.2945(0.2615) | Loss 3.7378(3.7155) | Error 0.1156(0.0938) Steps 784(783.53) | Grad Norm 4.5900(3.8237) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0206 | Time 94.0821, Epoch Time 1173.9142(1085.7393), Bit/dim 3.5915(best: 3.5873), Xent 0.8041, Loss 3.9935, Error 0.2231(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11340 | Time 19.3344(19.2445) | Bit/dim 3.5746(3.5851) | Xent 0.2915(0.2579) | Loss 3.7203(3.7140) | Error 0.1000(0.0927) Steps 808(782.40) | Grad Norm 3.0208(3.7043) | Total Time 14.00(14.00)\n",
      "Iter 11350 | Time 20.1580(19.2315) | Bit/dim 3.5709(3.5819) | Xent 0.2565(0.2569) | Loss 3.6992(3.7104) | Error 0.0933(0.0930) Steps 796(782.88) | Grad Norm 2.8163(3.6084) | Total Time 14.00(14.00)\n",
      "Iter 11360 | Time 19.0088(19.2351) | Bit/dim 3.5711(3.5810) | Xent 0.2793(0.2729) | Loss 3.7108(3.7175) | Error 0.1078(0.0986) Steps 784(784.37) | Grad Norm 4.0840(3.9440) | Total Time 14.00(14.00)\n",
      "Iter 11370 | Time 19.4223(19.2723) | Bit/dim 3.5656(3.5854) | Xent 0.2347(0.2716) | Loss 3.6830(3.7212) | Error 0.0889(0.0981) Steps 802(784.84) | Grad Norm 2.8171(3.7459) | Total Time 14.00(14.00)\n",
      "Iter 11380 | Time 18.9646(19.2443) | Bit/dim 3.5286(3.5829) | Xent 0.2329(0.2637) | Loss 3.6450(3.7148) | Error 0.0800(0.0947) Steps 766(783.08) | Grad Norm 2.5602(3.5911) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0207 | Time 93.6087, Epoch Time 1170.4491(1088.2806), Bit/dim 3.5865(best: 3.5873), Xent 0.8159, Loss 3.9945, Error 0.2231(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11390 | Time 19.4946(19.2957) | Bit/dim 3.5768(3.5840) | Xent 0.2520(0.2579) | Loss 3.7028(3.7129) | Error 0.0833(0.0920) Steps 790(784.18) | Grad Norm 4.6869(3.6246) | Total Time 14.00(14.00)\n",
      "Iter 11400 | Time 18.9121(19.2976) | Bit/dim 3.6509(3.5844) | Xent 0.2248(0.2534) | Loss 3.7633(3.7111) | Error 0.0811(0.0913) Steps 802(785.27) | Grad Norm 4.2483(3.5758) | Total Time 14.00(14.00)\n",
      "Iter 11410 | Time 18.8597(19.3065) | Bit/dim 3.5610(3.5827) | Xent 0.3244(0.2569) | Loss 3.7232(3.7112) | Error 0.1122(0.0916) Steps 766(784.80) | Grad Norm 4.4115(3.6064) | Total Time 14.00(14.00)\n",
      "Iter 11420 | Time 17.9639(19.2615) | Bit/dim 3.6214(3.5843) | Xent 0.2913(0.2583) | Loss 3.7671(3.7134) | Error 0.0978(0.0922) Steps 766(784.32) | Grad Norm 3.9219(3.7151) | Total Time 14.00(14.00)\n",
      "Iter 11430 | Time 19.0861(19.2876) | Bit/dim 3.5787(3.5859) | Xent 0.2610(0.2541) | Loss 3.7091(3.7129) | Error 0.0900(0.0908) Steps 772(786.73) | Grad Norm 3.8257(3.5762) | Total Time 14.00(14.00)\n",
      "Iter 11440 | Time 19.8814(19.3761) | Bit/dim 3.6180(3.5851) | Xent 0.2775(0.2587) | Loss 3.7568(3.7144) | Error 0.0978(0.0926) Steps 802(786.38) | Grad Norm 5.1410(3.6972) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0208 | Time 95.1366, Epoch Time 1178.0865(1090.9748), Bit/dim 3.5945(best: 3.5865), Xent 0.8421, Loss 4.0156, Error 0.2279(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11450 | Time 19.5418(19.4109) | Bit/dim 3.6095(3.5867) | Xent 0.2483(0.2559) | Loss 3.7337(3.7147) | Error 0.0956(0.0911) Steps 796(788.91) | Grad Norm 2.5969(3.5913) | Total Time 14.00(14.00)\n",
      "Iter 11460 | Time 19.0131(19.3500) | Bit/dim 3.5819(3.5857) | Xent 0.3064(0.2556) | Loss 3.7352(3.7135) | Error 0.1089(0.0913) Steps 784(790.42) | Grad Norm 4.2280(3.5706) | Total Time 14.00(14.00)\n",
      "Iter 11470 | Time 19.5960(19.3936) | Bit/dim 3.5572(3.5837) | Xent 0.3056(0.2548) | Loss 3.7100(3.7111) | Error 0.1067(0.0915) Steps 802(791.82) | Grad Norm 4.8036(3.7425) | Total Time 14.00(14.00)\n",
      "Iter 11480 | Time 19.7784(19.4771) | Bit/dim 3.5806(3.5823) | Xent 0.2724(0.2564) | Loss 3.7168(3.7105) | Error 0.0989(0.0920) Steps 808(792.31) | Grad Norm 5.9937(3.8252) | Total Time 14.00(14.00)\n",
      "Iter 11490 | Time 19.1799(19.4746) | Bit/dim 3.5672(3.5845) | Xent 0.2345(0.2586) | Loss 3.6844(3.7138) | Error 0.0789(0.0925) Steps 784(790.83) | Grad Norm 2.6616(3.8181) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0209 | Time 93.2368, Epoch Time 1179.5105(1093.6309), Bit/dim 3.5892(best: 3.5865), Xent 0.8171, Loss 3.9977, Error 0.2228(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11500 | Time 19.2230(19.3878) | Bit/dim 3.6165(3.5855) | Xent 0.2182(0.2548) | Loss 3.7256(3.7130) | Error 0.0744(0.0911) Steps 796(790.02) | Grad Norm 3.4891(3.7022) | Total Time 14.00(14.00)\n",
      "Iter 11510 | Time 19.0840(19.3705) | Bit/dim 3.5769(3.5863) | Xent 0.2136(0.2459) | Loss 3.6837(3.7093) | Error 0.0689(0.0883) Steps 784(792.03) | Grad Norm 2.6542(3.5748) | Total Time 14.00(14.00)\n",
      "Iter 11520 | Time 18.7977(19.3987) | Bit/dim 3.5845(3.5846) | Xent 0.2214(0.2445) | Loss 3.6952(3.7069) | Error 0.0811(0.0867) Steps 790(790.19) | Grad Norm 1.7367(3.5347) | Total Time 14.00(14.00)\n",
      "Iter 11530 | Time 19.0873(19.3727) | Bit/dim 3.5585(3.5827) | Xent 0.2525(0.2504) | Loss 3.6847(3.7079) | Error 0.0889(0.0891) Steps 796(790.16) | Grad Norm 4.6793(3.7139) | Total Time 14.00(14.00)\n",
      "Iter 11540 | Time 19.0174(19.3619) | Bit/dim 3.5672(3.5811) | Xent 0.2699(0.2511) | Loss 3.7022(3.7067) | Error 0.0933(0.0893) Steps 802(790.66) | Grad Norm 3.7304(3.8934) | Total Time 14.00(14.00)\n",
      "Iter 11550 | Time 20.2144(19.4210) | Bit/dim 3.5652(3.5808) | Xent 0.2827(0.2519) | Loss 3.7065(3.7068) | Error 0.0989(0.0894) Steps 790(792.80) | Grad Norm 3.3939(3.7487) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0210 | Time 94.9569, Epoch Time 1179.5655(1096.2089), Bit/dim 3.5868(best: 3.5865), Xent 0.8300, Loss 4.0018, Error 0.2266(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11560 | Time 19.1419(19.3990) | Bit/dim 3.5531(3.5804) | Xent 0.1973(0.2427) | Loss 3.6518(3.7017) | Error 0.0767(0.0863) Steps 778(792.17) | Grad Norm 3.7221(3.5928) | Total Time 14.00(14.00)\n",
      "Iter 11570 | Time 19.4491(19.4703) | Bit/dim 3.6018(3.5801) | Xent 0.2268(0.2375) | Loss 3.7152(3.6989) | Error 0.0867(0.0847) Steps 826(795.62) | Grad Norm 3.9726(3.4459) | Total Time 14.00(14.00)\n",
      "Iter 11580 | Time 19.5534(19.5043) | Bit/dim 3.5709(3.5802) | Xent 0.2563(0.2384) | Loss 3.6990(3.6994) | Error 0.0911(0.0849) Steps 790(796.36) | Grad Norm 3.6866(3.4258) | Total Time 14.00(14.00)\n",
      "Iter 11590 | Time 19.6067(19.4942) | Bit/dim 3.6204(3.5818) | Xent 0.3290(0.2486) | Loss 3.7849(3.7061) | Error 0.1100(0.0882) Steps 820(797.36) | Grad Norm 6.8939(3.7798) | Total Time 14.00(14.00)\n",
      "Iter 11600 | Time 19.7878(19.3931) | Bit/dim 3.5862(3.5839) | Xent 0.2589(0.2556) | Loss 3.7156(3.7116) | Error 0.0978(0.0909) Steps 796(795.87) | Grad Norm 2.7031(3.8614) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0211 | Time 94.2251, Epoch Time 1181.7921(1098.7764), Bit/dim 3.5934(best: 3.5865), Xent 0.7984, Loss 3.9926, Error 0.2222(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11610 | Time 19.2709(19.4429) | Bit/dim 3.5669(3.5843) | Xent 0.2653(0.2553) | Loss 3.6996(3.7119) | Error 0.0889(0.0903) Steps 808(796.94) | Grad Norm 4.5346(3.7057) | Total Time 14.00(14.00)\n",
      "Iter 11620 | Time 18.9554(19.4575) | Bit/dim 3.5588(3.5829) | Xent 0.2548(0.2505) | Loss 3.6862(3.7082) | Error 0.0867(0.0889) Steps 802(799.88) | Grad Norm 3.1317(3.7212) | Total Time 14.00(14.00)\n",
      "Iter 11630 | Time 19.6271(19.4451) | Bit/dim 3.5816(3.5837) | Xent 0.3135(0.2553) | Loss 3.7383(3.7113) | Error 0.1111(0.0908) Steps 796(800.55) | Grad Norm 6.2719(3.7953) | Total Time 14.00(14.00)\n",
      "Iter 11640 | Time 19.6614(19.5134) | Bit/dim 3.6033(3.5848) | Xent 0.3183(0.2736) | Loss 3.7625(3.7216) | Error 0.1167(0.0972) Steps 814(800.33) | Grad Norm 7.2084(4.4977) | Total Time 14.00(14.00)\n",
      "Iter 11650 | Time 19.1956(19.4738) | Bit/dim 3.5632(3.5861) | Xent 0.2336(0.2793) | Loss 3.6800(3.7257) | Error 0.0833(0.0990) Steps 778(798.27) | Grad Norm 2.4673(4.3935) | Total Time 14.00(14.00)\n",
      "Iter 11660 | Time 18.9274(19.4869) | Bit/dim 3.5813(3.5852) | Xent 0.2690(0.2762) | Loss 3.7158(3.7233) | Error 0.1056(0.0981) Steps 796(797.92) | Grad Norm 3.3422(4.1919) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0212 | Time 94.3266, Epoch Time 1185.1151(1101.3666), Bit/dim 3.5840(best: 3.5865), Xent 0.8008, Loss 3.9844, Error 0.2218(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11670 | Time 19.7267(19.4159) | Bit/dim 3.6112(3.5817) | Xent 0.2190(0.2627) | Loss 3.7207(3.7130) | Error 0.0822(0.0936) Steps 796(797.57) | Grad Norm 3.6203(3.8341) | Total Time 14.00(14.00)\n",
      "Iter 11680 | Time 19.7029(19.3471) | Bit/dim 3.5680(3.5777) | Xent 0.2172(0.2497) | Loss 3.6766(3.7026) | Error 0.0822(0.0888) Steps 790(795.67) | Grad Norm 2.0306(3.5588) | Total Time 14.00(14.00)\n",
      "Iter 11690 | Time 19.3199(19.3311) | Bit/dim 3.5682(3.5804) | Xent 0.2659(0.2462) | Loss 3.7011(3.7035) | Error 0.0989(0.0870) Steps 796(795.03) | Grad Norm 4.2656(3.4918) | Total Time 14.00(14.00)\n",
      "Iter 11700 | Time 19.4870(19.3775) | Bit/dim 3.5687(3.5808) | Xent 0.2507(0.2479) | Loss 3.6940(3.7047) | Error 0.0856(0.0873) Steps 790(794.33) | Grad Norm 3.5784(3.5410) | Total Time 14.00(14.00)\n",
      "Iter 11710 | Time 19.7549(19.3604) | Bit/dim 3.6117(3.5848) | Xent 0.2311(0.2553) | Loss 3.7272(3.7124) | Error 0.0944(0.0912) Steps 802(794.15) | Grad Norm 3.5889(3.7953) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0213 | Time 94.5982, Epoch Time 1173.9769(1103.5449), Bit/dim 3.5916(best: 3.5840), Xent 0.8331, Loss 4.0081, Error 0.2221(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11720 | Time 18.9904(19.3587) | Bit/dim 3.5858(3.5849) | Xent 0.2692(0.2540) | Loss 3.7204(3.7119) | Error 0.1000(0.0912) Steps 784(793.93) | Grad Norm 4.2604(3.8921) | Total Time 14.00(14.00)\n",
      "Iter 11730 | Time 19.7992(19.3686) | Bit/dim 3.5847(3.5846) | Xent 0.2937(0.2527) | Loss 3.7316(3.7109) | Error 0.1022(0.0901) Steps 796(793.80) | Grad Norm 3.4348(3.6791) | Total Time 14.00(14.00)\n",
      "Iter 11740 | Time 18.9768(19.3293) | Bit/dim 3.5969(3.5815) | Xent 0.2756(0.2583) | Loss 3.7347(3.7106) | Error 0.0989(0.0926) Steps 808(793.62) | Grad Norm 5.1684(3.8046) | Total Time 14.00(14.00)\n",
      "Iter 11750 | Time 19.3725(19.3393) | Bit/dim 3.5689(3.5837) | Xent 0.3137(0.2599) | Loss 3.7257(3.7136) | Error 0.1122(0.0935) Steps 820(795.64) | Grad Norm 6.0070(3.7412) | Total Time 14.00(14.00)\n",
      "Iter 11760 | Time 19.6634(19.3166) | Bit/dim 3.5964(3.5836) | Xent 0.2720(0.2669) | Loss 3.7324(3.7170) | Error 0.0922(0.0968) Steps 790(795.53) | Grad Norm 3.8939(4.0104) | Total Time 14.00(14.00)\n",
      "Iter 11770 | Time 19.6202(19.3550) | Bit/dim 3.5667(3.5842) | Xent 0.3171(0.2741) | Loss 3.7252(3.7212) | Error 0.1033(0.0985) Steps 826(796.89) | Grad Norm 5.2919(4.1778) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0214 | Time 94.3810, Epoch Time 1175.8355(1105.7136), Bit/dim 3.5942(best: 3.5840), Xent 0.8391, Loss 4.0137, Error 0.2279(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11780 | Time 18.8794(19.3363) | Bit/dim 3.5749(3.5883) | Xent 0.2515(0.2764) | Loss 3.7007(3.7265) | Error 0.0956(0.0990) Steps 796(796.00) | Grad Norm 3.9633(4.5552) | Total Time 14.00(14.00)\n",
      "Iter 11790 | Time 19.9558(19.3706) | Bit/dim 3.5867(3.5885) | Xent 0.3052(0.2803) | Loss 3.7393(3.7286) | Error 0.1000(0.1000) Steps 778(795.50) | Grad Norm 4.2055(4.6410) | Total Time 14.00(14.00)\n",
      "Iter 11800 | Time 18.5104(19.3638) | Bit/dim 3.5814(3.5859) | Xent 0.2419(0.2780) | Loss 3.7023(3.7249) | Error 0.0800(0.0992) Steps 784(795.82) | Grad Norm 3.6485(4.4808) | Total Time 14.00(14.00)\n",
      "Iter 11810 | Time 19.8698(19.4250) | Bit/dim 3.5733(3.5854) | Xent 0.2631(0.2747) | Loss 3.7049(3.7228) | Error 0.1022(0.0982) Steps 790(793.63) | Grad Norm 2.4480(4.3266) | Total Time 14.00(14.00)\n",
      "Iter 11820 | Time 19.3044(19.4286) | Bit/dim 3.5428(3.5834) | Xent 0.2038(0.2659) | Loss 3.6447(3.7164) | Error 0.0756(0.0949) Steps 784(791.94) | Grad Norm 1.8759(3.9888) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0215 | Time 94.6171, Epoch Time 1181.4834(1107.9867), Bit/dim 3.5845(best: 3.5840), Xent 0.8139, Loss 3.9914, Error 0.2235(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11830 | Time 19.4240(19.4508) | Bit/dim 3.5732(3.5829) | Xent 0.1905(0.2576) | Loss 3.6684(3.7117) | Error 0.0644(0.0918) Steps 802(793.84) | Grad Norm 2.3935(3.7104) | Total Time 14.00(14.00)\n",
      "Iter 11840 | Time 19.4450(19.4677) | Bit/dim 3.5882(3.5830) | Xent 0.2375(0.2458) | Loss 3.7070(3.7059) | Error 0.0822(0.0866) Steps 808(795.19) | Grad Norm 4.7702(3.5627) | Total Time 14.00(14.00)\n",
      "Iter 11850 | Time 19.5002(19.4666) | Bit/dim 3.5867(3.5854) | Xent 0.2385(0.2429) | Loss 3.7060(3.7068) | Error 0.0956(0.0866) Steps 826(796.11) | Grad Norm 4.9755(3.6883) | Total Time 14.00(14.00)\n",
      "Iter 11860 | Time 20.5105(19.5472) | Bit/dim 3.5919(3.5862) | Xent 0.2365(0.2387) | Loss 3.7101(3.7055) | Error 0.0756(0.0856) Steps 838(797.27) | Grad Norm 2.7441(3.5875) | Total Time 14.00(14.00)\n",
      "Iter 11870 | Time 19.4720(19.5008) | Bit/dim 3.5690(3.5819) | Xent 0.2023(0.2381) | Loss 3.6701(3.7010) | Error 0.0744(0.0859) Steps 790(798.33) | Grad Norm 3.1488(3.4424) | Total Time 14.00(14.00)\n",
      "Iter 11880 | Time 19.7509(19.5141) | Bit/dim 3.5845(3.5786) | Xent 0.3153(0.2443) | Loss 3.7422(3.7008) | Error 0.1200(0.0884) Steps 796(800.08) | Grad Norm 5.1254(3.7096) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0216 | Time 96.1011, Epoch Time 1187.9444(1110.3854), Bit/dim 3.5874(best: 3.5840), Xent 0.7942, Loss 3.9845, Error 0.2233(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11890 | Time 19.2459(19.4958) | Bit/dim 3.5958(3.5801) | Xent 0.2051(0.2383) | Loss 3.6983(3.6993) | Error 0.0778(0.0863) Steps 790(799.83) | Grad Norm 3.6476(3.7452) | Total Time 14.00(14.00)\n",
      "Iter 11900 | Time 19.5987(19.4880) | Bit/dim 3.5630(3.5793) | Xent 0.2083(0.2336) | Loss 3.6672(3.6961) | Error 0.0711(0.0839) Steps 790(798.36) | Grad Norm 1.9816(3.5070) | Total Time 14.00(14.00)\n",
      "Iter 11910 | Time 19.8840(19.4334) | Bit/dim 3.5662(3.5798) | Xent 0.2154(0.2379) | Loss 3.6739(3.6987) | Error 0.0856(0.0855) Steps 802(798.81) | Grad Norm 2.9685(3.4904) | Total Time 14.00(14.00)\n",
      "Iter 11920 | Time 19.0515(19.4593) | Bit/dim 3.5434(3.5768) | Xent 0.2317(0.2322) | Loss 3.6593(3.6929) | Error 0.0878(0.0834) Steps 796(800.56) | Grad Norm 3.7426(3.4010) | Total Time 14.00(14.00)\n",
      "Iter 11930 | Time 19.5916(19.4896) | Bit/dim 3.6005(3.5775) | Xent 0.2862(0.2370) | Loss 3.7435(3.6960) | Error 0.1033(0.0847) Steps 796(800.91) | Grad Norm 4.8295(3.4813) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0217 | Time 95.6998, Epoch Time 1184.5664(1112.6109), Bit/dim 3.5811(best: 3.5840), Xent 0.8165, Loss 3.9894, Error 0.2232(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 11940 | Time 19.6264(19.5655) | Bit/dim 3.5821(3.5791) | Xent 0.1732(0.2315) | Loss 3.6687(3.6948) | Error 0.0589(0.0836) Steps 784(800.71) | Grad Norm 2.0069(3.3561) | Total Time 14.00(14.00)\n",
      "Iter 11950 | Time 18.2983(19.4515) | Bit/dim 3.5667(3.5778) | Xent 0.3023(0.2293) | Loss 3.7179(3.6924) | Error 0.1078(0.0829) Steps 772(798.61) | Grad Norm 4.6609(3.3040) | Total Time 14.00(14.00)\n",
      "Iter 11960 | Time 19.7389(19.5304) | Bit/dim 3.5543(3.5766) | Xent 0.2892(0.2287) | Loss 3.6990(3.6910) | Error 0.0967(0.0817) Steps 784(800.72) | Grad Norm 5.5451(3.4444) | Total Time 14.00(14.00)\n",
      "Iter 11970 | Time 19.5434(19.4815) | Bit/dim 3.5905(3.5771) | Xent 0.2019(0.2294) | Loss 3.6915(3.6918) | Error 0.0756(0.0825) Steps 820(800.03) | Grad Norm 4.5120(3.4351) | Total Time 14.00(14.00)\n",
      "Iter 11980 | Time 19.4426(19.4308) | Bit/dim 3.5634(3.5780) | Xent 0.2548(0.2317) | Loss 3.6908(3.6938) | Error 0.0978(0.0825) Steps 790(797.15) | Grad Norm 4.9855(3.4789) | Total Time 14.00(14.00)\n",
      "Iter 11990 | Time 19.3116(19.3611) | Bit/dim 3.6052(3.5815) | Xent 0.2579(0.2375) | Loss 3.7342(3.7002) | Error 0.0878(0.0847) Steps 772(795.45) | Grad Norm 4.8264(3.7240) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0218 | Time 95.1166, Epoch Time 1179.1763(1114.6078), Bit/dim 3.5960(best: 3.5811), Xent 0.9226, Loss 4.0573, Error 0.2374(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12000 | Time 19.4629(19.3408) | Bit/dim 3.6232(3.5837) | Xent 0.3259(0.2436) | Loss 3.7861(3.7055) | Error 0.1211(0.0877) Steps 814(795.04) | Grad Norm 5.9690(4.0443) | Total Time 14.00(14.00)\n",
      "Iter 12010 | Time 19.4967(19.3888) | Bit/dim 3.6142(3.5846) | Xent 0.2241(0.2449) | Loss 3.7263(3.7070) | Error 0.0767(0.0872) Steps 796(795.35) | Grad Norm 3.9793(4.1125) | Total Time 14.00(14.00)\n",
      "Iter 12020 | Time 19.5259(19.4132) | Bit/dim 3.5724(3.5851) | Xent 0.2253(0.2406) | Loss 3.6851(3.7054) | Error 0.0800(0.0859) Steps 802(796.46) | Grad Norm 2.6045(4.0055) | Total Time 14.00(14.00)\n",
      "Iter 12030 | Time 19.3083(19.3762) | Bit/dim 3.5500(3.5837) | Xent 0.2040(0.2343) | Loss 3.6520(3.7009) | Error 0.0767(0.0842) Steps 778(796.12) | Grad Norm 3.3721(3.9578) | Total Time 14.00(14.00)\n",
      "Iter 12040 | Time 18.8430(19.3617) | Bit/dim 3.5581(3.5811) | Xent 0.2339(0.2333) | Loss 3.6750(3.6977) | Error 0.0844(0.0835) Steps 790(796.03) | Grad Norm 2.8139(3.7736) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0219 | Time 95.1635, Epoch Time 1180.1844(1116.5751), Bit/dim 3.5808(best: 3.5811), Xent 0.8249, Loss 3.9932, Error 0.2282(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12050 | Time 19.7743(19.3975) | Bit/dim 3.5940(3.5808) | Xent 0.1948(0.2327) | Loss 3.6914(3.6972) | Error 0.0700(0.0825) Steps 796(796.49) | Grad Norm 3.5632(3.6350) | Total Time 14.00(14.00)\n",
      "Iter 12060 | Time 19.6670(19.4347) | Bit/dim 3.5632(3.5793) | Xent 0.1858(0.2265) | Loss 3.6561(3.6926) | Error 0.0667(0.0799) Steps 784(799.01) | Grad Norm 3.1850(3.4877) | Total Time 14.00(14.00)\n",
      "Iter 12070 | Time 20.0258(19.5100) | Bit/dim 3.5848(3.5776) | Xent 0.2322(0.2249) | Loss 3.7009(3.6900) | Error 0.0867(0.0796) Steps 826(797.04) | Grad Norm 2.2142(3.4491) | Total Time 14.00(14.00)\n",
      "Iter 12080 | Time 19.2893(19.4732) | Bit/dim 3.6091(3.5791) | Xent 0.2582(0.2273) | Loss 3.7382(3.6927) | Error 0.0911(0.0808) Steps 796(796.72) | Grad Norm 3.9550(3.5901) | Total Time 14.00(14.00)\n",
      "Iter 12090 | Time 19.8696(19.4919) | Bit/dim 3.5906(3.5788) | Xent 0.2067(0.2319) | Loss 3.6940(3.6947) | Error 0.0756(0.0827) Steps 820(799.01) | Grad Norm 2.0485(3.5516) | Total Time 14.00(14.00)\n",
      "Iter 12100 | Time 19.5028(19.5156) | Bit/dim 3.5976(3.5789) | Xent 0.2649(0.2436) | Loss 3.7300(3.7007) | Error 0.0978(0.0877) Steps 790(799.19) | Grad Norm 5.3063(3.8148) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0220 | Time 96.0735, Epoch Time 1187.7253(1118.7096), Bit/dim 3.5888(best: 3.5808), Xent 0.8305, Loss 4.0040, Error 0.2251(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12110 | Time 20.6037(19.6012) | Bit/dim 3.5696(3.5795) | Xent 0.2246(0.2407) | Loss 3.6819(3.6998) | Error 0.0867(0.0869) Steps 808(800.16) | Grad Norm 5.0012(3.8268) | Total Time 14.00(14.00)\n",
      "Iter 12120 | Time 19.4979(19.5617) | Bit/dim 3.6067(3.5800) | Xent 0.2231(0.2381) | Loss 3.7183(3.6990) | Error 0.0833(0.0856) Steps 814(802.06) | Grad Norm 2.6024(3.6514) | Total Time 14.00(14.00)\n",
      "Iter 12130 | Time 19.9560(19.5718) | Bit/dim 3.5811(3.5790) | Xent 0.1887(0.2327) | Loss 3.6755(3.6954) | Error 0.0633(0.0833) Steps 796(801.30) | Grad Norm 1.9032(3.5024) | Total Time 14.00(14.00)\n",
      "Iter 12140 | Time 19.8294(19.6244) | Bit/dim 3.5592(3.5783) | Xent 0.2249(0.2313) | Loss 3.6717(3.6939) | Error 0.0811(0.0827) Steps 832(803.64) | Grad Norm 3.6202(3.3940) | Total Time 14.00(14.00)\n",
      "Iter 12150 | Time 20.2511(19.5858) | Bit/dim 3.5796(3.5792) | Xent 0.2552(0.2318) | Loss 3.7072(3.6951) | Error 0.0900(0.0831) Steps 820(802.72) | Grad Norm 3.3186(3.4087) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0221 | Time 95.4847, Epoch Time 1190.7144(1120.8698), Bit/dim 3.5929(best: 3.5808), Xent 0.9308, Loss 4.0583, Error 0.2429(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12160 | Time 19.5813(19.5844) | Bit/dim 3.5981(3.5792) | Xent 0.1771(0.2367) | Loss 3.6867(3.6976) | Error 0.0622(0.0852) Steps 802(801.70) | Grad Norm 2.2055(3.5885) | Total Time 14.00(14.00)\n",
      "Iter 12170 | Time 19.1480(19.5863) | Bit/dim 3.5527(3.5815) | Xent 0.2011(0.2306) | Loss 3.6533(3.6968) | Error 0.0678(0.0825) Steps 814(801.97) | Grad Norm 4.1079(3.5070) | Total Time 14.00(14.00)\n",
      "Iter 12180 | Time 19.5886(19.4890) | Bit/dim 3.5720(3.5792) | Xent 0.2554(0.2293) | Loss 3.6997(3.6938) | Error 0.0878(0.0825) Steps 784(801.41) | Grad Norm 6.2137(3.5930) | Total Time 14.00(14.00)\n",
      "Iter 12190 | Time 18.6597(19.4530) | Bit/dim 3.5633(3.5770) | Xent 0.2322(0.2312) | Loss 3.6794(3.6926) | Error 0.0822(0.0831) Steps 808(801.22) | Grad Norm 3.9371(3.6646) | Total Time 14.00(14.00)\n",
      "Iter 12200 | Time 18.8849(19.4834) | Bit/dim 3.6130(3.5795) | Xent 0.2373(0.2312) | Loss 3.7316(3.6951) | Error 0.0900(0.0830) Steps 796(800.13) | Grad Norm 4.5776(3.7349) | Total Time 14.00(14.00)\n",
      "Iter 12210 | Time 19.4261(19.5451) | Bit/dim 3.5546(3.5807) | Xent 0.3491(0.2382) | Loss 3.7291(3.6998) | Error 0.1189(0.0858) Steps 808(800.95) | Grad Norm 5.8209(3.9554) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0222 | Time 95.5379, Epoch Time 1187.0584(1122.8554), Bit/dim 3.5883(best: 3.5808), Xent 0.9004, Loss 4.0385, Error 0.2400(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12220 | Time 20.1830(19.5893) | Bit/dim 3.5796(3.5809) | Xent 0.2401(0.2412) | Loss 3.6997(3.7015) | Error 0.0811(0.0873) Steps 802(802.71) | Grad Norm 6.4010(4.1136) | Total Time 14.00(14.00)\n",
      "Iter 12230 | Time 18.8930(19.5320) | Bit/dim 3.5690(3.5796) | Xent 0.2657(0.2497) | Loss 3.7018(3.7044) | Error 0.0889(0.0896) Steps 778(801.51) | Grad Norm 4.7971(4.2970) | Total Time 14.00(14.00)\n",
      "Iter 12240 | Time 19.3413(19.5264) | Bit/dim 3.5633(3.5817) | Xent 0.2385(0.2518) | Loss 3.6826(3.7076) | Error 0.0867(0.0908) Steps 790(801.82) | Grad Norm 2.9962(4.1963) | Total Time 14.00(14.00)\n",
      "Iter 12250 | Time 20.5722(19.6073) | Bit/dim 3.5627(3.5838) | Xent 0.2519(0.2445) | Loss 3.6886(3.7060) | Error 0.0833(0.0880) Steps 832(801.38) | Grad Norm 3.1377(3.9307) | Total Time 14.00(14.00)\n",
      "Iter 12260 | Time 20.0850(19.6061) | Bit/dim 3.5895(3.5834) | Xent 0.1877(0.2363) | Loss 3.6834(3.7015) | Error 0.0667(0.0850) Steps 826(801.58) | Grad Norm 1.8658(3.5535) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0223 | Time 98.0695, Epoch Time 1197.6313(1125.0987), Bit/dim 3.5869(best: 3.5808), Xent 0.8658, Loss 4.0198, Error 0.2245(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12270 | Time 19.5410(19.7334) | Bit/dim 3.5463(3.5807) | Xent 0.1890(0.2275) | Loss 3.6408(3.6945) | Error 0.0667(0.0815) Steps 808(803.56) | Grad Norm 2.8075(3.4184) | Total Time 14.00(14.00)\n",
      "Iter 12280 | Time 19.3929(19.7039) | Bit/dim 3.5633(3.5806) | Xent 0.2735(0.2294) | Loss 3.7001(3.6953) | Error 0.0967(0.0820) Steps 796(804.20) | Grad Norm 4.7633(3.6392) | Total Time 14.00(14.00)\n",
      "Iter 12290 | Time 20.3239(19.6649) | Bit/dim 3.5482(3.5813) | Xent 0.2183(0.2322) | Loss 3.6574(3.6974) | Error 0.0822(0.0834) Steps 826(806.22) | Grad Norm 3.8357(3.8009) | Total Time 14.00(14.00)\n",
      "Iter 12300 | Time 19.8836(19.6891) | Bit/dim 3.5848(3.5819) | Xent 0.2533(0.2342) | Loss 3.7115(3.6990) | Error 0.0944(0.0837) Steps 808(805.43) | Grad Norm 4.0690(3.6941) | Total Time 14.00(14.00)\n",
      "Iter 12310 | Time 18.5057(19.6670) | Bit/dim 3.5761(3.5811) | Xent 0.2331(0.2416) | Loss 3.6927(3.7019) | Error 0.0778(0.0866) Steps 790(805.93) | Grad Norm 3.8662(3.9406) | Total Time 14.00(14.00)\n",
      "Iter 12320 | Time 20.0484(19.7084) | Bit/dim 3.5792(3.5811) | Xent 0.2585(0.2470) | Loss 3.7084(3.7046) | Error 0.0922(0.0897) Steps 832(807.95) | Grad Norm 4.6506(3.9082) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0224 | Time 97.6853, Epoch Time 1198.3138(1127.2952), Bit/dim 3.5866(best: 3.5808), Xent 0.8564, Loss 4.0148, Error 0.2270(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12330 | Time 19.1065(19.7255) | Bit/dim 3.5978(3.5824) | Xent 0.2010(0.2402) | Loss 3.6982(3.7025) | Error 0.0744(0.0875) Steps 814(809.92) | Grad Norm 3.1218(3.9768) | Total Time 14.00(14.00)\n",
      "Iter 12340 | Time 20.1396(19.7339) | Bit/dim 3.5610(3.5819) | Xent 0.1915(0.2337) | Loss 3.6568(3.6988) | Error 0.0700(0.0851) Steps 796(809.79) | Grad Norm 2.9646(3.8927) | Total Time 14.00(14.00)\n",
      "Iter 12350 | Time 19.7542(19.7888) | Bit/dim 3.5948(3.5797) | Xent 0.2158(0.2265) | Loss 3.7027(3.6929) | Error 0.0689(0.0811) Steps 814(810.84) | Grad Norm 3.4467(3.6168) | Total Time 14.00(14.00)\n",
      "Iter 12360 | Time 20.0239(19.7487) | Bit/dim 3.5653(3.5790) | Xent 0.2364(0.2331) | Loss 3.6835(3.6956) | Error 0.0878(0.0834) Steps 796(810.00) | Grad Norm 2.9345(3.7648) | Total Time 14.00(14.00)\n",
      "Iter 12370 | Time 18.8699(19.7011) | Bit/dim 3.6384(3.5803) | Xent 0.2241(0.2453) | Loss 3.7505(3.7030) | Error 0.0744(0.0870) Steps 796(807.61) | Grad Norm 3.0735(3.9332) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0225 | Time 97.9292, Epoch Time 1201.6043(1129.5244), Bit/dim 3.5867(best: 3.5808), Xent 0.8214, Loss 3.9974, Error 0.2196(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12380 | Time 20.2062(19.7383) | Bit/dim 3.5932(3.5809) | Xent 0.1813(0.2353) | Loss 3.6839(3.6986) | Error 0.0667(0.0834) Steps 808(808.58) | Grad Norm 1.7182(3.5849) | Total Time 14.00(14.00)\n",
      "Iter 12390 | Time 19.7400(19.8216) | Bit/dim 3.5635(3.5781) | Xent 0.2335(0.2239) | Loss 3.6802(3.6900) | Error 0.0811(0.0797) Steps 808(810.27) | Grad Norm 2.5728(3.2045) | Total Time 14.00(14.00)\n",
      "Iter 12400 | Time 19.8748(19.8024) | Bit/dim 3.6162(3.5780) | Xent 0.1920(0.2188) | Loss 3.7122(3.6874) | Error 0.0656(0.0777) Steps 832(812.41) | Grad Norm 2.7739(3.0871) | Total Time 14.00(14.00)\n",
      "Iter 12410 | Time 19.9102(19.7660) | Bit/dim 3.5841(3.5780) | Xent 0.2014(0.2093) | Loss 3.6848(3.6827) | Error 0.0656(0.0736) Steps 820(811.11) | Grad Norm 2.2825(2.9075) | Total Time 14.00(14.00)\n",
      "Iter 12420 | Time 20.2960(19.9118) | Bit/dim 3.5595(3.5727) | Xent 0.2266(0.2072) | Loss 3.6728(3.6763) | Error 0.0856(0.0740) Steps 832(815.67) | Grad Norm 3.7234(2.9131) | Total Time 14.00(14.00)\n",
      "Iter 12430 | Time 20.0839(19.9176) | Bit/dim 3.5796(3.5720) | Xent 0.1893(0.2069) | Loss 3.6743(3.6755) | Error 0.0633(0.0738) Steps 784(812.08) | Grad Norm 2.6170(2.9526) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0226 | Time 96.9612, Epoch Time 1210.6027(1131.9568), Bit/dim 3.5814(best: 3.5808), Xent 0.8797, Loss 4.0212, Error 0.2287(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12440 | Time 19.7147(19.8328) | Bit/dim 3.5762(3.5732) | Xent 0.2102(0.2131) | Loss 3.6813(3.6797) | Error 0.0822(0.0763) Steps 814(812.31) | Grad Norm 4.5924(3.3430) | Total Time 14.00(14.00)\n",
      "Iter 12450 | Time 19.9861(19.8629) | Bit/dim 3.5447(3.5725) | Xent 0.2253(0.2138) | Loss 3.6574(3.6794) | Error 0.0778(0.0768) Steps 808(812.73) | Grad Norm 4.5953(3.3206) | Total Time 14.00(14.00)\n",
      "Iter 12460 | Time 20.5420(19.9626) | Bit/dim 3.5851(3.5748) | Xent 0.1980(0.2147) | Loss 3.6841(3.6822) | Error 0.0667(0.0770) Steps 844(814.21) | Grad Norm 3.9058(3.4634) | Total Time 14.00(14.00)\n",
      "Iter 12470 | Time 19.4865(19.9595) | Bit/dim 3.5829(3.5749) | Xent 0.2719(0.2204) | Loss 3.7189(3.6850) | Error 0.1033(0.0793) Steps 808(812.07) | Grad Norm 4.1079(3.5332) | Total Time 14.00(14.00)\n",
      "Iter 12480 | Time 20.2068(19.8883) | Bit/dim 3.5688(3.5775) | Xent 0.2533(0.2283) | Loss 3.6955(3.6916) | Error 0.0911(0.0827) Steps 826(812.49) | Grad Norm 4.0091(3.7705) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0227 | Time 99.4533, Epoch Time 1211.7430(1134.3504), Bit/dim 3.5873(best: 3.5808), Xent 0.8803, Loss 4.0275, Error 0.2364(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12490 | Time 19.5241(19.8475) | Bit/dim 3.5959(3.5806) | Xent 0.2257(0.2340) | Loss 3.7088(3.6976) | Error 0.0822(0.0844) Steps 814(813.26) | Grad Norm 3.1079(3.9473) | Total Time 14.00(14.00)\n",
      "Iter 12500 | Time 19.7649(19.8537) | Bit/dim 3.5439(3.5804) | Xent 0.2045(0.2256) | Loss 3.6461(3.6932) | Error 0.0756(0.0810) Steps 802(815.02) | Grad Norm 2.4892(3.6554) | Total Time 14.00(14.00)\n",
      "Iter 12510 | Time 20.0276(19.9064) | Bit/dim 3.5628(3.5767) | Xent 0.2028(0.2205) | Loss 3.6642(3.6869) | Error 0.0856(0.0795) Steps 820(816.43) | Grad Norm 2.7583(3.4693) | Total Time 14.00(14.00)\n",
      "Iter 12520 | Time 19.6625(19.9049) | Bit/dim 3.5621(3.5778) | Xent 0.1919(0.2140) | Loss 3.6581(3.6847) | Error 0.0667(0.0772) Steps 796(814.58) | Grad Norm 2.9696(3.3141) | Total Time 14.00(14.00)\n",
      "Iter 12530 | Time 19.5184(19.8920) | Bit/dim 3.6012(3.5765) | Xent 0.2263(0.2149) | Loss 3.7143(3.6840) | Error 0.0833(0.0773) Steps 796(812.88) | Grad Norm 3.8616(3.3219) | Total Time 14.00(14.00)\n",
      "Iter 12540 | Time 19.3200(19.8020) | Bit/dim 3.5514(3.5767) | Xent 0.2330(0.2240) | Loss 3.6679(3.6888) | Error 0.0789(0.0800) Steps 790(810.52) | Grad Norm 2.8868(3.5919) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0228 | Time 98.6820, Epoch Time 1205.8783(1136.4962), Bit/dim 3.5835(best: 3.5808), Xent 0.8965, Loss 4.0318, Error 0.2362(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12550 | Time 19.2862(19.7470) | Bit/dim 3.5636(3.5771) | Xent 0.2227(0.2238) | Loss 3.6750(3.6890) | Error 0.0900(0.0807) Steps 802(811.15) | Grad Norm 3.8524(3.6172) | Total Time 14.00(14.00)\n",
      "Iter 12560 | Time 19.3995(19.7870) | Bit/dim 3.5954(3.5806) | Xent 0.2073(0.2217) | Loss 3.6991(3.6914) | Error 0.0767(0.0801) Steps 820(813.01) | Grad Norm 2.2190(3.6634) | Total Time 14.00(14.00)\n",
      "Iter 12570 | Time 19.4682(19.6855) | Bit/dim 3.5622(3.5810) | Xent 0.2045(0.2168) | Loss 3.6644(3.6894) | Error 0.0733(0.0785) Steps 808(813.08) | Grad Norm 2.8901(3.5237) | Total Time 14.00(14.00)\n",
      "Iter 12580 | Time 19.4928(19.6162) | Bit/dim 3.5846(3.5804) | Xent 0.2077(0.2153) | Loss 3.6884(3.6880) | Error 0.0744(0.0784) Steps 802(810.62) | Grad Norm 3.8529(3.4878) | Total Time 14.00(14.00)\n",
      "Iter 12590 | Time 19.3486(19.6283) | Bit/dim 3.6119(3.5776) | Xent 0.2481(0.2210) | Loss 3.7359(3.6881) | Error 0.0856(0.0802) Steps 814(812.20) | Grad Norm 4.4796(3.7149) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0229 | Time 98.0973, Epoch Time 1194.0495(1138.2228), Bit/dim 3.5828(best: 3.5808), Xent 0.8614, Loss 4.0135, Error 0.2291(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12600 | Time 20.0723(19.6422) | Bit/dim 3.5569(3.5745) | Xent 0.2116(0.2246) | Loss 3.6627(3.6868) | Error 0.0689(0.0808) Steps 826(810.72) | Grad Norm 2.7926(3.7792) | Total Time 14.00(14.00)\n",
      "Iter 12610 | Time 19.6657(19.6975) | Bit/dim 3.5845(3.5755) | Xent 0.2022(0.2162) | Loss 3.6856(3.6836) | Error 0.0733(0.0769) Steps 808(812.99) | Grad Norm 3.3436(3.6387) | Total Time 14.00(14.00)\n",
      "Iter 12620 | Time 19.7823(19.7804) | Bit/dim 3.5724(3.5776) | Xent 0.2052(0.2129) | Loss 3.6750(3.6840) | Error 0.0789(0.0761) Steps 814(812.38) | Grad Norm 2.5547(3.5104) | Total Time 14.00(14.00)\n",
      "Iter 12630 | Time 20.2217(19.8427) | Bit/dim 3.5936(3.5751) | Xent 0.1728(0.2096) | Loss 3.6800(3.6799) | Error 0.0700(0.0758) Steps 820(811.54) | Grad Norm 2.6558(3.4023) | Total Time 14.00(14.00)\n",
      "Iter 12640 | Time 20.5314(19.9511) | Bit/dim 3.5738(3.5760) | Xent 0.2471(0.2135) | Loss 3.6974(3.6828) | Error 0.0889(0.0767) Steps 808(815.57) | Grad Norm 3.7963(3.4357) | Total Time 14.00(14.00)\n",
      "Iter 12650 | Time 19.4994(19.9644) | Bit/dim 3.6090(3.5770) | Xent 0.2811(0.2213) | Loss 3.7495(3.6876) | Error 0.0956(0.0788) Steps 814(816.98) | Grad Norm 4.6568(3.5906) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0230 | Time 101.8594, Epoch Time 1219.9458(1140.6745), Bit/dim 3.5808(best: 3.5808), Xent 0.8625, Loss 4.0120, Error 0.2289(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12660 | Time 19.5152(19.9284) | Bit/dim 3.6119(3.5807) | Xent 0.1962(0.2252) | Loss 3.7100(3.6933) | Error 0.0656(0.0791) Steps 832(819.56) | Grad Norm 2.9203(3.6418) | Total Time 14.00(14.00)\n",
      "Iter 12670 | Time 19.7781(20.0201) | Bit/dim 3.5724(3.5775) | Xent 0.2169(0.2225) | Loss 3.6809(3.6888) | Error 0.0733(0.0785) Steps 808(817.70) | Grad Norm 3.6197(3.7778) | Total Time 14.00(14.00)\n",
      "Iter 12680 | Time 19.5108(20.0293) | Bit/dim 3.5536(3.5767) | Xent 0.2234(0.2185) | Loss 3.6653(3.6859) | Error 0.0744(0.0771) Steps 790(817.34) | Grad Norm 4.5482(3.8677) | Total Time 14.00(14.00)\n",
      "Iter 12690 | Time 21.2736(20.1204) | Bit/dim 3.5577(3.5751) | Xent 0.2013(0.2175) | Loss 3.6583(3.6839) | Error 0.0667(0.0769) Steps 820(816.96) | Grad Norm 3.2315(3.7934) | Total Time 14.00(14.00)\n",
      "Iter 12700 | Time 19.6799(19.9647) | Bit/dim 3.5876(3.5775) | Xent 0.1940(0.2212) | Loss 3.6846(3.6881) | Error 0.0711(0.0780) Steps 814(815.42) | Grad Norm 4.1596(3.9256) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0231 | Time 99.4675, Epoch Time 1220.2669(1143.0623), Bit/dim 3.5778(best: 3.5808), Xent 0.8721, Loss 4.0139, Error 0.2305(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12710 | Time 19.2696(20.0047) | Bit/dim 3.5571(3.5767) | Xent 0.1704(0.2187) | Loss 3.6423(3.6861) | Error 0.0667(0.0775) Steps 826(818.83) | Grad Norm 3.2808(3.8140) | Total Time 14.00(14.00)\n",
      "Iter 12720 | Time 19.5755(19.9731) | Bit/dim 3.5615(3.5759) | Xent 0.2144(0.2235) | Loss 3.6687(3.6876) | Error 0.0800(0.0801) Steps 820(819.24) | Grad Norm 3.1530(3.8025) | Total Time 14.00(14.00)\n",
      "Iter 12730 | Time 19.7446(19.9044) | Bit/dim 3.5801(3.5771) | Xent 0.2471(0.2248) | Loss 3.7037(3.6895) | Error 0.0789(0.0798) Steps 802(816.79) | Grad Norm 3.1794(3.7216) | Total Time 14.00(14.00)\n",
      "Iter 12740 | Time 18.9709(19.8407) | Bit/dim 3.5970(3.5785) | Xent 0.1822(0.2214) | Loss 3.6881(3.6892) | Error 0.0678(0.0796) Steps 826(816.63) | Grad Norm 2.9265(3.5324) | Total Time 14.00(14.00)\n",
      "Iter 12750 | Time 19.9996(19.8060) | Bit/dim 3.5517(3.5771) | Xent 0.2179(0.2164) | Loss 3.6607(3.6852) | Error 0.0711(0.0783) Steps 862(818.80) | Grad Norm 3.5465(3.4477) | Total Time 14.00(14.00)\n",
      "Iter 12760 | Time 20.2682(19.7760) | Bit/dim 3.5828(3.5768) | Xent 0.1756(0.2124) | Loss 3.6706(3.6830) | Error 0.0622(0.0765) Steps 826(817.28) | Grad Norm 2.7625(3.2244) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0232 | Time 101.1061, Epoch Time 1204.9396(1144.9186), Bit/dim 3.5786(best: 3.5778), Xent 0.8551, Loss 4.0061, Error 0.2174(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12770 | Time 20.2510(19.8349) | Bit/dim 3.5581(3.5720) | Xent 0.1642(0.2022) | Loss 3.6402(3.6730) | Error 0.0556(0.0722) Steps 814(817.81) | Grad Norm 3.0531(3.0536) | Total Time 14.00(14.00)\n",
      "Iter 12780 | Time 20.1482(19.8586) | Bit/dim 3.5560(3.5725) | Xent 0.1939(0.1981) | Loss 3.6530(3.6716) | Error 0.0789(0.0705) Steps 796(816.65) | Grad Norm 2.9495(3.0036) | Total Time 14.00(14.00)\n",
      "Iter 12790 | Time 20.6894(19.9662) | Bit/dim 3.5670(3.5728) | Xent 0.2587(0.2074) | Loss 3.6963(3.6765) | Error 0.1067(0.0743) Steps 814(820.19) | Grad Norm 5.0391(3.4028) | Total Time 14.00(14.00)\n",
      "Iter 12800 | Time 19.4617(19.9965) | Bit/dim 3.5832(3.5749) | Xent 0.2103(0.2290) | Loss 3.6883(3.6895) | Error 0.0856(0.0831) Steps 820(818.71) | Grad Norm 2.2157(4.0112) | Total Time 14.00(14.00)\n",
      "Iter 12810 | Time 19.6009(20.0017) | Bit/dim 3.5856(3.5782) | Xent 0.2772(0.2407) | Loss 3.7242(3.6986) | Error 0.1056(0.0869) Steps 808(818.83) | Grad Norm 3.5804(4.1697) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0233 | Time 100.8132, Epoch Time 1221.5473(1147.2175), Bit/dim 3.5874(best: 3.5778), Xent 0.8932, Loss 4.0340, Error 0.2326(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12820 | Time 19.5507(19.8871) | Bit/dim 3.5550(3.5807) | Xent 0.1997(0.2377) | Loss 3.6549(3.6995) | Error 0.0722(0.0862) Steps 796(817.35) | Grad Norm 2.5925(3.9113) | Total Time 14.00(14.00)\n",
      "Iter 12830 | Time 19.4525(19.8805) | Bit/dim 3.5718(3.5815) | Xent 0.2296(0.2335) | Loss 3.6866(3.6983) | Error 0.0811(0.0843) Steps 826(819.06) | Grad Norm 2.2531(3.6846) | Total Time 14.00(14.00)\n",
      "Iter 12840 | Time 20.1905(19.9913) | Bit/dim 3.5898(3.5819) | Xent 0.1845(0.2315) | Loss 3.6821(3.6977) | Error 0.0656(0.0837) Steps 832(821.31) | Grad Norm 2.9808(3.5359) | Total Time 14.00(14.00)\n",
      "Iter 12850 | Time 19.7469(20.0518) | Bit/dim 3.5494(3.5771) | Xent 0.2195(0.2187) | Loss 3.6591(3.6864) | Error 0.0867(0.0787) Steps 814(821.07) | Grad Norm 3.1337(3.3104) | Total Time 14.00(14.00)\n",
      "Iter 12860 | Time 20.2355(20.1511) | Bit/dim 3.5467(3.5731) | Xent 0.2064(0.2128) | Loss 3.6499(3.6794) | Error 0.0756(0.0764) Steps 832(823.82) | Grad Norm 4.1019(3.2154) | Total Time 14.00(14.00)\n",
      "Iter 12870 | Time 20.1258(20.1531) | Bit/dim 3.5459(3.5719) | Xent 0.2021(0.2135) | Loss 3.6469(3.6786) | Error 0.0756(0.0769) Steps 826(821.39) | Grad Norm 2.6471(3.3543) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0234 | Time 99.5974, Epoch Time 1223.8301(1149.5158), Bit/dim 3.5855(best: 3.5778), Xent 0.8786, Loss 4.0247, Error 0.2284(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12880 | Time 20.5094(20.1524) | Bit/dim 3.6032(3.5727) | Xent 0.2492(0.2130) | Loss 3.7278(3.6792) | Error 0.0856(0.0765) Steps 838(821.62) | Grad Norm 4.1865(3.4483) | Total Time 14.00(14.00)\n",
      "Iter 12890 | Time 19.9068(20.1996) | Bit/dim 3.5860(3.5725) | Xent 0.1957(0.2130) | Loss 3.6839(3.6790) | Error 0.0711(0.0762) Steps 802(823.10) | Grad Norm 4.2657(3.6381) | Total Time 14.00(14.00)\n",
      "Iter 12900 | Time 20.3820(20.2429) | Bit/dim 3.5813(3.5749) | Xent 0.3323(0.2281) | Loss 3.7474(3.6890) | Error 0.1200(0.0811) Steps 844(824.11) | Grad Norm 6.3203(4.4353) | Total Time 14.00(14.00)\n",
      "Iter 12910 | Time 20.3328(20.3498) | Bit/dim 3.5738(3.5793) | Xent 0.2425(0.2344) | Loss 3.6950(3.6965) | Error 0.0889(0.0836) Steps 814(825.36) | Grad Norm 3.3023(4.4658) | Total Time 14.00(14.00)\n",
      "Iter 12920 | Time 19.6774(20.2276) | Bit/dim 3.5516(3.5789) | Xent 0.2143(0.2337) | Loss 3.6588(3.6957) | Error 0.0733(0.0836) Steps 820(824.28) | Grad Norm 3.4343(4.3378) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0235 | Time 99.5775, Epoch Time 1232.4269(1152.0032), Bit/dim 3.5827(best: 3.5778), Xent 0.8769, Loss 4.0212, Error 0.2306(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12930 | Time 20.2359(20.1538) | Bit/dim 3.5609(3.5756) | Xent 0.2247(0.2344) | Loss 3.6733(3.6928) | Error 0.0822(0.0837) Steps 838(824.19) | Grad Norm 3.0028(4.2107) | Total Time 14.00(14.00)\n",
      "Iter 12940 | Time 20.2805(20.1133) | Bit/dim 3.6035(3.5765) | Xent 0.2278(0.2277) | Loss 3.7174(3.6904) | Error 0.0800(0.0810) Steps 814(824.05) | Grad Norm 2.9492(4.0178) | Total Time 14.00(14.00)\n",
      "Iter 12950 | Time 20.0721(20.1046) | Bit/dim 3.5715(3.5738) | Xent 0.2323(0.2231) | Loss 3.6877(3.6853) | Error 0.0900(0.0797) Steps 820(825.18) | Grad Norm 3.5925(3.8443) | Total Time 14.00(14.00)\n",
      "Iter 12960 | Time 19.9912(20.0910) | Bit/dim 3.5749(3.5764) | Xent 0.2086(0.2164) | Loss 3.6793(3.6846) | Error 0.0778(0.0768) Steps 802(823.94) | Grad Norm 3.5869(3.7103) | Total Time 14.00(14.00)\n",
      "Iter 12970 | Time 20.3113(20.1880) | Bit/dim 3.5892(3.5776) | Xent 0.1971(0.2231) | Loss 3.6877(3.6891) | Error 0.0733(0.0790) Steps 844(824.79) | Grad Norm 3.6665(3.7945) | Total Time 14.00(14.00)\n",
      "Iter 12980 | Time 20.9041(20.2128) | Bit/dim 3.5917(3.5793) | Xent 0.2484(0.2236) | Loss 3.7159(3.6911) | Error 0.0900(0.0792) Steps 820(825.26) | Grad Norm 4.0534(3.9564) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0236 | Time 99.7988, Epoch Time 1225.3711(1154.2042), Bit/dim 3.5849(best: 3.5778), Xent 0.8693, Loss 4.0195, Error 0.2208(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 12990 | Time 19.6192(20.0723) | Bit/dim 3.5527(3.5777) | Xent 0.1659(0.2132) | Loss 3.6357(3.6843) | Error 0.0600(0.0766) Steps 826(826.21) | Grad Norm 2.7829(3.7096) | Total Time 14.00(14.00)\n",
      "Iter 13000 | Time 19.7546(20.1013) | Bit/dim 3.6061(3.5766) | Xent 0.2425(0.2136) | Loss 3.7273(3.6834) | Error 0.0811(0.0762) Steps 832(827.70) | Grad Norm 3.7596(3.5788) | Total Time 14.00(14.00)\n",
      "Iter 13010 | Time 20.3392(20.1303) | Bit/dim 3.5619(3.5797) | Xent 0.2194(0.2138) | Loss 3.6715(3.6866) | Error 0.0811(0.0760) Steps 820(827.46) | Grad Norm 3.8608(3.5430) | Total Time 14.00(14.00)\n",
      "Iter 13020 | Time 20.4094(20.0901) | Bit/dim 3.5841(3.5785) | Xent 0.1774(0.2153) | Loss 3.6728(3.6861) | Error 0.0700(0.0772) Steps 832(825.48) | Grad Norm 2.1400(3.5344) | Total Time 14.00(14.00)\n",
      "Iter 13030 | Time 20.0010(20.0273) | Bit/dim 3.5443(3.5784) | Xent 0.2048(0.2157) | Loss 3.6467(3.6862) | Error 0.0689(0.0762) Steps 820(825.37) | Grad Norm 3.0378(3.4978) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0237 | Time 101.7744, Epoch Time 1220.8597(1156.2039), Bit/dim 3.5799(best: 3.5778), Xent 0.8827, Loss 4.0213, Error 0.2301(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13040 | Time 20.5852(20.0972) | Bit/dim 3.6000(3.5749) | Xent 0.2050(0.2124) | Loss 3.7025(3.6811) | Error 0.0744(0.0763) Steps 826(824.90) | Grad Norm 4.5498(3.5282) | Total Time 14.00(14.00)\n",
      "Iter 13050 | Time 20.3373(20.0818) | Bit/dim 3.6059(3.5766) | Xent 0.1918(0.2076) | Loss 3.7017(3.6805) | Error 0.0678(0.0743) Steps 844(827.64) | Grad Norm 3.3131(3.5018) | Total Time 14.00(14.00)\n",
      "Iter 13060 | Time 20.2548(20.1548) | Bit/dim 3.6063(3.5753) | Xent 0.2317(0.2155) | Loss 3.7221(3.6831) | Error 0.0811(0.0771) Steps 826(830.15) | Grad Norm 4.2624(3.8402) | Total Time 14.00(14.00)\n",
      "Iter 13070 | Time 19.8362(20.0691) | Bit/dim 3.5786(3.5750) | Xent 0.2298(0.2189) | Loss 3.6936(3.6844) | Error 0.0900(0.0779) Steps 820(828.29) | Grad Norm 3.1051(3.7672) | Total Time 14.00(14.00)\n",
      "Iter 13080 | Time 20.3866(20.1620) | Bit/dim 3.5633(3.5773) | Xent 0.2252(0.2140) | Loss 3.6759(3.6843) | Error 0.0811(0.0758) Steps 850(830.24) | Grad Norm 3.7101(3.6743) | Total Time 14.00(14.00)\n",
      "Iter 13090 | Time 20.7937(20.2468) | Bit/dim 3.5921(3.5759) | Xent 0.2116(0.2128) | Loss 3.6979(3.6823) | Error 0.0778(0.0762) Steps 820(829.90) | Grad Norm 3.3680(3.6401) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0238 | Time 102.0059, Epoch Time 1232.2728(1158.4859), Bit/dim 3.5832(best: 3.5778), Xent 0.9072, Loss 4.0368, Error 0.2247(best: 0.2157)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_tunetol_run1 --resume ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_tunetol_run1/epoch_250_checkpt.pth --seed 1 --conditional True --controlled_tol True --train_mode semisup --lr 0.0001 --warmup_iters 1000 --atol 1e-4  --rtol 1e-4 --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
