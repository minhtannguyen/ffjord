{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_cifar.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.0, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_run3/current_checkpt.pth', rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_run3', seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 1414198\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 13590 | Time 26.2596(26.6912) | Bit/dim 3.5524(3.5529) | Xent 0.0610(0.0775) | Loss 3.5829(3.5916) | Error 0.0200(0.0285) Steps 1030(1049.42) | Grad Norm 1.7404(3.4200) | Total Time 14.00(14.00)\n",
      "Iter 13600 | Time 26.1098(26.4732) | Bit/dim 3.5762(3.5486) | Xent 0.0469(0.0687) | Loss 3.5996(3.5829) | Error 0.0156(0.0249) Steps 1006(1042.38) | Grad Norm 1.5190(3.0400) | Total Time 14.00(14.00)\n",
      "Iter 13610 | Time 26.1039(26.2740) | Bit/dim 3.5445(3.5451) | Xent 0.0274(0.0595) | Loss 3.5582(3.5748) | Error 0.0111(0.0216) Steps 1060(1038.80) | Grad Norm 0.9556(2.5844) | Total Time 14.00(14.00)\n",
      "Iter 13620 | Time 25.2664(26.1151) | Bit/dim 3.5378(3.5431) | Xent 0.0290(0.0518) | Loss 3.5524(3.5690) | Error 0.0089(0.0184) Steps 1036(1036.90) | Grad Norm 1.0036(2.2167) | Total Time 14.00(14.00)\n",
      "Iter 13630 | Time 25.9368(26.0442) | Bit/dim 3.5290(3.5376) | Xent 0.0271(0.0454) | Loss 3.5425(3.5603) | Error 0.0089(0.0158) Steps 1048(1035.80) | Grad Norm 0.8649(1.9242) | Total Time 14.00(14.00)\n",
      "Iter 13640 | Time 25.9990(25.9425) | Bit/dim 3.5336(3.5337) | Xent 0.0280(0.0410) | Loss 3.5476(3.5542) | Error 0.0089(0.0138) Steps 1036(1031.12) | Grad Norm 0.9181(1.6561) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0248 | Time 124.2490, Epoch Time 1580.5909(1507.5830), Bit/dim 3.5313(best: inf), Xent 1.7910, Loss 4.4268, Error 0.2671(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13650 | Time 25.7091(25.8850) | Bit/dim 3.5028(3.5321) | Xent 0.0316(0.0374) | Loss 3.5186(3.5508) | Error 0.0078(0.0122) Steps 1030(1028.68) | Grad Norm 1.0603(1.4722) | Total Time 14.00(14.00)\n",
      "Iter 13660 | Time 25.8959(25.9167) | Bit/dim 3.5683(3.5315) | Xent 0.0257(0.0347) | Loss 3.5811(3.5488) | Error 0.0056(0.0109) Steps 1012(1029.13) | Grad Norm 0.8424(1.3161) | Total Time 14.00(14.00)\n",
      "Iter 13670 | Time 25.7378(25.9526) | Bit/dim 3.5255(3.5272) | Xent 0.0270(0.0330) | Loss 3.5390(3.5436) | Error 0.0056(0.0101) Steps 1048(1028.97) | Grad Norm 0.7279(1.2107) | Total Time 14.00(14.00)\n",
      "Iter 13680 | Time 26.1095(25.9947) | Bit/dim 3.5295(3.5270) | Xent 0.0246(0.0311) | Loss 3.5418(3.5425) | Error 0.0067(0.0094) Steps 1048(1033.02) | Grad Norm 0.8866(1.1216) | Total Time 14.00(14.00)\n",
      "Iter 13690 | Time 26.6478(26.0448) | Bit/dim 3.5098(3.5269) | Xent 0.0209(0.0296) | Loss 3.5202(3.5417) | Error 0.0044(0.0086) Steps 1054(1035.44) | Grad Norm 0.6587(1.0510) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0249 | Time 120.2353, Epoch Time 1568.4506(1509.4090), Bit/dim 3.5283(best: 3.5313), Xent 1.7969, Loss 4.4268, Error 0.2631(best: 0.2671)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13700 | Time 25.7617(26.0665) | Bit/dim 3.5369(3.5254) | Xent 0.0196(0.0281) | Loss 3.5467(3.5395) | Error 0.0022(0.0079) Steps 1048(1037.44) | Grad Norm 0.7625(0.9885) | Total Time 14.00(14.00)\n",
      "Iter 13710 | Time 27.2513(26.1674) | Bit/dim 3.5379(3.5250) | Xent 0.0202(0.0268) | Loss 3.5480(3.5384) | Error 0.0067(0.0073) Steps 1054(1040.09) | Grad Norm 0.7796(0.9489) | Total Time 14.00(14.00)\n",
      "Iter 13720 | Time 25.8445(26.1946) | Bit/dim 3.5172(3.5257) | Xent 0.0228(0.0258) | Loss 3.5286(3.5386) | Error 0.0033(0.0068) Steps 1048(1043.55) | Grad Norm 0.8497(0.9208) | Total Time 14.00(14.00)\n",
      "Iter 13730 | Time 26.1360(26.1726) | Bit/dim 3.5622(3.5260) | Xent 0.0348(0.0250) | Loss 3.5796(3.5385) | Error 0.0122(0.0067) Steps 1060(1043.81) | Grad Norm 1.0558(0.8890) | Total Time 14.00(14.00)\n",
      "Iter 13740 | Time 25.8286(26.1602) | Bit/dim 3.4854(3.5229) | Xent 0.0197(0.0243) | Loss 3.4952(3.5350) | Error 0.0022(0.0063) Steps 1030(1043.72) | Grad Norm 1.0614(0.8670) | Total Time 14.00(14.00)\n",
      "Iter 13750 | Time 26.6567(26.2175) | Bit/dim 3.5192(3.5233) | Xent 0.0226(0.0241) | Loss 3.5305(3.5354) | Error 0.0067(0.0064) Steps 1054(1044.21) | Grad Norm 0.8455(0.8461) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0250 | Time 121.3619, Epoch Time 1584.9619(1511.6756), Bit/dim 3.5262(best: 3.5283), Xent 1.8006, Loss 4.4265, Error 0.2680(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13760 | Time 26.5094(26.2770) | Bit/dim 3.5115(3.5234) | Xent 0.0233(0.0236) | Loss 3.5232(3.5352) | Error 0.0067(0.0063) Steps 1060(1045.30) | Grad Norm 0.7596(0.8244) | Total Time 14.00(14.00)\n",
      "Iter 13770 | Time 27.0514(26.2793) | Bit/dim 3.5118(3.5227) | Xent 0.0169(0.0234) | Loss 3.5202(3.5343) | Error 0.0033(0.0061) Steps 1078(1046.30) | Grad Norm 0.7221(0.8197) | Total Time 14.00(14.00)\n",
      "Iter 13780 | Time 26.5601(26.3487) | Bit/dim 3.4889(3.5207) | Xent 0.0176(0.0233) | Loss 3.4978(3.5323) | Error 0.0067(0.0061) Steps 1030(1047.59) | Grad Norm 0.6763(0.8330) | Total Time 14.00(14.00)\n",
      "Iter 13790 | Time 26.6970(26.3825) | Bit/dim 3.5261(3.5219) | Xent 0.0226(0.0237) | Loss 3.5374(3.5338) | Error 0.0078(0.0064) Steps 1048(1047.83) | Grad Norm 0.7300(0.8546) | Total Time 14.00(14.00)\n",
      "Iter 13800 | Time 26.2129(26.3752) | Bit/dim 3.5609(3.5233) | Xent 0.0177(0.0240) | Loss 3.5698(3.5353) | Error 0.0033(0.0066) Steps 1030(1044.68) | Grad Norm 0.7028(0.8668) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 119.5145, Epoch Time 1590.1949(1514.0312), Bit/dim 3.5263(best: 3.5262), Xent 1.8129, Loss 4.4327, Error 0.2668(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13810 | Time 25.8349(26.3251) | Bit/dim 3.5237(3.5198) | Xent 0.0139(0.0239) | Loss 3.5306(3.5317) | Error 0.0044(0.0065) Steps 1048(1043.12) | Grad Norm 0.6989(0.8564) | Total Time 14.00(14.00)\n",
      "Iter 13820 | Time 26.4345(26.3339) | Bit/dim 3.5221(3.5212) | Xent 0.0237(0.0233) | Loss 3.5340(3.5329) | Error 0.0056(0.0063) Steps 1042(1043.35) | Grad Norm 0.8698(0.8392) | Total Time 14.00(14.00)\n",
      "Iter 13830 | Time 25.5510(26.2762) | Bit/dim 3.5150(3.5221) | Xent 0.0190(0.0231) | Loss 3.5245(3.5337) | Error 0.0056(0.0062) Steps 1030(1042.45) | Grad Norm 0.7116(0.8299) | Total Time 14.00(14.00)\n",
      "Iter 13840 | Time 26.8733(26.3129) | Bit/dim 3.4859(3.5207) | Xent 0.0248(0.0236) | Loss 3.4983(3.5325) | Error 0.0067(0.0062) Steps 1024(1042.64) | Grad Norm 0.7933(0.8219) | Total Time 14.00(14.00)\n",
      "Iter 13850 | Time 26.6291(26.3448) | Bit/dim 3.5234(3.5205) | Xent 0.0181(0.0232) | Loss 3.5324(3.5321) | Error 0.0033(0.0060) Steps 1054(1043.68) | Grad Norm 0.9212(0.8280) | Total Time 14.00(14.00)\n",
      "Iter 13860 | Time 25.6693(26.2381) | Bit/dim 3.5607(3.5202) | Xent 0.0260(0.0232) | Loss 3.5737(3.5318) | Error 0.0056(0.0060) Steps 1042(1044.17) | Grad Norm 1.0548(0.8381) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 118.8099, Epoch Time 1579.5589(1515.9970), Bit/dim 3.5244(best: 3.5262), Xent 1.8332, Loss 4.4410, Error 0.2675(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13870 | Time 26.7637(26.2680) | Bit/dim 3.5549(3.5208) | Xent 0.0183(0.0225) | Loss 3.5640(3.5321) | Error 0.0044(0.0060) Steps 1066(1044.21) | Grad Norm 0.6806(0.8012) | Total Time 14.00(14.00)\n",
      "Iter 13880 | Time 25.7711(26.2474) | Bit/dim 3.5150(3.5167) | Xent 0.0151(0.0224) | Loss 3.5225(3.5279) | Error 0.0033(0.0061) Steps 1054(1046.64) | Grad Norm 0.5315(0.8086) | Total Time 14.00(14.00)\n",
      "Iter 13890 | Time 26.4495(26.3126) | Bit/dim 3.5214(3.5200) | Xent 0.0182(0.0224) | Loss 3.5305(3.5312) | Error 0.0044(0.0062) Steps 1030(1047.63) | Grad Norm 0.7559(0.8207) | Total Time 14.00(14.00)\n",
      "Iter 13900 | Time 27.8431(26.3996) | Bit/dim 3.5112(3.5195) | Xent 0.0157(0.0216) | Loss 3.5191(3.5303) | Error 0.0033(0.0059) Steps 1060(1048.39) | Grad Norm 0.7339(0.8019) | Total Time 14.00(14.00)\n",
      "Iter 13910 | Time 25.9463(26.3511) | Bit/dim 3.5049(3.5197) | Xent 0.0182(0.0219) | Loss 3.5140(3.5306) | Error 0.0033(0.0060) Steps 1030(1046.81) | Grad Norm 0.7232(0.8284) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 120.0671, Epoch Time 1587.8636(1518.1530), Bit/dim 3.5228(best: 3.5244), Xent 1.8354, Loss 4.4405, Error 0.2706(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13920 | Time 25.7222(26.3059) | Bit/dim 3.5296(3.5200) | Xent 0.0173(0.0217) | Loss 3.5382(3.5308) | Error 0.0033(0.0059) Steps 1048(1045.87) | Grad Norm 0.6543(0.8244) | Total Time 14.00(14.00)\n",
      "Iter 13930 | Time 26.6650(26.3592) | Bit/dim 3.5040(3.5177) | Xent 0.0207(0.0212) | Loss 3.5144(3.5283) | Error 0.0056(0.0053) Steps 1036(1046.77) | Grad Norm 0.7531(0.7947) | Total Time 14.00(14.00)\n",
      "Iter 13940 | Time 26.5173(26.3495) | Bit/dim 3.5111(3.5187) | Xent 0.0234(0.0212) | Loss 3.5228(3.5293) | Error 0.0044(0.0055) Steps 1054(1045.84) | Grad Norm 0.7026(0.7965) | Total Time 14.00(14.00)\n",
      "Iter 13950 | Time 26.2398(26.3803) | Bit/dim 3.4996(3.5184) | Xent 0.0235(0.0212) | Loss 3.5114(3.5290) | Error 0.0056(0.0056) Steps 1060(1045.90) | Grad Norm 0.8614(0.7952) | Total Time 14.00(14.00)\n",
      "Iter 13960 | Time 26.4761(26.3624) | Bit/dim 3.4839(3.5192) | Xent 0.0165(0.0211) | Loss 3.4921(3.5298) | Error 0.0022(0.0056) Steps 1042(1046.16) | Grad Norm 0.5847(0.7954) | Total Time 14.00(14.00)\n",
      "Iter 13970 | Time 26.1037(26.3712) | Bit/dim 3.4941(3.5196) | Xent 0.0249(0.0211) | Loss 3.5066(3.5301) | Error 0.0056(0.0056) Steps 1030(1047.25) | Grad Norm 0.8929(0.7934) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 119.6456, Epoch Time 1588.9002(1520.2754), Bit/dim 3.5220(best: 3.5228), Xent 1.8327, Loss 4.4384, Error 0.2691(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13980 | Time 26.0018(26.3456) | Bit/dim 3.5238(3.5182) | Xent 0.0226(0.0214) | Loss 3.5351(3.5289) | Error 0.0044(0.0055) Steps 1042(1045.52) | Grad Norm 0.7741(0.7982) | Total Time 14.00(14.00)\n",
      "Iter 13990 | Time 25.9601(26.4063) | Bit/dim 3.5254(3.5170) | Xent 0.0163(0.0215) | Loss 3.5335(3.5277) | Error 0.0022(0.0054) Steps 1036(1046.54) | Grad Norm 0.6348(0.8015) | Total Time 14.00(14.00)\n",
      "Iter 14000 | Time 26.5060(26.3760) | Bit/dim 3.5526(3.5179) | Xent 0.0151(0.0209) | Loss 3.5601(3.5284) | Error 0.0033(0.0052) Steps 1048(1045.45) | Grad Norm 0.5576(0.7854) | Total Time 14.00(14.00)\n",
      "Iter 14010 | Time 26.5028(26.3067) | Bit/dim 3.5401(3.5191) | Xent 0.0265(0.0209) | Loss 3.5534(3.5296) | Error 0.0078(0.0052) Steps 1060(1046.63) | Grad Norm 1.0185(0.7887) | Total Time 14.00(14.00)\n",
      "Iter 14020 | Time 26.4572(26.3169) | Bit/dim 3.5139(3.5186) | Xent 0.0208(0.0209) | Loss 3.5243(3.5290) | Error 0.0044(0.0051) Steps 1024(1044.51) | Grad Norm 0.8672(0.7780) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 119.8890, Epoch Time 1585.0722(1522.2193), Bit/dim 3.5221(best: 3.5220), Xent 1.8530, Loss 4.4486, Error 0.2685(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14030 | Time 26.2829(26.2959) | Bit/dim 3.5148(3.5185) | Xent 0.0134(0.0204) | Loss 3.5215(3.5287) | Error 0.0000(0.0049) Steps 1030(1044.13) | Grad Norm 0.5132(0.7631) | Total Time 14.00(14.00)\n",
      "Iter 14040 | Time 25.2362(26.2408) | Bit/dim 3.5403(3.5180) | Xent 0.0140(0.0205) | Loss 3.5473(3.5282) | Error 0.0011(0.0051) Steps 1024(1043.10) | Grad Norm 0.5762(0.7627) | Total Time 14.00(14.00)\n",
      "Iter 14050 | Time 25.7978(26.2399) | Bit/dim 3.5113(3.5190) | Xent 0.0209(0.0208) | Loss 3.5217(3.5294) | Error 0.0056(0.0050) Steps 1060(1043.80) | Grad Norm 0.9983(0.7800) | Total Time 14.00(14.00)\n",
      "Iter 14060 | Time 26.4369(26.2623) | Bit/dim 3.5102(3.5193) | Xent 0.0193(0.0209) | Loss 3.5199(3.5297) | Error 0.0044(0.0051) Steps 1036(1041.73) | Grad Norm 0.7441(0.7741) | Total Time 14.00(14.00)\n",
      "Iter 14070 | Time 25.9616(26.2417) | Bit/dim 3.5253(3.5163) | Xent 0.0216(0.0211) | Loss 3.5361(3.5269) | Error 0.0044(0.0052) Steps 1030(1044.40) | Grad Norm 0.6324(0.7774) | Total Time 14.00(14.00)\n",
      "Iter 14080 | Time 26.6549(26.2566) | Bit/dim 3.5223(3.5164) | Xent 0.0215(0.0211) | Loss 3.5330(3.5269) | Error 0.0044(0.0051) Steps 1060(1046.24) | Grad Norm 0.8159(0.7669) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 119.6095, Epoch Time 1580.3324(1523.9627), Bit/dim 3.5221(best: 3.5220), Xent 1.8314, Loss 4.4378, Error 0.2667(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14090 | Time 26.6016(26.2672) | Bit/dim 3.5088(3.5172) | Xent 0.0163(0.0212) | Loss 3.5170(3.5278) | Error 0.0033(0.0051) Steps 1042(1045.39) | Grad Norm 0.8192(0.7778) | Total Time 14.00(14.00)\n",
      "Iter 14100 | Time 26.3110(26.2799) | Bit/dim 3.5078(3.5152) | Xent 0.0262(0.0205) | Loss 3.5209(3.5255) | Error 0.0056(0.0047) Steps 1054(1044.93) | Grad Norm 0.7561(0.7643) | Total Time 14.00(14.00)\n",
      "Iter 14110 | Time 26.7710(26.3869) | Bit/dim 3.4998(3.5151) | Xent 0.0217(0.0203) | Loss 3.5107(3.5252) | Error 0.0078(0.0050) Steps 1066(1046.18) | Grad Norm 0.9640(0.7885) | Total Time 14.00(14.00)\n",
      "Iter 14120 | Time 26.8895(26.4027) | Bit/dim 3.5233(3.5175) | Xent 0.0158(0.0198) | Loss 3.5312(3.5273) | Error 0.0033(0.0047) Steps 1054(1046.36) | Grad Norm 0.8928(0.7791) | Total Time 14.00(14.00)\n",
      "Iter 14130 | Time 26.3630(26.3544) | Bit/dim 3.5091(3.5156) | Xent 0.0249(0.0203) | Loss 3.5216(3.5258) | Error 0.0078(0.0050) Steps 1060(1047.11) | Grad Norm 1.0225(0.7985) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 119.2836, Epoch Time 1588.1280(1525.8877), Bit/dim 3.5207(best: 3.5220), Xent 1.8432, Loss 4.4424, Error 0.2698(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14140 | Time 26.3975(26.3124) | Bit/dim 3.5396(3.5176) | Xent 0.0166(0.0198) | Loss 3.5479(3.5276) | Error 0.0011(0.0047) Steps 1066(1048.08) | Grad Norm 0.5174(0.7741) | Total Time 14.00(14.00)\n",
      "Iter 14150 | Time 25.6972(26.2711) | Bit/dim 3.5245(3.5204) | Xent 0.0265(0.0202) | Loss 3.5377(3.5305) | Error 0.0078(0.0050) Steps 1042(1048.17) | Grad Norm 1.0408(0.7634) | Total Time 14.00(14.00)\n",
      "Iter 14160 | Time 26.3056(26.2960) | Bit/dim 3.5271(3.5188) | Xent 0.0215(0.0202) | Loss 3.5378(3.5289) | Error 0.0033(0.0051) Steps 1036(1048.12) | Grad Norm 0.7642(0.7750) | Total Time 14.00(14.00)\n",
      "Iter 14170 | Time 25.7238(26.2987) | Bit/dim 3.4874(3.5161) | Xent 0.0216(0.0203) | Loss 3.4982(3.5262) | Error 0.0056(0.0051) Steps 1054(1047.95) | Grad Norm 0.7921(0.7877) | Total Time 14.00(14.00)\n",
      "Iter 14180 | Time 26.4945(26.3316) | Bit/dim 3.4881(3.5137) | Xent 0.0206(0.0200) | Loss 3.4984(3.5237) | Error 0.0067(0.0050) Steps 1060(1049.58) | Grad Norm 0.7669(0.7774) | Total Time 14.00(14.00)\n",
      "Iter 14190 | Time 27.7220(26.3813) | Bit/dim 3.5274(3.5151) | Xent 0.0196(0.0195) | Loss 3.5372(3.5248) | Error 0.0056(0.0046) Steps 1054(1047.73) | Grad Norm 0.7592(0.7572) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 120.3407, Epoch Time 1586.9077(1527.7183), Bit/dim 3.5206(best: 3.5207), Xent 1.8746, Loss 4.4578, Error 0.2688(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14200 | Time 26.2639(26.3301) | Bit/dim 3.5097(3.5158) | Xent 0.0142(0.0195) | Loss 3.5168(3.5255) | Error 0.0011(0.0045) Steps 1048(1048.21) | Grad Norm 0.5728(0.7755) | Total Time 14.00(14.00)\n",
      "Iter 14210 | Time 26.5066(26.3594) | Bit/dim 3.5375(3.5178) | Xent 0.0126(0.0199) | Loss 3.5438(3.5277) | Error 0.0022(0.0047) Steps 1066(1049.62) | Grad Norm 0.6515(0.8016) | Total Time 14.00(14.00)\n",
      "Iter 14220 | Time 25.7133(26.2962) | Bit/dim 3.4874(3.5164) | Xent 0.0273(0.0202) | Loss 3.5011(3.5266) | Error 0.0056(0.0048) Steps 1036(1047.75) | Grad Norm 0.9531(0.8221) | Total Time 14.00(14.00)\n",
      "Iter 14230 | Time 26.6628(26.3256) | Bit/dim 3.5056(3.5158) | Xent 0.0151(0.0194) | Loss 3.5131(3.5256) | Error 0.0011(0.0043) Steps 1036(1045.67) | Grad Norm 0.6298(0.7877) | Total Time 14.00(14.00)\n",
      "Iter 14240 | Time 26.6554(26.4292) | Bit/dim 3.5455(3.5133) | Xent 0.0231(0.0196) | Loss 3.5571(3.5231) | Error 0.0078(0.0044) Steps 1030(1045.95) | Grad Norm 1.0413(0.7933) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 120.7047, Epoch Time 1590.6941(1529.6076), Bit/dim 3.5205(best: 3.5206), Xent 1.8707, Loss 4.4559, Error 0.2732(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14250 | Time 26.7181(26.4703) | Bit/dim 3.5580(3.5163) | Xent 0.0264(0.0201) | Loss 3.5712(3.5264) | Error 0.0078(0.0047) Steps 1066(1048.02) | Grad Norm 1.0028(0.8279) | Total Time 14.00(14.00)\n",
      "Iter 14260 | Time 26.5852(26.3880) | Bit/dim 3.4910(3.5144) | Xent 0.0229(0.0200) | Loss 3.5024(3.5244) | Error 0.0056(0.0048) Steps 1054(1047.05) | Grad Norm 1.1139(0.8343) | Total Time 14.00(14.00)\n",
      "Iter 14270 | Time 26.6784(26.3765) | Bit/dim 3.5050(3.5148) | Xent 0.0193(0.0199) | Loss 3.5146(3.5247) | Error 0.0033(0.0049) Steps 1048(1047.18) | Grad Norm 0.8142(0.8195) | Total Time 14.00(14.00)\n",
      "Iter 14280 | Time 26.5018(26.3828) | Bit/dim 3.5396(3.5125) | Xent 0.0156(0.0195) | Loss 3.5474(3.5222) | Error 0.0011(0.0045) Steps 1042(1047.77) | Grad Norm 0.6557(0.7976) | Total Time 14.00(14.00)\n",
      "Iter 14290 | Time 25.9940(26.3392) | Bit/dim 3.4644(3.5134) | Xent 0.0186(0.0200) | Loss 3.4737(3.5235) | Error 0.0056(0.0050) Steps 1054(1047.02) | Grad Norm 0.7600(0.8044) | Total Time 14.00(14.00)\n",
      "Iter 14300 | Time 26.4825(26.3423) | Bit/dim 3.5604(3.5149) | Xent 0.0219(0.0198) | Loss 3.5714(3.5248) | Error 0.0078(0.0050) Steps 1072(1046.47) | Grad Norm 1.1259(0.8150) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 119.4619, Epoch Time 1584.7984(1531.2633), Bit/dim 3.5193(best: 3.5205), Xent 1.8780, Loss 4.4583, Error 0.2693(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14310 | Time 26.5544(26.3553) | Bit/dim 3.5248(3.5134) | Xent 0.0195(0.0200) | Loss 3.5345(3.5234) | Error 0.0044(0.0051) Steps 1060(1046.50) | Grad Norm 0.8006(0.8151) | Total Time 14.00(14.00)\n",
      "Iter 14320 | Time 26.2798(26.3327) | Bit/dim 3.4929(3.5155) | Xent 0.0218(0.0198) | Loss 3.5038(3.5254) | Error 0.0033(0.0050) Steps 1054(1045.16) | Grad Norm 0.8358(0.8236) | Total Time 14.00(14.00)\n",
      "Iter 14330 | Time 27.1709(26.3407) | Bit/dim 3.4691(3.5147) | Xent 0.0144(0.0199) | Loss 3.4763(3.5246) | Error 0.0033(0.0049) Steps 1030(1043.69) | Grad Norm 0.6099(0.8166) | Total Time 14.00(14.00)\n",
      "Iter 14340 | Time 26.3262(26.3324) | Bit/dim 3.5131(3.5130) | Xent 0.0154(0.0194) | Loss 3.5208(3.5227) | Error 0.0022(0.0044) Steps 1054(1045.44) | Grad Norm 0.6162(0.7933) | Total Time 14.00(14.00)\n",
      "Iter 14350 | Time 26.0454(26.3265) | Bit/dim 3.5078(3.5122) | Xent 0.0156(0.0195) | Loss 3.5156(3.5219) | Error 0.0022(0.0046) Steps 1054(1045.84) | Grad Norm 0.8089(0.8069) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 120.2812, Epoch Time 1586.6557(1532.9251), Bit/dim 3.5193(best: 3.5193), Xent 1.8650, Loss 4.4517, Error 0.2696(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14360 | Time 25.4951(26.3334) | Bit/dim 3.5422(3.5137) | Xent 0.0154(0.0189) | Loss 3.5499(3.5232) | Error 0.0044(0.0044) Steps 1048(1045.21) | Grad Norm 0.5136(0.7841) | Total Time 14.00(14.00)\n",
      "Iter 14370 | Time 27.3674(26.3669) | Bit/dim 3.5112(3.5156) | Xent 0.0217(0.0188) | Loss 3.5220(3.5251) | Error 0.0033(0.0045) Steps 1054(1046.40) | Grad Norm 0.9035(0.8016) | Total Time 14.00(14.00)\n",
      "Iter 14380 | Time 26.3561(26.4355) | Bit/dim 3.5352(3.5161) | Xent 0.0163(0.0191) | Loss 3.5433(3.5257) | Error 0.0033(0.0044) Steps 1048(1046.04) | Grad Norm 0.8702(0.8144) | Total Time 14.00(14.00)\n",
      "Iter 14390 | Time 26.7438(26.4168) | Bit/dim 3.5064(3.5154) | Xent 0.0244(0.0190) | Loss 3.5186(3.5249) | Error 0.0078(0.0046) Steps 1072(1045.08) | Grad Norm 0.8982(0.8125) | Total Time 14.00(14.00)\n",
      "Iter 14400 | Time 25.8914(26.4354) | Bit/dim 3.5513(3.5167) | Xent 0.0212(0.0187) | Loss 3.5619(3.5261) | Error 0.0044(0.0042) Steps 1048(1047.74) | Grad Norm 0.7730(0.8005) | Total Time 14.00(14.00)\n",
      "Iter 14410 | Time 26.1985(26.4003) | Bit/dim 3.5373(3.5132) | Xent 0.0153(0.0188) | Loss 3.5449(3.5226) | Error 0.0033(0.0043) Steps 1018(1046.39) | Grad Norm 0.7036(0.8460) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 119.9002, Epoch Time 1591.4326(1534.6803), Bit/dim 3.5187(best: 3.5193), Xent 1.8759, Loss 4.4566, Error 0.2700(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14420 | Time 26.5254(26.3976) | Bit/dim 3.5106(3.5116) | Xent 0.0150(0.0184) | Loss 3.5181(3.5208) | Error 0.0011(0.0039) Steps 1048(1047.78) | Grad Norm 0.7002(0.8301) | Total Time 14.00(14.00)\n",
      "Iter 14430 | Time 26.5666(26.3920) | Bit/dim 3.5299(3.5129) | Xent 0.0241(0.0190) | Loss 3.5420(3.5224) | Error 0.0056(0.0042) Steps 1030(1047.23) | Grad Norm 1.1190(0.8410) | Total Time 14.00(14.00)\n",
      "Iter 14440 | Time 26.3243(26.4001) | Bit/dim 3.4883(3.5108) | Xent 0.0299(0.0189) | Loss 3.5032(3.5202) | Error 0.0067(0.0041) Steps 1030(1047.81) | Grad Norm 0.9894(0.8179) | Total Time 14.00(14.00)\n",
      "Iter 14450 | Time 26.1290(26.4252) | Bit/dim 3.5198(3.5136) | Xent 0.0160(0.0191) | Loss 3.5278(3.5231) | Error 0.0033(0.0045) Steps 1054(1045.80) | Grad Norm 0.7002(0.8069) | Total Time 14.00(14.00)\n",
      "Iter 14460 | Time 26.7965(26.4310) | Bit/dim 3.5427(3.5152) | Xent 0.0261(0.0193) | Loss 3.5557(3.5249) | Error 0.0100(0.0048) Steps 1060(1047.68) | Grad Norm 1.2180(0.8306) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 120.0764, Epoch Time 1590.2138(1536.3463), Bit/dim 3.5183(best: 3.5187), Xent 1.8980, Loss 4.4673, Error 0.2721(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14470 | Time 26.8267(26.3572) | Bit/dim 3.4914(3.5127) | Xent 0.0184(0.0194) | Loss 3.5006(3.5225) | Error 0.0056(0.0048) Steps 1054(1046.02) | Grad Norm 0.8354(0.8342) | Total Time 14.00(14.00)\n",
      "Iter 14480 | Time 25.9693(26.3186) | Bit/dim 3.5294(3.5132) | Xent 0.0126(0.0188) | Loss 3.5358(3.5226) | Error 0.0011(0.0046) Steps 1048(1044.30) | Grad Norm 0.5851(0.8343) | Total Time 14.00(14.00)\n",
      "Iter 14490 | Time 26.3149(26.3152) | Bit/dim 3.5484(3.5131) | Xent 0.0202(0.0189) | Loss 3.5585(3.5225) | Error 0.0033(0.0043) Steps 1012(1041.76) | Grad Norm 0.7385(0.8190) | Total Time 14.00(14.00)\n",
      "Iter 14500 | Time 25.7348(26.3619) | Bit/dim 3.5125(3.5139) | Xent 0.0203(0.0191) | Loss 3.5226(3.5235) | Error 0.0067(0.0043) Steps 1048(1042.62) | Grad Norm 0.9273(0.8274) | Total Time 14.00(14.00)\n",
      "Iter 14510 | Time 25.5853(26.3473) | Bit/dim 3.5411(3.5149) | Xent 0.0151(0.0192) | Loss 3.5486(3.5245) | Error 0.0011(0.0044) Steps 1042(1041.23) | Grad Norm 0.6963(0.8315) | Total Time 14.00(14.00)\n",
      "Iter 14520 | Time 26.7084(26.3240) | Bit/dim 3.5069(3.5140) | Xent 0.0182(0.0186) | Loss 3.5160(3.5233) | Error 0.0044(0.0041) Steps 1036(1041.43) | Grad Norm 0.7206(0.7892) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 120.0944, Epoch Time 1584.5955(1537.7938), Bit/dim 3.5176(best: 3.5183), Xent 1.9027, Loss 4.4690, Error 0.2698(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14530 | Time 26.6033(26.3693) | Bit/dim 3.5060(3.5129) | Xent 0.0314(0.0187) | Loss 3.5217(3.5222) | Error 0.0133(0.0042) Steps 1060(1042.05) | Grad Norm 0.9225(0.7846) | Total Time 14.00(14.00)\n",
      "Iter 14540 | Time 25.9933(26.3950) | Bit/dim 3.4747(3.5125) | Xent 0.0145(0.0182) | Loss 3.4819(3.5216) | Error 0.0022(0.0040) Steps 1042(1042.48) | Grad Norm 0.8875(0.7733) | Total Time 14.00(14.00)\n",
      "Iter 14550 | Time 26.3359(26.3597) | Bit/dim 3.4889(3.5135) | Xent 0.0158(0.0180) | Loss 3.4968(3.5225) | Error 0.0033(0.0040) Steps 1042(1042.71) | Grad Norm 0.6337(0.7785) | Total Time 14.00(14.00)\n",
      "Iter 14560 | Time 26.5513(26.3261) | Bit/dim 3.4588(3.5140) | Xent 0.0199(0.0182) | Loss 3.4687(3.5231) | Error 0.0067(0.0040) Steps 1060(1043.37) | Grad Norm 0.9041(0.8171) | Total Time 14.00(14.00)\n",
      "Iter 14570 | Time 26.0460(26.3372) | Bit/dim 3.4842(3.5104) | Xent 0.0174(0.0183) | Loss 3.4929(3.5196) | Error 0.0033(0.0039) Steps 1054(1045.56) | Grad Norm 0.8788(0.8116) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 119.9127, Epoch Time 1586.1042(1539.2431), Bit/dim 3.5170(best: 3.5176), Xent 1.9039, Loss 4.4690, Error 0.2715(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14580 | Time 26.3593(26.2904) | Bit/dim 3.5170(3.5121) | Xent 0.0213(0.0183) | Loss 3.5277(3.5212) | Error 0.0056(0.0041) Steps 1030(1046.07) | Grad Norm 1.1529(0.8336) | Total Time 14.00(14.00)\n",
      "Iter 14590 | Time 26.3590(26.3294) | Bit/dim 3.5328(3.5123) | Xent 0.0179(0.0182) | Loss 3.5417(3.5213) | Error 0.0022(0.0040) Steps 1042(1045.73) | Grad Norm 0.9922(0.8220) | Total Time 14.00(14.00)\n",
      "Iter 14600 | Time 26.1103(26.3179) | Bit/dim 3.5448(3.5119) | Xent 0.0138(0.0179) | Loss 3.5517(3.5209) | Error 0.0000(0.0037) Steps 1042(1046.28) | Grad Norm 0.6915(0.8069) | Total Time 14.00(14.00)\n",
      "Iter 14610 | Time 25.9537(26.3073) | Bit/dim 3.5239(3.5101) | Xent 0.0136(0.0182) | Loss 3.5307(3.5192) | Error 0.0033(0.0040) Steps 1048(1045.98) | Grad Norm 0.5210(0.7991) | Total Time 14.00(14.00)\n",
      "Iter 14620 | Time 26.1568(26.2818) | Bit/dim 3.5158(3.5115) | Xent 0.0193(0.0183) | Loss 3.5255(3.5206) | Error 0.0067(0.0041) Steps 1048(1045.87) | Grad Norm 0.9040(0.7871) | Total Time 14.00(14.00)\n",
      "Iter 14630 | Time 26.2684(26.2663) | Bit/dim 3.5476(3.5122) | Xent 0.0204(0.0189) | Loss 3.5578(3.5216) | Error 0.0044(0.0043) Steps 1060(1046.29) | Grad Norm 0.8718(0.8100) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 120.5517, Epoch Time 1583.9977(1540.5857), Bit/dim 3.5175(best: 3.5170), Xent 1.9030, Loss 4.4690, Error 0.2713(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14640 | Time 26.7530(26.3291) | Bit/dim 3.5190(3.5116) | Xent 0.0126(0.0188) | Loss 3.5253(3.5210) | Error 0.0033(0.0043) Steps 1024(1045.92) | Grad Norm 0.7095(0.8101) | Total Time 14.00(14.00)\n",
      "Iter 14650 | Time 26.6054(26.3057) | Bit/dim 3.5087(3.5125) | Xent 0.0243(0.0186) | Loss 3.5208(3.5218) | Error 0.0067(0.0043) Steps 1060(1045.70) | Grad Norm 0.9324(0.8032) | Total Time 14.00(14.00)\n",
      "Iter 14660 | Time 26.3203(26.2954) | Bit/dim 3.5523(3.5125) | Xent 0.0185(0.0186) | Loss 3.5616(3.5218) | Error 0.0044(0.0043) Steps 1054(1047.23) | Grad Norm 0.8170(0.8092) | Total Time 14.00(14.00)\n",
      "Iter 14670 | Time 27.0813(26.3122) | Bit/dim 3.5169(3.5118) | Xent 0.0157(0.0184) | Loss 3.5248(3.5210) | Error 0.0056(0.0042) Steps 1030(1047.08) | Grad Norm 0.6209(0.8128) | Total Time 14.00(14.00)\n",
      "Iter 14680 | Time 26.4312(26.2545) | Bit/dim 3.5106(3.5118) | Xent 0.0196(0.0189) | Loss 3.5203(3.5212) | Error 0.0044(0.0044) Steps 1060(1046.73) | Grad Norm 0.6878(0.8056) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 118.9593, Epoch Time 1584.9440(1541.9165), Bit/dim 3.5159(best: 3.5170), Xent 1.9209, Loss 4.4763, Error 0.2705(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14690 | Time 26.4864(26.3314) | Bit/dim 3.5049(3.5114) | Xent 0.0225(0.0185) | Loss 3.5162(3.5206) | Error 0.0067(0.0041) Steps 1030(1048.13) | Grad Norm 1.1700(0.8095) | Total Time 14.00(14.00)\n",
      "Iter 14700 | Time 25.7881(26.2869) | Bit/dim 3.5183(3.5106) | Xent 0.0200(0.0182) | Loss 3.5283(3.5197) | Error 0.0056(0.0042) Steps 1042(1046.16) | Grad Norm 0.8006(0.8002) | Total Time 14.00(14.00)\n",
      "Iter 14710 | Time 26.6860(26.3313) | Bit/dim 3.5306(3.5095) | Xent 0.0240(0.0186) | Loss 3.5426(3.5188) | Error 0.0056(0.0042) Steps 1048(1047.42) | Grad Norm 0.8062(0.8308) | Total Time 14.00(14.00)\n",
      "Iter 14720 | Time 25.6508(26.3164) | Bit/dim 3.4991(3.5098) | Xent 0.0174(0.0186) | Loss 3.5078(3.5191) | Error 0.0044(0.0041) Steps 1054(1048.22) | Grad Norm 0.8601(0.8458) | Total Time 14.00(14.00)\n",
      "Iter 14730 | Time 26.3434(26.2806) | Bit/dim 3.5124(3.5113) | Xent 0.0199(0.0188) | Loss 3.5223(3.5207) | Error 0.0044(0.0042) Steps 1042(1050.30) | Grad Norm 0.8079(0.8560) | Total Time 14.00(14.00)\n",
      "Iter 14740 | Time 26.4996(26.3030) | Bit/dim 3.4940(3.5126) | Xent 0.0149(0.0186) | Loss 3.5014(3.5218) | Error 0.0022(0.0042) Steps 1024(1049.31) | Grad Norm 0.5830(0.8383) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 119.2748, Epoch Time 1583.3734(1543.1602), Bit/dim 3.5168(best: 3.5159), Xent 1.9366, Loss 4.4851, Error 0.2695(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14750 | Time 25.8346(26.3294) | Bit/dim 3.4858(3.5111) | Xent 0.0208(0.0190) | Loss 3.4962(3.5206) | Error 0.0056(0.0043) Steps 1030(1048.02) | Grad Norm 0.9109(0.8714) | Total Time 14.00(14.00)\n",
      "Iter 14760 | Time 26.6657(26.3590) | Bit/dim 3.5211(3.5073) | Xent 0.0163(0.0183) | Loss 3.5292(3.5164) | Error 0.0044(0.0041) Steps 1030(1046.81) | Grad Norm 0.8368(0.8517) | Total Time 14.00(14.00)\n",
      "Iter 14770 | Time 26.3277(26.2991) | Bit/dim 3.5166(3.5115) | Xent 0.0243(0.0179) | Loss 3.5287(3.5205) | Error 0.0067(0.0040) Steps 1012(1043.35) | Grad Norm 1.2017(0.8494) | Total Time 14.00(14.00)\n",
      "Iter 14780 | Time 26.2024(26.3233) | Bit/dim 3.5335(3.5126) | Xent 0.0334(0.0182) | Loss 3.5502(3.5217) | Error 0.0089(0.0041) Steps 1012(1042.69) | Grad Norm 1.2756(0.8426) | Total Time 14.00(14.00)\n",
      "Iter 14790 | Time 27.0675(26.3204) | Bit/dim 3.5163(3.5137) | Xent 0.0179(0.0183) | Loss 3.5253(3.5229) | Error 0.0033(0.0042) Steps 1042(1041.10) | Grad Norm 0.7300(0.8425) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 119.9647, Epoch Time 1584.4775(1544.3997), Bit/dim 3.5158(best: 3.5159), Xent 1.9307, Loss 4.4811, Error 0.2697(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14800 | Time 25.4643(26.2582) | Bit/dim 3.4761(3.5117) | Xent 0.0171(0.0179) | Loss 3.4846(3.5206) | Error 0.0033(0.0040) Steps 1042(1042.73) | Grad Norm 0.8309(0.8286) | Total Time 14.00(14.00)\n",
      "Iter 14810 | Time 25.8428(26.2442) | Bit/dim 3.5276(3.5134) | Xent 0.0221(0.0176) | Loss 3.5386(3.5222) | Error 0.0056(0.0039) Steps 1054(1043.43) | Grad Norm 0.8221(0.8132) | Total Time 14.00(14.00)\n",
      "Iter 14820 | Time 26.2329(26.2296) | Bit/dim 3.5097(3.5122) | Xent 0.0145(0.0173) | Loss 3.5170(3.5208) | Error 0.0022(0.0037) Steps 1042(1044.21) | Grad Norm 0.6769(0.7807) | Total Time 14.00(14.00)\n",
      "Iter 14830 | Time 25.9011(26.1762) | Bit/dim 3.4963(3.5109) | Xent 0.0173(0.0177) | Loss 3.5050(3.5197) | Error 0.0056(0.0038) Steps 1048(1044.71) | Grad Norm 1.0876(0.7948) | Total Time 14.00(14.00)\n",
      "Iter 14840 | Time 26.0527(26.1981) | Bit/dim 3.5404(3.5131) | Xent 0.0254(0.0179) | Loss 3.5531(3.5221) | Error 0.0078(0.0039) Steps 1030(1046.08) | Grad Norm 1.2297(0.7966) | Total Time 14.00(14.00)\n",
      "Iter 14850 | Time 27.2198(26.2614) | Bit/dim 3.4962(3.5111) | Xent 0.0152(0.0176) | Loss 3.5039(3.5200) | Error 0.0033(0.0038) Steps 1030(1043.40) | Grad Norm 0.9937(0.7974) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 120.0300, Epoch Time 1580.4244(1545.4804), Bit/dim 3.5149(best: 3.5158), Xent 1.9344, Loss 4.4821, Error 0.2711(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14860 | Time 25.5331(26.2263) | Bit/dim 3.5199(3.5099) | Xent 0.0123(0.0171) | Loss 3.5260(3.5185) | Error 0.0022(0.0036) Steps 1030(1042.70) | Grad Norm 0.8279(0.8025) | Total Time 14.00(14.00)\n",
      "Iter 14870 | Time 26.7917(26.2591) | Bit/dim 3.5013(3.5093) | Xent 0.0126(0.0172) | Loss 3.5076(3.5179) | Error 0.0000(0.0035) Steps 1054(1043.82) | Grad Norm 0.6934(0.8070) | Total Time 14.00(14.00)\n",
      "Iter 14880 | Time 26.0116(26.2387) | Bit/dim 3.4841(3.5102) | Xent 0.0179(0.0172) | Loss 3.4930(3.5188) | Error 0.0044(0.0036) Steps 1036(1042.90) | Grad Norm 0.6540(0.7923) | Total Time 14.00(14.00)\n",
      "Iter 14890 | Time 27.5195(26.3198) | Bit/dim 3.5077(3.5096) | Xent 0.0142(0.0176) | Loss 3.5148(3.5184) | Error 0.0022(0.0038) Steps 1036(1042.79) | Grad Norm 0.6320(0.8060) | Total Time 14.00(14.00)\n",
      "Iter 14900 | Time 26.5631(26.3059) | Bit/dim 3.5172(3.5097) | Xent 0.0119(0.0177) | Loss 3.5231(3.5186) | Error 0.0000(0.0038) Steps 1012(1043.59) | Grad Norm 0.5310(0.7863) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 119.2076, Epoch Time 1582.7404(1546.5982), Bit/dim 3.5150(best: 3.5149), Xent 1.9327, Loss 4.4814, Error 0.2715(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14910 | Time 26.6827(26.3322) | Bit/dim 3.5337(3.5128) | Xent 0.0158(0.0177) | Loss 3.5416(3.5217) | Error 0.0078(0.0039) Steps 1060(1044.58) | Grad Norm 0.8499(0.7892) | Total Time 14.00(14.00)\n",
      "Iter 14920 | Time 26.7389(26.3033) | Bit/dim 3.5258(3.5137) | Xent 0.0190(0.0173) | Loss 3.5353(3.5223) | Error 0.0056(0.0036) Steps 1072(1045.19) | Grad Norm 0.8366(0.7929) | Total Time 14.00(14.00)\n",
      "Iter 14930 | Time 26.1441(26.2680) | Bit/dim 3.5322(3.5116) | Xent 0.0230(0.0178) | Loss 3.5437(3.5205) | Error 0.0056(0.0037) Steps 1054(1046.11) | Grad Norm 0.8494(0.8108) | Total Time 14.00(14.00)\n",
      "Iter 14940 | Time 26.7367(26.3605) | Bit/dim 3.4663(3.5085) | Xent 0.0218(0.0179) | Loss 3.4772(3.5175) | Error 0.0056(0.0038) Steps 1060(1046.99) | Grad Norm 1.1546(0.8303) | Total Time 14.00(14.00)\n",
      "Iter 14950 | Time 27.4122(26.4361) | Bit/dim 3.5116(3.5093) | Xent 0.0257(0.0184) | Loss 3.5244(3.5184) | Error 0.0089(0.0041) Steps 1042(1046.94) | Grad Norm 0.9713(0.8546) | Total Time 14.00(14.00)\n",
      "Iter 14960 | Time 26.1621(26.3820) | Bit/dim 3.5118(3.5103) | Xent 0.0190(0.0187) | Loss 3.5213(3.5196) | Error 0.0067(0.0042) Steps 1036(1045.73) | Grad Norm 0.8148(0.8595) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 119.6604, Epoch Time 1589.4557(1547.8840), Bit/dim 3.5153(best: 3.5149), Xent 1.9350, Loss 4.4828, Error 0.2745(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14970 | Time 26.2931(26.3906) | Bit/dim 3.5133(3.5113) | Xent 0.0221(0.0185) | Loss 3.5244(3.5205) | Error 0.0056(0.0041) Steps 1060(1045.26) | Grad Norm 0.9242(0.8698) | Total Time 14.00(14.00)\n",
      "Iter 14980 | Time 25.2581(26.3167) | Bit/dim 3.4710(3.5116) | Xent 0.0137(0.0180) | Loss 3.4778(3.5205) | Error 0.0033(0.0039) Steps 1030(1043.03) | Grad Norm 0.7187(0.8401) | Total Time 14.00(14.00)\n",
      "Iter 14990 | Time 26.7797(26.2899) | Bit/dim 3.4752(3.5091) | Xent 0.0223(0.0179) | Loss 3.4863(3.5181) | Error 0.0056(0.0039) Steps 1048(1042.31) | Grad Norm 0.9953(0.8116) | Total Time 14.00(14.00)\n",
      "Iter 15000 | Time 26.6026(26.3441) | Bit/dim 3.5080(3.5103) | Xent 0.0190(0.0180) | Loss 3.5175(3.5193) | Error 0.0033(0.0041) Steps 1054(1043.17) | Grad Norm 1.1658(0.8380) | Total Time 14.00(14.00)\n",
      "Iter 15010 | Time 26.9328(26.3578) | Bit/dim 3.4877(3.5096) | Xent 0.0139(0.0178) | Loss 3.4946(3.5185) | Error 0.0011(0.0038) Steps 1066(1044.79) | Grad Norm 0.7665(0.8271) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 119.4423, Epoch Time 1585.4428(1549.0107), Bit/dim 3.5142(best: 3.5149), Xent 1.9355, Loss 4.4819, Error 0.2743(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15020 | Time 26.9123(26.3514) | Bit/dim 3.4898(3.5078) | Xent 0.0126(0.0178) | Loss 3.4961(3.5167) | Error 0.0033(0.0038) Steps 1042(1045.13) | Grad Norm 0.7314(0.8244) | Total Time 14.00(14.00)\n",
      "Iter 15030 | Time 26.0237(26.3299) | Bit/dim 3.5565(3.5101) | Xent 0.0172(0.0176) | Loss 3.5652(3.5189) | Error 0.0044(0.0038) Steps 1054(1045.75) | Grad Norm 0.8134(0.8416) | Total Time 14.00(14.00)\n",
      "Iter 15040 | Time 26.4499(26.3671) | Bit/dim 3.4995(3.5100) | Xent 0.0173(0.0175) | Loss 3.5081(3.5187) | Error 0.0033(0.0039) Steps 1048(1045.09) | Grad Norm 0.9676(0.8319) | Total Time 14.00(14.00)\n",
      "Iter 15050 | Time 26.6018(26.4206) | Bit/dim 3.4880(3.5069) | Xent 0.0148(0.0174) | Loss 3.4954(3.5156) | Error 0.0033(0.0038) Steps 1054(1046.43) | Grad Norm 0.6276(0.8141) | Total Time 14.00(14.00)\n",
      "Iter 15060 | Time 25.9310(26.3272) | Bit/dim 3.5037(3.5082) | Xent 0.0168(0.0177) | Loss 3.5121(3.5170) | Error 0.0044(0.0039) Steps 1054(1045.93) | Grad Norm 0.8367(0.8209) | Total Time 14.00(14.00)\n",
      "Iter 15070 | Time 25.8006(26.2519) | Bit/dim 3.5523(3.5113) | Xent 0.0151(0.0175) | Loss 3.5599(3.5200) | Error 0.0022(0.0039) Steps 1060(1045.91) | Grad Norm 0.7498(0.8176) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 118.8695, Epoch Time 1582.7875(1550.0240), Bit/dim 3.5154(best: 3.5142), Xent 1.9518, Loss 4.4913, Error 0.2723(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15080 | Time 26.2947(26.3105) | Bit/dim 3.5350(3.5103) | Xent 0.0131(0.0175) | Loss 3.5415(3.5190) | Error 0.0011(0.0038) Steps 1042(1043.90) | Grad Norm 0.7284(0.8148) | Total Time 14.00(14.00)\n",
      "Iter 15090 | Time 26.1319(26.3240) | Bit/dim 3.5205(3.5123) | Xent 0.0142(0.0178) | Loss 3.5277(3.5212) | Error 0.0000(0.0039) Steps 1048(1042.98) | Grad Norm 0.6725(0.8302) | Total Time 14.00(14.00)\n",
      "Iter 15100 | Time 27.2444(26.4324) | Bit/dim 3.5090(3.5128) | Xent 0.0149(0.0173) | Loss 3.5164(3.5215) | Error 0.0022(0.0036) Steps 1048(1045.35) | Grad Norm 0.8116(0.8221) | Total Time 14.00(14.00)\n",
      "Iter 15110 | Time 26.2501(26.4328) | Bit/dim 3.4795(3.5112) | Xent 0.0200(0.0176) | Loss 3.4895(3.5200) | Error 0.0067(0.0038) Steps 1018(1046.19) | Grad Norm 1.0188(0.8806) | Total Time 14.00(14.00)\n",
      "Iter 15120 | Time 26.5028(26.5029) | Bit/dim 3.4725(3.5078) | Xent 0.0179(0.0173) | Loss 3.4815(3.5164) | Error 0.0033(0.0038) Steps 1042(1046.49) | Grad Norm 1.0621(0.8929) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 120.3181, Epoch Time 1597.8642(1551.4592), Bit/dim 3.5138(best: 3.5142), Xent 1.9456, Loss 4.4866, Error 0.2706(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15130 | Time 26.3751(26.4646) | Bit/dim 3.5096(3.5090) | Xent 0.0120(0.0177) | Loss 3.5156(3.5179) | Error 0.0022(0.0040) Steps 1054(1047.63) | Grad Norm 0.6483(0.8978) | Total Time 14.00(14.00)\n",
      "Iter 15140 | Time 26.1357(26.4922) | Bit/dim 3.5138(3.5111) | Xent 0.0222(0.0179) | Loss 3.5249(3.5201) | Error 0.0067(0.0042) Steps 1024(1047.68) | Grad Norm 0.9100(0.9156) | Total Time 14.00(14.00)\n",
      "Iter 15150 | Time 26.0537(26.5157) | Bit/dim 3.4866(3.5084) | Xent 0.0200(0.0178) | Loss 3.4966(3.5174) | Error 0.0056(0.0041) Steps 1048(1049.20) | Grad Norm 1.0460(0.9215) | Total Time 14.00(14.00)\n",
      "Iter 15160 | Time 26.4499(26.4857) | Bit/dim 3.5247(3.5067) | Xent 0.0112(0.0175) | Loss 3.5303(3.5154) | Error 0.0000(0.0037) Steps 1066(1049.53) | Grad Norm 0.5755(0.9016) | Total Time 14.00(14.00)\n",
      "Iter 15170 | Time 26.7088(26.5009) | Bit/dim 3.5353(3.5072) | Xent 0.0228(0.0176) | Loss 3.5467(3.5160) | Error 0.0067(0.0036) Steps 1042(1051.46) | Grad Norm 1.0265(0.8826) | Total Time 14.00(14.00)\n",
      "Iter 15180 | Time 26.3360(26.4931) | Bit/dim 3.5343(3.5094) | Xent 0.0171(0.0174) | Loss 3.5429(3.5181) | Error 0.0056(0.0036) Steps 1042(1051.14) | Grad Norm 0.7157(0.8524) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 120.0458, Epoch Time 1595.4565(1552.7792), Bit/dim 3.5132(best: 3.5138), Xent 1.9664, Loss 4.4964, Error 0.2738(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15190 | Time 26.9184(26.4845) | Bit/dim 3.5000(3.5091) | Xent 0.0142(0.0178) | Loss 3.5071(3.5180) | Error 0.0022(0.0038) Steps 1030(1051.77) | Grad Norm 0.6717(0.9100) | Total Time 14.00(14.00)\n",
      "Iter 15200 | Time 25.7983(26.5181) | Bit/dim 3.5253(3.5090) | Xent 0.0259(0.0178) | Loss 3.5383(3.5179) | Error 0.0067(0.0036) Steps 1012(1050.95) | Grad Norm 1.0580(0.9079) | Total Time 14.00(14.00)\n",
      "Iter 15210 | Time 26.3254(26.4664) | Bit/dim 3.5255(3.5083) | Xent 0.0129(0.0173) | Loss 3.5319(3.5169) | Error 0.0022(0.0034) Steps 1030(1048.42) | Grad Norm 0.5240(0.9108) | Total Time 14.00(14.00)\n",
      "Iter 15220 | Time 26.8628(26.4621) | Bit/dim 3.4763(3.5061) | Xent 0.0192(0.0178) | Loss 3.4859(3.5149) | Error 0.0078(0.0040) Steps 1060(1047.62) | Grad Norm 0.9626(0.9177) | Total Time 14.00(14.00)\n",
      "Iter 15230 | Time 27.2277(26.4490) | Bit/dim 3.4998(3.5077) | Xent 0.0134(0.0172) | Loss 3.5065(3.5163) | Error 0.0022(0.0037) Steps 1036(1050.14) | Grad Norm 0.6137(0.8660) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 120.2604, Epoch Time 1594.5893(1554.0335), Bit/dim 3.5141(best: 3.5132), Xent 1.9883, Loss 4.5083, Error 0.2723(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15240 | Time 27.6197(26.5235) | Bit/dim 3.4737(3.5092) | Xent 0.0248(0.0175) | Loss 3.4862(3.5180) | Error 0.0056(0.0038) Steps 1072(1051.69) | Grad Norm 1.0269(0.8566) | Total Time 14.00(14.00)\n",
      "Iter 15250 | Time 26.8666(26.5402) | Bit/dim 3.5063(3.5097) | Xent 0.0179(0.0174) | Loss 3.5152(3.5184) | Error 0.0033(0.0037) Steps 1060(1053.97) | Grad Norm 1.0925(0.8592) | Total Time 14.00(14.00)\n",
      "Iter 15260 | Time 26.2031(26.5008) | Bit/dim 3.4971(3.5103) | Xent 0.0146(0.0173) | Loss 3.5044(3.5190) | Error 0.0022(0.0036) Steps 1048(1052.24) | Grad Norm 0.7294(0.8769) | Total Time 14.00(14.00)\n",
      "Iter 15270 | Time 26.9856(26.5955) | Bit/dim 3.4925(3.5077) | Xent 0.0203(0.0177) | Loss 3.5027(3.5165) | Error 0.0044(0.0038) Steps 1036(1052.70) | Grad Norm 1.0639(0.8952) | Total Time 14.00(14.00)\n",
      "Iter 15280 | Time 27.0381(26.5923) | Bit/dim 3.5242(3.5096) | Xent 0.0174(0.0176) | Loss 3.5330(3.5184) | Error 0.0033(0.0039) Steps 1066(1052.38) | Grad Norm 0.8234(0.8932) | Total Time 14.00(14.00)\n",
      "Iter 15290 | Time 26.8719(26.5442) | Bit/dim 3.4856(3.5064) | Xent 0.0219(0.0185) | Loss 3.4965(3.5157) | Error 0.0067(0.0044) Steps 1060(1052.25) | Grad Norm 1.1376(0.9375) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 119.8579, Epoch Time 1599.4350(1555.3955), Bit/dim 3.5127(best: 3.5132), Xent 1.9590, Loss 4.4922, Error 0.2734(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15300 | Time 26.3472(26.5074) | Bit/dim 3.5037(3.5081) | Xent 0.0183(0.0186) | Loss 3.5128(3.5174) | Error 0.0067(0.0046) Steps 1060(1049.77) | Grad Norm 0.9290(0.9579) | Total Time 14.00(14.00)\n",
      "Iter 15310 | Time 27.6440(26.5476) | Bit/dim 3.5081(3.5080) | Xent 0.0129(0.0182) | Loss 3.5145(3.5172) | Error 0.0011(0.0045) Steps 1024(1049.77) | Grad Norm 1.0161(0.9481) | Total Time 14.00(14.00)\n",
      "Iter 15320 | Time 26.8730(26.5885) | Bit/dim 3.5190(3.5081) | Xent 0.0112(0.0181) | Loss 3.5246(3.5171) | Error 0.0011(0.0041) Steps 1048(1050.92) | Grad Norm 0.6708(0.9453) | Total Time 14.00(14.00)\n",
      "Iter 15330 | Time 27.0323(26.5926) | Bit/dim 3.5492(3.5087) | Xent 0.0184(0.0182) | Loss 3.5584(3.5178) | Error 0.0056(0.0043) Steps 1054(1052.89) | Grad Norm 1.0867(0.9340) | Total Time 14.00(14.00)\n",
      "Iter 15340 | Time 26.5871(26.5665) | Bit/dim 3.4914(3.5087) | Xent 0.0169(0.0186) | Loss 3.4999(3.5180) | Error 0.0056(0.0047) Steps 1054(1052.94) | Grad Norm 0.8743(0.9432) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 120.2063, Epoch Time 1600.6788(1556.7540), Bit/dim 3.5138(best: 3.5127), Xent 1.9701, Loss 4.4989, Error 0.2707(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15350 | Time 26.7200(26.5813) | Bit/dim 3.5135(3.5065) | Xent 0.0193(0.0179) | Loss 3.5231(3.5154) | Error 0.0067(0.0045) Steps 1066(1050.64) | Grad Norm 0.9679(0.9290) | Total Time 14.00(14.00)\n",
      "Iter 15360 | Time 26.1335(26.5564) | Bit/dim 3.4733(3.5067) | Xent 0.0170(0.0177) | Loss 3.4818(3.5156) | Error 0.0011(0.0044) Steps 1054(1052.02) | Grad Norm 0.6851(0.9174) | Total Time 14.00(14.00)\n",
      "Iter 15370 | Time 25.8508(26.5392) | Bit/dim 3.4808(3.5104) | Xent 0.0264(0.0176) | Loss 3.4940(3.5192) | Error 0.0067(0.0042) Steps 1066(1052.13) | Grad Norm 1.1120(0.9010) | Total Time 14.00(14.00)\n",
      "Iter 15380 | Time 26.9821(26.5279) | Bit/dim 3.4867(3.5095) | Xent 0.0189(0.0177) | Loss 3.4961(3.5184) | Error 0.0056(0.0043) Steps 1072(1050.57) | Grad Norm 0.7644(0.8988) | Total Time 14.00(14.00)\n",
      "Iter 15390 | Time 27.3323(26.5921) | Bit/dim 3.4918(3.5074) | Xent 0.0163(0.0173) | Loss 3.5000(3.5160) | Error 0.0022(0.0042) Steps 1048(1050.30) | Grad Norm 0.9068(0.9053) | Total Time 14.00(14.00)\n",
      "Iter 15400 | Time 26.1195(26.5811) | Bit/dim 3.5005(3.5067) | Xent 0.0185(0.0175) | Loss 3.5098(3.5154) | Error 0.0044(0.0040) Steps 1066(1051.51) | Grad Norm 0.9570(0.8986) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 119.8794, Epoch Time 1598.6622(1558.0113), Bit/dim 3.5132(best: 3.5127), Xent 1.9944, Loss 4.5104, Error 0.2738(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15410 | Time 26.4089(26.6218) | Bit/dim 3.5204(3.5074) | Xent 0.0121(0.0173) | Loss 3.5264(3.5160) | Error 0.0000(0.0038) Steps 1072(1050.40) | Grad Norm 0.7330(0.9038) | Total Time 14.00(14.00)\n",
      "Iter 15420 | Time 27.3245(26.5746) | Bit/dim 3.4818(3.5065) | Xent 0.0197(0.0177) | Loss 3.4917(3.5154) | Error 0.0056(0.0038) Steps 1030(1049.38) | Grad Norm 1.2353(0.9529) | Total Time 14.00(14.00)\n",
      "Iter 15430 | Time 27.0917(26.6387) | Bit/dim 3.5081(3.5087) | Xent 0.0127(0.0173) | Loss 3.5144(3.5173) | Error 0.0022(0.0037) Steps 1060(1050.20) | Grad Norm 0.8672(0.9536) | Total Time 14.00(14.00)\n",
      "Iter 15440 | Time 26.8902(26.5702) | Bit/dim 3.4727(3.5082) | Xent 0.0215(0.0175) | Loss 3.4834(3.5170) | Error 0.0056(0.0037) Steps 1066(1050.00) | Grad Norm 1.1067(0.9579) | Total Time 14.00(14.00)\n",
      "Iter 15450 | Time 25.9774(26.5716) | Bit/dim 3.5295(3.5079) | Xent 0.0133(0.0173) | Loss 3.5361(3.5166) | Error 0.0022(0.0037) Steps 1048(1051.12) | Grad Norm 0.6644(0.9348) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 120.4912, Epoch Time 1599.2884(1559.2496), Bit/dim 3.5120(best: 3.5127), Xent 1.9765, Loss 4.5002, Error 0.2692(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15460 | Time 26.0354(26.6096) | Bit/dim 3.5010(3.5074) | Xent 0.0204(0.0177) | Loss 3.5112(3.5162) | Error 0.0022(0.0039) Steps 1042(1052.34) | Grad Norm 0.8351(0.9254) | Total Time 14.00(14.00)\n",
      "Iter 15470 | Time 26.7267(26.6940) | Bit/dim 3.5113(3.5087) | Xent 0.0164(0.0173) | Loss 3.5195(3.5174) | Error 0.0044(0.0039) Steps 1048(1052.78) | Grad Norm 0.8533(0.9136) | Total Time 14.00(14.00)\n",
      "Iter 15480 | Time 26.9398(26.7241) | Bit/dim 3.5506(3.5089) | Xent 0.0146(0.0169) | Loss 3.5579(3.5173) | Error 0.0033(0.0037) Steps 1048(1050.78) | Grad Norm 0.7192(0.8768) | Total Time 14.00(14.00)\n",
      "Iter 15490 | Time 26.9544(26.7367) | Bit/dim 3.4886(3.5066) | Xent 0.0133(0.0171) | Loss 3.4952(3.5152) | Error 0.0022(0.0037) Steps 1036(1050.19) | Grad Norm 0.6541(0.8826) | Total Time 14.00(14.00)\n",
      "Iter 15500 | Time 27.2014(26.8369) | Bit/dim 3.4975(3.5059) | Xent 0.0198(0.0171) | Loss 3.5075(3.5144) | Error 0.0044(0.0037) Steps 1066(1051.90) | Grad Norm 0.9966(0.8687) | Total Time 14.00(14.00)\n",
      "Iter 15510 | Time 26.4483(26.8365) | Bit/dim 3.4831(3.5062) | Xent 0.0273(0.0174) | Loss 3.4968(3.5149) | Error 0.0100(0.0040) Steps 1024(1051.14) | Grad Norm 1.2528(0.8767) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 120.0488, Epoch Time 1618.3786(1561.0234), Bit/dim 3.5128(best: 3.5120), Xent 2.0041, Loss 4.5148, Error 0.2698(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15520 | Time 26.8192(26.7767) | Bit/dim 3.4935(3.5051) | Xent 0.0216(0.0175) | Loss 3.5043(3.5138) | Error 0.0078(0.0042) Steps 1084(1050.86) | Grad Norm 0.9376(0.8904) | Total Time 14.00(14.00)\n",
      "Iter 15530 | Time 26.5752(26.7384) | Bit/dim 3.4998(3.5042) | Xent 0.0202(0.0173) | Loss 3.5099(3.5129) | Error 0.0033(0.0040) Steps 1036(1051.03) | Grad Norm 1.2780(0.8960) | Total Time 14.00(14.00)\n",
      "Iter 15540 | Time 26.7971(26.6174) | Bit/dim 3.4765(3.5042) | Xent 0.0140(0.0171) | Loss 3.4834(3.5128) | Error 0.0022(0.0039) Steps 1042(1048.34) | Grad Norm 0.7788(0.9026) | Total Time 14.00(14.00)\n",
      "Iter 15550 | Time 26.2054(26.5551) | Bit/dim 3.5048(3.5061) | Xent 0.0202(0.0176) | Loss 3.5149(3.5149) | Error 0.0056(0.0043) Steps 1036(1047.20) | Grad Norm 1.2491(0.9376) | Total Time 14.00(14.00)\n",
      "Iter 15560 | Time 26.9273(26.5396) | Bit/dim 3.5217(3.5068) | Xent 0.0135(0.0178) | Loss 3.5284(3.5157) | Error 0.0033(0.0043) Steps 1042(1046.66) | Grad Norm 0.7373(0.9783) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 120.2440, Epoch Time 1596.4270(1562.0855), Bit/dim 3.5119(best: 3.5120), Xent 1.9996, Loss 4.5117, Error 0.2720(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15570 | Time 25.8523(26.5544) | Bit/dim 3.5232(3.5085) | Xent 0.0189(0.0177) | Loss 3.5326(3.5174) | Error 0.0056(0.0042) Steps 1042(1048.54) | Grad Norm 0.9098(1.0157) | Total Time 14.00(14.00)\n",
      "Iter 15580 | Time 26.1805(26.5140) | Bit/dim 3.4782(3.5075) | Xent 0.0160(0.0175) | Loss 3.4862(3.5163) | Error 0.0044(0.0043) Steps 1054(1047.65) | Grad Norm 0.9629(0.9807) | Total Time 14.00(14.00)\n",
      "Iter 15590 | Time 26.3754(26.5601) | Bit/dim 3.5037(3.5069) | Xent 0.0139(0.0179) | Loss 3.5106(3.5158) | Error 0.0000(0.0044) Steps 1042(1047.56) | Grad Norm 0.6503(0.9512) | Total Time 14.00(14.00)\n",
      "Iter 15600 | Time 26.8497(26.5591) | Bit/dim 3.5137(3.5071) | Xent 0.0185(0.0184) | Loss 3.5229(3.5163) | Error 0.0044(0.0048) Steps 1066(1049.67) | Grad Norm 0.8716(0.9594) | Total Time 14.00(14.00)\n",
      "Iter 15610 | Time 26.4833(26.5892) | Bit/dim 3.5186(3.5067) | Xent 0.0174(0.0178) | Loss 3.5273(3.5156) | Error 0.0033(0.0045) Steps 1054(1050.63) | Grad Norm 1.0491(0.9509) | Total Time 14.00(14.00)\n",
      "Iter 15620 | Time 27.0774(26.5909) | Bit/dim 3.4906(3.5077) | Xent 0.0212(0.0174) | Loss 3.5012(3.5164) | Error 0.0067(0.0041) Steps 1066(1052.28) | Grad Norm 1.0614(0.9190) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 119.3303, Epoch Time 1599.1411(1563.1972), Bit/dim 3.5122(best: 3.5119), Xent 2.0295, Loss 4.5269, Error 0.2714(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15630 | Time 26.6643(26.6618) | Bit/dim 3.4927(3.5070) | Xent 0.0139(0.0168) | Loss 3.4996(3.5154) | Error 0.0044(0.0040) Steps 1042(1051.48) | Grad Norm 0.7121(0.8972) | Total Time 14.00(14.00)\n",
      "Iter 15640 | Time 26.5966(26.7428) | Bit/dim 3.5466(3.5067) | Xent 0.0199(0.0167) | Loss 3.5565(3.5151) | Error 0.0078(0.0039) Steps 1042(1052.40) | Grad Norm 1.2321(0.8883) | Total Time 14.00(14.00)\n",
      "Iter 15650 | Time 26.8269(26.6987) | Bit/dim 3.4875(3.5048) | Xent 0.0179(0.0171) | Loss 3.4965(3.5134) | Error 0.0056(0.0040) Steps 1048(1052.10) | Grad Norm 0.9143(0.8801) | Total Time 14.00(14.00)\n",
      "Iter 15660 | Time 26.9284(26.6838) | Bit/dim 3.5080(3.5055) | Xent 0.0123(0.0170) | Loss 3.5142(3.5139) | Error 0.0022(0.0038) Steps 1024(1053.46) | Grad Norm 0.6743(0.8751) | Total Time 14.00(14.00)\n",
      "Iter 15670 | Time 26.6426(26.7474) | Bit/dim 3.5166(3.5083) | Xent 0.0239(0.0175) | Loss 3.5286(3.5170) | Error 0.0078(0.0040) Steps 1060(1051.87) | Grad Norm 1.3351(0.8796) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 120.0402, Epoch Time 1613.2355(1564.6984), Bit/dim 3.5108(best: 3.5119), Xent 2.0364, Loss 4.5290, Error 0.2746(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15680 | Time 26.4643(26.7953) | Bit/dim 3.5132(3.5076) | Xent 0.0229(0.0174) | Loss 3.5247(3.5163) | Error 0.0067(0.0038) Steps 1060(1054.06) | Grad Norm 1.0776(0.8630) | Total Time 14.00(14.00)\n",
      "Iter 15690 | Time 26.7421(26.7377) | Bit/dim 3.5196(3.5091) | Xent 0.0153(0.0169) | Loss 3.5273(3.5175) | Error 0.0033(0.0037) Steps 1066(1052.68) | Grad Norm 0.9536(0.8896) | Total Time 14.00(14.00)\n",
      "Iter 15700 | Time 26.6705(26.6722) | Bit/dim 3.5068(3.5070) | Xent 0.0241(0.0171) | Loss 3.5188(3.5155) | Error 0.0078(0.0038) Steps 1024(1050.04) | Grad Norm 1.0221(0.8822) | Total Time 14.00(14.00)\n",
      "Iter 15710 | Time 27.4759(26.7044) | Bit/dim 3.4970(3.5070) | Xent 0.0164(0.0167) | Loss 3.5052(3.5154) | Error 0.0022(0.0038) Steps 1042(1050.68) | Grad Norm 0.9109(0.8792) | Total Time 14.00(14.00)\n",
      "Iter 15720 | Time 26.5529(26.6933) | Bit/dim 3.5006(3.5056) | Xent 0.0129(0.0169) | Loss 3.5070(3.5140) | Error 0.0011(0.0037) Steps 1042(1052.77) | Grad Norm 0.7818(0.8727) | Total Time 14.00(14.00)\n",
      "Iter 15730 | Time 26.9030(26.6628) | Bit/dim 3.5029(3.5059) | Xent 0.0234(0.0169) | Loss 3.5146(3.5143) | Error 0.0022(0.0037) Steps 1060(1053.25) | Grad Norm 1.2098(0.8706) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 119.6655, Epoch Time 1602.0007(1565.8174), Bit/dim 3.5104(best: 3.5108), Xent 2.0203, Loss 4.5206, Error 0.2757(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15740 | Time 26.5183(26.5549) | Bit/dim 3.5236(3.5049) | Xent 0.0122(0.0171) | Loss 3.5297(3.5134) | Error 0.0011(0.0036) Steps 1036(1053.46) | Grad Norm 0.7983(0.8809) | Total Time 14.00(14.00)\n",
      "Iter 15750 | Time 26.7763(26.5386) | Bit/dim 3.5084(3.5045) | Xent 0.0223(0.0166) | Loss 3.5195(3.5128) | Error 0.0067(0.0036) Steps 1078(1053.48) | Grad Norm 1.0483(0.8812) | Total Time 14.00(14.00)\n",
      "Iter 15760 | Time 26.5044(26.4896) | Bit/dim 3.5185(3.5047) | Xent 0.0171(0.0167) | Loss 3.5270(3.5131) | Error 0.0067(0.0037) Steps 1018(1054.05) | Grad Norm 1.0226(0.9054) | Total Time 14.00(14.00)\n",
      "Iter 15770 | Time 26.5014(26.5174) | Bit/dim 3.5116(3.5042) | Xent 0.0149(0.0169) | Loss 3.5191(3.5126) | Error 0.0033(0.0039) Steps 1048(1053.92) | Grad Norm 0.7828(0.9137) | Total Time 14.00(14.00)\n",
      "Iter 15780 | Time 26.6225(26.6496) | Bit/dim 3.5205(3.5060) | Xent 0.0195(0.0171) | Loss 3.5302(3.5146) | Error 0.0044(0.0039) Steps 1060(1053.76) | Grad Norm 1.2115(0.9125) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 119.2961, Epoch Time 1596.7684(1566.7460), Bit/dim 3.5110(best: 3.5104), Xent 2.0244, Loss 4.5232, Error 0.2725(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15790 | Time 26.5476(26.6017) | Bit/dim 3.4549(3.5070) | Xent 0.0146(0.0166) | Loss 3.4622(3.5153) | Error 0.0033(0.0037) Steps 1054(1054.56) | Grad Norm 1.2873(0.8982) | Total Time 14.00(14.00)\n",
      "Iter 15800 | Time 26.9741(26.5807) | Bit/dim 3.5310(3.5078) | Xent 0.0124(0.0162) | Loss 3.5373(3.5159) | Error 0.0022(0.0035) Steps 1042(1054.35) | Grad Norm 0.8093(0.8964) | Total Time 14.00(14.00)\n",
      "Iter 15810 | Time 26.6469(26.6006) | Bit/dim 3.5231(3.5069) | Xent 0.0163(0.0162) | Loss 3.5313(3.5150) | Error 0.0033(0.0035) Steps 1042(1053.40) | Grad Norm 1.1699(0.9489) | Total Time 14.00(14.00)\n",
      "Iter 15820 | Time 27.4860(26.5760) | Bit/dim 3.5162(3.5053) | Xent 0.0192(0.0160) | Loss 3.5258(3.5133) | Error 0.0067(0.0034) Steps 1078(1054.77) | Grad Norm 1.4583(0.9732) | Total Time 14.00(14.00)\n",
      "Iter 15830 | Time 26.3697(26.5646) | Bit/dim 3.5320(3.5057) | Xent 0.0242(0.0163) | Loss 3.5441(3.5138) | Error 0.0111(0.0037) Steps 1048(1056.37) | Grad Norm 0.9886(0.9636) | Total Time 14.00(14.00)\n",
      "Iter 15840 | Time 25.2297(26.4944) | Bit/dim 3.4891(3.5054) | Xent 0.0199(0.0170) | Loss 3.4991(3.5139) | Error 0.0033(0.0039) Steps 1048(1056.00) | Grad Norm 0.9015(0.9701) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 119.5331, Epoch Time 1595.4718(1567.6077), Bit/dim 3.5105(best: 3.5104), Xent 2.0412, Loss 4.5311, Error 0.2780(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15850 | Time 26.0704(26.4781) | Bit/dim 3.4751(3.5027) | Xent 0.0164(0.0170) | Loss 3.4832(3.5112) | Error 0.0011(0.0039) Steps 1054(1056.35) | Grad Norm 1.1324(0.9692) | Total Time 14.00(14.00)\n",
      "Iter 15860 | Time 26.4591(26.5120) | Bit/dim 3.5090(3.5047) | Xent 0.0231(0.0169) | Loss 3.5205(3.5131) | Error 0.0044(0.0038) Steps 1066(1058.33) | Grad Norm 1.1499(0.9420) | Total Time 14.00(14.00)\n",
      "Iter 15870 | Time 26.7220(26.5859) | Bit/dim 3.5465(3.5058) | Xent 0.0165(0.0169) | Loss 3.5548(3.5143) | Error 0.0044(0.0037) Steps 1066(1059.64) | Grad Norm 1.1945(0.9621) | Total Time 14.00(14.00)\n",
      "Iter 15880 | Time 26.9703(26.6065) | Bit/dim 3.4997(3.5066) | Xent 0.0155(0.0164) | Loss 3.5075(3.5148) | Error 0.0022(0.0037) Steps 1048(1059.65) | Grad Norm 0.7047(0.9316) | Total Time 14.00(14.00)\n",
      "Iter 15890 | Time 25.8126(26.5546) | Bit/dim 3.4938(3.5068) | Xent 0.0139(0.0164) | Loss 3.5007(3.5150) | Error 0.0033(0.0037) Steps 1048(1058.83) | Grad Norm 1.1018(0.9367) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 120.6705, Epoch Time 1599.5147(1568.5649), Bit/dim 3.5108(best: 3.5104), Xent 2.0194, Loss 4.5205, Error 0.2766(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15900 | Time 26.3252(26.5325) | Bit/dim 3.4936(3.5035) | Xent 0.0191(0.0163) | Loss 3.5031(3.5116) | Error 0.0044(0.0037) Steps 1036(1056.13) | Grad Norm 0.9578(0.9181) | Total Time 14.00(14.00)\n",
      "Iter 15910 | Time 26.4874(26.5451) | Bit/dim 3.5051(3.5039) | Xent 0.0104(0.0162) | Loss 3.5103(3.5120) | Error 0.0011(0.0034) Steps 1024(1053.84) | Grad Norm 0.6411(0.9079) | Total Time 14.00(14.00)\n",
      "Iter 15920 | Time 27.1355(26.5819) | Bit/dim 3.4839(3.5004) | Xent 0.0188(0.0169) | Loss 3.4933(3.5089) | Error 0.0056(0.0039) Steps 1078(1054.70) | Grad Norm 1.0073(0.9181) | Total Time 14.00(14.00)\n",
      "Iter 15930 | Time 26.1056(26.6047) | Bit/dim 3.5323(3.5066) | Xent 0.0140(0.0168) | Loss 3.5393(3.5150) | Error 0.0022(0.0038) Steps 1030(1053.22) | Grad Norm 0.8270(0.9309) | Total Time 14.00(14.00)\n",
      "Iter 15940 | Time 26.0723(26.5961) | Bit/dim 3.5076(3.5055) | Xent 0.0222(0.0171) | Loss 3.5187(3.5140) | Error 0.0067(0.0039) Steps 1072(1055.26) | Grad Norm 1.1741(0.9404) | Total Time 14.00(14.00)\n",
      "Iter 15950 | Time 26.3273(26.6410) | Bit/dim 3.5329(3.5066) | Xent 0.0172(0.0170) | Loss 3.5415(3.5151) | Error 0.0033(0.0038) Steps 1048(1051.98) | Grad Norm 1.0065(0.9214) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 120.3571, Epoch Time 1604.0921(1569.6308), Bit/dim 3.5107(best: 3.5104), Xent 2.0319, Loss 4.5267, Error 0.2722(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15960 | Time 26.4842(26.6405) | Bit/dim 3.5010(3.5054) | Xent 0.0118(0.0163) | Loss 3.5069(3.5136) | Error 0.0022(0.0034) Steps 1060(1050.74) | Grad Norm 0.7803(0.9173) | Total Time 14.00(14.00)\n",
      "Iter 15970 | Time 26.9920(26.6771) | Bit/dim 3.4950(3.5058) | Xent 0.0186(0.0167) | Loss 3.5043(3.5141) | Error 0.0022(0.0034) Steps 1060(1051.12) | Grad Norm 1.1841(0.9566) | Total Time 14.00(14.00)\n",
      "Iter 15980 | Time 27.3687(26.6106) | Bit/dim 3.5079(3.5059) | Xent 0.0106(0.0168) | Loss 3.5133(3.5144) | Error 0.0000(0.0035) Steps 1054(1051.95) | Grad Norm 0.8862(0.9733) | Total Time 14.00(14.00)\n",
      "Iter 15990 | Time 26.9421(26.6295) | Bit/dim 3.5344(3.5057) | Xent 0.0165(0.0162) | Loss 3.5427(3.5138) | Error 0.0056(0.0034) Steps 1072(1054.18) | Grad Norm 0.8396(0.9418) | Total Time 14.00(14.00)\n",
      "Iter 16000 | Time 27.0667(26.5912) | Bit/dim 3.5079(3.5062) | Xent 0.0142(0.0164) | Loss 3.5150(3.5144) | Error 0.0022(0.0034) Steps 1060(1051.87) | Grad Norm 0.8322(0.9228) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 119.2951, Epoch Time 1600.8900(1570.5685), Bit/dim 3.5103(best: 3.5104), Xent 2.0382, Loss 4.5294, Error 0.2742(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16010 | Time 27.9043(26.6049) | Bit/dim 3.4864(3.5052) | Xent 0.0140(0.0162) | Loss 3.4934(3.5133) | Error 0.0033(0.0035) Steps 1066(1051.29) | Grad Norm 0.8156(0.9148) | Total Time 14.00(14.00)\n",
      "Iter 16020 | Time 26.1573(26.6655) | Bit/dim 3.5042(3.5060) | Xent 0.0116(0.0160) | Loss 3.5100(3.5140) | Error 0.0011(0.0036) Steps 1066(1054.54) | Grad Norm 0.7960(0.9053) | Total Time 14.00(14.00)\n",
      "Iter 16030 | Time 27.0463(26.6310) | Bit/dim 3.4910(3.5058) | Xent 0.0142(0.0161) | Loss 3.4982(3.5139) | Error 0.0033(0.0039) Steps 1066(1053.28) | Grad Norm 0.6591(0.9188) | Total Time 14.00(14.00)\n",
      "Iter 16040 | Time 26.3118(26.5657) | Bit/dim 3.5264(3.5044) | Xent 0.0138(0.0163) | Loss 3.5333(3.5125) | Error 0.0022(0.0036) Steps 1066(1050.98) | Grad Norm 0.6791(0.9075) | Total Time 14.00(14.00)\n",
      "Iter 16050 | Time 26.7953(26.5878) | Bit/dim 3.4799(3.5043) | Xent 0.0166(0.0164) | Loss 3.4882(3.5125) | Error 0.0044(0.0039) Steps 1066(1053.97) | Grad Norm 0.7069(0.9306) | Total Time 14.00(14.00)\n",
      "Iter 16060 | Time 26.6658(26.5624) | Bit/dim 3.5107(3.5045) | Xent 0.0184(0.0166) | Loss 3.5198(3.5128) | Error 0.0056(0.0041) Steps 1042(1054.31) | Grad Norm 0.8129(0.9303) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 119.3553, Epoch Time 1599.0670(1571.4235), Bit/dim 3.5093(best: 3.5103), Xent 2.0287, Loss 4.5236, Error 0.2739(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16070 | Time 25.6018(26.5012) | Bit/dim 3.4817(3.4998) | Xent 0.0229(0.0170) | Loss 3.4932(3.5083) | Error 0.0067(0.0043) Steps 1060(1055.47) | Grad Norm 1.4224(0.9805) | Total Time 14.00(14.00)\n",
      "Iter 16080 | Time 26.9178(26.5075) | Bit/dim 3.5202(3.5009) | Xent 0.0112(0.0168) | Loss 3.5258(3.5093) | Error 0.0011(0.0043) Steps 1036(1055.71) | Grad Norm 0.7017(0.9933) | Total Time 14.00(14.00)\n",
      "Iter 16090 | Time 26.9451(26.5543) | Bit/dim 3.5231(3.5022) | Xent 0.0186(0.0169) | Loss 3.5324(3.5107) | Error 0.0044(0.0042) Steps 1054(1055.70) | Grad Norm 1.6420(1.0367) | Total Time 14.00(14.00)\n",
      "Iter 16100 | Time 26.5519(26.5049) | Bit/dim 3.5227(3.5044) | Xent 0.0231(0.0174) | Loss 3.5342(3.5131) | Error 0.0067(0.0040) Steps 1060(1055.24) | Grad Norm 1.2148(1.0499) | Total Time 14.00(14.00)\n",
      "Iter 16110 | Time 26.6947(26.5281) | Bit/dim 3.5181(3.5080) | Xent 0.0154(0.0174) | Loss 3.5258(3.5166) | Error 0.0033(0.0043) Steps 1036(1055.02) | Grad Norm 0.9402(1.0446) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 120.6946, Epoch Time 1597.8265(1572.2156), Bit/dim 3.5089(best: 3.5093), Xent 2.0534, Loss 4.5356, Error 0.2695(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16120 | Time 27.3856(26.5969) | Bit/dim 3.5009(3.5044) | Xent 0.0178(0.0172) | Loss 3.5097(3.5130) | Error 0.0044(0.0041) Steps 1042(1056.61) | Grad Norm 0.9826(1.0326) | Total Time 14.00(14.00)\n",
      "Iter 16130 | Time 26.8120(26.5783) | Bit/dim 3.4583(3.5036) | Xent 0.0191(0.0172) | Loss 3.4679(3.5122) | Error 0.0044(0.0041) Steps 1054(1056.38) | Grad Norm 1.3220(1.0165) | Total Time 14.00(14.00)\n",
      "Iter 16140 | Time 27.2081(26.5968) | Bit/dim 3.5010(3.5067) | Xent 0.0164(0.0168) | Loss 3.5092(3.5151) | Error 0.0044(0.0040) Steps 1078(1058.32) | Grad Norm 1.0159(0.9977) | Total Time 14.00(14.00)\n",
      "Iter 16150 | Time 27.5196(26.6131) | Bit/dim 3.5235(3.5078) | Xent 0.0193(0.0167) | Loss 3.5331(3.5162) | Error 0.0056(0.0039) Steps 1078(1057.65) | Grad Norm 1.0550(0.9936) | Total Time 14.00(14.00)\n",
      "Iter 16160 | Time 26.4180(26.5845) | Bit/dim 3.4991(3.5058) | Xent 0.0110(0.0166) | Loss 3.5046(3.5141) | Error 0.0011(0.0037) Steps 1054(1057.51) | Grad Norm 0.8570(0.9819) | Total Time 14.00(14.00)\n",
      "Iter 16170 | Time 26.7055(26.6117) | Bit/dim 3.4932(3.5033) | Xent 0.0179(0.0166) | Loss 3.5022(3.5116) | Error 0.0022(0.0038) Steps 1072(1058.67) | Grad Norm 0.9505(0.9716) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 120.6031, Epoch Time 1602.3585(1573.1199), Bit/dim 3.5090(best: 3.5089), Xent 2.0692, Loss 4.5436, Error 0.2730(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16180 | Time 26.9931(26.6370) | Bit/dim 3.5204(3.5015) | Xent 0.0196(0.0169) | Loss 3.5302(3.5099) | Error 0.0056(0.0039) Steps 1054(1058.83) | Grad Norm 1.3677(1.0270) | Total Time 14.00(14.00)\n",
      "Iter 16190 | Time 27.1967(26.6857) | Bit/dim 3.5220(3.5008) | Xent 0.0211(0.0168) | Loss 3.5326(3.5092) | Error 0.0033(0.0037) Steps 1084(1058.04) | Grad Norm 1.5359(1.0178) | Total Time 14.00(14.00)\n",
      "Iter 16200 | Time 27.4101(26.6679) | Bit/dim 3.5095(3.5020) | Xent 0.0148(0.0167) | Loss 3.5169(3.5103) | Error 0.0022(0.0036) Steps 1036(1056.55) | Grad Norm 0.9709(0.9960) | Total Time 14.00(14.00)\n",
      "Iter 16210 | Time 26.5769(26.6386) | Bit/dim 3.5170(3.5035) | Xent 0.0144(0.0170) | Loss 3.5242(3.5120) | Error 0.0044(0.0039) Steps 1066(1056.71) | Grad Norm 0.9210(0.9960) | Total Time 14.00(14.00)\n",
      "Iter 16220 | Time 26.8603(26.6534) | Bit/dim 3.5321(3.5044) | Xent 0.0190(0.0168) | Loss 3.5416(3.5128) | Error 0.0056(0.0039) Steps 1048(1055.25) | Grad Norm 1.0423(0.9904) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 121.1664, Epoch Time 1606.9286(1574.1341), Bit/dim 3.5098(best: 3.5089), Xent 2.0626, Loss 4.5410, Error 0.2728(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16230 | Time 27.1157(26.6873) | Bit/dim 3.5258(3.5032) | Xent 0.0114(0.0167) | Loss 3.5315(3.5116) | Error 0.0033(0.0039) Steps 1042(1054.49) | Grad Norm 0.6619(0.9649) | Total Time 14.00(14.00)\n",
      "Iter 16240 | Time 26.8242(26.6875) | Bit/dim 3.4913(3.5000) | Xent 0.0113(0.0167) | Loss 3.4970(3.5084) | Error 0.0033(0.0039) Steps 1048(1052.59) | Grad Norm 0.8508(0.9844) | Total Time 14.00(14.00)\n",
      "Iter 16250 | Time 26.4420(26.6504) | Bit/dim 3.4939(3.5005) | Xent 0.0182(0.0168) | Loss 3.5030(3.5089) | Error 0.0033(0.0040) Steps 1048(1053.07) | Grad Norm 0.9634(1.0132) | Total Time 14.00(14.00)\n",
      "Iter 16260 | Time 25.9381(26.6762) | Bit/dim 3.4939(3.5027) | Xent 0.0221(0.0167) | Loss 3.5049(3.5111) | Error 0.0033(0.0039) Steps 1072(1056.14) | Grad Norm 0.9764(1.0114) | Total Time 14.00(14.00)\n",
      "Iter 16270 | Time 26.7823(26.6030) | Bit/dim 3.5009(3.5051) | Xent 0.0192(0.0164) | Loss 3.5104(3.5133) | Error 0.0067(0.0039) Steps 1072(1056.11) | Grad Norm 0.8625(0.9884) | Total Time 14.00(14.00)\n",
      "Iter 16280 | Time 26.6804(26.5587) | Bit/dim 3.4803(3.5049) | Xent 0.0148(0.0165) | Loss 3.4877(3.5131) | Error 0.0011(0.0037) Steps 1066(1055.40) | Grad Norm 1.2378(1.0081) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 120.1651, Epoch Time 1600.4517(1574.9237), Bit/dim 3.5085(best: 3.5089), Xent 2.0687, Loss 4.5428, Error 0.2693(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16290 | Time 26.6547(26.5945) | Bit/dim 3.4826(3.5057) | Xent 0.0150(0.0165) | Loss 3.4901(3.5139) | Error 0.0056(0.0039) Steps 1048(1056.01) | Grad Norm 0.7942(1.0044) | Total Time 14.00(14.00)\n",
      "Iter 16300 | Time 26.3617(26.6409) | Bit/dim 3.5348(3.5047) | Xent 0.0147(0.0168) | Loss 3.5422(3.5131) | Error 0.0022(0.0040) Steps 1054(1055.13) | Grad Norm 0.8442(0.9878) | Total Time 14.00(14.00)\n",
      "Iter 16310 | Time 26.2698(26.6463) | Bit/dim 3.5177(3.5052) | Xent 0.0163(0.0165) | Loss 3.5258(3.5134) | Error 0.0033(0.0039) Steps 1054(1054.51) | Grad Norm 0.7701(0.9671) | Total Time 14.00(14.00)\n",
      "Iter 16320 | Time 26.4680(26.6554) | Bit/dim 3.4826(3.5052) | Xent 0.0137(0.0161) | Loss 3.4895(3.5132) | Error 0.0022(0.0037) Steps 1048(1056.55) | Grad Norm 0.7541(0.9288) | Total Time 14.00(14.00)\n",
      "Iter 16330 | Time 26.9589(26.6476) | Bit/dim 3.4713(3.4999) | Xent 0.0140(0.0166) | Loss 3.4783(3.5083) | Error 0.0044(0.0038) Steps 1036(1054.11) | Grad Norm 0.8094(0.9375) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 119.1444, Epoch Time 1609.0004(1575.9460), Bit/dim 3.5090(best: 3.5085), Xent 2.0951, Loss 4.5565, Error 0.2725(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16340 | Time 26.0594(26.6935) | Bit/dim 3.4985(3.5029) | Xent 0.0168(0.0165) | Loss 3.5069(3.5111) | Error 0.0044(0.0038) Steps 1048(1053.27) | Grad Norm 1.0271(0.9548) | Total Time 14.00(14.00)\n",
      "Iter 16350 | Time 26.8342(26.7408) | Bit/dim 3.5015(3.5019) | Xent 0.0156(0.0167) | Loss 3.5093(3.5102) | Error 0.0033(0.0040) Steps 1048(1055.71) | Grad Norm 1.0840(0.9610) | Total Time 14.00(14.00)\n",
      "Iter 16360 | Time 27.4621(26.7046) | Bit/dim 3.4801(3.5013) | Xent 0.0140(0.0162) | Loss 3.4871(3.5094) | Error 0.0022(0.0038) Steps 1048(1057.06) | Grad Norm 0.8068(0.9331) | Total Time 14.00(14.00)\n",
      "Iter 16370 | Time 25.8731(26.6910) | Bit/dim 3.4996(3.5038) | Xent 0.0154(0.0169) | Loss 3.5073(3.5123) | Error 0.0022(0.0040) Steps 1030(1053.62) | Grad Norm 1.1752(0.9840) | Total Time 14.00(14.00)\n",
      "Iter 16380 | Time 26.2076(26.6496) | Bit/dim 3.5109(3.5013) | Xent 0.0114(0.0175) | Loss 3.5166(3.5101) | Error 0.0022(0.0044) Steps 1048(1052.86) | Grad Norm 1.0820(1.0840) | Total Time 14.00(14.00)\n",
      "Iter 16390 | Time 26.9047(26.6448) | Bit/dim 3.5105(3.5035) | Xent 0.0189(0.0169) | Loss 3.5199(3.5120) | Error 0.0056(0.0042) Steps 1078(1054.81) | Grad Norm 1.4419(1.1146) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 120.3598, Epoch Time 1602.6887(1576.7482), Bit/dim 3.5087(best: 3.5085), Xent 2.0766, Loss 4.5470, Error 0.2751(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16400 | Time 25.4695(26.5616) | Bit/dim 3.4772(3.5031) | Xent 0.0152(0.0164) | Loss 3.4848(3.5113) | Error 0.0022(0.0038) Steps 1042(1055.40) | Grad Norm 1.2167(1.1095) | Total Time 14.00(14.00)\n",
      "Iter 16410 | Time 26.5293(26.4764) | Bit/dim 3.4775(3.5014) | Xent 0.0177(0.0163) | Loss 3.4864(3.5095) | Error 0.0033(0.0037) Steps 1054(1054.09) | Grad Norm 1.0248(1.1374) | Total Time 14.00(14.00)\n",
      "Iter 16420 | Time 26.3026(26.4899) | Bit/dim 3.4962(3.5033) | Xent 0.0191(0.0162) | Loss 3.5058(3.5114) | Error 0.0056(0.0036) Steps 1054(1057.54) | Grad Norm 0.9384(1.0972) | Total Time 14.00(14.00)\n",
      "Iter 16430 | Time 26.0671(26.5069) | Bit/dim 3.5341(3.5048) | Xent 0.0154(0.0163) | Loss 3.5418(3.5130) | Error 0.0022(0.0037) Steps 1042(1058.32) | Grad Norm 0.8118(1.0480) | Total Time 14.00(14.00)\n",
      "Iter 16440 | Time 26.6271(26.4702) | Bit/dim 3.4917(3.5040) | Xent 0.0174(0.0164) | Loss 3.5004(3.5122) | Error 0.0067(0.0039) Steps 1048(1056.69) | Grad Norm 0.8688(1.0520) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 120.0424, Epoch Time 1592.2500(1577.2133), Bit/dim 3.5071(best: 3.5085), Xent 2.1005, Loss 4.5574, Error 0.2725(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16450 | Time 26.6610(26.5072) | Bit/dim 3.5001(3.5009) | Xent 0.0164(0.0165) | Loss 3.5084(3.5092) | Error 0.0044(0.0038) Steps 1078(1058.92) | Grad Norm 1.2796(1.0378) | Total Time 14.00(14.00)\n",
      "Iter 16460 | Time 26.7702(26.4822) | Bit/dim 3.5091(3.4998) | Xent 0.0197(0.0162) | Loss 3.5190(3.5079) | Error 0.0067(0.0036) Steps 1054(1055.40) | Grad Norm 0.9318(0.9973) | Total Time 14.00(14.00)\n",
      "Iter 16470 | Time 26.5459(26.4742) | Bit/dim 3.4702(3.5005) | Xent 0.0176(0.0160) | Loss 3.4790(3.5086) | Error 0.0033(0.0037) Steps 1060(1055.29) | Grad Norm 0.9954(0.9889) | Total Time 14.00(14.00)\n",
      "Iter 16480 | Time 26.2976(26.5007) | Bit/dim 3.5163(3.5008) | Xent 0.0138(0.0165) | Loss 3.5232(3.5090) | Error 0.0011(0.0037) Steps 1054(1056.98) | Grad Norm 0.9272(1.0184) | Total Time 14.00(14.00)\n",
      "Iter 16490 | Time 26.8866(26.4755) | Bit/dim 3.5309(3.5034) | Xent 0.0207(0.0164) | Loss 3.5413(3.5116) | Error 0.0089(0.0039) Steps 1012(1051.79) | Grad Norm 0.9946(1.0107) | Total Time 14.00(14.00)\n",
      "Iter 16500 | Time 26.2074(26.5019) | Bit/dim 3.5117(3.5040) | Xent 0.0167(0.0165) | Loss 3.5201(3.5123) | Error 0.0033(0.0039) Steps 1066(1051.37) | Grad Norm 1.1862(1.0275) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 120.1532, Epoch Time 1595.8165(1577.7714), Bit/dim 3.5069(best: 3.5071), Xent 2.1086, Loss 4.5612, Error 0.2740(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16510 | Time 26.2037(26.4892) | Bit/dim 3.5170(3.5021) | Xent 0.0173(0.0165) | Loss 3.5257(3.5104) | Error 0.0022(0.0040) Steps 1048(1051.75) | Grad Norm 1.1397(1.0570) | Total Time 14.00(14.00)\n",
      "Iter 16520 | Time 26.4706(26.4491) | Bit/dim 3.5114(3.5012) | Xent 0.0271(0.0168) | Loss 3.5249(3.5096) | Error 0.0089(0.0043) Steps 1060(1052.10) | Grad Norm 1.0629(1.0434) | Total Time 14.00(14.00)\n",
      "Iter 16530 | Time 26.7441(26.4534) | Bit/dim 3.5325(3.5037) | Xent 0.0146(0.0166) | Loss 3.5398(3.5120) | Error 0.0022(0.0040) Steps 1078(1052.92) | Grad Norm 0.7969(1.0073) | Total Time 14.00(14.00)\n",
      "Iter 16540 | Time 26.5452(26.4701) | Bit/dim 3.5077(3.5033) | Xent 0.0159(0.0168) | Loss 3.5157(3.5117) | Error 0.0056(0.0042) Steps 1084(1054.85) | Grad Norm 0.7721(1.0003) | Total Time 14.00(14.00)\n",
      "Iter 16550 | Time 26.9264(26.5537) | Bit/dim 3.5107(3.5035) | Xent 0.0145(0.0165) | Loss 3.5179(3.5117) | Error 0.0022(0.0041) Steps 1060(1054.83) | Grad Norm 0.9051(0.9921) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 119.9268, Epoch Time 1598.2604(1578.3861), Bit/dim 3.5074(best: 3.5069), Xent 2.1077, Loss 4.5613, Error 0.2745(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16560 | Time 26.9964(26.6510) | Bit/dim 3.4907(3.5027) | Xent 0.0158(0.0169) | Loss 3.4985(3.5111) | Error 0.0044(0.0042) Steps 1072(1055.41) | Grad Norm 0.9587(1.0268) | Total Time 14.00(14.00)\n",
      "Iter 16570 | Time 26.5988(26.7347) | Bit/dim 3.5512(3.5016) | Xent 0.0131(0.0166) | Loss 3.5577(3.5099) | Error 0.0022(0.0038) Steps 1072(1058.92) | Grad Norm 0.6573(1.0267) | Total Time 14.00(14.00)\n",
      "Iter 16580 | Time 26.0492(26.7278) | Bit/dim 3.5006(3.4997) | Xent 0.0176(0.0161) | Loss 3.5094(3.5078) | Error 0.0044(0.0036) Steps 1042(1058.71) | Grad Norm 0.9450(0.9919) | Total Time 14.00(14.00)\n",
      "Iter 16590 | Time 27.0249(26.6915) | Bit/dim 3.4581(3.5021) | Xent 0.0190(0.0165) | Loss 3.4675(3.5104) | Error 0.0044(0.0037) Steps 1060(1059.67) | Grad Norm 1.0690(1.0265) | Total Time 14.00(14.00)\n",
      "Iter 16600 | Time 27.1460(26.6519) | Bit/dim 3.5114(3.5016) | Xent 0.0141(0.0170) | Loss 3.5184(3.5101) | Error 0.0022(0.0038) Steps 1078(1059.69) | Grad Norm 1.1225(1.0532) | Total Time 14.00(14.00)\n",
      "Iter 16610 | Time 26.1076(26.6104) | Bit/dim 3.4865(3.5033) | Xent 0.0185(0.0170) | Loss 3.4958(3.5117) | Error 0.0044(0.0038) Steps 1066(1059.37) | Grad Norm 0.8948(1.0427) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 118.0535, Epoch Time 1603.6541(1579.1441), Bit/dim 3.5062(best: 3.5069), Xent 2.1135, Loss 4.5629, Error 0.2726(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16620 | Time 26.5985(26.5770) | Bit/dim 3.5126(3.5056) | Xent 0.0152(0.0164) | Loss 3.5202(3.5138) | Error 0.0033(0.0037) Steps 1036(1059.74) | Grad Norm 1.2172(1.0441) | Total Time 14.00(14.00)\n",
      "Iter 16630 | Time 27.7458(26.6285) | Bit/dim 3.4720(3.5028) | Xent 0.0183(0.0163) | Loss 3.4812(3.5109) | Error 0.0056(0.0038) Steps 1060(1059.21) | Grad Norm 0.8295(1.0523) | Total Time 14.00(14.00)\n",
      "Iter 16640 | Time 26.5688(26.7284) | Bit/dim 3.5271(3.5017) | Xent 0.0157(0.0167) | Loss 3.5349(3.5100) | Error 0.0044(0.0038) Steps 1048(1060.38) | Grad Norm 1.1242(1.0901) | Total Time 14.00(14.00)\n",
      "Iter 16650 | Time 26.6285(26.7511) | Bit/dim 3.5085(3.5022) | Xent 0.0132(0.0167) | Loss 3.5151(3.5105) | Error 0.0022(0.0037) Steps 1048(1059.10) | Grad Norm 0.9530(1.0827) | Total Time 14.00(14.00)\n",
      "Iter 16660 | Time 26.4894(26.7261) | Bit/dim 3.5136(3.5019) | Xent 0.0152(0.0166) | Loss 3.5212(3.5102) | Error 0.0033(0.0037) Steps 1054(1057.77) | Grad Norm 0.9086(1.0420) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 120.2666, Epoch Time 1610.4093(1580.0821), Bit/dim 3.5073(best: 3.5062), Xent 2.1366, Loss 4.5756, Error 0.2736(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16670 | Time 26.6149(26.6705) | Bit/dim 3.5099(3.5003) | Xent 0.0155(0.0167) | Loss 3.5176(3.5086) | Error 0.0033(0.0038) Steps 1060(1060.72) | Grad Norm 1.0842(1.0390) | Total Time 14.00(14.00)\n",
      "Iter 16680 | Time 27.0465(26.6283) | Bit/dim 3.5122(3.5000) | Xent 0.0170(0.0165) | Loss 3.5207(3.5083) | Error 0.0033(0.0038) Steps 1066(1059.53) | Grad Norm 1.0159(1.0256) | Total Time 14.00(14.00)\n",
      "Iter 16690 | Time 26.2351(26.5966) | Bit/dim 3.4765(3.5010) | Xent 0.0174(0.0161) | Loss 3.4852(3.5091) | Error 0.0033(0.0037) Steps 1066(1057.19) | Grad Norm 0.9654(1.0111) | Total Time 14.00(14.00)\n",
      "Iter 16700 | Time 26.4723(26.6177) | Bit/dim 3.4817(3.5020) | Xent 0.0107(0.0160) | Loss 3.4870(3.5100) | Error 0.0000(0.0035) Steps 1078(1059.86) | Grad Norm 0.6857(0.9815) | Total Time 14.00(14.00)\n",
      "Iter 16710 | Time 26.9789(26.6059) | Bit/dim 3.4998(3.5013) | Xent 0.0119(0.0166) | Loss 3.5058(3.5096) | Error 0.0044(0.0038) Steps 1066(1057.86) | Grad Norm 0.6674(0.9879) | Total Time 14.00(14.00)\n",
      "Iter 16720 | Time 26.6240(26.5545) | Bit/dim 3.4870(3.5020) | Xent 0.0171(0.0165) | Loss 3.4956(3.5102) | Error 0.0044(0.0037) Steps 1072(1057.76) | Grad Norm 0.9349(0.9768) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 119.9806, Epoch Time 1596.1647(1580.5645), Bit/dim 3.5077(best: 3.5062), Xent 2.1350, Loss 4.5752, Error 0.2722(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16730 | Time 26.3165(26.5093) | Bit/dim 3.5014(3.5027) | Xent 0.0159(0.0158) | Loss 3.5094(3.5106) | Error 0.0044(0.0036) Steps 1066(1057.37) | Grad Norm 0.8542(0.9479) | Total Time 14.00(14.00)\n",
      "Iter 16740 | Time 26.5536(26.5044) | Bit/dim 3.5035(3.5026) | Xent 0.0220(0.0161) | Loss 3.5145(3.5106) | Error 0.0067(0.0038) Steps 1030(1057.23) | Grad Norm 1.0642(0.9475) | Total Time 14.00(14.00)\n",
      "Iter 16750 | Time 26.5593(26.5205) | Bit/dim 3.4822(3.5010) | Xent 0.0137(0.0158) | Loss 3.4890(3.5089) | Error 0.0022(0.0034) Steps 1054(1057.83) | Grad Norm 1.0962(0.9401) | Total Time 14.00(14.00)\n",
      "Iter 16760 | Time 26.9261(26.5407) | Bit/dim 3.5124(3.5015) | Xent 0.0142(0.0159) | Loss 3.5195(3.5094) | Error 0.0044(0.0036) Steps 1042(1058.24) | Grad Norm 0.9373(0.9685) | Total Time 14.00(14.00)\n",
      "Iter 16770 | Time 26.8940(26.5636) | Bit/dim 3.5116(3.5006) | Xent 0.0156(0.0164) | Loss 3.5195(3.5088) | Error 0.0033(0.0039) Steps 1042(1058.20) | Grad Norm 1.1248(1.0547) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 119.4367, Epoch Time 1597.8778(1581.0839), Bit/dim 3.5068(best: 3.5062), Xent 2.1122, Loss 4.5629, Error 0.2727(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16780 | Time 26.7346(26.5397) | Bit/dim 3.4983(3.5006) | Xent 0.0143(0.0168) | Loss 3.5055(3.5090) | Error 0.0033(0.0042) Steps 1078(1058.50) | Grad Norm 1.1231(1.1241) | Total Time 14.00(14.00)\n",
      "Iter 16790 | Time 26.3567(26.5613) | Bit/dim 3.5542(3.5035) | Xent 0.0156(0.0165) | Loss 3.5620(3.5118) | Error 0.0056(0.0039) Steps 1054(1059.89) | Grad Norm 0.9636(1.1137) | Total Time 14.00(14.00)\n",
      "Iter 16800 | Time 26.4725(26.5342) | Bit/dim 3.5141(3.5019) | Xent 0.0162(0.0161) | Loss 3.5222(3.5100) | Error 0.0022(0.0038) Steps 1072(1059.21) | Grad Norm 1.0208(1.0830) | Total Time 14.00(14.00)\n",
      "Iter 16810 | Time 26.5270(26.5127) | Bit/dim 3.5102(3.5000) | Xent 0.0108(0.0164) | Loss 3.5156(3.5082) | Error 0.0022(0.0040) Steps 1054(1059.17) | Grad Norm 0.8006(1.0654) | Total Time 14.00(14.00)\n",
      "Iter 16820 | Time 26.4350(26.4791) | Bit/dim 3.4776(3.4996) | Xent 0.0167(0.0164) | Loss 3.4859(3.5078) | Error 0.0033(0.0040) Steps 1066(1058.90) | Grad Norm 0.8074(1.0440) | Total Time 14.00(14.00)\n",
      "Iter 16830 | Time 26.5110(26.5552) | Bit/dim 3.5193(3.5013) | Xent 0.0153(0.0161) | Loss 3.5270(3.5093) | Error 0.0022(0.0037) Steps 1054(1061.33) | Grad Norm 1.1306(1.0738) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 119.3028, Epoch Time 1595.7010(1581.5224), Bit/dim 3.5058(best: 3.5062), Xent 2.1326, Loss 4.5721, Error 0.2731(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16840 | Time 25.9540(26.5161) | Bit/dim 3.4899(3.5002) | Xent 0.0098(0.0156) | Loss 3.4948(3.5081) | Error 0.0011(0.0036) Steps 1060(1062.67) | Grad Norm 0.9990(1.0914) | Total Time 14.00(14.00)\n",
      "Iter 16850 | Time 26.6117(26.5884) | Bit/dim 3.5274(3.4997) | Xent 0.0140(0.0157) | Loss 3.5345(3.5075) | Error 0.0044(0.0035) Steps 1072(1063.76) | Grad Norm 1.3282(1.0825) | Total Time 14.00(14.00)\n",
      "Iter 16860 | Time 26.6491(26.6219) | Bit/dim 3.5142(3.5006) | Xent 0.0163(0.0157) | Loss 3.5224(3.5084) | Error 0.0056(0.0036) Steps 1048(1060.18) | Grad Norm 1.1900(1.1235) | Total Time 14.00(14.00)\n",
      "Iter 16870 | Time 26.8760(26.6883) | Bit/dim 3.4779(3.5031) | Xent 0.0211(0.0160) | Loss 3.4884(3.5111) | Error 0.0044(0.0038) Steps 1084(1060.60) | Grad Norm 1.0536(1.1077) | Total Time 14.00(14.00)\n",
      "Iter 16880 | Time 26.3039(26.6649) | Bit/dim 3.5230(3.5012) | Xent 0.0205(0.0163) | Loss 3.5333(3.5094) | Error 0.0078(0.0040) Steps 1030(1058.74) | Grad Norm 1.1720(1.1043) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 119.9393, Epoch Time 1604.1509(1582.2013), Bit/dim 3.5053(best: 3.5058), Xent 2.1311, Loss 4.5709, Error 0.2737(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16890 | Time 26.4020(26.5742) | Bit/dim 3.4942(3.5010) | Xent 0.0160(0.0163) | Loss 3.5022(3.5092) | Error 0.0033(0.0041) Steps 1072(1057.82) | Grad Norm 0.9798(1.1115) | Total Time 14.00(14.00)\n",
      "Iter 16900 | Time 26.9195(26.6036) | Bit/dim 3.4966(3.5002) | Xent 0.0114(0.0168) | Loss 3.5023(3.5086) | Error 0.0011(0.0043) Steps 1084(1056.88) | Grad Norm 0.8934(1.1102) | Total Time 14.00(14.00)\n",
      "Iter 16910 | Time 26.6311(26.6257) | Bit/dim 3.4867(3.5009) | Xent 0.0154(0.0167) | Loss 3.4944(3.5092) | Error 0.0044(0.0042) Steps 1066(1056.99) | Grad Norm 1.1730(1.1006) | Total Time 14.00(14.00)\n",
      "Iter 16920 | Time 26.6068(26.5545) | Bit/dim 3.5301(3.5017) | Xent 0.0171(0.0170) | Loss 3.5386(3.5102) | Error 0.0033(0.0042) Steps 1060(1058.31) | Grad Norm 1.0577(1.1270) | Total Time 14.00(14.00)\n",
      "Iter 16930 | Time 27.0461(26.5536) | Bit/dim 3.4841(3.5000) | Xent 0.0145(0.0160) | Loss 3.4913(3.5080) | Error 0.0011(0.0038) Steps 1042(1059.53) | Grad Norm 1.0600(1.0744) | Total Time 14.00(14.00)\n",
      "Iter 16940 | Time 26.2840(26.6006) | Bit/dim 3.5246(3.5016) | Xent 0.0247(0.0162) | Loss 3.5369(3.5097) | Error 0.0078(0.0038) Steps 1048(1058.82) | Grad Norm 1.2119(1.0915) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 118.9867, Epoch Time 1598.1998(1582.6813), Bit/dim 3.5057(best: 3.5053), Xent 2.1263, Loss 4.5689, Error 0.2705(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16950 | Time 26.4037(26.6201) | Bit/dim 3.4891(3.5005) | Xent 0.0122(0.0156) | Loss 3.4952(3.5083) | Error 0.0011(0.0037) Steps 1084(1060.24) | Grad Norm 0.7809(1.0470) | Total Time 14.00(14.00)\n",
      "Iter 16960 | Time 26.4130(26.6499) | Bit/dim 3.5073(3.5010) | Xent 0.0104(0.0158) | Loss 3.5125(3.5088) | Error 0.0000(0.0038) Steps 1042(1060.16) | Grad Norm 0.7518(1.0721) | Total Time 14.00(14.00)\n",
      "Iter 16970 | Time 26.1943(26.6222) | Bit/dim 3.5145(3.5026) | Xent 0.0225(0.0165) | Loss 3.5258(3.5108) | Error 0.0100(0.0042) Steps 1078(1059.38) | Grad Norm 1.4402(1.1167) | Total Time 14.00(14.00)\n",
      "Iter 16980 | Time 26.9984(26.6366) | Bit/dim 3.4999(3.5001) | Xent 0.0151(0.0165) | Loss 3.5074(3.5084) | Error 0.0033(0.0040) Steps 1072(1058.96) | Grad Norm 1.0246(1.1151) | Total Time 14.00(14.00)\n",
      "Iter 16990 | Time 26.4020(26.5684) | Bit/dim 3.4838(3.5005) | Xent 0.0260(0.0172) | Loss 3.4968(3.5091) | Error 0.0078(0.0041) Steps 1054(1058.76) | Grad Norm 1.7209(1.1637) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 119.1310, Epoch Time 1601.0495(1583.2323), Bit/dim 3.5056(best: 3.5053), Xent 2.1408, Loss 4.5760, Error 0.2734(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17000 | Time 25.9445(26.5568) | Bit/dim 3.5464(3.5036) | Xent 0.0107(0.0168) | Loss 3.5517(3.5120) | Error 0.0011(0.0040) Steps 1048(1058.62) | Grad Norm 0.7535(1.1215) | Total Time 14.00(14.00)\n",
      "Iter 17010 | Time 26.8894(26.4987) | Bit/dim 3.5005(3.5033) | Xent 0.0179(0.0175) | Loss 3.5094(3.5120) | Error 0.0056(0.0044) Steps 1054(1058.15) | Grad Norm 1.4484(1.1718) | Total Time 14.00(14.00)\n",
      "Iter 17020 | Time 26.7905(26.5201) | Bit/dim 3.4976(3.5025) | Xent 0.0159(0.0174) | Loss 3.5056(3.5111) | Error 0.0044(0.0044) Steps 1048(1059.07) | Grad Norm 1.2944(1.2429) | Total Time 14.00(14.00)\n",
      "Iter 17030 | Time 26.4541(26.5083) | Bit/dim 3.4933(3.5027) | Xent 0.0125(0.0170) | Loss 3.4995(3.5112) | Error 0.0022(0.0043) Steps 1060(1059.37) | Grad Norm 1.1112(1.2342) | Total Time 14.00(14.00)\n",
      "Iter 17040 | Time 27.5725(26.5748) | Bit/dim 3.5181(3.5017) | Xent 0.0150(0.0168) | Loss 3.5256(3.5101) | Error 0.0044(0.0042) Steps 1042(1059.85) | Grad Norm 1.1503(1.2151) | Total Time 14.00(14.00)\n",
      "Iter 17050 | Time 26.6053(26.5482) | Bit/dim 3.5179(3.5006) | Xent 0.0135(0.0175) | Loss 3.5246(3.5093) | Error 0.0022(0.0044) Steps 1078(1060.62) | Grad Norm 0.9301(1.2354) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 118.9630, Epoch Time 1594.6027(1583.5734), Bit/dim 3.5067(best: 3.5053), Xent 2.1738, Loss 4.5936, Error 0.2743(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17060 | Time 26.7978(26.4845) | Bit/dim 3.4873(3.5015) | Xent 0.0181(0.0168) | Loss 3.4964(3.5099) | Error 0.0044(0.0042) Steps 1060(1060.99) | Grad Norm 0.9627(1.1976) | Total Time 14.00(14.00)\n",
      "Iter 17070 | Time 27.1343(26.5893) | Bit/dim 3.4930(3.5023) | Xent 0.0263(0.0164) | Loss 3.5062(3.5105) | Error 0.0056(0.0040) Steps 1048(1060.39) | Grad Norm 1.5273(1.1524) | Total Time 14.00(14.00)\n",
      "Iter 17080 | Time 26.5309(26.5314) | Bit/dim 3.4832(3.4993) | Xent 0.0133(0.0166) | Loss 3.4899(3.5076) | Error 0.0022(0.0041) Steps 1024(1058.51) | Grad Norm 1.5223(1.1906) | Total Time 14.00(14.00)\n",
      "Iter 17090 | Time 26.5596(26.5924) | Bit/dim 3.5240(3.5024) | Xent 0.0186(0.0164) | Loss 3.5333(3.5106) | Error 0.0044(0.0039) Steps 1054(1060.11) | Grad Norm 1.7460(1.2070) | Total Time 14.00(14.00)\n",
      "Iter 17100 | Time 26.3841(26.5984) | Bit/dim 3.4905(3.5013) | Xent 0.0163(0.0167) | Loss 3.4986(3.5097) | Error 0.0033(0.0039) Steps 1048(1059.71) | Grad Norm 1.1923(1.1964) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 119.3566, Epoch Time 1600.5020(1584.0813), Bit/dim 3.5051(best: 3.5053), Xent 2.1498, Loss 4.5800, Error 0.2728(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17110 | Time 26.9498(26.5830) | Bit/dim 3.4579(3.4980) | Xent 0.0185(0.0167) | Loss 3.4672(3.5063) | Error 0.0033(0.0038) Steps 1066(1058.93) | Grad Norm 0.9428(1.1730) | Total Time 14.00(14.00)\n",
      "Iter 17120 | Time 26.5883(26.5490) | Bit/dim 3.4855(3.4978) | Xent 0.0170(0.0164) | Loss 3.4941(3.5060) | Error 0.0056(0.0040) Steps 1078(1060.28) | Grad Norm 0.9727(1.1611) | Total Time 14.00(14.00)\n",
      "Iter 17130 | Time 26.7392(26.5149) | Bit/dim 3.4865(3.4981) | Xent 0.0188(0.0165) | Loss 3.4958(3.5064) | Error 0.0056(0.0041) Steps 1078(1057.86) | Grad Norm 1.3116(1.2058) | Total Time 14.00(14.00)\n",
      "Iter 17140 | Time 26.5053(26.4798) | Bit/dim 3.5120(3.4985) | Xent 0.0104(0.0161) | Loss 3.5172(3.5066) | Error 0.0011(0.0040) Steps 1060(1059.34) | Grad Norm 0.7989(1.1371) | Total Time 14.00(14.00)\n",
      "Iter 17150 | Time 26.7159(26.5498) | Bit/dim 3.5049(3.5002) | Xent 0.0149(0.0162) | Loss 3.5124(3.5083) | Error 0.0011(0.0038) Steps 1060(1059.51) | Grad Norm 0.8766(1.0874) | Total Time 14.00(14.00)\n",
      "Iter 17160 | Time 26.4470(26.5899) | Bit/dim 3.4924(3.5006) | Xent 0.0156(0.0164) | Loss 3.5002(3.5088) | Error 0.0033(0.0040) Steps 1078(1061.29) | Grad Norm 1.0742(1.0810) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 120.7508, Epoch Time 1597.6960(1584.4897), Bit/dim 3.5047(best: 3.5051), Xent 2.1461, Loss 4.5778, Error 0.2713(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17170 | Time 27.1339(26.5704) | Bit/dim 3.4772(3.4995) | Xent 0.0118(0.0161) | Loss 3.4831(3.5076) | Error 0.0033(0.0039) Steps 1024(1059.65) | Grad Norm 0.9835(1.1101) | Total Time 14.00(14.00)\n",
      "Iter 17180 | Time 27.3956(26.6328) | Bit/dim 3.5060(3.4981) | Xent 0.0099(0.0157) | Loss 3.5109(3.5060) | Error 0.0011(0.0036) Steps 1048(1059.28) | Grad Norm 0.9774(1.0749) | Total Time 14.00(14.00)\n",
      "Iter 17190 | Time 26.9163(26.5743) | Bit/dim 3.4982(3.4973) | Xent 0.0214(0.0166) | Loss 3.5089(3.5056) | Error 0.0056(0.0039) Steps 1066(1059.98) | Grad Norm 1.3368(1.1723) | Total Time 14.00(14.00)\n",
      "Iter 17200 | Time 26.9138(26.5684) | Bit/dim 3.5480(3.4991) | Xent 0.0115(0.0169) | Loss 3.5538(3.5076) | Error 0.0000(0.0037) Steps 1060(1058.65) | Grad Norm 0.7285(1.1714) | Total Time 14.00(14.00)\n",
      "Iter 17210 | Time 27.0503(26.5692) | Bit/dim 3.5211(3.5019) | Xent 0.0116(0.0172) | Loss 3.5270(3.5105) | Error 0.0000(0.0039) Steps 1054(1058.20) | Grad Norm 0.9107(1.1971) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 120.1168, Epoch Time 1599.5737(1584.9422), Bit/dim 3.5056(best: 3.5047), Xent 2.1625, Loss 4.5868, Error 0.2752(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17220 | Time 26.9071(26.5765) | Bit/dim 3.5006(3.5008) | Xent 0.0183(0.0169) | Loss 3.5097(3.5092) | Error 0.0044(0.0039) Steps 1036(1056.62) | Grad Norm 1.4834(1.2067) | Total Time 14.00(14.00)\n",
      "Iter 17230 | Time 25.5368(26.5417) | Bit/dim 3.5010(3.5028) | Xent 0.0224(0.0167) | Loss 3.5122(3.5111) | Error 0.0044(0.0038) Steps 1054(1056.01) | Grad Norm 1.6671(1.1803) | Total Time 14.00(14.00)\n",
      "Iter 17240 | Time 26.8021(26.5248) | Bit/dim 3.5324(3.5030) | Xent 0.0103(0.0169) | Loss 3.5375(3.5115) | Error 0.0011(0.0039) Steps 1072(1055.88) | Grad Norm 0.8898(1.1960) | Total Time 14.00(14.00)\n",
      "Iter 17250 | Time 26.7597(26.5020) | Bit/dim 3.5057(3.5015) | Xent 0.0165(0.0165) | Loss 3.5140(3.5097) | Error 0.0044(0.0037) Steps 1060(1057.92) | Grad Norm 1.0562(1.1675) | Total Time 14.00(14.00)\n",
      "Iter 17260 | Time 26.5409(26.5056) | Bit/dim 3.4775(3.5001) | Xent 0.0197(0.0166) | Loss 3.4873(3.5084) | Error 0.0078(0.0038) Steps 1066(1057.62) | Grad Norm 1.2475(1.1499) | Total Time 14.00(14.00)\n",
      "Iter 17270 | Time 26.4545(26.4445) | Bit/dim 3.4805(3.4999) | Xent 0.0115(0.0165) | Loss 3.4863(3.5082) | Error 0.0022(0.0038) Steps 1078(1056.51) | Grad Norm 0.6967(1.1023) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 119.0976, Epoch Time 1591.6565(1585.1437), Bit/dim 3.5048(best: 3.5047), Xent 2.1672, Loss 4.5884, Error 0.2721(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17280 | Time 26.2195(26.5153) | Bit/dim 3.5300(3.5000) | Xent 0.0140(0.0163) | Loss 3.5370(3.5082) | Error 0.0022(0.0039) Steps 1048(1057.41) | Grad Norm 0.8462(1.0960) | Total Time 14.00(14.00)\n",
      "Iter 17290 | Time 26.5618(26.5186) | Bit/dim 3.4905(3.5011) | Xent 0.0126(0.0159) | Loss 3.4968(3.5091) | Error 0.0011(0.0036) Steps 1060(1057.83) | Grad Norm 0.8547(1.0660) | Total Time 14.00(14.00)\n",
      "Iter 17300 | Time 26.7704(26.5565) | Bit/dim 3.5078(3.5010) | Xent 0.0171(0.0161) | Loss 3.5163(3.5091) | Error 0.0022(0.0035) Steps 1066(1056.30) | Grad Norm 0.9643(1.0645) | Total Time 14.00(14.00)\n",
      "Iter 17310 | Time 26.7657(26.6123) | Bit/dim 3.5034(3.4994) | Xent 0.0195(0.0163) | Loss 3.5132(3.5076) | Error 0.0067(0.0038) Steps 1036(1056.48) | Grad Norm 1.4889(1.0965) | Total Time 14.00(14.00)\n",
      "Iter 17320 | Time 26.1623(26.6010) | Bit/dim 3.5263(3.5015) | Xent 0.0179(0.0163) | Loss 3.5352(3.5096) | Error 0.0056(0.0039) Steps 1048(1058.85) | Grad Norm 0.9933(1.0841) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 118.8720, Epoch Time 1602.0352(1585.6504), Bit/dim 3.5045(best: 3.5047), Xent 2.1679, Loss 4.5885, Error 0.2759(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17330 | Time 27.3583(26.5754) | Bit/dim 3.4853(3.4980) | Xent 0.0137(0.0160) | Loss 3.4922(3.5060) | Error 0.0022(0.0039) Steps 1060(1058.86) | Grad Norm 0.8572(1.0589) | Total Time 14.00(14.00)\n",
      "Iter 17340 | Time 26.9302(26.6088) | Bit/dim 3.5195(3.4972) | Xent 0.0168(0.0159) | Loss 3.5278(3.5052) | Error 0.0033(0.0038) Steps 1066(1061.06) | Grad Norm 1.1683(1.0295) | Total Time 14.00(14.00)\n",
      "Iter 17350 | Time 26.8643(26.6232) | Bit/dim 3.5072(3.4974) | Xent 0.0138(0.0158) | Loss 3.5141(3.5053) | Error 0.0022(0.0035) Steps 1060(1061.76) | Grad Norm 1.0220(1.0145) | Total Time 14.00(14.00)\n",
      "Iter 17360 | Time 26.5548(26.5958) | Bit/dim 3.5099(3.4977) | Xent 0.0209(0.0161) | Loss 3.5203(3.5057) | Error 0.0100(0.0039) Steps 1036(1060.88) | Grad Norm 1.2380(1.0405) | Total Time 14.00(14.00)\n",
      "Iter 17370 | Time 26.5291(26.6002) | Bit/dim 3.4763(3.5004) | Xent 0.0182(0.0165) | Loss 3.4854(3.5087) | Error 0.0033(0.0040) Steps 1054(1060.95) | Grad Norm 1.2187(1.0705) | Total Time 14.00(14.00)\n",
      "Iter 17380 | Time 26.2485(26.6048) | Bit/dim 3.4858(3.5000) | Xent 0.0151(0.0159) | Loss 3.4934(3.5080) | Error 0.0044(0.0039) Steps 1048(1060.41) | Grad Norm 1.1798(1.1036) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 118.2520, Epoch Time 1600.0046(1586.0810), Bit/dim 3.5041(best: 3.5045), Xent 2.2001, Loss 4.6041, Error 0.2787(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17390 | Time 27.1323(26.5791) | Bit/dim 3.4851(3.4962) | Xent 0.0213(0.0160) | Loss 3.4958(3.5042) | Error 0.0067(0.0040) Steps 1060(1061.06) | Grad Norm 1.6869(1.1718) | Total Time 14.00(14.00)\n",
      "Iter 17400 | Time 26.8495(26.6274) | Bit/dim 3.4773(3.4982) | Xent 0.0162(0.0159) | Loss 3.4854(3.5061) | Error 0.0067(0.0040) Steps 1042(1061.06) | Grad Norm 1.9132(1.2331) | Total Time 14.00(14.00)\n",
      "Iter 17410 | Time 25.7050(26.5749) | Bit/dim 3.4646(3.4994) | Xent 0.0183(0.0163) | Loss 3.4738(3.5076) | Error 0.0067(0.0041) Steps 1066(1061.22) | Grad Norm 1.2990(1.2111) | Total Time 14.00(14.00)\n",
      "Iter 17420 | Time 27.7137(26.6397) | Bit/dim 3.5065(3.4991) | Xent 0.0151(0.0158) | Loss 3.5140(3.5071) | Error 0.0033(0.0039) Steps 1078(1060.33) | Grad Norm 1.1099(1.1532) | Total Time 14.00(14.00)\n",
      "Iter 17430 | Time 26.4826(26.6497) | Bit/dim 3.5087(3.5003) | Xent 0.0225(0.0159) | Loss 3.5199(3.5083) | Error 0.0078(0.0038) Steps 1072(1059.60) | Grad Norm 1.1991(1.1199) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 120.5235, Epoch Time 1602.1705(1586.5637), Bit/dim 3.5042(best: 3.5041), Xent 2.2069, Loss 4.6076, Error 0.2750(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17440 | Time 27.1402(26.5771) | Bit/dim 3.4982(3.5001) | Xent 0.0111(0.0156) | Loss 3.5037(3.5079) | Error 0.0011(0.0039) Steps 1078(1057.29) | Grad Norm 0.8511(1.0860) | Total Time 14.00(14.00)\n",
      "Iter 17450 | Time 26.7490(26.5942) | Bit/dim 3.4894(3.5021) | Xent 0.0166(0.0160) | Loss 3.4977(3.5101) | Error 0.0022(0.0041) Steps 1054(1057.37) | Grad Norm 0.9131(1.0938) | Total Time 14.00(14.00)\n",
      "Iter 17460 | Time 26.4549(26.6284) | Bit/dim 3.4662(3.4995) | Xent 0.0123(0.0157) | Loss 3.4723(3.5073) | Error 0.0022(0.0039) Steps 1060(1056.67) | Grad Norm 1.1611(1.1146) | Total Time 14.00(14.00)\n",
      "Iter 17470 | Time 26.2908(26.5547) | Bit/dim 3.5009(3.4994) | Xent 0.0129(0.0161) | Loss 3.5073(3.5074) | Error 0.0011(0.0040) Steps 1072(1057.36) | Grad Norm 1.1721(1.1445) | Total Time 14.00(14.00)\n",
      "Iter 17480 | Time 26.7092(26.5641) | Bit/dim 3.4830(3.4981) | Xent 0.0171(0.0157) | Loss 3.4916(3.5060) | Error 0.0044(0.0037) Steps 1078(1059.40) | Grad Norm 1.2104(1.1344) | Total Time 14.00(14.00)\n",
      "Iter 17490 | Time 26.8928(26.6186) | Bit/dim 3.4983(3.4973) | Xent 0.0191(0.0160) | Loss 3.5078(3.5053) | Error 0.0044(0.0038) Steps 1066(1060.20) | Grad Norm 0.9280(1.1258) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 119.7312, Epoch Time 1599.8776(1586.9631), Bit/dim 3.5031(best: 3.5041), Xent 2.1840, Loss 4.5951, Error 0.2719(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17500 | Time 26.3143(26.6239) | Bit/dim 3.5190(3.4988) | Xent 0.0144(0.0159) | Loss 3.5262(3.5067) | Error 0.0056(0.0038) Steps 1030(1058.29) | Grad Norm 1.0624(1.1452) | Total Time 14.00(14.00)\n",
      "Iter 17510 | Time 26.7793(26.6153) | Bit/dim 3.4591(3.4964) | Xent 0.0126(0.0160) | Loss 3.4654(3.5044) | Error 0.0044(0.0041) Steps 1036(1058.54) | Grad Norm 1.0700(1.1718) | Total Time 14.00(14.00)\n",
      "Iter 17520 | Time 27.5189(26.6459) | Bit/dim 3.4995(3.4982) | Xent 0.0156(0.0162) | Loss 3.5074(3.5063) | Error 0.0011(0.0041) Steps 1078(1058.04) | Grad Norm 1.1986(1.1669) | Total Time 14.00(14.00)\n",
      "Iter 17530 | Time 26.7036(26.7048) | Bit/dim 3.4751(3.4976) | Xent 0.0183(0.0161) | Loss 3.4843(3.5057) | Error 0.0067(0.0041) Steps 1054(1058.86) | Grad Norm 1.0443(1.1493) | Total Time 14.00(14.00)\n",
      "Iter 17540 | Time 26.4354(26.7486) | Bit/dim 3.5175(3.4989) | Xent 0.0184(0.0165) | Loss 3.5266(3.5072) | Error 0.0044(0.0042) Steps 1066(1059.90) | Grad Norm 0.9835(1.1576) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 120.0796, Epoch Time 1611.0207(1587.6849), Bit/dim 3.5046(best: 3.5031), Xent 2.2232, Loss 4.6162, Error 0.2752(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17550 | Time 26.9060(26.8389) | Bit/dim 3.4719(3.4997) | Xent 0.0105(0.0166) | Loss 3.4771(3.5080) | Error 0.0011(0.0043) Steps 1048(1061.11) | Grad Norm 0.8770(1.1820) | Total Time 14.00(14.00)\n",
      "Iter 17560 | Time 26.5751(26.7580) | Bit/dim 3.5196(3.4991) | Xent 0.0146(0.0160) | Loss 3.5269(3.5070) | Error 0.0011(0.0040) Steps 1066(1059.25) | Grad Norm 1.0915(1.1799) | Total Time 14.00(14.00)\n",
      "Iter 17570 | Time 26.4935(26.8056) | Bit/dim 3.5227(3.4978) | Xent 0.0141(0.0168) | Loss 3.5297(3.5062) | Error 0.0022(0.0042) Steps 1018(1060.20) | Grad Norm 1.2225(1.2073) | Total Time 14.00(14.00)\n",
      "Iter 17580 | Time 26.0492(26.7574) | Bit/dim 3.4725(3.4986) | Xent 0.0196(0.0169) | Loss 3.4823(3.5071) | Error 0.0044(0.0042) Steps 1060(1059.17) | Grad Norm 1.0649(1.2141) | Total Time 14.00(14.00)\n",
      "Iter 17590 | Time 26.3221(26.7020) | Bit/dim 3.5061(3.4987) | Xent 0.0154(0.0170) | Loss 3.5138(3.5072) | Error 0.0067(0.0045) Steps 1066(1059.96) | Grad Norm 0.8297(1.2130) | Total Time 14.00(14.00)\n",
      "Iter 17600 | Time 27.2754(26.6349) | Bit/dim 3.5105(3.5004) | Xent 0.0136(0.0176) | Loss 3.5173(3.5092) | Error 0.0011(0.0046) Steps 1078(1060.90) | Grad Norm 0.8673(1.2296) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 119.6448, Epoch Time 1603.6092(1588.1626), Bit/dim 3.5048(best: 3.5031), Xent 2.2088, Loss 4.6093, Error 0.2724(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17610 | Time 26.4399(26.5815) | Bit/dim 3.4862(3.4978) | Xent 0.0217(0.0173) | Loss 3.4970(3.5064) | Error 0.0044(0.0043) Steps 1066(1059.26) | Grad Norm 2.0144(1.2525) | Total Time 14.00(14.00)\n",
      "Iter 17620 | Time 27.0802(26.5168) | Bit/dim 3.5017(3.4988) | Xent 0.0208(0.0166) | Loss 3.5121(3.5070) | Error 0.0067(0.0041) Steps 1048(1057.83) | Grad Norm 1.3985(1.2822) | Total Time 14.00(14.00)\n",
      "Iter 17630 | Time 26.9794(26.5586) | Bit/dim 3.4825(3.5020) | Xent 0.0115(0.0165) | Loss 3.4882(3.5102) | Error 0.0022(0.0042) Steps 1066(1058.42) | Grad Norm 0.7704(1.2794) | Total Time 14.00(14.00)\n",
      "Iter 17640 | Time 24.8673(26.4711) | Bit/dim 3.5262(3.5012) | Xent 0.0114(0.0163) | Loss 3.5319(3.5094) | Error 0.0000(0.0039) Steps 1048(1057.41) | Grad Norm 1.2075(1.2956) | Total Time 14.00(14.00)\n",
      "Iter 17650 | Time 26.1060(26.5038) | Bit/dim 3.5189(3.5006) | Xent 0.0186(0.0163) | Loss 3.5282(3.5087) | Error 0.0044(0.0038) Steps 1042(1057.35) | Grad Norm 1.3067(1.2431) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 120.1638, Epoch Time 1593.4235(1588.3204), Bit/dim 3.5040(best: 3.5031), Xent 2.2310, Loss 4.6195, Error 0.2785(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17660 | Time 26.7426(26.5297) | Bit/dim 3.4710(3.4972) | Xent 0.0114(0.0158) | Loss 3.4768(3.5051) | Error 0.0033(0.0037) Steps 1054(1057.29) | Grad Norm 0.8817(1.1893) | Total Time 14.00(14.00)\n",
      "Iter 17670 | Time 26.5528(26.5934) | Bit/dim 3.4926(3.4965) | Xent 0.0182(0.0156) | Loss 3.5017(3.5044) | Error 0.0067(0.0038) Steps 1042(1057.46) | Grad Norm 1.1682(1.1267) | Total Time 14.00(14.00)\n",
      "Iter 17680 | Time 26.7066(26.6276) | Bit/dim 3.4879(3.4966) | Xent 0.0193(0.0160) | Loss 3.4976(3.5046) | Error 0.0044(0.0037) Steps 1054(1057.08) | Grad Norm 1.2173(1.0949) | Total Time 14.00(14.00)\n",
      "Iter 17690 | Time 25.7688(26.6573) | Bit/dim 3.4950(3.4981) | Xent 0.0142(0.0156) | Loss 3.5021(3.5060) | Error 0.0011(0.0036) Steps 1042(1057.30) | Grad Norm 0.7872(1.0756) | Total Time 14.00(14.00)\n",
      "Iter 17700 | Time 26.8934(26.6838) | Bit/dim 3.4835(3.4981) | Xent 0.0159(0.0155) | Loss 3.4915(3.5058) | Error 0.0056(0.0036) Steps 1036(1056.80) | Grad Norm 1.4378(1.0759) | Total Time 14.00(14.00)\n",
      "Iter 17710 | Time 26.1428(26.6092) | Bit/dim 3.5195(3.4998) | Xent 0.0143(0.0162) | Loss 3.5266(3.5079) | Error 0.0033(0.0038) Steps 1048(1055.62) | Grad Norm 0.9891(1.1079) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 120.4104, Epoch Time 1605.8082(1588.8451), Bit/dim 3.5035(best: 3.5031), Xent 2.2204, Loss 4.6137, Error 0.2766(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17720 | Time 25.7327(26.5623) | Bit/dim 3.5111(3.5013) | Xent 0.0150(0.0165) | Loss 3.5186(3.5095) | Error 0.0044(0.0040) Steps 1036(1056.18) | Grad Norm 1.8063(1.1704) | Total Time 14.00(14.00)\n",
      "Iter 17730 | Time 26.4189(26.5819) | Bit/dim 3.4851(3.4981) | Xent 0.0127(0.0160) | Loss 3.4914(3.5061) | Error 0.0011(0.0038) Steps 1054(1055.36) | Grad Norm 1.5383(1.1872) | Total Time 14.00(14.00)\n",
      "Iter 17740 | Time 27.2041(26.6069) | Bit/dim 3.4887(3.4985) | Xent 0.0154(0.0157) | Loss 3.4964(3.5064) | Error 0.0056(0.0037) Steps 1078(1056.31) | Grad Norm 0.9746(1.1579) | Total Time 14.00(14.00)\n",
      "Iter 17750 | Time 26.4939(26.5860) | Bit/dim 3.5061(3.4989) | Xent 0.0138(0.0158) | Loss 3.5130(3.5068) | Error 0.0011(0.0035) Steps 1090(1056.24) | Grad Norm 1.1768(1.1833) | Total Time 14.00(14.00)\n",
      "Iter 17760 | Time 26.0532(26.6608) | Bit/dim 3.4858(3.4977) | Xent 0.0170(0.0156) | Loss 3.4943(3.5055) | Error 0.0033(0.0034) Steps 1054(1057.72) | Grad Norm 0.7580(1.1486) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 120.3254, Epoch Time 1602.1244(1589.2434), Bit/dim 3.5023(best: 3.5031), Xent 2.2279, Loss 4.6163, Error 0.2763(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17770 | Time 26.2142(26.6206) | Bit/dim 3.5176(3.4991) | Xent 0.0147(0.0153) | Loss 3.5249(3.5067) | Error 0.0022(0.0033) Steps 1072(1058.16) | Grad Norm 1.5097(1.1481) | Total Time 14.00(14.00)\n",
      "Iter 17780 | Time 25.5874(26.4851) | Bit/dim 3.4987(3.4962) | Xent 0.0148(0.0153) | Loss 3.5061(3.5039) | Error 0.0044(0.0035) Steps 1036(1056.73) | Grad Norm 1.0297(1.1170) | Total Time 14.00(14.00)\n",
      "Iter 17790 | Time 26.8308(26.4961) | Bit/dim 3.5222(3.4960) | Xent 0.0197(0.0156) | Loss 3.5321(3.5038) | Error 0.0022(0.0035) Steps 1066(1058.57) | Grad Norm 1.2310(1.1094) | Total Time 14.00(14.00)\n",
      "Iter 17800 | Time 26.4607(26.4551) | Bit/dim 3.4879(3.4968) | Xent 0.0152(0.0153) | Loss 3.4955(3.5045) | Error 0.0033(0.0034) Steps 1066(1058.66) | Grad Norm 1.3155(1.0789) | Total Time 14.00(14.00)\n",
      "Iter 17810 | Time 26.5322(26.4161) | Bit/dim 3.4918(3.4978) | Xent 0.0180(0.0160) | Loss 3.5008(3.5058) | Error 0.0078(0.0037) Steps 1078(1058.95) | Grad Norm 1.1277(1.1037) | Total Time 14.00(14.00)\n",
      "Iter 17820 | Time 25.9472(26.3450) | Bit/dim 3.5026(3.4980) | Xent 0.0153(0.0159) | Loss 3.5102(3.5059) | Error 0.0044(0.0038) Steps 1036(1058.51) | Grad Norm 1.1401(1.1049) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 119.1429, Epoch Time 1584.4460(1589.0995), Bit/dim 3.5039(best: 3.5023), Xent 2.2440, Loss 4.6259, Error 0.2743(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17830 | Time 26.6830(26.2819) | Bit/dim 3.5194(3.4976) | Xent 0.0104(0.0157) | Loss 3.5246(3.5055) | Error 0.0022(0.0039) Steps 1060(1057.70) | Grad Norm 0.7835(1.0941) | Total Time 14.00(14.00)\n",
      "Iter 17840 | Time 25.8568(26.3081) | Bit/dim 3.5053(3.4975) | Xent 0.0245(0.0161) | Loss 3.5176(3.5056) | Error 0.0033(0.0039) Steps 1060(1059.67) | Grad Norm 1.4631(1.0951) | Total Time 14.00(14.00)\n",
      "Iter 17850 | Time 26.2560(26.2547) | Bit/dim 3.4745(3.4948) | Xent 0.0142(0.0160) | Loss 3.4816(3.5028) | Error 0.0033(0.0039) Steps 1036(1056.41) | Grad Norm 1.1634(1.1466) | Total Time 14.00(14.00)\n",
      "Iter 17860 | Time 26.5233(26.2155) | Bit/dim 3.5183(3.4986) | Xent 0.0150(0.0158) | Loss 3.5258(3.5065) | Error 0.0033(0.0037) Steps 1060(1053.96) | Grad Norm 1.5678(1.2158) | Total Time 14.00(14.00)\n",
      "Iter 17870 | Time 26.4757(26.1722) | Bit/dim 3.5118(3.4983) | Xent 0.0172(0.0161) | Loss 3.5204(3.5064) | Error 0.0044(0.0040) Steps 1060(1054.85) | Grad Norm 1.4660(1.2916) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 118.7328, Epoch Time 1577.4446(1588.7499), Bit/dim 3.5035(best: 3.5023), Xent 2.2837, Loss 4.6453, Error 0.2748(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17880 | Time 25.5870(26.2480) | Bit/dim 3.4907(3.5007) | Xent 0.0156(0.0159) | Loss 3.4985(3.5086) | Error 0.0044(0.0039) Steps 1042(1054.96) | Grad Norm 0.8943(1.2783) | Total Time 14.00(14.00)\n",
      "Iter 17890 | Time 26.5846(26.2614) | Bit/dim 3.4730(3.4997) | Xent 0.0170(0.0161) | Loss 3.4815(3.5077) | Error 0.0044(0.0040) Steps 1072(1054.08) | Grad Norm 1.1058(1.2837) | Total Time 14.00(14.00)\n",
      "Iter 17900 | Time 26.5106(26.3414) | Bit/dim 3.4782(3.4980) | Xent 0.0151(0.0161) | Loss 3.4857(3.5060) | Error 0.0033(0.0040) Steps 1042(1055.22) | Grad Norm 0.8725(1.2343) | Total Time 14.00(14.00)\n",
      "Iter 17910 | Time 25.8638(26.3610) | Bit/dim 3.4877(3.4959) | Xent 0.0237(0.0162) | Loss 3.4996(3.5040) | Error 0.0056(0.0037) Steps 1042(1055.00) | Grad Norm 1.4346(1.1991) | Total Time 14.00(14.00)\n",
      "Iter 17920 | Time 26.7336(26.3913) | Bit/dim 3.4574(3.4966) | Xent 0.0103(0.0160) | Loss 3.4625(3.5046) | Error 0.0022(0.0038) Steps 1078(1056.63) | Grad Norm 0.9336(1.1965) | Total Time 14.00(14.00)\n",
      "Iter 17930 | Time 26.1587(26.4054) | Bit/dim 3.5103(3.4982) | Xent 0.0102(0.0158) | Loss 3.5154(3.5061) | Error 0.0000(0.0034) Steps 1060(1057.05) | Grad Norm 0.7307(1.1463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 119.8178, Epoch Time 1591.1295(1588.8213), Bit/dim 3.5033(best: 3.5023), Xent 2.2647, Loss 4.6356, Error 0.2757(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17940 | Time 26.2737(26.3725) | Bit/dim 3.5237(3.4995) | Xent 0.0137(0.0157) | Loss 3.5306(3.5073) | Error 0.0044(0.0037) Steps 1072(1057.48) | Grad Norm 1.2391(1.1765) | Total Time 14.00(14.00)\n",
      "Iter 17950 | Time 26.4190(26.3826) | Bit/dim 3.4947(3.5007) | Xent 0.0134(0.0155) | Loss 3.5014(3.5084) | Error 0.0033(0.0035) Steps 1048(1057.38) | Grad Norm 0.9630(1.1574) | Total Time 14.00(14.00)\n",
      "Iter 17960 | Time 26.1742(26.4094) | Bit/dim 3.4843(3.4974) | Xent 0.0198(0.0160) | Loss 3.4942(3.5054) | Error 0.0067(0.0039) Steps 1072(1058.65) | Grad Norm 1.1360(1.1754) | Total Time 14.00(14.00)\n",
      "Iter 17970 | Time 26.1881(26.4316) | Bit/dim 3.4783(3.4968) | Xent 0.0104(0.0159) | Loss 3.4835(3.5047) | Error 0.0033(0.0039) Steps 1054(1060.02) | Grad Norm 1.0706(1.3068) | Total Time 14.00(14.00)\n",
      "Iter 17980 | Time 27.1622(26.4594) | Bit/dim 3.5242(3.4958) | Xent 0.0155(0.0154) | Loss 3.5319(3.5035) | Error 0.0033(0.0037) Steps 1048(1057.88) | Grad Norm 1.1840(1.2699) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 120.8515, Epoch Time 1593.4373(1588.9597), Bit/dim 3.5032(best: 3.5023), Xent 2.2637, Loss 4.6351, Error 0.2789(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17990 | Time 27.1298(26.4833) | Bit/dim 3.4701(3.4955) | Xent 0.0168(0.0158) | Loss 3.4784(3.5033) | Error 0.0033(0.0038) Steps 1030(1056.74) | Grad Norm 1.3370(1.2748) | Total Time 14.00(14.00)\n",
      "Iter 18000 | Time 25.8002(26.4882) | Bit/dim 3.5093(3.4971) | Xent 0.0153(0.0166) | Loss 3.5170(3.5054) | Error 0.0022(0.0039) Steps 1048(1055.40) | Grad Norm 1.4006(1.3537) | Total Time 14.00(14.00)\n",
      "Iter 18010 | Time 26.6073(26.4371) | Bit/dim 3.5074(3.4981) | Xent 0.0179(0.0171) | Loss 3.5163(3.5067) | Error 0.0056(0.0042) Steps 1060(1056.95) | Grad Norm 1.4948(1.4570) | Total Time 14.00(14.00)\n",
      "Iter 18020 | Time 26.7343(26.4378) | Bit/dim 3.4852(3.4962) | Xent 0.0172(0.0165) | Loss 3.4938(3.5045) | Error 0.0056(0.0040) Steps 1066(1058.00) | Grad Norm 1.0755(1.3932) | Total Time 14.00(14.00)\n",
      "Iter 18030 | Time 26.1750(26.4044) | Bit/dim 3.5005(3.4974) | Xent 0.0172(0.0160) | Loss 3.5091(3.5054) | Error 0.0056(0.0040) Steps 1036(1057.70) | Grad Norm 1.1947(1.3128) | Total Time 14.00(14.00)\n",
      "Iter 18040 | Time 26.3049(26.4042) | Bit/dim 3.5101(3.4978) | Xent 0.0214(0.0161) | Loss 3.5208(3.5058) | Error 0.0067(0.0040) Steps 1048(1057.56) | Grad Norm 1.2293(1.2687) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 120.2234, Epoch Time 1590.5464(1589.0073), Bit/dim 3.5016(best: 3.5023), Xent 2.2723, Loss 4.6377, Error 0.2758(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18050 | Time 26.5712(26.3809) | Bit/dim 3.4862(3.4981) | Xent 0.0153(0.0161) | Loss 3.4939(3.5062) | Error 0.0011(0.0040) Steps 1060(1056.00) | Grad Norm 1.2127(1.2278) | Total Time 14.00(14.00)\n",
      "Iter 18060 | Time 26.8160(26.3779) | Bit/dim 3.4993(3.4967) | Xent 0.0190(0.0156) | Loss 3.5088(3.5045) | Error 0.0056(0.0038) Steps 1042(1056.62) | Grad Norm 1.2775(1.2038) | Total Time 14.00(14.00)\n",
      "Iter 18070 | Time 26.4904(26.3838) | Bit/dim 3.5171(3.4952) | Xent 0.0244(0.0164) | Loss 3.5293(3.5034) | Error 0.0078(0.0042) Steps 1030(1053.92) | Grad Norm 1.7848(1.2327) | Total Time 14.00(14.00)\n",
      "Iter 18080 | Time 25.4429(26.3497) | Bit/dim 3.4936(3.4959) | Xent 0.0131(0.0161) | Loss 3.5001(3.5040) | Error 0.0022(0.0041) Steps 1048(1052.76) | Grad Norm 1.0068(1.1947) | Total Time 14.00(14.00)\n",
      "Iter 18090 | Time 25.8774(26.2891) | Bit/dim 3.4920(3.4973) | Xent 0.0156(0.0159) | Loss 3.4998(3.5052) | Error 0.0033(0.0040) Steps 1066(1053.20) | Grad Norm 1.2537(1.1719) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 120.1699, Epoch Time 1584.7204(1588.8787), Bit/dim 3.5020(best: 3.5016), Xent 2.2425, Loss 4.6232, Error 0.2703(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18100 | Time 26.1936(26.3149) | Bit/dim 3.4985(3.4991) | Xent 0.0222(0.0157) | Loss 3.5096(3.5070) | Error 0.0078(0.0038) Steps 1048(1053.72) | Grad Norm 1.0887(1.1421) | Total Time 14.00(14.00)\n",
      "Iter 18110 | Time 26.6121(26.3154) | Bit/dim 3.4650(3.4995) | Xent 0.0129(0.0154) | Loss 3.4714(3.5072) | Error 0.0022(0.0037) Steps 1048(1055.07) | Grad Norm 0.8072(1.1042) | Total Time 14.00(14.00)\n",
      "Iter 18120 | Time 26.1400(26.3737) | Bit/dim 3.5018(3.4979) | Xent 0.0224(0.0158) | Loss 3.5130(3.5058) | Error 0.0067(0.0037) Steps 1084(1056.60) | Grad Norm 1.6089(1.1090) | Total Time 14.00(14.00)\n",
      "Iter 18130 | Time 26.1590(26.3499) | Bit/dim 3.5339(3.4984) | Xent 0.0090(0.0152) | Loss 3.5384(3.5060) | Error 0.0022(0.0034) Steps 1060(1058.54) | Grad Norm 0.6245(1.0592) | Total Time 14.00(14.00)\n",
      "Iter 18140 | Time 25.3061(26.3050) | Bit/dim 3.5139(3.4976) | Xent 0.0089(0.0145) | Loss 3.5184(3.5049) | Error 0.0000(0.0033) Steps 1036(1056.83) | Grad Norm 0.7124(1.0271) | Total Time 14.00(14.00)\n",
      "Iter 18150 | Time 26.1099(26.2326) | Bit/dim 3.4528(3.4945) | Xent 0.0146(0.0146) | Loss 3.4601(3.5018) | Error 0.0044(0.0036) Steps 1048(1056.66) | Grad Norm 0.9746(1.0030) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 119.9035, Epoch Time 1582.9916(1588.7021), Bit/dim 3.5004(best: 3.5016), Xent 2.2781, Loss 4.6395, Error 0.2753(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18160 | Time 26.7923(26.2163) | Bit/dim 3.4836(3.4941) | Xent 0.0102(0.0151) | Loss 3.4886(3.5016) | Error 0.0011(0.0036) Steps 1072(1053.48) | Grad Norm 0.7670(1.0267) | Total Time 14.00(14.00)\n",
      "Iter 18170 | Time 26.5098(26.3345) | Bit/dim 3.5443(3.4953) | Xent 0.0141(0.0153) | Loss 3.5513(3.5029) | Error 0.0044(0.0038) Steps 1048(1052.16) | Grad Norm 1.4184(1.1230) | Total Time 14.00(14.00)\n",
      "Iter 18180 | Time 26.1172(26.3490) | Bit/dim 3.4906(3.4976) | Xent 0.0216(0.0152) | Loss 3.5014(3.5052) | Error 0.0067(0.0036) Steps 1054(1051.85) | Grad Norm 1.2418(1.1315) | Total Time 14.00(14.00)\n",
      "Iter 18190 | Time 25.7147(26.3426) | Bit/dim 3.5228(3.4970) | Xent 0.0085(0.0152) | Loss 3.5270(3.5047) | Error 0.0011(0.0036) Steps 1048(1052.58) | Grad Norm 0.7127(1.1310) | Total Time 14.00(14.00)\n",
      "Iter 18200 | Time 25.4260(26.3009) | Bit/dim 3.4555(3.4966) | Xent 0.0093(0.0152) | Loss 3.4602(3.5042) | Error 0.0000(0.0037) Steps 1042(1051.24) | Grad Norm 0.6170(1.1279) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 120.5139, Epoch Time 1587.3052(1588.6602), Bit/dim 3.5006(best: 3.5004), Xent 2.2677, Loss 4.6345, Error 0.2729(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18210 | Time 25.9944(26.2789) | Bit/dim 3.5216(3.4975) | Xent 0.0217(0.0154) | Loss 3.5324(3.5053) | Error 0.0078(0.0039) Steps 1048(1052.59) | Grad Norm 1.2809(1.1461) | Total Time 14.00(14.00)\n",
      "Iter 18220 | Time 26.3037(26.2955) | Bit/dim 3.4833(3.4979) | Xent 0.0174(0.0157) | Loss 3.4920(3.5057) | Error 0.0044(0.0039) Steps 1066(1054.96) | Grad Norm 1.0561(1.1523) | Total Time 14.00(14.00)\n",
      "Iter 18230 | Time 26.1200(26.2893) | Bit/dim 3.4886(3.4985) | Xent 0.0155(0.0160) | Loss 3.4963(3.5065) | Error 0.0033(0.0043) Steps 1036(1055.37) | Grad Norm 1.5271(1.1829) | Total Time 14.00(14.00)\n",
      "Iter 18240 | Time 26.2729(26.3287) | Bit/dim 3.5151(3.4978) | Xent 0.0124(0.0151) | Loss 3.5213(3.5053) | Error 0.0022(0.0039) Steps 1066(1054.03) | Grad Norm 1.0852(1.1539) | Total Time 14.00(14.00)\n",
      "Iter 18250 | Time 26.7892(26.3656) | Bit/dim 3.5112(3.4965) | Xent 0.0118(0.0151) | Loss 3.5171(3.5041) | Error 0.0011(0.0039) Steps 1072(1052.64) | Grad Norm 0.9819(1.1339) | Total Time 14.00(14.00)\n",
      "Iter 18260 | Time 26.6686(26.3816) | Bit/dim 3.4886(3.4949) | Xent 0.0106(0.0155) | Loss 3.4939(3.5027) | Error 0.0000(0.0040) Steps 1048(1053.23) | Grad Norm 1.2836(1.1743) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 118.0017, Epoch Time 1586.3159(1588.5899), Bit/dim 3.5019(best: 3.5004), Xent 2.2946, Loss 4.6492, Error 0.2762(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18270 | Time 25.8837(26.3817) | Bit/dim 3.4897(3.4937) | Xent 0.0116(0.0151) | Loss 3.4955(3.5013) | Error 0.0022(0.0037) Steps 1060(1054.85) | Grad Norm 0.8400(1.1240) | Total Time 14.00(14.00)\n",
      "Iter 18280 | Time 26.4056(26.3455) | Bit/dim 3.4969(3.4938) | Xent 0.0140(0.0155) | Loss 3.5039(3.5015) | Error 0.0033(0.0038) Steps 1036(1053.76) | Grad Norm 0.9880(1.1200) | Total Time 14.00(14.00)\n",
      "Iter 18290 | Time 25.9456(26.3712) | Bit/dim 3.5178(3.4970) | Xent 0.0219(0.0160) | Loss 3.5288(3.5050) | Error 0.0067(0.0039) Steps 1054(1052.51) | Grad Norm 1.6024(1.1457) | Total Time 14.00(14.00)\n",
      "Iter 18300 | Time 26.6724(26.3646) | Bit/dim 3.4976(3.4933) | Xent 0.0151(0.0164) | Loss 3.5052(3.5015) | Error 0.0011(0.0039) Steps 1054(1053.32) | Grad Norm 1.4867(1.2576) | Total Time 14.00(14.00)\n",
      "Iter 18310 | Time 26.2852(26.3994) | Bit/dim 3.5161(3.4957) | Xent 0.0189(0.0157) | Loss 3.5255(3.5035) | Error 0.0078(0.0038) Steps 1060(1054.47) | Grad Norm 1.1516(1.2241) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 120.6568, Epoch Time 1588.7556(1588.5948), Bit/dim 3.5019(best: 3.5004), Xent 2.2859, Loss 4.6449, Error 0.2752(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18320 | Time 26.1282(26.3635) | Bit/dim 3.4930(3.4980) | Xent 0.0124(0.0159) | Loss 3.4992(3.5059) | Error 0.0022(0.0040) Steps 1054(1054.40) | Grad Norm 1.3024(1.2513) | Total Time 14.00(14.00)\n",
      "Iter 18330 | Time 26.1850(26.3203) | Bit/dim 3.5015(3.4967) | Xent 0.0170(0.0157) | Loss 3.5100(3.5046) | Error 0.0033(0.0039) Steps 1060(1053.29) | Grad Norm 1.2906(1.2417) | Total Time 14.00(14.00)\n",
      "Iter 18340 | Time 25.7349(26.2562) | Bit/dim 3.4934(3.4955) | Xent 0.0146(0.0153) | Loss 3.5007(3.5031) | Error 0.0022(0.0037) Steps 1036(1050.46) | Grad Norm 0.8630(1.2107) | Total Time 14.00(14.00)\n",
      "Iter 18350 | Time 26.6374(26.3342) | Bit/dim 3.5029(3.4968) | Xent 0.0120(0.0148) | Loss 3.5089(3.5042) | Error 0.0033(0.0034) Steps 1066(1051.97) | Grad Norm 1.0408(1.1736) | Total Time 14.00(14.00)\n",
      "Iter 18360 | Time 26.0040(26.3735) | Bit/dim 3.5113(3.4958) | Xent 0.0150(0.0151) | Loss 3.5188(3.5033) | Error 0.0044(0.0037) Steps 1048(1051.86) | Grad Norm 1.3847(1.2005) | Total Time 14.00(14.00)\n",
      "Iter 18370 | Time 26.0149(26.3232) | Bit/dim 3.4708(3.4961) | Xent 0.0124(0.0152) | Loss 3.4770(3.5038) | Error 0.0022(0.0036) Steps 1060(1052.03) | Grad Norm 1.3263(1.1742) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 119.3233, Epoch Time 1583.9347(1588.4550), Bit/dim 3.5003(best: 3.5004), Xent 2.3235, Loss 4.6621, Error 0.2774(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18380 | Time 25.7905(26.3306) | Bit/dim 3.4792(3.4949) | Xent 0.0181(0.0153) | Loss 3.4882(3.5025) | Error 0.0067(0.0037) Steps 1060(1052.50) | Grad Norm 1.6037(1.2420) | Total Time 14.00(14.00)\n",
      "Iter 18390 | Time 26.0678(26.3026) | Bit/dim 3.4812(3.4973) | Xent 0.0169(0.0150) | Loss 3.4896(3.5048) | Error 0.0056(0.0038) Steps 1060(1053.04) | Grad Norm 1.2083(1.2720) | Total Time 14.00(14.00)\n",
      "Iter 18400 | Time 25.7188(26.2055) | Bit/dim 3.5024(3.4971) | Xent 0.0118(0.0148) | Loss 3.5083(3.5046) | Error 0.0022(0.0038) Steps 1042(1051.27) | Grad Norm 0.8347(1.2417) | Total Time 14.00(14.00)\n",
      "Iter 18410 | Time 25.9658(26.2894) | Bit/dim 3.5222(3.4967) | Xent 0.0198(0.0151) | Loss 3.5321(3.5043) | Error 0.0078(0.0039) Steps 1048(1052.08) | Grad Norm 1.4623(1.2178) | Total Time 14.00(14.00)\n",
      "Iter 18420 | Time 25.4703(26.3086) | Bit/dim 3.4774(3.4950) | Xent 0.0097(0.0152) | Loss 3.4823(3.5026) | Error 0.0011(0.0040) Steps 1042(1052.34) | Grad Norm 0.7813(1.1948) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 119.8882, Epoch Time 1584.0950(1588.3242), Bit/dim 3.5008(best: 3.5003), Xent 2.2976, Loss 4.6496, Error 0.2739(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18430 | Time 25.9868(26.3416) | Bit/dim 3.4972(3.4957) | Xent 0.0167(0.0155) | Loss 3.5055(3.5034) | Error 0.0044(0.0043) Steps 1048(1054.00) | Grad Norm 1.4651(1.2144) | Total Time 14.00(14.00)\n",
      "Iter 18440 | Time 26.5578(26.3338) | Bit/dim 3.4989(3.4959) | Xent 0.0102(0.0150) | Loss 3.5040(3.5034) | Error 0.0000(0.0041) Steps 1030(1051.91) | Grad Norm 1.1813(1.2190) | Total Time 14.00(14.00)\n",
      "Iter 18450 | Time 25.8142(26.3165) | Bit/dim 3.5096(3.4952) | Xent 0.0139(0.0153) | Loss 3.5165(3.5028) | Error 0.0022(0.0041) Steps 1054(1051.68) | Grad Norm 1.2860(1.3145) | Total Time 14.00(14.00)\n",
      "Iter 18460 | Time 27.1970(26.3132) | Bit/dim 3.4987(3.4966) | Xent 0.0145(0.0158) | Loss 3.5059(3.5045) | Error 0.0033(0.0043) Steps 1048(1051.43) | Grad Norm 1.2219(1.3102) | Total Time 14.00(14.00)\n",
      "Iter 18470 | Time 26.8933(26.3270) | Bit/dim 3.4921(3.4967) | Xent 0.0157(0.0156) | Loss 3.4999(3.5045) | Error 0.0044(0.0042) Steps 1030(1051.22) | Grad Norm 1.4327(1.2884) | Total Time 14.00(14.00)\n",
      "Iter 18480 | Time 26.3385(26.2748) | Bit/dim 3.5052(3.4948) | Xent 0.0157(0.0154) | Loss 3.5131(3.5025) | Error 0.0056(0.0041) Steps 1066(1050.57) | Grad Norm 1.2078(1.2882) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 119.8103, Epoch Time 1583.2090(1588.1708), Bit/dim 3.5016(best: 3.5003), Xent 2.3180, Loss 4.6607, Error 0.2716(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18490 | Time 26.6199(26.3981) | Bit/dim 3.5373(3.4956) | Xent 0.0090(0.0152) | Loss 3.5418(3.5032) | Error 0.0000(0.0041) Steps 1042(1049.59) | Grad Norm 0.7637(1.2533) | Total Time 14.00(14.00)\n",
      "Iter 18500 | Time 25.6201(26.3447) | Bit/dim 3.5014(3.4927) | Xent 0.0115(0.0148) | Loss 3.5072(3.5001) | Error 0.0011(0.0039) Steps 1072(1050.82) | Grad Norm 0.7916(1.1918) | Total Time 14.00(14.00)\n",
      "Iter 18510 | Time 26.5745(26.3427) | Bit/dim 3.4894(3.4920) | Xent 0.0124(0.0147) | Loss 3.4956(3.4994) | Error 0.0022(0.0036) Steps 1048(1049.96) | Grad Norm 1.0675(1.1474) | Total Time 14.00(14.00)\n",
      "Iter 18520 | Time 26.3576(26.2916) | Bit/dim 3.4735(3.4942) | Xent 0.0132(0.0143) | Loss 3.4801(3.5014) | Error 0.0022(0.0034) Steps 1042(1050.98) | Grad Norm 0.8812(1.1189) | Total Time 14.00(14.00)\n",
      "Iter 18530 | Time 26.7976(26.2883) | Bit/dim 3.5255(3.4967) | Xent 0.0114(0.0144) | Loss 3.5312(3.5039) | Error 0.0022(0.0035) Steps 1060(1053.79) | Grad Norm 0.8279(1.1419) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 119.7321, Epoch Time 1586.8624(1588.1315), Bit/dim 3.5000(best: 3.5003), Xent 2.3067, Loss 4.6533, Error 0.2762(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18540 | Time 26.5651(26.3717) | Bit/dim 3.5406(3.4979) | Xent 0.0101(0.0147) | Loss 3.5456(3.5052) | Error 0.0033(0.0037) Steps 1066(1054.50) | Grad Norm 1.0290(1.1269) | Total Time 14.00(14.00)\n",
      "Iter 18550 | Time 26.3786(26.4428) | Bit/dim 3.5045(3.4973) | Xent 0.0118(0.0151) | Loss 3.5104(3.5049) | Error 0.0044(0.0038) Steps 1036(1055.11) | Grad Norm 0.9013(1.1568) | Total Time 14.00(14.00)\n",
      "Iter 18560 | Time 25.8350(26.4000) | Bit/dim 3.4842(3.4965) | Xent 0.0126(0.0152) | Loss 3.4905(3.5041) | Error 0.0011(0.0039) Steps 1048(1055.36) | Grad Norm 1.1115(1.1607) | Total Time 14.00(14.00)\n",
      "Iter 18570 | Time 25.7815(26.3555) | Bit/dim 3.4576(3.4935) | Xent 0.0267(0.0153) | Loss 3.4709(3.5011) | Error 0.0111(0.0040) Steps 1066(1055.63) | Grad Norm 1.9897(1.1881) | Total Time 14.00(14.00)\n",
      "Iter 18580 | Time 26.1962(26.2987) | Bit/dim 3.4966(3.4961) | Xent 0.0187(0.0153) | Loss 3.5060(3.5038) | Error 0.0044(0.0039) Steps 1072(1055.22) | Grad Norm 1.5751(1.1892) | Total Time 14.00(14.00)\n",
      "Iter 18590 | Time 26.8231(26.3284) | Bit/dim 3.4903(3.4960) | Xent 0.0143(0.0154) | Loss 3.4975(3.5037) | Error 0.0044(0.0039) Steps 1054(1055.20) | Grad Norm 1.2997(1.1708) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 120.6902, Epoch Time 1589.3125(1588.1670), Bit/dim 3.5013(best: 3.5000), Xent 2.3169, Loss 4.6598, Error 0.2758(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18600 | Time 26.8176(26.3239) | Bit/dim 3.5132(3.4958) | Xent 0.0148(0.0156) | Loss 3.5206(3.5036) | Error 0.0033(0.0041) Steps 1036(1054.07) | Grad Norm 0.7978(1.1790) | Total Time 14.00(14.00)\n",
      "Iter 18610 | Time 25.8004(26.3548) | Bit/dim 3.5022(3.4953) | Xent 0.0149(0.0156) | Loss 3.5097(3.5031) | Error 0.0022(0.0043) Steps 1066(1055.93) | Grad Norm 1.0083(1.1660) | Total Time 14.00(14.00)\n",
      "Iter 18620 | Time 26.7973(26.3009) | Bit/dim 3.4783(3.4935) | Xent 0.0128(0.0151) | Loss 3.4847(3.5011) | Error 0.0022(0.0041) Steps 1018(1053.11) | Grad Norm 0.8335(1.1596) | Total Time 14.00(14.00)\n",
      "Iter 18630 | Time 26.7503(26.3345) | Bit/dim 3.5047(3.4959) | Xent 0.0140(0.0150) | Loss 3.5117(3.5034) | Error 0.0022(0.0039) Steps 1066(1055.16) | Grad Norm 1.3558(1.1624) | Total Time 14.00(14.00)\n",
      "Iter 18640 | Time 26.1941(26.3845) | Bit/dim 3.5116(3.4957) | Xent 0.0164(0.0146) | Loss 3.5198(3.5030) | Error 0.0044(0.0037) Steps 1042(1055.57) | Grad Norm 0.9952(1.1167) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 120.1583, Epoch Time 1589.0608(1588.1938), Bit/dim 3.4999(best: 3.5000), Xent 2.3147, Loss 4.6573, Error 0.2770(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18650 | Time 26.5027(26.3697) | Bit/dim 3.4860(3.4959) | Xent 0.0171(0.0148) | Loss 3.4946(3.5033) | Error 0.0067(0.0039) Steps 1066(1054.26) | Grad Norm 1.1364(1.1116) | Total Time 14.00(14.00)\n",
      "Iter 18660 | Time 26.7925(26.3279) | Bit/dim 3.4964(3.4925) | Xent 0.0120(0.0149) | Loss 3.5025(3.5000) | Error 0.0022(0.0038) Steps 1072(1052.87) | Grad Norm 1.0107(1.1368) | Total Time 14.00(14.00)\n",
      "Iter 18670 | Time 26.3063(26.3258) | Bit/dim 3.5048(3.4934) | Xent 0.0094(0.0148) | Loss 3.5095(3.5008) | Error 0.0011(0.0036) Steps 1066(1054.77) | Grad Norm 0.9912(1.1228) | Total Time 14.00(14.00)\n",
      "Iter 18680 | Time 26.0152(26.3512) | Bit/dim 3.4852(3.4934) | Xent 0.0179(0.0159) | Loss 3.4941(3.5013) | Error 0.0056(0.0041) Steps 1042(1055.56) | Grad Norm 1.3450(1.2024) | Total Time 14.00(14.00)\n",
      "Iter 18690 | Time 25.7847(26.3217) | Bit/dim 3.5091(3.4957) | Xent 0.0193(0.0161) | Loss 3.5188(3.5037) | Error 0.0033(0.0044) Steps 1066(1055.51) | Grad Norm 1.3191(1.2485) | Total Time 14.00(14.00)\n",
      "Iter 18700 | Time 26.3898(26.3418) | Bit/dim 3.4757(3.4975) | Xent 0.0117(0.0162) | Loss 3.4815(3.5056) | Error 0.0033(0.0044) Steps 1054(1055.66) | Grad Norm 0.9276(1.2661) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 120.3736, Epoch Time 1585.6302(1588.1169), Bit/dim 3.5006(best: 3.4999), Xent 2.3477, Loss 4.6744, Error 0.2778(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18710 | Time 26.9325(26.4054) | Bit/dim 3.5120(3.4969) | Xent 0.0207(0.0165) | Loss 3.5223(3.5052) | Error 0.0089(0.0048) Steps 1042(1054.19) | Grad Norm 1.3910(1.3352) | Total Time 14.00(14.00)\n",
      "Iter 18720 | Time 26.5698(26.3955) | Bit/dim 3.4746(3.4969) | Xent 0.0142(0.0165) | Loss 3.4817(3.5052) | Error 0.0056(0.0048) Steps 1024(1051.51) | Grad Norm 1.3054(1.4049) | Total Time 14.00(14.00)\n",
      "Iter 18730 | Time 26.8899(26.4268) | Bit/dim 3.5149(3.4965) | Xent 0.0121(0.0163) | Loss 3.5210(3.5047) | Error 0.0033(0.0048) Steps 1042(1049.64) | Grad Norm 1.3321(1.3989) | Total Time 14.00(14.00)\n",
      "Iter 18740 | Time 25.4050(26.3842) | Bit/dim 3.5027(3.4973) | Xent 0.0177(0.0161) | Loss 3.5115(3.5054) | Error 0.0056(0.0045) Steps 1048(1050.39) | Grad Norm 1.2867(1.3079) | Total Time 14.00(14.00)\n",
      "Iter 18750 | Time 26.3294(26.3733) | Bit/dim 3.5009(3.4968) | Xent 0.0128(0.0158) | Loss 3.5073(3.5047) | Error 0.0033(0.0042) Steps 1054(1050.17) | Grad Norm 1.1127(1.2543) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 120.1002, Epoch Time 1591.8992(1588.2303), Bit/dim 3.4998(best: 3.4999), Xent 2.3711, Loss 4.6854, Error 0.2774(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18760 | Time 26.4447(26.3731) | Bit/dim 3.5121(3.4962) | Xent 0.0155(0.0151) | Loss 3.5199(3.5038) | Error 0.0033(0.0037) Steps 1060(1050.62) | Grad Norm 0.9943(1.1570) | Total Time 14.00(14.00)\n",
      "Iter 18770 | Time 25.8865(26.3351) | Bit/dim 3.5311(3.4960) | Xent 0.0121(0.0154) | Loss 3.5372(3.5038) | Error 0.0033(0.0037) Steps 1066(1051.47) | Grad Norm 0.9446(1.2233) | Total Time 14.00(14.00)\n",
      "Iter 18780 | Time 26.1118(26.3017) | Bit/dim 3.5220(3.4946) | Xent 0.0137(0.0155) | Loss 3.5289(3.5024) | Error 0.0022(0.0037) Steps 1060(1051.15) | Grad Norm 1.2590(1.2323) | Total Time 14.00(14.00)\n",
      "Iter 18790 | Time 26.9214(26.3338) | Bit/dim 3.5208(3.4943) | Xent 0.0167(0.0154) | Loss 3.5292(3.5021) | Error 0.0044(0.0038) Steps 1048(1052.00) | Grad Norm 1.0522(1.2243) | Total Time 14.00(14.00)\n",
      "Iter 18800 | Time 27.0109(26.3233) | Bit/dim 3.4800(3.4934) | Xent 0.0173(0.0152) | Loss 3.4887(3.5010) | Error 0.0056(0.0038) Steps 1078(1051.92) | Grad Norm 1.3888(1.1878) | Total Time 14.00(14.00)\n",
      "Iter 18810 | Time 26.6093(26.3530) | Bit/dim 3.4671(3.4939) | Xent 0.0274(0.0151) | Loss 3.4808(3.5014) | Error 0.0078(0.0038) Steps 1072(1052.84) | Grad Norm 1.6752(1.1714) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 120.7772, Epoch Time 1585.4980(1588.1484), Bit/dim 3.4990(best: 3.4998), Xent 2.3301, Loss 4.6640, Error 0.2776(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18820 | Time 25.6100(26.2896) | Bit/dim 3.5122(3.4947) | Xent 0.0105(0.0146) | Loss 3.5174(3.5020) | Error 0.0022(0.0036) Steps 1066(1054.04) | Grad Norm 1.0328(1.1477) | Total Time 14.00(14.00)\n",
      "Iter 18830 | Time 26.0986(26.1787) | Bit/dim 3.4723(3.4937) | Xent 0.0160(0.0146) | Loss 3.4802(3.5010) | Error 0.0022(0.0036) Steps 1042(1051.30) | Grad Norm 1.1096(1.2205) | Total Time 14.00(14.00)\n",
      "Iter 18840 | Time 26.1434(26.1995) | Bit/dim 3.4862(3.4932) | Xent 0.0194(0.0148) | Loss 3.4959(3.5006) | Error 0.0067(0.0035) Steps 1042(1053.65) | Grad Norm 1.4397(1.2431) | Total Time 14.00(14.00)\n",
      "Iter 18850 | Time 27.0434(26.2636) | Bit/dim 3.5075(3.4930) | Xent 0.0181(0.0144) | Loss 3.5166(3.5001) | Error 0.0044(0.0033) Steps 1030(1052.49) | Grad Norm 1.5211(1.2228) | Total Time 14.00(14.00)\n",
      "Iter 18860 | Time 26.3173(26.2600) | Bit/dim 3.4922(3.4954) | Xent 0.0138(0.0144) | Loss 3.4991(3.5027) | Error 0.0033(0.0034) Steps 1048(1052.51) | Grad Norm 1.2482(1.2258) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 120.0499, Epoch Time 1578.1681(1587.8490), Bit/dim 3.4983(best: 3.4990), Xent 2.3625, Loss 4.6795, Error 0.2789(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18870 | Time 25.7076(26.2186) | Bit/dim 3.5153(3.4949) | Xent 0.0206(0.0150) | Loss 3.5256(3.5025) | Error 0.0078(0.0039) Steps 1042(1050.47) | Grad Norm 1.1941(1.1973) | Total Time 14.00(14.00)\n",
      "Iter 18880 | Time 27.1901(26.2774) | Bit/dim 3.4850(3.4956) | Xent 0.0098(0.0149) | Loss 3.4899(3.5030) | Error 0.0011(0.0039) Steps 1066(1053.78) | Grad Norm 0.9903(1.2190) | Total Time 14.00(14.00)\n",
      "Iter 18890 | Time 26.5110(26.2837) | Bit/dim 3.4867(3.4935) | Xent 0.0118(0.0150) | Loss 3.4927(3.5010) | Error 0.0011(0.0038) Steps 1054(1053.54) | Grad Norm 1.0505(1.2232) | Total Time 14.00(14.00)\n",
      "Iter 18900 | Time 25.7195(26.2486) | Bit/dim 3.4883(3.4957) | Xent 0.0232(0.0151) | Loss 3.4999(3.5033) | Error 0.0089(0.0040) Steps 1054(1053.70) | Grad Norm 1.5800(1.2613) | Total Time 14.00(14.00)\n",
      "Iter 18910 | Time 26.8194(26.1709) | Bit/dim 3.4592(3.4923) | Xent 0.0155(0.0151) | Loss 3.4669(3.4999) | Error 0.0033(0.0040) Steps 1048(1052.07) | Grad Norm 1.2166(1.2139) | Total Time 14.00(14.00)\n",
      "Iter 18920 | Time 26.1883(26.2131) | Bit/dim 3.4620(3.4941) | Xent 0.0154(0.0148) | Loss 3.4697(3.5015) | Error 0.0022(0.0038) Steps 1054(1053.04) | Grad Norm 1.4927(1.2056) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 119.2018, Epoch Time 1579.3507(1587.5940), Bit/dim 3.4991(best: 3.4983), Xent 2.3221, Loss 4.6601, Error 0.2776(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18930 | Time 25.6635(26.2198) | Bit/dim 3.4870(3.4925) | Xent 0.0145(0.0152) | Loss 3.4942(3.5001) | Error 0.0056(0.0042) Steps 1060(1055.23) | Grad Norm 1.5634(1.2388) | Total Time 14.00(14.00)\n",
      "Iter 18940 | Time 27.2724(26.1745) | Bit/dim 3.5242(3.4920) | Xent 0.0155(0.0150) | Loss 3.5320(3.4996) | Error 0.0033(0.0040) Steps 1048(1054.19) | Grad Norm 1.3081(1.2152) | Total Time 14.00(14.00)\n",
      "Iter 18950 | Time 26.2199(26.1784) | Bit/dim 3.4901(3.4928) | Xent 0.0122(0.0151) | Loss 3.4963(3.5003) | Error 0.0033(0.0040) Steps 1042(1054.05) | Grad Norm 0.9562(1.1828) | Total Time 14.00(14.00)\n",
      "Iter 18960 | Time 26.0922(26.2408) | Bit/dim 3.4762(3.4934) | Xent 0.0166(0.0154) | Loss 3.4845(3.5011) | Error 0.0056(0.0041) Steps 1072(1053.30) | Grad Norm 1.8937(1.2449) | Total Time 14.00(14.00)\n",
      "Iter 18970 | Time 26.3658(26.2358) | Bit/dim 3.4970(3.4943) | Xent 0.0109(0.0156) | Loss 3.5024(3.5021) | Error 0.0022(0.0042) Steps 1060(1053.26) | Grad Norm 1.0855(1.2759) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 118.4446, Epoch Time 1579.5857(1587.3538), Bit/dim 3.4996(best: 3.4983), Xent 2.3390, Loss 4.6691, Error 0.2745(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18980 | Time 26.1707(26.2383) | Bit/dim 3.4699(3.4969) | Xent 0.0109(0.0155) | Loss 3.4753(3.5047) | Error 0.0044(0.0045) Steps 1036(1050.83) | Grad Norm 0.9761(1.2988) | Total Time 14.00(14.00)\n",
      "Iter 18990 | Time 27.1413(26.2921) | Bit/dim 3.4557(3.4967) | Xent 0.0144(0.0153) | Loss 3.4629(3.5044) | Error 0.0022(0.0044) Steps 1060(1050.55) | Grad Norm 1.1789(1.3024) | Total Time 14.00(14.00)\n",
      "Iter 19000 | Time 26.1639(26.3096) | Bit/dim 3.5076(3.4960) | Xent 0.0185(0.0159) | Loss 3.5169(3.5039) | Error 0.0056(0.0044) Steps 1066(1051.42) | Grad Norm 1.7942(1.3676) | Total Time 14.00(14.00)\n",
      "Iter 19010 | Time 25.8690(26.3298) | Bit/dim 3.5158(3.4942) | Xent 0.0186(0.0158) | Loss 3.5251(3.5021) | Error 0.0078(0.0043) Steps 1036(1050.31) | Grad Norm 1.5428(1.3695) | Total Time 14.00(14.00)\n",
      "Iter 19020 | Time 26.3177(26.2800) | Bit/dim 3.4660(3.4952) | Xent 0.0112(0.0151) | Loss 3.4716(3.5028) | Error 0.0011(0.0038) Steps 1060(1050.95) | Grad Norm 1.3412(1.3390) | Total Time 14.00(14.00)\n",
      "Iter 19030 | Time 26.5672(26.2582) | Bit/dim 3.5279(3.4948) | Xent 0.0207(0.0150) | Loss 3.5382(3.5023) | Error 0.0056(0.0038) Steps 1060(1051.15) | Grad Norm 1.6847(1.3082) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 119.7918, Epoch Time 1583.7009(1587.2442), Bit/dim 3.4991(best: 3.4983), Xent 2.3248, Loss 4.6615, Error 0.2782(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19040 | Time 26.3486(26.2783) | Bit/dim 3.4923(3.4956) | Xent 0.0205(0.0154) | Loss 3.5026(3.5033) | Error 0.0078(0.0041) Steps 1048(1050.56) | Grad Norm 1.6752(1.3132) | Total Time 14.00(14.00)\n",
      "Iter 19050 | Time 26.6990(26.3677) | Bit/dim 3.4816(3.4947) | Xent 0.0129(0.0153) | Loss 3.4880(3.5023) | Error 0.0033(0.0040) Steps 1054(1051.12) | Grad Norm 0.8356(1.2992) | Total Time 14.00(14.00)\n",
      "Iter 19060 | Time 26.8050(26.3963) | Bit/dim 3.4617(3.4951) | Xent 0.0169(0.0153) | Loss 3.4701(3.5027) | Error 0.0056(0.0041) Steps 1066(1052.99) | Grad Norm 1.6344(1.3026) | Total Time 14.00(14.00)\n",
      "Iter 19070 | Time 26.3161(26.3373) | Bit/dim 3.5077(3.4970) | Xent 0.0083(0.0150) | Loss 3.5119(3.5045) | Error 0.0011(0.0039) Steps 1084(1052.86) | Grad Norm 0.8650(1.2615) | Total Time 14.00(14.00)\n",
      "Iter 19080 | Time 26.0248(26.2666) | Bit/dim 3.4675(3.4949) | Xent 0.0178(0.0156) | Loss 3.4764(3.5027) | Error 0.0033(0.0040) Steps 1054(1052.12) | Grad Norm 1.2871(1.2958) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 118.5783, Epoch Time 1585.0778(1587.1792), Bit/dim 3.4990(best: 3.4983), Xent 2.3851, Loss 4.6915, Error 0.2766(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19090 | Time 27.0096(26.3565) | Bit/dim 3.4879(3.4950) | Xent 0.0194(0.0159) | Loss 3.4976(3.5030) | Error 0.0044(0.0041) Steps 1036(1053.15) | Grad Norm 1.8830(1.3717) | Total Time 14.00(14.00)\n",
      "Iter 19100 | Time 25.8276(26.3490) | Bit/dim 3.4803(3.4931) | Xent 0.0119(0.0158) | Loss 3.4863(3.5010) | Error 0.0022(0.0041) Steps 1030(1051.77) | Grad Norm 1.6356(1.4533) | Total Time 14.00(14.00)\n",
      "Iter 19110 | Time 26.0892(26.3721) | Bit/dim 3.4845(3.4916) | Xent 0.0119(0.0159) | Loss 3.4905(3.4996) | Error 0.0044(0.0044) Steps 1042(1051.95) | Grad Norm 1.0087(1.4213) | Total Time 14.00(14.00)\n",
      "Iter 19120 | Time 26.4852(26.4157) | Bit/dim 3.4929(3.4940) | Xent 0.0176(0.0164) | Loss 3.5018(3.5022) | Error 0.0078(0.0045) Steps 1066(1055.01) | Grad Norm 1.6843(1.4398) | Total Time 14.00(14.00)\n",
      "Iter 19130 | Time 26.7572(26.4975) | Bit/dim 3.4798(3.4930) | Xent 0.0181(0.0165) | Loss 3.4888(3.5013) | Error 0.0078(0.0045) Steps 1060(1053.72) | Grad Norm 1.4094(1.5045) | Total Time 14.00(14.00)\n",
      "Iter 19140 | Time 25.7052(26.4965) | Bit/dim 3.4473(3.4947) | Xent 0.0182(0.0168) | Loss 3.4564(3.5031) | Error 0.0067(0.0048) Steps 1036(1052.91) | Grad Norm 1.9119(1.5160) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 120.1002, Epoch Time 1597.4489(1587.4873), Bit/dim 3.4992(best: 3.4983), Xent 2.3548, Loss 4.6766, Error 0.2712(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19150 | Time 26.5026(26.4789) | Bit/dim 3.4920(3.4947) | Xent 0.0199(0.0170) | Loss 3.5020(3.5032) | Error 0.0044(0.0048) Steps 1036(1052.15) | Grad Norm 1.2518(1.4652) | Total Time 14.00(14.00)\n",
      "Iter 19160 | Time 26.9728(26.4358) | Bit/dim 3.4789(3.4958) | Xent 0.0124(0.0163) | Loss 3.4851(3.5039) | Error 0.0022(0.0046) Steps 1048(1051.41) | Grad Norm 1.1319(1.4240) | Total Time 14.00(14.00)\n",
      "Iter 19170 | Time 25.3870(26.3640) | Bit/dim 3.4937(3.4941) | Xent 0.0168(0.0160) | Loss 3.5021(3.5021) | Error 0.0078(0.0045) Steps 1066(1051.80) | Grad Norm 1.3088(1.4062) | Total Time 14.00(14.00)\n",
      "Iter 19180 | Time 26.5760(26.3983) | Bit/dim 3.4708(3.4915) | Xent 0.0175(0.0153) | Loss 3.4796(3.4991) | Error 0.0067(0.0040) Steps 1036(1049.93) | Grad Norm 1.2028(1.3364) | Total Time 14.00(14.00)\n",
      "Iter 19190 | Time 27.1172(26.4378) | Bit/dim 3.4883(3.4917) | Xent 0.0200(0.0157) | Loss 3.4983(3.4995) | Error 0.0089(0.0043) Steps 1066(1052.83) | Grad Norm 1.5100(1.3331) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 118.4949, Epoch Time 1586.1464(1587.4471), Bit/dim 3.4999(best: 3.4983), Xent 2.3501, Loss 4.6749, Error 0.2757(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19200 | Time 26.5482(26.3887) | Bit/dim 3.4745(3.4934) | Xent 0.0148(0.0155) | Loss 3.4819(3.5012) | Error 0.0067(0.0044) Steps 1066(1051.96) | Grad Norm 1.6474(1.3401) | Total Time 14.00(14.00)\n",
      "Iter 19210 | Time 26.8958(26.4337) | Bit/dim 3.4695(3.4910) | Xent 0.0150(0.0155) | Loss 3.4770(3.4988) | Error 0.0033(0.0044) Steps 1060(1051.55) | Grad Norm 1.1806(1.3300) | Total Time 14.00(14.00)\n",
      "Iter 19220 | Time 26.3725(26.4391) | Bit/dim 3.4830(3.4956) | Xent 0.0146(0.0148) | Loss 3.4903(3.5029) | Error 0.0044(0.0039) Steps 1042(1052.71) | Grad Norm 2.0204(1.2961) | Total Time 14.00(14.00)\n",
      "Iter 19230 | Time 26.3801(26.3823) | Bit/dim 3.5098(3.4954) | Xent 0.0128(0.0151) | Loss 3.5162(3.5030) | Error 0.0022(0.0040) Steps 1054(1052.03) | Grad Norm 1.2657(1.2694) | Total Time 14.00(14.00)\n",
      "Iter 19240 | Time 26.4514(26.4119) | Bit/dim 3.4880(3.4966) | Xent 0.0162(0.0156) | Loss 3.4962(3.5044) | Error 0.0022(0.0042) Steps 1042(1053.14) | Grad Norm 1.2785(1.3510) | Total Time 14.00(14.00)\n",
      "Iter 19250 | Time 25.6994(26.4096) | Bit/dim 3.4899(3.4933) | Xent 0.0177(0.0155) | Loss 3.4988(3.5010) | Error 0.0044(0.0043) Steps 1072(1054.46) | Grad Norm 1.3683(1.3461) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 120.1025, Epoch Time 1590.6168(1587.5421), Bit/dim 3.5003(best: 3.4983), Xent 2.3941, Loss 4.6973, Error 0.2759(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19260 | Time 26.5754(26.3864) | Bit/dim 3.4782(3.4954) | Xent 0.0116(0.0148) | Loss 3.4840(3.5028) | Error 0.0044(0.0041) Steps 1036(1054.31) | Grad Norm 1.0480(1.2592) | Total Time 14.00(14.00)\n",
      "Iter 19270 | Time 26.1696(26.3951) | Bit/dim 3.4825(3.4947) | Xent 0.0110(0.0149) | Loss 3.4880(3.5021) | Error 0.0022(0.0040) Steps 1048(1052.58) | Grad Norm 0.8870(1.2226) | Total Time 14.00(14.00)\n",
      "Iter 19280 | Time 26.5130(26.4344) | Bit/dim 3.4941(3.4941) | Xent 0.0139(0.0147) | Loss 3.5010(3.5015) | Error 0.0033(0.0039) Steps 1042(1052.77) | Grad Norm 1.3851(1.1821) | Total Time 14.00(14.00)\n",
      "Iter 19290 | Time 26.1208(26.3870) | Bit/dim 3.4894(3.4902) | Xent 0.0185(0.0149) | Loss 3.4987(3.4977) | Error 0.0067(0.0040) Steps 1042(1052.39) | Grad Norm 1.0971(1.1562) | Total Time 14.00(14.00)\n",
      "Iter 19300 | Time 25.1580(26.3860) | Bit/dim 3.5154(3.4902) | Xent 0.0135(0.0153) | Loss 3.5221(3.4979) | Error 0.0033(0.0040) Steps 1042(1053.11) | Grad Norm 0.9560(1.1523) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 120.6619, Epoch Time 1589.1001(1587.5889), Bit/dim 3.4981(best: 3.4983), Xent 2.3657, Loss 4.6810, Error 0.2753(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19310 | Time 26.6154(26.3918) | Bit/dim 3.4760(3.4938) | Xent 0.0124(0.0151) | Loss 3.4822(3.5014) | Error 0.0022(0.0038) Steps 1048(1054.78) | Grad Norm 1.1702(1.1914) | Total Time 14.00(14.00)\n",
      "Iter 19320 | Time 26.3886(26.3111) | Bit/dim 3.5197(3.4928) | Xent 0.0115(0.0149) | Loss 3.5254(3.5002) | Error 0.0022(0.0037) Steps 1048(1054.20) | Grad Norm 0.8586(1.1637) | Total Time 14.00(14.00)\n",
      "Iter 19330 | Time 25.8178(26.2683) | Bit/dim 3.5108(3.4940) | Xent 0.0173(0.0150) | Loss 3.5194(3.5015) | Error 0.0033(0.0039) Steps 1042(1052.33) | Grad Norm 1.8882(1.2783) | Total Time 14.00(14.00)\n",
      "Iter 19340 | Time 26.5556(26.3257) | Bit/dim 3.4739(3.4914) | Xent 0.0165(0.0146) | Loss 3.4822(3.4987) | Error 0.0056(0.0036) Steps 1048(1052.74) | Grad Norm 1.1929(1.2942) | Total Time 14.00(14.00)\n",
      "Iter 19350 | Time 26.4124(26.3787) | Bit/dim 3.4530(3.4919) | Xent 0.0174(0.0148) | Loss 3.4617(3.4994) | Error 0.0044(0.0038) Steps 1048(1053.00) | Grad Norm 1.3146(1.3212) | Total Time 14.00(14.00)\n",
      "Iter 19360 | Time 26.9796(26.3892) | Bit/dim 3.4763(3.4928) | Xent 0.0146(0.0147) | Loss 3.4836(3.5001) | Error 0.0033(0.0036) Steps 1066(1054.32) | Grad Norm 1.0865(1.2824) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 119.6780, Epoch Time 1586.7081(1587.5625), Bit/dim 3.4991(best: 3.4981), Xent 2.3882, Loss 4.6932, Error 0.2779(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19370 | Time 27.1114(26.3865) | Bit/dim 3.4805(3.4952) | Xent 0.0149(0.0152) | Loss 3.4880(3.5028) | Error 0.0044(0.0039) Steps 1084(1055.82) | Grad Norm 1.1815(1.2665) | Total Time 14.00(14.00)\n",
      "Iter 19380 | Time 25.7076(26.3101) | Bit/dim 3.4680(3.4949) | Xent 0.0122(0.0151) | Loss 3.4741(3.5024) | Error 0.0011(0.0038) Steps 1042(1053.83) | Grad Norm 1.1550(1.2605) | Total Time 14.00(14.00)\n",
      "Iter 19390 | Time 26.2743(26.3222) | Bit/dim 3.4841(3.4952) | Xent 0.0181(0.0152) | Loss 3.4931(3.5028) | Error 0.0044(0.0040) Steps 1042(1052.64) | Grad Norm 1.3328(1.2463) | Total Time 14.00(14.00)\n",
      "Iter 19400 | Time 25.7911(26.2655) | Bit/dim 3.5181(3.4948) | Xent 0.0182(0.0146) | Loss 3.5272(3.5021) | Error 0.0033(0.0037) Steps 1042(1051.03) | Grad Norm 1.3743(1.2020) | Total Time 14.00(14.00)\n",
      "Iter 19410 | Time 25.7621(26.2336) | Bit/dim 3.4854(3.4912) | Xent 0.0263(0.0156) | Loss 3.4985(3.4990) | Error 0.0056(0.0040) Steps 1048(1049.96) | Grad Norm 1.2477(1.1978) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 119.6878, Epoch Time 1581.3617(1587.3764), Bit/dim 3.4978(best: 3.4981), Xent 2.3946, Loss 4.6951, Error 0.2789(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19420 | Time 26.0068(26.2366) | Bit/dim 3.4933(3.4909) | Xent 0.0208(0.0153) | Loss 3.5038(3.4985) | Error 0.0067(0.0038) Steps 1048(1050.53) | Grad Norm 1.2046(1.1641) | Total Time 14.00(14.00)\n",
      "Iter 19430 | Time 26.5126(26.3026) | Bit/dim 3.5083(3.4924) | Xent 0.0180(0.0154) | Loss 3.5173(3.5001) | Error 0.0044(0.0037) Steps 1024(1053.29) | Grad Norm 1.4372(1.1828) | Total Time 14.00(14.00)\n",
      "Iter 19440 | Time 26.4762(26.3467) | Bit/dim 3.5409(3.4930) | Xent 0.0176(0.0153) | Loss 3.5496(3.5006) | Error 0.0056(0.0039) Steps 1036(1054.54) | Grad Norm 1.0573(1.2805) | Total Time 14.00(14.00)\n",
      "Iter 19450 | Time 26.5951(26.3653) | Bit/dim 3.5091(3.4906) | Xent 0.0211(0.0153) | Loss 3.5197(3.4982) | Error 0.0089(0.0039) Steps 1048(1054.65) | Grad Norm 1.6028(1.3068) | Total Time 14.00(14.00)\n",
      "Iter 19460 | Time 26.5238(26.3513) | Bit/dim 3.5155(3.4921) | Xent 0.0128(0.0149) | Loss 3.5219(3.4995) | Error 0.0022(0.0037) Steps 1042(1051.89) | Grad Norm 0.9466(1.3078) | Total Time 14.00(14.00)\n",
      "Iter 19470 | Time 26.2703(26.3143) | Bit/dim 3.4677(3.4936) | Xent 0.0175(0.0153) | Loss 3.4764(3.5013) | Error 0.0022(0.0038) Steps 1048(1049.76) | Grad Norm 1.6432(1.3908) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 120.4610, Epoch Time 1587.7714(1587.3883), Bit/dim 3.4983(best: 3.4978), Xent 2.4484, Loss 4.7225, Error 0.2793(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19480 | Time 26.9094(26.3510) | Bit/dim 3.5066(3.4923) | Xent 0.0164(0.0162) | Loss 3.5148(3.5003) | Error 0.0056(0.0044) Steps 1048(1050.68) | Grad Norm 1.2485(1.4777) | Total Time 14.00(14.00)\n",
      "Iter 19490 | Time 26.6481(26.3411) | Bit/dim 3.5122(3.4933) | Xent 0.0137(0.0153) | Loss 3.5190(3.5010) | Error 0.0033(0.0042) Steps 1060(1050.60) | Grad Norm 1.5277(1.4089) | Total Time 14.00(14.00)\n",
      "Iter 19500 | Time 26.4782(26.3141) | Bit/dim 3.4951(3.4919) | Xent 0.0113(0.0148) | Loss 3.5007(3.4993) | Error 0.0000(0.0039) Steps 1066(1052.13) | Grad Norm 0.8885(1.3080) | Total Time 14.00(14.00)\n",
      "Iter 19510 | Time 26.2602(26.3113) | Bit/dim 3.4804(3.4911) | Xent 0.0090(0.0150) | Loss 3.4850(3.4986) | Error 0.0011(0.0038) Steps 1054(1052.64) | Grad Norm 0.7710(1.2896) | Total Time 14.00(14.00)\n",
      "Iter 19520 | Time 26.3468(26.3570) | Bit/dim 3.5544(3.4939) | Xent 0.0171(0.0149) | Loss 3.5630(3.5014) | Error 0.0056(0.0037) Steps 1042(1051.37) | Grad Norm 1.3113(1.3590) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 119.4240, Epoch Time 1585.4243(1587.3294), Bit/dim 3.4988(best: 3.4978), Xent 2.4142, Loss 4.7059, Error 0.2791(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19530 | Time 26.2212(26.3275) | Bit/dim 3.4916(3.4939) | Xent 0.0224(0.0155) | Loss 3.5028(3.5016) | Error 0.0078(0.0040) Steps 1066(1052.47) | Grad Norm 2.8346(1.4362) | Total Time 14.00(14.00)\n",
      "Iter 19540 | Time 26.5854(26.3026) | Bit/dim 3.4953(3.4927) | Xent 0.0108(0.0152) | Loss 3.5007(3.5003) | Error 0.0033(0.0042) Steps 1060(1052.81) | Grad Norm 1.8523(1.5744) | Total Time 14.00(14.00)\n",
      "Iter 19550 | Time 26.2338(26.2880) | Bit/dim 3.4920(3.4949) | Xent 0.0182(0.0152) | Loss 3.5011(3.5025) | Error 0.0056(0.0044) Steps 1048(1051.88) | Grad Norm 1.6340(1.5356) | Total Time 14.00(14.00)\n",
      "Iter 19560 | Time 26.6992(26.3610) | Bit/dim 3.5042(3.4963) | Xent 0.0189(0.0154) | Loss 3.5137(3.5040) | Error 0.0067(0.0046) Steps 1066(1051.74) | Grad Norm 1.6381(1.5525) | Total Time 14.00(14.00)\n",
      "Iter 19570 | Time 25.8812(26.4077) | Bit/dim 3.4827(3.4960) | Xent 0.0145(0.0152) | Loss 3.4899(3.5036) | Error 0.0044(0.0044) Steps 1066(1050.99) | Grad Norm 1.5327(1.5246) | Total Time 14.00(14.00)\n",
      "Iter 19580 | Time 27.2808(26.3805) | Bit/dim 3.4763(3.4917) | Xent 0.0247(0.0154) | Loss 3.4887(3.4994) | Error 0.0078(0.0044) Steps 1054(1050.55) | Grad Norm 1.9817(1.5450) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 119.5461, Epoch Time 1587.6247(1587.3382), Bit/dim 3.4992(best: 3.4978), Xent 2.4322, Loss 4.7153, Error 0.2838(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19590 | Time 26.5344(26.2735) | Bit/dim 3.5046(3.4929) | Xent 0.0158(0.0156) | Loss 3.5125(3.5007) | Error 0.0022(0.0041) Steps 1072(1051.11) | Grad Norm 1.8444(1.5463) | Total Time 14.00(14.00)\n",
      "Iter 19600 | Time 26.6887(26.2625) | Bit/dim 3.5084(3.4928) | Xent 0.0163(0.0157) | Loss 3.5165(3.5007) | Error 0.0044(0.0041) Steps 1060(1051.61) | Grad Norm 2.0722(1.5305) | Total Time 14.00(14.00)\n",
      "Iter 19610 | Time 26.0682(26.2574) | Bit/dim 3.4635(3.4920) | Xent 0.0129(0.0157) | Loss 3.4699(3.4998) | Error 0.0033(0.0040) Steps 1048(1050.36) | Grad Norm 1.1844(1.5087) | Total Time 14.00(14.00)\n",
      "Iter 19620 | Time 25.7724(26.2386) | Bit/dim 3.4747(3.4898) | Xent 0.0130(0.0156) | Loss 3.4812(3.4977) | Error 0.0044(0.0040) Steps 1060(1050.19) | Grad Norm 1.2786(1.4375) | Total Time 14.00(14.00)\n",
      "Iter 19630 | Time 25.6889(26.0652) | Bit/dim 3.5038(3.4916) | Xent 0.0197(0.0159) | Loss 3.5136(3.4996) | Error 0.0056(0.0042) Steps 1072(1049.45) | Grad Norm 1.5471(1.4191) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 120.5334, Epoch Time 1572.5620(1586.8949), Bit/dim 3.4996(best: 3.4978), Xent 2.3872, Loss 4.6932, Error 0.2763(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19640 | Time 25.5069(26.0900) | Bit/dim 3.4797(3.4929) | Xent 0.0124(0.0158) | Loss 3.4859(3.5008) | Error 0.0033(0.0041) Steps 1048(1049.25) | Grad Norm 1.3273(1.3960) | Total Time 14.00(14.00)\n",
      "Iter 19650 | Time 25.4850(26.0544) | Bit/dim 3.4547(3.4907) | Xent 0.0157(0.0152) | Loss 3.4626(3.4983) | Error 0.0056(0.0037) Steps 1036(1048.67) | Grad Norm 1.0127(1.2984) | Total Time 14.00(14.00)\n",
      "Iter 19660 | Time 25.7684(26.0501) | Bit/dim 3.4667(3.4902) | Xent 0.0160(0.0150) | Loss 3.4747(3.4977) | Error 0.0044(0.0039) Steps 1060(1048.63) | Grad Norm 1.6797(1.2650) | Total Time 14.00(14.00)\n",
      "Iter 19670 | Time 27.0451(26.0882) | Bit/dim 3.4932(3.4910) | Xent 0.0170(0.0157) | Loss 3.5017(3.4988) | Error 0.0067(0.0043) Steps 1036(1046.48) | Grad Norm 1.9902(1.3069) | Total Time 14.00(14.00)\n",
      "Iter 19680 | Time 25.9042(26.1298) | Bit/dim 3.4905(3.4916) | Xent 0.0171(0.0149) | Loss 3.4990(3.4990) | Error 0.0067(0.0040) Steps 1042(1048.72) | Grad Norm 1.4213(1.2744) | Total Time 14.00(14.00)\n",
      "Iter 19690 | Time 25.9607(26.0657) | Bit/dim 3.5329(3.4945) | Xent 0.0193(0.0148) | Loss 3.5426(3.5019) | Error 0.0056(0.0041) Steps 1054(1048.29) | Grad Norm 1.6414(1.3014) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 119.7745, Epoch Time 1571.0229(1586.4188), Bit/dim 3.4978(best: 3.4978), Xent 2.4035, Loss 4.6995, Error 0.2761(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19700 | Time 25.7061(26.0374) | Bit/dim 3.4948(3.4927) | Xent 0.0104(0.0151) | Loss 3.5000(3.5002) | Error 0.0011(0.0040) Steps 1006(1047.08) | Grad Norm 1.0794(1.2790) | Total Time 14.00(14.00)\n",
      "Iter 19710 | Time 26.1544(26.0317) | Bit/dim 3.5005(3.4931) | Xent 0.0118(0.0149) | Loss 3.5064(3.5006) | Error 0.0022(0.0039) Steps 1036(1046.72) | Grad Norm 1.3728(1.2762) | Total Time 14.00(14.00)\n",
      "Iter 19720 | Time 25.2220(26.0266) | Bit/dim 3.4653(3.4930) | Xent 0.0126(0.0146) | Loss 3.4716(3.5004) | Error 0.0033(0.0037) Steps 1042(1045.12) | Grad Norm 1.1289(1.2596) | Total Time 14.00(14.00)\n",
      "Iter 19730 | Time 25.2584(26.0435) | Bit/dim 3.5048(3.4949) | Xent 0.0173(0.0144) | Loss 3.5135(3.5021) | Error 0.0033(0.0037) Steps 1036(1046.94) | Grad Norm 1.3846(1.2494) | Total Time 14.00(14.00)\n",
      "Iter 19740 | Time 25.7971(26.0476) | Bit/dim 3.4827(3.4937) | Xent 0.0212(0.0150) | Loss 3.4933(3.5012) | Error 0.0056(0.0038) Steps 1048(1047.34) | Grad Norm 1.5508(1.2383) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 119.4081, Epoch Time 1569.0792(1585.8986), Bit/dim 3.4976(best: 3.4978), Xent 2.4083, Loss 4.7017, Error 0.2764(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19750 | Time 26.4850(26.0753) | Bit/dim 3.4837(3.4911) | Xent 0.0146(0.0153) | Loss 3.4910(3.4987) | Error 0.0033(0.0039) Steps 1054(1047.31) | Grad Norm 1.7997(1.2992) | Total Time 14.00(14.00)\n",
      "Iter 19760 | Time 26.3178(26.0706) | Bit/dim 3.5157(3.4938) | Xent 0.0113(0.0147) | Loss 3.5213(3.5011) | Error 0.0022(0.0038) Steps 1060(1048.95) | Grad Norm 1.6501(1.3077) | Total Time 14.00(14.00)\n",
      "Iter 19770 | Time 26.4407(26.0822) | Bit/dim 3.5145(3.4952) | Xent 0.0097(0.0145) | Loss 3.5194(3.5025) | Error 0.0022(0.0037) Steps 1042(1047.71) | Grad Norm 0.9086(1.3066) | Total Time 14.00(14.00)\n",
      "Iter 19780 | Time 26.0705(26.1290) | Bit/dim 3.5054(3.4938) | Xent 0.0276(0.0153) | Loss 3.5192(3.5015) | Error 0.0111(0.0040) Steps 1054(1048.97) | Grad Norm 2.0278(1.2877) | Total Time 14.00(14.00)\n",
      "Iter 19790 | Time 25.9546(26.0814) | Bit/dim 3.4944(3.4925) | Xent 0.0141(0.0155) | Loss 3.5015(3.5002) | Error 0.0044(0.0039) Steps 1036(1049.62) | Grad Norm 1.6983(1.2944) | Total Time 14.00(14.00)\n",
      "Iter 19800 | Time 27.7771(26.2142) | Bit/dim 3.4542(3.4901) | Xent 0.0240(0.0151) | Loss 3.4662(3.4976) | Error 0.0067(0.0034) Steps 1060(1051.01) | Grad Norm 1.3201(1.2148) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 119.5204, Epoch Time 1577.9510(1585.6602), Bit/dim 3.4962(best: 3.4976), Xent 2.4188, Loss 4.7056, Error 0.2758(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19810 | Time 26.0146(26.2131) | Bit/dim 3.4968(3.4912) | Xent 0.0242(0.0146) | Loss 3.5090(3.4985) | Error 0.0044(0.0032) Steps 1048(1051.04) | Grad Norm 1.5089(1.1680) | Total Time 14.00(14.00)\n",
      "Iter 19820 | Time 26.2145(26.2179) | Bit/dim 3.5142(3.4901) | Xent 0.0200(0.0150) | Loss 3.5241(3.4976) | Error 0.0056(0.0036) Steps 1072(1051.87) | Grad Norm 1.3563(1.1825) | Total Time 14.00(14.00)\n",
      "Iter 19830 | Time 25.7996(26.2243) | Bit/dim 3.4821(3.4905) | Xent 0.0133(0.0148) | Loss 3.4888(3.4979) | Error 0.0033(0.0035) Steps 1042(1053.55) | Grad Norm 1.2943(1.2552) | Total Time 14.00(14.00)\n",
      "Iter 19840 | Time 26.3104(26.2375) | Bit/dim 3.4928(3.4899) | Xent 0.0121(0.0157) | Loss 3.4989(3.4978) | Error 0.0022(0.0040) Steps 1042(1053.53) | Grad Norm 1.8185(1.3997) | Total Time 14.00(14.00)\n",
      "Iter 19850 | Time 27.0928(26.2817) | Bit/dim 3.4924(3.4905) | Xent 0.0119(0.0161) | Loss 3.4984(3.4985) | Error 0.0022(0.0041) Steps 1090(1054.15) | Grad Norm 1.1392(1.4116) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 119.0725, Epoch Time 1580.9780(1585.5197), Bit/dim 3.4969(best: 3.4962), Xent 2.4846, Loss 4.7392, Error 0.2782(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19860 | Time 25.9825(26.2308) | Bit/dim 3.4958(3.4926) | Xent 0.0127(0.0157) | Loss 3.5022(3.5004) | Error 0.0022(0.0041) Steps 1060(1053.15) | Grad Norm 1.0608(1.4521) | Total Time 14.00(14.00)\n",
      "Iter 19870 | Time 26.5062(26.2814) | Bit/dim 3.4864(3.4929) | Xent 0.0131(0.0153) | Loss 3.4929(3.5006) | Error 0.0033(0.0040) Steps 1078(1055.31) | Grad Norm 1.4262(1.4215) | Total Time 14.00(14.00)\n",
      "Iter 19880 | Time 26.0837(26.2785) | Bit/dim 3.5016(3.4937) | Xent 0.0162(0.0151) | Loss 3.5097(3.5013) | Error 0.0056(0.0040) Steps 1066(1055.32) | Grad Norm 1.0613(1.3996) | Total Time 14.00(14.00)\n",
      "Iter 19890 | Time 26.4484(26.2715) | Bit/dim 3.5030(3.4909) | Xent 0.0180(0.0160) | Loss 3.5120(3.4989) | Error 0.0056(0.0045) Steps 1066(1055.14) | Grad Norm 1.0149(1.4311) | Total Time 14.00(14.00)\n",
      "Iter 19900 | Time 26.4655(26.2676) | Bit/dim 3.4619(3.4905) | Xent 0.0163(0.0156) | Loss 3.4701(3.4983) | Error 0.0022(0.0042) Steps 1048(1055.82) | Grad Norm 1.3092(1.3611) | Total Time 14.00(14.00)\n",
      "Iter 19910 | Time 26.0234(26.2391) | Bit/dim 3.4488(3.4915) | Xent 0.0243(0.0154) | Loss 3.4609(3.4993) | Error 0.0078(0.0041) Steps 1048(1053.37) | Grad Norm 1.6415(1.3184) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 118.7928, Epoch Time 1580.1894(1585.3598), Bit/dim 3.4963(best: 3.4962), Xent 2.4184, Loss 4.7055, Error 0.2793(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19920 | Time 26.2431(26.2319) | Bit/dim 3.4863(3.4922) | Xent 0.0092(0.0147) | Loss 3.4909(3.4995) | Error 0.0011(0.0039) Steps 1048(1051.32) | Grad Norm 0.7839(1.2746) | Total Time 14.00(14.00)\n",
      "Iter 19930 | Time 27.1170(26.2946) | Bit/dim 3.4666(3.4927) | Xent 0.0076(0.0148) | Loss 3.4704(3.5001) | Error 0.0000(0.0039) Steps 1054(1050.57) | Grad Norm 0.7625(1.2505) | Total Time 14.00(14.00)\n",
      "Iter 19940 | Time 27.3416(26.3677) | Bit/dim 3.5093(3.4932) | Xent 0.0271(0.0155) | Loss 3.5228(3.5009) | Error 0.0089(0.0043) Steps 1036(1051.70) | Grad Norm 3.0530(1.3353) | Total Time 14.00(14.00)\n",
      "Iter 19950 | Time 25.6412(26.3316) | Bit/dim 3.4932(3.4904) | Xent 0.0183(0.0157) | Loss 3.5023(3.4982) | Error 0.0033(0.0042) Steps 1054(1053.14) | Grad Norm 1.8516(1.4024) | Total Time 14.00(14.00)\n",
      "Iter 19960 | Time 26.6931(26.3523) | Bit/dim 3.4891(3.4930) | Xent 0.0186(0.0173) | Loss 3.4984(3.5016) | Error 0.0044(0.0047) Steps 1048(1054.28) | Grad Norm 2.3486(1.6564) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 119.9989, Epoch Time 1588.3079(1585.4482), Bit/dim 3.4997(best: 3.4962), Xent 2.4181, Loss 4.7088, Error 0.2758(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19970 | Time 26.1044(26.2994) | Bit/dim 3.4984(3.4921) | Xent 0.0194(0.0187) | Loss 3.5081(3.5014) | Error 0.0078(0.0052) Steps 1036(1053.81) | Grad Norm 1.7819(1.8455) | Total Time 14.00(14.00)\n",
      "Iter 19980 | Time 26.2759(26.2868) | Bit/dim 3.5025(3.4926) | Xent 0.0164(0.0182) | Loss 3.5107(3.5017) | Error 0.0044(0.0050) Steps 1060(1053.92) | Grad Norm 1.4135(1.7286) | Total Time 14.00(14.00)\n",
      "Iter 19990 | Time 27.1905(26.2955) | Bit/dim 3.4964(3.4954) | Xent 0.0154(0.0168) | Loss 3.5041(3.5038) | Error 0.0067(0.0047) Steps 1042(1053.53) | Grad Norm 1.2568(1.5726) | Total Time 14.00(14.00)\n",
      "Iter 20000 | Time 26.5084(26.3362) | Bit/dim 3.5061(3.4945) | Xent 0.0165(0.0161) | Loss 3.5143(3.5026) | Error 0.0033(0.0044) Steps 1060(1052.38) | Grad Norm 1.5419(1.4818) | Total Time 14.00(14.00)\n",
      "Iter 20010 | Time 26.3377(26.2696) | Bit/dim 3.5007(3.4945) | Xent 0.0123(0.0157) | Loss 3.5068(3.5024) | Error 0.0033(0.0041) Steps 1054(1051.93) | Grad Norm 1.3938(1.4325) | Total Time 14.00(14.00)\n",
      "Iter 20020 | Time 27.4970(26.2572) | Bit/dim 3.4551(3.4908) | Xent 0.0137(0.0154) | Loss 3.4619(3.4985) | Error 0.0022(0.0041) Steps 1048(1051.64) | Grad Norm 1.3475(1.4053) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 119.6956, Epoch Time 1580.6840(1585.3053), Bit/dim 3.4970(best: 3.4962), Xent 2.4284, Loss 4.7111, Error 0.2777(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20030 | Time 27.3086(26.2846) | Bit/dim 3.4830(3.4914) | Xent 0.0141(0.0146) | Loss 3.4900(3.4987) | Error 0.0033(0.0037) Steps 1048(1052.36) | Grad Norm 1.3417(1.3407) | Total Time 14.00(14.00)\n",
      "Iter 20040 | Time 26.7432(26.3393) | Bit/dim 3.4864(3.4890) | Xent 0.0206(0.0144) | Loss 3.4968(3.4963) | Error 0.0089(0.0037) Steps 1030(1053.41) | Grad Norm 1.5232(1.2938) | Total Time 14.00(14.00)\n",
      "Iter 20050 | Time 25.8991(26.3492) | Bit/dim 3.4660(3.4888) | Xent 0.0118(0.0144) | Loss 3.4719(3.4960) | Error 0.0022(0.0038) Steps 1036(1052.14) | Grad Norm 1.4067(1.2826) | Total Time 14.00(14.00)\n",
      "Iter 20060 | Time 26.9985(26.3869) | Bit/dim 3.4965(3.4932) | Xent 0.0108(0.0146) | Loss 3.5019(3.5005) | Error 0.0011(0.0037) Steps 1072(1053.12) | Grad Norm 0.8810(1.2715) | Total Time 14.00(14.00)\n",
      "Iter 20070 | Time 26.9549(26.3860) | Bit/dim 3.4924(3.4909) | Xent 0.0143(0.0148) | Loss 3.4995(3.4982) | Error 0.0044(0.0038) Steps 1060(1052.93) | Grad Norm 1.5526(1.2835) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 120.9014, Epoch Time 1595.7572(1585.6189), Bit/dim 3.4978(best: 3.4962), Xent 2.4377, Loss 4.7166, Error 0.2771(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20080 | Time 27.0025(26.4878) | Bit/dim 3.4766(3.4902) | Xent 0.0084(0.0145) | Loss 3.4808(3.4975) | Error 0.0011(0.0038) Steps 1078(1054.17) | Grad Norm 0.9354(1.2515) | Total Time 14.00(14.00)\n",
      "Iter 20090 | Time 26.5099(26.4734) | Bit/dim 3.4873(3.4917) | Xent 0.0150(0.0145) | Loss 3.4948(3.4989) | Error 0.0056(0.0038) Steps 1042(1052.34) | Grad Norm 1.2260(1.2238) | Total Time 14.00(14.00)\n",
      "Iter 20100 | Time 27.1748(26.5252) | Bit/dim 3.4632(3.4887) | Xent 0.0139(0.0143) | Loss 3.4702(3.4959) | Error 0.0056(0.0036) Steps 1054(1054.36) | Grad Norm 1.0149(1.2470) | Total Time 14.00(14.00)\n",
      "Iter 20110 | Time 26.6510(26.4940) | Bit/dim 3.4779(3.4870) | Xent 0.0179(0.0145) | Loss 3.4868(3.4942) | Error 0.0067(0.0038) Steps 1048(1053.35) | Grad Norm 1.0952(1.2119) | Total Time 14.00(14.00)\n",
      "Iter 20120 | Time 26.4140(26.4855) | Bit/dim 3.5023(3.4893) | Xent 0.0211(0.0148) | Loss 3.5129(3.4967) | Error 0.0067(0.0040) Steps 1060(1051.51) | Grad Norm 1.3955(1.2356) | Total Time 14.00(14.00)\n",
      "Iter 20130 | Time 26.5183(26.4937) | Bit/dim 3.4847(3.4921) | Xent 0.0098(0.0144) | Loss 3.4896(3.4993) | Error 0.0022(0.0039) Steps 1054(1051.89) | Grad Norm 0.8647(1.2198) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 122.0075, Epoch Time 1600.6358(1586.0694), Bit/dim 3.4960(best: 3.4962), Xent 2.4357, Loss 4.7139, Error 0.2777(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20140 | Time 25.8376(26.4312) | Bit/dim 3.4971(3.4918) | Xent 0.0135(0.0146) | Loss 3.5039(3.4991) | Error 0.0033(0.0041) Steps 1060(1053.74) | Grad Norm 1.4580(1.2264) | Total Time 14.00(14.00)\n",
      "Iter 20150 | Time 26.7026(26.3926) | Bit/dim 3.5137(3.4924) | Xent 0.0151(0.0143) | Loss 3.5212(3.4995) | Error 0.0056(0.0039) Steps 1048(1052.22) | Grad Norm 1.1601(1.2356) | Total Time 14.00(14.00)\n",
      "Iter 20160 | Time 25.5436(26.2804) | Bit/dim 3.5356(3.4943) | Xent 0.0135(0.0145) | Loss 3.5424(3.5015) | Error 0.0044(0.0039) Steps 1054(1050.90) | Grad Norm 1.1281(1.2287) | Total Time 14.00(14.00)\n",
      "Iter 20170 | Time 25.9939(26.3408) | Bit/dim 3.4766(3.4943) | Xent 0.0104(0.0137) | Loss 3.4818(3.5011) | Error 0.0011(0.0034) Steps 1054(1051.37) | Grad Norm 0.7670(1.1581) | Total Time 14.00(14.00)\n",
      "Iter 20180 | Time 25.9003(26.2954) | Bit/dim 3.5025(3.4918) | Xent 0.0112(0.0135) | Loss 3.5081(3.4986) | Error 0.0022(0.0034) Steps 1048(1050.80) | Grad Norm 0.7677(1.1465) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 119.9182, Epoch Time 1582.7165(1585.9688), Bit/dim 3.4956(best: 3.4960), Xent 2.4526, Loss 4.7219, Error 0.2771(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20190 | Time 26.4199(26.3047) | Bit/dim 3.4845(3.4870) | Xent 0.0132(0.0141) | Loss 3.4911(3.4941) | Error 0.0033(0.0036) Steps 1042(1053.43) | Grad Norm 1.3188(1.1566) | Total Time 14.00(14.00)\n",
      "Iter 20200 | Time 26.0547(26.2289) | Bit/dim 3.4920(3.4874) | Xent 0.0100(0.0137) | Loss 3.4970(3.4942) | Error 0.0022(0.0034) Steps 1054(1054.53) | Grad Norm 0.9441(1.1477) | Total Time 14.00(14.00)\n",
      "Iter 20210 | Time 26.9593(26.3187) | Bit/dim 3.5023(3.4883) | Xent 0.0139(0.0138) | Loss 3.5092(3.4952) | Error 0.0044(0.0036) Steps 1090(1057.80) | Grad Norm 1.0286(1.1449) | Total Time 14.00(14.00)\n",
      "Iter 20220 | Time 27.0906(26.3196) | Bit/dim 3.5222(3.4885) | Xent 0.0139(0.0138) | Loss 3.5292(3.4954) | Error 0.0056(0.0037) Steps 1048(1057.35) | Grad Norm 2.1077(1.1921) | Total Time 14.00(14.00)\n",
      "Iter 20230 | Time 26.5848(26.2847) | Bit/dim 3.4833(3.4900) | Xent 0.0176(0.0138) | Loss 3.4921(3.4969) | Error 0.0044(0.0038) Steps 1048(1055.49) | Grad Norm 1.4715(1.2124) | Total Time 14.00(14.00)\n",
      "Iter 20240 | Time 26.3938(26.2616) | Bit/dim 3.4864(3.4915) | Xent 0.0169(0.0138) | Loss 3.4949(3.4984) | Error 0.0067(0.0038) Steps 1054(1055.05) | Grad Norm 1.1884(1.2086) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 120.1186, Epoch Time 1581.0423(1585.8210), Bit/dim 3.4957(best: 3.4956), Xent 2.4230, Loss 4.7072, Error 0.2762(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20250 | Time 26.2988(26.2792) | Bit/dim 3.4638(3.4890) | Xent 0.0127(0.0138) | Loss 3.4702(3.4959) | Error 0.0044(0.0037) Steps 1048(1056.07) | Grad Norm 1.1980(1.1752) | Total Time 14.00(14.00)\n",
      "Iter 20260 | Time 25.6806(26.2269) | Bit/dim 3.4897(3.4893) | Xent 0.0131(0.0138) | Loss 3.4963(3.4962) | Error 0.0033(0.0038) Steps 1036(1053.53) | Grad Norm 1.5051(1.1809) | Total Time 14.00(14.00)\n",
      "Iter 20270 | Time 26.4204(26.2174) | Bit/dim 3.4832(3.4894) | Xent 0.0157(0.0141) | Loss 3.4910(3.4965) | Error 0.0056(0.0039) Steps 1072(1053.74) | Grad Norm 1.8351(1.2129) | Total Time 14.00(14.00)\n",
      "Iter 20280 | Time 26.3181(26.1972) | Bit/dim 3.5025(3.4907) | Xent 0.0148(0.0145) | Loss 3.5099(3.4979) | Error 0.0033(0.0040) Steps 1042(1054.15) | Grad Norm 1.4348(1.2945) | Total Time 14.00(14.00)\n",
      "Iter 20290 | Time 26.6280(26.2664) | Bit/dim 3.4814(3.4919) | Xent 0.0120(0.0146) | Loss 3.4873(3.4992) | Error 0.0022(0.0038) Steps 1042(1052.17) | Grad Norm 1.1012(1.3645) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 119.9905, Epoch Time 1581.2323(1585.6833), Bit/dim 3.4958(best: 3.4956), Xent 2.4475, Loss 4.7196, Error 0.2758(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20300 | Time 26.9284(26.2594) | Bit/dim 3.5056(3.4926) | Xent 0.0205(0.0145) | Loss 3.5159(3.4998) | Error 0.0056(0.0037) Steps 1078(1053.09) | Grad Norm 1.4683(1.3194) | Total Time 14.00(14.00)\n",
      "Iter 20310 | Time 26.2757(26.2616) | Bit/dim 3.4977(3.4931) | Xent 0.0116(0.0149) | Loss 3.5035(3.5005) | Error 0.0022(0.0039) Steps 1036(1050.60) | Grad Norm 0.8794(1.3637) | Total Time 14.00(14.00)\n",
      "Iter 20320 | Time 26.4040(26.2350) | Bit/dim 3.5138(3.4932) | Xent 0.0234(0.0153) | Loss 3.5254(3.5008) | Error 0.0078(0.0040) Steps 1066(1051.36) | Grad Norm 1.7179(1.3558) | Total Time 14.00(14.00)\n",
      "Iter 20330 | Time 26.6633(26.2132) | Bit/dim 3.5063(3.4924) | Xent 0.0097(0.0149) | Loss 3.5111(3.4998) | Error 0.0011(0.0040) Steps 1036(1050.68) | Grad Norm 0.6846(1.3016) | Total Time 14.00(14.00)\n",
      "Iter 20340 | Time 27.0280(26.2478) | Bit/dim 3.4854(3.4920) | Xent 0.0164(0.0147) | Loss 3.4937(3.4993) | Error 0.0044(0.0041) Steps 1030(1049.50) | Grad Norm 1.4055(1.2612) | Total Time 14.00(14.00)\n",
      "Iter 20350 | Time 26.1411(26.2471) | Bit/dim 3.4539(3.4910) | Xent 0.0135(0.0141) | Loss 3.4607(3.4981) | Error 0.0044(0.0038) Steps 1054(1051.04) | Grad Norm 1.2629(1.2223) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 120.1048, Epoch Time 1581.0667(1585.5448), Bit/dim 3.4959(best: 3.4956), Xent 2.4627, Loss 4.7272, Error 0.2761(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20360 | Time 25.2852(26.2195) | Bit/dim 3.4807(3.4904) | Xent 0.0164(0.0142) | Loss 3.4889(3.4975) | Error 0.0044(0.0036) Steps 1078(1052.57) | Grad Norm 1.2442(1.1896) | Total Time 14.00(14.00)\n",
      "Iter 20370 | Time 26.0287(26.2616) | Bit/dim 3.4765(3.4920) | Xent 0.0146(0.0138) | Loss 3.4838(3.4990) | Error 0.0044(0.0034) Steps 1054(1051.45) | Grad Norm 0.8718(1.1457) | Total Time 14.00(14.00)\n",
      "Iter 20380 | Time 25.9843(26.2447) | Bit/dim 3.4845(3.4908) | Xent 0.0136(0.0137) | Loss 3.4913(3.4977) | Error 0.0022(0.0035) Steps 1060(1053.16) | Grad Norm 0.8954(1.1369) | Total Time 14.00(14.00)\n",
      "Iter 20390 | Time 26.1420(26.2591) | Bit/dim 3.4730(3.4916) | Xent 0.0125(0.0138) | Loss 3.4792(3.4985) | Error 0.0044(0.0036) Steps 1072(1054.11) | Grad Norm 2.2138(1.2148) | Total Time 14.00(14.00)\n",
      "Iter 20400 | Time 26.2458(26.2539) | Bit/dim 3.5116(3.4907) | Xent 0.0128(0.0144) | Loss 3.5180(3.4978) | Error 0.0033(0.0038) Steps 1054(1054.29) | Grad Norm 1.9234(1.4389) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 120.6560, Epoch Time 1587.1856(1585.5940), Bit/dim 3.4949(best: 3.4956), Xent 2.4740, Loss 4.7319, Error 0.2796(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20410 | Time 25.9269(26.2275) | Bit/dim 3.5189(3.4923) | Xent 0.0183(0.0144) | Loss 3.5280(3.4995) | Error 0.0078(0.0039) Steps 1072(1055.93) | Grad Norm 1.5101(1.5100) | Total Time 14.00(14.00)\n",
      "Iter 20420 | Time 26.2490(26.2160) | Bit/dim 3.4963(3.4921) | Xent 0.0109(0.0139) | Loss 3.5017(3.4990) | Error 0.0022(0.0037) Steps 1048(1053.74) | Grad Norm 1.8053(1.4348) | Total Time 14.00(14.00)\n",
      "Iter 20430 | Time 26.7874(26.2217) | Bit/dim 3.4940(3.4943) | Xent 0.0163(0.0135) | Loss 3.5021(3.5011) | Error 0.0044(0.0034) Steps 1042(1053.39) | Grad Norm 1.0196(1.3259) | Total Time 14.00(14.00)\n",
      "Iter 20440 | Time 26.3355(26.3162) | Bit/dim 3.4441(3.4907) | Xent 0.0084(0.0141) | Loss 3.4483(3.4978) | Error 0.0011(0.0039) Steps 1042(1054.63) | Grad Norm 0.9854(1.2988) | Total Time 14.00(14.00)\n",
      "Iter 20450 | Time 26.5651(26.4063) | Bit/dim 3.4864(3.4900) | Xent 0.0096(0.0141) | Loss 3.4912(3.4971) | Error 0.0011(0.0038) Steps 1072(1055.97) | Grad Norm 0.9276(1.2831) | Total Time 14.00(14.00)\n",
      "Iter 20460 | Time 26.6128(26.4140) | Bit/dim 3.4972(3.4887) | Xent 0.0188(0.0147) | Loss 3.5066(3.4961) | Error 0.0067(0.0040) Steps 1042(1053.68) | Grad Norm 1.2136(1.3455) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 121.6568, Epoch Time 1590.6581(1585.7460), Bit/dim 3.4957(best: 3.4949), Xent 2.4372, Loss 4.7143, Error 0.2784(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20470 | Time 26.1679(26.4376) | Bit/dim 3.5103(3.4905) | Xent 0.0148(0.0144) | Loss 3.5177(3.4977) | Error 0.0044(0.0038) Steps 1042(1051.14) | Grad Norm 1.2345(1.3196) | Total Time 14.00(14.00)\n",
      "Iter 20480 | Time 26.3033(26.4082) | Bit/dim 3.4565(3.4883) | Xent 0.0114(0.0143) | Loss 3.4622(3.4954) | Error 0.0033(0.0037) Steps 1060(1051.90) | Grad Norm 1.4710(1.3303) | Total Time 14.00(14.00)\n",
      "Iter 20490 | Time 26.2697(26.3069) | Bit/dim 3.5209(3.4882) | Xent 0.0071(0.0140) | Loss 3.5244(3.4952) | Error 0.0000(0.0037) Steps 1066(1051.47) | Grad Norm 0.7125(1.2865) | Total Time 14.00(14.00)\n",
      "Iter 20500 | Time 26.4740(26.1902) | Bit/dim 3.5011(3.4879) | Xent 0.0115(0.0141) | Loss 3.5069(3.4949) | Error 0.0022(0.0039) Steps 1060(1049.77) | Grad Norm 0.9146(1.2480) | Total Time 14.00(14.00)\n",
      "Iter 20510 | Time 26.3175(26.1163) | Bit/dim 3.4866(3.4908) | Xent 0.0178(0.0142) | Loss 3.4955(3.4979) | Error 0.0056(0.0039) Steps 1072(1050.94) | Grad Norm 1.5299(1.2699) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 120.9994, Epoch Time 1577.2552(1585.4912), Bit/dim 3.4959(best: 3.4949), Xent 2.4666, Loss 4.7291, Error 0.2755(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20520 | Time 26.2808(26.1532) | Bit/dim 3.5115(3.4915) | Xent 0.0117(0.0150) | Loss 3.5173(3.4990) | Error 0.0011(0.0041) Steps 1042(1051.19) | Grad Norm 1.5829(1.3939) | Total Time 14.00(14.00)\n",
      "Iter 20530 | Time 27.1144(26.1998) | Bit/dim 3.4936(3.4902) | Xent 0.0104(0.0151) | Loss 3.4989(3.4978) | Error 0.0000(0.0043) Steps 1072(1050.08) | Grad Norm 1.0201(1.4253) | Total Time 14.00(14.00)\n",
      "Iter 20540 | Time 25.3751(26.2287) | Bit/dim 3.4655(3.4901) | Xent 0.0180(0.0153) | Loss 3.4745(3.4977) | Error 0.0056(0.0045) Steps 1048(1049.35) | Grad Norm 1.4276(1.4380) | Total Time 14.00(14.00)\n",
      "Iter 20550 | Time 26.9183(26.3106) | Bit/dim 3.5174(3.4915) | Xent 0.0151(0.0153) | Loss 3.5249(3.4992) | Error 0.0033(0.0045) Steps 1042(1049.67) | Grad Norm 1.4808(1.4295) | Total Time 14.00(14.00)\n",
      "Iter 20560 | Time 25.5208(26.2700) | Bit/dim 3.4806(3.4910) | Xent 0.0127(0.0147) | Loss 3.4869(3.4983) | Error 0.0033(0.0042) Steps 1042(1051.35) | Grad Norm 1.3556(1.4127) | Total Time 14.00(14.00)\n",
      "Iter 20570 | Time 25.3494(26.2320) | Bit/dim 3.5160(3.4905) | Xent 0.0176(0.0145) | Loss 3.5248(3.4978) | Error 0.0056(0.0041) Steps 1030(1052.15) | Grad Norm 1.3156(1.4277) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 121.5746, Epoch Time 1584.9649(1585.4755), Bit/dim 3.4951(best: 3.4949), Xent 2.4660, Loss 4.7281, Error 0.2758(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20580 | Time 25.9393(26.1418) | Bit/dim 3.5101(3.4905) | Xent 0.0134(0.0148) | Loss 3.5168(3.4979) | Error 0.0044(0.0042) Steps 1042(1051.27) | Grad Norm 1.3345(1.5403) | Total Time 14.00(14.00)\n",
      "Iter 20590 | Time 25.6848(26.0751) | Bit/dim 3.5219(3.4892) | Xent 0.0162(0.0149) | Loss 3.5300(3.4966) | Error 0.0044(0.0042) Steps 1030(1051.60) | Grad Norm 1.1927(1.5130) | Total Time 14.00(14.00)\n",
      "Iter 20600 | Time 25.9419(26.1517) | Bit/dim 3.4875(3.4904) | Xent 0.0188(0.0150) | Loss 3.4969(3.4979) | Error 0.0067(0.0041) Steps 1042(1052.43) | Grad Norm 2.1871(1.4855) | Total Time 14.00(14.00)\n",
      "Iter 20610 | Time 26.5732(26.1410) | Bit/dim 3.5023(3.4898) | Xent 0.0161(0.0148) | Loss 3.5104(3.4971) | Error 0.0044(0.0040) Steps 1048(1053.11) | Grad Norm 1.0939(1.4064) | Total Time 14.00(14.00)\n",
      "Iter 20620 | Time 26.4864(26.1892) | Bit/dim 3.5140(3.4913) | Xent 0.0101(0.0143) | Loss 3.5191(3.4984) | Error 0.0011(0.0038) Steps 1048(1053.27) | Grad Norm 1.4332(1.3671) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 120.2044, Epoch Time 1574.4946(1585.1460), Bit/dim 3.4963(best: 3.4949), Xent 2.4791, Loss 4.7358, Error 0.2840(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20630 | Time 25.4967(26.1448) | Bit/dim 3.5092(3.4917) | Xent 0.0186(0.0146) | Loss 3.5185(3.4990) | Error 0.0078(0.0040) Steps 1048(1051.31) | Grad Norm 1.3319(1.3478) | Total Time 14.00(14.00)\n",
      "Iter 20640 | Time 26.0294(26.1419) | Bit/dim 3.5086(3.4907) | Xent 0.0189(0.0147) | Loss 3.5180(3.4981) | Error 0.0044(0.0039) Steps 1054(1052.04) | Grad Norm 1.2260(1.3277) | Total Time 14.00(14.00)\n",
      "Iter 20650 | Time 26.8588(26.2917) | Bit/dim 3.5138(3.4919) | Xent 0.0181(0.0152) | Loss 3.5228(3.4995) | Error 0.0056(0.0041) Steps 1048(1051.32) | Grad Norm 1.2152(1.3923) | Total Time 14.00(14.00)\n",
      "Iter 20660 | Time 25.7461(26.2734) | Bit/dim 3.5112(3.4912) | Xent 0.0112(0.0150) | Loss 3.5168(3.4987) | Error 0.0011(0.0040) Steps 1048(1052.02) | Grad Norm 1.0190(1.3941) | Total Time 14.00(14.00)\n",
      "Iter 20670 | Time 26.2396(26.2814) | Bit/dim 3.5307(3.4925) | Xent 0.0143(0.0151) | Loss 3.5378(3.5000) | Error 0.0033(0.0040) Steps 1054(1052.76) | Grad Norm 1.2106(1.3985) | Total Time 14.00(14.00)\n",
      "Iter 20680 | Time 26.7856(26.2896) | Bit/dim 3.4850(3.4892) | Xent 0.0137(0.0150) | Loss 3.4919(3.4967) | Error 0.0044(0.0041) Steps 1066(1052.14) | Grad Norm 1.8071(1.3906) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 121.8592, Epoch Time 1586.9523(1585.2002), Bit/dim 3.4967(best: 3.4949), Xent 2.4891, Loss 4.7412, Error 0.2781(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20690 | Time 26.0559(26.2731) | Bit/dim 3.4644(3.4897) | Xent 0.0153(0.0150) | Loss 3.4720(3.4972) | Error 0.0044(0.0041) Steps 1048(1052.76) | Grad Norm 1.4659(1.4343) | Total Time 14.00(14.00)\n",
      "Iter 20700 | Time 25.4774(26.2185) | Bit/dim 3.4733(3.4905) | Xent 0.0139(0.0145) | Loss 3.4803(3.4978) | Error 0.0056(0.0040) Steps 1060(1051.90) | Grad Norm 1.0776(1.4090) | Total Time 14.00(14.00)\n",
      "Iter 20710 | Time 26.3690(26.1823) | Bit/dim 3.4795(3.4868) | Xent 0.0106(0.0147) | Loss 3.4849(3.4942) | Error 0.0033(0.0041) Steps 1066(1053.63) | Grad Norm 0.9251(1.4199) | Total Time 14.00(14.00)\n",
      "Iter 20720 | Time 25.8649(26.1827) | Bit/dim 3.5008(3.4895) | Xent 0.0120(0.0142) | Loss 3.5069(3.4966) | Error 0.0033(0.0039) Steps 1060(1053.58) | Grad Norm 1.0606(1.3459) | Total Time 14.00(14.00)\n",
      "Iter 20730 | Time 26.3962(26.1701) | Bit/dim 3.4655(3.4900) | Xent 0.0114(0.0146) | Loss 3.4712(3.4973) | Error 0.0022(0.0040) Steps 1078(1052.68) | Grad Norm 1.3392(1.3362) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 122.1306, Epoch Time 1579.1201(1585.0178), Bit/dim 3.4939(best: 3.4949), Xent 2.5262, Loss 4.7570, Error 0.2798(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20740 | Time 26.3438(26.2356) | Bit/dim 3.4883(3.4899) | Xent 0.0127(0.0147) | Loss 3.4947(3.4972) | Error 0.0044(0.0040) Steps 1072(1052.49) | Grad Norm 1.5658(1.4317) | Total Time 14.00(14.00)\n",
      "Iter 20750 | Time 26.1599(26.2793) | Bit/dim 3.4977(3.4892) | Xent 0.0111(0.0141) | Loss 3.5032(3.4963) | Error 0.0022(0.0039) Steps 1054(1052.95) | Grad Norm 0.9537(1.3878) | Total Time 14.00(14.00)\n",
      "Iter 20760 | Time 26.3849(26.2672) | Bit/dim 3.4965(3.4890) | Xent 0.0182(0.0145) | Loss 3.5057(3.4963) | Error 0.0044(0.0040) Steps 1090(1054.33) | Grad Norm 2.1075(1.3969) | Total Time 14.00(14.00)\n",
      "Iter 20770 | Time 25.7689(26.3174) | Bit/dim 3.5129(3.4905) | Xent 0.0088(0.0150) | Loss 3.5173(3.4980) | Error 0.0000(0.0039) Steps 1048(1052.97) | Grad Norm 1.3315(1.4450) | Total Time 14.00(14.00)\n",
      "Iter 20780 | Time 26.1955(26.2706) | Bit/dim 3.4850(3.4899) | Xent 0.0150(0.0157) | Loss 3.4924(3.4977) | Error 0.0067(0.0044) Steps 1072(1052.07) | Grad Norm 1.2051(1.4802) | Total Time 14.00(14.00)\n",
      "Iter 20790 | Time 25.0284(26.1391) | Bit/dim 3.4872(3.4900) | Xent 0.0161(0.0150) | Loss 3.4952(3.4975) | Error 0.0044(0.0040) Steps 1048(1050.33) | Grad Norm 1.5661(1.4678) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 120.9140, Epoch Time 1580.3729(1584.8785), Bit/dim 3.4950(best: 3.4939), Xent 2.4814, Loss 4.7356, Error 0.2769(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20800 | Time 26.4176(26.1498) | Bit/dim 3.4826(3.4904) | Xent 0.0178(0.0144) | Loss 3.4915(3.4976) | Error 0.0056(0.0038) Steps 1048(1049.59) | Grad Norm 1.4046(1.3981) | Total Time 14.00(14.00)\n",
      "Iter 20810 | Time 25.5891(26.2024) | Bit/dim 3.5211(3.4897) | Xent 0.0126(0.0142) | Loss 3.5273(3.4968) | Error 0.0022(0.0039) Steps 1054(1050.97) | Grad Norm 1.0735(1.3694) | Total Time 14.00(14.00)\n",
      "Iter 20820 | Time 26.2668(26.1239) | Bit/dim 3.5023(3.4902) | Xent 0.0171(0.0141) | Loss 3.5108(3.4972) | Error 0.0067(0.0040) Steps 1030(1050.00) | Grad Norm 1.5200(1.3571) | Total Time 14.00(14.00)\n",
      "Iter 20830 | Time 25.4625(26.0443) | Bit/dim 3.4951(3.4897) | Xent 0.0192(0.0142) | Loss 3.5047(3.4968) | Error 0.0067(0.0040) Steps 1060(1050.84) | Grad Norm 1.4197(1.3174) | Total Time 14.00(14.00)\n",
      "Iter 20840 | Time 25.7062(26.0752) | Bit/dim 3.5071(3.4899) | Xent 0.0138(0.0145) | Loss 3.5140(3.4972) | Error 0.0044(0.0040) Steps 1054(1051.71) | Grad Norm 1.1547(1.2828) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 121.2009, Epoch Time 1574.6391(1584.5713), Bit/dim 3.4950(best: 3.4939), Xent 2.5020, Loss 4.7460, Error 0.2780(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20850 | Time 26.8841(26.1269) | Bit/dim 3.4992(3.4915) | Xent 0.0082(0.0141) | Loss 3.5033(3.4986) | Error 0.0000(0.0038) Steps 1060(1052.85) | Grad Norm 0.8578(1.2317) | Total Time 14.00(14.00)\n",
      "Iter 20860 | Time 25.7813(26.0900) | Bit/dim 3.4706(3.4880) | Xent 0.0075(0.0137) | Loss 3.4743(3.4948) | Error 0.0000(0.0034) Steps 1048(1052.50) | Grad Norm 0.7715(1.1990) | Total Time 14.00(14.00)\n",
      "Iter 20870 | Time 26.6263(26.1193) | Bit/dim 3.4465(3.4868) | Xent 0.0260(0.0146) | Loss 3.4595(3.4941) | Error 0.0089(0.0042) Steps 1072(1052.61) | Grad Norm 1.3196(1.2530) | Total Time 14.00(14.00)\n",
      "Iter 20880 | Time 25.7870(26.1944) | Bit/dim 3.4771(3.4887) | Xent 0.0094(0.0145) | Loss 3.4818(3.4959) | Error 0.0022(0.0042) Steps 1060(1054.40) | Grad Norm 1.5808(1.3570) | Total Time 14.00(14.00)\n",
      "Iter 20890 | Time 26.5461(26.1978) | Bit/dim 3.4817(3.4895) | Xent 0.0127(0.0142) | Loss 3.4881(3.4966) | Error 0.0022(0.0039) Steps 1054(1054.39) | Grad Norm 0.9715(1.3322) | Total Time 14.00(14.00)\n",
      "Iter 20900 | Time 26.8111(26.2212) | Bit/dim 3.4802(3.4910) | Xent 0.0143(0.0148) | Loss 3.4874(3.4984) | Error 0.0044(0.0041) Steps 1078(1056.02) | Grad Norm 1.4676(1.4000) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 121.2333, Epoch Time 1580.4763(1584.4484), Bit/dim 3.4950(best: 3.4939), Xent 2.4765, Loss 4.7332, Error 0.2721(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20910 | Time 26.2321(26.2517) | Bit/dim 3.4830(3.4946) | Xent 0.0180(0.0147) | Loss 3.4921(3.5019) | Error 0.0033(0.0040) Steps 1054(1054.54) | Grad Norm 1.2745(1.3456) | Total Time 14.00(14.00)\n",
      "Iter 20920 | Time 26.0834(26.2256) | Bit/dim 3.4991(3.4920) | Xent 0.0185(0.0143) | Loss 3.5084(3.4992) | Error 0.0056(0.0040) Steps 1036(1054.15) | Grad Norm 1.1257(1.2692) | Total Time 14.00(14.00)\n",
      "Iter 20930 | Time 26.0606(26.1615) | Bit/dim 3.4783(3.4908) | Xent 0.0140(0.0139) | Loss 3.4853(3.4977) | Error 0.0033(0.0037) Steps 1048(1053.67) | Grad Norm 1.0961(1.2159) | Total Time 14.00(14.00)\n",
      "Iter 20940 | Time 26.0047(26.1617) | Bit/dim 3.4802(3.4889) | Xent 0.0134(0.0138) | Loss 3.4869(3.4958) | Error 0.0022(0.0034) Steps 1048(1053.20) | Grad Norm 1.0251(1.1817) | Total Time 14.00(14.00)\n",
      "Iter 20950 | Time 26.6037(26.2414) | Bit/dim 3.4926(3.4871) | Xent 0.0093(0.0136) | Loss 3.4972(3.4939) | Error 0.0011(0.0033) Steps 1054(1053.79) | Grad Norm 0.7666(1.1463) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 121.8907, Epoch Time 1582.8620(1584.4008), Bit/dim 3.4926(best: 3.4939), Xent 2.4963, Loss 4.7408, Error 0.2778(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20960 | Time 26.1697(26.2593) | Bit/dim 3.4887(3.4860) | Xent 0.0089(0.0136) | Loss 3.4932(3.4928) | Error 0.0011(0.0034) Steps 1048(1055.03) | Grad Norm 0.7510(1.1221) | Total Time 14.00(14.00)\n",
      "Iter 20970 | Time 26.2709(26.2727) | Bit/dim 3.5009(3.4849) | Xent 0.0140(0.0138) | Loss 3.5080(3.4918) | Error 0.0033(0.0034) Steps 1048(1055.75) | Grad Norm 1.5578(1.1762) | Total Time 14.00(14.00)\n",
      "Iter 20980 | Time 25.3487(26.3127) | Bit/dim 3.4908(3.4860) | Xent 0.0192(0.0140) | Loss 3.5004(3.4931) | Error 0.0067(0.0036) Steps 1030(1056.39) | Grad Norm 1.3305(1.1708) | Total Time 14.00(14.00)\n",
      "Iter 20990 | Time 26.3237(26.3827) | Bit/dim 3.5226(3.4862) | Xent 0.0162(0.0150) | Loss 3.5307(3.4937) | Error 0.0033(0.0040) Steps 1042(1055.74) | Grad Norm 1.2878(1.2506) | Total Time 14.00(14.00)\n",
      "Iter 21000 | Time 26.0578(26.4362) | Bit/dim 3.5141(3.4907) | Xent 0.0210(0.0153) | Loss 3.5246(3.4983) | Error 0.0122(0.0043) Steps 1066(1055.71) | Grad Norm 2.7055(1.4209) | Total Time 14.00(14.00)\n",
      "Iter 21010 | Time 27.1818(26.5061) | Bit/dim 3.5153(3.4900) | Xent 0.0124(0.0147) | Loss 3.5216(3.4973) | Error 0.0033(0.0039) Steps 1042(1056.42) | Grad Norm 1.1306(1.4182) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 121.3692, Epoch Time 1596.8230(1584.7735), Bit/dim 3.4944(best: 3.4926), Xent 2.4950, Loss 4.7419, Error 0.2751(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21020 | Time 25.6653(26.4436) | Bit/dim 3.5273(3.4925) | Xent 0.0146(0.0139) | Loss 3.5346(3.4994) | Error 0.0044(0.0036) Steps 1048(1056.53) | Grad Norm 0.9947(1.3452) | Total Time 14.00(14.00)\n",
      "Iter 21030 | Time 26.3555(26.3497) | Bit/dim 3.4857(3.4928) | Xent 0.0172(0.0136) | Loss 3.4943(3.4996) | Error 0.0067(0.0035) Steps 1054(1055.74) | Grad Norm 1.2558(1.2844) | Total Time 14.00(14.00)\n",
      "Iter 21040 | Time 27.2340(26.3995) | Bit/dim 3.4783(3.4923) | Xent 0.0127(0.0142) | Loss 3.4846(3.4994) | Error 0.0022(0.0036) Steps 1036(1055.49) | Grad Norm 1.6895(1.3378) | Total Time 14.00(14.00)\n",
      "Iter 21050 | Time 26.0162(26.3635) | Bit/dim 3.4610(3.4901) | Xent 0.0210(0.0146) | Loss 3.4715(3.4974) | Error 0.0067(0.0038) Steps 1042(1057.39) | Grad Norm 1.3464(1.3487) | Total Time 14.00(14.00)\n",
      "Iter 21060 | Time 26.6946(26.3512) | Bit/dim 3.4869(3.4897) | Xent 0.0092(0.0141) | Loss 3.4915(3.4967) | Error 0.0011(0.0037) Steps 1060(1056.28) | Grad Norm 0.9717(1.3020) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 120.5100, Epoch Time 1584.7392(1584.7725), Bit/dim 3.4939(best: 3.4926), Xent 2.5365, Loss 4.7621, Error 0.2822(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21070 | Time 26.6812(26.3175) | Bit/dim 3.4922(3.4879) | Xent 0.0124(0.0138) | Loss 3.4984(3.4948) | Error 0.0022(0.0035) Steps 1078(1055.94) | Grad Norm 1.6978(1.3109) | Total Time 14.00(14.00)\n",
      "Iter 21080 | Time 26.2682(26.3233) | Bit/dim 3.4787(3.4911) | Xent 0.0079(0.0137) | Loss 3.4827(3.4980) | Error 0.0022(0.0037) Steps 1072(1056.40) | Grad Norm 1.1118(1.3137) | Total Time 14.00(14.00)\n",
      "Iter 21090 | Time 25.5657(26.2465) | Bit/dim 3.4902(3.4887) | Xent 0.0131(0.0141) | Loss 3.4968(3.4957) | Error 0.0044(0.0040) Steps 1048(1057.08) | Grad Norm 2.0738(1.3225) | Total Time 14.00(14.00)\n",
      "Iter 21100 | Time 26.1436(26.2870) | Bit/dim 3.4618(3.4879) | Xent 0.0148(0.0144) | Loss 3.4692(3.4951) | Error 0.0067(0.0042) Steps 1060(1057.92) | Grad Norm 1.1757(1.3870) | Total Time 14.00(14.00)\n",
      "Iter 21110 | Time 26.7198(26.3337) | Bit/dim 3.4762(3.4871) | Xent 0.0152(0.0146) | Loss 3.4838(3.4944) | Error 0.0044(0.0041) Steps 1048(1058.52) | Grad Norm 1.3729(1.3799) | Total Time 14.00(14.00)\n",
      "Iter 21120 | Time 26.3599(26.3379) | Bit/dim 3.4800(3.4875) | Xent 0.0270(0.0155) | Loss 3.4935(3.4953) | Error 0.0100(0.0045) Steps 1054(1058.02) | Grad Norm 1.5038(1.4092) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 121.2317, Epoch Time 1585.8462(1584.8047), Bit/dim 3.4953(best: 3.4926), Xent 2.5081, Loss 4.7494, Error 0.2806(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21130 | Time 27.0708(26.3525) | Bit/dim 3.5177(3.4902) | Xent 0.0194(0.0152) | Loss 3.5274(3.4978) | Error 0.0067(0.0042) Steps 1054(1056.77) | Grad Norm 1.4119(1.3654) | Total Time 14.00(14.00)\n",
      "Iter 21140 | Time 26.0065(26.4520) | Bit/dim 3.4987(3.4889) | Xent 0.0097(0.0148) | Loss 3.5035(3.4963) | Error 0.0022(0.0040) Steps 1054(1055.95) | Grad Norm 0.9388(1.3259) | Total Time 14.00(14.00)\n",
      "Iter 21150 | Time 26.3568(26.4403) | Bit/dim 3.4691(3.4891) | Xent 0.0093(0.0147) | Loss 3.4737(3.4964) | Error 0.0011(0.0040) Steps 1060(1056.79) | Grad Norm 1.2441(1.4044) | Total Time 14.00(14.00)\n",
      "Iter 21160 | Time 26.2104(26.4247) | Bit/dim 3.4665(3.4871) | Xent 0.0271(0.0154) | Loss 3.4800(3.4949) | Error 0.0067(0.0043) Steps 1066(1057.16) | Grad Norm 2.5379(1.4024) | Total Time 14.00(14.00)\n",
      "Iter 21170 | Time 26.8217(26.3689) | Bit/dim 3.4917(3.4873) | Xent 0.0113(0.0152) | Loss 3.4974(3.4949) | Error 0.0033(0.0043) Steps 1060(1057.29) | Grad Norm 1.4431(1.4006) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 121.1219, Epoch Time 1591.3741(1585.0018), Bit/dim 3.4935(best: 3.4926), Xent 2.5021, Loss 4.7446, Error 0.2793(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21180 | Time 26.3425(26.3618) | Bit/dim 3.5141(3.4893) | Xent 0.0122(0.0149) | Loss 3.5202(3.4967) | Error 0.0022(0.0041) Steps 1048(1056.51) | Grad Norm 1.0712(1.3963) | Total Time 14.00(14.00)\n",
      "Iter 21190 | Time 26.0567(26.3982) | Bit/dim 3.5040(3.4901) | Xent 0.0197(0.0151) | Loss 3.5139(3.4977) | Error 0.0067(0.0043) Steps 1060(1056.08) | Grad Norm 1.2340(1.4197) | Total Time 14.00(14.00)\n",
      "Iter 21200 | Time 26.6638(26.4236) | Bit/dim 3.4695(3.4871) | Xent 0.0156(0.0153) | Loss 3.4773(3.4948) | Error 0.0078(0.0045) Steps 1054(1056.57) | Grad Norm 1.3736(1.4952) | Total Time 14.00(14.00)\n",
      "Iter 21210 | Time 26.7357(26.4071) | Bit/dim 3.4700(3.4894) | Xent 0.0124(0.0144) | Loss 3.4762(3.4966) | Error 0.0011(0.0039) Steps 1078(1056.07) | Grad Norm 1.0600(1.3979) | Total Time 14.00(14.00)\n",
      "Iter 21220 | Time 26.7283(26.3691) | Bit/dim 3.4978(3.4907) | Xent 0.0139(0.0145) | Loss 3.5047(3.4979) | Error 0.0011(0.0040) Steps 1072(1057.45) | Grad Norm 1.0705(1.3469) | Total Time 14.00(14.00)\n",
      "Iter 21230 | Time 26.0993(26.3673) | Bit/dim 3.4832(3.4879) | Xent 0.0128(0.0143) | Loss 3.4896(3.4951) | Error 0.0033(0.0040) Steps 1060(1059.17) | Grad Norm 1.3581(1.3100) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 120.5838, Epoch Time 1590.3858(1585.1633), Bit/dim 3.4935(best: 3.4926), Xent 2.5214, Loss 4.7542, Error 0.2795(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21240 | Time 26.4187(26.3903) | Bit/dim 3.4888(3.4869) | Xent 0.0178(0.0144) | Loss 3.4977(3.4941) | Error 0.0033(0.0039) Steps 1048(1058.68) | Grad Norm 1.3011(1.3072) | Total Time 14.00(14.00)\n",
      "Iter 21250 | Time 25.6330(26.3819) | Bit/dim 3.4875(3.4879) | Xent 0.0137(0.0144) | Loss 3.4943(3.4951) | Error 0.0044(0.0039) Steps 1042(1058.59) | Grad Norm 1.7052(1.3302) | Total Time 14.00(14.00)\n",
      "Iter 21260 | Time 26.5257(26.4162) | Bit/dim 3.4628(3.4887) | Xent 0.0129(0.0144) | Loss 3.4692(3.4959) | Error 0.0033(0.0039) Steps 1060(1059.39) | Grad Norm 1.4224(1.4396) | Total Time 14.00(14.00)\n",
      "Iter 21270 | Time 26.4292(26.3845) | Bit/dim 3.5001(3.4884) | Xent 0.0118(0.0135) | Loss 3.5060(3.4952) | Error 0.0022(0.0034) Steps 1084(1058.36) | Grad Norm 1.3586(1.3365) | Total Time 14.00(14.00)\n",
      "Iter 21280 | Time 26.1062(26.3971) | Bit/dim 3.4799(3.4883) | Xent 0.0095(0.0133) | Loss 3.4846(3.4949) | Error 0.0011(0.0033) Steps 1048(1056.27) | Grad Norm 0.7643(1.3060) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 121.7563, Epoch Time 1592.3173(1585.3779), Bit/dim 3.4935(best: 3.4926), Xent 2.5751, Loss 4.7811, Error 0.2760(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21290 | Time 25.9784(26.3789) | Bit/dim 3.4819(3.4868) | Xent 0.0111(0.0136) | Loss 3.4874(3.4936) | Error 0.0022(0.0034) Steps 1066(1056.09) | Grad Norm 1.0946(1.3019) | Total Time 14.00(14.00)\n",
      "Iter 21300 | Time 26.0685(26.3687) | Bit/dim 3.5101(3.4871) | Xent 0.0120(0.0132) | Loss 3.5162(3.4937) | Error 0.0011(0.0033) Steps 1054(1055.15) | Grad Norm 1.6627(1.2983) | Total Time 14.00(14.00)\n",
      "Iter 21310 | Time 25.7387(26.3431) | Bit/dim 3.4579(3.4870) | Xent 0.0127(0.0130) | Loss 3.4642(3.4935) | Error 0.0033(0.0034) Steps 1048(1055.82) | Grad Norm 1.1546(1.2732) | Total Time 14.00(14.00)\n",
      "Iter 21320 | Time 26.0375(26.2893) | Bit/dim 3.4779(3.4862) | Xent 0.0170(0.0134) | Loss 3.4864(3.4929) | Error 0.0044(0.0034) Steps 1048(1055.58) | Grad Norm 1.4143(1.2777) | Total Time 14.00(14.00)\n",
      "Iter 21330 | Time 25.9218(26.2683) | Bit/dim 3.5151(3.4889) | Xent 0.0134(0.0131) | Loss 3.5218(3.4954) | Error 0.0033(0.0034) Steps 1036(1055.89) | Grad Norm 2.0489(1.2816) | Total Time 14.00(14.00)\n",
      "Iter 21340 | Time 26.0646(26.2411) | Bit/dim 3.4960(3.4890) | Xent 0.0143(0.0137) | Loss 3.5031(3.4959) | Error 0.0056(0.0036) Steps 1036(1055.63) | Grad Norm 1.1217(1.2888) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 121.7283, Epoch Time 1582.4374(1585.2897), Bit/dim 3.4935(best: 3.4926), Xent 2.5453, Loss 4.7662, Error 0.2771(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21350 | Time 26.6447(26.2359) | Bit/dim 3.5317(3.4897) | Xent 0.0106(0.0137) | Loss 3.5370(3.4965) | Error 0.0011(0.0037) Steps 1066(1055.34) | Grad Norm 1.7330(1.3478) | Total Time 14.00(14.00)\n",
      "Iter 21360 | Time 26.5508(26.2264) | Bit/dim 3.4977(3.4931) | Xent 0.0119(0.0137) | Loss 3.5037(3.5000) | Error 0.0033(0.0038) Steps 1078(1055.49) | Grad Norm 1.5109(1.3213) | Total Time 14.00(14.00)\n",
      "Iter 21370 | Time 26.3062(26.2728) | Bit/dim 3.4863(3.4903) | Xent 0.0154(0.0136) | Loss 3.4940(3.4971) | Error 0.0044(0.0038) Steps 1054(1056.22) | Grad Norm 1.1066(1.2993) | Total Time 14.00(14.00)\n",
      "Iter 21380 | Time 25.9412(26.3207) | Bit/dim 3.4528(3.4869) | Xent 0.0135(0.0138) | Loss 3.4595(3.4938) | Error 0.0022(0.0039) Steps 1036(1056.03) | Grad Norm 1.0917(1.2954) | Total Time 14.00(14.00)\n",
      "Iter 21390 | Time 25.7153(26.2691) | Bit/dim 3.4662(3.4857) | Xent 0.0215(0.0139) | Loss 3.4770(3.4926) | Error 0.0067(0.0040) Steps 1048(1054.82) | Grad Norm 1.7187(1.3014) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 121.3842, Epoch Time 1584.9615(1585.2799), Bit/dim 3.4934(best: 3.4926), Xent 2.5262, Loss 4.7565, Error 0.2785(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21400 | Time 25.7930(26.1968) | Bit/dim 3.5086(3.4888) | Xent 0.0128(0.0141) | Loss 3.5150(3.4959) | Error 0.0022(0.0039) Steps 1060(1053.67) | Grad Norm 1.6921(1.3606) | Total Time 14.00(14.00)\n",
      "Iter 21410 | Time 26.0184(26.1516) | Bit/dim 3.4930(3.4901) | Xent 0.0090(0.0135) | Loss 3.4975(3.4968) | Error 0.0000(0.0035) Steps 1030(1053.43) | Grad Norm 0.8897(1.3261) | Total Time 14.00(14.00)\n",
      "Iter 21420 | Time 26.2305(26.1655) | Bit/dim 3.4627(3.4895) | Xent 0.0125(0.0139) | Loss 3.4690(3.4965) | Error 0.0033(0.0040) Steps 1042(1054.89) | Grad Norm 1.1386(1.3261) | Total Time 14.00(14.00)\n",
      "Iter 21430 | Time 25.9418(26.1903) | Bit/dim 3.5392(3.4922) | Xent 0.0166(0.0141) | Loss 3.5474(3.4993) | Error 0.0056(0.0041) Steps 1066(1056.12) | Grad Norm 1.9236(1.3171) | Total Time 14.00(14.00)\n",
      "Iter 21440 | Time 26.4435(26.2056) | Bit/dim 3.4863(3.4849) | Xent 0.0168(0.0145) | Loss 3.4946(3.4921) | Error 0.0067(0.0043) Steps 1072(1055.72) | Grad Norm 1.4443(1.2998) | Total Time 14.00(14.00)\n",
      "Iter 21450 | Time 25.8139(26.2190) | Bit/dim 3.4553(3.4863) | Xent 0.0148(0.0143) | Loss 3.4627(3.4934) | Error 0.0033(0.0040) Steps 1054(1057.83) | Grad Norm 1.2510(1.2618) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 122.2450, Epoch Time 1579.7390(1585.1136), Bit/dim 3.4934(best: 3.4926), Xent 2.5167, Loss 4.7517, Error 0.2792(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21460 | Time 26.4380(26.1890) | Bit/dim 3.4702(3.4845) | Xent 0.0087(0.0141) | Loss 3.4746(3.4915) | Error 0.0000(0.0038) Steps 1054(1057.92) | Grad Norm 0.7941(1.2248) | Total Time 14.00(14.00)\n",
      "Iter 21470 | Time 26.6892(26.1364) | Bit/dim 3.4513(3.4874) | Xent 0.0150(0.0144) | Loss 3.4588(3.4946) | Error 0.0056(0.0039) Steps 1066(1058.95) | Grad Norm 1.0970(1.2169) | Total Time 14.00(14.00)\n",
      "Iter 21480 | Time 26.1990(26.1580) | Bit/dim 3.5111(3.4870) | Xent 0.0244(0.0150) | Loss 3.5233(3.4945) | Error 0.0078(0.0043) Steps 1036(1058.08) | Grad Norm 2.3045(1.3322) | Total Time 14.00(14.00)\n",
      "Iter 21490 | Time 25.8781(26.1577) | Bit/dim 3.5199(3.4883) | Xent 0.0112(0.0150) | Loss 3.5255(3.4958) | Error 0.0022(0.0042) Steps 1066(1056.82) | Grad Norm 1.0881(1.3530) | Total Time 14.00(14.00)\n",
      "Iter 21500 | Time 25.8801(26.2005) | Bit/dim 3.4827(3.4884) | Xent 0.0189(0.0150) | Loss 3.4922(3.4958) | Error 0.0033(0.0039) Steps 1048(1057.18) | Grad Norm 1.5796(1.2936) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 120.4649, Epoch Time 1578.7440(1584.9225), Bit/dim 3.4944(best: 3.4926), Xent 2.5204, Loss 4.7546, Error 0.2736(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21510 | Time 25.8349(26.2521) | Bit/dim 3.4756(3.4888) | Xent 0.0136(0.0145) | Loss 3.4824(3.4960) | Error 0.0033(0.0039) Steps 1036(1056.97) | Grad Norm 1.0376(1.2496) | Total Time 14.00(14.00)\n",
      "Iter 21520 | Time 26.3449(26.2392) | Bit/dim 3.5158(3.4877) | Xent 0.0202(0.0145) | Loss 3.5259(3.4949) | Error 0.0089(0.0040) Steps 1036(1055.67) | Grad Norm 1.8148(1.2979) | Total Time 14.00(14.00)\n",
      "Iter 21530 | Time 26.0290(26.2982) | Bit/dim 3.5068(3.4909) | Xent 0.0124(0.0140) | Loss 3.5130(3.4979) | Error 0.0022(0.0037) Steps 1060(1056.72) | Grad Norm 2.1960(1.4597) | Total Time 14.00(14.00)\n",
      "Iter 21540 | Time 26.2422(26.2840) | Bit/dim 3.4486(3.4893) | Xent 0.0180(0.0146) | Loss 3.4576(3.4966) | Error 0.0056(0.0040) Steps 1060(1055.92) | Grad Norm 2.0538(1.6561) | Total Time 14.00(14.00)\n",
      "Iter 21550 | Time 26.0256(26.3014) | Bit/dim 3.5439(3.4888) | Xent 0.0090(0.0143) | Loss 3.5484(3.4960) | Error 0.0022(0.0040) Steps 1048(1057.30) | Grad Norm 0.7735(1.6020) | Total Time 14.00(14.00)\n",
      "Iter 21560 | Time 27.3443(26.3140) | Bit/dim 3.4898(3.4862) | Xent 0.0181(0.0144) | Loss 3.4989(3.4935) | Error 0.0044(0.0040) Steps 1102(1057.61) | Grad Norm 1.5318(1.5807) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 121.2089, Epoch Time 1586.6778(1584.9752), Bit/dim 3.4930(best: 3.4926), Xent 2.5608, Loss 4.7734, Error 0.2832(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21570 | Time 26.6740(26.2606) | Bit/dim 3.4938(3.4869) | Xent 0.0147(0.0142) | Loss 3.5012(3.4940) | Error 0.0056(0.0040) Steps 1048(1057.71) | Grad Norm 1.8303(1.5636) | Total Time 14.00(14.00)\n",
      "Iter 21580 | Time 26.4317(26.2657) | Bit/dim 3.4887(3.4877) | Xent 0.0111(0.0144) | Loss 3.4943(3.4949) | Error 0.0033(0.0040) Steps 1072(1056.70) | Grad Norm 1.7428(1.6325) | Total Time 14.00(14.00)\n",
      "Iter 21590 | Time 25.5242(26.1980) | Bit/dim 3.4900(3.4888) | Xent 0.0138(0.0146) | Loss 3.4969(3.4961) | Error 0.0033(0.0042) Steps 1042(1054.80) | Grad Norm 1.8626(1.7682) | Total Time 14.00(14.00)\n",
      "Iter 21600 | Time 26.6280(26.1495) | Bit/dim 3.5056(3.4885) | Xent 0.0144(0.0141) | Loss 3.5128(3.4955) | Error 0.0044(0.0039) Steps 1048(1056.85) | Grad Norm 1.7626(1.7417) | Total Time 14.00(14.00)\n",
      "Iter 21610 | Time 25.9752(26.0941) | Bit/dim 3.4855(3.4891) | Xent 0.0137(0.0144) | Loss 3.4924(3.4963) | Error 0.0033(0.0039) Steps 1060(1056.50) | Grad Norm 1.1751(1.7575) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 120.9432, Epoch Time 1572.5316(1584.6019), Bit/dim 3.4940(best: 3.4926), Xent 2.5697, Loss 4.7788, Error 0.2789(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21620 | Time 24.9425(26.0744) | Bit/dim 3.4499(3.4867) | Xent 0.0102(0.0151) | Loss 3.4550(3.4943) | Error 0.0033(0.0042) Steps 1054(1055.65) | Grad Norm 1.0190(1.8146) | Total Time 14.00(14.00)\n",
      "Iter 21630 | Time 26.7841(26.1461) | Bit/dim 3.4917(3.4837) | Xent 0.0140(0.0147) | Loss 3.4988(3.4910) | Error 0.0056(0.0041) Steps 1048(1056.75) | Grad Norm 1.1643(1.6750) | Total Time 14.00(14.00)\n",
      "Iter 21640 | Time 26.3836(26.1861) | Bit/dim 3.4675(3.4849) | Xent 0.0161(0.0144) | Loss 3.4755(3.4922) | Error 0.0044(0.0039) Steps 1066(1055.83) | Grad Norm 1.1322(1.5432) | Total Time 14.00(14.00)\n",
      "Iter 21650 | Time 25.5995(26.1751) | Bit/dim 3.4809(3.4860) | Xent 0.0088(0.0143) | Loss 3.4853(3.4932) | Error 0.0022(0.0039) Steps 1042(1054.12) | Grad Norm 0.8148(1.4499) | Total Time 14.00(14.00)\n",
      "Iter 21660 | Time 26.2066(26.2156) | Bit/dim 3.5028(3.4886) | Xent 0.0211(0.0148) | Loss 3.5133(3.4960) | Error 0.0067(0.0042) Steps 1066(1056.96) | Grad Norm 2.0868(1.4935) | Total Time 14.00(14.00)\n",
      "Iter 21670 | Time 25.8868(26.2274) | Bit/dim 3.4894(3.4901) | Xent 0.0110(0.0148) | Loss 3.4949(3.4975) | Error 0.0011(0.0041) Steps 1060(1057.54) | Grad Norm 1.8308(1.5356) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 120.8631, Epoch Time 1582.2371(1584.5309), Bit/dim 3.4938(best: 3.4926), Xent 2.5557, Loss 4.7716, Error 0.2791(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21680 | Time 25.3772(26.1437) | Bit/dim 3.4927(3.4879) | Xent 0.0112(0.0144) | Loss 3.4983(3.4951) | Error 0.0011(0.0040) Steps 1054(1054.43) | Grad Norm 1.0022(1.4962) | Total Time 14.00(14.00)\n",
      "Iter 21690 | Time 25.8890(26.1272) | Bit/dim 3.4911(3.4884) | Xent 0.0133(0.0142) | Loss 3.4977(3.4956) | Error 0.0044(0.0040) Steps 1042(1053.90) | Grad Norm 1.4686(1.4601) | Total Time 14.00(14.00)\n",
      "Iter 21700 | Time 25.2395(26.1384) | Bit/dim 3.5159(3.4889) | Xent 0.0111(0.0142) | Loss 3.5215(3.4960) | Error 0.0011(0.0039) Steps 1060(1053.61) | Grad Norm 1.1183(1.3753) | Total Time 14.00(14.00)\n",
      "Iter 21710 | Time 25.9879(26.0516) | Bit/dim 3.4892(3.4886) | Xent 0.0109(0.0138) | Loss 3.4946(3.4955) | Error 0.0033(0.0037) Steps 1036(1052.98) | Grad Norm 1.3162(1.3469) | Total Time 14.00(14.00)\n",
      "Iter 21720 | Time 26.4605(26.1356) | Bit/dim 3.4786(3.4911) | Xent 0.0117(0.0138) | Loss 3.4844(3.4980) | Error 0.0033(0.0036) Steps 1054(1052.54) | Grad Norm 0.9605(1.3303) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 120.5154, Epoch Time 1574.0058(1584.2152), Bit/dim 3.4928(best: 3.4926), Xent 2.5813, Loss 4.7834, Error 0.2784(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21730 | Time 26.0903(26.1444) | Bit/dim 3.4928(3.4894) | Xent 0.0131(0.0133) | Loss 3.4994(3.4960) | Error 0.0033(0.0034) Steps 1042(1053.90) | Grad Norm 1.0879(1.2648) | Total Time 14.00(14.00)\n",
      "Iter 21740 | Time 26.3025(26.2080) | Bit/dim 3.5339(3.4890) | Xent 0.0146(0.0137) | Loss 3.5412(3.4959) | Error 0.0033(0.0037) Steps 1054(1055.64) | Grad Norm 1.5761(1.2376) | Total Time 14.00(14.00)\n",
      "Iter 21750 | Time 26.4503(26.2157) | Bit/dim 3.4665(3.4857) | Xent 0.0289(0.0150) | Loss 3.4810(3.4932) | Error 0.0122(0.0045) Steps 1066(1056.02) | Grad Norm 2.9432(1.3878) | Total Time 14.00(14.00)\n",
      "Iter 21760 | Time 25.8094(26.1471) | Bit/dim 3.5049(3.4863) | Xent 0.0158(0.0149) | Loss 3.5128(3.4938) | Error 0.0056(0.0044) Steps 1066(1055.11) | Grad Norm 1.9193(1.5463) | Total Time 14.00(14.00)\n",
      "Iter 21770 | Time 25.9746(26.1852) | Bit/dim 3.4771(3.4883) | Xent 0.0117(0.0138) | Loss 3.4830(3.4952) | Error 0.0011(0.0038) Steps 1042(1056.35) | Grad Norm 0.9171(1.5272) | Total Time 14.00(14.00)\n",
      "Iter 21780 | Time 26.3040(26.1660) | Bit/dim 3.5090(3.4888) | Xent 0.0121(0.0141) | Loss 3.5150(3.4958) | Error 0.0022(0.0041) Steps 1054(1056.34) | Grad Norm 1.1159(1.4808) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 121.8565, Epoch Time 1580.0020(1584.0888), Bit/dim 3.4916(best: 3.4926), Xent 2.5356, Loss 4.7595, Error 0.2782(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21790 | Time 25.9154(26.2356) | Bit/dim 3.4855(3.4890) | Xent 0.0107(0.0139) | Loss 3.4908(3.4959) | Error 0.0033(0.0042) Steps 1066(1056.89) | Grad Norm 1.1598(1.4330) | Total Time 14.00(14.00)\n",
      "Iter 21800 | Time 26.5974(26.2484) | Bit/dim 3.5147(3.4938) | Xent 0.0090(0.0135) | Loss 3.5192(3.5005) | Error 0.0011(0.0038) Steps 1060(1057.01) | Grad Norm 0.8913(1.3864) | Total Time 14.00(14.00)\n",
      "Iter 21810 | Time 26.6318(26.2336) | Bit/dim 3.4737(3.4904) | Xent 0.0126(0.0135) | Loss 3.4800(3.4971) | Error 0.0033(0.0040) Steps 1060(1056.46) | Grad Norm 1.2864(1.3483) | Total Time 14.00(14.00)\n",
      "Iter 21820 | Time 25.6907(26.2546) | Bit/dim 3.4930(3.4878) | Xent 0.0187(0.0140) | Loss 3.5024(3.4948) | Error 0.0044(0.0041) Steps 1048(1056.93) | Grad Norm 1.4103(1.3136) | Total Time 14.00(14.00)\n",
      "Iter 21830 | Time 25.4061(26.2181) | Bit/dim 3.5061(3.4871) | Xent 0.0098(0.0135) | Loss 3.5110(3.4939) | Error 0.0022(0.0037) Steps 1060(1056.81) | Grad Norm 0.9561(1.2828) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 121.3875, Epoch Time 1584.9874(1584.1158), Bit/dim 3.4917(best: 3.4916), Xent 2.5803, Loss 4.7818, Error 0.2771(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21840 | Time 26.4142(26.2748) | Bit/dim 3.4970(3.4855) | Xent 0.0088(0.0133) | Loss 3.5014(3.4922) | Error 0.0011(0.0035) Steps 1042(1055.48) | Grad Norm 1.0848(1.2958) | Total Time 14.00(14.00)\n",
      "Iter 21850 | Time 26.2043(26.2843) | Bit/dim 3.4923(3.4879) | Xent 0.0159(0.0135) | Loss 3.5002(3.4946) | Error 0.0056(0.0037) Steps 1072(1056.55) | Grad Norm 1.1984(1.2621) | Total Time 14.00(14.00)\n",
      "Iter 21860 | Time 26.1148(26.3171) | Bit/dim 3.4710(3.4861) | Xent 0.0103(0.0136) | Loss 3.4761(3.4929) | Error 0.0011(0.0036) Steps 1054(1057.22) | Grad Norm 0.9499(1.2593) | Total Time 14.00(14.00)\n",
      "Iter 21870 | Time 26.7173(26.3624) | Bit/dim 3.4824(3.4868) | Xent 0.0142(0.0134) | Loss 3.4895(3.4935) | Error 0.0067(0.0036) Steps 1030(1056.81) | Grad Norm 1.6945(1.2621) | Total Time 14.00(14.00)\n",
      "Iter 21880 | Time 25.9773(26.3857) | Bit/dim 3.4692(3.4865) | Xent 0.0128(0.0140) | Loss 3.4756(3.4935) | Error 0.0033(0.0040) Steps 1060(1058.66) | Grad Norm 1.4052(1.3503) | Total Time 14.00(14.00)\n",
      "Iter 21890 | Time 27.3544(26.4766) | Bit/dim 3.4648(3.4850) | Xent 0.0133(0.0139) | Loss 3.4714(3.4919) | Error 0.0044(0.0040) Steps 1048(1058.19) | Grad Norm 1.2060(1.3199) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 121.6653, Epoch Time 1595.5253(1584.4580), Bit/dim 3.4928(best: 3.4916), Xent 2.5503, Loss 4.7679, Error 0.2777(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21900 | Time 26.7556(26.3973) | Bit/dim 3.4662(3.4831) | Xent 0.0123(0.0141) | Loss 3.4724(3.4902) | Error 0.0033(0.0042) Steps 1060(1058.09) | Grad Norm 1.7464(1.3824) | Total Time 14.00(14.00)\n",
      "Iter 21910 | Time 26.3361(26.3431) | Bit/dim 3.5347(3.4866) | Xent 0.0123(0.0142) | Loss 3.5408(3.4937) | Error 0.0022(0.0042) Steps 1048(1056.13) | Grad Norm 1.0014(1.3846) | Total Time 14.00(14.00)\n",
      "Iter 21920 | Time 26.8688(26.3216) | Bit/dim 3.4497(3.4865) | Xent 0.0107(0.0139) | Loss 3.4551(3.4934) | Error 0.0033(0.0040) Steps 1072(1058.27) | Grad Norm 1.3969(1.3769) | Total Time 14.00(14.00)\n",
      "Iter 21930 | Time 26.4506(26.3566) | Bit/dim 3.5047(3.4868) | Xent 0.0105(0.0133) | Loss 3.5100(3.4934) | Error 0.0033(0.0036) Steps 1036(1057.19) | Grad Norm 0.9484(1.3429) | Total Time 14.00(14.00)\n",
      "Iter 21940 | Time 25.5628(26.2735) | Bit/dim 3.4788(3.4859) | Xent 0.0178(0.0135) | Loss 3.4877(3.4926) | Error 0.0067(0.0037) Steps 1060(1057.15) | Grad Norm 3.2492(1.3948) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 121.3603, Epoch Time 1582.2612(1584.3921), Bit/dim 3.4927(best: 3.4916), Xent 2.6145, Loss 4.8000, Error 0.2793(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21950 | Time 26.2028(26.2897) | Bit/dim 3.4898(3.4882) | Xent 0.0226(0.0140) | Loss 3.5011(3.4952) | Error 0.0056(0.0036) Steps 1054(1058.63) | Grad Norm 2.3785(1.5077) | Total Time 14.00(14.00)\n",
      "Iter 21960 | Time 26.0757(26.3136) | Bit/dim 3.5083(3.4903) | Xent 0.0121(0.0135) | Loss 3.5144(3.4971) | Error 0.0022(0.0035) Steps 1066(1058.62) | Grad Norm 1.0102(1.4481) | Total Time 14.00(14.00)\n",
      "Iter 21970 | Time 25.9554(26.2849) | Bit/dim 3.4831(3.4886) | Xent 0.0242(0.0139) | Loss 3.4952(3.4956) | Error 0.0089(0.0038) Steps 1048(1058.17) | Grad Norm 2.6058(1.4698) | Total Time 14.00(14.00)\n",
      "Iter 21980 | Time 26.1291(26.2273) | Bit/dim 3.4771(3.4857) | Xent 0.0192(0.0143) | Loss 3.4867(3.4928) | Error 0.0078(0.0041) Steps 1072(1056.55) | Grad Norm 2.1363(1.5158) | Total Time 14.00(14.00)\n",
      "Iter 21990 | Time 26.8426(26.1712) | Bit/dim 3.4855(3.4875) | Xent 0.0093(0.0144) | Loss 3.4901(3.4947) | Error 0.0033(0.0042) Steps 1078(1057.76) | Grad Norm 0.8020(1.4811) | Total Time 14.00(14.00)\n",
      "Iter 22000 | Time 25.9841(26.1765) | Bit/dim 3.5039(3.4856) | Xent 0.0146(0.0148) | Loss 3.5112(3.4930) | Error 0.0033(0.0042) Steps 1054(1057.29) | Grad Norm 2.0069(1.5064) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 121.5109, Epoch Time 1578.6143(1584.2188), Bit/dim 3.4931(best: 3.4916), Xent 2.5920, Loss 4.7891, Error 0.2796(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22010 | Time 26.2126(26.1638) | Bit/dim 3.5052(3.4867) | Xent 0.0163(0.0152) | Loss 3.5133(3.4943) | Error 0.0044(0.0042) Steps 1060(1057.00) | Grad Norm 1.4993(1.5012) | Total Time 14.00(14.00)\n",
      "Iter 22020 | Time 25.8797(26.1874) | Bit/dim 3.4836(3.4884) | Xent 0.0146(0.0155) | Loss 3.4909(3.4962) | Error 0.0067(0.0044) Steps 1036(1056.85) | Grad Norm 2.1220(1.5772) | Total Time 14.00(14.00)\n",
      "Iter 22030 | Time 26.2787(26.2199) | Bit/dim 3.4793(3.4898) | Xent 0.0073(0.0153) | Loss 3.4830(3.4975) | Error 0.0000(0.0043) Steps 1066(1059.11) | Grad Norm 1.0860(1.4970) | Total Time 14.00(14.00)\n",
      "Iter 22040 | Time 26.8291(26.2298) | Bit/dim 3.4949(3.4894) | Xent 0.0151(0.0145) | Loss 3.5024(3.4967) | Error 0.0078(0.0041) Steps 1078(1059.54) | Grad Norm 1.2957(1.4254) | Total Time 14.00(14.00)\n",
      "Iter 22050 | Time 26.4762(26.2206) | Bit/dim 3.4671(3.4873) | Xent 0.0155(0.0144) | Loss 3.4748(3.4945) | Error 0.0033(0.0040) Steps 1054(1060.18) | Grad Norm 2.0844(1.4579) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 120.7536, Epoch Time 1581.6377(1584.1414), Bit/dim 3.4937(best: 3.4916), Xent 2.5768, Loss 4.7821, Error 0.2791(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22060 | Time 26.5926(26.2434) | Bit/dim 3.5223(3.4860) | Xent 0.0146(0.0139) | Loss 3.5296(3.4930) | Error 0.0044(0.0038) Steps 1060(1058.00) | Grad Norm 1.9345(1.4794) | Total Time 14.00(14.00)\n",
      "Iter 22070 | Time 26.5987(26.4347) | Bit/dim 3.4983(3.4856) | Xent 0.0151(0.0138) | Loss 3.5059(3.4925) | Error 0.0033(0.0037) Steps 1048(1057.78) | Grad Norm 1.3767(1.4374) | Total Time 14.00(14.00)\n",
      "Iter 22080 | Time 26.9359(26.4801) | Bit/dim 3.4882(3.4865) | Xent 0.0170(0.0144) | Loss 3.4967(3.4938) | Error 0.0033(0.0038) Steps 1048(1057.55) | Grad Norm 1.5522(1.4794) | Total Time 14.00(14.00)\n",
      "Iter 22090 | Time 26.8357(26.5800) | Bit/dim 3.4847(3.4845) | Xent 0.0154(0.0142) | Loss 3.4924(3.4916) | Error 0.0033(0.0035) Steps 1060(1056.39) | Grad Norm 1.3546(1.4198) | Total Time 14.00(14.00)\n",
      "Iter 22100 | Time 26.5962(26.5466) | Bit/dim 3.4772(3.4866) | Xent 0.0151(0.0151) | Loss 3.4848(3.4941) | Error 0.0022(0.0042) Steps 1072(1055.98) | Grad Norm 1.7136(1.5005) | Total Time 14.00(14.00)\n",
      "Iter 22110 | Time 26.6459(26.5121) | Bit/dim 3.5142(3.4865) | Xent 0.0153(0.0147) | Loss 3.5219(3.4938) | Error 0.0033(0.0041) Steps 1072(1055.41) | Grad Norm 2.5491(1.5203) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 122.8650, Epoch Time 1605.3238(1584.7768), Bit/dim 3.4927(best: 3.4916), Xent 2.6405, Loss 4.8130, Error 0.2814(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22120 | Time 26.3705(26.4493) | Bit/dim 3.4902(3.4881) | Xent 0.0158(0.0145) | Loss 3.4982(3.4954) | Error 0.0044(0.0042) Steps 1084(1057.96) | Grad Norm 1.5816(1.4987) | Total Time 14.00(14.00)\n",
      "Iter 22130 | Time 26.6004(26.4610) | Bit/dim 3.4828(3.4857) | Xent 0.0141(0.0138) | Loss 3.4899(3.4926) | Error 0.0011(0.0037) Steps 1084(1060.21) | Grad Norm 1.1013(1.3705) | Total Time 14.00(14.00)\n",
      "Iter 22140 | Time 25.9536(26.3742) | Bit/dim 3.4915(3.4855) | Xent 0.0176(0.0138) | Loss 3.5003(3.4924) | Error 0.0056(0.0039) Steps 1048(1058.86) | Grad Norm 1.7106(1.3608) | Total Time 14.00(14.00)\n",
      "Iter 22150 | Time 26.1155(26.3597) | Bit/dim 3.4731(3.4844) | Xent 0.0191(0.0140) | Loss 3.4827(3.4914) | Error 0.0089(0.0040) Steps 1060(1057.70) | Grad Norm 1.8960(1.4259) | Total Time 14.00(14.00)\n",
      "Iter 22160 | Time 26.3502(26.3219) | Bit/dim 3.5005(3.4868) | Xent 0.0107(0.0136) | Loss 3.5058(3.4935) | Error 0.0022(0.0038) Steps 1036(1058.46) | Grad Norm 1.1706(1.3528) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 121.2730, Epoch Time 1586.3211(1584.8232), Bit/dim 3.4915(best: 3.4916), Xent 2.5809, Loss 4.7820, Error 0.2760(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22170 | Time 27.1469(26.3566) | Bit/dim 3.4810(3.4871) | Xent 0.0118(0.0133) | Loss 3.4869(3.4937) | Error 0.0033(0.0036) Steps 1054(1057.44) | Grad Norm 0.9962(1.2830) | Total Time 14.00(14.00)\n",
      "Iter 22180 | Time 25.6342(26.2755) | Bit/dim 3.4726(3.4834) | Xent 0.0131(0.0139) | Loss 3.4791(3.4904) | Error 0.0044(0.0039) Steps 1048(1055.70) | Grad Norm 1.3802(1.2588) | Total Time 14.00(14.00)\n",
      "Iter 22190 | Time 26.9455(26.3515) | Bit/dim 3.4669(3.4847) | Xent 0.0179(0.0134) | Loss 3.4759(3.4914) | Error 0.0056(0.0036) Steps 1054(1057.43) | Grad Norm 1.2159(1.2385) | Total Time 14.00(14.00)\n",
      "Iter 22200 | Time 26.1589(26.3231) | Bit/dim 3.5080(3.4874) | Xent 0.0118(0.0132) | Loss 3.5139(3.4940) | Error 0.0033(0.0035) Steps 1054(1056.38) | Grad Norm 2.0622(1.2531) | Total Time 14.00(14.00)\n",
      "Iter 22210 | Time 25.7646(26.3147) | Bit/dim 3.4857(3.4862) | Xent 0.0169(0.0138) | Loss 3.4942(3.4931) | Error 0.0044(0.0038) Steps 1054(1057.15) | Grad Norm 1.3355(1.2496) | Total Time 14.00(14.00)\n",
      "Iter 22220 | Time 26.2823(26.3208) | Bit/dim 3.4782(3.4876) | Xent 0.0105(0.0134) | Loss 3.4835(3.4943) | Error 0.0011(0.0036) Steps 1072(1058.19) | Grad Norm 1.0813(1.2512) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 121.4822, Epoch Time 1586.7170(1584.8800), Bit/dim 3.4911(best: 3.4915), Xent 2.5635, Loss 4.7729, Error 0.2774(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22230 | Time 27.2875(26.3569) | Bit/dim 3.5131(3.4856) | Xent 0.0087(0.0129) | Loss 3.5175(3.4921) | Error 0.0011(0.0034) Steps 1060(1055.97) | Grad Norm 1.0559(1.1917) | Total Time 14.00(14.00)\n",
      "Iter 22240 | Time 26.3208(26.4064) | Bit/dim 3.4998(3.4838) | Xent 0.0077(0.0129) | Loss 3.5036(3.4902) | Error 0.0011(0.0034) Steps 1048(1057.31) | Grad Norm 0.8590(1.2006) | Total Time 14.00(14.00)\n",
      "Iter 22250 | Time 25.6083(26.2718) | Bit/dim 3.4729(3.4862) | Xent 0.0151(0.0133) | Loss 3.4804(3.4928) | Error 0.0067(0.0037) Steps 1042(1057.21) | Grad Norm 1.2731(1.3015) | Total Time 14.00(14.00)\n",
      "Iter 22260 | Time 26.3038(26.3314) | Bit/dim 3.4786(3.4863) | Xent 0.0065(0.0127) | Loss 3.4818(3.4927) | Error 0.0000(0.0035) Steps 1060(1058.57) | Grad Norm 0.7301(1.3061) | Total Time 14.00(14.00)\n",
      "Iter 22270 | Time 26.0599(26.3250) | Bit/dim 3.4729(3.4869) | Xent 0.0104(0.0130) | Loss 3.4781(3.4934) | Error 0.0022(0.0035) Steps 1060(1058.89) | Grad Norm 1.0907(1.3373) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 121.4670, Epoch Time 1588.8881(1585.0002), Bit/dim 3.4913(best: 3.4911), Xent 2.5945, Loss 4.7886, Error 0.2757(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22280 | Time 27.2979(26.3548) | Bit/dim 3.4633(3.4865) | Xent 0.0114(0.0134) | Loss 3.4690(3.4932) | Error 0.0033(0.0037) Steps 1060(1059.33) | Grad Norm 0.9776(1.3788) | Total Time 14.00(14.00)\n",
      "Iter 22290 | Time 27.4693(26.4392) | Bit/dim 3.4967(3.4876) | Xent 0.0185(0.0136) | Loss 3.5060(3.4944) | Error 0.0067(0.0038) Steps 1042(1057.73) | Grad Norm 3.6317(1.4844) | Total Time 14.00(14.00)\n",
      "Iter 22300 | Time 25.5762(26.3171) | Bit/dim 3.4555(3.4843) | Xent 0.0148(0.0140) | Loss 3.4629(3.4913) | Error 0.0022(0.0038) Steps 1066(1056.55) | Grad Norm 2.9810(1.6534) | Total Time 14.00(14.00)\n",
      "Iter 22310 | Time 26.7286(26.2322) | Bit/dim 3.4749(3.4864) | Xent 0.0091(0.0147) | Loss 3.4794(3.4938) | Error 0.0011(0.0040) Steps 1066(1056.05) | Grad Norm 1.2031(1.7606) | Total Time 14.00(14.00)\n",
      "Iter 22320 | Time 26.1819(26.2330) | Bit/dim 3.4390(3.4859) | Xent 0.0191(0.0145) | Loss 3.4486(3.4931) | Error 0.0056(0.0038) Steps 1066(1056.85) | Grad Norm 1.5194(1.7038) | Total Time 14.00(14.00)\n",
      "Iter 22330 | Time 25.8948(26.1177) | Bit/dim 3.4848(3.4868) | Xent 0.0162(0.0141) | Loss 3.4929(3.4939) | Error 0.0044(0.0038) Steps 1066(1056.94) | Grad Norm 1.1439(1.5755) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 121.7966, Epoch Time 1578.2103(1584.7965), Bit/dim 3.4918(best: 3.4911), Xent 2.6051, Loss 4.7943, Error 0.2779(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22340 | Time 25.8847(26.0822) | Bit/dim 3.4721(3.4823) | Xent 0.0170(0.0143) | Loss 3.4806(3.4894) | Error 0.0067(0.0039) Steps 1042(1056.18) | Grad Norm 1.3808(1.5191) | Total Time 14.00(14.00)\n",
      "Iter 22350 | Time 26.3658(26.1841) | Bit/dim 3.4629(3.4826) | Xent 0.0111(0.0140) | Loss 3.4684(3.4896) | Error 0.0022(0.0039) Steps 1048(1057.02) | Grad Norm 1.0381(1.4791) | Total Time 14.00(14.00)\n",
      "Iter 22360 | Time 25.6422(26.1359) | Bit/dim 3.5107(3.4843) | Xent 0.0160(0.0137) | Loss 3.5187(3.4912) | Error 0.0056(0.0036) Steps 1054(1056.67) | Grad Norm 1.1028(1.4124) | Total Time 14.00(14.00)\n",
      "Iter 22370 | Time 25.6753(26.1153) | Bit/dim 3.5021(3.4879) | Xent 0.0135(0.0137) | Loss 3.5088(3.4948) | Error 0.0044(0.0037) Steps 1048(1057.08) | Grad Norm 1.5092(1.4316) | Total Time 14.00(14.00)\n",
      "Iter 22380 | Time 26.3372(26.1325) | Bit/dim 3.5017(3.4880) | Xent 0.0120(0.0138) | Loss 3.5077(3.4949) | Error 0.0033(0.0038) Steps 1036(1055.31) | Grad Norm 0.9436(1.3799) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 122.3098, Epoch Time 1578.3655(1584.6036), Bit/dim 3.4907(best: 3.4911), Xent 2.5927, Loss 4.7870, Error 0.2805(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22390 | Time 25.8684(26.1262) | Bit/dim 3.4458(3.4857) | Xent 0.0123(0.0138) | Loss 3.4519(3.4926) | Error 0.0033(0.0040) Steps 1066(1056.84) | Grad Norm 1.2028(1.3499) | Total Time 14.00(14.00)\n",
      "Iter 22400 | Time 25.6111(26.1084) | Bit/dim 3.5096(3.4862) | Xent 0.0194(0.0139) | Loss 3.5193(3.4931) | Error 0.0067(0.0042) Steps 1060(1058.31) | Grad Norm 1.6978(1.3305) | Total Time 14.00(14.00)\n",
      "Iter 22410 | Time 26.2301(26.1625) | Bit/dim 3.5124(3.4863) | Xent 0.0179(0.0139) | Loss 3.5213(3.4932) | Error 0.0044(0.0042) Steps 1066(1057.00) | Grad Norm 1.8760(1.3943) | Total Time 14.00(14.00)\n",
      "Iter 22420 | Time 26.9677(26.2480) | Bit/dim 3.4543(3.4876) | Xent 0.0172(0.0136) | Loss 3.4629(3.4944) | Error 0.0044(0.0039) Steps 1048(1055.61) | Grad Norm 1.5437(1.3863) | Total Time 14.00(14.00)\n",
      "Iter 22430 | Time 25.8996(26.2900) | Bit/dim 3.4797(3.4901) | Xent 0.0173(0.0138) | Loss 3.4883(3.4970) | Error 0.0067(0.0041) Steps 1042(1055.78) | Grad Norm 1.2579(1.3826) | Total Time 14.00(14.00)\n",
      "Iter 22440 | Time 26.2477(26.3595) | Bit/dim 3.4486(3.4858) | Xent 0.0245(0.0138) | Loss 3.4609(3.4927) | Error 0.0078(0.0040) Steps 1048(1056.97) | Grad Norm 3.7338(1.4853) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 122.7143, Epoch Time 1588.4383(1584.7186), Bit/dim 3.4923(best: 3.4907), Xent 2.6240, Loss 4.8043, Error 0.2781(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22450 | Time 26.1890(26.3718) | Bit/dim 3.5260(3.4876) | Xent 0.0092(0.0139) | Loss 3.5306(3.4945) | Error 0.0011(0.0040) Steps 1060(1058.75) | Grad Norm 1.0527(1.4678) | Total Time 14.00(14.00)\n",
      "Iter 22460 | Time 26.3665(26.4229) | Bit/dim 3.4802(3.4854) | Xent 0.0181(0.0138) | Loss 3.4893(3.4923) | Error 0.0044(0.0040) Steps 1042(1058.09) | Grad Norm 3.3147(1.5011) | Total Time 14.00(14.00)\n",
      "Iter 22470 | Time 26.1142(26.4530) | Bit/dim 3.4775(3.4872) | Xent 0.0149(0.0142) | Loss 3.4850(3.4943) | Error 0.0044(0.0040) Steps 1054(1058.51) | Grad Norm 1.5765(1.5484) | Total Time 14.00(14.00)\n",
      "Iter 22480 | Time 26.6021(26.4544) | Bit/dim 3.4908(3.4867) | Xent 0.0097(0.0141) | Loss 3.4957(3.4937) | Error 0.0022(0.0039) Steps 1054(1058.55) | Grad Norm 1.2452(1.4816) | Total Time 14.00(14.00)\n",
      "Iter 22490 | Time 26.1972(26.4946) | Bit/dim 3.4901(3.4863) | Xent 0.0197(0.0139) | Loss 3.5000(3.4932) | Error 0.0056(0.0038) Steps 1066(1058.57) | Grad Norm 2.0359(1.4164) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 120.9602, Epoch Time 1597.3718(1585.0982), Bit/dim 3.4915(best: 3.4907), Xent 2.6151, Loss 4.7991, Error 0.2762(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22500 | Time 26.4236(26.4469) | Bit/dim 3.4805(3.4861) | Xent 0.0174(0.0141) | Loss 3.4892(3.4931) | Error 0.0067(0.0042) Steps 1072(1059.62) | Grad Norm 1.4669(1.3812) | Total Time 14.00(14.00)\n",
      "Iter 22510 | Time 26.2679(26.3481) | Bit/dim 3.4858(3.4867) | Xent 0.0157(0.0137) | Loss 3.4937(3.4936) | Error 0.0033(0.0039) Steps 1054(1059.34) | Grad Norm 1.1632(1.2885) | Total Time 14.00(14.00)\n",
      "Iter 22520 | Time 25.8342(26.3468) | Bit/dim 3.4829(3.4870) | Xent 0.0248(0.0143) | Loss 3.4953(3.4941) | Error 0.0067(0.0041) Steps 1024(1056.88) | Grad Norm 1.6587(1.3538) | Total Time 14.00(14.00)\n",
      "Iter 22530 | Time 26.1294(26.2883) | Bit/dim 3.4593(3.4833) | Xent 0.0120(0.0141) | Loss 3.4653(3.4904) | Error 0.0022(0.0041) Steps 1048(1055.82) | Grad Norm 1.5299(1.3800) | Total Time 14.00(14.00)\n",
      "Iter 22540 | Time 26.1664(26.2569) | Bit/dim 3.5032(3.4845) | Xent 0.0225(0.0146) | Loss 3.5144(3.4918) | Error 0.0067(0.0042) Steps 1048(1056.59) | Grad Norm 1.7860(1.3918) | Total Time 14.00(14.00)\n",
      "Iter 22550 | Time 26.5192(26.2627) | Bit/dim 3.4928(3.4867) | Xent 0.0144(0.0148) | Loss 3.5000(3.4941) | Error 0.0056(0.0044) Steps 1048(1057.03) | Grad Norm 1.2189(1.3816) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 121.9428, Epoch Time 1580.5780(1584.9626), Bit/dim 3.4915(best: 3.4907), Xent 2.6581, Loss 4.8205, Error 0.2778(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22560 | Time 25.4855(26.2746) | Bit/dim 3.4677(3.4869) | Xent 0.0189(0.0143) | Loss 3.4771(3.4940) | Error 0.0067(0.0040) Steps 1054(1059.21) | Grad Norm 1.4379(1.3529) | Total Time 14.00(14.00)\n",
      "Iter 22570 | Time 27.5184(26.3339) | Bit/dim 3.4568(3.4867) | Xent 0.0162(0.0140) | Loss 3.4649(3.4937) | Error 0.0011(0.0038) Steps 1036(1057.27) | Grad Norm 1.2257(1.3261) | Total Time 14.00(14.00)\n",
      "Iter 22580 | Time 25.8590(26.3653) | Bit/dim 3.4982(3.4865) | Xent 0.0120(0.0138) | Loss 3.5042(3.4934) | Error 0.0044(0.0039) Steps 1054(1057.81) | Grad Norm 1.0117(1.3256) | Total Time 14.00(14.00)\n",
      "Iter 22590 | Time 25.7113(26.2972) | Bit/dim 3.4774(3.4831) | Xent 0.0175(0.0136) | Loss 3.4861(3.4899) | Error 0.0056(0.0036) Steps 1078(1057.96) | Grad Norm 1.5388(1.3078) | Total Time 14.00(14.00)\n",
      "Iter 22600 | Time 26.4717(26.3301) | Bit/dim 3.4884(3.4858) | Xent 0.0121(0.0139) | Loss 3.4944(3.4927) | Error 0.0033(0.0039) Steps 1048(1057.04) | Grad Norm 1.4397(1.3401) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 120.4746, Epoch Time 1588.1952(1585.0596), Bit/dim 3.4933(best: 3.4907), Xent 2.6573, Loss 4.8219, Error 0.2770(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22610 | Time 26.4828(26.2883) | Bit/dim 3.5108(3.4888) | Xent 0.0198(0.0147) | Loss 3.5207(3.4961) | Error 0.0100(0.0045) Steps 1072(1056.90) | Grad Norm 1.7457(1.4127) | Total Time 14.00(14.00)\n",
      "Iter 22620 | Time 26.3759(26.3520) | Bit/dim 3.5006(3.4877) | Xent 0.0101(0.0143) | Loss 3.5057(3.4949) | Error 0.0000(0.0044) Steps 1060(1060.63) | Grad Norm 1.3367(1.4013) | Total Time 14.00(14.00)\n",
      "Iter 22630 | Time 26.7432(26.3201) | Bit/dim 3.4599(3.4879) | Xent 0.0121(0.0142) | Loss 3.4659(3.4950) | Error 0.0033(0.0044) Steps 1066(1059.54) | Grad Norm 1.2615(1.3923) | Total Time 14.00(14.00)\n",
      "Iter 22640 | Time 25.8553(26.2409) | Bit/dim 3.4667(3.4867) | Xent 0.0098(0.0143) | Loss 3.4716(3.4938) | Error 0.0000(0.0043) Steps 1042(1059.93) | Grad Norm 1.2278(1.3800) | Total Time 14.00(14.00)\n",
      "Iter 22650 | Time 25.7427(26.1748) | Bit/dim 3.4737(3.4862) | Xent 0.0161(0.0147) | Loss 3.4818(3.4935) | Error 0.0022(0.0041) Steps 1066(1057.95) | Grad Norm 1.2567(1.4465) | Total Time 14.00(14.00)\n",
      "Iter 22660 | Time 26.3733(26.1711) | Bit/dim 3.4821(3.4838) | Xent 0.0122(0.0146) | Loss 3.4882(3.4911) | Error 0.0022(0.0040) Steps 1042(1056.91) | Grad Norm 1.2935(1.4556) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 120.9452, Epoch Time 1578.0158(1584.8483), Bit/dim 3.4910(best: 3.4907), Xent 2.6273, Loss 4.8046, Error 0.2784(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22670 | Time 25.9709(26.1862) | Bit/dim 3.4761(3.4825) | Xent 0.0142(0.0141) | Loss 3.4832(3.4895) | Error 0.0044(0.0039) Steps 1054(1057.68) | Grad Norm 1.9526(1.4300) | Total Time 14.00(14.00)\n",
      "Iter 22680 | Time 25.7249(26.2122) | Bit/dim 3.4751(3.4833) | Xent 0.0168(0.0139) | Loss 3.4835(3.4902) | Error 0.0033(0.0037) Steps 1066(1057.49) | Grad Norm 1.1872(1.4160) | Total Time 14.00(14.00)\n",
      "Iter 22690 | Time 26.2537(26.0861) | Bit/dim 3.4962(3.4859) | Xent 0.0140(0.0138) | Loss 3.5032(3.4928) | Error 0.0033(0.0038) Steps 1048(1054.22) | Grad Norm 1.3852(1.3966) | Total Time 14.00(14.00)\n",
      "Iter 22700 | Time 25.4636(26.1056) | Bit/dim 3.4901(3.4850) | Xent 0.0093(0.0137) | Loss 3.4947(3.4918) | Error 0.0022(0.0038) Steps 1060(1055.25) | Grad Norm 1.5565(1.4463) | Total Time 14.00(14.00)\n",
      "Iter 22710 | Time 26.2468(26.1134) | Bit/dim 3.4903(3.4859) | Xent 0.0090(0.0140) | Loss 3.4948(3.4929) | Error 0.0011(0.0038) Steps 1072(1055.13) | Grad Norm 0.8925(1.4653) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 121.6025, Epoch Time 1576.8305(1584.6078), Bit/dim 3.4925(best: 3.4907), Xent 2.6522, Loss 4.8186, Error 0.2767(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22720 | Time 26.2064(26.1247) | Bit/dim 3.4961(3.4857) | Xent 0.0136(0.0140) | Loss 3.5030(3.4927) | Error 0.0011(0.0037) Steps 1054(1055.42) | Grad Norm 1.0687(1.5980) | Total Time 14.00(14.00)\n",
      "Iter 22730 | Time 27.0218(26.1572) | Bit/dim 3.4609(3.4848) | Xent 0.0135(0.0140) | Loss 3.4676(3.4918) | Error 0.0044(0.0040) Steps 1066(1055.39) | Grad Norm 1.6256(1.6103) | Total Time 14.00(14.00)\n",
      "Iter 22740 | Time 26.2567(26.2330) | Bit/dim 3.4703(3.4850) | Xent 0.0065(0.0138) | Loss 3.4735(3.4919) | Error 0.0000(0.0040) Steps 1084(1057.71) | Grad Norm 0.6744(1.5876) | Total Time 14.00(14.00)\n",
      "Iter 22750 | Time 26.1293(26.3398) | Bit/dim 3.4748(3.4858) | Xent 0.0149(0.0136) | Loss 3.4823(3.4926) | Error 0.0044(0.0037) Steps 1066(1060.44) | Grad Norm 1.5510(1.4998) | Total Time 14.00(14.00)\n",
      "Iter 22760 | Time 25.8205(26.2956) | Bit/dim 3.4970(3.4864) | Xent 0.0118(0.0137) | Loss 3.5029(3.4932) | Error 0.0033(0.0037) Steps 1060(1059.23) | Grad Norm 1.2699(1.4622) | Total Time 14.00(14.00)\n",
      "Iter 22770 | Time 26.3193(26.3509) | Bit/dim 3.4714(3.4855) | Xent 0.0196(0.0137) | Loss 3.4811(3.4923) | Error 0.0033(0.0036) Steps 1054(1059.08) | Grad Norm 1.2162(1.4205) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 121.2164, Epoch Time 1588.8402(1584.7347), Bit/dim 3.4896(best: 3.4907), Xent 2.6528, Loss 4.8160, Error 0.2764(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22780 | Time 25.6522(26.2827) | Bit/dim 3.4901(3.4865) | Xent 0.0073(0.0129) | Loss 3.4938(3.4929) | Error 0.0011(0.0033) Steps 1054(1058.33) | Grad Norm 0.9741(1.3333) | Total Time 14.00(14.00)\n",
      "Iter 22790 | Time 26.5797(26.2391) | Bit/dim 3.4753(3.4872) | Xent 0.0083(0.0130) | Loss 3.4794(3.4937) | Error 0.0022(0.0034) Steps 1036(1058.20) | Grad Norm 0.8476(1.2748) | Total Time 14.00(14.00)\n",
      "Iter 22800 | Time 26.9881(26.3339) | Bit/dim 3.4627(3.4859) | Xent 0.0234(0.0135) | Loss 3.4744(3.4927) | Error 0.0067(0.0034) Steps 1066(1057.96) | Grad Norm 1.6210(1.2580) | Total Time 14.00(14.00)\n",
      "Iter 22810 | Time 26.4158(26.3268) | Bit/dim 3.4402(3.4843) | Xent 0.0101(0.0135) | Loss 3.4452(3.4910) | Error 0.0033(0.0035) Steps 1054(1057.18) | Grad Norm 1.0132(1.2686) | Total Time 14.00(14.00)\n",
      "Iter 22820 | Time 27.2893(26.4325) | Bit/dim 3.5018(3.4832) | Xent 0.0134(0.0142) | Loss 3.5085(3.4903) | Error 0.0033(0.0039) Steps 1060(1060.00) | Grad Norm 1.5052(1.3101) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 121.0982, Epoch Time 1589.8964(1584.8896), Bit/dim 3.4916(best: 3.4896), Xent 2.6192, Loss 4.8012, Error 0.2758(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22830 | Time 26.7309(26.4326) | Bit/dim 3.5065(3.4857) | Xent 0.0121(0.0144) | Loss 3.5126(3.4929) | Error 0.0011(0.0039) Steps 1108(1060.39) | Grad Norm 1.1915(1.3325) | Total Time 14.00(14.00)\n",
      "Iter 22840 | Time 25.2291(26.3811) | Bit/dim 3.4695(3.4860) | Xent 0.0123(0.0147) | Loss 3.4756(3.4933) | Error 0.0044(0.0043) Steps 1042(1058.91) | Grad Norm 1.4188(1.3700) | Total Time 14.00(14.00)\n",
      "Iter 22850 | Time 26.1168(26.3442) | Bit/dim 3.5072(3.4868) | Xent 0.0117(0.0145) | Loss 3.5130(3.4940) | Error 0.0044(0.0043) Steps 1078(1060.78) | Grad Norm 1.3158(1.4036) | Total Time 14.00(14.00)\n",
      "Iter 22860 | Time 25.3392(26.3365) | Bit/dim 3.4887(3.4852) | Xent 0.0239(0.0151) | Loss 3.5006(3.4927) | Error 0.0089(0.0046) Steps 1048(1060.58) | Grad Norm 1.5667(1.4380) | Total Time 14.00(14.00)\n",
      "Iter 22870 | Time 26.1895(26.2522) | Bit/dim 3.4730(3.4834) | Xent 0.0135(0.0154) | Loss 3.4797(3.4910) | Error 0.0033(0.0049) Steps 1060(1059.81) | Grad Norm 1.5654(1.5089) | Total Time 14.00(14.00)\n",
      "Iter 22880 | Time 25.8706(26.1888) | Bit/dim 3.4814(3.4851) | Xent 0.0116(0.0155) | Loss 3.4872(3.4929) | Error 0.0033(0.0049) Steps 1042(1058.50) | Grad Norm 0.9357(1.5059) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 120.9698, Epoch Time 1579.0428(1584.7142), Bit/dim 3.4916(best: 3.4896), Xent 2.6664, Loss 4.8248, Error 0.2781(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22890 | Time 26.1632(26.1822) | Bit/dim 3.4352(3.4847) | Xent 0.0089(0.0146) | Loss 3.4396(3.4920) | Error 0.0000(0.0044) Steps 1042(1057.24) | Grad Norm 1.1243(1.4378) | Total Time 14.00(14.00)\n",
      "Iter 22900 | Time 25.9997(26.2143) | Bit/dim 3.4744(3.4826) | Xent 0.0124(0.0139) | Loss 3.4806(3.4895) | Error 0.0044(0.0042) Steps 1048(1055.27) | Grad Norm 1.2696(1.3841) | Total Time 14.00(14.00)\n",
      "Iter 22910 | Time 26.6235(26.2593) | Bit/dim 3.4674(3.4837) | Xent 0.0119(0.0139) | Loss 3.4733(3.4907) | Error 0.0022(0.0041) Steps 1060(1057.14) | Grad Norm 0.8329(1.3404) | Total Time 14.00(14.00)\n",
      "Iter 22920 | Time 25.4984(26.2020) | Bit/dim 3.5196(3.4869) | Xent 0.0207(0.0140) | Loss 3.5300(3.4939) | Error 0.0056(0.0040) Steps 1042(1058.18) | Grad Norm 1.3563(1.3175) | Total Time 14.00(14.00)\n",
      "Iter 22930 | Time 26.9771(26.2115) | Bit/dim 3.4528(3.4856) | Xent 0.0137(0.0138) | Loss 3.4596(3.4925) | Error 0.0044(0.0038) Steps 1060(1057.36) | Grad Norm 2.0044(1.3948) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 121.3941, Epoch Time 1581.4348(1584.6158), Bit/dim 3.4905(best: 3.4896), Xent 2.6466, Loss 4.8138, Error 0.2765(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22940 | Time 25.6664(26.1681) | Bit/dim 3.4717(3.4863) | Xent 0.0157(0.0138) | Loss 3.4795(3.4932) | Error 0.0056(0.0039) Steps 1048(1056.74) | Grad Norm 1.4579(1.4508) | Total Time 14.00(14.00)\n",
      "Iter 22950 | Time 26.9340(26.1499) | Bit/dim 3.4949(3.4855) | Xent 0.0090(0.0136) | Loss 3.4994(3.4923) | Error 0.0011(0.0038) Steps 1072(1057.13) | Grad Norm 0.8250(1.5297) | Total Time 14.00(14.00)\n",
      "Iter 22960 | Time 26.1844(26.1858) | Bit/dim 3.4884(3.4840) | Xent 0.0083(0.0135) | Loss 3.4926(3.4908) | Error 0.0011(0.0038) Steps 1060(1057.50) | Grad Norm 0.9825(1.4454) | Total Time 14.00(14.00)\n",
      "Iter 22970 | Time 26.4515(26.1864) | Bit/dim 3.4843(3.4838) | Xent 0.0095(0.0133) | Loss 3.4890(3.4905) | Error 0.0033(0.0037) Steps 1054(1057.88) | Grad Norm 0.9834(1.3432) | Total Time 14.00(14.00)\n",
      "Iter 22980 | Time 26.0363(26.2073) | Bit/dim 3.4515(3.4843) | Xent 0.0080(0.0134) | Loss 3.4555(3.4910) | Error 0.0022(0.0039) Steps 1072(1057.66) | Grad Norm 1.2786(1.3323) | Total Time 14.00(14.00)\n",
      "Iter 22990 | Time 26.6942(26.2543) | Bit/dim 3.4834(3.4869) | Xent 0.0133(0.0137) | Loss 3.4901(3.4937) | Error 0.0044(0.0040) Steps 1060(1056.91) | Grad Norm 1.1845(1.2992) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 121.5663, Epoch Time 1580.7799(1584.5007), Bit/dim 3.4901(best: 3.4896), Xent 2.6625, Loss 4.8213, Error 0.2754(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23000 | Time 26.2046(26.1376) | Bit/dim 3.5179(3.4900) | Xent 0.0095(0.0133) | Loss 3.5227(3.4967) | Error 0.0000(0.0038) Steps 1042(1054.25) | Grad Norm 0.7954(1.2539) | Total Time 14.00(14.00)\n",
      "Iter 23010 | Time 26.6239(26.1381) | Bit/dim 3.4577(3.4882) | Xent 0.0176(0.0134) | Loss 3.4665(3.4949) | Error 0.0078(0.0039) Steps 1072(1056.76) | Grad Norm 1.6512(1.3803) | Total Time 14.00(14.00)\n",
      "Iter 23020 | Time 26.2030(26.1525) | Bit/dim 3.4708(3.4872) | Xent 0.0180(0.0138) | Loss 3.4799(3.4941) | Error 0.0067(0.0039) Steps 1066(1057.48) | Grad Norm 1.3921(1.5184) | Total Time 14.00(14.00)\n",
      "Iter 23030 | Time 26.5928(26.2068) | Bit/dim 3.4700(3.4860) | Xent 0.0171(0.0141) | Loss 3.4786(3.4931) | Error 0.0078(0.0040) Steps 1054(1056.26) | Grad Norm 2.1585(1.4971) | Total Time 14.00(14.00)\n",
      "Iter 23040 | Time 26.5627(26.1464) | Bit/dim 3.4707(3.4856) | Xent 0.0144(0.0145) | Loss 3.4779(3.4929) | Error 0.0033(0.0043) Steps 1054(1055.50) | Grad Norm 1.3646(1.4964) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 122.5050, Epoch Time 1575.1216(1584.2193), Bit/dim 3.4905(best: 3.4896), Xent 2.6630, Loss 4.8220, Error 0.2820(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23050 | Time 26.4032(26.1383) | Bit/dim 3.4728(3.4846) | Xent 0.0084(0.0145) | Loss 3.4770(3.4918) | Error 0.0011(0.0042) Steps 1072(1055.16) | Grad Norm 1.3325(1.5447) | Total Time 14.00(14.00)\n",
      "Iter 23060 | Time 27.0852(26.1693) | Bit/dim 3.5074(3.4834) | Xent 0.0164(0.0145) | Loss 3.5156(3.4906) | Error 0.0033(0.0042) Steps 1042(1055.74) | Grad Norm 1.3381(1.5054) | Total Time 14.00(14.00)\n",
      "Iter 23070 | Time 26.3793(26.1825) | Bit/dim 3.5106(3.4858) | Xent 0.0196(0.0148) | Loss 3.5204(3.4932) | Error 0.0078(0.0045) Steps 1072(1056.09) | Grad Norm 1.6563(1.5035) | Total Time 14.00(14.00)\n",
      "Iter 23080 | Time 26.1972(26.1247) | Bit/dim 3.4877(3.4867) | Xent 0.0144(0.0155) | Loss 3.4949(3.4945) | Error 0.0044(0.0047) Steps 1090(1057.67) | Grad Norm 1.6837(1.5915) | Total Time 14.00(14.00)\n",
      "Iter 23090 | Time 25.8445(26.1421) | Bit/dim 3.5078(3.4873) | Xent 0.0096(0.0147) | Loss 3.5126(3.4946) | Error 0.0044(0.0042) Steps 1042(1057.79) | Grad Norm 0.8780(1.4941) | Total Time 14.00(14.00)\n",
      "Iter 23100 | Time 26.5539(26.1216) | Bit/dim 3.4708(3.4852) | Xent 0.0145(0.0138) | Loss 3.4780(3.4921) | Error 0.0033(0.0038) Steps 1054(1056.91) | Grad Norm 1.3165(1.3802) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 122.0723, Epoch Time 1577.8730(1584.0290), Bit/dim 3.4909(best: 3.4896), Xent 2.6659, Loss 4.8239, Error 0.2773(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23110 | Time 25.5854(26.1285) | Bit/dim 3.4746(3.4879) | Xent 0.0129(0.0136) | Loss 3.4810(3.4946) | Error 0.0022(0.0037) Steps 1054(1055.93) | Grad Norm 1.5762(1.3291) | Total Time 14.00(14.00)\n",
      "Iter 23120 | Time 25.8323(26.1574) | Bit/dim 3.4783(3.4864) | Xent 0.0134(0.0134) | Loss 3.4850(3.4931) | Error 0.0056(0.0036) Steps 1054(1054.87) | Grad Norm 1.5606(1.3431) | Total Time 14.00(14.00)\n",
      "Iter 23130 | Time 26.0365(26.1828) | Bit/dim 3.4437(3.4867) | Xent 0.0153(0.0138) | Loss 3.4514(3.4936) | Error 0.0022(0.0036) Steps 1042(1055.45) | Grad Norm 1.8100(1.4156) | Total Time 14.00(14.00)\n",
      "Iter 23140 | Time 24.8123(26.1701) | Bit/dim 3.5029(3.4846) | Xent 0.0210(0.0146) | Loss 3.5135(3.4919) | Error 0.0078(0.0041) Steps 1048(1056.41) | Grad Norm 2.0890(1.4869) | Total Time 14.00(14.00)\n",
      "Iter 23150 | Time 25.7158(26.1843) | Bit/dim 3.4751(3.4833) | Xent 0.0148(0.0136) | Loss 3.4825(3.4901) | Error 0.0022(0.0038) Steps 1048(1057.23) | Grad Norm 1.8888(1.4543) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 121.4170, Epoch Time 1579.7964(1583.9020), Bit/dim 3.4903(best: 3.4896), Xent 2.6419, Loss 4.8113, Error 0.2782(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23160 | Time 26.2650(26.1449) | Bit/dim 3.4580(3.4827) | Xent 0.0108(0.0134) | Loss 3.4633(3.4894) | Error 0.0022(0.0038) Steps 1060(1057.20) | Grad Norm 1.0325(1.4165) | Total Time 14.00(14.00)\n",
      "Iter 23170 | Time 26.7502(26.1444) | Bit/dim 3.4780(3.4889) | Xent 0.0167(0.0136) | Loss 3.4864(3.4957) | Error 0.0067(0.0038) Steps 1078(1057.01) | Grad Norm 1.9753(1.3899) | Total Time 14.00(14.00)\n",
      "Iter 23180 | Time 26.3187(26.1501) | Bit/dim 3.4599(3.4869) | Xent 0.0224(0.0138) | Loss 3.4711(3.4937) | Error 0.0100(0.0038) Steps 1060(1056.16) | Grad Norm 1.4756(1.3986) | Total Time 14.00(14.00)\n",
      "Iter 23190 | Time 26.8613(26.2240) | Bit/dim 3.5092(3.4845) | Xent 0.0162(0.0137) | Loss 3.5173(3.4913) | Error 0.0022(0.0038) Steps 1048(1055.67) | Grad Norm 1.4341(1.4252) | Total Time 14.00(14.00)\n",
      "Iter 23200 | Time 26.4382(26.3131) | Bit/dim 3.4981(3.4837) | Xent 0.0128(0.0134) | Loss 3.5045(3.4903) | Error 0.0044(0.0037) Steps 1048(1056.43) | Grad Norm 1.5748(1.4177) | Total Time 14.00(14.00)\n",
      "Iter 23210 | Time 25.8958(26.3701) | Bit/dim 3.4334(3.4826) | Xent 0.0173(0.0137) | Loss 3.4420(3.4894) | Error 0.0056(0.0039) Steps 1054(1057.34) | Grad Norm 1.9905(1.4291) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 121.5571, Epoch Time 1587.8926(1584.0217), Bit/dim 3.4908(best: 3.4896), Xent 2.6609, Loss 4.8212, Error 0.2793(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23220 | Time 26.0330(26.3238) | Bit/dim 3.4778(3.4815) | Xent 0.0173(0.0130) | Loss 3.4864(3.4880) | Error 0.0044(0.0035) Steps 1060(1060.03) | Grad Norm 1.6828(1.4178) | Total Time 14.00(14.00)\n",
      "Iter 23230 | Time 25.8720(26.2650) | Bit/dim 3.5207(3.4831) | Xent 0.0127(0.0133) | Loss 3.5271(3.4897) | Error 0.0033(0.0037) Steps 1048(1058.63) | Grad Norm 1.4046(1.4355) | Total Time 14.00(14.00)\n",
      "Iter 23240 | Time 25.8810(26.1845) | Bit/dim 3.4923(3.4833) | Xent 0.0103(0.0134) | Loss 3.4974(3.4900) | Error 0.0033(0.0038) Steps 1066(1057.03) | Grad Norm 0.9917(1.4578) | Total Time 14.00(14.00)\n",
      "Iter 23250 | Time 26.3720(26.2058) | Bit/dim 3.4809(3.4833) | Xent 0.0286(0.0141) | Loss 3.4952(3.4903) | Error 0.0100(0.0040) Steps 1060(1057.39) | Grad Norm 2.9192(1.5668) | Total Time 14.00(14.00)\n",
      "Iter 23260 | Time 26.6374(26.1556) | Bit/dim 3.5167(3.4850) | Xent 0.0144(0.0141) | Loss 3.5239(3.4920) | Error 0.0044(0.0040) Steps 1060(1055.87) | Grad Norm 1.2556(1.5547) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 121.5184, Epoch Time 1575.0440(1583.7524), Bit/dim 3.4890(best: 3.4896), Xent 2.6612, Loss 4.8196, Error 0.2769(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23270 | Time 26.9494(26.1832) | Bit/dim 3.5104(3.4867) | Xent 0.0094(0.0131) | Loss 3.5151(3.4933) | Error 0.0022(0.0036) Steps 1066(1056.52) | Grad Norm 1.0765(1.4683) | Total Time 14.00(14.00)\n",
      "Iter 23280 | Time 26.1259(26.1289) | Bit/dim 3.4682(3.4864) | Xent 0.0132(0.0130) | Loss 3.4748(3.4929) | Error 0.0022(0.0037) Steps 1060(1055.84) | Grad Norm 0.9269(1.3953) | Total Time 14.00(14.00)\n",
      "Iter 23290 | Time 26.2739(26.1041) | Bit/dim 3.4946(3.4869) | Xent 0.0121(0.0138) | Loss 3.5006(3.4938) | Error 0.0022(0.0039) Steps 1066(1054.38) | Grad Norm 2.7077(1.4925) | Total Time 14.00(14.00)\n",
      "Iter 23300 | Time 26.8320(26.0884) | Bit/dim 3.4701(3.4873) | Xent 0.0133(0.0151) | Loss 3.4767(3.4949) | Error 0.0044(0.0046) Steps 1060(1055.85) | Grad Norm 1.3214(1.6098) | Total Time 14.00(14.00)\n",
      "Iter 23310 | Time 26.8940(26.1174) | Bit/dim 3.5103(3.4859) | Xent 0.0160(0.0146) | Loss 3.5184(3.4932) | Error 0.0044(0.0044) Steps 1060(1056.77) | Grad Norm 1.4813(1.5694) | Total Time 14.00(14.00)\n",
      "Iter 23320 | Time 25.1165(26.1183) | Bit/dim 3.4754(3.4843) | Xent 0.0095(0.0137) | Loss 3.4802(3.4912) | Error 0.0033(0.0041) Steps 1048(1055.19) | Grad Norm 1.5781(1.4942) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 121.9515, Epoch Time 1575.2994(1583.4988), Bit/dim 3.4901(best: 3.4890), Xent 2.6563, Loss 4.8182, Error 0.2796(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23330 | Time 26.7751(26.1326) | Bit/dim 3.5164(3.4845) | Xent 0.0076(0.0132) | Loss 3.5202(3.4911) | Error 0.0022(0.0038) Steps 1072(1056.28) | Grad Norm 0.8568(1.4164) | Total Time 14.00(14.00)\n",
      "Iter 23340 | Time 26.4037(26.1082) | Bit/dim 3.5194(3.4821) | Xent 0.0122(0.0132) | Loss 3.5254(3.4887) | Error 0.0044(0.0038) Steps 1078(1056.40) | Grad Norm 1.2081(1.4225) | Total Time 14.00(14.00)\n",
      "Iter 23350 | Time 25.2245(26.1521) | Bit/dim 3.4756(3.4818) | Xent 0.0134(0.0132) | Loss 3.4823(3.4884) | Error 0.0056(0.0039) Steps 1048(1057.30) | Grad Norm 1.4418(1.4359) | Total Time 14.00(14.00)\n",
      "Iter 23360 | Time 26.3005(26.1851) | Bit/dim 3.5100(3.4831) | Xent 0.0095(0.0130) | Loss 3.5148(3.4896) | Error 0.0044(0.0039) Steps 1048(1057.88) | Grad Norm 1.6990(1.4322) | Total Time 14.00(14.00)\n",
      "Iter 23370 | Time 25.6063(26.2073) | Bit/dim 3.4960(3.4859) | Xent 0.0099(0.0134) | Loss 3.5010(3.4926) | Error 0.0033(0.0040) Steps 1060(1057.22) | Grad Norm 1.2028(1.3996) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 122.9800, Epoch Time 1584.9723(1583.5430), Bit/dim 3.4899(best: 3.4890), Xent 2.6501, Loss 4.8150, Error 0.2801(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23380 | Time 26.4954(26.3185) | Bit/dim 3.5087(3.4870) | Xent 0.0118(0.0134) | Loss 3.5146(3.4937) | Error 0.0022(0.0039) Steps 1066(1058.79) | Grad Norm 1.2455(1.4339) | Total Time 14.00(14.00)\n",
      "Iter 23390 | Time 25.9847(26.3559) | Bit/dim 3.4741(3.4852) | Xent 0.0149(0.0139) | Loss 3.4816(3.4922) | Error 0.0044(0.0041) Steps 1060(1060.22) | Grad Norm 1.1378(1.3963) | Total Time 14.00(14.00)\n",
      "Iter 23400 | Time 25.9834(26.3889) | Bit/dim 3.5296(3.4846) | Xent 0.0107(0.0134) | Loss 3.5349(3.4913) | Error 0.0033(0.0040) Steps 1060(1060.64) | Grad Norm 1.2440(1.3630) | Total Time 14.00(14.00)\n",
      "Iter 23410 | Time 26.7831(26.3903) | Bit/dim 3.4915(3.4828) | Xent 0.0166(0.0139) | Loss 3.4998(3.4898) | Error 0.0044(0.0042) Steps 1060(1061.01) | Grad Norm 1.7463(1.4488) | Total Time 14.00(14.00)\n",
      "Iter 23420 | Time 25.8638(26.3358) | Bit/dim 3.4901(3.4840) | Xent 0.0141(0.0136) | Loss 3.4971(3.4908) | Error 0.0044(0.0040) Steps 1054(1059.22) | Grad Norm 1.1751(1.4080) | Total Time 14.00(14.00)\n",
      "Iter 23430 | Time 25.6408(26.2686) | Bit/dim 3.4776(3.4856) | Xent 0.0204(0.0138) | Loss 3.4878(3.4925) | Error 0.0078(0.0042) Steps 1048(1058.23) | Grad Norm 1.6355(1.3856) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 124.1109, Epoch Time 1590.9473(1583.7651), Bit/dim 3.4903(best: 3.4890), Xent 2.6578, Loss 4.8193, Error 0.2781(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23440 | Time 25.8831(26.2901) | Bit/dim 3.4861(3.4851) | Xent 0.0155(0.0145) | Loss 3.4939(3.4924) | Error 0.0044(0.0045) Steps 1054(1060.07) | Grad Norm 1.5550(1.4745) | Total Time 14.00(14.00)\n",
      "Iter 23450 | Time 26.1206(26.3258) | Bit/dim 3.4918(3.4855) | Xent 0.0094(0.0142) | Loss 3.4965(3.4926) | Error 0.0022(0.0043) Steps 1060(1059.59) | Grad Norm 1.0609(1.5091) | Total Time 14.00(14.00)\n",
      "Iter 23460 | Time 25.8628(26.3346) | Bit/dim 3.4894(3.4876) | Xent 0.0194(0.0142) | Loss 3.4990(3.4947) | Error 0.0067(0.0043) Steps 1042(1058.30) | Grad Norm 1.6888(1.4667) | Total Time 14.00(14.00)\n",
      "Iter 23470 | Time 26.2340(26.2356) | Bit/dim 3.4482(3.4852) | Xent 0.0106(0.0144) | Loss 3.4535(3.4923) | Error 0.0022(0.0043) Steps 1084(1057.62) | Grad Norm 1.0651(1.4279) | Total Time 14.00(14.00)\n",
      "Iter 23480 | Time 25.5187(26.1893) | Bit/dim 3.4499(3.4844) | Xent 0.0122(0.0141) | Loss 3.4560(3.4915) | Error 0.0022(0.0043) Steps 1072(1057.91) | Grad Norm 1.7224(1.4242) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 120.8296, Epoch Time 1581.9723(1583.7113), Bit/dim 3.4893(best: 3.4890), Xent 2.6733, Loss 4.8259, Error 0.2796(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23490 | Time 26.4470(26.1769) | Bit/dim 3.4548(3.4834) | Xent 0.0111(0.0137) | Loss 3.4604(3.4902) | Error 0.0022(0.0038) Steps 1042(1055.66) | Grad Norm 1.3944(1.4302) | Total Time 14.00(14.00)\n",
      "Iter 23500 | Time 25.5205(26.2026) | Bit/dim 3.4457(3.4821) | Xent 0.0208(0.0137) | Loss 3.4561(3.4889) | Error 0.0067(0.0038) Steps 1054(1056.74) | Grad Norm 1.6712(1.5571) | Total Time 14.00(14.00)\n",
      "Iter 23510 | Time 26.2980(26.2797) | Bit/dim 3.4852(3.4845) | Xent 0.0160(0.0142) | Loss 3.4932(3.4916) | Error 0.0044(0.0039) Steps 1072(1058.47) | Grad Norm 1.5396(1.5105) | Total Time 14.00(14.00)\n",
      "Iter 23520 | Time 26.6897(26.2829) | Bit/dim 3.4825(3.4844) | Xent 0.0121(0.0140) | Loss 3.4886(3.4914) | Error 0.0033(0.0038) Steps 1072(1058.60) | Grad Norm 1.1429(1.4997) | Total Time 14.00(14.00)\n",
      "Iter 23530 | Time 26.2399(26.3017) | Bit/dim 3.4771(3.4839) | Xent 0.0153(0.0135) | Loss 3.4848(3.4907) | Error 0.0033(0.0036) Steps 1048(1058.90) | Grad Norm 1.3135(1.4076) | Total Time 14.00(14.00)\n",
      "Iter 23540 | Time 25.8332(26.2127) | Bit/dim 3.5112(3.4851) | Xent 0.0215(0.0146) | Loss 3.5219(3.4924) | Error 0.0056(0.0039) Steps 1060(1058.18) | Grad Norm 1.6472(1.4478) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 121.1880, Epoch Time 1583.2821(1583.6984), Bit/dim 3.4893(best: 3.4890), Xent 2.6505, Loss 4.8146, Error 0.2815(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23550 | Time 26.3493(26.2466) | Bit/dim 3.4945(3.4843) | Xent 0.0120(0.0141) | Loss 3.5005(3.4914) | Error 0.0022(0.0036) Steps 1042(1058.77) | Grad Norm 1.1951(1.4302) | Total Time 14.00(14.00)\n",
      "Iter 23560 | Time 26.1934(26.2762) | Bit/dim 3.4912(3.4838) | Xent 0.0204(0.0139) | Loss 3.5014(3.4908) | Error 0.0056(0.0035) Steps 1060(1060.58) | Grad Norm 1.6443(1.4077) | Total Time 14.00(14.00)\n",
      "Iter 23570 | Time 27.3495(26.2593) | Bit/dim 3.4823(3.4877) | Xent 0.0148(0.0133) | Loss 3.4897(3.4944) | Error 0.0056(0.0034) Steps 1066(1061.66) | Grad Norm 1.4476(1.3521) | Total Time 14.00(14.00)\n",
      "Iter 23580 | Time 26.7609(26.2034) | Bit/dim 3.4869(3.4839) | Xent 0.0117(0.0132) | Loss 3.4928(3.4905) | Error 0.0011(0.0034) Steps 1060(1060.14) | Grad Norm 1.1201(1.3390) | Total Time 14.00(14.00)\n",
      "Iter 23590 | Time 26.7201(26.2971) | Bit/dim 3.4978(3.4851) | Xent 0.0079(0.0131) | Loss 3.5018(3.4917) | Error 0.0000(0.0034) Steps 1066(1061.11) | Grad Norm 0.8440(1.3818) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 121.7403, Epoch Time 1588.3623(1583.8384), Bit/dim 3.4901(best: 3.4890), Xent 2.6956, Loss 4.8379, Error 0.2825(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23600 | Time 26.1535(26.3120) | Bit/dim 3.4974(3.4861) | Xent 0.0172(0.0131) | Loss 3.5060(3.4926) | Error 0.0044(0.0034) Steps 1090(1062.93) | Grad Norm 1.7482(1.4047) | Total Time 14.00(14.00)\n",
      "Iter 23610 | Time 25.6909(26.2793) | Bit/dim 3.4869(3.4859) | Xent 0.0061(0.0125) | Loss 3.4900(3.4921) | Error 0.0011(0.0032) Steps 1066(1061.77) | Grad Norm 0.7746(1.3785) | Total Time 14.00(14.00)\n",
      "Iter 23620 | Time 24.9350(26.1795) | Bit/dim 3.4562(3.4809) | Xent 0.0094(0.0124) | Loss 3.4608(3.4871) | Error 0.0022(0.0031) Steps 1054(1060.44) | Grad Norm 1.3335(1.3148) | Total Time 14.00(14.00)\n",
      "Iter 23630 | Time 26.9634(26.2244) | Bit/dim 3.4994(3.4835) | Xent 0.0163(0.0129) | Loss 3.5075(3.4900) | Error 0.0033(0.0033) Steps 1054(1059.27) | Grad Norm 1.3395(1.3313) | Total Time 14.00(14.00)\n",
      "Iter 23640 | Time 26.0539(26.1650) | Bit/dim 3.4932(3.4832) | Xent 0.0139(0.0137) | Loss 3.5002(3.4900) | Error 0.0044(0.0037) Steps 1054(1057.78) | Grad Norm 2.7876(1.4266) | Total Time 14.00(14.00)\n",
      "Iter 23650 | Time 25.9227(26.1305) | Bit/dim 3.4984(3.4852) | Xent 0.0143(0.0138) | Loss 3.5055(3.4920) | Error 0.0033(0.0037) Steps 1060(1058.13) | Grad Norm 1.7371(1.4343) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 122.0142, Epoch Time 1574.8591(1583.5690), Bit/dim 3.4887(best: 3.4890), Xent 2.6779, Loss 4.8276, Error 0.2797(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23660 | Time 25.9872(26.1313) | Bit/dim 3.4631(3.4842) | Xent 0.0126(0.0135) | Loss 3.4694(3.4910) | Error 0.0033(0.0036) Steps 1072(1059.68) | Grad Norm 1.3794(1.3611) | Total Time 14.00(14.00)\n",
      "Iter 23670 | Time 26.2410(26.1407) | Bit/dim 3.4838(3.4834) | Xent 0.0115(0.0132) | Loss 3.4895(3.4900) | Error 0.0044(0.0035) Steps 1060(1059.43) | Grad Norm 1.3596(1.3139) | Total Time 14.00(14.00)\n",
      "Iter 23680 | Time 25.8393(26.1132) | Bit/dim 3.4731(3.4855) | Xent 0.0184(0.0139) | Loss 3.4822(3.4924) | Error 0.0044(0.0039) Steps 1054(1058.42) | Grad Norm 1.2456(1.3871) | Total Time 14.00(14.00)\n",
      "Iter 23690 | Time 26.3823(26.1648) | Bit/dim 3.5078(3.4851) | Xent 0.0114(0.0142) | Loss 3.5134(3.4922) | Error 0.0022(0.0041) Steps 1066(1058.86) | Grad Norm 1.1571(1.4100) | Total Time 14.00(14.00)\n",
      "Iter 23700 | Time 25.2647(26.0567) | Bit/dim 3.4794(3.4834) | Xent 0.0110(0.0138) | Loss 3.4849(3.4903) | Error 0.0044(0.0040) Steps 1054(1058.08) | Grad Norm 1.2656(1.3824) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 122.3857, Epoch Time 1574.6494(1583.3014), Bit/dim 3.4894(best: 3.4887), Xent 2.6900, Loss 4.8344, Error 0.2793(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23710 | Time 25.8596(26.0501) | Bit/dim 3.4634(3.4837) | Xent 0.0163(0.0139) | Loss 3.4716(3.4906) | Error 0.0067(0.0042) Steps 1060(1058.71) | Grad Norm 1.8844(1.3890) | Total Time 14.00(14.00)\n",
      "Iter 23720 | Time 27.0486(26.1878) | Bit/dim 3.4836(3.4845) | Xent 0.0146(0.0138) | Loss 3.4909(3.4914) | Error 0.0056(0.0040) Steps 1084(1060.23) | Grad Norm 1.4116(1.3901) | Total Time 14.00(14.00)\n",
      "Iter 23730 | Time 26.3480(26.2725) | Bit/dim 3.4950(3.4867) | Xent 0.0104(0.0135) | Loss 3.5002(3.4934) | Error 0.0000(0.0037) Steps 1054(1058.56) | Grad Norm 1.6642(1.3863) | Total Time 14.00(14.00)\n",
      "Iter 23740 | Time 25.5784(26.2508) | Bit/dim 3.4947(3.4856) | Xent 0.0098(0.0137) | Loss 3.4996(3.4924) | Error 0.0033(0.0038) Steps 1060(1058.45) | Grad Norm 1.5713(1.4165) | Total Time 14.00(14.00)\n",
      "Iter 23750 | Time 26.2765(26.1912) | Bit/dim 3.4476(3.4826) | Xent 0.0077(0.0134) | Loss 3.4514(3.4893) | Error 0.0011(0.0037) Steps 1072(1058.44) | Grad Norm 0.8959(1.3817) | Total Time 14.00(14.00)\n",
      "Iter 23760 | Time 26.3372(26.1109) | Bit/dim 3.4610(3.4834) | Xent 0.0230(0.0141) | Loss 3.4725(3.4904) | Error 0.0078(0.0041) Steps 1054(1057.48) | Grad Norm 2.7325(1.4251) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 123.5984, Epoch Time 1583.3227(1583.3020), Bit/dim 3.4894(best: 3.4887), Xent 2.6803, Loss 4.8296, Error 0.2780(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23770 | Time 26.8060(26.1248) | Bit/dim 3.4701(3.4845) | Xent 0.0120(0.0140) | Loss 3.4761(3.4915) | Error 0.0022(0.0041) Steps 1066(1057.11) | Grad Norm 1.8123(1.5458) | Total Time 14.00(14.00)\n",
      "Iter 23780 | Time 26.4561(26.2076) | Bit/dim 3.4938(3.4853) | Xent 0.0130(0.0145) | Loss 3.5003(3.4926) | Error 0.0033(0.0044) Steps 1036(1057.09) | Grad Norm 1.5303(1.5644) | Total Time 14.00(14.00)\n",
      "Iter 23790 | Time 25.4249(26.1811) | Bit/dim 3.4782(3.4830) | Xent 0.0164(0.0142) | Loss 3.4864(3.4901) | Error 0.0056(0.0043) Steps 1048(1056.78) | Grad Norm 1.2662(1.5193) | Total Time 14.00(14.00)\n",
      "Iter 23800 | Time 26.7385(26.1899) | Bit/dim 3.5123(3.4819) | Xent 0.0171(0.0151) | Loss 3.5209(3.4895) | Error 0.0056(0.0047) Steps 1060(1058.51) | Grad Norm 2.0014(1.6054) | Total Time 14.00(14.00)\n",
      "Iter 23810 | Time 25.9139(26.1887) | Bit/dim 3.4727(3.4811) | Xent 0.0132(0.0144) | Loss 3.4792(3.4883) | Error 0.0033(0.0043) Steps 1054(1059.58) | Grad Norm 1.2908(1.5516) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 122.8981, Epoch Time 1582.8024(1583.2870), Bit/dim 3.4901(best: 3.4887), Xent 2.6576, Loss 4.8189, Error 0.2757(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23820 | Time 26.6749(26.2154) | Bit/dim 3.4974(3.4869) | Xent 0.0053(0.0135) | Loss 3.5000(3.4936) | Error 0.0000(0.0039) Steps 1054(1060.81) | Grad Norm 0.7913(1.5116) | Total Time 14.00(14.00)\n",
      "Iter 23830 | Time 25.9377(26.2874) | Bit/dim 3.4753(3.4864) | Xent 0.0149(0.0133) | Loss 3.4828(3.4930) | Error 0.0056(0.0037) Steps 1054(1060.85) | Grad Norm 1.8986(1.4657) | Total Time 14.00(14.00)\n",
      "Iter 23840 | Time 25.4713(26.2551) | Bit/dim 3.4674(3.4853) | Xent 0.0112(0.0134) | Loss 3.4730(3.4919) | Error 0.0011(0.0038) Steps 1054(1061.81) | Grad Norm 1.5323(1.4240) | Total Time 14.00(14.00)\n",
      "Iter 23850 | Time 25.9287(26.1727) | Bit/dim 3.4582(3.4835) | Xent 0.0148(0.0136) | Loss 3.4656(3.4903) | Error 0.0056(0.0039) Steps 1054(1059.62) | Grad Norm 1.8886(1.5333) | Total Time 14.00(14.00)\n",
      "Iter 23860 | Time 25.5683(26.1299) | Bit/dim 3.4791(3.4844) | Xent 0.0120(0.0134) | Loss 3.4851(3.4911) | Error 0.0033(0.0037) Steps 1060(1059.78) | Grad Norm 1.1815(1.6130) | Total Time 14.00(14.00)\n",
      "Iter 23870 | Time 26.1873(26.1063) | Bit/dim 3.4550(3.4814) | Xent 0.0165(0.0138) | Loss 3.4632(3.4883) | Error 0.0044(0.0037) Steps 1066(1059.15) | Grad Norm 1.3698(1.5518) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 120.3832, Epoch Time 1576.5568(1583.0851), Bit/dim 3.4879(best: 3.4887), Xent 2.6585, Loss 4.8172, Error 0.2799(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23880 | Time 25.7415(26.1308) | Bit/dim 3.4942(3.4811) | Xent 0.0101(0.0133) | Loss 3.4992(3.4878) | Error 0.0022(0.0035) Steps 1054(1058.92) | Grad Norm 1.2781(1.4397) | Total Time 14.00(14.00)\n",
      "Iter 23890 | Time 26.2123(26.1939) | Bit/dim 3.4740(3.4829) | Xent 0.0148(0.0132) | Loss 3.4814(3.4895) | Error 0.0044(0.0035) Steps 1060(1059.55) | Grad Norm 1.7221(1.3996) | Total Time 14.00(14.00)\n",
      "Iter 23900 | Time 25.9851(26.1838) | Bit/dim 3.5117(3.4833) | Xent 0.0126(0.0124) | Loss 3.5180(3.4895) | Error 0.0011(0.0031) Steps 1060(1060.19) | Grad Norm 1.5643(1.3385) | Total Time 14.00(14.00)\n",
      "Iter 23910 | Time 26.0919(26.0878) | Bit/dim 3.4789(3.4813) | Xent 0.0087(0.0123) | Loss 3.4833(3.4874) | Error 0.0011(0.0030) Steps 1060(1058.24) | Grad Norm 1.0495(1.3445) | Total Time 14.00(14.00)\n",
      "Iter 23920 | Time 26.0521(26.0714) | Bit/dim 3.4677(3.4815) | Xent 0.0158(0.0137) | Loss 3.4756(3.4883) | Error 0.0022(0.0037) Steps 1042(1056.91) | Grad Norm 1.5226(1.5225) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 122.9779, Epoch Time 1577.7291(1582.9245), Bit/dim 3.4900(best: 3.4879), Xent 2.7061, Loss 4.8431, Error 0.2808(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23930 | Time 25.9080(26.1333) | Bit/dim 3.5108(3.4840) | Xent 0.0133(0.0141) | Loss 3.5175(3.4911) | Error 0.0033(0.0038) Steps 1042(1057.36) | Grad Norm 1.8675(1.5576) | Total Time 14.00(14.00)\n",
      "Iter 23940 | Time 26.8029(26.2262) | Bit/dim 3.4530(3.4813) | Xent 0.0141(0.0139) | Loss 3.4600(3.4883) | Error 0.0056(0.0039) Steps 1060(1058.17) | Grad Norm 1.8201(1.6155) | Total Time 14.00(14.00)\n",
      "Iter 23950 | Time 26.0750(26.2084) | Bit/dim 3.4994(3.4823) | Xent 0.0140(0.0134) | Loss 3.5064(3.4890) | Error 0.0056(0.0039) Steps 1072(1056.65) | Grad Norm 1.0368(1.5423) | Total Time 14.00(14.00)\n",
      "Iter 23960 | Time 26.1997(26.2118) | Bit/dim 3.4857(3.4829) | Xent 0.0125(0.0140) | Loss 3.4920(3.4899) | Error 0.0022(0.0041) Steps 1054(1056.46) | Grad Norm 1.1655(1.5520) | Total Time 14.00(14.00)\n",
      "Iter 23970 | Time 26.5384(26.2866) | Bit/dim 3.4839(3.4831) | Xent 0.0120(0.0144) | Loss 3.4899(3.4903) | Error 0.0033(0.0042) Steps 1048(1057.21) | Grad Norm 0.9189(1.6150) | Total Time 14.00(14.00)\n",
      "Iter 23980 | Time 26.4944(26.3337) | Bit/dim 3.5133(3.4838) | Xent 0.0122(0.0142) | Loss 3.5194(3.4909) | Error 0.0033(0.0041) Steps 1066(1057.06) | Grad Norm 1.7303(1.5662) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 123.3834, Epoch Time 1591.7884(1583.1904), Bit/dim 3.4897(best: 3.4879), Xent 2.6757, Loss 4.8275, Error 0.2774(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23990 | Time 26.4262(26.2986) | Bit/dim 3.4643(3.4834) | Xent 0.0061(0.0138) | Loss 3.4673(3.4903) | Error 0.0000(0.0039) Steps 1048(1055.99) | Grad Norm 1.0150(1.5471) | Total Time 14.00(14.00)\n",
      "Iter 24000 | Time 26.2309(26.2183) | Bit/dim 3.4832(3.4828) | Xent 0.0118(0.0135) | Loss 3.4891(3.4896) | Error 0.0022(0.0036) Steps 1042(1056.37) | Grad Norm 1.3002(1.5384) | Total Time 14.00(14.00)\n",
      "Iter 24010 | Time 26.0547(26.1856) | Bit/dim 3.4595(3.4824) | Xent 0.0141(0.0142) | Loss 3.4666(3.4895) | Error 0.0056(0.0041) Steps 1066(1057.10) | Grad Norm 1.5378(1.5954) | Total Time 14.00(14.00)\n",
      "Iter 24020 | Time 26.0226(26.2100) | Bit/dim 3.4628(3.4841) | Xent 0.0171(0.0146) | Loss 3.4714(3.4914) | Error 0.0044(0.0042) Steps 1066(1057.45) | Grad Norm 2.4494(1.6332) | Total Time 14.00(14.00)\n",
      "Iter 24030 | Time 26.8261(26.3019) | Bit/dim 3.4778(3.4850) | Xent 0.0177(0.0140) | Loss 3.4866(3.4920) | Error 0.0067(0.0040) Steps 1060(1058.84) | Grad Norm 2.3792(1.6295) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 121.8779, Epoch Time 1581.7305(1583.1466), Bit/dim 3.4887(best: 3.4879), Xent 2.6693, Loss 4.8234, Error 0.2791(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24040 | Time 27.5482(26.3259) | Bit/dim 3.4656(3.4819) | Xent 0.0222(0.0140) | Loss 3.4767(3.4889) | Error 0.0100(0.0040) Steps 1096(1059.07) | Grad Norm 2.1893(1.5679) | Total Time 14.00(14.00)\n",
      "Iter 24050 | Time 25.6846(26.2276) | Bit/dim 3.4738(3.4840) | Xent 0.0111(0.0143) | Loss 3.4794(3.4912) | Error 0.0044(0.0041) Steps 1054(1059.84) | Grad Norm 1.8284(1.6461) | Total Time 14.00(14.00)\n",
      "Iter 24060 | Time 27.0485(26.2377) | Bit/dim 3.4896(3.4824) | Xent 0.0149(0.0141) | Loss 3.4971(3.4894) | Error 0.0011(0.0040) Steps 1066(1060.93) | Grad Norm 1.4952(1.6505) | Total Time 14.00(14.00)\n",
      "Iter 24070 | Time 25.2427(26.2089) | Bit/dim 3.4703(3.4841) | Xent 0.0212(0.0137) | Loss 3.4809(3.4909) | Error 0.0067(0.0038) Steps 1060(1059.36) | Grad Norm 1.8756(1.6432) | Total Time 14.00(14.00)\n",
      "Iter 24080 | Time 25.6663(26.1950) | Bit/dim 3.4820(3.4850) | Xent 0.0136(0.0136) | Loss 3.4888(3.4918) | Error 0.0044(0.0038) Steps 1060(1058.73) | Grad Norm 2.1086(1.6335) | Total Time 14.00(14.00)\n",
      "Iter 24090 | Time 26.0769(26.1819) | Bit/dim 3.5091(3.4847) | Xent 0.0101(0.0134) | Loss 3.5142(3.4914) | Error 0.0011(0.0036) Steps 1072(1058.96) | Grad Norm 0.8154(1.5703) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 121.0045, Epoch Time 1579.3043(1583.0313), Bit/dim 3.4889(best: 3.4879), Xent 2.7200, Loss 4.8489, Error 0.2779(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24100 | Time 26.0613(26.2527) | Bit/dim 3.4899(3.4836) | Xent 0.0116(0.0134) | Loss 3.4957(3.4903) | Error 0.0022(0.0036) Steps 1066(1062.05) | Grad Norm 1.1372(1.5075) | Total Time 14.00(14.00)\n",
      "Iter 24110 | Time 27.1423(26.3299) | Bit/dim 3.4895(3.4835) | Xent 0.0147(0.0142) | Loss 3.4968(3.4906) | Error 0.0022(0.0039) Steps 1060(1061.28) | Grad Norm 1.8384(1.5712) | Total Time 14.00(14.00)\n",
      "Iter 24120 | Time 26.2455(26.3410) | Bit/dim 3.5237(3.4848) | Xent 0.0295(0.0153) | Loss 3.5385(3.4924) | Error 0.0078(0.0042) Steps 1042(1060.71) | Grad Norm 1.9772(1.6235) | Total Time 14.00(14.00)\n",
      "Iter 24130 | Time 25.8980(26.2548) | Bit/dim 3.4807(3.4849) | Xent 0.0066(0.0149) | Loss 3.4840(3.4924) | Error 0.0011(0.0043) Steps 1042(1058.98) | Grad Norm 1.7515(1.7031) | Total Time 14.00(14.00)\n",
      "Iter 24140 | Time 26.7923(26.3054) | Bit/dim 3.5079(3.4836) | Xent 0.0116(0.0139) | Loss 3.5137(3.4906) | Error 0.0044(0.0039) Steps 1054(1058.90) | Grad Norm 1.3441(1.6304) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 122.0796, Epoch Time 1588.8597(1583.2062), Bit/dim 3.4903(best: 3.4879), Xent 2.6493, Loss 4.8150, Error 0.2765(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24150 | Time 26.2545(26.2369) | Bit/dim 3.4897(3.4821) | Xent 0.0100(0.0141) | Loss 3.4947(3.4891) | Error 0.0044(0.0042) Steps 1060(1058.71) | Grad Norm 1.8276(1.6588) | Total Time 14.00(14.00)\n",
      "Iter 24160 | Time 26.4286(26.3051) | Bit/dim 3.4761(3.4828) | Xent 0.0168(0.0143) | Loss 3.4845(3.4900) | Error 0.0056(0.0043) Steps 1036(1059.12) | Grad Norm 1.8732(1.7029) | Total Time 14.00(14.00)\n",
      "Iter 24170 | Time 26.1045(26.3082) | Bit/dim 3.5185(3.4844) | Xent 0.0069(0.0137) | Loss 3.5220(3.4913) | Error 0.0011(0.0041) Steps 1054(1059.89) | Grad Norm 1.0213(1.6239) | Total Time 14.00(14.00)\n",
      "Iter 24180 | Time 26.3116(26.2544) | Bit/dim 3.4784(3.4850) | Xent 0.0099(0.0137) | Loss 3.4834(3.4918) | Error 0.0022(0.0041) Steps 1060(1058.67) | Grad Norm 1.3057(1.5832) | Total Time 14.00(14.00)\n",
      "Iter 24190 | Time 26.7717(26.2889) | Bit/dim 3.4734(3.4843) | Xent 0.0130(0.0142) | Loss 3.4799(3.4914) | Error 0.0044(0.0042) Steps 1060(1060.14) | Grad Norm 1.1228(1.5922) | Total Time 14.00(14.00)\n",
      "Iter 24200 | Time 26.3624(26.2454) | Bit/dim 3.4717(3.4838) | Xent 0.0141(0.0144) | Loss 3.4788(3.4910) | Error 0.0056(0.0042) Steps 1078(1060.33) | Grad Norm 1.1933(1.5671) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 122.5161, Epoch Time 1584.4130(1583.2424), Bit/dim 3.4884(best: 3.4879), Xent 2.7040, Loss 4.8404, Error 0.2821(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24210 | Time 26.0664(26.1961) | Bit/dim 3.4828(3.4833) | Xent 0.0133(0.0141) | Loss 3.4894(3.4904) | Error 0.0044(0.0040) Steps 1048(1060.20) | Grad Norm 1.8068(1.5100) | Total Time 14.00(14.00)\n",
      "Iter 24220 | Time 26.5175(26.1803) | Bit/dim 3.4773(3.4831) | Xent 0.0146(0.0136) | Loss 3.4846(3.4899) | Error 0.0033(0.0038) Steps 1048(1059.25) | Grad Norm 1.2422(1.4260) | Total Time 14.00(14.00)\n",
      "Iter 24230 | Time 26.2069(26.1862) | Bit/dim 3.4596(3.4829) | Xent 0.0133(0.0137) | Loss 3.4662(3.4897) | Error 0.0011(0.0038) Steps 1054(1058.96) | Grad Norm 1.4242(1.4408) | Total Time 14.00(14.00)\n",
      "Iter 24240 | Time 25.5159(26.1355) | Bit/dim 3.4930(3.4809) | Xent 0.0096(0.0132) | Loss 3.4978(3.4875) | Error 0.0022(0.0036) Steps 1054(1060.32) | Grad Norm 0.9052(1.3922) | Total Time 14.00(14.00)\n",
      "Iter 24250 | Time 25.6622(26.0473) | Bit/dim 3.4662(3.4802) | Xent 0.0183(0.0132) | Loss 3.4754(3.4868) | Error 0.0078(0.0036) Steps 1060(1058.94) | Grad Norm 1.4124(1.3581) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 121.7782, Epoch Time 1572.2090(1582.9114), Bit/dim 3.4875(best: 3.4879), Xent 2.7179, Loss 4.8464, Error 0.2808(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24260 | Time 25.5924(26.0211) | Bit/dim 3.5123(3.4838) | Xent 0.0171(0.0136) | Loss 3.5209(3.4906) | Error 0.0044(0.0038) Steps 1060(1057.75) | Grad Norm 1.6922(1.3918) | Total Time 14.00(14.00)\n",
      "Iter 24270 | Time 26.3413(26.1081) | Bit/dim 3.4814(3.4843) | Xent 0.0126(0.0139) | Loss 3.4877(3.4913) | Error 0.0044(0.0040) Steps 1084(1060.73) | Grad Norm 1.6624(1.5148) | Total Time 14.00(14.00)\n",
      "Iter 24280 | Time 27.1004(26.1722) | Bit/dim 3.4327(3.4820) | Xent 0.0196(0.0144) | Loss 3.4425(3.4892) | Error 0.0056(0.0041) Steps 1066(1060.78) | Grad Norm 2.0653(1.5990) | Total Time 14.00(14.00)\n",
      "Iter 24290 | Time 26.2484(26.1659) | Bit/dim 3.4762(3.4818) | Xent 0.0075(0.0137) | Loss 3.4799(3.4886) | Error 0.0011(0.0040) Steps 1060(1059.45) | Grad Norm 1.1294(1.5980) | Total Time 14.00(14.00)\n",
      "Iter 24300 | Time 25.7545(26.1712) | Bit/dim 3.5061(3.4817) | Xent 0.0125(0.0138) | Loss 3.5123(3.4885) | Error 0.0044(0.0041) Steps 1060(1059.51) | Grad Norm 1.3857(1.5329) | Total Time 14.00(14.00)\n",
      "Iter 24310 | Time 25.5331(26.1889) | Bit/dim 3.5006(3.4837) | Xent 0.0131(0.0135) | Loss 3.5071(3.4905) | Error 0.0044(0.0039) Steps 1054(1060.80) | Grad Norm 2.0168(1.5392) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 122.3512, Epoch Time 1581.9808(1582.8834), Bit/dim 3.4881(best: 3.4875), Xent 2.7222, Loss 4.8492, Error 0.2814(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24320 | Time 25.6982(26.1594) | Bit/dim 3.4697(3.4819) | Xent 0.0134(0.0130) | Loss 3.4764(3.4884) | Error 0.0044(0.0037) Steps 1048(1059.30) | Grad Norm 2.0142(1.5059) | Total Time 14.00(14.00)\n",
      "Iter 24330 | Time 26.4791(26.1344) | Bit/dim 3.4574(3.4805) | Xent 0.0135(0.0131) | Loss 3.4642(3.4871) | Error 0.0033(0.0037) Steps 1084(1060.67) | Grad Norm 1.3711(1.4569) | Total Time 14.00(14.00)\n",
      "Iter 24340 | Time 25.8396(26.0551) | Bit/dim 3.4781(3.4796) | Xent 0.0131(0.0135) | Loss 3.4846(3.4864) | Error 0.0033(0.0037) Steps 1042(1059.83) | Grad Norm 1.2599(1.4254) | Total Time 14.00(14.00)\n",
      "Iter 24350 | Time 26.2411(26.0921) | Bit/dim 3.5047(3.4842) | Xent 0.0232(0.0138) | Loss 3.5163(3.4911) | Error 0.0078(0.0037) Steps 1078(1060.42) | Grad Norm 1.9496(1.4519) | Total Time 14.00(14.00)\n",
      "Iter 24360 | Time 26.5649(26.2024) | Bit/dim 3.4796(3.4836) | Xent 0.0094(0.0137) | Loss 3.4843(3.4905) | Error 0.0022(0.0037) Steps 1090(1061.19) | Grad Norm 1.2342(1.4482) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 123.6440, Epoch Time 1581.6449(1582.8463), Bit/dim 3.4884(best: 3.4875), Xent 2.6966, Loss 4.8367, Error 0.2789(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24370 | Time 26.6024(26.2276) | Bit/dim 3.4800(3.4818) | Xent 0.0143(0.0135) | Loss 3.4871(3.4886) | Error 0.0044(0.0039) Steps 1060(1060.98) | Grad Norm 1.7087(1.4743) | Total Time 14.00(14.00)\n",
      "Iter 24380 | Time 26.2115(26.2167) | Bit/dim 3.4936(3.4829) | Xent 0.0170(0.0134) | Loss 3.5021(3.4896) | Error 0.0056(0.0038) Steps 1048(1059.74) | Grad Norm 1.6697(1.4205) | Total Time 14.00(14.00)\n",
      "Iter 24390 | Time 25.9168(26.1864) | Bit/dim 3.4647(3.4823) | Xent 0.0152(0.0137) | Loss 3.4723(3.4892) | Error 0.0056(0.0039) Steps 1048(1059.33) | Grad Norm 1.4323(1.4435) | Total Time 14.00(14.00)\n",
      "Iter 24400 | Time 25.3038(26.1696) | Bit/dim 3.4752(3.4827) | Xent 0.0115(0.0128) | Loss 3.4810(3.4891) | Error 0.0044(0.0034) Steps 1042(1058.74) | Grad Norm 0.9238(1.3549) | Total Time 14.00(14.00)\n",
      "Iter 24410 | Time 26.7244(26.2113) | Bit/dim 3.4495(3.4829) | Xent 0.0070(0.0129) | Loss 3.4530(3.4894) | Error 0.0011(0.0035) Steps 1048(1058.36) | Grad Norm 0.9338(1.3503) | Total Time 14.00(14.00)\n",
      "Iter 24420 | Time 25.8672(26.1946) | Bit/dim 3.4698(3.4832) | Xent 0.0230(0.0128) | Loss 3.4813(3.4896) | Error 0.0067(0.0035) Steps 1042(1057.90) | Grad Norm 1.5321(1.3248) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 121.5995, Epoch Time 1578.3186(1582.7105), Bit/dim 3.4882(best: 3.4875), Xent 2.7433, Loss 4.8598, Error 0.2823(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24430 | Time 25.8504(26.1622) | Bit/dim 3.4925(3.4829) | Xent 0.0088(0.0120) | Loss 3.4969(3.4889) | Error 0.0033(0.0032) Steps 1072(1058.69) | Grad Norm 0.9655(1.2429) | Total Time 14.00(14.00)\n",
      "Iter 24440 | Time 26.1697(26.2407) | Bit/dim 3.4892(3.4820) | Xent 0.0135(0.0122) | Loss 3.4960(3.4882) | Error 0.0044(0.0033) Steps 1078(1060.26) | Grad Norm 1.2076(1.2493) | Total Time 14.00(14.00)\n",
      "Iter 24450 | Time 27.0547(26.2891) | Bit/dim 3.4901(3.4838) | Xent 0.0135(0.0124) | Loss 3.4968(3.4900) | Error 0.0022(0.0033) Steps 1066(1061.89) | Grad Norm 1.2228(1.3165) | Total Time 14.00(14.00)\n",
      "Iter 24460 | Time 26.8524(26.3055) | Bit/dim 3.4649(3.4841) | Xent 0.0129(0.0123) | Loss 3.4714(3.4903) | Error 0.0044(0.0031) Steps 1054(1060.92) | Grad Norm 1.5292(1.3219) | Total Time 14.00(14.00)\n",
      "Iter 24470 | Time 26.2647(26.3285) | Bit/dim 3.4971(3.4814) | Xent 0.0146(0.0125) | Loss 3.5044(3.4876) | Error 0.0033(0.0033) Steps 1060(1060.51) | Grad Norm 1.9179(1.3202) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 120.8355, Epoch Time 1587.7342(1582.8612), Bit/dim 3.4892(best: 3.4875), Xent 2.7625, Loss 4.8705, Error 0.2797(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24480 | Time 26.4936(26.3657) | Bit/dim 3.4745(3.4816) | Xent 0.0104(0.0128) | Loss 3.4797(3.4881) | Error 0.0033(0.0037) Steps 1072(1062.26) | Grad Norm 1.0665(1.3725) | Total Time 14.00(14.00)\n",
      "Iter 24490 | Time 26.0029(26.3374) | Bit/dim 3.4832(3.4824) | Xent 0.0083(0.0128) | Loss 3.4874(3.4888) | Error 0.0022(0.0038) Steps 1054(1062.29) | Grad Norm 1.1148(1.3821) | Total Time 14.00(14.00)\n",
      "Iter 24500 | Time 26.0156(26.3683) | Bit/dim 3.4858(3.4822) | Xent 0.0215(0.0129) | Loss 3.4966(3.4887) | Error 0.0078(0.0038) Steps 1096(1063.94) | Grad Norm 1.9724(1.4267) | Total Time 14.00(14.00)\n",
      "Iter 24510 | Time 26.5662(26.3918) | Bit/dim 3.4607(3.4798) | Xent 0.0096(0.0128) | Loss 3.4654(3.4862) | Error 0.0022(0.0038) Steps 1042(1063.13) | Grad Norm 1.3123(1.3767) | Total Time 14.00(14.00)\n",
      "Iter 24520 | Time 27.0398(26.4433) | Bit/dim 3.4804(3.4815) | Xent 0.0072(0.0125) | Loss 3.4840(3.4877) | Error 0.0022(0.0036) Steps 1078(1063.40) | Grad Norm 0.8852(1.3085) | Total Time 14.00(14.00)\n",
      "Iter 24530 | Time 26.5914(26.4020) | Bit/dim 3.4828(3.4824) | Xent 0.0189(0.0131) | Loss 3.4922(3.4889) | Error 0.0044(0.0036) Steps 1054(1063.04) | Grad Norm 2.1398(1.3699) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 122.2247, Epoch Time 1592.9157(1583.1628), Bit/dim 3.4881(best: 3.4875), Xent 2.7196, Loss 4.8479, Error 0.2794(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24540 | Time 26.8921(26.3818) | Bit/dim 3.4877(3.4854) | Xent 0.0117(0.0131) | Loss 3.4935(3.4919) | Error 0.0022(0.0037) Steps 1072(1062.81) | Grad Norm 1.0402(1.3689) | Total Time 14.00(14.00)\n",
      "Iter 24550 | Time 25.8197(26.3389) | Bit/dim 3.4586(3.4796) | Xent 0.0135(0.0134) | Loss 3.4654(3.4863) | Error 0.0022(0.0038) Steps 1066(1060.17) | Grad Norm 1.2944(1.4611) | Total Time 14.00(14.00)\n",
      "Iter 24560 | Time 26.7096(26.3183) | Bit/dim 3.5033(3.4782) | Xent 0.0100(0.0139) | Loss 3.5083(3.4851) | Error 0.0022(0.0040) Steps 1066(1061.26) | Grad Norm 1.0015(1.5644) | Total Time 14.00(14.00)\n",
      "Iter 24570 | Time 26.0802(26.3922) | Bit/dim 3.5037(3.4821) | Xent 0.0123(0.0140) | Loss 3.5099(3.4891) | Error 0.0044(0.0041) Steps 1072(1060.21) | Grad Norm 1.3879(1.5484) | Total Time 14.00(14.00)\n",
      "Iter 24580 | Time 26.5220(26.3808) | Bit/dim 3.4645(3.4823) | Xent 0.0156(0.0141) | Loss 3.4722(3.4894) | Error 0.0033(0.0042) Steps 1066(1059.83) | Grad Norm 1.5921(1.6004) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 122.6199, Epoch Time 1590.1831(1583.3734), Bit/dim 3.4872(best: 3.4875), Xent 2.7304, Loss 4.8523, Error 0.2791(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24590 | Time 25.6909(26.3675) | Bit/dim 3.5135(3.4838) | Xent 0.0176(0.0146) | Loss 3.5223(3.4911) | Error 0.0067(0.0044) Steps 1054(1060.51) | Grad Norm 1.6955(1.6609) | Total Time 14.00(14.00)\n",
      "Iter 24600 | Time 25.7762(26.2753) | Bit/dim 3.4790(3.4818) | Xent 0.0139(0.0144) | Loss 3.4860(3.4889) | Error 0.0033(0.0040) Steps 1054(1058.93) | Grad Norm 1.4030(1.6877) | Total Time 14.00(14.00)\n",
      "Iter 24610 | Time 26.8003(26.2318) | Bit/dim 3.4587(3.4799) | Xent 0.0133(0.0139) | Loss 3.4653(3.4868) | Error 0.0044(0.0038) Steps 1066(1057.63) | Grad Norm 1.3686(1.6325) | Total Time 14.00(14.00)\n",
      "Iter 24620 | Time 26.8121(26.2446) | Bit/dim 3.5026(3.4806) | Xent 0.0109(0.0141) | Loss 3.5080(3.4876) | Error 0.0033(0.0038) Steps 1060(1058.52) | Grad Norm 1.2044(1.6365) | Total Time 14.00(14.00)\n",
      "Iter 24630 | Time 26.1935(26.2889) | Bit/dim 3.5147(3.4845) | Xent 0.0113(0.0134) | Loss 3.5204(3.4912) | Error 0.0033(0.0036) Steps 1072(1058.68) | Grad Norm 1.0478(1.5248) | Total Time 14.00(14.00)\n",
      "Iter 24640 | Time 26.3188(26.2970) | Bit/dim 3.4885(3.4834) | Xent 0.0105(0.0131) | Loss 3.4937(3.4900) | Error 0.0022(0.0035) Steps 1078(1059.58) | Grad Norm 1.0306(1.4841) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 123.3785, Epoch Time 1584.1395(1583.3964), Bit/dim 3.4870(best: 3.4872), Xent 2.7259, Loss 4.8500, Error 0.2775(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24650 | Time 26.4369(26.3246) | Bit/dim 3.4659(3.4841) | Xent 0.0175(0.0127) | Loss 3.4746(3.4905) | Error 0.0078(0.0034) Steps 1054(1060.06) | Grad Norm 1.2939(1.4024) | Total Time 14.00(14.00)\n",
      "Iter 24660 | Time 26.3477(26.2732) | Bit/dim 3.4865(3.4822) | Xent 0.0087(0.0123) | Loss 3.4909(3.4883) | Error 0.0033(0.0032) Steps 1078(1061.05) | Grad Norm 0.8503(1.3126) | Total Time 14.00(14.00)\n",
      "Iter 24670 | Time 26.1178(26.2231) | Bit/dim 3.4731(3.4827) | Xent 0.0229(0.0126) | Loss 3.4845(3.4890) | Error 0.0056(0.0033) Steps 1060(1061.40) | Grad Norm 1.8126(1.3036) | Total Time 14.00(14.00)\n",
      "Iter 24680 | Time 26.1678(26.2497) | Bit/dim 3.4892(3.4814) | Xent 0.0067(0.0122) | Loss 3.4926(3.4875) | Error 0.0000(0.0031) Steps 1048(1060.34) | Grad Norm 1.1896(1.2754) | Total Time 14.00(14.00)\n",
      "Iter 24690 | Time 24.5099(26.1909) | Bit/dim 3.4710(3.4813) | Xent 0.0190(0.0126) | Loss 3.4805(3.4876) | Error 0.0044(0.0033) Steps 1048(1060.87) | Grad Norm 2.3629(1.3286) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 122.1616, Epoch Time 1581.3566(1583.3352), Bit/dim 3.4870(best: 3.4870), Xent 2.7703, Loss 4.8721, Error 0.2789(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24700 | Time 26.3772(26.2227) | Bit/dim 3.4835(3.4826) | Xent 0.0187(0.0130) | Loss 3.4928(3.4891) | Error 0.0056(0.0035) Steps 1066(1062.10) | Grad Norm 2.4954(1.4160) | Total Time 14.00(14.00)\n",
      "Iter 24710 | Time 26.3100(26.2165) | Bit/dim 3.4452(3.4816) | Xent 0.0121(0.0134) | Loss 3.4513(3.4883) | Error 0.0022(0.0038) Steps 1054(1062.78) | Grad Norm 1.6699(1.4626) | Total Time 14.00(14.00)\n",
      "Iter 24720 | Time 27.1992(26.2492) | Bit/dim 3.4772(3.4834) | Xent 0.0077(0.0137) | Loss 3.4810(3.4903) | Error 0.0011(0.0037) Steps 1066(1062.64) | Grad Norm 1.2863(1.4106) | Total Time 14.00(14.00)\n",
      "Iter 24730 | Time 26.5571(26.3100) | Bit/dim 3.4708(3.4838) | Xent 0.0157(0.0135) | Loss 3.4786(3.4905) | Error 0.0067(0.0038) Steps 1060(1062.82) | Grad Norm 1.7445(1.3987) | Total Time 14.00(14.00)\n",
      "Iter 24740 | Time 26.9659(26.3082) | Bit/dim 3.4601(3.4790) | Xent 0.0210(0.0132) | Loss 3.4706(3.4856) | Error 0.0078(0.0037) Steps 1054(1062.65) | Grad Norm 1.9664(1.4253) | Total Time 14.00(14.00)\n",
      "Iter 24750 | Time 27.0066(26.3113) | Bit/dim 3.5124(3.4819) | Xent 0.0100(0.0134) | Loss 3.5174(3.4886) | Error 0.0011(0.0039) Steps 1060(1062.02) | Grad Norm 2.2986(1.5103) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 122.9213, Epoch Time 1589.2452(1583.5125), Bit/dim 3.4876(best: 3.4870), Xent 2.7279, Loss 4.8515, Error 0.2787(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24760 | Time 25.7552(26.2394) | Bit/dim 3.4900(3.4802) | Xent 0.0129(0.0134) | Loss 3.4965(3.4869) | Error 0.0044(0.0040) Steps 1054(1060.14) | Grad Norm 1.4430(1.5382) | Total Time 14.00(14.00)\n",
      "Iter 24770 | Time 26.6138(26.3015) | Bit/dim 3.4813(3.4789) | Xent 0.0127(0.0135) | Loss 3.4876(3.4856) | Error 0.0033(0.0041) Steps 1042(1061.28) | Grad Norm 0.9705(1.4783) | Total Time 14.00(14.00)\n",
      "Iter 24780 | Time 25.8260(26.3568) | Bit/dim 3.5059(3.4811) | Xent 0.0111(0.0138) | Loss 3.5115(3.4880) | Error 0.0011(0.0041) Steps 1060(1060.44) | Grad Norm 1.4364(1.4616) | Total Time 14.00(14.00)\n",
      "Iter 24790 | Time 26.0187(26.2558) | Bit/dim 3.4784(3.4846) | Xent 0.0156(0.0136) | Loss 3.4862(3.4914) | Error 0.0044(0.0040) Steps 1042(1060.16) | Grad Norm 1.2512(1.4207) | Total Time 14.00(14.00)\n",
      "Iter 24800 | Time 27.0847(26.2344) | Bit/dim 3.4904(3.4849) | Xent 0.0133(0.0140) | Loss 3.4970(3.4919) | Error 0.0022(0.0041) Steps 1060(1060.17) | Grad Norm 1.3494(1.4636) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 121.5992, Epoch Time 1582.8971(1583.4940), Bit/dim 3.4894(best: 3.4870), Xent 2.7407, Loss 4.8598, Error 0.2816(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24810 | Time 26.2856(26.2313) | Bit/dim 3.4513(3.4819) | Xent 0.0149(0.0137) | Loss 3.4588(3.4887) | Error 0.0044(0.0041) Steps 1060(1059.57) | Grad Norm 1.0679(1.4108) | Total Time 14.00(14.00)\n",
      "Iter 24820 | Time 26.1264(26.2686) | Bit/dim 3.4711(3.4819) | Xent 0.0136(0.0136) | Loss 3.4779(3.4887) | Error 0.0056(0.0040) Steps 1054(1059.62) | Grad Norm 1.4653(1.3865) | Total Time 14.00(14.00)\n",
      "Iter 24830 | Time 25.6895(26.3303) | Bit/dim 3.4833(3.4794) | Xent 0.0202(0.0136) | Loss 3.4934(3.4862) | Error 0.0067(0.0041) Steps 1048(1061.33) | Grad Norm 2.4805(1.4540) | Total Time 14.00(14.00)\n",
      "Iter 24840 | Time 25.9112(26.2732) | Bit/dim 3.4442(3.4793) | Xent 0.0126(0.0132) | Loss 3.4505(3.4859) | Error 0.0044(0.0039) Steps 1054(1061.15) | Grad Norm 1.2245(1.4318) | Total Time 14.00(14.00)\n",
      "Iter 24850 | Time 25.8348(26.2514) | Bit/dim 3.5123(3.4828) | Xent 0.0149(0.0127) | Loss 3.5198(3.4892) | Error 0.0033(0.0037) Steps 1060(1060.07) | Grad Norm 1.8587(1.3933) | Total Time 14.00(14.00)\n",
      "Iter 24860 | Time 25.7202(26.2270) | Bit/dim 3.4906(3.4840) | Xent 0.0136(0.0132) | Loss 3.4975(3.4906) | Error 0.0056(0.0040) Steps 1054(1059.46) | Grad Norm 2.2577(1.5178) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 120.8452, Epoch Time 1583.4607(1583.4930), Bit/dim 3.4882(best: 3.4870), Xent 2.7599, Loss 4.8682, Error 0.2837(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24870 | Time 26.8486(26.2597) | Bit/dim 3.4887(3.4819) | Xent 0.0110(0.0128) | Loss 3.4942(3.4883) | Error 0.0033(0.0037) Steps 1072(1061.13) | Grad Norm 1.0238(1.5144) | Total Time 14.00(14.00)\n",
      "Iter 24880 | Time 26.0501(26.2737) | Bit/dim 3.4842(3.4837) | Xent 0.0180(0.0132) | Loss 3.4932(3.4903) | Error 0.0067(0.0040) Steps 1054(1060.83) | Grad Norm 1.6365(1.4967) | Total Time 14.00(14.00)\n",
      "Iter 24890 | Time 26.2349(26.2884) | Bit/dim 3.5305(3.4830) | Xent 0.0080(0.0136) | Loss 3.5345(3.4898) | Error 0.0011(0.0041) Steps 1066(1063.65) | Grad Norm 2.2130(1.5557) | Total Time 14.00(14.00)\n",
      "Iter 24900 | Time 26.3402(26.2785) | Bit/dim 3.4225(3.4821) | Xent 0.0111(0.0135) | Loss 3.4280(3.4889) | Error 0.0022(0.0041) Steps 1060(1063.21) | Grad Norm 1.5174(1.6499) | Total Time 14.00(14.00)\n",
      "Iter 24910 | Time 26.8822(26.3131) | Bit/dim 3.4687(3.4824) | Xent 0.0124(0.0132) | Loss 3.4749(3.4890) | Error 0.0056(0.0041) Steps 1042(1062.12) | Grad Norm 1.0945(1.5546) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 121.8768, Epoch Time 1587.0861(1583.6008), Bit/dim 3.4868(best: 3.4870), Xent 2.7208, Loss 4.8471, Error 0.2768(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24920 | Time 26.1934(26.3108) | Bit/dim 3.4606(3.4826) | Xent 0.0173(0.0133) | Loss 3.4693(3.4892) | Error 0.0044(0.0040) Steps 1060(1062.39) | Grad Norm 1.4337(1.5413) | Total Time 14.00(14.00)\n",
      "Iter 24930 | Time 25.8352(26.2967) | Bit/dim 3.4917(3.4842) | Xent 0.0095(0.0128) | Loss 3.4965(3.4906) | Error 0.0022(0.0036) Steps 1072(1062.07) | Grad Norm 0.9996(1.4408) | Total Time 14.00(14.00)\n",
      "Iter 24940 | Time 26.5450(26.2773) | Bit/dim 3.4785(3.4836) | Xent 0.0172(0.0138) | Loss 3.4871(3.4905) | Error 0.0044(0.0041) Steps 1054(1063.61) | Grad Norm 2.5420(1.5120) | Total Time 14.00(14.00)\n",
      "Iter 24950 | Time 26.4730(26.3100) | Bit/dim 3.4651(3.4850) | Xent 0.0118(0.0132) | Loss 3.4710(3.4916) | Error 0.0044(0.0038) Steps 1066(1063.59) | Grad Norm 1.5488(1.4625) | Total Time 14.00(14.00)\n",
      "Iter 24960 | Time 26.0265(26.3274) | Bit/dim 3.4540(3.4816) | Xent 0.0206(0.0133) | Loss 3.4643(3.4883) | Error 0.0067(0.0039) Steps 1066(1064.50) | Grad Norm 1.9537(1.4610) | Total Time 14.00(14.00)\n",
      "Iter 24970 | Time 26.7342(26.3029) | Bit/dim 3.5209(3.4802) | Xent 0.0134(0.0130) | Loss 3.5276(3.4867) | Error 0.0056(0.0038) Steps 1084(1063.68) | Grad Norm 1.9861(1.4181) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 121.9932, Epoch Time 1586.5042(1583.6879), Bit/dim 3.4859(best: 3.4868), Xent 2.7536, Loss 4.8627, Error 0.2785(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 24980 | Time 26.6027(26.2824) | Bit/dim 3.4727(3.4807) | Xent 0.0154(0.0136) | Loss 3.4804(3.4875) | Error 0.0044(0.0039) Steps 1084(1062.23) | Grad Norm 2.2150(1.4610) | Total Time 14.00(14.00)\n",
      "Iter 24990 | Time 26.2597(26.2334) | Bit/dim 3.4893(3.4793) | Xent 0.0208(0.0143) | Loss 3.4997(3.4864) | Error 0.0111(0.0044) Steps 1060(1063.12) | Grad Norm 2.0415(1.5316) | Total Time 14.00(14.00)\n",
      "Iter 25000 | Time 26.9139(26.2229) | Bit/dim 3.4361(3.4796) | Xent 0.0084(0.0143) | Loss 3.4403(3.4867) | Error 0.0033(0.0043) Steps 1054(1061.85) | Grad Norm 0.8607(1.4887) | Total Time 14.00(14.00)\n",
      "Iter 25010 | Time 26.0505(26.2235) | Bit/dim 3.4902(3.4818) | Xent 0.0127(0.0140) | Loss 3.4966(3.4888) | Error 0.0022(0.0043) Steps 1048(1061.07) | Grad Norm 1.3723(1.4450) | Total Time 14.00(14.00)\n",
      "Iter 25020 | Time 26.5654(26.2978) | Bit/dim 3.4685(3.4823) | Xent 0.0221(0.0142) | Loss 3.4795(3.4894) | Error 0.0067(0.0045) Steps 1048(1062.44) | Grad Norm 1.9197(1.4746) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 123.4749, Epoch Time 1586.6252(1583.7760), Bit/dim 3.4896(best: 3.4859), Xent 2.8457, Loss 4.9125, Error 0.2861(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25030 | Time 25.7517(26.3326) | Bit/dim 3.4817(3.4812) | Xent 0.0073(0.0144) | Loss 3.4854(3.4884) | Error 0.0000(0.0045) Steps 1048(1062.22) | Grad Norm 1.7029(1.6477) | Total Time 14.00(14.00)\n",
      "Iter 25040 | Time 25.7685(26.3605) | Bit/dim 3.4979(3.4804) | Xent 0.0074(0.0140) | Loss 3.5016(3.4874) | Error 0.0011(0.0042) Steps 1054(1061.60) | Grad Norm 0.9497(1.6512) | Total Time 14.00(14.00)\n",
      "Iter 25050 | Time 26.7125(26.3992) | Bit/dim 3.5110(3.4815) | Xent 0.0118(0.0135) | Loss 3.5170(3.4882) | Error 0.0022(0.0039) Steps 1072(1062.44) | Grad Norm 1.2135(1.5952) | Total Time 14.00(14.00)\n",
      "Iter 25060 | Time 26.1374(26.3606) | Bit/dim 3.5126(3.4814) | Xent 0.0112(0.0131) | Loss 3.5182(3.4880) | Error 0.0033(0.0039) Steps 1060(1061.23) | Grad Norm 1.0407(1.5071) | Total Time 14.00(14.00)\n",
      "Iter 25070 | Time 26.6050(26.3615) | Bit/dim 3.5051(3.4837) | Xent 0.0088(0.0134) | Loss 3.5095(3.4904) | Error 0.0022(0.0039) Steps 1054(1061.65) | Grad Norm 1.6000(1.6242) | Total Time 14.00(14.00)\n",
      "Iter 25080 | Time 27.0981(26.3959) | Bit/dim 3.4748(3.4829) | Xent 0.0075(0.0136) | Loss 3.4785(3.4897) | Error 0.0022(0.0039) Steps 1060(1060.97) | Grad Norm 1.5149(1.6431) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 123.5445, Epoch Time 1593.1148(1584.0562), Bit/dim 3.4873(best: 3.4859), Xent 2.7801, Loss 4.8773, Error 0.2770(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25090 | Time 26.9760(26.4053) | Bit/dim 3.4859(3.4849) | Xent 0.0210(0.0141) | Loss 3.4964(3.4919) | Error 0.0067(0.0042) Steps 1066(1059.67) | Grad Norm 2.5335(1.6914) | Total Time 14.00(14.00)\n",
      "Iter 25100 | Time 26.0775(26.3571) | Bit/dim 3.4850(3.4832) | Xent 0.0099(0.0143) | Loss 3.4899(3.4904) | Error 0.0033(0.0042) Steps 1054(1058.77) | Grad Norm 2.1805(1.7571) | Total Time 14.00(14.00)\n",
      "Iter 25110 | Time 26.9052(26.3411) | Bit/dim 3.4920(3.4821) | Xent 0.0124(0.0140) | Loss 3.4982(3.4891) | Error 0.0033(0.0040) Steps 1072(1059.52) | Grad Norm 1.2446(1.6894) | Total Time 14.00(14.00)\n",
      "Iter 25120 | Time 26.7312(26.3531) | Bit/dim 3.4495(3.4802) | Xent 0.0106(0.0139) | Loss 3.4548(3.4871) | Error 0.0022(0.0040) Steps 1048(1060.55) | Grad Norm 1.4441(1.6468) | Total Time 14.00(14.00)\n",
      "Iter 25130 | Time 26.8640(26.4365) | Bit/dim 3.4807(3.4816) | Xent 0.0191(0.0141) | Loss 3.4902(3.4887) | Error 0.0078(0.0042) Steps 1060(1060.03) | Grad Norm 1.9667(1.7124) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 122.6415, Epoch Time 1592.2627(1584.3024), Bit/dim 3.4882(best: 3.4859), Xent 2.7888, Loss 4.8826, Error 0.2823(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25140 | Time 26.2930(26.3945) | Bit/dim 3.4602(3.4815) | Xent 0.0116(0.0137) | Loss 3.4660(3.4884) | Error 0.0033(0.0039) Steps 1078(1061.68) | Grad Norm 1.4512(1.6661) | Total Time 14.00(14.00)\n",
      "Iter 25150 | Time 25.9967(26.3905) | Bit/dim 3.4978(3.4811) | Xent 0.0126(0.0135) | Loss 3.5041(3.4878) | Error 0.0033(0.0038) Steps 1054(1060.32) | Grad Norm 1.7032(1.6232) | Total Time 14.00(14.00)\n",
      "Iter 25160 | Time 26.7319(26.4150) | Bit/dim 3.4929(3.4795) | Xent 0.0127(0.0135) | Loss 3.4992(3.4863) | Error 0.0033(0.0039) Steps 1072(1059.95) | Grad Norm 1.2224(1.5767) | Total Time 14.00(14.00)\n",
      "Iter 25170 | Time 28.0778(26.5026) | Bit/dim 3.4891(3.4840) | Xent 0.0127(0.0130) | Loss 3.4955(3.4905) | Error 0.0056(0.0038) Steps 1078(1062.96) | Grad Norm 1.3003(1.5090) | Total Time 14.00(14.00)\n",
      "Iter 25180 | Time 26.6867(26.4185) | Bit/dim 3.5230(3.4835) | Xent 0.0104(0.0128) | Loss 3.5282(3.4899) | Error 0.0022(0.0037) Steps 1054(1063.22) | Grad Norm 1.2251(1.4585) | Total Time 14.00(14.00)\n",
      "Iter 25190 | Time 26.4456(26.4687) | Bit/dim 3.4609(3.4813) | Xent 0.0193(0.0134) | Loss 3.4705(3.4880) | Error 0.0067(0.0038) Steps 1066(1063.60) | Grad Norm 1.5427(1.4909) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 123.4131, Epoch Time 1596.0006(1584.6534), Bit/dim 3.4868(best: 3.4859), Xent 2.7456, Loss 4.8596, Error 0.2811(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25200 | Time 26.0868(26.4541) | Bit/dim 3.4749(3.4796) | Xent 0.0144(0.0138) | Loss 3.4821(3.4865) | Error 0.0044(0.0039) Steps 1066(1063.45) | Grad Norm 1.3054(1.5299) | Total Time 14.00(14.00)\n",
      "Iter 25210 | Time 26.4103(26.4119) | Bit/dim 3.4891(3.4805) | Xent 0.0086(0.0131) | Loss 3.4934(3.4870) | Error 0.0022(0.0036) Steps 1060(1062.96) | Grad Norm 1.0136(1.4291) | Total Time 14.00(14.00)\n",
      "Iter 25220 | Time 26.5051(26.3747) | Bit/dim 3.4906(3.4808) | Xent 0.0107(0.0130) | Loss 3.4960(3.4873) | Error 0.0033(0.0037) Steps 1066(1062.70) | Grad Norm 1.6584(1.4286) | Total Time 14.00(14.00)\n",
      "Iter 25230 | Time 26.1634(26.4156) | Bit/dim 3.5017(3.4833) | Xent 0.0260(0.0136) | Loss 3.5147(3.4901) | Error 0.0089(0.0040) Steps 1048(1061.59) | Grad Norm 2.9010(1.5010) | Total Time 14.00(14.00)\n",
      "Iter 25240 | Time 26.2327(26.3901) | Bit/dim 3.5008(3.4847) | Xent 0.0181(0.0144) | Loss 3.5098(3.4918) | Error 0.0078(0.0043) Steps 1078(1062.99) | Grad Norm 2.6331(1.5965) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 123.4118, Epoch Time 1591.9139(1584.8712), Bit/dim 3.4880(best: 3.4859), Xent 2.7680, Loss 4.8720, Error 0.2819(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25250 | Time 26.3385(26.3648) | Bit/dim 3.4863(3.4843) | Xent 0.0096(0.0137) | Loss 3.4910(3.4912) | Error 0.0033(0.0041) Steps 1072(1063.51) | Grad Norm 1.1378(1.5905) | Total Time 14.00(14.00)\n",
      "Iter 25260 | Time 25.6017(26.3156) | Bit/dim 3.4768(3.4847) | Xent 0.0132(0.0134) | Loss 3.4834(3.4914) | Error 0.0022(0.0039) Steps 1060(1063.49) | Grad Norm 1.2685(1.6368) | Total Time 14.00(14.00)\n",
      "Iter 25270 | Time 26.8523(26.4277) | Bit/dim 3.4446(3.4787) | Xent 0.0104(0.0135) | Loss 3.4498(3.4855) | Error 0.0022(0.0040) Steps 1072(1063.80) | Grad Norm 1.6679(1.6703) | Total Time 14.00(14.00)\n",
      "Iter 25280 | Time 26.9239(26.4762) | Bit/dim 3.4903(3.4806) | Xent 0.0178(0.0131) | Loss 3.4992(3.4871) | Error 0.0044(0.0037) Steps 1060(1065.39) | Grad Norm 2.5526(1.6229) | Total Time 14.00(14.00)\n",
      "Iter 25290 | Time 26.3389(26.4064) | Bit/dim 3.4914(3.4816) | Xent 0.0116(0.0128) | Loss 3.4972(3.4880) | Error 0.0033(0.0037) Steps 1078(1064.97) | Grad Norm 1.2055(1.5409) | Total Time 14.00(14.00)\n",
      "Iter 25300 | Time 26.0071(26.4319) | Bit/dim 3.4884(3.4817) | Xent 0.0143(0.0132) | Loss 3.4956(3.4883) | Error 0.0067(0.0040) Steps 1060(1063.13) | Grad Norm 1.4946(1.5604) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 123.1138, Epoch Time 1594.1572(1585.1498), Bit/dim 3.4867(best: 3.4859), Xent 2.8150, Loss 4.8942, Error 0.2792(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25310 | Time 25.9707(26.3544) | Bit/dim 3.4769(3.4810) | Xent 0.0174(0.0134) | Loss 3.4856(3.4878) | Error 0.0056(0.0039) Steps 1066(1061.28) | Grad Norm 1.5270(1.5938) | Total Time 14.00(14.00)\n",
      "Iter 25320 | Time 27.1057(26.3089) | Bit/dim 3.4666(3.4824) | Xent 0.0120(0.0142) | Loss 3.4726(3.4896) | Error 0.0011(0.0042) Steps 1054(1060.60) | Grad Norm 1.5895(1.6516) | Total Time 14.00(14.00)\n",
      "Iter 25330 | Time 26.7585(26.2727) | Bit/dim 3.4845(3.4840) | Xent 0.0146(0.0145) | Loss 3.4918(3.4913) | Error 0.0044(0.0042) Steps 1054(1059.00) | Grad Norm 1.4787(1.6349) | Total Time 14.00(14.00)\n",
      "Iter 25340 | Time 26.1013(26.2981) | Bit/dim 3.4550(3.4808) | Xent 0.0191(0.0158) | Loss 3.4645(3.4887) | Error 0.0056(0.0048) Steps 1066(1060.93) | Grad Norm 2.3395(1.8103) | Total Time 14.00(14.00)\n",
      "Iter 25350 | Time 27.0993(26.4027) | Bit/dim 3.4724(3.4810) | Xent 0.0106(0.0154) | Loss 3.4777(3.4887) | Error 0.0022(0.0046) Steps 1060(1062.25) | Grad Norm 1.1943(1.8220) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 124.3979, Epoch Time 1589.3134(1585.2747), Bit/dim 3.4875(best: 3.4859), Xent 2.7496, Loss 4.8622, Error 0.2817(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25360 | Time 26.2881(26.4267) | Bit/dim 3.5056(3.4821) | Xent 0.0096(0.0146) | Loss 3.5104(3.4894) | Error 0.0056(0.0044) Steps 1042(1062.21) | Grad Norm 1.1047(1.7260) | Total Time 14.00(14.00)\n",
      "Iter 25370 | Time 26.3478(26.4318) | Bit/dim 3.4740(3.4828) | Xent 0.0187(0.0143) | Loss 3.4834(3.4900) | Error 0.0056(0.0041) Steps 1060(1062.02) | Grad Norm 1.7683(1.6575) | Total Time 14.00(14.00)\n",
      "Iter 25380 | Time 26.4617(26.3080) | Bit/dim 3.4886(3.4820) | Xent 0.0146(0.0142) | Loss 3.4959(3.4892) | Error 0.0067(0.0042) Steps 1054(1058.98) | Grad Norm 1.2032(1.5523) | Total Time 14.00(14.00)\n",
      "Iter 25390 | Time 25.3785(26.1881) | Bit/dim 3.4708(3.4792) | Xent 0.0171(0.0144) | Loss 3.4794(3.4864) | Error 0.0044(0.0042) Steps 1072(1059.27) | Grad Norm 2.3295(1.5331) | Total Time 14.00(14.00)\n",
      "Iter 25400 | Time 26.3542(26.2332) | Bit/dim 3.4716(3.4803) | Xent 0.0161(0.0143) | Loss 3.4796(3.4874) | Error 0.0044(0.0042) Steps 1072(1060.28) | Grad Norm 1.7346(1.6026) | Total Time 14.00(14.00)\n",
      "Iter 25410 | Time 26.6497(26.2577) | Bit/dim 3.5054(3.4820) | Xent 0.0072(0.0142) | Loss 3.5090(3.4891) | Error 0.0033(0.0044) Steps 1072(1061.89) | Grad Norm 1.2382(1.5966) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 123.5640, Epoch Time 1584.2554(1585.2441), Bit/dim 3.4878(best: 3.4859), Xent 2.7709, Loss 4.8733, Error 0.2762(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25420 | Time 26.1549(26.3132) | Bit/dim 3.4374(3.4826) | Xent 0.0104(0.0131) | Loss 3.4426(3.4891) | Error 0.0022(0.0039) Steps 1060(1062.64) | Grad Norm 1.6577(1.5844) | Total Time 14.00(14.00)\n",
      "Iter 25430 | Time 26.1697(26.2461) | Bit/dim 3.4684(3.4824) | Xent 0.0069(0.0126) | Loss 3.4718(3.4887) | Error 0.0000(0.0035) Steps 1048(1061.45) | Grad Norm 0.8189(1.4777) | Total Time 14.00(14.00)\n",
      "Iter 25440 | Time 25.9614(26.2538) | Bit/dim 3.4973(3.4832) | Xent 0.0323(0.0133) | Loss 3.5134(3.4899) | Error 0.0122(0.0038) Steps 1066(1060.89) | Grad Norm 3.0838(1.5057) | Total Time 14.00(14.00)\n",
      "Iter 25450 | Time 26.3778(26.3006) | Bit/dim 3.4624(3.4792) | Xent 0.0075(0.0136) | Loss 3.4661(3.4860) | Error 0.0022(0.0039) Steps 1054(1061.66) | Grad Norm 0.8713(1.5288) | Total Time 14.00(14.00)\n",
      "Iter 25460 | Time 25.9699(26.3366) | Bit/dim 3.5033(3.4789) | Xent 0.0162(0.0135) | Loss 3.5114(3.4856) | Error 0.0044(0.0038) Steps 1048(1061.07) | Grad Norm 1.9287(1.4883) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 122.0579, Epoch Time 1589.2652(1585.3647), Bit/dim 3.4870(best: 3.4859), Xent 2.7670, Loss 4.8705, Error 0.2780(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25470 | Time 26.0470(26.3319) | Bit/dim 3.4962(3.4822) | Xent 0.0074(0.0132) | Loss 3.4999(3.4888) | Error 0.0011(0.0038) Steps 1054(1060.11) | Grad Norm 0.8495(1.4564) | Total Time 14.00(14.00)\n",
      "Iter 25480 | Time 27.1754(26.3443) | Bit/dim 3.4316(3.4808) | Xent 0.0139(0.0129) | Loss 3.4385(3.4872) | Error 0.0056(0.0038) Steps 1072(1061.44) | Grad Norm 1.3628(1.3992) | Total Time 14.00(14.00)\n",
      "Iter 25490 | Time 25.8159(26.3175) | Bit/dim 3.4653(3.4817) | Xent 0.0106(0.0128) | Loss 3.4706(3.4881) | Error 0.0022(0.0037) Steps 1060(1060.96) | Grad Norm 1.0902(1.3543) | Total Time 14.00(14.00)\n",
      "Iter 25500 | Time 26.8732(26.3786) | Bit/dim 3.4806(3.4816) | Xent 0.0192(0.0130) | Loss 3.4902(3.4881) | Error 0.0056(0.0039) Steps 1060(1060.76) | Grad Norm 1.3413(1.3588) | Total Time 14.00(14.00)\n",
      "Iter 25510 | Time 26.0669(26.4037) | Bit/dim 3.4463(3.4829) | Xent 0.0165(0.0131) | Loss 3.4545(3.4894) | Error 0.0044(0.0038) Steps 1066(1063.08) | Grad Norm 1.4711(1.3572) | Total Time 14.00(14.00)\n",
      "Iter 25520 | Time 26.1023(26.3720) | Bit/dim 3.4858(3.4800) | Xent 0.0091(0.0129) | Loss 3.4904(3.4864) | Error 0.0011(0.0036) Steps 1078(1062.85) | Grad Norm 1.4134(1.3259) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 123.8051, Epoch Time 1591.8542(1585.5594), Bit/dim 3.4862(best: 3.4859), Xent 2.7823, Loss 4.8773, Error 0.2818(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25530 | Time 26.1035(26.3493) | Bit/dim 3.4822(3.4783) | Xent 0.0118(0.0127) | Loss 3.4881(3.4847) | Error 0.0033(0.0036) Steps 1060(1062.35) | Grad Norm 1.3816(1.3316) | Total Time 14.00(14.00)\n",
      "Iter 25540 | Time 25.8774(26.2851) | Bit/dim 3.5054(3.4796) | Xent 0.0126(0.0135) | Loss 3.5116(3.4863) | Error 0.0033(0.0039) Steps 1054(1060.94) | Grad Norm 1.0131(1.4217) | Total Time 14.00(14.00)\n",
      "Iter 25550 | Time 26.0656(26.3059) | Bit/dim 3.4926(3.4799) | Xent 0.0141(0.0135) | Loss 3.4996(3.4867) | Error 0.0033(0.0038) Steps 1066(1060.60) | Grad Norm 1.2391(1.3824) | Total Time 14.00(14.00)\n",
      "Iter 25560 | Time 26.4219(26.3190) | Bit/dim 3.4717(3.4792) | Xent 0.0117(0.0132) | Loss 3.4775(3.4857) | Error 0.0033(0.0036) Steps 1060(1060.64) | Grad Norm 1.2220(1.3965) | Total Time 14.00(14.00)\n",
      "Iter 25570 | Time 26.0112(26.3370) | Bit/dim 3.4789(3.4813) | Xent 0.0196(0.0145) | Loss 3.4888(3.4886) | Error 0.0089(0.0045) Steps 1072(1060.97) | Grad Norm 3.0706(1.6205) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 122.9873, Epoch Time 1590.0358(1585.6937), Bit/dim 3.4880(best: 3.4859), Xent 2.8057, Loss 4.8908, Error 0.2806(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25580 | Time 26.2497(26.3378) | Bit/dim 3.5029(3.4822) | Xent 0.0163(0.0141) | Loss 3.5110(3.4893) | Error 0.0067(0.0043) Steps 1072(1060.49) | Grad Norm 1.5454(1.6179) | Total Time 14.00(14.00)\n",
      "Iter 25590 | Time 26.0559(26.3181) | Bit/dim 3.5063(3.4833) | Xent 0.0126(0.0139) | Loss 3.5126(3.4902) | Error 0.0022(0.0039) Steps 1060(1060.74) | Grad Norm 1.2052(1.5963) | Total Time 14.00(14.00)\n",
      "Iter 25600 | Time 25.7372(26.2869) | Bit/dim 3.4610(3.4822) | Xent 0.0139(0.0141) | Loss 3.4680(3.4893) | Error 0.0033(0.0041) Steps 1054(1062.17) | Grad Norm 1.1517(1.5433) | Total Time 14.00(14.00)\n",
      "Iter 25610 | Time 25.9225(26.3000) | Bit/dim 3.4776(3.4811) | Xent 0.0133(0.0138) | Loss 3.4843(3.4880) | Error 0.0044(0.0042) Steps 1054(1061.42) | Grad Norm 2.0158(1.5888) | Total Time 14.00(14.00)\n",
      "Iter 25620 | Time 25.8737(26.3211) | Bit/dim 3.4971(3.4828) | Xent 0.0108(0.0138) | Loss 3.5025(3.4897) | Error 0.0022(0.0040) Steps 1048(1062.87) | Grad Norm 1.4420(1.6352) | Total Time 14.00(14.00)\n",
      "Iter 25630 | Time 26.2585(26.2956) | Bit/dim 3.4641(3.4812) | Xent 0.0199(0.0137) | Loss 3.4740(3.4881) | Error 0.0067(0.0039) Steps 1036(1062.20) | Grad Norm 1.3824(1.5665) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 123.6947, Epoch Time 1585.5968(1585.6908), Bit/dim 3.4867(best: 3.4859), Xent 2.7641, Loss 4.8688, Error 0.2799(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25640 | Time 25.9442(26.2751) | Bit/dim 3.4974(3.4820) | Xent 0.0107(0.0140) | Loss 3.5027(3.4891) | Error 0.0022(0.0042) Steps 1066(1061.38) | Grad Norm 0.8309(1.5216) | Total Time 14.00(14.00)\n",
      "Iter 25650 | Time 25.7172(26.2455) | Bit/dim 3.4778(3.4835) | Xent 0.0112(0.0133) | Loss 3.4834(3.4901) | Error 0.0056(0.0039) Steps 1048(1061.08) | Grad Norm 1.4023(1.4567) | Total Time 14.00(14.00)\n",
      "Iter 25660 | Time 26.7772(26.2488) | Bit/dim 3.4551(3.4786) | Xent 0.0126(0.0129) | Loss 3.4614(3.4850) | Error 0.0033(0.0037) Steps 1078(1060.84) | Grad Norm 1.4706(1.4272) | Total Time 14.00(14.00)\n",
      "Iter 25670 | Time 27.6725(26.3204) | Bit/dim 3.4627(3.4776) | Xent 0.0105(0.0128) | Loss 3.4680(3.4840) | Error 0.0022(0.0036) Steps 1084(1062.13) | Grad Norm 1.2715(1.3729) | Total Time 14.00(14.00)\n",
      "Iter 25680 | Time 26.5543(26.3277) | Bit/dim 3.4853(3.4805) | Xent 0.0148(0.0129) | Loss 3.4927(3.4869) | Error 0.0044(0.0034) Steps 1066(1062.89) | Grad Norm 1.4558(1.3384) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 121.9401, Epoch Time 1586.7097(1585.7214), Bit/dim 3.4852(best: 3.4859), Xent 2.8050, Loss 4.8878, Error 0.2844(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25690 | Time 26.7971(26.3421) | Bit/dim 3.4816(3.4803) | Xent 0.0103(0.0132) | Loss 3.4867(3.4869) | Error 0.0011(0.0036) Steps 1072(1063.02) | Grad Norm 1.2791(1.3420) | Total Time 14.00(14.00)\n",
      "Iter 25700 | Time 26.8842(26.3336) | Bit/dim 3.4642(3.4821) | Xent 0.0069(0.0128) | Loss 3.4677(3.4885) | Error 0.0011(0.0033) Steps 1054(1063.07) | Grad Norm 1.4952(1.3788) | Total Time 14.00(14.00)\n",
      "Iter 25710 | Time 25.4992(26.3633) | Bit/dim 3.5149(3.4834) | Xent 0.0265(0.0141) | Loss 3.5281(3.4905) | Error 0.0078(0.0041) Steps 1066(1062.28) | Grad Norm 2.2776(1.5423) | Total Time 14.00(14.00)\n",
      "Iter 25720 | Time 25.7973(26.2911) | Bit/dim 3.4490(3.4824) | Xent 0.0138(0.0143) | Loss 3.4559(3.4896) | Error 0.0056(0.0042) Steps 1066(1060.36) | Grad Norm 1.8529(1.5534) | Total Time 14.00(14.00)\n",
      "Iter 25730 | Time 26.3528(26.2708) | Bit/dim 3.4426(3.4827) | Xent 0.0118(0.0142) | Loss 3.4486(3.4898) | Error 0.0033(0.0040) Steps 1042(1061.21) | Grad Norm 1.4774(1.5832) | Total Time 14.00(14.00)\n",
      "Iter 25740 | Time 26.9492(26.3533) | Bit/dim 3.4594(3.4801) | Xent 0.0232(0.0149) | Loss 3.4710(3.4876) | Error 0.0100(0.0043) Steps 1066(1060.93) | Grad Norm 1.9119(1.5822) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 124.4650, Epoch Time 1590.8921(1585.8765), Bit/dim 3.4870(best: 3.4852), Xent 2.8041, Loss 4.8890, Error 0.2796(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25750 | Time 26.2821(26.3567) | Bit/dim 3.4725(3.4836) | Xent 0.0097(0.0149) | Loss 3.4774(3.4911) | Error 0.0044(0.0044) Steps 1054(1060.27) | Grad Norm 1.1095(1.5558) | Total Time 14.00(14.00)\n",
      "Iter 25760 | Time 25.8129(26.3247) | Bit/dim 3.4697(3.4815) | Xent 0.0092(0.0149) | Loss 3.4743(3.4889) | Error 0.0056(0.0046) Steps 1066(1060.06) | Grad Norm 1.7527(1.7005) | Total Time 14.00(14.00)\n",
      "Iter 25770 | Time 25.8947(26.3462) | Bit/dim 3.5220(3.4804) | Xent 0.0109(0.0145) | Loss 3.5275(3.4876) | Error 0.0022(0.0045) Steps 1066(1061.78) | Grad Norm 2.6232(1.8579) | Total Time 14.00(14.00)\n",
      "Iter 25780 | Time 27.2852(26.4339) | Bit/dim 3.4588(3.4796) | Xent 0.0206(0.0145) | Loss 3.4691(3.4869) | Error 0.0056(0.0044) Steps 1078(1061.09) | Grad Norm 4.1084(1.9134) | Total Time 14.00(14.00)\n",
      "Iter 25790 | Time 25.8395(26.4603) | Bit/dim 3.4700(3.4802) | Xent 0.0084(0.0145) | Loss 3.4742(3.4874) | Error 0.0022(0.0047) Steps 1042(1060.88) | Grad Norm 1.3272(1.9049) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 124.6616, Epoch Time 1599.1934(1586.2760), Bit/dim 3.4883(best: 3.4852), Xent 2.8100, Loss 4.8933, Error 0.2806(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25800 | Time 26.4302(26.4984) | Bit/dim 3.5003(3.4813) | Xent 0.0139(0.0142) | Loss 3.5073(3.4884) | Error 0.0044(0.0045) Steps 1054(1060.43) | Grad Norm 1.2784(1.8226) | Total Time 14.00(14.00)\n",
      "Iter 25810 | Time 26.1564(26.4689) | Bit/dim 3.4837(3.4810) | Xent 0.0185(0.0138) | Loss 3.4930(3.4879) | Error 0.0044(0.0042) Steps 1054(1061.12) | Grad Norm 1.4518(1.7045) | Total Time 14.00(14.00)\n",
      "Iter 25820 | Time 25.9456(26.4871) | Bit/dim 3.4711(3.4806) | Xent 0.0150(0.0137) | Loss 3.4786(3.4875) | Error 0.0044(0.0041) Steps 1060(1061.54) | Grad Norm 1.4731(1.6418) | Total Time 14.00(14.00)\n",
      "Iter 25830 | Time 26.1129(26.4808) | Bit/dim 3.4490(3.4793) | Xent 0.0111(0.0133) | Loss 3.4546(3.4859) | Error 0.0022(0.0039) Steps 1042(1059.82) | Grad Norm 1.1662(1.5408) | Total Time 14.00(14.00)\n",
      "Iter 25840 | Time 26.8970(26.4666) | Bit/dim 3.4627(3.4814) | Xent 0.0126(0.0129) | Loss 3.4690(3.4879) | Error 0.0033(0.0037) Steps 1054(1059.79) | Grad Norm 1.1692(1.4643) | Total Time 14.00(14.00)\n",
      "Iter 25850 | Time 26.2727(26.5231) | Bit/dim 3.4797(3.4807) | Xent 0.0076(0.0130) | Loss 3.4835(3.4872) | Error 0.0022(0.0038) Steps 1060(1062.44) | Grad Norm 1.1437(1.4041) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 125.9052, Epoch Time 1601.1532(1586.7223), Bit/dim 3.4854(best: 3.4852), Xent 2.8012, Loss 4.8860, Error 0.2813(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25860 | Time 26.7838(26.4857) | Bit/dim 3.4775(3.4810) | Xent 0.0086(0.0126) | Loss 3.4818(3.4873) | Error 0.0011(0.0036) Steps 1084(1061.82) | Grad Norm 0.7171(1.3209) | Total Time 14.00(14.00)\n",
      "Iter 25870 | Time 26.0043(26.4136) | Bit/dim 3.5096(3.4788) | Xent 0.0164(0.0127) | Loss 3.5178(3.4852) | Error 0.0056(0.0038) Steps 1066(1060.91) | Grad Norm 2.1069(1.4104) | Total Time 14.00(14.00)\n",
      "Iter 25880 | Time 26.5973(26.3890) | Bit/dim 3.4618(3.4768) | Xent 0.0155(0.0128) | Loss 3.4695(3.4832) | Error 0.0056(0.0038) Steps 1060(1062.23) | Grad Norm 2.0120(1.4832) | Total Time 14.00(14.00)\n",
      "Iter 25890 | Time 26.7838(26.4376) | Bit/dim 3.4867(3.4798) | Xent 0.0191(0.0132) | Loss 3.4962(3.4864) | Error 0.0067(0.0039) Steps 1054(1061.83) | Grad Norm 2.2657(1.5546) | Total Time 14.00(14.00)\n",
      "Iter 25900 | Time 26.9890(26.4558) | Bit/dim 3.5064(3.4805) | Xent 0.0148(0.0130) | Loss 3.5138(3.4870) | Error 0.0044(0.0037) Steps 1066(1061.70) | Grad Norm 1.3036(1.5253) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 124.7423, Epoch Time 1596.1334(1587.0046), Bit/dim 3.4869(best: 3.4852), Xent 2.8323, Loss 4.9031, Error 0.2798(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25910 | Time 26.7300(26.5076) | Bit/dim 3.5163(3.4827) | Xent 0.0118(0.0126) | Loss 3.5222(3.4890) | Error 0.0022(0.0034) Steps 1066(1062.16) | Grad Norm 1.7089(1.4909) | Total Time 14.00(14.00)\n",
      "Iter 25920 | Time 26.6256(26.4264) | Bit/dim 3.4920(3.4815) | Xent 0.0274(0.0134) | Loss 3.5057(3.4882) | Error 0.0078(0.0036) Steps 1060(1062.58) | Grad Norm 2.2686(1.5924) | Total Time 14.00(14.00)\n",
      "Iter 25930 | Time 26.8061(26.4376) | Bit/dim 3.4737(3.4813) | Xent 0.0188(0.0148) | Loss 3.4831(3.4887) | Error 0.0033(0.0043) Steps 1060(1061.51) | Grad Norm 2.2412(1.7696) | Total Time 14.00(14.00)\n",
      "Iter 25940 | Time 26.1121(26.4621) | Bit/dim 3.4749(3.4797) | Xent 0.0153(0.0139) | Loss 3.4825(3.4867) | Error 0.0067(0.0041) Steps 1066(1063.36) | Grad Norm 1.3410(1.7015) | Total Time 14.00(14.00)\n",
      "Iter 25950 | Time 26.8446(26.4800) | Bit/dim 3.4806(3.4784) | Xent 0.0137(0.0144) | Loss 3.4875(3.4856) | Error 0.0033(0.0041) Steps 1060(1060.95) | Grad Norm 1.5171(1.6767) | Total Time 14.00(14.00)\n",
      "Iter 25960 | Time 26.0332(26.3766) | Bit/dim 3.4758(3.4821) | Xent 0.0116(0.0135) | Loss 3.4816(3.4889) | Error 0.0033(0.0037) Steps 1048(1061.09) | Grad Norm 1.5245(1.5729) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 124.4890, Epoch Time 1592.8755(1587.1808), Bit/dim 3.4862(best: 3.4852), Xent 2.8275, Loss 4.9000, Error 0.2822(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 25970 | Time 26.0815(26.3208) | Bit/dim 3.4668(3.4811) | Xent 0.0142(0.0137) | Loss 3.4739(3.4880) | Error 0.0033(0.0039) Steps 1042(1060.25) | Grad Norm 1.6250(1.5630) | Total Time 14.00(14.00)\n",
      "Iter 25980 | Time 25.9158(26.3593) | Bit/dim 3.4714(3.4803) | Xent 0.0113(0.0137) | Loss 3.4770(3.4872) | Error 0.0033(0.0039) Steps 1048(1059.13) | Grad Norm 1.9177(1.5809) | Total Time 14.00(14.00)\n",
      "Iter 25990 | Time 26.7135(26.3224) | Bit/dim 3.4773(3.4783) | Xent 0.0155(0.0134) | Loss 3.4851(3.4849) | Error 0.0022(0.0037) Steps 1054(1058.57) | Grad Norm 1.4037(1.5875) | Total Time 14.00(14.00)\n",
      "Iter 26000 | Time 26.1558(26.2697) | Bit/dim 3.5160(3.4800) | Xent 0.0128(0.0139) | Loss 3.5224(3.4869) | Error 0.0033(0.0039) Steps 1066(1060.48) | Grad Norm 1.9819(1.6080) | Total Time 14.00(14.00)\n",
      "Iter 26010 | Time 25.8669(26.2868) | Bit/dim 3.5257(3.4807) | Xent 0.0152(0.0133) | Loss 3.5333(3.4874) | Error 0.0033(0.0035) Steps 1060(1061.80) | Grad Norm 1.7054(1.5235) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 123.0046, Epoch Time 1586.4934(1587.1601), Bit/dim 3.4863(best: 3.4852), Xent 2.7840, Loss 4.8783, Error 0.2808(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26020 | Time 26.0258(26.2971) | Bit/dim 3.4939(3.4817) | Xent 0.0128(0.0131) | Loss 3.5003(3.4882) | Error 0.0044(0.0034) Steps 1060(1062.43) | Grad Norm 1.7257(1.4686) | Total Time 14.00(14.00)\n",
      "Iter 26030 | Time 26.0260(26.3553) | Bit/dim 3.5034(3.4810) | Xent 0.0059(0.0131) | Loss 3.5063(3.4875) | Error 0.0011(0.0034) Steps 1054(1060.96) | Grad Norm 1.0766(1.4386) | Total Time 14.00(14.00)\n",
      "Iter 26040 | Time 26.3670(26.2811) | Bit/dim 3.4626(3.4807) | Xent 0.0131(0.0129) | Loss 3.4691(3.4872) | Error 0.0033(0.0033) Steps 1060(1061.46) | Grad Norm 1.1641(1.4147) | Total Time 14.00(14.00)\n",
      "Iter 26050 | Time 25.9930(26.2594) | Bit/dim 3.4806(3.4795) | Xent 0.0116(0.0129) | Loss 3.4864(3.4859) | Error 0.0033(0.0034) Steps 1048(1062.56) | Grad Norm 1.3371(1.3722) | Total Time 14.00(14.00)\n",
      "Iter 26060 | Time 25.3664(26.2567) | Bit/dim 3.4717(3.4809) | Xent 0.0181(0.0132) | Loss 3.4807(3.4875) | Error 0.0056(0.0037) Steps 1054(1061.25) | Grad Norm 1.5719(1.3647) | Total Time 14.00(14.00)\n",
      "Iter 26070 | Time 25.9082(26.2759) | Bit/dim 3.4772(3.4806) | Xent 0.0111(0.0135) | Loss 3.4828(3.4873) | Error 0.0033(0.0038) Steps 1048(1059.99) | Grad Norm 1.1912(1.3872) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 122.8469, Epoch Time 1585.2140(1587.1017), Bit/dim 3.4865(best: 3.4852), Xent 2.8063, Loss 4.8896, Error 0.2797(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26080 | Time 26.9765(26.3643) | Bit/dim 3.4188(3.4795) | Xent 0.0095(0.0131) | Loss 3.4235(3.4861) | Error 0.0022(0.0036) Steps 1078(1061.61) | Grad Norm 1.2658(1.3619) | Total Time 14.00(14.00)\n",
      "Iter 26090 | Time 26.1008(26.2954) | Bit/dim 3.4679(3.4781) | Xent 0.0166(0.0133) | Loss 3.4762(3.4847) | Error 0.0056(0.0039) Steps 1060(1061.22) | Grad Norm 2.8929(1.4234) | Total Time 14.00(14.00)\n",
      "Iter 26100 | Time 25.7050(26.2494) | Bit/dim 3.4540(3.4783) | Xent 0.0173(0.0136) | Loss 3.4626(3.4851) | Error 0.0067(0.0041) Steps 1054(1061.24) | Grad Norm 1.9483(1.4702) | Total Time 14.00(14.00)\n",
      "Iter 26110 | Time 25.6911(26.2207) | Bit/dim 3.4760(3.4792) | Xent 0.0112(0.0132) | Loss 3.4815(3.4858) | Error 0.0022(0.0040) Steps 1060(1061.00) | Grad Norm 1.3471(1.4551) | Total Time 14.00(14.00)\n",
      "Iter 26120 | Time 25.8534(26.2495) | Bit/dim 3.4700(3.4810) | Xent 0.0088(0.0135) | Loss 3.4744(3.4877) | Error 0.0022(0.0041) Steps 1054(1060.63) | Grad Norm 1.0702(1.5206) | Total Time 14.00(14.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 121.8654, Epoch Time 1585.4487(1587.0522), Bit/dim 3.4860(best: 3.4852), Xent 2.8365, Loss 4.9043, Error 0.2826(best: 0.2631)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 26130 | Time 26.3455(26.2942) | Bit/dim 3.4708(3.4814) | Xent 0.0068(0.0137) | Loss 3.4742(3.4882) | Error 0.0011(0.0043) Steps 1072(1062.42) | Grad Norm 0.7843(1.5226) | Total Time 14.00(14.00)\n",
      "Iter 26140 | Time 26.0576(26.2920) | Bit/dim 3.4691(3.4789) | Xent 0.0079(0.0135) | Loss 3.4731(3.4857) | Error 0.0011(0.0041) Steps 1066(1062.49) | Grad Norm 1.4219(1.5411) | Total Time 14.00(14.00)\n",
      "Iter 26150 | Time 26.2405(26.3145) | Bit/dim 3.4701(3.4794) | Xent 0.0053(0.0125) | Loss 3.4727(3.4857) | Error 0.0000(0.0038) Steps 1066(1061.92) | Grad Norm 0.7545(1.4345) | Total Time 14.00(14.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_cifar.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_run3 --resume ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_run3/current_checkpt.pth --seed 3 --lr 0.0001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
