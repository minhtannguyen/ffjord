{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "if args.controlled_tol:\n",
      "    import lib.odenvp_conditional_tol as odenvp\n",
      "else:\n",
      "    import lib.odenvp_conditional as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp = model(x, zero)  # run model forward\n",
      "    \n",
      "    dim_sup = int(args.condition_ratio * np.prod(z.size()[1:]))\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z[:, 0:dim_sup]).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z[:, dim_sup:]).view(z.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        zsup = model.module.dropout(z[:, 0:dim_sup])\n",
      "    else:\n",
      "        zsup = z[:, 0:dim_sup]\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(zsup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        dim_unsup = int((1.0 - args.condition_ratio) * np.prod(data_shape))\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            fixed_z = torch.cat((fixed_z_sup, fixed_z_unsup),1)\n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            loss.backward()\n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "        \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, atol=0.0001, autoencode=False, batch_norm=False, batch_size=8000, batch_size_schedule='', begin_epoch=1, condition_ratio=0.25, conditional=True, controlled_tol=True, conv=True, data='mnist', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=1, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=1000, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_bs8K_sratio_0_25_drop_0_5_run2/epoch_365_checkpt.pth', rtol=0.0001, save='../experiments_published/cnf_conditional_disentangle_bs8K_sratio_0_25_drop_0_5_run2', seed=2, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=5000, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=113.0, weight_decay=0.0, weight_y=0.5)\n",
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF(\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=392, bias=True)\n",
      "  (project_class): LinearZeros(in_features=196, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 807722\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "Iter 2556 | Time 69.5867(31.2893) | Bit/dim 1.1100(1.1177) | Xent 0.0547(0.0554) | Loss 1.1374(1.1454) | Error 0.0156(0.0169) Steps 416(414.27) | Grad Norm 1.1876(1.1513) | Total Time 10.00(10.00)\n",
      "Iter 2557 | Time 31.2405(31.2878) | Bit/dim 1.1143(1.1176) | Xent 0.0511(0.0553) | Loss 1.1398(1.1452) | Error 0.0175(0.0170) Steps 416(414.32) | Grad Norm 1.0093(1.1471) | Total Time 10.00(10.00)\n",
      "Iter 2558 | Time 30.4368(31.2623) | Bit/dim 1.1100(1.1174) | Xent 0.0586(0.0554) | Loss 1.1393(1.1451) | Error 0.0180(0.0170) Steps 416(414.37) | Grad Norm 0.5860(1.1303) | Total Time 10.00(10.00)\n",
      "Iter 2559 | Time 29.0145(31.1949) | Bit/dim 1.1099(1.1171) | Xent 0.0526(0.0553) | Loss 1.1362(1.1448) | Error 0.0164(0.0170) Steps 410(414.24) | Grad Norm 0.4022(1.1084) | Total Time 10.00(10.00)\n",
      "Iter 2560 | Time 29.9334(31.1570) | Bit/dim 1.1137(1.1170) | Xent 0.0540(0.0553) | Loss 1.1406(1.1447) | Error 0.0166(0.0170) Steps 410(414.12) | Grad Norm 0.5971(1.0931) | Total Time 10.00(10.00)\n",
      "Iter 2561 | Time 29.1360(31.0964) | Bit/dim 1.1122(1.1169) | Xent 0.0588(0.0554) | Loss 1.1416(1.1446) | Error 0.0192(0.0170) Steps 410(413.99) | Grad Norm 0.7178(1.0818) | Total Time 10.00(10.00)\n",
      "Iter 2562 | Time 29.1741(31.0387) | Bit/dim 1.1105(1.1167) | Xent 0.0526(0.0553) | Loss 1.1368(1.1443) | Error 0.0164(0.0170) Steps 410(413.87) | Grad Norm 0.6083(1.0676) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 26.5202, Epoch Time 287.1342(240.6152), Bit/dim 1.1061(best: inf), Xent 0.0322, Loss 1.1222, Error 0.0102(best: inf)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2563 | Time 30.6940(31.0284) | Bit/dim 1.1107(1.1165) | Xent 0.0507(0.0551) | Loss 1.1361(1.1441) | Error 0.0168(0.0170) Steps 410(413.76) | Grad Norm 0.4878(1.0502) | Total Time 10.00(10.00)\n",
      "Iter 2564 | Time 28.8033(30.9616) | Bit/dim 1.1079(1.1163) | Xent 0.0465(0.0549) | Loss 1.1312(1.1437) | Error 0.0158(0.0170) Steps 410(413.64) | Grad Norm 0.2181(1.0253) | Total Time 10.00(10.00)\n",
      "Iter 2565 | Time 29.0284(30.9036) | Bit/dim 1.1132(1.1162) | Xent 0.0511(0.0548) | Loss 1.1387(1.1436) | Error 0.0152(0.0169) Steps 410(413.53) | Grad Norm 0.2706(1.0026) | Total Time 10.00(10.00)\n",
      "Iter 2566 | Time 29.8750(30.8728) | Bit/dim 1.1085(1.1159) | Xent 0.0520(0.0547) | Loss 1.1345(1.1433) | Error 0.0166(0.0169) Steps 410(413.43) | Grad Norm 0.4046(0.9847) | Total Time 10.00(10.00)\n",
      "Iter 2567 | Time 29.6049(30.8347) | Bit/dim 1.1184(1.1160) | Xent 0.0613(0.0549) | Loss 1.1490(1.1435) | Error 0.0182(0.0169) Steps 410(413.33) | Grad Norm 0.8000(0.9791) | Total Time 10.00(10.00)\n",
      "Iter 2568 | Time 29.9342(30.8077) | Bit/dim 1.1138(1.1159) | Xent 0.0543(0.0549) | Loss 1.1409(1.1434) | Error 0.0162(0.0169) Steps 410(413.23) | Grad Norm 0.2710(0.9579) | Total Time 10.00(10.00)\n",
      "Iter 2569 | Time 30.8808(30.8099) | Bit/dim 1.1059(1.1156) | Xent 0.0537(0.0548) | Loss 1.1327(1.1431) | Error 0.0176(0.0169) Steps 410(413.13) | Grad Norm 0.2829(0.9376) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 16.2152, Epoch Time 237.2563(240.5144), Bit/dim 1.1060(best: 1.1061), Xent 0.0316, Loss 1.1218, Error 0.0092(best: 0.0102)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2570 | Time 29.4395(30.7688) | Bit/dim 1.1140(1.1156) | Xent 0.0465(0.0546) | Loss 1.1373(1.1429) | Error 0.0156(0.0169) Steps 410(413.04) | Grad Norm 0.2830(0.9180) | Total Time 10.00(10.00)\n",
      "Iter 2571 | Time 28.9297(30.7136) | Bit/dim 1.1121(1.1155) | Xent 0.0554(0.0546) | Loss 1.1398(1.1428) | Error 0.0189(0.0170) Steps 410(412.94) | Grad Norm 0.3214(0.9001) | Total Time 10.00(10.00)\n",
      "Iter 2572 | Time 29.4586(30.6760) | Bit/dim 1.1096(1.1153) | Xent 0.0520(0.0545) | Loss 1.1356(1.1426) | Error 0.0159(0.0169) Steps 410(412.86) | Grad Norm 0.3879(0.8847) | Total Time 10.00(10.00)\n",
      "Iter 2573 | Time 29.1333(30.6297) | Bit/dim 1.1135(1.1153) | Xent 0.0571(0.0546) | Loss 1.1420(1.1426) | Error 0.0171(0.0169) Steps 410(412.77) | Grad Norm 0.3428(0.8685) | Total Time 10.00(10.00)\n",
      "Iter 2574 | Time 29.0500(30.5823) | Bit/dim 1.1089(1.1151) | Xent 0.0510(0.0545) | Loss 1.1344(1.1423) | Error 0.0145(0.0169) Steps 410(412.69) | Grad Norm 0.2664(0.8504) | Total Time 10.00(10.00)\n",
      "Iter 2575 | Time 30.0438(30.5662) | Bit/dim 1.1136(1.1150) | Xent 0.0604(0.0547) | Loss 1.1438(1.1424) | Error 0.0176(0.0169) Steps 410(412.61) | Grad Norm 0.3769(0.8362) | Total Time 10.00(10.00)\n",
      "Iter 2576 | Time 30.7152(30.5706) | Bit/dim 1.1109(1.1149) | Xent 0.0599(0.0548) | Loss 1.1409(1.1423) | Error 0.0181(0.0169) Steps 410(412.53) | Grad Norm 0.3313(0.8211) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 16.3086, Epoch Time 235.1580(240.3537), Bit/dim 1.1059(best: 1.1060), Xent 0.0323, Loss 1.1221, Error 0.0103(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2577 | Time 29.1970(30.5294) | Bit/dim 1.1095(1.1147) | Xent 0.0478(0.0546) | Loss 1.1334(1.1420) | Error 0.0158(0.0169) Steps 410(412.45) | Grad Norm 0.3475(0.8069) | Total Time 10.00(10.00)\n",
      "Iter 2578 | Time 29.1789(30.4889) | Bit/dim 1.1132(1.1147) | Xent 0.0520(0.0545) | Loss 1.1392(1.1420) | Error 0.0154(0.0168) Steps 410(412.38) | Grad Norm 0.1860(0.7882) | Total Time 10.00(10.00)\n",
      "Iter 2579 | Time 29.4706(30.4584) | Bit/dim 1.1139(1.1147) | Xent 0.0555(0.0546) | Loss 1.1416(1.1420) | Error 0.0176(0.0169) Steps 410(412.31) | Grad Norm 0.1372(0.7687) | Total Time 10.00(10.00)\n",
      "Iter 2580 | Time 30.2446(30.4519) | Bit/dim 1.1077(1.1145) | Xent 0.0540(0.0546) | Loss 1.1347(1.1417) | Error 0.0160(0.0168) Steps 410(412.24) | Grad Norm 0.1472(0.7501) | Total Time 10.00(10.00)\n",
      "Iter 2581 | Time 31.1973(30.4743) | Bit/dim 1.1099(1.1143) | Xent 0.0529(0.0545) | Loss 1.1363(1.1416) | Error 0.0161(0.0168) Steps 416(412.35) | Grad Norm 0.3236(0.7373) | Total Time 10.00(10.00)\n",
      "Iter 2582 | Time 31.0991(30.4930) | Bit/dim 1.1122(1.1143) | Xent 0.0543(0.0545) | Loss 1.1393(1.1415) | Error 0.0182(0.0169) Steps 410(412.28) | Grad Norm 0.1528(0.7197) | Total Time 10.00(10.00)\n",
      "Iter 2583 | Time 29.1308(30.4522) | Bit/dim 1.1125(1.1142) | Xent 0.0587(0.0546) | Loss 1.1419(1.1415) | Error 0.0179(0.0169) Steps 410(412.21) | Grad Norm 0.1810(0.7036) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 16.2441, Epoch Time 238.0912(240.2858), Bit/dim 1.1060(best: 1.1059), Xent 0.0321, Loss 1.1220, Error 0.0100(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2584 | Time 30.0676(30.4406) | Bit/dim 1.1113(1.1141) | Xent 0.0488(0.0544) | Loss 1.1357(1.1413) | Error 0.0148(0.0168) Steps 410(412.15) | Grad Norm 0.2772(0.6908) | Total Time 10.00(10.00)\n",
      "Iter 2585 | Time 29.4504(30.4109) | Bit/dim 1.1105(1.1140) | Xent 0.0559(0.0545) | Loss 1.1384(1.1413) | Error 0.0164(0.0168) Steps 410(412.08) | Grad Norm 0.2572(0.6778) | Total Time 10.00(10.00)\n",
      "Iter 2586 | Time 30.7499(30.4211) | Bit/dim 1.1118(1.1139) | Xent 0.0522(0.0544) | Loss 1.1379(1.1412) | Error 0.0158(0.0168) Steps 410(412.02) | Grad Norm 0.2455(0.6648) | Total Time 10.00(10.00)\n",
      "Iter 2587 | Time 29.7408(30.4007) | Bit/dim 1.1105(1.1138) | Xent 0.0470(0.0542) | Loss 1.1340(1.1409) | Error 0.0142(0.0167) Steps 410(411.96) | Grad Norm 0.2798(0.6532) | Total Time 10.00(10.00)\n",
      "Iter 2588 | Time 29.1614(30.3635) | Bit/dim 1.1125(1.1138) | Xent 0.0556(0.0542) | Loss 1.1403(1.1409) | Error 0.0166(0.0167) Steps 410(411.90) | Grad Norm 0.2602(0.6415) | Total Time 10.00(10.00)\n",
      "Iter 2589 | Time 29.2786(30.3310) | Bit/dim 1.1127(1.1138) | Xent 0.0473(0.0540) | Loss 1.1363(1.1408) | Error 0.0158(0.0167) Steps 410(411.84) | Grad Norm 0.1896(0.6279) | Total Time 10.00(10.00)\n",
      "Iter 2590 | Time 29.1113(30.2944) | Bit/dim 1.1103(1.1137) | Xent 0.0519(0.0540) | Loss 1.1363(1.1406) | Error 0.0161(0.0167) Steps 410(411.79) | Grad Norm 0.2693(0.6171) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 15.9303, Epoch Time 235.7477(240.1497), Bit/dim 1.1053(best: 1.1059), Xent 0.0318, Loss 1.1212, Error 0.0092(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2591 | Time 30.4304(30.2985) | Bit/dim 1.1075(1.1135) | Xent 0.0553(0.0540) | Loss 1.1352(1.1405) | Error 0.0170(0.0167) Steps 410(411.73) | Grad Norm 0.3046(0.6078) | Total Time 10.00(10.00)\n",
      "Iter 2592 | Time 30.2130(30.2959) | Bit/dim 1.1119(1.1134) | Xent 0.0533(0.0540) | Loss 1.1385(1.1404) | Error 0.0152(0.0166) Steps 410(411.68) | Grad Norm 0.3042(0.5987) | Total Time 10.00(10.00)\n",
      "Iter 2593 | Time 29.1033(30.2601) | Bit/dim 1.1117(1.1134) | Xent 0.0488(0.0538) | Loss 1.1361(1.1403) | Error 0.0145(0.0166) Steps 410(411.63) | Grad Norm 0.3498(0.5912) | Total Time 10.00(10.00)\n",
      "Iter 2594 | Time 29.7837(30.2458) | Bit/dim 1.1157(1.1134) | Xent 0.0489(0.0537) | Loss 1.1401(1.1403) | Error 0.0144(0.0165) Steps 416(411.76) | Grad Norm 0.4066(0.5857) | Total Time 10.00(10.00)\n",
      "Iter 2595 | Time 31.3391(30.2786) | Bit/dim 1.1100(1.1133) | Xent 0.0491(0.0535) | Loss 1.1346(1.1401) | Error 0.0160(0.0165) Steps 410(411.71) | Grad Norm 0.1892(0.5738) | Total Time 10.00(10.00)\n",
      "Iter 2596 | Time 29.7303(30.2622) | Bit/dim 1.1101(1.1133) | Xent 0.0534(0.0535) | Loss 1.1368(1.1400) | Error 0.0146(0.0164) Steps 410(411.66) | Grad Norm 0.1571(0.5613) | Total Time 10.00(10.00)\n",
      "Iter 2597 | Time 29.2829(30.2328) | Bit/dim 1.1119(1.1132) | Xent 0.0565(0.0536) | Loss 1.1401(1.1400) | Error 0.0174(0.0165) Steps 410(411.61) | Grad Norm 0.1941(0.5503) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 16.2803, Epoch Time 238.7220(240.1069), Bit/dim 1.1053(best: 1.1053), Xent 0.0332, Loss 1.1219, Error 0.0105(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2598 | Time 29.9022(30.2229) | Bit/dim 1.1131(1.1132) | Xent 0.0557(0.0537) | Loss 1.1410(1.1401) | Error 0.0160(0.0164) Steps 410(411.56) | Grad Norm 0.3856(0.5453) | Total Time 10.00(10.00)\n",
      "Iter 2599 | Time 29.8426(30.2115) | Bit/dim 1.1106(1.1131) | Xent 0.0496(0.0536) | Loss 1.1353(1.1399) | Error 0.0155(0.0164) Steps 410(411.51) | Grad Norm 0.3281(0.5388) | Total Time 10.00(10.00)\n",
      "Iter 2600 | Time 29.7563(30.1978) | Bit/dim 1.1107(1.1131) | Xent 0.0561(0.0536) | Loss 1.1388(1.1399) | Error 0.0158(0.0164) Steps 410(411.47) | Grad Norm 0.2354(0.5297) | Total Time 10.00(10.00)\n",
      "Iter 2601 | Time 29.7011(30.1829) | Bit/dim 1.1101(1.1130) | Xent 0.0582(0.0538) | Loss 1.1392(1.1399) | Error 0.0185(0.0165) Steps 410(411.42) | Grad Norm 0.2370(0.5209) | Total Time 10.00(10.00)\n",
      "Iter 2602 | Time 30.7424(30.1997) | Bit/dim 1.1140(1.1130) | Xent 0.0547(0.0538) | Loss 1.1414(1.1399) | Error 0.0159(0.0164) Steps 410(411.38) | Grad Norm 0.2636(0.5132) | Total Time 10.00(10.00)\n",
      "Iter 2603 | Time 30.5580(30.2104) | Bit/dim 1.1118(1.1130) | Xent 0.0477(0.0536) | Loss 1.1356(1.1398) | Error 0.0142(0.0164) Steps 410(411.34) | Grad Norm 0.2093(0.5041) | Total Time 10.00(10.00)\n",
      "Iter 2604 | Time 29.7521(30.1967) | Bit/dim 1.1121(1.1129) | Xent 0.0524(0.0536) | Loss 1.1382(1.1397) | Error 0.0159(0.0164) Steps 410(411.30) | Grad Norm 0.2971(0.4979) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 16.2189, Epoch Time 238.7129(240.0651), Bit/dim 1.1054(best: 1.1053), Xent 0.0317, Loss 1.1213, Error 0.0109(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2605 | Time 29.3652(30.1718) | Bit/dim 1.1113(1.1129) | Xent 0.0485(0.0534) | Loss 1.1356(1.1396) | Error 0.0146(0.0163) Steps 410(411.26) | Grad Norm 0.2048(0.4891) | Total Time 10.00(10.00)\n",
      "Iter 2606 | Time 31.5274(30.2124) | Bit/dim 1.1124(1.1129) | Xent 0.0551(0.0535) | Loss 1.1400(1.1396) | Error 0.0159(0.0163) Steps 416(411.40) | Grad Norm 0.2472(0.4818) | Total Time 10.00(10.00)\n",
      "Iter 2607 | Time 30.5087(30.2213) | Bit/dim 1.1119(1.1128) | Xent 0.0488(0.0533) | Loss 1.1363(1.1395) | Error 0.0154(0.0163) Steps 410(411.36) | Grad Norm 0.1891(0.4730) | Total Time 10.00(10.00)\n",
      "Iter 2608 | Time 29.5778(30.2020) | Bit/dim 1.1052(1.1126) | Xent 0.0577(0.0535) | Loss 1.1340(1.1393) | Error 0.0165(0.0163) Steps 410(411.32) | Grad Norm 0.3008(0.4679) | Total Time 10.00(10.00)\n",
      "Iter 2609 | Time 29.9523(30.1945) | Bit/dim 1.1101(1.1125) | Xent 0.0520(0.0534) | Loss 1.1361(1.1393) | Error 0.0169(0.0163) Steps 410(411.28) | Grad Norm 0.2711(0.4620) | Total Time 10.00(10.00)\n",
      "Iter 2610 | Time 30.5121(30.2040) | Bit/dim 1.1112(1.1125) | Xent 0.0537(0.0534) | Loss 1.1381(1.1392) | Error 0.0182(0.0164) Steps 410(411.24) | Grad Norm 0.2494(0.4556) | Total Time 10.00(10.00)\n",
      "Iter 2611 | Time 29.8855(30.1945) | Bit/dim 1.1154(1.1126) | Xent 0.0581(0.0536) | Loss 1.1445(1.1394) | Error 0.0168(0.0164) Steps 410(411.20) | Grad Norm 0.1974(0.4478) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 16.1446, Epoch Time 239.6848(240.0536), Bit/dim 1.1056(best: 1.1053), Xent 0.0317, Loss 1.1214, Error 0.0099(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2612 | Time 30.1005(30.1917) | Bit/dim 1.1092(1.1125) | Xent 0.0495(0.0535) | Loss 1.1339(1.1392) | Error 0.0146(0.0163) Steps 410(411.17) | Grad Norm 0.1575(0.4391) | Total Time 10.00(10.00)\n",
      "Iter 2613 | Time 29.3978(30.1678) | Bit/dim 1.1079(1.1123) | Xent 0.0513(0.0534) | Loss 1.1335(1.1390) | Error 0.0176(0.0163) Steps 410(411.13) | Grad Norm 0.1957(0.4318) | Total Time 10.00(10.00)\n",
      "Iter 2614 | Time 30.8531(30.1884) | Bit/dim 1.1119(1.1123) | Xent 0.0483(0.0532) | Loss 1.1360(1.1390) | Error 0.0142(0.0163) Steps 410(411.10) | Grad Norm 0.2403(0.4261) | Total Time 10.00(10.00)\n",
      "Iter 2615 | Time 29.5721(30.1699) | Bit/dim 1.1137(1.1124) | Xent 0.0551(0.0533) | Loss 1.1412(1.1390) | Error 0.0172(0.0163) Steps 410(411.07) | Grad Norm 0.1701(0.4184) | Total Time 10.00(10.00)\n",
      "Iter 2616 | Time 29.0218(30.1355) | Bit/dim 1.1120(1.1124) | Xent 0.0464(0.0531) | Loss 1.1352(1.1389) | Error 0.0140(0.0162) Steps 410(411.03) | Grad Norm 0.1556(0.4105) | Total Time 10.00(10.00)\n",
      "Iter 2617 | Time 30.6128(30.1498) | Bit/dim 1.1174(1.1125) | Xent 0.0491(0.0530) | Loss 1.1419(1.1390) | Error 0.0142(0.0162) Steps 410(411.00) | Grad Norm 0.1384(0.4024) | Total Time 10.00(10.00)\n",
      "Iter 2618 | Time 31.1079(30.1785) | Bit/dim 1.1094(1.1124) | Xent 0.0552(0.0530) | Loss 1.1370(1.1389) | Error 0.0168(0.0162) Steps 410(410.97) | Grad Norm 0.1972(0.3962) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 15.9869, Epoch Time 238.7678(240.0151), Bit/dim 1.1056(best: 1.1053), Xent 0.0335, Loss 1.1224, Error 0.0108(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2619 | Time 29.3940(30.1550) | Bit/dim 1.1101(1.1123) | Xent 0.0484(0.0529) | Loss 1.1343(1.1388) | Error 0.0138(0.0161) Steps 410(410.94) | Grad Norm 0.1880(0.3900) | Total Time 10.00(10.00)\n",
      "Iter 2620 | Time 30.2641(30.1583) | Bit/dim 1.1092(1.1123) | Xent 0.0576(0.0530) | Loss 1.1380(1.1388) | Error 0.0169(0.0162) Steps 416(411.10) | Grad Norm 0.1396(0.3824) | Total Time 10.00(10.00)\n",
      "Iter 2621 | Time 29.0593(30.1253) | Bit/dim 1.1154(1.1123) | Xent 0.0577(0.0532) | Loss 1.1443(1.1389) | Error 0.0166(0.0162) Steps 410(411.06) | Grad Norm 0.1696(0.3761) | Total Time 10.00(10.00)\n",
      "Iter 2622 | Time 29.7204(30.1132) | Bit/dim 1.1118(1.1123) | Xent 0.0508(0.0531) | Loss 1.1372(1.1389) | Error 0.0158(0.0162) Steps 410(411.03) | Grad Norm 0.1466(0.3692) | Total Time 10.00(10.00)\n",
      "Iter 2623 | Time 29.5049(30.0949) | Bit/dim 1.1071(1.1122) | Xent 0.0569(0.0532) | Loss 1.1355(1.1388) | Error 0.0186(0.0162) Steps 410(411.00) | Grad Norm 0.2136(0.3645) | Total Time 10.00(10.00)\n",
      "Iter 2624 | Time 29.2879(30.0707) | Bit/dim 1.1141(1.1122) | Xent 0.0514(0.0532) | Loss 1.1398(1.1388) | Error 0.0151(0.0162) Steps 410(410.97) | Grad Norm 0.2000(0.3596) | Total Time 10.00(10.00)\n",
      "Iter 2625 | Time 29.3957(30.0504) | Bit/dim 1.1097(1.1122) | Xent 0.0483(0.0530) | Loss 1.1338(1.1387) | Error 0.0155(0.0162) Steps 410(410.94) | Grad Norm 0.2448(0.3561) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 16.2853, Epoch Time 235.1180(239.8682), Bit/dim 1.1052(best: 1.1053), Xent 0.0329, Loss 1.1217, Error 0.0113(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2626 | Time 31.0240(30.0797) | Bit/dim 1.1156(1.1123) | Xent 0.0540(0.0531) | Loss 1.1426(1.1388) | Error 0.0159(0.0162) Steps 410(410.91) | Grad Norm 0.2588(0.3532) | Total Time 10.00(10.00)\n",
      "Iter 2627 | Time 30.3161(30.0867) | Bit/dim 1.1096(1.1122) | Xent 0.0473(0.0529) | Loss 1.1333(1.1386) | Error 0.0146(0.0161) Steps 410(410.89) | Grad Norm 0.1859(0.3482) | Total Time 10.00(10.00)\n",
      "Iter 2628 | Time 30.9758(30.1134) | Bit/dim 1.1060(1.1120) | Xent 0.0534(0.0529) | Loss 1.1327(1.1384) | Error 0.0174(0.0162) Steps 410(410.86) | Grad Norm 0.2148(0.3442) | Total Time 10.00(10.00)\n",
      "Iter 2629 | Time 29.7377(30.1021) | Bit/dim 1.1089(1.1119) | Xent 0.0522(0.0529) | Loss 1.1350(1.1383) | Error 0.0161(0.0162) Steps 416(411.01) | Grad Norm 0.2278(0.3407) | Total Time 10.00(10.00)\n",
      "Iter 2630 | Time 30.1050(30.1022) | Bit/dim 1.1106(1.1119) | Xent 0.0535(0.0529) | Loss 1.1374(1.1383) | Error 0.0172(0.0162) Steps 416(411.16) | Grad Norm 0.3971(0.3424) | Total Time 10.00(10.00)\n",
      "Iter 2631 | Time 29.0639(30.0711) | Bit/dim 1.1113(1.1118) | Xent 0.0593(0.0531) | Loss 1.1410(1.1384) | Error 0.0178(0.0162) Steps 410(411.13) | Grad Norm 0.2297(0.3390) | Total Time 10.00(10.00)\n",
      "Iter 2632 | Time 29.2565(30.0466) | Bit/dim 1.1129(1.1119) | Xent 0.0473(0.0529) | Loss 1.1365(1.1383) | Error 0.0148(0.0162) Steps 410(411.09) | Grad Norm 0.1548(0.3335) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 16.0660, Epoch Time 238.9394(239.8403), Bit/dim 1.1051(best: 1.1052), Xent 0.0327, Loss 1.1215, Error 0.0103(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2633 | Time 30.6011(30.0633) | Bit/dim 1.1181(1.1121) | Xent 0.0541(0.0530) | Loss 1.1452(1.1385) | Error 0.0159(0.0162) Steps 416(411.24) | Grad Norm 0.3530(0.3341) | Total Time 10.00(10.00)\n",
      "Iter 2634 | Time 29.6382(30.0505) | Bit/dim 1.1121(1.1121) | Xent 0.0545(0.0530) | Loss 1.1394(1.1386) | Error 0.0166(0.0162) Steps 410(411.20) | Grad Norm 0.2419(0.3313) | Total Time 10.00(10.00)\n",
      "Iter 2635 | Time 29.4375(30.0321) | Bit/dim 1.1110(1.1120) | Xent 0.0545(0.0530) | Loss 1.1383(1.1386) | Error 0.0168(0.0162) Steps 410(411.17) | Grad Norm 0.1977(0.3273) | Total Time 10.00(10.00)\n",
      "Iter 2636 | Time 30.1568(30.0359) | Bit/dim 1.1087(1.1119) | Xent 0.0487(0.0529) | Loss 1.1331(1.1384) | Error 0.0150(0.0162) Steps 410(411.13) | Grad Norm 0.1830(0.3230) | Total Time 10.00(10.00)\n",
      "Iter 2637 | Time 30.6327(30.0538) | Bit/dim 1.1063(1.1118) | Xent 0.0441(0.0527) | Loss 1.1283(1.1381) | Error 0.0142(0.0161) Steps 410(411.10) | Grad Norm 0.1837(0.3188) | Total Time 10.00(10.00)\n",
      "Iter 2638 | Time 28.8138(30.0166) | Bit/dim 1.1122(1.1118) | Xent 0.0510(0.0526) | Loss 1.1377(1.1381) | Error 0.0159(0.0161) Steps 410(411.07) | Grad Norm 0.4228(0.3219) | Total Time 10.00(10.00)\n",
      "Iter 2639 | Time 30.3306(30.0260) | Bit/dim 1.1102(1.1117) | Xent 0.0565(0.0527) | Loss 1.1384(1.1381) | Error 0.0182(0.0162) Steps 410(411.03) | Grad Norm 0.2516(0.3198) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 16.0665, Epoch Time 237.8828(239.7816), Bit/dim 1.1051(best: 1.1051), Xent 0.0318, Loss 1.1210, Error 0.0102(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2640 | Time 29.2248(30.0020) | Bit/dim 1.1067(1.1116) | Xent 0.0540(0.0528) | Loss 1.1337(1.1380) | Error 0.0161(0.0162) Steps 410(411.00) | Grad Norm 0.1393(0.3144) | Total Time 10.00(10.00)\n",
      "Iter 2641 | Time 29.3737(29.9831) | Bit/dim 1.1218(1.1119) | Xent 0.0547(0.0528) | Loss 1.1492(1.1383) | Error 0.0172(0.0162) Steps 410(410.97) | Grad Norm 0.2202(0.3116) | Total Time 10.00(10.00)\n",
      "Iter 2642 | Time 29.8021(29.9777) | Bit/dim 1.1088(1.1118) | Xent 0.0519(0.0528) | Loss 1.1347(1.1382) | Error 0.0161(0.0162) Steps 410(410.94) | Grad Norm 0.2118(0.3086) | Total Time 10.00(10.00)\n",
      "Iter 2643 | Time 29.2990(29.9573) | Bit/dim 1.1064(1.1116) | Xent 0.0539(0.0528) | Loss 1.1334(1.1380) | Error 0.0168(0.0162) Steps 410(410.92) | Grad Norm 0.1748(0.3046) | Total Time 10.00(10.00)\n",
      "Iter 2644 | Time 29.9649(29.9576) | Bit/dim 1.1119(1.1116) | Xent 0.0523(0.0528) | Loss 1.1381(1.1380) | Error 0.0162(0.0162) Steps 410(410.89) | Grad Norm 0.2002(0.3014) | Total Time 10.00(10.00)\n",
      "Iter 2645 | Time 29.6136(29.9472) | Bit/dim 1.1165(1.1118) | Xent 0.0580(0.0530) | Loss 1.1455(1.1383) | Error 0.0162(0.0162) Steps 410(410.86) | Grad Norm 0.2638(0.3003) | Total Time 10.00(10.00)\n",
      "Iter 2646 | Time 29.4064(29.9310) | Bit/dim 1.1057(1.1116) | Xent 0.0495(0.0528) | Loss 1.1305(1.1380) | Error 0.0135(0.0161) Steps 410(410.84) | Grad Norm 0.1514(0.2958) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 16.1006, Epoch Time 235.0737(239.6403), Bit/dim 1.1053(best: 1.1051), Xent 0.0349, Loss 1.1227, Error 0.0116(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2647 | Time 30.3740(29.9443) | Bit/dim 1.1130(1.1117) | Xent 0.0619(0.0531) | Loss 1.1439(1.1382) | Error 0.0190(0.0162) Steps 410(410.81) | Grad Norm 0.2704(0.2951) | Total Time 10.00(10.00)\n",
      "Iter 2648 | Time 29.5491(29.9324) | Bit/dim 1.1118(1.1117) | Xent 0.0613(0.0534) | Loss 1.1424(1.1383) | Error 0.0184(0.0163) Steps 410(410.79) | Grad Norm 0.1998(0.2922) | Total Time 10.00(10.00)\n",
      "Iter 2649 | Time 28.9760(29.9037) | Bit/dim 1.1142(1.1117) | Xent 0.0567(0.0535) | Loss 1.1426(1.1385) | Error 0.0175(0.0163) Steps 410(410.76) | Grad Norm 0.2695(0.2915) | Total Time 10.00(10.00)\n",
      "Iter 2650 | Time 30.1784(29.9120) | Bit/dim 1.1096(1.1117) | Xent 0.0584(0.0536) | Loss 1.1388(1.1385) | Error 0.0170(0.0163) Steps 410(410.74) | Grad Norm 0.1488(0.2872) | Total Time 10.00(10.00)\n",
      "Iter 2651 | Time 30.4984(29.9296) | Bit/dim 1.1099(1.1116) | Xent 0.0482(0.0535) | Loss 1.1340(1.1383) | Error 0.0125(0.0162) Steps 410(410.72) | Grad Norm 0.2596(0.2864) | Total Time 10.00(10.00)\n",
      "Iter 2652 | Time 30.1066(29.9349) | Bit/dim 1.1127(1.1116) | Xent 0.0540(0.0535) | Loss 1.1397(1.1384) | Error 0.0156(0.0162) Steps 410(410.70) | Grad Norm 0.1673(0.2828) | Total Time 10.00(10.00)\n",
      "Iter 2653 | Time 28.7830(29.9003) | Bit/dim 1.1058(1.1115) | Xent 0.0487(0.0533) | Loss 1.1302(1.1381) | Error 0.0156(0.0162) Steps 410(410.67) | Grad Norm 0.1796(0.2797) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 16.2276, Epoch Time 237.2024(239.5672), Bit/dim 1.1053(best: 1.1051), Xent 0.0333, Loss 1.1220, Error 0.0109(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2654 | Time 30.3098(29.9126) | Bit/dim 1.1135(1.1115) | Xent 0.0598(0.0535) | Loss 1.1434(1.1383) | Error 0.0159(0.0162) Steps 410(410.65) | Grad Norm 0.2153(0.2778) | Total Time 10.00(10.00)\n",
      "Iter 2655 | Time 29.5009(29.9003) | Bit/dim 1.1068(1.1114) | Xent 0.0617(0.0538) | Loss 1.1377(1.1383) | Error 0.0181(0.0162) Steps 410(410.64) | Grad Norm 0.2001(0.2755) | Total Time 10.00(10.00)\n",
      "Iter 2656 | Time 30.4062(29.9154) | Bit/dim 1.1093(1.1113) | Xent 0.0539(0.0538) | Loss 1.1362(1.1382) | Error 0.0169(0.0163) Steps 410(410.62) | Grad Norm 0.1517(0.2718) | Total Time 10.00(10.00)\n",
      "Iter 2657 | Time 29.5309(29.9039) | Bit/dim 1.1069(1.1112) | Xent 0.0492(0.0536) | Loss 1.1315(1.1380) | Error 0.0149(0.0162) Steps 410(410.60) | Grad Norm 0.1603(0.2684) | Total Time 10.00(10.00)\n",
      "Iter 2658 | Time 29.7326(29.8988) | Bit/dim 1.1147(1.1113) | Xent 0.0503(0.0535) | Loss 1.1399(1.1381) | Error 0.0156(0.0162) Steps 410(410.58) | Grad Norm 0.1852(0.2659) | Total Time 10.00(10.00)\n",
      "Iter 2659 | Time 30.6228(29.9205) | Bit/dim 1.1095(1.1113) | Xent 0.0543(0.0536) | Loss 1.1366(1.1380) | Error 0.0161(0.0162) Steps 410(410.56) | Grad Norm 0.2569(0.2657) | Total Time 10.00(10.00)\n",
      "Iter 2660 | Time 30.1464(29.9273) | Bit/dim 1.1157(1.1114) | Xent 0.0571(0.0537) | Loss 1.1443(1.1382) | Error 0.0180(0.0163) Steps 416(410.73) | Grad Norm 0.3457(0.2681) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 16.0870, Epoch Time 238.4820(239.5346), Bit/dim 1.1055(best: 1.1051), Xent 0.0300, Loss 1.1205, Error 0.0103(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2661 | Time 29.1783(29.9048) | Bit/dim 1.1139(1.1115) | Xent 0.0445(0.0534) | Loss 1.1362(1.1382) | Error 0.0151(0.0162) Steps 410(410.70) | Grad Norm 0.1353(0.2641) | Total Time 10.00(10.00)\n",
      "Iter 2662 | Time 30.8409(29.9329) | Bit/dim 1.1082(1.1114) | Xent 0.0558(0.0535) | Loss 1.1361(1.1381) | Error 0.0161(0.0162) Steps 410(410.68) | Grad Norm 0.1634(0.2611) | Total Time 10.00(10.00)\n",
      "Iter 2663 | Time 29.1916(29.9106) | Bit/dim 1.1096(1.1113) | Xent 0.0572(0.0536) | Loss 1.1382(1.1381) | Error 0.0178(0.0163) Steps 416(410.84) | Grad Norm 0.2189(0.2598) | Total Time 10.00(10.00)\n",
      "Iter 2664 | Time 29.9351(29.9114) | Bit/dim 1.1127(1.1114) | Xent 0.0518(0.0535) | Loss 1.1386(1.1381) | Error 0.0174(0.0163) Steps 410(410.82) | Grad Norm 0.1666(0.2570) | Total Time 10.00(10.00)\n",
      "Iter 2665 | Time 30.5017(29.9291) | Bit/dim 1.1109(1.1113) | Xent 0.0522(0.0535) | Loss 1.1370(1.1381) | Error 0.0170(0.0163) Steps 410(410.79) | Grad Norm 0.1436(0.2536) | Total Time 10.00(10.00)\n",
      "Iter 2666 | Time 29.2209(29.9078) | Bit/dim 1.1106(1.1113) | Xent 0.0559(0.0536) | Loss 1.1385(1.1381) | Error 0.0164(0.0163) Steps 410(410.77) | Grad Norm 0.2599(0.2538) | Total Time 10.00(10.00)\n",
      "Iter 2667 | Time 29.2299(29.8875) | Bit/dim 1.1093(1.1113) | Xent 0.0558(0.0536) | Loss 1.1372(1.1381) | Error 0.0155(0.0163) Steps 410(410.75) | Grad Norm 0.2050(0.2523) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 15.9768, Epoch Time 236.4819(239.4431), Bit/dim 1.1055(best: 1.1051), Xent 0.0311, Loss 1.1211, Error 0.0098(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2668 | Time 31.3005(29.9299) | Bit/dim 1.1120(1.1113) | Xent 0.0531(0.0536) | Loss 1.1385(1.1381) | Error 0.0158(0.0163) Steps 410(410.72) | Grad Norm 0.1683(0.2498) | Total Time 10.00(10.00)\n",
      "Iter 2669 | Time 30.0362(29.9331) | Bit/dim 1.1131(1.1113) | Xent 0.0563(0.0537) | Loss 1.1413(1.1382) | Error 0.0194(0.0164) Steps 410(410.70) | Grad Norm 0.2433(0.2496) | Total Time 10.00(10.00)\n",
      "Iter 2670 | Time 29.7883(29.9287) | Bit/dim 1.1085(1.1112) | Xent 0.0548(0.0537) | Loss 1.1359(1.1381) | Error 0.0178(0.0164) Steps 410(410.68) | Grad Norm 0.3800(0.2535) | Total Time 10.00(10.00)\n",
      "Iter 2671 | Time 30.4889(29.9455) | Bit/dim 1.1134(1.1113) | Xent 0.0484(0.0536) | Loss 1.1376(1.1381) | Error 0.0155(0.0164) Steps 410(410.66) | Grad Norm 0.2693(0.2540) | Total Time 10.00(10.00)\n",
      "Iter 2672 | Time 29.8954(29.9440) | Bit/dim 1.1099(1.1113) | Xent 0.0549(0.0536) | Loss 1.1374(1.1381) | Error 0.0164(0.0164) Steps 410(410.64) | Grad Norm 0.1741(0.2516) | Total Time 10.00(10.00)\n",
      "Iter 2673 | Time 29.3042(29.9248) | Bit/dim 1.1077(1.1112) | Xent 0.0521(0.0536) | Loss 1.1338(1.1379) | Error 0.0149(0.0163) Steps 410(410.62) | Grad Norm 0.1783(0.2494) | Total Time 10.00(10.00)\n",
      "Iter 2674 | Time 30.4465(29.9405) | Bit/dim 1.1150(1.1113) | Xent 0.0534(0.0535) | Loss 1.1417(1.1381) | Error 0.0159(0.0163) Steps 410(410.60) | Grad Norm 0.2480(0.2493) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 16.2224, Epoch Time 239.5622(239.4466), Bit/dim 1.1055(best: 1.1051), Xent 0.0311, Loss 1.1211, Error 0.0090(best: 0.0092)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2675 | Time 28.8233(29.9070) | Bit/dim 1.1053(1.1111) | Xent 0.0519(0.0535) | Loss 1.1313(1.1378) | Error 0.0155(0.0163) Steps 410(410.58) | Grad Norm 0.2803(0.2503) | Total Time 10.00(10.00)\n",
      "Iter 2676 | Time 30.4186(29.9223) | Bit/dim 1.1085(1.1110) | Xent 0.0547(0.0535) | Loss 1.1358(1.1378) | Error 0.0162(0.0163) Steps 410(410.57) | Grad Norm 0.1400(0.2470) | Total Time 10.00(10.00)\n",
      "Iter 2677 | Time 29.2996(29.9036) | Bit/dim 1.1106(1.1110) | Xent 0.0535(0.0535) | Loss 1.1374(1.1378) | Error 0.0178(0.0163) Steps 410(410.55) | Grad Norm 0.1852(0.2451) | Total Time 10.00(10.00)\n",
      "Iter 2678 | Time 30.0568(29.9082) | Bit/dim 1.1142(1.1111) | Xent 0.0510(0.0535) | Loss 1.1397(1.1378) | Error 0.0164(0.0163) Steps 410(410.53) | Grad Norm 0.2297(0.2447) | Total Time 10.00(10.00)\n",
      "Iter 2679 | Time 30.2952(29.9198) | Bit/dim 1.1112(1.1111) | Xent 0.0551(0.0535) | Loss 1.1387(1.1379) | Error 0.0169(0.0164) Steps 410(410.52) | Grad Norm 0.2690(0.2454) | Total Time 10.00(10.00)\n",
      "Iter 2680 | Time 29.2443(29.8996) | Bit/dim 1.1103(1.1111) | Xent 0.0509(0.0534) | Loss 1.1358(1.1378) | Error 0.0140(0.0163) Steps 410(410.50) | Grad Norm 0.1629(0.2429) | Total Time 10.00(10.00)\n",
      "Iter 2681 | Time 30.2099(29.9089) | Bit/dim 1.1153(1.1112) | Xent 0.0521(0.0534) | Loss 1.1413(1.1379) | Error 0.0160(0.0163) Steps 416(410.67) | Grad Norm 0.1668(0.2406) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 16.0438, Epoch Time 236.6772(239.3636), Bit/dim 1.1052(best: 1.1051), Xent 0.0335, Loss 1.1219, Error 0.0108(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2682 | Time 28.8969(29.8785) | Bit/dim 1.1126(1.1113) | Xent 0.0487(0.0532) | Loss 1.1370(1.1379) | Error 0.0160(0.0163) Steps 410(410.65) | Grad Norm 0.2647(0.2413) | Total Time 10.00(10.00)\n",
      "Iter 2683 | Time 29.6003(29.8702) | Bit/dim 1.1102(1.1112) | Xent 0.0539(0.0533) | Loss 1.1371(1.1379) | Error 0.0168(0.0163) Steps 410(410.63) | Grad Norm 0.1849(0.2397) | Total Time 10.00(10.00)\n",
      "Iter 2684 | Time 30.4831(29.8886) | Bit/dim 1.1106(1.1112) | Xent 0.0511(0.0532) | Loss 1.1362(1.1378) | Error 0.0142(0.0162) Steps 410(410.61) | Grad Norm 0.1729(0.2376) | Total Time 10.00(10.00)\n",
      "Iter 2685 | Time 30.3850(29.9035) | Bit/dim 1.1118(1.1112) | Xent 0.0545(0.0532) | Loss 1.1390(1.1378) | Error 0.0182(0.0163) Steps 410(410.59) | Grad Norm 0.2774(0.2388) | Total Time 10.00(10.00)\n",
      "Iter 2686 | Time 29.8813(29.9028) | Bit/dim 1.1128(1.1113) | Xent 0.0573(0.0534) | Loss 1.1415(1.1380) | Error 0.0170(0.0163) Steps 410(410.57) | Grad Norm 0.1842(0.2372) | Total Time 10.00(10.00)\n",
      "Iter 2687 | Time 28.5881(29.8634) | Bit/dim 1.1100(1.1112) | Xent 0.0537(0.0534) | Loss 1.1369(1.1379) | Error 0.0169(0.0163) Steps 410(410.56) | Grad Norm 0.1841(0.2356) | Total Time 10.00(10.00)\n",
      "Iter 2688 | Time 29.6482(29.8569) | Bit/dim 1.1102(1.1112) | Xent 0.0535(0.0534) | Loss 1.1370(1.1379) | Error 0.0155(0.0163) Steps 416(410.72) | Grad Norm 0.2541(0.2362) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 16.1526, Epoch Time 235.6913(239.2534), Bit/dim 1.1053(best: 1.1051), Xent 0.0331, Loss 1.1218, Error 0.0110(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2689 | Time 30.2361(29.8683) | Bit/dim 1.1110(1.1112) | Xent 0.0519(0.0533) | Loss 1.1369(1.1379) | Error 0.0168(0.0163) Steps 410(410.70) | Grad Norm 0.2934(0.2379) | Total Time 10.00(10.00)\n",
      "Iter 2690 | Time 30.8639(29.8981) | Bit/dim 1.1087(1.1111) | Xent 0.0520(0.0533) | Loss 1.1347(1.1378) | Error 0.0165(0.0163) Steps 410(410.68) | Grad Norm 0.2425(0.2380) | Total Time 10.00(10.00)\n",
      "Iter 2691 | Time 30.5912(29.9189) | Bit/dim 1.1109(1.1111) | Xent 0.0493(0.0532) | Loss 1.1355(1.1377) | Error 0.0155(0.0163) Steps 410(410.66) | Grad Norm 0.1960(0.2368) | Total Time 10.00(10.00)\n",
      "Iter 2692 | Time 30.5358(29.9374) | Bit/dim 1.1109(1.1111) | Xent 0.0479(0.0530) | Loss 1.1348(1.1376) | Error 0.0159(0.0163) Steps 410(410.64) | Grad Norm 0.2637(0.2376) | Total Time 10.00(10.00)\n",
      "Iter 2693 | Time 29.9799(29.9387) | Bit/dim 1.1122(1.1111) | Xent 0.0538(0.0530) | Loss 1.1391(1.1377) | Error 0.0161(0.0163) Steps 410(410.62) | Grad Norm 0.2527(0.2380) | Total Time 10.00(10.00)\n",
      "Iter 2694 | Time 28.7541(29.9032) | Bit/dim 1.1115(1.1111) | Xent 0.0566(0.0531) | Loss 1.1398(1.1377) | Error 0.0170(0.0163) Steps 410(410.60) | Grad Norm 0.4448(0.2442) | Total Time 10.00(10.00)\n",
      "Iter 2695 | Time 29.7037(29.8972) | Bit/dim 1.1121(1.1112) | Xent 0.0564(0.0532) | Loss 1.1403(1.1378) | Error 0.0162(0.0163) Steps 410(410.58) | Grad Norm 0.1761(0.2422) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 16.0380, Epoch Time 239.0132(239.2462), Bit/dim 1.1051(best: 1.1051), Xent 0.0329, Loss 1.1215, Error 0.0096(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2696 | Time 28.6859(29.8609) | Bit/dim 1.1145(1.1113) | Xent 0.0512(0.0532) | Loss 1.1401(1.1379) | Error 0.0158(0.0163) Steps 410(410.56) | Grad Norm 0.2160(0.2414) | Total Time 10.00(10.00)\n",
      "Iter 2697 | Time 29.1767(29.8403) | Bit/dim 1.1061(1.1111) | Xent 0.0549(0.0532) | Loss 1.1336(1.1377) | Error 0.0172(0.0163) Steps 410(410.55) | Grad Norm 0.1951(0.2400) | Total Time 10.00(10.00)\n",
      "Iter 2698 | Time 29.2311(29.8221) | Bit/dim 1.1068(1.1110) | Xent 0.0462(0.0530) | Loss 1.1299(1.1375) | Error 0.0145(0.0163) Steps 410(410.53) | Grad Norm 0.3673(0.2438) | Total Time 10.00(10.00)\n",
      "Iter 2699 | Time 29.6992(29.8184) | Bit/dim 1.1094(1.1109) | Xent 0.0492(0.0529) | Loss 1.1340(1.1374) | Error 0.0145(0.0162) Steps 410(410.51) | Grad Norm 0.2830(0.2450) | Total Time 10.00(10.00)\n",
      "Iter 2700 | Time 30.0964(29.8267) | Bit/dim 1.1147(1.1111) | Xent 0.0643(0.0533) | Loss 1.1469(1.1377) | Error 0.0184(0.0163) Steps 410(410.50) | Grad Norm 0.1937(0.2435) | Total Time 10.00(10.00)\n",
      "Iter 2701 | Time 29.6211(29.8205) | Bit/dim 1.1104(1.1110) | Xent 0.0536(0.0533) | Loss 1.1373(1.1377) | Error 0.0161(0.0163) Steps 410(410.48) | Grad Norm 0.1832(0.2417) | Total Time 10.00(10.00)\n",
      "Iter 2702 | Time 28.9911(29.7957) | Bit/dim 1.1129(1.1111) | Xent 0.0559(0.0533) | Loss 1.1408(1.1378) | Error 0.0180(0.0163) Steps 410(410.47) | Grad Norm 0.2418(0.2417) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 16.2776, Epoch Time 234.6198(239.1074), Bit/dim 1.1050(best: 1.1051), Xent 0.0329, Loss 1.1214, Error 0.0106(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2703 | Time 29.8833(29.7983) | Bit/dim 1.1114(1.1111) | Xent 0.0543(0.0534) | Loss 1.1385(1.1378) | Error 0.0150(0.0163) Steps 410(410.46) | Grad Norm 0.2497(0.2419) | Total Time 10.00(10.00)\n",
      "Iter 2704 | Time 28.9159(29.7718) | Bit/dim 1.1140(1.1112) | Xent 0.0583(0.0535) | Loss 1.1431(1.1379) | Error 0.0171(0.0163) Steps 410(410.44) | Grad Norm 0.1847(0.2402) | Total Time 10.00(10.00)\n",
      "Iter 2705 | Time 29.0434(29.7500) | Bit/dim 1.1090(1.1111) | Xent 0.0469(0.0533) | Loss 1.1325(1.1378) | Error 0.0146(0.0163) Steps 410(410.43) | Grad Norm 0.1937(0.2388) | Total Time 10.00(10.00)\n",
      "Iter 2706 | Time 29.6362(29.7465) | Bit/dim 1.1070(1.1110) | Xent 0.0536(0.0533) | Loss 1.1338(1.1377) | Error 0.0166(0.0163) Steps 410(410.42) | Grad Norm 0.1832(0.2371) | Total Time 10.00(10.00)\n",
      "Iter 2707 | Time 29.5101(29.7395) | Bit/dim 1.1135(1.1111) | Xent 0.0555(0.0534) | Loss 1.1413(1.1378) | Error 0.0166(0.0163) Steps 410(410.40) | Grad Norm 0.1341(0.2340) | Total Time 10.00(10.00)\n",
      "Iter 2708 | Time 29.3443(29.7276) | Bit/dim 1.1138(1.1112) | Xent 0.0480(0.0532) | Loss 1.1378(1.1378) | Error 0.0151(0.0162) Steps 410(410.39) | Grad Norm 0.1461(0.2314) | Total Time 10.00(10.00)\n",
      "Iter 2709 | Time 29.1608(29.7106) | Bit/dim 1.1065(1.1110) | Xent 0.0494(0.0531) | Loss 1.1312(1.1376) | Error 0.0149(0.0162) Steps 410(410.38) | Grad Norm 0.1731(0.2296) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 15.9584, Epoch Time 233.7206(238.9458), Bit/dim 1.1047(best: 1.1050), Xent 0.0288, Loss 1.1191, Error 0.0087(best: 0.0090)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2710 | Time 29.4435(29.7026) | Bit/dim 1.1112(1.1110) | Xent 0.0556(0.0532) | Loss 1.1389(1.1376) | Error 0.0168(0.0162) Steps 410(410.37) | Grad Norm 0.1644(0.2277) | Total Time 10.00(10.00)\n",
      "Iter 2711 | Time 28.8710(29.6776) | Bit/dim 1.1122(1.1111) | Xent 0.0559(0.0533) | Loss 1.1402(1.1377) | Error 0.0180(0.0163) Steps 410(410.36) | Grad Norm 0.1992(0.2268) | Total Time 10.00(10.00)\n",
      "Iter 2712 | Time 29.3329(29.6673) | Bit/dim 1.1129(1.1111) | Xent 0.0510(0.0532) | Loss 1.1384(1.1377) | Error 0.0155(0.0162) Steps 410(410.35) | Grad Norm 0.2554(0.2277) | Total Time 10.00(10.00)\n",
      "Iter 2713 | Time 29.5498(29.6638) | Bit/dim 1.1116(1.1111) | Xent 0.0512(0.0531) | Loss 1.1372(1.1377) | Error 0.0154(0.0162) Steps 410(410.34) | Grad Norm 0.2353(0.2279) | Total Time 10.00(10.00)\n",
      "Iter 2714 | Time 29.7947(29.6677) | Bit/dim 1.1053(1.1110) | Xent 0.0563(0.0532) | Loss 1.1335(1.1376) | Error 0.0178(0.0163) Steps 410(410.33) | Grad Norm 0.1961(0.2270) | Total Time 10.00(10.00)\n",
      "Iter 2715 | Time 29.2798(29.6561) | Bit/dim 1.1079(1.1109) | Xent 0.0541(0.0533) | Loss 1.1349(1.1375) | Error 0.0159(0.0163) Steps 410(410.32) | Grad Norm 0.1905(0.2259) | Total Time 10.00(10.00)\n",
      "Iter 2716 | Time 30.6420(29.6856) | Bit/dim 1.1124(1.1109) | Xent 0.0531(0.0533) | Loss 1.1389(1.1375) | Error 0.0169(0.0163) Steps 410(410.31) | Grad Norm 0.2112(0.2254) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 16.1252, Epoch Time 235.5108(238.8427), Bit/dim 1.1046(best: 1.1047), Xent 0.0312, Loss 1.1203, Error 0.0092(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2717 | Time 30.2745(29.7033) | Bit/dim 1.1120(1.1109) | Xent 0.0601(0.0535) | Loss 1.1420(1.1377) | Error 0.0174(0.0163) Steps 410(410.30) | Grad Norm 0.3331(0.2287) | Total Time 10.00(10.00)\n",
      "Iter 2718 | Time 30.0402(29.7134) | Bit/dim 1.1140(1.1110) | Xent 0.0555(0.0535) | Loss 1.1417(1.1378) | Error 0.0152(0.0163) Steps 410(410.29) | Grad Norm 0.2042(0.2279) | Total Time 10.00(10.00)\n",
      "Iter 2719 | Time 30.0313(29.7229) | Bit/dim 1.1140(1.1111) | Xent 0.0558(0.0536) | Loss 1.1420(1.1379) | Error 0.0164(0.0163) Steps 410(410.28) | Grad Norm 0.2035(0.2272) | Total Time 10.00(10.00)\n",
      "Iter 2720 | Time 30.2889(29.7399) | Bit/dim 1.1078(1.1110) | Xent 0.0488(0.0535) | Loss 1.1322(1.1377) | Error 0.0162(0.0163) Steps 410(410.27) | Grad Norm 0.1853(0.2259) | Total Time 10.00(10.00)\n",
      "Iter 2721 | Time 29.4546(29.7314) | Bit/dim 1.1080(1.1109) | Xent 0.0482(0.0533) | Loss 1.1320(1.1376) | Error 0.0166(0.0163) Steps 410(410.26) | Grad Norm 0.2001(0.2252) | Total Time 10.00(10.00)\n",
      "Iter 2722 | Time 31.2051(29.7756) | Bit/dim 1.1077(1.1108) | Xent 0.0534(0.0533) | Loss 1.1344(1.1375) | Error 0.0168(0.0163) Steps 416(410.44) | Grad Norm 0.1651(0.2234) | Total Time 10.00(10.00)\n",
      "Iter 2723 | Time 29.9522(29.7809) | Bit/dim 1.1113(1.1108) | Xent 0.0502(0.0532) | Loss 1.1364(1.1374) | Error 0.0160(0.0163) Steps 416(410.60) | Grad Norm 0.2378(0.2238) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 16.0320, Epoch Time 239.3802(238.8589), Bit/dim 1.1055(best: 1.1046), Xent 0.0297, Loss 1.1204, Error 0.0095(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2724 | Time 29.9791(29.7868) | Bit/dim 1.1126(1.1109) | Xent 0.0532(0.0532) | Loss 1.1392(1.1375) | Error 0.0170(0.0163) Steps 410(410.58) | Grad Norm 0.2121(0.2234) | Total Time 10.00(10.00)\n",
      "Iter 2725 | Time 29.7398(29.7854) | Bit/dim 1.1122(1.1109) | Xent 0.0559(0.0533) | Loss 1.1402(1.1376) | Error 0.0165(0.0163) Steps 410(410.57) | Grad Norm 0.2035(0.2228) | Total Time 10.00(10.00)\n",
      "Iter 2726 | Time 30.4764(29.8061) | Bit/dim 1.1093(1.1109) | Xent 0.0582(0.0534) | Loss 1.1384(1.1376) | Error 0.0162(0.0163) Steps 410(410.55) | Grad Norm 0.1988(0.2221) | Total Time 10.00(10.00)\n",
      "Iter 2727 | Time 29.7202(29.8036) | Bit/dim 1.1110(1.1109) | Xent 0.0501(0.0533) | Loss 1.1360(1.1376) | Error 0.0155(0.0163) Steps 410(410.53) | Grad Norm 0.2561(0.2231) | Total Time 10.00(10.00)\n",
      "Iter 2728 | Time 29.7125(29.8008) | Bit/dim 1.1093(1.1108) | Xent 0.0527(0.0533) | Loss 1.1356(1.1375) | Error 0.0159(0.0163) Steps 410(410.52) | Grad Norm 0.1765(0.2217) | Total Time 10.00(10.00)\n",
      "Iter 2729 | Time 28.9087(29.7741) | Bit/dim 1.1134(1.1109) | Xent 0.0483(0.0532) | Loss 1.1375(1.1375) | Error 0.0141(0.0162) Steps 410(410.50) | Grad Norm 0.2033(0.2212) | Total Time 10.00(10.00)\n",
      "Iter 2730 | Time 29.2818(29.7593) | Bit/dim 1.1079(1.1108) | Xent 0.0541(0.0532) | Loss 1.1350(1.1374) | Error 0.0175(0.0163) Steps 410(410.49) | Grad Norm 0.2107(0.2209) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 16.3094, Epoch Time 236.4188(238.7857), Bit/dim 1.1044(best: 1.1046), Xent 0.0306, Loss 1.1196, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2731 | Time 30.1282(29.7704) | Bit/dim 1.1101(1.1108) | Xent 0.0503(0.0531) | Loss 1.1353(1.1374) | Error 0.0156(0.0162) Steps 416(410.65) | Grad Norm 0.2078(0.2205) | Total Time 10.00(10.00)\n",
      "Iter 2732 | Time 29.2252(29.7540) | Bit/dim 1.1152(1.1109) | Xent 0.0516(0.0531) | Loss 1.1410(1.1375) | Error 0.0148(0.0162) Steps 410(410.63) | Grad Norm 0.1615(0.2187) | Total Time 10.00(10.00)\n",
      "Iter 2733 | Time 29.1648(29.7363) | Bit/dim 1.1142(1.1110) | Xent 0.0527(0.0530) | Loss 1.1406(1.1376) | Error 0.0146(0.0161) Steps 410(410.61) | Grad Norm 0.1507(0.2167) | Total Time 10.00(10.00)\n",
      "Iter 2734 | Time 28.8593(29.7100) | Bit/dim 1.1098(1.1110) | Xent 0.0550(0.0531) | Loss 1.1373(1.1376) | Error 0.0172(0.0162) Steps 410(410.59) | Grad Norm 0.2267(0.2170) | Total Time 10.00(10.00)\n",
      "Iter 2735 | Time 30.2095(29.7250) | Bit/dim 1.1121(1.1110) | Xent 0.0528(0.0531) | Loss 1.1385(1.1376) | Error 0.0152(0.0161) Steps 416(410.76) | Grad Norm 0.1876(0.2161) | Total Time 10.00(10.00)\n",
      "Iter 2736 | Time 29.9257(29.7310) | Bit/dim 1.1074(1.1109) | Xent 0.0582(0.0532) | Loss 1.1365(1.1376) | Error 0.0162(0.0162) Steps 410(410.73) | Grad Norm 0.1962(0.2155) | Total Time 10.00(10.00)\n",
      "Iter 2737 | Time 29.6948(29.7299) | Bit/dim 1.1096(1.1109) | Xent 0.0534(0.0533) | Loss 1.1364(1.1375) | Error 0.0156(0.0161) Steps 410(410.71) | Grad Norm 0.1977(0.2150) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 16.0255, Epoch Time 235.3839(238.6836), Bit/dim 1.1054(best: 1.1044), Xent 0.0323, Loss 1.1216, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2738 | Time 30.2221(29.7447) | Bit/dim 1.1130(1.1110) | Xent 0.0553(0.0533) | Loss 1.1407(1.1376) | Error 0.0180(0.0162) Steps 416(410.87) | Grad Norm 0.2301(0.2154) | Total Time 10.00(10.00)\n",
      "Iter 2739 | Time 30.5579(29.7691) | Bit/dim 1.1104(1.1109) | Xent 0.0545(0.0533) | Loss 1.1376(1.1376) | Error 0.0152(0.0162) Steps 410(410.84) | Grad Norm 0.1505(0.2135) | Total Time 10.00(10.00)\n",
      "Iter 2740 | Time 30.0189(29.7766) | Bit/dim 1.1066(1.1108) | Xent 0.0516(0.0533) | Loss 1.1324(1.1375) | Error 0.0141(0.0161) Steps 410(410.82) | Grad Norm 0.2157(0.2135) | Total Time 10.00(10.00)\n",
      "Iter 2741 | Time 29.0412(29.7545) | Bit/dim 1.1106(1.1108) | Xent 0.0508(0.0532) | Loss 1.1360(1.1374) | Error 0.0155(0.0161) Steps 410(410.79) | Grad Norm 0.2733(0.2153) | Total Time 10.00(10.00)\n",
      "Iter 2742 | Time 30.0325(29.7629) | Bit/dim 1.1125(1.1108) | Xent 0.0455(0.0530) | Loss 1.1352(1.1373) | Error 0.0150(0.0161) Steps 410(410.77) | Grad Norm 0.1596(0.2137) | Total Time 10.00(10.00)\n",
      "Iter 2743 | Time 30.4991(29.7850) | Bit/dim 1.1106(1.1108) | Xent 0.0603(0.0532) | Loss 1.1407(1.1374) | Error 0.0186(0.0161) Steps 410(410.75) | Grad Norm 0.2410(0.2145) | Total Time 10.00(10.00)\n",
      "Iter 2744 | Time 30.4339(29.8044) | Bit/dim 1.1119(1.1109) | Xent 0.0567(0.0533) | Loss 1.1403(1.1375) | Error 0.0171(0.0162) Steps 410(410.73) | Grad Norm 0.3102(0.2174) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 16.3584, Epoch Time 239.6005(238.7111), Bit/dim 1.1052(best: 1.1044), Xent 0.0294, Loss 1.1199, Error 0.0088(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2745 | Time 29.8429(29.8056) | Bit/dim 1.1132(1.1109) | Xent 0.0552(0.0534) | Loss 1.1408(1.1376) | Error 0.0180(0.0162) Steps 410(410.70) | Grad Norm 0.2068(0.2170) | Total Time 10.00(10.00)\n",
      "Iter 2746 | Time 30.6411(29.8306) | Bit/dim 1.1098(1.1109) | Xent 0.0474(0.0532) | Loss 1.1335(1.1375) | Error 0.0136(0.0161) Steps 410(410.68) | Grad Norm 0.1785(0.2159) | Total Time 10.00(10.00)\n",
      "Iter 2747 | Time 29.5385(29.8219) | Bit/dim 1.1114(1.1109) | Xent 0.0567(0.0533) | Loss 1.1397(1.1376) | Error 0.0168(0.0162) Steps 410(410.66) | Grad Norm 0.1765(0.2147) | Total Time 10.00(10.00)\n",
      "Iter 2748 | Time 29.6468(29.8166) | Bit/dim 1.1106(1.1109) | Xent 0.0507(0.0532) | Loss 1.1360(1.1375) | Error 0.0156(0.0161) Steps 416(410.82) | Grad Norm 0.1558(0.2129) | Total Time 10.00(10.00)\n",
      "Iter 2749 | Time 29.0240(29.7928) | Bit/dim 1.1074(1.1108) | Xent 0.0515(0.0532) | Loss 1.1331(1.1374) | Error 0.0166(0.0162) Steps 410(410.80) | Grad Norm 0.1825(0.2120) | Total Time 10.00(10.00)\n",
      "Iter 2750 | Time 29.8823(29.7955) | Bit/dim 1.1107(1.1108) | Xent 0.0606(0.0534) | Loss 1.1410(1.1375) | Error 0.0172(0.0162) Steps 410(410.77) | Grad Norm 0.3940(0.2175) | Total Time 10.00(10.00)\n",
      "Iter 2751 | Time 30.4682(29.8157) | Bit/dim 1.1089(1.1107) | Xent 0.0523(0.0534) | Loss 1.1351(1.1374) | Error 0.0146(0.0161) Steps 416(410.93) | Grad Norm 0.1787(0.2163) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 16.0287, Epoch Time 237.5978(238.6777), Bit/dim 1.1044(best: 1.1044), Xent 0.0297, Loss 1.1193, Error 0.0092(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2752 | Time 30.1882(29.8269) | Bit/dim 1.1097(1.1107) | Xent 0.0439(0.0531) | Loss 1.1317(1.1373) | Error 0.0141(0.0161) Steps 410(410.90) | Grad Norm 0.2179(0.2164) | Total Time 10.00(10.00)\n",
      "Iter 2753 | Time 29.9063(29.8293) | Bit/dim 1.1104(1.1107) | Xent 0.0588(0.0532) | Loss 1.1398(1.1373) | Error 0.0168(0.0161) Steps 410(410.88) | Grad Norm 0.2158(0.2163) | Total Time 10.00(10.00)\n",
      "Iter 2754 | Time 30.7269(29.8562) | Bit/dim 1.1106(1.1107) | Xent 0.0527(0.0532) | Loss 1.1370(1.1373) | Error 0.0169(0.0161) Steps 410(410.85) | Grad Norm 0.4271(0.2227) | Total Time 10.00(10.00)\n",
      "Iter 2755 | Time 29.2327(29.8375) | Bit/dim 1.1088(1.1106) | Xent 0.0558(0.0533) | Loss 1.1367(1.1373) | Error 0.0174(0.0162) Steps 410(410.82) | Grad Norm 0.2093(0.2223) | Total Time 10.00(10.00)\n",
      "Iter 2756 | Time 31.7240(29.8941) | Bit/dim 1.1078(1.1106) | Xent 0.0481(0.0532) | Loss 1.1319(1.1371) | Error 0.0150(0.0161) Steps 410(410.80) | Grad Norm 0.1804(0.2210) | Total Time 10.00(10.00)\n",
      "Iter 2757 | Time 29.2692(29.8753) | Bit/dim 1.1126(1.1106) | Xent 0.0516(0.0531) | Loss 1.1384(1.1372) | Error 0.0160(0.0161) Steps 410(410.78) | Grad Norm 0.3092(0.2237) | Total Time 10.00(10.00)\n",
      "Iter 2758 | Time 29.8551(29.8747) | Bit/dim 1.1122(1.1107) | Xent 0.0559(0.0532) | Loss 1.1401(1.1373) | Error 0.0155(0.0161) Steps 410(410.75) | Grad Norm 0.2379(0.2241) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 16.0252, Epoch Time 239.1721(238.6925), Bit/dim 1.1051(best: 1.1044), Xent 0.0318, Loss 1.1210, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2759 | Time 29.4295(29.8614) | Bit/dim 1.1117(1.1107) | Xent 0.0498(0.0531) | Loss 1.1367(1.1372) | Error 0.0171(0.0161) Steps 410(410.73) | Grad Norm 0.2300(0.2243) | Total Time 10.00(10.00)\n",
      "Iter 2760 | Time 30.7932(29.8893) | Bit/dim 1.1108(1.1107) | Xent 0.0543(0.0531) | Loss 1.1379(1.1373) | Error 0.0154(0.0161) Steps 410(410.71) | Grad Norm 0.1717(0.2227) | Total Time 10.00(10.00)\n",
      "Iter 2761 | Time 29.0754(29.8649) | Bit/dim 1.1161(1.1109) | Xent 0.0541(0.0532) | Loss 1.1431(1.1374) | Error 0.0175(0.0162) Steps 410(410.69) | Grad Norm 0.1550(0.2207) | Total Time 10.00(10.00)\n",
      "Iter 2762 | Time 29.7114(29.8603) | Bit/dim 1.1094(1.1108) | Xent 0.0516(0.0531) | Loss 1.1352(1.1374) | Error 0.0152(0.0161) Steps 416(410.85) | Grad Norm 0.1885(0.2197) | Total Time 10.00(10.00)\n",
      "Iter 2763 | Time 28.9530(29.8331) | Bit/dim 1.1094(1.1108) | Xent 0.0544(0.0531) | Loss 1.1366(1.1374) | Error 0.0152(0.0161) Steps 410(410.82) | Grad Norm 0.2147(0.2195) | Total Time 10.00(10.00)\n",
      "Iter 2764 | Time 30.3946(29.8499) | Bit/dim 1.1128(1.1108) | Xent 0.0508(0.0531) | Loss 1.1382(1.1374) | Error 0.0134(0.0160) Steps 410(410.80) | Grad Norm 0.1545(0.2176) | Total Time 10.00(10.00)\n",
      "Iter 2765 | Time 30.7620(29.8773) | Bit/dim 1.1059(1.1107) | Xent 0.0565(0.0532) | Loss 1.1341(1.1373) | Error 0.0165(0.0160) Steps 410(410.77) | Grad Norm 0.2152(0.2175) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 16.0148, Epoch Time 237.5462(238.6582), Bit/dim 1.1049(best: 1.1044), Xent 0.0319, Loss 1.1209, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2766 | Time 31.0211(29.9116) | Bit/dim 1.1144(1.1108) | Xent 0.0566(0.0533) | Loss 1.1427(1.1374) | Error 0.0179(0.0161) Steps 410(410.75) | Grad Norm 0.1869(0.2166) | Total Time 10.00(10.00)\n",
      "Iter 2767 | Time 29.9354(29.9123) | Bit/dim 1.1097(1.1108) | Xent 0.0461(0.0531) | Loss 1.1327(1.1373) | Error 0.0162(0.0161) Steps 410(410.73) | Grad Norm 0.2601(0.2179) | Total Time 10.00(10.00)\n",
      "Iter 2768 | Time 28.8579(29.8807) | Bit/dim 1.1063(1.1106) | Xent 0.0608(0.0533) | Loss 1.1367(1.1373) | Error 0.0166(0.0161) Steps 410(410.70) | Grad Norm 0.1551(0.2160) | Total Time 10.00(10.00)\n",
      "Iter 2769 | Time 29.9902(29.8840) | Bit/dim 1.1030(1.1104) | Xent 0.0534(0.0533) | Loss 1.1297(1.1371) | Error 0.0178(0.0162) Steps 410(410.68) | Grad Norm 0.2457(0.2169) | Total Time 10.00(10.00)\n",
      "Iter 2770 | Time 30.1618(29.8923) | Bit/dim 1.1112(1.1104) | Xent 0.0518(0.0533) | Loss 1.1371(1.1371) | Error 0.0170(0.0162) Steps 410(410.66) | Grad Norm 0.2229(0.2171) | Total Time 10.00(10.00)\n",
      "Iter 2771 | Time 30.3917(29.9073) | Bit/dim 1.1153(1.1106) | Xent 0.0531(0.0532) | Loss 1.1419(1.1372) | Error 0.0165(0.0162) Steps 416(410.82) | Grad Norm 0.2206(0.2172) | Total Time 10.00(10.00)\n",
      "Iter 2772 | Time 31.3626(29.9509) | Bit/dim 1.1107(1.1106) | Xent 0.0528(0.0532) | Loss 1.1371(1.1372) | Error 0.0158(0.0162) Steps 410(410.80) | Grad Norm 0.2346(0.2177) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 16.0812, Epoch Time 240.0001(238.6984), Bit/dim 1.1044(best: 1.1044), Xent 0.0319, Loss 1.1204, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2773 | Time 29.2981(29.9314) | Bit/dim 1.1116(1.1106) | Xent 0.0524(0.0532) | Loss 1.1378(1.1372) | Error 0.0151(0.0161) Steps 410(410.77) | Grad Norm 0.2191(0.2178) | Total Time 10.00(10.00)\n",
      "Iter 2774 | Time 30.4052(29.9456) | Bit/dim 1.1155(1.1108) | Xent 0.0584(0.0534) | Loss 1.1448(1.1374) | Error 0.0181(0.0162) Steps 410(410.75) | Grad Norm 0.2064(0.2174) | Total Time 10.00(10.00)\n",
      "Iter 2775 | Time 29.9407(29.9454) | Bit/dim 1.1078(1.1107) | Xent 0.0481(0.0532) | Loss 1.1319(1.1373) | Error 0.0149(0.0162) Steps 416(410.91) | Grad Norm 0.2489(0.2184) | Total Time 10.00(10.00)\n",
      "Iter 2776 | Time 30.8213(29.9717) | Bit/dim 1.1108(1.1107) | Xent 0.0522(0.0532) | Loss 1.1369(1.1373) | Error 0.0164(0.0162) Steps 410(410.88) | Grad Norm 0.1598(0.2166) | Total Time 10.00(10.00)\n",
      "Iter 2777 | Time 30.0209(29.9732) | Bit/dim 1.1094(1.1106) | Xent 0.0502(0.0531) | Loss 1.1345(1.1372) | Error 0.0164(0.0162) Steps 410(410.85) | Grad Norm 0.3981(0.2221) | Total Time 10.00(10.00)\n",
      "Iter 2778 | Time 29.6035(29.9621) | Bit/dim 1.1035(1.1104) | Xent 0.0516(0.0530) | Loss 1.1293(1.1369) | Error 0.0159(0.0162) Steps 410(410.83) | Grad Norm 0.2969(0.2243) | Total Time 10.00(10.00)\n",
      "Iter 2779 | Time 29.1763(29.9385) | Bit/dim 1.1146(1.1105) | Xent 0.0503(0.0530) | Loss 1.1398(1.1370) | Error 0.0160(0.0162) Steps 410(410.80) | Grad Norm 0.1906(0.2233) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 16.0549, Epoch Time 237.5739(238.6647), Bit/dim 1.1052(best: 1.1044), Xent 0.0332, Loss 1.1218, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2780 | Time 29.5556(29.9270) | Bit/dim 1.1102(1.1105) | Xent 0.0523(0.0529) | Loss 1.1363(1.1370) | Error 0.0155(0.0161) Steps 410(410.78) | Grad Norm 0.2976(0.2255) | Total Time 10.00(10.00)\n",
      "Iter 2781 | Time 28.6968(29.8901) | Bit/dim 1.1095(1.1105) | Xent 0.0459(0.0527) | Loss 1.1324(1.1369) | Error 0.0149(0.0161) Steps 410(410.76) | Grad Norm 0.4049(0.2309) | Total Time 10.00(10.00)\n",
      "Iter 2782 | Time 28.9961(29.8633) | Bit/dim 1.1093(1.1105) | Xent 0.0529(0.0527) | Loss 1.1358(1.1368) | Error 0.0176(0.0162) Steps 410(410.73) | Grad Norm 0.2274(0.2308) | Total Time 10.00(10.00)\n",
      "Iter 2783 | Time 29.5316(29.8533) | Bit/dim 1.1086(1.1104) | Xent 0.0601(0.0530) | Loss 1.1387(1.1369) | Error 0.0190(0.0162) Steps 410(410.71) | Grad Norm 0.1863(0.2295) | Total Time 10.00(10.00)\n",
      "Iter 2784 | Time 29.5295(29.8436) | Bit/dim 1.1124(1.1105) | Xent 0.0557(0.0530) | Loss 1.1403(1.1370) | Error 0.0181(0.0163) Steps 410(410.69) | Grad Norm 0.1828(0.2281) | Total Time 10.00(10.00)\n",
      "Iter 2785 | Time 30.4013(29.8604) | Bit/dim 1.1126(1.1105) | Xent 0.0549(0.0531) | Loss 1.1400(1.1371) | Error 0.0169(0.0163) Steps 410(410.67) | Grad Norm 0.3432(0.2315) | Total Time 10.00(10.00)\n",
      "Iter 2786 | Time 30.3832(29.8760) | Bit/dim 1.1103(1.1105) | Xent 0.0491(0.0530) | Loss 1.1348(1.1370) | Error 0.0150(0.0163) Steps 410(410.65) | Grad Norm 0.2057(0.2307) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 16.1696, Epoch Time 235.4560(238.5684), Bit/dim 1.1045(best: 1.1044), Xent 0.0333, Loss 1.1211, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2787 | Time 29.5447(29.8661) | Bit/dim 1.1110(1.1105) | Xent 0.0521(0.0529) | Loss 1.1370(1.1370) | Error 0.0139(0.0162) Steps 410(410.63) | Grad Norm 0.2602(0.2316) | Total Time 10.00(10.00)\n",
      "Iter 2788 | Time 30.3911(29.8819) | Bit/dim 1.1134(1.1106) | Xent 0.0467(0.0528) | Loss 1.1367(1.1370) | Error 0.0160(0.0162) Steps 410(410.61) | Grad Norm 0.1481(0.2291) | Total Time 10.00(10.00)\n",
      "Iter 2789 | Time 29.5631(29.8723) | Bit/dim 1.1095(1.1106) | Xent 0.0512(0.0527) | Loss 1.1351(1.1369) | Error 0.0165(0.0162) Steps 410(410.59) | Grad Norm 0.2708(0.2304) | Total Time 10.00(10.00)\n",
      "Iter 2790 | Time 29.1716(29.8513) | Bit/dim 1.1091(1.1105) | Xent 0.0521(0.0527) | Loss 1.1352(1.1369) | Error 0.0164(0.0162) Steps 410(410.58) | Grad Norm 0.1939(0.2293) | Total Time 10.00(10.00)\n",
      "Iter 2791 | Time 30.3542(29.8664) | Bit/dim 1.1099(1.1105) | Xent 0.0513(0.0526) | Loss 1.1355(1.1369) | Error 0.0164(0.0162) Steps 410(410.56) | Grad Norm 0.1984(0.2283) | Total Time 10.00(10.00)\n",
      "Iter 2792 | Time 29.9982(29.8703) | Bit/dim 1.1100(1.1105) | Xent 0.0515(0.0526) | Loss 1.1358(1.1368) | Error 0.0168(0.0162) Steps 416(410.72) | Grad Norm 0.3525(0.2321) | Total Time 10.00(10.00)\n",
      "Iter 2793 | Time 29.8060(29.8684) | Bit/dim 1.1118(1.1106) | Xent 0.0606(0.0529) | Loss 1.1421(1.1370) | Error 0.0174(0.0163) Steps 410(410.70) | Grad Norm 0.2051(0.2313) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 16.1977, Epoch Time 237.1314(238.5253), Bit/dim 1.1043(best: 1.1044), Xent 0.0322, Loss 1.1204, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2794 | Time 30.6715(29.8925) | Bit/dim 1.1094(1.1105) | Xent 0.0546(0.0529) | Loss 1.1367(1.1370) | Error 0.0162(0.0163) Steps 416(410.86) | Grad Norm 0.1931(0.2301) | Total Time 10.00(10.00)\n",
      "Iter 2795 | Time 30.4046(29.9078) | Bit/dim 1.1144(1.1106) | Xent 0.0527(0.0529) | Loss 1.1407(1.1371) | Error 0.0162(0.0163) Steps 410(410.83) | Grad Norm 0.2113(0.2296) | Total Time 10.00(10.00)\n",
      "Iter 2796 | Time 30.3319(29.9206) | Bit/dim 1.1095(1.1106) | Xent 0.0501(0.0528) | Loss 1.1345(1.1370) | Error 0.0136(0.0162) Steps 410(410.81) | Grad Norm 0.2707(0.2308) | Total Time 10.00(10.00)\n",
      "Iter 2797 | Time 30.0446(29.9243) | Bit/dim 1.1057(1.1105) | Xent 0.0499(0.0527) | Loss 1.1306(1.1368) | Error 0.0160(0.0162) Steps 410(410.78) | Grad Norm 0.1732(0.2291) | Total Time 10.00(10.00)\n",
      "Iter 2798 | Time 29.8312(29.9215) | Bit/dim 1.1136(1.1105) | Xent 0.0503(0.0526) | Loss 1.1388(1.1369) | Error 0.0160(0.0162) Steps 410(410.76) | Grad Norm 0.2190(0.2288) | Total Time 10.00(10.00)\n",
      "Iter 2799 | Time 30.1995(29.9298) | Bit/dim 1.1117(1.1106) | Xent 0.0512(0.0526) | Loss 1.1374(1.1369) | Error 0.0151(0.0161) Steps 410(410.74) | Grad Norm 0.2564(0.2296) | Total Time 10.00(10.00)\n",
      "Iter 2800 | Time 30.0901(29.9346) | Bit/dim 1.1089(1.1105) | Xent 0.0545(0.0527) | Loss 1.1362(1.1369) | Error 0.0149(0.0161) Steps 410(410.72) | Grad Norm 0.2229(0.2294) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 16.4263, Epoch Time 240.3835(238.5811), Bit/dim 1.1043(best: 1.1043), Xent 0.0316, Loss 1.1201, Error 0.0094(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2801 | Time 30.0607(29.9384) | Bit/dim 1.1137(1.1106) | Xent 0.0468(0.0525) | Loss 1.1372(1.1369) | Error 0.0150(0.0161) Steps 416(410.87) | Grad Norm 0.1800(0.2279) | Total Time 10.00(10.00)\n",
      "Iter 2802 | Time 30.4202(29.9529) | Bit/dim 1.1083(1.1106) | Xent 0.0532(0.0525) | Loss 1.1349(1.1368) | Error 0.0175(0.0161) Steps 410(410.85) | Grad Norm 0.2030(0.2272) | Total Time 10.00(10.00)\n",
      "Iter 2803 | Time 28.8110(29.9186) | Bit/dim 1.1092(1.1105) | Xent 0.0507(0.0525) | Loss 1.1345(1.1367) | Error 0.0158(0.0161) Steps 410(410.82) | Grad Norm 0.1684(0.2254) | Total Time 10.00(10.00)\n",
      "Iter 2804 | Time 30.0558(29.9227) | Bit/dim 1.1107(1.1105) | Xent 0.0588(0.0526) | Loss 1.1401(1.1368) | Error 0.0170(0.0161) Steps 410(410.80) | Grad Norm 0.1759(0.2239) | Total Time 10.00(10.00)\n",
      "Iter 2805 | Time 29.3079(29.9043) | Bit/dim 1.1125(1.1106) | Xent 0.0491(0.0525) | Loss 1.1371(1.1369) | Error 0.0160(0.0161) Steps 410(410.77) | Grad Norm 0.2717(0.2253) | Total Time 10.00(10.00)\n",
      "Iter 2806 | Time 30.2967(29.9161) | Bit/dim 1.1084(1.1105) | Xent 0.0649(0.0529) | Loss 1.1409(1.1370) | Error 0.0182(0.0162) Steps 410(410.75) | Grad Norm 0.3105(0.2279) | Total Time 10.00(10.00)\n",
      "Iter 2807 | Time 29.2173(29.8951) | Bit/dim 1.1085(1.1105) | Xent 0.0518(0.0529) | Loss 1.1345(1.1369) | Error 0.0171(0.0162) Steps 410(410.73) | Grad Norm 0.1949(0.2269) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 16.3204, Epoch Time 236.4844(238.5182), Bit/dim 1.1039(best: 1.1043), Xent 0.0293, Loss 1.1185, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2808 | Time 28.9434(29.8665) | Bit/dim 1.1120(1.1105) | Xent 0.0492(0.0528) | Loss 1.1366(1.1369) | Error 0.0156(0.0162) Steps 410(410.71) | Grad Norm 0.1629(0.2250) | Total Time 10.00(10.00)\n",
      "Iter 2809 | Time 29.6907(29.8613) | Bit/dim 1.1139(1.1106) | Xent 0.0579(0.0529) | Loss 1.1429(1.1371) | Error 0.0171(0.0162) Steps 410(410.68) | Grad Norm 0.1454(0.2226) | Total Time 10.00(10.00)\n",
      "Iter 2810 | Time 29.1231(29.8391) | Bit/dim 1.1066(1.1105) | Xent 0.0477(0.0528) | Loss 1.1305(1.1369) | Error 0.0142(0.0162) Steps 410(410.66) | Grad Norm 0.2419(0.2232) | Total Time 10.00(10.00)\n",
      "Iter 2811 | Time 29.3352(29.8240) | Bit/dim 1.1093(1.1105) | Xent 0.0519(0.0527) | Loss 1.1352(1.1368) | Error 0.0160(0.0162) Steps 410(410.64) | Grad Norm 0.1918(0.2222) | Total Time 10.00(10.00)\n",
      "Iter 2812 | Time 30.4051(29.8414) | Bit/dim 1.1049(1.1103) | Xent 0.0494(0.0526) | Loss 1.1296(1.1366) | Error 0.0155(0.0161) Steps 416(410.81) | Grad Norm 0.2249(0.2223) | Total Time 10.00(10.00)\n",
      "Iter 2813 | Time 29.1104(29.8195) | Bit/dim 1.1083(1.1102) | Xent 0.0480(0.0525) | Loss 1.1323(1.1365) | Error 0.0131(0.0161) Steps 410(410.78) | Grad Norm 0.1567(0.2203) | Total Time 10.00(10.00)\n",
      "Iter 2814 | Time 30.4757(29.8392) | Bit/dim 1.1119(1.1103) | Xent 0.0494(0.0524) | Loss 1.1366(1.1365) | Error 0.0158(0.0160) Steps 416(410.94) | Grad Norm 0.1945(0.2196) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 16.1917, Epoch Time 235.3671(238.4236), Bit/dim 1.1037(best: 1.1039), Xent 0.0304, Loss 1.1189, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2815 | Time 29.9170(29.8415) | Bit/dim 1.1118(1.1103) | Xent 0.0544(0.0525) | Loss 1.1390(1.1366) | Error 0.0166(0.0161) Steps 416(411.09) | Grad Norm 0.1909(0.2187) | Total Time 10.00(10.00)\n",
      "Iter 2816 | Time 29.9532(29.8449) | Bit/dim 1.1049(1.1102) | Xent 0.0547(0.0525) | Loss 1.1322(1.1364) | Error 0.0162(0.0161) Steps 416(411.24) | Grad Norm 0.2683(0.2202) | Total Time 10.00(10.00)\n",
      "Iter 2817 | Time 29.8270(29.8443) | Bit/dim 1.1101(1.1102) | Xent 0.0464(0.0524) | Loss 1.1333(1.1363) | Error 0.0141(0.0160) Steps 410(411.20) | Grad Norm 0.2256(0.2204) | Total Time 10.00(10.00)\n",
      "Iter 2818 | Time 30.6505(29.8685) | Bit/dim 1.1109(1.1102) | Xent 0.0447(0.0521) | Loss 1.1332(1.1362) | Error 0.0139(0.0159) Steps 410(411.16) | Grad Norm 0.1895(0.2194) | Total Time 10.00(10.00)\n",
      "Iter 2819 | Time 30.0274(29.8733) | Bit/dim 1.1098(1.1102) | Xent 0.0550(0.0522) | Loss 1.1374(1.1363) | Error 0.0159(0.0159) Steps 410(411.13) | Grad Norm 0.2237(0.2196) | Total Time 10.00(10.00)\n",
      "Iter 2820 | Time 29.2693(29.8552) | Bit/dim 1.1121(1.1102) | Xent 0.0555(0.0523) | Loss 1.1399(1.1364) | Error 0.0169(0.0160) Steps 410(411.09) | Grad Norm 0.1960(0.2189) | Total Time 10.00(10.00)\n",
      "Iter 2821 | Time 31.0872(29.8921) | Bit/dim 1.1100(1.1102) | Xent 0.0539(0.0524) | Loss 1.1370(1.1364) | Error 0.0175(0.0160) Steps 410(411.06) | Grad Norm 0.2537(0.2199) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 16.2089, Epoch Time 239.2127(238.4473), Bit/dim 1.1044(best: 1.1037), Xent 0.0307, Loss 1.1198, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2822 | Time 30.7803(29.9188) | Bit/dim 1.1114(1.1103) | Xent 0.0547(0.0524) | Loss 1.1388(1.1365) | Error 0.0158(0.0160) Steps 410(411.03) | Grad Norm 0.1968(0.2192) | Total Time 10.00(10.00)\n",
      "Iter 2823 | Time 29.2782(29.8996) | Bit/dim 1.1086(1.1102) | Xent 0.0559(0.0525) | Loss 1.1365(1.1365) | Error 0.0158(0.0160) Steps 410(411.00) | Grad Norm 0.1582(0.2174) | Total Time 10.00(10.00)\n",
      "Iter 2824 | Time 29.8810(29.8990) | Bit/dim 1.1088(1.1102) | Xent 0.0530(0.0525) | Loss 1.1353(1.1364) | Error 0.0152(0.0160) Steps 410(410.97) | Grad Norm 0.2217(0.2175) | Total Time 10.00(10.00)\n",
      "Iter 2825 | Time 31.5051(29.9472) | Bit/dim 1.1056(1.1100) | Xent 0.0591(0.0527) | Loss 1.1352(1.1364) | Error 0.0179(0.0160) Steps 422(411.30) | Grad Norm 0.1964(0.2169) | Total Time 10.00(10.00)\n",
      "Iter 2826 | Time 29.8203(29.9434) | Bit/dim 1.1113(1.1101) | Xent 0.0482(0.0526) | Loss 1.1354(1.1364) | Error 0.0169(0.0161) Steps 410(411.26) | Grad Norm 0.2297(0.2173) | Total Time 10.00(10.00)\n",
      "Iter 2827 | Time 31.1669(29.9801) | Bit/dim 1.1151(1.1102) | Xent 0.0578(0.0528) | Loss 1.1441(1.1366) | Error 0.0165(0.0161) Steps 410(411.22) | Grad Norm 0.1948(0.2166) | Total Time 10.00(10.00)\n",
      "Iter 2828 | Time 30.4099(29.9930) | Bit/dim 1.1116(1.1103) | Xent 0.0498(0.0527) | Loss 1.1365(1.1366) | Error 0.0149(0.0160) Steps 410(411.19) | Grad Norm 0.2152(0.2165) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 16.1785, Epoch Time 241.1685(238.5289), Bit/dim 1.1042(best: 1.1037), Xent 0.0339, Loss 1.1211, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2829 | Time 31.3680(30.0342) | Bit/dim 1.1080(1.1102) | Xent 0.0534(0.0527) | Loss 1.1347(1.1365) | Error 0.0148(0.0160) Steps 410(411.15) | Grad Norm 0.2155(0.2165) | Total Time 10.00(10.00)\n",
      "Iter 2830 | Time 28.6922(29.9940) | Bit/dim 1.1084(1.1101) | Xent 0.0512(0.0527) | Loss 1.1340(1.1365) | Error 0.0161(0.0160) Steps 410(411.12) | Grad Norm 0.2058(0.2162) | Total Time 10.00(10.00)\n",
      "Iter 2831 | Time 29.2432(29.9714) | Bit/dim 1.1114(1.1102) | Xent 0.0518(0.0526) | Loss 1.1373(1.1365) | Error 0.0160(0.0160) Steps 410(411.08) | Grad Norm 0.2174(0.2162) | Total Time 10.00(10.00)\n",
      "Iter 2832 | Time 30.4202(29.9849) | Bit/dim 1.1109(1.1102) | Xent 0.0571(0.0528) | Loss 1.1395(1.1366) | Error 0.0156(0.0160) Steps 410(411.05) | Grad Norm 0.2810(0.2182) | Total Time 10.00(10.00)\n",
      "Iter 2833 | Time 29.8892(29.9820) | Bit/dim 1.1066(1.1101) | Xent 0.0536(0.0528) | Loss 1.1334(1.1365) | Error 0.0156(0.0160) Steps 410(411.02) | Grad Norm 0.1556(0.2163) | Total Time 10.00(10.00)\n",
      "Iter 2834 | Time 31.1353(30.0166) | Bit/dim 1.1123(1.1102) | Xent 0.0515(0.0527) | Loss 1.1381(1.1365) | Error 0.0165(0.0160) Steps 416(411.17) | Grad Norm 0.2279(0.2166) | Total Time 10.00(10.00)\n",
      "Iter 2835 | Time 30.3111(30.0255) | Bit/dim 1.1111(1.1102) | Xent 0.0555(0.0528) | Loss 1.1388(1.1366) | Error 0.0194(0.0161) Steps 410(411.13) | Grad Norm 0.1860(0.2157) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 16.3563, Epoch Time 239.8001(238.5671), Bit/dim 1.1048(best: 1.1037), Xent 0.0332, Loss 1.1215, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2836 | Time 29.4263(30.0075) | Bit/dim 1.1110(1.1102) | Xent 0.0557(0.0529) | Loss 1.1389(1.1367) | Error 0.0182(0.0162) Steps 410(411.10) | Grad Norm 0.1619(0.2141) | Total Time 10.00(10.00)\n",
      "Iter 2837 | Time 29.6190(29.9958) | Bit/dim 1.1117(1.1103) | Xent 0.0537(0.0529) | Loss 1.1385(1.1367) | Error 0.0164(0.0162) Steps 410(411.07) | Grad Norm 0.1977(0.2136) | Total Time 10.00(10.00)\n",
      "Iter 2838 | Time 28.7873(29.9596) | Bit/dim 1.1106(1.1103) | Xent 0.0458(0.0527) | Loss 1.1335(1.1366) | Error 0.0148(0.0161) Steps 410(411.03) | Grad Norm 0.1598(0.2120) | Total Time 10.00(10.00)\n",
      "Iter 2839 | Time 30.4470(29.9742) | Bit/dim 1.1099(1.1103) | Xent 0.0501(0.0526) | Loss 1.1350(1.1366) | Error 0.0158(0.0161) Steps 410(411.00) | Grad Norm 0.2489(0.2131) | Total Time 10.00(10.00)\n",
      "Iter 2840 | Time 29.4441(29.9583) | Bit/dim 1.1056(1.1101) | Xent 0.0482(0.0525) | Loss 1.1297(1.1364) | Error 0.0150(0.0161) Steps 410(410.97) | Grad Norm 0.1913(0.2125) | Total Time 10.00(10.00)\n",
      "Iter 2841 | Time 29.7368(29.9517) | Bit/dim 1.1094(1.1101) | Xent 0.0504(0.0524) | Loss 1.1346(1.1363) | Error 0.0145(0.0160) Steps 410(410.94) | Grad Norm 0.1936(0.2119) | Total Time 10.00(10.00)\n",
      "Iter 2842 | Time 29.8219(29.9478) | Bit/dim 1.1128(1.1102) | Xent 0.0534(0.0525) | Loss 1.1395(1.1364) | Error 0.0154(0.0160) Steps 410(410.92) | Grad Norm 0.2210(0.2122) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 16.4233, Epoch Time 236.2160(238.4965), Bit/dim 1.1040(best: 1.1037), Xent 0.0313, Loss 1.1197, Error 0.0094(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2843 | Time 29.5311(29.9353) | Bit/dim 1.1078(1.1101) | Xent 0.0482(0.0523) | Loss 1.1319(1.1363) | Error 0.0145(0.0160) Steps 410(410.89) | Grad Norm 0.2399(0.2130) | Total Time 10.00(10.00)\n",
      "Iter 2844 | Time 30.1859(29.9428) | Bit/dim 1.1029(1.1099) | Xent 0.0567(0.0525) | Loss 1.1312(1.1361) | Error 0.0168(0.0160) Steps 410(410.86) | Grad Norm 0.3020(0.2157) | Total Time 10.00(10.00)\n",
      "Iter 2845 | Time 30.4395(29.9577) | Bit/dim 1.1119(1.1099) | Xent 0.0519(0.0525) | Loss 1.1378(1.1362) | Error 0.0149(0.0160) Steps 410(410.84) | Grad Norm 0.2634(0.2171) | Total Time 10.00(10.00)\n",
      "Iter 2846 | Time 31.1444(29.9933) | Bit/dim 1.1112(1.1100) | Xent 0.0543(0.0525) | Loss 1.1384(1.1362) | Error 0.0160(0.0160) Steps 410(410.81) | Grad Norm 0.1600(0.2154) | Total Time 10.00(10.00)\n",
      "Iter 2847 | Time 30.7801(30.0169) | Bit/dim 1.1120(1.1100) | Xent 0.0509(0.0525) | Loss 1.1374(1.1363) | Error 0.0151(0.0159) Steps 410(410.79) | Grad Norm 0.3727(0.2201) | Total Time 10.00(10.00)\n",
      "Iter 2848 | Time 30.2477(30.0238) | Bit/dim 1.1103(1.1101) | Xent 0.0582(0.0526) | Loss 1.1394(1.1364) | Error 0.0179(0.0160) Steps 416(410.94) | Grad Norm 0.4418(0.2267) | Total Time 10.00(10.00)\n",
      "Iter 2849 | Time 29.7719(30.0163) | Bit/dim 1.1162(1.1102) | Xent 0.0436(0.0524) | Loss 1.1381(1.1364) | Error 0.0149(0.0160) Steps 410(410.91) | Grad Norm 0.2866(0.2285) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 16.2591, Epoch Time 240.6577(238.5614), Bit/dim 1.1047(best: 1.1037), Xent 0.0320, Loss 1.1207, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2850 | Time 29.2560(29.9934) | Bit/dim 1.1135(1.1103) | Xent 0.0480(0.0522) | Loss 1.1375(1.1365) | Error 0.0145(0.0159) Steps 410(410.89) | Grad Norm 0.1863(0.2273) | Total Time 10.00(10.00)\n",
      "Iter 2851 | Time 29.4253(29.9764) | Bit/dim 1.1089(1.1103) | Xent 0.0527(0.0523) | Loss 1.1353(1.1364) | Error 0.0154(0.0159) Steps 416(411.04) | Grad Norm 0.1765(0.2258) | Total Time 10.00(10.00)\n",
      "Iter 2852 | Time 30.9744(30.0063) | Bit/dim 1.1102(1.1103) | Xent 0.0562(0.0524) | Loss 1.1383(1.1365) | Error 0.0181(0.0160) Steps 410(411.01) | Grad Norm 0.4232(0.2317) | Total Time 10.00(10.00)\n",
      "Iter 2853 | Time 30.6483(30.0256) | Bit/dim 1.1092(1.1103) | Xent 0.0543(0.0524) | Loss 1.1364(1.1365) | Error 0.0171(0.0160) Steps 410(410.98) | Grad Norm 0.3368(0.2348) | Total Time 10.00(10.00)\n",
      "Iter 2854 | Time 29.9632(30.0237) | Bit/dim 1.1062(1.1101) | Xent 0.0530(0.0524) | Loss 1.1327(1.1364) | Error 0.0158(0.0160) Steps 410(410.95) | Grad Norm 0.2307(0.2347) | Total Time 10.00(10.00)\n",
      "Iter 2855 | Time 28.6913(29.9838) | Bit/dim 1.1111(1.1102) | Xent 0.0504(0.0524) | Loss 1.1363(1.1364) | Error 0.0151(0.0160) Steps 410(410.92) | Grad Norm 0.1749(0.2329) | Total Time 10.00(10.00)\n",
      "Iter 2856 | Time 29.3272(29.9641) | Bit/dim 1.1103(1.1102) | Xent 0.0562(0.0525) | Loss 1.1384(1.1364) | Error 0.0175(0.0160) Steps 410(410.89) | Grad Norm 0.1502(0.2304) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 16.4219, Epoch Time 237.1124(238.5179), Bit/dim 1.1044(best: 1.1037), Xent 0.0306, Loss 1.1197, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2857 | Time 28.8270(29.9299) | Bit/dim 1.1117(1.1102) | Xent 0.0569(0.0526) | Loss 1.1401(1.1365) | Error 0.0182(0.0161) Steps 410(410.87) | Grad Norm 0.2823(0.2320) | Total Time 10.00(10.00)\n",
      "Iter 2858 | Time 30.1942(29.9379) | Bit/dim 1.1086(1.1102) | Xent 0.0453(0.0524) | Loss 1.1313(1.1364) | Error 0.0139(0.0160) Steps 410(410.84) | Grad Norm 0.2392(0.2322) | Total Time 10.00(10.00)\n",
      "Iter 2859 | Time 29.7859(29.9333) | Bit/dim 1.1075(1.1101) | Xent 0.0531(0.0524) | Loss 1.1340(1.1363) | Error 0.0166(0.0160) Steps 410(410.82) | Grad Norm 0.1609(0.2301) | Total Time 10.00(10.00)\n",
      "Iter 2860 | Time 31.0328(29.9663) | Bit/dim 1.1102(1.1101) | Xent 0.0466(0.0523) | Loss 1.1334(1.1362) | Error 0.0130(0.0159) Steps 410(410.79) | Grad Norm 0.1974(0.2291) | Total Time 10.00(10.00)\n",
      "Iter 2861 | Time 30.2048(29.9735) | Bit/dim 1.1091(1.1101) | Xent 0.0563(0.0524) | Loss 1.1372(1.1362) | Error 0.0171(0.0160) Steps 410(410.77) | Grad Norm 0.2226(0.2289) | Total Time 10.00(10.00)\n",
      "Iter 2862 | Time 30.2860(29.9828) | Bit/dim 1.1095(1.1100) | Xent 0.0483(0.0523) | Loss 1.1337(1.1362) | Error 0.0156(0.0160) Steps 416(410.92) | Grad Norm 0.1563(0.2267) | Total Time 10.00(10.00)\n",
      "Iter 2863 | Time 28.8296(29.9482) | Bit/dim 1.1159(1.1102) | Xent 0.0566(0.0524) | Loss 1.1443(1.1364) | Error 0.0176(0.0160) Steps 410(410.90) | Grad Norm 0.2787(0.2283) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 16.1779, Epoch Time 237.6424(238.4916), Bit/dim 1.1049(best: 1.1037), Xent 0.0324, Loss 1.1211, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2864 | Time 28.9665(29.9188) | Bit/dim 1.1095(1.1102) | Xent 0.0526(0.0524) | Loss 1.1357(1.1364) | Error 0.0158(0.0160) Steps 410(410.87) | Grad Norm 0.1559(0.2261) | Total Time 10.00(10.00)\n",
      "Iter 2865 | Time 30.4840(29.9357) | Bit/dim 1.1044(1.1100) | Xent 0.0497(0.0523) | Loss 1.1292(1.1362) | Error 0.0159(0.0160) Steps 410(410.84) | Grad Norm 0.1524(0.2239) | Total Time 10.00(10.00)\n",
      "Iter 2866 | Time 30.2210(29.9443) | Bit/dim 1.1133(1.1101) | Xent 0.0584(0.0525) | Loss 1.1426(1.1364) | Error 0.0166(0.0160) Steps 410(410.82) | Grad Norm 0.1706(0.2223) | Total Time 10.00(10.00)\n",
      "Iter 2867 | Time 30.3308(29.9559) | Bit/dim 1.1101(1.1101) | Xent 0.0529(0.0525) | Loss 1.1366(1.1364) | Error 0.0164(0.0160) Steps 410(410.79) | Grad Norm 0.1675(0.2206) | Total Time 10.00(10.00)\n",
      "Iter 2868 | Time 28.9552(29.9259) | Bit/dim 1.1098(1.1101) | Xent 0.0564(0.0526) | Loss 1.1381(1.1364) | Error 0.0172(0.0161) Steps 410(410.77) | Grad Norm 0.2568(0.2217) | Total Time 10.00(10.00)\n",
      "Iter 2869 | Time 30.4655(29.9421) | Bit/dim 1.1146(1.1102) | Xent 0.0527(0.0526) | Loss 1.1409(1.1366) | Error 0.0168(0.0161) Steps 410(410.75) | Grad Norm 0.1501(0.2196) | Total Time 10.00(10.00)\n",
      "Iter 2870 | Time 30.3327(29.9538) | Bit/dim 1.1100(1.1102) | Xent 0.0486(0.0525) | Loss 1.1343(1.1365) | Error 0.0155(0.0161) Steps 416(410.90) | Grad Norm 0.1640(0.2179) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 16.1761, Epoch Time 237.8149(238.4713), Bit/dim 1.1044(best: 1.1037), Xent 0.0297, Loss 1.1192, Error 0.0087(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2871 | Time 30.1584(29.9599) | Bit/dim 1.1107(1.1103) | Xent 0.0517(0.0525) | Loss 1.1365(1.1365) | Error 0.0144(0.0160) Steps 416(411.06) | Grad Norm 0.1755(0.2166) | Total Time 10.00(10.00)\n",
      "Iter 2872 | Time 30.8990(29.9881) | Bit/dim 1.1095(1.1102) | Xent 0.0516(0.0525) | Loss 1.1353(1.1365) | Error 0.0164(0.0160) Steps 416(411.21) | Grad Norm 0.1911(0.2159) | Total Time 10.00(10.00)\n",
      "Iter 2873 | Time 29.1354(29.9625) | Bit/dim 1.1085(1.1102) | Xent 0.0504(0.0524) | Loss 1.1336(1.1364) | Error 0.0154(0.0160) Steps 410(411.17) | Grad Norm 0.2217(0.2161) | Total Time 10.00(10.00)\n",
      "Iter 2874 | Time 29.5631(29.9505) | Bit/dim 1.1124(1.1102) | Xent 0.0594(0.0526) | Loss 1.1421(1.1365) | Error 0.0168(0.0160) Steps 410(411.13) | Grad Norm 0.2077(0.2158) | Total Time 10.00(10.00)\n",
      "Iter 2875 | Time 30.0641(29.9539) | Bit/dim 1.1087(1.1102) | Xent 0.0494(0.0525) | Loss 1.1333(1.1364) | Error 0.0151(0.0160) Steps 416(411.28) | Grad Norm 0.1571(0.2140) | Total Time 10.00(10.00)\n",
      "Iter 2876 | Time 30.6902(29.9760) | Bit/dim 1.1102(1.1102) | Xent 0.0513(0.0525) | Loss 1.1359(1.1364) | Error 0.0134(0.0159) Steps 410(411.24) | Grad Norm 0.1714(0.2128) | Total Time 10.00(10.00)\n",
      "Iter 2877 | Time 30.0434(29.9780) | Bit/dim 1.1098(1.1102) | Xent 0.0504(0.0524) | Loss 1.1350(1.1364) | Error 0.0151(0.0159) Steps 416(411.38) | Grad Norm 0.2031(0.2125) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 15.9106, Epoch Time 238.4948(238.4720), Bit/dim 1.1043(best: 1.1037), Xent 0.0309, Loss 1.1198, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2878 | Time 29.8491(29.9742) | Bit/dim 1.1086(1.1101) | Xent 0.0604(0.0526) | Loss 1.1388(1.1365) | Error 0.0186(0.0160) Steps 410(411.34) | Grad Norm 0.2064(0.2123) | Total Time 10.00(10.00)\n",
      "Iter 2879 | Time 29.4081(29.9572) | Bit/dim 1.1111(1.1102) | Xent 0.0556(0.0527) | Loss 1.1388(1.1365) | Error 0.0166(0.0160) Steps 410(411.30) | Grad Norm 0.2441(0.2132) | Total Time 10.00(10.00)\n",
      "Iter 2880 | Time 29.9333(29.9565) | Bit/dim 1.1109(1.1102) | Xent 0.0549(0.0528) | Loss 1.1384(1.1366) | Error 0.0169(0.0160) Steps 410(411.26) | Grad Norm 0.2122(0.2132) | Total Time 10.00(10.00)\n",
      "Iter 2881 | Time 30.7525(29.9804) | Bit/dim 1.1101(1.1102) | Xent 0.0432(0.0525) | Loss 1.1317(1.1364) | Error 0.0138(0.0160) Steps 416(411.41) | Grad Norm 0.1501(0.2113) | Total Time 10.00(10.00)\n",
      "Iter 2882 | Time 29.2499(29.9584) | Bit/dim 1.1159(1.1104) | Xent 0.0488(0.0524) | Loss 1.1403(1.1366) | Error 0.0152(0.0159) Steps 410(411.36) | Grad Norm 0.1913(0.2107) | Total Time 10.00(10.00)\n",
      "Iter 2883 | Time 31.4676(30.0037) | Bit/dim 1.1069(1.1103) | Xent 0.0611(0.0527) | Loss 1.1374(1.1366) | Error 0.0188(0.0160) Steps 410(411.32) | Grad Norm 0.1631(0.2093) | Total Time 10.00(10.00)\n",
      "Iter 2884 | Time 29.0853(29.9762) | Bit/dim 1.1063(1.1101) | Xent 0.0553(0.0527) | Loss 1.1340(1.1365) | Error 0.0181(0.0161) Steps 410(411.28) | Grad Norm 0.2444(0.2103) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 16.0958, Epoch Time 238.5425(238.4741), Bit/dim 1.1044(best: 1.1037), Xent 0.0328, Loss 1.1208, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2885 | Time 30.2144(29.9833) | Bit/dim 1.1111(1.1102) | Xent 0.0519(0.0527) | Loss 1.1370(1.1365) | Error 0.0151(0.0161) Steps 416(411.42) | Grad Norm 0.2635(0.2119) | Total Time 10.00(10.00)\n",
      "Iter 2886 | Time 29.7684(29.9769) | Bit/dim 1.1100(1.1102) | Xent 0.0533(0.0527) | Loss 1.1367(1.1365) | Error 0.0166(0.0161) Steps 410(411.38) | Grad Norm 0.2713(0.2137) | Total Time 10.00(10.00)\n",
      "Iter 2887 | Time 30.4084(29.9898) | Bit/dim 1.1116(1.1102) | Xent 0.0557(0.0528) | Loss 1.1394(1.1366) | Error 0.0189(0.0162) Steps 410(411.34) | Grad Norm 0.2027(0.2134) | Total Time 10.00(10.00)\n",
      "Iter 2888 | Time 28.8911(29.9568) | Bit/dim 1.1063(1.1101) | Xent 0.0570(0.0529) | Loss 1.1348(1.1366) | Error 0.0169(0.0162) Steps 410(411.30) | Grad Norm 0.2497(0.2145) | Total Time 10.00(10.00)\n",
      "Iter 2889 | Time 30.1867(29.9637) | Bit/dim 1.1096(1.1101) | Xent 0.0542(0.0530) | Loss 1.1367(1.1366) | Error 0.0160(0.0162) Steps 410(411.26) | Grad Norm 0.1636(0.2130) | Total Time 10.00(10.00)\n",
      "Iter 2890 | Time 30.3649(29.9758) | Bit/dim 1.1141(1.1102) | Xent 0.0439(0.0527) | Loss 1.1361(1.1365) | Error 0.0135(0.0161) Steps 410(411.22) | Grad Norm 0.1829(0.2121) | Total Time 10.00(10.00)\n",
      "Iter 2891 | Time 29.9594(29.9753) | Bit/dim 1.1082(1.1101) | Xent 0.0515(0.0527) | Loss 1.1339(1.1365) | Error 0.0161(0.0161) Steps 410(411.19) | Grad Norm 0.3251(0.2154) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 16.0506, Epoch Time 237.9486(238.4584), Bit/dim 1.1039(best: 1.1037), Xent 0.0311, Loss 1.1194, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2892 | Time 30.0312(29.9770) | Bit/dim 1.1106(1.1101) | Xent 0.0532(0.0527) | Loss 1.1371(1.1365) | Error 0.0148(0.0161) Steps 410(411.15) | Grad Norm 0.2503(0.2165) | Total Time 10.00(10.00)\n",
      "Iter 2893 | Time 30.3348(29.9877) | Bit/dim 1.1108(1.1102) | Xent 0.0500(0.0526) | Loss 1.1358(1.1365) | Error 0.0144(0.0160) Steps 410(411.12) | Grad Norm 0.2423(0.2173) | Total Time 10.00(10.00)\n",
      "Iter 2894 | Time 29.8017(29.9821) | Bit/dim 1.1068(1.1101) | Xent 0.0533(0.0526) | Loss 1.1335(1.1364) | Error 0.0158(0.0160) Steps 410(411.08) | Grad Norm 0.1699(0.2158) | Total Time 10.00(10.00)\n",
      "Iter 2895 | Time 31.4946(30.0275) | Bit/dim 1.1097(1.1101) | Xent 0.0514(0.0526) | Loss 1.1354(1.1364) | Error 0.0158(0.0160) Steps 410(411.05) | Grad Norm 0.3035(0.2185) | Total Time 10.00(10.00)\n",
      "Iter 2896 | Time 29.2135(30.0031) | Bit/dim 1.1082(1.1100) | Xent 0.0514(0.0526) | Loss 1.1339(1.1363) | Error 0.0150(0.0160) Steps 410(411.02) | Grad Norm 0.3381(0.2221) | Total Time 10.00(10.00)\n",
      "Iter 2897 | Time 29.8343(29.9980) | Bit/dim 1.1115(1.1100) | Xent 0.0490(0.0524) | Loss 1.1361(1.1363) | Error 0.0161(0.0160) Steps 410(410.99) | Grad Norm 0.2176(0.2219) | Total Time 10.00(10.00)\n",
      "Iter 2898 | Time 29.8321(29.9930) | Bit/dim 1.1141(1.1102) | Xent 0.0500(0.0524) | Loss 1.1391(1.1364) | Error 0.0158(0.0160) Steps 410(410.96) | Grad Norm 0.2736(0.2235) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 16.4521, Epoch Time 239.0346(238.4757), Bit/dim 1.1039(best: 1.1037), Xent 0.0327, Loss 1.1203, Error 0.0112(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2899 | Time 30.2082(29.9995) | Bit/dim 1.1112(1.1102) | Xent 0.0514(0.0523) | Loss 1.1369(1.1364) | Error 0.0150(0.0159) Steps 410(410.93) | Grad Norm 0.1938(0.2226) | Total Time 10.00(10.00)\n",
      "Iter 2900 | Time 30.0955(30.0024) | Bit/dim 1.1072(1.1101) | Xent 0.0610(0.0526) | Loss 1.1378(1.1364) | Error 0.0171(0.0160) Steps 410(410.90) | Grad Norm 0.2812(0.2243) | Total Time 10.00(10.00)\n",
      "Iter 2901 | Time 30.2714(30.0104) | Bit/dim 1.1108(1.1101) | Xent 0.0480(0.0525) | Loss 1.1348(1.1364) | Error 0.0146(0.0159) Steps 410(410.88) | Grad Norm 0.2444(0.2249) | Total Time 10.00(10.00)\n",
      "Iter 2902 | Time 29.5869(29.9977) | Bit/dim 1.1090(1.1101) | Xent 0.0472(0.0523) | Loss 1.1327(1.1363) | Error 0.0139(0.0159) Steps 410(410.85) | Grad Norm 0.3121(0.2276) | Total Time 10.00(10.00)\n",
      "Iter 2903 | Time 31.7003(30.0488) | Bit/dim 1.1094(1.1101) | Xent 0.0507(0.0523) | Loss 1.1347(1.1362) | Error 0.0166(0.0159) Steps 410(410.82) | Grad Norm 0.1698(0.2258) | Total Time 10.00(10.00)\n",
      "Iter 2904 | Time 30.1729(30.0525) | Bit/dim 1.1072(1.1100) | Xent 0.0592(0.0525) | Loss 1.1368(1.1362) | Error 0.0179(0.0159) Steps 410(410.80) | Grad Norm 0.1904(0.2248) | Total Time 10.00(10.00)\n",
      "Iter 2905 | Time 30.4268(30.0638) | Bit/dim 1.1118(1.1100) | Xent 0.0511(0.0524) | Loss 1.1373(1.1363) | Error 0.0166(0.0160) Steps 410(410.77) | Grad Norm 0.2895(0.2267) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 16.1347, Epoch Time 240.7765(238.5447), Bit/dim 1.1041(best: 1.1037), Xent 0.0327, Loss 1.1205, Error 0.0109(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2906 | Time 30.1409(30.0661) | Bit/dim 1.1107(1.1101) | Xent 0.0562(0.0525) | Loss 1.1388(1.1363) | Error 0.0179(0.0160) Steps 410(410.75) | Grad Norm 0.1910(0.2256) | Total Time 10.00(10.00)\n",
      "Iter 2907 | Time 30.3306(30.0740) | Bit/dim 1.1147(1.1102) | Xent 0.0617(0.0528) | Loss 1.1455(1.1366) | Error 0.0189(0.0161) Steps 410(410.73) | Grad Norm 0.1794(0.2243) | Total Time 10.00(10.00)\n",
      "Iter 2908 | Time 30.0243(30.0725) | Bit/dim 1.1102(1.1102) | Xent 0.0419(0.0525) | Loss 1.1311(1.1364) | Error 0.0124(0.0160) Steps 410(410.71) | Grad Norm 0.2081(0.2238) | Total Time 10.00(10.00)\n",
      "Iter 2909 | Time 31.0207(30.1010) | Bit/dim 1.1060(1.1101) | Xent 0.0465(0.0523) | Loss 1.1292(1.1362) | Error 0.0142(0.0159) Steps 410(410.69) | Grad Norm 0.1776(0.2224) | Total Time 10.00(10.00)\n",
      "Iter 2910 | Time 29.4409(30.0812) | Bit/dim 1.1081(1.1100) | Xent 0.0523(0.0523) | Loss 1.1342(1.1362) | Error 0.0162(0.0160) Steps 410(410.67) | Grad Norm 0.1549(0.2204) | Total Time 10.00(10.00)\n",
      "Iter 2911 | Time 30.0112(30.0791) | Bit/dim 1.1147(1.1102) | Xent 0.0540(0.0524) | Loss 1.1417(1.1363) | Error 0.0166(0.0160) Steps 416(410.83) | Grad Norm 0.1563(0.2184) | Total Time 10.00(10.00)\n",
      "Iter 2912 | Time 29.5231(30.0624) | Bit/dim 1.1079(1.1101) | Xent 0.0579(0.0525) | Loss 1.1368(1.1364) | Error 0.0180(0.0160) Steps 410(410.80) | Grad Norm 0.1650(0.2168) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 16.3095, Epoch Time 238.8961(238.5552), Bit/dim 1.1041(best: 1.1037), Xent 0.0331, Loss 1.1206, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2913 | Time 29.6105(30.0488) | Bit/dim 1.1118(1.1101) | Xent 0.0593(0.0527) | Loss 1.1414(1.1365) | Error 0.0176(0.0161) Steps 410(410.78) | Grad Norm 0.1482(0.2148) | Total Time 10.00(10.00)\n",
      "Iter 2914 | Time 30.1258(30.0511) | Bit/dim 1.1068(1.1100) | Xent 0.0514(0.0527) | Loss 1.1325(1.1364) | Error 0.0152(0.0161) Steps 410(410.75) | Grad Norm 0.2127(0.2147) | Total Time 10.00(10.00)\n",
      "Iter 2915 | Time 29.9146(30.0470) | Bit/dim 1.1173(1.1103) | Xent 0.0532(0.0527) | Loss 1.1439(1.1366) | Error 0.0155(0.0160) Steps 416(410.91) | Grad Norm 0.1232(0.2120) | Total Time 10.00(10.00)\n",
      "Iter 2916 | Time 30.3012(30.0547) | Bit/dim 1.1134(1.1104) | Xent 0.0480(0.0526) | Loss 1.1374(1.1366) | Error 0.0150(0.0160) Steps 410(410.88) | Grad Norm 0.2807(0.2140) | Total Time 10.00(10.00)\n",
      "Iter 2917 | Time 29.7383(30.0452) | Bit/dim 1.1150(1.1105) | Xent 0.0546(0.0526) | Loss 1.1423(1.1368) | Error 0.0150(0.0160) Steps 422(411.22) | Grad Norm 0.2146(0.2140) | Total Time 10.00(10.00)\n",
      "Iter 2918 | Time 29.3739(30.0250) | Bit/dim 1.1036(1.1103) | Xent 0.0523(0.0526) | Loss 1.1298(1.1366) | Error 0.0181(0.0160) Steps 416(411.36) | Grad Norm 0.2132(0.2140) | Total Time 10.00(10.00)\n",
      "Iter 2919 | Time 29.6686(30.0143) | Bit/dim 1.1012(1.1100) | Xent 0.0481(0.0525) | Loss 1.1252(1.1363) | Error 0.0148(0.0160) Steps 422(411.68) | Grad Norm 0.1524(0.2122) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 16.1953, Epoch Time 237.0251(238.5093), Bit/dim 1.1036(best: 1.1037), Xent 0.0322, Loss 1.1197, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2920 | Time 30.0469(30.0153) | Bit/dim 1.1120(1.1101) | Xent 0.0578(0.0526) | Loss 1.1409(1.1364) | Error 0.0174(0.0160) Steps 410(411.63) | Grad Norm 0.1794(0.2112) | Total Time 10.00(10.00)\n",
      "Iter 2921 | Time 29.2391(29.9920) | Bit/dim 1.1164(1.1103) | Xent 0.0519(0.0526) | Loss 1.1424(1.1366) | Error 0.0168(0.0161) Steps 410(411.58) | Grad Norm 0.3235(0.2146) | Total Time 10.00(10.00)\n",
      "Iter 2922 | Time 29.4077(29.9745) | Bit/dim 1.1070(1.1102) | Xent 0.0558(0.0527) | Loss 1.1349(1.1365) | Error 0.0161(0.0161) Steps 410(411.53) | Grad Norm 0.2210(0.2147) | Total Time 10.00(10.00)\n",
      "Iter 2923 | Time 29.0991(29.9482) | Bit/dim 1.1116(1.1102) | Xent 0.0584(0.0529) | Loss 1.1408(1.1366) | Error 0.0180(0.0161) Steps 410(411.49) | Grad Norm 0.2966(0.2172) | Total Time 10.00(10.00)\n",
      "Iter 2924 | Time 29.4974(29.9347) | Bit/dim 1.1127(1.1103) | Xent 0.0567(0.0530) | Loss 1.1411(1.1368) | Error 0.0160(0.0161) Steps 410(411.44) | Grad Norm 0.3324(0.2207) | Total Time 10.00(10.00)\n",
      "Iter 2925 | Time 30.5138(29.9521) | Bit/dim 1.1065(1.1102) | Xent 0.0519(0.0530) | Loss 1.1325(1.1367) | Error 0.0166(0.0161) Steps 410(411.40) | Grad Norm 0.1636(0.2189) | Total Time 10.00(10.00)\n",
      "Iter 2926 | Time 30.5663(29.9705) | Bit/dim 1.1017(1.1099) | Xent 0.0529(0.0530) | Loss 1.1282(1.1364) | Error 0.0160(0.0161) Steps 410(411.36) | Grad Norm 0.2165(0.2189) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 16.2920, Epoch Time 237.0254(238.4648), Bit/dim 1.1041(best: 1.1036), Xent 0.0315, Loss 1.1199, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2927 | Time 30.1394(29.9756) | Bit/dim 1.1122(1.1100) | Xent 0.0561(0.0531) | Loss 1.1402(1.1365) | Error 0.0166(0.0161) Steps 416(411.50) | Grad Norm 0.1896(0.2180) | Total Time 10.00(10.00)\n",
      "Iter 2928 | Time 29.8832(29.9728) | Bit/dim 1.1087(1.1099) | Xent 0.0547(0.0531) | Loss 1.1361(1.1365) | Error 0.0160(0.0161) Steps 410(411.45) | Grad Norm 0.3357(0.2215) | Total Time 10.00(10.00)\n",
      "Iter 2929 | Time 30.2425(29.9809) | Bit/dim 1.1139(1.1101) | Xent 0.0514(0.0531) | Loss 1.1396(1.1366) | Error 0.0159(0.0161) Steps 410(411.41) | Grad Norm 0.2208(0.2215) | Total Time 10.00(10.00)\n",
      "Iter 2930 | Time 29.9207(29.9791) | Bit/dim 1.1114(1.1101) | Xent 0.0504(0.0530) | Loss 1.1366(1.1366) | Error 0.0156(0.0161) Steps 410(411.37) | Grad Norm 0.2163(0.2214) | Total Time 10.00(10.00)\n",
      "Iter 2931 | Time 29.8216(29.9744) | Bit/dim 1.1060(1.1100) | Xent 0.0522(0.0530) | Loss 1.1321(1.1365) | Error 0.0169(0.0161) Steps 410(411.32) | Grad Norm 0.2854(0.2233) | Total Time 10.00(10.00)\n",
      "Iter 2932 | Time 29.6476(29.9646) | Bit/dim 1.1079(1.1099) | Xent 0.0608(0.0532) | Loss 1.1383(1.1365) | Error 0.0182(0.0162) Steps 410(411.28) | Grad Norm 0.2802(0.2250) | Total Time 10.00(10.00)\n",
      "Iter 2933 | Time 29.6107(29.9540) | Bit/dim 1.1088(1.1099) | Xent 0.0501(0.0531) | Loss 1.1338(1.1364) | Error 0.0158(0.0162) Steps 410(411.25) | Grad Norm 0.3305(0.2281) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 16.0405, Epoch Time 237.4253(238.4336), Bit/dim 1.1037(best: 1.1036), Xent 0.0305, Loss 1.1190, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2934 | Time 29.7748(29.9486) | Bit/dim 1.1086(1.1098) | Xent 0.0581(0.0532) | Loss 1.1377(1.1365) | Error 0.0184(0.0163) Steps 410(411.21) | Grad Norm 0.1582(0.2260) | Total Time 10.00(10.00)\n",
      "Iter 2935 | Time 31.7274(30.0019) | Bit/dim 1.1151(1.1100) | Xent 0.0521(0.0532) | Loss 1.1411(1.1366) | Error 0.0156(0.0162) Steps 410(411.17) | Grad Norm 0.1584(0.2240) | Total Time 10.00(10.00)\n",
      "Iter 2936 | Time 30.4149(30.0143) | Bit/dim 1.1127(1.1101) | Xent 0.0587(0.0534) | Loss 1.1421(1.1368) | Error 0.0185(0.0163) Steps 416(411.32) | Grad Norm 0.2364(0.2244) | Total Time 10.00(10.00)\n",
      "Iter 2937 | Time 30.6746(30.0341) | Bit/dim 1.1108(1.1101) | Xent 0.0517(0.0533) | Loss 1.1366(1.1368) | Error 0.0150(0.0163) Steps 410(411.28) | Grad Norm 0.1617(0.2225) | Total Time 10.00(10.00)\n",
      "Iter 2938 | Time 30.3550(30.0438) | Bit/dim 1.1065(1.1100) | Xent 0.0478(0.0532) | Loss 1.1304(1.1366) | Error 0.0155(0.0162) Steps 416(411.42) | Grad Norm 0.2320(0.2228) | Total Time 10.00(10.00)\n",
      "Iter 2939 | Time 30.1023(30.0455) | Bit/dim 1.1061(1.1099) | Xent 0.0539(0.0532) | Loss 1.1330(1.1365) | Error 0.0164(0.0162) Steps 410(411.38) | Grad Norm 0.1735(0.2213) | Total Time 10.00(10.00)\n",
      "Iter 2940 | Time 29.9319(30.0421) | Bit/dim 1.1078(1.1098) | Xent 0.0480(0.0530) | Loss 1.1319(1.1363) | Error 0.0142(0.0162) Steps 410(411.34) | Grad Norm 0.2214(0.2213) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 16.1986, Epoch Time 241.2815(238.5191), Bit/dim 1.1041(best: 1.1036), Xent 0.0325, Loss 1.1204, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2941 | Time 29.7786(30.0342) | Bit/dim 1.1064(1.1097) | Xent 0.0478(0.0529) | Loss 1.1304(1.1362) | Error 0.0156(0.0162) Steps 410(411.30) | Grad Norm 0.1640(0.2196) | Total Time 10.00(10.00)\n",
      "Iter 2942 | Time 29.7392(30.0254) | Bit/dim 1.1089(1.1097) | Xent 0.0517(0.0528) | Loss 1.1347(1.1361) | Error 0.0164(0.0162) Steps 410(411.26) | Grad Norm 0.1812(0.2184) | Total Time 10.00(10.00)\n",
      "Iter 2943 | Time 30.2737(30.0328) | Bit/dim 1.1082(1.1097) | Xent 0.0484(0.0527) | Loss 1.1324(1.1360) | Error 0.0144(0.0161) Steps 410(411.22) | Grad Norm 0.2008(0.2179) | Total Time 10.00(10.00)\n",
      "Iter 2944 | Time 30.0779(30.0342) | Bit/dim 1.1088(1.1096) | Xent 0.0473(0.0525) | Loss 1.1324(1.1359) | Error 0.0138(0.0161) Steps 416(411.36) | Grad Norm 0.1723(0.2165) | Total Time 10.00(10.00)\n",
      "Iter 2945 | Time 29.1057(30.0063) | Bit/dim 1.1117(1.1097) | Xent 0.0518(0.0525) | Loss 1.1376(1.1359) | Error 0.0171(0.0161) Steps 410(411.32) | Grad Norm 0.2474(0.2175) | Total Time 10.00(10.00)\n",
      "Iter 2946 | Time 30.2342(30.0131) | Bit/dim 1.1092(1.1097) | Xent 0.0562(0.0526) | Loss 1.1374(1.1360) | Error 0.0164(0.0161) Steps 410(411.28) | Grad Norm 0.1854(0.2165) | Total Time 10.00(10.00)\n",
      "Iter 2947 | Time 30.6418(30.0320) | Bit/dim 1.1102(1.1097) | Xent 0.0540(0.0527) | Loss 1.1372(1.1360) | Error 0.0154(0.0161) Steps 416(411.42) | Grad Norm 0.1968(0.2159) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 16.0471, Epoch Time 237.9367(238.5016), Bit/dim 1.1037(best: 1.1036), Xent 0.0305, Loss 1.1190, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2948 | Time 30.4303(30.0439) | Bit/dim 1.1088(1.1097) | Xent 0.0496(0.0526) | Loss 1.1336(1.1359) | Error 0.0148(0.0160) Steps 410(411.38) | Grad Norm 0.1753(0.2147) | Total Time 10.00(10.00)\n",
      "Iter 2949 | Time 29.9426(30.0409) | Bit/dim 1.1159(1.1098) | Xent 0.0502(0.0525) | Loss 1.1410(1.1361) | Error 0.0156(0.0160) Steps 416(411.52) | Grad Norm 0.2143(0.2147) | Total Time 10.00(10.00)\n",
      "Iter 2950 | Time 30.1946(30.0455) | Bit/dim 1.1063(1.1097) | Xent 0.0542(0.0526) | Loss 1.1334(1.1360) | Error 0.0164(0.0160) Steps 410(411.47) | Grad Norm 0.2232(0.2149) | Total Time 10.00(10.00)\n",
      "Iter 2951 | Time 30.4169(30.0567) | Bit/dim 1.1081(1.1097) | Xent 0.0515(0.0525) | Loss 1.1338(1.1360) | Error 0.0160(0.0160) Steps 422(411.79) | Grad Norm 0.2040(0.2146) | Total Time 10.00(10.00)\n",
      "Iter 2952 | Time 30.2516(30.0625) | Bit/dim 1.1110(1.1097) | Xent 0.0474(0.0524) | Loss 1.1347(1.1359) | Error 0.0140(0.0160) Steps 416(411.92) | Grad Norm 0.1926(0.2140) | Total Time 10.00(10.00)\n",
      "Iter 2953 | Time 30.3504(30.0711) | Bit/dim 1.1098(1.1097) | Xent 0.0537(0.0524) | Loss 1.1367(1.1359) | Error 0.0155(0.0160) Steps 410(411.86) | Grad Norm 0.2563(0.2152) | Total Time 10.00(10.00)\n",
      "Iter 2954 | Time 30.3186(30.0786) | Bit/dim 1.1065(1.1096) | Xent 0.0601(0.0526) | Loss 1.1366(1.1360) | Error 0.0176(0.0160) Steps 410(411.80) | Grad Norm 0.2163(0.2153) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 16.1556, Epoch Time 240.5067(238.5617), Bit/dim 1.1034(best: 1.1036), Xent 0.0304, Loss 1.1186, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2955 | Time 30.8843(30.1027) | Bit/dim 1.1047(1.1095) | Xent 0.0513(0.0526) | Loss 1.1303(1.1358) | Error 0.0150(0.0160) Steps 416(411.93) | Grad Norm 0.2578(0.2165) | Total Time 10.00(10.00)\n",
      "Iter 2956 | Time 31.6285(30.1485) | Bit/dim 1.1074(1.1094) | Xent 0.0578(0.0528) | Loss 1.1364(1.1358) | Error 0.0161(0.0160) Steps 416(412.05) | Grad Norm 0.2501(0.2175) | Total Time 10.00(10.00)\n",
      "Iter 2957 | Time 29.7930(30.1378) | Bit/dim 1.1058(1.1093) | Xent 0.0489(0.0526) | Loss 1.1303(1.1356) | Error 0.0144(0.0159) Steps 410(411.99) | Grad Norm 0.1455(0.2154) | Total Time 10.00(10.00)\n",
      "Iter 2958 | Time 30.1301(30.1376) | Bit/dim 1.1115(1.1094) | Xent 0.0428(0.0523) | Loss 1.1329(1.1356) | Error 0.0148(0.0159) Steps 410(411.93) | Grad Norm 0.2416(0.2162) | Total Time 10.00(10.00)\n",
      "Iter 2959 | Time 30.5496(30.1500) | Bit/dim 1.1139(1.1095) | Xent 0.0524(0.0523) | Loss 1.1400(1.1357) | Error 0.0141(0.0158) Steps 410(411.87) | Grad Norm 0.4403(0.2229) | Total Time 10.00(10.00)\n",
      "Iter 2960 | Time 30.0155(30.1459) | Bit/dim 1.1104(1.1095) | Xent 0.0520(0.0523) | Loss 1.1364(1.1357) | Error 0.0169(0.0159) Steps 410(411.82) | Grad Norm 0.1796(0.2216) | Total Time 10.00(10.00)\n",
      "Iter 2961 | Time 29.9746(30.1408) | Bit/dim 1.1107(1.1096) | Xent 0.0466(0.0522) | Loss 1.1340(1.1357) | Error 0.0142(0.0158) Steps 410(411.76) | Grad Norm 0.2148(0.2214) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 16.2158, Epoch Time 241.6113(238.6532), Bit/dim 1.1036(best: 1.1034), Xent 0.0331, Loss 1.1201, Error 0.0112(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2962 | Time 29.1443(30.1109) | Bit/dim 1.1079(1.1095) | Xent 0.0522(0.0522) | Loss 1.1340(1.1356) | Error 0.0148(0.0158) Steps 416(411.89) | Grad Norm 0.2511(0.2223) | Total Time 10.00(10.00)\n",
      "Iter 2963 | Time 29.2234(30.0843) | Bit/dim 1.1054(1.1094) | Xent 0.0498(0.0521) | Loss 1.1303(1.1355) | Error 0.0164(0.0158) Steps 410(411.83) | Grad Norm 0.2958(0.2245) | Total Time 10.00(10.00)\n",
      "Iter 2964 | Time 31.1210(30.1154) | Bit/dim 1.1114(1.1095) | Xent 0.0550(0.0522) | Loss 1.1389(1.1356) | Error 0.0175(0.0159) Steps 416(411.96) | Grad Norm 0.1829(0.2232) | Total Time 10.00(10.00)\n",
      "Iter 2965 | Time 30.2124(30.1183) | Bit/dim 1.1097(1.1095) | Xent 0.0459(0.0520) | Loss 1.1326(1.1355) | Error 0.0149(0.0158) Steps 416(412.08) | Grad Norm 0.2990(0.2255) | Total Time 10.00(10.00)\n",
      "Iter 2966 | Time 29.7872(30.1084) | Bit/dim 1.1099(1.1095) | Xent 0.0518(0.0520) | Loss 1.1358(1.1355) | Error 0.0140(0.0158) Steps 416(412.20) | Grad Norm 0.2478(0.2262) | Total Time 10.00(10.00)\n",
      "Iter 2967 | Time 30.1757(30.1104) | Bit/dim 1.1142(1.1096) | Xent 0.0505(0.0519) | Loss 1.1394(1.1356) | Error 0.0160(0.0158) Steps 416(412.31) | Grad Norm 0.2107(0.2257) | Total Time 10.00(10.00)\n",
      "Iter 2968 | Time 30.5905(30.1248) | Bit/dim 1.1070(1.1095) | Xent 0.0510(0.0519) | Loss 1.1325(1.1355) | Error 0.0159(0.0158) Steps 410(412.24) | Grad Norm 0.2791(0.2273) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 16.3767, Epoch Time 238.8436(238.6589), Bit/dim 1.1038(best: 1.1034), Xent 0.0324, Loss 1.1200, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2969 | Time 29.5982(30.1090) | Bit/dim 1.1092(1.1095) | Xent 0.0522(0.0519) | Loss 1.1353(1.1355) | Error 0.0166(0.0158) Steps 410(412.17) | Grad Norm 0.1557(0.2252) | Total Time 10.00(10.00)\n",
      "Iter 2970 | Time 29.6469(30.0951) | Bit/dim 1.1064(1.1094) | Xent 0.0491(0.0518) | Loss 1.1309(1.1354) | Error 0.0159(0.0158) Steps 410(412.11) | Grad Norm 0.1873(0.2240) | Total Time 10.00(10.00)\n",
      "Iter 2971 | Time 30.0024(30.0923) | Bit/dim 1.1112(1.1095) | Xent 0.0598(0.0521) | Loss 1.1411(1.1355) | Error 0.0169(0.0158) Steps 410(412.04) | Grad Norm 0.2173(0.2238) | Total Time 10.00(10.00)\n",
      "Iter 2972 | Time 29.6540(30.0792) | Bit/dim 1.1081(1.1095) | Xent 0.0530(0.0521) | Loss 1.1346(1.1355) | Error 0.0168(0.0159) Steps 410(411.98) | Grad Norm 0.2874(0.2257) | Total Time 10.00(10.00)\n",
      "Iter 2973 | Time 30.2555(30.0845) | Bit/dim 1.1097(1.1095) | Xent 0.0485(0.0520) | Loss 1.1339(1.1355) | Error 0.0141(0.0158) Steps 416(412.10) | Grad Norm 0.2309(0.2259) | Total Time 10.00(10.00)\n",
      "Iter 2974 | Time 30.6540(30.1016) | Bit/dim 1.1088(1.1094) | Xent 0.0507(0.0520) | Loss 1.1341(1.1354) | Error 0.0139(0.0158) Steps 410(412.04) | Grad Norm 0.2536(0.2267) | Total Time 10.00(10.00)\n",
      "Iter 2975 | Time 30.0508(30.1000) | Bit/dim 1.1133(1.1096) | Xent 0.0535(0.0520) | Loss 1.1400(1.1356) | Error 0.0159(0.0158) Steps 410(411.98) | Grad Norm 0.1633(0.2248) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 16.3544, Epoch Time 238.2950(238.6480), Bit/dim 1.1043(best: 1.1034), Xent 0.0344, Loss 1.1214, Error 0.0111(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2976 | Time 30.9195(30.1246) | Bit/dim 1.1072(1.1095) | Xent 0.0513(0.0520) | Loss 1.1329(1.1355) | Error 0.0148(0.0157) Steps 416(412.10) | Grad Norm 0.3594(0.2289) | Total Time 10.00(10.00)\n",
      "Iter 2977 | Time 29.8024(30.1150) | Bit/dim 1.1083(1.1094) | Xent 0.0492(0.0519) | Loss 1.1329(1.1354) | Error 0.0154(0.0157) Steps 416(412.22) | Grad Norm 0.4911(0.2367) | Total Time 10.00(10.00)\n",
      "Iter 2978 | Time 30.5111(30.1268) | Bit/dim 1.1112(1.1095) | Xent 0.0536(0.0519) | Loss 1.1380(1.1355) | Error 0.0180(0.0158) Steps 416(412.33) | Grad Norm 0.2571(0.2373) | Total Time 10.00(10.00)\n",
      "Iter 2979 | Time 30.3281(30.1329) | Bit/dim 1.1120(1.1096) | Xent 0.0573(0.0521) | Loss 1.1406(1.1356) | Error 0.0171(0.0158) Steps 410(412.26) | Grad Norm 0.2640(0.2381) | Total Time 10.00(10.00)\n",
      "Iter 2980 | Time 30.3012(30.1379) | Bit/dim 1.1107(1.1096) | Xent 0.0571(0.0523) | Loss 1.1393(1.1357) | Error 0.0168(0.0159) Steps 410(412.19) | Grad Norm 0.2871(0.2396) | Total Time 10.00(10.00)\n",
      "Iter 2981 | Time 30.7193(30.1554) | Bit/dim 1.1084(1.1096) | Xent 0.0595(0.0525) | Loss 1.1382(1.1358) | Error 0.0172(0.0159) Steps 410(412.13) | Grad Norm 0.3737(0.2436) | Total Time 10.00(10.00)\n",
      "Iter 2982 | Time 30.5435(30.1670) | Bit/dim 1.1076(1.1095) | Xent 0.0511(0.0524) | Loss 1.1332(1.1357) | Error 0.0151(0.0159) Steps 410(412.06) | Grad Norm 0.2146(0.2428) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 16.1218, Epoch Time 241.2789(238.7270), Bit/dim 1.1039(best: 1.1034), Xent 0.0304, Loss 1.1191, Error 0.0111(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2983 | Time 31.1316(30.1960) | Bit/dim 1.1086(1.1095) | Xent 0.0514(0.0524) | Loss 1.1343(1.1357) | Error 0.0155(0.0159) Steps 416(412.18) | Grad Norm 0.1740(0.2407) | Total Time 10.00(10.00)\n",
      "Iter 2984 | Time 28.7475(30.1525) | Bit/dim 1.1058(1.1094) | Xent 0.0411(0.0521) | Loss 1.1264(1.1354) | Error 0.0120(0.0158) Steps 410(412.12) | Grad Norm 0.2113(0.2398) | Total Time 10.00(10.00)\n",
      "Iter 2985 | Time 29.9017(30.1450) | Bit/dim 1.1114(1.1094) | Xent 0.0560(0.0522) | Loss 1.1394(1.1355) | Error 0.0164(0.0158) Steps 410(412.05) | Grad Norm 0.3119(0.2420) | Total Time 10.00(10.00)\n",
      "Iter 2986 | Time 31.4365(30.1837) | Bit/dim 1.1121(1.1095) | Xent 0.0511(0.0522) | Loss 1.1377(1.1356) | Error 0.0165(0.0158) Steps 416(412.17) | Grad Norm 0.1395(0.2389) | Total Time 10.00(10.00)\n",
      "Iter 2987 | Time 30.3730(30.1894) | Bit/dim 1.1162(1.1097) | Xent 0.0561(0.0523) | Loss 1.1443(1.1359) | Error 0.0181(0.0159) Steps 422(412.47) | Grad Norm 0.1968(0.2376) | Total Time 10.00(10.00)\n",
      "Iter 2988 | Time 30.1198(30.1873) | Bit/dim 1.1076(1.1097) | Xent 0.0573(0.0524) | Loss 1.1363(1.1359) | Error 0.0168(0.0159) Steps 416(412.57) | Grad Norm 0.2638(0.2384) | Total Time 10.00(10.00)\n",
      "Iter 2989 | Time 30.8905(30.2084) | Bit/dim 1.1046(1.1095) | Xent 0.0579(0.0526) | Loss 1.1335(1.1358) | Error 0.0176(0.0159) Steps 410(412.49) | Grad Norm 0.2324(0.2382) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 16.4650, Epoch Time 241.1115(238.7985), Bit/dim 1.1045(best: 1.1034), Xent 0.0335, Loss 1.1213, Error 0.0109(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2990 | Time 30.1393(30.2063) | Bit/dim 1.1110(1.1095) | Xent 0.0507(0.0525) | Loss 1.1364(1.1358) | Error 0.0159(0.0159) Steps 410(412.42) | Grad Norm 0.2912(0.2398) | Total Time 10.00(10.00)\n",
      "Iter 2991 | Time 29.5810(30.1876) | Bit/dim 1.1109(1.1096) | Xent 0.0490(0.0524) | Loss 1.1354(1.1358) | Error 0.0164(0.0160) Steps 410(412.35) | Grad Norm 0.2273(0.2395) | Total Time 10.00(10.00)\n",
      "Iter 2992 | Time 31.0556(30.2136) | Bit/dim 1.1099(1.1096) | Xent 0.0500(0.0524) | Loss 1.1349(1.1358) | Error 0.0145(0.0159) Steps 416(412.46) | Grad Norm 0.1599(0.2371) | Total Time 10.00(10.00)\n",
      "Iter 2993 | Time 28.9280(30.1750) | Bit/dim 1.1100(1.1096) | Xent 0.0548(0.0524) | Loss 1.1374(1.1358) | Error 0.0179(0.0160) Steps 410(412.38) | Grad Norm 0.1996(0.2359) | Total Time 10.00(10.00)\n",
      "Iter 2994 | Time 30.4253(30.1826) | Bit/dim 1.1122(1.1097) | Xent 0.0592(0.0526) | Loss 1.1418(1.1360) | Error 0.0166(0.0160) Steps 416(412.49) | Grad Norm 0.2286(0.2357) | Total Time 10.00(10.00)\n",
      "Iter 2995 | Time 30.5642(30.1940) | Bit/dim 1.1062(1.1096) | Xent 0.0462(0.0524) | Loss 1.1293(1.1358) | Error 0.0159(0.0160) Steps 416(412.60) | Grad Norm 0.1568(0.2334) | Total Time 10.00(10.00)\n",
      "Iter 2996 | Time 29.8035(30.1823) | Bit/dim 1.1071(1.1095) | Xent 0.0530(0.0525) | Loss 1.1336(1.1357) | Error 0.0166(0.0160) Steps 410(412.52) | Grad Norm 0.1590(0.2311) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 16.2625, Epoch Time 239.3239(238.8143), Bit/dim 1.1043(best: 1.1034), Xent 0.0328, Loss 1.1207, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 2997 | Time 30.2155(30.1833) | Bit/dim 1.1108(1.1095) | Xent 0.0484(0.0523) | Loss 1.1350(1.1357) | Error 0.0156(0.0160) Steps 410(412.44) | Grad Norm 0.1279(0.2280) | Total Time 10.00(10.00)\n",
      "Iter 2998 | Time 29.9196(30.1754) | Bit/dim 1.1063(1.1094) | Xent 0.0533(0.0524) | Loss 1.1329(1.1356) | Error 0.0162(0.0160) Steps 410(412.37) | Grad Norm 0.1650(0.2261) | Total Time 10.00(10.00)\n",
      "Iter 2999 | Time 29.8435(30.1654) | Bit/dim 1.1085(1.1094) | Xent 0.0473(0.0522) | Loss 1.1321(1.1355) | Error 0.0140(0.0159) Steps 410(412.30) | Grad Norm 0.3001(0.2284) | Total Time 10.00(10.00)\n",
      "Iter 3000 | Time 29.5485(30.1469) | Bit/dim 1.1100(1.1094) | Xent 0.0493(0.0521) | Loss 1.1346(1.1355) | Error 0.0162(0.0159) Steps 410(412.23) | Grad Norm 0.3258(0.2313) | Total Time 10.00(10.00)\n",
      "Iter 3001 | Time 29.7645(30.1354) | Bit/dim 1.1122(1.1095) | Xent 0.0529(0.0521) | Loss 1.1387(1.1356) | Error 0.0165(0.0160) Steps 410(412.16) | Grad Norm 0.1629(0.2292) | Total Time 10.00(10.00)\n",
      "Iter 3002 | Time 30.2138(30.1378) | Bit/dim 1.1111(1.1096) | Xent 0.0545(0.0522) | Loss 1.1383(1.1357) | Error 0.0150(0.0159) Steps 410(412.10) | Grad Norm 0.2071(0.2286) | Total Time 10.00(10.00)\n",
      "Iter 3003 | Time 30.0005(30.1337) | Bit/dim 1.1078(1.1095) | Xent 0.0578(0.0524) | Loss 1.1367(1.1357) | Error 0.0176(0.0160) Steps 416(412.22) | Grad Norm 0.4790(0.2361) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 16.5291, Epoch Time 238.1796(238.7952), Bit/dim 1.1034(best: 1.1034), Xent 0.0318, Loss 1.1193, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3004 | Time 30.3420(30.1399) | Bit/dim 1.1099(1.1095) | Xent 0.0535(0.0524) | Loss 1.1367(1.1357) | Error 0.0172(0.0160) Steps 416(412.33) | Grad Norm 0.2098(0.2353) | Total Time 10.00(10.00)\n",
      "Iter 3005 | Time 29.6731(30.1259) | Bit/dim 1.1055(1.1094) | Xent 0.0542(0.0525) | Loss 1.1326(1.1356) | Error 0.0165(0.0160) Steps 410(412.26) | Grad Norm 0.1913(0.2340) | Total Time 10.00(10.00)\n",
      "Iter 3006 | Time 29.9976(30.1221) | Bit/dim 1.1070(1.1093) | Xent 0.0507(0.0524) | Loss 1.1323(1.1355) | Error 0.0144(0.0160) Steps 410(412.19) | Grad Norm 0.2589(0.2347) | Total Time 10.00(10.00)\n",
      "Iter 3007 | Time 31.5023(30.1635) | Bit/dim 1.1116(1.1094) | Xent 0.0514(0.0524) | Loss 1.1373(1.1356) | Error 0.0154(0.0160) Steps 416(412.31) | Grad Norm 0.1964(0.2336) | Total Time 10.00(10.00)\n",
      "Iter 3008 | Time 29.0916(30.1313) | Bit/dim 1.1079(1.1094) | Xent 0.0477(0.0522) | Loss 1.1317(1.1355) | Error 0.0135(0.0159) Steps 416(412.42) | Grad Norm 0.2520(0.2341) | Total Time 10.00(10.00)\n",
      "Iter 3009 | Time 29.9321(30.1253) | Bit/dim 1.1149(1.1095) | Xent 0.0524(0.0523) | Loss 1.1411(1.1356) | Error 0.0160(0.0159) Steps 416(412.52) | Grad Norm 0.2197(0.2337) | Total Time 10.00(10.00)\n",
      "Iter 3010 | Time 29.8165(30.1161) | Bit/dim 1.1105(1.1096) | Xent 0.0473(0.0521) | Loss 1.1342(1.1356) | Error 0.0125(0.0158) Steps 422(412.81) | Grad Norm 0.1785(0.2320) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 15.9271, Epoch Time 238.4713(238.7855), Bit/dim 1.1035(best: 1.1034), Xent 0.0295, Loss 1.1183, Error 0.0091(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3011 | Time 30.0763(30.1149) | Bit/dim 1.1103(1.1096) | Xent 0.0602(0.0523) | Loss 1.1404(1.1357) | Error 0.0184(0.0159) Steps 410(412.72) | Grad Norm 0.2667(0.2331) | Total Time 10.00(10.00)\n",
      "Iter 3012 | Time 29.8998(30.1084) | Bit/dim 1.1078(1.1095) | Xent 0.0461(0.0522) | Loss 1.1309(1.1356) | Error 0.0132(0.0158) Steps 416(412.82) | Grad Norm 0.2773(0.2344) | Total Time 10.00(10.00)\n",
      "Iter 3013 | Time 30.4930(30.1200) | Bit/dim 1.1099(1.1095) | Xent 0.0506(0.0521) | Loss 1.1352(1.1356) | Error 0.0146(0.0158) Steps 416(412.92) | Grad Norm 0.2180(0.2339) | Total Time 10.00(10.00)\n",
      "Iter 3014 | Time 30.4240(30.1291) | Bit/dim 1.1081(1.1095) | Xent 0.0530(0.0521) | Loss 1.1346(1.1356) | Error 0.0170(0.0158) Steps 410(412.83) | Grad Norm 0.2312(0.2338) | Total Time 10.00(10.00)\n",
      "Iter 3015 | Time 30.1302(30.1291) | Bit/dim 1.1080(1.1094) | Xent 0.0525(0.0522) | Loss 1.1343(1.1355) | Error 0.0149(0.0158) Steps 410(412.75) | Grad Norm 0.2397(0.2340) | Total Time 10.00(10.00)\n",
      "Iter 3016 | Time 30.1587(30.1300) | Bit/dim 1.1080(1.1094) | Xent 0.0514(0.0521) | Loss 1.1336(1.1355) | Error 0.0159(0.0158) Steps 410(412.66) | Grad Norm 0.3426(0.2373) | Total Time 10.00(10.00)\n",
      "Iter 3017 | Time 30.1388(30.1303) | Bit/dim 1.1108(1.1094) | Xent 0.0474(0.0520) | Loss 1.1345(1.1354) | Error 0.0151(0.0158) Steps 422(412.94) | Grad Norm 0.4121(0.2425) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 16.4575, Epoch Time 240.0673(238.8239), Bit/dim 1.1039(best: 1.1034), Xent 0.0315, Loss 1.1196, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3018 | Time 29.9650(30.1253) | Bit/dim 1.1043(1.1093) | Xent 0.0468(0.0518) | Loss 1.1277(1.1352) | Error 0.0124(0.0157) Steps 422(413.21) | Grad Norm 0.2897(0.2439) | Total Time 10.00(10.00)\n",
      "Iter 3019 | Time 30.1778(30.1269) | Bit/dim 1.1072(1.1092) | Xent 0.0577(0.0520) | Loss 1.1360(1.1352) | Error 0.0175(0.0157) Steps 410(413.12) | Grad Norm 0.1741(0.2418) | Total Time 10.00(10.00)\n",
      "Iter 3020 | Time 29.7867(30.1167) | Bit/dim 1.1099(1.1092) | Xent 0.0458(0.0518) | Loss 1.1328(1.1352) | Error 0.0152(0.0157) Steps 416(413.20) | Grad Norm 0.3177(0.2441) | Total Time 10.00(10.00)\n",
      "Iter 3021 | Time 30.5367(30.1293) | Bit/dim 1.1082(1.1092) | Xent 0.0511(0.0518) | Loss 1.1338(1.1351) | Error 0.0168(0.0157) Steps 416(413.29) | Grad Norm 0.3344(0.2468) | Total Time 10.00(10.00)\n",
      "Iter 3022 | Time 31.4158(30.1679) | Bit/dim 1.1139(1.1094) | Xent 0.0561(0.0519) | Loss 1.1420(1.1353) | Error 0.0182(0.0158) Steps 416(413.37) | Grad Norm 0.2060(0.2456) | Total Time 10.00(10.00)\n",
      "Iter 3023 | Time 30.4755(30.1771) | Bit/dim 1.1077(1.1093) | Xent 0.0565(0.0521) | Loss 1.1360(1.1353) | Error 0.0168(0.0158) Steps 410(413.27) | Grad Norm 0.1929(0.2440) | Total Time 10.00(10.00)\n",
      "Iter 3024 | Time 29.8878(30.1684) | Bit/dim 1.1135(1.1094) | Xent 0.0500(0.0520) | Loss 1.1385(1.1354) | Error 0.0148(0.0158) Steps 416(413.35) | Grad Norm 0.2539(0.2443) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 16.2094, Epoch Time 240.7534(238.8818), Bit/dim 1.1034(best: 1.1034), Xent 0.0340, Loss 1.1204, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3025 | Time 30.2121(30.1697) | Bit/dim 1.1075(1.1094) | Xent 0.0527(0.0520) | Loss 1.1338(1.1354) | Error 0.0155(0.0158) Steps 410(413.25) | Grad Norm 0.3880(0.2486) | Total Time 10.00(10.00)\n",
      "Iter 3026 | Time 30.4634(30.1785) | Bit/dim 1.1114(1.1094) | Xent 0.0531(0.0521) | Loss 1.1379(1.1355) | Error 0.0170(0.0158) Steps 416(413.33) | Grad Norm 0.1764(0.2464) | Total Time 10.00(10.00)\n",
      "Iter 3027 | Time 30.5895(30.1909) | Bit/dim 1.1090(1.1094) | Xent 0.0522(0.0521) | Loss 1.1351(1.1355) | Error 0.0152(0.0158) Steps 410(413.23) | Grad Norm 0.1543(0.2437) | Total Time 10.00(10.00)\n",
      "Iter 3028 | Time 30.4916(30.1999) | Bit/dim 1.1085(1.1094) | Xent 0.0599(0.0523) | Loss 1.1385(1.1355) | Error 0.0182(0.0159) Steps 416(413.32) | Grad Norm 0.1611(0.2412) | Total Time 10.00(10.00)\n",
      "Iter 3029 | Time 29.5746(30.1811) | Bit/dim 1.1133(1.1095) | Xent 0.0462(0.0521) | Loss 1.1364(1.1356) | Error 0.0151(0.0159) Steps 410(413.22) | Grad Norm 0.1396(0.2382) | Total Time 10.00(10.00)\n",
      "Iter 3030 | Time 30.7553(30.1984) | Bit/dim 1.1076(1.1095) | Xent 0.0551(0.0522) | Loss 1.1352(1.1356) | Error 0.0165(0.0159) Steps 416(413.30) | Grad Norm 0.2806(0.2394) | Total Time 10.00(10.00)\n",
      "Iter 3031 | Time 29.9839(30.1919) | Bit/dim 1.1097(1.1095) | Xent 0.0548(0.0523) | Loss 1.1371(1.1356) | Error 0.0179(0.0159) Steps 416(413.38) | Grad Norm 0.2839(0.2408) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 16.3001, Epoch Time 240.4261(238.9282), Bit/dim 1.1030(best: 1.1034), Xent 0.0322, Loss 1.1191, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3032 | Time 30.1355(30.1902) | Bit/dim 1.1098(1.1095) | Xent 0.0544(0.0523) | Loss 1.1370(1.1356) | Error 0.0162(0.0159) Steps 410(413.28) | Grad Norm 0.1596(0.2383) | Total Time 10.00(10.00)\n",
      "Iter 3033 | Time 29.4471(30.1679) | Bit/dim 1.1083(1.1094) | Xent 0.0496(0.0523) | Loss 1.1331(1.1356) | Error 0.0145(0.0159) Steps 410(413.18) | Grad Norm 0.1859(0.2368) | Total Time 10.00(10.00)\n",
      "Iter 3034 | Time 30.5458(30.1793) | Bit/dim 1.1061(1.1093) | Xent 0.0531(0.0523) | Loss 1.1326(1.1355) | Error 0.0160(0.0159) Steps 422(413.45) | Grad Norm 0.3399(0.2398) | Total Time 10.00(10.00)\n",
      "Iter 3035 | Time 30.4811(30.1883) | Bit/dim 1.1060(1.1092) | Xent 0.0532(0.0523) | Loss 1.1326(1.1354) | Error 0.0171(0.0159) Steps 416(413.52) | Grad Norm 0.3443(0.2430) | Total Time 10.00(10.00)\n",
      "Iter 3036 | Time 30.0763(30.1850) | Bit/dim 1.1106(1.1093) | Xent 0.0485(0.0522) | Loss 1.1348(1.1354) | Error 0.0134(0.0159) Steps 410(413.42) | Grad Norm 0.1748(0.2409) | Total Time 10.00(10.00)\n",
      "Iter 3037 | Time 30.5629(30.1963) | Bit/dim 1.1112(1.1093) | Xent 0.0500(0.0521) | Loss 1.1362(1.1354) | Error 0.0145(0.0158) Steps 416(413.49) | Grad Norm 0.1858(0.2393) | Total Time 10.00(10.00)\n",
      "Iter 3038 | Time 30.4226(30.2031) | Bit/dim 1.1098(1.1093) | Xent 0.0514(0.0521) | Loss 1.1355(1.1354) | Error 0.0151(0.0158) Steps 410(413.39) | Grad Norm 0.3307(0.2420) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 16.4361, Epoch Time 240.4634(238.9742), Bit/dim 1.1043(best: 1.1030), Xent 0.0321, Loss 1.1203, Error 0.0109(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3039 | Time 29.4866(30.1816) | Bit/dim 1.1049(1.1092) | Xent 0.0495(0.0520) | Loss 1.1296(1.1352) | Error 0.0146(0.0158) Steps 410(413.29) | Grad Norm 0.2636(0.2427) | Total Time 10.00(10.00)\n",
      "Iter 3040 | Time 30.7462(30.1985) | Bit/dim 1.1138(1.1094) | Xent 0.0515(0.0520) | Loss 1.1396(1.1354) | Error 0.0178(0.0158) Steps 410(413.19) | Grad Norm 0.2580(0.2431) | Total Time 10.00(10.00)\n",
      "Iter 3041 | Time 30.0559(30.1943) | Bit/dim 1.1071(1.1093) | Xent 0.0560(0.0521) | Loss 1.1351(1.1354) | Error 0.0154(0.0158) Steps 410(413.09) | Grad Norm 0.1862(0.2414) | Total Time 10.00(10.00)\n",
      "Iter 3042 | Time 29.7398(30.1806) | Bit/dim 1.1075(1.1092) | Xent 0.0521(0.0521) | Loss 1.1336(1.1353) | Error 0.0166(0.0158) Steps 410(413.00) | Grad Norm 0.2779(0.2425) | Total Time 10.00(10.00)\n",
      "Iter 3043 | Time 30.5734(30.1924) | Bit/dim 1.1122(1.1093) | Xent 0.0535(0.0522) | Loss 1.1390(1.1354) | Error 0.0162(0.0159) Steps 416(413.09) | Grad Norm 0.2531(0.2428) | Total Time 10.00(10.00)\n",
      "Iter 3044 | Time 30.5827(30.2041) | Bit/dim 1.1114(1.1094) | Xent 0.0548(0.0523) | Loss 1.1388(1.1355) | Error 0.0168(0.0159) Steps 416(413.18) | Grad Norm 0.3105(0.2449) | Total Time 10.00(10.00)\n",
      "Iter 3045 | Time 30.1493(30.2025) | Bit/dim 1.1075(1.1093) | Xent 0.0528(0.0523) | Loss 1.1339(1.1355) | Error 0.0169(0.0159) Steps 416(413.26) | Grad Norm 0.2131(0.2439) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 16.5652, Epoch Time 240.1079(239.0082), Bit/dim 1.1032(best: 1.1030), Xent 0.0325, Loss 1.1195, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3046 | Time 29.9701(30.1955) | Bit/dim 1.1091(1.1093) | Xent 0.0546(0.0523) | Loss 1.1364(1.1355) | Error 0.0170(0.0159) Steps 416(413.34) | Grad Norm 0.1967(0.2425) | Total Time 10.00(10.00)\n",
      "Iter 3047 | Time 29.9324(30.1876) | Bit/dim 1.1080(1.1093) | Xent 0.0540(0.0524) | Loss 1.1351(1.1355) | Error 0.0170(0.0160) Steps 422(413.60) | Grad Norm 0.1915(0.2410) | Total Time 10.00(10.00)\n",
      "Iter 3048 | Time 30.2472(30.1894) | Bit/dim 1.1066(1.1092) | Xent 0.0562(0.0525) | Loss 1.1347(1.1355) | Error 0.0178(0.0160) Steps 416(413.68) | Grad Norm 0.2523(0.2413) | Total Time 10.00(10.00)\n",
      "Iter 3049 | Time 30.7397(30.2059) | Bit/dim 1.1029(1.1090) | Xent 0.0472(0.0524) | Loss 1.1265(1.1352) | Error 0.0152(0.0160) Steps 410(413.57) | Grad Norm 0.1630(0.2390) | Total Time 10.00(10.00)\n",
      "Iter 3050 | Time 30.2252(30.2065) | Bit/dim 1.1105(1.1091) | Xent 0.0513(0.0523) | Loss 1.1361(1.1352) | Error 0.0156(0.0160) Steps 416(413.64) | Grad Norm 0.1861(0.2374) | Total Time 10.00(10.00)\n",
      "Iter 3051 | Time 29.6521(30.1899) | Bit/dim 1.1163(1.1093) | Xent 0.0542(0.0524) | Loss 1.1434(1.1355) | Error 0.0195(0.0161) Steps 410(413.53) | Grad Norm 0.2535(0.2379) | Total Time 10.00(10.00)\n",
      "Iter 3052 | Time 29.9559(30.1828) | Bit/dim 1.1106(1.1093) | Xent 0.0520(0.0524) | Loss 1.1366(1.1355) | Error 0.0156(0.0161) Steps 410(413.42) | Grad Norm 0.2178(0.2373) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0436 | Time 16.0752, Epoch Time 238.9810(239.0074), Bit/dim 1.1039(best: 1.1030), Xent 0.0311, Loss 1.1194, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3053 | Time 29.7883(30.1710) | Bit/dim 1.1104(1.1093) | Xent 0.0550(0.0524) | Loss 1.1379(1.1356) | Error 0.0160(0.0161) Steps 416(413.50) | Grad Norm 0.1667(0.2351) | Total Time 10.00(10.00)\n",
      "Iter 3054 | Time 30.3238(30.1756) | Bit/dim 1.1108(1.1094) | Xent 0.0527(0.0525) | Loss 1.1372(1.1356) | Error 0.0159(0.0161) Steps 416(413.58) | Grad Norm 0.1614(0.2329) | Total Time 10.00(10.00)\n",
      "Iter 3055 | Time 30.3459(30.1807) | Bit/dim 1.1099(1.1094) | Xent 0.0524(0.0525) | Loss 1.1362(1.1356) | Error 0.0140(0.0160) Steps 416(413.65) | Grad Norm 0.1846(0.2315) | Total Time 10.00(10.00)\n",
      "Iter 3056 | Time 30.0497(30.1768) | Bit/dim 1.1062(1.1093) | Xent 0.0498(0.0524) | Loss 1.1311(1.1355) | Error 0.0161(0.0160) Steps 410(413.54) | Grad Norm 0.2546(0.2322) | Total Time 10.00(10.00)\n",
      "Iter 3057 | Time 30.4689(30.1855) | Bit/dim 1.1061(1.1092) | Xent 0.0507(0.0523) | Loss 1.1315(1.1354) | Error 0.0159(0.0160) Steps 422(413.79) | Grad Norm 0.1846(0.2307) | Total Time 10.00(10.00)\n",
      "Iter 3058 | Time 30.5060(30.1951) | Bit/dim 1.1076(1.1092) | Xent 0.0549(0.0524) | Loss 1.1351(1.1354) | Error 0.0154(0.0160) Steps 416(413.86) | Grad Norm 0.2289(0.2307) | Total Time 10.00(10.00)\n",
      "Iter 3059 | Time 30.5565(30.2060) | Bit/dim 1.1104(1.1092) | Xent 0.0506(0.0523) | Loss 1.1358(1.1354) | Error 0.0151(0.0160) Steps 416(413.92) | Grad Norm 0.2458(0.2311) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0437 | Time 16.1035, Epoch Time 240.4408(239.0504), Bit/dim 1.1032(best: 1.1030), Xent 0.0319, Loss 1.1191, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3060 | Time 30.2208(30.2064) | Bit/dim 1.1070(1.1091) | Xent 0.0487(0.0522) | Loss 1.1313(1.1353) | Error 0.0152(0.0159) Steps 416(413.99) | Grad Norm 0.2516(0.2318) | Total Time 10.00(10.00)\n",
      "Iter 3061 | Time 30.9564(30.2289) | Bit/dim 1.1095(1.1092) | Xent 0.0497(0.0522) | Loss 1.1344(1.1352) | Error 0.0160(0.0159) Steps 416(414.05) | Grad Norm 0.1376(0.2289) | Total Time 10.00(10.00)\n",
      "Iter 3062 | Time 31.0655(30.2540) | Bit/dim 1.1079(1.1091) | Xent 0.0555(0.0523) | Loss 1.1356(1.1352) | Error 0.0185(0.0160) Steps 416(414.10) | Grad Norm 0.1892(0.2277) | Total Time 10.00(10.00)\n",
      "Iter 3063 | Time 30.3150(30.2559) | Bit/dim 1.1110(1.1092) | Xent 0.0533(0.0523) | Loss 1.1377(1.1353) | Error 0.0162(0.0160) Steps 422(414.34) | Grad Norm 0.1771(0.2262) | Total Time 10.00(10.00)\n",
      "Iter 3064 | Time 30.4705(30.2623) | Bit/dim 1.1075(1.1091) | Xent 0.0510(0.0523) | Loss 1.1330(1.1352) | Error 0.0158(0.0160) Steps 410(414.21) | Grad Norm 0.2591(0.2272) | Total Time 10.00(10.00)\n",
      "Iter 3065 | Time 31.2142(30.2908) | Bit/dim 1.1070(1.1091) | Xent 0.0538(0.0523) | Loss 1.1339(1.1352) | Error 0.0142(0.0160) Steps 416(414.27) | Grad Norm 0.2608(0.2282) | Total Time 10.00(10.00)\n",
      "Iter 3066 | Time 29.9830(30.2816) | Bit/dim 1.1126(1.1092) | Xent 0.0482(0.0522) | Loss 1.1367(1.1353) | Error 0.0142(0.0159) Steps 410(414.14) | Grad Norm 0.2331(0.2284) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0438 | Time 16.1346, Epoch Time 242.5304(239.1548), Bit/dim 1.1030(best: 1.1030), Xent 0.0338, Loss 1.1199, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3067 | Time 29.9822(30.2726) | Bit/dim 1.1070(1.1091) | Xent 0.0487(0.0521) | Loss 1.1313(1.1351) | Error 0.0151(0.0159) Steps 410(414.01) | Grad Norm 0.1513(0.2260) | Total Time 10.00(10.00)\n",
      "Iter 3068 | Time 30.5197(30.2800) | Bit/dim 1.1011(1.1089) | Xent 0.0603(0.0523) | Loss 1.1313(1.1350) | Error 0.0189(0.0160) Steps 416(414.07) | Grad Norm 0.2535(0.2269) | Total Time 10.00(10.00)\n",
      "Iter 3069 | Time 30.6127(30.2900) | Bit/dim 1.1101(1.1089) | Xent 0.0504(0.0523) | Loss 1.1353(1.1350) | Error 0.0151(0.0160) Steps 410(413.95) | Grad Norm 0.1333(0.2241) | Total Time 10.00(10.00)\n",
      "Iter 3070 | Time 30.0815(30.2838) | Bit/dim 1.1133(1.1090) | Xent 0.0492(0.0522) | Loss 1.1379(1.1351) | Error 0.0134(0.0159) Steps 416(414.01) | Grad Norm 0.1706(0.2225) | Total Time 10.00(10.00)\n",
      "Iter 3071 | Time 29.8953(30.2721) | Bit/dim 1.1123(1.1091) | Xent 0.0470(0.0520) | Loss 1.1358(1.1351) | Error 0.0144(0.0158) Steps 422(414.25) | Grad Norm 0.1679(0.2208) | Total Time 10.00(10.00)\n",
      "Iter 3072 | Time 30.1315(30.2679) | Bit/dim 1.1113(1.1092) | Xent 0.0552(0.0521) | Loss 1.1388(1.1352) | Error 0.0166(0.0159) Steps 416(414.30) | Grad Norm 0.2032(0.2203) | Total Time 10.00(10.00)\n",
      "Iter 3073 | Time 30.5248(30.2756) | Bit/dim 1.1075(1.1091) | Xent 0.0505(0.0521) | Loss 1.1328(1.1352) | Error 0.0156(0.0159) Steps 416(414.35) | Grad Norm 0.1668(0.2187) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0439 | Time 16.1308, Epoch Time 240.3971(239.1921), Bit/dim 1.1037(best: 1.1030), Xent 0.0324, Loss 1.1199, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3074 | Time 30.5797(30.2847) | Bit/dim 1.1098(1.1092) | Xent 0.0520(0.0521) | Loss 1.1358(1.1352) | Error 0.0170(0.0159) Steps 416(414.40) | Grad Norm 0.1993(0.2181) | Total Time 10.00(10.00)\n",
      "Iter 3075 | Time 30.7213(30.2978) | Bit/dim 1.1047(1.1090) | Xent 0.0588(0.0523) | Loss 1.1341(1.1352) | Error 0.0162(0.0159) Steps 410(414.27) | Grad Norm 0.1763(0.2169) | Total Time 10.00(10.00)\n",
      "Iter 3076 | Time 30.2040(30.2950) | Bit/dim 1.1111(1.1091) | Xent 0.0539(0.0523) | Loss 1.1381(1.1352) | Error 0.0174(0.0159) Steps 410(414.14) | Grad Norm 0.2849(0.2189) | Total Time 10.00(10.00)\n",
      "Iter 3077 | Time 30.2109(30.2925) | Bit/dim 1.1115(1.1092) | Xent 0.0515(0.0523) | Loss 1.1373(1.1353) | Error 0.0162(0.0159) Steps 416(414.20) | Grad Norm 0.1910(0.2181) | Total Time 10.00(10.00)\n",
      "Iter 3078 | Time 30.3056(30.2929) | Bit/dim 1.1051(1.1090) | Xent 0.0521(0.0523) | Loss 1.1311(1.1352) | Error 0.0169(0.0160) Steps 422(414.43) | Grad Norm 0.2514(0.2191) | Total Time 10.00(10.00)\n",
      "Iter 3079 | Time 29.9508(30.2826) | Bit/dim 1.1084(1.1090) | Xent 0.0495(0.0522) | Loss 1.1331(1.1351) | Error 0.0161(0.0160) Steps 410(414.30) | Grad Norm 0.1911(0.2182) | Total Time 10.00(10.00)\n",
      "Iter 3080 | Time 30.6384(30.2933) | Bit/dim 1.1119(1.1091) | Xent 0.0474(0.0520) | Loss 1.1356(1.1351) | Error 0.0148(0.0159) Steps 416(414.35) | Grad Norm 0.2210(0.2183) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0440 | Time 15.9623, Epoch Time 240.8384(239.2415), Bit/dim 1.1035(best: 1.1030), Xent 0.0327, Loss 1.1198, Error 0.0093(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3081 | Time 30.7100(30.3058) | Bit/dim 1.1065(1.1090) | Xent 0.0476(0.0519) | Loss 1.1303(1.1350) | Error 0.0145(0.0159) Steps 416(414.40) | Grad Norm 0.1621(0.2166) | Total Time 10.00(10.00)\n",
      "Iter 3082 | Time 29.9729(30.2958) | Bit/dim 1.1087(1.1090) | Xent 0.0458(0.0517) | Loss 1.1316(1.1349) | Error 0.0140(0.0158) Steps 410(414.27) | Grad Norm 0.2170(0.2166) | Total Time 10.00(10.00)\n",
      "Iter 3083 | Time 30.3166(30.2964) | Bit/dim 1.1055(1.1089) | Xent 0.0496(0.0517) | Loss 1.1303(1.1348) | Error 0.0139(0.0158) Steps 416(414.32) | Grad Norm 0.1991(0.2161) | Total Time 10.00(10.00)\n",
      "Iter 3084 | Time 29.7970(30.2814) | Bit/dim 1.1070(1.1089) | Xent 0.0590(0.0519) | Loss 1.1365(1.1348) | Error 0.0162(0.0158) Steps 416(414.37) | Grad Norm 0.2623(0.2175) | Total Time 10.00(10.00)\n",
      "Iter 3085 | Time 29.6263(30.2618) | Bit/dim 1.1093(1.1089) | Xent 0.0543(0.0520) | Loss 1.1365(1.1349) | Error 0.0168(0.0158) Steps 416(414.42) | Grad Norm 0.2939(0.2198) | Total Time 10.00(10.00)\n",
      "Iter 3086 | Time 30.3618(30.2648) | Bit/dim 1.1121(1.1090) | Xent 0.0565(0.0521) | Loss 1.1403(1.1350) | Error 0.0172(0.0159) Steps 410(414.29) | Grad Norm 0.1960(0.2191) | Total Time 10.00(10.00)\n",
      "Iter 3087 | Time 29.8796(30.2532) | Bit/dim 1.1139(1.1091) | Xent 0.0515(0.0521) | Loss 1.1396(1.1352) | Error 0.0155(0.0159) Steps 422(414.52) | Grad Norm 0.1856(0.2181) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0441 | Time 16.1886, Epoch Time 238.9048(239.2314), Bit/dim 1.1037(best: 1.1030), Xent 0.0318, Loss 1.1196, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3088 | Time 30.1295(30.2495) | Bit/dim 1.1118(1.1092) | Xent 0.0492(0.0520) | Loss 1.1364(1.1352) | Error 0.0144(0.0158) Steps 416(414.56) | Grad Norm 0.2252(0.2183) | Total Time 10.00(10.00)\n",
      "Iter 3089 | Time 30.1327(30.2460) | Bit/dim 1.1058(1.1091) | Xent 0.0497(0.0519) | Loss 1.1307(1.1351) | Error 0.0156(0.0158) Steps 410(414.43) | Grad Norm 0.2820(0.2202) | Total Time 10.00(10.00)\n",
      "Iter 3090 | Time 30.4968(30.2535) | Bit/dim 1.1081(1.1091) | Xent 0.0568(0.0521) | Loss 1.1365(1.1351) | Error 0.0175(0.0159) Steps 410(414.29) | Grad Norm 0.1818(0.2190) | Total Time 10.00(10.00)\n",
      "Iter 3091 | Time 30.8905(30.2727) | Bit/dim 1.1100(1.1091) | Xent 0.0531(0.0521) | Loss 1.1366(1.1351) | Error 0.0146(0.0158) Steps 416(414.34) | Grad Norm 0.3156(0.2219) | Total Time 10.00(10.00)\n",
      "Iter 3092 | Time 29.9058(30.2616) | Bit/dim 1.1119(1.1092) | Xent 0.0554(0.0522) | Loss 1.1396(1.1353) | Error 0.0159(0.0158) Steps 416(414.39) | Grad Norm 0.3041(0.2244) | Total Time 10.00(10.00)\n",
      "Iter 3093 | Time 30.1513(30.2583) | Bit/dim 1.1105(1.1092) | Xent 0.0488(0.0521) | Loss 1.1349(1.1353) | Error 0.0168(0.0159) Steps 416(414.44) | Grad Norm 0.2158(0.2241) | Total Time 10.00(10.00)\n",
      "Iter 3094 | Time 30.9338(30.2786) | Bit/dim 1.1050(1.1091) | Xent 0.0498(0.0520) | Loss 1.1299(1.1351) | Error 0.0149(0.0158) Steps 422(414.67) | Grad Norm 0.1632(0.2223) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0442 | Time 15.9928, Epoch Time 240.7530(239.2770), Bit/dim 1.1031(best: 1.1030), Xent 0.0326, Loss 1.1194, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3095 | Time 30.3767(30.2815) | Bit/dim 1.1117(1.1092) | Xent 0.0547(0.0521) | Loss 1.1390(1.1352) | Error 0.0162(0.0158) Steps 410(414.53) | Grad Norm 0.1393(0.2198) | Total Time 10.00(10.00)\n",
      "Iter 3096 | Time 29.8508(30.2686) | Bit/dim 1.1079(1.1091) | Xent 0.0489(0.0520) | Loss 1.1323(1.1351) | Error 0.0141(0.0158) Steps 410(414.39) | Grad Norm 0.3521(0.2238) | Total Time 10.00(10.00)\n",
      "Iter 3097 | Time 30.0334(30.2616) | Bit/dim 1.1126(1.1092) | Xent 0.0529(0.0520) | Loss 1.1390(1.1353) | Error 0.0176(0.0158) Steps 416(414.44) | Grad Norm 0.2364(0.2242) | Total Time 10.00(10.00)\n",
      "Iter 3098 | Time 29.9358(30.2518) | Bit/dim 1.1076(1.1092) | Xent 0.0596(0.0523) | Loss 1.1374(1.1353) | Error 0.0180(0.0159) Steps 416(414.49) | Grad Norm 0.1875(0.2231) | Total Time 10.00(10.00)\n",
      "Iter 3099 | Time 31.5192(30.2898) | Bit/dim 1.1079(1.1091) | Xent 0.0487(0.0522) | Loss 1.1322(1.1352) | Error 0.0142(0.0159) Steps 416(414.53) | Grad Norm 0.2684(0.2244) | Total Time 10.00(10.00)\n",
      "Iter 3100 | Time 30.5595(30.2979) | Bit/dim 1.1106(1.1092) | Xent 0.0561(0.0523) | Loss 1.1386(1.1353) | Error 0.0161(0.0159) Steps 422(414.76) | Grad Norm 0.2395(0.2249) | Total Time 10.00(10.00)\n",
      "Iter 3101 | Time 29.2407(30.2662) | Bit/dim 1.1047(1.1091) | Xent 0.0479(0.0521) | Loss 1.1287(1.1351) | Error 0.0166(0.0159) Steps 416(414.80) | Grad Norm 0.2039(0.2243) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0443 | Time 16.2147, Epoch Time 239.9776(239.2980), Bit/dim 1.1033(best: 1.1030), Xent 0.0321, Loss 1.1193, Error 0.0098(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3102 | Time 30.0224(30.2589) | Bit/dim 1.1108(1.1091) | Xent 0.0572(0.0523) | Loss 1.1394(1.1353) | Error 0.0171(0.0159) Steps 410(414.65) | Grad Norm 0.2508(0.2250) | Total Time 10.00(10.00)\n",
      "Iter 3103 | Time 32.4714(30.3252) | Bit/dim 1.1084(1.1091) | Xent 0.0514(0.0523) | Loss 1.1341(1.1352) | Error 0.0168(0.0159) Steps 422(414.87) | Grad Norm 0.1601(0.2231) | Total Time 10.00(10.00)\n",
      "Iter 3104 | Time 29.5740(30.3027) | Bit/dim 1.1068(1.1090) | Xent 0.0513(0.0522) | Loss 1.1324(1.1351) | Error 0.0156(0.0159) Steps 422(415.09) | Grad Norm 0.3911(0.2281) | Total Time 10.00(10.00)\n",
      "Iter 3105 | Time 29.7771(30.2869) | Bit/dim 1.1058(1.1089) | Xent 0.0522(0.0522) | Loss 1.1319(1.1350) | Error 0.0151(0.0159) Steps 410(414.93) | Grad Norm 0.4036(0.2334) | Total Time 10.00(10.00)\n",
      "Iter 3106 | Time 31.4206(30.3210) | Bit/dim 1.1076(1.1089) | Xent 0.0480(0.0521) | Loss 1.1316(1.1349) | Error 0.0159(0.0159) Steps 416(414.96) | Grad Norm 0.2870(0.2350) | Total Time 10.00(10.00)\n",
      "Iter 3107 | Time 30.4100(30.3236) | Bit/dim 1.1099(1.1089) | Xent 0.0519(0.0521) | Loss 1.1358(1.1350) | Error 0.0155(0.0159) Steps 416(415.00) | Grad Norm 0.2150(0.2344) | Total Time 10.00(10.00)\n",
      "Iter 3108 | Time 30.3343(30.3239) | Bit/dim 1.1113(1.1090) | Xent 0.0510(0.0521) | Loss 1.1368(1.1350) | Error 0.0156(0.0159) Steps 410(414.85) | Grad Norm 0.3542(0.2380) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0444 | Time 16.1427, Epoch Time 242.4945(239.3939), Bit/dim 1.1028(best: 1.1030), Xent 0.0332, Loss 1.1194, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3109 | Time 30.9100(30.3415) | Bit/dim 1.1076(1.1089) | Xent 0.0571(0.0522) | Loss 1.1362(1.1351) | Error 0.0172(0.0159) Steps 416(414.88) | Grad Norm 0.4615(0.2447) | Total Time 10.00(10.00)\n",
      "Iter 3110 | Time 31.5388(30.3774) | Bit/dim 1.1121(1.1090) | Xent 0.0469(0.0521) | Loss 1.1356(1.1351) | Error 0.0156(0.0159) Steps 416(414.91) | Grad Norm 0.2866(0.2460) | Total Time 10.00(10.00)\n",
      "Iter 3111 | Time 30.0813(30.3686) | Bit/dim 1.1131(1.1092) | Xent 0.0559(0.0522) | Loss 1.1411(1.1352) | Error 0.0164(0.0159) Steps 410(414.77) | Grad Norm 0.1661(0.2436) | Total Time 10.00(10.00)\n",
      "Iter 3112 | Time 30.2204(30.3641) | Bit/dim 1.1112(1.1092) | Xent 0.0509(0.0521) | Loss 1.1366(1.1353) | Error 0.0161(0.0159) Steps 410(414.62) | Grad Norm 0.4899(0.2510) | Total Time 10.00(10.00)\n",
      "Iter 3113 | Time 29.9554(30.3519) | Bit/dim 1.1086(1.1092) | Xent 0.0580(0.0523) | Loss 1.1376(1.1354) | Error 0.0174(0.0160) Steps 416(414.67) | Grad Norm 0.3898(0.2551) | Total Time 10.00(10.00)\n",
      "Iter 3114 | Time 30.3657(30.3523) | Bit/dim 1.1053(1.1091) | Xent 0.0479(0.0522) | Loss 1.1293(1.1352) | Error 0.0141(0.0159) Steps 416(414.71) | Grad Norm 0.2030(0.2536) | Total Time 10.00(10.00)\n",
      "Iter 3115 | Time 30.9740(30.3709) | Bit/dim 1.1077(1.1090) | Xent 0.0532(0.0522) | Loss 1.1343(1.1351) | Error 0.0160(0.0159) Steps 410(414.56) | Grad Norm 0.1702(0.2511) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0445 | Time 16.4148, Epoch Time 242.4814(239.4866), Bit/dim 1.1033(best: 1.1028), Xent 0.0325, Loss 1.1195, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3116 | Time 29.7444(30.3521) | Bit/dim 1.1099(1.1091) | Xent 0.0484(0.0521) | Loss 1.1341(1.1351) | Error 0.0162(0.0159) Steps 416(414.61) | Grad Norm 0.2321(0.2505) | Total Time 10.00(10.00)\n",
      "Iter 3117 | Time 30.3597(30.3524) | Bit/dim 1.1048(1.1089) | Xent 0.0492(0.0520) | Loss 1.1295(1.1349) | Error 0.0149(0.0159) Steps 422(414.83) | Grad Norm 0.2116(0.2493) | Total Time 10.00(10.00)\n",
      "Iter 3118 | Time 30.3132(30.3512) | Bit/dim 1.1126(1.1090) | Xent 0.0543(0.0521) | Loss 1.1398(1.1351) | Error 0.0166(0.0159) Steps 422(415.04) | Grad Norm 0.2787(0.2502) | Total Time 10.00(10.00)\n",
      "Iter 3119 | Time 30.7683(30.3637) | Bit/dim 1.1093(1.1091) | Xent 0.0532(0.0521) | Loss 1.1359(1.1351) | Error 0.0159(0.0159) Steps 422(415.25) | Grad Norm 0.2286(0.2496) | Total Time 10.00(10.00)\n",
      "Iter 3120 | Time 30.3209(30.3624) | Bit/dim 1.1073(1.1090) | Xent 0.0575(0.0523) | Loss 1.1360(1.1351) | Error 0.0165(0.0159) Steps 422(415.46) | Grad Norm 0.1547(0.2467) | Total Time 10.00(10.00)\n",
      "Iter 3121 | Time 29.4248(30.3343) | Bit/dim 1.1099(1.1090) | Xent 0.0502(0.0522) | Loss 1.1351(1.1351) | Error 0.0150(0.0159) Steps 416(415.47) | Grad Norm 0.2124(0.2457) | Total Time 10.00(10.00)\n",
      "Iter 3122 | Time 30.3618(30.3351) | Bit/dim 1.1070(1.1090) | Xent 0.0474(0.0521) | Loss 1.1307(1.1350) | Error 0.0154(0.0159) Steps 410(415.31) | Grad Norm 0.1950(0.2442) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0446 | Time 16.2781, Epoch Time 239.5878(239.4896), Bit/dim 1.1030(best: 1.1028), Xent 0.0314, Loss 1.1187, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3123 | Time 30.2486(30.3325) | Bit/dim 1.1109(1.1090) | Xent 0.0488(0.0520) | Loss 1.1354(1.1350) | Error 0.0158(0.0159) Steps 416(415.33) | Grad Norm 0.2243(0.2436) | Total Time 10.00(10.00)\n",
      "Iter 3124 | Time 29.9469(30.3209) | Bit/dim 1.1120(1.1091) | Xent 0.0530(0.0520) | Loss 1.1385(1.1351) | Error 0.0149(0.0159) Steps 416(415.35) | Grad Norm 0.2429(0.2435) | Total Time 10.00(10.00)\n",
      "Iter 3125 | Time 29.7331(30.3033) | Bit/dim 1.1088(1.1091) | Xent 0.0454(0.0518) | Loss 1.1316(1.1350) | Error 0.0136(0.0158) Steps 410(415.19) | Grad Norm 0.1868(0.2418) | Total Time 10.00(10.00)\n",
      "Iter 3126 | Time 30.4076(30.3064) | Bit/dim 1.1096(1.1091) | Xent 0.0552(0.0519) | Loss 1.1372(1.1351) | Error 0.0169(0.0158) Steps 422(415.39) | Grad Norm 0.2639(0.2425) | Total Time 10.00(10.00)\n",
      "Iter 3127 | Time 30.0665(30.2992) | Bit/dim 1.1108(1.1092) | Xent 0.0555(0.0520) | Loss 1.1386(1.1352) | Error 0.0179(0.0159) Steps 416(415.41) | Grad Norm 0.3716(0.2464) | Total Time 10.00(10.00)\n",
      "Iter 3128 | Time 30.3737(30.3015) | Bit/dim 1.1021(1.1090) | Xent 0.0479(0.0519) | Loss 1.1261(1.1349) | Error 0.0150(0.0159) Steps 416(415.43) | Grad Norm 0.2528(0.2466) | Total Time 10.00(10.00)\n",
      "Iter 3129 | Time 30.6409(30.3117) | Bit/dim 1.1068(1.1089) | Xent 0.0448(0.0517) | Loss 1.1292(1.1347) | Error 0.0135(0.0158) Steps 410(415.27) | Grad Norm 0.2369(0.2463) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0447 | Time 15.9860, Epoch Time 239.5864(239.4925), Bit/dim 1.1031(best: 1.1028), Xent 0.0317, Loss 1.1190, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3130 | Time 30.3135(30.3117) | Bit/dim 1.1089(1.1089) | Xent 0.0494(0.0516) | Loss 1.1336(1.1347) | Error 0.0155(0.0158) Steps 410(415.11) | Grad Norm 0.2147(0.2453) | Total Time 10.00(10.00)\n",
      "Iter 3131 | Time 30.0052(30.3025) | Bit/dim 1.1091(1.1089) | Xent 0.0533(0.0517) | Loss 1.1358(1.1347) | Error 0.0159(0.0158) Steps 410(414.95) | Grad Norm 0.3995(0.2500) | Total Time 10.00(10.00)\n",
      "Iter 3132 | Time 30.3028(30.3025) | Bit/dim 1.1143(1.1091) | Xent 0.0502(0.0516) | Loss 1.1394(1.1349) | Error 0.0174(0.0158) Steps 422(415.17) | Grad Norm 0.1892(0.2481) | Total Time 10.00(10.00)\n",
      "Iter 3133 | Time 30.1199(30.2970) | Bit/dim 1.1027(1.1089) | Xent 0.0522(0.0516) | Loss 1.1287(1.1347) | Error 0.0160(0.0158) Steps 416(415.19) | Grad Norm 0.1914(0.2464) | Total Time 10.00(10.00)\n",
      "Iter 3134 | Time 29.6065(30.2763) | Bit/dim 1.1133(1.1090) | Xent 0.0558(0.0518) | Loss 1.1412(1.1349) | Error 0.0188(0.0159) Steps 416(415.21) | Grad Norm 0.2601(0.2468) | Total Time 10.00(10.00)\n",
      "Iter 3135 | Time 30.6861(30.2886) | Bit/dim 1.1065(1.1089) | Xent 0.0487(0.0517) | Loss 1.1309(1.1348) | Error 0.0159(0.0159) Steps 410(415.06) | Grad Norm 0.2642(0.2474) | Total Time 10.00(10.00)\n",
      "Iter 3136 | Time 30.3261(30.2897) | Bit/dim 1.1071(1.1089) | Xent 0.0480(0.0516) | Loss 1.1311(1.1347) | Error 0.0156(0.0159) Steps 416(415.09) | Grad Norm 0.2360(0.2470) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0448 | Time 16.3272, Epoch Time 239.7248(239.4995), Bit/dim 1.1027(best: 1.1028), Xent 0.0335, Loss 1.1195, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3137 | Time 29.9583(30.2798) | Bit/dim 1.1092(1.1089) | Xent 0.0552(0.0517) | Loss 1.1368(1.1347) | Error 0.0164(0.0159) Steps 410(414.93) | Grad Norm 0.2135(0.2460) | Total Time 10.00(10.00)\n",
      "Iter 3138 | Time 29.9844(30.2709) | Bit/dim 1.1095(1.1089) | Xent 0.0536(0.0517) | Loss 1.1363(1.1348) | Error 0.0161(0.0159) Steps 416(414.97) | Grad Norm 0.1709(0.2438) | Total Time 10.00(10.00)\n",
      "Iter 3139 | Time 30.6284(30.2817) | Bit/dim 1.1108(1.1090) | Xent 0.0483(0.0516) | Loss 1.1349(1.1348) | Error 0.0149(0.0159) Steps 416(415.00) | Grad Norm 0.2840(0.2450) | Total Time 10.00(10.00)\n",
      "Iter 3140 | Time 31.2432(30.3105) | Bit/dim 1.1098(1.1090) | Xent 0.0554(0.0517) | Loss 1.1374(1.1349) | Error 0.0159(0.0159) Steps 410(414.85) | Grad Norm 0.1843(0.2431) | Total Time 10.00(10.00)\n",
      "Iter 3141 | Time 30.1344(30.3052) | Bit/dim 1.1089(1.1090) | Xent 0.0535(0.0518) | Loss 1.1357(1.1349) | Error 0.0170(0.0159) Steps 416(414.88) | Grad Norm 0.2463(0.2432) | Total Time 10.00(10.00)\n",
      "Iter 3142 | Time 29.8258(30.2908) | Bit/dim 1.1072(1.1089) | Xent 0.0498(0.0517) | Loss 1.1321(1.1348) | Error 0.0156(0.0159) Steps 416(414.92) | Grad Norm 0.2359(0.2430) | Total Time 10.00(10.00)\n",
      "Iter 3143 | Time 30.1823(30.2876) | Bit/dim 1.1082(1.1089) | Xent 0.0480(0.0516) | Loss 1.1322(1.1347) | Error 0.0156(0.0159) Steps 416(414.95) | Grad Norm 0.3811(0.2472) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0449 | Time 16.5728, Epoch Time 240.8133(239.5389), Bit/dim 1.1031(best: 1.1027), Xent 0.0312, Loss 1.1187, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3144 | Time 30.3631(30.2899) | Bit/dim 1.1049(1.1088) | Xent 0.0497(0.0516) | Loss 1.1297(1.1346) | Error 0.0142(0.0159) Steps 410(414.80) | Grad Norm 0.2497(0.2472) | Total Time 10.00(10.00)\n",
      "Iter 3145 | Time 30.3970(30.2931) | Bit/dim 1.1081(1.1088) | Xent 0.0488(0.0515) | Loss 1.1325(1.1345) | Error 0.0135(0.0158) Steps 416(414.84) | Grad Norm 0.1533(0.2444) | Total Time 10.00(10.00)\n",
      "Iter 3146 | Time 30.6311(30.3032) | Bit/dim 1.1068(1.1087) | Xent 0.0515(0.0515) | Loss 1.1326(1.1344) | Error 0.0168(0.0158) Steps 410(414.69) | Grad Norm 0.2064(0.2433) | Total Time 10.00(10.00)\n",
      "Iter 3147 | Time 30.7306(30.3160) | Bit/dim 1.1123(1.1088) | Xent 0.0471(0.0513) | Loss 1.1359(1.1345) | Error 0.0148(0.0158) Steps 410(414.55) | Grad Norm 0.1556(0.2407) | Total Time 10.00(10.00)\n",
      "Iter 3148 | Time 30.8778(30.3329) | Bit/dim 1.1067(1.1088) | Xent 0.0523(0.0514) | Loss 1.1329(1.1344) | Error 0.0176(0.0158) Steps 422(414.77) | Grad Norm 0.1819(0.2389) | Total Time 10.00(10.00)\n",
      "Iter 3149 | Time 30.3527(30.3335) | Bit/dim 1.1110(1.1088) | Xent 0.0488(0.0513) | Loss 1.1354(1.1345) | Error 0.0139(0.0158) Steps 416(414.81) | Grad Norm 0.1719(0.2369) | Total Time 10.00(10.00)\n",
      "Iter 3150 | Time 30.1499(30.3280) | Bit/dim 1.1066(1.1088) | Xent 0.0494(0.0512) | Loss 1.1313(1.1344) | Error 0.0139(0.0157) Steps 410(414.67) | Grad Norm 0.2026(0.2359) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0450 | Time 16.3080, Epoch Time 242.0869(239.6153), Bit/dim 1.1030(best: 1.1027), Xent 0.0321, Loss 1.1190, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3151 | Time 30.2804(30.3265) | Bit/dim 1.1068(1.1087) | Xent 0.0577(0.0514) | Loss 1.1357(1.1344) | Error 0.0185(0.0158) Steps 410(414.53) | Grad Norm 0.2647(0.2367) | Total Time 10.00(10.00)\n",
      "Iter 3152 | Time 29.8404(30.3120) | Bit/dim 1.1132(1.1088) | Xent 0.0519(0.0514) | Loss 1.1392(1.1346) | Error 0.0155(0.0158) Steps 410(414.39) | Grad Norm 0.3346(0.2397) | Total Time 10.00(10.00)\n",
      "Iter 3153 | Time 31.0447(30.3339) | Bit/dim 1.1107(1.1089) | Xent 0.0549(0.0516) | Loss 1.1382(1.1347) | Error 0.0149(0.0158) Steps 410(414.26) | Grad Norm 0.3034(0.2416) | Total Time 10.00(10.00)\n",
      "Iter 3154 | Time 30.0281(30.3248) | Bit/dim 1.1057(1.1088) | Xent 0.0470(0.0514) | Loss 1.1292(1.1345) | Error 0.0141(0.0157) Steps 422(414.49) | Grad Norm 0.1747(0.2396) | Total Time 10.00(10.00)\n",
      "Iter 3155 | Time 32.0289(30.3759) | Bit/dim 1.1091(1.1088) | Xent 0.0567(0.0516) | Loss 1.1374(1.1346) | Error 0.0171(0.0158) Steps 410(414.36) | Grad Norm 0.2300(0.2393) | Total Time 10.00(10.00)\n",
      "Iter 3156 | Time 31.6904(30.4153) | Bit/dim 1.1082(1.1088) | Xent 0.0538(0.0516) | Loss 1.1351(1.1346) | Error 0.0169(0.0158) Steps 416(414.41) | Grad Norm 0.2954(0.2410) | Total Time 10.00(10.00)\n",
      "Iter 3157 | Time 30.3323(30.4128) | Bit/dim 1.1041(1.1086) | Xent 0.0552(0.0517) | Loss 1.1317(1.1345) | Error 0.0152(0.0158) Steps 422(414.63) | Grad Norm 0.1766(0.2390) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0451 | Time 16.4812, Epoch Time 244.3691(239.7579), Bit/dim 1.1028(best: 1.1027), Xent 0.0319, Loss 1.1188, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3158 | Time 30.0097(30.4007) | Bit/dim 1.1064(1.1086) | Xent 0.0575(0.0519) | Loss 1.1352(1.1345) | Error 0.0166(0.0158) Steps 416(414.67) | Grad Norm 0.2379(0.2390) | Total Time 10.00(10.00)\n",
      "Iter 3159 | Time 30.7029(30.4098) | Bit/dim 1.1017(1.1084) | Xent 0.0552(0.0520) | Loss 1.1293(1.1344) | Error 0.0166(0.0158) Steps 410(414.53) | Grad Norm 0.3728(0.2430) | Total Time 10.00(10.00)\n",
      "Iter 3160 | Time 29.5984(30.3855) | Bit/dim 1.1121(1.1085) | Xent 0.0541(0.0521) | Loss 1.1392(1.1345) | Error 0.0168(0.0159) Steps 410(414.40) | Grad Norm 0.1604(0.2405) | Total Time 10.00(10.00)\n",
      "Iter 3161 | Time 29.6798(30.3643) | Bit/dim 1.1150(1.1087) | Xent 0.0567(0.0522) | Loss 1.1434(1.1348) | Error 0.0159(0.0159) Steps 416(414.45) | Grad Norm 0.2103(0.2396) | Total Time 10.00(10.00)\n",
      "Iter 3162 | Time 30.7248(30.3751) | Bit/dim 1.1031(1.1085) | Xent 0.0517(0.0522) | Loss 1.1290(1.1346) | Error 0.0151(0.0158) Steps 422(414.67) | Grad Norm 0.1702(0.2375) | Total Time 10.00(10.00)\n",
      "Iter 3163 | Time 30.0419(30.3651) | Bit/dim 1.1099(1.1086) | Xent 0.0436(0.0519) | Loss 1.1317(1.1345) | Error 0.0150(0.0158) Steps 416(414.71) | Grad Norm 0.2340(0.2374) | Total Time 10.00(10.00)\n",
      "Iter 3164 | Time 30.0814(30.3566) | Bit/dim 1.1103(1.1086) | Xent 0.0519(0.0519) | Loss 1.1362(1.1346) | Error 0.0181(0.0159) Steps 410(414.57) | Grad Norm 0.1741(0.2355) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0452 | Time 16.4337, Epoch Time 239.6836(239.7557), Bit/dim 1.1030(best: 1.1027), Xent 0.0311, Loss 1.1186, Error 0.0090(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3165 | Time 30.4542(30.3595) | Bit/dim 1.1057(1.1085) | Xent 0.0499(0.0519) | Loss 1.1306(1.1345) | Error 0.0141(0.0158) Steps 422(414.79) | Grad Norm 0.1729(0.2337) | Total Time 10.00(10.00)\n",
      "Iter 3166 | Time 30.2947(30.3576) | Bit/dim 1.1110(1.1086) | Xent 0.0529(0.0519) | Loss 1.1374(1.1345) | Error 0.0165(0.0159) Steps 416(414.83) | Grad Norm 0.1727(0.2318) | Total Time 10.00(10.00)\n",
      "Iter 3167 | Time 30.3109(30.3562) | Bit/dim 1.1074(1.1086) | Xent 0.0455(0.0517) | Loss 1.1301(1.1344) | Error 0.0152(0.0158) Steps 422(415.05) | Grad Norm 0.2161(0.2314) | Total Time 10.00(10.00)\n",
      "Iter 3168 | Time 29.5658(30.3325) | Bit/dim 1.1039(1.1084) | Xent 0.0509(0.0517) | Loss 1.1293(1.1343) | Error 0.0150(0.0158) Steps 416(415.07) | Grad Norm 0.1524(0.2290) | Total Time 10.00(10.00)\n",
      "Iter 3169 | Time 29.9437(30.3208) | Bit/dim 1.1092(1.1084) | Xent 0.0536(0.0518) | Loss 1.1360(1.1343) | Error 0.0170(0.0158) Steps 410(414.92) | Grad Norm 0.1443(0.2265) | Total Time 10.00(10.00)\n",
      "Iter 3170 | Time 30.4806(30.3256) | Bit/dim 1.1109(1.1085) | Xent 0.0545(0.0518) | Loss 1.1381(1.1344) | Error 0.0152(0.0158) Steps 416(414.95) | Grad Norm 0.3133(0.2291) | Total Time 10.00(10.00)\n",
      "Iter 3171 | Time 30.0161(30.3163) | Bit/dim 1.1103(1.1086) | Xent 0.0459(0.0517) | Loss 1.1332(1.1344) | Error 0.0141(0.0158) Steps 416(414.99) | Grad Norm 0.1743(0.2274) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0453 | Time 16.1701, Epoch Time 239.6026(239.7511), Bit/dim 1.1027(best: 1.1027), Xent 0.0321, Loss 1.1188, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3172 | Time 29.9305(30.3047) | Bit/dim 1.1132(1.1087) | Xent 0.0551(0.0518) | Loss 1.1408(1.1346) | Error 0.0148(0.0157) Steps 416(415.02) | Grad Norm 0.3959(0.2325) | Total Time 10.00(10.00)\n",
      "Iter 3173 | Time 30.1258(30.2994) | Bit/dim 1.1056(1.1086) | Xent 0.0588(0.0520) | Loss 1.1350(1.1346) | Error 0.0172(0.0158) Steps 410(414.87) | Grad Norm 0.3371(0.2356) | Total Time 10.00(10.00)\n",
      "Iter 3174 | Time 30.3299(30.3003) | Bit/dim 1.1036(1.1085) | Xent 0.0543(0.0520) | Loss 1.1308(1.1345) | Error 0.0165(0.0158) Steps 410(414.72) | Grad Norm 0.1709(0.2337) | Total Time 10.00(10.00)\n",
      "Iter 3175 | Time 29.9773(30.2906) | Bit/dim 1.1029(1.1083) | Xent 0.0468(0.0519) | Loss 1.1263(1.1342) | Error 0.0138(0.0158) Steps 416(414.76) | Grad Norm 0.4265(0.2395) | Total Time 10.00(10.00)\n",
      "Iter 3176 | Time 30.3672(30.2929) | Bit/dim 1.1098(1.1083) | Xent 0.0478(0.0518) | Loss 1.1337(1.1342) | Error 0.0159(0.0158) Steps 416(414.79) | Grad Norm 0.3185(0.2418) | Total Time 10.00(10.00)\n",
      "Iter 3177 | Time 31.0591(30.3159) | Bit/dim 1.1128(1.1085) | Xent 0.0531(0.0518) | Loss 1.1394(1.1344) | Error 0.0159(0.0158) Steps 416(414.83) | Grad Norm 0.1863(0.2402) | Total Time 10.00(10.00)\n",
      "Iter 3178 | Time 30.2032(30.3125) | Bit/dim 1.1078(1.1085) | Xent 0.0481(0.0517) | Loss 1.1318(1.1343) | Error 0.0139(0.0157) Steps 416(414.87) | Grad Norm 0.1302(0.2369) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0454 | Time 16.2962, Epoch Time 240.4145(239.7710), Bit/dim 1.1028(best: 1.1027), Xent 0.0304, Loss 1.1180, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3179 | Time 30.2555(30.3108) | Bit/dim 1.1053(1.1084) | Xent 0.0466(0.0515) | Loss 1.1286(1.1341) | Error 0.0155(0.0157) Steps 416(414.90) | Grad Norm 0.2334(0.2368) | Total Time 10.00(10.00)\n",
      "Iter 3180 | Time 30.1068(30.3047) | Bit/dim 1.1057(1.1083) | Xent 0.0577(0.0517) | Loss 1.1346(1.1341) | Error 0.0144(0.0157) Steps 416(414.93) | Grad Norm 0.2623(0.2375) | Total Time 10.00(10.00)\n",
      "Iter 3181 | Time 30.2480(30.3030) | Bit/dim 1.1109(1.1084) | Xent 0.0511(0.0517) | Loss 1.1364(1.1342) | Error 0.0156(0.0157) Steps 422(415.15) | Grad Norm 0.2146(0.2368) | Total Time 10.00(10.00)\n",
      "Iter 3182 | Time 30.2021(30.2999) | Bit/dim 1.1053(1.1083) | Xent 0.0448(0.0515) | Loss 1.1277(1.1340) | Error 0.0132(0.0156) Steps 416(415.17) | Grad Norm 0.2278(0.2366) | Total Time 10.00(10.00)\n",
      "Iter 3183 | Time 30.1140(30.2944) | Bit/dim 1.1088(1.1083) | Xent 0.0556(0.0516) | Loss 1.1366(1.1341) | Error 0.0178(0.0156) Steps 416(415.20) | Grad Norm 0.4158(0.2419) | Total Time 10.00(10.00)\n",
      "Iter 3184 | Time 30.2367(30.2926) | Bit/dim 1.1098(1.1083) | Xent 0.0464(0.0515) | Loss 1.1330(1.1341) | Error 0.0156(0.0156) Steps 410(415.04) | Grad Norm 0.2340(0.2417) | Total Time 10.00(10.00)\n",
      "Iter 3185 | Time 30.0997(30.2869) | Bit/dim 1.1107(1.1084) | Xent 0.0513(0.0515) | Loss 1.1364(1.1341) | Error 0.0152(0.0156) Steps 410(414.89) | Grad Norm 0.2766(0.2427) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0455 | Time 16.2470, Epoch Time 239.6730(239.7681), Bit/dim 1.1022(best: 1.1027), Xent 0.0308, Loss 1.1176, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3186 | Time 30.2947(30.2871) | Bit/dim 1.1045(1.1083) | Xent 0.0497(0.0514) | Loss 1.1294(1.1340) | Error 0.0140(0.0156) Steps 422(415.10) | Grad Norm 0.2621(0.2433) | Total Time 10.00(10.00)\n",
      "Iter 3187 | Time 30.4141(30.2909) | Bit/dim 1.1109(1.1084) | Xent 0.0543(0.0515) | Loss 1.1380(1.1341) | Error 0.0148(0.0156) Steps 422(415.31) | Grad Norm 0.2606(0.2438) | Total Time 10.00(10.00)\n",
      "Iter 3188 | Time 30.5102(30.2975) | Bit/dim 1.1062(1.1083) | Xent 0.0577(0.0517) | Loss 1.1350(1.1341) | Error 0.0185(0.0156) Steps 416(415.33) | Grad Norm 0.1505(0.2410) | Total Time 10.00(10.00)\n",
      "Iter 3189 | Time 29.6367(30.2776) | Bit/dim 1.1105(1.1084) | Xent 0.0586(0.0519) | Loss 1.1397(1.1343) | Error 0.0170(0.0157) Steps 422(415.53) | Grad Norm 0.3176(0.2433) | Total Time 10.00(10.00)\n",
      "Iter 3190 | Time 30.9068(30.2965) | Bit/dim 1.1102(1.1084) | Xent 0.0471(0.0517) | Loss 1.1338(1.1343) | Error 0.0156(0.0157) Steps 422(415.72) | Grad Norm 0.1487(0.2405) | Total Time 10.00(10.00)\n",
      "Iter 3191 | Time 29.8119(30.2820) | Bit/dim 1.1044(1.1083) | Xent 0.0460(0.0516) | Loss 1.1274(1.1341) | Error 0.0134(0.0156) Steps 410(415.55) | Grad Norm 0.3075(0.2425) | Total Time 10.00(10.00)\n",
      "Iter 3192 | Time 30.0747(30.2758) | Bit/dim 1.1119(1.1084) | Xent 0.0486(0.0515) | Loss 1.1362(1.1341) | Error 0.0155(0.0156) Steps 416(415.57) | Grad Norm 0.1705(0.2404) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0456 | Time 16.1203, Epoch Time 240.1086(239.7783), Bit/dim 1.1024(best: 1.1022), Xent 0.0315, Loss 1.1181, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3193 | Time 30.6232(30.2862) | Bit/dim 1.1062(1.1083) | Xent 0.0490(0.0514) | Loss 1.1307(1.1340) | Error 0.0145(0.0156) Steps 416(415.58) | Grad Norm 0.3895(0.2448) | Total Time 10.00(10.00)\n",
      "Iter 3194 | Time 30.0080(30.2778) | Bit/dim 1.1093(1.1084) | Xent 0.0590(0.0516) | Loss 1.1388(1.1342) | Error 0.0161(0.0156) Steps 416(415.59) | Grad Norm 0.3070(0.2467) | Total Time 10.00(10.00)\n",
      "Iter 3195 | Time 30.4336(30.2825) | Bit/dim 1.1113(1.1085) | Xent 0.0525(0.0517) | Loss 1.1376(1.1343) | Error 0.0158(0.0156) Steps 422(415.78) | Grad Norm 0.2225(0.2460) | Total Time 10.00(10.00)\n",
      "Iter 3196 | Time 30.0439(30.2754) | Bit/dim 1.1088(1.1085) | Xent 0.0464(0.0515) | Loss 1.1320(1.1342) | Error 0.0139(0.0156) Steps 416(415.79) | Grad Norm 0.3096(0.2479) | Total Time 10.00(10.00)\n",
      "Iter 3197 | Time 30.7883(30.2907) | Bit/dim 1.1100(1.1085) | Xent 0.0470(0.0514) | Loss 1.1335(1.1342) | Error 0.0150(0.0155) Steps 422(415.98) | Grad Norm 0.1833(0.2459) | Total Time 10.00(10.00)\n",
      "Iter 3198 | Time 31.0427(30.3133) | Bit/dim 1.1076(1.1085) | Xent 0.0535(0.0514) | Loss 1.1343(1.1342) | Error 0.0165(0.0156) Steps 416(415.98) | Grad Norm 0.2000(0.2446) | Total Time 10.00(10.00)\n",
      "Iter 3199 | Time 30.7071(30.3251) | Bit/dim 1.1078(1.1085) | Xent 0.0551(0.0515) | Loss 1.1353(1.1342) | Error 0.0172(0.0156) Steps 416(415.98) | Grad Norm 0.1327(0.2412) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0457 | Time 16.2137, Epoch Time 241.9718(239.8441), Bit/dim 1.1031(best: 1.1022), Xent 0.0325, Loss 1.1193, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3200 | Time 31.5000(30.3604) | Bit/dim 1.1036(1.1083) | Xent 0.0467(0.0514) | Loss 1.1269(1.1340) | Error 0.0134(0.0155) Steps 416(415.98) | Grad Norm 0.1711(0.2391) | Total Time 10.00(10.00)\n",
      "Iter 3201 | Time 30.1560(30.3542) | Bit/dim 1.1081(1.1083) | Xent 0.0541(0.0515) | Loss 1.1351(1.1340) | Error 0.0152(0.0155) Steps 416(415.98) | Grad Norm 0.2262(0.2387) | Total Time 10.00(10.00)\n",
      "Iter 3202 | Time 30.3415(30.3539) | Bit/dim 1.1055(1.1082) | Xent 0.0543(0.0516) | Loss 1.1327(1.1340) | Error 0.0175(0.0156) Steps 422(416.16) | Grad Norm 0.2768(0.2399) | Total Time 10.00(10.00)\n",
      "Iter 3203 | Time 30.4630(30.3571) | Bit/dim 1.1105(1.1083) | Xent 0.0533(0.0516) | Loss 1.1371(1.1341) | Error 0.0159(0.0156) Steps 422(416.33) | Grad Norm 0.3061(0.2418) | Total Time 10.00(10.00)\n",
      "Iter 3204 | Time 30.5418(30.3627) | Bit/dim 1.1102(1.1084) | Xent 0.0501(0.0516) | Loss 1.1353(1.1341) | Error 0.0160(0.0156) Steps 422(416.50) | Grad Norm 0.2629(0.2425) | Total Time 10.00(10.00)\n",
      "Iter 3205 | Time 30.2274(30.3586) | Bit/dim 1.1101(1.1084) | Xent 0.0549(0.0517) | Loss 1.1375(1.1342) | Error 0.0164(0.0156) Steps 416(416.49) | Grad Norm 0.2912(0.2439) | Total Time 10.00(10.00)\n",
      "Iter 3206 | Time 30.2205(30.3545) | Bit/dim 1.1112(1.1085) | Xent 0.0545(0.0518) | Loss 1.1384(1.1344) | Error 0.0162(0.0157) Steps 422(416.65) | Grad Norm 0.3268(0.2464) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0458 | Time 16.5059, Epoch Time 242.1939(239.9146), Bit/dim 1.1022(best: 1.1022), Xent 0.0316, Loss 1.1180, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3207 | Time 30.5609(30.3607) | Bit/dim 1.1074(1.1085) | Xent 0.0488(0.0517) | Loss 1.1318(1.1343) | Error 0.0151(0.0156) Steps 422(416.82) | Grad Norm 0.2733(0.2472) | Total Time 10.00(10.00)\n",
      "Iter 3208 | Time 30.7263(30.3716) | Bit/dim 1.1064(1.1084) | Xent 0.0536(0.0517) | Loss 1.1332(1.1343) | Error 0.0176(0.0157) Steps 422(416.97) | Grad Norm 0.4183(0.2524) | Total Time 10.00(10.00)\n",
      "Iter 3209 | Time 31.7779(30.4138) | Bit/dim 1.1096(1.1084) | Xent 0.0574(0.0519) | Loss 1.1383(1.1344) | Error 0.0170(0.0157) Steps 422(417.12) | Grad Norm 0.1521(0.2494) | Total Time 10.00(10.00)\n",
      "Iter 3210 | Time 30.2449(30.4088) | Bit/dim 1.1079(1.1084) | Xent 0.0536(0.0519) | Loss 1.1347(1.1344) | Error 0.0165(0.0158) Steps 416(417.09) | Grad Norm 0.2359(0.2490) | Total Time 10.00(10.00)\n",
      "Iter 3211 | Time 30.6711(30.4166) | Bit/dim 1.1075(1.1084) | Xent 0.0538(0.0520) | Loss 1.1344(1.1344) | Error 0.0169(0.0158) Steps 416(417.06) | Grad Norm 0.2419(0.2487) | Total Time 10.00(10.00)\n",
      "Iter 3212 | Time 31.2158(30.4406) | Bit/dim 1.1115(1.1085) | Xent 0.0545(0.0521) | Loss 1.1387(1.1345) | Error 0.0166(0.0158) Steps 416(417.02) | Grad Norm 0.3158(0.2508) | Total Time 10.00(10.00)\n",
      "Iter 3213 | Time 30.5126(30.4428) | Bit/dim 1.1064(1.1084) | Xent 0.0547(0.0522) | Loss 1.1337(1.1345) | Error 0.0170(0.0159) Steps 416(416.99) | Grad Norm 0.3564(0.2539) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0459 | Time 16.2401, Epoch Time 244.2035(240.0433), Bit/dim 1.1032(best: 1.1022), Xent 0.0328, Loss 1.1196, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3214 | Time 29.9101(30.4268) | Bit/dim 1.1091(1.1084) | Xent 0.0464(0.0520) | Loss 1.1323(1.1344) | Error 0.0161(0.0159) Steps 422(417.14) | Grad Norm 0.2073(0.2525) | Total Time 10.00(10.00)\n",
      "Iter 3215 | Time 30.2730(30.4222) | Bit/dim 1.0999(1.1082) | Xent 0.0503(0.0519) | Loss 1.1250(1.1341) | Error 0.0150(0.0158) Steps 422(417.29) | Grad Norm 0.3075(0.2542) | Total Time 10.00(10.00)\n",
      "Iter 3216 | Time 30.9464(30.4379) | Bit/dim 1.1115(1.1083) | Xent 0.0487(0.0518) | Loss 1.1359(1.1342) | Error 0.0156(0.0158) Steps 422(417.43) | Grad Norm 0.2712(0.2547) | Total Time 10.00(10.00)\n",
      "Iter 3217 | Time 30.6182(30.4433) | Bit/dim 1.1144(1.1085) | Xent 0.0514(0.0518) | Loss 1.1402(1.1344) | Error 0.0151(0.0158) Steps 422(417.57) | Grad Norm 0.2991(0.2560) | Total Time 10.00(10.00)\n",
      "Iter 3218 | Time 30.0687(30.4321) | Bit/dim 1.1073(1.1084) | Xent 0.0544(0.0519) | Loss 1.1345(1.1344) | Error 0.0174(0.0159) Steps 416(417.52) | Grad Norm 0.2362(0.2554) | Total Time 10.00(10.00)\n",
      "Iter 3219 | Time 30.1536(30.4237) | Bit/dim 1.1073(1.1084) | Xent 0.0562(0.0520) | Loss 1.1354(1.1344) | Error 0.0174(0.0159) Steps 422(417.65) | Grad Norm 0.3106(0.2571) | Total Time 10.00(10.00)\n",
      "Iter 3220 | Time 30.3785(30.4224) | Bit/dim 1.1117(1.1085) | Xent 0.0563(0.0522) | Loss 1.1399(1.1346) | Error 0.0156(0.0159) Steps 416(417.61) | Grad Norm 0.2412(0.2566) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0460 | Time 16.2128, Epoch Time 240.8739(240.0682), Bit/dim 1.1031(best: 1.1022), Xent 0.0314, Loss 1.1188, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3221 | Time 30.1537(30.4143) | Bit/dim 1.1058(1.1084) | Xent 0.0525(0.0522) | Loss 1.1320(1.1345) | Error 0.0160(0.0159) Steps 416(417.56) | Grad Norm 0.2600(0.2567) | Total Time 10.00(10.00)\n",
      "Iter 3222 | Time 30.9132(30.4293) | Bit/dim 1.1108(1.1085) | Xent 0.0501(0.0521) | Loss 1.1358(1.1345) | Error 0.0148(0.0159) Steps 416(417.51) | Grad Norm 0.1802(0.2544) | Total Time 10.00(10.00)\n",
      "Iter 3223 | Time 31.5065(30.4616) | Bit/dim 1.1112(1.1086) | Xent 0.0466(0.0519) | Loss 1.1345(1.1345) | Error 0.0142(0.0158) Steps 422(417.64) | Grad Norm 0.2592(0.2546) | Total Time 10.00(10.00)\n",
      "Iter 3224 | Time 30.0751(30.4500) | Bit/dim 1.1092(1.1086) | Xent 0.0527(0.0520) | Loss 1.1356(1.1346) | Error 0.0172(0.0159) Steps 410(417.42) | Grad Norm 0.4343(0.2599) | Total Time 10.00(10.00)\n",
      "Iter 3225 | Time 30.6337(30.4555) | Bit/dim 1.1039(1.1084) | Xent 0.0540(0.0520) | Loss 1.1309(1.1345) | Error 0.0166(0.0159) Steps 410(417.19) | Grad Norm 0.2048(0.2583) | Total Time 10.00(10.00)\n",
      "Iter 3226 | Time 30.2879(30.4505) | Bit/dim 1.1090(1.1085) | Xent 0.0579(0.0522) | Loss 1.1379(1.1346) | Error 0.0165(0.0159) Steps 416(417.16) | Grad Norm 0.2489(0.2580) | Total Time 10.00(10.00)\n",
      "Iter 3227 | Time 31.6440(30.4863) | Bit/dim 1.1091(1.1085) | Xent 0.0529(0.0522) | Loss 1.1355(1.1346) | Error 0.0148(0.0159) Steps 422(417.30) | Grad Norm 0.1667(0.2553) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0461 | Time 16.2421, Epoch Time 243.7096(240.1774), Bit/dim 1.1025(best: 1.1022), Xent 0.0320, Loss 1.1185, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3228 | Time 30.2116(30.4780) | Bit/dim 1.1066(1.1084) | Xent 0.0490(0.0521) | Loss 1.1311(1.1345) | Error 0.0159(0.0159) Steps 422(417.44) | Grad Norm 0.2129(0.2540) | Total Time 10.00(10.00)\n",
      "Iter 3229 | Time 30.2621(30.4716) | Bit/dim 1.1046(1.1083) | Xent 0.0561(0.0522) | Loss 1.1326(1.1344) | Error 0.0171(0.0159) Steps 416(417.40) | Grad Norm 0.1659(0.2514) | Total Time 10.00(10.00)\n",
      "Iter 3230 | Time 30.4034(30.4695) | Bit/dim 1.1088(1.1083) | Xent 0.0559(0.0524) | Loss 1.1368(1.1345) | Error 0.0154(0.0159) Steps 422(417.54) | Grad Norm 0.2374(0.2509) | Total Time 10.00(10.00)\n",
      "Iter 3231 | Time 30.3965(30.4673) | Bit/dim 1.1075(1.1083) | Xent 0.0501(0.0523) | Loss 1.1326(1.1344) | Error 0.0156(0.0159) Steps 422(417.67) | Grad Norm 0.1766(0.2487) | Total Time 10.00(10.00)\n",
      "Iter 3232 | Time 30.2070(30.4595) | Bit/dim 1.1095(1.1083) | Xent 0.0429(0.0520) | Loss 1.1309(1.1343) | Error 0.0141(0.0158) Steps 410(417.44) | Grad Norm 0.1710(0.2464) | Total Time 10.00(10.00)\n",
      "Iter 3233 | Time 30.1128(30.4491) | Bit/dim 1.1077(1.1083) | Xent 0.0490(0.0519) | Loss 1.1322(1.1343) | Error 0.0139(0.0158) Steps 416(417.40) | Grad Norm 0.2197(0.2456) | Total Time 10.00(10.00)\n",
      "Iter 3234 | Time 30.0702(30.4377) | Bit/dim 1.1082(1.1083) | Xent 0.0523(0.0519) | Loss 1.1344(1.1343) | Error 0.0162(0.0158) Steps 422(417.54) | Grad Norm 0.2941(0.2470) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0462 | Time 16.3270, Epoch Time 240.1555(240.1768), Bit/dim 1.1027(best: 1.1022), Xent 0.0314, Loss 1.1183, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3235 | Time 29.8008(30.4186) | Bit/dim 1.1126(1.1084) | Xent 0.0542(0.0520) | Loss 1.1397(1.1344) | Error 0.0174(0.0158) Steps 410(417.31) | Grad Norm 0.3577(0.2503) | Total Time 10.00(10.00)\n",
      "Iter 3236 | Time 30.3184(30.4156) | Bit/dim 1.1086(1.1084) | Xent 0.0511(0.0520) | Loss 1.1342(1.1344) | Error 0.0160(0.0158) Steps 422(417.45) | Grad Norm 0.1976(0.2488) | Total Time 10.00(10.00)\n",
      "Iter 3237 | Time 30.0723(30.4053) | Bit/dim 1.1061(1.1084) | Xent 0.0491(0.0519) | Loss 1.1306(1.1343) | Error 0.0145(0.0158) Steps 416(417.41) | Grad Norm 0.2737(0.2495) | Total Time 10.00(10.00)\n",
      "Iter 3238 | Time 30.1600(30.3980) | Bit/dim 1.1071(1.1083) | Xent 0.0453(0.0517) | Loss 1.1297(1.1342) | Error 0.0144(0.0158) Steps 410(417.19) | Grad Norm 0.2636(0.2499) | Total Time 10.00(10.00)\n",
      "Iter 3239 | Time 30.2500(30.3935) | Bit/dim 1.1091(1.1084) | Xent 0.0468(0.0515) | Loss 1.1325(1.1341) | Error 0.0156(0.0157) Steps 416(417.15) | Grad Norm 0.3013(0.2515) | Total Time 10.00(10.00)\n",
      "Iter 3240 | Time 30.0755(30.3840) | Bit/dim 1.1061(1.1083) | Xent 0.0565(0.0517) | Loss 1.1343(1.1341) | Error 0.0182(0.0158) Steps 422(417.30) | Grad Norm 0.2193(0.2505) | Total Time 10.00(10.00)\n",
      "Iter 3241 | Time 30.5227(30.3881) | Bit/dim 1.1095(1.1083) | Xent 0.0537(0.0517) | Loss 1.1363(1.1342) | Error 0.0179(0.0159) Steps 422(417.44) | Grad Norm 0.2650(0.2510) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0463 | Time 16.2617, Epoch Time 239.7635(240.1644), Bit/dim 1.1028(best: 1.1022), Xent 0.0331, Loss 1.1193, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3242 | Time 29.6632(30.3664) | Bit/dim 1.1130(1.1085) | Xent 0.0497(0.0517) | Loss 1.1379(1.1343) | Error 0.0158(0.0159) Steps 422(417.57) | Grad Norm 0.2594(0.2512) | Total Time 10.00(10.00)\n",
      "Iter 3243 | Time 30.0100(30.3557) | Bit/dim 1.1108(1.1085) | Xent 0.0501(0.0516) | Loss 1.1358(1.1344) | Error 0.0135(0.0158) Steps 422(417.71) | Grad Norm 0.1628(0.2486) | Total Time 10.00(10.00)\n",
      "Iter 3244 | Time 31.0459(30.3764) | Bit/dim 1.1054(1.1084) | Xent 0.0525(0.0517) | Loss 1.1316(1.1343) | Error 0.0159(0.0158) Steps 422(417.84) | Grad Norm 0.2046(0.2472) | Total Time 10.00(10.00)\n",
      "Iter 3245 | Time 30.3151(30.3746) | Bit/dim 1.1105(1.1085) | Xent 0.0452(0.0515) | Loss 1.1331(1.1342) | Error 0.0154(0.0158) Steps 416(417.78) | Grad Norm 0.1579(0.2446) | Total Time 10.00(10.00)\n",
      "Iter 3246 | Time 30.5678(30.3804) | Bit/dim 1.1058(1.1084) | Xent 0.0531(0.0515) | Loss 1.1323(1.1342) | Error 0.0158(0.0158) Steps 416(417.73) | Grad Norm 0.2405(0.2444) | Total Time 10.00(10.00)\n",
      "Iter 3247 | Time 30.6978(30.3899) | Bit/dim 1.1103(1.1085) | Xent 0.0526(0.0515) | Loss 1.1366(1.1343) | Error 0.0176(0.0159) Steps 416(417.67) | Grad Norm 0.1992(0.2431) | Total Time 10.00(10.00)\n",
      "Iter 3248 | Time 30.1505(30.3827) | Bit/dim 1.1028(1.1083) | Xent 0.0491(0.0515) | Loss 1.1274(1.1340) | Error 0.0132(0.0158) Steps 410(417.44) | Grad Norm 0.2208(0.2424) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0464 | Time 16.3703, Epoch Time 241.1387(240.1936), Bit/dim 1.1021(best: 1.1022), Xent 0.0317, Loss 1.1179, Error 0.0110(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3249 | Time 30.3948(30.3831) | Bit/dim 1.1127(1.1084) | Xent 0.0551(0.0516) | Loss 1.1403(1.1342) | Error 0.0166(0.0158) Steps 416(417.40) | Grad Norm 0.1439(0.2395) | Total Time 10.00(10.00)\n",
      "Iter 3250 | Time 29.5611(30.3584) | Bit/dim 1.1089(1.1085) | Xent 0.0538(0.0517) | Loss 1.1358(1.1343) | Error 0.0172(0.0158) Steps 422(417.54) | Grad Norm 0.2613(0.2401) | Total Time 10.00(10.00)\n",
      "Iter 3251 | Time 30.4891(30.3623) | Bit/dim 1.1072(1.1084) | Xent 0.0515(0.0516) | Loss 1.1329(1.1342) | Error 0.0145(0.0158) Steps 416(417.49) | Grad Norm 0.1649(0.2379) | Total Time 10.00(10.00)\n",
      "Iter 3252 | Time 29.9964(30.3514) | Bit/dim 1.1044(1.1083) | Xent 0.0461(0.0515) | Loss 1.1275(1.1340) | Error 0.0138(0.0157) Steps 422(417.63) | Grad Norm 0.2933(0.2395) | Total Time 10.00(10.00)\n",
      "Iter 3253 | Time 30.7921(30.3646) | Bit/dim 1.1054(1.1082) | Xent 0.0627(0.0518) | Loss 1.1367(1.1341) | Error 0.0184(0.0158) Steps 422(417.76) | Grad Norm 0.1607(0.2372) | Total Time 10.00(10.00)\n",
      "Iter 3254 | Time 30.2149(30.3601) | Bit/dim 1.1062(1.1081) | Xent 0.0433(0.0516) | Loss 1.1278(1.1339) | Error 0.0144(0.0158) Steps 422(417.89) | Grad Norm 0.1788(0.2354) | Total Time 10.00(10.00)\n",
      "Iter 3255 | Time 30.5492(30.3658) | Bit/dim 1.1089(1.1082) | Xent 0.0536(0.0516) | Loss 1.1357(1.1340) | Error 0.0142(0.0157) Steps 422(418.01) | Grad Norm 0.1791(0.2337) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0465 | Time 16.3621, Epoch Time 240.7599(240.2106), Bit/dim 1.1026(best: 1.1021), Xent 0.0323, Loss 1.1187, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3256 | Time 30.2139(30.3612) | Bit/dim 1.1072(1.1081) | Xent 0.0434(0.0514) | Loss 1.1289(1.1338) | Error 0.0128(0.0156) Steps 416(417.95) | Grad Norm 0.2483(0.2342) | Total Time 10.00(10.00)\n",
      "Iter 3257 | Time 30.2225(30.3570) | Bit/dim 1.1099(1.1082) | Xent 0.0486(0.0513) | Loss 1.1342(1.1338) | Error 0.0154(0.0156) Steps 416(417.89) | Grad Norm 0.2052(0.2333) | Total Time 10.00(10.00)\n",
      "Iter 3258 | Time 30.2234(30.3530) | Bit/dim 1.1056(1.1081) | Xent 0.0595(0.0515) | Loss 1.1353(1.1339) | Error 0.0178(0.0157) Steps 416(417.83) | Grad Norm 0.2694(0.2344) | Total Time 10.00(10.00)\n",
      "Iter 3259 | Time 30.8487(30.3679) | Bit/dim 1.1089(1.1081) | Xent 0.0498(0.0515) | Loss 1.1337(1.1339) | Error 0.0161(0.0157) Steps 416(417.78) | Grad Norm 0.1870(0.2329) | Total Time 10.00(10.00)\n",
      "Iter 3260 | Time 29.9887(30.3565) | Bit/dim 1.1096(1.1082) | Xent 0.0547(0.0516) | Loss 1.1370(1.1340) | Error 0.0166(0.0157) Steps 416(417.73) | Grad Norm 0.2123(0.2323) | Total Time 10.00(10.00)\n",
      "Iter 3261 | Time 30.1468(30.3502) | Bit/dim 1.1033(1.1080) | Xent 0.0446(0.0514) | Loss 1.1256(1.1337) | Error 0.0142(0.0157) Steps 422(417.85) | Grad Norm 0.2481(0.2328) | Total Time 10.00(10.00)\n",
      "Iter 3262 | Time 30.7581(30.3625) | Bit/dim 1.1130(1.1082) | Xent 0.0558(0.0515) | Loss 1.1409(1.1339) | Error 0.0169(0.0157) Steps 422(417.98) | Grad Norm 0.2622(0.2337) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0466 | Time 16.3658, Epoch Time 240.9429(240.2326), Bit/dim 1.1029(best: 1.1021), Xent 0.0326, Loss 1.1191, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3263 | Time 30.2493(30.3591) | Bit/dim 1.1088(1.1082) | Xent 0.0531(0.0516) | Loss 1.1354(1.1340) | Error 0.0160(0.0157) Steps 416(417.92) | Grad Norm 0.1676(0.2317) | Total Time 10.00(10.00)\n",
      "Iter 3264 | Time 30.5950(30.3662) | Bit/dim 1.1122(1.1083) | Xent 0.0481(0.0515) | Loss 1.1363(1.1340) | Error 0.0159(0.0157) Steps 410(417.68) | Grad Norm 0.2307(0.2317) | Total Time 10.00(10.00)\n",
      "Iter 3265 | Time 30.6972(30.3761) | Bit/dim 1.1066(1.1083) | Xent 0.0508(0.0514) | Loss 1.1320(1.1340) | Error 0.0161(0.0158) Steps 422(417.81) | Grad Norm 0.1857(0.2303) | Total Time 10.00(10.00)\n",
      "Iter 3266 | Time 30.8349(30.3899) | Bit/dim 1.1076(1.1083) | Xent 0.0456(0.0513) | Loss 1.1304(1.1339) | Error 0.0140(0.0157) Steps 416(417.76) | Grad Norm 0.2041(0.2295) | Total Time 10.00(10.00)\n",
      "Iter 3267 | Time 29.9015(30.3752) | Bit/dim 1.1070(1.1082) | Xent 0.0531(0.0513) | Loss 1.1335(1.1339) | Error 0.0170(0.0157) Steps 410(417.52) | Grad Norm 0.2343(0.2296) | Total Time 10.00(10.00)\n",
      "Iter 3268 | Time 29.9292(30.3618) | Bit/dim 1.1045(1.1081) | Xent 0.0542(0.0514) | Loss 1.1316(1.1338) | Error 0.0159(0.0157) Steps 422(417.66) | Grad Norm 0.1782(0.2281) | Total Time 10.00(10.00)\n",
      "Iter 3269 | Time 30.6450(30.3703) | Bit/dim 1.1084(1.1081) | Xent 0.0549(0.0515) | Loss 1.1359(1.1339) | Error 0.0149(0.0157) Steps 422(417.79) | Grad Norm 0.2419(0.2285) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0467 | Time 15.8971, Epoch Time 241.1581(240.2603), Bit/dim 1.1025(best: 1.1021), Xent 0.0321, Loss 1.1185, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3270 | Time 29.8665(30.3552) | Bit/dim 1.1095(1.1082) | Xent 0.0511(0.0515) | Loss 1.1351(1.1339) | Error 0.0149(0.0157) Steps 416(417.74) | Grad Norm 0.3117(0.2310) | Total Time 10.00(10.00)\n",
      "Iter 3271 | Time 30.3223(30.3542) | Bit/dim 1.1077(1.1081) | Xent 0.0539(0.0516) | Loss 1.1346(1.1339) | Error 0.0166(0.0157) Steps 416(417.68) | Grad Norm 0.2176(0.2306) | Total Time 10.00(10.00)\n",
      "Iter 3272 | Time 30.3510(30.3541) | Bit/dim 1.1049(1.1080) | Xent 0.0586(0.0518) | Loss 1.1342(1.1339) | Error 0.0172(0.0158) Steps 422(417.81) | Grad Norm 0.2113(0.2300) | Total Time 10.00(10.00)\n",
      "Iter 3273 | Time 30.2257(30.3503) | Bit/dim 1.1104(1.1081) | Xent 0.0581(0.0520) | Loss 1.1395(1.1341) | Error 0.0168(0.0158) Steps 422(417.94) | Grad Norm 0.2605(0.2309) | Total Time 10.00(10.00)\n",
      "Iter 3274 | Time 32.2772(30.4081) | Bit/dim 1.1039(1.1080) | Xent 0.0417(0.0517) | Loss 1.1247(1.1338) | Error 0.0152(0.0158) Steps 422(418.06) | Grad Norm 0.2947(0.2329) | Total Time 10.00(10.00)\n",
      "Iter 3275 | Time 30.4351(30.4089) | Bit/dim 1.1152(1.1082) | Xent 0.0488(0.0516) | Loss 1.1396(1.1340) | Error 0.0154(0.0158) Steps 422(418.18) | Grad Norm 0.2704(0.2340) | Total Time 10.00(10.00)\n",
      "Iter 3276 | Time 30.6728(30.4168) | Bit/dim 1.1068(1.1082) | Xent 0.0518(0.0516) | Loss 1.1327(1.1340) | Error 0.0168(0.0158) Steps 422(418.29) | Grad Norm 0.3388(0.2371) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0468 | Time 16.5315, Epoch Time 242.9316(240.3405), Bit/dim 1.1025(best: 1.1021), Xent 0.0317, Loss 1.1184, Error 0.0093(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3277 | Time 30.1714(30.4094) | Bit/dim 1.1073(1.1081) | Xent 0.0472(0.0514) | Loss 1.1308(1.1339) | Error 0.0154(0.0158) Steps 422(418.40) | Grad Norm 0.2367(0.2371) | Total Time 10.00(10.00)\n",
      "Iter 3278 | Time 30.4965(30.4121) | Bit/dim 1.1153(1.1083) | Xent 0.0628(0.0518) | Loss 1.1467(1.1342) | Error 0.0180(0.0158) Steps 416(418.33) | Grad Norm 0.1977(0.2359) | Total Time 10.00(10.00)\n",
      "Iter 3279 | Time 30.9307(30.4276) | Bit/dim 1.1103(1.1084) | Xent 0.0495(0.0517) | Loss 1.1351(1.1343) | Error 0.0149(0.0158) Steps 422(418.44) | Grad Norm 0.2378(0.2360) | Total Time 10.00(10.00)\n",
      "Iter 3280 | Time 30.7213(30.4364) | Bit/dim 1.1108(1.1085) | Xent 0.0471(0.0516) | Loss 1.1343(1.1343) | Error 0.0136(0.0158) Steps 416(418.37) | Grad Norm 0.2114(0.2353) | Total Time 10.00(10.00)\n",
      "Iter 3281 | Time 30.5056(30.4385) | Bit/dim 1.1024(1.1083) | Xent 0.0463(0.0514) | Loss 1.1256(1.1340) | Error 0.0138(0.0157) Steps 422(418.48) | Grad Norm 0.2563(0.2359) | Total Time 10.00(10.00)\n",
      "Iter 3282 | Time 30.4746(30.4396) | Bit/dim 1.1035(1.1082) | Xent 0.0534(0.0515) | Loss 1.1302(1.1339) | Error 0.0161(0.0157) Steps 416(418.40) | Grad Norm 0.2365(0.2359) | Total Time 10.00(10.00)\n",
      "Iter 3283 | Time 30.6619(30.4463) | Bit/dim 1.1058(1.1081) | Xent 0.0491(0.0514) | Loss 1.1303(1.1338) | Error 0.0152(0.0157) Steps 416(418.33) | Grad Norm 0.1610(0.2337) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0469 | Time 16.3235, Epoch Time 242.5618(240.4071), Bit/dim 1.1029(best: 1.1021), Xent 0.0290, Loss 1.1174, Error 0.0088(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3284 | Time 30.6327(30.4518) | Bit/dim 1.1078(1.1081) | Xent 0.0500(0.0514) | Loss 1.1328(1.1338) | Error 0.0162(0.0157) Steps 416(418.26) | Grad Norm 0.3393(0.2368) | Total Time 10.00(10.00)\n",
      "Iter 3285 | Time 29.9599(30.4371) | Bit/dim 1.1091(1.1081) | Xent 0.0514(0.0514) | Loss 1.1348(1.1338) | Error 0.0160(0.0157) Steps 416(418.19) | Grad Norm 0.3062(0.2389) | Total Time 10.00(10.00)\n",
      "Iter 3286 | Time 29.9444(30.4223) | Bit/dim 1.1024(1.1079) | Xent 0.0526(0.0514) | Loss 1.1287(1.1336) | Error 0.0155(0.0157) Steps 422(418.31) | Grad Norm 0.1532(0.2363) | Total Time 10.00(10.00)\n",
      "Iter 3287 | Time 30.5384(30.4258) | Bit/dim 1.1084(1.1079) | Xent 0.0536(0.0515) | Loss 1.1352(1.1337) | Error 0.0174(0.0158) Steps 416(418.24) | Grad Norm 0.3203(0.2389) | Total Time 10.00(10.00)\n",
      "Iter 3288 | Time 30.3077(30.4222) | Bit/dim 1.1115(1.1081) | Xent 0.0495(0.0514) | Loss 1.1362(1.1338) | Error 0.0156(0.0158) Steps 416(418.17) | Grad Norm 0.3147(0.2411) | Total Time 10.00(10.00)\n",
      "Iter 3289 | Time 30.6391(30.4287) | Bit/dim 1.1113(1.1081) | Xent 0.0521(0.0514) | Loss 1.1374(1.1339) | Error 0.0162(0.0158) Steps 416(418.11) | Grad Norm 0.2644(0.2418) | Total Time 10.00(10.00)\n",
      "Iter 3290 | Time 30.3458(30.4263) | Bit/dim 1.1088(1.1082) | Xent 0.0524(0.0515) | Loss 1.1350(1.1339) | Error 0.0168(0.0158) Steps 410(417.86) | Grad Norm 0.2645(0.2425) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0470 | Time 16.4894, Epoch Time 241.1129(240.4283), Bit/dim 1.1025(best: 1.1021), Xent 0.0318, Loss 1.1183, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3291 | Time 30.4545(30.4271) | Bit/dim 1.1090(1.1082) | Xent 0.0518(0.0515) | Loss 1.1349(1.1339) | Error 0.0159(0.0158) Steps 416(417.81) | Grad Norm 0.2742(0.2435) | Total Time 10.00(10.00)\n",
      "Iter 3292 | Time 29.7418(30.4065) | Bit/dim 1.1087(1.1082) | Xent 0.0467(0.0513) | Loss 1.1320(1.1339) | Error 0.0145(0.0158) Steps 422(417.93) | Grad Norm 0.1697(0.2412) | Total Time 10.00(10.00)\n",
      "Iter 3293 | Time 30.5058(30.4095) | Bit/dim 1.1017(1.1080) | Xent 0.0497(0.0513) | Loss 1.1265(1.1337) | Error 0.0174(0.0158) Steps 416(417.87) | Grad Norm 0.3515(0.2446) | Total Time 10.00(10.00)\n",
      "Iter 3294 | Time 29.8971(30.3942) | Bit/dim 1.1106(1.1081) | Xent 0.0539(0.0514) | Loss 1.1375(1.1338) | Error 0.0154(0.0158) Steps 422(418.00) | Grad Norm 0.2435(0.2445) | Total Time 10.00(10.00)\n",
      "Iter 3295 | Time 30.4282(30.3952) | Bit/dim 1.1120(1.1082) | Xent 0.0515(0.0514) | Loss 1.1378(1.1339) | Error 0.0165(0.0158) Steps 422(418.12) | Grad Norm 0.3645(0.2481) | Total Time 10.00(10.00)\n",
      "Iter 3296 | Time 30.5355(30.3994) | Bit/dim 1.1070(1.1082) | Xent 0.0537(0.0514) | Loss 1.1338(1.1339) | Error 0.0160(0.0158) Steps 416(418.06) | Grad Norm 0.3396(0.2509) | Total Time 10.00(10.00)\n",
      "Iter 3297 | Time 31.8854(30.4440) | Bit/dim 1.1066(1.1081) | Xent 0.0513(0.0514) | Loss 1.1322(1.1338) | Error 0.0144(0.0158) Steps 416(417.99) | Grad Norm 0.3146(0.2528) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0471 | Time 16.2985, Epoch Time 242.1429(240.4797), Bit/dim 1.1027(best: 1.1021), Xent 0.0311, Loss 1.1183, Error 0.0098(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3298 | Time 30.9091(30.4579) | Bit/dim 1.1056(1.1080) | Xent 0.0566(0.0516) | Loss 1.1339(1.1338) | Error 0.0175(0.0158) Steps 416(417.93) | Grad Norm 0.2224(0.2519) | Total Time 10.00(10.00)\n",
      "Iter 3299 | Time 30.7455(30.4665) | Bit/dim 1.1100(1.1081) | Xent 0.0532(0.0516) | Loss 1.1366(1.1339) | Error 0.0146(0.0158) Steps 422(418.06) | Grad Norm 0.3060(0.2535) | Total Time 10.00(10.00)\n",
      "Iter 3300 | Time 31.2728(30.4907) | Bit/dim 1.1099(1.1082) | Xent 0.0509(0.0516) | Loss 1.1354(1.1340) | Error 0.0165(0.0158) Steps 422(418.17) | Grad Norm 0.2321(0.2529) | Total Time 10.00(10.00)\n",
      "Iter 3301 | Time 30.6085(30.4943) | Bit/dim 1.1079(1.1082) | Xent 0.0543(0.0517) | Loss 1.1350(1.1340) | Error 0.0169(0.0159) Steps 422(418.29) | Grad Norm 0.2233(0.2520) | Total Time 10.00(10.00)\n",
      "Iter 3302 | Time 30.6080(30.4977) | Bit/dim 1.1069(1.1081) | Xent 0.0488(0.0516) | Loss 1.1313(1.1339) | Error 0.0154(0.0158) Steps 422(418.40) | Grad Norm 0.1891(0.2501) | Total Time 10.00(10.00)\n",
      "Iter 3303 | Time 30.5940(30.5006) | Bit/dim 1.1104(1.1082) | Xent 0.0450(0.0514) | Loss 1.1329(1.1339) | Error 0.0156(0.0158) Steps 422(418.51) | Grad Norm 0.2321(0.2495) | Total Time 10.00(10.00)\n",
      "Iter 3304 | Time 30.1357(30.4896) | Bit/dim 1.1049(1.1081) | Xent 0.0520(0.0514) | Loss 1.1309(1.1338) | Error 0.0162(0.0158) Steps 410(418.25) | Grad Norm 0.3431(0.2523) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0472 | Time 16.4027, Epoch Time 243.5412(240.5716), Bit/dim 1.1023(best: 1.1021), Xent 0.0329, Loss 1.1187, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3305 | Time 30.1901(30.4806) | Bit/dim 1.1001(1.1078) | Xent 0.0537(0.0515) | Loss 1.1269(1.1336) | Error 0.0162(0.0159) Steps 422(418.37) | Grad Norm 0.2016(0.2508) | Total Time 10.00(10.00)\n",
      "Iter 3306 | Time 30.6319(30.4852) | Bit/dim 1.1083(1.1079) | Xent 0.0500(0.0515) | Loss 1.1333(1.1336) | Error 0.0156(0.0158) Steps 422(418.47) | Grad Norm 0.2758(0.2516) | Total Time 10.00(10.00)\n",
      "Iter 3307 | Time 29.7712(30.4638) | Bit/dim 1.1141(1.1080) | Xent 0.0560(0.0516) | Loss 1.1422(1.1338) | Error 0.0166(0.0159) Steps 422(418.58) | Grad Norm 0.1682(0.2491) | Total Time 10.00(10.00)\n",
      "Iter 3308 | Time 30.3627(30.4607) | Bit/dim 1.1106(1.1081) | Xent 0.0476(0.0515) | Loss 1.1345(1.1339) | Error 0.0129(0.0158) Steps 422(418.68) | Grad Norm 0.2619(0.2495) | Total Time 10.00(10.00)\n",
      "Iter 3309 | Time 30.1182(30.4504) | Bit/dim 1.1072(1.1081) | Xent 0.0517(0.0515) | Loss 1.1331(1.1338) | Error 0.0175(0.0158) Steps 422(418.78) | Grad Norm 0.1804(0.2474) | Total Time 10.00(10.00)\n",
      "Iter 3310 | Time 30.6311(30.4559) | Bit/dim 1.1117(1.1082) | Xent 0.0535(0.0515) | Loss 1.1384(1.1340) | Error 0.0154(0.0158) Steps 410(418.52) | Grad Norm 0.2374(0.2471) | Total Time 10.00(10.00)\n",
      "Iter 3311 | Time 30.1691(30.4473) | Bit/dim 1.1053(1.1081) | Xent 0.0517(0.0515) | Loss 1.1312(1.1339) | Error 0.0165(0.0158) Steps 416(418.44) | Grad Norm 0.2635(0.2476) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0473 | Time 16.5402, Epoch Time 240.9854(240.5840), Bit/dim 1.1027(best: 1.1021), Xent 0.0322, Loss 1.1188, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3312 | Time 30.9964(30.4637) | Bit/dim 1.1049(1.1080) | Xent 0.0505(0.0515) | Loss 1.1301(1.1338) | Error 0.0155(0.0158) Steps 416(418.37) | Grad Norm 0.2218(0.2468) | Total Time 10.00(10.00)\n",
      "Iter 3313 | Time 31.1774(30.4852) | Bit/dim 1.1065(1.1080) | Xent 0.0552(0.0516) | Loss 1.1341(1.1338) | Error 0.0162(0.0158) Steps 422(418.48) | Grad Norm 0.1409(0.2436) | Total Time 10.00(10.00)\n",
      "Iter 3314 | Time 29.5879(30.4582) | Bit/dim 1.1126(1.1081) | Xent 0.0498(0.0516) | Loss 1.1375(1.1339) | Error 0.0156(0.0158) Steps 422(418.58) | Grad Norm 0.2023(0.2424) | Total Time 10.00(10.00)\n",
      "Iter 3315 | Time 30.0863(30.4471) | Bit/dim 1.1062(1.1081) | Xent 0.0540(0.0516) | Loss 1.1332(1.1339) | Error 0.0166(0.0159) Steps 422(418.69) | Grad Norm 0.2847(0.2437) | Total Time 10.00(10.00)\n",
      "Iter 3316 | Time 30.1197(30.4373) | Bit/dim 1.1097(1.1081) | Xent 0.0498(0.0516) | Loss 1.1347(1.1339) | Error 0.0152(0.0158) Steps 422(418.79) | Grad Norm 0.2023(0.2424) | Total Time 10.00(10.00)\n",
      "Iter 3317 | Time 31.2088(30.4604) | Bit/dim 1.1103(1.1082) | Xent 0.0455(0.0514) | Loss 1.1330(1.1339) | Error 0.0145(0.0158) Steps 416(418.70) | Grad Norm 0.2112(0.2415) | Total Time 10.00(10.00)\n",
      "Iter 3318 | Time 30.4752(30.4608) | Bit/dim 1.1072(1.1081) | Xent 0.0513(0.0514) | Loss 1.1329(1.1338) | Error 0.0164(0.0158) Steps 416(418.62) | Grad Norm 0.2667(0.2422) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0474 | Time 16.4386, Epoch Time 242.3697(240.6375), Bit/dim 1.1023(best: 1.1021), Xent 0.0310, Loss 1.1178, Error 0.0094(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3319 | Time 31.6408(30.4962) | Bit/dim 1.1094(1.1082) | Xent 0.0436(0.0512) | Loss 1.1312(1.1338) | Error 0.0146(0.0158) Steps 422(418.72) | Grad Norm 0.2872(0.2436) | Total Time 10.00(10.00)\n",
      "Iter 3320 | Time 30.5862(30.4989) | Bit/dim 1.1075(1.1082) | Xent 0.0563(0.0513) | Loss 1.1357(1.1338) | Error 0.0155(0.0158) Steps 416(418.64) | Grad Norm 0.1937(0.2421) | Total Time 10.00(10.00)\n",
      "Iter 3321 | Time 30.4354(30.4970) | Bit/dim 1.1108(1.1082) | Xent 0.0608(0.0516) | Loss 1.1412(1.1340) | Error 0.0195(0.0159) Steps 422(418.74) | Grad Norm 0.3294(0.2447) | Total Time 10.00(10.00)\n",
      "Iter 3322 | Time 30.6637(30.5020) | Bit/dim 1.1066(1.1082) | Xent 0.0552(0.0517) | Loss 1.1342(1.1340) | Error 0.0180(0.0159) Steps 416(418.66) | Grad Norm 0.2508(0.2449) | Total Time 10.00(10.00)\n",
      "Iter 3323 | Time 30.3030(30.4961) | Bit/dim 1.1105(1.1083) | Xent 0.0437(0.0515) | Loss 1.1323(1.1340) | Error 0.0132(0.0159) Steps 416(418.58) | Grad Norm 0.1938(0.2434) | Total Time 10.00(10.00)\n",
      "Iter 3324 | Time 30.0602(30.4830) | Bit/dim 1.1051(1.1082) | Xent 0.0506(0.0514) | Loss 1.1304(1.1339) | Error 0.0165(0.0159) Steps 416(418.50) | Grad Norm 0.1595(0.2408) | Total Time 10.00(10.00)\n",
      "Iter 3325 | Time 31.3225(30.5082) | Bit/dim 1.1054(1.1081) | Xent 0.0458(0.0513) | Loss 1.1283(1.1337) | Error 0.0146(0.0158) Steps 422(418.61) | Grad Norm 0.2256(0.2404) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0475 | Time 16.4230, Epoch Time 243.7174(240.7299), Bit/dim 1.1023(best: 1.1021), Xent 0.0318, Loss 1.1182, Error 0.0109(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3326 | Time 30.8348(30.5180) | Bit/dim 1.1057(1.1080) | Xent 0.0511(0.0513) | Loss 1.1312(1.1336) | Error 0.0145(0.0158) Steps 422(418.71) | Grad Norm 0.2991(0.2421) | Total Time 10.00(10.00)\n",
      "Iter 3327 | Time 30.3631(30.5133) | Bit/dim 1.1094(1.1081) | Xent 0.0474(0.0512) | Loss 1.1331(1.1336) | Error 0.0141(0.0158) Steps 416(418.63) | Grad Norm 0.2047(0.2410) | Total Time 10.00(10.00)\n",
      "Iter 3328 | Time 30.1957(30.5038) | Bit/dim 1.1102(1.1081) | Xent 0.0633(0.0515) | Loss 1.1418(1.1339) | Error 0.0190(0.0159) Steps 422(418.73) | Grad Norm 0.2113(0.2401) | Total Time 10.00(10.00)\n",
      "Iter 3329 | Time 31.0698(30.5208) | Bit/dim 1.1050(1.1080) | Xent 0.0486(0.0514) | Loss 1.1293(1.1337) | Error 0.0144(0.0158) Steps 416(418.65) | Grad Norm 0.3003(0.2419) | Total Time 10.00(10.00)\n",
      "Iter 3330 | Time 30.8841(30.5317) | Bit/dim 1.1054(1.1079) | Xent 0.0499(0.0514) | Loss 1.1303(1.1336) | Error 0.0142(0.0158) Steps 410(418.39) | Grad Norm 0.2535(0.2423) | Total Time 10.00(10.00)\n",
      "Iter 3331 | Time 30.0785(30.5181) | Bit/dim 1.1085(1.1080) | Xent 0.0475(0.0513) | Loss 1.1322(1.1336) | Error 0.0150(0.0157) Steps 410(418.14) | Grad Norm 0.1586(0.2398) | Total Time 10.00(10.00)\n",
      "Iter 3332 | Time 30.6290(30.5214) | Bit/dim 1.1080(1.1080) | Xent 0.0470(0.0511) | Loss 1.1315(1.1335) | Error 0.0164(0.0158) Steps 416(418.07) | Grad Norm 0.1388(0.2367) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0476 | Time 16.3149, Epoch Time 242.6465(240.7874), Bit/dim 1.1027(best: 1.1021), Xent 0.0333, Loss 1.1194, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3333 | Time 30.2436(30.5131) | Bit/dim 1.1074(1.1079) | Xent 0.0490(0.0511) | Loss 1.1319(1.1335) | Error 0.0168(0.0158) Steps 416(418.01) | Grad Norm 0.2232(0.2363) | Total Time 10.00(10.00)\n",
      "Iter 3334 | Time 30.1247(30.5014) | Bit/dim 1.1115(1.1081) | Xent 0.0487(0.0510) | Loss 1.1359(1.1336) | Error 0.0149(0.0158) Steps 416(417.95) | Grad Norm 0.2834(0.2377) | Total Time 10.00(10.00)\n",
      "Iter 3335 | Time 30.3198(30.4960) | Bit/dim 1.1050(1.1080) | Xent 0.0565(0.0512) | Loss 1.1333(1.1335) | Error 0.0172(0.0158) Steps 416(417.89) | Grad Norm 0.2982(0.2396) | Total Time 10.00(10.00)\n",
      "Iter 3336 | Time 30.4843(30.4956) | Bit/dim 1.1044(1.1079) | Xent 0.0515(0.0512) | Loss 1.1302(1.1334) | Error 0.0156(0.0158) Steps 422(418.01) | Grad Norm 0.2408(0.2396) | Total Time 10.00(10.00)\n",
      "Iter 3337 | Time 31.3862(30.5223) | Bit/dim 1.1089(1.1079) | Xent 0.0538(0.0513) | Loss 1.1357(1.1335) | Error 0.0148(0.0158) Steps 416(417.95) | Grad Norm 0.2173(0.2389) | Total Time 10.00(10.00)\n",
      "Iter 3338 | Time 29.9861(30.5063) | Bit/dim 1.1050(1.1078) | Xent 0.0462(0.0511) | Loss 1.1281(1.1333) | Error 0.0142(0.0157) Steps 422(418.08) | Grad Norm 0.2534(0.2394) | Total Time 10.00(10.00)\n",
      "Iter 3339 | Time 30.5742(30.5083) | Bit/dim 1.1094(1.1078) | Xent 0.0490(0.0510) | Loss 1.1339(1.1334) | Error 0.0142(0.0157) Steps 422(418.19) | Grad Norm 0.1874(0.2378) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0477 | Time 16.2823, Epoch Time 241.6239(240.8125), Bit/dim 1.1022(best: 1.1021), Xent 0.0326, Loss 1.1185, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3340 | Time 30.2249(30.4998) | Bit/dim 1.1102(1.1079) | Xent 0.0504(0.0510) | Loss 1.1354(1.1334) | Error 0.0178(0.0157) Steps 416(418.13) | Grad Norm 0.1523(0.2352) | Total Time 10.00(10.00)\n",
      "Iter 3341 | Time 30.8839(30.5113) | Bit/dim 1.1061(1.1079) | Xent 0.0548(0.0511) | Loss 1.1335(1.1334) | Error 0.0160(0.0158) Steps 422(418.24) | Grad Norm 0.2690(0.2363) | Total Time 10.00(10.00)\n",
      "Iter 3342 | Time 30.4459(30.5094) | Bit/dim 1.1063(1.1078) | Xent 0.0546(0.0512) | Loss 1.1336(1.1334) | Error 0.0158(0.0158) Steps 422(418.36) | Grad Norm 0.3357(0.2392) | Total Time 10.00(10.00)\n",
      "Iter 3343 | Time 30.3684(30.5051) | Bit/dim 1.1062(1.1078) | Xent 0.0484(0.0512) | Loss 1.1304(1.1333) | Error 0.0162(0.0158) Steps 422(418.47) | Grad Norm 0.2257(0.2388) | Total Time 10.00(10.00)\n",
      "Iter 3344 | Time 30.7318(30.5119) | Bit/dim 1.1091(1.1078) | Xent 0.0611(0.0515) | Loss 1.1397(1.1335) | Error 0.0188(0.0159) Steps 422(418.57) | Grad Norm 0.3100(0.2410) | Total Time 10.00(10.00)\n",
      "Iter 3345 | Time 30.2571(30.5043) | Bit/dim 1.1080(1.1078) | Xent 0.0407(0.0511) | Loss 1.1284(1.1334) | Error 0.0126(0.0158) Steps 422(418.67) | Grad Norm 0.2519(0.2413) | Total Time 10.00(10.00)\n",
      "Iter 3346 | Time 30.8416(30.5144) | Bit/dim 1.1095(1.1079) | Xent 0.0473(0.0510) | Loss 1.1332(1.1334) | Error 0.0149(0.0157) Steps 422(418.77) | Grad Norm 0.3212(0.2437) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0478 | Time 16.4703, Epoch Time 242.2251(240.8549), Bit/dim 1.1022(best: 1.1021), Xent 0.0318, Loss 1.1181, Error 0.0110(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3347 | Time 31.1660(30.5339) | Bit/dim 1.1099(1.1079) | Xent 0.0532(0.0511) | Loss 1.1365(1.1335) | Error 0.0148(0.0157) Steps 422(418.87) | Grad Norm 0.2091(0.2427) | Total Time 10.00(10.00)\n",
      "Iter 3348 | Time 30.6056(30.5361) | Bit/dim 1.1134(1.1081) | Xent 0.0468(0.0510) | Loss 1.1368(1.1336) | Error 0.0158(0.0157) Steps 416(418.78) | Grad Norm 0.1848(0.2409) | Total Time 10.00(10.00)\n",
      "Iter 3349 | Time 30.6472(30.5394) | Bit/dim 1.1117(1.1082) | Xent 0.0545(0.0511) | Loss 1.1389(1.1337) | Error 0.0161(0.0157) Steps 416(418.70) | Grad Norm 0.2999(0.2427) | Total Time 10.00(10.00)\n",
      "Iter 3350 | Time 30.2749(30.5315) | Bit/dim 1.1066(1.1082) | Xent 0.0575(0.0513) | Loss 1.1354(1.1338) | Error 0.0176(0.0158) Steps 416(418.62) | Grad Norm 0.1955(0.2413) | Total Time 10.00(10.00)\n",
      "Iter 3351 | Time 30.7405(30.5378) | Bit/dim 1.1077(1.1081) | Xent 0.0540(0.0513) | Loss 1.1347(1.1338) | Error 0.0164(0.0158) Steps 416(418.54) | Grad Norm 0.1997(0.2400) | Total Time 10.00(10.00)\n",
      "Iter 3352 | Time 30.4577(30.5354) | Bit/dim 1.1046(1.1080) | Xent 0.0501(0.0513) | Loss 1.1297(1.1337) | Error 0.0159(0.0158) Steps 422(418.65) | Grad Norm 0.1614(0.2377) | Total Time 10.00(10.00)\n",
      "Iter 3353 | Time 32.8526(30.6049) | Bit/dim 1.1036(1.1079) | Xent 0.0439(0.0511) | Loss 1.1256(1.1334) | Error 0.0140(0.0157) Steps 422(418.75) | Grad Norm 0.2607(0.2384) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0479 | Time 16.5471, Epoch Time 245.7028(241.0003), Bit/dim 1.1017(best: 1.1021), Xent 0.0325, Loss 1.1180, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3354 | Time 30.1733(30.5919) | Bit/dim 1.1154(1.1081) | Xent 0.0515(0.0511) | Loss 1.1411(1.1337) | Error 0.0139(0.0157) Steps 422(418.84) | Grad Norm 0.2231(0.2379) | Total Time 10.00(10.00)\n",
      "Iter 3355 | Time 31.3649(30.6151) | Bit/dim 1.1072(1.1081) | Xent 0.0546(0.0512) | Loss 1.1345(1.1337) | Error 0.0172(0.0157) Steps 422(418.94) | Grad Norm 0.2144(0.2372) | Total Time 10.00(10.00)\n",
      "Iter 3356 | Time 30.3936(30.6085) | Bit/dim 1.1039(1.1080) | Xent 0.0505(0.0512) | Loss 1.1292(1.1336) | Error 0.0158(0.0157) Steps 416(418.85) | Grad Norm 0.1762(0.2354) | Total Time 10.00(10.00)\n",
      "Iter 3357 | Time 29.8349(30.5853) | Bit/dim 1.1115(1.1081) | Xent 0.0598(0.0514) | Loss 1.1414(1.1338) | Error 0.0175(0.0158) Steps 416(418.76) | Grad Norm 0.2659(0.2363) | Total Time 10.00(10.00)\n",
      "Iter 3358 | Time 30.9125(30.5951) | Bit/dim 1.1025(1.1079) | Xent 0.0515(0.0514) | Loss 1.1282(1.1336) | Error 0.0166(0.0158) Steps 422(418.86) | Grad Norm 0.2856(0.2378) | Total Time 10.00(10.00)\n",
      "Iter 3359 | Time 30.3835(30.5887) | Bit/dim 1.1088(1.1079) | Xent 0.0540(0.0515) | Loss 1.1358(1.1337) | Error 0.0175(0.0159) Steps 416(418.78) | Grad Norm 0.2196(0.2372) | Total Time 10.00(10.00)\n",
      "Iter 3360 | Time 30.3018(30.5801) | Bit/dim 1.1042(1.1078) | Xent 0.0474(0.0514) | Loss 1.1279(1.1335) | Error 0.0152(0.0158) Steps 422(418.87) | Grad Norm 0.1841(0.2356) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0480 | Time 16.4781, Epoch Time 242.0977(241.0333), Bit/dim 1.1023(best: 1.1017), Xent 0.0317, Loss 1.1181, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3361 | Time 30.0041(30.5628) | Bit/dim 1.1064(1.1078) | Xent 0.0543(0.0515) | Loss 1.1336(1.1335) | Error 0.0168(0.0159) Steps 422(418.97) | Grad Norm 0.1776(0.2339) | Total Time 10.00(10.00)\n",
      "Iter 3362 | Time 30.1786(30.5513) | Bit/dim 1.1099(1.1078) | Xent 0.0534(0.0515) | Loss 1.1366(1.1336) | Error 0.0166(0.0159) Steps 422(419.06) | Grad Norm 0.1345(0.2309) | Total Time 10.00(10.00)\n",
      "Iter 3363 | Time 30.8382(30.5599) | Bit/dim 1.1064(1.1078) | Xent 0.0530(0.0516) | Loss 1.1329(1.1336) | Error 0.0170(0.0159) Steps 422(419.15) | Grad Norm 0.1739(0.2292) | Total Time 10.00(10.00)\n",
      "Iter 3364 | Time 30.6163(30.5616) | Bit/dim 1.1052(1.1077) | Xent 0.0494(0.0515) | Loss 1.1299(1.1335) | Error 0.0164(0.0159) Steps 416(419.05) | Grad Norm 0.3071(0.2315) | Total Time 10.00(10.00)\n",
      "Iter 3365 | Time 30.6553(30.5644) | Bit/dim 1.1115(1.1078) | Xent 0.0441(0.0513) | Loss 1.1336(1.1335) | Error 0.0129(0.0158) Steps 416(418.96) | Grad Norm 0.2070(0.2308) | Total Time 10.00(10.00)\n",
      "Iter 3366 | Time 31.7516(30.6000) | Bit/dim 1.1063(1.1078) | Xent 0.0417(0.0510) | Loss 1.1271(1.1333) | Error 0.0121(0.0157) Steps 422(419.05) | Grad Norm 0.1601(0.2287) | Total Time 10.00(10.00)\n",
      "Iter 3367 | Time 30.5301(30.5979) | Bit/dim 1.1055(1.1077) | Xent 0.0489(0.0509) | Loss 1.1300(1.1332) | Error 0.0148(0.0157) Steps 422(419.14) | Grad Norm 0.2734(0.2300) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0481 | Time 16.2947, Epoch Time 243.0830(241.0948), Bit/dim 1.1018(best: 1.1017), Xent 0.0319, Loss 1.1178, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3368 | Time 30.8895(30.6067) | Bit/dim 1.1074(1.1077) | Xent 0.0496(0.0509) | Loss 1.1321(1.1332) | Error 0.0164(0.0157) Steps 416(419.05) | Grad Norm 0.1616(0.2280) | Total Time 10.00(10.00)\n",
      "Iter 3369 | Time 30.3783(30.5998) | Bit/dim 1.1029(1.1076) | Xent 0.0520(0.0509) | Loss 1.1289(1.1330) | Error 0.0150(0.0157) Steps 416(418.95) | Grad Norm 0.2276(0.2280) | Total Time 10.00(10.00)\n",
      "Iter 3370 | Time 30.7461(30.6042) | Bit/dim 1.1110(1.1077) | Xent 0.0485(0.0509) | Loss 1.1352(1.1331) | Error 0.0150(0.0157) Steps 422(419.05) | Grad Norm 0.2278(0.2279) | Total Time 10.00(10.00)\n",
      "Iter 3371 | Time 30.0423(30.5874) | Bit/dim 1.1105(1.1078) | Xent 0.0543(0.0510) | Loss 1.1376(1.1332) | Error 0.0159(0.0157) Steps 422(419.13) | Grad Norm 0.2073(0.2273) | Total Time 10.00(10.00)\n",
      "Iter 3372 | Time 30.7993(30.5937) | Bit/dim 1.1121(1.1079) | Xent 0.0501(0.0509) | Loss 1.1372(1.1334) | Error 0.0148(0.0157) Steps 416(419.04) | Grad Norm 0.1936(0.2263) | Total Time 10.00(10.00)\n",
      "Iter 3373 | Time 31.1724(30.6111) | Bit/dim 1.1066(1.1078) | Xent 0.0559(0.0511) | Loss 1.1345(1.1334) | Error 0.0175(0.0157) Steps 422(419.13) | Grad Norm 0.2187(0.2261) | Total Time 10.00(10.00)\n",
      "Iter 3374 | Time 30.7869(30.6164) | Bit/dim 1.1025(1.1077) | Xent 0.0514(0.0511) | Loss 1.1282(1.1332) | Error 0.0151(0.0157) Steps 422(419.21) | Grad Norm 0.2589(0.2271) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0482 | Time 16.6610, Epoch Time 243.6489(241.1714), Bit/dim 1.1028(best: 1.1017), Xent 0.0316, Loss 1.1186, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3375 | Time 30.2510(30.6054) | Bit/dim 1.1093(1.1077) | Xent 0.0531(0.0512) | Loss 1.1358(1.1333) | Error 0.0176(0.0158) Steps 416(419.12) | Grad Norm 0.2575(0.2280) | Total Time 10.00(10.00)\n",
      "Iter 3376 | Time 29.9498(30.5857) | Bit/dim 1.1069(1.1077) | Xent 0.0512(0.0512) | Loss 1.1325(1.1333) | Error 0.0164(0.0158) Steps 422(419.20) | Grad Norm 0.2677(0.2292) | Total Time 10.00(10.00)\n",
      "Iter 3377 | Time 30.1225(30.5718) | Bit/dim 1.1055(1.1076) | Xent 0.0528(0.0512) | Loss 1.1319(1.1332) | Error 0.0149(0.0157) Steps 422(419.29) | Grad Norm 0.3854(0.2339) | Total Time 10.00(10.00)\n",
      "Iter 3378 | Time 30.6309(30.5736) | Bit/dim 1.1101(1.1077) | Xent 0.0500(0.0512) | Loss 1.1352(1.1333) | Error 0.0152(0.0157) Steps 422(419.37) | Grad Norm 0.1647(0.2318) | Total Time 10.00(10.00)\n",
      "Iter 3379 | Time 31.4837(30.6009) | Bit/dim 1.1140(1.1079) | Xent 0.0565(0.0513) | Loss 1.1422(1.1336) | Error 0.0175(0.0158) Steps 422(419.45) | Grad Norm 0.3037(0.2339) | Total Time 10.00(10.00)\n",
      "Iter 3380 | Time 30.6753(30.6031) | Bit/dim 1.1016(1.1077) | Xent 0.0529(0.0514) | Loss 1.1281(1.1334) | Error 0.0159(0.0158) Steps 422(419.53) | Grad Norm 0.2497(0.2344) | Total Time 10.00(10.00)\n",
      "Iter 3381 | Time 30.6846(30.6056) | Bit/dim 1.1059(1.1077) | Xent 0.0464(0.0512) | Loss 1.1292(1.1333) | Error 0.0146(0.0158) Steps 422(419.60) | Grad Norm 0.2956(0.2363) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0483 | Time 16.3256, Epoch Time 242.4396(241.2094), Bit/dim 1.1018(best: 1.1017), Xent 0.0319, Loss 1.1177, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3382 | Time 30.1361(30.5915) | Bit/dim 1.1095(1.1077) | Xent 0.0539(0.0513) | Loss 1.1364(1.1334) | Error 0.0179(0.0158) Steps 422(419.67) | Grad Norm 0.3320(0.2391) | Total Time 10.00(10.00)\n",
      "Iter 3383 | Time 30.1245(30.5775) | Bit/dim 1.1091(1.1078) | Xent 0.0473(0.0512) | Loss 1.1328(1.1334) | Error 0.0134(0.0157) Steps 422(419.74) | Grad Norm 0.3745(0.2432) | Total Time 10.00(10.00)\n",
      "Iter 3384 | Time 30.0079(30.5604) | Bit/dim 1.1056(1.1077) | Xent 0.0557(0.0513) | Loss 1.1334(1.1334) | Error 0.0186(0.0158) Steps 416(419.63) | Grad Norm 0.4132(0.2483) | Total Time 10.00(10.00)\n",
      "Iter 3385 | Time 31.0859(30.5762) | Bit/dim 1.1102(1.1078) | Xent 0.0498(0.0513) | Loss 1.1351(1.1334) | Error 0.0142(0.0158) Steps 422(419.70) | Grad Norm 0.2854(0.2494) | Total Time 10.00(10.00)\n",
      "Iter 3386 | Time 30.4805(30.5733) | Bit/dim 1.1081(1.1078) | Xent 0.0530(0.0513) | Loss 1.1346(1.1334) | Error 0.0139(0.0157) Steps 422(419.77) | Grad Norm 0.2162(0.2484) | Total Time 10.00(10.00)\n",
      "Iter 3387 | Time 29.7282(30.5479) | Bit/dim 1.1037(1.1077) | Xent 0.0521(0.0513) | Loss 1.1297(1.1333) | Error 0.0148(0.0157) Steps 422(419.84) | Grad Norm 0.1484(0.2454) | Total Time 10.00(10.00)\n",
      "Iter 3388 | Time 30.6904(30.5522) | Bit/dim 1.1090(1.1077) | Xent 0.0538(0.0514) | Loss 1.1359(1.1334) | Error 0.0169(0.0157) Steps 422(419.90) | Grad Norm 0.5221(0.2537) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0484 | Time 16.4191, Epoch Time 240.8206(241.1978), Bit/dim 1.1022(best: 1.1017), Xent 0.0305, Loss 1.1175, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3389 | Time 30.8215(30.5603) | Bit/dim 1.1053(1.1076) | Xent 0.0425(0.0512) | Loss 1.1266(1.1332) | Error 0.0132(0.0157) Steps 422(419.96) | Grad Norm 0.2353(0.2532) | Total Time 10.00(10.00)\n",
      "Iter 3390 | Time 30.6318(30.5624) | Bit/dim 1.1077(1.1076) | Xent 0.0509(0.0511) | Loss 1.1332(1.1332) | Error 0.0156(0.0157) Steps 416(419.85) | Grad Norm 0.2097(0.2519) | Total Time 10.00(10.00)\n",
      "Iter 3391 | Time 30.5650(30.5625) | Bit/dim 1.1091(1.1077) | Xent 0.0520(0.0512) | Loss 1.1351(1.1333) | Error 0.0164(0.0157) Steps 416(419.73) | Grad Norm 0.1435(0.2486) | Total Time 10.00(10.00)\n",
      "Iter 3392 | Time 30.3243(30.5554) | Bit/dim 1.1047(1.1076) | Xent 0.0469(0.0510) | Loss 1.1281(1.1331) | Error 0.0146(0.0156) Steps 416(419.62) | Grad Norm 0.4852(0.2557) | Total Time 10.00(10.00)\n",
      "Iter 3393 | Time 30.5936(30.5565) | Bit/dim 1.1100(1.1077) | Xent 0.0593(0.0513) | Loss 1.1396(1.1333) | Error 0.0179(0.0157) Steps 416(419.51) | Grad Norm 0.2140(0.2544) | Total Time 10.00(10.00)\n",
      "Iter 3394 | Time 30.0947(30.5427) | Bit/dim 1.1066(1.1076) | Xent 0.0498(0.0512) | Loss 1.1315(1.1332) | Error 0.0139(0.0157) Steps 416(419.40) | Grad Norm 0.1999(0.2528) | Total Time 10.00(10.00)\n",
      "Iter 3395 | Time 30.1927(30.5322) | Bit/dim 1.1074(1.1076) | Xent 0.0508(0.0512) | Loss 1.1327(1.1332) | Error 0.0164(0.0157) Steps 416(419.30) | Grad Norm 0.4042(0.2574) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0485 | Time 16.4426, Epoch Time 242.0305(241.2227), Bit/dim 1.1016(best: 1.1017), Xent 0.0309, Loss 1.1171, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3396 | Time 30.6506(30.5357) | Bit/dim 1.1052(1.1075) | Xent 0.0503(0.0512) | Loss 1.1303(1.1331) | Error 0.0142(0.0156) Steps 422(419.38) | Grad Norm 0.3052(0.2588) | Total Time 10.00(10.00)\n",
      "Iter 3397 | Time 30.2207(30.5263) | Bit/dim 1.1066(1.1075) | Xent 0.0550(0.0513) | Loss 1.1341(1.1332) | Error 0.0155(0.0156) Steps 428(419.64) | Grad Norm 0.1430(0.2553) | Total Time 10.00(10.00)\n",
      "Iter 3398 | Time 29.9376(30.5086) | Bit/dim 1.1079(1.1075) | Xent 0.0545(0.0514) | Loss 1.1352(1.1332) | Error 0.0152(0.0156) Steps 416(419.53) | Grad Norm 0.1789(0.2530) | Total Time 10.00(10.00)\n",
      "Iter 3399 | Time 30.4780(30.5077) | Bit/dim 1.1080(1.1075) | Xent 0.0546(0.0515) | Loss 1.1353(1.1333) | Error 0.0166(0.0157) Steps 416(419.43) | Grad Norm 0.4703(0.2595) | Total Time 10.00(10.00)\n",
      "Iter 3400 | Time 31.7185(30.5440) | Bit/dim 1.1044(1.1074) | Xent 0.0495(0.0515) | Loss 1.1292(1.1332) | Error 0.0172(0.0157) Steps 422(419.50) | Grad Norm 0.2785(0.2601) | Total Time 10.00(10.00)\n",
      "Iter 3401 | Time 30.3606(30.5385) | Bit/dim 1.1123(1.1076) | Xent 0.0447(0.0513) | Loss 1.1346(1.1332) | Error 0.0135(0.0156) Steps 422(419.58) | Grad Norm 0.2460(0.2597) | Total Time 10.00(10.00)\n",
      "Iter 3402 | Time 30.0801(30.5248) | Bit/dim 1.1076(1.1076) | Xent 0.0513(0.0513) | Loss 1.1333(1.1332) | Error 0.0141(0.0156) Steps 428(419.83) | Grad Norm 0.1998(0.2579) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0486 | Time 16.5912, Epoch Time 242.4973(241.2610), Bit/dim 1.1018(best: 1.1016), Xent 0.0331, Loss 1.1184, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3403 | Time 31.0082(30.5393) | Bit/dim 1.1063(1.1076) | Xent 0.0487(0.0512) | Loss 1.1306(1.1331) | Error 0.0162(0.0156) Steps 422(419.90) | Grad Norm 0.2880(0.2588) | Total Time 10.00(10.00)\n",
      "Iter 3404 | Time 30.1978(30.5290) | Bit/dim 1.1070(1.1075) | Xent 0.0510(0.0512) | Loss 1.1325(1.1331) | Error 0.0144(0.0156) Steps 428(420.14) | Grad Norm 0.1972(0.2569) | Total Time 10.00(10.00)\n",
      "Iter 3405 | Time 30.3457(30.5235) | Bit/dim 1.1069(1.1075) | Xent 0.0493(0.0511) | Loss 1.1315(1.1331) | Error 0.0159(0.0156) Steps 428(420.38) | Grad Norm 0.1556(0.2539) | Total Time 10.00(10.00)\n",
      "Iter 3406 | Time 30.1708(30.5129) | Bit/dim 1.1074(1.1075) | Xent 0.0540(0.0512) | Loss 1.1344(1.1331) | Error 0.0175(0.0156) Steps 422(420.42) | Grad Norm 0.2333(0.2533) | Total Time 10.00(10.00)\n",
      "Iter 3407 | Time 30.9933(30.5274) | Bit/dim 1.1056(1.1075) | Xent 0.0475(0.0511) | Loss 1.1294(1.1330) | Error 0.0156(0.0156) Steps 428(420.65) | Grad Norm 0.2631(0.2536) | Total Time 10.00(10.00)\n",
      "Iter 3408 | Time 30.9388(30.5397) | Bit/dim 1.1077(1.1075) | Xent 0.0521(0.0511) | Loss 1.1338(1.1330) | Error 0.0162(0.0157) Steps 428(420.87) | Grad Norm 0.3856(0.2575) | Total Time 10.00(10.00)\n",
      "Iter 3409 | Time 30.4239(30.5362) | Bit/dim 1.1111(1.1076) | Xent 0.0511(0.0511) | Loss 1.1366(1.1331) | Error 0.0166(0.0157) Steps 422(420.91) | Grad Norm 0.2394(0.2570) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0487 | Time 16.5068, Epoch Time 242.7830(241.3066), Bit/dim 1.1017(best: 1.1016), Xent 0.0322, Loss 1.1178, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3410 | Time 30.5665(30.5371) | Bit/dim 1.1030(1.1074) | Xent 0.0559(0.0513) | Loss 1.1309(1.1331) | Error 0.0162(0.0157) Steps 422(420.94) | Grad Norm 0.2078(0.2555) | Total Time 10.00(10.00)\n",
      "Iter 3411 | Time 30.7751(30.5443) | Bit/dim 1.1039(1.1073) | Xent 0.0459(0.0511) | Loss 1.1269(1.1329) | Error 0.0154(0.0157) Steps 422(420.97) | Grad Norm 0.2326(0.2548) | Total Time 10.00(10.00)\n",
      "Iter 3412 | Time 30.9487(30.5564) | Bit/dim 1.1097(1.1074) | Xent 0.0583(0.0513) | Loss 1.1389(1.1331) | Error 0.0172(0.0157) Steps 428(421.18) | Grad Norm 0.4511(0.2607) | Total Time 10.00(10.00)\n",
      "Iter 3413 | Time 29.9955(30.5396) | Bit/dim 1.1083(1.1074) | Xent 0.0489(0.0512) | Loss 1.1327(1.1331) | Error 0.0144(0.0157) Steps 428(421.39) | Grad Norm 0.3231(0.2626) | Total Time 10.00(10.00)\n",
      "Iter 3414 | Time 30.4031(30.5355) | Bit/dim 1.1080(1.1074) | Xent 0.0481(0.0511) | Loss 1.1320(1.1330) | Error 0.0158(0.0157) Steps 422(421.40) | Grad Norm 0.1966(0.2606) | Total Time 10.00(10.00)\n",
      "Iter 3415 | Time 30.3286(30.5293) | Bit/dim 1.1080(1.1075) | Xent 0.0540(0.0512) | Loss 1.1350(1.1331) | Error 0.0176(0.0158) Steps 422(421.42) | Grad Norm 0.2917(0.2615) | Total Time 10.00(10.00)\n",
      "Iter 3416 | Time 30.4917(30.5281) | Bit/dim 1.1090(1.1075) | Xent 0.0517(0.0512) | Loss 1.1348(1.1331) | Error 0.0164(0.0158) Steps 428(421.62) | Grad Norm 0.4622(0.2676) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0488 | Time 16.3875, Epoch Time 242.2551(241.3351), Bit/dim 1.1016(best: 1.1016), Xent 0.0311, Loss 1.1172, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3417 | Time 31.1725(30.5475) | Bit/dim 1.1105(1.1076) | Xent 0.0562(0.0514) | Loss 1.1386(1.1333) | Error 0.0165(0.0158) Steps 416(421.45) | Grad Norm 0.2230(0.2662) | Total Time 10.00(10.00)\n",
      "Iter 3418 | Time 30.7807(30.5545) | Bit/dim 1.1048(1.1075) | Xent 0.0489(0.0513) | Loss 1.1292(1.1332) | Error 0.0150(0.0158) Steps 422(421.47) | Grad Norm 0.2336(0.2653) | Total Time 10.00(10.00)\n",
      "Iter 3419 | Time 30.3033(30.5469) | Bit/dim 1.1117(1.1076) | Xent 0.0529(0.0514) | Loss 1.1382(1.1333) | Error 0.0161(0.0158) Steps 422(421.48) | Grad Norm 0.2943(0.2661) | Total Time 10.00(10.00)\n",
      "Iter 3420 | Time 30.5554(30.5472) | Bit/dim 1.1032(1.1075) | Xent 0.0481(0.0513) | Loss 1.1272(1.1331) | Error 0.0141(0.0157) Steps 428(421.68) | Grad Norm 0.2183(0.2647) | Total Time 10.00(10.00)\n",
      "Iter 3421 | Time 30.8269(30.5556) | Bit/dim 1.1079(1.1075) | Xent 0.0477(0.0512) | Loss 1.1318(1.1331) | Error 0.0146(0.0157) Steps 416(421.51) | Grad Norm 0.2591(0.2645) | Total Time 10.00(10.00)\n",
      "Iter 3422 | Time 30.6244(30.5576) | Bit/dim 1.1104(1.1076) | Xent 0.0487(0.0511) | Loss 1.1348(1.1332) | Error 0.0156(0.0157) Steps 416(421.34) | Grad Norm 0.1901(0.2623) | Total Time 10.00(10.00)\n",
      "Iter 3423 | Time 30.3282(30.5508) | Bit/dim 1.1072(1.1076) | Xent 0.0549(0.0512) | Loss 1.1347(1.1332) | Error 0.0145(0.0157) Steps 422(421.36) | Grad Norm 0.2162(0.2609) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0489 | Time 16.8212, Epoch Time 243.5622(241.4019), Bit/dim 1.1020(best: 1.1016), Xent 0.0326, Loss 1.1183, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3424 | Time 31.1003(30.5672) | Bit/dim 1.1137(1.1078) | Xent 0.0466(0.0511) | Loss 1.1370(1.1333) | Error 0.0135(0.0156) Steps 416(421.20) | Grad Norm 0.1581(0.2578) | Total Time 10.00(10.00)\n",
      "Iter 3425 | Time 31.4677(30.5943) | Bit/dim 1.1042(1.1077) | Xent 0.0552(0.0512) | Loss 1.1318(1.1333) | Error 0.0166(0.0156) Steps 428(421.41) | Grad Norm 0.3359(0.2602) | Total Time 10.00(10.00)\n",
      "Iter 3426 | Time 29.8906(30.5731) | Bit/dim 1.1069(1.1076) | Xent 0.0527(0.0512) | Loss 1.1333(1.1333) | Error 0.0165(0.0157) Steps 422(421.42) | Grad Norm 0.1639(0.2573) | Total Time 10.00(10.00)\n",
      "Iter 3427 | Time 30.8658(30.5819) | Bit/dim 1.1000(1.1074) | Xent 0.0535(0.0513) | Loss 1.1268(1.1331) | Error 0.0168(0.0157) Steps 422(421.44) | Grad Norm 0.2346(0.2566) | Total Time 10.00(10.00)\n",
      "Iter 3428 | Time 31.3150(30.6039) | Bit/dim 1.1039(1.1073) | Xent 0.0517(0.0513) | Loss 1.1298(1.1330) | Error 0.0146(0.0157) Steps 428(421.64) | Grad Norm 0.3074(0.2581) | Total Time 10.00(10.00)\n",
      "Iter 3429 | Time 30.4211(30.5984) | Bit/dim 1.1101(1.1074) | Xent 0.0534(0.0514) | Loss 1.1368(1.1331) | Error 0.0171(0.0157) Steps 416(421.47) | Grad Norm 0.3366(0.2605) | Total Time 10.00(10.00)\n",
      "Iter 3430 | Time 31.1778(30.6158) | Bit/dim 1.1112(1.1075) | Xent 0.0502(0.0513) | Loss 1.1363(1.1332) | Error 0.0144(0.0157) Steps 422(421.48) | Grad Norm 0.2218(0.2593) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0490 | Time 16.5320, Epoch Time 245.1192(241.5134), Bit/dim 1.1014(best: 1.1016), Xent 0.0317, Loss 1.1172, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3431 | Time 30.0256(30.5981) | Bit/dim 1.1079(1.1075) | Xent 0.0473(0.0512) | Loss 1.1316(1.1331) | Error 0.0142(0.0156) Steps 422(421.50) | Grad Norm 0.2956(0.2604) | Total Time 10.00(10.00)\n",
      "Iter 3432 | Time 30.7240(30.6019) | Bit/dim 1.1058(1.1075) | Xent 0.0551(0.0513) | Loss 1.1334(1.1331) | Error 0.0182(0.0157) Steps 428(421.69) | Grad Norm 0.2289(0.2595) | Total Time 10.00(10.00)\n",
      "Iter 3433 | Time 30.7406(30.6060) | Bit/dim 1.1085(1.1075) | Xent 0.0522(0.0514) | Loss 1.1345(1.1332) | Error 0.0164(0.0157) Steps 416(421.52) | Grad Norm 0.2775(0.2600) | Total Time 10.00(10.00)\n",
      "Iter 3434 | Time 30.3887(30.5995) | Bit/dim 1.1061(1.1075) | Xent 0.0539(0.0514) | Loss 1.1330(1.1332) | Error 0.0170(0.0158) Steps 422(421.54) | Grad Norm 0.4088(0.2645) | Total Time 10.00(10.00)\n",
      "Iter 3435 | Time 32.2080(30.6478) | Bit/dim 1.1053(1.1074) | Xent 0.0461(0.0513) | Loss 1.1283(1.1330) | Error 0.0146(0.0157) Steps 428(421.73) | Grad Norm 0.1858(0.2621) | Total Time 10.00(10.00)\n",
      "Iter 3436 | Time 31.2913(30.6671) | Bit/dim 1.1065(1.1074) | Xent 0.0486(0.0512) | Loss 1.1308(1.1330) | Error 0.0141(0.0157) Steps 422(421.74) | Grad Norm 0.2303(0.2612) | Total Time 10.00(10.00)\n",
      "Iter 3437 | Time 31.0012(30.6771) | Bit/dim 1.1080(1.1074) | Xent 0.0507(0.0512) | Loss 1.1334(1.1330) | Error 0.0144(0.0156) Steps 428(421.93) | Grad Norm 0.2388(0.2605) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0491 | Time 16.8569, Epoch Time 245.2842(241.6265), Bit/dim 1.1020(best: 1.1014), Xent 0.0324, Loss 1.1182, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3438 | Time 30.7172(30.6783) | Bit/dim 1.1092(1.1074) | Xent 0.0466(0.0510) | Loss 1.1325(1.1330) | Error 0.0140(0.0156) Steps 422(421.93) | Grad Norm 0.4111(0.2650) | Total Time 10.00(10.00)\n",
      "Iter 3439 | Time 30.4767(30.6723) | Bit/dim 1.1073(1.1074) | Xent 0.0475(0.0509) | Loss 1.1310(1.1329) | Error 0.0136(0.0155) Steps 422(421.93) | Grad Norm 0.3145(0.2665) | Total Time 10.00(10.00)\n",
      "Iter 3440 | Time 30.1823(30.6576) | Bit/dim 1.1065(1.1074) | Xent 0.0506(0.0509) | Loss 1.1318(1.1329) | Error 0.0150(0.0155) Steps 422(421.93) | Grad Norm 0.3511(0.2690) | Total Time 10.00(10.00)\n",
      "Iter 3441 | Time 30.6134(30.6562) | Bit/dim 1.1050(1.1073) | Xent 0.0518(0.0510) | Loss 1.1309(1.1328) | Error 0.0159(0.0155) Steps 422(421.94) | Grad Norm 0.3710(0.2721) | Total Time 10.00(10.00)\n",
      "Iter 3442 | Time 30.8226(30.6612) | Bit/dim 1.1075(1.1073) | Xent 0.0518(0.0510) | Loss 1.1334(1.1328) | Error 0.0150(0.0155) Steps 428(422.12) | Grad Norm 0.2994(0.2729) | Total Time 10.00(10.00)\n",
      "Iter 3443 | Time 31.6008(30.6894) | Bit/dim 1.1064(1.1073) | Xent 0.0491(0.0509) | Loss 1.1310(1.1328) | Error 0.0165(0.0155) Steps 428(422.29) | Grad Norm 0.3079(0.2740) | Total Time 10.00(10.00)\n",
      "Iter 3444 | Time 30.6314(30.6877) | Bit/dim 1.1094(1.1074) | Xent 0.0488(0.0509) | Loss 1.1338(1.1328) | Error 0.0154(0.0155) Steps 428(422.47) | Grad Norm 0.2574(0.2735) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0492 | Time 16.9165, Epoch Time 244.0659(241.6997), Bit/dim 1.1012(best: 1.1014), Xent 0.0316, Loss 1.1170, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3445 | Time 30.4954(30.6819) | Bit/dim 1.1124(1.1075) | Xent 0.0518(0.0509) | Loss 1.1383(1.1330) | Error 0.0144(0.0155) Steps 422(422.45) | Grad Norm 0.4659(0.2792) | Total Time 10.00(10.00)\n",
      "Iter 3446 | Time 30.7549(30.6841) | Bit/dim 1.1096(1.1076) | Xent 0.0453(0.0507) | Loss 1.1322(1.1329) | Error 0.0125(0.0154) Steps 428(422.62) | Grad Norm 0.1939(0.2767) | Total Time 10.00(10.00)\n",
      "Iter 3447 | Time 32.5295(30.7395) | Bit/dim 1.1053(1.1075) | Xent 0.0509(0.0507) | Loss 1.1307(1.1329) | Error 0.0160(0.0154) Steps 422(422.60) | Grad Norm 0.1436(0.2727) | Total Time 10.00(10.00)\n",
      "Iter 3448 | Time 31.3066(30.7565) | Bit/dim 1.1065(1.1075) | Xent 0.0499(0.0507) | Loss 1.1314(1.1328) | Error 0.0161(0.0154) Steps 428(422.76) | Grad Norm 0.3404(0.2747) | Total Time 10.00(10.00)\n",
      "Iter 3449 | Time 30.3670(30.7448) | Bit/dim 1.1099(1.1076) | Xent 0.0592(0.0510) | Loss 1.1394(1.1330) | Error 0.0192(0.0156) Steps 422(422.74) | Grad Norm 0.1783(0.2718) | Total Time 10.00(10.00)\n",
      "Iter 3450 | Time 30.8613(30.7483) | Bit/dim 1.1051(1.1075) | Xent 0.0474(0.0508) | Loss 1.1287(1.1329) | Error 0.0154(0.0156) Steps 428(422.90) | Grad Norm 0.2925(0.2724) | Total Time 10.00(10.00)\n",
      "Iter 3451 | Time 31.5455(30.7722) | Bit/dim 1.1020(1.1073) | Xent 0.0466(0.0507) | Loss 1.1252(1.1327) | Error 0.0129(0.0155) Steps 422(422.87) | Grad Norm 0.1986(0.2702) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0493 | Time 16.8215, Epoch Time 246.8932(241.8555), Bit/dim 1.1017(best: 1.1012), Xent 0.0318, Loss 1.1176, Error 0.0109(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3452 | Time 30.9811(30.7785) | Bit/dim 1.1035(1.1072) | Xent 0.0496(0.0507) | Loss 1.1283(1.1325) | Error 0.0150(0.0155) Steps 428(423.02) | Grad Norm 0.3028(0.2712) | Total Time 10.00(10.00)\n",
      "Iter 3453 | Time 30.8931(30.7819) | Bit/dim 1.1079(1.1072) | Xent 0.0580(0.0509) | Loss 1.1369(1.1327) | Error 0.0180(0.0155) Steps 422(422.99) | Grad Norm 0.4356(0.2761) | Total Time 10.00(10.00)\n",
      "Iter 3454 | Time 30.7974(30.7824) | Bit/dim 1.1060(1.1072) | Xent 0.0494(0.0509) | Loss 1.1306(1.1326) | Error 0.0141(0.0155) Steps 422(422.96) | Grad Norm 0.2042(0.2740) | Total Time 10.00(10.00)\n",
      "Iter 3455 | Time 30.9820(30.7884) | Bit/dim 1.1111(1.1073) | Xent 0.0551(0.0510) | Loss 1.1387(1.1328) | Error 0.0162(0.0155) Steps 428(423.11) | Grad Norm 0.2928(0.2745) | Total Time 10.00(10.00)\n",
      "Iter 3456 | Time 31.2366(30.8018) | Bit/dim 1.1065(1.1073) | Xent 0.0519(0.0510) | Loss 1.1324(1.1328) | Error 0.0162(0.0155) Steps 428(423.26) | Grad Norm 0.3723(0.2775) | Total Time 10.00(10.00)\n",
      "Iter 3457 | Time 30.4101(30.7901) | Bit/dim 1.1076(1.1073) | Xent 0.0498(0.0510) | Loss 1.1325(1.1328) | Error 0.0146(0.0155) Steps 422(423.22) | Grad Norm 0.2686(0.2772) | Total Time 10.00(10.00)\n",
      "Iter 3458 | Time 30.3832(30.7779) | Bit/dim 1.1072(1.1073) | Xent 0.0486(0.0509) | Loss 1.1315(1.1327) | Error 0.0162(0.0155) Steps 428(423.37) | Grad Norm 0.2303(0.2758) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0494 | Time 16.7174, Epoch Time 244.6601(241.9397), Bit/dim 1.1020(best: 1.1012), Xent 0.0337, Loss 1.1188, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3459 | Time 30.9056(30.7817) | Bit/dim 1.1076(1.1073) | Xent 0.0501(0.0509) | Loss 1.1326(1.1327) | Error 0.0161(0.0156) Steps 428(423.51) | Grad Norm 0.1895(0.2732) | Total Time 10.00(10.00)\n",
      "Iter 3460 | Time 30.9970(30.7881) | Bit/dim 1.1073(1.1073) | Xent 0.0464(0.0507) | Loss 1.1305(1.1327) | Error 0.0114(0.0154) Steps 428(423.64) | Grad Norm 0.1268(0.2688) | Total Time 10.00(10.00)\n",
      "Iter 3461 | Time 30.3849(30.7760) | Bit/dim 1.1056(1.1072) | Xent 0.0551(0.0509) | Loss 1.1331(1.1327) | Error 0.0166(0.0155) Steps 428(423.77) | Grad Norm 0.2951(0.2696) | Total Time 10.00(10.00)\n",
      "Iter 3462 | Time 31.4169(30.7953) | Bit/dim 1.1079(1.1073) | Xent 0.0535(0.0510) | Loss 1.1347(1.1327) | Error 0.0164(0.0155) Steps 428(423.90) | Grad Norm 0.2374(0.2686) | Total Time 10.00(10.00)\n",
      "Iter 3463 | Time 32.0625(30.8333) | Bit/dim 1.1083(1.1073) | Xent 0.0462(0.0508) | Loss 1.1314(1.1327) | Error 0.0141(0.0154) Steps 428(424.02) | Grad Norm 0.2638(0.2685) | Total Time 10.00(10.00)\n",
      "Iter 3464 | Time 30.3463(30.8187) | Bit/dim 1.1077(1.1073) | Xent 0.0557(0.0510) | Loss 1.1356(1.1328) | Error 0.0148(0.0154) Steps 422(423.96) | Grad Norm 0.4418(0.2737) | Total Time 10.00(10.00)\n",
      "Iter 3465 | Time 31.0518(30.8257) | Bit/dim 1.1045(1.1072) | Xent 0.0500(0.0509) | Loss 1.1295(1.1327) | Error 0.0165(0.0155) Steps 428(424.08) | Grad Norm 0.1531(0.2701) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0495 | Time 16.7859, Epoch Time 246.5428(242.0778), Bit/dim 1.1016(best: 1.1012), Xent 0.0317, Loss 1.1175, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3466 | Time 30.5531(30.8175) | Bit/dim 1.1088(1.1073) | Xent 0.0502(0.0509) | Loss 1.1340(1.1327) | Error 0.0160(0.0155) Steps 428(424.20) | Grad Norm 0.3458(0.2723) | Total Time 10.00(10.00)\n",
      "Iter 3467 | Time 31.0141(30.8234) | Bit/dim 1.1103(1.1074) | Xent 0.0540(0.0510) | Loss 1.1373(1.1329) | Error 0.0162(0.0155) Steps 428(424.31) | Grad Norm 0.2404(0.2714) | Total Time 10.00(10.00)\n",
      "Iter 3468 | Time 30.5360(30.8148) | Bit/dim 1.1057(1.1073) | Xent 0.0514(0.0510) | Loss 1.1313(1.1328) | Error 0.0141(0.0155) Steps 428(424.42) | Grad Norm 0.3381(0.2734) | Total Time 10.00(10.00)\n",
      "Iter 3469 | Time 30.2137(30.7967) | Bit/dim 1.1071(1.1073) | Xent 0.0461(0.0509) | Loss 1.1302(1.1327) | Error 0.0146(0.0154) Steps 428(424.53) | Grad Norm 0.4189(0.2778) | Total Time 10.00(10.00)\n",
      "Iter 3470 | Time 31.5954(30.8207) | Bit/dim 1.1052(1.1072) | Xent 0.0586(0.0511) | Loss 1.1345(1.1328) | Error 0.0198(0.0156) Steps 428(424.64) | Grad Norm 0.2161(0.2759) | Total Time 10.00(10.00)\n",
      "Iter 3471 | Time 31.5908(30.8438) | Bit/dim 1.1090(1.1073) | Xent 0.0484(0.0510) | Loss 1.1332(1.1328) | Error 0.0161(0.0156) Steps 422(424.56) | Grad Norm 0.3490(0.2781) | Total Time 10.00(10.00)\n",
      "Iter 3472 | Time 30.3044(30.8276) | Bit/dim 1.1073(1.1073) | Xent 0.0485(0.0509) | Loss 1.1316(1.1328) | Error 0.0134(0.0155) Steps 428(424.66) | Grad Norm 0.4735(0.2840) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0496 | Time 16.8044, Epoch Time 244.8032(242.1595), Bit/dim 1.1010(best: 1.1012), Xent 0.0317, Loss 1.1168, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3473 | Time 30.9634(30.8317) | Bit/dim 1.1055(1.1072) | Xent 0.0523(0.0510) | Loss 1.1316(1.1327) | Error 0.0151(0.0155) Steps 422(424.58) | Grad Norm 0.1708(0.2806) | Total Time 10.00(10.00)\n",
      "Iter 3474 | Time 31.8972(30.8637) | Bit/dim 1.1082(1.1073) | Xent 0.0525(0.0510) | Loss 1.1344(1.1328) | Error 0.0160(0.0155) Steps 428(424.68) | Grad Norm 0.2567(0.2798) | Total Time 10.00(10.00)\n",
      "Iter 3475 | Time 32.1179(30.9013) | Bit/dim 1.1101(1.1074) | Xent 0.0510(0.0510) | Loss 1.1356(1.1329) | Error 0.0162(0.0155) Steps 428(424.78) | Grad Norm 0.3157(0.2809) | Total Time 10.00(10.00)\n",
      "Iter 3476 | Time 30.8337(30.8993) | Bit/dim 1.1040(1.1073) | Xent 0.0450(0.0508) | Loss 1.1265(1.1327) | Error 0.0145(0.0155) Steps 422(424.70) | Grad Norm 0.4320(0.2855) | Total Time 10.00(10.00)\n",
      "Iter 3477 | Time 30.3482(30.8827) | Bit/dim 1.1089(1.1073) | Xent 0.0480(0.0508) | Loss 1.1329(1.1327) | Error 0.0148(0.0155) Steps 428(424.80) | Grad Norm 0.1561(0.2816) | Total Time 10.00(10.00)\n",
      "Iter 3478 | Time 30.4337(30.8693) | Bit/dim 1.1076(1.1073) | Xent 0.0566(0.0509) | Loss 1.1359(1.1328) | Error 0.0159(0.0155) Steps 428(424.89) | Grad Norm 0.2273(0.2799) | Total Time 10.00(10.00)\n",
      "Iter 3479 | Time 30.3652(30.8541) | Bit/dim 1.1056(1.1073) | Xent 0.0500(0.0509) | Loss 1.1306(1.1327) | Error 0.0149(0.0155) Steps 422(424.81) | Grad Norm 0.2282(0.2784) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0497 | Time 16.7419, Epoch Time 246.2314(242.2817), Bit/dim 1.1013(best: 1.1010), Xent 0.0326, Loss 1.1175, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3480 | Time 30.2436(30.8358) | Bit/dim 1.1031(1.1071) | Xent 0.0433(0.0507) | Loss 1.1248(1.1325) | Error 0.0138(0.0154) Steps 428(424.90) | Grad Norm 0.3496(0.2805) | Total Time 10.00(10.00)\n",
      "Iter 3481 | Time 30.4502(30.8242) | Bit/dim 1.1046(1.1071) | Xent 0.0489(0.0506) | Loss 1.1290(1.1324) | Error 0.0165(0.0155) Steps 428(425.00) | Grad Norm 0.2001(0.2781) | Total Time 10.00(10.00)\n",
      "Iter 3482 | Time 32.3293(30.8694) | Bit/dim 1.1049(1.1070) | Xent 0.0518(0.0507) | Loss 1.1308(1.1323) | Error 0.0155(0.0155) Steps 428(425.09) | Grad Norm 0.2809(0.2782) | Total Time 10.00(10.00)\n",
      "Iter 3483 | Time 31.5905(30.8910) | Bit/dim 1.1127(1.1072) | Xent 0.0512(0.0507) | Loss 1.1383(1.1325) | Error 0.0168(0.0155) Steps 428(425.17) | Grad Norm 0.3896(0.2815) | Total Time 10.00(10.00)\n",
      "Iter 3484 | Time 31.1715(30.8994) | Bit/dim 1.1091(1.1072) | Xent 0.0554(0.0508) | Loss 1.1368(1.1326) | Error 0.0170(0.0155) Steps 428(425.26) | Grad Norm 0.1510(0.2776) | Total Time 10.00(10.00)\n",
      "Iter 3485 | Time 31.1281(30.9063) | Bit/dim 1.1071(1.1072) | Xent 0.0540(0.0509) | Loss 1.1340(1.1327) | Error 0.0171(0.0156) Steps 422(425.16) | Grad Norm 0.3018(0.2784) | Total Time 10.00(10.00)\n",
      "Iter 3486 | Time 30.8388(30.9043) | Bit/dim 1.1099(1.1073) | Xent 0.0487(0.0509) | Loss 1.1342(1.1327) | Error 0.0146(0.0156) Steps 428(425.25) | Grad Norm 0.2753(0.2783) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0498 | Time 16.7099, Epoch Time 246.8217(242.4179), Bit/dim 1.1011(best: 1.1010), Xent 0.0319, Loss 1.1171, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3487 | Time 32.2852(30.9457) | Bit/dim 1.1069(1.1073) | Xent 0.0514(0.0509) | Loss 1.1326(1.1327) | Error 0.0159(0.0156) Steps 422(425.15) | Grad Norm 0.2602(0.2777) | Total Time 10.00(10.00)\n",
      "Iter 3488 | Time 30.0656(30.9193) | Bit/dim 1.1052(1.1072) | Xent 0.0466(0.0507) | Loss 1.1285(1.1326) | Error 0.0145(0.0155) Steps 428(425.23) | Grad Norm 0.2447(0.2767) | Total Time 10.00(10.00)\n",
      "Iter 3489 | Time 30.5810(30.9092) | Bit/dim 1.1119(1.1074) | Xent 0.0496(0.0507) | Loss 1.1367(1.1327) | Error 0.0154(0.0155) Steps 428(425.32) | Grad Norm 0.2575(0.2762) | Total Time 10.00(10.00)\n",
      "Iter 3490 | Time 31.2367(30.9190) | Bit/dim 1.1071(1.1074) | Xent 0.0543(0.0508) | Loss 1.1343(1.1328) | Error 0.0169(0.0156) Steps 428(425.40) | Grad Norm 0.2736(0.2761) | Total Time 10.00(10.00)\n",
      "Iter 3491 | Time 30.7949(30.9153) | Bit/dim 1.1100(1.1074) | Xent 0.0538(0.0509) | Loss 1.1369(1.1329) | Error 0.0148(0.0155) Steps 428(425.47) | Grad Norm 0.1599(0.2726) | Total Time 10.00(10.00)\n",
      "Iter 3492 | Time 30.9284(30.9157) | Bit/dim 1.1083(1.1075) | Xent 0.0497(0.0509) | Loss 1.1332(1.1329) | Error 0.0148(0.0155) Steps 428(425.55) | Grad Norm 0.2251(0.2712) | Total Time 10.00(10.00)\n",
      "Iter 3493 | Time 30.1264(30.8920) | Bit/dim 1.1026(1.1073) | Xent 0.0516(0.0509) | Loss 1.1284(1.1328) | Error 0.0142(0.0155) Steps 422(425.44) | Grad Norm 0.2531(0.2706) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0499 | Time 16.9145, Epoch Time 245.2690(242.5034), Bit/dim 1.1011(best: 1.1010), Xent 0.0324, Loss 1.1174, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3494 | Time 31.0386(30.8964) | Bit/dim 1.1059(1.1073) | Xent 0.0480(0.0508) | Loss 1.1299(1.1327) | Error 0.0155(0.0155) Steps 428(425.52) | Grad Norm 0.1810(0.2679) | Total Time 10.00(10.00)\n",
      "Iter 3495 | Time 30.1764(30.8748) | Bit/dim 1.1045(1.1072) | Xent 0.0512(0.0508) | Loss 1.1301(1.1326) | Error 0.0156(0.0155) Steps 428(425.60) | Grad Norm 0.2905(0.2686) | Total Time 10.00(10.00)\n",
      "Iter 3496 | Time 30.9406(30.8768) | Bit/dim 1.1083(1.1072) | Xent 0.0469(0.0507) | Loss 1.1318(1.1326) | Error 0.0155(0.0155) Steps 428(425.67) | Grad Norm 0.2720(0.2687) | Total Time 10.00(10.00)\n",
      "Iter 3497 | Time 30.7985(30.8744) | Bit/dim 1.1033(1.1071) | Xent 0.0573(0.0509) | Loss 1.1320(1.1326) | Error 0.0175(0.0156) Steps 422(425.56) | Grad Norm 0.2002(0.2667) | Total Time 10.00(10.00)\n",
      "Iter 3498 | Time 30.8864(30.8748) | Bit/dim 1.1057(1.1071) | Xent 0.0540(0.0510) | Loss 1.1327(1.1326) | Error 0.0159(0.0156) Steps 428(425.63) | Grad Norm 0.2763(0.2669) | Total Time 10.00(10.00)\n",
      "Iter 3499 | Time 30.8931(30.8753) | Bit/dim 1.1101(1.1072) | Xent 0.0559(0.0511) | Loss 1.1380(1.1327) | Error 0.0184(0.0156) Steps 428(425.70) | Grad Norm 0.3169(0.2684) | Total Time 10.00(10.00)\n",
      "Iter 3500 | Time 30.9027(30.8761) | Bit/dim 1.1105(1.1073) | Xent 0.0542(0.0512) | Loss 1.1375(1.1329) | Error 0.0159(0.0157) Steps 428(425.77) | Grad Norm 0.3072(0.2696) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0500 | Time 16.7382, Epoch Time 244.8548(242.5740), Bit/dim 1.1015(best: 1.1010), Xent 0.0328, Loss 1.1179, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3501 | Time 30.5024(30.8649) | Bit/dim 1.1090(1.1073) | Xent 0.0482(0.0511) | Loss 1.1331(1.1329) | Error 0.0145(0.0156) Steps 428(425.84) | Grad Norm 0.1419(0.2658) | Total Time 10.00(10.00)\n",
      "Iter 3502 | Time 30.4979(30.8539) | Bit/dim 1.1081(1.1073) | Xent 0.0526(0.0512) | Loss 1.1344(1.1329) | Error 0.0166(0.0156) Steps 428(425.90) | Grad Norm 0.3537(0.2684) | Total Time 10.00(10.00)\n",
      "Iter 3503 | Time 30.9687(30.8574) | Bit/dim 1.1040(1.1072) | Xent 0.0498(0.0511) | Loss 1.1289(1.1328) | Error 0.0159(0.0157) Steps 428(425.97) | Grad Norm 0.3032(0.2695) | Total Time 10.00(10.00)\n",
      "Iter 3504 | Time 32.0727(30.8938) | Bit/dim 1.1055(1.1072) | Xent 0.0499(0.0511) | Loss 1.1304(1.1327) | Error 0.0145(0.0156) Steps 428(426.03) | Grad Norm 0.1832(0.2669) | Total Time 10.00(10.00)\n",
      "Iter 3505 | Time 30.7496(30.8895) | Bit/dim 1.1032(1.1071) | Xent 0.0500(0.0511) | Loss 1.1282(1.1326) | Error 0.0150(0.0156) Steps 428(426.09) | Grad Norm 0.1760(0.2641) | Total Time 10.00(10.00)\n",
      "Iter 3506 | Time 30.5488(30.8793) | Bit/dim 1.1113(1.1072) | Xent 0.0532(0.0511) | Loss 1.1379(1.1328) | Error 0.0179(0.0157) Steps 422(425.96) | Grad Norm 0.2368(0.2633) | Total Time 10.00(10.00)\n",
      "Iter 3507 | Time 30.5019(30.8679) | Bit/dim 1.1073(1.1072) | Xent 0.0547(0.0512) | Loss 1.1346(1.1328) | Error 0.0150(0.0157) Steps 428(426.02) | Grad Norm 0.2989(0.2644) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0501 | Time 17.0021, Epoch Time 244.9988(242.6467), Bit/dim 1.1011(best: 1.1010), Xent 0.0297, Loss 1.1160, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3508 | Time 30.4730(30.8561) | Bit/dim 1.1021(1.1070) | Xent 0.0479(0.0511) | Loss 1.1260(1.1326) | Error 0.0155(0.0156) Steps 428(426.08) | Grad Norm 0.2231(0.2632) | Total Time 10.00(10.00)\n",
      "Iter 3509 | Time 30.4147(30.8429) | Bit/dim 1.1088(1.1071) | Xent 0.0561(0.0513) | Loss 1.1368(1.1327) | Error 0.0171(0.0157) Steps 428(426.14) | Grad Norm 0.2643(0.2632) | Total Time 10.00(10.00)\n",
      "Iter 3510 | Time 31.8469(30.8730) | Bit/dim 1.1046(1.1070) | Xent 0.0515(0.0513) | Loss 1.1303(1.1327) | Error 0.0161(0.0157) Steps 428(426.20) | Grad Norm 0.3977(0.2672) | Total Time 10.00(10.00)\n",
      "Iter 3511 | Time 30.5837(30.8643) | Bit/dim 1.1045(1.1069) | Xent 0.0549(0.0514) | Loss 1.1320(1.1326) | Error 0.0158(0.0157) Steps 428(426.25) | Grad Norm 0.2285(0.2661) | Total Time 10.00(10.00)\n",
      "Iter 3512 | Time 31.3972(30.8803) | Bit/dim 1.1085(1.1070) | Xent 0.0488(0.0513) | Loss 1.1329(1.1326) | Error 0.0158(0.0157) Steps 422(426.12) | Grad Norm 0.2863(0.2667) | Total Time 10.00(10.00)\n",
      "Iter 3513 | Time 31.5663(30.9009) | Bit/dim 1.1119(1.1071) | Xent 0.0531(0.0514) | Loss 1.1385(1.1328) | Error 0.0164(0.0157) Steps 428(426.18) | Grad Norm 0.1639(0.2636) | Total Time 10.00(10.00)\n",
      "Iter 3514 | Time 30.3088(30.8831) | Bit/dim 1.1081(1.1072) | Xent 0.0444(0.0512) | Loss 1.1303(1.1327) | Error 0.0138(0.0157) Steps 422(426.05) | Grad Norm 0.2363(0.2628) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0502 | Time 16.4766, Epoch Time 245.3802(242.7287), Bit/dim 1.1013(best: 1.1010), Xent 0.0309, Loss 1.1167, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3515 | Time 30.8256(30.8814) | Bit/dim 1.1058(1.1071) | Xent 0.0434(0.0509) | Loss 1.1275(1.1326) | Error 0.0129(0.0156) Steps 422(425.93) | Grad Norm 0.1474(0.2593) | Total Time 10.00(10.00)\n",
      "Iter 3516 | Time 30.2403(30.8621) | Bit/dim 1.1115(1.1073) | Xent 0.0516(0.0510) | Loss 1.1373(1.1327) | Error 0.0145(0.0156) Steps 428(425.99) | Grad Norm 0.2841(0.2600) | Total Time 10.00(10.00)\n",
      "Iter 3517 | Time 30.5876(30.8539) | Bit/dim 1.1088(1.1073) | Xent 0.0522(0.0510) | Loss 1.1348(1.1328) | Error 0.0155(0.0155) Steps 428(426.05) | Grad Norm 0.1703(0.2574) | Total Time 10.00(10.00)\n",
      "Iter 3518 | Time 30.8188(30.8529) | Bit/dim 1.1077(1.1073) | Xent 0.0517(0.0510) | Loss 1.1336(1.1328) | Error 0.0156(0.0156) Steps 428(426.11) | Grad Norm 0.2739(0.2579) | Total Time 10.00(10.00)\n",
      "Iter 3519 | Time 32.0157(30.8877) | Bit/dim 1.1055(1.1073) | Xent 0.0484(0.0509) | Loss 1.1297(1.1327) | Error 0.0155(0.0155) Steps 428(426.17) | Grad Norm 0.3864(0.2617) | Total Time 10.00(10.00)\n",
      "Iter 3520 | Time 30.6393(30.8803) | Bit/dim 1.1035(1.1071) | Xent 0.0482(0.0509) | Loss 1.1276(1.1326) | Error 0.0142(0.0155) Steps 422(426.04) | Grad Norm 0.3223(0.2635) | Total Time 10.00(10.00)\n",
      "Iter 3521 | Time 30.5611(30.8707) | Bit/dim 1.1035(1.1070) | Xent 0.0597(0.0511) | Loss 1.1333(1.1326) | Error 0.0186(0.0156) Steps 428(426.10) | Grad Norm 0.2536(0.2632) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0503 | Time 17.0330, Epoch Time 245.0611(242.7987), Bit/dim 1.1018(best: 1.1010), Xent 0.0317, Loss 1.1176, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3522 | Time 30.7778(30.8679) | Bit/dim 1.1016(1.1069) | Xent 0.0527(0.0512) | Loss 1.1279(1.1325) | Error 0.0154(0.0156) Steps 428(426.16) | Grad Norm 0.1936(0.2611) | Total Time 10.00(10.00)\n",
      "Iter 3523 | Time 30.7481(30.8643) | Bit/dim 1.1072(1.1069) | Xent 0.0468(0.0510) | Loss 1.1306(1.1324) | Error 0.0141(0.0156) Steps 428(426.22) | Grad Norm 0.2282(0.2602) | Total Time 10.00(10.00)\n",
      "Iter 3524 | Time 30.2670(30.8464) | Bit/dim 1.1118(1.1070) | Xent 0.0510(0.0510) | Loss 1.1373(1.1325) | Error 0.0155(0.0156) Steps 428(426.27) | Grad Norm 0.1890(0.2580) | Total Time 10.00(10.00)\n",
      "Iter 3525 | Time 30.4939(30.8358) | Bit/dim 1.1058(1.1070) | Xent 0.0457(0.0509) | Loss 1.1286(1.1324) | Error 0.0150(0.0155) Steps 428(426.32) | Grad Norm 0.3121(0.2596) | Total Time 10.00(10.00)\n",
      "Iter 3526 | Time 32.1657(30.8757) | Bit/dim 1.1098(1.1071) | Xent 0.0571(0.0511) | Loss 1.1383(1.1326) | Error 0.0171(0.0156) Steps 422(426.19) | Grad Norm 0.2664(0.2598) | Total Time 10.00(10.00)\n",
      "Iter 3527 | Time 31.1579(30.8842) | Bit/dim 1.1024(1.1069) | Xent 0.0544(0.0512) | Loss 1.1296(1.1325) | Error 0.0159(0.0156) Steps 428(426.25) | Grad Norm 0.3124(0.2614) | Total Time 10.00(10.00)\n",
      "Iter 3528 | Time 30.4326(30.8706) | Bit/dim 1.1068(1.1069) | Xent 0.0501(0.0511) | Loss 1.1319(1.1325) | Error 0.0168(0.0156) Steps 428(426.30) | Grad Norm 0.1841(0.2591) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0504 | Time 16.9630, Epoch Time 245.0415(242.8660), Bit/dim 1.1017(best: 1.1010), Xent 0.0313, Loss 1.1174, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3529 | Time 30.5914(30.8623) | Bit/dim 1.1070(1.1069) | Xent 0.0529(0.0512) | Loss 1.1335(1.1325) | Error 0.0165(0.0157) Steps 428(426.35) | Grad Norm 0.3665(0.2623) | Total Time 10.00(10.00)\n",
      "Iter 3530 | Time 30.2658(30.8444) | Bit/dim 1.1077(1.1070) | Xent 0.0509(0.0512) | Loss 1.1331(1.1325) | Error 0.0148(0.0156) Steps 428(426.40) | Grad Norm 0.3294(0.2643) | Total Time 10.00(10.00)\n",
      "Iter 3531 | Time 30.4041(30.8312) | Bit/dim 1.1076(1.1070) | Xent 0.0536(0.0512) | Loss 1.1345(1.1326) | Error 0.0175(0.0157) Steps 428(426.45) | Grad Norm 0.3383(0.2666) | Total Time 10.00(10.00)\n",
      "Iter 3532 | Time 29.9017(30.8033) | Bit/dim 1.1023(1.1068) | Xent 0.0526(0.0513) | Loss 1.1286(1.1325) | Error 0.0169(0.0157) Steps 428(426.49) | Grad Norm 0.1769(0.2639) | Total Time 10.00(10.00)\n",
      "Iter 3533 | Time 31.1637(30.8141) | Bit/dim 1.1048(1.1068) | Xent 0.0516(0.0513) | Loss 1.1306(1.1324) | Error 0.0158(0.0157) Steps 428(426.54) | Grad Norm 0.3034(0.2650) | Total Time 10.00(10.00)\n",
      "Iter 3534 | Time 30.7805(30.8131) | Bit/dim 1.1088(1.1068) | Xent 0.0469(0.0512) | Loss 1.1322(1.1324) | Error 0.0152(0.0157) Steps 422(426.40) | Grad Norm 0.2471(0.2645) | Total Time 10.00(10.00)\n",
      "Iter 3535 | Time 31.1307(30.8226) | Bit/dim 1.1086(1.1069) | Xent 0.0490(0.0511) | Loss 1.1331(1.1324) | Error 0.0156(0.0157) Steps 428(426.45) | Grad Norm 0.2743(0.2648) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0505 | Time 16.8100, Epoch Time 243.2383(242.8771), Bit/dim 1.1016(best: 1.1010), Xent 0.0325, Loss 1.1178, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3536 | Time 30.1095(30.8012) | Bit/dim 1.1064(1.1069) | Xent 0.0532(0.0512) | Loss 1.1329(1.1325) | Error 0.0170(0.0157) Steps 428(426.50) | Grad Norm 0.2542(0.2645) | Total Time 10.00(10.00)\n",
      "Iter 3537 | Time 30.8724(30.8034) | Bit/dim 1.1059(1.1068) | Xent 0.0489(0.0511) | Loss 1.1303(1.1324) | Error 0.0144(0.0157) Steps 428(426.54) | Grad Norm 0.2082(0.2628) | Total Time 10.00(10.00)\n",
      "Iter 3538 | Time 29.9242(30.7770) | Bit/dim 1.1123(1.1070) | Xent 0.0531(0.0512) | Loss 1.1388(1.1326) | Error 0.0162(0.0157) Steps 428(426.59) | Grad Norm 0.4983(0.2699) | Total Time 10.00(10.00)\n",
      "Iter 3539 | Time 31.3321(30.7936) | Bit/dim 1.1066(1.1070) | Xent 0.0489(0.0511) | Loss 1.1311(1.1325) | Error 0.0154(0.0157) Steps 428(426.63) | Grad Norm 0.2786(0.2701) | Total Time 10.00(10.00)\n",
      "Iter 3540 | Time 32.0901(30.8325) | Bit/dim 1.1040(1.1069) | Xent 0.0519(0.0511) | Loss 1.1299(1.1325) | Error 0.0172(0.0158) Steps 428(426.67) | Grad Norm 0.2926(0.2708) | Total Time 10.00(10.00)\n",
      "Iter 3541 | Time 30.7760(30.8308) | Bit/dim 1.1053(1.1069) | Xent 0.0546(0.0512) | Loss 1.1326(1.1325) | Error 0.0150(0.0157) Steps 428(426.71) | Grad Norm 0.2650(0.2706) | Total Time 10.00(10.00)\n",
      "Iter 3542 | Time 30.7224(30.8276) | Bit/dim 1.1057(1.1068) | Xent 0.0483(0.0511) | Loss 1.1299(1.1324) | Error 0.0154(0.0157) Steps 422(426.57) | Grad Norm 0.2407(0.2697) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0506 | Time 16.8006, Epoch Time 244.9680(242.9399), Bit/dim 1.1008(best: 1.1010), Xent 0.0311, Loss 1.1164, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3543 | Time 30.3982(30.8147) | Bit/dim 1.1038(1.1067) | Xent 0.0513(0.0511) | Loss 1.1295(1.1323) | Error 0.0158(0.0157) Steps 428(426.61) | Grad Norm 0.2281(0.2685) | Total Time 10.00(10.00)\n",
      "Iter 3544 | Time 30.6039(30.8084) | Bit/dim 1.1064(1.1067) | Xent 0.0520(0.0512) | Loss 1.1324(1.1323) | Error 0.0156(0.0157) Steps 428(426.65) | Grad Norm 0.2091(0.2667) | Total Time 10.00(10.00)\n",
      "Iter 3545 | Time 30.8956(30.8110) | Bit/dim 1.1055(1.1067) | Xent 0.0450(0.0510) | Loss 1.1281(1.1322) | Error 0.0145(0.0157) Steps 422(426.51) | Grad Norm 0.2391(0.2659) | Total Time 10.00(10.00)\n",
      "Iter 3546 | Time 31.2491(30.8241) | Bit/dim 1.1066(1.1067) | Xent 0.0530(0.0510) | Loss 1.1331(1.1322) | Error 0.0174(0.0157) Steps 428(426.56) | Grad Norm 0.2495(0.2654) | Total Time 10.00(10.00)\n",
      "Iter 3547 | Time 30.4382(30.8126) | Bit/dim 1.1061(1.1067) | Xent 0.0446(0.0508) | Loss 1.1284(1.1321) | Error 0.0135(0.0157) Steps 428(426.60) | Grad Norm 0.2140(0.2638) | Total Time 10.00(10.00)\n",
      "Iter 3548 | Time 30.2907(30.7969) | Bit/dim 1.1089(1.1067) | Xent 0.0551(0.0510) | Loss 1.1365(1.1322) | Error 0.0175(0.0157) Steps 428(426.64) | Grad Norm 0.1768(0.2612) | Total Time 10.00(10.00)\n",
      "Iter 3549 | Time 29.9729(30.7722) | Bit/dim 1.1114(1.1069) | Xent 0.0548(0.0511) | Loss 1.1388(1.1324) | Error 0.0166(0.0157) Steps 428(426.68) | Grad Norm 0.2863(0.2620) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0507 | Time 16.5328, Epoch Time 242.6968(242.9326), Bit/dim 1.1011(best: 1.1008), Xent 0.0343, Loss 1.1182, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3550 | Time 31.0036(30.7791) | Bit/dim 1.1036(1.1068) | Xent 0.0465(0.0509) | Loss 1.1268(1.1322) | Error 0.0138(0.0157) Steps 428(426.72) | Grad Norm 0.1845(0.2597) | Total Time 10.00(10.00)\n",
      "Iter 3551 | Time 30.3256(30.7655) | Bit/dim 1.1058(1.1067) | Xent 0.0538(0.0510) | Loss 1.1327(1.1323) | Error 0.0170(0.0157) Steps 428(426.76) | Grad Norm 0.1724(0.2570) | Total Time 10.00(10.00)\n",
      "Iter 3552 | Time 30.2419(30.7498) | Bit/dim 1.1095(1.1068) | Xent 0.0490(0.0510) | Loss 1.1340(1.1323) | Error 0.0130(0.0156) Steps 428(426.80) | Grad Norm 0.2332(0.2563) | Total Time 10.00(10.00)\n",
      "Iter 3553 | Time 32.1120(30.7907) | Bit/dim 1.1048(1.1068) | Xent 0.0435(0.0507) | Loss 1.1266(1.1321) | Error 0.0135(0.0156) Steps 428(426.83) | Grad Norm 0.1859(0.2542) | Total Time 10.00(10.00)\n",
      "Iter 3554 | Time 30.8647(30.7929) | Bit/dim 1.1059(1.1067) | Xent 0.0530(0.0508) | Loss 1.1324(1.1321) | Error 0.0181(0.0157) Steps 428(426.87) | Grad Norm 0.2863(0.2552) | Total Time 10.00(10.00)\n",
      "Iter 3555 | Time 30.0356(30.7702) | Bit/dim 1.1092(1.1068) | Xent 0.0550(0.0509) | Loss 1.1367(1.1323) | Error 0.0182(0.0157) Steps 428(426.90) | Grad Norm 0.4369(0.2606) | Total Time 10.00(10.00)\n",
      "Iter 3556 | Time 30.8635(30.7730) | Bit/dim 1.1071(1.1068) | Xent 0.0568(0.0511) | Loss 1.1355(1.1324) | Error 0.0175(0.0158) Steps 428(426.94) | Grad Norm 0.2165(0.2593) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0508 | Time 16.8098, Epoch Time 244.6136(242.9830), Bit/dim 1.1017(best: 1.1008), Xent 0.0329, Loss 1.1181, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3557 | Time 30.7398(30.7720) | Bit/dim 1.1059(1.1068) | Xent 0.0457(0.0510) | Loss 1.1287(1.1323) | Error 0.0148(0.0158) Steps 422(426.79) | Grad Norm 0.2921(0.2603) | Total Time 10.00(10.00)\n",
      "Iter 3558 | Time 30.8705(30.7749) | Bit/dim 1.1049(1.1067) | Xent 0.0544(0.0511) | Loss 1.1321(1.1323) | Error 0.0160(0.0158) Steps 422(426.64) | Grad Norm 0.4889(0.2671) | Total Time 10.00(10.00)\n",
      "Iter 3559 | Time 31.1316(30.7856) | Bit/dim 1.1036(1.1066) | Xent 0.0456(0.0509) | Loss 1.1264(1.1321) | Error 0.0141(0.0157) Steps 422(426.51) | Grad Norm 0.2175(0.2657) | Total Time 10.00(10.00)\n",
      "Iter 3560 | Time 30.9907(30.7918) | Bit/dim 1.1056(1.1066) | Xent 0.0592(0.0511) | Loss 1.1352(1.1322) | Error 0.0189(0.0158) Steps 428(426.55) | Grad Norm 0.3793(0.2691) | Total Time 10.00(10.00)\n",
      "Iter 3561 | Time 30.6253(30.7868) | Bit/dim 1.1134(1.1068) | Xent 0.0461(0.0510) | Loss 1.1365(1.1323) | Error 0.0148(0.0158) Steps 428(426.59) | Grad Norm 0.2079(0.2672) | Total Time 10.00(10.00)\n",
      "Iter 3562 | Time 31.7042(30.8143) | Bit/dim 1.1057(1.1068) | Xent 0.0528(0.0510) | Loss 1.1321(1.1323) | Error 0.0170(0.0158) Steps 428(426.64) | Grad Norm 0.2515(0.2668) | Total Time 10.00(10.00)\n",
      "Iter 3563 | Time 30.9437(30.8182) | Bit/dim 1.1111(1.1069) | Xent 0.0495(0.0510) | Loss 1.1359(1.1324) | Error 0.0142(0.0158) Steps 428(426.68) | Grad Norm 0.2536(0.2664) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0509 | Time 17.0189, Epoch Time 246.2391(243.0807), Bit/dim 1.1014(best: 1.1008), Xent 0.0315, Loss 1.1172, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3564 | Time 30.6392(30.8128) | Bit/dim 1.1090(1.1070) | Xent 0.0552(0.0511) | Loss 1.1365(1.1325) | Error 0.0185(0.0158) Steps 428(426.72) | Grad Norm 0.3011(0.2674) | Total Time 10.00(10.00)\n",
      "Iter 3565 | Time 29.9481(30.7869) | Bit/dim 1.1050(1.1069) | Xent 0.0468(0.0510) | Loss 1.1284(1.1324) | Error 0.0158(0.0158) Steps 428(426.75) | Grad Norm 0.1726(0.2646) | Total Time 10.00(10.00)\n",
      "Iter 3566 | Time 30.8360(30.7884) | Bit/dim 1.1114(1.1071) | Xent 0.0564(0.0512) | Loss 1.1396(1.1326) | Error 0.0171(0.0159) Steps 428(426.79) | Grad Norm 0.1958(0.2625) | Total Time 10.00(10.00)\n",
      "Iter 3567 | Time 32.9726(30.8539) | Bit/dim 1.1055(1.1070) | Xent 0.0487(0.0511) | Loss 1.1298(1.1325) | Error 0.0152(0.0159) Steps 428(426.83) | Grad Norm 0.2002(0.2606) | Total Time 10.00(10.00)\n",
      "Iter 3568 | Time 30.8608(30.8541) | Bit/dim 1.1060(1.1070) | Xent 0.0489(0.0510) | Loss 1.1305(1.1325) | Error 0.0159(0.0159) Steps 428(426.86) | Grad Norm 0.2284(0.2597) | Total Time 10.00(10.00)\n",
      "Iter 3569 | Time 30.4712(30.8426) | Bit/dim 1.1070(1.1070) | Xent 0.0486(0.0509) | Loss 1.1313(1.1324) | Error 0.0148(0.0158) Steps 428(426.90) | Grad Norm 0.2738(0.2601) | Total Time 10.00(10.00)\n",
      "Iter 3570 | Time 30.4561(30.8310) | Bit/dim 1.1090(1.1070) | Xent 0.0481(0.0509) | Loss 1.1330(1.1325) | Error 0.0145(0.0158) Steps 428(426.93) | Grad Norm 0.2071(0.2585) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0510 | Time 16.7476, Epoch Time 245.0890(243.1409), Bit/dim 1.1014(best: 1.1008), Xent 0.0324, Loss 1.1176, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3571 | Time 31.5059(30.8513) | Bit/dim 1.1072(1.1070) | Xent 0.0541(0.0510) | Loss 1.1342(1.1325) | Error 0.0154(0.0158) Steps 428(426.96) | Grad Norm 0.1680(0.2558) | Total Time 10.00(10.00)\n",
      "Iter 3572 | Time 31.6328(30.8747) | Bit/dim 1.1039(1.1069) | Xent 0.0519(0.0510) | Loss 1.1299(1.1324) | Error 0.0140(0.0157) Steps 428(426.99) | Grad Norm 0.2706(0.2562) | Total Time 10.00(10.00)\n",
      "Iter 3573 | Time 31.2181(30.8850) | Bit/dim 1.1055(1.1069) | Xent 0.0477(0.0509) | Loss 1.1294(1.1323) | Error 0.0164(0.0157) Steps 428(427.02) | Grad Norm 0.2183(0.2551) | Total Time 10.00(10.00)\n",
      "Iter 3574 | Time 31.6535(30.9081) | Bit/dim 1.1069(1.1069) | Xent 0.0464(0.0508) | Loss 1.1302(1.1323) | Error 0.0154(0.0157) Steps 428(427.05) | Grad Norm 0.2378(0.2546) | Total Time 10.00(10.00)\n",
      "Iter 3575 | Time 30.9801(30.9102) | Bit/dim 1.1048(1.1068) | Xent 0.0468(0.0506) | Loss 1.1281(1.1322) | Error 0.0135(0.0157) Steps 428(427.08) | Grad Norm 0.2212(0.2536) | Total Time 10.00(10.00)\n",
      "Iter 3576 | Time 29.9649(30.8819) | Bit/dim 1.1082(1.1069) | Xent 0.0528(0.0507) | Loss 1.1346(1.1322) | Error 0.0154(0.0157) Steps 422(426.93) | Grad Norm 0.3575(0.2567) | Total Time 10.00(10.00)\n",
      "Iter 3577 | Time 31.9529(30.9140) | Bit/dim 1.1099(1.1070) | Xent 0.0510(0.0507) | Loss 1.1354(1.1323) | Error 0.0159(0.0157) Steps 428(426.96) | Grad Norm 0.2655(0.2569) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0511 | Time 16.4279, Epoch Time 247.6378(243.2758), Bit/dim 1.1014(best: 1.1008), Xent 0.0307, Loss 1.1168, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3578 | Time 30.6078(30.9048) | Bit/dim 1.1092(1.1070) | Xent 0.0538(0.0508) | Loss 1.1361(1.1324) | Error 0.0164(0.0157) Steps 422(426.81) | Grad Norm 0.2308(0.2562) | Total Time 10.00(10.00)\n",
      "Iter 3579 | Time 30.7265(30.8995) | Bit/dim 1.1011(1.1069) | Xent 0.0498(0.0508) | Loss 1.1260(1.1322) | Error 0.0155(0.0157) Steps 428(426.85) | Grad Norm 0.2260(0.2553) | Total Time 10.00(10.00)\n",
      "Iter 3580 | Time 31.5887(30.9201) | Bit/dim 1.1059(1.1068) | Xent 0.0532(0.0508) | Loss 1.1325(1.1323) | Error 0.0162(0.0157) Steps 428(426.88) | Grad Norm 0.2485(0.2551) | Total Time 10.00(10.00)\n",
      "Iter 3581 | Time 31.5830(30.9400) | Bit/dim 1.1091(1.1069) | Xent 0.0570(0.0510) | Loss 1.1376(1.1324) | Error 0.0175(0.0158) Steps 428(426.92) | Grad Norm 0.1708(0.2525) | Total Time 10.00(10.00)\n",
      "Iter 3582 | Time 31.3149(30.9513) | Bit/dim 1.1086(1.1069) | Xent 0.0467(0.0509) | Loss 1.1320(1.1324) | Error 0.0154(0.0157) Steps 428(426.95) | Grad Norm 0.1822(0.2504) | Total Time 10.00(10.00)\n",
      "Iter 3583 | Time 30.5674(30.9398) | Bit/dim 1.1074(1.1070) | Xent 0.0481(0.0508) | Loss 1.1315(1.1324) | Error 0.0156(0.0157) Steps 422(426.80) | Grad Norm 0.2183(0.2495) | Total Time 10.00(10.00)\n",
      "Iter 3584 | Time 31.0307(30.9425) | Bit/dim 1.1063(1.1069) | Xent 0.0540(0.0509) | Loss 1.1333(1.1324) | Error 0.0151(0.0157) Steps 428(426.84) | Grad Norm 0.1702(0.2471) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0512 | Time 16.9782, Epoch Time 246.5601(243.3744), Bit/dim 1.1012(best: 1.1008), Xent 0.0322, Loss 1.1173, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3585 | Time 31.0776(30.9465) | Bit/dim 1.1067(1.1069) | Xent 0.0552(0.0510) | Loss 1.1344(1.1325) | Error 0.0170(0.0158) Steps 428(426.87) | Grad Norm 0.1605(0.2445) | Total Time 10.00(10.00)\n",
      "Iter 3586 | Time 31.0118(30.9485) | Bit/dim 1.1029(1.1068) | Xent 0.0540(0.0511) | Loss 1.1299(1.1324) | Error 0.0161(0.0158) Steps 428(426.91) | Grad Norm 0.1542(0.2418) | Total Time 10.00(10.00)\n",
      "Iter 3587 | Time 31.1469(30.9544) | Bit/dim 1.1075(1.1068) | Xent 0.0491(0.0511) | Loss 1.1321(1.1324) | Error 0.0155(0.0158) Steps 428(426.94) | Grad Norm 0.2276(0.2413) | Total Time 10.00(10.00)\n",
      "Iter 3588 | Time 32.5821(31.0033) | Bit/dim 1.1059(1.1068) | Xent 0.0487(0.0510) | Loss 1.1303(1.1323) | Error 0.0152(0.0157) Steps 428(426.97) | Grad Norm 0.2011(0.2401) | Total Time 10.00(10.00)\n",
      "Iter 3589 | Time 31.2902(31.0119) | Bit/dim 1.1097(1.1069) | Xent 0.0456(0.0508) | Loss 1.1325(1.1323) | Error 0.0145(0.0157) Steps 422(426.82) | Grad Norm 0.2524(0.2405) | Total Time 10.00(10.00)\n",
      "Iter 3590 | Time 30.4828(30.9960) | Bit/dim 1.1039(1.1068) | Xent 0.0510(0.0508) | Loss 1.1294(1.1322) | Error 0.0159(0.0157) Steps 422(426.68) | Grad Norm 0.2581(0.2410) | Total Time 10.00(10.00)\n",
      "Iter 3591 | Time 30.2281(30.9730) | Bit/dim 1.1103(1.1069) | Xent 0.0425(0.0506) | Loss 1.1316(1.1322) | Error 0.0126(0.0156) Steps 428(426.72) | Grad Norm 0.3152(0.2433) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0513 | Time 16.9286, Epoch Time 246.9349(243.4812), Bit/dim 1.1010(best: 1.1008), Xent 0.0298, Loss 1.1159, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3592 | Time 30.1376(30.9479) | Bit/dim 1.1028(1.1068) | Xent 0.0513(0.0506) | Loss 1.1285(1.1321) | Error 0.0149(0.0156) Steps 428(426.75) | Grad Norm 0.1442(0.2403) | Total Time 10.00(10.00)\n",
      "Iter 3593 | Time 30.5934(30.9373) | Bit/dim 1.1085(1.1068) | Xent 0.0459(0.0505) | Loss 1.1315(1.1321) | Error 0.0126(0.0155) Steps 428(426.79) | Grad Norm 0.2370(0.2402) | Total Time 10.00(10.00)\n",
      "Iter 3594 | Time 30.8991(30.9361) | Bit/dim 1.1073(1.1069) | Xent 0.0555(0.0506) | Loss 1.1351(1.1322) | Error 0.0160(0.0155) Steps 428(426.83) | Grad Norm 0.2484(0.2404) | Total Time 10.00(10.00)\n",
      "Iter 3595 | Time 30.5396(30.9242) | Bit/dim 1.1083(1.1069) | Xent 0.0469(0.0505) | Loss 1.1317(1.1322) | Error 0.0149(0.0155) Steps 428(426.86) | Grad Norm 0.3686(0.2443) | Total Time 10.00(10.00)\n",
      "Iter 3596 | Time 31.3782(30.9378) | Bit/dim 1.1089(1.1070) | Xent 0.0529(0.0506) | Loss 1.1354(1.1323) | Error 0.0178(0.0156) Steps 428(426.90) | Grad Norm 0.2251(0.2437) | Total Time 10.00(10.00)\n",
      "Iter 3597 | Time 32.2957(30.9786) | Bit/dim 1.1027(1.1068) | Xent 0.0492(0.0505) | Loss 1.1273(1.1321) | Error 0.0162(0.0156) Steps 428(426.93) | Grad Norm 0.4173(0.2489) | Total Time 10.00(10.00)\n",
      "Iter 3598 | Time 31.3740(30.9904) | Bit/dim 1.1081(1.1069) | Xent 0.0467(0.0504) | Loss 1.1314(1.1321) | Error 0.0145(0.0156) Steps 428(426.96) | Grad Norm 0.2747(0.2497) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0514 | Time 16.8183, Epoch Time 246.2714(243.5649), Bit/dim 1.1015(best: 1.1008), Xent 0.0313, Loss 1.1171, Error 0.0094(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3599 | Time 31.3673(31.0018) | Bit/dim 1.1025(1.1067) | Xent 0.0513(0.0505) | Loss 1.1282(1.1320) | Error 0.0172(0.0156) Steps 428(426.99) | Grad Norm 0.2344(0.2492) | Total Time 10.00(10.00)\n",
      "Iter 3600 | Time 30.4993(30.9867) | Bit/dim 1.1073(1.1068) | Xent 0.0474(0.0504) | Loss 1.1310(1.1319) | Error 0.0134(0.0155) Steps 428(427.02) | Grad Norm 0.1956(0.2476) | Total Time 10.00(10.00)\n",
      "Iter 3601 | Time 30.9900(30.9868) | Bit/dim 1.1072(1.1068) | Xent 0.0607(0.0507) | Loss 1.1375(1.1321) | Error 0.0180(0.0156) Steps 428(427.05) | Grad Norm 0.3167(0.2497) | Total Time 10.00(10.00)\n",
      "Iter 3602 | Time 31.4697(31.0013) | Bit/dim 1.1084(1.1068) | Xent 0.0476(0.0506) | Loss 1.1322(1.1321) | Error 0.0138(0.0156) Steps 428(427.08) | Grad Norm 0.1536(0.2468) | Total Time 10.00(10.00)\n",
      "Iter 3603 | Time 30.6798(30.9916) | Bit/dim 1.1047(1.1068) | Xent 0.0419(0.0503) | Loss 1.1257(1.1319) | Error 0.0136(0.0155) Steps 428(427.11) | Grad Norm 0.1390(0.2436) | Total Time 10.00(10.00)\n",
      "Iter 3604 | Time 31.7499(31.0144) | Bit/dim 1.1042(1.1067) | Xent 0.0510(0.0503) | Loss 1.1297(1.1318) | Error 0.0155(0.0155) Steps 428(427.14) | Grad Norm 0.1419(0.2405) | Total Time 10.00(10.00)\n",
      "Iter 3605 | Time 31.4116(31.0263) | Bit/dim 1.1131(1.1069) | Xent 0.0521(0.0504) | Loss 1.1392(1.1321) | Error 0.0155(0.0155) Steps 422(426.98) | Grad Norm 0.1582(0.2381) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0515 | Time 16.5827, Epoch Time 246.5587(243.6547), Bit/dim 1.1013(best: 1.1008), Xent 0.0313, Loss 1.1170, Error 0.0098(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3606 | Time 29.9301(30.9934) | Bit/dim 1.1054(1.1068) | Xent 0.0622(0.0507) | Loss 1.1365(1.1322) | Error 0.0184(0.0156) Steps 422(426.83) | Grad Norm 0.1701(0.2360) | Total Time 10.00(10.00)\n",
      "Iter 3607 | Time 31.1150(30.9970) | Bit/dim 1.1118(1.1070) | Xent 0.0491(0.0507) | Loss 1.1363(1.1323) | Error 0.0146(0.0156) Steps 428(426.87) | Grad Norm 0.2594(0.2367) | Total Time 10.00(10.00)\n",
      "Iter 3608 | Time 30.4449(30.9805) | Bit/dim 1.1061(1.1069) | Xent 0.0436(0.0505) | Loss 1.1279(1.1322) | Error 0.0145(0.0155) Steps 428(426.90) | Grad Norm 0.1883(0.2353) | Total Time 10.00(10.00)\n",
      "Iter 3609 | Time 30.5032(30.9662) | Bit/dim 1.1056(1.1069) | Xent 0.0471(0.0504) | Loss 1.1292(1.1321) | Error 0.0132(0.0155) Steps 428(426.93) | Grad Norm 0.2417(0.2355) | Total Time 10.00(10.00)\n",
      "Iter 3610 | Time 30.6993(30.9582) | Bit/dim 1.1046(1.1068) | Xent 0.0511(0.0504) | Loss 1.1301(1.1320) | Error 0.0151(0.0154) Steps 428(426.97) | Grad Norm 0.1833(0.2339) | Total Time 10.00(10.00)\n",
      "Iter 3611 | Time 30.3986(30.9414) | Bit/dim 1.1075(1.1069) | Xent 0.0536(0.0505) | Loss 1.1343(1.1321) | Error 0.0166(0.0155) Steps 428(427.00) | Grad Norm 0.1821(0.2323) | Total Time 10.00(10.00)\n",
      "Iter 3612 | Time 30.2676(30.9212) | Bit/dim 1.1048(1.1068) | Xent 0.0497(0.0505) | Loss 1.1297(1.1320) | Error 0.0138(0.0154) Steps 428(427.03) | Grad Norm 0.1764(0.2307) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0516 | Time 16.7946, Epoch Time 242.2186(243.6116), Bit/dim 1.1006(best: 1.1008), Xent 0.0323, Loss 1.1167, Error 0.0112(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3613 | Time 30.7748(30.9168) | Bit/dim 1.1018(1.1066) | Xent 0.0480(0.0504) | Loss 1.1258(1.1318) | Error 0.0144(0.0154) Steps 428(427.06) | Grad Norm 0.1777(0.2291) | Total Time 10.00(10.00)\n",
      "Iter 3614 | Time 30.5115(30.9046) | Bit/dim 1.1073(1.1067) | Xent 0.0450(0.0502) | Loss 1.1298(1.1318) | Error 0.0151(0.0154) Steps 428(427.08) | Grad Norm 0.2402(0.2294) | Total Time 10.00(10.00)\n",
      "Iter 3615 | Time 30.1149(30.8809) | Bit/dim 1.1099(1.1068) | Xent 0.0459(0.0501) | Loss 1.1328(1.1318) | Error 0.0142(0.0154) Steps 428(427.11) | Grad Norm 0.2037(0.2286) | Total Time 10.00(10.00)\n",
      "Iter 3616 | Time 30.5659(30.8715) | Bit/dim 1.1079(1.1068) | Xent 0.0501(0.0501) | Loss 1.1329(1.1318) | Error 0.0174(0.0154) Steps 428(427.14) | Grad Norm 0.2254(0.2285) | Total Time 10.00(10.00)\n",
      "Iter 3617 | Time 31.3297(30.8852) | Bit/dim 1.1008(1.1066) | Xent 0.0475(0.0500) | Loss 1.1245(1.1316) | Error 0.0145(0.0154) Steps 428(427.16) | Grad Norm 0.2468(0.2291) | Total Time 10.00(10.00)\n",
      "Iter 3618 | Time 30.6236(30.8774) | Bit/dim 1.1046(1.1066) | Xent 0.0539(0.0501) | Loss 1.1316(1.1316) | Error 0.0170(0.0154) Steps 428(427.19) | Grad Norm 0.2121(0.2286) | Total Time 10.00(10.00)\n",
      "Iter 3619 | Time 32.0902(30.9138) | Bit/dim 1.1103(1.1067) | Xent 0.0548(0.0503) | Loss 1.1378(1.1318) | Error 0.0141(0.0154) Steps 428(427.21) | Grad Norm 0.2699(0.2298) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0517 | Time 16.9010, Epoch Time 245.1956(243.6591), Bit/dim 1.1009(best: 1.1006), Xent 0.0309, Loss 1.1164, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3620 | Time 30.1099(30.8896) | Bit/dim 1.1058(1.1066) | Xent 0.0505(0.0503) | Loss 1.1311(1.1318) | Error 0.0154(0.0154) Steps 428(427.24) | Grad Norm 0.3586(0.2337) | Total Time 10.00(10.00)\n",
      "Iter 3621 | Time 31.0318(30.8939) | Bit/dim 1.1029(1.1065) | Xent 0.0436(0.0501) | Loss 1.1247(1.1316) | Error 0.0140(0.0154) Steps 422(427.08) | Grad Norm 0.1883(0.2323) | Total Time 10.00(10.00)\n",
      "Iter 3622 | Time 31.8473(30.9225) | Bit/dim 1.1084(1.1066) | Xent 0.0501(0.0501) | Loss 1.1334(1.1316) | Error 0.0149(0.0153) Steps 428(427.11) | Grad Norm 0.3124(0.2347) | Total Time 10.00(10.00)\n",
      "Iter 3623 | Time 31.7258(30.9466) | Bit/dim 1.1049(1.1065) | Xent 0.0547(0.0502) | Loss 1.1322(1.1316) | Error 0.0174(0.0154) Steps 428(427.13) | Grad Norm 0.1643(0.2326) | Total Time 10.00(10.00)\n",
      "Iter 3624 | Time 30.4197(30.9308) | Bit/dim 1.1038(1.1064) | Xent 0.0529(0.0503) | Loss 1.1303(1.1316) | Error 0.0158(0.0154) Steps 428(427.16) | Grad Norm 0.2544(0.2333) | Total Time 10.00(10.00)\n",
      "Iter 3625 | Time 30.7951(30.9267) | Bit/dim 1.1124(1.1066) | Xent 0.0513(0.0503) | Loss 1.1381(1.1318) | Error 0.0165(0.0154) Steps 428(427.19) | Grad Norm 0.1599(0.2311) | Total Time 10.00(10.00)\n",
      "Iter 3626 | Time 32.3625(30.9698) | Bit/dim 1.1076(1.1067) | Xent 0.0589(0.0506) | Loss 1.1371(1.1320) | Error 0.0182(0.0155) Steps 428(427.21) | Grad Norm 0.2015(0.2302) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0518 | Time 16.8876, Epoch Time 247.5186(243.7749), Bit/dim 1.1005(best: 1.1006), Xent 0.0328, Loss 1.1169, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3627 | Time 31.2402(30.9779) | Bit/dim 1.1105(1.1068) | Xent 0.0493(0.0506) | Loss 1.1351(1.1321) | Error 0.0160(0.0155) Steps 428(427.23) | Grad Norm 0.3202(0.2329) | Total Time 10.00(10.00)\n",
      "Iter 3628 | Time 31.5389(30.9947) | Bit/dim 1.1047(1.1067) | Xent 0.0467(0.0504) | Loss 1.1280(1.1319) | Error 0.0148(0.0155) Steps 428(427.26) | Grad Norm 0.2157(0.2324) | Total Time 10.00(10.00)\n",
      "Iter 3629 | Time 30.3036(30.9740) | Bit/dim 1.1095(1.1068) | Xent 0.0551(0.0506) | Loss 1.1370(1.1321) | Error 0.0181(0.0156) Steps 422(427.10) | Grad Norm 0.3829(0.2369) | Total Time 10.00(10.00)\n",
      "Iter 3630 | Time 30.6658(30.9648) | Bit/dim 1.1063(1.1068) | Xent 0.0537(0.0507) | Loss 1.1331(1.1321) | Error 0.0151(0.0156) Steps 422(426.95) | Grad Norm 0.2190(0.2363) | Total Time 10.00(10.00)\n",
      "Iter 3631 | Time 29.8530(30.9314) | Bit/dim 1.1027(1.1067) | Xent 0.0513(0.0507) | Loss 1.1283(1.1320) | Error 0.0151(0.0156) Steps 422(426.80) | Grad Norm 0.3107(0.2386) | Total Time 10.00(10.00)\n",
      "Iter 3632 | Time 30.9660(30.9324) | Bit/dim 1.1086(1.1067) | Xent 0.0492(0.0506) | Loss 1.1332(1.1320) | Error 0.0148(0.0155) Steps 428(426.83) | Grad Norm 0.2899(0.2401) | Total Time 10.00(10.00)\n",
      "Iter 3633 | Time 31.3719(30.9456) | Bit/dim 1.1007(1.1065) | Xent 0.0560(0.0508) | Loss 1.1286(1.1319) | Error 0.0180(0.0156) Steps 428(426.87) | Grad Norm 0.3863(0.2445) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0519 | Time 16.6811, Epoch Time 244.8276(243.8065), Bit/dim 1.1010(best: 1.1005), Xent 0.0326, Loss 1.1174, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3634 | Time 30.7133(30.9387) | Bit/dim 1.1077(1.1066) | Xent 0.0443(0.0506) | Loss 1.1299(1.1319) | Error 0.0145(0.0156) Steps 428(426.90) | Grad Norm 0.1895(0.2429) | Total Time 10.00(10.00)\n",
      "Iter 3635 | Time 30.2828(30.9190) | Bit/dim 1.1039(1.1065) | Xent 0.0460(0.0505) | Loss 1.1269(1.1317) | Error 0.0152(0.0156) Steps 428(426.94) | Grad Norm 0.2688(0.2436) | Total Time 10.00(10.00)\n",
      "Iter 3636 | Time 30.6356(30.9105) | Bit/dim 1.1077(1.1065) | Xent 0.0568(0.0507) | Loss 1.1361(1.1319) | Error 0.0172(0.0156) Steps 428(426.97) | Grad Norm 0.1585(0.2411) | Total Time 10.00(10.00)\n",
      "Iter 3637 | Time 30.4960(30.8980) | Bit/dim 1.1060(1.1065) | Xent 0.0518(0.0507) | Loss 1.1319(1.1319) | Error 0.0156(0.0156) Steps 428(427.00) | Grad Norm 0.2046(0.2400) | Total Time 10.00(10.00)\n",
      "Iter 3638 | Time 30.3898(30.8828) | Bit/dim 1.1056(1.1065) | Xent 0.0494(0.0507) | Loss 1.1303(1.1318) | Error 0.0154(0.0156) Steps 428(427.03) | Grad Norm 0.1803(0.2382) | Total Time 10.00(10.00)\n",
      "Iter 3639 | Time 31.1874(30.8919) | Bit/dim 1.1058(1.1065) | Xent 0.0512(0.0507) | Loss 1.1314(1.1318) | Error 0.0145(0.0156) Steps 428(427.06) | Grad Norm 0.3392(0.2412) | Total Time 10.00(10.00)\n",
      "Iter 3640 | Time 31.2075(30.9014) | Bit/dim 1.1072(1.1065) | Xent 0.0506(0.0507) | Loss 1.1324(1.1318) | Error 0.0155(0.0156) Steps 428(427.09) | Grad Norm 0.2553(0.2416) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0520 | Time 16.8526, Epoch Time 243.8412(243.8075), Bit/dim 1.1004(best: 1.1005), Xent 0.0339, Loss 1.1174, Error 0.0116(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3641 | Time 30.9825(30.9038) | Bit/dim 1.1034(1.1064) | Xent 0.0556(0.0508) | Loss 1.1312(1.1318) | Error 0.0152(0.0156) Steps 428(427.11) | Grad Norm 0.2460(0.2418) | Total Time 10.00(10.00)\n",
      "Iter 3642 | Time 30.3502(30.8872) | Bit/dim 1.1070(1.1064) | Xent 0.0630(0.0512) | Loss 1.1385(1.1320) | Error 0.0194(0.0157) Steps 428(427.14) | Grad Norm 0.2477(0.2420) | Total Time 10.00(10.00)\n",
      "Iter 3643 | Time 30.9327(30.8886) | Bit/dim 1.1096(1.1065) | Xent 0.0527(0.0512) | Loss 1.1359(1.1321) | Error 0.0169(0.0157) Steps 428(427.17) | Grad Norm 0.2640(0.2426) | Total Time 10.00(10.00)\n",
      "Iter 3644 | Time 31.7026(30.9130) | Bit/dim 1.1081(1.1065) | Xent 0.0461(0.0511) | Loss 1.1311(1.1321) | Error 0.0134(0.0157) Steps 428(427.19) | Grad Norm 0.2360(0.2424) | Total Time 10.00(10.00)\n",
      "Iter 3645 | Time 30.1387(30.8898) | Bit/dim 1.1072(1.1066) | Xent 0.0451(0.0509) | Loss 1.1298(1.1320) | Error 0.0135(0.0156) Steps 428(427.22) | Grad Norm 0.5026(0.2502) | Total Time 10.00(10.00)\n",
      "Iter 3646 | Time 31.0184(30.8936) | Bit/dim 1.1035(1.1065) | Xent 0.0502(0.0509) | Loss 1.1285(1.1319) | Error 0.0136(0.0155) Steps 428(427.24) | Grad Norm 0.2103(0.2490) | Total Time 10.00(10.00)\n",
      "Iter 3647 | Time 30.2894(30.8755) | Bit/dim 1.1067(1.1065) | Xent 0.0508(0.0509) | Loss 1.1321(1.1319) | Error 0.0174(0.0156) Steps 428(427.26) | Grad Norm 0.3017(0.2506) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0521 | Time 16.9961, Epoch Time 244.4946(243.8282), Bit/dim 1.1011(best: 1.1004), Xent 0.0322, Loss 1.1171, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3648 | Time 30.2166(30.8557) | Bit/dim 1.1064(1.1065) | Xent 0.0533(0.0509) | Loss 1.1330(1.1320) | Error 0.0169(0.0156) Steps 428(427.28) | Grad Norm 0.4466(0.2565) | Total Time 10.00(10.00)\n",
      "Iter 3649 | Time 31.4710(30.8742) | Bit/dim 1.1014(1.1063) | Xent 0.0475(0.0508) | Loss 1.1251(1.1317) | Error 0.0154(0.0156) Steps 428(427.31) | Grad Norm 0.1706(0.2539) | Total Time 10.00(10.00)\n",
      "Iter 3650 | Time 30.5159(30.8635) | Bit/dim 1.1069(1.1063) | Xent 0.0567(0.0510) | Loss 1.1353(1.1319) | Error 0.0184(0.0157) Steps 422(427.15) | Grad Norm 0.2077(0.2525) | Total Time 10.00(10.00)\n",
      "Iter 3651 | Time 30.3193(30.8471) | Bit/dim 1.1079(1.1064) | Xent 0.0519(0.0510) | Loss 1.1338(1.1319) | Error 0.0151(0.0157) Steps 428(427.17) | Grad Norm 0.2529(0.2525) | Total Time 10.00(10.00)\n",
      "Iter 3652 | Time 30.7189(30.8433) | Bit/dim 1.1051(1.1064) | Xent 0.0492(0.0510) | Loss 1.1297(1.1318) | Error 0.0150(0.0157) Steps 428(427.20) | Grad Norm 0.5683(0.2620) | Total Time 10.00(10.00)\n",
      "Iter 3653 | Time 30.6033(30.8361) | Bit/dim 1.1056(1.1063) | Xent 0.0549(0.0511) | Loss 1.1330(1.1319) | Error 0.0144(0.0156) Steps 428(427.22) | Grad Norm 0.1722(0.2593) | Total Time 10.00(10.00)\n",
      "Iter 3654 | Time 31.3720(30.8522) | Bit/dim 1.1072(1.1064) | Xent 0.0465(0.0510) | Loss 1.1304(1.1318) | Error 0.0145(0.0156) Steps 428(427.24) | Grad Norm 0.3922(0.2633) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0522 | Time 16.8056, Epoch Time 244.4888(243.8480), Bit/dim 1.1005(best: 1.1004), Xent 0.0303, Loss 1.1157, Error 0.0091(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3655 | Time 30.4576(30.8403) | Bit/dim 1.1064(1.1064) | Xent 0.0440(0.0508) | Loss 1.1284(1.1317) | Error 0.0152(0.0156) Steps 428(427.27) | Grad Norm 0.3118(0.2648) | Total Time 10.00(10.00)\n",
      "Iter 3656 | Time 30.3458(30.8255) | Bit/dim 1.1047(1.1063) | Xent 0.0529(0.0508) | Loss 1.1312(1.1317) | Error 0.0162(0.0156) Steps 422(427.11) | Grad Norm 0.4479(0.2702) | Total Time 10.00(10.00)\n",
      "Iter 3657 | Time 30.3130(30.8101) | Bit/dim 1.1062(1.1063) | Xent 0.0548(0.0509) | Loss 1.1336(1.1318) | Error 0.0165(0.0156) Steps 428(427.14) | Grad Norm 0.2115(0.2685) | Total Time 10.00(10.00)\n",
      "Iter 3658 | Time 30.3021(30.7949) | Bit/dim 1.1030(1.1062) | Xent 0.0507(0.0509) | Loss 1.1283(1.1317) | Error 0.0144(0.0156) Steps 422(426.98) | Grad Norm 0.4529(0.2740) | Total Time 10.00(10.00)\n",
      "Iter 3659 | Time 31.8180(30.8256) | Bit/dim 1.1101(1.1063) | Xent 0.0512(0.0509) | Loss 1.1357(1.1318) | Error 0.0162(0.0156) Steps 428(427.01) | Grad Norm 0.7322(0.2878) | Total Time 10.00(10.00)\n",
      "Iter 3660 | Time 31.7846(30.8543) | Bit/dim 1.1065(1.1063) | Xent 0.0555(0.0511) | Loss 1.1343(1.1319) | Error 0.0169(0.0156) Steps 422(426.86) | Grad Norm 0.1915(0.2849) | Total Time 10.00(10.00)\n",
      "Iter 3661 | Time 31.1747(30.8639) | Bit/dim 1.1043(1.1063) | Xent 0.0513(0.0511) | Loss 1.1299(1.1318) | Error 0.0154(0.0156) Steps 428(426.90) | Grad Norm 0.2587(0.2841) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0523 | Time 16.8004, Epoch Time 245.1401(243.8867), Bit/dim 1.1001(best: 1.1004), Xent 0.0336, Loss 1.1170, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3662 | Time 30.7426(30.8603) | Bit/dim 1.1088(1.1063) | Xent 0.0476(0.0510) | Loss 1.1326(1.1318) | Error 0.0146(0.0156) Steps 428(426.93) | Grad Norm 0.4370(0.2887) | Total Time 10.00(10.00)\n",
      "Iter 3663 | Time 31.2852(30.8731) | Bit/dim 1.1053(1.1063) | Xent 0.0491(0.0509) | Loss 1.1299(1.1318) | Error 0.0155(0.0156) Steps 428(426.96) | Grad Norm 0.4986(0.2950) | Total Time 10.00(10.00)\n",
      "Iter 3664 | Time 30.7348(30.8689) | Bit/dim 1.1091(1.1064) | Xent 0.0509(0.0509) | Loss 1.1345(1.1319) | Error 0.0152(0.0156) Steps 422(426.81) | Grad Norm 0.2296(0.2930) | Total Time 10.00(10.00)\n",
      "Iter 3665 | Time 31.5340(30.8889) | Bit/dim 1.1060(1.1064) | Xent 0.0468(0.0508) | Loss 1.1294(1.1318) | Error 0.0152(0.0156) Steps 428(426.85) | Grad Norm 0.2479(0.2917) | Total Time 10.00(10.00)\n",
      "Iter 3666 | Time 31.3465(30.9026) | Bit/dim 1.1084(1.1064) | Xent 0.0467(0.0507) | Loss 1.1317(1.1318) | Error 0.0140(0.0155) Steps 428(426.88) | Grad Norm 0.4479(0.2964) | Total Time 10.00(10.00)\n",
      "Iter 3667 | Time 31.2801(30.9139) | Bit/dim 1.1054(1.1064) | Xent 0.0436(0.0505) | Loss 1.1272(1.1316) | Error 0.0152(0.0155) Steps 422(426.74) | Grad Norm 0.2021(0.2935) | Total Time 10.00(10.00)\n",
      "Iter 3668 | Time 31.0645(30.9184) | Bit/dim 1.1023(1.1063) | Xent 0.0504(0.0505) | Loss 1.1275(1.1315) | Error 0.0151(0.0155) Steps 428(426.77) | Grad Norm 0.1568(0.2894) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0524 | Time 16.8890, Epoch Time 247.1267(243.9839), Bit/dim 1.1006(best: 1.1001), Xent 0.0324, Loss 1.1168, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3669 | Time 31.4983(30.9358) | Bit/dim 1.1048(1.1062) | Xent 0.0551(0.0506) | Loss 1.1323(1.1315) | Error 0.0168(0.0156) Steps 428(426.81) | Grad Norm 0.2753(0.2890) | Total Time 10.00(10.00)\n",
      "Iter 3670 | Time 30.5499(30.9243) | Bit/dim 1.1036(1.1062) | Xent 0.0502(0.0506) | Loss 1.1287(1.1315) | Error 0.0151(0.0155) Steps 428(426.85) | Grad Norm 0.2674(0.2884) | Total Time 10.00(10.00)\n",
      "Iter 3671 | Time 30.2947(30.9054) | Bit/dim 1.1096(1.1063) | Xent 0.0490(0.0505) | Loss 1.1341(1.1315) | Error 0.0146(0.0155) Steps 428(426.88) | Grad Norm 0.2485(0.2872) | Total Time 10.00(10.00)\n",
      "Iter 3672 | Time 30.8580(30.9039) | Bit/dim 1.1065(1.1063) | Xent 0.0550(0.0507) | Loss 1.1340(1.1316) | Error 0.0161(0.0155) Steps 428(426.91) | Grad Norm 0.2884(0.2872) | Total Time 10.00(10.00)\n",
      "Iter 3673 | Time 31.4037(30.9189) | Bit/dim 1.1015(1.1061) | Xent 0.0467(0.0506) | Loss 1.1249(1.1314) | Error 0.0144(0.0155) Steps 422(426.77) | Grad Norm 0.3865(0.2902) | Total Time 10.00(10.00)\n",
      "Iter 3674 | Time 30.9129(30.9188) | Bit/dim 1.1094(1.1062) | Xent 0.0572(0.0508) | Loss 1.1380(1.1316) | Error 0.0159(0.0155) Steps 428(426.80) | Grad Norm 0.3932(0.2933) | Total Time 10.00(10.00)\n",
      "Iter 3675 | Time 31.3084(30.9304) | Bit/dim 1.1081(1.1063) | Xent 0.0559(0.0509) | Loss 1.1360(1.1317) | Error 0.0175(0.0156) Steps 428(426.84) | Grad Norm 0.2452(0.2918) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0525 | Time 16.8159, Epoch Time 245.7747(244.0377), Bit/dim 1.1006(best: 1.1001), Xent 0.0327, Loss 1.1169, Error 0.0114(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3676 | Time 30.8627(30.9284) | Bit/dim 1.1052(1.1062) | Xent 0.0458(0.0508) | Loss 1.1280(1.1316) | Error 0.0155(0.0156) Steps 428(426.87) | Grad Norm 0.3464(0.2935) | Total Time 10.00(10.00)\n",
      "Iter 3677 | Time 31.2174(30.9371) | Bit/dim 1.1071(1.1063) | Xent 0.0535(0.0508) | Loss 1.1338(1.1317) | Error 0.0158(0.0156) Steps 428(426.91) | Grad Norm 0.4202(0.2973) | Total Time 10.00(10.00)\n",
      "Iter 3678 | Time 30.5829(30.9265) | Bit/dim 1.1020(1.1061) | Xent 0.0525(0.0509) | Loss 1.1282(1.1316) | Error 0.0161(0.0156) Steps 428(426.94) | Grad Norm 0.2532(0.2959) | Total Time 10.00(10.00)\n",
      "Iter 3679 | Time 31.8513(30.9542) | Bit/dim 1.1079(1.1062) | Xent 0.0562(0.0511) | Loss 1.1360(1.1317) | Error 0.0178(0.0157) Steps 428(426.97) | Grad Norm 0.3336(0.2971) | Total Time 10.00(10.00)\n",
      "Iter 3680 | Time 31.0460(30.9570) | Bit/dim 1.1094(1.1063) | Xent 0.0506(0.0510) | Loss 1.1347(1.1318) | Error 0.0149(0.0156) Steps 428(427.00) | Grad Norm 0.4202(0.3008) | Total Time 10.00(10.00)\n",
      "Iter 3681 | Time 30.2733(30.9364) | Bit/dim 1.1071(1.1063) | Xent 0.0488(0.0510) | Loss 1.1315(1.1318) | Error 0.0152(0.0156) Steps 428(427.03) | Grad Norm 0.3351(0.3018) | Total Time 10.00(10.00)\n",
      "Iter 3682 | Time 31.1815(30.9438) | Bit/dim 1.1027(1.1062) | Xent 0.0502(0.0509) | Loss 1.1278(1.1317) | Error 0.0142(0.0156) Steps 428(427.06) | Grad Norm 0.3076(0.3020) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0526 | Time 16.9315, Epoch Time 246.1558(244.1012), Bit/dim 1.1008(best: 1.1001), Xent 0.0323, Loss 1.1169, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3683 | Time 31.7867(30.9691) | Bit/dim 1.1105(1.1063) | Xent 0.0479(0.0509) | Loss 1.1344(1.1318) | Error 0.0138(0.0155) Steps 428(427.09) | Grad Norm 0.3287(0.3028) | Total Time 10.00(10.00)\n",
      "Iter 3684 | Time 30.6198(30.9586) | Bit/dim 1.1050(1.1063) | Xent 0.0512(0.0509) | Loss 1.1306(1.1317) | Error 0.0144(0.0155) Steps 428(427.12) | Grad Norm 0.3296(0.3036) | Total Time 10.00(10.00)\n",
      "Iter 3685 | Time 30.5995(30.9478) | Bit/dim 1.1086(1.1064) | Xent 0.0522(0.0509) | Loss 1.1347(1.1318) | Error 0.0159(0.0155) Steps 428(427.14) | Grad Norm 0.3263(0.3043) | Total Time 10.00(10.00)\n",
      "Iter 3686 | Time 31.7771(30.9727) | Bit/dim 1.1044(1.1063) | Xent 0.0468(0.0508) | Loss 1.1278(1.1317) | Error 0.0126(0.0154) Steps 428(427.17) | Grad Norm 0.2826(0.3036) | Total Time 10.00(10.00)\n",
      "Iter 3687 | Time 31.1549(30.9782) | Bit/dim 1.1050(1.1063) | Xent 0.0534(0.0509) | Loss 1.1316(1.1317) | Error 0.0155(0.0154) Steps 428(427.20) | Grad Norm 0.1876(0.3001) | Total Time 10.00(10.00)\n",
      "Iter 3688 | Time 32.0355(31.0099) | Bit/dim 1.1039(1.1062) | Xent 0.0545(0.0510) | Loss 1.1312(1.1317) | Error 0.0165(0.0154) Steps 422(427.04) | Grad Norm 0.5111(0.3065) | Total Time 10.00(10.00)\n",
      "Iter 3689 | Time 30.5063(30.9948) | Bit/dim 1.1040(1.1061) | Xent 0.0499(0.0509) | Loss 1.1289(1.1316) | Error 0.0154(0.0154) Steps 422(426.89) | Grad Norm 0.2347(0.3043) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0527 | Time 16.8300, Epoch Time 247.5324(244.2041), Bit/dim 1.1000(best: 1.1001), Xent 0.0317, Loss 1.1158, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3690 | Time 30.3122(30.9743) | Bit/dim 1.1097(1.1062) | Xent 0.0558(0.0511) | Loss 1.1375(1.1318) | Error 0.0165(0.0155) Steps 428(426.92) | Grad Norm 0.3623(0.3060) | Total Time 10.00(10.00)\n",
      "Iter 3691 | Time 31.5104(30.9904) | Bit/dim 1.1017(1.1061) | Xent 0.0491(0.0510) | Loss 1.1262(1.1316) | Error 0.0139(0.0154) Steps 428(426.95) | Grad Norm 0.2402(0.3041) | Total Time 10.00(10.00)\n",
      "Iter 3692 | Time 30.5647(30.9776) | Bit/dim 1.1038(1.1060) | Xent 0.0583(0.0512) | Loss 1.1330(1.1316) | Error 0.0175(0.0155) Steps 422(426.81) | Grad Norm 0.2055(0.3011) | Total Time 10.00(10.00)\n",
      "Iter 3693 | Time 31.2941(30.9871) | Bit/dim 1.1003(1.1059) | Xent 0.0434(0.0510) | Loss 1.1220(1.1314) | Error 0.0131(0.0154) Steps 428(426.84) | Grad Norm 0.4507(0.3056) | Total Time 10.00(10.00)\n",
      "Iter 3694 | Time 30.8573(30.9832) | Bit/dim 1.1095(1.1060) | Xent 0.0517(0.0510) | Loss 1.1353(1.1315) | Error 0.0158(0.0154) Steps 428(426.88) | Grad Norm 0.2461(0.3038) | Total Time 10.00(10.00)\n",
      "Iter 3695 | Time 31.0651(30.9857) | Bit/dim 1.1106(1.1061) | Xent 0.0492(0.0510) | Loss 1.1352(1.1316) | Error 0.0155(0.0154) Steps 428(426.91) | Grad Norm 0.2684(0.3028) | Total Time 10.00(10.00)\n",
      "Iter 3696 | Time 31.1783(30.9915) | Bit/dim 1.1060(1.1061) | Xent 0.0455(0.0508) | Loss 1.1287(1.1315) | Error 0.0135(0.0154) Steps 428(426.94) | Grad Norm 0.4429(0.3070) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0528 | Time 16.6602, Epoch Time 245.5930(244.2458), Bit/dim 1.0996(best: 1.1000), Xent 0.0326, Loss 1.1159, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3697 | Time 30.5850(30.9793) | Bit/dim 1.0997(1.1059) | Xent 0.0482(0.0507) | Loss 1.1238(1.1313) | Error 0.0154(0.0154) Steps 428(426.97) | Grad Norm 0.3519(0.3083) | Total Time 10.00(10.00)\n",
      "Iter 3698 | Time 30.8704(30.9760) | Bit/dim 1.1039(1.1058) | Xent 0.0536(0.0508) | Loss 1.1306(1.1313) | Error 0.0152(0.0154) Steps 428(427.00) | Grad Norm 0.2632(0.3070) | Total Time 10.00(10.00)\n",
      "Iter 3699 | Time 31.4120(30.9891) | Bit/dim 1.1092(1.1059) | Xent 0.0499(0.0508) | Loss 1.1342(1.1313) | Error 0.0171(0.0154) Steps 428(427.03) | Grad Norm 0.2374(0.3049) | Total Time 10.00(10.00)\n",
      "Iter 3700 | Time 30.7442(30.9817) | Bit/dim 1.1087(1.1060) | Xent 0.0459(0.0506) | Loss 1.1316(1.1314) | Error 0.0126(0.0153) Steps 428(427.06) | Grad Norm 0.3198(0.3053) | Total Time 10.00(10.00)\n",
      "Iter 3701 | Time 32.2638(31.0202) | Bit/dim 1.1087(1.1061) | Xent 0.0510(0.0507) | Loss 1.1343(1.1314) | Error 0.0170(0.0154) Steps 428(427.09) | Grad Norm 0.2786(0.3045) | Total Time 10.00(10.00)\n",
      "Iter 3702 | Time 30.5763(31.0069) | Bit/dim 1.1102(1.1062) | Xent 0.0476(0.0506) | Loss 1.1340(1.1315) | Error 0.0141(0.0154) Steps 428(427.12) | Grad Norm 0.2205(0.3020) | Total Time 10.00(10.00)\n",
      "Iter 3703 | Time 30.7132(30.9981) | Bit/dim 1.1028(1.1061) | Xent 0.0523(0.0506) | Loss 1.1290(1.1314) | Error 0.0176(0.0154) Steps 428(427.15) | Grad Norm 0.3520(0.3035) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0529 | Time 16.8547, Epoch Time 246.0174(244.2989), Bit/dim 1.1004(best: 1.0996), Xent 0.0334, Loss 1.1171, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3704 | Time 31.3441(31.0084) | Bit/dim 1.1100(1.1062) | Xent 0.0609(0.0509) | Loss 1.1404(1.1317) | Error 0.0186(0.0155) Steps 422(426.99) | Grad Norm 0.3731(0.3056) | Total Time 10.00(10.00)\n",
      "Iter 3705 | Time 30.1813(30.9836) | Bit/dim 1.1054(1.1062) | Xent 0.0452(0.0508) | Loss 1.1280(1.1316) | Error 0.0126(0.0154) Steps 428(427.02) | Grad Norm 0.3467(0.3068) | Total Time 10.00(10.00)\n",
      "Iter 3706 | Time 32.2339(31.0211) | Bit/dim 1.1053(1.1062) | Xent 0.0446(0.0506) | Loss 1.1277(1.1315) | Error 0.0130(0.0154) Steps 422(426.87) | Grad Norm 0.3485(0.3081) | Total Time 10.00(10.00)\n",
      "Iter 3707 | Time 31.4984(31.0355) | Bit/dim 1.1047(1.1062) | Xent 0.0550(0.0507) | Loss 1.1322(1.1315) | Error 0.0156(0.0154) Steps 428(426.90) | Grad Norm 0.4158(0.3113) | Total Time 10.00(10.00)\n",
      "Iter 3708 | Time 30.9530(31.0330) | Bit/dim 1.1047(1.1061) | Xent 0.0486(0.0506) | Loss 1.1290(1.1314) | Error 0.0150(0.0154) Steps 428(426.94) | Grad Norm 0.2687(0.3100) | Total Time 10.00(10.00)\n",
      "Iter 3709 | Time 31.1662(31.0370) | Bit/dim 1.1089(1.1062) | Xent 0.0503(0.0506) | Loss 1.1340(1.1315) | Error 0.0169(0.0154) Steps 428(426.97) | Grad Norm 0.4163(0.3132) | Total Time 10.00(10.00)\n",
      "Iter 3710 | Time 30.5846(31.0234) | Bit/dim 1.1050(1.1062) | Xent 0.0494(0.0506) | Loss 1.1297(1.1314) | Error 0.0148(0.0154) Steps 428(427.00) | Grad Norm 0.2870(0.3124) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0530 | Time 17.0067, Epoch Time 247.0223(244.3807), Bit/dim 1.1005(best: 1.0996), Xent 0.0320, Loss 1.1165, Error 0.0092(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3711 | Time 30.8884(31.0194) | Bit/dim 1.1051(1.1061) | Xent 0.0516(0.0506) | Loss 1.1309(1.1314) | Error 0.0158(0.0154) Steps 428(427.03) | Grad Norm 0.1842(0.3086) | Total Time 10.00(10.00)\n",
      "Iter 3712 | Time 30.6705(31.0089) | Bit/dim 1.1062(1.1061) | Xent 0.0477(0.0505) | Loss 1.1300(1.1314) | Error 0.0148(0.0154) Steps 428(427.06) | Grad Norm 0.3438(0.3096) | Total Time 10.00(10.00)\n",
      "Iter 3713 | Time 30.3946(30.9905) | Bit/dim 1.1003(1.1059) | Xent 0.0563(0.0507) | Loss 1.1285(1.1313) | Error 0.0168(0.0154) Steps 428(427.09) | Grad Norm 0.2457(0.3077) | Total Time 10.00(10.00)\n",
      "Iter 3714 | Time 31.1144(30.9942) | Bit/dim 1.1094(1.1061) | Xent 0.0505(0.0507) | Loss 1.1347(1.1314) | Error 0.0148(0.0154) Steps 428(427.11) | Grad Norm 0.2486(0.3059) | Total Time 10.00(10.00)\n",
      "Iter 3715 | Time 30.5037(30.9795) | Bit/dim 1.1050(1.1060) | Xent 0.0525(0.0508) | Loss 1.1313(1.1314) | Error 0.0160(0.0154) Steps 428(427.14) | Grad Norm 0.2156(0.3032) | Total Time 10.00(10.00)\n",
      "Iter 3716 | Time 30.7953(30.9739) | Bit/dim 1.1054(1.1060) | Xent 0.0511(0.0508) | Loss 1.1309(1.1314) | Error 0.0166(0.0154) Steps 428(427.17) | Grad Norm 0.4394(0.3073) | Total Time 10.00(10.00)\n",
      "Iter 3717 | Time 31.8498(31.0002) | Bit/dim 1.1078(1.1061) | Xent 0.0470(0.0507) | Loss 1.1313(1.1314) | Error 0.0148(0.0154) Steps 428(427.19) | Grad Norm 0.4049(0.3102) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0531 | Time 16.9549, Epoch Time 245.3669(244.4102), Bit/dim 1.1002(best: 1.0996), Xent 0.0303, Loss 1.1153, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3718 | Time 30.8847(30.9968) | Bit/dim 1.1098(1.1062) | Xent 0.0492(0.0506) | Loss 1.1344(1.1315) | Error 0.0152(0.0154) Steps 428(427.22) | Grad Norm 0.2487(0.3084) | Total Time 10.00(10.00)\n",
      "Iter 3719 | Time 31.0093(30.9971) | Bit/dim 1.1076(1.1062) | Xent 0.0579(0.0508) | Loss 1.1365(1.1316) | Error 0.0146(0.0154) Steps 428(427.24) | Grad Norm 0.3068(0.3083) | Total Time 10.00(10.00)\n",
      "Iter 3720 | Time 30.5845(30.9847) | Bit/dim 1.1019(1.1061) | Xent 0.0537(0.0509) | Loss 1.1288(1.1315) | Error 0.0158(0.0154) Steps 428(427.26) | Grad Norm 0.4793(0.3135) | Total Time 10.00(10.00)\n",
      "Iter 3721 | Time 30.7504(30.9777) | Bit/dim 1.1066(1.1061) | Xent 0.0492(0.0509) | Loss 1.1312(1.1315) | Error 0.0148(0.0154) Steps 428(427.28) | Grad Norm 0.2049(0.3102) | Total Time 10.00(10.00)\n",
      "Iter 3722 | Time 30.2459(30.9558) | Bit/dim 1.1069(1.1061) | Xent 0.0521(0.0509) | Loss 1.1330(1.1316) | Error 0.0164(0.0154) Steps 428(427.31) | Grad Norm 0.5115(0.3163) | Total Time 10.00(10.00)\n",
      "Iter 3723 | Time 30.3544(30.9377) | Bit/dim 1.1054(1.1061) | Xent 0.0492(0.0508) | Loss 1.1300(1.1315) | Error 0.0149(0.0154) Steps 428(427.33) | Grad Norm 0.3440(0.3171) | Total Time 10.00(10.00)\n",
      "Iter 3724 | Time 30.3963(30.9215) | Bit/dim 1.1022(1.1060) | Xent 0.0467(0.0507) | Loss 1.1255(1.1313) | Error 0.0141(0.0154) Steps 422(427.17) | Grad Norm 0.2689(0.3156) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0532 | Time 17.0746, Epoch Time 243.4561(244.3816), Bit/dim 1.1002(best: 1.0996), Xent 0.0330, Loss 1.1167, Error 0.0110(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3725 | Time 30.7808(30.9173) | Bit/dim 1.1067(1.1060) | Xent 0.0607(0.0510) | Loss 1.1370(1.1315) | Error 0.0176(0.0154) Steps 422(427.01) | Grad Norm 0.2694(0.3143) | Total Time 10.00(10.00)\n",
      "Iter 3726 | Time 30.6302(30.9086) | Bit/dim 1.1065(1.1060) | Xent 0.0477(0.0509) | Loss 1.1304(1.1315) | Error 0.0151(0.0154) Steps 428(427.04) | Grad Norm 0.2368(0.3119) | Total Time 10.00(10.00)\n",
      "Iter 3727 | Time 30.5450(30.8977) | Bit/dim 1.1063(1.1060) | Xent 0.0465(0.0508) | Loss 1.1296(1.1314) | Error 0.0128(0.0153) Steps 428(427.07) | Grad Norm 0.4594(0.3164) | Total Time 10.00(10.00)\n",
      "Iter 3728 | Time 30.7496(30.8933) | Bit/dim 1.1033(1.1059) | Xent 0.0505(0.0508) | Loss 1.1286(1.1313) | Error 0.0155(0.0153) Steps 428(427.10) | Grad Norm 0.5755(0.3241) | Total Time 10.00(10.00)\n",
      "Iter 3729 | Time 31.2411(30.9037) | Bit/dim 1.1051(1.1059) | Xent 0.0554(0.0509) | Loss 1.1328(1.1314) | Error 0.0159(0.0154) Steps 428(427.13) | Grad Norm 0.1932(0.3202) | Total Time 10.00(10.00)\n",
      "Iter 3730 | Time 30.3803(30.8880) | Bit/dim 1.1050(1.1059) | Xent 0.0546(0.0510) | Loss 1.1323(1.1314) | Error 0.0180(0.0154) Steps 428(427.15) | Grad Norm 0.3490(0.3211) | Total Time 10.00(10.00)\n",
      "Iter 3731 | Time 31.0878(30.8940) | Bit/dim 1.1060(1.1059) | Xent 0.0490(0.0510) | Loss 1.1304(1.1314) | Error 0.0145(0.0154) Steps 428(427.18) | Grad Norm 0.2566(0.3191) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0533 | Time 17.1242, Epoch Time 244.6973(244.3911), Bit/dim 1.1007(best: 1.0996), Xent 0.0323, Loss 1.1169, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3732 | Time 32.3142(30.9366) | Bit/dim 1.1033(1.1058) | Xent 0.0515(0.0510) | Loss 1.1290(1.1313) | Error 0.0144(0.0154) Steps 428(427.20) | Grad Norm 0.4192(0.3221) | Total Time 10.00(10.00)\n",
      "Iter 3733 | Time 30.4380(30.9217) | Bit/dim 1.1039(1.1058) | Xent 0.0470(0.0509) | Loss 1.1274(1.1312) | Error 0.0156(0.0154) Steps 428(427.23) | Grad Norm 0.2520(0.3200) | Total Time 10.00(10.00)\n",
      "Iter 3734 | Time 30.8220(30.9187) | Bit/dim 1.1029(1.1057) | Xent 0.0458(0.0507) | Loss 1.1258(1.1310) | Error 0.0140(0.0153) Steps 428(427.25) | Grad Norm 0.2192(0.3170) | Total Time 10.00(10.00)\n",
      "Iter 3735 | Time 31.9584(30.9499) | Bit/dim 1.1082(1.1058) | Xent 0.0553(0.0509) | Loss 1.1359(1.1312) | Error 0.0179(0.0154) Steps 428(427.27) | Grad Norm 0.4465(0.3209) | Total Time 10.00(10.00)\n",
      "Iter 3736 | Time 30.5365(30.9375) | Bit/dim 1.1075(1.1058) | Xent 0.0452(0.0507) | Loss 1.1302(1.1311) | Error 0.0146(0.0154) Steps 422(427.11) | Grad Norm 0.1409(0.3155) | Total Time 10.00(10.00)\n",
      "Iter 3737 | Time 31.6601(30.9591) | Bit/dim 1.1036(1.1057) | Xent 0.0488(0.0506) | Loss 1.1280(1.1311) | Error 0.0145(0.0154) Steps 428(427.14) | Grad Norm 0.1862(0.3116) | Total Time 10.00(10.00)\n",
      "Iter 3738 | Time 31.9373(30.9885) | Bit/dim 1.1118(1.1059) | Xent 0.0490(0.0506) | Loss 1.1363(1.1312) | Error 0.0152(0.0154) Steps 422(426.99) | Grad Norm 0.3321(0.3122) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0534 | Time 16.7556, Epoch Time 248.7137(244.5208), Bit/dim 1.1001(best: 1.0996), Xent 0.0321, Loss 1.1162, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3739 | Time 30.3880(30.9705) | Bit/dim 1.1144(1.1062) | Xent 0.0509(0.0506) | Loss 1.1398(1.1315) | Error 0.0155(0.0154) Steps 428(427.02) | Grad Norm 0.3951(0.3147) | Total Time 10.00(10.00)\n",
      "Iter 3740 | Time 31.5494(30.9878) | Bit/dim 1.1104(1.1063) | Xent 0.0554(0.0507) | Loss 1.1381(1.1317) | Error 0.0165(0.0154) Steps 428(427.05) | Grad Norm 0.3565(0.3160) | Total Time 10.00(10.00)\n",
      "Iter 3741 | Time 31.0532(30.9898) | Bit/dim 1.1052(1.1063) | Xent 0.0474(0.0506) | Loss 1.1289(1.1316) | Error 0.0142(0.0154) Steps 428(427.07) | Grad Norm 0.2002(0.3125) | Total Time 10.00(10.00)\n",
      "Iter 3744 | Time 30.3816(30.9829) | Bit/dim 1.1029(1.1059) | Xent 0.0472(0.0506) | Loss 1.1266(1.1312) | Error 0.0148(0.0154) Steps 428(427.16) | Grad Norm 0.2912(0.3096) | Total Time 10.00(10.00)\n",
      "Iter 3745 | Time 31.0393(30.9846) | Bit/dim 1.1046(1.1059) | Xent 0.0537(0.0507) | Loss 1.1315(1.1312) | Error 0.0170(0.0155) Steps 422(427.00) | Grad Norm 0.1790(0.3057) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0535 | Time 16.6498, Epoch Time 245.5703(244.5522), Bit/dim 1.1004(best: 1.0996), Xent 0.0299, Loss 1.1153, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3746 | Time 32.1896(31.0207) | Bit/dim 1.1074(1.1059) | Xent 0.0538(0.0508) | Loss 1.1343(1.1313) | Error 0.0160(0.0155) Steps 428(427.03) | Grad Norm 0.2997(0.3055) | Total Time 10.00(10.00)\n",
      "Iter 3747 | Time 30.4884(31.0048) | Bit/dim 1.1070(1.1060) | Xent 0.0494(0.0508) | Loss 1.1317(1.1313) | Error 0.0144(0.0154) Steps 428(427.06) | Grad Norm 0.3276(0.3062) | Total Time 10.00(10.00)\n",
      "Iter 3748 | Time 30.4667(30.9886) | Bit/dim 1.1062(1.1060) | Xent 0.0514(0.0508) | Loss 1.1319(1.1314) | Error 0.0159(0.0155) Steps 428(427.09) | Grad Norm 0.1718(0.3021) | Total Time 10.00(10.00)\n",
      "Iter 3749 | Time 30.6651(30.9789) | Bit/dim 1.1030(1.1059) | Xent 0.0467(0.0507) | Loss 1.1263(1.1312) | Error 0.0144(0.0154) Steps 428(427.12) | Grad Norm 0.1794(0.2984) | Total Time 10.00(10.00)\n",
      "Iter 3750 | Time 30.6381(30.9687) | Bit/dim 1.1085(1.1060) | Xent 0.0495(0.0506) | Loss 1.1332(1.1313) | Error 0.0161(0.0154) Steps 428(427.14) | Grad Norm 0.1421(0.2938) | Total Time 10.00(10.00)\n",
      "Iter 3751 | Time 30.9170(30.9671) | Bit/dim 1.1028(1.1059) | Xent 0.0490(0.0506) | Loss 1.1273(1.1312) | Error 0.0140(0.0154) Steps 428(427.17) | Grad Norm 0.2116(0.2913) | Total Time 10.00(10.00)\n",
      "Iter 3752 | Time 30.5124(30.9535) | Bit/dim 1.1052(1.1058) | Xent 0.0533(0.0507) | Loss 1.1318(1.1312) | Error 0.0164(0.0154) Steps 428(427.19) | Grad Norm 0.2075(0.2888) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0536 | Time 16.6799, Epoch Time 244.5840(244.5532), Bit/dim 1.0999(best: 1.0996), Xent 0.0321, Loss 1.1159, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3753 | Time 31.0455(30.9563) | Bit/dim 1.1029(1.1058) | Xent 0.0511(0.0507) | Loss 1.1285(1.1311) | Error 0.0141(0.0154) Steps 428(427.22) | Grad Norm 0.1905(0.2858) | Total Time 10.00(10.00)\n",
      "Iter 3754 | Time 32.3346(30.9976) | Bit/dim 1.1040(1.1057) | Xent 0.0433(0.0505) | Loss 1.1256(1.1309) | Error 0.0142(0.0154) Steps 428(427.24) | Grad Norm 0.2331(0.2842) | Total Time 10.00(10.00)\n",
      "Iter 3755 | Time 30.8212(30.9923) | Bit/dim 1.1045(1.1057) | Xent 0.0481(0.0504) | Loss 1.1286(1.1309) | Error 0.0151(0.0153) Steps 428(427.26) | Grad Norm 0.2577(0.2835) | Total Time 10.00(10.00)\n",
      "Iter 3756 | Time 31.0877(30.9952) | Bit/dim 1.1106(1.1058) | Xent 0.0495(0.0504) | Loss 1.1354(1.1310) | Error 0.0165(0.0154) Steps 428(427.29) | Grad Norm 0.1689(0.2800) | Total Time 10.00(10.00)\n",
      "Iter 3757 | Time 30.8944(30.9922) | Bit/dim 1.1060(1.1058) | Xent 0.0548(0.0505) | Loss 1.1334(1.1311) | Error 0.0152(0.0154) Steps 428(427.31) | Grad Norm 0.1806(0.2770) | Total Time 10.00(10.00)\n",
      "Iter 3758 | Time 31.1878(30.9980) | Bit/dim 1.1090(1.1059) | Xent 0.0457(0.0504) | Loss 1.1318(1.1311) | Error 0.0148(0.0154) Steps 428(427.33) | Grad Norm 0.2178(0.2753) | Total Time 10.00(10.00)\n",
      "Iter 3759 | Time 30.8610(30.9939) | Bit/dim 1.1031(1.1058) | Xent 0.0542(0.0505) | Loss 1.1302(1.1311) | Error 0.0139(0.0153) Steps 428(427.35) | Grad Norm 0.2221(0.2737) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0537 | Time 16.9634, Epoch Time 247.4406(244.6398), Bit/dim 1.1003(best: 1.0996), Xent 0.0314, Loss 1.1160, Error 0.0093(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3760 | Time 32.1317(31.0280) | Bit/dim 1.1043(1.1058) | Xent 0.0466(0.0504) | Loss 1.1276(1.1310) | Error 0.0150(0.0153) Steps 428(427.37) | Grad Norm 0.3345(0.2755) | Total Time 10.00(10.00)\n",
      "Iter 3761 | Time 30.7817(31.0207) | Bit/dim 1.1069(1.1058) | Xent 0.0470(0.0503) | Loss 1.1304(1.1309) | Error 0.0144(0.0153) Steps 428(427.39) | Grad Norm 0.2326(0.2742) | Total Time 10.00(10.00)\n",
      "Iter 3762 | Time 30.7549(31.0127) | Bit/dim 1.1122(1.1060) | Xent 0.0516(0.0503) | Loss 1.1380(1.1312) | Error 0.0159(0.0153) Steps 428(427.40) | Grad Norm 0.3650(0.2769) | Total Time 10.00(10.00)\n",
      "Iter 3763 | Time 31.3399(31.0225) | Bit/dim 1.1052(1.1060) | Xent 0.0504(0.0503) | Loss 1.1304(1.1311) | Error 0.0150(0.0153) Steps 428(427.42) | Grad Norm 0.3880(0.2803) | Total Time 10.00(10.00)\n",
      "Iter 3764 | Time 30.9900(31.0215) | Bit/dim 1.1003(1.1058) | Xent 0.0483(0.0502) | Loss 1.1245(1.1309) | Error 0.0150(0.0153) Steps 428(427.44) | Grad Norm 0.1871(0.2775) | Total Time 10.00(10.00)\n",
      "Iter 3765 | Time 31.2645(31.0288) | Bit/dim 1.1048(1.1058) | Xent 0.0500(0.0502) | Loss 1.1298(1.1309) | Error 0.0156(0.0153) Steps 428(427.46) | Grad Norm 0.6692(0.2892) | Total Time 10.00(10.00)\n",
      "Iter 3766 | Time 30.7403(31.0202) | Bit/dim 1.1090(1.1059) | Xent 0.0483(0.0502) | Loss 1.1332(1.1310) | Error 0.0161(0.0153) Steps 428(427.47) | Grad Norm 0.5060(0.2957) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0538 | Time 16.7519, Epoch Time 246.6764(244.7009), Bit/dim 1.1002(best: 1.0996), Xent 0.0309, Loss 1.1156, Error 0.0093(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3767 | Time 30.5673(31.0066) | Bit/dim 1.1099(1.1060) | Xent 0.0525(0.0502) | Loss 1.1361(1.1311) | Error 0.0172(0.0154) Steps 422(427.31) | Grad Norm 0.1831(0.2923) | Total Time 10.00(10.00)\n",
      "Iter 3768 | Time 30.8719(31.0025) | Bit/dim 1.1004(1.1058) | Xent 0.0514(0.0503) | Loss 1.1261(1.1310) | Error 0.0174(0.0154) Steps 422(427.15) | Grad Norm 0.6082(0.3018) | Total Time 10.00(10.00)\n",
      "Iter 3769 | Time 30.7951(30.9963) | Bit/dim 1.1088(1.1059) | Xent 0.0479(0.0502) | Loss 1.1327(1.1310) | Error 0.0146(0.0154) Steps 422(426.99) | Grad Norm 0.5952(0.3106) | Total Time 10.00(10.00)\n",
      "Iter 3770 | Time 29.9862(30.9660) | Bit/dim 1.1024(1.1058) | Xent 0.0439(0.0500) | Loss 1.1244(1.1308) | Error 0.0148(0.0154) Steps 428(427.03) | Grad Norm 0.1972(0.3072) | Total Time 10.00(10.00)\n",
      "Iter 3771 | Time 32.5326(31.0130) | Bit/dim 1.1025(1.1057) | Xent 0.0488(0.0500) | Loss 1.1270(1.1307) | Error 0.0151(0.0154) Steps 428(427.05) | Grad Norm 0.5941(0.3158) | Total Time 10.00(10.00)\n",
      "Iter 3772 | Time 30.4033(30.9947) | Bit/dim 1.1053(1.1057) | Xent 0.0488(0.0499) | Loss 1.1297(1.1307) | Error 0.0146(0.0154) Steps 428(427.08) | Grad Norm 0.5447(0.3227) | Total Time 10.00(10.00)\n",
      "Iter 3773 | Time 30.9042(30.9920) | Bit/dim 1.1065(1.1057) | Xent 0.0512(0.0500) | Loss 1.1321(1.1307) | Error 0.0155(0.0154) Steps 428(427.11) | Grad Norm 0.2724(0.3212) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0539 | Time 16.9933, Epoch Time 245.4037(244.7220), Bit/dim 1.1000(best: 1.0996), Xent 0.0309, Loss 1.1155, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3774 | Time 31.0943(30.9951) | Bit/dim 1.1051(1.1057) | Xent 0.0541(0.0501) | Loss 1.1322(1.1308) | Error 0.0155(0.0154) Steps 428(427.14) | Grad Norm 0.4806(0.3260) | Total Time 10.00(10.00)\n",
      "Iter 3775 | Time 30.4579(30.9790) | Bit/dim 1.1100(1.1058) | Xent 0.0462(0.0500) | Loss 1.1331(1.1308) | Error 0.0144(0.0153) Steps 422(426.98) | Grad Norm 0.6457(0.3356) | Total Time 10.00(10.00)\n",
      "Iter 3776 | Time 31.1750(30.9848) | Bit/dim 1.1068(1.1059) | Xent 0.0518(0.0500) | Loss 1.1327(1.1309) | Error 0.0159(0.0154) Steps 428(427.01) | Grad Norm 0.2363(0.3326) | Total Time 10.00(10.00)\n",
      "Iter 3777 | Time 32.0645(31.0172) | Bit/dim 1.1044(1.1058) | Xent 0.0513(0.0501) | Loss 1.1300(1.1309) | Error 0.0146(0.0153) Steps 428(427.04) | Grad Norm 0.6561(0.3423) | Total Time 10.00(10.00)\n",
      "Iter 3778 | Time 31.0876(31.0193) | Bit/dim 1.1060(1.1058) | Xent 0.0518(0.0501) | Loss 1.1319(1.1309) | Error 0.0155(0.0153) Steps 428(427.07) | Grad Norm 0.2742(0.3402) | Total Time 10.00(10.00)\n",
      "Iter 3779 | Time 32.0322(31.0497) | Bit/dim 1.1029(1.1057) | Xent 0.0550(0.0503) | Loss 1.1304(1.1309) | Error 0.0170(0.0154) Steps 428(427.10) | Grad Norm 0.2208(0.3367) | Total Time 10.00(10.00)\n",
      "Iter 3780 | Time 30.8472(31.0437) | Bit/dim 1.1037(1.1057) | Xent 0.0599(0.0506) | Loss 1.1337(1.1310) | Error 0.0189(0.0155) Steps 428(427.13) | Grad Norm 0.2613(0.3344) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0540 | Time 17.0495, Epoch Time 248.1136(244.8238), Bit/dim 1.1000(best: 1.0996), Xent 0.0316, Loss 1.1158, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3781 | Time 30.4349(31.0254) | Bit/dim 1.1041(1.1056) | Xent 0.0471(0.0505) | Loss 1.1277(1.1309) | Error 0.0141(0.0154) Steps 422(426.97) | Grad Norm 0.6098(0.3427) | Total Time 10.00(10.00)\n",
      "Iter 3782 | Time 31.0940(31.0274) | Bit/dim 1.1030(1.1056) | Xent 0.0520(0.0505) | Loss 1.1290(1.1308) | Error 0.0165(0.0155) Steps 428(427.00) | Grad Norm 0.2905(0.3411) | Total Time 10.00(10.00)\n",
      "Iter 3783 | Time 31.0596(31.0284) | Bit/dim 1.1098(1.1057) | Xent 0.0543(0.0506) | Loss 1.1369(1.1310) | Error 0.0174(0.0155) Steps 428(427.03) | Grad Norm 0.4991(0.3458) | Total Time 10.00(10.00)\n",
      "Iter 3784 | Time 31.1960(31.0334) | Bit/dim 1.1070(1.1057) | Xent 0.0474(0.0505) | Loss 1.1307(1.1310) | Error 0.0136(0.0155) Steps 428(427.06) | Grad Norm 0.3058(0.3446) | Total Time 10.00(10.00)\n",
      "Iter 3785 | Time 32.0925(31.0652) | Bit/dim 1.1052(1.1057) | Xent 0.0470(0.0504) | Loss 1.1287(1.1309) | Error 0.0136(0.0154) Steps 428(427.09) | Grad Norm 0.3041(0.3434) | Total Time 10.00(10.00)\n",
      "Iter 3786 | Time 30.3372(31.0434) | Bit/dim 1.1052(1.1057) | Xent 0.0502(0.0504) | Loss 1.1303(1.1309) | Error 0.0156(0.0154) Steps 428(427.12) | Grad Norm 0.3723(0.3443) | Total Time 10.00(10.00)\n",
      "Iter 3787 | Time 30.7455(31.0344) | Bit/dim 1.1074(1.1057) | Xent 0.0429(0.0502) | Loss 1.1289(1.1308) | Error 0.0122(0.0153) Steps 428(427.14) | Grad Norm 0.3457(0.3443) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0541 | Time 16.9725, Epoch Time 246.1509(244.8636), Bit/dim 1.0998(best: 1.0996), Xent 0.0314, Loss 1.1155, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3788 | Time 30.8552(31.0291) | Bit/dim 1.1026(1.1056) | Xent 0.0466(0.0501) | Loss 1.1258(1.1307) | Error 0.0149(0.0153) Steps 428(427.17) | Grad Norm 0.2770(0.3423) | Total Time 10.00(10.00)\n",
      "Iter 3789 | Time 30.9759(31.0275) | Bit/dim 1.1000(1.1055) | Xent 0.0474(0.0500) | Loss 1.1237(1.1305) | Error 0.0136(0.0153) Steps 428(427.19) | Grad Norm 0.2520(0.3396) | Total Time 10.00(10.00)\n",
      "Iter 3790 | Time 30.6988(31.0176) | Bit/dim 1.1078(1.1055) | Xent 0.0542(0.0501) | Loss 1.1349(1.1306) | Error 0.0142(0.0152) Steps 428(427.22) | Grad Norm 0.3286(0.3393) | Total Time 10.00(10.00)\n",
      "Iter 3791 | Time 30.6872(31.0077) | Bit/dim 1.1104(1.1057) | Xent 0.0522(0.0502) | Loss 1.1366(1.1308) | Error 0.0166(0.0153) Steps 428(427.24) | Grad Norm 0.2792(0.3375) | Total Time 10.00(10.00)\n",
      "Iter 3792 | Time 30.7860(31.0010) | Bit/dim 1.1068(1.1057) | Xent 0.0476(0.0501) | Loss 1.1306(1.1308) | Error 0.0156(0.0153) Steps 428(427.27) | Grad Norm 0.2170(0.3339) | Total Time 10.00(10.00)\n",
      "Iter 3793 | Time 30.0518(30.9726) | Bit/dim 1.1064(1.1057) | Xent 0.0507(0.0501) | Loss 1.1318(1.1308) | Error 0.0140(0.0153) Steps 428(427.29) | Grad Norm 0.7204(0.3455) | Total Time 10.00(10.00)\n",
      "Iter 3794 | Time 30.9088(30.9706) | Bit/dim 1.1082(1.1058) | Xent 0.0518(0.0502) | Loss 1.1341(1.1309) | Error 0.0162(0.0153) Steps 428(427.31) | Grad Norm 0.3125(0.3445) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0542 | Time 16.8796, Epoch Time 243.9365(244.8358), Bit/dim 1.0998(best: 1.0996), Xent 0.0306, Loss 1.1151, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3795 | Time 30.7844(30.9651) | Bit/dim 1.1045(1.1058) | Xent 0.0460(0.0501) | Loss 1.1275(1.1308) | Error 0.0144(0.0153) Steps 428(427.33) | Grad Norm 0.2488(0.3416) | Total Time 10.00(10.00)\n",
      "Iter 3796 | Time 31.1123(30.9695) | Bit/dim 1.1056(1.1058) | Xent 0.0532(0.0502) | Loss 1.1322(1.1309) | Error 0.0158(0.0153) Steps 428(427.35) | Grad Norm 0.3150(0.3408) | Total Time 10.00(10.00)\n",
      "Iter 3797 | Time 31.4034(30.9825) | Bit/dim 1.1080(1.1058) | Xent 0.0469(0.0501) | Loss 1.1315(1.1309) | Error 0.0144(0.0152) Steps 428(427.37) | Grad Norm 0.2383(0.3377) | Total Time 10.00(10.00)\n",
      "Iter 3798 | Time 30.9208(30.9806) | Bit/dim 1.1042(1.1058) | Xent 0.0437(0.0499) | Loss 1.1261(1.1307) | Error 0.0145(0.0152) Steps 428(427.39) | Grad Norm 0.3039(0.3367) | Total Time 10.00(10.00)\n",
      "Iter 3799 | Time 30.5196(30.9668) | Bit/dim 1.1045(1.1058) | Xent 0.0521(0.0499) | Loss 1.1305(1.1307) | Error 0.0148(0.0152) Steps 428(427.41) | Grad Norm 0.1927(0.3324) | Total Time 10.00(10.00)\n",
      "Iter 3800 | Time 30.4038(30.9499) | Bit/dim 1.1021(1.1056) | Xent 0.0454(0.0498) | Loss 1.1248(1.1305) | Error 0.0141(0.0152) Steps 428(427.42) | Grad Norm 0.2830(0.3309) | Total Time 10.00(10.00)\n",
      "Iter 3801 | Time 30.9726(30.9506) | Bit/dim 1.1088(1.1057) | Xent 0.0514(0.0498) | Loss 1.1345(1.1307) | Error 0.0169(0.0152) Steps 428(427.44) | Grad Norm 0.1556(0.3256) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0543 | Time 17.0390, Epoch Time 245.3641(244.8516), Bit/dim 1.0999(best: 1.0996), Xent 0.0315, Loss 1.1156, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3802 | Time 30.3228(30.9318) | Bit/dim 1.1071(1.1058) | Xent 0.0532(0.0499) | Loss 1.1337(1.1308) | Error 0.0146(0.0152) Steps 428(427.46) | Grad Norm 0.2497(0.3234) | Total Time 10.00(10.00)\n",
      "Iter 3803 | Time 31.3872(30.9454) | Bit/dim 1.1060(1.1058) | Xent 0.0502(0.0500) | Loss 1.1311(1.1308) | Error 0.0160(0.0152) Steps 428(427.47) | Grad Norm 0.3091(0.3229) | Total Time 10.00(10.00)\n",
      "Iter 3804 | Time 30.4995(30.9320) | Bit/dim 1.1078(1.1058) | Xent 0.0574(0.0502) | Loss 1.1365(1.1309) | Error 0.0180(0.0153) Steps 428(427.49) | Grad Norm 0.2107(0.3196) | Total Time 10.00(10.00)\n",
      "Iter 3805 | Time 31.5470(30.9505) | Bit/dim 1.1027(1.1058) | Xent 0.0516(0.0502) | Loss 1.1285(1.1309) | Error 0.0156(0.0153) Steps 428(427.51) | Grad Norm 0.2319(0.3169) | Total Time 10.00(10.00)\n",
      "Iter 3806 | Time 31.5523(30.9686) | Bit/dim 1.1061(1.1058) | Xent 0.0469(0.0501) | Loss 1.1296(1.1308) | Error 0.0150(0.0153) Steps 428(427.52) | Grad Norm 0.1620(0.3123) | Total Time 10.00(10.00)\n",
      "Iter 3807 | Time 31.3719(30.9807) | Bit/dim 1.1042(1.1057) | Xent 0.0486(0.0501) | Loss 1.1285(1.1308) | Error 0.0155(0.0153) Steps 428(427.53) | Grad Norm 0.3156(0.3124) | Total Time 10.00(10.00)\n",
      "Iter 3808 | Time 31.4861(30.9958) | Bit/dim 1.1060(1.1057) | Xent 0.0577(0.0503) | Loss 1.1348(1.1309) | Error 0.0168(0.0154) Steps 428(427.55) | Grad Norm 0.3029(0.3121) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0544 | Time 16.8519, Epoch Time 247.0955(244.9189), Bit/dim 1.0999(best: 1.0996), Xent 0.0328, Loss 1.1163, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3809 | Time 31.6258(31.0147) | Bit/dim 1.1052(1.1057) | Xent 0.0480(0.0502) | Loss 1.1292(1.1308) | Error 0.0145(0.0153) Steps 428(427.56) | Grad Norm 0.2065(0.3089) | Total Time 10.00(10.00)\n",
      "Iter 3810 | Time 32.0247(31.0450) | Bit/dim 1.1068(1.1057) | Xent 0.0538(0.0503) | Loss 1.1337(1.1309) | Error 0.0162(0.0154) Steps 428(427.58) | Grad Norm 0.2497(0.3072) | Total Time 10.00(10.00)\n",
      "Iter 3811 | Time 30.9125(31.0410) | Bit/dim 1.1104(1.1059) | Xent 0.0452(0.0502) | Loss 1.1330(1.1310) | Error 0.0158(0.0154) Steps 428(427.59) | Grad Norm 0.2585(0.3057) | Total Time 10.00(10.00)\n",
      "Iter 3812 | Time 30.4863(31.0244) | Bit/dim 1.1005(1.1057) | Xent 0.0507(0.0502) | Loss 1.1259(1.1308) | Error 0.0156(0.0154) Steps 428(427.60) | Grad Norm 0.2460(0.3039) | Total Time 10.00(10.00)\n",
      "Iter 3813 | Time 31.5644(31.0406) | Bit/dim 1.1057(1.1057) | Xent 0.0513(0.0502) | Loss 1.1314(1.1308) | Error 0.0172(0.0154) Steps 428(427.61) | Grad Norm 0.5926(0.3126) | Total Time 10.00(10.00)\n",
      "Iter 3814 | Time 31.7185(31.0609) | Bit/dim 1.1072(1.1058) | Xent 0.0478(0.0502) | Loss 1.1310(1.1308) | Error 0.0152(0.0154) Steps 428(427.62) | Grad Norm 0.2010(0.3092) | Total Time 10.00(10.00)\n",
      "Iter 3815 | Time 30.7675(31.0521) | Bit/dim 1.1052(1.1057) | Xent 0.0494(0.0501) | Loss 1.1299(1.1308) | Error 0.0148(0.0154) Steps 428(427.64) | Grad Norm 0.3780(0.3113) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0545 | Time 16.9335, Epoch Time 248.2268(245.0182), Bit/dim 1.0995(best: 1.0996), Xent 0.0310, Loss 1.1150, Error 0.0098(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3816 | Time 30.2154(31.0270) | Bit/dim 1.1045(1.1057) | Xent 0.0481(0.0501) | Loss 1.1285(1.1307) | Error 0.0158(0.0154) Steps 428(427.65) | Grad Norm 0.5926(0.3197) | Total Time 10.00(10.00)\n",
      "Iter 3817 | Time 30.6166(31.0147) | Bit/dim 1.1052(1.1057) | Xent 0.0479(0.0500) | Loss 1.1292(1.1307) | Error 0.0145(0.0154) Steps 428(427.66) | Grad Norm 0.4575(0.3239) | Total Time 10.00(10.00)\n",
      "Iter 3818 | Time 30.7169(31.0058) | Bit/dim 1.1014(1.1056) | Xent 0.0503(0.0500) | Loss 1.1266(1.1306) | Error 0.0164(0.0154) Steps 428(427.67) | Grad Norm 0.2158(0.3206) | Total Time 10.00(10.00)\n",
      "Iter 3819 | Time 30.8758(31.0019) | Bit/dim 1.1067(1.1056) | Xent 0.0466(0.0499) | Loss 1.1300(1.1306) | Error 0.0144(0.0154) Steps 428(427.68) | Grad Norm 0.6206(0.3296) | Total Time 10.00(10.00)\n",
      "Iter 3820 | Time 30.5382(30.9880) | Bit/dim 1.1056(1.1056) | Xent 0.0515(0.0500) | Loss 1.1314(1.1306) | Error 0.0160(0.0154) Steps 428(427.69) | Grad Norm 0.6409(0.3390) | Total Time 10.00(10.00)\n",
      "Iter 3821 | Time 30.5386(30.9745) | Bit/dim 1.1068(1.1056) | Xent 0.0487(0.0499) | Loss 1.1312(1.1306) | Error 0.0145(0.0154) Steps 428(427.70) | Grad Norm 0.2019(0.3348) | Total Time 10.00(10.00)\n",
      "Iter 3822 | Time 30.9083(30.9725) | Bit/dim 1.1056(1.1056) | Xent 0.0486(0.0499) | Loss 1.1298(1.1306) | Error 0.0134(0.0153) Steps 428(427.71) | Grad Norm 0.5758(0.3421) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0546 | Time 16.8961, Epoch Time 243.5349(244.9737), Bit/dim 1.0997(best: 1.0995), Xent 0.0329, Loss 1.1161, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3823 | Time 30.4533(30.9569) | Bit/dim 1.1059(1.1056) | Xent 0.0506(0.0499) | Loss 1.1312(1.1306) | Error 0.0170(0.0154) Steps 428(427.71) | Grad Norm 0.3915(0.3436) | Total Time 10.00(10.00)\n",
      "Iter 3824 | Time 30.8604(30.9540) | Bit/dim 1.1044(1.1056) | Xent 0.0505(0.0499) | Loss 1.1297(1.1306) | Error 0.0158(0.0154) Steps 428(427.72) | Grad Norm 0.1758(0.3385) | Total Time 10.00(10.00)\n",
      "Iter 3825 | Time 30.9951(30.9553) | Bit/dim 1.1050(1.1056) | Xent 0.0495(0.0499) | Loss 1.1298(1.1305) | Error 0.0142(0.0154) Steps 428(427.73) | Grad Norm 0.3146(0.3378) | Total Time 10.00(10.00)\n",
      "Iter 3826 | Time 30.8303(30.9515) | Bit/dim 1.1050(1.1056) | Xent 0.0476(0.0498) | Loss 1.1288(1.1305) | Error 0.0149(0.0153) Steps 428(427.74) | Grad Norm 0.4443(0.3410) | Total Time 10.00(10.00)\n",
      "Iter 3827 | Time 32.0211(30.9836) | Bit/dim 1.1043(1.1055) | Xent 0.0606(0.0502) | Loss 1.1346(1.1306) | Error 0.0179(0.0154) Steps 428(427.75) | Grad Norm 0.3731(0.3420) | Total Time 10.00(10.00)\n",
      "Iter 3828 | Time 30.9167(30.9816) | Bit/dim 1.1082(1.1056) | Xent 0.0548(0.0503) | Loss 1.1356(1.1308) | Error 0.0165(0.0154) Steps 428(427.75) | Grad Norm 0.3134(0.3411) | Total Time 10.00(10.00)\n",
      "Iter 3829 | Time 30.9736(30.9814) | Bit/dim 1.1044(1.1056) | Xent 0.0468(0.0502) | Loss 1.1279(1.1307) | Error 0.0139(0.0154) Steps 428(427.76) | Grad Norm 0.4447(0.3442) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0547 | Time 16.9573, Epoch Time 246.2527(245.0120), Bit/dim 1.1002(best: 1.0995), Xent 0.0315, Loss 1.1160, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3830 | Time 31.4634(30.9958) | Bit/dim 1.1055(1.1056) | Xent 0.0498(0.0502) | Loss 1.1304(1.1307) | Error 0.0162(0.0154) Steps 428(427.77) | Grad Norm 0.4503(0.3474) | Total Time 10.00(10.00)\n",
      "Iter 3831 | Time 30.3552(30.9766) | Bit/dim 1.1030(1.1055) | Xent 0.0594(0.0505) | Loss 1.1327(1.1307) | Error 0.0188(0.0155) Steps 428(427.78) | Grad Norm 0.2577(0.3447) | Total Time 10.00(10.00)\n",
      "Iter 3832 | Time 30.9592(30.9761) | Bit/dim 1.1079(1.1056) | Xent 0.0532(0.0506) | Loss 1.1345(1.1308) | Error 0.0162(0.0155) Steps 428(427.78) | Grad Norm 0.3540(0.3450) | Total Time 10.00(10.00)\n",
      "Iter 3833 | Time 31.1404(30.9810) | Bit/dim 1.1099(1.1057) | Xent 0.0483(0.0505) | Loss 1.1340(1.1309) | Error 0.0148(0.0155) Steps 428(427.79) | Grad Norm 0.5521(0.3512) | Total Time 10.00(10.00)\n",
      "Iter 3834 | Time 32.0594(31.0134) | Bit/dim 1.1067(1.1057) | Xent 0.0478(0.0504) | Loss 1.1306(1.1309) | Error 0.0152(0.0155) Steps 428(427.80) | Grad Norm 0.1675(0.3457) | Total Time 10.00(10.00)\n",
      "Iter 3835 | Time 31.3111(31.0223) | Bit/dim 1.1013(1.1056) | Xent 0.0456(0.0503) | Loss 1.1241(1.1307) | Error 0.0131(0.0154) Steps 428(427.80) | Grad Norm 0.2633(0.3432) | Total Time 10.00(10.00)\n",
      "Iter 3836 | Time 30.8689(31.0177) | Bit/dim 1.1071(1.1056) | Xent 0.0475(0.0502) | Loss 1.1309(1.1307) | Error 0.0139(0.0154) Steps 428(427.81) | Grad Norm 0.2762(0.3412) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0548 | Time 16.8784, Epoch Time 247.4530(245.0853), Bit/dim 1.0999(best: 1.0995), Xent 0.0302, Loss 1.1150, Error 0.0095(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3837 | Time 30.3405(30.9974) | Bit/dim 1.1020(1.1055) | Xent 0.0542(0.0503) | Loss 1.1291(1.1307) | Error 0.0170(0.0154) Steps 428(427.81) | Grad Norm 0.2515(0.3385) | Total Time 10.00(10.00)\n",
      "Iter 3838 | Time 32.2688(31.0355) | Bit/dim 1.1057(1.1055) | Xent 0.0495(0.0503) | Loss 1.1304(1.1307) | Error 0.0149(0.0154) Steps 428(427.82) | Grad Norm 0.2925(0.3371) | Total Time 10.00(10.00)\n",
      "Iter 3839 | Time 30.9930(31.0342) | Bit/dim 1.1046(1.1055) | Xent 0.0477(0.0502) | Loss 1.1284(1.1306) | Error 0.0149(0.0154) Steps 428(427.82) | Grad Norm 0.1493(0.3315) | Total Time 10.00(10.00)\n",
      "Iter 3840 | Time 30.2228(31.0099) | Bit/dim 1.1043(1.1055) | Xent 0.0528(0.0503) | Loss 1.1307(1.1306) | Error 0.0181(0.0155) Steps 428(427.83) | Grad Norm 0.3285(0.3314) | Total Time 10.00(10.00)\n",
      "Iter 3841 | Time 31.2090(31.0159) | Bit/dim 1.1063(1.1055) | Xent 0.0562(0.0505) | Loss 1.1344(1.1307) | Error 0.0162(0.0155) Steps 428(427.83) | Grad Norm 0.2891(0.3301) | Total Time 10.00(10.00)\n",
      "Iter 3842 | Time 30.8894(31.0121) | Bit/dim 1.1085(1.1056) | Xent 0.0450(0.0503) | Loss 1.1310(1.1307) | Error 0.0156(0.0155) Steps 428(427.84) | Grad Norm 0.1947(0.3261) | Total Time 10.00(10.00)\n",
      "Iter 3843 | Time 30.6789(31.0021) | Bit/dim 1.1054(1.1056) | Xent 0.0399(0.0500) | Loss 1.1254(1.1306) | Error 0.0124(0.0154) Steps 428(427.84) | Grad Norm 0.2379(0.3234) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0549 | Time 16.9239, Epoch Time 245.4070(245.0949), Bit/dim 1.1005(best: 1.0995), Xent 0.0317, Loss 1.1164, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3844 | Time 30.4810(30.9864) | Bit/dim 1.1024(1.1055) | Xent 0.0543(0.0501) | Loss 1.1295(1.1305) | Error 0.0158(0.0154) Steps 428(427.85) | Grad Norm 0.2117(0.3201) | Total Time 10.00(10.00)\n",
      "Iter 3845 | Time 32.2326(31.0238) | Bit/dim 1.1021(1.1054) | Xent 0.0465(0.0500) | Loss 1.1253(1.1304) | Error 0.0141(0.0154) Steps 428(427.85) | Grad Norm 0.2639(0.3184) | Total Time 10.00(10.00)\n",
      "Iter 3846 | Time 31.0112(31.0235) | Bit/dim 1.1065(1.1054) | Xent 0.0447(0.0498) | Loss 1.1289(1.1303) | Error 0.0139(0.0153) Steps 428(427.86) | Grad Norm 0.5032(0.3239) | Total Time 10.00(10.00)\n",
      "Iter 3847 | Time 30.4453(31.0061) | Bit/dim 1.1089(1.1055) | Xent 0.0476(0.0498) | Loss 1.1327(1.1304) | Error 0.0139(0.0153) Steps 428(427.86) | Grad Norm 0.2236(0.3209) | Total Time 10.00(10.00)\n",
      "Iter 3848 | Time 31.7314(31.0279) | Bit/dim 1.1047(1.1055) | Xent 0.0411(0.0495) | Loss 1.1252(1.1303) | Error 0.0128(0.0152) Steps 428(427.87) | Grad Norm 0.1711(0.3164) | Total Time 10.00(10.00)\n",
      "Iter 3849 | Time 30.2384(31.0042) | Bit/dim 1.1075(1.1056) | Xent 0.0545(0.0497) | Loss 1.1348(1.1304) | Error 0.0170(0.0153) Steps 428(427.87) | Grad Norm 0.3409(0.3172) | Total Time 10.00(10.00)\n",
      "Iter 3850 | Time 31.7023(31.0251) | Bit/dim 1.1077(1.1056) | Xent 0.0517(0.0497) | Loss 1.1335(1.1305) | Error 0.0145(0.0153) Steps 428(427.87) | Grad Norm 0.3827(0.3191) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0550 | Time 16.6723, Epoch Time 246.8049(245.1462), Bit/dim 1.1001(best: 1.0995), Xent 0.0317, Loss 1.1160, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3851 | Time 30.5590(31.0111) | Bit/dim 1.1064(1.1056) | Xent 0.0537(0.0498) | Loss 1.1333(1.1306) | Error 0.0178(0.0153) Steps 428(427.88) | Grad Norm 0.1960(0.3154) | Total Time 10.00(10.00)\n",
      "Iter 3852 | Time 30.5939(30.9986) | Bit/dim 1.1050(1.1056) | Xent 0.0477(0.0498) | Loss 1.1289(1.1305) | Error 0.0141(0.0153) Steps 428(427.88) | Grad Norm 0.2799(0.3144) | Total Time 10.00(10.00)\n",
      "Iter 3853 | Time 31.1081(31.0019) | Bit/dim 1.1052(1.1056) | Xent 0.0480(0.0497) | Loss 1.1292(1.1305) | Error 0.0144(0.0153) Steps 428(427.89) | Grad Norm 0.2044(0.3111) | Total Time 10.00(10.00)\n",
      "Iter 3854 | Time 30.5948(30.9897) | Bit/dim 1.1043(1.1056) | Xent 0.0590(0.0500) | Loss 1.1338(1.1306) | Error 0.0166(0.0153) Steps 428(427.89) | Grad Norm 0.2867(0.3103) | Total Time 10.00(10.00)\n",
      "Iter 3855 | Time 30.5137(30.9754) | Bit/dim 1.1033(1.1055) | Xent 0.0450(0.0499) | Loss 1.1258(1.1304) | Error 0.0158(0.0153) Steps 428(427.89) | Grad Norm 0.3096(0.3103) | Total Time 10.00(10.00)\n",
      "Iter 3856 | Time 30.7217(30.9678) | Bit/dim 1.1081(1.1056) | Xent 0.0514(0.0499) | Loss 1.1338(1.1305) | Error 0.0151(0.0153) Steps 428(427.90) | Grad Norm 0.2378(0.3081) | Total Time 10.00(10.00)\n",
      "Iter 3857 | Time 30.2836(30.9473) | Bit/dim 1.1042(1.1055) | Xent 0.0515(0.0499) | Loss 1.1299(1.1305) | Error 0.0145(0.0153) Steps 428(427.90) | Grad Norm 0.3051(0.3081) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0551 | Time 16.9276, Epoch Time 243.6138(245.1002), Bit/dim 1.1000(best: 1.0995), Xent 0.0336, Loss 1.1168, Error 0.0096(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3858 | Time 30.3697(30.9300) | Bit/dim 1.1024(1.1054) | Xent 0.0521(0.0500) | Loss 1.1284(1.1305) | Error 0.0176(0.0154) Steps 428(427.90) | Grad Norm 0.3974(0.3107) | Total Time 10.00(10.00)\n",
      "Iter 3859 | Time 30.2327(30.9090) | Bit/dim 1.1049(1.1054) | Xent 0.0554(0.0502) | Loss 1.1327(1.1305) | Error 0.0188(0.0155) Steps 428(427.90) | Grad Norm 0.3342(0.3114) | Total Time 10.00(10.00)\n",
      "Iter 3860 | Time 30.3921(30.8935) | Bit/dim 1.1043(1.1054) | Xent 0.0545(0.0503) | Loss 1.1315(1.1306) | Error 0.0159(0.0155) Steps 428(427.91) | Grad Norm 0.2109(0.3084) | Total Time 10.00(10.00)\n",
      "Iter 3861 | Time 30.2590(30.8745) | Bit/dim 1.1021(1.1053) | Xent 0.0462(0.0502) | Loss 1.1252(1.1304) | Error 0.0136(0.0154) Steps 428(427.91) | Grad Norm 0.2230(0.3059) | Total Time 10.00(10.00)\n",
      "Iter 3862 | Time 31.4244(30.8910) | Bit/dim 1.1059(1.1053) | Xent 0.0486(0.0501) | Loss 1.1302(1.1304) | Error 0.0146(0.0154) Steps 428(427.91) | Grad Norm 0.3676(0.3077) | Total Time 10.00(10.00)\n",
      "Iter 3863 | Time 31.2691(30.9023) | Bit/dim 1.1083(1.1054) | Xent 0.0471(0.0500) | Loss 1.1319(1.1304) | Error 0.0139(0.0154) Steps 428(427.92) | Grad Norm 0.2004(0.3045) | Total Time 10.00(10.00)\n",
      "Iter 3864 | Time 32.2590(30.9430) | Bit/dim 1.1082(1.1055) | Xent 0.0413(0.0498) | Loss 1.1288(1.1304) | Error 0.0128(0.0153) Steps 428(427.92) | Grad Norm 0.2172(0.3019) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0552 | Time 16.8342, Epoch Time 245.3825(245.1087), Bit/dim 1.0995(best: 1.0995), Xent 0.0306, Loss 1.1149, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3865 | Time 30.9378(30.9429) | Bit/dim 1.1024(1.1054) | Xent 0.0451(0.0496) | Loss 1.1249(1.1302) | Error 0.0149(0.0153) Steps 428(427.92) | Grad Norm 0.1514(0.2974) | Total Time 10.00(10.00)\n",
      "Iter 3866 | Time 30.8653(30.9406) | Bit/dim 1.1099(1.1055) | Xent 0.0503(0.0497) | Loss 1.1351(1.1304) | Error 0.0159(0.0153) Steps 428(427.92) | Grad Norm 0.2725(0.2966) | Total Time 10.00(10.00)\n",
      "Iter 3867 | Time 32.1370(30.9764) | Bit/dim 1.1064(1.1056) | Xent 0.0483(0.0496) | Loss 1.1306(1.1304) | Error 0.0151(0.0153) Steps 428(427.93) | Grad Norm 0.1668(0.2927) | Total Time 10.00(10.00)\n",
      "Iter 3868 | Time 30.2911(30.9559) | Bit/dim 1.1028(1.1055) | Xent 0.0461(0.0495) | Loss 1.1258(1.1302) | Error 0.0155(0.0153) Steps 428(427.93) | Grad Norm 0.2450(0.2913) | Total Time 10.00(10.00)\n",
      "Iter 3869 | Time 31.3319(30.9672) | Bit/dim 1.1026(1.1054) | Xent 0.0438(0.0493) | Loss 1.1244(1.1301) | Error 0.0149(0.0153) Steps 428(427.93) | Grad Norm 0.5022(0.2976) | Total Time 10.00(10.00)\n",
      "Iter 3870 | Time 30.7806(30.9616) | Bit/dim 1.1066(1.1054) | Xent 0.0535(0.0495) | Loss 1.1334(1.1302) | Error 0.0158(0.0153) Steps 428(427.93) | Grad Norm 0.2343(0.2957) | Total Time 10.00(10.00)\n",
      "Iter 3871 | Time 30.9583(30.9615) | Bit/dim 1.1051(1.1054) | Xent 0.0535(0.0496) | Loss 1.1318(1.1302) | Error 0.0161(0.0153) Steps 428(427.93) | Grad Norm 0.2452(0.2942) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0553 | Time 16.8820, Epoch Time 246.3967(245.1473), Bit/dim 1.0996(best: 1.0995), Xent 0.0324, Loss 1.1158, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3872 | Time 31.8904(30.9893) | Bit/dim 1.1074(1.1055) | Xent 0.0527(0.0497) | Loss 1.1338(1.1303) | Error 0.0151(0.0153) Steps 428(427.94) | Grad Norm 0.5233(0.3011) | Total Time 10.00(10.00)\n",
      "Iter 3873 | Time 31.6123(31.0080) | Bit/dim 1.1031(1.1054) | Xent 0.0475(0.0496) | Loss 1.1268(1.1302) | Error 0.0139(0.0153) Steps 428(427.94) | Grad Norm 0.4178(0.3046) | Total Time 10.00(10.00)\n",
      "Iter 3874 | Time 30.8074(31.0020) | Bit/dim 1.1083(1.1055) | Xent 0.0501(0.0496) | Loss 1.1333(1.1303) | Error 0.0152(0.0153) Steps 428(427.94) | Grad Norm 0.3156(0.3049) | Total Time 10.00(10.00)\n",
      "Iter 3875 | Time 30.7106(30.9933) | Bit/dim 1.1028(1.1054) | Xent 0.0486(0.0496) | Loss 1.1271(1.1302) | Error 0.0155(0.0153) Steps 428(427.94) | Grad Norm 0.3977(0.3077) | Total Time 10.00(10.00)\n",
      "Iter 3876 | Time 30.4213(30.9761) | Bit/dim 1.1068(1.1055) | Xent 0.0418(0.0494) | Loss 1.1277(1.1301) | Error 0.0130(0.0152) Steps 428(427.94) | Grad Norm 0.3570(0.3092) | Total Time 10.00(10.00)\n",
      "Iter 3877 | Time 30.6605(30.9666) | Bit/dim 1.1043(1.1054) | Xent 0.0491(0.0494) | Loss 1.1289(1.1301) | Error 0.0146(0.0152) Steps 428(427.94) | Grad Norm 0.1706(0.3050) | Total Time 10.00(10.00)\n",
      "Iter 3878 | Time 30.8650(30.9636) | Bit/dim 1.1034(1.1054) | Xent 0.0490(0.0493) | Loss 1.1279(1.1300) | Error 0.0154(0.0152) Steps 428(427.95) | Grad Norm 0.5743(0.3131) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0554 | Time 16.7411, Epoch Time 245.9130(245.1703), Bit/dim 1.0992(best: 1.0995), Xent 0.0337, Loss 1.1161, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3879 | Time 30.3740(30.9459) | Bit/dim 1.1047(1.1053) | Xent 0.0480(0.0493) | Loss 1.1287(1.1300) | Error 0.0131(0.0151) Steps 428(427.95) | Grad Norm 0.4524(0.3173) | Total Time 10.00(10.00)\n",
      "Iter 3880 | Time 30.4067(30.9297) | Bit/dim 1.1056(1.1053) | Xent 0.0530(0.0494) | Loss 1.1320(1.1301) | Error 0.0146(0.0151) Steps 428(427.95) | Grad Norm 0.3305(0.3177) | Total Time 10.00(10.00)\n",
      "Iter 3881 | Time 30.2933(30.9106) | Bit/dim 1.1066(1.1054) | Xent 0.0539(0.0496) | Loss 1.1336(1.1302) | Error 0.0161(0.0151) Steps 428(427.95) | Grad Norm 0.5225(0.3238) | Total Time 10.00(10.00)\n",
      "Iter 3882 | Time 30.4505(30.8968) | Bit/dim 1.1013(1.1053) | Xent 0.0451(0.0494) | Loss 1.1239(1.1300) | Error 0.0128(0.0151) Steps 428(427.95) | Grad Norm 0.5709(0.3312) | Total Time 10.00(10.00)\n",
      "Iter 3883 | Time 30.3871(30.8815) | Bit/dim 1.1044(1.1052) | Xent 0.0514(0.0495) | Loss 1.1301(1.1300) | Error 0.0171(0.0151) Steps 428(427.95) | Grad Norm 0.5187(0.3368) | Total Time 10.00(10.00)\n",
      "Iter 3884 | Time 30.7819(30.8786) | Bit/dim 1.1020(1.1051) | Xent 0.0450(0.0493) | Loss 1.1245(1.1298) | Error 0.0121(0.0150) Steps 428(427.96) | Grad Norm 0.5663(0.3437) | Total Time 10.00(10.00)\n",
      "Iter 3885 | Time 30.7751(30.8754) | Bit/dim 1.1072(1.1052) | Xent 0.0512(0.0494) | Loss 1.1328(1.1299) | Error 0.0159(0.0151) Steps 428(427.96) | Grad Norm 0.3850(0.3450) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0555 | Time 16.8790, Epoch Time 242.4084(245.0875), Bit/dim 1.0993(best: 1.0992), Xent 0.0307, Loss 1.1147, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3886 | Time 32.2052(30.9153) | Bit/dim 1.1093(1.1053) | Xent 0.0471(0.0493) | Loss 1.1329(1.1300) | Error 0.0132(0.0150) Steps 428(427.96) | Grad Norm 0.2902(0.3433) | Total Time 10.00(10.00)\n",
      "Iter 3887 | Time 30.9153(30.9153) | Bit/dim 1.1004(1.1052) | Xent 0.0514(0.0494) | Loss 1.1261(1.1299) | Error 0.0151(0.0150) Steps 422(427.78) | Grad Norm 0.5366(0.3491) | Total Time 10.00(10.00)\n",
      "Iter 3888 | Time 30.5060(30.9031) | Bit/dim 1.1049(1.1052) | Xent 0.0521(0.0495) | Loss 1.1310(1.1299) | Error 0.0155(0.0150) Steps 422(427.61) | Grad Norm 0.6323(0.3576) | Total Time 10.00(10.00)\n",
      "Iter 3889 | Time 30.0282(30.8768) | Bit/dim 1.1092(1.1053) | Xent 0.0526(0.0496) | Loss 1.1355(1.1301) | Error 0.0155(0.0150) Steps 428(427.62) | Grad Norm 0.1983(0.3528) | Total Time 10.00(10.00)\n",
      "Iter 3890 | Time 30.5576(30.8672) | Bit/dim 1.1033(1.1052) | Xent 0.0503(0.0496) | Loss 1.1285(1.1300) | Error 0.0141(0.0150) Steps 428(427.63) | Grad Norm 0.6773(0.3626) | Total Time 10.00(10.00)\n",
      "Iter 3891 | Time 30.4500(30.8547) | Bit/dim 1.1071(1.1053) | Xent 0.0501(0.0496) | Loss 1.1321(1.1301) | Error 0.0165(0.0151) Steps 428(427.64) | Grad Norm 0.9615(0.3805) | Total Time 10.00(10.00)\n",
      "Iter 3892 | Time 30.7337(30.8511) | Bit/dim 1.1063(1.1053) | Xent 0.0471(0.0495) | Loss 1.1298(1.1301) | Error 0.0151(0.0151) Steps 428(427.65) | Grad Norm 0.2074(0.3753) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0556 | Time 17.2059, Epoch Time 244.7674(245.0779), Bit/dim 1.0996(best: 1.0992), Xent 0.0312, Loss 1.1152, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3893 | Time 31.2209(30.8622) | Bit/dim 1.1065(1.1054) | Xent 0.0439(0.0494) | Loss 1.1285(1.1300) | Error 0.0134(0.0150) Steps 428(427.66) | Grad Norm 0.7437(0.3864) | Total Time 10.00(10.00)\n",
      "Iter 3894 | Time 31.0734(30.8685) | Bit/dim 1.1020(1.1053) | Xent 0.0428(0.0492) | Loss 1.1234(1.1298) | Error 0.0121(0.0149) Steps 422(427.49) | Grad Norm 0.6969(0.3957) | Total Time 10.00(10.00)\n",
      "Iter 3895 | Time 30.9524(30.8710) | Bit/dim 1.1066(1.1053) | Xent 0.0440(0.0490) | Loss 1.1286(1.1298) | Error 0.0136(0.0149) Steps 428(427.51) | Grad Norm 0.2766(0.3921) | Total Time 10.00(10.00)\n",
      "Iter 3896 | Time 31.3111(30.8842) | Bit/dim 1.1029(1.1052) | Xent 0.0420(0.0488) | Loss 1.1239(1.1296) | Error 0.0128(0.0148) Steps 428(427.52) | Grad Norm 0.7779(0.4037) | Total Time 10.00(10.00)\n",
      "Iter 3897 | Time 30.2819(30.8662) | Bit/dim 1.1071(1.1053) | Xent 0.0553(0.0490) | Loss 1.1347(1.1298) | Error 0.0161(0.0149) Steps 428(427.54) | Grad Norm 1.1235(0.4253) | Total Time 10.00(10.00)\n",
      "Iter 3898 | Time 31.6887(30.8908) | Bit/dim 1.1013(1.1052) | Xent 0.0474(0.0489) | Loss 1.1249(1.1296) | Error 0.0145(0.0149) Steps 428(427.55) | Grad Norm 0.1814(0.4180) | Total Time 10.00(10.00)\n",
      "Iter 3899 | Time 31.6848(30.9147) | Bit/dim 1.1088(1.1053) | Xent 0.0538(0.0491) | Loss 1.1357(1.1298) | Error 0.0160(0.0149) Steps 422(427.38) | Grad Norm 0.8128(0.4298) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0557 | Time 16.7262, Epoch Time 247.1345(245.1396), Bit/dim 1.0997(best: 1.0992), Xent 0.0303, Loss 1.1148, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3900 | Time 30.5504(30.9037) | Bit/dim 1.1065(1.1053) | Xent 0.0492(0.0491) | Loss 1.1311(1.1299) | Error 0.0149(0.0149) Steps 428(427.40) | Grad Norm 1.0777(0.4493) | Total Time 10.00(10.00)\n",
      "Iter 3901 | Time 31.1447(30.9110) | Bit/dim 1.1075(1.1054) | Xent 0.0609(0.0494) | Loss 1.1380(1.1301) | Error 0.0179(0.0150) Steps 428(427.42) | Grad Norm 0.2961(0.4447) | Total Time 10.00(10.00)\n",
      "Iter 3902 | Time 30.6715(30.9038) | Bit/dim 1.1060(1.1054) | Xent 0.0466(0.0494) | Loss 1.1293(1.1301) | Error 0.0155(0.0150) Steps 428(427.44) | Grad Norm 0.8806(0.4578) | Total Time 10.00(10.00)\n",
      "Iter 3903 | Time 32.3499(30.9472) | Bit/dim 1.1016(1.1053) | Xent 0.0513(0.0494) | Loss 1.1273(1.1300) | Error 0.0158(0.0150) Steps 428(427.45) | Grad Norm 0.7119(0.4654) | Total Time 10.00(10.00)\n",
      "Iter 3904 | Time 30.8639(30.9447) | Bit/dim 1.1041(1.1052) | Xent 0.0513(0.0495) | Loss 1.1297(1.1300) | Error 0.0160(0.0150) Steps 428(427.47) | Grad Norm 0.1840(0.4569) | Total Time 10.00(10.00)\n",
      "Iter 3905 | Time 30.8180(30.9409) | Bit/dim 1.1067(1.1053) | Xent 0.0463(0.0494) | Loss 1.1298(1.1300) | Error 0.0128(0.0150) Steps 428(427.49) | Grad Norm 0.7148(0.4647) | Total Time 10.00(10.00)\n",
      "Iter 3906 | Time 30.4546(30.9263) | Bit/dim 1.1030(1.1052) | Xent 0.0478(0.0493) | Loss 1.1269(1.1299) | Error 0.0156(0.0150) Steps 428(427.50) | Grad Norm 0.6140(0.4692) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0558 | Time 17.1995, Epoch Time 246.4403(245.1786), Bit/dim 1.0988(best: 1.0992), Xent 0.0322, Loss 1.1149, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3907 | Time 30.4615(30.9123) | Bit/dim 1.1081(1.1053) | Xent 0.0443(0.0492) | Loss 1.1302(1.1299) | Error 0.0150(0.0150) Steps 428(427.52) | Grad Norm 0.2100(0.4614) | Total Time 10.00(10.00)\n",
      "Iter 3908 | Time 30.9761(30.9143) | Bit/dim 1.1020(1.1052) | Xent 0.0566(0.0494) | Loss 1.1303(1.1299) | Error 0.0185(0.0151) Steps 428(427.53) | Grad Norm 0.7888(0.4712) | Total Time 10.00(10.00)\n",
      "Iter 3909 | Time 31.9944(30.9467) | Bit/dim 1.1034(1.1051) | Xent 0.0495(0.0494) | Loss 1.1281(1.1298) | Error 0.0144(0.0151) Steps 428(427.55) | Grad Norm 0.4049(0.4692) | Total Time 10.00(10.00)\n",
      "Iter 3910 | Time 30.9916(30.9480) | Bit/dim 1.1068(1.1052) | Xent 0.0507(0.0494) | Loss 1.1322(1.1299) | Error 0.0138(0.0150) Steps 428(427.56) | Grad Norm 0.2607(0.4630) | Total Time 10.00(10.00)\n",
      "Iter 3911 | Time 31.0554(30.9512) | Bit/dim 1.1057(1.1052) | Xent 0.0503(0.0495) | Loss 1.1308(1.1299) | Error 0.0161(0.0151) Steps 422(427.39) | Grad Norm 0.3256(0.4588) | Total Time 10.00(10.00)\n",
      "Iter 3912 | Time 30.5882(30.9403) | Bit/dim 1.1023(1.1051) | Xent 0.0458(0.0494) | Loss 1.1252(1.1298) | Error 0.0130(0.0150) Steps 428(427.41) | Grad Norm 0.5126(0.4605) | Total Time 10.00(10.00)\n",
      "Iter 3913 | Time 31.6238(30.9608) | Bit/dim 1.1072(1.1052) | Xent 0.0455(0.0492) | Loss 1.1299(1.1298) | Error 0.0135(0.0150) Steps 422(427.25) | Grad Norm 0.3394(0.4568) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0559 | Time 16.7010, Epoch Time 246.4875(245.2178), Bit/dim 1.0984(best: 1.0988), Xent 0.0321, Loss 1.1145, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3914 | Time 31.4081(30.9743) | Bit/dim 1.1056(1.1052) | Xent 0.0401(0.0490) | Loss 1.1257(1.1297) | Error 0.0116(0.0149) Steps 428(427.27) | Grad Norm 0.3497(0.4536) | Total Time 10.00(10.00)\n",
      "Iter 3915 | Time 30.3355(30.9551) | Bit/dim 1.0998(1.1050) | Xent 0.0479(0.0489) | Loss 1.1237(1.1295) | Error 0.0154(0.0149) Steps 428(427.29) | Grad Norm 0.4356(0.4531) | Total Time 10.00(10.00)\n",
      "Iter 3916 | Time 30.6388(30.9456) | Bit/dim 1.1065(1.1051) | Xent 0.0528(0.0491) | Loss 1.1329(1.1296) | Error 0.0149(0.0149) Steps 428(427.31) | Grad Norm 0.1913(0.4452) | Total Time 10.00(10.00)\n",
      "Iter 3917 | Time 32.2617(30.9851) | Bit/dim 1.1027(1.1050) | Xent 0.0505(0.0491) | Loss 1.1280(1.1296) | Error 0.0160(0.0149) Steps 428(427.33) | Grad Norm 0.2368(0.4390) | Total Time 10.00(10.00)\n",
      "Iter 3918 | Time 30.6004(30.9735) | Bit/dim 1.1068(1.1051) | Xent 0.0524(0.0492) | Loss 1.1330(1.1297) | Error 0.0154(0.0149) Steps 428(427.35) | Grad Norm 0.2598(0.4336) | Total Time 10.00(10.00)\n",
      "Iter 3919 | Time 31.9696(31.0034) | Bit/dim 1.1089(1.1052) | Xent 0.0507(0.0492) | Loss 1.1342(1.1298) | Error 0.0156(0.0149) Steps 428(427.37) | Grad Norm 0.3818(0.4320) | Total Time 10.00(10.00)\n",
      "Iter 3920 | Time 31.8685(31.0294) | Bit/dim 1.1027(1.1051) | Xent 0.0452(0.0491) | Loss 1.1253(1.1297) | Error 0.0145(0.0149) Steps 422(427.21) | Grad Norm 0.2400(0.4263) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0560 | Time 16.5394, Epoch Time 247.8873(245.2979), Bit/dim 1.0995(best: 1.0984), Xent 0.0330, Loss 1.1161, Error 0.0109(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3921 | Time 31.0729(31.0307) | Bit/dim 1.1011(1.1050) | Xent 0.0463(0.0490) | Loss 1.1243(1.1295) | Error 0.0158(0.0150) Steps 428(427.24) | Grad Norm 0.2297(0.4204) | Total Time 10.00(10.00)\n",
      "Iter 3922 | Time 30.7586(31.0225) | Bit/dim 1.1082(1.1051) | Xent 0.0543(0.0492) | Loss 1.1353(1.1297) | Error 0.0168(0.0150) Steps 428(427.26) | Grad Norm 0.2384(0.4149) | Total Time 10.00(10.00)\n",
      "Iter 3923 | Time 30.5377(31.0080) | Bit/dim 1.1093(1.1052) | Xent 0.0536(0.0493) | Loss 1.1361(1.1299) | Error 0.0152(0.0150) Steps 428(427.28) | Grad Norm 0.2715(0.4106) | Total Time 10.00(10.00)\n",
      "Iter 3924 | Time 30.6190(30.9963) | Bit/dim 1.1072(1.1053) | Xent 0.0503(0.0494) | Loss 1.1324(1.1299) | Error 0.0159(0.0150) Steps 428(427.30) | Grad Norm 0.4022(0.4104) | Total Time 10.00(10.00)\n",
      "Iter 3925 | Time 31.0971(30.9993) | Bit/dim 1.1024(1.1052) | Xent 0.0598(0.0497) | Loss 1.1323(1.1300) | Error 0.0162(0.0151) Steps 428(427.32) | Grad Norm 0.2523(0.4056) | Total Time 10.00(10.00)\n",
      "Iter 3926 | Time 30.7206(30.9910) | Bit/dim 1.1027(1.1051) | Xent 0.0423(0.0494) | Loss 1.1239(1.1298) | Error 0.0134(0.0150) Steps 428(427.34) | Grad Norm 0.3853(0.4050) | Total Time 10.00(10.00)\n",
      "Iter 3927 | Time 30.3741(30.9725) | Bit/dim 1.1062(1.1051) | Xent 0.0458(0.0493) | Loss 1.1291(1.1298) | Error 0.0148(0.0150) Steps 428(427.36) | Grad Norm 0.1999(0.3989) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0561 | Time 17.0792, Epoch Time 244.6158(245.2775), Bit/dim 1.0990(best: 1.0984), Xent 0.0319, Loss 1.1150, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3928 | Time 30.1387(30.9475) | Bit/dim 1.0983(1.1049) | Xent 0.0531(0.0495) | Loss 1.1248(1.1297) | Error 0.0172(0.0151) Steps 428(427.38) | Grad Norm 0.4908(0.4016) | Total Time 10.00(10.00)\n",
      "Iter 3929 | Time 30.7023(30.9401) | Bit/dim 1.1074(1.1050) | Xent 0.0499(0.0495) | Loss 1.1324(1.1297) | Error 0.0154(0.0151) Steps 428(427.40) | Grad Norm 0.3488(0.4000) | Total Time 10.00(10.00)\n",
      "Iter 3930 | Time 32.6734(30.9921) | Bit/dim 1.1079(1.1051) | Xent 0.0525(0.0496) | Loss 1.1342(1.1299) | Error 0.0150(0.0151) Steps 422(427.24) | Grad Norm 0.4237(0.4007) | Total Time 10.00(10.00)\n",
      "Iter 3931 | Time 30.5008(30.9774) | Bit/dim 1.1010(1.1050) | Xent 0.0444(0.0494) | Loss 1.1232(1.1297) | Error 0.0140(0.0151) Steps 428(427.26) | Grad Norm 0.3524(0.3993) | Total Time 10.00(10.00)\n",
      "Iter 3932 | Time 30.3123(30.9574) | Bit/dim 1.1044(1.1050) | Xent 0.0447(0.0493) | Loss 1.1268(1.1296) | Error 0.0154(0.0151) Steps 428(427.28) | Grad Norm 0.2361(0.3944) | Total Time 10.00(10.00)\n",
      "Iter 3933 | Time 31.3286(30.9685) | Bit/dim 1.1075(1.1050) | Xent 0.0463(0.0492) | Loss 1.1306(1.1296) | Error 0.0156(0.0151) Steps 428(427.31) | Grad Norm 0.4250(0.3953) | Total Time 10.00(10.00)\n",
      "Iter 3934 | Time 30.6024(30.9576) | Bit/dim 1.1058(1.1051) | Xent 0.0471(0.0491) | Loss 1.1294(1.1296) | Error 0.0148(0.0151) Steps 428(427.33) | Grad Norm 0.3496(0.3939) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0562 | Time 16.8746, Epoch Time 245.3318(245.2791), Bit/dim 1.0992(best: 1.0984), Xent 0.0320, Loss 1.1152, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3935 | Time 31.0430(30.9601) | Bit/dim 1.1088(1.1052) | Xent 0.0507(0.0492) | Loss 1.1342(1.1297) | Error 0.0151(0.0151) Steps 428(427.35) | Grad Norm 0.3440(0.3924) | Total Time 10.00(10.00)\n",
      "Iter 3936 | Time 31.5693(30.9784) | Bit/dim 1.0991(1.1050) | Xent 0.0458(0.0491) | Loss 1.1220(1.1295) | Error 0.0140(0.0150) Steps 428(427.37) | Grad Norm 0.2333(0.3877) | Total Time 10.00(10.00)\n",
      "Iter 3937 | Time 30.8047(30.9732) | Bit/dim 1.1007(1.1049) | Xent 0.0413(0.0488) | Loss 1.1214(1.1293) | Error 0.0134(0.0150) Steps 428(427.39) | Grad Norm 0.3667(0.3870) | Total Time 10.00(10.00)\n",
      "Iter 3938 | Time 30.6754(30.9643) | Bit/dim 1.1076(1.1049) | Xent 0.0544(0.0490) | Loss 1.1348(1.1294) | Error 0.0171(0.0151) Steps 428(427.40) | Grad Norm 0.3943(0.3873) | Total Time 10.00(10.00)\n",
      "Iter 3939 | Time 30.4006(30.9473) | Bit/dim 1.1116(1.1051) | Xent 0.0540(0.0491) | Loss 1.1386(1.1297) | Error 0.0166(0.0151) Steps 428(427.42) | Grad Norm 0.4231(0.3883) | Total Time 10.00(10.00)\n",
      "Iter 3940 | Time 31.5008(30.9639) | Bit/dim 1.1069(1.1052) | Xent 0.0480(0.0491) | Loss 1.1309(1.1297) | Error 0.0134(0.0151) Steps 428(427.44) | Grad Norm 0.2794(0.3851) | Total Time 10.00(10.00)\n",
      "Iter 3941 | Time 30.8712(30.9612) | Bit/dim 1.1020(1.1051) | Xent 0.0523(0.0492) | Loss 1.1281(1.1297) | Error 0.0170(0.0151) Steps 428(427.46) | Grad Norm 0.4659(0.3875) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0563 | Time 16.8361, Epoch Time 245.7904(245.2944), Bit/dim 1.0991(best: 1.0984), Xent 0.0325, Loss 1.1153, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3942 | Time 31.1452(30.9667) | Bit/dim 1.1066(1.1051) | Xent 0.0471(0.0491) | Loss 1.1302(1.1297) | Error 0.0138(0.0151) Steps 428(427.47) | Grad Norm 0.2603(0.3837) | Total Time 10.00(10.00)\n",
      "Iter 3943 | Time 31.1545(30.9723) | Bit/dim 1.1068(1.1052) | Xent 0.0493(0.0491) | Loss 1.1315(1.1298) | Error 0.0171(0.0151) Steps 422(427.31) | Grad Norm 0.5214(0.3878) | Total Time 10.00(10.00)\n",
      "Iter 3944 | Time 31.0904(30.9759) | Bit/dim 1.1032(1.1051) | Xent 0.0484(0.0491) | Loss 1.1275(1.1297) | Error 0.0146(0.0151) Steps 428(427.33) | Grad Norm 0.4674(0.3902) | Total Time 10.00(10.00)\n",
      "Iter 3945 | Time 30.6450(30.9659) | Bit/dim 1.1065(1.1052) | Xent 0.0520(0.0492) | Loss 1.1325(1.1298) | Error 0.0151(0.0151) Steps 428(427.35) | Grad Norm 0.4309(0.3914) | Total Time 10.00(10.00)\n",
      "Iter 3946 | Time 30.5476(30.9534) | Bit/dim 1.1062(1.1052) | Xent 0.0483(0.0492) | Loss 1.1303(1.1298) | Error 0.0169(0.0152) Steps 428(427.37) | Grad Norm 0.6678(0.3997) | Total Time 10.00(10.00)\n",
      "Iter 3947 | Time 30.8386(30.9499) | Bit/dim 1.1022(1.1051) | Xent 0.0547(0.0493) | Loss 1.1296(1.1298) | Error 0.0171(0.0152) Steps 428(427.39) | Grad Norm 0.2883(0.3964) | Total Time 10.00(10.00)\n",
      "Iter 3948 | Time 31.1109(30.9548) | Bit/dim 1.1028(1.1050) | Xent 0.0492(0.0493) | Loss 1.1274(1.1297) | Error 0.0136(0.0152) Steps 422(427.23) | Grad Norm 0.3740(0.3957) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0564 | Time 17.0541, Epoch Time 245.7972(245.3095), Bit/dim 1.0992(best: 1.0984), Xent 0.0300, Loss 1.1142, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3949 | Time 31.5701(30.9732) | Bit/dim 1.1071(1.1051) | Xent 0.0546(0.0495) | Loss 1.1344(1.1299) | Error 0.0165(0.0152) Steps 422(427.07) | Grad Norm 0.6627(0.4037) | Total Time 10.00(10.00)\n",
      "Iter 3950 | Time 30.4102(30.9563) | Bit/dim 1.0997(1.1049) | Xent 0.0453(0.0494) | Loss 1.1223(1.1296) | Error 0.0156(0.0152) Steps 428(427.10) | Grad Norm 0.2853(0.4002) | Total Time 10.00(10.00)\n",
      "Iter 3951 | Time 32.3519(30.9982) | Bit/dim 1.1059(1.1050) | Xent 0.0485(0.0493) | Loss 1.1301(1.1296) | Error 0.0161(0.0153) Steps 428(427.12) | Grad Norm 0.5030(0.4032) | Total Time 10.00(10.00)\n",
      "Iter 3952 | Time 30.2700(30.9764) | Bit/dim 1.1094(1.1051) | Xent 0.0564(0.0496) | Loss 1.1376(1.1299) | Error 0.0165(0.0153) Steps 428(427.15) | Grad Norm 0.5650(0.4081) | Total Time 10.00(10.00)\n",
      "Iter 3953 | Time 30.7525(30.9696) | Bit/dim 1.1035(1.1051) | Xent 0.0491(0.0495) | Loss 1.1281(1.1298) | Error 0.0146(0.0153) Steps 428(427.18) | Grad Norm 0.1400(0.4001) | Total Time 10.00(10.00)\n",
      "Iter 3954 | Time 31.0898(30.9732) | Bit/dim 1.1059(1.1051) | Xent 0.0427(0.0493) | Loss 1.1273(1.1298) | Error 0.0124(0.0152) Steps 428(427.20) | Grad Norm 0.5753(0.4053) | Total Time 10.00(10.00)\n",
      "Iter 3955 | Time 31.4507(30.9876) | Bit/dim 1.1023(1.1050) | Xent 0.0509(0.0494) | Loss 1.1277(1.1297) | Error 0.0152(0.0152) Steps 428(427.22) | Grad Norm 0.2469(0.4006) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0565 | Time 17.0105, Epoch Time 247.3307(245.3702), Bit/dim 1.1000(best: 1.0984), Xent 0.0335, Loss 1.1167, Error 0.0108(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3956 | Time 30.5467(30.9743) | Bit/dim 1.1078(1.1051) | Xent 0.0527(0.0495) | Loss 1.1341(1.1298) | Error 0.0154(0.0152) Steps 428(427.25) | Grad Norm 0.2097(0.3948) | Total Time 10.00(10.00)\n",
      "Iter 3957 | Time 31.1391(30.9793) | Bit/dim 1.1066(1.1051) | Xent 0.0506(0.0495) | Loss 1.1319(1.1299) | Error 0.0150(0.0152) Steps 428(427.27) | Grad Norm 0.1881(0.3886) | Total Time 10.00(10.00)\n",
      "Iter 3958 | Time 30.5274(30.9657) | Bit/dim 1.1039(1.1051) | Xent 0.0614(0.0499) | Loss 1.1346(1.1300) | Error 0.0188(0.0153) Steps 428(427.29) | Grad Norm 0.5119(0.3923) | Total Time 10.00(10.00)\n",
      "Iter 3959 | Time 31.3886(30.9784) | Bit/dim 1.1033(1.1050) | Xent 0.0518(0.0499) | Loss 1.1292(1.1300) | Error 0.0158(0.0153) Steps 428(427.31) | Grad Norm 0.2343(0.3876) | Total Time 10.00(10.00)\n",
      "Iter 3960 | Time 32.0135(31.0095) | Bit/dim 1.1002(1.1049) | Xent 0.0432(0.0497) | Loss 1.1218(1.1298) | Error 0.0148(0.0153) Steps 428(427.33) | Grad Norm 0.4159(0.3884) | Total Time 10.00(10.00)\n",
      "Iter 3961 | Time 30.3583(30.9899) | Bit/dim 1.1062(1.1049) | Xent 0.0468(0.0496) | Loss 1.1296(1.1298) | Error 0.0148(0.0153) Steps 422(427.17) | Grad Norm 0.4430(0.3901) | Total Time 10.00(10.00)\n",
      "Iter 3962 | Time 30.3097(30.9695) | Bit/dim 1.1061(1.1050) | Xent 0.0469(0.0496) | Loss 1.1296(1.1298) | Error 0.0139(0.0152) Steps 428(427.20) | Grad Norm 0.2587(0.3861) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0566 | Time 17.0670, Epoch Time 245.6141(245.3775), Bit/dim 1.0990(best: 1.0984), Xent 0.0298, Loss 1.1139, Error 0.0095(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3963 | Time 31.2992(30.9794) | Bit/dim 1.1062(1.1050) | Xent 0.0492(0.0496) | Loss 1.1308(1.1298) | Error 0.0160(0.0153) Steps 428(427.22) | Grad Norm 0.2738(0.3828) | Total Time 10.00(10.00)\n",
      "Iter 3964 | Time 31.2499(30.9875) | Bit/dim 1.1023(1.1049) | Xent 0.0524(0.0496) | Loss 1.1285(1.1297) | Error 0.0154(0.0153) Steps 428(427.25) | Grad Norm 0.4530(0.3849) | Total Time 10.00(10.00)\n",
      "Iter 3965 | Time 30.6095(30.9762) | Bit/dim 1.1046(1.1049) | Xent 0.0500(0.0496) | Loss 1.1296(1.1297) | Error 0.0171(0.0153) Steps 422(427.09) | Grad Norm 0.2295(0.3802) | Total Time 10.00(10.00)\n",
      "Iter 3966 | Time 31.5427(30.9932) | Bit/dim 1.1043(1.1049) | Xent 0.0520(0.0497) | Loss 1.1303(1.1298) | Error 0.0156(0.0153) Steps 428(427.12) | Grad Norm 0.4893(0.3835) | Total Time 10.00(10.00)\n",
      "Iter 3967 | Time 30.4283(30.9762) | Bit/dim 1.1075(1.1050) | Xent 0.0463(0.0496) | Loss 1.1307(1.1298) | Error 0.0138(0.0153) Steps 428(427.14) | Grad Norm 0.6322(0.3909) | Total Time 10.00(10.00)\n",
      "Iter 3968 | Time 31.6611(30.9968) | Bit/dim 1.1036(1.1049) | Xent 0.0483(0.0496) | Loss 1.1278(1.1297) | Error 0.0136(0.0152) Steps 428(427.17) | Grad Norm 0.2135(0.3856) | Total Time 10.00(10.00)\n",
      "Iter 3969 | Time 30.9766(30.9962) | Bit/dim 1.1045(1.1049) | Xent 0.0428(0.0494) | Loss 1.1259(1.1296) | Error 0.0136(0.0152) Steps 428(427.19) | Grad Norm 0.4111(0.3864) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0567 | Time 16.9027, Epoch Time 246.9263(245.4239), Bit/dim 1.0987(best: 1.0984), Xent 0.0298, Loss 1.1136, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3970 | Time 31.4596(31.0101) | Bit/dim 1.1086(1.1050) | Xent 0.0433(0.0492) | Loss 1.1303(1.1296) | Error 0.0135(0.0151) Steps 428(427.22) | Grad Norm 0.6727(0.3950) | Total Time 10.00(10.00)\n",
      "Iter 3971 | Time 29.5025(30.9649) | Bit/dim 1.1060(1.1051) | Xent 0.0546(0.0494) | Loss 1.1333(1.1297) | Error 0.0166(0.0152) Steps 428(427.24) | Grad Norm 0.2838(0.3916) | Total Time 10.00(10.00)\n",
      "Iter 3972 | Time 31.2691(30.9740) | Bit/dim 1.1036(1.1050) | Xent 0.0499(0.0494) | Loss 1.1285(1.1297) | Error 0.0159(0.0152) Steps 428(427.26) | Grad Norm 0.3960(0.3918) | Total Time 10.00(10.00)\n",
      "Iter 3973 | Time 30.1692(30.9498) | Bit/dim 1.1063(1.1051) | Xent 0.0475(0.0493) | Loss 1.1301(1.1297) | Error 0.0131(0.0151) Steps 428(427.29) | Grad Norm 0.6880(0.4007) | Total Time 10.00(10.00)\n",
      "Iter 3974 | Time 30.8991(30.9483) | Bit/dim 1.1010(1.1049) | Xent 0.0524(0.0494) | Loss 1.1272(1.1296) | Error 0.0164(0.0152) Steps 428(427.31) | Grad Norm 0.3277(0.3985) | Total Time 10.00(10.00)\n",
      "Iter 3975 | Time 30.4678(30.9339) | Bit/dim 1.1026(1.1049) | Xent 0.0546(0.0496) | Loss 1.1299(1.1296) | Error 0.0171(0.0152) Steps 428(427.33) | Grad Norm 0.2724(0.3947) | Total Time 10.00(10.00)\n",
      "Iter 3976 | Time 30.7548(30.9285) | Bit/dim 1.1069(1.1049) | Xent 0.0538(0.0497) | Loss 1.1338(1.1298) | Error 0.0174(0.0153) Steps 428(427.35) | Grad Norm 0.7705(0.4060) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0568 | Time 16.8188, Epoch Time 243.4748(245.3655), Bit/dim 1.0993(best: 1.0984), Xent 0.0318, Loss 1.1152, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3977 | Time 30.0250(30.9014) | Bit/dim 1.1065(1.1050) | Xent 0.0472(0.0496) | Loss 1.1301(1.1298) | Error 0.0140(0.0153) Steps 428(427.37) | Grad Norm 0.2938(0.4026) | Total Time 10.00(10.00)\n",
      "Iter 3978 | Time 31.5590(30.9211) | Bit/dim 1.1067(1.1050) | Xent 0.0486(0.0496) | Loss 1.1310(1.1298) | Error 0.0142(0.0152) Steps 428(427.39) | Grad Norm 0.2500(0.3980) | Total Time 10.00(10.00)\n",
      "Iter 3979 | Time 30.1415(30.8978) | Bit/dim 1.1021(1.1049) | Xent 0.0522(0.0497) | Loss 1.1282(1.1298) | Error 0.0162(0.0153) Steps 428(427.41) | Grad Norm 0.8772(0.4124) | Total Time 10.00(10.00)\n",
      "Iter 3980 | Time 30.4651(30.8848) | Bit/dim 1.1035(1.1049) | Xent 0.0419(0.0494) | Loss 1.1245(1.1296) | Error 0.0130(0.0152) Steps 428(427.42) | Grad Norm 0.2883(0.4087) | Total Time 10.00(10.00)\n",
      "Iter 3981 | Time 31.0875(30.8909) | Bit/dim 1.1050(1.1049) | Xent 0.0502(0.0495) | Loss 1.1301(1.1296) | Error 0.0155(0.0152) Steps 428(427.44) | Grad Norm 0.6847(0.4169) | Total Time 10.00(10.00)\n",
      "Iter 3982 | Time 32.6129(30.9425) | Bit/dim 1.1053(1.1049) | Xent 0.0541(0.0496) | Loss 1.1323(1.1297) | Error 0.0160(0.0152) Steps 428(427.46) | Grad Norm 0.4269(0.4172) | Total Time 10.00(10.00)\n",
      "Iter 3983 | Time 32.6456(30.9936) | Bit/dim 1.1032(1.1049) | Xent 0.0450(0.0495) | Loss 1.1257(1.1296) | Error 0.0145(0.0152) Steps 428(427.47) | Grad Norm 0.2926(0.4135) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0569 | Time 16.9646, Epoch Time 247.8205(245.4391), Bit/dim 1.0989(best: 1.0984), Xent 0.0311, Loss 1.1144, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3984 | Time 30.2348(30.9708) | Bit/dim 1.1043(1.1048) | Xent 0.0512(0.0495) | Loss 1.1299(1.1296) | Error 0.0152(0.0152) Steps 428(427.49) | Grad Norm 0.4097(0.4134) | Total Time 10.00(10.00)\n",
      "Iter 3985 | Time 31.3174(30.9812) | Bit/dim 1.1057(1.1049) | Xent 0.0434(0.0493) | Loss 1.1274(1.1295) | Error 0.0136(0.0152) Steps 428(427.50) | Grad Norm 0.4922(0.4158) | Total Time 10.00(10.00)\n",
      "Iter 3986 | Time 30.8113(30.9761) | Bit/dim 1.1003(1.1047) | Xent 0.0528(0.0494) | Loss 1.1267(1.1294) | Error 0.0162(0.0152) Steps 428(427.52) | Grad Norm 0.2864(0.4119) | Total Time 10.00(10.00)\n",
      "Iter 3987 | Time 30.9629(30.9757) | Bit/dim 1.1070(1.1048) | Xent 0.0499(0.0494) | Loss 1.1320(1.1295) | Error 0.0160(0.0152) Steps 428(427.53) | Grad Norm 0.2636(0.4074) | Total Time 10.00(10.00)\n",
      "Iter 3988 | Time 30.9844(30.9760) | Bit/dim 1.1020(1.1047) | Xent 0.0548(0.0496) | Loss 1.1294(1.1295) | Error 0.0160(0.0152) Steps 428(427.55) | Grad Norm 0.5331(0.4112) | Total Time 10.00(10.00)\n",
      "Iter 3989 | Time 31.6796(30.9971) | Bit/dim 1.1100(1.1049) | Xent 0.0460(0.0495) | Loss 1.1330(1.1296) | Error 0.0131(0.0152) Steps 428(427.56) | Grad Norm 0.3042(0.4080) | Total Time 10.00(10.00)\n",
      "Iter 3990 | Time 31.3664(31.0082) | Bit/dim 1.1040(1.1049) | Xent 0.0550(0.0497) | Loss 1.1316(1.1297) | Error 0.0165(0.0152) Steps 428(427.57) | Grad Norm 0.3067(0.4049) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0570 | Time 16.8270, Epoch Time 246.2634(245.4638), Bit/dim 1.0986(best: 1.0984), Xent 0.0310, Loss 1.1141, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3991 | Time 30.8962(31.0048) | Bit/dim 1.1022(1.1048) | Xent 0.0497(0.0497) | Loss 1.1270(1.1296) | Error 0.0152(0.0152) Steps 428(427.59) | Grad Norm 0.4768(0.4071) | Total Time 10.00(10.00)\n",
      "Iter 3992 | Time 31.2137(31.0111) | Bit/dim 1.1047(1.1048) | Xent 0.0496(0.0497) | Loss 1.1296(1.1296) | Error 0.0154(0.0152) Steps 428(427.60) | Grad Norm 0.2659(0.4029) | Total Time 10.00(10.00)\n",
      "Iter 3993 | Time 32.2724(31.0489) | Bit/dim 1.1058(1.1048) | Xent 0.0475(0.0496) | Loss 1.1295(1.1296) | Error 0.0132(0.0152) Steps 428(427.61) | Grad Norm 0.2138(0.3972) | Total Time 10.00(10.00)\n",
      "Iter 3994 | Time 30.6888(31.0381) | Bit/dim 1.1084(1.1049) | Xent 0.0504(0.0496) | Loss 1.1335(1.1297) | Error 0.0148(0.0151) Steps 428(427.62) | Grad Norm 0.5096(0.4006) | Total Time 10.00(10.00)\n",
      "Iter 3995 | Time 30.7984(31.0309) | Bit/dim 1.1040(1.1049) | Xent 0.0376(0.0493) | Loss 1.1228(1.1295) | Error 0.0111(0.0150) Steps 428(427.63) | Grad Norm 0.3454(0.3989) | Total Time 10.00(10.00)\n",
      "Iter 3996 | Time 31.3421(31.0403) | Bit/dim 1.1027(1.1048) | Xent 0.0534(0.0494) | Loss 1.1294(1.1295) | Error 0.0160(0.0151) Steps 428(427.65) | Grad Norm 0.2481(0.3944) | Total Time 10.00(10.00)\n",
      "Iter 3997 | Time 30.5659(31.0260) | Bit/dim 1.1038(1.1048) | Xent 0.0454(0.0493) | Loss 1.1265(1.1294) | Error 0.0135(0.0150) Steps 428(427.66) | Grad Norm 0.6931(0.4034) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0571 | Time 16.8397, Epoch Time 246.8750(245.5062), Bit/dim 1.0990(best: 1.0984), Xent 0.0323, Loss 1.1151, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 3998 | Time 30.7944(31.0191) | Bit/dim 1.1039(1.1048) | Xent 0.0546(0.0494) | Loss 1.1312(1.1295) | Error 0.0179(0.0151) Steps 428(427.67) | Grad Norm 0.2270(0.3981) | Total Time 10.00(10.00)\n",
      "Iter 3999 | Time 31.1857(31.0241) | Bit/dim 1.1031(1.1047) | Xent 0.0449(0.0493) | Loss 1.1255(1.1294) | Error 0.0131(0.0150) Steps 428(427.68) | Grad Norm 0.1790(0.3915) | Total Time 10.00(10.00)\n",
      "Iter 4000 | Time 30.8340(31.0184) | Bit/dim 1.1081(1.1048) | Xent 0.0487(0.0493) | Loss 1.1324(1.1294) | Error 0.0158(0.0151) Steps 428(427.69) | Grad Norm 0.4567(0.3934) | Total Time 10.00(10.00)\n",
      "Iter 4001 | Time 31.8201(31.0424) | Bit/dim 1.1011(1.1047) | Xent 0.0455(0.0492) | Loss 1.1239(1.1293) | Error 0.0138(0.0150) Steps 428(427.70) | Grad Norm 0.3196(0.3912) | Total Time 10.00(10.00)\n",
      "Iter 4002 | Time 30.6370(31.0303) | Bit/dim 1.1024(1.1046) | Xent 0.0472(0.0491) | Loss 1.1260(1.1292) | Error 0.0135(0.0150) Steps 422(427.52) | Grad Norm 0.2912(0.3882) | Total Time 10.00(10.00)\n",
      "Iter 4003 | Time 31.7149(31.0508) | Bit/dim 1.1121(1.1049) | Xent 0.0520(0.0492) | Loss 1.1381(1.1294) | Error 0.0169(0.0150) Steps 428(427.54) | Grad Norm 0.6086(0.3948) | Total Time 10.00(10.00)\n",
      "Iter 4004 | Time 30.2094(31.0256) | Bit/dim 1.1059(1.1049) | Xent 0.0433(0.0490) | Loss 1.1275(1.1294) | Error 0.0132(0.0150) Steps 428(427.55) | Grad Norm 0.2245(0.3897) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0572 | Time 17.1388, Epoch Time 246.6051(245.5391), Bit/dim 1.0992(best: 1.0984), Xent 0.0299, Loss 1.1142, Error 0.0094(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4005 | Time 30.0772(30.9971) | Bit/dim 1.1023(1.1048) | Xent 0.0517(0.0491) | Loss 1.1282(1.1294) | Error 0.0172(0.0150) Steps 428(427.57) | Grad Norm 0.4181(0.3906) | Total Time 10.00(10.00)\n",
      "Iter 4006 | Time 30.6766(30.9875) | Bit/dim 1.1051(1.1048) | Xent 0.0489(0.0491) | Loss 1.1296(1.1294) | Error 0.0141(0.0150) Steps 428(427.58) | Grad Norm 0.2803(0.3873) | Total Time 10.00(10.00)\n",
      "Iter 4007 | Time 30.5587(30.9746) | Bit/dim 1.1047(1.1048) | Xent 0.0510(0.0491) | Loss 1.1302(1.1294) | Error 0.0165(0.0151) Steps 428(427.59) | Grad Norm 0.2681(0.3837) | Total Time 10.00(10.00)\n",
      "Iter 4008 | Time 30.5809(30.9628) | Bit/dim 1.1041(1.1048) | Xent 0.0493(0.0491) | Loss 1.1287(1.1294) | Error 0.0146(0.0150) Steps 428(427.60) | Grad Norm 0.6122(0.3906) | Total Time 10.00(10.00)\n",
      "Iter 4009 | Time 30.9055(30.9611) | Bit/dim 1.1057(1.1048) | Xent 0.0505(0.0492) | Loss 1.1309(1.1294) | Error 0.0149(0.0150) Steps 428(427.62) | Grad Norm 0.2620(0.3867) | Total Time 10.00(10.00)\n",
      "Iter 4010 | Time 30.9140(30.9597) | Bit/dim 1.1044(1.1048) | Xent 0.0518(0.0493) | Loss 1.1303(1.1294) | Error 0.0162(0.0151) Steps 428(427.63) | Grad Norm 0.4065(0.3873) | Total Time 10.00(10.00)\n",
      "Iter 4011 | Time 30.6162(30.9494) | Bit/dim 1.1068(1.1049) | Xent 0.0515(0.0493) | Loss 1.1326(1.1295) | Error 0.0150(0.0151) Steps 428(427.64) | Grad Norm 0.2721(0.3838) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0573 | Time 16.6206, Epoch Time 243.0570(245.4647), Bit/dim 1.0986(best: 1.0984), Xent 0.0308, Loss 1.1139, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4012 | Time 30.6119(30.9393) | Bit/dim 1.1067(1.1049) | Xent 0.0530(0.0494) | Loss 1.1332(1.1296) | Error 0.0168(0.0151) Steps 428(427.65) | Grad Norm 0.1715(0.3775) | Total Time 10.00(10.00)\n",
      "Iter 4013 | Time 31.8321(30.9661) | Bit/dim 1.1022(1.1048) | Xent 0.0499(0.0495) | Loss 1.1271(1.1296) | Error 0.0152(0.0151) Steps 428(427.66) | Grad Norm 0.2953(0.3750) | Total Time 10.00(10.00)\n",
      "Iter 4014 | Time 30.7256(30.9588) | Bit/dim 1.1038(1.1048) | Xent 0.0475(0.0494) | Loss 1.1276(1.1295) | Error 0.0158(0.0151) Steps 428(427.67) | Grad Norm 0.2877(0.3724) | Total Time 10.00(10.00)\n",
      "Iter 4015 | Time 31.1869(30.9657) | Bit/dim 1.1023(1.1047) | Xent 0.0463(0.0493) | Loss 1.1254(1.1294) | Error 0.0149(0.0151) Steps 428(427.68) | Grad Norm 0.4070(0.3734) | Total Time 10.00(10.00)\n",
      "Iter 4016 | Time 31.2280(30.9736) | Bit/dim 1.1085(1.1048) | Xent 0.0515(0.0494) | Loss 1.1343(1.1295) | Error 0.0156(0.0152) Steps 428(427.69) | Grad Norm 0.2934(0.3710) | Total Time 10.00(10.00)\n",
      "Iter 4017 | Time 31.4817(30.9888) | Bit/dim 1.1038(1.1048) | Xent 0.0526(0.0495) | Loss 1.1301(1.1296) | Error 0.0164(0.0152) Steps 428(427.70) | Grad Norm 0.3504(0.3704) | Total Time 10.00(10.00)\n",
      "Iter 4018 | Time 31.2850(30.9977) | Bit/dim 1.1028(1.1048) | Xent 0.0455(0.0493) | Loss 1.1255(1.1294) | Error 0.0139(0.0152) Steps 428(427.71) | Grad Norm 0.3842(0.3708) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0574 | Time 16.7908, Epoch Time 247.3636(245.5216), Bit/dim 1.0984(best: 1.0984), Xent 0.0333, Loss 1.1151, Error 0.0098(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4019 | Time 31.0754(31.0000) | Bit/dim 1.1076(1.1048) | Xent 0.0426(0.0491) | Loss 1.1289(1.1294) | Error 0.0144(0.0151) Steps 428(427.72) | Grad Norm 0.2538(0.3673) | Total Time 10.00(10.00)\n",
      "Iter 4020 | Time 30.7359(30.9921) | Bit/dim 1.1066(1.1049) | Xent 0.0492(0.0491) | Loss 1.1312(1.1295) | Error 0.0155(0.0151) Steps 428(427.73) | Grad Norm 0.4354(0.3693) | Total Time 10.00(10.00)\n",
      "Iter 4021 | Time 30.7190(30.9839) | Bit/dim 1.1026(1.1048) | Xent 0.0500(0.0492) | Loss 1.1275(1.1294) | Error 0.0154(0.0151) Steps 428(427.73) | Grad Norm 0.4877(0.3729) | Total Time 10.00(10.00)\n",
      "Iter 4022 | Time 31.6014(31.0024) | Bit/dim 1.1057(1.1049) | Xent 0.0518(0.0493) | Loss 1.1316(1.1295) | Error 0.0130(0.0151) Steps 428(427.74) | Grad Norm 0.2382(0.3689) | Total Time 10.00(10.00)\n",
      "Iter 4023 | Time 31.0064(31.0025) | Bit/dim 1.0985(1.1047) | Xent 0.0464(0.0492) | Loss 1.1217(1.1292) | Error 0.0146(0.0151) Steps 428(427.75) | Grad Norm 0.7283(0.3796) | Total Time 10.00(10.00)\n",
      "Iter 4024 | Time 30.8817(30.9989) | Bit/dim 1.1053(1.1047) | Xent 0.0508(0.0492) | Loss 1.1307(1.1293) | Error 0.0164(0.0151) Steps 428(427.76) | Grad Norm 0.2955(0.3771) | Total Time 10.00(10.00)\n",
      "Iter 4025 | Time 30.9708(30.9981) | Bit/dim 1.1052(1.1047) | Xent 0.0446(0.0491) | Loss 1.1275(1.1292) | Error 0.0136(0.0151) Steps 428(427.76) | Grad Norm 0.3359(0.3759) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0575 | Time 17.1249, Epoch Time 246.4361(245.5491), Bit/dim 1.0991(best: 1.0984), Xent 0.0312, Loss 1.1147, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4026 | Time 30.7274(30.9900) | Bit/dim 1.1042(1.1047) | Xent 0.0474(0.0490) | Loss 1.1279(1.1292) | Error 0.0139(0.0150) Steps 428(427.77) | Grad Norm 0.3516(0.3751) | Total Time 10.00(10.00)\n",
      "Iter 4027 | Time 30.4274(30.9731) | Bit/dim 1.1002(1.1045) | Xent 0.0528(0.0491) | Loss 1.1266(1.1291) | Error 0.0168(0.0151) Steps 428(427.78) | Grad Norm 0.1655(0.3689) | Total Time 10.00(10.00)\n",
      "Iter 4028 | Time 30.6434(30.9632) | Bit/dim 1.1070(1.1046) | Xent 0.0457(0.0490) | Loss 1.1298(1.1291) | Error 0.0156(0.0151) Steps 428(427.78) | Grad Norm 0.2830(0.3663) | Total Time 10.00(10.00)\n",
      "Iter 4029 | Time 30.7373(30.9564) | Bit/dim 1.1043(1.1046) | Xent 0.0550(0.0492) | Loss 1.1318(1.1292) | Error 0.0170(0.0152) Steps 428(427.79) | Grad Norm 0.5213(0.3709) | Total Time 10.00(10.00)\n",
      "Iter 4030 | Time 30.8344(30.9528) | Bit/dim 1.1073(1.1047) | Xent 0.0481(0.0492) | Loss 1.1314(1.1293) | Error 0.0131(0.0151) Steps 428(427.80) | Grad Norm 0.2338(0.3668) | Total Time 10.00(10.00)\n",
      "Iter 4031 | Time 30.8401(30.9494) | Bit/dim 1.1021(1.1046) | Xent 0.0525(0.0493) | Loss 1.1284(1.1293) | Error 0.0161(0.0151) Steps 428(427.80) | Grad Norm 0.5243(0.3715) | Total Time 10.00(10.00)\n",
      "Iter 4032 | Time 32.0895(30.9836) | Bit/dim 1.1057(1.1046) | Xent 0.0440(0.0491) | Loss 1.1277(1.1292) | Error 0.0122(0.0150) Steps 428(427.81) | Grad Norm 0.6494(0.3799) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0576 | Time 17.3285, Epoch Time 246.1819(245.5681), Bit/dim 1.0988(best: 1.0984), Xent 0.0333, Loss 1.1155, Error 0.0098(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4033 | Time 30.5136(30.9695) | Bit/dim 1.1080(1.1047) | Xent 0.0504(0.0492) | Loss 1.1333(1.1293) | Error 0.0152(0.0150) Steps 428(427.82) | Grad Norm 0.3852(0.3800) | Total Time 10.00(10.00)\n",
      "Iter 4034 | Time 30.2876(30.9490) | Bit/dim 1.1030(1.1047) | Xent 0.0445(0.0490) | Loss 1.1252(1.1292) | Error 0.0146(0.0150) Steps 428(427.82) | Grad Norm 0.5994(0.3866) | Total Time 10.00(10.00)\n",
      "Iter 4035 | Time 31.0061(30.9507) | Bit/dim 1.1066(1.1048) | Xent 0.0469(0.0490) | Loss 1.1301(1.1292) | Error 0.0141(0.0150) Steps 428(427.83) | Grad Norm 0.3322(0.3850) | Total Time 10.00(10.00)\n",
      "Iter 4036 | Time 31.1887(30.9579) | Bit/dim 1.0997(1.1046) | Xent 0.0560(0.0492) | Loss 1.1277(1.1292) | Error 0.0169(0.0151) Steps 428(427.83) | Grad Norm 0.2751(0.3817) | Total Time 10.00(10.00)\n",
      "Iter 4037 | Time 32.4182(31.0017) | Bit/dim 1.1004(1.1045) | Xent 0.0497(0.0492) | Loss 1.1253(1.1291) | Error 0.0146(0.0150) Steps 422(427.66) | Grad Norm 0.3728(0.3814) | Total Time 10.00(10.00)\n",
      "Iter 4038 | Time 31.7614(31.0245) | Bit/dim 1.1053(1.1045) | Xent 0.0522(0.0493) | Loss 1.1313(1.1291) | Error 0.0164(0.0151) Steps 428(427.67) | Grad Norm 0.3961(0.3819) | Total Time 10.00(10.00)\n",
      "Iter 4039 | Time 30.6412(31.0130) | Bit/dim 1.1049(1.1045) | Xent 0.0522(0.0494) | Loss 1.1310(1.1292) | Error 0.0158(0.0151) Steps 428(427.68) | Grad Norm 0.2099(0.3767) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0577 | Time 16.8613, Epoch Time 246.7997(245.6050), Bit/dim 1.0988(best: 1.0984), Xent 0.0340, Loss 1.1158, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4040 | Time 30.9843(31.0121) | Bit/dim 1.1013(1.1044) | Xent 0.0480(0.0493) | Loss 1.1253(1.1291) | Error 0.0154(0.0151) Steps 428(427.69) | Grad Norm 0.5914(0.3831) | Total Time 10.00(10.00)\n",
      "Iter 4041 | Time 30.4428(30.9950) | Bit/dim 1.1020(1.1043) | Xent 0.0530(0.0494) | Loss 1.1285(1.1291) | Error 0.0151(0.0151) Steps 428(427.70) | Grad Norm 0.2765(0.3799) | Total Time 10.00(10.00)\n",
      "Iter 4042 | Time 30.8896(30.9919) | Bit/dim 1.1097(1.1045) | Xent 0.0481(0.0494) | Loss 1.1337(1.1292) | Error 0.0148(0.0151) Steps 428(427.70) | Grad Norm 0.5156(0.3840) | Total Time 10.00(10.00)\n",
      "Iter 4043 | Time 30.9434(30.9904) | Bit/dim 1.1034(1.1045) | Xent 0.0516(0.0495) | Loss 1.1292(1.1292) | Error 0.0169(0.0152) Steps 428(427.71) | Grad Norm 0.1910(0.3782) | Total Time 10.00(10.00)\n",
      "Iter 4044 | Time 30.8849(30.9873) | Bit/dim 1.1062(1.1045) | Xent 0.0494(0.0495) | Loss 1.1309(1.1293) | Error 0.0139(0.0151) Steps 428(427.72) | Grad Norm 0.2274(0.3737) | Total Time 10.00(10.00)\n",
      "Iter 4045 | Time 30.7930(30.9814) | Bit/dim 1.0997(1.1044) | Xent 0.0471(0.0494) | Loss 1.1232(1.1291) | Error 0.0144(0.0151) Steps 428(427.73) | Grad Norm 0.1848(0.3680) | Total Time 10.00(10.00)\n",
      "Iter 4046 | Time 30.5521(30.9685) | Bit/dim 1.1071(1.1045) | Xent 0.0454(0.0493) | Loss 1.1298(1.1291) | Error 0.0135(0.0150) Steps 428(427.74) | Grad Norm 0.1859(0.3626) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0578 | Time 16.8956, Epoch Time 244.5034(245.5720), Bit/dim 1.0988(best: 1.0984), Xent 0.0336, Loss 1.1156, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4047 | Time 31.8755(30.9958) | Bit/dim 1.1019(1.1044) | Xent 0.0505(0.0493) | Loss 1.1272(1.1290) | Error 0.0159(0.0151) Steps 428(427.75) | Grad Norm 0.3934(0.3635) | Total Time 10.00(10.00)\n",
      "Iter 4048 | Time 31.3522(31.0065) | Bit/dim 1.1027(1.1043) | Xent 0.0475(0.0493) | Loss 1.1264(1.1290) | Error 0.0139(0.0150) Steps 428(427.75) | Grad Norm 0.2026(0.3587) | Total Time 10.00(10.00)\n",
      "Iter 4049 | Time 30.3610(30.9871) | Bit/dim 1.1086(1.1045) | Xent 0.0506(0.0493) | Loss 1.1339(1.1291) | Error 0.0150(0.0150) Steps 428(427.76) | Grad Norm 0.1892(0.3536) | Total Time 10.00(10.00)\n",
      "Iter 4050 | Time 30.4937(30.9723) | Bit/dim 1.1071(1.1045) | Xent 0.0520(0.0494) | Loss 1.1331(1.1292) | Error 0.0160(0.0151) Steps 428(427.77) | Grad Norm 0.1716(0.3481) | Total Time 10.00(10.00)\n",
      "Iter 4051 | Time 31.3847(30.9847) | Bit/dim 1.1027(1.1045) | Xent 0.0512(0.0494) | Loss 1.1283(1.1292) | Error 0.0166(0.0151) Steps 428(427.78) | Grad Norm 0.3034(0.3468) | Total Time 10.00(10.00)\n",
      "Iter 4052 | Time 31.1071(30.9883) | Bit/dim 1.1048(1.1045) | Xent 0.0531(0.0495) | Loss 1.1314(1.1293) | Error 0.0166(0.0152) Steps 428(427.78) | Grad Norm 0.3817(0.3478) | Total Time 10.00(10.00)\n",
      "Iter 4053 | Time 30.2052(30.9648) | Bit/dim 1.1036(1.1045) | Xent 0.0483(0.0495) | Loss 1.1277(1.1292) | Error 0.0134(0.0151) Steps 428(427.79) | Grad Norm 0.2099(0.3437) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0579 | Time 16.8415, Epoch Time 245.7902(245.5785), Bit/dim 1.0984(best: 1.0984), Xent 0.0310, Loss 1.1139, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4054 | Time 31.4763(30.9802) | Bit/dim 1.1013(1.1044) | Xent 0.0445(0.0494) | Loss 1.1236(1.1290) | Error 0.0151(0.0151) Steps 428(427.80) | Grad Norm 0.6008(0.3514) | Total Time 10.00(10.00)\n",
      "Iter 4055 | Time 32.3071(31.0200) | Bit/dim 1.1068(1.1044) | Xent 0.0492(0.0493) | Loss 1.1314(1.1291) | Error 0.0152(0.0151) Steps 428(427.80) | Grad Norm 0.1947(0.3467) | Total Time 10.00(10.00)\n",
      "Iter 4056 | Time 30.2871(30.9980) | Bit/dim 1.1040(1.1044) | Xent 0.0516(0.0494) | Loss 1.1298(1.1291) | Error 0.0160(0.0151) Steps 428(427.81) | Grad Norm 0.2582(0.3440) | Total Time 10.00(10.00)\n",
      "Iter 4057 | Time 32.8312(31.0530) | Bit/dim 1.1027(1.1044) | Xent 0.0466(0.0493) | Loss 1.1259(1.1290) | Error 0.0140(0.0151) Steps 428(427.81) | Grad Norm 0.3740(0.3449) | Total Time 10.00(10.00)\n",
      "Iter 4058 | Time 31.2124(31.0578) | Bit/dim 1.1064(1.1044) | Xent 0.0482(0.0493) | Loss 1.1305(1.1291) | Error 0.0146(0.0151) Steps 428(427.82) | Grad Norm 0.2454(0.3420) | Total Time 10.00(10.00)\n",
      "Iter 4059 | Time 30.7572(31.0488) | Bit/dim 1.1020(1.1044) | Xent 0.0482(0.0493) | Loss 1.1261(1.1290) | Error 0.0125(0.0150) Steps 428(427.82) | Grad Norm 0.2661(0.3397) | Total Time 10.00(10.00)\n",
      "Iter 4060 | Time 30.3586(31.0281) | Bit/dim 1.1086(1.1045) | Xent 0.0528(0.0494) | Loss 1.1350(1.1292) | Error 0.0178(0.0151) Steps 428(427.83) | Grad Norm 0.2438(0.3368) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0580 | Time 16.6986, Epoch Time 248.2072(245.6574), Bit/dim 1.0988(best: 1.0984), Xent 0.0313, Loss 1.1145, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4061 | Time 30.9848(31.0268) | Bit/dim 1.1046(1.1045) | Xent 0.0444(0.0492) | Loss 1.1267(1.1291) | Error 0.0135(0.0150) Steps 428(427.83) | Grad Norm 0.2199(0.3333) | Total Time 10.00(10.00)\n",
      "Iter 4062 | Time 30.7050(31.0171) | Bit/dim 1.1034(1.1045) | Xent 0.0547(0.0494) | Loss 1.1308(1.1292) | Error 0.0145(0.0150) Steps 428(427.84) | Grad Norm 0.2379(0.3304) | Total Time 10.00(10.00)\n",
      "Iter 4063 | Time 30.3379(30.9967) | Bit/dim 1.1038(1.1044) | Xent 0.0508(0.0494) | Loss 1.1293(1.1292) | Error 0.0141(0.0150) Steps 428(427.84) | Grad Norm 0.3211(0.3302) | Total Time 10.00(10.00)\n",
      "Iter 4064 | Time 31.2385(31.0040) | Bit/dim 1.1077(1.1045) | Xent 0.0460(0.0493) | Loss 1.1307(1.1292) | Error 0.0151(0.0150) Steps 428(427.85) | Grad Norm 0.3250(0.3300) | Total Time 10.00(10.00)\n",
      "Iter 4065 | Time 30.6721(30.9940) | Bit/dim 1.1030(1.1045) | Xent 0.0537(0.0495) | Loss 1.1298(1.1292) | Error 0.0150(0.0150) Steps 428(427.85) | Grad Norm 0.2300(0.3270) | Total Time 10.00(10.00)\n",
      "Iter 4066 | Time 32.4758(31.0385) | Bit/dim 1.1006(1.1044) | Xent 0.0457(0.0493) | Loss 1.1235(1.1290) | Error 0.0154(0.0150) Steps 428(427.86) | Grad Norm 0.1856(0.3228) | Total Time 10.00(10.00)\n",
      "Iter 4067 | Time 30.6017(31.0254) | Bit/dim 1.1079(1.1045) | Xent 0.0496(0.0494) | Loss 1.1327(1.1292) | Error 0.0152(0.0150) Steps 428(427.86) | Grad Norm 0.2671(0.3211) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0581 | Time 16.9699, Epoch Time 246.1925(245.6734), Bit/dim 1.0987(best: 1.0984), Xent 0.0313, Loss 1.1144, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4068 | Time 30.1986(31.0006) | Bit/dim 1.1037(1.1045) | Xent 0.0521(0.0494) | Loss 1.1298(1.1292) | Error 0.0170(0.0151) Steps 428(427.87) | Grad Norm 0.3763(0.3227) | Total Time 10.00(10.00)\n",
      "Iter 4069 | Time 31.3849(31.0121) | Bit/dim 1.1024(1.1044) | Xent 0.0498(0.0494) | Loss 1.1273(1.1291) | Error 0.0164(0.0151) Steps 428(427.87) | Grad Norm 0.2775(0.3214) | Total Time 10.00(10.00)\n",
      "Iter 4070 | Time 30.8380(31.0069) | Bit/dim 1.1090(1.1045) | Xent 0.0489(0.0494) | Loss 1.1335(1.1293) | Error 0.0130(0.0151) Steps 428(427.87) | Grad Norm 0.3172(0.3213) | Total Time 10.00(10.00)\n",
      "Iter 4071 | Time 30.2139(30.9831) | Bit/dim 1.1026(1.1045) | Xent 0.0485(0.0494) | Loss 1.1268(1.1292) | Error 0.0142(0.0150) Steps 428(427.88) | Grad Norm 0.4029(0.3237) | Total Time 10.00(10.00)\n",
      "Iter 4072 | Time 30.0580(30.9553) | Bit/dim 1.1043(1.1045) | Xent 0.0477(0.0493) | Loss 1.1281(1.1291) | Error 0.0152(0.0150) Steps 428(427.88) | Grad Norm 0.2056(0.3202) | Total Time 10.00(10.00)\n",
      "Iter 4073 | Time 31.6747(30.9769) | Bit/dim 1.1031(1.1044) | Xent 0.0479(0.0493) | Loss 1.1271(1.1291) | Error 0.0144(0.0150) Steps 428(427.89) | Grad Norm 0.2842(0.3191) | Total Time 10.00(10.00)\n",
      "Iter 4074 | Time 30.9560(30.9763) | Bit/dim 1.1034(1.1044) | Xent 0.0470(0.0492) | Loss 1.1269(1.1290) | Error 0.0145(0.0150) Steps 428(427.89) | Grad Norm 0.1929(0.3153) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0582 | Time 16.6256, Epoch Time 244.0982(245.6262), Bit/dim 1.0984(best: 1.0984), Xent 0.0310, Loss 1.1139, Error 0.0105(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4075 | Time 30.9976(30.9769) | Bit/dim 1.1005(1.1043) | Xent 0.0557(0.0494) | Loss 1.1283(1.1290) | Error 0.0166(0.0151) Steps 428(427.89) | Grad Norm 0.3429(0.3161) | Total Time 10.00(10.00)\n",
      "Iter 4076 | Time 30.8976(30.9746) | Bit/dim 1.1061(1.1043) | Xent 0.0494(0.0494) | Loss 1.1308(1.1291) | Error 0.0142(0.0150) Steps 428(427.90) | Grad Norm 0.2600(0.3144) | Total Time 10.00(10.00)\n",
      "Iter 4077 | Time 30.8450(30.9707) | Bit/dim 1.1035(1.1043) | Xent 0.0542(0.0496) | Loss 1.1306(1.1291) | Error 0.0178(0.0151) Steps 428(427.90) | Grad Norm 0.2236(0.3117) | Total Time 10.00(10.00)\n",
      "Iter 4078 | Time 31.1301(30.9755) | Bit/dim 1.1065(1.1044) | Xent 0.0487(0.0495) | Loss 1.1309(1.1291) | Error 0.0142(0.0151) Steps 428(427.90) | Grad Norm 0.2017(0.3084) | Total Time 10.00(10.00)\n",
      "Iter 4079 | Time 30.5212(30.9618) | Bit/dim 1.1020(1.1043) | Xent 0.0500(0.0496) | Loss 1.1270(1.1291) | Error 0.0144(0.0151) Steps 428(427.90) | Grad Norm 0.2919(0.3079) | Total Time 10.00(10.00)\n",
      "Iter 4080 | Time 30.8018(30.9570) | Bit/dim 1.1048(1.1043) | Xent 0.0431(0.0494) | Loss 1.1264(1.1290) | Error 0.0146(0.0150) Steps 428(427.91) | Grad Norm 0.1542(0.3033) | Total Time 10.00(10.00)\n",
      "Iter 4081 | Time 30.4728(30.9425) | Bit/dim 1.1054(1.1044) | Xent 0.0477(0.0493) | Loss 1.1293(1.1290) | Error 0.0145(0.0150) Steps 428(427.91) | Grad Norm 0.1769(0.2995) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0583 | Time 17.0406, Epoch Time 244.8153(245.6018), Bit/dim 1.0991(best: 1.0984), Xent 0.0333, Loss 1.1158, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4082 | Time 30.7531(30.9368) | Bit/dim 1.1010(1.1043) | Xent 0.0522(0.0494) | Loss 1.1271(1.1290) | Error 0.0156(0.0151) Steps 428(427.91) | Grad Norm 0.3386(0.3007) | Total Time 10.00(10.00)\n",
      "Iter 4083 | Time 31.5293(30.9546) | Bit/dim 1.1005(1.1041) | Xent 0.0511(0.0495) | Loss 1.1260(1.1289) | Error 0.0149(0.0150) Steps 428(427.92) | Grad Norm 0.2271(0.2985) | Total Time 10.00(10.00)\n",
      "Iter 4084 | Time 30.6035(30.9441) | Bit/dim 1.1055(1.1042) | Xent 0.0489(0.0494) | Loss 1.1299(1.1289) | Error 0.0152(0.0151) Steps 428(427.92) | Grad Norm 0.1584(0.2943) | Total Time 10.00(10.00)\n",
      "Iter 4085 | Time 31.0703(30.9478) | Bit/dim 1.1056(1.1042) | Xent 0.0480(0.0494) | Loss 1.1296(1.1289) | Error 0.0158(0.0151) Steps 428(427.92) | Grad Norm 0.2188(0.2920) | Total Time 10.00(10.00)\n",
      "Iter 4086 | Time 31.1805(30.9548) | Bit/dim 1.1048(1.1042) | Xent 0.0450(0.0493) | Loss 1.1273(1.1289) | Error 0.0132(0.0150) Steps 428(427.92) | Grad Norm 0.1915(0.2890) | Total Time 10.00(10.00)\n",
      "Iter 4087 | Time 30.5990(30.9441) | Bit/dim 1.1071(1.1043) | Xent 0.0524(0.0494) | Loss 1.1333(1.1290) | Error 0.0151(0.0150) Steps 428(427.93) | Grad Norm 0.2440(0.2877) | Total Time 10.00(10.00)\n",
      "Iter 4088 | Time 30.5358(30.9319) | Bit/dim 1.1031(1.1043) | Xent 0.0518(0.0494) | Loss 1.1290(1.1290) | Error 0.0171(0.0151) Steps 428(427.93) | Grad Norm 0.2368(0.2861) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0584 | Time 16.8319, Epoch Time 245.2520(245.5913), Bit/dim 1.0987(best: 1.0984), Xent 0.0317, Loss 1.1146, Error 0.0106(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4089 | Time 30.7048(30.9251) | Bit/dim 1.1051(1.1043) | Xent 0.0527(0.0495) | Loss 1.1314(1.1291) | Error 0.0134(0.0150) Steps 428(427.93) | Grad Norm 0.1353(0.2816) | Total Time 10.00(10.00)\n",
      "Iter 4090 | Time 31.4729(30.9415) | Bit/dim 1.1034(1.1043) | Xent 0.0501(0.0495) | Loss 1.1284(1.1291) | Error 0.0142(0.0150) Steps 428(427.93) | Grad Norm 0.1928(0.2789) | Total Time 10.00(10.00)\n",
      "Iter 4091 | Time 30.5554(30.9299) | Bit/dim 1.1039(1.1043) | Xent 0.0496(0.0495) | Loss 1.1287(1.1290) | Error 0.0151(0.0150) Steps 428(427.93) | Grad Norm 0.3184(0.2801) | Total Time 10.00(10.00)\n",
      "Iter 4092 | Time 31.2583(30.9398) | Bit/dim 1.1030(1.1042) | Xent 0.0376(0.0492) | Loss 1.1218(1.1288) | Error 0.0119(0.0149) Steps 428(427.94) | Grad Norm 0.3130(0.2811) | Total Time 10.00(10.00)\n",
      "Iter 4093 | Time 31.5159(30.9571) | Bit/dim 1.1025(1.1042) | Xent 0.0478(0.0491) | Loss 1.1264(1.1288) | Error 0.0152(0.0149) Steps 428(427.94) | Grad Norm 0.2224(0.2793) | Total Time 10.00(10.00)\n",
      "Iter 4094 | Time 31.9837(30.9879) | Bit/dim 1.1068(1.1043) | Xent 0.0502(0.0492) | Loss 1.1319(1.1289) | Error 0.0162(0.0150) Steps 428(427.94) | Grad Norm 0.2884(0.2796) | Total Time 10.00(10.00)\n",
      "Iter 4095 | Time 30.7610(30.9811) | Bit/dim 1.1030(1.1042) | Xent 0.0508(0.0492) | Loss 1.1284(1.1288) | Error 0.0152(0.0150) Steps 428(427.94) | Grad Norm 0.2259(0.2780) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0585 | Time 16.9430, Epoch Time 247.9978(245.6635), Bit/dim 1.0989(best: 1.0984), Xent 0.0331, Loss 1.1155, Error 0.0117(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4096 | Time 30.9266(30.9794) | Bit/dim 1.1053(1.1043) | Xent 0.0478(0.0492) | Loss 1.1292(1.1288) | Error 0.0159(0.0150) Steps 428(427.94) | Grad Norm 0.1689(0.2747) | Total Time 10.00(10.00)\n",
      "Iter 4097 | Time 31.9506(31.0086) | Bit/dim 1.1059(1.1043) | Xent 0.0490(0.0492) | Loss 1.1304(1.1289) | Error 0.0155(0.0150) Steps 428(427.94) | Grad Norm 0.1935(0.2723) | Total Time 10.00(10.00)\n",
      "Iter 4098 | Time 31.2431(31.0156) | Bit/dim 1.1044(1.1043) | Xent 0.0484(0.0492) | Loss 1.1287(1.1289) | Error 0.0140(0.0150) Steps 428(427.95) | Grad Norm 0.2357(0.2712) | Total Time 10.00(10.00)\n",
      "Iter 4099 | Time 31.4922(31.0299) | Bit/dim 1.0981(1.1041) | Xent 0.0474(0.0491) | Loss 1.1218(1.1287) | Error 0.0135(0.0149) Steps 428(427.95) | Grad Norm 0.1708(0.2682) | Total Time 10.00(10.00)\n",
      "Iter 4100 | Time 30.6464(31.0184) | Bit/dim 1.1057(1.1042) | Xent 0.0493(0.0491) | Loss 1.1303(1.1287) | Error 0.0144(0.0149) Steps 428(427.95) | Grad Norm 0.4829(0.2746) | Total Time 10.00(10.00)\n",
      "Iter 4101 | Time 30.8485(31.0133) | Bit/dim 1.1041(1.1042) | Xent 0.0501(0.0491) | Loss 1.1291(1.1287) | Error 0.0139(0.0149) Steps 428(427.95) | Grad Norm 0.3443(0.2767) | Total Time 10.00(10.00)\n",
      "Iter 4102 | Time 31.3697(31.0240) | Bit/dim 1.1060(1.1042) | Xent 0.0461(0.0490) | Loss 1.1291(1.1287) | Error 0.0158(0.0149) Steps 428(427.95) | Grad Norm 0.2313(0.2754) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0586 | Time 16.8062, Epoch Time 247.4918(245.7184), Bit/dim 1.0980(best: 1.0984), Xent 0.0316, Loss 1.1138, Error 0.0107(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4103 | Time 30.8896(31.0200) | Bit/dim 1.0998(1.1041) | Xent 0.0517(0.0491) | Loss 1.1257(1.1287) | Error 0.0162(0.0150) Steps 428(427.95) | Grad Norm 0.2224(0.2738) | Total Time 10.00(10.00)\n",
      "Iter 4104 | Time 31.2310(31.0263) | Bit/dim 1.1028(1.1041) | Xent 0.0532(0.0493) | Loss 1.1294(1.1287) | Error 0.0162(0.0150) Steps 428(427.96) | Grad Norm 0.4117(0.2779) | Total Time 10.00(10.00)\n",
      "Iter 4105 | Time 31.0832(31.0280) | Bit/dim 1.1036(1.1040) | Xent 0.0506(0.0493) | Loss 1.1289(1.1287) | Error 0.0154(0.0150) Steps 428(427.96) | Grad Norm 0.2497(0.2771) | Total Time 10.00(10.00)\n",
      "Iter 4106 | Time 30.5149(31.0126) | Bit/dim 1.1064(1.1041) | Xent 0.0477(0.0492) | Loss 1.1303(1.1287) | Error 0.0155(0.0150) Steps 428(427.96) | Grad Norm 0.2925(0.2775) | Total Time 10.00(10.00)\n",
      "Iter 4107 | Time 30.8624(31.0081) | Bit/dim 1.1007(1.1040) | Xent 0.0545(0.0494) | Loss 1.1280(1.1287) | Error 0.0154(0.0150) Steps 428(427.96) | Grad Norm 0.4144(0.2816) | Total Time 10.00(10.00)\n",
      "Iter 4108 | Time 31.1205(31.0115) | Bit/dim 1.1099(1.1042) | Xent 0.0473(0.0493) | Loss 1.1335(1.1289) | Error 0.0145(0.0150) Steps 428(427.96) | Grad Norm 0.3980(0.2851) | Total Time 10.00(10.00)\n",
      "Iter 4109 | Time 31.0951(31.0140) | Bit/dim 1.1064(1.1043) | Xent 0.0415(0.0491) | Loss 1.1272(1.1288) | Error 0.0144(0.0150) Steps 428(427.96) | Grad Norm 0.2018(0.2826) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0587 | Time 16.7104, Epoch Time 245.7434(245.7191), Bit/dim 1.0982(best: 1.0980), Xent 0.0271, Loss 1.1117, Error 0.0087(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4110 | Time 31.5414(31.0298) | Bit/dim 1.1025(1.1042) | Xent 0.0427(0.0489) | Loss 1.1239(1.1287) | Error 0.0139(0.0150) Steps 428(427.96) | Grad Norm 0.2312(0.2811) | Total Time 10.00(10.00)\n",
      "Iter 4111 | Time 30.4123(31.0113) | Bit/dim 1.1055(1.1042) | Xent 0.0435(0.0487) | Loss 1.1272(1.1286) | Error 0.0140(0.0149) Steps 428(427.96) | Grad Norm 0.3389(0.2828) | Total Time 10.00(10.00)\n",
      "Iter 4112 | Time 30.9291(31.0088) | Bit/dim 1.1021(1.1042) | Xent 0.0520(0.0488) | Loss 1.1281(1.1286) | Error 0.0168(0.0150) Steps 428(427.97) | Grad Norm 0.3540(0.2849) | Total Time 10.00(10.00)\n",
      "Iter 4113 | Time 31.7933(31.0323) | Bit/dim 1.1085(1.1043) | Xent 0.0536(0.0490) | Loss 1.1353(1.1288) | Error 0.0161(0.0150) Steps 428(427.97) | Grad Norm 0.2612(0.2842) | Total Time 10.00(10.00)\n",
      "Iter 4114 | Time 30.5387(31.0175) | Bit/dim 1.1031(1.1043) | Xent 0.0478(0.0490) | Loss 1.1270(1.1287) | Error 0.0155(0.0150) Steps 428(427.97) | Grad Norm 0.2628(0.2836) | Total Time 10.00(10.00)\n",
      "Iter 4115 | Time 30.7582(31.0098) | Bit/dim 1.1073(1.1044) | Xent 0.0561(0.0492) | Loss 1.1354(1.1289) | Error 0.0169(0.0151) Steps 428(427.97) | Grad Norm 0.2501(0.2826) | Total Time 10.00(10.00)\n",
      "Iter 4116 | Time 31.2122(31.0158) | Bit/dim 1.1015(1.1043) | Xent 0.0493(0.0492) | Loss 1.1261(1.1289) | Error 0.0171(0.0152) Steps 428(427.97) | Grad Norm 0.3225(0.2838) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0588 | Time 16.9369, Epoch Time 246.4761(245.7419), Bit/dim 1.0985(best: 1.0980), Xent 0.0312, Loss 1.1141, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4117 | Time 30.6935(31.0062) | Bit/dim 1.1012(1.1042) | Xent 0.0496(0.0492) | Loss 1.1260(1.1288) | Error 0.0144(0.0151) Steps 428(427.97) | Grad Norm 0.3041(0.2844) | Total Time 10.00(10.00)\n",
      "Iter 4118 | Time 30.3451(30.9863) | Bit/dim 1.1101(1.1044) | Xent 0.0533(0.0493) | Loss 1.1367(1.1290) | Error 0.0170(0.0152) Steps 428(427.97) | Grad Norm 0.4251(0.2886) | Total Time 10.00(10.00)\n",
      "Iter 4119 | Time 31.0057(30.9869) | Bit/dim 1.1009(1.1043) | Xent 0.0421(0.0491) | Loss 1.1220(1.1288) | Error 0.0122(0.0151) Steps 428(427.97) | Grad Norm 0.1738(0.2852) | Total Time 10.00(10.00)\n",
      "Iter 4120 | Time 30.7138(30.9787) | Bit/dim 1.1042(1.1043) | Xent 0.0557(0.0493) | Loss 1.1320(1.1289) | Error 0.0172(0.0152) Steps 428(427.97) | Grad Norm 0.5617(0.2935) | Total Time 10.00(10.00)\n",
      "Iter 4121 | Time 29.9681(30.9484) | Bit/dim 1.1050(1.1043) | Xent 0.0471(0.0492) | Loss 1.1285(1.1289) | Error 0.0154(0.0152) Steps 428(427.97) | Grad Norm 0.1953(0.2905) | Total Time 10.00(10.00)\n",
      "Iter 4122 | Time 30.5209(30.9356) | Bit/dim 1.1053(1.1043) | Xent 0.0561(0.0494) | Loss 1.1333(1.1290) | Error 0.0160(0.0152) Steps 428(427.97) | Grad Norm 0.4122(0.2942) | Total Time 10.00(10.00)\n",
      "Iter 4123 | Time 31.2193(30.9441) | Bit/dim 1.1012(1.1042) | Xent 0.0456(0.0493) | Loss 1.1241(1.1289) | Error 0.0142(0.0152) Steps 428(427.97) | Grad Norm 0.1716(0.2905) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0589 | Time 16.8429, Epoch Time 243.6881(245.6802), Bit/dim 1.0983(best: 1.0980), Xent 0.0318, Loss 1.1142, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4124 | Time 31.5681(30.9628) | Bit/dim 1.1054(1.1043) | Xent 0.0518(0.0494) | Loss 1.1313(1.1289) | Error 0.0166(0.0152) Steps 428(427.98) | Grad Norm 0.1691(0.2869) | Total Time 10.00(10.00)\n",
      "Iter 4125 | Time 30.9078(30.9612) | Bit/dim 1.1052(1.1043) | Xent 0.0499(0.0494) | Loss 1.1302(1.1290) | Error 0.0156(0.0152) Steps 428(427.98) | Grad Norm 0.4512(0.2918) | Total Time 10.00(10.00)\n",
      "Iter 4126 | Time 30.6020(30.9504) | Bit/dim 1.1009(1.1042) | Xent 0.0422(0.0492) | Loss 1.1220(1.1288) | Error 0.0142(0.0152) Steps 428(427.98) | Grad Norm 0.2963(0.2919) | Total Time 10.00(10.00)\n",
      "Iter 4127 | Time 31.7300(30.9738) | Bit/dim 1.1036(1.1042) | Xent 0.0496(0.0492) | Loss 1.1284(1.1288) | Error 0.0154(0.0152) Steps 428(427.98) | Grad Norm 0.2644(0.2911) | Total Time 10.00(10.00)\n",
      "Iter 4128 | Time 30.8739(30.9708) | Bit/dim 1.1009(1.1041) | Xent 0.0511(0.0493) | Loss 1.1265(1.1287) | Error 0.0141(0.0152) Steps 428(427.98) | Grad Norm 0.3051(0.2915) | Total Time 10.00(10.00)\n",
      "Iter 4129 | Time 31.2061(30.9778) | Bit/dim 1.1018(1.1040) | Xent 0.0428(0.0491) | Loss 1.1232(1.1285) | Error 0.0138(0.0151) Steps 422(427.80) | Grad Norm 0.5427(0.2991) | Total Time 10.00(10.00)\n",
      "Iter 4130 | Time 30.1213(30.9521) | Bit/dim 1.1070(1.1041) | Xent 0.0471(0.0490) | Loss 1.1306(1.1286) | Error 0.0142(0.0151) Steps 428(427.81) | Grad Norm 0.2150(0.2965) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0590 | Time 16.6903, Epoch Time 245.8319(245.6848), Bit/dim 1.0985(best: 1.0980), Xent 0.0295, Loss 1.1132, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4131 | Time 30.2278(30.9304) | Bit/dim 1.1013(1.1040) | Xent 0.0522(0.0491) | Loss 1.1274(1.1286) | Error 0.0158(0.0151) Steps 428(427.81) | Grad Norm 0.7015(0.3087) | Total Time 10.00(10.00)\n",
      "Iter 4132 | Time 30.5957(30.9204) | Bit/dim 1.1047(1.1040) | Xent 0.0458(0.0490) | Loss 1.1276(1.1285) | Error 0.0146(0.0151) Steps 428(427.82) | Grad Norm 0.3102(0.3087) | Total Time 10.00(10.00)\n",
      "Iter 4133 | Time 30.6897(30.9134) | Bit/dim 1.1029(1.1040) | Xent 0.0445(0.0489) | Loss 1.1252(1.1284) | Error 0.0135(0.0151) Steps 428(427.82) | Grad Norm 0.2418(0.3067) | Total Time 10.00(10.00)\n",
      "Iter 4134 | Time 32.2754(30.9543) | Bit/dim 1.1028(1.1040) | Xent 0.0520(0.0490) | Loss 1.1288(1.1284) | Error 0.0155(0.0151) Steps 428(427.83) | Grad Norm 0.4165(0.3100) | Total Time 10.00(10.00)\n",
      "Iter 4135 | Time 31.3365(30.9658) | Bit/dim 1.1037(1.1039) | Xent 0.0464(0.0489) | Loss 1.1269(1.1284) | Error 0.0161(0.0151) Steps 428(427.83) | Grad Norm 0.4166(0.3132) | Total Time 10.00(10.00)\n",
      "Iter 4136 | Time 31.0536(30.9684) | Bit/dim 1.1079(1.1041) | Xent 0.0485(0.0489) | Loss 1.1322(1.1285) | Error 0.0151(0.0151) Steps 428(427.84) | Grad Norm 0.4989(0.3188) | Total Time 10.00(10.00)\n",
      "Iter 4137 | Time 32.0681(31.0014) | Bit/dim 1.0993(1.1039) | Xent 0.0448(0.0488) | Loss 1.1218(1.1283) | Error 0.0148(0.0151) Steps 428(427.84) | Grad Norm 0.2874(0.3178) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0591 | Time 16.8542, Epoch Time 247.6257(245.7430), Bit/dim 1.0982(best: 1.0980), Xent 0.0326, Loss 1.1145, Error 0.0112(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4138 | Time 30.7766(30.9947) | Bit/dim 1.1051(1.1040) | Xent 0.0509(0.0488) | Loss 1.1305(1.1284) | Error 0.0151(0.0151) Steps 428(427.85) | Grad Norm 0.2108(0.3146) | Total Time 10.00(10.00)\n",
      "Iter 4139 | Time 31.9479(31.0233) | Bit/dim 1.1033(1.1039) | Xent 0.0487(0.0488) | Loss 1.1277(1.1283) | Error 0.0159(0.0151) Steps 428(427.85) | Grad Norm 0.3252(0.3149) | Total Time 10.00(10.00)\n",
      "Iter 4140 | Time 31.0736(31.0248) | Bit/dim 1.1030(1.1039) | Xent 0.0479(0.0488) | Loss 1.1270(1.1283) | Error 0.0150(0.0151) Steps 428(427.86) | Grad Norm 0.2277(0.3123) | Total Time 10.00(10.00)\n",
      "Iter 4141 | Time 30.4390(31.0072) | Bit/dim 1.1052(1.1040) | Xent 0.0455(0.0487) | Loss 1.1280(1.1283) | Error 0.0149(0.0151) Steps 428(427.86) | Grad Norm 0.2901(0.3117) | Total Time 10.00(10.00)\n",
      "Iter 4142 | Time 30.5662(30.9940) | Bit/dim 1.1098(1.1041) | Xent 0.0505(0.0487) | Loss 1.1350(1.1285) | Error 0.0164(0.0151) Steps 428(427.86) | Grad Norm 0.2428(0.3096) | Total Time 10.00(10.00)\n",
      "Iter 4143 | Time 30.6697(30.9842) | Bit/dim 1.0997(1.1040) | Xent 0.0456(0.0486) | Loss 1.1225(1.1283) | Error 0.0139(0.0151) Steps 428(427.87) | Grad Norm 0.2704(0.3084) | Total Time 10.00(10.00)\n",
      "Iter 4144 | Time 30.6805(30.9751) | Bit/dim 1.1022(1.1039) | Xent 0.0472(0.0486) | Loss 1.1258(1.1282) | Error 0.0144(0.0151) Steps 428(427.87) | Grad Norm 0.3276(0.3090) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0592 | Time 17.0254, Epoch Time 245.4371(245.7338), Bit/dim 1.0983(best: 1.0980), Xent 0.0322, Loss 1.1144, Error 0.0109(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4145 | Time 30.5805(30.9633) | Bit/dim 1.1066(1.1040) | Xent 0.0496(0.0486) | Loss 1.1314(1.1283) | Error 0.0145(0.0151) Steps 428(427.88) | Grad Norm 0.3299(0.3096) | Total Time 10.00(10.00)\n",
      "Iter 4146 | Time 30.3559(30.9451) | Bit/dim 1.1047(1.1040) | Xent 0.0566(0.0489) | Loss 1.1330(1.1285) | Error 0.0169(0.0151) Steps 428(427.88) | Grad Norm 0.3885(0.3120) | Total Time 10.00(10.00)\n",
      "Iter 4147 | Time 31.6472(30.9661) | Bit/dim 1.1056(1.1041) | Xent 0.0502(0.0489) | Loss 1.1308(1.1285) | Error 0.0149(0.0151) Steps 428(427.88) | Grad Norm 0.2393(0.3098) | Total Time 10.00(10.00)\n",
      "Iter 4148 | Time 30.7325(30.9591) | Bit/dim 1.1024(1.1040) | Xent 0.0494(0.0489) | Loss 1.1270(1.1285) | Error 0.0146(0.0151) Steps 428(427.89) | Grad Norm 0.1499(0.3050) | Total Time 10.00(10.00)\n",
      "Iter 4149 | Time 30.7548(30.9530) | Bit/dim 1.1008(1.1039) | Xent 0.0491(0.0489) | Loss 1.1253(1.1284) | Error 0.0141(0.0151) Steps 428(427.89) | Grad Norm 0.2485(0.3033) | Total Time 10.00(10.00)\n",
      "Iter 4150 | Time 31.5268(30.9702) | Bit/dim 1.1053(1.1040) | Xent 0.0412(0.0487) | Loss 1.1259(1.1283) | Error 0.0122(0.0150) Steps 428(427.89) | Grad Norm 0.3124(0.3036) | Total Time 10.00(10.00)\n",
      "Iter 4151 | Time 31.8324(30.9961) | Bit/dim 1.1021(1.1039) | Xent 0.0522(0.0488) | Loss 1.1282(1.1283) | Error 0.0165(0.0150) Steps 428(427.90) | Grad Norm 0.2460(0.3019) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0593 | Time 16.8811, Epoch Time 246.5070(245.7570), Bit/dim 1.0987(best: 1.0980), Xent 0.0316, Loss 1.1145, Error 0.0110(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4152 | Time 30.2401(30.9734) | Bit/dim 1.1044(1.1039) | Xent 0.0510(0.0489) | Loss 1.1299(1.1284) | Error 0.0162(0.0151) Steps 428(427.90) | Grad Norm 0.5796(0.3102) | Total Time 10.00(10.00)\n",
      "Iter 4153 | Time 30.6076(30.9624) | Bit/dim 1.1038(1.1039) | Xent 0.0413(0.0486) | Loss 1.1244(1.1283) | Error 0.0130(0.0150) Steps 428(427.90) | Grad Norm 0.2117(0.3072) | Total Time 10.00(10.00)\n",
      "Iter 4154 | Time 31.0848(30.9661) | Bit/dim 1.1025(1.1039) | Xent 0.0453(0.0485) | Loss 1.1251(1.1282) | Error 0.0138(0.0150) Steps 428(427.91) | Grad Norm 0.4786(0.3124) | Total Time 10.00(10.00)\n",
      "Iter 4155 | Time 30.3918(30.9489) | Bit/dim 1.1005(1.1038) | Xent 0.0438(0.0484) | Loss 1.1224(1.1280) | Error 0.0129(0.0149) Steps 428(427.91) | Grad Norm 0.2803(0.3114) | Total Time 10.00(10.00)\n",
      "Iter 4156 | Time 32.5478(30.9968) | Bit/dim 1.1002(1.1037) | Xent 0.0479(0.0484) | Loss 1.1241(1.1279) | Error 0.0144(0.0149) Steps 428(427.91) | Grad Norm 0.3571(0.3128) | Total Time 10.00(10.00)\n",
      "Iter 4157 | Time 30.1925(30.9727) | Bit/dim 1.1059(1.1037) | Xent 0.0549(0.0486) | Loss 1.1334(1.1280) | Error 0.0174(0.0150) Steps 428(427.91) | Grad Norm 0.3733(0.3146) | Total Time 10.00(10.00)\n",
      "Iter 4158 | Time 31.3377(30.9837) | Bit/dim 1.1067(1.1038) | Xent 0.0483(0.0486) | Loss 1.1308(1.1281) | Error 0.0141(0.0149) Steps 428(427.92) | Grad Norm 0.3523(0.3157) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0594 | Time 17.0410, Epoch Time 245.6764(245.7546), Bit/dim 1.0979(best: 1.0980), Xent 0.0345, Loss 1.1151, Error 0.0103(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4159 | Time 31.7063(31.0053) | Bit/dim 1.1020(1.1038) | Xent 0.0464(0.0485) | Loss 1.1253(1.1280) | Error 0.0139(0.0149) Steps 428(427.92) | Grad Norm 0.4018(0.3183) | Total Time 10.00(10.00)\n",
      "Iter 4160 | Time 31.3531(31.0158) | Bit/dim 1.1009(1.1037) | Xent 0.0478(0.0485) | Loss 1.1248(1.1279) | Error 0.0144(0.0149) Steps 428(427.92) | Grad Norm 0.3505(0.3193) | Total Time 10.00(10.00)\n",
      "Iter 4161 | Time 31.4605(31.0291) | Bit/dim 1.1074(1.1038) | Xent 0.0542(0.0487) | Loss 1.1345(1.1281) | Error 0.0160(0.0149) Steps 428(427.92) | Grad Norm 0.7464(0.3321) | Total Time 10.00(10.00)\n",
      "Iter 4162 | Time 30.6213(31.0169) | Bit/dim 1.1051(1.1038) | Xent 0.0457(0.0486) | Loss 1.1280(1.1281) | Error 0.0141(0.0149) Steps 428(427.93) | Grad Norm 0.2623(0.3300) | Total Time 10.00(10.00)\n",
      "Iter 4163 | Time 30.4601(31.0002) | Bit/dim 1.1059(1.1039) | Xent 0.0519(0.0487) | Loss 1.1318(1.1282) | Error 0.0156(0.0149) Steps 428(427.93) | Grad Norm 0.5052(0.3353) | Total Time 10.00(10.00)\n",
      "Iter 4164 | Time 31.1100(31.0035) | Bit/dim 1.1029(1.1039) | Xent 0.0482(0.0487) | Loss 1.1271(1.1282) | Error 0.0152(0.0149) Steps 428(427.93) | Grad Norm 0.3783(0.3366) | Total Time 10.00(10.00)\n",
      "Iter 4165 | Time 30.2684(30.9814) | Bit/dim 1.1018(1.1038) | Xent 0.0431(0.0485) | Loss 1.1233(1.1281) | Error 0.0129(0.0149) Steps 428(427.93) | Grad Norm 0.3080(0.3357) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0595 | Time 16.9596, Epoch Time 246.2100(245.7683), Bit/dim 1.0979(best: 1.0979), Xent 0.0308, Loss 1.1133, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4166 | Time 31.1778(30.9873) | Bit/dim 1.1024(1.1038) | Xent 0.0526(0.0486) | Loss 1.1287(1.1281) | Error 0.0161(0.0149) Steps 428(427.93) | Grad Norm 0.5566(0.3423) | Total Time 10.00(10.00)\n",
      "Iter 4167 | Time 31.1196(30.9913) | Bit/dim 1.1026(1.1037) | Xent 0.0471(0.0486) | Loss 1.1262(1.1280) | Error 0.0139(0.0149) Steps 428(427.94) | Grad Norm 0.2860(0.3406) | Total Time 10.00(10.00)\n",
      "Iter 4168 | Time 30.6286(30.9804) | Bit/dim 1.1038(1.1037) | Xent 0.0517(0.0487) | Loss 1.1297(1.1281) | Error 0.0164(0.0149) Steps 428(427.94) | Grad Norm 0.4171(0.3429) | Total Time 10.00(10.00)\n",
      "Iter 4169 | Time 30.1928(30.9568) | Bit/dim 1.0989(1.1036) | Xent 0.0526(0.0488) | Loss 1.1252(1.1280) | Error 0.0151(0.0149) Steps 428(427.94) | Grad Norm 0.5161(0.3481) | Total Time 10.00(10.00)\n",
      "Iter 4170 | Time 30.7206(30.9497) | Bit/dim 1.1035(1.1036) | Xent 0.0491(0.0488) | Loss 1.1280(1.1280) | Error 0.0154(0.0149) Steps 428(427.94) | Grad Norm 0.1976(0.3436) | Total Time 10.00(10.00)\n",
      "Iter 4171 | Time 33.0776(31.0135) | Bit/dim 1.1068(1.1037) | Xent 0.0487(0.0488) | Loss 1.1312(1.1281) | Error 0.0162(0.0150) Steps 428(427.94) | Grad Norm 0.4700(0.3474) | Total Time 10.00(10.00)\n",
      "Iter 4172 | Time 31.3716(31.0243) | Bit/dim 1.1045(1.1037) | Xent 0.0478(0.0488) | Loss 1.1284(1.1281) | Error 0.0149(0.0150) Steps 428(427.95) | Grad Norm 0.3941(0.3488) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0596 | Time 16.8365, Epoch Time 247.3262(245.8150), Bit/dim 1.0980(best: 1.0979), Xent 0.0320, Loss 1.1140, Error 0.0098(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4173 | Time 30.6763(31.0138) | Bit/dim 1.1026(1.1037) | Xent 0.0426(0.0486) | Loss 1.1239(1.1280) | Error 0.0122(0.0149) Steps 428(427.95) | Grad Norm 0.3025(0.3474) | Total Time 10.00(10.00)\n",
      "Iter 4174 | Time 30.7888(31.0071) | Bit/dim 1.1041(1.1037) | Xent 0.0475(0.0485) | Loss 1.1278(1.1280) | Error 0.0159(0.0149) Steps 428(427.95) | Grad Norm 0.2911(0.3457) | Total Time 10.00(10.00)\n",
      "Iter 4175 | Time 31.3449(31.0172) | Bit/dim 1.1033(1.1037) | Xent 0.0458(0.0485) | Loss 1.1262(1.1279) | Error 0.0140(0.0149) Steps 428(427.95) | Grad Norm 0.2561(0.3430) | Total Time 10.00(10.00)\n",
      "Iter 4176 | Time 32.1806(31.0521) | Bit/dim 1.1029(1.1037) | Xent 0.0452(0.0484) | Loss 1.1255(1.1278) | Error 0.0151(0.0149) Steps 428(427.95) | Grad Norm 0.3680(0.3438) | Total Time 10.00(10.00)\n",
      "Iter 4177 | Time 31.2828(31.0590) | Bit/dim 1.1075(1.1038) | Xent 0.0536(0.0485) | Loss 1.1344(1.1280) | Error 0.0139(0.0149) Steps 428(427.95) | Grad Norm 0.2677(0.3415) | Total Time 10.00(10.00)\n",
      "Iter 4178 | Time 31.1137(31.0607) | Bit/dim 1.0993(1.1036) | Xent 0.0457(0.0484) | Loss 1.1222(1.1279) | Error 0.0141(0.0148) Steps 428(427.95) | Grad Norm 0.2416(0.3385) | Total Time 10.00(10.00)\n",
      "Iter 4179 | Time 30.5594(31.0456) | Bit/dim 1.1061(1.1037) | Xent 0.0479(0.0484) | Loss 1.1300(1.1279) | Error 0.0139(0.0148) Steps 428(427.96) | Grad Norm 0.4911(0.3431) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0597 | Time 17.1441, Epoch Time 247.0545(245.8522), Bit/dim 1.0978(best: 1.0979), Xent 0.0301, Loss 1.1128, Error 0.0091(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4180 | Time 32.2675(31.0823) | Bit/dim 1.1053(1.1038) | Xent 0.0502(0.0485) | Loss 1.1304(1.1280) | Error 0.0136(0.0148) Steps 428(427.96) | Grad Norm 0.2870(0.3414) | Total Time 10.00(10.00)\n",
      "Iter 4181 | Time 30.9487(31.0783) | Bit/dim 1.1063(1.1038) | Xent 0.0506(0.0485) | Loss 1.1316(1.1281) | Error 0.0154(0.0148) Steps 428(427.96) | Grad Norm 0.3582(0.3419) | Total Time 10.00(10.00)\n",
      "Iter 4182 | Time 30.5041(31.0611) | Bit/dim 1.1042(1.1038) | Xent 0.0473(0.0485) | Loss 1.1279(1.1281) | Error 0.0142(0.0148) Steps 428(427.96) | Grad Norm 0.3005(0.3407) | Total Time 10.00(10.00)\n",
      "Iter 4183 | Time 30.5752(31.0465) | Bit/dim 1.1046(1.1039) | Xent 0.0484(0.0485) | Loss 1.1288(1.1281) | Error 0.0168(0.0148) Steps 428(427.96) | Grad Norm 0.2862(0.3390) | Total Time 10.00(10.00)\n",
      "Iter 4184 | Time 30.6451(31.0344) | Bit/dim 1.1014(1.1038) | Xent 0.0503(0.0485) | Loss 1.1266(1.1281) | Error 0.0148(0.0148) Steps 428(427.96) | Grad Norm 0.6374(0.3480) | Total Time 10.00(10.00)\n",
      "Iter 4185 | Time 30.7688(31.0265) | Bit/dim 1.1002(1.1037) | Xent 0.0393(0.0483) | Loss 1.1199(1.1278) | Error 0.0115(0.0147) Steps 428(427.96) | Grad Norm 0.2742(0.3458) | Total Time 10.00(10.00)\n",
      "Iter 4186 | Time 31.0033(31.0258) | Bit/dim 1.1047(1.1037) | Xent 0.0474(0.0482) | Loss 1.1284(1.1278) | Error 0.0156(0.0148) Steps 428(427.96) | Grad Norm 0.6435(0.3547) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0598 | Time 16.9204, Epoch Time 245.7586(245.8494), Bit/dim 1.0979(best: 1.0978), Xent 0.0323, Loss 1.1141, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4187 | Time 30.5818(31.0124) | Bit/dim 1.1039(1.1037) | Xent 0.0468(0.0482) | Loss 1.1272(1.1278) | Error 0.0161(0.0148) Steps 428(427.97) | Grad Norm 0.4875(0.3587) | Total Time 10.00(10.00)\n",
      "Iter 4188 | Time 30.9275(31.0099) | Bit/dim 1.1053(1.1038) | Xent 0.0436(0.0481) | Loss 1.1271(1.1278) | Error 0.0149(0.0148) Steps 428(427.97) | Grad Norm 0.3325(0.3579) | Total Time 10.00(10.00)\n",
      "Iter 4189 | Time 30.7684(31.0027) | Bit/dim 1.1046(1.1038) | Xent 0.0499(0.0481) | Loss 1.1295(1.1279) | Error 0.0159(0.0148) Steps 428(427.97) | Grad Norm 0.7077(0.3684) | Total Time 10.00(10.00)\n",
      "Iter 4190 | Time 31.4902(31.0173) | Bit/dim 1.1044(1.1038) | Xent 0.0479(0.0481) | Loss 1.1283(1.1279) | Error 0.0151(0.0149) Steps 428(427.97) | Grad Norm 0.4650(0.3713) | Total Time 10.00(10.00)\n",
      "Iter 4191 | Time 30.9632(31.0157) | Bit/dim 1.1043(1.1038) | Xent 0.0462(0.0481) | Loss 1.1274(1.1279) | Error 0.0144(0.0148) Steps 428(427.97) | Grad Norm 0.2148(0.3666) | Total Time 10.00(10.00)\n",
      "Iter 4192 | Time 30.9775(31.0145) | Bit/dim 1.1009(1.1037) | Xent 0.0479(0.0480) | Loss 1.1248(1.1278) | Error 0.0161(0.0149) Steps 428(427.97) | Grad Norm 0.8130(0.3800) | Total Time 10.00(10.00)\n",
      "Iter 4193 | Time 31.0786(31.0164) | Bit/dim 1.1033(1.1037) | Xent 0.0490(0.0481) | Loss 1.1278(1.1278) | Error 0.0160(0.0149) Steps 428(427.97) | Grad Norm 0.3565(0.3793) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0599 | Time 16.6113, Epoch Time 245.6765(245.8442), Bit/dim 1.0977(best: 1.0978), Xent 0.0349, Loss 1.1151, Error 0.0104(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4194 | Time 30.3739(30.9972) | Bit/dim 1.1020(1.1037) | Xent 0.0463(0.0480) | Loss 1.1252(1.1277) | Error 0.0129(0.0148) Steps 428(427.97) | Grad Norm 0.6116(0.3862) | Total Time 10.00(10.00)\n",
      "Iter 4195 | Time 30.5641(30.9842) | Bit/dim 1.1059(1.1037) | Xent 0.0554(0.0482) | Loss 1.1336(1.1279) | Error 0.0159(0.0149) Steps 428(427.97) | Grad Norm 0.2164(0.3811) | Total Time 10.00(10.00)\n",
      "Iter 4196 | Time 30.5718(30.9718) | Bit/dim 1.0998(1.1036) | Xent 0.0436(0.0481) | Loss 1.1216(1.1277) | Error 0.0136(0.0148) Steps 428(427.97) | Grad Norm 0.2835(0.3782) | Total Time 10.00(10.00)\n",
      "Iter 4197 | Time 30.5638(30.9596) | Bit/dim 1.1027(1.1036) | Xent 0.0459(0.0480) | Loss 1.1257(1.1276) | Error 0.0156(0.0149) Steps 428(427.97) | Grad Norm 0.2702(0.3750) | Total Time 10.00(10.00)\n",
      "Iter 4198 | Time 31.4126(30.9731) | Bit/dim 1.1083(1.1037) | Xent 0.0458(0.0480) | Loss 1.1312(1.1277) | Error 0.0154(0.0149) Steps 428(427.98) | Grad Norm 0.2806(0.3721) | Total Time 10.00(10.00)\n",
      "Iter 4199 | Time 31.1880(30.9796) | Bit/dim 1.1026(1.1037) | Xent 0.0507(0.0481) | Loss 1.1280(1.1277) | Error 0.0158(0.0149) Steps 428(427.98) | Grad Norm 0.2142(0.3674) | Total Time 10.00(10.00)\n",
      "Iter 4200 | Time 30.8923(30.9770) | Bit/dim 1.1001(1.1036) | Xent 0.0435(0.0479) | Loss 1.1218(1.1276) | Error 0.0146(0.0149) Steps 428(427.98) | Grad Norm 0.4318(0.3693) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0600 | Time 16.7379, Epoch Time 244.6970(245.8098), Bit/dim 1.0981(best: 1.0977), Xent 0.0324, Loss 1.1143, Error 0.0100(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4201 | Time 30.2782(30.9560) | Bit/dim 1.1012(1.1035) | Xent 0.0480(0.0479) | Loss 1.1252(1.1275) | Error 0.0158(0.0149) Steps 428(427.98) | Grad Norm 0.2773(0.3666) | Total Time 10.00(10.00)\n",
      "Iter 4202 | Time 30.3787(30.9387) | Bit/dim 1.1027(1.1035) | Xent 0.0465(0.0479) | Loss 1.1260(1.1274) | Error 0.0150(0.0149) Steps 428(427.98) | Grad Norm 0.3934(0.3674) | Total Time 10.00(10.00)\n",
      "Iter 4203 | Time 30.6226(30.9292) | Bit/dim 1.1070(1.1036) | Xent 0.0560(0.0481) | Loss 1.1350(1.1277) | Error 0.0184(0.0150) Steps 428(427.98) | Grad Norm 0.4061(0.3685) | Total Time 10.00(10.00)\n",
      "Iter 4204 | Time 30.7576(30.9241) | Bit/dim 1.1035(1.1036) | Xent 0.0449(0.0480) | Loss 1.1260(1.1276) | Error 0.0138(0.0150) Steps 428(427.98) | Grad Norm 0.5502(0.3740) | Total Time 10.00(10.00)\n",
      "Iter 4205 | Time 31.3653(30.9373) | Bit/dim 1.1012(1.1035) | Xent 0.0481(0.0480) | Loss 1.1252(1.1275) | Error 0.0155(0.0150) Steps 428(427.98) | Grad Norm 0.4173(0.3753) | Total Time 10.00(10.00)\n",
      "Iter 4206 | Time 31.2463(30.9466) | Bit/dim 1.1067(1.1036) | Xent 0.0478(0.0480) | Loss 1.1306(1.1276) | Error 0.0135(0.0150) Steps 428(427.98) | Grad Norm 0.2949(0.3729) | Total Time 10.00(10.00)\n",
      "Iter 4207 | Time 32.3916(30.9899) | Bit/dim 1.1029(1.1036) | Xent 0.0483(0.0480) | Loss 1.1271(1.1276) | Error 0.0140(0.0149) Steps 428(427.98) | Grad Norm 0.3753(0.3730) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0601 | Time 16.6332, Epoch Time 245.8655(245.8115), Bit/dim 1.0975(best: 1.0977), Xent 0.0318, Loss 1.1134, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4208 | Time 30.3147(30.9697) | Bit/dim 1.1061(1.1037) | Xent 0.0433(0.0479) | Loss 1.1278(1.1276) | Error 0.0148(0.0149) Steps 428(427.98) | Grad Norm 0.5420(0.3780) | Total Time 10.00(10.00)\n",
      "Iter 4209 | Time 31.2796(30.9790) | Bit/dim 1.1047(1.1037) | Xent 0.0487(0.0479) | Loss 1.1291(1.1277) | Error 0.0126(0.0149) Steps 428(427.98) | Grad Norm 0.2228(0.3734) | Total Time 10.00(10.00)\n",
      "Iter 4210 | Time 31.4540(30.9932) | Bit/dim 1.1024(1.1037) | Xent 0.0494(0.0480) | Loss 1.1270(1.1276) | Error 0.0158(0.0149) Steps 428(427.98) | Grad Norm 0.4606(0.3760) | Total Time 10.00(10.00)\n",
      "Iter 4211 | Time 30.2692(30.9715) | Bit/dim 1.1066(1.1038) | Xent 0.0513(0.0481) | Loss 1.1323(1.1278) | Error 0.0152(0.0149) Steps 428(427.98) | Grad Norm 0.2841(0.3732) | Total Time 10.00(10.00)\n",
      "Iter 4212 | Time 31.1000(30.9753) | Bit/dim 1.1039(1.1038) | Xent 0.0488(0.0481) | Loss 1.1283(1.1278) | Error 0.0135(0.0149) Steps 428(427.98) | Grad Norm 0.2354(0.3691) | Total Time 10.00(10.00)\n",
      "Iter 4213 | Time 30.9732(30.9753) | Bit/dim 1.1037(1.1038) | Xent 0.0458(0.0480) | Loss 1.1266(1.1278) | Error 0.0131(0.0148) Steps 428(427.98) | Grad Norm 0.4051(0.3702) | Total Time 10.00(10.00)\n",
      "Iter 4214 | Time 31.1651(30.9810) | Bit/dim 1.0990(1.1036) | Xent 0.0499(0.0481) | Loss 1.1239(1.1276) | Error 0.0144(0.0148) Steps 428(427.98) | Grad Norm 0.3208(0.3687) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0602 | Time 16.6459, Epoch Time 245.4219(245.7998), Bit/dim 1.0975(best: 1.0975), Xent 0.0309, Loss 1.1129, Error 0.0092(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4215 | Time 30.4297(30.9644) | Bit/dim 1.1104(1.1038) | Xent 0.0567(0.0483) | Loss 1.1387(1.1280) | Error 0.0184(0.0149) Steps 428(427.99) | Grad Norm 0.2257(0.3644) | Total Time 10.00(10.00)\n",
      "Iter 4216 | Time 30.8222(30.9602) | Bit/dim 1.1003(1.1037) | Xent 0.0472(0.0483) | Loss 1.1239(1.1279) | Error 0.0152(0.0149) Steps 428(427.99) | Grad Norm 0.5542(0.3701) | Total Time 10.00(10.00)\n",
      "Iter 4217 | Time 30.6322(30.9503) | Bit/dim 1.0963(1.1035) | Xent 0.0491(0.0483) | Loss 1.1209(1.1276) | Error 0.0140(0.0149) Steps 428(427.99) | Grad Norm 0.3068(0.3682) | Total Time 10.00(10.00)\n",
      "Iter 4218 | Time 30.8976(30.9487) | Bit/dim 1.1069(1.1036) | Xent 0.0416(0.0481) | Loss 1.1277(1.1277) | Error 0.0132(0.0148) Steps 428(427.99) | Grad Norm 0.3317(0.3671) | Total Time 10.00(10.00)\n",
      "Iter 4219 | Time 30.9400(30.9485) | Bit/dim 1.1004(1.1035) | Xent 0.0447(0.0480) | Loss 1.1228(1.1275) | Error 0.0148(0.0148) Steps 428(427.99) | Grad Norm 0.5175(0.3716) | Total Time 10.00(10.00)\n",
      "Iter 4220 | Time 30.3786(30.9314) | Bit/dim 1.1045(1.1035) | Xent 0.0503(0.0481) | Loss 1.1296(1.1276) | Error 0.0154(0.0148) Steps 428(427.99) | Grad Norm 0.2341(0.3675) | Total Time 10.00(10.00)\n",
      "Iter 4221 | Time 30.4954(30.9183) | Bit/dim 1.1029(1.1035) | Xent 0.0500(0.0481) | Loss 1.1279(1.1276) | Error 0.0145(0.0148) Steps 428(427.99) | Grad Norm 0.4889(0.3711) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0603 | Time 16.7045, Epoch Time 243.5377(245.7319), Bit/dim 1.0982(best: 1.0975), Xent 0.0324, Loss 1.1144, Error 0.0111(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4222 | Time 30.9455(30.9191) | Bit/dim 1.1031(1.1035) | Xent 0.0457(0.0481) | Loss 1.1259(1.1275) | Error 0.0130(0.0148) Steps 428(427.99) | Grad Norm 0.4173(0.3725) | Total Time 10.00(10.00)\n",
      "Iter 4223 | Time 31.3433(30.9319) | Bit/dim 1.1014(1.1034) | Xent 0.0443(0.0479) | Loss 1.1236(1.1274) | Error 0.0112(0.0147) Steps 428(427.99) | Grad Norm 0.3665(0.3723) | Total Time 10.00(10.00)\n",
      "Iter 4224 | Time 30.4649(30.9178) | Bit/dim 1.1064(1.1035) | Xent 0.0477(0.0479) | Loss 1.1303(1.1275) | Error 0.0149(0.0147) Steps 428(427.99) | Grad Norm 0.5788(0.3785) | Total Time 10.00(10.00)\n",
      "Iter 4225 | Time 30.6309(30.9092) | Bit/dim 1.1036(1.1035) | Xent 0.0441(0.0478) | Loss 1.1257(1.1274) | Error 0.0152(0.0147) Steps 428(427.99) | Grad Norm 0.4548(0.3808) | Total Time 10.00(10.00)\n",
      "Iter 4226 | Time 31.4820(30.9264) | Bit/dim 1.1055(1.1036) | Xent 0.0421(0.0477) | Loss 1.1266(1.1274) | Error 0.0139(0.0147) Steps 428(427.99) | Grad Norm 0.8228(0.3941) | Total Time 10.00(10.00)\n",
      "Iter 4227 | Time 32.0487(30.9601) | Bit/dim 1.1069(1.1037) | Xent 0.0493(0.0477) | Loss 1.1316(1.1275) | Error 0.0154(0.0147) Steps 428(427.99) | Grad Norm 0.6732(0.4025) | Total Time 10.00(10.00)\n",
      "Iter 4228 | Time 30.6202(30.9499) | Bit/dim 1.0999(1.1036) | Xent 0.0529(0.0479) | Loss 1.1263(1.1275) | Error 0.0162(0.0147) Steps 428(427.99) | Grad Norm 0.3412(0.4006) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0604 | Time 16.5977, Epoch Time 246.4141(245.7524), Bit/dim 1.0975(best: 1.0975), Xent 0.0335, Loss 1.1143, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4229 | Time 30.3217(30.9311) | Bit/dim 1.1053(1.1036) | Xent 0.0489(0.0479) | Loss 1.1297(1.1276) | Error 0.0138(0.0147) Steps 428(427.99) | Grad Norm 0.6192(0.4072) | Total Time 10.00(10.00)\n",
      "Iter 4230 | Time 30.7926(30.9269) | Bit/dim 1.1005(1.1035) | Xent 0.0476(0.0479) | Loss 1.1244(1.1275) | Error 0.0141(0.0147) Steps 428(427.99) | Grad Norm 0.4887(0.4096) | Total Time 10.00(10.00)\n",
      "Iter 4231 | Time 32.0437(30.9604) | Bit/dim 1.1037(1.1035) | Xent 0.0530(0.0480) | Loss 1.1302(1.1276) | Error 0.0162(0.0147) Steps 428(427.99) | Grad Norm 0.2934(0.4061) | Total Time 10.00(10.00)\n",
      "Iter 4232 | Time 30.2391(30.9388) | Bit/dim 1.1050(1.1036) | Xent 0.0503(0.0481) | Loss 1.1302(1.1276) | Error 0.0160(0.0148) Steps 428(427.99) | Grad Norm 0.8459(0.4193) | Total Time 10.00(10.00)\n",
      "Iter 4233 | Time 30.6799(30.9310) | Bit/dim 1.1033(1.1036) | Xent 0.0455(0.0480) | Loss 1.1260(1.1276) | Error 0.0136(0.0147) Steps 428(427.99) | Grad Norm 0.4865(0.4213) | Total Time 10.00(10.00)\n",
      "Iter 4234 | Time 30.4510(30.9166) | Bit/dim 1.1007(1.1035) | Xent 0.0512(0.0481) | Loss 1.1263(1.1275) | Error 0.0150(0.0148) Steps 428(427.99) | Grad Norm 0.5802(0.4261) | Total Time 10.00(10.00)\n",
      "Iter 4235 | Time 30.7609(30.9119) | Bit/dim 1.1018(1.1034) | Xent 0.0482(0.0481) | Loss 1.1259(1.1275) | Error 0.0154(0.0148) Steps 428(427.99) | Grad Norm 0.6190(0.4319) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0605 | Time 16.8053, Epoch Time 244.3117(245.7092), Bit/dim 1.0974(best: 1.0975), Xent 0.0320, Loss 1.1134, Error 0.0101(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4236 | Time 30.6424(30.9038) | Bit/dim 1.1007(1.1034) | Xent 0.0497(0.0482) | Loss 1.1256(1.1274) | Error 0.0151(0.0148) Steps 428(427.99) | Grad Norm 0.1759(0.4242) | Total Time 10.00(10.00)\n",
      "Iter 4237 | Time 31.5801(30.9241) | Bit/dim 1.1030(1.1033) | Xent 0.0451(0.0481) | Loss 1.1256(1.1274) | Error 0.0135(0.0147) Steps 428(427.99) | Grad Norm 0.4174(0.4240) | Total Time 10.00(10.00)\n",
      "Iter 4238 | Time 31.8884(30.9531) | Bit/dim 1.1062(1.1034) | Xent 0.0448(0.0480) | Loss 1.1286(1.1274) | Error 0.0136(0.0147) Steps 428(427.99) | Grad Norm 0.3042(0.4204) | Total Time 10.00(10.00)\n",
      "Iter 4239 | Time 31.9337(30.9825) | Bit/dim 1.1044(1.1035) | Xent 0.0520(0.0481) | Loss 1.1304(1.1275) | Error 0.0160(0.0147) Steps 428(427.99) | Grad Norm 0.2426(0.4151) | Total Time 10.00(10.00)\n",
      "Iter 4240 | Time 30.9874(30.9826) | Bit/dim 1.1032(1.1034) | Xent 0.0454(0.0480) | Loss 1.1259(1.1275) | Error 0.0131(0.0147) Steps 428(427.99) | Grad Norm 0.7658(0.4256) | Total Time 10.00(10.00)\n",
      "Iter 4241 | Time 31.3764(30.9944) | Bit/dim 1.1015(1.1034) | Xent 0.0443(0.0479) | Loss 1.1236(1.1273) | Error 0.0125(0.0146) Steps 428(427.99) | Grad Norm 0.1936(0.4186) | Total Time 10.00(10.00)\n",
      "Iter 4242 | Time 31.3311(31.0045) | Bit/dim 1.1033(1.1034) | Xent 0.0557(0.0481) | Loss 1.1311(1.1275) | Error 0.0162(0.0147) Steps 422(427.81) | Grad Norm 0.2784(0.4144) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0606 | Time 16.9157, Epoch Time 248.8768(245.8042), Bit/dim 1.0976(best: 1.0974), Xent 0.0313, Loss 1.1132, Error 0.0099(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4243 | Time 30.8522(31.0000) | Bit/dim 1.1017(1.1033) | Xent 0.0494(0.0482) | Loss 1.1264(1.1274) | Error 0.0155(0.0147) Steps 428(427.82) | Grad Norm 0.2991(0.4110) | Total Time 10.00(10.00)\n",
      "Iter 4244 | Time 30.9362(30.9981) | Bit/dim 1.1022(1.1033) | Xent 0.0416(0.0480) | Loss 1.1230(1.1273) | Error 0.0138(0.0147) Steps 428(427.82) | Grad Norm 0.1829(0.4041) | Total Time 10.00(10.00)\n",
      "Iter 4245 | Time 31.2647(31.0061) | Bit/dim 1.1007(1.1032) | Xent 0.0503(0.0481) | Loss 1.1258(1.1273) | Error 0.0149(0.0147) Steps 428(427.83) | Grad Norm 0.1595(0.3968) | Total Time 10.00(10.00)\n",
      "Iter 4246 | Time 30.3974(30.9878) | Bit/dim 1.1032(1.1032) | Xent 0.0479(0.0481) | Loss 1.1272(1.1273) | Error 0.0145(0.0147) Steps 428(427.83) | Grad Norm 0.3665(0.3959) | Total Time 10.00(10.00)\n",
      "Iter 4247 | Time 30.9275(30.9860) | Bit/dim 1.1070(1.1033) | Xent 0.0501(0.0481) | Loss 1.1321(1.1274) | Error 0.0156(0.0147) Steps 428(427.84) | Grad Norm 0.2251(0.3908) | Total Time 10.00(10.00)\n",
      "Iter 4248 | Time 30.4719(30.9706) | Bit/dim 1.0998(1.1032) | Xent 0.0501(0.0482) | Loss 1.1249(1.1273) | Error 0.0152(0.0147) Steps 428(427.84) | Grad Norm 0.2732(0.3872) | Total Time 10.00(10.00)\n",
      "Iter 4249 | Time 30.9736(30.9707) | Bit/dim 1.1049(1.1033) | Xent 0.0538(0.0483) | Loss 1.1318(1.1275) | Error 0.0161(0.0148) Steps 428(427.85) | Grad Norm 0.2875(0.3842) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0607 | Time 16.8501, Epoch Time 244.8435(245.7754), Bit/dim 1.0971(best: 1.0974), Xent 0.0340, Loss 1.1141, Error 0.0110(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4250 | Time 31.9860(31.0011) | Bit/dim 1.1055(1.1034) | Xent 0.0529(0.0485) | Loss 1.1319(1.1276) | Error 0.0155(0.0148) Steps 428(427.85) | Grad Norm 0.2554(0.3804) | Total Time 10.00(10.00)\n",
      "Iter 4251 | Time 30.4801(30.9855) | Bit/dim 1.1026(1.1033) | Xent 0.0538(0.0486) | Loss 1.1295(1.1276) | Error 0.0161(0.0148) Steps 428(427.86) | Grad Norm 0.2171(0.3755) | Total Time 10.00(10.00)\n",
      "Iter 4252 | Time 30.2007(30.9619) | Bit/dim 1.1004(1.1032) | Xent 0.0426(0.0485) | Loss 1.1218(1.1275) | Error 0.0135(0.0148) Steps 428(427.86) | Grad Norm 0.2547(0.3719) | Total Time 10.00(10.00)\n",
      "Iter 4253 | Time 30.3581(30.9438) | Bit/dim 1.1015(1.1032) | Xent 0.0489(0.0485) | Loss 1.1259(1.1274) | Error 0.0142(0.0148) Steps 428(427.87) | Grad Norm 0.2801(0.3691) | Total Time 10.00(10.00)\n",
      "Iter 4254 | Time 30.7309(30.9374) | Bit/dim 1.1064(1.1033) | Xent 0.0443(0.0483) | Loss 1.1285(1.1275) | Error 0.0140(0.0147) Steps 428(427.87) | Grad Norm 0.2289(0.3649) | Total Time 10.00(10.00)\n",
      "Iter 4255 | Time 30.8462(30.9347) | Bit/dim 1.1022(1.1033) | Xent 0.0470(0.0483) | Loss 1.1257(1.1274) | Error 0.0142(0.0147) Steps 428(427.87) | Grad Norm 0.3099(0.3632) | Total Time 10.00(10.00)\n",
      "Iter 4256 | Time 30.8324(30.9316) | Bit/dim 1.1056(1.1033) | Xent 0.0502(0.0484) | Loss 1.1307(1.1275) | Error 0.0149(0.0147) Steps 428(427.88) | Grad Norm 0.2207(0.3590) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0608 | Time 16.8142, Epoch Time 244.7317(245.7441), Bit/dim 1.0976(best: 1.0971), Xent 0.0323, Loss 1.1137, Error 0.0097(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4257 | Time 30.5608(30.9205) | Bit/dim 1.1019(1.1033) | Xent 0.0504(0.0484) | Loss 1.1271(1.1275) | Error 0.0159(0.0148) Steps 428(427.88) | Grad Norm 0.6209(0.3668) | Total Time 10.00(10.00)\n",
      "Iter 4258 | Time 30.8334(30.9179) | Bit/dim 1.1073(1.1034) | Xent 0.0425(0.0482) | Loss 1.1285(1.1275) | Error 0.0136(0.0147) Steps 428(427.89) | Grad Norm 0.1965(0.3617) | Total Time 10.00(10.00)\n",
      "Iter 4259 | Time 31.0595(30.9221) | Bit/dim 1.1038(1.1034) | Xent 0.0403(0.0480) | Loss 1.1239(1.1274) | Error 0.0131(0.0147) Steps 428(427.89) | Grad Norm 0.3289(0.3607) | Total Time 10.00(10.00)\n",
      "Iter 4260 | Time 30.4996(30.9095) | Bit/dim 1.1071(1.1035) | Xent 0.0485(0.0480) | Loss 1.1313(1.1275) | Error 0.0149(0.0147) Steps 428(427.89) | Grad Norm 0.6084(0.3682) | Total Time 10.00(10.00)\n",
      "Iter 4261 | Time 30.8152(30.9066) | Bit/dim 1.1012(1.1035) | Xent 0.0529(0.0482) | Loss 1.1277(1.1275) | Error 0.0168(0.0148) Steps 428(427.90) | Grad Norm 0.2588(0.3649) | Total Time 10.00(10.00)\n",
      "Iter 4262 | Time 30.1963(30.8853) | Bit/dim 1.1012(1.1034) | Xent 0.0487(0.0482) | Loss 1.1255(1.1275) | Error 0.0155(0.0148) Steps 428(427.90) | Grad Norm 0.7441(0.3763) | Total Time 10.00(10.00)\n",
      "Iter 4263 | Time 30.4296(30.8717) | Bit/dim 1.0995(1.1033) | Xent 0.0489(0.0482) | Loss 1.1240(1.1274) | Error 0.0142(0.0148) Steps 428(427.90) | Grad Norm 0.3222(0.3746) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0609 | Time 17.0175, Epoch Time 243.8609(245.6876), Bit/dim 1.0975(best: 1.0971), Xent 0.0322, Loss 1.1136, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4264 | Time 30.7083(30.8668) | Bit/dim 1.1022(1.1032) | Xent 0.0471(0.0482) | Loss 1.1257(1.1273) | Error 0.0141(0.0147) Steps 428(427.90) | Grad Norm 0.4593(0.3772) | Total Time 10.00(10.00)\n",
      "Iter 4265 | Time 30.7275(30.8626) | Bit/dim 1.0988(1.1031) | Xent 0.0523(0.0483) | Loss 1.1249(1.1273) | Error 0.0156(0.0148) Steps 428(427.91) | Grad Norm 0.4594(0.3796) | Total Time 10.00(10.00)\n",
      "Iter 4266 | Time 31.1452(30.8711) | Bit/dim 1.1063(1.1032) | Xent 0.0497(0.0483) | Loss 1.1312(1.1274) | Error 0.0164(0.0148) Steps 428(427.91) | Grad Norm 0.1886(0.3739) | Total Time 10.00(10.00)\n",
      "Iter 4267 | Time 31.9811(30.9044) | Bit/dim 1.1024(1.1032) | Xent 0.0481(0.0483) | Loss 1.1264(1.1273) | Error 0.0149(0.0148) Steps 428(427.91) | Grad Norm 0.6407(0.3819) | Total Time 10.00(10.00)\n",
      "Iter 4268 | Time 31.5747(30.9245) | Bit/dim 1.1028(1.1032) | Xent 0.0504(0.0484) | Loss 1.1280(1.1274) | Error 0.0152(0.0148) Steps 428(427.92) | Grad Norm 0.2949(0.3793) | Total Time 10.00(10.00)\n",
      "Iter 4269 | Time 30.9322(30.9247) | Bit/dim 1.1001(1.1031) | Xent 0.0491(0.0484) | Loss 1.1246(1.1273) | Error 0.0152(0.0148) Steps 428(427.92) | Grad Norm 0.3041(0.3770) | Total Time 10.00(10.00)\n",
      "Iter 4270 | Time 29.8714(30.8931) | Bit/dim 1.1070(1.1032) | Xent 0.0505(0.0485) | Loss 1.1323(1.1274) | Error 0.0154(0.0149) Steps 422(427.74) | Grad Norm 0.4306(0.3787) | Total Time 10.00(10.00)\n",
      "validating...\n",
      "Epoch 0610 | Time 16.8979, Epoch Time 245.9416(245.6952), Bit/dim 1.0968(best: 1.0971), Xent 0.0321, Loss 1.1128, Error 0.0102(best: 0.0087)\n",
      "===> Using batch size 8000. Total 7 iterations/epoch.\n",
      "Iter 4271 | Time 31.0261(30.8971) | Bit/dim 1.1053(1.1033) | Xent 0.0475(0.0484) | Loss 1.1291(1.1275) | Error 0.0146(0.0149) Steps 428(427.75) | Grad Norm 0.1897(0.3730) | Total Time 10.00(10.00)\n",
      "Iter 4272 | Time 30.0540(30.8718) | Bit/dim 1.1063(1.1033) | Xent 0.0499(0.0485) | Loss 1.1312(1.1276) | Error 0.0149(0.0149) Steps 428(427.76) | Grad Norm 0.2418(0.3690) | Total Time 10.00(10.00)\n",
      "Iter 4273 | Time 31.0110(30.8760) | Bit/dim 1.1052(1.1034) | Xent 0.0494(0.0485) | Loss 1.1299(1.1277) | Error 0.0158(0.0149) Steps 428(427.76) | Grad Norm 0.4679(0.3720) | Total Time 10.00(10.00)\n",
      "Iter 4274 | Time 30.5837(30.8672) | Bit/dim 1.1014(1.1033) | Xent 0.0481(0.0485) | Loss 1.1254(1.1276) | Error 0.0146(0.0149) Steps 428(427.77) | Grad Norm 0.2353(0.3679) | Total Time 10.00(10.00)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tancode/repos/tan-ffjord/train_cnf_disentangle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mloss_nll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_xent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_bits_per_dim_conditional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"semisup\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mloss_nll\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_y\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_xent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tancode/repos/tan-ffjord/train_cnf_disentangle.py\u001b[0m in \u001b[0;36mcompute_bits_per_dim_conditional\u001b[0;34m(x, y, model)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;31m#     model = model.module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_logp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run model forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mdim_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondition_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         1368410603 function calls (1354599947 primitive calls) in 62467.311 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "     1719 35078.045   20.406 35078.045   20.406 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
       "   228430 23418.162    0.103 23418.162    0.103 {method 'acquire' of '_thread.lock' objects}\n",
       " 16210000  509.096    0.000  732.101    0.000 train_cnf_disentangle.py:130(add_noise)\n",
       " 16210000  319.577    0.000 1358.774    0.000 functional.py:32(to_tensor)\n",
       " 16210000  253.105    0.000  253.105    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
       " 16210000  226.146    0.000 3365.738    0.000 mnist.py:59(__getitem__)\n",
       " 16210084  142.228    0.000  142.228    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
       " 16210490  126.429    0.000  730.820    0.000 Image.py:2457(fromarray)\n",
       " 16210000  126.315    0.000  126.315    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
       "   164647  114.541    0.001  114.541    0.001 {method '_write_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
       " 16210000  114.428    0.000  365.188    0.000 Image.py:711(tobytes)\n",
       " 32420000  100.774    0.000  100.774    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
       "192390574/192386021   96.514    0.000   96.642    0.000 {built-in method builtins.isinstance}\n",
       " 16210490   86.170    0.000  322.032    0.000 Image.py:2322(new)\n",
       " 16210490   83.503    0.000  586.157    0.000 Image.py:2396(frombuffer)\n",
       " 16214663   83.075    0.000   83.075    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
       " 16210000   80.970    0.000 2322.988    0.000 transforms.py:47(__call__)\n",
       " 32420735   77.481    0.000  126.747    0.000 Image.py:553(_new)\n",
       " 16210490   69.860    0.000  111.202    0.000 Image.py:451(_getencoder)\n",
       "48678724/48678710   55.522    0.000   55.540    0.000 {built-in method builtins.hasattr}\n",
       " 32421470   55.150    0.000   84.401    0.000 Image.py:2304(_check_size)\n",
       " 48631225   55.001    0.000   55.001    0.000 Image.py:529(__init__)\n",
       "     4420   54.827    0.012   54.827    0.012 {built-in method stack}\n",
       " 48631225   54.568    0.000  110.003    0.000 Image.py:601(__del__)\n",
       " 16210000   52.211    0.000   97.481    0.000 functional.py:172(resize)\n",
       " 16210490   51.431    0.000   51.431    0.000 {built-in method PIL._imaging.fill}\n",
       "114850401/114847640   48.976    0.000   48.987    0.000 {built-in method builtins.len}\n",
       " 16210245   48.769    0.000   48.769    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
       " 16210000   44.416    0.000   44.416    0.000 {built-in method PIL._imaging.map_buffer}\n",
       " 16210000   43.991    0.000   43.991    0.000 {method 'resize_as_' of 'torch._C._TensorBase' objects}\n",
       " 12286738   43.606    0.000   67.484    0.000 module.py:537(__setattr__)\n",
       " 16210439   36.796    0.000   36.796    0.000 {method 'new' of 'torch._C._TensorBase' objects}\n",
       " 16244071   35.441    0.000   35.441    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
       " 16210000   33.726    0.000   33.726    0.000 {built-in method from_buffer}\n",
       " 32420000   32.242    0.000   45.506    0.000 functional.py:17(_is_pil_image)\n",
       " 16210000   29.470    0.000 1388.244    0.000 transforms.py:68(__call__)\n",
       "     2210   28.009    0.013 3393.747    1.536 dataloader.py:615(<listcomp>)\n",
       " 64842205   27.900    0.000   27.900    0.000 Image.py:549(size)\n",
       " 16210000   24.192    0.000  121.673    0.000 transforms.py:167(__call__)\n",
       " 16211225   24.033    0.000   34.732    0.000 Image.py:809(load)\n",
       " 53095183   22.653    0.000   22.653    0.000 {method 'get' of 'dict' objects}\n",
       "     2455   20.256    0.008  126.065    0.051 replicate.py:5(replicate)\n",
       " 16210000   19.180    0.000   19.180    0.000 {built-in method PIL._imaging.raw_encoder}\n",
       " 35464937   18.324    0.000   18.324    0.000 {method 'copy' of 'dict' objects}\n",
       "     2701   17.899    0.007   32.147    0.012 sampler.py:158(__iter__)\n",
       "    23765   17.760    0.001   17.760    0.001 {method 'sort' of 'numpy.ndarray' objects}\n",
       " 16236653   16.820    0.000   16.820    0.000 {built-in method builtins.max}\n",
       " 36520591   16.242    0.000   16.242    0.000 {method 'append' of 'list' objects}\n",
       "     4665   16.095    0.003   16.095    0.003 {built-in method torch._C._scatter}\n",
       " 16210735   15.029    0.000   22.295    0.000 _util.py:7(isStringType)\n",
       " 16397833   14.934    0.000   14.934    0.000 {built-in method builtins.getattr}\n",
       "     2700   14.633    0.005 3516.282    1.302 dataloader.py:612(__next__)\n",
       "14483656/1457756   13.430    0.000   15.067    0.000 module.py:938(named_modules)\n",
       " 16210490   11.939    0.000   11.939    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
       "     3440   11.810    0.003   11.810    0.003 {method 'pin_memory' of 'torch._C._TensorBase' objects}\n",
       "     4910   11.643    0.002   11.643    0.002 {built-in method torch._C._broadcast_coalesced}\n",
       "    23765   11.269    0.000   45.266    0.002 summary.py:150(make_histogram)\n",
       " 16211225   10.698    0.000   10.698    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
       " 16210000    8.795    0.000    8.795    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
       "        1    8.519    8.519 62467.251 62467.251 train_cnf_disentangle.py:1(<module>)\n",
       "  4475581    8.444    0.000   14.582    0.000 serialization.py:234(persistent_id)\n",
       "6630/2210    8.039    0.001   63.834    0.029 dataloader.py:196(default_collate)\n",
       " 16210736    7.559    0.000    7.559    0.000 {method 'join' of 'bytes' objects}\n",
       "    11634    7.313    0.001    7.333    0.001 {method 'to' of 'torch._C._TensorBase' objects}\n",
       "   166743    7.241    0.000    7.241    0.000 {built-in method norm}\n",
       "      993    7.212    0.007    7.212    0.007 {built-in method io.open}\n",
       "   175567    6.191    0.000    6.191    0.000 {built-in method numpy.core.multiarray.array}\n",
       "   333486    5.941    0.000    5.941    0.000 {method 'mul_' of 'torch._C._TensorBase' objects}\n",
       "  9132607    5.257    0.000    5.257    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
       "   333486    5.096    0.000    5.096    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
       "     2460    4.995    0.002    4.995    0.002 {method 'flush' of '_io.TextIOWrapper' objects}\n",
       "    31862    4.970    0.000    4.970    0.000 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
       "   193019    4.141    0.000    4.141    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
       "      547    3.610    0.007   19.832    0.036 {method 'dump' of '_pickle.Pickler' objects}\n",
       "    23766    3.458    0.000    3.458    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
       "    11292    3.397    0.000 23025.381    2.039 module.py:483(__call__)\n",
       "     1719    3.260    0.002   21.663    0.013 adam.py:49(step)\n",
       "    25975    3.158    0.000    3.158    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
       "  4475581    2.716    0.000    2.716    0.000 __init__.py:128(is_storage)\n",
       "      547    2.563    0.005  140.009    0.256 serialization.py:221(_save)\n",
       "   166743    2.465    0.000    2.465    0.000 {method 'sqrt' of 'torch._C._TensorBase' objects}\n",
       "   166743    2.291    0.000    2.291    0.000 {method 'addcdiv_' of 'torch._C._TensorBase' objects}\n",
       "   460361    2.142    0.000   16.815    0.000 module.py:771(_named_members)\n",
       "   166743    2.140    0.000    2.140    0.000 {method 'addcmul_' of 'torch._C._TensorBase' objects}\n",
       "    23765    2.089    0.000   48.118    0.002 summary.py:126(histogram)\n",
       "   100215    1.943    0.000    1.943    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "  2567601    1.821    0.000    2.345    0.000 {method 'add' of 'set' objects}\n",
       "  4609787    1.710    0.000    1.710    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
       "      570    1.679    0.003    1.679    0.003 {method 'flush' of '_io.BufferedWriter' objects}\n",
       "567434/3439    1.675    0.000    6.865    0.002 module.py:203(apply)\n",
       "  1293297    1.646    0.000    2.154    0.000 module.py:891(named_children)\n",
       "     4663    1.587    0.000    1.587    0.000 {built-in method torch._C._gather}\n",
       "    11783    1.535    0.000   30.835    0.003 {built-in method apply}\n",
       "    12305    1.404    0.000    1.404    0.000 socket.py:334(send)\n",
       "  1599275    1.314    0.000    1.948    0.000 tensor.py:416(__hash__)\n",
       "  3046364    1.303    0.000    1.303    0.000 {built-in method __new__ of type object at 0x55f915aecd60}\n",
       "      245    1.296    0.005    4.474    0.018 summary.py:184(image)\n",
       "  1293297    1.295    0.000    3.449    0.000 module.py:882(children)\n",
       "     1719    1.189    0.001   18.054    0.011 clip_grad.py:6(clip_grad_norm_)\n",
       "    19663    1.185    0.000    1.185    0.000 {built-in method _thread.start_new_thread}\n",
       "     6155    1.163    0.000    1.163    0.000 {built-in method posix.stat}\n",
       "    43402    1.110    0.000  546.402    0.013 writer.py:82(add_summary)\n",
       "   283635    1.062    0.000    1.240    0.000 train_misc.py:81(__call__)\n",
       "   165194    1.060    0.000    1.639    0.000 tensor.py:33(__reduce_ex__)\n",
       "     2210    0.995    0.000    2.024    0.001 odenvp_conditional_tol.py:124(_prior)\n",
       "   166747    0.990    0.000    0.990    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
       "     2211    0.962    0.000    0.962    0.000 {method 'scatter_' of 'torch._C._TensorBase' objects}\n",
       "    47530    0.904    0.000    0.904    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
       "     2210    0.904    0.000   55.770    0.025 dataloader.py:232(<listcomp>)\n",
       "   687374    0.788    0.000    1.049    0.000 module.py:829(<lambda>)\n",
       "     2210    0.766    0.000 20971.680    9.489 train_cnf_disentangle.py:276(compute_bits_per_dim_conditional)\n",
       "      245    0.747    0.003    0.747    0.003 {method 'encode_to_file' of 'ImagingEncoder' objects}\n",
       "100648/547    0.689    0.000    0.860    0.002 module.py:602(state_dict)\n",
       "  1707996    0.680    0.000    0.680    0.000 {built-in method builtins.id}\n",
       "    26465    0.637    0.000    0.637    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "        1    0.625    0.625    0.625    0.625 {built-in method caffe2.python.caffe2_pybind11_state_gpu.num_cuda_devices}\n",
       "    23765    0.606    0.000   28.322    0.001 histograms.py:597(histogram)\n",
       "      245    0.570    0.002    0.570    0.002 {method 'tobytes' of 'numpy.ndarray' objects}\n",
       "      246    0.548    0.002    0.548    0.002 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
       "   165197    0.535    0.000    0.535    0.000 serialization.py:149(_is_compressed_file)\n",
       "     4419    0.534    0.000    0.534    0.000 {built-in method addmm}\n",
       "     2209    0.508    0.000    0.508    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
       "    43402    0.502    0.000  544.775    0.013 queue.py:115(put)\n",
       "     2209    0.455    0.000    0.498    0.000 modules.py:268(likelihood)\n",
       "    37657    0.445    0.000  561.440    0.015 threading.py:263(wait)\n",
       "    23805    0.434    0.000    0.434    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "    23765    0.427    0.000    7.262    0.000 histograms.py:297(_get_bin_edges)\n",
       "   166743    0.421    0.000    7.747    0.000 functional.py:607(norm)\n",
       "   433356    0.397    0.000   12.678    0.000 module.py:808(named_parameters)\n",
       "   165197    0.375    0.000    1.054    0.000 serialization.py:157(_should_read_directly)\n",
       "     1720    0.370    0.000    1.475    0.001 optimizer.py:157(zero_grad)\n",
       "   380525    0.365    0.000    0.499    0.000 module.py:877(<lambda>)\n",
       "    17182    0.360    0.000    2.163    0.000 summary.py:105(scalar)\n",
       "   409346    0.355    0.000   11.906    0.000 module.py:784(parameters)\n",
       "   165194    0.354    0.000    0.843    0.000 serialization.py:102(location_tag)\n",
       "      126    0.349    0.003    0.349    0.003 {method 'read' of '_io.BufferedReader' objects}\n",
       "    23765    0.341    0.000    0.420    0.000 function_base.py:1079(diff)\n",
       "     4419    0.339    0.000    1.112    0.000 modules.py:105(forward)\n",
       "    24010    0.338    0.000    0.338    0.000 {built-in method numpy.core.multiarray.zeros}\n",
       "    47530    0.331    0.000    0.331    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "    17182    0.323    0.000    5.914    0.000 writer.py:344(add_scalars)\n",
       "    23765    0.316    0.000  593.745    0.025 writer.py:390(add_histogram)\n",
       "    76970    0.312    0.000    0.312    0.000 {method 'release' of '_thread.lock' objects}\n",
       "   382980    0.297    0.000    3.783    0.000 module.py:911(modules)\n",
       "      547    0.284    0.001    0.284    0.001 {method '_write_file' of 'torch._C.FloatStorageBase' objects}\n",
       "      246    0.281    0.001    0.281    0.001 {built-in method randperm}\n",
       "81015/491    0.279    0.000    1.291    0.003 module.py:976(train)\n",
       "   164647    0.279    0.000    0.362    0.000 serialization.py:57(_cuda_tag)\n",
       "   283635    0.269    0.000    0.966    0.000 train_misc.py:61(__call__)\n",
       "   166743    0.265    0.000    8.012    0.000 tensor.py:250(norm)\n",
       "    43402    0.262    0.000  545.210    0.013 writer.py:137(_add_event)\n",
       "    24607    0.259    0.000    0.259    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}\n",
       "    13997    0.253    0.000    0.253    0.000 utils.py:74(update)\n",
       "     2210    0.247    0.000    0.266    0.000 summary.py:380(text)\n",
       "    43402    0.226    0.000    0.619    0.000 threading.py:334(notify)\n",
       "      302    0.224    0.001    0.224    0.001 {method '_set_from_file' of 'torch._C.FloatStorageBase' objects}\n",
       "    47530    0.221    0.000    4.364    0.000 fromnumeric.py:2651(ndim)\n",
       "    17182    0.204    0.000    1.783    0.000 writer.py:303(__append_to_scalar_dict)\n",
       "    58374    0.202    0.000    3.253    0.000 x2num.py:10(make_np)\n",
       "     4424    0.199    0.000    0.199    0.000 {built-in method zeros}\n",
       "   219553    0.196    0.000    0.196    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
       "   165194    0.194    0.000    0.276    0.000 serialization.py:121(normalize_storage_type)\n",
       "     2455    0.189    0.000 22875.453    9.318 parallel_apply.py:21(parallel_apply)\n",
       "    22125    0.189    0.000   18.550    0.001 threading.py:533(wait)\n",
       "   126966    0.188    0.000    0.193    0.000 module.py:521(__getattr__)\n",
       "    27/24    0.172    0.006    0.179    0.007 {built-in method _imp.create_dynamic}\n",
       "339809/338591    0.168    0.000    0.179    0.000 {built-in method builtins.issubclass}\n",
       "   101138    0.165    0.000    0.258    0.000 _utils.py:5(_get_device_index)\n",
       "    23765    0.165    0.000    0.165    0.000 {built-in method numpy.core.multiarray.concatenate}\n",
       "   166743    0.164    0.000    0.164    0.000 clip_grad.py:24(<lambda>)\n",
       "    26466    0.159    0.000    0.603    0.000 fromnumeric.py:64(_wrapreduction)\n",
       "      547    0.158    0.000  140.166    0.256 serialization.py:218(<lambda>)\n",
       "    41520    0.157    0.000    0.157    0.000 {method 'sub' of '_sre.SRE_Pattern' objects}\n",
       "    19663    0.156    0.000   16.954    0.001 threading.py:828(start)\n",
       "     2455    0.154    0.000    0.405    0.000 replicate.py:12(<dictcomp>)\n",
       "     6629    0.149    0.000    0.149    0.000 {built-in method exp}\n",
       "   165388    0.145    0.000    0.145    0.000 {method 'storage' of 'torch._C._TensorBase' objects}\n",
       "   165194    0.144    0.000    0.144    0.000 {method 'fileno' of '_io.BufferedWriter' objects}\n",
       "    81059    0.140    0.000    0.245    0.000 threading.py:254(_is_owned)\n",
       "    19663    0.137    0.000    0.382    0.000 threading.py:757(__init__)\n",
       "5144/5140    0.135    0.000    0.222    0.000 {built-in method builtins.__build_class__}\n",
       "    23765    0.135    0.000    1.204    0.000 histograms.py:391(_search_sorted_inclusive)\n",
       "    34400    0.134    0.000 22857.640    0.664 threading.py:1062(_wait_for_tstate_lock)\n",
       "    43402    0.133    0.000  544.908    0.013 event_file_writer.py:131(add_event)\n",
       "    95060    0.131    0.000    6.170    0.000 numeric.py:433(asarray)\n",
       "      245    0.130    0.001    0.537    0.002 utils.py:6(make_grid)\n",
       "    65527    0.129    0.000    0.198    0.000 threading.py:239(__enter__)\n",
       "     4419    0.129    0.000    0.129    0.000 {built-in method sum}\n",
       "   165194    0.127    0.000    0.127    0.000 serialization.py:52(_cpu_tag)\n",
       "     2460    0.126    0.000    0.255    0.000 __init__.py:251(__init__)\n",
       "    49000    0.125    0.000    0.125    0.000 {method 'narrow' of 'torch._C._TensorBase' objects}\n",
       "      245    0.124    0.001    0.209    0.001 utils.py:70(make_grid)\n",
       "    11998    0.123    0.000    0.274    0.000 {built-in method builtins.all}\n",
       "    41192    0.120    0.000    0.324    0.000 summary.py:64(_clean_tag)\n",
       "   240590    0.119    0.000    0.119    0.000 _functions.py:13(<genexpr>)\n",
       "     4663    0.118    0.000    1.941    0.000 _functions.py:52(forward)\n",
       "   166743    0.116    0.000    0.116    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}\n",
       "    19633    0.114    0.000 22857.782    1.164 threading.py:1024(join)\n",
       "     4418    0.112    0.000    0.112    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
       "     2209    0.108    0.000    0.260    0.000 train_misc.py:10(standard_normal_logprob)\n",
       "    12305    0.107    0.000    1.651    0.000 iostream.py:195(schedule)\n",
       "   165194    0.107    0.000    0.107    0.000 hooks.py:51(warn_if_has_hooks)\n",
       "    23765    0.106    0.000    0.204    0.000 histograms.py:220(_ravel_and_check_weights)\n",
       "   165388    0.105    0.000    0.105    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
       "    23765    0.104    0.000    0.104    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "    22194    0.103    0.000    0.103    0.000 threading.py:215(__init__)\n",
       "    65527    0.102    0.000    0.144    0.000 threading.py:242(__exit__)\n",
       "    23765    0.102    0.000   18.352    0.001 fromnumeric.py:760(sort)\n",
       "      695    0.101    0.000    0.124    0.000 <frozen importlib._bootstrap_external>:830(get_data)\n",
       "   166953    0.100    0.000    0.100    0.000 {built-in method math.sqrt}\n",
       "   183515    0.098    0.000    0.098    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
       "     2209    0.094    0.000    0.094    0.000 {built-in method torch._C._nn.nll_loss}\n",
       "    58951    0.094    0.000    0.137    0.000 queue.py:202(_qsize)\n",
       "     2455    0.092    0.000 22875.592    9.318 data_parallel.py:152(parallel_apply)\n",
       "     2455    0.091    0.000   11.035    0.004 _functions.py:11(forward)\n",
       "    41192    0.091    0.000    0.142    0.000 writer.py:314(_check_caffe2)\n",
       "     6852    0.091    0.000    0.435    0.000 {method 'format' of 'str' objects}\n",
       "   165388    0.089    0.000    0.089    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
       "      491    0.089    0.000    0.089    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
       "     2455    0.089    0.000    0.089    0.000 _functions.py:28(<listcomp>)\n",
       "   164647    0.084    0.000    0.084    0.000 {method 'get_device' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "   164647    0.084    0.000    0.084    0.000 {method 'size' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "     2209    0.082    0.000    0.082    0.000 {built-in method rsub}\n",
       "    34609    0.080    0.000    0.165    0.000 numeric.py:1927(isscalar)\n",
       "    37657    0.079    0.000    0.125    0.000 threading.py:251(_acquire_restore)\n",
       "    64996    0.078    0.000    0.078    0.000 {built-in method _thread.allocate_lock}\n",
       "    41756    0.077    0.000    0.105    0.000 threading.py:1230(current_thread)\n",
       "     2209    0.075    0.000    0.075    0.000 {built-in method dropout}\n",
       "    12521    0.074    0.000    0.122    0.000 abc.py:180(__instancecheck__)\n",
       "    50573    0.074    0.000    0.074    0.000 {built-in method time.time}\n",
       "      547    0.074    0.000    0.074    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
       "     2209    0.071    0.000    0.071    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}\n",
       "     4665    0.070    0.000   16.324    0.003 _functions.py:80(forward)\n",
       "    65527    0.069    0.000    0.069    0.000 {method '__enter__' of '_thread.lock' objects}\n",
       "    17190    0.069    0.000    0.552    0.000 cnf.py:88(num_evals)\n",
       "    23765    0.069    0.000    0.495    0.000 fromnumeric.py:1933(any)\n",
       "    49984    0.068    0.000    0.124    0.000 numeric.py:504(asanyarray)\n",
       "    93364    0.068    0.000    0.068    0.000 {method 'append' of 'collections.deque' objects}\n",
       "     4920    0.067    0.000    1.515    0.000 iostream.py:382(write)\n",
       "     4920    0.064    0.000   10.145    0.002 __init__.py:982(emit)\n",
       "    23765    0.064    0.000    0.963    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "    43402    0.064    0.000    0.095    0.000 queue.py:206(_put)\n",
       "8100/2700    0.063    0.000   16.493    0.006 scatter_gather.py:11(scatter_map)\n",
       "    22125    0.063    0.000    0.184    0.000 threading.py:498(__init__)\n",
       "      547    0.060    0.000    0.106    0.000 optimizer.py:88(<dictcomp>)\n",
       "    14767    0.060    0.000    0.123    0.000 threading.py:1104(is_alive)\n",
       "   123580    0.060    0.000    0.060    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
       "     2455    0.060    0.000 23020.462    9.377 data_parallel.py:136(forward)\n",
       "6872/2454    0.058    0.000    2.114    0.001 scatter_gather.py:51(gather_map)\n",
       "     4173    0.057    0.000    2.738    0.001 x2num.py:27(prepare_pytorch)\n",
       "      695    0.057    0.000    0.057    0.000 {built-in method marshal.loads}\n",
       "     2454    0.054    0.000    0.143    0.000 _methods.py:58(_mean)\n",
       "     2209    0.054    0.000    0.054    0.000 {method 'pow' of 'torch._C._TensorBase' objects}\n",
       "     4920    0.053    0.000    8.403    0.002 __init__.py:971(flush)\n",
       "    21413    0.050    0.000    0.075    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "     2460    0.049    0.000    0.092    0.000 __init__.py:1376(findCaller)\n",
       "    37657    0.049    0.000    0.073    0.000 threading.py:248(_release_save)\n",
       "    23765    0.048    0.000    0.899    0.000 _methods.py:30(_amin)\n",
       "    41670    0.048    0.000    0.048    0.000 {method 'lstrip' of 'str' objects}\n",
       "    19632    0.046    0.000    0.057    0.000 threading.py:966(_stop)\n",
       "     2455    0.045    0.000    0.426    0.000 parallel_apply.py:67(<listcomp>)\n",
       "    54086    0.044    0.000    0.044    0.000 threading.py:506(is_set)\n",
       "     2462    0.044    0.000    3.316    0.001 iostream.py:334(flush)\n",
       "     2783    0.044    0.000    0.097    0.000 {built-in method builtins.sorted}\n",
       "     4419    0.044    0.000    0.044    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
       "    17190    0.044    0.000    0.089    0.000 cnf_regularization.py:30(_num_evals)\n",
       "    21668    0.044    0.000    0.044    0.000 _weakrefset.py:70(__contains__)\n",
       "    37320    0.043    0.000    0.136    0.000 _functions.py:82(<lambda>)\n",
       "    23765    0.043    0.000    0.343    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "     2210    0.042    0.000    0.047    0.000 thops.py:47(split_feature)\n",
       "    65527    0.042    0.000    0.042    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "22810/21021    0.042    0.000    1.556    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
       "    23765    0.040    0.000    0.430    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "     4419    0.040    0.000    0.625    0.000 functional.py:1335(linear)\n",
       "     4920    0.039    0.000   10.245    0.002 __init__.py:852(handle)\n",
       "     2210    0.039    0.000    0.484    0.000 writer.py:523(add_text)\n",
       "      245    0.038    0.000    0.038    0.000 {method 'close' of '_io.BufferedRandom' objects}\n",
       "5160/1720    0.038    0.000   11.910    0.007 dataloader.py:237(pin_memory_batch)\n",
       "     2460    0.038    0.000   10.283    0.004 __init__.py:1500(callHandlers)\n",
       "    37304    0.037    0.000    0.062    0.000 _functions.py:58(<lambda>)\n",
       "     4920    0.037    0.000    0.132    0.000 __init__.py:564(format)\n",
       "    37304    0.036    0.000    0.069    0.000 _functions.py:67(<lambda>)\n",
       "     2455    0.036    0.000  126.101    0.051 data_parallel.py:146(replicate)\n",
       "     1720    0.035    0.000    0.035    0.000 {built-in method ones_like}\n",
       "    11292    0.035    0.000    0.035    0.000 {built-in method torch._C._get_tracing_state}\n",
       "        2    0.034    0.017    0.034    0.017 {method '_set_from_file' of 'torch._C.ByteStorageBase' objects}\n",
       "      490    0.034    0.000    0.034    0.000 {method 'decode' of 'ImagingDecoder' objects}\n",
       "    17183    0.033    0.000    0.045    0.000 writer.py:204(get_logdir)\n",
       "     2455    0.033    0.000   16.555    0.007 scatter_gather.py:33(scatter_kwargs)\n",
       "     2371    0.033    0.000    0.186    0.000 module.py:62(__init__)\n",
       "     2211    0.033    0.000    1.153    0.001 thops.py:4(onehot)\n",
       "    23765    0.033    0.000    0.390    0.000 _methods.py:26(_amax)\n",
       "      491    0.033    0.000    0.172    0.000 dataloader.py:518(__init__)\n",
       "    48188    0.033    0.000    0.033    0.000 {built-in method _thread.get_ident}\n",
       "    19632    0.033    0.000    0.046    0.000 _weakrefset.py:38(_remove)\n",
       "    46633    0.033    0.000    0.033    0.000 {method 'get_device' of 'torch._C._TensorBase' objects}\n",
       "    20181    0.032    0.000    0.045    0.000 _weakrefset.py:81(add)\n",
       "     1720    0.032    0.000    0.041    0.000 train_cnf_disentangle.py:141(update_lr)\n",
       "        3    0.030    0.010    0.091    0.030 utils.py:70(parse_header)\n",
       "     2209    0.030    0.000    0.646    0.000 modules.py:277(logp)\n",
       "    23765    0.030    0.000    0.301    0.000 _methods.py:34(_sum)\n",
       "    45772    0.030    0.000    0.030    0.000 {method 'items' of 'dict' objects}\n",
       "      547    0.030    0.000    0.053    0.000 optimizer.py:84(<listcomp>)\n",
       "      823    0.030    0.000    0.030    0.000 {built-in method torch._C._cuda_isDriverSufficient}\n",
       "    27005    0.029    0.000    4.592    0.000 module.py:834(buffers)\n",
       "    27005    0.029    0.000    4.563    0.000 module.py:856(named_buffers)\n",
       "     2188    0.028    0.000    0.028    0.000 {built-in method _pickle.dump}\n",
       "     2460    0.028    0.000   10.699    0.004 __init__.py:1421(_log)\n",
       "     2209    0.028    0.000    0.575    0.000 odenvp_conditional_tol.py:155(loss_class)\n",
       "    26481    0.028    0.000    0.028    0.000 {method 'rpartition' of 'str' objects}\n",
       "     9840    0.027    0.000    0.040    0.000 __init__.py:809(acquire)\n",
       "     2460    0.027    0.000   10.749    0.004 __init__.py:1298(info)\n",
       "    23765    0.026    0.000    0.026    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "     1719    0.026    0.000 35078.150   20.406 tensor.py:74(backward)\n",
       "    19663    0.026    0.000    0.026    0.000 threading.py:727(_newname)\n",
       "     4419    0.026    0.000    0.660    0.000 linear.py:65(forward)\n",
       "     9840    0.025    0.000    0.033    0.000 __init__.py:816(release)\n",
       "    23765    0.024    0.000    0.024    0.000 {built-in method numpy.core.multiarray.normalize_axis_index}\n",
       "     2211    0.024    0.000    0.024    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}\n",
       "     2209    0.023    0.000    0.110    0.000 thops.py:15(sum)\n",
       "      695    0.023    0.000    0.023    0.000 {method 'read' of '_io.FileIO' objects}\n",
       "     2209    0.023    0.000    0.126    0.000 functional.py:1734(nll_loss)\n",
       "     2455    0.023    0.000    0.030    0.000 replicate.py:15(<listcomp>)\n",
       "    12305    0.023    0.000    0.023    0.000 iostream.py:93(_event_pipe)\n",
       "    37304    0.023    0.000    0.023    0.000 _functions.py:54(<lambda>)\n",
       "     3586    0.022    0.000    0.050    0.000 posixpath.py:121(splitext)\n",
       "     2209    0.022    0.000    0.106    0.000 functional.py:728(dropout)\n",
       "      412    0.022    0.000    0.022    0.000 {built-in method posix.listdir}\n",
       "  742/127    0.022    0.000    0.075    0.001 sre_parse.py:470(_parse)\n",
       "     3438    0.021    0.000    0.344    0.000 tensor.py:362(__format__)\n",
       "    43462    0.021    0.000    0.021    0.000 {method 'startswith' of 'str' objects}\n",
       "    34949    0.020    0.000    0.020    0.000 {method 'keys' of 'dict' objects}\n",
       "    19640    0.020    0.000    0.068    0.000 parallel_apply.py:45(<lambda>)\n",
       "     4920    0.020    0.000    0.152    0.000 __init__.py:829(format)\n",
       "    19640    0.020    0.000    0.066    0.000 replicate.py:8(<lambda>)\n",
       "     1264    0.020    0.000    0.220    0.000 <frozen importlib._bootstrap_external>:1233(find_spec)\n",
       "     4665    0.020    0.000   16.115    0.003 comm.py:131(scatter)\n",
       "     2781    0.020    0.000    0.037    0.000 posixpath.py:144(basename)\n",
       "     2455    0.019    0.000    0.047    0.000 replicate.py:19(<dictcomp>)\n",
       "      246    0.019    0.000    0.019    0.000 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
       "    19640    0.019    0.000    0.067    0.000 _functions.py:15(<lambda>)\n",
       "        1    0.019    0.019    0.019    0.019 {built-in method torch._C._cuda_init}\n",
       "     2454    0.019    0.000    0.161    0.000 fromnumeric.py:2817(mean)\n",
       "     2460    0.019    0.000   10.307    0.004 __init__.py:1446(handle)\n",
       "    17182    0.019    0.000    0.019    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
       "     4419    0.019    0.000    0.019    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
       "     4920    0.018    0.000    0.046    0.000 __init__.py:542(usesTime)\n",
       "     4920    0.018    0.000    0.018    0.000 __init__.py:390(format)\n",
       "     1719    0.018    0.000 35078.124   20.406 __init__.py:38(backward)\n",
       "     1719    0.018    0.000    0.059    0.000 __init__.py:20(_make_grads)\n",
       "     2209    0.017    0.000    0.017    0.000 {method 'squeeze_' of 'torch._C._TensorBase' objects}\n",
       "     4920    0.017    0.000    0.149    0.000 iostream.py:320(_schedule_flush)\n",
       "     2460    0.017    0.000    0.023    0.000 __init__.py:1544(isEnabledFor)\n",
       "     2460    0.017    0.000    0.271    0.000 __init__.py:1406(makeRecord)\n",
       "     2454    0.017    0.000    0.018    0.000 _methods.py:48(_count_reduce_items)\n",
       "    10708    0.017    0.000    0.017    0.000 {method 'rfind' of 'str' objects}\n",
       "      245    0.017    0.000    2.800    0.011 summary.py:248(make_image)\n",
       "     4920    0.017    0.000    0.027    0.000 __init__.py:387(usesTime)\n",
       "      246    0.016    0.000    0.016    0.000 {built-in method cat}\n",
       "     4920    0.016    0.000    0.022    0.000 iostream.py:307(_is_master_process)\n",
       "     1719    0.016    0.000    3.252    0.002 train_misc.py:54(count_nfe)\n",
       " 1482/120    0.015    0.000    0.068    0.001 sre_compile.py:64(_compile)\n",
       "     3586    0.015    0.000    0.023    0.000 genericpath.py:117(_splitext)\n",
       "     8743    0.015    0.000    0.043    0.000 <frozen importlib._bootstrap_external>:57(_path_join)\n",
       "     4663    0.015    0.000    1.602    0.000 comm.py:151(gather)\n",
       "     7380    0.015    0.000    0.015    0.000 __init__.py:705(filter)\n",
       "     2920    0.015    0.000   32.174    0.011 {built-in method builtins.next}\n",
       "     2405    0.015    0.000    2.990    0.001 train_cnf_disentangle.py:397(<lambda>)\n",
       "     2460    0.014    0.000    5.189    0.002 __init__.py:1063(emit)\n",
       "     2406    0.014    0.000    0.014    0.000 {method 'type' of 'torch._C._TensorBase' objects}\n",
       "     8743    0.014    0.000    0.023    0.000 <frozen importlib._bootstrap_external>:59(<listcomp>)\n",
       "     2483    0.014    0.000    0.022    0.000 posixpath.py:52(normcase)\n",
       "    26632    0.014    0.000    0.014    0.000 {method 'rstrip' of 'str' objects}\n",
       "    19663    0.013    0.000    0.013    0.000 threading.py:1120(daemon)\n",
       "     4910    0.013    0.000   11.657    0.002 comm.py:24(broadcast_coalesced)\n",
       "     9861    0.013    0.000    0.013    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "    13474    0.013    0.000    0.013    0.000 {built-in method posix.fspath}\n",
       "    14811    0.013    0.000    0.023    0.000 sre_parse.py:253(get)\n",
       "     1719    0.013    0.000    3.756    0.002 train_misc.py:74(count_total_time)\n",
       "    19632    0.013    0.000    0.013    0.000 {method 'discard' of 'set' objects}\n",
       "     2209    0.013    0.000    0.251    0.000 loss.py:22(__init__)\n",
       "     2209    0.013    0.000    0.221    0.000 functional.py:1923(cross_entropy)\n",
       "     2454    0.013    0.000    2.136    0.001 data_parallel.py:155(gather)\n",
       "     2211    0.013    0.000    0.175    0.000 fromnumeric.py:2478(prod)\n",
       "     1650    0.013    0.000    0.022    0.000 posixpath.py:75(join)\n",
       "     2209    0.013    0.000    0.236    0.000 loss.py:901(forward)\n",
       "     4920    0.013    0.000    0.019    0.000 __init__.py:329(getMessage)\n",
       "     2209    0.013    0.000    0.277    0.000 loss.py:896(__init__)\n",
       "      490    0.013    0.000    2.875    0.006 ImageFile.py:463(_save)\n",
       "      490    0.013    0.000    5.311    0.011 Image.py:1892(save)\n",
       "     1528    0.013    0.000    0.030    0.000 version.py:198(__init__)\n",
       "     2460    0.012    0.000    0.017    0.000 __init__.py:157(<lambda>)\n",
       "    19681    0.012    0.000    0.012    0.000 {method 'remove' of 'collections.deque' objects}\n",
       "      245    0.012    0.000    3.860    0.016 utils.py:90(save_image)\n",
       "     4920    0.012    0.000    0.030    0.000 __init__.py:548(formatMessage)\n",
       "       14    0.012    0.001    0.012    0.001 {built-in method _pickle.load}\n",
       "     9326    0.012    0.000    0.014    0.000 _functions.py:59(<genexpr>)\n",
       "     5967    0.012    0.000    0.012    0.000 {method 'find' of 'str' objects}\n",
       "    17183    0.012    0.000    0.012    0.000 event_file_writer.py:118(get_logdir)\n",
       "    19632    0.012    0.000    0.012    0.000 {method 'locked' of '_thread.lock' objects}\n",
       "     2209    0.011    0.000    0.202    0.000 loss.py:13(__init__)\n",
       "     2219    0.011    0.000    0.036    0.000 module.py:87(register_buffer)\n",
       "     1470    0.011    0.000    0.011    0.000 {built-in method zlib.crc32}\n",
       "     2209    0.011    0.000    0.117    0.000 dropout.py:56(forward)\n",
       "      184    0.011    0.000    0.023    0.000 module.py:647(_load_from_state_dict)\n",
       "     4920    0.011    0.000    0.011    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
       "    16531    0.011    0.000    0.011    0.000 sre_parse.py:232(__next)\n",
       "      245    0.010    0.000    0.010    0.000 {method 'copy' of 'ImagingCore' objects}\n",
       "     2700    0.010    0.000   16.503    0.006 scatter_gather.py:5(scatter)\n",
       "     4167    0.010    0.000    0.027    0.000 enum.py:803(__and__)\n",
       "     2455    0.010    0.000   16.565    0.007 data_parallel.py:149(scatter)\n",
       "    719/1    0.010    0.000 62467.313 62467.313 {built-in method builtins.exec}\n",
       "     9613    0.010    0.000    0.018    0.000 enum.py:267(__call__)\n",
       "     2233    0.010    0.000    0.010    0.000 {method 'SerializeToString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "     2209    0.010    0.000    0.092    0.000 tensor.py:348(__rsub__)\n",
       "     1720    0.010    0.000   11.842    0.007 dataloader.py:245(<listcomp>)\n",
       "     2210    0.009    0.000    0.009    0.000 scatter_gather.py:40(<listcomp>)\n",
       "      245    0.009    0.000    0.009    0.000 {method 'mul' of 'torch._C._TensorBase' objects}\n",
       "     2454    0.009    0.000    2.123    0.001 scatter_gather.py:46(gather)\n",
       "     2492    0.009    0.000    0.009    0.000 {method 'encode' of 'str' objects}\n",
       "     3438    0.009    0.000    0.009    0.000 {method '__format__' of 'float' objects}\n",
       "     2209    0.009    0.000    0.082    0.000 functional.py:1271(log_softmax)\n",
       "     7385    0.009    0.000    0.009    0.000 {built-in method posix.getpid}\n",
       "      245    0.009    0.000    0.780    0.003 JpegImagePlugin.py:617(_save)\n",
       "     2209    0.009    0.000    0.528    0.000 fromnumeric.py:976(argmax)\n",
       "     5213    0.009    0.000    0.013    0.000 posixpath.py:41(_get_sep)\n",
       "      245    0.009    0.000    2.135    0.009 PngImagePlugin.py:689(_save)\n",
       "     9861    0.008    0.000    0.008    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "     2460    0.008    0.000    0.012    0.000 __init__.py:120(getLevelName)\n",
       "11942/11870    0.008    0.000    0.011    0.000 {method 'join' of 'str' objects}\n",
       " 1066/326    0.008    0.000    2.077    0.006 <frozen importlib._bootstrap>:966(_find_and_load)\n",
       "      749    0.008    0.000    0.223    0.000 <frozen importlib._bootstrap>:870(_find_spec)\n",
       "     1986    0.008    0.000    0.014    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "     2209    0.008    0.000    0.520    0.000 fromnumeric.py:49(_wrapfunc)\n",
       "      695    0.007    0.000    0.011    0.000 <frozen importlib._bootstrap_external>:430(_validate_bytecode_header)\n",
       "     1390    0.007    0.000    0.024    0.000 <frozen importlib._bootstrap_external>:263(cache_from_source)\n",
       "     9612    0.007    0.000    0.008    0.000 enum.py:517(__new__)\n",
       "      695    0.007    0.000    0.254    0.000 <frozen importlib._bootstrap_external>:743(get_code)\n",
       "      245    0.007    0.000    0.007    0.000 {method 'byte' of 'torch._C._TensorBase' objects}\n",
       "     2209    0.007    0.000    0.007    0.000 {method 'long' of 'torch._C._TensorBase' objects}\n",
       "    10563    0.007    0.000    0.007    0.000 {method 'split' of 'str' objects}\n",
       "      735    0.007    0.000    0.031    0.000 PngImagePlugin.py:667(putchunk)\n",
       "     2209    0.007    0.000    0.007    0.000 {built-in method math.log}\n",
       "     2460    0.007    0.000    0.007    0.000 threading.py:1076(name)\n",
       "      614    0.007    0.000    0.012    0.000 sre_compile.py:250(_optimize_charset)\n",
       "     2460    0.006    0.000    0.006    0.000 __init__.py:1530(getEffectiveLevel)\n",
       "     4173    0.006    0.000    0.009    0.000 variable.py:6(__instancecheck__)\n",
       "     6232    0.006    0.000    0.010    0.000 sre_parse.py:163(__getitem__)\n",
       "      245    0.006    0.000    0.006    0.000 {method 'clamp' of 'torch._C._TensorBase' objects}\n",
       "      724    0.006    0.000    0.028    0.000 <frozen importlib._bootstrap>:504(_init_module_attrs)\n",
       "     2450    0.006    0.000    0.006    0.000 {method 'write' of '_io.BytesIO' objects}\n",
       "      245    0.006    0.000    0.219    0.001 utils.py:95(convert_to_HWC)\n",
       "     2210    0.006    0.000    0.009    0.000 _VF.py:11(__getattr__)\n",
       "      547    0.006    0.000  144.649    0.264 serialization.py:131(_with_file_like)\n",
       "      822    0.006    0.000    0.038    0.000 __init__.py:45(is_available)\n",
       "     3814    0.006    0.000    0.009    0.000 utils.py:51(add_argument)\n",
       "       97    0.005    0.000    0.012    0.000 <frozen importlib._bootstrap_external>:1067(_path_hooks)\n",
       "    12310    0.005    0.000    0.005    0.000 {method 'strip' of 'str' objects}\n",
       "   738/21    0.005    0.000    2.033    0.097 <frozen importlib._bootstrap>:651(_load_unlocked)\n",
       "      760    0.005    0.000    0.016    0.000 version.py:131(_legacy_cmpkey)\n",
       "        1    0.005    0.005    0.005    0.005 {built-in method builtins.compile}\n",
       "     2455    0.005    0.000    0.005    0.000 replicate.py:23(<listcomp>)\n",
       "     4833    0.005    0.000    0.176    0.000 <frozen importlib._bootstrap_external>:75(_path_stat)\n",
       "      246    0.005    0.000    3.001    0.012 train_cnf_disentangle.py:148(get_train_loader)\n",
       "     2209    0.005    0.000    0.005    0.000 {method 'nelement' of 'torch._C._TensorBase' objects}\n",
       "     7541    0.005    0.000    0.005    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "     3312    0.005    0.000    0.009    0.000 version.py:114(_parse_version_parts)\n",
       " 2304/962    0.005    0.000    0.007    0.000 sre_parse.py:173(getwidth)\n",
       "     3488    0.005    0.000    0.008    0.000 utils.py:79(<lambda>)\n",
       "     3993    0.005    0.000    0.005    0.000 {built-in method torch._C.is_grad_enabled}\n",
       "     1986    0.005    0.000    0.006    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "     3488    0.005    0.000    0.009    0.000 utils.py:81(<lambda>)\n",
       "      245    0.005    0.000    0.005    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
       "      245    0.005    0.000    4.505    0.018 writer.py:429(add_images)\n",
       "     2841    0.005    0.000    0.005    0.000 {built-in method sys._getframe}\n",
       "      247    0.005    0.000    0.016    0.000 dataloader.py:768(__init__)\n",
       "   760/20    0.005    0.000    2.063    0.103 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)\n",
       "      730    0.005    0.000    0.009    0.000 posixpath.py:154(dirname)\n",
       "     1986    0.005    0.000    0.006    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "      547    0.005    0.000    0.170    0.000 optimizer.py:72(state_dict)\n",
       "     2455    0.005    0.000    0.005    0.000 replicate.py:69(<listcomp>)\n",
       "     5734    0.005    0.000    0.005    0.000 {built-in method builtins.min}\n",
       "       28    0.005    0.000    0.005    0.000 {method 'readlines' of '_io._IOBase' objects}\n",
       "  483/175    0.005    0.000    0.013    0.000 abc.py:196(__subclasscheck__)\n",
       "     2455    0.004    0.000    0.004    0.000 function.py:45(mark_non_differentiable)\n",
       "     3740    0.004    0.000    0.007    0.000 version.py:65(_compare)\n",
       "     1228    0.004    0.000    0.006    0.000 tensor.py:395(__len__)\n",
       "     6628    0.004    0.000    0.004    0.000 __init__.py:1408(_unwrap_optional)\n",
       "     1993    0.004    0.000    0.004    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
       "     2461    0.004    0.000    0.004    0.000 process.py:35(current_process)\n",
       "  750/749    0.004    0.000    0.204    0.000 <frozen importlib._bootstrap_external>:1117(_get_spec)\n",
       "     2717    0.004    0.000    0.004    0.000 dataloader.py:811(__setattr__)\n",
       "      547    0.004    0.000  144.653    0.264 serialization.py:191(save)\n",
       "     2874    0.004    0.000    0.068    0.000 <frozen importlib._bootstrap_external>:85(_path_is_mode_type)\n",
       "     4226    0.004    0.000    0.006    0.000 utils.py:92(<lambda>)\n",
       "     2460    0.004    0.000    0.004    0.000 process.py:146(name)\n",
       "     2836    0.004    0.000    0.004    0.000 {method 'extend' of 'list' objects}\n",
       "      490    0.004    0.000    0.046    0.000 Image.py:779(frombytes)\n",
       "      768    0.004    0.000    0.005    0.000 version.py:343(_cmpkey)\n",
       "     8043    0.004    0.000    0.004    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
       "     1719    0.004    0.000    0.004    0.000 train_misc.py:56(AccNumEvals)\n",
       "      597    0.004    0.000    0.008    0.000 tokenize.py:492(_tokenize)\n",
       "        1    0.004    0.004    0.004    0.004 {built-in method posix.read}\n",
       "      548    0.004    0.000    0.944    0.002 utils.py:8(makedirs)\n",
       "      352    0.004    0.000    0.012    0.000 inspect.py:2100(_signature_from_function)\n",
       "     4135    0.004    0.000    0.004    0.000 {built-in method builtins.setattr}\n",
       "      490    0.004    0.000    0.006    0.000 Image.py:430(_getdecoder)\n",
       "      547    0.004    0.000    0.058    0.000 optimizer.py:82(pack_group)\n",
       "     3830    0.004    0.000    0.005    0.000 utils.py:75(<lambda>)\n",
       "      490    0.004    0.000    0.101    0.000 Image.py:2353(frombytes)\n",
       "      107    0.004    0.000    0.004    0.000 {method 'cuda' of 'torch._C._TensorBase' objects}\n",
       "     1361    0.003    0.000    0.006    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "     1228    0.003    0.000    0.012    0.000 mnist.py:84(__len__)\n",
       "     3488    0.003    0.000    0.005    0.000 utils.py:83(<lambda>)\n",
       "     1531    0.003    0.000    0.003    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n",
       "      894    0.003    0.000    0.990    0.001 genericpath.py:16(exists)\n",
       "     2583    0.003    0.000    0.005    0.000 {built-in method builtins.any}\n",
       "      444    0.003    0.000    0.005    0.000 PyColorize.py:284(_inner_call_)\n",
       "       10    0.003    0.000    0.003    0.000 {built-in method sqrt}\n",
       "  498/120    0.003    0.000    0.076    0.001 sre_parse.py:407(_parse_sub)\n",
       "     1719    0.003    0.000    0.003    0.000 train_misc.py:76(Accumulator)\n",
       "        1    0.003    0.003    0.003    0.003 {built-in method _posixsubprocess.fork_exec}\n",
       "     2462    0.003    0.000    0.003    0.000 {built-in method _imp.lock_held}\n",
       "      769    0.003    0.000    0.008    0.000 grad_mode.py:35(__exit__)\n",
       "     3814    0.003    0.000    0.003    0.000 utils.py:61(__init__)\n",
       "     3488    0.003    0.000    0.005    0.000 utils.py:77(<lambda>)\n",
       "        1    0.003    0.003    0.015    0.015 {built-in method torch._C._initExtension}\n",
       "     2209    0.003    0.000    0.003    0.000 _reduction.py:8(get_enum)\n",
       "        3    0.003    0.001    0.026    0.009 {method 'load' of '_pickle.Unpickler' objects}\n",
       "      695    0.003    0.000    0.062    0.000 <frozen importlib._bootstrap_external>:485(_compile_bytecode)\n",
       "      491    0.003    0.000    0.175    0.000 dataloader.py:818(__iter__)\n",
       "      769    0.003    0.000    0.004    0.000 grad_mode.py:122(__init__)\n",
       "  724/718    0.003    0.000    0.212    0.000 <frozen importlib._bootstrap>:564(module_from_spec)\n",
       "      246    0.003    0.000    0.834    0.003 sampler.py:69(__iter__)\n",
       "     5821    0.003    0.000    0.003    0.000 {built-in method _imp.acquire_lock}\n",
       "      490    0.003    0.000    0.017    0.000 fromnumeric.py:1821(sum)\n",
       "     5821    0.003    0.000    0.003    0.000 {built-in method _imp.release_lock}\n",
       "      769    0.003    0.000    0.004    0.000 grad_mode.py:31(__enter__)\n",
       "      724    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:524(spec_from_file_location)\n",
       "     2209    0.003    0.000    0.003    0.000 modules.py:280(<listcomp>)\n",
       "   695/19    0.003    0.000    2.032    0.107 <frozen importlib._bootstrap_external>:672(exec_module)\n",
       "     1470    0.003    0.000    0.014    0.000 PngImagePlugin.py:90(_crc32)\n",
       "     1361    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "     2488    0.003    0.000    0.063    0.000 <frozen importlib._bootstrap_external>:94(_path_isfile)\n",
       "     1762    0.003    0.000    0.005    0.000 __init__.py:1972(dist_factory)\n",
       "     1960    0.003    0.000    0.005    0.000 _binary.py:93(o32be)\n",
       "      320    0.003    0.000    0.047    0.000 __init__.py:2481(from_location)\n",
       "     4189    0.003    0.000    0.004    0.000 sre_parse.py:248(match)\n",
       "      628    0.003    0.000    0.062    0.000 __init__.py:2027(distributions_from_metadata)\n",
       "     1390    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:63(_path_split)\n",
       "      352    0.003    0.000    0.006    0.000 inspect.py:2832(_hash_basis)\n",
       "     1016    0.003    0.000    0.159    0.000 re.py:286(_compile)\n",
       "    893/1    0.002    0.000    0.015    0.015 copy.py:132(deepcopy)\n",
       "      724    0.002    0.000    0.007    0.000 <frozen importlib._bootstrap>:318(__exit__)\n",
       "     1719    0.002    0.000    0.002    0.000 train_misc.py:58(__init__)\n",
       "     1719    0.002    0.000    0.002    0.000 train_misc.py:78(__init__)\n",
       "      614    0.002    0.000    0.017    0.000 sre_compile.py:223(_compile_charset)\n",
       "      512    0.002    0.000    0.007    0.000 copy.py:66(copy)\n",
       "     2307    0.002    0.000    0.004    0.000 <frozen importlib._bootstrap>:847(__exit__)\n",
       "      245    0.002    0.000    0.017    0.000 Image.py:1738(resize)\n",
       "     2029    0.002    0.000    0.002    0.000 {built-in method _struct.pack}\n",
       "      920    0.002    0.000    0.011    0.000 <frozen importlib._bootstrap>:194(_lock_unlock_module)\n",
       "        1    0.002    0.002    0.004    0.004 packages.py:1(<module>)\n",
       "      352    0.002    0.000    0.018    0.000 inspect.py:2181(_signature_from_callable)\n",
       "      490    0.002    0.000    0.002    0.000 {method 'flush' of '_io.BufferedRandom' objects}\n",
       "     1066    0.002    0.000    0.016    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "     2993    0.002    0.000    0.002    0.000 {method 'endswith' of 'str' objects}\n",
       "      724    0.002    0.000    0.007    0.000 <frozen importlib._bootstrap_external>:1228(_get_spec)\n",
       "      744    0.002    0.000    0.004    0.000 inspect.py:2450(__init__)\n",
       "     4491    0.002    0.000    0.002    0.000 {method 'lower' of 'str' objects}\n",
       "     2307    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:843(__enter__)\n",
       "     1076    0.002    0.000    0.033    0.000 version.py:24(parse)\n",
       "      503    0.002    0.000    0.003    0.000 {method 'sort' of 'list' objects}\n",
       "      722    0.002    0.000    0.015    0.000 <frozen importlib._bootstrap_external>:361(_get_cached)\n",
       "      320    0.002    0.000    0.005    0.000 __init__.py:683(add)\n",
       "     2281    0.002    0.000    0.003    0.000 sre_parse.py:159(__len__)\n",
       "     2992    0.002    0.000    0.002    0.000 version.py:207(<genexpr>)\n",
       "      306    0.002    0.000    0.019    0.000 _utils.py:127(_rebuild_tensor)\n",
       "     3828    0.002    0.000    0.002    0.000 {method 'partition' of 'str' objects}\n",
       "        1    0.002    0.002    0.032    0.032 binding.py:81(build_conditional_library)\n",
       "      884    0.002    0.000    0.002    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
       "      245    0.002    0.000    0.002    0.000 {built-in method PIL._imaging.jpeg_encoder}\n",
       "      245    0.002    0.000    0.002    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
       "      306    0.002    0.000    0.003    0.000 serialization.py:513(persistent_load)\n",
       "      490    0.002    0.000    0.002    0.000 {built-in method PIL._imaging.raw_decoder}\n",
       "     1140    0.002    0.000    0.002    0.000 {built-in method builtins.iter}\n",
       "    368/2    0.002    0.000    0.006    0.003 module.py:1024(__repr__)\n",
       "      194    0.002    0.000    0.002    0.000 {method 'copy_' of 'torch._C.FloatStorageBase' objects}\n",
       "        8    0.002    0.000    0.002    0.000 traitlets.py:1421(<listcomp>)\n",
       "      138    0.002    0.000    0.002    0.000 {method 'splitlines' of 'str' objects}\n",
       "     4226    0.002    0.000    0.002    0.000 utils.py:94(<lambda>)\n",
       "      326    0.002    0.000    0.044    0.000 __init__.py:2094(_handle_ns)\n",
       "     2103    0.002    0.000    0.003    0.000 sre_parse.py:171(append)\n",
       "      500    0.002    0.000    0.002    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
       "      194    0.002    0.000    0.009    0.000 tensor.py:16(__deepcopy__)\n",
       "     1866    0.002    0.000    0.002    0.000 sre_parse.py:285(tell)\n",
       "      150    0.002    0.000    0.028    0.000 utils.py:89(verify_interface)\n",
       "      245    0.002    0.000    0.002    0.000 summary.py:59(_calc_scale_factor)\n",
       "      547    0.002    0.000    0.002    0.000 optimizer.py:83(<dictcomp>)\n",
       "      246    0.002    0.000    0.006    0.000 sampler.py:50(__init__)\n",
       "      245    0.002    0.000    0.603    0.002 module.py:992(eval)\n",
       "     1417    0.002    0.000    0.016    0.000 <frozen importlib._bootstrap>:403(cached)\n",
       "      352    0.002    0.000    0.003    0.000 inspect.py:2730(__init__)\n",
       "      691    0.002    0.000    0.017    0.000 __init__.py:2647(_get_metadata)\n",
       "       93    0.002    0.000    0.002    0.000 function.py:89(__init__)\n",
       "     1390    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:52(_r_long)\n",
       "     1870    0.002    0.000    0.005    0.000 version.py:47(__lt__)\n",
       "     1870    0.002    0.000    0.005    0.000 version.py:53(__eq__)\n",
       "      245    0.002    0.000    0.007    0.000 sampler.py:33(__iter__)\n",
       "     1136    0.002    0.000    0.004    0.000 _weakrefset.py:58(__iter__)\n",
       "      452    0.001    0.000    0.022    0.000 __init__.py:1323(safe_version)\n",
       "     2896    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:321(<genexpr>)\n",
       "       16    0.001    0.000    0.001    0.000 {method 'AddSerializedFile' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "     1066    0.001    0.000    0.005    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "      330    0.001    0.000    0.005    0.000 __init__.py:1958(<genexpr>)\n",
       "      490    0.001    0.000    0.001    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "      452    0.001    0.000    0.004    0.000 version.py:236(__str__)\n",
       "      471    0.001    0.000    0.003    0.000 copy.py:268(_reconstruct)\n",
       "       68    0.001    0.000    0.001    0.000 {built-in method posix.lstat}\n",
       "      547    0.001    0.000    0.060    0.000 optimizer.py:86(<listcomp>)\n",
       "       40    0.001    0.000    0.014    0.000 PyColorize.py:207(format2)\n",
       "      695    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:393(_check_name_wrapper)\n",
       "     1054    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "      775    0.001    0.000    0.001    0.000 {method 'split' of '_sre.SRE_Pattern' objects}\n",
       "      247    0.001    0.000    0.002    0.000 sampler.py:142(__init__)\n",
       "       52    0.001    0.000    1.500    0.029 __init__.py:1(<module>)\n",
       "      956    0.001    0.000    0.002    0.000 __init__.py:2540(key)\n",
       "      695    0.001    0.000    0.036    0.000 <frozen importlib._bootstrap_external>:840(path_stats)\n",
       "   530/46    0.001    0.000    1.619    0.035 {built-in method builtins.__import__}\n",
       "      342    0.001    0.000    0.130    0.000 __init__.py:1940(find_on_path)\n",
       "      749    0.001    0.000    0.206    0.000 <frozen importlib._bootstrap_external>:1149(find_spec)\n",
       "      982    0.001    0.000    0.014    0.000 <frozen importlib._bootstrap_external>:1080(_path_importer_cache)\n",
       "     1758    0.001    0.000    0.001    0.000 {method 'upper' of 'str' objects}\n",
       "   963/20    0.001    0.000    2.019    0.101 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "      245    0.001    0.000    0.014    0.000 Image.py:1083(copy)\n",
       "       25    0.001    0.000    0.001    0.000 {built-in method builtins.dir}\n",
       "      245    0.001    0.000    0.002    0.000 utils.py:102(<listcomp>)\n",
       "      507    0.001    0.000    0.001    0.000 _weakrefset.py:36(__init__)\n",
       "     1482    0.001    0.000    0.001    0.000 sre_parse.py:111(__init__)\n",
       "      697    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
       "     1390    0.001    0.000    0.001    0.000 {built-in method from_bytes}\n",
       "       86    0.001    0.000    0.005    0.000 abc.py:132(__new__)\n",
       "      120    0.001    0.000    0.005    0.000 sre_compile.py:482(_compile_info)\n",
       "      630    0.001    0.000    0.002    0.000 sre_compile.py:388(_simple)\n",
       "      133    0.001    0.000    0.003    0.000 pyparsing.py:3260(__init__)\n",
       "    165/1    0.001    0.000    0.006    0.006 module.py:185(_apply)\n",
       "       84    0.001    0.000    0.001    0.000 init.py:178(_calculate_fan_in_and_fan_out)\n",
       "       31    0.001    0.000    0.002    0.000 auto.py:107(_make_function_class)\n",
       "      748    0.001    0.000    0.002    0.000 __init__.py:2688(__getattr__)\n",
       "      537    0.001    0.000    0.003    0.000 __init__.py:2281(yield_lines)\n",
       "      120    0.001    0.000    0.155    0.001 sre_compile.py:557(compile)\n",
       "      695    0.001    0.000    0.001    0.000 {built-in method _imp._fix_co_filename}\n",
       "      323    0.001    0.000    0.037    0.000 <frozen importlib._bootstrap_external>:413(_find_module_shim)\n",
       "       29    0.001    0.000    0.015    0.001 traceback.py:319(extract)\n",
       "     2552    0.001    0.000    0.001    0.000 {built-in method builtins.ord}\n",
       "      282    0.001    0.000    0.003    0.000 function_base.py:3895(add_newdoc)\n",
       "      245    0.001    0.000    0.002    0.000 JpegImagePlugin.py:626(<listcomp>)\n",
       "     1096    0.001    0.000    0.001    0.000 inspect.py:2779(<genexpr>)\n",
       "      335    0.001    0.000    0.001    0.000 pyparsing.py:1144(__init__)\n",
       "     1015    0.001    0.000    0.002    0.000 sre_compile.py:102(fixup)\n",
       "      760    0.001    0.000    0.017    0.000 version.py:74(__init__)\n",
       "        3    0.001    0.000    0.361    0.120 __init__.py:9(<module>)\n",
       "     1806    0.001    0.000    0.001    0.000 {method 'find' of 'bytearray' objects}\n",
       "     1538    0.001    0.000    0.001    0.000 {built-in method torch._C.set_grad_enabled}\n",
       "      314    0.001    0.000    0.034    0.000 __init__.py:1935(<listcomp>)\n",
       "      194    0.001    0.000    0.004    0.000 storage.py:40(clone)\n",
       "     1096    0.001    0.000    0.001    0.000 inspect.py:2833(<genexpr>)\n",
       "     2304    0.001    0.000    0.001    0.000 version.py:298(_parse_letter_version)\n",
       "      285    0.001    0.000    0.001    0.000 {built-in method _warnings.warn}\n",
       "     1758    0.001    0.000    0.001    0.000 version.py:244(<genexpr>)\n",
       "      159    0.001    0.000    0.002    0.000 __init__.py:2772(<listcomp>)\n",
       "      384    0.001    0.000    0.003    0.000 loader.py:231(_has_section)\n",
       "       40    0.001    0.000    0.015    0.000 conv.py:17(__init__)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method normal}\n",
       "      490    0.001    0.000    0.001    0.000 {built-in method builtins.round}\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method torch._C._c10d_init}\n",
       "     1066    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "   388/97    0.001    0.000    0.002    0.000 optimizer.py:122(cast)\n",
       "      314    0.001    0.000    0.037    0.000 __init__.py:1929(_by_version)\n",
       "      366    0.001    0.000    0.002    0.000 module.py:11(_addindent)\n",
       "      444    0.001    0.000    0.006    0.000 PyColorize.py:328(__call__)\n",
       "      352    0.001    0.000    0.002    0.000 inspect.py:485(unwrap)\n",
       "      749    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:780(find_spec)\n",
       "      388    0.001    0.000    0.004    0.000 __init__.py:1468(_fn)\n",
       "      121    0.001    0.000    0.003    0.000 __init__.py:1521(_get)\n",
       "        1    0.001    0.001    0.002    0.002 descriptor_pb2.py:4(<module>)\n",
       "      336    0.001    0.000    0.002    0.000 warnings.py:159(_add_filter)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:48(<lambda>)\n",
       "       15    0.001    0.000    0.003    0.000 enum.py:124(__new__)\n",
       "      848    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
       "      803    0.001    0.000    0.001    0.000 inspect.py:159(isfunction)\n",
       "      320    0.001    0.000    0.019    0.000 __init__.py:2468(__init__)\n",
       "        2    0.001    0.000    0.002    0.001 __init__.py:1420(register_all)\n",
       "      724    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:311(__enter__)\n",
       "      741    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C.FloatStorageBase' objects}\n",
       "     1940    0.001    0.000    0.004    0.000 __init__.py:2248(_normalize_cached)\n",
       "     1499    0.001    0.000    0.001    0.000 {built-in method _sre.getlower}\n",
       "      120    0.001    0.000    0.079    0.001 sre_parse.py:844(parse)\n",
       "      661    0.001    0.000    0.158    0.000 re.py:231(compile)\n",
       "      471    0.001    0.000    0.008    0.000 pyparsing.py:1167(copy)\n",
       "       20    0.001    0.000    0.001    0.000 {method 'read' of '_io.TextIOWrapper' objects}\n",
       "      245    0.001    0.000    0.001    0.000 {built-in method PIL._imaging.zip_encoder}\n",
       "      490    0.001    0.000    0.001    0.000 _util.py:10(isPath)\n",
       "       95    0.001    0.000    0.001    0.000 functools.py:44(update_wrapper)\n",
       "    184/1    0.001    0.000    0.024    0.024 module.py:746(load)\n",
       "        1    0.001    0.001    0.693    0.693 writer.py:246(__init__)\n",
       "      176    0.001    0.000    0.007    0.000 inspect.py:2846(__eq__)\n",
       "      352    0.001    0.000    0.001    0.000 inspect.py:2836(<dictcomp>)\n",
       "     1870    0.001    0.000    0.001    0.000 version.py:54(<lambda>)\n",
       "      267    0.001    0.000    0.002    0.000 enum.py:797(__or__)\n",
       "      159    0.001    0.000    0.004    0.000 __init__.py:2746(insert_on)\n",
       "     1399    0.001    0.000    0.001    0.000 {method 'isidentifier' of 'str' objects}\n",
       "      749    0.001    0.000    0.001    0.000 {built-in method _imp.is_frozen}\n",
       "       18    0.001    0.000    0.010    0.001 __init__.py:357(namedtuple)\n",
       "      724    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:307(__init__)\n",
       "      384    0.001    0.000    0.001    0.000 loader.py:150(_is_section_key)\n",
       "      324    0.001    0.000    0.001    0.000 warnings.py:449(__enter__)\n",
       "      697    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:800(__init__)\n",
       "    100/1    0.001    0.000    0.015    0.015 copy.py:236(_deepcopy_dict)\n",
       "      716    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
       "       24    0.001    0.000    0.137    0.006 __init__.py:609(add_entry)\n",
       "       98    0.001    0.000    0.012    0.000 <frozen importlib._bootstrap_external>:1281(_fill_cache)\n",
       "      490    0.001    0.000    0.001    0.000 {method 'setimage' of 'ImagingDecoder' objects}\n",
       "     1526    0.001    0.000    0.001    0.000 _structures.py:33(__neg__)\n",
       "      316    0.001    0.000    0.003    0.000 genericpath.py:39(isdir)\n",
       "        3    0.001    0.000    0.643    0.214 serialization.py:385(_load)\n",
       "      536    0.001    0.000    0.001    0.000 __init__.py:119(is_tensor)\n",
       "      159    0.001    0.000    0.039    0.000 __init__.py:2193(fixup_namespace_packages)\n",
       "       42    0.001    0.000    0.013    0.000 linecache.py:82(updatecache)\n",
       "      355    0.001    0.000    0.001    0.000 _weakrefset.py:26(__exit__)\n",
       "      245    0.001    0.000    0.020    0.000 PngImagePlugin.py:685(write)\n",
       "      549    0.001    0.000    0.001    0.000 <string>:12(__new__)\n",
       "        3    0.001    0.000    0.002    0.001 six.py:1(<module>)\n",
       "      490    0.001    0.000    0.001    0.000 scatter_gather.py:20(<listcomp>)\n",
       "      330    0.001    0.000    0.002    0.000 warnings.py:143(simplefilter)\n",
       "      491    0.001    0.000    0.001    0.000 dataloader.py:715(__del__)\n",
       "      306    0.001    0.000    0.015    0.000 __init__.py:108(import_module)\n",
       "       86    0.001    0.000    0.001    0.000 abc.py:135(<setcomp>)\n",
       "      227    0.001    0.000    0.001    0.000 sre_parse.py:294(_class_escape)\n",
       "       32    0.001    0.000    0.001    0.000 {method 'readline' of '_io.BufferedReader' objects}\n",
       "      214    0.001    0.000    0.001    0.000 module.py:17(<listcomp>)\n",
       "       90    0.001    0.000    0.001    0.000 sre_compile.py:376(_mk_bitmap)\n",
       "      161    0.001    0.000    0.010    0.000 abc.py:151(register)\n",
       "     1488    0.001    0.000    0.001    0.000 inspect.py:2512(kind)\n",
       "      374    0.001    0.000    0.001    0.000 sre_parse.py:342(_escape)\n",
       "     1264    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:41(_relax_case)\n",
       "        1    0.001    0.001    0.003    0.003 caffe2_pb2.py:4(<module>)\n",
       "     40/8    0.001    0.000    0.005    0.001 configurable.py:106(_find_my_config)\n",
       "      612    0.001    0.000    0.001    0.000 serialization.py:502(maybe_decode_ascii)\n",
       "      656    0.001    0.000    0.001    0.000 sre_parse.py:81(groups)\n",
       "      324    0.001    0.000    0.002    0.000 re.py:184(sub)\n",
       "       23    0.001    0.000    0.483    0.021 event_file_writer.py:35(__init__)\n",
       "       80    0.001    0.000    0.001    0.000 configurable.py:102(<listcomp>)\n",
       "        8    0.001    0.000    0.002    0.000 traitlets.py:224(getmembers)\n",
       "  472/114    0.001    0.000    0.006    0.000 {built-in method builtins.repr}\n",
       "      159    0.001    0.000    0.053    0.000 __init__.py:2652(activate)\n",
       "        8    0.001    0.000    0.031    0.004 ultratb.py:833(format_record)\n",
       "      132    0.001    0.000    0.021    0.000 __init__.py:2451(_version_from_file)\n",
       "      267    0.001    0.000    0.005    0.000 __init__.py:1404(has_metadata)\n",
       "      796    0.001    0.000    0.001    0.000 {method 'pop' of 'dict' objects}\n",
       "      471    0.001    0.000    0.001    0.000 {method '__reduce_ex__' of 'object' objects}\n",
       "      490    0.001    0.000    0.015    0.000 Image.py:370(preinit)\n",
       "        8    0.001    0.000    0.003    0.000 traitlets.py:961(setup_instance)\n",
       "        1    0.001    0.001    0.001    0.001 case.py:341(TestCase)\n",
       "      245    0.001    0.000    0.001    0.000 {built-in method math.ceil}\n",
       "      917    0.001    0.000    0.001    0.000 {method 'setdefault' of 'dict' objects}\n",
       "      283    0.001    0.000    0.001    0.000 {method 'decode' of 'bytes' objects}\n",
       "       98    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:1196(__init__)\n",
       "        1    0.001    0.001    0.001    0.001 encoder.py:65(<module>)\n",
       "      399    0.001    0.000    0.001    0.000 tokenize.py:152(_compile)\n",
       "      396    0.001    0.000    0.001    0.000 __init__.py:2456(is_version_line)\n",
       "      372    0.001    0.000    0.001    0.000 inspect.py:2559(__eq__)\n",
       "       56    0.001    0.000    0.003    0.000 argparse.py:1307(add_argument)\n",
       "      306    0.001    0.000    0.014    0.000 <frozen importlib._bootstrap>:982(_gcd_import)\n",
       "      356    0.001    0.000    0.001    0.000 {method 'remove' of 'list' objects}\n",
       "      118    0.001    0.000    0.001    0.000 enum.py:70(__setitem__)\n",
       "      246    0.001    0.000    0.003    0.000 sampler.py:168(__len__)\n",
       "      392    0.001    0.000    0.001    0.000 loader.py:218(__contains__)\n",
       "      202    0.001    0.000    0.001    0.000 sre_parse.py:84(opengroup)\n",
       "      977    0.001    0.000    0.001    0.000 {method 'write' of '_io.StringIO' objects}\n",
       "    102/2    0.001    0.000    0.002    0.001 pyparsing.py:1370(_parseNoCache)\n",
       "      471    0.001    0.000    0.001    0.000 copyreg.py:87(__newobj__)\n",
       "      306    0.000    0.000    0.019    0.000 _utils.py:134(_rebuild_tensor_v2)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
       "       27    0.000    0.000    0.001    0.000 {built-in method _imp.exec_dynamic}\n",
       "      749    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:707(find_spec)\n",
       "       86    0.000    0.000    0.001    0.000 _oid.py:11(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method randn}\n",
       "      324    0.000    0.000    0.001    0.000 warnings.py:468(__exit__)\n",
       "       40    0.000    0.000    0.009    0.000 conv.py:45(reset_parameters)\n",
       "      355    0.000    0.000    0.001    0.000 _weakrefset.py:20(__enter__)\n",
       "      374    0.000    0.000    0.001    0.000 descriptor.py:524(__new__)\n",
       "      386    0.000    0.000    0.009    0.000 <frozen importlib._bootstrap_external>:99(_path_isdir)\n",
       "       60    0.000    0.000    0.004    0.000 six.py:837(wrapper)\n",
       "       15    0.000    0.000    0.001    0.000 enum.py:160(<setcomp>)\n",
       "      245    0.000    0.000    0.000    0.000 PngImagePlugin.py:681(__init__)\n",
       "     1024    0.000    0.000    0.000    0.000 version.py:352(<lambda>)\n",
       "      564    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "      352    0.000    0.000    0.018    0.000 inspect.py:3055(signature)\n",
       "     1134    0.000    0.000    0.000    0.000 __init__.py:1997(__bool__)\n",
       "     1113    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
       "      490    0.000    0.000    0.000    0.000 {method 'cleanup' of 'ImagingEncoder' objects}\n",
       "      784    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1202(<genexpr>)\n",
       "      296    0.000    0.000    0.001    0.000 copy.py:252(_keep_alive)\n",
       "      386    0.000    0.000    0.010    0.000 traceback.py:283(line)\n",
       "      193    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
       "      613    0.000    0.000    0.000    0.000 ipstruct.py:125(__getattr__)\n",
       "        1    0.000    0.000 62467.258 62467.258 py3compat.py:184(execfile)\n",
       "      352    0.000    0.000    0.018    0.000 inspect.py:2803(from_callable)\n",
       "       90    0.000    0.000    0.000    0.000 sre_compile.py:378(<listcomp>)\n",
       "       98    0.000    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:1322(path_hook_for_FileFinder)\n",
       "      121    0.000    0.000    0.005    0.000 __init__.py:1407(get_metadata)\n",
       "      695    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:825(get_filename)\n",
       "      120    0.000    0.000    0.001    0.000 sre_parse.py:223(__init__)\n",
       "      320    0.000    0.000    0.002    0.000 __init__.py:1315(safe_name)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_library_init}\n",
       "       23    0.000    0.000    0.527    0.023 event_file_writer.py:90(__init__)\n",
       "       46    0.000    0.000    0.000    0.000 crc32c.py:77(crc_update)\n",
       "      120    0.000    0.000    0.074    0.001 sre_compile.py:542(_code)\n",
       "        1    0.000    0.000    0.629    0.629 _import_c_extension.py:3(<module>)\n",
       "       28    0.000    0.000    0.006    0.000 tokenize.py:448(open)\n",
       "      490    0.000    0.000    0.000    0.000 ImageFile.py:65(_tilesort)\n",
       "        2    0.000    0.000    0.001    0.000 traceback.py:386(format)\n",
       "      245    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedRandom' objects}\n",
       "        8    0.000    0.000    0.014    0.002 ultratb.py:379(_format_traceback_lines)\n",
       "      323    0.000    0.000    0.035    0.000 <frozen importlib._bootstrap_external>:1216(find_loader)\n",
       "   131/65    0.000    0.000    0.007    0.000 pyparsing.py:3363(copy)\n",
       "      149    0.000    0.000    0.035    0.000 utils.py:38(register_decorator)\n",
       "      194    0.000    0.000    0.004    0.000 storage.py:24(__deepcopy__)\n",
       "      132    0.000    0.000    0.022    0.000 __init__.py:2858(_reload_version)\n",
       "        2    0.000    0.000    0.000    0.000 {method '_set_from_file' of 'torch._C.LongStorageBase' objects}\n",
       "      840    0.000    0.000    0.000    0.000 {built-in method builtins.chr}\n",
       "       10    0.000    0.000    0.025    0.003 odefunc.py:99(__init__)\n",
       "      704    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
       "      267    0.000    0.000    0.002    0.000 __init__.py:1509(_has)\n",
       "      246    0.000    0.000    0.002    0.000 sampler.py:75(__len__)\n",
       "      744    0.000    0.000    0.000    0.000 inspect.py:2500(name)\n",
       "      724    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:424(has_location)\n",
       "       36    0.000    0.000    0.001    0.000 posixpath.py:331(normpath)\n",
       "   219/58    0.000    0.000    0.005    0.000 typing.py:1145(__subclasscheck__)\n",
       "        1    0.000    0.000    0.038    0.038 pyparsing.py:75(<module>)\n",
       "       56    0.000    0.000    0.001    0.000 argparse.py:157(__init__)\n",
       "      768    0.000    0.000    0.000    0.000 version.py:332(_parse_local_version)\n",
       "      246    0.000    0.000    0.004    0.000 dataloader.py:821(__len__)\n",
       "      302    0.000    0.000    0.001    0.000 serialization.py:401(restore_location)\n",
       "      352    0.000    0.000    0.001    0.000 inspect.py:505(_is_wrapper)\n",
       "      984    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
       "      188    0.000    0.000    0.009    0.000 linecache.py:15(getline)\n",
       "       21    0.000    0.000    0.000    0.000 {built-in method tensor}\n",
       "        1    0.000    0.000    0.032    0.032 auto.py:268(_generate_function_classes)\n",
       "       24    0.000    0.000    0.000    0.000 traitlets.py:486(_dynamic_default_callable)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1444(_get_optional_kwargs)\n",
       "      160    0.000    0.000    0.053    0.000 __init__.py:3153(<genexpr>)\n",
       "       42    0.000    0.000    0.007    0.000 init.py:261(kaiming_uniform_)\n",
       "      695    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:669(create_module)\n",
       "       82    0.000    0.000    0.001    0.000 pyparsing.py:3719(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.SSL_load_error_strings}\n",
       "      286    0.000    0.000    0.001    0.000 _tensor_docs.py:8(add_docstr_all)\n",
       "       98    0.000    0.000    0.001    0.000 module.py:122(register_parameter)\n",
       "       80    0.000    0.000    0.001    0.000 conv.py:53(extra_repr)\n",
       "        9    0.000    0.000    0.001    0.000 auto.py:14(_make_function_class_criterion)\n",
       "      306    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:917(_sanity_check)\n",
       "      630    0.000    0.000    0.000    0.000 sre_parse.py:167(__setitem__)\n",
       "      136    0.000    0.000    0.000    0.000 enum.py:353(__setattr__)\n",
       "       84    0.000    0.000    0.002    0.000 pyparsing.py:3390(__init__)\n",
       "      208    0.000    0.000    0.013    0.000 linecache.py:37(getlines)\n",
       "      194    0.000    0.000    0.001    0.000 __init__.py:219(__init__)\n",
       "      200    0.000    0.000    0.004    0.000 utils.py:6(parse)\n",
       "      120    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
       "      495    0.000    0.000    0.000    0.000 {built-in method torch._C._add_docstr}\n",
       "      296    0.000    0.000    0.000    0.000 weakref.py:406(__setitem__)\n",
       "      193    0.000    0.000    0.001    0.000 codecs.py:318(decode)\n",
       "      106    0.000    0.000    0.001    0.000 os.py:664(__getitem__)\n",
       "       40    0.000    0.000    0.000    0.000 bunch.py:11(__getattr__)\n",
       "    98/50    0.000    0.000    0.001    0.000 typing.py:1164(__setattr__)\n",
       "      754    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "      374    0.000    0.000    0.000    0.000 {method 'FindFieldByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "      196    0.000    0.000    0.006    0.000 train_misc.py:71(<genexpr>)\n",
       "      324    0.000    0.000    0.000    0.000 warnings.py:428(__init__)\n",
       "       23    0.000    0.000    0.010    0.000 record_writer.py:114(write)\n",
       "      178    0.000    0.000    0.001    0.000 _jit_internal.py:34(createResolutionCallback)\n",
       "      704    0.000    0.000    0.000    0.000 inspect.py:2809(parameters)\n",
       "      120    0.000    0.000    0.001    0.000 sre_parse.py:828(fix_flags)\n",
       "      444    0.000    0.000    0.000    0.000 {method 'read' of '_io.StringIO' objects}\n",
       "      350    0.000    0.000    0.001    0.000 pkgutil.py:402(get_importer)\n",
       "        1    0.000    0.000    0.001    0.001 step_stats_pb2.py:4(<module>)\n",
       "       69    0.000    0.000    0.001    0.000 pyparsing.py:2412(__init__)\n",
       "      304    0.000    0.000    0.000    0.000 __init__.py:1837(__init__)\n",
       "      355    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
       "       23    0.000    0.000    0.001    0.000 queue.py:27(__init__)\n",
       "      164    0.000    0.000    0.001    0.000 train_misc.py:17(_set)\n",
       "   131/65    0.000    0.000    0.005    0.000 pyparsing.py:3365(<listcomp>)\n",
       "      331    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "       16    0.000    0.000    0.010    0.001 traitlets.py:1142(notify_change)\n",
       "        1    0.000    0.000    0.004    0.004 summary_pb2.py:4(<module>)\n",
       "      409    0.000    0.000    0.000    0.000 utils.py:47(__init__)\n",
       "       39    0.000    0.000    0.001    0.000 _inspect.py:142(formatargspec)\n",
       "       40    0.000    0.000    0.022    0.001 basic.py:152(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:104(_init)\n",
       "        3    0.000    0.000    0.650    0.217 serialization.py:300(load)\n",
       "      596    0.000    0.000    0.000    0.000 copy.py:190(_deepcopy_atomic)\n",
       "      202    0.000    0.000    0.005    0.000 sre_parse.py:96(closegroup)\n",
       "      355    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)\n",
       "        1    0.000    0.000    0.002    0.002 numerictypes.py:81(<module>)\n",
       "      180    0.000    0.000    0.000    0.000 linecache.py:147(lazycache)\n",
       "      184    0.000    0.000    0.000    0.000 module.py:684(<dictcomp>)\n",
       "      586    0.000    0.000    0.000    0.000 {built-in method _CheckCalledFromGeneratedFile}\n",
       "      245    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
       "      240    0.000    0.000    0.000    0.000 sre_compile.py:539(isstring)\n",
       "      121    0.000    0.000    0.005    0.000 __init__.py:1413(get_metadata_lines)\n",
       "      385    0.000    0.000    0.000    0.000 {method '__subclasses__' of 'type' objects}\n",
       "      444    0.000    0.000    0.000    0.000 {method 'seek' of '_io.StringIO' objects}\n",
       "      245    0.000    0.000    0.000    0.000 JpegImagePlugin.py:665(validate_qtables)\n",
       "      178    0.000    0.000    0.000    0.000 inspect.py:1493(currentframe)\n",
       "    61/11    0.000    0.000    0.006    0.001 pyparsing.py:3288(leaveWhitespace)\n",
       "      399    0.000    0.000    0.000    0.000 {method 'span' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.003    0.003 core.py:21(<module>)\n",
       "       97    0.000    0.000    0.002    0.000 optimizer.py:132(<dictcomp>)\n",
       "       15    0.000    0.000    0.000    0.000 {built-in method builtins.eval}\n",
       "       57    0.000    0.000    0.000    0.000 sre_parse.py:266(getuntil)\n",
       "       91    0.000    0.000    0.001    0.000 _jit_internal.py:105(weak_script_method)\n",
       "        1    0.000    0.000    0.025    0.025 utils.py:13(get_logger)\n",
       "    32/31    0.000    0.000    0.001    0.000 typing.py:875(__extrahook__)\n",
       "      166    0.000    0.000    0.000    0.000 six.py:141(__init__)\n",
       "   117/99    0.000    0.000    0.000    0.000 sre_compile.py:414(_get_literal_prefix)\n",
       "       12    0.000    0.000    0.006    0.000 pyparsing.py:2653(__init__)\n",
       "       40    0.000    0.000    0.019    0.000 conv.py:307(__init__)\n",
       "       83    0.000    0.000    0.002    0.000 pyparsing.py:1821(__add__)\n",
       "      392    0.000    0.000    0.000    0.000 {function Config.__contains__ at 0x7f8c15d1e620}\n",
       "        1    0.000    0.000 62467.313 62467.313 interactiveshell.py:2637(safe_execfile)\n",
       "       10    0.000    0.000    0.009    0.001 ultratb.py:157(findsource)\n",
       "      148    0.000    0.000    0.000    0.000 _oid.py:58(__hash__)\n",
       "      160    0.000    0.000    0.000    0.000 __init__.py:666(__iter__)\n",
       "        1    0.000    0.000    0.017    0.017 optimizer.py:95(load_state_dict)\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:349(_populate)\n",
       "       26    0.000    0.000    0.038    0.001 pyparsing.py:2779(__init__)\n",
       "      248    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "        1    0.000    0.000    0.347    0.347 event_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.077    0.077 __init__.py:106(<module>)\n",
       "       42    0.000    0.000    0.000    0.000 pyparsing.py:2826(__str__)\n",
       "      111    0.000    0.000    0.000    0.000 _jit_internal.py:98(weak_module)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:67(getargs)\n",
       "      245    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BytesIO' objects}\n",
       "       46    0.000    0.000    0.001    0.000 record_writer.py:127(masked_crc32c)\n",
       "       86    0.000    0.000    0.004    0.000 compilerop.py:137(check_linecache_ipython)\n",
       "        1    0.000    0.000    0.000    0.000 attr_value_pb2.py:4(<module>)\n",
       "       48    0.000    0.000    0.002    0.000 pyparsing.py:3540(__init__)\n",
       "        1    0.000    0.000    0.045    0.045 extensions.py:5(<module>)\n",
       "       14    0.000    0.000    0.002    0.000 posixpath.py:393(_joinrealpath)\n",
       "       86    0.000    0.000    0.001    0.000 module.py:161(add_module)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1775(_parse_known_args)\n",
       "      198    0.000    0.000    0.000    0.000 traceback.py:290(walk_stack)\n",
       "       86    0.000    0.000    0.003    0.000 linecache.py:53(checkcache)\n",
       "      362    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
       "       10    0.000    0.000    0.006    0.001 cnf.py:12(__init__)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1364(_add_action)\n",
       "      112    0.000    0.000    0.000    0.000 os.py:742(encode)\n",
       "        1    0.000    0.000    0.003    0.003 kl.py:1(<module>)\n",
       "      266    0.000    0.000    0.000    0.000 pyparsing.py:3270(<genexpr>)\n",
       "      352    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
       "       28    0.000    0.000    0.001    0.000 tokenize.py:355(detect_encoding)\n",
       "       42    0.000    0.000    0.000    0.000 init.py:8(calculate_gain)\n",
       "        3    0.000    0.000    0.143    0.048 functional.py:1(<module>)\n",
       "      120    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 token.py:3(<module>)\n",
       "       23    0.000    0.000    0.036    0.002 record_writer.py:35(directory_check)\n",
       "       60    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:861(_find_spec_legacy)\n",
       "        1    0.000    0.000    0.323    0.323 __init__.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 layout_pb2.py:4(<module>)\n",
       "      120    0.000    0.000    0.001    0.000 pyparsing.py:2368(__init__)\n",
       "      368    0.000    0.000    0.000    0.000 module.py:1012(_get_name)\n",
       "       20    0.000    0.000    0.007    0.000 inspect.py:680(getsourcefile)\n",
       "        1    0.000    0.000    0.001    0.001 inspect.py:317(getmembers)\n",
       "        2    0.000    0.000    0.259    0.129 __init__.py:41(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:2916(extend_all)\n",
       "        1    0.000    0.000    0.001    0.001 getlimits.py:3(<module>)\n",
       "      352    0.000    0.000    0.000    0.000 inspect.py:2813(return_annotation)\n",
       "       24    0.000    0.000    0.001    0.000 container.py:187(extend)\n",
       "     19/4    0.000    0.000    0.001    0.000 pyparsing.py:3319(streamline)\n",
       "      118    0.000    0.000    0.000    0.000 enum.py:28(_is_dunder)\n",
       "       46    0.000    0.000    0.001    0.000 crc32c.py:114(crc32c)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:118(__repr__)\n",
       "      282    0.000    0.000    0.000    0.000 {method 'zfill' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd_init}\n",
       "       87    0.000    0.000    0.001    0.000 _jit_internal.py:83(weak_script)\n",
       "        1    0.000    0.000    0.045    0.045 add_newdocs.py:10(<module>)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1796(get_metadata)\n",
       "        8    0.000    0.000    0.004    0.000 traitlets.py:1407(traits)\n",
       "        1    0.000    0.000    0.017    0.017 pyparsing.py:5399(pyparsing_common)\n",
       "        1    0.000    0.000    0.009    0.009 Image.py:30(<module>)\n",
       "      302    0.000    0.000    0.000    0.000 train_cnf_disentangle.py:433(<lambda>)\n",
       "      148    0.000    0.000    0.000    0.000 utils.py:34(<lambda>)\n",
       "       28    0.000    0.000    0.013    0.000 traceback.py:200(extract_stack)\n",
       "       23    0.000    0.000    0.472    0.021 record_writer.py:46(open_file)\n",
       "        1    0.000    0.000    0.103    0.103 crypto.py:1(<module>)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:38(register_kl)\n",
       "      183    0.000    0.000    0.000    0.000 module.py:538(remove_from)\n",
       "       68    0.000    0.000    0.000    0.000 status_codes.py:111(doc)\n",
       "       10    0.000    0.000    0.013    0.001 inspect.py:1430(getframeinfo)\n",
       "       34    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
       "       27    0.000    0.000    0.004    0.000 pyparsing.py:1039(_trim_arity)\n",
       "       48    0.000    0.000    0.002    0.000 pyparsing.py:1948(__or__)\n",
       "      180    0.000    0.000    0.000    0.000 traceback.py:243(__init__)\n",
       "    82/80    0.000    0.000    0.000    0.000 pyparsing.py:372(__init__)\n",
       "       11    0.000    0.000    0.117    0.011 __init__.py:5(<module>)\n",
       "        1    0.000    0.000    0.016    0.016 __init__.py:184(<module>)\n",
       "      109    0.000    0.000    0.000    0.000 __init__.py:422(<genexpr>)\n",
       "      146    0.000    0.000    0.000    0.000 traitlets.py:545(__get__)\n",
       "        6    0.000    0.000    0.000    0.000 getlimits.py:65(__init__)\n",
       "       53    0.000    0.000    0.000    0.000 core.py:893(__init__)\n",
       "        1    0.000    0.000    0.007    0.007 subprocess.py:1208(_execute_child)\n",
       "        1    0.000    0.000    0.018    0.018 __init__.py:72(<module>)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:464(_find_new_)\n",
       "      108    0.000    0.000    0.000    0.000 utils.py:33(read_only_property)\n",
       "        1    0.000    0.000    0.001    0.001 _torch_docs.py:1(<module>)\n",
       "       98    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
       "        1    0.000    0.000    0.001    0.001 _tensor_docs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:180(ConcatSquashConv2d)\n",
       "       24    0.000    0.000    0.001    0.000 traitlets.py:516(instance_init)\n",
       "      315    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
       "      127    0.000    0.000    0.000    0.000 typing.py:1019(_abc_negative_cache)\n",
       "      138    0.000    0.000    0.000    0.000 argparse.py:1282(_registry_get)\n",
       "       68    0.000    0.000    0.002    0.000 posixpath.py:168(islink)\n",
       "       23    0.000    0.000    0.010    0.000 event_file_writer.py:54(write_event)\n",
       "      107    0.000    0.000    0.004    0.000 module.py:260(<lambda>)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1555(_add_action)\n",
       "      245    0.000    0.000    0.000    0.000 {method '__contains__' of 'frozenset' objects}\n",
       "      194    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:237(SummaryWriter)\n",
       "        2    0.000    0.000    0.005    0.003 ec.py:5(<module>)\n",
       "        1    0.000    0.000    0.049    0.049 backend.py:5(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 core.py:47(<module>)\n",
       "       42    0.000    0.000    0.001    0.000 init.py:50(uniform_)\n",
       "       31    0.000    0.000    0.000    0.000 enum.py:419(_get_mixins_)\n",
       "       23    0.000    0.000    0.527    0.023 writer.py:162(__init__)\n",
       "      189    0.000    0.000    0.000    0.000 status_codes.py:112(<genexpr>)\n",
       "      109    0.000    0.000    0.000    0.000 __init__.py:420(<genexpr>)\n",
       "      103    0.000    0.000    0.000    0.000 TiffTags.py:26(__new__)\n",
       "      252    0.000    0.000    0.000    0.000 six.py:88(__init__)\n",
       "        1    0.000    0.000    0.006    0.006 __init__.py:57(<module>)\n",
       "       23    0.000    0.000    0.001    0.000 event_file_writer.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:299(_add_aliases)\n",
       "       90    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
       "       38    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "        8    0.000    0.000    0.011    0.001 configurable.py:38(__init__)\n",
       "        1    0.000    0.000    0.190    0.190 __init__.py:3126(_initialize_master_working_set)\n",
       "      277    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.add_docstring}\n",
       "       26    0.000    0.000    0.000    0.000 numerictypes.py:229(bitname)\n",
       "       80    0.000    0.000    0.001    0.000 configurable.py:99(section_names)\n",
       "       23    0.000    0.000    0.472    0.021 record_writer.py:105(__init__)\n",
       "      149    0.000    0.000    0.000    0.000 utils.py:37(register_interface)\n",
       "       98    0.000    0.000    0.000    0.000 parameter.py:23(__new__)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:71(<lambda>)\n",
       "      132    0.000    0.000    0.000    0.000 {method 'mro' of 'type' objects}\n",
       "      194    0.000    0.000    0.000    0.000 __init__.py:231(__exit__)\n",
       "      2/1    0.000    0.000    0.001    0.001 copy.py:210(_deepcopy_list)\n",
       "      118    0.000    0.000    0.000    0.000 enum.py:36(_is_sunder)\n",
       "    27/24    0.000    0.000    0.179    0.007 <frozen importlib._bootstrap_external>:919(create_module)\n",
       "       60    0.000    0.000    0.000    0.000 pyparsing.py:1351(preParse)\n",
       "       42    0.000    0.000    0.001    0.000 init.py:251(_calculate_correct_fan)\n",
       "       20    0.000    0.000    0.000    0.000 inspect.py:643(getfile)\n",
       "       73    0.000    0.000    0.000    0.000 sre_compile.py:441(_get_charset_prefix)\n",
       "       86    0.000    0.000    0.000    0.000 six.py:105(__init__)\n",
       "      100    0.000    0.000    0.000    0.000 six.py:177(_add_module)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:580(_format_args)\n",
       "       44    0.000    0.000    0.000    0.000 posixpath.py:64(isabs)\n",
       "       25    0.000    0.000    0.004    0.000 pyparsing.py:1250(setParseAction)\n",
       "        1    0.000    0.000    0.003    0.003 numeric.py:1(<module>)\n",
       "      245    0.000    0.000    0.000    0.000 {method 'close' of '_io.BytesIO' objects}\n",
       "       61    0.000    0.000    0.005    0.000 pyparsing.py:3292(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:174(add_param_group)\n",
       "       88    0.000    0.000    0.000    0.000 typing.py:1033(_abc_negative_cache_version)\n",
       "       42    0.000    0.000    0.000    0.000 contextlib.py:157(helper)\n",
       "      164    0.000    0.000    0.000    0.000 abc.py:9(abstractmethod)\n",
       "        1    0.000    0.000    0.007    0.007 TiffImagePlugin.py:42(<module>)\n",
       "     10/2    0.000    0.000    0.002    0.001 pyparsing.py:3397(parseImpl)\n",
       "       67    0.000    0.000    0.000    0.000 auto.py:95(_find_buffers)\n",
       "      128    0.000    0.000    0.000    0.000 typing.py:1089(__eq__)\n",
       "        1    0.000    0.000    0.072    0.072 requirements.py:4(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 modules.py:283(sample)\n",
       "       60    0.000    0.000    0.000    0.000 enum.py:20(_is_descriptor)\n",
       "       26    0.000    0.000    0.003    0.000 pyparsing.py:1047(extract_stack)\n",
       "        2    0.000    0.000    0.064    0.032 base.py:5(<module>)\n",
       "       42    0.000    0.000    0.000    0.000 contextlib.py:59(__init__)\n",
       "        2    0.000    0.000    0.006    0.003 {built-in method builtins.sum}\n",
       "      220    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "        1    0.000    0.000    0.003    0.003 oid.py:5(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 markers.py:4(<module>)\n",
       "      159    0.000    0.000    0.000    0.000 __init__.py:919(_added_new)\n",
       "        1    0.000    0.000    0.003    0.003 tensor_pb2.py:4(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 descriptor.py:281(__new__)\n",
       "      170    0.000    0.000    0.000    0.000 pyparsing.py:2061(setWhitespaceChars)\n",
       "       69    0.000    0.000    0.000    0.000 status_codes.py:117(<genexpr>)\n",
       "       11    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "       28    0.000    0.000    0.000    0.000 pyparsing.py:3997(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:930(__init__)\n",
       "        1    0.000    0.000    0.034    0.034 odenvp_conditional_tol.py:21(__init__)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1161(getLogger)\n",
       "       49    0.000    0.000    0.000    0.000 codecs.py:308(__init__)\n",
       "        1    0.000    0.000    0.359    0.359 writer.py:15(<module>)\n",
       "       32    0.000    0.000    0.000    0.000 traitlets.py:1067(hold_trait_notifications)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:294(IFDRational)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:409(_init)\n",
       "       30    0.000    0.000    0.001    0.000 contextlib.py:129(contextmanager)\n",
       "      113    0.000    0.000    0.000    0.000 descriptor.py:690(__new__)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:98(getargspec)\n",
       "        1    0.000    0.000    0.001    0.001 SSL.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2710(MaskedArray)\n",
       "        1    0.000    0.000    0.002    0.002 lapack.py:461(<module>)\n",
       "       55    0.000    0.000    0.000    0.000 argparse.py:835(__init__)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:114(__prepare__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.Cryptography_add_osrandom_engine}\n",
       "       82    0.000    0.000    0.000    0.000 types.py:135(__get__)\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:85(RegisterMessageDescriptor)\n",
       "      195    0.000    0.000    0.000    0.000 pyparsing.py:3392(<genexpr>)\n",
       "       23    0.000    0.000    0.010    0.000 event_file_writer.py:63(_write_serialized_event)\n",
       "       51    0.000    0.000    0.000    0.000 _internal.py:715(_ufunc_doc_signature_formatter)\n",
       "        2    0.000    0.000    0.000    0.000 traceback.py:367(from_list)\n",
       "       22    0.000    0.000    0.001    0.000 posixpath.py:369(abspath)\n",
       "       69    0.000    0.000    0.000    0.000 __init__.py:1265(<lambda>)\n",
       "        1    0.000    0.000    0.002    0.002 npyio.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _methods.py:5(<module>)\n",
       "       97    0.000    0.000    0.000    0.000 pyparsing.py:4781(<genexpr>)\n",
       "       82    0.000    0.000    0.000    0.000 pyparsing.py:363(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:37(<listcomp>)\n",
       "        3    0.000    0.000    0.116    0.039 __init__.py:6(<module>)\n",
       "      188    0.000    0.000    0.000    0.000 __init__.py:2498(_reload_version)\n",
       "      194    0.000    0.000    0.000    0.000 __init__.py:223(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}\n",
       "        2    0.000    0.000    0.005    0.002 dsa.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:5(<module>)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1480(_pop_action_class)\n",
       "      183    0.000    0.000    0.000    0.000 {method '__subclasshook__' of 'object' objects}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:50(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 interfaces.py:5(<module>)\n",
       "        3    0.000    0.000    0.019    0.006 __init__.py:3(<module>)\n",
       "       45    0.000    0.000    0.000    0.000 pyparsing.py:1190(setName)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3037(_find_adapter)\n",
       "        1    0.000    0.000    0.000    0.000 stringprep.py:6(<module>)\n",
       "    36/11    0.000    0.000    0.008    0.001 pyparsing.py:3743(leaveWhitespace)\n",
       "        1    0.000    0.000    0.001    0.001 tarfile.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:120(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _ctypes.dlopen}\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:2234(_get_values)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:204(iterencode)\n",
       "        1    0.000    0.000    0.019    0.019 cookiejar.py:26(<module>)\n",
       "      168    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
       "       82    0.000    0.000    0.000    0.000 symbol_database.py:68(RegisterMessage)\n",
       "       20    0.000    0.000    0.000    0.000 pyparsing.py:2813(parseImpl)\n",
       "        1    0.000    0.000    0.160    0.160 pyopenssl.py:43(<module>)\n",
       "       16    0.000    0.000    0.010    0.001 traitlets.py:558(set)\n",
       "        1    0.000    0.000    0.001    0.001 node_def_pb2.py:4(<module>)\n",
       "      222    0.000    0.000    0.000    0.000 module.py:1015(extra_repr)\n",
       "       98    0.000    0.000    0.000    0.000 traitlets.py:526(get)\n",
       "       44    0.000    0.000    0.001    0.000 core.py:149(get_object_signature)\n",
       "        1    0.000    0.000    0.031    0.031 ultratb.py:820(format_records)\n",
       "       42    0.000    0.000    0.000    0.000 contextlib.py:85(__exit__)\n",
       "        1    0.000    0.000    0.678    0.678 workspace.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:720(DataLoader)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:1822(take_action)\n",
       "       32    0.000    0.000    0.000    0.000 tokenize.py:385(find_cookie)\n",
       "       96    0.000    0.000    0.000    0.000 pyparsing.py:2153(__str__)\n",
       "       71    0.000    0.000    0.000    0.000 kl.py:69(decorator)\n",
       "        7    0.000    0.000    0.000    0.000 inspect.py:1251(formatargvalues)\n",
       "       26    0.000    0.000    0.000    0.000 sre_compile.py:393(_generate_overlap_table)\n",
       "        1    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:4875(_makeTags)\n",
       "        1    0.000    0.000    0.053    0.053 interactiveshell.py:1981(showtraceback)\n",
       "     20/8    0.000    0.000    0.001    0.000 pyparsing.py:3547(parseImpl)\n",
       "      188    0.000    0.000    0.000    0.000 pyparsing.py:2656(<genexpr>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2707(parseImpl)\n",
       "        2    0.000    0.000    0.061    0.031 mnist.py:39(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 response.py:1(<module>)\n",
       "        2    0.000    0.000    0.007    0.004 transforms.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:83(<module>)\n",
       "        8    0.000    0.000    0.001    0.000 utils.py:1(<module>)\n",
       "     15/1    0.000    0.000    0.001    0.001 jsonutil.py:109(json_clean)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(<listcomp>)\n",
       "       10    0.000    0.000    0.001    0.000 odefunc.py:257(__init__)\n",
       "       56    0.000    0.000    0.001    0.000 argparse.py:2352(_get_formatter)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1212(_fixupParents)\n",
       "       10    0.000    0.000    0.000    0.000 sre_compile.py:381(_bytes_to_codes)\n",
       "       27    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:927(exec_module)\n",
       "       14    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:433(spec_from_loader)\n",
       "        1    0.000    0.000    0.021    0.021 tokenize.py:26(<module>)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:564(_metavar_formatter)\n",
       "        1    0.000    0.000    0.002    0.002 resource_handle_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 general_name.py:5(<module>)\n",
       "        1    0.000    0.000    0.024    0.024 keys.py:15(<module>)\n",
       "        3    0.000    0.000    0.346    0.115 tarfile.py:1411(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 extras.py:10(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:61(__new__)\n",
       "       80    0.000    0.000    0.000    0.000 inspect.py:690(<genexpr>)\n",
       "       23    0.000    0.000    0.000    0.000 pyparsing.py:2742(__str__)\n",
       "       14    0.000    0.000    0.003    0.000 __init__.py:2232(normalize_path)\n",
       "      138    0.000    0.000    0.000    0.000 record_writer.py:132(u32)\n",
       "        2    0.000    0.000    0.008    0.004 connection.py:1(<module>)\n",
       "       60    0.000    0.000    0.000    0.000 activation.py:617(extra_repr)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6573(getdoc)\n",
       "        2    0.000    0.000    0.007    0.004 ocsp.py:5(<module>)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:109(has_argument)\n",
       "       30    0.000    0.000    0.000    0.000 inspect.py:64(ismodule)\n",
       "       18    0.000    0.000    0.000    0.000 copyreg.py:96(_slotnames)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:857(<listcomp>)\n",
       "       15    0.000    0.000    0.000    0.000 pyparsing.py:4565(_escapeRegexRangeChars)\n",
       "      8/6    0.000    0.000    0.006    0.001 __init__.py:2159(declare_namespace)\n",
       "        1    0.000    0.000    0.003    0.003 modes.py:5(<module>)\n",
       "        1    0.000    0.000    0.011    0.011 _big_num_ctypes.py:20(<module>)\n",
       "        3    0.000    0.000    0.033    0.011 odenvp_conditional_tol.py:181(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 types_pb2.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:98(_Boolean)\n",
       "       24    0.000    0.000    0.002    0.000 container.py:119(__init__)\n",
       "       82    0.000    0.000    0.000    0.000 backend.py:13(register_function)\n",
       "      101    0.000    0.000    0.000    0.000 _inspect.py:133(strseq)\n",
       "       40    0.000    0.000    0.000    0.000 loader.py:161(__init__)\n",
       "       24    0.000    0.000    0.000    0.000 traitlets.py:587(_validate)\n",
       "        1    0.000    0.000    0.000    0.000 shutil.py:1093(which)\n",
       "       72    0.000    0.000    0.000    0.000 functools.py:74(wraps)\n",
       "        1    0.000    0.000    0.037    0.037 utils.py:9(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 activation.py:1(<module>)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:793(__init__)\n",
       "      102    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3050(Sequence)\n",
       "       26    0.000    0.000    0.000    0.000 argparse.py:2286(_get_value)\n",
       "        2    0.000    0.000    0.001    0.001 function_base.py:1(<module>)\n",
       "       24    0.000    0.000    0.001    0.000 __init__.py:1870(find_distributions)\n",
       "       13    0.000    0.000    0.000    0.000 __init__.py:1268(__init__)\n",
       "        3    0.000    0.000    0.003    0.001 distributed.py:1(<module>)\n",
       "        2    0.000    0.000    0.007    0.004 rsa.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:272(<setcomp>)\n",
       "        1    0.000    0.000    0.010    0.010 util.py:150(_get_soname)\n",
       "       22    0.000    0.000    0.001    0.000 argparse.py:1843(consume_optional)\n",
       "        3    0.000    0.000    0.040    0.013 _util.py:1(<module>)\n",
       "        3    0.000    0.000    0.007    0.002 __init__.py:15(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 hashes.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:39(EllipticCurveSignatureAlgorithm)\n",
       "        1    0.000    0.000    0.014    0.014 connectionpool.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 loss.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1740(parse_known_args)\n",
       "        8    0.000    0.000    0.009    0.001 configurable.py:170(_config_changed)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:3120(<genexpr>)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:2050(_match_argument)\n",
       "       74    0.000    0.000    0.000    0.000 {method 'readline' of '_io.StringIO' objects}\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:83(<listcomp>)\n",
       "       16    0.000    0.000    0.001    0.000 __init__.py:1813(get_metadata_lines)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method zeros_like}\n",
       "        1    0.000    0.000    0.001    0.001 blas.py:202(<module>)\n",
       "       50    0.000    0.000    0.000    0.000 inspect.py:239(isframe)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:1(<module>)\n",
       "        6    0.000    0.000    0.002    0.000 warnings.py:119(filterwarnings)\n",
       "       60    0.000    0.000    0.000    0.000 {method 'copy' of 'mappingproxy' objects}\n",
       "       92    0.000    0.000    0.000    0.000 {method 'write' of '_io.BufferedWriter' objects}\n",
       "        1    0.000    0.000    0.000    0.000 versions_pb2.py:4(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 {method 'FindMessageTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       25    0.000    0.000    0.000    0.000 typing.py:1039(_abc_negative_cache_version)\n",
       "       42    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3439(<genexpr>)\n",
       "        1    0.000    0.000    0.006    0.006 cookies.py:127(<module>)\n",
       "       17    0.000    0.000    0.000    0.000 ocsp.py:25(_requires_successful_response)\n",
       "       62    0.000    0.000    0.000    0.000 numerictypes.py:127(english_lower)\n",
       "        4    0.000    0.000    0.000    0.000 getlimits.py:376(__new__)\n",
       "        8    0.000    0.000    0.005    0.001 configurable.py:131(_load_config)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:573(format)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method torch.cuda._get_device_properties}\n",
       "        1    0.000    0.000    0.022    0.022 grammar.py:13(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 algos.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:185(CertificateRevocationList)\n",
       "        2    0.000    0.000    0.004    0.002 rnn.py:1(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 {built-in method _socket.gethostname}\n",
       "        1    0.000    0.000    0.047    0.047 ultratb.py:1056(format_exception_as_a_whole)\n",
       "       53    0.000    0.000    0.000    0.000 inspect.py:81(ismethod)\n",
       "       30    0.000    0.000    0.000    0.000 sre_parse.py:257(getwhile)\n",
       "        1    0.000    0.000    0.002    0.002 graph_pb2.py:4(<module>)\n",
       "       10    0.000    0.000    0.026    0.003 odenvp_conditional_tol.py:196(_make_odefunc)\n",
       "        1    0.000    0.000    0.001    0.001 poolmanager.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:174(nti)\n",
       "       78    0.000    0.000    0.000    0.000 _internal.py:726(<genexpr>)\n",
       "        1    0.000    0.000    0.006    0.006 zmqshell.py:538(_showtraceback)\n",
       "        1    0.000    0.000    0.016    0.016 ultratb.py:343(_fixed_getinnerframes)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:466(find)\n",
       "       31    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n",
       "        1    0.000    0.000    0.007    0.007 subprocess.py:588(__init__)\n",
       "       24    0.000    0.000    0.001    0.000 re.py:169(match)\n",
       "      139    0.000    0.000    0.000    0.000 pyparsing.py:3543(<genexpr>)\n",
       "       25    0.000    0.000    0.000    0.000 typing.py:1025(_abc_negative_cache)\n",
       "        3    0.000    0.000    0.001    0.000 utils.py:5(<module>)\n",
       "       94    0.000    0.000    0.000    0.000 pyparsing.py:4890(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 cookiejar.py:1224(CookieJar)\n",
       "       49    0.000    0.000    0.000    0.000 py3compat.py:28(cast_unicode)\n",
       "       38    0.000    0.000    0.001    0.000 pyparsing.py:4230(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 models.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:5(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "       12    0.000    0.000    0.008    0.001 pyparsing.py:4251(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:4757(<lambda>)\n",
       "        1    0.000    0.000    0.001    0.001 distributed_c10d.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 utils.py:4(<module>)\n",
       "        1    0.000    0.000    0.040    0.040 odefunc.py:1(<module>)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1713(_add_action)\n",
       "       40    0.000    0.000    0.000    0.000 {method '__getitem__' of 'dict' objects}\n",
       "        1    0.000    0.000    0.038    0.038 binding.py:5(<module>)\n",
       "       23    0.000    0.000    0.000    0.000 utils.py:112(__init__)\n",
       "        4    0.000    0.000    0.001    0.000 core.py:126(doc_note)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:365(__getitem__)\n",
       "       42    0.000    0.000    0.000    0.000 contextlib.py:79(__enter__)\n",
       "       95    0.000    0.000    0.000    0.000 pyparsing.py:203(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:663(__iadd__)\n",
       "        1    0.000    0.000    0.005    0.005 plistlib.py:47(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 serialization.py:5(<module>)\n",
       "        1    0.000    0.000    0.105    0.105 thnn.py:21(_initialize_backend)\n",
       "        2    0.000    0.000    0.000    0.000 util.py:301(_findLib_prefix)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "        2    0.000    0.000    0.000    0.000 shutil.py:1048(get_terminal_size)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:760(_missing_)\n",
       "      102    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
       "    14/13    0.000    0.000    0.045    0.003 <frozen importlib._bootstrap>:622(_load_backward_compatible)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:52(__new__)\n",
       "        1    0.000    0.000    0.001    0.001 socks.py:55(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 optimizer.py:32(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 pooling.py:1(<module>)\n",
       "        2    0.000    0.000    0.008    0.004 __init__.py:45(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:285(_add_types)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:202(__init__)\n",
       "       60    0.000    0.000    0.000    0.000 inspect.py:687(<genexpr>)\n",
       "       11    0.000    0.000    0.001    0.000 six.py:91(__get__)\n",
       "       50    0.000    0.000    0.000    0.000 six.py:184(find_module)\n",
       "        2    0.000    0.000    0.000    0.000 pygram.py:22(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:4(<module>)\n",
       "       41    0.000    0.000    0.000    0.000 pyparsing.py:3581(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 matfuncs.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 encode_asn1.py:5(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 serialization.py:1(<module>)\n",
       "       62    0.000    0.000    0.000    0.000 _inspect.py:146(<lambda>)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:70(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1226(__init__)\n",
       "       60    0.000    0.000    0.000    0.000 six.py:835(add_metaclass)\n",
       "        1    0.000    0.000    0.002    0.002 summary.py:30(<module>)\n",
       "        2    0.000    0.000    0.004    0.002 dh.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:5(Parameter)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:296(get_device_properties)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:74(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2923(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 inspect.py:1026(_getfullargs)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:988(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 type_checkers.py:44(<module>)\n",
       "       43    0.000    0.000    0.000    0.000 caffe2_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.005    0.005 __init__.py:206(_sanity_check)\n",
       "        8    0.000    0.000    0.011    0.001 PyColorize.py:180(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 inspect.py:1180(getargvalues)\n",
       "        3    0.000    0.000    0.001    0.000 _utils.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 normalization.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:225(_register_default_ciphers)\n",
       "        1    0.000    0.000    0.000    0.000 ssl_.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:88(<module>)\n",
       "        1    0.000    0.000    0.013    0.013 inspect.py:1481(getinnerframes)\n",
       "        4    0.000    0.000    0.366    0.091 __init__.py:2(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 adapters.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:170(<dictcomp>)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:331(device_count)\n",
       "       27    0.000    0.000    0.000    0.000 core.py:920(__init__)\n",
       "       16    0.000    0.000    0.001    0.000 traitlets.py:1690(instance_init)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:771(__init__)\n",
       "        1    0.000    0.000    0.004    0.004 sessions.py:9(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 sbcsgroupprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 function.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:59(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 fromnumeric.py:3(<module>)\n",
       "       16    0.000    0.000    0.010    0.001 traitlets.py:1133(_notify_trait)\n",
       "       40    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
       "       15    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
       "        3    0.000    0.000    0.346    0.115 serialization.py:448(legacy_load)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:340(_add_integer_aliases)\n",
       "        1    0.000    0.000    0.062    0.062 train_cnf_disentangle.py:162(get_dataset)\n",
       "        8    0.000    0.000    0.000    0.000 inspect.py:1016(getargs)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1838(getLogger)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2263(_is_unpacked_egg)\n",
       "        1    0.000    0.000    0.001    0.001 certificate_transparency.py:5(<module>)\n",
       "        1    0.000    0.000    0.011    0.011 mbcsgroupprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:113(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 gettext.py:205(_expand_lang)\n",
       "       40    0.000    0.000    0.000    0.000 inspect.py:229(istraceback)\n",
       "       35    0.000    0.000    0.000    0.000 enum.py:822(_high_bit)\n",
       "       14    0.000    0.000    0.003    0.000 posixpath.py:384(realpath)\n",
       "       24    0.000    0.000    0.000    0.000 genericpath.py:27(isfile)\n",
       "       49    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
       "        2    0.000    0.000    0.358    0.179 __init__.py:33(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:2863(__init__)\n",
       "       23    0.000    0.000    0.000    0.000 writer.py:53(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 _tqdm.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:5(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 idna.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:86(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:59(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 __init__.py:88(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 index_tricks.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 ImageFilter.py:18(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 re.py:249(escape)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:4(<module>)\n",
       "       61    0.000    0.000    0.000    0.000 pyparsing.py:2159(streamline)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1103(ParserElement)\n",
       "       24    0.000    0.000    0.000    0.000 __init__.py:1793(has_metadata)\n",
       "        1    0.000    0.000    0.001    0.001 decomp_schur.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 constraint_registry.py:66(<module>)\n",
       "        1    0.000    0.000    0.103    0.103 auto.py:1(<module>)\n",
       "        3    0.000    0.000    0.346    0.115 tarfile.py:2276(next)\n",
       "       26    0.000    0.000    0.000    0.000 traceback.py:273(__getitem__)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:65(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 enum.py:874(_power_of_two)\n",
       "        3    0.000    0.000    0.004    0.001 misc.py:1(<module>)\n",
       "       28    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
       "       84    0.000    0.000    0.000    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
       "       13    0.000    0.000    0.000    0.000 {method 'FindEnumTypeByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        4    0.000    0.000    0.006    0.001 mnist.py:90(_check_exists)\n",
       "        1    0.000    0.000    0.004    0.004 chardistribution.py:28(<module>)\n",
       "       38    0.000    0.000    0.000    0.000 constraint_registry.py:86(register)\n",
       "       31    0.000    0.000    0.000    0.000 auto.py:118(<listcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 mixins.py:20(_binary_method)\n",
       "        1    0.000    0.000    0.016    0.016 tsit5.py:1(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:2190(_get_nargs_pattern)\n",
       "        8    0.000    0.000    0.003    0.000 traitlets.py:950(__new__)\n",
       "       16    0.000    0.000    0.000    0.000 _collections_abc.py:664(__contains__)\n",
       "       42    0.000    0.000    0.000    0.000 {method 'expandtabs' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 algorithms.py:5(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 core.py:1(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:147(deprecated)\n",
       "       23    0.000    0.000    0.000    0.000 numerictypes.py:216(_evalname)\n",
       "       56    0.000    0.000    0.000    0.000 argparse.py:1493(_check_conflict)\n",
       "       20    0.000    0.000    0.000    0.000 os.py:746(decode)\n",
       "        1    0.000    0.000    0.001    0.001 TiffTags.py:20(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 name.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:126(EventHandle)\n",
       "       40    0.000    0.000    0.000    0.000 numerictypes.py:154(english_upper)\n",
       "        4    0.000    0.000    0.000    0.000 jsonapi.py:31(dumps)\n",
       "       11    0.000    0.000    0.000    0.000 __init__.py:358(__getattr__)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
       "       38    0.000    0.000    0.000    0.000 inspect.py:253(iscode)\n",
       "       48    0.000    0.000    0.000    0.000 tokenize.py:739(generate_tokens)\n",
       "        1    0.000    0.000    0.001    0.001 decoder.py:79(<module>)\n",
       "       82    0.000    0.000    0.000    0.000 {method 'AddDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        6    0.000    0.000    0.045    0.007 __init__.py:35(load_module)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:126(_EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.019    0.019 universaldetector.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:11(<module>)\n",
       "        3    0.000    0.000    0.006    0.002 container.py:1(<module>)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:28(isfunction)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:766(_construct_lookups)\n",
       "       48    0.000    0.000    0.000    0.000 traitlets.py:1047(cross_validation_lock)\n",
       "       59    0.000    0.000    0.000    0.000 enum.py:594(name)\n",
       "        1    0.000    0.000    0.001    0.001 PngImagePlugin.py:34(<module>)\n",
       "        3    0.000    0.000    0.002    0.001 __init__.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:48(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp.py:15(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 x509.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1082(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:308(init_reductions)\n",
       "        2    0.000    0.000    0.000    0.000 linear.py:47(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:1024(frombuf)\n",
       "       26    0.000    0.000    0.001    0.000 core.py:6568(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:63(NDArrayOperatorsMixin)\n",
       "        1    0.000    0.000    0.001    0.001 case.py:1(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 _internal.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:17(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 modules.py:96(__init__)\n",
       "       10    0.000    0.000    0.001    0.000 cnf_regularization.py:6(__init__)\n",
       "        8    0.000    0.000    0.003    0.000 traitlets.py:982(setup_instance)\n",
       "       46    0.000    0.000    0.000    0.000 inspect.py:358(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 weakref.py:102(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 shape_base.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.putenv}\n",
       "       16    0.000    0.000    0.001    0.000 pyparsing.py:1204(setResultsName)\n",
       "        1    0.000    0.000    0.000    0.000 filepost.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 sparse.py:1(<module>)\n",
       "       27    0.000    0.000    0.000    0.000 auto.py:339(make_default_double_backwards_fn)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:146(rng)\n",
       "       34    0.000    0.000    0.000    0.000 argparse.py:1278(register)\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:219(_acquireLock)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
       "       10    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:980(_recalculate)\n",
       "        1    0.000    0.000    0.009    0.009 JpegImagePlugin.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:4(<module>)\n",
       "       16    0.000    0.000    0.002    0.000 descriptor.py:869(__new__)\n",
       "       78    0.000    0.000    0.000    0.000 pyparsing.py:2052(leaveWhitespace)\n",
       "        1    0.000    0.000    0.000    0.000 parser.py:12(<module>)\n",
       "        1    0.000    0.000    0.017    0.017 _int.py:32(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 util.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:2(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 profiler.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 polynomial.py:56(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 getlimits.py:18(_fr0)\n",
       "       23    0.000    0.000    0.000    0.000 queue.py:199(_init)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.unsetenv}\n",
       "        1    0.000    0.000    0.003    0.003 fixer_util.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:3935(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 pyparsing.py:209(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:11(ExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:29(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 exceptions.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 linalg.py:10(<module>)\n",
       "       30    0.000    0.000    0.000    0.000 getlimits.py:26(_fr1)\n",
       "        1    0.000    0.000    0.001    0.001 rk_common.py:2(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 traitlets.py:596(_cross_validate)\n",
       "       23    0.000    0.000    0.000    0.000 threading.py:1136(daemon)\n",
       "       32    0.000    0.000    0.001    0.000 tokenize.py:379(read_or_stop)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:976(_get_parent_path)\n",
       "        1    0.000    0.000    0.005    0.005 pytorch_graph.py:1(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 pyparsing.py:3576(__str__)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:4763(srange)\n",
       "        1    0.000    0.000    0.000    0.000 _solvers.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 basic.py:7(<module>)\n",
       "        2    0.000    0.000    0.005    0.002 mnist.py:94(download)\n",
       "        1    0.000    0.000    0.002    0.002 bernoulli.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 tensor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:94(_check_capability)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method from_numpy}\n",
       "       18    0.000    0.000    0.000    0.000 core.py:996(__init__)\n",
       "        1    0.000    0.000    0.011    0.011 __init__.py:7(<module>)\n",
       "        1    0.000    0.000    0.048    0.048 odeint.py:1(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:1950(<listcomp>)\n",
       "       40    0.000    0.000    0.000    0.000 loader.py:165(_ensure_subconfig)\n",
       "        1    0.000    0.000    0.000    0.000 proto_graph.py:1(<module>)\n",
       "        1    0.000    0.000    0.010    0.010 descriptor.py:33(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3130(LineStart)\n",
       "        1    0.000    0.000    0.003    0.003 socks.py:23(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mbcssm.py:28(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:238(__init__)\n",
       "        8    0.000    0.000    0.009    0.001 traitlets.py:805(compatible_observer)\n",
       "       40    0.000    0.000    0.000    0.000 traitlets.py:911(__get__)\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:228(_releaseLock)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:135(<dictcomp>)\n",
       "       15    0.000    0.000    0.000    0.000 enum.py:312(__getattr__)\n",
       "        7    0.000    0.000    0.000    0.000 TiffImagePlugin.py:635(_register_basic)\n",
       "       34    0.000    0.000    0.000    0.000 descriptor_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.033    0.033 odenvp_conditional_tol.py:65(_build_net)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'AddEnumDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3781(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:294(socksocket)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:22(SignedCertificateTimestamp)\n",
       "       21    0.000    0.000    0.000    0.000 utils.py:126(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:19(ABCPolyBase)\n",
       "       22    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.empty}\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:118(deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:369(_set_up_aliases)\n",
       "       30    0.000    0.000    0.000    0.000 numerictypes.py:432(_add_array_type)\n",
       "        1    0.000    0.000    0.001    0.001 session.py:657(send)\n",
       "        1    0.000    0.000    0.016    0.016 ultratb.py:307(wrapped)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:321(fix_frame_records_filenames)\n",
       "       18    0.000    0.000    0.000    0.000 inspect.py:1262(convert)\n",
       "       21    0.000    0.000    0.000    0.000 __init__.py:190(_checkLevel)\n",
       "       27    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:908(__init__)\n",
       "       20    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}\n",
       "       73    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "        1    0.000    0.000    0.004    0.004 fractions.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:84(<listcomp>)\n",
       "     15/4    0.000    0.000    0.000    0.000 pyparsing.py:3762(streamline)\n",
       "       16    0.000    0.000    0.005    0.000 __init__.py:2006(safe_listdir)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:11(<module>)\n",
       "        1    0.000    0.000    0.030    0.030 compat.py:9(<module>)\n",
       "        2    0.000    0.000    0.001    0.001 x25519.py:5(<module>)\n",
       "        5    0.000    0.000    0.033    0.007 binding.py:122(_ensure_ffi_initialized)\n",
       "       24    0.000    0.000    0.001    0.000 container.py:159(__iadd__)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:1(<module>)\n",
       "        1    0.000    0.000    0.019    0.019 __init__.py:147(_lazy_init)\n",
       "       10    0.000    0.000    0.000    0.000 extras.py:242(getdoc)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:332(<dictcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:251(_get_machar)\n",
       "        5    0.000    0.000    0.000    0.000 getlimits.py:507(__init__)\n",
       "        1    0.000    0.000    0.034    0.034 train_cnf_disentangle.py:312(create_model)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:73(CFUNCTYPE)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:332(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:1(<module>)\n",
       "       49    0.000    0.000    0.000    0.000 reduction.py:43(register)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1020(prepare_header)\n",
       "        8    0.000    0.000    0.000    0.000 loader.py:182(merge)\n",
       "        3    0.000    0.000    0.001    0.000 re.py:179(search)\n",
       "        2    0.000    0.000    0.001    0.001 request.py:1(<module>)\n",
       "       18    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "        1    0.000    0.000    0.006    0.006 text_format.py:41(<module>)\n",
       "     12/2    0.000    0.000    0.000    0.000 pyparsing.py:1926(makeOptionalList)\n",
       "        8    0.000    0.000    0.000    0.000 six.py:195(load_module)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 adam.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:5(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:20(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:54(with_metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2931(__array_finalize__)\n",
       "       44    0.000    0.000    0.000    0.000 _inspect.py:15(ismethod)\n",
       "       39    0.000    0.000    0.000    0.000 _inspect.py:43(iscode)\n",
       "        8    0.000    0.000    0.000    0.000 ultratb.py:968(<listcomp>)\n",
       "       16    0.000    0.000    0.010    0.001 traitlets.py:576(__set__)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:746(__exit__)\n",
       "        1    0.000    0.000    0.001    0.001 pygram.py:4(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 descriptor.py:635(__new__)\n",
       "       10    0.000    0.000    0.000    0.000 __init__.py:23(find_module)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:89(_OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:52(NameOID)\n",
       "        1    0.000    0.000    0.017    0.017 _elliptic_curve.py:47(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 _iri.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:10(Geometric)\n",
       "        1    0.000    0.000    0.001    0.001 constraints.py:19(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:1(<module>)\n",
       "        3    0.000    0.000    0.346    0.115 tarfile.py:1087(fromtarfile)\n",
       "        3    0.000    0.000    0.346    0.115 tarfile.py:1522(open)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:239(manager_path)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:7(<module>)\n",
       "       36    0.000    0.000    0.000    0.000 getlimits.py:69(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 train_cnf_disentangle.py:163(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:65(__init__)\n",
       "       44    0.000    0.000    0.000    0.000 argparse.py:2087(_parse_optional)\n",
       "       17    0.000    0.000    0.000    0.000 __init__.py:685(__init__)\n",
       "       46    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._tracer_warn_use_python}\n",
       "        2    0.000    0.000    0.001    0.000 grammar.py:105(load)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:49(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 well_known_types.py:39(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:116(RegisterFileDescriptor)\n",
       "     16/2    0.000    0.000    0.001    0.001 pyparsing.py:3737(parseImpl)\n",
       "       24    0.000    0.000    0.000    0.000 pyparsing.py:411(__getitem__)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:2751(charsAsStr)\n",
       "    13/12    0.000    0.000    0.000    0.000 pyparsing.py:3434(__str__)\n",
       "        1    0.000    0.000    0.004    0.004 train_misc.py:1(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 _main.py:1(<module>)\n",
       "        2    0.000    0.000    0.006    0.003 resnet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 sjisprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:74(_check_cryptography)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:9(parse_kwargs)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 _version.py:55(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:183(dumps)\n",
       "        1    0.000    0.000    0.001    0.001 GifImagePlugin.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:411(ImageFileDirectory_v2)\n",
       "        1    0.000    0.000    0.003    0.003 text_format.py:1006(Tokenizer)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4781(<lambda>)\n",
       "        1    0.000    0.000    0.030    0.030 specifiers.py:4(<module>)\n",
       "       16    0.000    0.000    0.055    0.003 __init__.py:1914(_by_version_descending)\n",
       "        1    0.000    0.000    0.002    0.002 record_writer.py:4(<module>)\n",
       "        1    0.000    0.000    0.348    0.348 event_file_writer.py:15(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 api.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:684(Context)\n",
       "       11    0.000    0.000    0.000    0.000 name.py:28(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 auto.py:271(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:59(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:418(_construct_char_code_lookup)\n",
       "        1    0.000    0.000    0.005    0.005 dopri5.py:2(<module>)\n",
       "       32    0.000    0.000    0.000    0.000 typing.py:889(__extrahook__)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:1059(system)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:188(parse_notifier_name)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:839(_decompose)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.urandom}\n",
       "       10    0.000    0.000    0.000    0.000 {method 'tolist' of 'memoryview' objects}\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:48(<module>)\n",
       "        1    0.000    0.000    0.007    0.007 utils.py:3(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 api_implementation.py:32(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 __init__.py:2256(_is_egg_path)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:1529(Connection)\n",
       "        6    0.000    0.000    0.000    0.000 _elliptic_curve.py:97(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 escprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 retry.py:1(<module>)\n",
       "        1    0.000    0.000    0.263    0.263 model_zoo.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 reductions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:1(<module>)\n",
       "       24    0.000    0.000    0.000    0.000 container.py:153(__len__)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:25(register_func)\n",
       "        1    0.000    0.000    0.001    0.001 fftpack.py:32(<module>)\n",
       "        1    0.000    0.000    0.011    0.011 util.py:310(find_library)\n",
       "        1    0.000    0.000    0.030    0.030 modules.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data.py:23(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 path.py:86(compress_user)\n",
       "        4    0.000    0.000    0.000    0.000 textwrap.py:414(dedent)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:1178(_add_notifiers)\n",
       "       10    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:993(__iter__)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
       "       67    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
       "        1    0.000    0.000    0.003    0.003 BmpImagePlugin.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:31(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 text_encoding.py:31(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 pyparsing.py:3851(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:1069(wrapper)\n",
       "       14    0.000    0.000    0.001    0.000 pyparsing.py:2026(__call__)\n",
       "        1    0.000    0.000    0.010    0.010 version.py:4(<module>)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1805(_warn_on_replacement)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:91(set_self_blocking)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 idnadata.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(AsymmetricSignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PoolKey)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:1(<module>)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1414(_get_builtin_table)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:328(ExprBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:27(DistributedDataParallel)\n",
       "        1    0.000    0.000    0.001    0.001 data_parallel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:51(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:440(_set_array_types)\n",
       "        8    0.000    0.000    0.000    0.000 data.py:13(uniq_stable)\n",
       "        1    0.000    0.000    0.016    0.016 ultratb.py:1090(get_records)\n",
       "        6    0.000    0.000    0.000    0.000 locale.py:379(normalize)\n",
       "       10    0.000    0.000    0.000    0.000 traceback.py:276(__iter__)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:366(_create_)\n",
       "       13    0.000    0.000    0.000    0.000 _collections_abc.py:72(_check_methods)\n",
       "        1    0.000    0.000    0.000    0.000 scope.py:3(<module>)\n",
       "        1    0.000    0.000    0.027    0.027 refactor.py:9(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 descriptor.py:919(_ParseOptions)\n",
       "       12    0.000    0.000    0.000    0.000 six.py:126(__init__)\n",
       "        1    0.000    0.000    0.360    0.360 torchvis.py:1(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 dual.py:52(register_func)\n",
       "       12    0.000    0.000    0.000    0.000 Image.py:2810(register_extension)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:5(<module>)\n",
       "       36    0.000    0.000    0.000    0.000 backend.py:218(register_cipher_adapter)\n",
       "       35    0.000    0.000    0.000    0.000 backend.py:2100(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:79(Certificate)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 utf8prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 url.py:14(Url)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 linear.py:58(reset_parameters)\n",
       "        1    0.000    0.000    0.005    0.005 linear.py:1(<module>)\n",
       "        7    0.000    0.000    0.000    0.000 _jit_internal.py:113(boolean_dispatch)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:48(_numeric_methods)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:36(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 __config__.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:265(GaussianDiag)\n",
       "        3    0.000    0.000    0.000    0.000 util.py:136(register_after_fork)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1604(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:923(instance_init)\n",
       "       24    0.000    0.000    0.000    0.000 traitlets.py:215(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:115(copy)\n",
       "        2    0.000    0.000    0.010    0.005 odenvp_conditional_tol.py:208(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:420(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:514(Image)\n",
       "        1    0.000    0.000    0.008    0.008 ciphers.py:5(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:78(contains)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:34(MultiByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:254(ReduceLROnPlateau)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:2905(_update_from)\n",
       "        1    0.000    0.000    0.028    0.028 type_check.py:3(<module>)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:864(__call__)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:1237(observe)\n",
       "       27    0.000    0.000    0.000    0.000 inspect.py:479(getmro)\n",
       "       24    0.000    0.000    0.000    0.000 traitlets.py:216(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:182(encode)\n",
       "       25    0.000    0.000    0.000    0.000 enum.py:332(<genexpr>)\n",
       "       20    0.000    0.000    0.000    0.000 enum.py:581(__hash__)\n",
       "       28    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
       "       24    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
       "       34    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:621(decorator)\n",
       "        2    0.000    0.000    0.001    0.001 pyparsing.py:3859(parseImpl)\n",
       "       46    0.000    0.000    0.000    0.000 pyparsing.py:1366(postParse)\n",
       "       26    0.000    0.000    0.000    0.000 __init__.py:3027(_always_object)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:14(X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:81(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:76(Error)\n",
       "        1    0.000    0.000    0.000    0.000 escsm.py:28(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 gumbel.py:1(<module>)\n",
       "       19    0.000    0.000    0.000    0.000 constraint_registry.py:105(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:190(Conv2d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:81(__init__)\n",
       "        1    0.000    0.000    0.107    0.107 module.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 random.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:15(Tensor)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:598(serialize)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7f8c160bba60}\n",
       "        1    0.000    0.000    0.047    0.047 ultratb.py:1128(structured_traceback)\n",
       "       18    0.000    0.000    0.000    0.000 argparse.py:568(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 shutil.py:1106(_access_check)\n",
       "        2    0.000    0.000    0.001    0.000 pyparsing.py:4681(originalTextFor)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2431(parseImpl)\n",
       "        8    0.000    0.000    0.000    0.000 six.py:114(_resolve)\n",
       "       46    0.000    0.000    0.000    0.000 crc32c.py:100(crc_finalize)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_svd.py:1(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2761(register_open)\n",
       "        1    0.000    0.000    0.003    0.003 constant_time.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1078(X509)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.021    0.021 __init__.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:23(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:3(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:20(warn_imbalance)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:9(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:108(Function)\n",
       "        1    0.000    0.000    0.003    0.003 random.py:22(manual_seed)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8061(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _numpy_fft.py:54(<module>)\n",
       "        1    0.000    0.000    0.005    0.005 cnf_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:9(_ActNorm)\n",
       "        1    0.000    0.000    0.001    0.001 adams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:29(ReshapeDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:1933(_get_exc_info)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:223(_randbelow)\n",
       "        8    0.000    0.000    0.000    0.000 random.py:255(choice)\n",
       "       16    0.000    0.000    0.000    0.000 traitlets.py:1673(validate)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'isoformat' of 'datetime.datetime' objects}\n",
       "        6    0.000    0.000    0.000    0.000 weakref.py:354(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:966(_find_parent_path_names)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._multiprocessing_init}\n",
       "        1    0.000    0.000    0.000    0.000 ImageColor.py:20(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 driver.py:117(load_grammar)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:1841(__radd__)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:2707(from_filename)\n",
       "        2    0.000    0.000    0.000    0.000 spectral_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_cholesky.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:72(BaseType)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:10(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 scrypt.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.X509_new}\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:491(PrivateKeyInfo)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:154(cached_property)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:104(_has_ipv6)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:1(<module>)\n",
       "        3    0.000    0.000    0.346    0.115 tarfile.py:1613(taropen)\n",
       "        2    0.000    0.000    0.001    0.000 _distributor_init.py:10(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 scimath.py:17(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 twodim_base.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mixins.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 loader.py:1(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 numerictypes.py:181(english_capitalize)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2592(geterr)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 context.py:69(RLock)\n",
       "       16    0.000    0.000    0.000    0.000 traitlets.py:1694(_resolve_classes)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:752(_addHandlerRef)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:349(__subclasshook__)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._init_names}\n",
       "        1    0.000    0.000    0.000    0.000 fractions.py:60(Fraction)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 visdom_writer.py:23(VisdomWriter)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4450(delimitedList)\n",
       "        7    0.000    0.000    0.000    0.000 pyparsing.py:4825(tokenMap)\n",
       "       12    0.000    0.000    0.000    0.000 pyparsing.py:2045(suppress)\n",
       "        7    0.000    0.000    0.000    0.000 specifiers.py:266(_require_version_compare)\n",
       "       13    0.000    0.000    0.000    0.000 six.py:80(_import_module)\n",
       "        1    0.000    0.000    0.073    0.073 __init__.py:554(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _expm_frechet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.015    0.015 lsun.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 cmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:81(SignatureAlgorithmOID)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:514(X509Name)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:147(SpectralNormLoadStateDictPreHook)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:1(<module>)\n",
       "        2    0.000    0.000    0.001    0.000 _version.py:7(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 mixins.py:40(_inplace_binary_method)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:484(cast)\n",
       "        8    0.000    0.000    0.000    0.000 ultratb.py:917(linereader)\n",
       "        6    0.000    0.000    0.000    0.000 tokenize.py:344(_get_normal_name)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:767(_create_pseudo_member_)\n",
       "        1    0.000    0.000    0.000    0.000 latin_1.py:41(getregentry)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(normalize_encoding)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:71(search_function)\n",
       "       28    0.000    0.000    0.000    0.000 TiffImagePlugin.py:368(_delegate)\n",
       "        1    0.000    0.000    0.002    0.002 noniterators.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:9(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 onnx_graph.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:3841(__str__)\n",
       "        1    0.000    0.000    0.026    0.026 specifiers.py:275(Specifier)\n",
       "        1    0.000    0.000    0.000    0.000 dual.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_lu.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_ldl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 status_codes.py:18(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 hmac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:26(_Certificate)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:148(activate_osrandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_init}\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:115(inject_into_urllib3)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:28(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 charsetgroupprober.py:28(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:22(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rendezvous.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 module.py:23(Module)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:57(_load_cudart)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:267(get_device_name)\n",
       "        3    0.000    0.000    0.000    0.000 serialization.py:173(_check_seekable)\n",
       "        2    0.000    0.000    0.000    0.000 terminal.py:109(get_terminal_size)\n",
       "        2    0.000    0.000    0.011    0.005 traceback.py:193(format_stack)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1414(wait)\n",
       "       10    0.000    0.000    0.000    0.000 {method 'cast' of 'memoryview' objects}\n",
       "       43    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
       "        1    0.000    0.000    0.000    0.000 extension_loader.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 visdom_writer.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3829(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 pyparsing.py:4017(__str__)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:1877(__mul__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:2963(__str__)\n",
       "       16    0.000    0.000    0.000    0.000 six.py:189(__get_module)\n",
       "        8    0.000    0.000    0.000    0.000 six.py:209(is_package)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_qz.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2932(_apply_env_variables)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:112(tqdm)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:13(where)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:10(_Reasons)\n",
       "       12    0.000    0.000    0.000    0.000 utils.py:116(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 url.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:118(<dictcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:29(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:11(_check_balance)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:169(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 gradcheck.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 __init__.py:279(get_device_capability)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:727(TarInfo)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2775(__new__)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:8066(getdoc)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:1145(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 financial.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nanfunctions.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:156(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:35(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 defmatrix.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 numerictypes.py:565(obj2sctype)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:583(sign)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:87(date_default)\n",
       "        1    0.000    0.000    0.001    0.001 _ccallback.py:1(<module>)\n",
       "        3    0.000    0.000    0.001    0.000 container.py:8(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 ImageOps.py:20(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:826(__new__)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1456(addHandler)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
       "       12    0.000    0.000    0.000    0.000 {built-in method builtins.delattr}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_manualSeedAll}\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:40(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:6(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 summary_pb2.py:5(<lambda>)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'AddFileDescriptor' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "       13    0.000    0.000    0.000    0.000 symbol_database.py:93(RegisterEnumDescriptor)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3164(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:78(_IndividualSpecifier)\n",
       "        5    0.000    0.000    0.000    0.000 six.py:159(_resolve)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:135(create_regularization_fns)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:135(_declare_state)\n",
       "        1    0.000    0.000    0.000    0.000 special_matrices.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:21(FFI)\n",
       "        2    0.000    0.000    0.000    0.000 backend.py:128(_get_osurandom_engine)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:581(ReasonFlags)\n",
       "        1    0.000    0.000    0.263    0.263 alexnet.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:8(NegativeBinomial)\n",
       "        1    0.000    0.000    0.000    0.000 negative_binomial.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 relaxed_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 comm.py:1(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 init.py:403(_make_deprecate)\n",
       "        4    0.000    0.000    0.000    0.000 linear.py:69(extra_repr)\n",
       "        2    0.000    0.000    0.011    0.005 __init__.py:120(_lazy_call)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6266(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'seed' of 'mtrand.RandomState' objects}\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:45(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _polybase.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:493(StringConverter)\n",
       "        1    0.000    0.000    0.000    0.000 histograms.py:3(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 mixins.py:30(_reflected_binary_method)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 main.py:1(<module>)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:2491(seterr)\n",
       "        1    0.000    0.000    0.000    0.000 einsumfunc.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1533(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 __init__.py:1109(__init__)\n",
       "        2    0.000    0.000    0.001    0.000 traceback.py:27(format_list)\n",
       "        1    0.000    0.000    0.000    0.000 getipython.py:17(get_ipython)\n",
       "       14    0.000    0.000    0.000    0.000 weakref.py:428(get)\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'findall' of '_sre.SRE_Pattern' objects}\n",
       "        1    0.000    0.000    0.002    0.002 ImagePalette.py:19(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 decoder.py:190(_SimpleDecoder)\n",
       "        1    0.000    0.000    0.023    0.023 driver.py:12(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 descriptor_pool.py:56(<module>)\n",
       "       25    0.000    0.000    0.000    0.000 {method 'append' of 'DescriptorSequence' objects}\n",
       "       13    0.000    0.000    0.000    0.000 enum_type_wrapper.py:46(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:324(ParseResults)\n",
       "        2    0.000    0.000    0.002    0.001 pyparsing.py:1608(parseString)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:3098(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:9(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:389(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 __init__.py:15(search_path)\n",
       "       14    0.000    0.000    0.000    0.000 __init__.py:2237(_cygwin_patch)\n",
       "        2    0.000    0.000    0.006    0.003 train_misc.py:70(count_parameters)\n",
       "        1    0.000    0.000    0.000    0.000 decomp_qr.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:1(<module>)\n",
       "        1    0.000    0.000    0.008    0.008 fakedata.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 SSL.py:701(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:109(_register_osrandom_engine)\n",
       "        1    0.000    0.000    0.001    0.001 exceptions.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:383(PyOpenSSLContext)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:124(HTTPResponse)\n",
       "        1    0.000    0.000    0.001    0.001 universaldetector.py:51(UniversalDetector)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:1(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 _torch_docs.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 lowrank_multivariate_normal.py:57(LowRankMultivariateNormal)\n",
       "        1    0.000    0.000    0.001    0.001 lowrank_multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:7(Distribution)\n",
       "        1    0.000    0.000    0.001    0.001 beta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:8(Binomial)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1385(TarFile)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:166(nts)\n",
       "        4    0.000    0.000    0.000    0.000 _utils_internal.py:16(get_file_path)\n",
       "        1    0.000    0.000    0.000    0.000 _six.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 result.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 defchararray.py:1669(chararray)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jsonutil.py:177(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 session.py:102(<lambda>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:62(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:1(<module>)\n",
       "        1    0.000    0.000    0.047    0.047 ultratb.py:1373(structured_traceback)\n",
       "       22    0.000    0.000    0.000    0.000 argparse.py:2312(_check_value)\n",
       "        1    0.000    0.000    0.000    0.000 sysconfig.py:612(get_platform)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'count' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.open}\n",
       "        1    0.000    0.000    0.000    0.000 JpegPresets.py:67(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:18(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:16(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_TagInfo)\n",
       "        4    0.000    0.000    0.000    0.000 decoder.py:263(_StructPackDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:1(<module>)\n",
       "       20    0.000    0.000    0.000    0.000 tokenize.py:48(group)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'ParseFromString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:40(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 descriptor.py:729(__new__)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:338(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2464(Distribution)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:259(Morsel)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:214(_CertificateRevocationList)\n",
       "        7    0.000    0.000    0.000    0.000 ocsp.py:43(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:302(OCSPResponse)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_get_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3848(SequenceOf)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:131(DSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Url)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:10(Normal)\n",
       "        1    0.000    0.000    0.000    0.000 normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:58(MultivariateNormal)\n",
       "        1    0.000    0.000    0.000    0.000 multivariate_normal.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 binomial.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 data_parallel.py:21(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _reduction.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 grad.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 function.py:183(once_differentiable)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 core.py:2551(_arraymethod)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:934(poly1d)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:15(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ufunclike.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 py3k.py:4(<module>)\n",
       "        1    0.000    0.000    0.090    0.090 cnf.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 debugger.py:53(make_arrow)\n",
       "       23    0.000    0.000    0.000    0.000 enum.py:599(value)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:193(total_ordering)\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:960(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'end' of '_sre.SRE_Match' objects}\n",
       "       12    0.000    0.000    0.000    0.000 {method 'groupdict' of '_sre.SRE_Match' objects}\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Int8Tensor)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:24(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:32(Base)\n",
       "        2    0.000    0.000    0.001    0.000 __init__.py:4(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:138(_newer)\n",
       "       11    0.000    0.000    0.000    0.000 attr_value_pb2.py:5(<lambda>)\n",
       "       16    0.000    0.000    0.000    0.000 symbol_database.py:187(Default)\n",
       "        1    0.000    0.000    0.000    0.000 text_encoding.py:47(<listcomp>)\n",
       "       16    0.000    0.000    0.000    0.000 pyparsing.py:317(__getitem__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1288(addParseAction)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:2376(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:3032(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:21(BaseSpecifier)\n",
       "        1    0.000    0.000    0.001    0.001 expat.py:1(<module>)\n",
       "        1    0.000    0.000    0.073    0.073 __init__.py:567(_build_master)\n",
       "       16    0.000    0.000    0.000    0.000 __init__.py:1790(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:264(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 Image.py:2787(register_save)\n",
       "        1    0.000    0.000    0.000    0.000 _binary.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:387(_CertificateSigningRequest)\n",
       "        5    0.000    0.000    0.000    0.000 backend.py:114(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_OpenSSLErrorWithText)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:15(_ASN1Type)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:15(EllipticCurveOID)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:103(EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2665(_PassphraseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:292(CertificateSigningRequest)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:217(PKey)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:50(SequenceLikelihood)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 multinomial.py:10(Multinomial)\n",
       "        1    0.000    0.000    0.000    0.000 geometric.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:7(Independent)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:8(Categorical)\n",
       "        1    0.000    0.000    0.000    0.000 categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:225(StmtBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:2(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:17(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:18(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:79(__init__)\n",
       "        1    0.000    0.000    0.024    0.024 module.py:723(load_state_dict)\n",
       "        1    0.000    0.000    0.106    0.106 thnn.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 serialization.py:111(default_restore_location)\n",
       "        1    0.000    0.000    0.000    0.000 legendre.py:1794(Legendre)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.seterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 defmatrix.py:70(matrix)\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:69(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 case.py:1316(_deprecate)\n",
       "        1    0.000    0.000    0.001    0.001 util.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:388(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:169(utcnow)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:561(msg_header)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interp.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'bind' of '_socket.socket' objects}\n",
       "        1    0.000    0.000    0.047    0.047 ultratb.py:1276(structured_traceback)\n",
       "        6    0.000    0.000    0.000    0.000 platform.py:921(uname)\n",
       "       11    0.000    0.000    0.000    0.000 traceback.py:303(walk_tb)\n",
       "        4    0.000    0.000    0.000    0.000 fractions.py:294(_operator_fallbacks)\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:12(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:5(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 symbol_database.py:58(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:788(ListValue)\n",
       "        1    0.000    0.000    0.000    0.000 reflection.py:46(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 pyparsing.py:4783(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:668(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:2020(__invert__)\n",
       "        1    0.000    0.000    0.000    0.000 py31compat.py:1(<module>)\n",
       "        1    0.000    0.000    0.009    0.009 version.py:191(Version)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_Version)\n",
       "       10    0.000    0.000    0.000    0.000 six.py:181(_get_module)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:385(get_build_platform)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:2205(file_ns_handler)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ArgSpec)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:1(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 Image.py:2821(register_extensions)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:16(ResNeXtBottleneckC)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1063(ZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:34(OCSPResponseStatus)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:264(OCSPRequest)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:102(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 aead.py:5(<module>)\n",
       "       10    0.000    0.000    0.000    0.000 SSL.py:646(_requires_decorator)\n",
       "        2    0.000    0.000    0.033    0.017 binding.py:136(init_static_locks)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:120(ExtendedKeyUsageOID)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:613(EncryptionAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:949(KeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:92(PrimePoint)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:275(X509Backend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:488(DistributionPoint)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:21(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2111(CRL)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:13(LogEntryType)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:137(_validate_dependencies_met)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:714(X509Extension)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:872(X509Req)\n",
       "        1    0.000    0.000    0.000    0.000 mbcharsetprober.py:30(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:29(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(RequestHistory)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:9(Poisson)\n",
       "        1    0.000    0.000    0.000    0.000 poisson.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:18(add_docstr_all)\n",
       "        1    0.000    0.000    0.000    0.000 independent.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distribution.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 beta.py:10(Beta)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 bernoulli.py:10(Bernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:128(<lambda>)\n",
       "        1    0.000    0.000    0.001    0.001 scatter_gather.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(Function)\n",
       "        1    0.000    0.000    0.000    0.000 hermite.py:1814(Hermite)\n",
       "        1    0.000    0.000    0.000    0.000 hermite_e.py:1811(HermiteE)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:323(_get_typecodes)\n",
       "        1    0.000    0.000    0.000    0.000 arraypad.py:5(<module>)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method numpy.core.umath.geterrobj}\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:74(_determine_error_states)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:29(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2891(__enter__)\n",
       "        3    0.000    0.000    0.000    0.000 session.py:132(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:121(new_id)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:564(msg)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:739(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 hmac.py:90(update)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:95(copy)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:342(_FuncPtr)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_ButcherTableau)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_RungeKuttaState)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:409(_real_close)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:506(translation)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:611(gettext)\n",
       "        8    0.000    0.000    0.000    0.000 loader.py:252(__getitem__)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:1014(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1154(_get_handles)\n",
       "        4    0.000    0.000    0.001    0.000 re.py:204(split)\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method sys.setdlopenflags}\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.get_terminal_size}\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "        1    0.000    0.000    0.000    0.000 ImageChops.py:18(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 extension_loader.py:16(DlopenGuard)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:171(RefactoringTool)\n",
       "        2    0.000    0.000    0.000    0.000 driver.py:110(_generate_pickle_name)\n",
       "        3    0.000    0.000    0.000    0.000 grammar.py:77(__init__)\n",
       "        1    0.000    0.000    0.034    0.034 __init__.py:85(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 tensor_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(manifest_mod)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3523(MatchFirst)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4003(parseImpl)\n",
       "       18    0.000    0.000    0.000    0.000 pyparsing.py:458(__bool__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3061(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 specifiers.py:214(LegacySpecifier)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:469(Module_six_moves_urllib)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2310(EntryPoint)\n",
       "        1    0.000    0.000    0.000    0.000 _sketches.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 flinalg.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _decomp_polar.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:1(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 api.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:325(_OCSPRequest)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _openssl.OpenSSL_add_all_algorithms}\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:33(HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 _types.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:11(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 extensions.py:915(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:964(PublicKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:388(extended_datetime)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:268(RSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:336(BasicConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:150(DSAParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(Version)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:28(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:49(check_compatibility)\n",
       "        1    0.000    0.000    0.000    0.000 weibull.py:10(Weibull)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:32(_OpNamespace)\n",
       "        1    0.000    0.000    0.000    0.000 uniform.py:9(Uniform)\n",
       "        1    0.000    0.000    0.000    0.000 transformed_distribution.py:8(TransformedDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:209(ComposeTransform)\n",
       "        1    0.000    0.000    0.000    0.000 exponential.py:9(Exponential)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ScriptMethodStub)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:44(__setstate__)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:1(<module>)\n",
       "        8    0.000    0.000    0.000    0.000 data_parallel.py:31(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(PackedSequence)\n",
       "        1    0.000    0.000    0.001    0.001 vision.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:451(__set__)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:341(FormattedTimesMixin)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:7(Stream)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:7(cudaOutputMode)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 storage.py:7(_StorageBase)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:7(<module>)\n",
       "        3    0.000    0.000    0.000    0.000 ufunclike.py:14(_deprecate_out_named_y)\n",
       "        1    0.000    0.000    0.000    0.000 _inspect.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:845(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:24(TestResult)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(Mismatch)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:242(extract_header)\n",
       "        1    0.000    0.000    0.000    0.000 linalg_version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:110(Conv2d)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1042(format_exception)\n",
       "       22    0.000    0.000    0.000    0.000 ultratb.py:1466(nullrepr)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1354(add_argument_group)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:572(dgettext)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:96(seed)\n",
       "        8    0.000    0.000    0.000    0.000 traitlets.py:2045(validate)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:1115(append)\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:219(_deepcopy_tuple)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:773(_get_devnull)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1348(_handle_exitstatus)\n",
       "        1    0.000    0.000    0.000    0.000 functools.py:196(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:252(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:672(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:806(fsdecode)\n",
       "       16    0.000    0.000    0.000    0.000 six.py:75(_add_doc)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_cudnn_benchmark}\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:110(GzipFile)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 compatibility.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:318(Leaf)\n",
       "        2    0.000    0.000    0.001    0.001 driver.py:147(load_packaged_grammar)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:37(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:93(StrictVersion)\n",
       "        9    0.000    0.000    0.000    0.000 step_stats_pb2.py:5(<lambda>)\n",
       "        6    0.000    0.000    0.000    0.000 layout_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:105(calc_output_size)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:102(DescriptorPool)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:392(FieldDescriptor)\n",
       "        5    0.000    0.000    0.000    0.000 pyparsing.py:4292(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:1567(resetCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2991(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:3015(parseImpl)\n",
       "        4    0.000    0.000    0.001    0.000 pyparsing.py:3353(setResultsName)\n",
       "       12    0.000    0.000    0.000    0.000 version.py:248(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:957(Environment)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1603(ZipProvider)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:56(S3RecordWriter)\n",
       "       10    0.000    0.000    0.000    0.000 event_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 _procrustes.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 phototour.py:12(PhotoTour)\n",
       "        5    0.000    0.000    0.000    0.000 Image.py:2776(register_mime)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:171(RequestsCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:586(Response)\n",
       "        1    0.000    0.000    0.030    0.030 _internal_utils.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:863(DefaultCookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:76(Blowfish)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:106(ARC4)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_MemoryBIO)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:172(Encoding)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(Concat)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:50(_ForceNullParameters)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:183(EllipticCurveBackend)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:32(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:80(DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:69(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 hebrewprober.py:128(HebrewProber)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:375(_EllipticCurve)\n",
       "        6    0.000    0.000    0.000    0.000 crypto.py:625(_cmp)\n",
       "        1    0.000    0.000    0.000    0.000 utf8prober.py:35(UTF8Prober)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:70(HTTPConnection)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:28(Retry)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:102(HTTPHeaderDict)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:736(HTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 one_hot_categorical.py:7(OneHotCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:10(LogitRelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:87(RelaxedOneHotCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 studentT.py:11(StudentT)\n",
       "        1    0.000    0.000    0.000    0.000 _storage_docs.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cauchy.py:11(Cauchy)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:26(Transform)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:17(Optimizer)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(ASMoutput)\n",
       "        1    0.000    0.000    0.000    0.000 clip_grad.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:41(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auto_double_backwards.py:1(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 random.py:77(manual_seed_all)\n",
       "        1    0.000    0.000    0.000    0.000 nvtx.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:612(_FileInFile)\n",
       "        2    0.000    0.000    0.000    0.000 serialization.py:46(register_package)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3080(view)\n",
       "        1    0.000    0.000    0.000    0.000 chebyshev.py:2109(Chebyshev)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.copyto}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.arange}\n",
       "        7    0.000    0.000    0.000    0.000 utils.py:52(_set_function_name)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:5(_LoggingWatcher)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:942(_register_types)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2896(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:450(decorating_function)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:70(set)\n",
       "        2    0.000    0.000    0.000    0.000 odefunc.py:75(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 ImageEnhance.py:21(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:142(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:160(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 tempfile.py:157(__next__)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1484(_get_handler)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1920(consume_positionals)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:133(_get_kwargs)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1236(_fixupChildren)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'datetime.datetime' objects}\n",
       "        1    0.000    0.000    0.002    0.002 traceback.py:59(extract_tb)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:104(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:331(__iter__)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:339(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:334(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 weakref.py:288(update)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.TextIOWrapper' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.access}\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:1552(AppendingTiffWriter)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:947(TiffImageFile)\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:504(_StructPackEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:27(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:11(<module>)\n",
       "        1    0.000    0.000    0.002    0.002 version.py:27(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 x2num.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:10(ODENVP)\n",
       "        1    0.000    0.000    0.003    0.003 odenvp_conditional_tol.py:212(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 message_factory.py:50(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:434(ScalarMap)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3850(_MultipleMatch)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:506(haskeys)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:39(NegativeInfinity)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:589(SpecifierSet)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:551(WorkingSet)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:2876(DistInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 torchvis.py:19(TorchVis)\n",
       "        4    0.000    0.000    0.000    0.000 _utils.py:8(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:114(_make_name)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:95(SessionRedirectMixin)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:29(OCSPResponderEncoding)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:57(OCSPCertStatus)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:80(DHParameterNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:185(DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:96(Cipher)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:96(Binding)\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:22(_OpenSSLError)\n",
       "        3    0.000    0.000    0.000    0.000 binding.py:106(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:168(Asn1Value)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:904(TLSFeatureType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1044(NameConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:54(OtherPrimeInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:329(NamedCurve)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:60(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _errors.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:12(CipherBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:334(DHBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:142(AuthorityKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:594(PolicyConstraints)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:48(EllipticCurvePrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:313(EllipticCurvePublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1941(Revoked)\n",
       "        1    0.000    0.000    0.000    0.000 __about__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:46(register_decorator)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:247(WrappedSocket)\n",
       "        1    0.000    0.000    0.000    0.000 euckrprober.py:34(EUCKRProber)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:8(is_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 retry.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pareto.py:9(Pareto)\n",
       "        1    0.000    0.000    0.000    0.000 log_normal.py:8(LogNormal)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_categorical.py:10(ExpRelaxedCategorical)\n",
       "        1    0.000    0.000    0.000    0.000 laplace.py:8(Laplace)\n",
       "        1    0.000    0.000    0.000    0.000 gamma.py:13(Gamma)\n",
       "        1    0.000    0.000    0.000    0.000 fishersnedecor.py:11(FisherSnedecor)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:1262(_get_methods)\n",
       "        2    0.000    0.000    0.000    0.000 distributed_cpu.py:10(DistributedDataParallelCPU)\n",
       "        1    0.000    0.000    0.000    0.000 parallel_apply.py:1(<module>)\n",
       "        1    0.000    0.000    0.001    0.001 replicate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 nccl.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:13(_BatchNorm)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:6(_InstanceNorm)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:9(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:459(CudnnModule)\n",
       "        1    0.000    0.000    0.001    0.001 auto_symbolic.py:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:3350(dtype)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6348(__setattr__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:6449(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 laguerre.py:1764(Laguerre)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:1362(getmask)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:1606(Polynomial)\n",
       "        1    0.000    0.000    0.000    0.000 arraysetops.py:27(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 mixins.py:55(_unary_method)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1923(suppress_warnings)\n",
       "       10    0.000    0.000    0.000    0.000 pytesttester.py:72(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:246(_ctypes)\n",
       "        7    0.000    0.000    0.000    0.000 _inspect.py:144(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2887(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:96(_str_xmin)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:532(max)\n",
       "        3    0.000    0.000    0.000    0.000 result.py:12(failfast)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:260(send_multipart)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:108(_current)\n",
       "        5    0.000    0.000    0.000    0.000 __init__.py:99(CFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:425(LoadLibrary)\n",
       "        2    0.000    0.000    0.000    0.000 _version.py:62(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:26(LowLevelCallable)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:156(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:7(CouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:1(<module>)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:66(reset)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:8(MultiscaleParallelCNF)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:214(GatedLinear)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:32(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:6(AdaptiveStepsizeODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:46(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:413(close)\n",
       "        9    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'copy' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1011(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:586(iteritems)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:800(createLock)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:960(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:678(__delitem__)\n",
       "        2    0.000    0.000    0.000    0.000 os.py:760(getenv)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:93(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.uname}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'isalnum' of 'str' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:16(<module>)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:620(_register_loader)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:630(decorator)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:854(ImageFileDirectory_v1)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:561(PyDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:593(_Parser)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:98(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:375(EncodeVarint)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:49(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:208(Node)\n",
       "        3    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:191(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 resource_handle_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:241(Duration)\n",
       "        3    0.000    0.000    0.000    0.000 graph_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:76(_Lock)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:44(Message)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3962(Optional)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:315(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1298(addCondition)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1972(__xor__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2765(Regex)\n",
       "        1    0.000    0.000    0.000    0.000 appdirs.py:407(AppDirs)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:10(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:164(_SixMetaPathImporter)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:342(register_loader_type)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1123(ResourceManager)\n",
       "        1    0.000    0.000    0.001    0.001 __init__.py:1583(MemoizedZipManifests)\n",
       "        2    0.000    0.000    0.190    0.095 __init__.py:3109(_call_aside)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3114(_initialize)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:127(Plist)\n",
       "        1    0.000    0.000    0.000    0.000 thops.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:11(SpectralNorm)\n",
       "        1    0.000    0.000    0.000    0.000 crc32c.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:40(SummaryToEventTransformer)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:102(PrimitiveType)\n",
       "        2    0.000    0.000    0.000    0.000 transforms.py:44(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 model.py:12(qualify)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:300(_DataLoaderIter)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:371(Barrier)\n",
       "        1    0.000    0.000    0.000    0.000 sessions.py:340(Session)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:25(MockRequest)\n",
       "        1    0.000    0.000    0.002    0.002 certs.py:14(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1961(MozillaCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 makefile.py:8(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:740(_Tellable)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:499(_SignedCertificateTimestamp)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:118(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:108(_DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:228(_EllipticCurvePublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:20(CipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:44(CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:14(Mode)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:161(CFB8)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:197(GCM)\n",
       "        1    0.000    0.000    0.000    0.000 mac.py:12(MACContext)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:18(DHPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ciphers.py:13(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:46(CRLEntryExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:135(CertificatePoliciesOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:18(HashAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:183(PublicFormat)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:50(RFC822Name)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2737(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2964(Enumerated)\n",
       "        1    0.000    0.000    0.000    0.000 _ordereddict.py:23(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:561(EncryptionAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:764(Void)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(Any)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:694(PolicyInformation)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1343(InvalidityDate)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1421(OCSPNonce)\n",
       "        1    0.000    0.000    0.000    0.000 _elliptic_curve.py:54(PrimeCurve)\n",
       "        5    0.000    0.000    0.000    0.000 _elliptic_curve.py:170(__mul__)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:338(RSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:96(RSABackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:253(DERSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:384(EllipticCurvePrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 _oid.py:10(ObjectIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2387(PKCS12)\n",
       "        1    0.000    0.000    0.000    0.000 certificate_transparency.py:18(Version)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:122(_ModuleWithDeprecations)\n",
       "        1    0.000    0.000    0.000    0.000 sbcharsetprober.py:33(SingleByteCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 langcyrillicmodel.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langhebrewmodel.py:38(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1573(X509Store)\n",
       "        1    0.000    0.000    0.000    0.000 latin1prober.py:96(Latin1Prober)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:31(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:93(MultiDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 charsetprober.py:35(CharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 escprober.py:35(EscCharSetProber)\n",
       "        1    0.000    0.000    0.000    0.000 timeout.py:18(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:95(HTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 gumbel.py:13(Gumbel)\n",
       "        1    0.000    0.000    0.000    0.000 half_cauchy.py:11(HalfCauchy)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:24(_Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 dirichlet.py:38(Dirichlet)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:164(_InverseTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:217(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(PowerTransform)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:63(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:38(_parse_env)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:550(ignore_lib_warnings)\n",
       "        2    0.000    0.000    0.002    0.001 __init__.py:1450(_register_builtin)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:113(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:154(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 rprop.py:6(Rprop)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:110(Unfold)\n",
       "        1    0.000    0.000    0.000    0.000 data_parallel.py:35(DataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:19(DistributedDataParallel)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:21(RNNBase)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:10(PackedSequence)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:202(ModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:444(AvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:321(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:608(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:621(Softshrink)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:658(MultiLabelMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 parameter.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:11(Linear)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:331(NestedIOFunction)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:86(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:73(_check_driver)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:237(device_of)\n",
       "        4    0.000    0.000    0.000    0.000 serialization.py:62(_cpu_deserialize)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:312(_LowLevelFile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6256(MaskedConstant)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6440(_extrema_operation)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:86(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 helper.py:245(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 helper.py:224(_FFTCache)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:17(__enter__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'tobytes' of 'numpy.generic' objects}\n",
       "        3    0.000    0.000    0.000    0.000 index_tricks.py:241(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:66(TestLoader)\n",
       "        1    0.000    0.000    0.000    0.000 main.py:49(TestProgram)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2902(_setdef)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:62(MachArLike)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:455(iinfo)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1202(DatetimeFormat)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:1506(set_string_function)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:217(record)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:63(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:127(hexdigest)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:17(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(MovingBatchNormNd)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_augment.py:11(CNF_augment)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:94(ODEnet)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:260(BlendLinear)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:221(Pad)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:24(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:48(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:55(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1114(get_parts_of_chained_exception)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1726(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1733(parse_args)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1255(python_implementation)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:819(with_metaclass)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1280(setLevel)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:758(__del__)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1401(_try_wait)\n",
       "        3    0.000    0.000    0.000    0.000 threading.py:74(RLock)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:794(fsencode)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'bytes' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:286(PngStream)\n",
       "        1    0.000    0.000    0.000    0.000 GifImagePlugin.py:46(GifImageFile)\n",
       "        5    0.000    0.000    0.000    0.000 TiffImagePlugin.py:629(_register_writer)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:1022(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 encoder.py:184(_FixedSizer)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:409(_VarintBytes)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:418(TagBytes)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:82(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:33(olddict)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:37(oldstr)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:77(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:100(TextWriter)\n",
       "        1    0.000    0.000    0.000    0.000 literals.py:4(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:17(BMNode)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:10(ParserGenerator)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:19(LParen)\n",
       "        1    0.000    0.000    0.000    0.000 fixer_util.py:22(RParen)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:50(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 pytree.py:327(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:252(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 tokenize.py:50(maybe)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:31(Version)\n",
       "        1    0.000    0.000    0.001    0.001 version.py:267(LooseVersion)\n",
       "       14    0.000    0.000    0.000    0.000 visdom_writer.py:13(_check_connection)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:107(__new__)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'FindOneofByName' of 'google.protobuf.pyext._message.DescriptorPool' objects}\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:230(RepeatedScalarFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3715(ParseElementEnhance)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:4214(copy)\n",
       "        6    0.000    0.000    0.000    0.000 pyparsing.py:4296(postParse)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:460(__iter__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2439(Keyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2527(CaselessKeyword)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3195(StringEnd)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:72(LegacyVersion)\n",
       "        8    0.000    0.000    0.000    0.000 version.py:261(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:28(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:20(with_metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:764(_BinaryPlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:64(install)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:4(VendorImporter)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:86(_LazyDescr)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:173(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1381(NullProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1484(EggProvider)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1860(register_finder)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2973(Requirement)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:312(_PlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 writer.py:144(FileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:32(EventsWriter)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:79(EventFileWriter)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(VersionConflict)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:97(BasePrimitiveType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:341(StructOrUnion)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:16(CIFAR10)\n",
       "        1    0.000    0.000    0.000    0.000 stl10.py:12(STL10)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:12(MNIST)\n",
       "        1    0.000    0.000    0.000    0.000 svhn.py:10(SVHN)\n",
       "        1    0.000    0.000    0.000    0.000 lock.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:155(_Transition)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:126(BatchSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:46(ConcatDataset)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:46(SemLock)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:332(Event)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_pandas.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:84(HTTPAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:485(BaseCookie)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:90(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:60(RequestEncodingMixin)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:272(PreparedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:989(_ZipWriteFile)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:732(Cookie)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:31(X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:26(AES)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:91(CAST5)\n",
       "        1    0.000    0.000    0.000    0.000 scrypt.py:23(Scrypt)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:318(ZipInfo)\n",
       "        4    0.000    0.000    0.000    0.000 ocsp.py:63(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:329(_RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:418(_RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:49(DHPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:142(DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:170(DHPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:52(Prehashed)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:15(_HMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 x509.py:176(_RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:228(_AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:131(OFB)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:176(CTR)\n",
       "        7    0.000    0.000    0.000    0.000 decode_asn1.py:187(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:106(_DHPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:217(_DHPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:7(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:117(activate_builtin_random)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:297(_VerifyHelper)\n",
       "        3    0.000    0.000    0.000    0.000 SSL.py:636(_make_requires)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_set_default_RAND}\n",
       "        1    0.000    0.000    0.000    0.000 intranges.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:40(NameAttribute)\n",
       "        1    0.000    0.000    0.000    0.000 name.py:142(Name)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:130(AuthorityInformationAccessOID)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'new_allocator' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:189(ParameterFormat)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:41(GeneralName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:115(DNSName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:160(UniformResourceIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:227(DirectoryName)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:279(IPAddress)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:317(OtherName)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2198(OctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2501(ParsableOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2706(Null)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:180(RSASSAPSSParams)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:220(SignedDigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:272(SignedDigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:971(Choice)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:744(UserNotice)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:862(TLSFeature)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:918(InhibitAnyPolicy)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1126(Extension)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1315(CRLReason)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1373(PrecertificateSignedCertificateTimestamps)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1449(UnrecognizedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:116(DSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:136(_ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:264(CharacteristicTwo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:384(ECDomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:202(extended_date)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:48(HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:64(CMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:79(PBKDF2HMACBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:231(PEMSerializationBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:63(ExtensionType)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:232(SubjectKeyIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:378(DeltaCRLIndicator)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:406(CRLDistributionPoints)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:655(CertificatePolicies)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:14(DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:23(DSAParametersWithNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:227(DSAPrivateNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:24(EllipticCurve)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:88(EllipticCurvePrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:54(RSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1696(X509StoreContext)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2336(PKCS7)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:2568(NetscapeSPKI)\n",
       "        2    0.000    0.000    0.000    0.000 utils.py:123(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 euctwprober.py:33(EUCTWProber)\n",
       "        1    0.000    0.000    0.000    0.000 langbulgarianmodel.py:38(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 pyopenssl.py:102(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1550(X509StoreFlags)\n",
       "        1    0.000    0.000    0.000    0.000 eucjpprober.py:36(EUCJPProber)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312prober.py:33(GB2312Prober)\n",
       "        1    0.000    0.000    0.000    0.000 cp949prober.py:34(CP949Prober)\n",
       "        1    0.000    0.000    0.000    0.000 big5prober.py:34(Big5Prober)\n",
       "        1    0.000    0.000    0.000    0.000 sjisprober.py:36(SJISProber)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:40(CharDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:183(SJISContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 compat.py:22(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 charsetgroupprober.py:32(CharSetGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:17(LanguageFilter)\n",
       "        1    0.000    0.000    0.000    0.000 codingstatemachine.py:33(CodingStateMachine)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:18(is_local_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 relaxed_bernoulli.py:92(RelaxedBernoulli)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:19(cuFFTPlanCache)\n",
       "        1    0.000    0.000    0.000    0.000 half_normal.py:11(HalfNormal)\n",
       "        1    0.000    0.000    0.000    0.000 logistic_normal.py:8(LogisticNormal)\n",
       "        1    0.000    0.000    0.000    0.000 constraint_registry.py:79(ConstraintRegistry)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:379(AffineTransform)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:211(_Interval)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:8(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:1279(_make_fail)\n",
       "        3    0.000    0.000    0.000    0.000 rendezvous.py:13(register_rendezvous_handler)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:112(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:161(MultiStepLR)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:4(is_available)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:10(_ConstantPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:10(Embedding)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:658(LSTMCell)\n",
       "        1    0.000    0.000    0.000    0.000 pixelshuffle.py:6(PixelShuffle)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:9(Upsample)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:415(ParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:11(LocalResponseNorm)\n",
       "        2    0.000    0.000    0.000    0.000 dropout.py:17(extra_repr)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:451(_ConvTransposeMixin)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:335(CELU)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:27(L1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 sparse.py:13(EmbeddingBag)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:256(FilterDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:460(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:129(profile)\n",
       "        4    0.000    0.000    0.000    0.000 profiler.py:337(attr_formatter)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:39(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 function.py:273(_iter_filter)\n",
       "        1    0.000    0.000    0.006    0.006 module.py:246(cuda)\n",
       "        3    0.000    0.000    0.000    0.000 tarfile.py:2363(_check)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:336(_Stream)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1489(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 _six.py:59(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6060(mvoid)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1315(_replace_dtype_fields)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:270(NameValidator)\n",
       "        1    0.000    0.000    0.000    0.000 arrayterator.py:20(Arrayterator)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:184(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:138(_FileOpeners)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:265(DataSource)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.generic' objects}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:216(_getintp_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:34(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:76(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:29(TextTestResult)\n",
       "        5    0.000    0.000    0.000    0.000 _inspect.py:145(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:759(__getitem__)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:88(_str_eps)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:92(_str_epsneg)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:44(_Outcome)\n",
       "        1    0.000    0.000    0.000    0.000 machar.py:17(MachAr)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:9(PackageLoader)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:83(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:206(utcoffset)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:236(msg_header)\n",
       "        3    0.000    0.000    0.000    0.000 _testutils.py:26(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 glow.py:6(BruteForceLayer)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:151(AdamsBashforthMoulton)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_regularization.py:5(RegularizedODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 omniglot.py:9(Omniglot)\n",
       "        1    0.000    0.000    0.000    0.000 solvers.py:36(FixedGridODESolver)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:567(FiveCrop)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:306(Color3DLUT)\n",
       "        1    0.000    0.000    0.000    0.000 ImageStat.py:29(Stat)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:436(find_recursion)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:1115(get_chained_exception)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1725(_get_positional_actions)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:2071(_match_arguments_partial)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:87(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1148(_sys_version)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:19(encode)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:823(setLevel)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:1056(_open)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method utcnow}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method binascii.b2a_hex}\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:537(_generate_next_value_)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:868(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 genericpath.py:53(getmtime)\n",
       "        2    0.000    0.000    0.000    0.000 _collections_abc.py:271(__subclasshook__)\n",
       "        4    0.000    0.000    0.000    0.000 _collections_abc.py:367(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rfind' of 'bytes' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method sys.getdlopenflags}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.register}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.charmap_build}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'title' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rjust' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:540(PngImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:97(ChunkStream)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(Iterator)\n",
       "        1    0.000    0.000    0.000    0.000 ImageSequence.py:19(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:56(BmpImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImagePalette.py:23(ImagePalette)\n",
       "        1    0.000    0.000    0.000    0.000 JpegImagePlugin.py:300(JpegImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffImagePlugin.py:137(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:74(ImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:324(Parser)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:377(_GzipReader)\n",
       "        1    0.000    0.000    0.000    0.000 gzip.py:69(_PaddedFile)\n",
       "        4    0.000    0.000    0.000    0.000 type_checkers.py:115(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 decoder.py:249(_ModifiedDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:822(_FieldSkipper)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:542(_FloatingPointEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:415(BasePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:606(WildcardPattern)\n",
       "        1    0.000    0.000    0.000    0.000 workspace.py:494(_BlobDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(RTs)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:241(Py2Fixer)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:692(MultiprocessRefactoringTool)\n",
       "        1    0.000    0.000    0.000    0.000 grammar.py:23(Grammar)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:180(StackedCNFLayers)\n",
       "        7    0.000    0.000    0.000    0.000 node_def_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:96(_calc_n_scale)\n",
       "        1    0.000    0.000    0.000    0.000 symbol_database.py:65(SymbolDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:98(Timestamp)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:541(_FieldMaskTree)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:735(Struct)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:94(DescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:803(MethodDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:524(MessageMap)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:185(BaseContainer)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:222(Descriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:607(EnumDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 containers.py:343(RepeatedCompositeFieldContainer)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:41(EnumTypeWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:36(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:272(Marker)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:44(Node)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3914(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4141(Forward)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4335(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 pyparsing.py:4383(postParse)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:205(ParseBaseException)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:644(__getattr__)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:666(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2545(CloseMatch)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3064(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 pyparsing.py:3066(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3151(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3256(ParseExpression)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3368(And)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3458(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3444(Or)\n",
       "        1    0.000    0.000    0.000    0.000 _structures.py:7(Infinity)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:103(MovedModule)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:124(_LazyModule)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:229(_MovedItems)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:360(Module_six_moves_urllib_error)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:380(Module_six_moves_urllib_request)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:301(DistributionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:500(IMetadataProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:523(IResourceProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:905(subscribe)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1127(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1525(_register)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1506(DefaultProvider)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:79(_InternalDict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:204(Data)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:416(_DumbXMLWriter)\n",
       "        1    0.000    0.000    0.002    0.002 train_misc.py:15(set_cnf_options)\n",
       "        1    0.000    0.000    0.000    0.000 embedding.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:175(get_supported_platform)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:288(ContextualVersionConflict)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:160(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:278(ConstPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:297(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:47(DatasetFolder)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:7(CocoCaptions)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:179(EMNIST)\n",
       "        2    0.000    0.000    0.000    0.000 Image.py:2798(register_save_all)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:17(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:25(BaseTypeByIdentity)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:88(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:5(Sampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _utils.py:123(Comparable)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:14(TMonitor)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:186(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:210(Condition)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:25(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 adapters.py:55(BaseAdapter)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:93(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:86(TqdmDefaultWriteLock)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:13(CaseInsensitiveDict)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:108(HTTPDigestAuth)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:760(ZipExtFile)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:9(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:830(CookiePolicy)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1841(LWPCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:42(Camellia)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:57(TripleDES)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:119(IDEA)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:148(ChaCha20)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(KeyDerivationFunction)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:76(OCSPRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:175(OCSPResponseBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:17(AsymmetricPadding)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:68(_DSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:197(_DSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:13(_HashContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:35(BlockCipherAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:67(AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:76(AEADDecryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:86(AEADEncryptionContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:141(_CipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:164(_AEADCipherContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:48(ModeWithNonce)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:57(ModeWithAuthenticationTag)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:85(CBC)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:100(XTS)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:146(CFB)\n",
       "        1    0.000    0.000    0.000    0.000 cmac.py:16(_CMACContext)\n",
       "        1    0.000    0.000    0.000    0.000 dh.py:36(_DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:269(_CallbackExceptionHelper)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_by_id}\n",
       "        1    0.000    0.000    0.000    0.000 name.py:102(RelativeDistinguishedName)\n",
       "        1    0.000    0.000    0.000    0.000 oid.py:42(OCSPExtensionOID)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:60(Hash)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:146(BLAKE2b)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:167(BLAKE2s)\n",
       "        2    0.000    0.000    0.000    0.000 _util.py:57(make_assert)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:178(PrivateFormat)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:253(RegisteredID)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1695(AbstractString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1910(BitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2370(OctetString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:64(register)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:146(Codec)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:107(HmacAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:372(Pbkdf2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:510(DSASignature)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:622(ValueMap)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:781(NoticeReference)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:817(ExtendedKeyUsage)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1165(GeneralNames)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1210(SubjectAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1245(IssuerAlternativeName)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:1280(CertificateIssuer)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:74(RSAPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:86(RSAPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:252(Pentanomial)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:313(SpecifiedECDomain)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:407(ECPrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:435(Attribute)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:473(PrivateKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:944(PublicKeyAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:33(HashBackend)\n",
       "        1    0.000    0.000    0.000    0.000 interfaces.py:389(ScryptBackend)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:51(DuplicateExtension)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:72(Extensions)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:114(CRLNumber)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:261(AuthorityInformationAccess)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:300(AccessDescription)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:447(FreshestCRL)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(AsymmetricVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:65(DSAPrivateKeyWithSerialization)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:189(DSAPublicNumbers)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:369(RevokedCertificate)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:390(CertificateSigningRequestBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:431(CertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:598(CertificateRevocationListBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 langgreekmodel.py:35(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langthaimodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:6(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 langturkishmodel.py:37(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:12(RequestException)\n",
       "        2    0.000    0.000    0.000    0.000 exceptions.py:40(SSLError)\n",
       "        2    0.000    0.000    0.000    0.000 crypto.py:205(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:204(_X509NameInvalidator)\n",
       "        1    0.000    0.000    0.000    0.000 mbcsgroupprober.py:41(MBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:113(EUCTWDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 gb2312freq.py:42(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:116(JapaneseContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 queue.py:10(LifoQueue)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:122(PoolManager)\n",
       "        1    0.000    0.000    0.000    0.000 poolmanager.py:362(ProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:32(ProbingState)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:223(HTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:23(is_prod_appengine)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:28(RecentlyUsedContainer)\n",
       "        1    0.000    0.000    0.000    0.000 request.py:10(RequestMethods)\n",
       "        1    0.000    0.000    0.000    0.000 alexnet.py:13(AlexNet)\n",
       "        1    0.000    0.000    0.000    0.000 connectionpool.py:55(ConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:117(__getattr__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:6(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _ops.py:68(_Ops)\n",
       "        1    0.000    0.000    0.000    0.000 kl.py:77(_Match)\n",
       "        1    0.000    0.000    0.000    0.000 chi2.py:6(Chi2)\n",
       "        2    0.000    0.000    0.000    0.000 constraint_registry.py:83(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:340(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:472(StickBreakingTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:514(LowerCholeskyTransform)\n",
       "        2    0.000    0.000    0.000    0.000 constraints.py:143(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 exp_family.py:5(ExponentialFamily)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:42(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:61(_ResourceSharer)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:7(Warning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:784(OrderedDictWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:960(ScriptModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1354(_ConstModuleList)\n",
       "        2    0.000    0.000    0.000    0.000 annotations.py:15(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:142(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:58(__setstate__)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:120(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 adagrad.py:5(Adagrad)\n",
       "        1    0.000    0.000    0.000    0.000 adam.py:6(Adam)\n",
       "        1    0.000    0.000    0.000    0.000 sparse_adam.py:6(SparseAdam)\n",
       "        1    0.000    0.000    0.000    0.000 asgd.py:6(ASGD)\n",
       "        1    0.000    0.000    0.000    0.000 rmsprop.py:5(RMSprop)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:10(_LRScheduler)\n",
       "        1    0.000    0.000    0.000    0.000 fold.py:6(Fold)\n",
       "        1    0.000    0.000    0.000    0.000 adaptive.py:15(AdaptiveLogSoftmaxWithLoss)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:35(ReduceAddCoalesced)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:29(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:22(Dropout)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:105(Dropout3d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:193(FeatureAlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:166(_ReflectionPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:270(_ReplicationPadNd)\n",
       "        1    0.000    0.000    0.000    0.000 weight_norm.py:8(WeightNorm)\n",
       "        1    0.000    0.000    0.000    0.000 convert_parameters.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:7(PairwiseDistance)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:22(Sequential)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:96(ModuleList)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:318(ParameterList)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:9(_MaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:29(MaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:723(LPPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:838(AdaptiveMaxPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:863(AdaptiveMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:1005(AdaptiveAvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:98(BatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:210(InstanceNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:75(LayerNorm)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:165(GroupNorm)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:6(_DropoutNd)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:12(_ConvNd)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:69(Conv1d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:509(ConvTranspose1d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:10(Threshold)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:242(Sigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:269(Tanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:425(GLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:501(LeakyReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:551(LogSigmoid)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:576(Softplus)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:663(PReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:754(Tanhshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:780(Softmin)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:868(Softmax2d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:897(LogSoftmax)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:96(NLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:223(PoissonNLLLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:438(BCELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:598(HingeEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:713(SmoothL1Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:954(CosineEmbeddingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1112(TripletMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1188(CTCLoss)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:75(Bilinear)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:444(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:464(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:24(EventList)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:225(emit_nvtx)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:377(FunctionEvent)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:7(Type)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:8(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:23(THNNBackendBase)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:10(_ContextMethodMixin)\n",
       "        1    0.000    0.000    0.000    0.000 streams.py:131(Event)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:7(RemovableHandle)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1443(MAxisConcatenator)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:1(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:3366(shape)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6284(__array_finalize__)\n",
       "        1    0.000    0.000    0.000    0.000 ctypeslib.py:177(_ndptr)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:805(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 core.py:845(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:882(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:976(_MaskedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:170(LineSplitter)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:18(NumpyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:115(NpzFile)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:162(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _datasource.py:621(Repository)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1858(clear_and_catch_warnings)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:997(SafeEval)\n",
       "        1    0.000    0.000    0.000    0.000 nosetester.py:115(NoseTester)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:231(AxisConcatenator)\n",
       "        1    0.000    0.000    0.000    0.000 function_base.py:1760(vectorize)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1338(FunctionTestCase)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:1396(_SubTest)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:16(BaseTestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:92(TestSuite)\n",
       "        1    0.000    0.000    0.000    0.000 loader.py:23(_FailedTest)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:156(ones)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:100(_str_xmax)\n",
       "        2    0.000    0.000    0.000    0.000 getlimits.py:104(_str_resolution)\n",
       "        1    0.000    0.000    0.000    0.000 getlimits.py:305(finfo)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:278(_CapturingHandler)\n",
       "        6    0.000    0.000    0.000    0.000 case.py:420(addTypeEqualityFunc)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:304(recarray)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:55(_NoValueType)\n",
       "        1    0.000    0.000    0.000    0.000 info.py:156(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:250(_isdst)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:207(send_multipart)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:509(msg_id)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:34(_ensure_tzinfo)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:3(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:114(_compare)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:136(__lt__)\n",
       "        4    0.000    0.000    0.000    0.000 six.py:67(_add_doc)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:138(DeprecatedImport)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:128(MovingBatchNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 norm_flows.py:7(PlanarFlow)\n",
       "        1    0.000    0.000    0.000    0.000 cnf_gate.py:20(CNF_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:6(FeedforwardGateI)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(RunningAverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 dopri5.py:58(Dopri5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:5(Euler)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:7(SequentialDiffEq)\n",
       "        1    0.000    0.000    0.000    0.000 wrappers.py:7(DiffEqWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 adjoint.py:7(OdeintAdjointMethod)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:13(HyperLinear)\n",
       "        2    0.000    0.000    0.000    0.000 squeeze.py:7(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 squeeze.py:6(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:4(SequentialFlow)\n",
       "        1    0.000    0.000    0.000    0.000 cnf.py:11(CNF)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:31(Compose)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:120(Normalize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:360(RandomCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:481(RandomResizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:695(ColorJitter)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:767(RandomRotation)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:71(RankFilter)\n",
       "        1    0.000    0.000    0.000    0.000 semeion.py:17(SEMEION)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:1138(_get_call_pdb)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 configurable.py:381(instance)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:136(_get_args)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:188(iteritems)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:829(__prepare__)\n",
       "        1    0.000    0.000    0.000    0.000 six.py:824(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 py3compat.py:60(safe_unicode)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:1254(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1982(createLock)\n",
       "        1    0.000    0.000    0.000    0.000 copy.py:220(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:203(_cleanup)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:22(constructor)\n",
       "        1    0.000    0.000    0.000    0.000 copyreg.py:12(pickle)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:98(checkgroup)\n",
       "        1    0.000    0.000    0.000    0.000 _collections_abc.py:406(__subclasshook__)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:185(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rstrip' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method '__prepare__' of 'type' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getCompiledVersion}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._jit_init}\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:678(_idat)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:188(iTXt)\n",
       "        1    0.000    0.000    0.000    0.000 PngImagePlugin.py:209(PngInfo)\n",
       "        1    0.000    0.000    0.000    0.000 PpmImagePlugin.py:48(PpmImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:103(GimpGradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 PaletteFile.py:22(PaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 BmpImagePlugin.py:249(DibImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 GimpPaletteFile.py:24(GimpPaletteFile)\n",
       "        1    0.000    0.000    0.000    0.000 TiffTags.py:23(TagInfo)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:294(StubImageFile)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFile.py:549(PyCodecState)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:92(TypeChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:113(TypeCheckerWithDefault)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:125(IntValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:146(EnumValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:166(UnicodeValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:194(Int32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:202(Uint32ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:214(Uint64ValueChecker)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:107(_VarintDecoder)\n",
       "        2    0.000    0.000    0.000    0.000 decoder.py:134(_SignedVarintDecoder)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:126(_SimpleSizer)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:387(_SignedVarintEncoder)\n",
       "        2    0.000    0.000    0.000    0.000 encoder.py:429(_SimpleEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 wire_format.py:80(PackTag)\n",
       "        1    0.000    0.000    0.000    0.000 btm_utils.py:16(MinNode)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:24(BaseBaseString)\n",
       "        1    0.000    0.000    0.000    0.000 basestring.py:33(basestring)\n",
       "        1    0.000    0.000    0.000    0.000 olddict.py:28(BaseOldDict)\n",
       "        1    0.000    0.000    0.000    0.000 oldstr.py:14(BaseOldStr)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:272(DebugMode)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:73(Error)\n",
       "        1    0.000    0.000    0.000    0.000 text_format.py:253(_Printer)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:38(PatternCompiler)\n",
       "        1    0.000    0.000    0.000    0.000 btm_matcher.py:26(BottomMatcher)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:337(NFAState)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:347(DFAState)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:501(LeafPattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:545(NodePattern)\n",
       "        1    0.000    0.000    0.000    0.000 pytree.py:794(NegatedPattern)\n",
       "        1    0.000    0.000    0.000    0.000 patcomp.py:24(PatternSyntaxError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(hooks)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:477(suspend_hooks)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:16(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:43(_EveryNode)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:167(FixerError)\n",
       "        1    0.000    0.000    0.000    0.000 driver.py:30(Driver)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:49(any)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:164(TokenError)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:197(Untokenizer)\n",
       "        1    0.000    0.000    0.000    0.000 pgen.py:7(PgenGrammar)\n",
       "        2    0.000    0.000    0.000    0.000 versions_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:19(Node_base)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:38(Node_py)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:63(Node_py_IO)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:72(Node_py_OP)\n",
       "        1    0.000    0.000    0.000    0.000 pytorch_graph.py:79(Graph_py)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_pr_curve_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 plugin_text_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 odenvp_conditional_tol.py:50(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:1056(Default)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:38(Error)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:42(DescriptorDatabaseConflictingDefinitionError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor_database.py:46(DescriptorDatabase)\n",
       "        1    0.000    0.000    0.000    0.000 message_factory.py:47(MessageFactory)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:60(Error)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:64(ParseError)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:68(Any)\n",
       "        1    0.000    0.000    0.000    0.000 well_known_types.py:398(FieldMask)\n",
       "        2    0.000    0.000    0.000    0.000 types_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:51(Error)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:55(TypeTransformationError)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:64(DescriptorMetaclass)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:165(_NestedDescriptorBase)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:843(FileDescriptor)\n",
       "        2    0.000    0.000    0.000    0.000 api_implementation.py:136(Type)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:672(EnumValueDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:712(OneofDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 descriptor.py:748(ServiceDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:40(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:41(EncodeError)\n",
       "        1    0.000    0.000    0.000    0.000 cpp_message.py:42(GeneratedProtocolMessageType)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:25(InvalidMarker)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:65(Value)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3591(Each)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3792(FollowedBy)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3818(NotAny)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3888(OneOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3923(ZeroOrMore)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3954(_NullToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4026(SkipTo)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4163(__lshift__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4226(TokenConverter)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4234(Combine)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4278(Group)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4299(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4364(Suppress)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4390(OnlyOnce)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:75(Requirement)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:183(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:195(_Constants)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:261(ParseException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:306(RecursiveGrammarException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:314(_ParseResultsWithOffset)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1455(_UnboundedCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2364(Token)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2383(NoMatch)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2398(Literal)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2504(CaselessLiteral)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2606(Word)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2838(QuotedString)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2975(CharsNotIn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3046(White)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3104(GoToColumn)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3160(LineEnd)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3184(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3180(StringStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3199(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3213(WordStart)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3233(WordEnd)\n",
       "        2    0.000    0.000    0.000    0.000 pyparsing.py:3461(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:36(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:42(_BaseVersion)\n",
       "        1    0.000    0.000    0.000    0.000 specifiers.py:15(InvalidSpecifier)\n",
       "        1    0.000    0.000    0.000    0.000 _compat.py:27(metaclass)\n",
       "        1    0.000    0.000    0.000    0.000 requirements.py:18(InvalidRequirement)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:139(MovedAttribute)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:430(Module_six_moves_urllib_response)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:451(Module_six_moves_urllib_robotparser)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:937(_ReqExtras)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1107(ExtractionError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1549(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1536(EmptyProvider)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1556(ZipManifests)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1778(FileMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1817(PathMetadata)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1842(EggMetadata)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1907(find_nothing)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1989(NoDists)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2857(EggInfoDistribution)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:2946(RequirementParseError)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:109(Dict)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:454(_PlistWriter)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:595(_BinaryPlistParser)\n",
       "        1    0.000    0.000    0.000    0.000 train_misc.py:126(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:29(register_writer_factory)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:89(S3RecordWriterFactory)\n",
       "        1    0.000    0.000    0.000    0.000 record_writer.py:104(RecordWriter)\n",
       "        1    0.000    0.000    0.000    0.000 event_file_writer.py:156(_EventLoggerThread)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:118(PEP440Warning)\n",
       "        1    0.000    0.000    0.000    0.000 _matfuncs_sqrtm.py:22(SqrtmError)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:1044(LstsqLapackError)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:85(VoidType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:178(UnknownIntegerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:224(RawFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:239(FunctionPtrType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:261(PointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:293(ArrayType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:324(StructOrUnionOrEnum)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:479(UnionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:483(EnumType)\n",
       "        1    0.000    0.000    0.000    0.000 folder.py:150(ImageFolder)\n",
       "        1    0.000    0.000    0.000    0.000 coco.py:82(CocoDetection)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:174(CIFAR100)\n",
       "        1    0.000    0.000    0.000    0.000 mnist.py:155(FashionMNIST)\n",
       "        1    0.000    0.000    0.000    0.000 fakedata.py:6(FakeData)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2287(ImageTransformHandler)\n",
       "        1    0.000    0.000    0.000    0.000 ImageMode.py:20(ModeDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:2(FFIError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:5(CDefError)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:16(VerificationError)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:185(InceptionC)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:224(InceptionD)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:250(InceptionE)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:292(InceptionAux)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:317(BasicConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:127(_DenseLayer)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:147(_DenseBlock)\n",
       "        1    0.000    0.000    0.000    0.000 densenet.py:165(DenseNet)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:14(LSUNClass)\n",
       "        1    0.000    0.000    0.000    0.000 lsun.py:59(LSUN)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:23(SequentialSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:40(RandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:79(SubsetRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:96(WeightedRandomSampler)\n",
       "        1    0.000    0.000    0.000    0.000 distributed.py:7(DistributedSampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:8(Dataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:26(TensorDataset)\n",
       "        1    0.000    0.000    0.000    0.000 dataset.py:90(Subset)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:39(ExceptionWrapper)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:86(ManagerWatchdog)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:40(DecompressionBombWarning)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:48(_imaging_not_installed)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:479(_E)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:159(Lock)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:184(RLock)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm_gui.py:26(tqdm_gui)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:57(Bottleneck)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:96(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 resnext.py:58(ResNeXt)\n",
       "        1    0.000    0.000    0.000    0.000 vgg.py:24(VGG)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:17(Fire)\n",
       "        1    0.000    0.000    0.000    0.000 squeezenet.py:40(SqueezeNet)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:33(Inception3)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:130(InceptionA)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:59(SOCKSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:133(SOCKSHTTPConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:141(SOCKSProxyManager)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:110(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:123(GeneralProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:127(ProxyConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:131(SOCKS5AuthError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:135(SOCKS5Error)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:143(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:267(_BaseSocket)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:36(TqdmTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:44(TqdmWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:62(TqdmDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:95(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:625(SimpleCookie)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:97(MockResponse)\n",
       "        1    0.000    0.000    0.000    0.000 structures.py:87(LookupDict)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:174(RequestHooksMixin)\n",
       "        1    0.000    0.000    0.000    0.000 models.py:198(Request)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:13(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:79(HTTPBasicAuth)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:1819(PyZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1222(Absent)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1753(LoadError)\n",
       "        1    0.000    0.000    0.000    0.000 cookiejar.py:1755(FileCookieJar)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:150(CookieError)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:32(_X25519PrivateKey)\n",
       "        1    0.000    0.000    0.000    0.000 algorithms.py:133(SEED)\n",
       "        1    0.000    0.000    0.000    0.000 __version__.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:43(BadZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:47(LargeZipFile)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:534(_ZipDecrypter)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:595(LZMACompressor)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:714(_SharedFile)\n",
       "        1    0.000    0.000    0.000    0.000 ocsp.py:113(_SingleResponse)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:272(_RSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 rsa.py:299(_RSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:31(PSS)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:62(MGF1)\n",
       "        1    0.000    0.000    0.000    0.000 x25519.py:13(_X25519PublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:47(_DSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 dsa.py:84(_DSAParameters)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:92(_ECDSASignatureContext)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:108(_ECDSAVerificationContext)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:30(ModeWithInitializationVector)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:39(ModeWithTweak)\n",
       "        1    0.000    0.000    0.000    0.000 modes.py:124(ECB)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:23(_Integers)\n",
       "        1    0.000    0.000    0.000    0.000 decode_asn1.py:186(_X509ExtensionParser)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2099(GetCipherByName)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:118(_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:239(Error)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:253(WantWriteError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:257(WantX509LookupError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:265(SysCallError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:336(_NpnAdvertiseHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:377(_NpnSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:426(_ALPNSelectHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:477(_OCSPServerCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:549(_OCSPClientCallbackHelper)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_finish}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ERR_clear_error}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.RAND_cleanup}\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:46(cryptography_has_ssl3_method)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:151(cryptography_has_locking_callbacks)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ASN1_STRING_set_default_mask_asc}\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:104(SHA1)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:111(SHA224)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:118(SHA256)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:125(SHA384)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:132(SHA512)\n",
       "        1    0.000    0.000    0.000    0.000 hashes.py:139(MD5)\n",
       "        6    0.000    0.000    0.000    0.000 binding.py:54(_openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'gc' of 'CompiledFFI' objects}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:193(KeySerializationEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 general_name.py:35(UnsupportedGeneralNameType)\n",
       "        1    0.000    0.000    0.000    0.000 package_data.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:16(IDNAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:21(IDNABidiError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:26(InvalidCodepoint)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:31(InvalidCodepointContext)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1572(Primitive)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1776(Boolean)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1829(Integer)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2286(IntegerBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2448(IntegerOctetString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2665(ParsableOctetBitString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2948(InstanceOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3032(UTF8String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:3041(RelativeOid)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4298(Set)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4484(SetOf)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4525(NumericString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4534(PrintableString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4543(TeletexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4560(IA5String)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4569(AbstractTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4615(UTCTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4671(GeneralizedTime)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4744(GraphicString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4754(VisibleString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4782(CharacterString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4792(BMPString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:14(TeletexCodec)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:23(TeletexIncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:29(TeletexIncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:35(TeletexStreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:218(IncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:253(IncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:292(StreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:30(LibraryNotFoundError)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:43(AlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:120(HmacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:127(DigestAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:141(DigestAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:149(DigestInfo)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:162(MaskGenAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:174(TrailerField)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:365(Pbkdf2Salt)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:381(KdfAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:387(KdfAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:398(DHParameters)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:411(KeyExchangeAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:417(KeyExchangeAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:428(Rc2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:435(Rc5ParamVersion)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:441(Rc5Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:450(Pbes1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:457(PSourceAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:475(RSAESOAEPParams)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1084(Pbes2Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1091(Pbmac1Params)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1104(Pkcs5MacAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1119(AnyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1129(AnyAlgorithmIdentifier)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:649(Castable)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:693(Constructable)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:852(OCSPNoCheck)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:857(PrecertPoison)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:66(OtherPrimeInfos)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:206(ECPoint)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:211(ECPointBitString)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:216(SpecifiedECDomainVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:227(FieldType)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:239(CharacteristicTwoBasis)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:284(FieldID)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:301(Curve)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:396(ECPrivateKeyVersion)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:420(DSAParams)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:454(PrivateKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:886(EncryptedPrivateKeyInfo)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:899(ValidationParms)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:910(DomainParameters)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:924(PublicKeyAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:24(UnsupportedAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:34(AlreadyUpdated)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:38(NotYetFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:46(InvalidSignature)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(InternalError)\n",
       "        1    0.000    0.000    0.000    0.000 extensions.py:57(ExtensionNotFound)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:145(SECT571R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:151(SECT409R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:157(SECT283R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:163(SECT233R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:175(SECT571K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:181(SECT409K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:187(SECT283K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:193(SECT233K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:199(SECT163K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:205(SECP521R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:211(SECP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:229(SECP224R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:241(BrainpoolP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:253(BrainpoolP512R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:288(ECDSA)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:420(ECDH)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:16(CryptographyDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:73(InvalidVersion)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:693(RevokedCertificateBuilder)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(register_interface_if)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:79(InterfaceNotImplemented)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:115(_DeprecatedValue)\n",
       "        1    0.000    0.000    0.000    0.000 sbcsgroupprober.py:43(SBCSGroupProber)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:28(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:32(ConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:36(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:44(Timeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:53(ConnectTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:64(URLRequired)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:72(MissingSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:80(InvalidURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:84(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:88(InvalidProxyURL)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:92(ChunkedEncodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:96(ContentDecodingError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:104(RetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:114(RequestsWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:124(RequestsDependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 crypto.py:1682(X509StoreContextError)\n",
       "        1    0.000    0.000    0.000    0.000 euctwfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:132(EUCKRDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:151(GB2312DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:170(Big5DistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:192(SJISDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 chardistribution.py:217(EUCJPDistributionAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 euckrfreq.py:41(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 big5freq.py:43(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jisfreq.py:44(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 jpcntx.py:212(EUCJPContextAnalysis)\n",
       "        1    0.000    0.000    0.000    0.000 fields.py:50(RequestField)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:22(DeflateDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:55(GzipDecoderState)\n",
       "        1    0.000    0.000    0.000    0.000 response.py:62(GzipDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:8(InputState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:41(MachineState)\n",
       "        1    0.000    0.000    0.000    0.000 enums.py:65(CharacterCategory)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:65(DummyConnection)\n",
       "        1    0.000    0.000    0.000    0.000 connection.py:263(VerifiedHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 wait.py:13(NoWayToWaitForSocketError)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:14(is_appengine_sandbox)\n",
       "        1    0.000    0.000    0.000    0.000 _appengine_environ.py:29(is_prod_appengine_mvms)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:8(HTTPError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:13(HTTPWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:18(PoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:29(RequestError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:45(ProxyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:50(DecodeError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:66(MaxRetryError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:99(TimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(ReadTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:120(NewConnectionError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:125(EmptyPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:140(LocationParseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:194(ResponseNotChunked)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:207(IncompleteRead)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:228(ProxySchemeUnknown)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:237(HeaderParsingError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:5(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:28(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:27(CUDAModule)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:77(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:290(ExpTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:362(AbsTransform)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:446(SoftmaxTransform)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:49(Constraint)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:67(_Dependent)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:106(_IntegerInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:123(_IntegerLessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:139(_IntegerGreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:155(_Real)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:167(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:163(_GreaterThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:183(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:179(_GreaterThanEq)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:195(_LessThan)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:215(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:232(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:228(_HalfOpenInterval)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:245(_Simplex)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:263(_LowerCholesky)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:277(_PositiveDefinite)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:105(lazy_property)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:20(StorageWeakRef)\n",
       "        1    0.000    0.000    0.000    0.000 reductions.py:39(SharedCache)\n",
       "        1    0.000    0.000    0.000    0.000 resource_sharer.py:45(DupFd)\n",
       "        1    0.000    0.000    0.000    0.000 spawn.py:40(SpawnContext)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:13(ExportTypes)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:234(LegacyTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:408(TracingCheckError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:549(TracerWarning)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:649(CompilationUnit)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:817(OrderedModuleDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:847(OrderedParameterDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:868(OrderedBufferDict)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:926(ScriptMeta)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1164(WeakScriptModuleProxy)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1292(TracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1349(TopLevelTracedModule)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1384(_ConstSequential)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1465(_disable_tracing)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:90(FrontendError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:102(NotSupportedError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:106(UnsupportedNodeError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:119(FrontendTypeError)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:152(SourceContext)\n",
       "        1    0.000    0.000    0.000    0.000 frontend.py:158(Builder)\n",
       "        1    0.000    0.000    0.000    0.000 annotations.py:14(Module)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:12(dist_backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:149(group)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:153(_DistributedRequest)\n",
       "        1    0.000    0.000    0.000    0.000 adadelta.py:6(Adadelta)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:9(_RequiredParameter)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:111(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 optimizer.py:150(update_group)\n",
       "        1    0.000    0.000    0.000    0.000 adamax.py:5(Adamax)\n",
       "        1    0.000    0.000    0.000    0.000 sgd.py:5(SGD)\n",
       "        1    0.000    0.000    0.000    0.000 lbfgs.py:6(LBFGS)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:56(LambdaLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:126(StepLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:198(ExponentialLR)\n",
       "        1    0.000    0.000    0.000    0.000 lr_scheduler.py:217(CosineAnnealingLR)\n",
       "        1    0.000    0.000    0.000    0.000 distance.py:47(CosineSimilarity)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:9(Broadcast)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:50(Gather)\n",
       "        1    0.000    0.000    0.000    0.000 _functions.py:78(Scatter)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:71(reduce_op)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:93(group)\n",
       "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:97(GroupMember)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:61(Dropout2d)\n",
       "        1    0.000    0.000    0.000    0.000 dropout.py:149(AlphaDropout)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(ConstantPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:75(ConstantPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:178(ReflectionPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:220(ReflectionPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:282(ReplicationPad1d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:370(ReplicationPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:232(RNN)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:333(LSTM)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:441(GRU)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:537(RNNCellBase)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:585(RNNCell)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:143(UpsamplingNearest2d)\n",
       "        1    0.000    0.000    0.000    0.000 upsampling.py:188(UpsamplingBilinear2d)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:11(Container)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:84(MaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:151(MaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:222(_MaxUnpoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:231(MaxUnpool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:297(MaxUnpool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:371(MaxUnpool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:434(_AvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:502(AvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:568(AvgPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:647(FractionalMaxPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:707(_LPPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:766(LPPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:822(_AdaptiveMaxPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:899(AdaptiveMaxPool3d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:936(_AdaptiveAvgPoolNd)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:948(AdaptiveAvgPool1d)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:971(AdaptiveAvgPool2d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:172(BatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 batchnorm.py:246(BatchNorm3d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:58(InstanceNorm1d)\n",
       "        1    0.000    0.000    0.000    0.000 instancenorm.py:134(InstanceNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:58(CrossMapLRN2d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:323(Conv3d)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:760(ConvTranspose3d)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:59(ReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:89(RReLU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:146(Hardtanh)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:210(ReLU6)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:295(ELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:380(SELU)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:459(Hardshrink)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:728(Softsign)\n",
       "        1    0.000    0.000    0.000    0.000 activation.py:818(Softmax)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:12(_Loss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:370(MSELoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:507(BCEWithLogitsLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:773(SoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:815(CrossEntropyLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:907(MultiLabelSoftMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1001(MarginRankingLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:1049(MultiMarginLoss)\n",
       "        1    0.000    0.000    0.000    0.000 _jit_internal.py:196(BroadcastingListCls)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:160(flags_frozen)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:204(TensorDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:226(TensorDescriptorArray)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:277(DropoutDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:321(RNNDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:443(ContextProp)\n",
       "        1    0.000    0.000    0.000    0.000 _VF.py:6(VFModule)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:12(range)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:360(Interval)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:407(FunctionEventAvg)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:431(StringTable)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:497(EnforceUnique)\n",
       "        1    0.000    0.000    0.000    0.000 tensor.py:25(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:5(no_grad)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:47(enable_grad)\n",
       "        1    0.000    0.000    0.000    0.000 grad_mode.py:91(set_grad_enabled)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:4(detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:75(set_detect_anomaly)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:61(_HookMixin)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:72(BackwardCFunction)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:79(FunctionMeta)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:242(InplaceFunction)\n",
       "        1    0.000    0.000    0.000    0.000 function.py:249(_nested_map)\n",
       "        1    0.000    0.000    0.000    0.000 thnn.py:4(THNNFunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:4(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 backend.py:2(FunctionBackend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:6(Backends)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:18(Backend)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(THNNCudaBackendStateMixin)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:59(Argument)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:5(VariableMeta)\n",
       "        1    0.000    0.000    0.000    0.000 variable.py:10(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:130(DeferredCudaCallError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:195(cudaStatus)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:200(CudaError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:211(device)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:499(_CudaBase)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:510(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:530(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:538(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:716(ExFileObject)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:8(__PrinterOptions)\n",
       "        1    0.000    0.000    0.000    0.000 _tensor_str.py:68(_Formatter)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:275(TarError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:278(ExtractError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:281(ReadError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:284(CompressionError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:287(StreamError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:290(HeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:293(EmptyHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:296(TruncatedHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:299(EOFHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:305(SubsequentHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:582(_StreamProxy)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:1473(mr_class)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:194(DoubleStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:202(HalfStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:206(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:210(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:214(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:218(CharStorage)\n",
       "        1    0.000    0.000    0.000    0.000 _utils_internal.py:28(prepare_multiprocessing_environment)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:32(SourceChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2384(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2378(_MaskedPrintOption)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2596(MaskedIterator)\n",
       "        4    0.000    0.000    0.000    0.000 core.py:6260(__has_singleton)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:6557(_frommethod)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:8048(_convert2ma)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:218(_fromnxfunction)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:273(_fromnxfunction_single)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:291(_fromnxfunction_seq)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:304(_fromnxfunction_args)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:329(_fromnxfunction_allargs)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:95(MaskedArrayFutureWarning)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:174(MaskError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:206(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:208(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:796(_DomainCheckInterval)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:829(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:821(_DomainTan)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:839(_DomainSafeDivide)\n",
       "        3    0.000    0.000    0.000    0.000 core.py:866(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:860(_DomainGreater)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:876(_DomainGreaterEqual)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:892(_MaskedUFunc)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:902(_MaskedUnaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1124(_DomainedBinaryOperation)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1283(_replace_dtype_fields_recursive)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:58(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:62(PolyError)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:79(PolyBase)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:464(ConverterError)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:14(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:28(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 _distributor_init.py:13(RTLD_for_MKL)\n",
       "        1    0.000    0.000    0.000    0.000 polynomial.py:22(RankWarning)\n",
       "        1    0.000    0.000    0.000    0.000 npyio.py:51(BagObj)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_string_function}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.set_typeDict}\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:204(dummy_ctype)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:239(_missing_ctypes)\n",
       "        1    0.000    0.000    0.000    0.000 linalg.py:44(LinAlgError)\n",
       "        1    0.000    0.000    0.000    0.000 stride_tricks.py:15(DummyArray)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:57(_Deprecate)\n",
       "        1    0.000    0.000    0.000    0.000 decorators.py:99(skipif)\n",
       "        1    0.000    0.000    0.000    0.000 pytesttester.py:47(PytestTester)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:159(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:98(nd_grid)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:446(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:351(RClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:476(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:451(CClass)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:481(ndenumerate)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:531(ndindex)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:653(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:609(IndexExpression)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:270(_ErrorHolder)\n",
       "        1    0.000    0.000    0.000    0.000 suite.py:317(_DebugResult)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:13(_WritelnDecorator)\n",
       "        1    0.000    0.000    0.000    0.000 runner.py:120(TextTestRunner)\n",
       "        1    0.000    0.000    0.000    0.000 signals.py:9(_InterruptHandler)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:45(KnownFailureException)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1212(_Dummy)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:683(TooHardError)\n",
       "        1    0.000    0.000    0.000    0.000 _internal.py:686(AxisError)\n",
       "        1    0.000    0.000    0.000    0.000 numerictypes.py:750(_typedict)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:83(ComplexWarning)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2817(_unspecified)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:2824(errstate)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:25(SkipTest)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:33(_ShouldStop)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:128(_BaseTestCaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:184(_AssertRaisesContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:221(_AssertWarnsContext)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:297(_AssertLogsContext)\n",
       "        2    0.000    0.000    0.000    0.000 arrayprint.py:440(_recursive_guard)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:810(FloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:960(LongFloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1109(IntegerFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1132(ComplexFloatingFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1161(ComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1168(LongComplexFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1176(_TimelikeFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1234(TimedeltaFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1239(SubArrayFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1249(StructuredVoidFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1286(StructureFormat)\n",
       "        1    0.000    0.000    0.000    0.000 records.py:85(format_parser)\n",
       "        1    0.000    0.000    0.000    0.000 memmap.py:20(memmap)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:45(VisibleDeprecationWarning)\n",
       "        9    0.000    0.000    0.000    0.000 _globals.py:73(__repr__)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:5(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 _import_tools.py:339(PackageLoaderDebug)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:21(PytestTester)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:78(_compare_version)\n",
       "        1    0.000    0.000    0.000    0.000 _ccallback.py:9(CData)\n",
       "        1    0.000    0.000    0.000    0.000 normalization.py:134(MovingBatchNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 coupling.py:51(MaskedCouplingLayer)\n",
       "        1    0.000    0.000    0.000    0.000 gate.py:47(FeedforwardGateII)\n",
       "        1    0.000    0.000    0.000    0.000 container_gate.py:4(SequentialFlow_Gate)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:40(AverageMeter)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:115(ParallelSumModules)\n",
       "        1    0.000    0.000    0.000    0.000 multiscale_parallel.py:126(ParallelCNFLayers)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:83(ActNorm2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:95(LinearZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:152(Conv2dZeros)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:170(Permute2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:194(InvertibleConv1x1)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:291(Split2d)\n",
       "        1    0.000    0.000    0.000    0.000 modules.py:347(SqueezeLayer)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:26(RK4)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_adams.py:208(AdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:18(_VCABMState)\n",
       "        1    0.000    0.000    0.000    0.000 fixed_grid.py:15(Midpoint)\n",
       "        1    0.000    0.000    0.000    0.000 adams.py:61(VariableCoefficientAdamsBashforth)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:63(Swish)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:73(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:176(AutoencoderDiffEqNet)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:255(ODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 odefunc.py:316(AutoencoderODEfunc)\n",
       "        1    0.000    0.000    0.000    0.000 container.py:21(MixtureODELayer)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:9(ResNet)\n",
       "        1    0.000    0.000    0.000    0.000 resnet.py:38(BasicBlock)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:36(IgnoreLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:45(ConcatLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:56(ConcatLinear_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:66(SquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:76(ConcatSquashLinear)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:88(HyperConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:124(IgnoreConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:137(SquashConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:151(ConcatConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:166(ConcatConv2d_v2)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:196(ConcatCoordConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:226(GatedConv)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:272(BlendConv2d)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:8(ZeroMeanTransform)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:25(LogitTransform)\n",
       "        1    0.000    0.000    0.000    0.000 elemwise.py:43(SigmoidTransform)\n",
       "        1    0.000    0.000    0.000    0.000 tsit5.py:66(Tsit5Solver)\n",
       "        1    0.000    0.000    0.000    0.000 rk_common.py:8(_RungeKuttaState)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:61(ToTensor)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:82(ToPILImage)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:149(Resize)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:182(Scale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:192(CenterCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:271(Lambda)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:289(RandomTransforms)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:312(RandomApply)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:341(RandomOrder)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:352(RandomChoice)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:429(RandomHorizontalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:455(RandomVerticalFlip)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:557(RandomSizedCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:606(TenCrop)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:649(LinearTransformation)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:834(RandomAffine)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:954(Grayscale)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:984(RandomGrayscale)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:24(_Enhance)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:74(Brightness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:89(Sharpness)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:28(Filter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:36(BuiltinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:43(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:94(MedianFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:108(MinFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:122(MaxFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:136(ModeFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:153(GaussianBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:167(BoxBlur)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:187(UnsharpMask)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:212(BLUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:223(CONTOUR)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:232(DETAIL)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:268(FIND_EDGES)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:295(SMOOTH_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 hooks.py:124(synchronize_with_editor)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:45(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:39(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 ultratb.py:422(is_recursion_error)\n",
       "        1    0.000    0.000    0.000    0.000 configurable.py:426(initialized)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:595(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1211(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'pack' of 'Struct' objects}\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:1253(<lambda>)\n",
       "       10    0.000    0.000    0.000    0.000 copy.py:111(_copy_immutable)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:287(seek)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:743(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 subprocess.py:1366(_internal_poll)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:337(__members__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:101(checklookbehindgroup)\n",
       "        4    0.000    0.000    0.000    0.000 sre_parse.py:161(__delitem__)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:213(setstate)\n",
       "        1    0.000    0.000    0.000    0.000 GimpGradientFile.py:62(GradientFile)\n",
       "        1    0.000    0.000    0.000    0.000 type_checkers.py:208(Int64ValueChecker)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:288(_FloatDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 decoder.py:323(_DoubleDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:155(_ModifiedSizer)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:372(_VarintEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 encoder.py:470(_ModifiedEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 pygram.py:20(Symbols)\n",
       "        1    0.000    0.000    0.000    0.000 refactor.py:688(MultiprocessingUnsupported)\n",
       "        1    0.000    0.000    0.000    0.000 tokenize.py:166(StopTokenizing)\n",
       "        3    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:5(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 message.py:39(Error)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:31(UndefinedComparison)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:37(UndefinedEnvironmentName)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:59(Variable)\n",
       "        1    0.000    0.000    0.000    0.000 markers.py:71(Op)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:4222(_ForwardNoRecurse)\n",
       "        1    0.000    0.000    0.003    0.003 pyparsing.py:4904(makeHTMLTags)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:282(ParseFatalException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:287(ParseSyntaxException)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:1478(_FifoCache)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:2372(Empty)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3097(_PositionToken)\n",
       "        1    0.000    0.000    0.000    0.000 pyparsing.py:3384(_ErrorStop)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:8(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:320(Module_six_moves_urllib_parse)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:328(UnknownExtra)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:2076(register_namespace_handler)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:3165(PkgResourcesDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 plistlib.py:587(InvalidFileException)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:249(ResolutionError)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:192(UnknownFloatType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:204(BaseFunctionType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:284(NamedPointerType)\n",
       "        1    0.000    0.000    0.000    0.000 model.py:475(StructType)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:2282(ImagePointHandler)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:25(deferred_error)\n",
       "        1    0.000    0.000    0.000    0.000 error.py:20(VerificationMissing)\n",
       "        1    0.000    0.000    0.000    0.000 Image.py:44(DecompressionBombError)\n",
       "        1    0.000    0.000    0.000    0.000 _monitor.py:8(TqdmSynchronisationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:123(Semaphore)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:142(BoundedSemaphore)\n",
       "        1    0.000    0.000    0.000    0.000 inception.py:162(InceptionB)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:129(SOCKSHTTPSConnection)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:137(SOCKSHTTPSConnectionPool)\n",
       "        1    0.000    0.000    0.000    0.000 socks.py:139(SOCKS4Error)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:40(TqdmKeyError)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:57(TqdmExperimentalWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _tqdm.py:67(TqdmMonitorWarning)\n",
       "        1    0.000    0.000    0.000    0.000 cookies.py:165(CookieConflictError)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:72(AuthBase)\n",
       "        1    0.000    0.000    0.000    0.000 auth.py:100(HTTPProxyAuth)\n",
       "        1    0.000    0.000    0.000    0.000 zipfile.py:618(LZMADecompressor)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:26(PKCS1v15)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:49(OAEP)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:249(WantReadError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:261(ZeroReturnError)\n",
       "        1    0.000    0.000    0.000    0.000 SSL.py:673(Session)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _openssl.ENGINE_free}\n",
       "        1    0.000    0.000    0.000    0.000 binding.py:154(_verify_openssl_version)\n",
       "        1    0.000    0.000    0.000    0.000 _conditional.py:135(cryptography_has_ssl_st)\n",
       "        1    0.000    0.000    0.000    0.000 _util.py:62(openssl_assert)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:198(BestAvailableEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:207(NoEncryption)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2940(ObjectDescriptor)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:2956(Real)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4517(EmbeddedPdv)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4552(VideotexString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4763(GeneralString)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:4773(UniversalString)\n",
       "        1    0.000    0.000    0.000    0.000 _teletex_codec.py:40(TeletexStreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:295(StreamReader)\n",
       "        1    0.000    0.000    0.000    0.000 _ffi.py:39(FFIEngineError)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:156(MaskGenAlgorithmId)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:463(PSourceAlgorithm)\n",
       "        1    0.000    0.000    0.000    0.000 algos.py:1098(Pkcs5MacId)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:105(RSAPublicKey)\n",
       "        1    0.000    0.000    0.000    0.000 keys.py:446(Attributes)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:30(AlreadyFinalized)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:42(InvalidTag)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:56(InvalidKey)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:169(SECT163R2)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:217(SECP256R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:223(SECP256K1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:235(SECP192R1)\n",
       "        1    0.000    0.000    0.000    0.000 ec.py:247(BrainpoolP384R1)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:60(ReadTimeout)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:68(TooManyRedirects)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:76(InvalidSchema)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:100(StreamConsumedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:108(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:119(FileModeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 pyopenssl.py:54(UnsupportedExtension)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:55(ProtocolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:85(HostChangedError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:94(TimeoutStateError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:115(ConnectTimeoutError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:130(ClosedPoolError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:135(LocationValueError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:150(ResponseError)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:156(SecurityWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:161(SubjectAltNameWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:166(InsecureRequestWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:171(SystemTimeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:176(InsecurePlatformWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:181(SNIMissingWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:186(DependencyWarning)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:199(BodyNotHttplibCompatible)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:223(InvalidHeader)\n",
       "        1    0.000    0.000    0.000    0.000 exceptions.py:244(UnrewindableBodyError)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:80(_DependentProperty)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:254(_LowerTriangular)\n",
       "        1    0.000    0.000    0.000    0.000 constraints.py:291(_RealVector)\n",
       "        2    0.000    0.000    0.000    0.000 optimizer.py:119(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:130(ConstantPad3d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:321(ReplicationPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 padding.py:406(ZeroPad2d)\n",
       "        1    0.000    0.000    0.000    0.000 rnn.py:736(GRUCell)\n",
       "        1    0.000    0.000    0.000    0.000 spectral_norm.py:177(SpectralNormStateDictHook)\n",
       "        1    0.000    0.000    0.000    0.000 conv.py:617(ConvTranspose2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:21(_WeightedLoss)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:213(NLLLoss2d)\n",
       "        1    0.000    0.000    0.000    0.000 loss.py:289(KLDivLoss)\n",
       "        4    0.000    0.000    0.000    0.000 utils.py:5(_ntuple)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:187(CuDNNHandle)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:197(CuDNNError)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:369(Kernel)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:514(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:518(LongStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:522(IntStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:526(ShortStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:534(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:302(InvalidHeaderError)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:198(FloatStorage)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:222(ByteStorage)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:166(MAError)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:1329(make_mask_descr)\n",
       "        1    0.000    0.000    0.000    0.000 _version.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 polyutils.py:66(PolyDomainError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:472(ConverterLockError)\n",
       "        1    0.000    0.000    0.000    0.000 _iotools.py:480(ConversionWarning)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:1816(IgnoreException)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:38(_UnexpectedSuccess)\n",
       "        1    0.000    0.000    0.000    0.000 case.py:137(_AssertRaisesBaseContext)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:953(FloatFormat)\n",
       "        1    0.000    0.000    0.000    0.000 arrayprint.py:1122(BoolFormat)\n",
       "        1    0.000    0.000    0.000    0.000 _globals.py:33(ModuleDeprecationWarning)\n",
       "        1    0.000    0.000    0.000    0.000 _testutils.py:16(FPUModeChangeWarning)\n",
       "        1    0.000    0.000    0.000    0.000 misc.py:11(LinAlgWarning)\n",
       "        1    0.000    0.000    0.000    0.000 basic.py:242(GatedConvTranspose)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:40(Color)\n",
       "        1    0.000    0.000    0.000    0.000 ImageEnhance.py:58(Contrast)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:32(MultibandFilter)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:241(EDGE_ENHANCE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:250(EDGE_ENHANCE_MORE)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:259(EMBOSS)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:277(SHARPEN)\n",
       "        1    0.000    0.000    0.000    0.000 ImageFilter.py:286(SMOOTH)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:196(get_start_method)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle.py --data mnist --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 8000 --test_batch_size 5000 --save ../experiments_published/cnf_conditional_disentangle_bs8K_sratio_0_25_drop_0_5_run2 --resume ../experiments_published/cnf_conditional_disentangle_bs8K_sratio_0_25_drop_0_5_run2/epoch_365_checkpt.pth --seed 2 --conditional True --controlled_tol True --train_mode semisup --lr 0.0001 --warmup_iters 113 --atol 1e-4  --rtol 1e-4 --weight_y 0.5 --condition_ratio 0.25 --dropout_rate 0.5\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
