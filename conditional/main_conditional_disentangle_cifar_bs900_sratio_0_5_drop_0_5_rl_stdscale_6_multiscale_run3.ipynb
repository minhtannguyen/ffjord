{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/train_cnf_disentangle_rl_multiscale.py\n",
      "import argparse\n",
      "import os\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torchvision.datasets as dset\n",
      "import torchvision.transforms as tforms\n",
      "from torchvision.utils import save_image\n",
      "\n",
      "import torch.utils.data as data\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['figure.dpi'] = 300\n",
      "\n",
      "from PIL import Image\n",
      "import os.path\n",
      "import errno\n",
      "import codecs\n",
      "\n",
      "import lib.layers as layers\n",
      "import lib.utils as utils\n",
      "import lib.multiscale_parallel as multiscale_parallel\n",
      "import lib.modules as modules\n",
      "import lib.thops as thops\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time, count_nfe_gate\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "# go fast boi!!\n",
      "torch.backends.cudnn.benchmark = True\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams']\n",
      "GATES = [\"cnn1\", \"cnn2\", \"rnn\"]\n",
      "\n",
      "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
      "parser.add_argument(\"--data\", choices=[\"mnist\", \"colormnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
      "parser.add_argument(\"--dims\", type=str, default=\"8,32,32,8\")\n",
      "parser.add_argument(\"--strides\", type=str, default=\"2,2,1,-2,-2\")\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "\n",
      "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"ignore\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\n",
      "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--seed\", type=int, default=0)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--gate', type=str, default='cnn1', choices=GATES)\n",
      "parser.add_argument('--scale', type=float, default=1.0)\n",
      "parser.add_argument('--scale_fac', type=float, default=1.0)\n",
      "parser.add_argument('--scale_std', type=float, default=1.0)\n",
      "parser.add_argument('--eta', default=0.1, type=float,\n",
      "                        help='tuning parameter that allows us to trade-off the competing goals of' \n",
      "                                'minimizing the prediction loss and maximizing the gate rewards ')\n",
      "parser.add_argument('--rl-weight', default=0.01, type=float,\n",
      "                        help='rl weight')\n",
      "\n",
      "parser.add_argument('--gamma', default=0.99, type=float,\n",
      "                        help='discount factor, default: (0.99)')\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
      "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
      "parser.add_argument('--time_length', type=float, default=1.0)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "\n",
      "parser.add_argument(\"--num_epochs\", type=int, default=500)\n",
      "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
      "parser.add_argument(\n",
      "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
      ")\n",
      "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
      "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
      "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
      "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
      "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
      "parser.add_argument(\"--weight_y\", type=float, default=0.5)\n",
      "parser.add_argument(\"--annealing_std\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--y_class\", type=int, default=10)\n",
      "parser.add_argument(\"--y_color\", type=int, default=10)\n",
      "\n",
      "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--multiscale', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--conditional', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--controlled_tol', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument(\"--train_mode\", choices=[\"semisup\", \"sup\", \"unsup\"], type=str, default=\"semisup\")\n",
      "parser.add_argument(\"--condition_ratio\", type=float, default=0.5)\n",
      "parser.add_argument(\"--dropout_rate\", type=float, default=0.0)\n",
      "\n",
      "\n",
      "# Regularizations\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
      "parser.add_argument(\n",
      "    \"--max_grad_norm\", type=float, default=1e10,\n",
      "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
      ")\n",
      "\n",
      "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
      "parser.add_argument(\"--resume\", type=str, default=None)\n",
      "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
      "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
      "parser.add_argument(\"--log_freq\", type=int, default=1)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "import lib.odenvp_conditional_rl_multiscale as odenvp\n",
      "    \n",
      "# set seed\n",
      "torch.manual_seed(args.seed)\n",
      "np.random.seed(args.seed)\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__)) # write to log file\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "class ColorMNIST(data.Dataset):\n",
      "    \"\"\"\n",
      "    ColorMNIST\n",
      "    \"\"\"\n",
      "    urls = [\n",
      "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
      "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
      "    ]\n",
      "    raw_folder = 'raw'\n",
      "    processed_folder = 'processed'\n",
      "    training_file = 'training.pt'\n",
      "    test_file = 'test.pt'\n",
      "\n",
      "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
      "        self.root = os.path.expanduser(root)\n",
      "        self.transform = transform\n",
      "        self.target_transform = target_transform\n",
      "        self.train = train  # training set or test set\n",
      "\n",
      "        if download:\n",
      "            self.download()\n",
      "\n",
      "        if not self._check_exists():\n",
      "            raise RuntimeError('Dataset not found.' +\n",
      "                               ' You can use download=True to download it')\n",
      "\n",
      "        if self.train:\n",
      "            self.train_data, self.train_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
      "            \n",
      "            self.train_data = np.tile(self.train_data[:, :, :, np.newaxis], 3)\n",
      "        else:\n",
      "            self.test_data, self.test_labels = torch.load(\n",
      "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "            \n",
      "            self.test_data = np.tile(self.test_data[:, :, :, np.newaxis], 3)\n",
      "        \n",
      "        self.pallette = [[31, 119, 180],\n",
      "                         [255, 127, 14],\n",
      "                         [44, 160, 44],\n",
      "                         [214, 39, 40],\n",
      "                         [148, 103, 189],\n",
      "                         [140, 86, 75],\n",
      "                         [227, 119, 194],\n",
      "                         [127, 127, 127],\n",
      "                         [188, 189, 34],\n",
      "                         [23, 190, 207]]\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            index (int): Index\n",
      "\n",
      "        Returns:\n",
      "            tuple: (image, target) where target is index of the target class.\n",
      "        \"\"\"\n",
      "        if self.train:\n",
      "            img, target = self.train_data[index].copy(), self.train_labels[index]\n",
      "        else:\n",
      "            img, target = self.test_data[index].copy(), self.test_labels[index]\n",
      "        \n",
      "        # doing this so that it is consistent with all other datasets\n",
      "        # to return a PIL Image\n",
      "        y_color_digit = np.random.randint(0, args.y_color)\n",
      "        c_digit = self.pallette[y_color_digit]\n",
      "        \n",
      "        img[:, :, 0] = img[:, :, 0] / 255 * c_digit[0]\n",
      "        img[:, :, 1] = img[:, :, 1] / 255 * c_digit[1]\n",
      "        img[:, :, 2] = img[:, :, 2] / 255 * c_digit[2]\n",
      "        \n",
      "        img = Image.fromarray(img)\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "\n",
      "        return img, [target,torch.from_numpy(np.array(y_color_digit))]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.train:\n",
      "            return len(self.train_data)\n",
      "        else:\n",
      "            return len(self.test_data)\n",
      "\n",
      "    def _check_exists(self):\n",
      "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
      "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
      "\n",
      "    def download(self):\n",
      "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
      "        from six.moves import urllib\n",
      "        import gzip\n",
      "\n",
      "        if self._check_exists():\n",
      "            return\n",
      "\n",
      "        # download files\n",
      "        try:\n",
      "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
      "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
      "        except OSError as e:\n",
      "            if e.errno == errno.EEXIST:\n",
      "                pass\n",
      "            else:\n",
      "                raise\n",
      "\n",
      "        for url in self.urls:\n",
      "            print('Downloading ' + url)\n",
      "            data = urllib.request.urlopen(url)\n",
      "            filename = url.rpartition('/')[2]\n",
      "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
      "            with open(file_path, 'wb') as f:\n",
      "                f.write(data.read())\n",
      "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
      "                    gzip.GzipFile(file_path) as zip_f:\n",
      "                out_f.write(zip_f.read())\n",
      "            os.unlink(file_path)\n",
      "\n",
      "        # process and save as torch files\n",
      "        print('Processing...')\n",
      "\n",
      "        training_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
      "        )\n",
      "        test_set = (\n",
      "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
      "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
      "        )\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
      "            torch.save(training_set, f)\n",
      "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
      "            torch.save(test_set, f)\n",
      "\n",
      "        print('Done!')\n",
      "\n",
      "    def __repr__(self):\n",
      "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
      "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
      "        tmp = 'train' if self.train is True else 'test'\n",
      "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
      "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
      "        tmp = '    Transforms (if any): '\n",
      "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        tmp = '    Target Transforms (if any): '\n",
      "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
      "        return fmt_str\n",
      "\n",
      "def add_noise(x):\n",
      "    \"\"\"\n",
      "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
      "    \"\"\"\n",
      "    if args.add_noise:\n",
      "        noise = x.new().resize_as_(x).uniform_()\n",
      "        x = x * 255 + noise\n",
      "        x = x / 256\n",
      "    return x\n",
      "\n",
      "\n",
      "def update_lr(optimizer, itr):\n",
      "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
      "    lr = args.lr * iter_frac\n",
      "    for param_group in optimizer.param_groups:\n",
      "        param_group[\"lr\"] = lr\n",
      "\n",
      "        \n",
      "def update_scale_std(model, epoch):\n",
      "    epoch_frac = 1.0 - float(epoch - 1) / max(args.num_epochs + 1, 1)\n",
      "    scale_std = args.scale_std * epoch_frac\n",
      "    model.set_scale_std(scale_std)\n",
      "\n",
      "\n",
      "def get_train_loader(train_set, epoch):\n",
      "    if args.batch_size_schedule != \"\":\n",
      "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
      "        n_passed = sum(np.array(epochs) <= epoch)\n",
      "        current_batch_size = int(args.batch_size * n_passed)\n",
      "    else:\n",
      "        current_batch_size = args.batch_size\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
      "    )\n",
      "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
      "    return train_loader\n",
      "\n",
      "\n",
      "def get_dataset(args):\n",
      "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
      "\n",
      "    if args.data == \"mnist\":\n",
      "        im_dim = 1\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.MNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = dset.MNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"colormnist\":\n",
      "        im_dim = 3\n",
      "        im_size = 28 if args.imagesize is None else args.imagesize\n",
      "        train_set = ColorMNIST(root=\"../data\", train=True, transform=trans(im_size), download=True)\n",
      "        test_set = ColorMNIST(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == \"svhn\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.SVHN(root=\"../data\", split=\"train\", transform=trans(im_size), download=True)\n",
      "        test_set = dset.SVHN(root=\"../data\", split=\"test\", transform=trans(im_size), download=True)\n",
      "    elif args.data == \"cifar10\":\n",
      "        im_dim = 3\n",
      "        im_size = 32 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CIFAR10(\n",
      "            root=\"../data\", train=True, transform=tforms.Compose([\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ]), download=True\n",
      "        )\n",
      "        test_set = dset.CIFAR10(root=\"../data\", train=False, transform=trans(im_size), download=True)\n",
      "    elif args.data == 'celeba':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.CelebA(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.CelebA(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    elif args.data == 'lsun_church':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_train'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.LSUN(\n",
      "            '../data', ['church_outdoor_val'], transform=tforms.Compose([\n",
      "                tforms.Resize(96),\n",
      "                tforms.RandomCrop(64),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )    \n",
      "    elif args.data == 'imagenet_64':\n",
      "        im_dim = 3\n",
      "        im_size = 64 if args.imagesize is None else args.imagesize\n",
      "        train_set = dset.ImageFolder(\n",
      "            train=True, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.RandomHorizontalFlip(),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "        test_set = dset.ImageFolder(\n",
      "            train=False, transform=tforms.Compose([\n",
      "                tforms.ToPILImage(),\n",
      "                tforms.Resize(im_size),\n",
      "                tforms.ToTensor(),\n",
      "                add_noise,\n",
      "            ])\n",
      "        )\n",
      "    \n",
      "    data_shape = (im_dim, im_size, im_size)\n",
      "    if not args.conv:\n",
      "        data_shape = (im_dim * im_size * im_size,)\n",
      "\n",
      "    test_loader = torch.utils.data.DataLoader(\n",
      "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
      "    )\n",
      "    return train_set, test_loader, data_shape\n",
      "\n",
      "\n",
      "def compute_bits_per_dim(x, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "\n",
      "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "\n",
      "    return bits_per_dim, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def compute_bits_per_dim_conditional(x, y, model):\n",
      "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "    y_onehot = thops.onehot(y, num_classes=model.module.y_class).to(x)\n",
      "\n",
      "    # Don't use data parallelize if batch size is small.\n",
      "    # if x.shape[0] < 200:\n",
      "    #     model = model.module\n",
      "    \n",
      "    z_sup, z_unsup, delta_logp, atol, rtol, logp_actions, nfe = model(x, zero)  # run model forward\n",
      "    \n",
      "    z_sup = torch.cat(z_sup, 1)\n",
      "    z_unsup = torch.cat(z_unsup, 1)\n",
      "    \n",
      "    # prior\n",
      "    mean, logs = model.module._prior(y_onehot)\n",
      "\n",
      "    logpz_sup = modules.GaussianDiag.logp(mean, logs, z_sup).view(-1,1)  # logp(z)_sup\n",
      "    logpz_unsup = standard_normal_logprob(z_unsup).view(z_unsup.shape[0], -1).sum(1, keepdim=True)\n",
      "    logpz = logpz_sup + logpz_unsup\n",
      "    logpx = logpz - delta_logp\n",
      "\n",
      "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
      "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
      "    \n",
      "    # dropout\n",
      "    if args.dropout_rate > 0:\n",
      "        z_sup = model.module.dropout(z_sup)\n",
      "    \n",
      "    # compute xentropy loss\n",
      "    y_logits = model.module.project_class(z_sup)\n",
      "    loss_xent = model.module.loss_class(y_logits, y.to(x.get_device()))\n",
      "    y_predicted = np.argmax(y_logits.cpu().detach().numpy(), axis=1)\n",
      "\n",
      "    return bits_per_dim, loss_xent, y_predicted, atol, rtol, logp_actions, nfe\n",
      "\n",
      "def create_model(args, data_shape, regularization_fns):\n",
      "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
      "    strides = tuple(map(int, args.strides.split(\",\")))\n",
      "\n",
      "    if args.multiscale:\n",
      "        model = odenvp.ODENVP(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            nonlinearity=args.nonlinearity,\n",
      "            alpha=args.alpha,\n",
      "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns, \"solver\": args.solver, \"atol\": args.atol, \"rtol\": args.rtol, \"scale\": args.scale, \"scale_fac\": args.scale_fac, \"scale_std\": args.scale_std, \"gate\": args.gate},\n",
      "            condition_ratio=args.condition_ratio,\n",
      "            dropout_rate=args.dropout_rate,\n",
      "            y_class = args.y_class)\n",
      "    elif args.parallel:\n",
      "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
      "            (args.batch_size, *data_shape),\n",
      "            n_blocks=args.num_blocks,\n",
      "            intermediate_dims=hidden_dims,\n",
      "            alpha=args.alpha,\n",
      "            time_length=args.time_length,\n",
      "        )\n",
      "    else:\n",
      "        if args.autoencode:\n",
      "\n",
      "            def build_cnf():\n",
      "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.AutoencoderODEfunc(\n",
      "                    autoencoder_diffeq=autoencoder_diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "        else:\n",
      "\n",
      "            def build_cnf():\n",
      "                diffeq = layers.ODEnet(\n",
      "                    hidden_dims=hidden_dims,\n",
      "                    input_shape=data_shape,\n",
      "                    strides=strides,\n",
      "                    conv=args.conv,\n",
      "                    layer_type=args.layer_type,\n",
      "                    nonlinearity=args.nonlinearity,\n",
      "                )\n",
      "                odefunc = layers.ODEfunc(\n",
      "                    diffeq=diffeq,\n",
      "                    divergence_fn=args.divergence_fn,\n",
      "                    residual=args.residual,\n",
      "                    rademacher=args.rademacher,\n",
      "                )\n",
      "                cnf = layers.CNF(\n",
      "                    odefunc=odefunc,\n",
      "                    T=args.time_length,\n",
      "                    train_T=args.train_T,\n",
      "                    regularization_fns=regularization_fns,\n",
      "                    solver=args.solver,\n",
      "                )\n",
      "                return cnf\n",
      "\n",
      "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
      "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
      "        if args.batch_norm:\n",
      "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
      "        model = layers.SequentialFlow(chain)\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    # get deivce\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "    cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
      "\n",
      "    # load dataset\n",
      "    train_set, test_loader, data_shape = get_dataset(args)\n",
      "\n",
      "    # build model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = create_model(args, data_shape, regularization_fns)\n",
      "\n",
      "    if args.spectral_norm: add_spectral_norm(model, logger)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    logger.info(model)\n",
      "    logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "    \n",
      "    writer.add_text('info', \"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
      "\n",
      "    # optimizer\n",
      "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
      "    \n",
      "    # set initial iter\n",
      "    itr = 1\n",
      "    \n",
      "    # set the meters\n",
      "    time_epoch_meter = utils.RunningAverageMeter(0.97)\n",
      "    time_meter = utils.RunningAverageMeter(0.97)\n",
      "    loss_meter = utils.RunningAverageMeter(0.97) # track total loss\n",
      "    nll_meter = utils.RunningAverageMeter(0.97) # track negative log-likelihood\n",
      "    xent_meter = utils.RunningAverageMeter(0.97) # track xentropy score\n",
      "    error_meter = utils.RunningAverageMeter(0.97) # track error score\n",
      "    steps_meter = utils.RunningAverageMeter(0.97)\n",
      "    grad_meter = utils.RunningAverageMeter(0.97)\n",
      "    tt_meter = utils.RunningAverageMeter(0.97)\n",
      "\n",
      "    # restore parameters\n",
      "    if args.resume is not None:\n",
      "        checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
      "        model.load_state_dict(checkpt[\"state_dict\"])\n",
      "        if \"optim_state_dict\" in checkpt.keys():\n",
      "            optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
      "            # Manually move optimizer state to device.\n",
      "            for state in optimizer.state.values():\n",
      "                for k, v in state.items():\n",
      "                    if torch.is_tensor(v):\n",
      "                        state[k] = cvt(v)\n",
      "        args.begin_epoch = checkpt['epoch'] + 1\n",
      "        itr = checkpt['iter'] + 1\n",
      "        time_epoch_meter.set(checkpt['epoch_time_avg'])\n",
      "        time_meter.set(checkpt['time_train'])\n",
      "        loss_meter.set(checkpt['loss_train'])\n",
      "        nll_meter.set(checkpt['bits_per_dim_train'])\n",
      "        xent_meter.set(checkpt['xent_train'])\n",
      "        error_meter.set(checkpt['error_train'])\n",
      "        steps_meter.set(checkpt['nfe_train'])\n",
      "        grad_meter.set(checkpt['grad_train'])\n",
      "        tt_meter.set(checkpt['total_time_train'])\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "        model = torch.nn.DataParallel(model).cuda()\n",
      "\n",
      "    # For visualization.\n",
      "    if args.conditional:\n",
      "        fixed_y = torch.from_numpy(np.arange(model.module.y_class)).repeat(model.module.y_class).type(torch.long).to(device, non_blocking=True)\n",
      "        fixed_y_onehot = thops.onehot(fixed_y, num_classes=model.module.y_class)\n",
      "        with torch.no_grad():\n",
      "            mean, logs = model.module._prior(fixed_y_onehot)\n",
      "            fixed_z_sup = modules.GaussianDiag.sample(mean, logs)\n",
      "            dim_unsup = np.prod(data_shape) - np.prod(fixed_z_sup.shape[1:])\n",
      "            fixed_z_unsup = cvt(torch.randn(model.module.y_class**2, dim_unsup))\n",
      "            \n",
      "            a_sup = fixed_z_sup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            a_unsup = fixed_z_unsup.shape[1] // (2**(model.module.n_scale - 1))\n",
      "            \n",
      "            fixed_z = []\n",
      "            start_sup = 0; start_unsup = 0\n",
      "            for ns in range(model.module.n_scale, 1, -1):\n",
      "                end_sup = start_sup + (2**(ns-2))*a_sup\n",
      "                end_unsup = start_unsup + (2**(ns-2))*a_unsup\n",
      "                \n",
      "                fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "                fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "                \n",
      "                start_sup = end_sup; start_unsup = end_unsup\n",
      "            \n",
      "            end_sup = start_sup + a_sup\n",
      "            end_unsup = start_unsup + a_unsup\n",
      "            \n",
      "            fixed_z.append(fixed_z_sup[:,start_sup:end_sup])\n",
      "            fixed_z.append(fixed_z_unsup[:,start_unsup:end_unsup])\n",
      "            \n",
      "            # for i_z in range(len(fixed_z)): print(fixed_z[i_z].shape)\n",
      "            \n",
      "            fixed_z = torch.cat(fixed_z,1)\n",
      "            \n",
      "    else:\n",
      "        fixed_z = cvt(torch.randn(100, *data_shape))\n",
      "    \n",
      "\n",
      "    if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
      "\n",
      "    best_loss_nll = float(\"inf\")\n",
      "    best_error_score = float(\"inf\")\n",
      "    \n",
      "    for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
      "        start_epoch = time.time()\n",
      "        model.train()\n",
      "        if args.annealing_std:\n",
      "            update_scale_std(model.module, epoch)\n",
      "            \n",
      "        train_loader = get_train_loader(train_set, epoch)\n",
      "        for _, (x, y) in enumerate(train_loader):\n",
      "            if args.data == \"colormnist\":\n",
      "                y = y[0]\n",
      "            \n",
      "            start = time.time()\n",
      "            update_lr(optimizer, itr)\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            if not args.conv:\n",
      "                x = x.view(x.shape[0], -1)\n",
      "\n",
      "            # cast data and move to device\n",
      "            x = cvt(x)\n",
      "            \n",
      "            # compute loss\n",
      "            if args.conditional:\n",
      "                loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                if args.train_mode == \"semisup\":\n",
      "                    loss =  loss_nll + args.weight_y * loss_xent\n",
      "                elif args.train_mode == \"sup\":\n",
      "                    loss =  loss_xent\n",
      "                elif args.train_mode == \"unsup\":\n",
      "                    loss =  loss_nll\n",
      "                else:\n",
      "                    raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                error_score = 1. - np.mean(y_predicted.astype(int) == y.numpy())   \n",
      "                \n",
      "            else:\n",
      "                loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                loss_nll, loss_xent, error_score = loss, 0., 0.\n",
      "            \n",
      "            if regularization_coeffs:\n",
      "                reg_states = get_regularization(model, regularization_coeffs)\n",
      "                reg_loss = sum(\n",
      "                    reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
      "                )\n",
      "                loss = loss + reg_loss\n",
      "            total_time = count_total_time(model)\n",
      "            loss = loss + total_time * args.time_penalty\n",
      "\n",
      "            # re-weight the gate rewards\n",
      "            normalized_eta = args.eta / len(logp_actions)\n",
      "            \n",
      "            # collect cumulative future rewards\n",
      "            R = - loss\n",
      "            cum_rewards = []\n",
      "            for r in nfe[::-1]:\n",
      "                R = -normalized_eta * r.view(-1,1) + args.gamma * R\n",
      "                cum_rewards.insert(0,R)\n",
      "            \n",
      "            # apply REINFORCE\n",
      "            rl_loss = 0\n",
      "            for lpa, r in zip(logp_actions, cum_rewards):\n",
      "                rl_loss = rl_loss - lpa.view(-1,1) * args.rl_weight * r\n",
      "                \n",
      "            loss = loss + rl_loss.mean()\n",
      "            \n",
      "            loss.backward()\n",
      "            \n",
      "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
      "            \n",
      "            time_meter.update(time.time() - start)\n",
      "            loss_meter.update(loss.item())\n",
      "            nll_meter.update(loss_nll.item())\n",
      "            if args.conditional:\n",
      "                xent_meter.update(loss_xent.item())\n",
      "            else:\n",
      "                xent_meter.update(loss_xent)\n",
      "            error_meter.update(error_score)\n",
      "            steps_meter.update(count_nfe_gate(model))\n",
      "            grad_meter.update(grad_norm)\n",
      "            tt_meter.update(total_time)\n",
      "            \n",
      "            for idx in range(len(model.module.transforms)):\n",
      "                for layer in model.module.transforms[idx].chain:\n",
      "                    if hasattr(layer, 'atol'):\n",
      "                        layer.odefunc.after_odeint()\n",
      "            \n",
      "            # write to tensorboard\n",
      "            writer.add_scalars('time', {'train_iter': time_meter.val}, itr)\n",
      "            writer.add_scalars('loss', {'train_iter': loss_meter.val}, itr)\n",
      "            writer.add_scalars('bits_per_dim', {'train_iter': nll_meter.val}, itr)\n",
      "            writer.add_scalars('xent', {'train_iter': xent_meter.val}, itr)\n",
      "            writer.add_scalars('error', {'train_iter': error_meter.val}, itr)\n",
      "            writer.add_scalars('nfe', {'train_iter': steps_meter.val}, itr)\n",
      "            writer.add_scalars('grad', {'train_iter': grad_meter.val}, itr)\n",
      "            writer.add_scalars('total_time', {'train_iter': tt_meter.val}, itr)\n",
      "\n",
      "            if itr % args.log_freq == 0:\n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'train': atol[tol_indx].mean()}, itr)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'train': rtol[tol_indx].mean()}, itr)\n",
      "                    \n",
      "                log_message = (\n",
      "                    \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | Xent {:.4f}({:.4f}) | Loss {:.4f}({:.4f}) | Error {:.4f}({:.4f}) \"\n",
      "                    \"Steps {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
      "                        itr, time_meter.val, time_meter.avg, nll_meter.val, nll_meter.avg, xent_meter.val, xent_meter.avg, loss_meter.val, loss_meter.avg, error_meter.val, error_meter.avg, steps_meter.val, steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
      "                    )\n",
      "                )\n",
      "                if regularization_coeffs:\n",
      "                    log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, itr)\n",
      "\n",
      "            itr += 1\n",
      "            \n",
      "        # compute test loss\n",
      "        model.eval()\n",
      "        if epoch % args.val_freq == 0:\n",
      "            with torch.no_grad():\n",
      "                # write to tensorboard\n",
      "                writer.add_scalars('time', {'train_epoch': time_meter.avg}, epoch)\n",
      "                writer.add_scalars('loss', {'train_epoch': loss_meter.avg}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'train_epoch': nll_meter.avg}, epoch)\n",
      "                writer.add_scalars('xent', {'train_epoch': xent_meter.avg}, epoch)\n",
      "                writer.add_scalars('error', {'train_epoch': error_meter.avg}, epoch)\n",
      "                writer.add_scalars('nfe', {'train_epoch': steps_meter.avg}, epoch)\n",
      "                writer.add_scalars('grad', {'train_epoch': grad_meter.avg}, epoch)\n",
      "                writer.add_scalars('total_time', {'train_epoch': tt_meter.avg}, epoch)\n",
      "                \n",
      "                start = time.time()\n",
      "                logger.info(\"validating...\")\n",
      "                writer.add_text('info', \"validating...\", epoch)\n",
      "                losses_nll = []; losses_xent = []; losses = []\n",
      "                total_correct = 0\n",
      "                \n",
      "                for (x, y) in test_loader:\n",
      "                    if args.data == \"colormnist\":\n",
      "                        y = y[0]\n",
      "                        \n",
      "                    if not args.conv:\n",
      "                        x = x.view(x.shape[0], -1)\n",
      "                    x = cvt(x)\n",
      "                    if args.conditional:\n",
      "                        loss_nll, loss_xent, y_predicted, atol, rtol, logp_actions, nfe = compute_bits_per_dim_conditional(x, y, model)\n",
      "                        if args.train_mode == \"semisup\":\n",
      "                            loss =  loss_nll + args.weight_y * loss_xent\n",
      "                        elif args.train_mode == \"sup\":\n",
      "                            loss =  loss_xent\n",
      "                        elif args.train_mode == \"unsup\":\n",
      "                            loss =  loss_nll\n",
      "                        else:\n",
      "                            raise ValueError('Choose supported train_mode: semisup, sup, unsup')\n",
      "                        total_correct += np.sum(y_predicted.astype(int) == y.numpy())\n",
      "                    else:\n",
      "                        loss, atol, rtol, logp_actions, nfe = compute_bits_per_dim(x, model)\n",
      "                        loss_nll, loss_xent = loss, 0.\n",
      "                    losses_nll.append(loss_nll.cpu().numpy()); losses.append(loss.cpu().numpy())\n",
      "                    if args.conditional: \n",
      "                        losses_xent.append(loss_xent.cpu().numpy())\n",
      "                    else:\n",
      "                        losses_xent.append(loss_xent)\n",
      "                    \n",
      "                loss_nll = np.mean(losses_nll); loss_xent = np.mean(losses_xent); loss = np.mean(losses)\n",
      "                error_score =  1. - total_correct / len(test_loader.dataset)\n",
      "                time_epoch_meter.update(time.time() - start_epoch)\n",
      "                \n",
      "                # write to tensorboard\n",
      "                test_time_spent = time.time() - start\n",
      "                writer.add_scalars('time', {'validation': test_time_spent}, epoch)\n",
      "                writer.add_scalars('epoch_time', {'validation': time_epoch_meter.val}, epoch)\n",
      "                writer.add_scalars('bits_per_dim', {'validation': loss_nll}, epoch)\n",
      "                writer.add_scalars('xent', {'validation': loss_xent}, epoch)\n",
      "                writer.add_scalars('loss', {'validation': loss}, epoch)\n",
      "                writer.add_scalars('error', {'validation': error_score}, epoch)\n",
      "                \n",
      "                for tol_indx in range(len(atol)):\n",
      "                    writer.add_scalars('atol_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                    writer.add_scalars('rtol_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "                \n",
      "                log_message = \"Epoch {:04d} | Time {:.4f}, Epoch Time {:.4f}({:.4f}), Bit/dim {:.4f}(best: {:.4f}), Xent {:.4f}, Loss {:.4f}, Error {:.4f}(best: {:.4f})\".format(epoch, time.time() - start, time_epoch_meter.val, time_epoch_meter.avg, loss_nll, best_loss_nll, loss_xent, loss, error_score, best_error_score)\n",
      "                logger.info(log_message)\n",
      "                writer.add_text('info', log_message, epoch)\n",
      "                \n",
      "                for name, param in model.named_parameters():\n",
      "                    writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
      "                    \n",
      "                \n",
      "                utils.makedirs(args.save)\n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"epoch_%i_checkpt.pth\"%epoch))\n",
      "                \n",
      "                torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"current_checkpt.pth\"))\n",
      "                \n",
      "                if loss_nll < best_loss_nll:\n",
      "                    best_loss_nll = loss_nll\n",
      "                    utils.makedirs(args.save)\n",
      "                    torch.save({\n",
      "                        \"args\": args,\n",
      "                        \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                        \"optim_state_dict\": optimizer.state_dict(),\n",
      "                        \"epoch\": epoch,\n",
      "                        \"iter\": itr-1,\n",
      "                        \"error\": error_score,\n",
      "                        \"loss\": loss,\n",
      "                        \"xent\": loss_xent,\n",
      "                        \"bits_per_dim\": loss_nll,\n",
      "                        \"best_bits_per_dim\": best_loss_nll,\n",
      "                        \"best_error_score\": best_error_score,\n",
      "                        \"epoch_time\": time_epoch_meter.val,\n",
      "                        \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                        \"time\": test_time_spent,\n",
      "                        \"error_train\": error_meter.avg,\n",
      "                        \"loss_train\": loss_meter.avg,\n",
      "                        \"xent_train\": xent_meter.avg,\n",
      "                        \"bits_per_dim_train\": nll_meter.avg,\n",
      "                        \"total_time_train\": tt_meter.avg,\n",
      "                        \"time_train\": time_meter.avg,\n",
      "                        \"nfe_train\": steps_meter.avg,\n",
      "                        \"grad_train\": grad_meter.avg,\n",
      "                    }, os.path.join(args.save, \"best_nll_checkpt.pth\"))\n",
      "                    \n",
      "                if args.conditional:\n",
      "                    if error_score < best_error_score:\n",
      "                        best_error_score = error_score\n",
      "                        utils.makedirs(args.save)\n",
      "                        torch.save({\n",
      "                            \"args\": args,\n",
      "                            \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
      "                            \"optim_state_dict\": optimizer.state_dict(),\n",
      "                            \"epoch\": epoch,\n",
      "                            \"iter\": itr-1,\n",
      "                            \"error\": error_score,\n",
      "                            \"loss\": loss,\n",
      "                            \"xent\": loss_xent,\n",
      "                            \"bits_per_dim\": loss_nll,\n",
      "                            \"best_bits_per_dim\": best_loss_nll,\n",
      "                            \"best_error_score\": best_error_score,\n",
      "                            \"epoch_time\": time_epoch_meter.val,\n",
      "                            \"epoch_time_avg\": time_epoch_meter.avg,\n",
      "                            \"time\": test_time_spent,\n",
      "                            \"error_train\": error_meter.avg,\n",
      "                            \"loss_train\": loss_meter.avg,\n",
      "                            \"xent_train\": xent_meter.avg,\n",
      "                            \"bits_per_dim_train\": nll_meter.avg,\n",
      "                            \"total_time_train\": tt_meter.avg,\n",
      "                            \"time_train\": time_meter.avg,\n",
      "                            \"nfe_train\": steps_meter.avg,\n",
      "                            \"grad_train\": grad_meter.avg,\n",
      "                        }, os.path.join(args.save, \"best_error_checkpt.pth\"))\n",
      "                        \n",
      "\n",
      "        # visualize samples and density\n",
      "        with torch.no_grad():\n",
      "            fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
      "            utils.makedirs(os.path.dirname(fig_filename))\n",
      "            generated_samples, atol, rtol, logp_actions, nfe = model(fixed_z, reverse=True)\n",
      "            generated_samples = generated_samples.view(-1, *data_shape)\n",
      "            for tol_indx in range(len(atol)):\n",
      "                writer.add_scalars('atol_gen_%i'%tol_indx, {'validation': atol[tol_indx].mean()}, epoch)\n",
      "                writer.add_scalars('rtol_gen_%i'%tol_indx, {'validation': rtol[tol_indx].mean()}, epoch)\n",
      "            save_image(generated_samples, fig_filename, nrow=10)\n",
      "            if args.data == \"mnist\":\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,3,1,1), epoch)\n",
      "            else:\n",
      "                writer.add_images('generated_images', generated_samples.repeat(1,1,1,1), epoch)\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, add_noise=True, alpha=1e-06, annealing_std=False, atol=1e-05, autoencode=False, batch_norm=False, batch_size=900, batch_size_schedule='', begin_epoch=1, condition_ratio=0.5, conditional=True, controlled_tol=False, conv=True, data='cifar10', dims='64,64,64', divergence_fn='approximate', dl2int=None, dropout_rate=0.5, eta=0.1, gamma=0.99, gate='cnn1', imagesize=None, l1int=None, l2int=None, layer_type='concat', log_freq=10, lr=0.0001, max_grad_norm=10000000000.0, multiscale=True, nonlinearity='softplus', num_blocks=2, num_epochs=500, parallel=False, rademacher=True, residual=False, resume='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run3/epoch_250_checkpt.pth', rl_weight=0.01, rtol=1e-05, save='../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run3', scale=1.0, scale_fac=1.0, scale_std=6.0, seed=3, solver='dopri5', spectral_norm=False, spectral_norm_niter=10, step_size=None, strides='1,1,1,1', test_atol=None, test_batch_size=500, test_rtol=None, test_solver=None, time_length=1.0, time_penalty=0, train_T=True, train_mode='semisup', val_freq=1, warmup_iters=1000, weight_decay=0.0, weight_y=0.5, y_class=10, y_color=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ODENVP(\n",
      "  (transforms): ModuleList(\n",
      "    (0): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): LogitTransform()\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SqueezeLayer()\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SqueezeLayer()\n",
      "        (3): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(48, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): StackedCNFLayers(\n",
      "      (chain): ModuleList(\n",
      "        (0): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CNF_Gate(\n",
      "          (gate_net): FeedforwardGateI(\n",
      "            (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "            (conv1): Conv2d(24, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace)\n",
      "            (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace)\n",
      "            (avg_layer): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "            (linear_layer): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (odefunc): RegularizedODEfunc(\n",
      "            (odefunc): ODEfunc_rl(\n",
      "              (diffeq): ODEnet(\n",
      "                (layers): ModuleList(\n",
      "                  (0): ConcatConv2d(\n",
      "                    (_layer): Conv2d(25, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (1): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (2): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                  (3): ConcatConv2d(\n",
      "                    (_layer): Conv2d(65, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (activation_fns): ModuleList(\n",
      "                  (0): Softplus(beta=1, threshold=20)\n",
      "                  (1): Softplus(beta=1, threshold=20)\n",
      "                  (2): Softplus(beta=1, threshold=20)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (project_ycond): LinearZeros(in_features=10, out_features=3072, bias=True)\n",
      "  (project_class): LinearZeros(in_features=1536, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "Number of trainable parameters: 1450732\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "/tancode/repos/tan-ffjord/lib/layers/odefunc_rl.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Iter 13760 | Time 21.4021(22.0357) | Bit/dim 3.5433(3.5463) | Xent 0.0154(0.0324) | Loss 8.8233(9.7259) | Error 0.0044(0.0095) Steps 820(813.09) | Grad Norm 1.7658(3.6900) | Total Time 0.00(0.00)\n",
      "Iter 13770 | Time 22.0866(21.8867) | Bit/dim 3.5563(3.5428) | Xent 0.0259(0.0285) | Loss 8.9753(9.4912) | Error 0.0056(0.0083) Steps 850(810.70) | Grad Norm 2.7874(3.3099) | Total Time 0.00(0.00)\n",
      "Iter 13780 | Time 21.5442(21.7054) | Bit/dim 3.5262(3.5394) | Xent 0.0054(0.0245) | Loss 8.8019(9.3127) | Error 0.0011(0.0070) Steps 838(811.71) | Grad Norm 0.8900(2.8575) | Total Time 0.00(0.00)\n",
      "Iter 13790 | Time 22.2036(21.6876) | Bit/dim 3.5257(3.5355) | Xent 0.0110(0.0208) | Loss 8.9123(9.1874) | Error 0.0033(0.0058) Steps 850(812.73) | Grad Norm 1.8240(2.4881) | Total Time 0.00(0.00)\n",
      "Iter 13800 | Time 22.3102(21.6591) | Bit/dim 3.5179(3.5339) | Xent 0.0135(0.0199) | Loss 8.9225(9.1056) | Error 0.0033(0.0055) Steps 838(810.58) | Grad Norm 1.4316(2.3386) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0251 | Time 105.8896, Epoch Time 1332.0666(1233.4002), Bit/dim 3.5447(best: inf), Xent 1.9485, Loss 4.5190, Error 0.3183(best: inf)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13810 | Time 22.0664(21.6087) | Bit/dim 3.5121(3.5296) | Xent 0.0130(0.0171) | Loss 8.8486(9.8252) | Error 0.0033(0.0047) Steps 850(809.86) | Grad Norm 1.3878(2.0643) | Total Time 0.00(0.00)\n",
      "Iter 13820 | Time 21.1865(21.6089) | Bit/dim 3.5085(3.5279) | Xent 0.0090(0.0154) | Loss 8.7447(9.5737) | Error 0.0022(0.0043) Steps 814(811.55) | Grad Norm 1.7383(1.9606) | Total Time 0.00(0.00)\n",
      "Iter 13830 | Time 22.6931(21.6181) | Bit/dim 3.5324(3.5262) | Xent 0.0028(0.0137) | Loss 8.9522(9.3919) | Error 0.0000(0.0038) Steps 832(813.22) | Grad Norm 0.5260(1.7499) | Total Time 0.00(0.00)\n",
      "Iter 13840 | Time 21.9694(21.6162) | Bit/dim 3.5022(3.5225) | Xent 0.0073(0.0122) | Loss 8.7789(9.2432) | Error 0.0022(0.0034) Steps 808(813.43) | Grad Norm 1.2369(1.6182) | Total Time 0.00(0.00)\n",
      "Iter 13850 | Time 21.6773(21.6006) | Bit/dim 3.5013(3.5228) | Xent 0.0029(0.0112) | Loss 8.8335(9.1356) | Error 0.0000(0.0031) Steps 832(813.00) | Grad Norm 0.5279(1.5167) | Total Time 0.00(0.00)\n",
      "Iter 13860 | Time 21.7993(21.6031) | Bit/dim 3.5398(3.5244) | Xent 0.0024(0.0097) | Loss 8.8631(9.0578) | Error 0.0000(0.0027) Steps 814(813.13) | Grad Norm 0.4812(1.4060) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0252 | Time 102.9489, Epoch Time 1313.1861(1235.7937), Bit/dim 3.5450(best: 3.5447), Xent 1.9812, Loss 4.5356, Error 0.3164(best: 0.3183)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13870 | Time 21.5822(21.6080) | Bit/dim 3.5247(3.5254) | Xent 0.0070(0.0093) | Loss 8.7285(9.7218) | Error 0.0022(0.0024) Steps 784(813.01) | Grad Norm 1.2816(1.3239) | Total Time 0.00(0.00)\n",
      "Iter 13880 | Time 21.4624(21.5803) | Bit/dim 3.5420(3.5249) | Xent 0.0093(0.0087) | Loss 8.7762(9.4814) | Error 0.0022(0.0023) Steps 796(811.03) | Grad Norm 1.2673(1.2342) | Total Time 0.00(0.00)\n",
      "Iter 13890 | Time 21.0655(21.5176) | Bit/dim 3.5098(3.5226) | Xent 0.0043(0.0078) | Loss 8.8487(9.3106) | Error 0.0011(0.0020) Steps 808(811.30) | Grad Norm 0.9369(1.1176) | Total Time 0.00(0.00)\n",
      "Iter 13900 | Time 21.7268(21.5298) | Bit/dim 3.5258(3.5204) | Xent 0.0063(0.0080) | Loss 8.7407(9.1751) | Error 0.0033(0.0021) Steps 844(812.63) | Grad Norm 1.4358(1.1718) | Total Time 0.00(0.00)\n",
      "Iter 13910 | Time 20.3619(21.5991) | Bit/dim 3.4972(3.5194) | Xent 0.0077(0.0076) | Loss 8.8009(9.0867) | Error 0.0022(0.0019) Steps 814(813.97) | Grad Norm 1.9719(1.1953) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0253 | Time 102.9689, Epoch Time 1309.1015(1237.9930), Bit/dim 3.5447(best: 3.5447), Xent 2.0292, Loss 4.5593, Error 0.3182(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13920 | Time 21.3237(21.5656) | Bit/dim 3.5297(3.5198) | Xent 0.0057(0.0070) | Loss 8.7696(9.8296) | Error 0.0022(0.0017) Steps 808(810.75) | Grad Norm 0.8632(1.1551) | Total Time 0.00(0.00)\n",
      "Iter 13930 | Time 22.3737(21.6316) | Bit/dim 3.4837(3.5155) | Xent 0.0054(0.0068) | Loss 8.7653(9.5618) | Error 0.0011(0.0016) Steps 844(814.08) | Grad Norm 0.8397(1.0936) | Total Time 0.00(0.00)\n",
      "Iter 13940 | Time 22.0251(21.6107) | Bit/dim 3.5107(3.5175) | Xent 0.0056(0.0064) | Loss 8.7228(9.3593) | Error 0.0011(0.0015) Steps 808(810.41) | Grad Norm 1.6429(1.0875) | Total Time 0.00(0.00)\n",
      "Iter 13950 | Time 20.8766(21.5870) | Bit/dim 3.5406(3.5211) | Xent 0.0054(0.0062) | Loss 8.9790(9.2354) | Error 0.0022(0.0015) Steps 820(810.05) | Grad Norm 1.2661(1.0814) | Total Time 0.00(0.00)\n",
      "Iter 13960 | Time 21.9111(21.6147) | Bit/dim 3.4842(3.5202) | Xent 0.0086(0.0068) | Loss 8.8497(9.1316) | Error 0.0033(0.0017) Steps 814(810.83) | Grad Norm 1.8780(1.1957) | Total Time 0.00(0.00)\n",
      "Iter 13970 | Time 21.3255(21.6643) | Bit/dim 3.5538(3.5185) | Xent 0.0117(0.0065) | Loss 8.8502(9.0575) | Error 0.0033(0.0017) Steps 814(812.07) | Grad Norm 1.8742(1.1888) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0254 | Time 101.0828, Epoch Time 1314.1393(1240.2774), Bit/dim 3.5435(best: 3.5447), Xent 2.0740, Loss 4.5805, Error 0.3219(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 13980 | Time 21.5033(21.7055) | Bit/dim 3.5318(3.5164) | Xent 0.0133(0.0065) | Loss 8.9091(9.6834) | Error 0.0033(0.0015) Steps 820(811.83) | Grad Norm 2.3515(1.1648) | Total Time 0.00(0.00)\n",
      "Iter 13990 | Time 22.1952(21.7874) | Bit/dim 3.5352(3.5166) | Xent 0.0058(0.0072) | Loss 8.8700(9.4588) | Error 0.0011(0.0016) Steps 802(813.25) | Grad Norm 1.8713(1.2784) | Total Time 0.00(0.00)\n",
      "Iter 14000 | Time 21.5812(21.7015) | Bit/dim 3.5059(3.5184) | Xent 0.0032(0.0065) | Loss 8.6902(9.2856) | Error 0.0000(0.0014) Steps 814(809.82) | Grad Norm 0.7277(1.2925) | Total Time 0.00(0.00)\n",
      "Iter 14010 | Time 21.8436(21.7190) | Bit/dim 3.5260(3.5180) | Xent 0.0034(0.0063) | Loss 8.8342(9.1612) | Error 0.0000(0.0014) Steps 790(808.85) | Grad Norm 0.8093(1.2765) | Total Time 0.00(0.00)\n",
      "Iter 14020 | Time 21.6896(21.6897) | Bit/dim 3.5135(3.5166) | Xent 0.0054(0.0063) | Loss 8.7463(9.0632) | Error 0.0022(0.0015) Steps 826(808.84) | Grad Norm 1.6403(1.2932) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0255 | Time 101.7344, Epoch Time 1316.4680(1242.5631), Bit/dim 3.5428(best: 3.5435), Xent 2.0927, Loss 4.5891, Error 0.3213(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14030 | Time 22.8596(21.6968) | Bit/dim 3.5431(3.5174) | Xent 0.0037(0.0054) | Loss 8.9496(9.8169) | Error 0.0011(0.0013) Steps 802(809.44) | Grad Norm 0.7871(1.1504) | Total Time 0.00(0.00)\n",
      "Iter 14040 | Time 20.4441(21.7219) | Bit/dim 3.5086(3.5201) | Xent 0.0058(0.0058) | Loss 8.8283(9.5713) | Error 0.0033(0.0014) Steps 838(813.18) | Grad Norm 1.0885(1.1719) | Total Time 0.00(0.00)\n",
      "Iter 14050 | Time 22.2092(21.7028) | Bit/dim 3.5267(3.5189) | Xent 0.0038(0.0057) | Loss 8.7599(9.3727) | Error 0.0022(0.0014) Steps 790(812.39) | Grad Norm 0.8144(1.1927) | Total Time 0.00(0.00)\n",
      "Iter 14060 | Time 21.9473(21.6374) | Bit/dim 3.5257(3.5190) | Xent 0.0064(0.0059) | Loss 8.9642(9.2358) | Error 0.0022(0.0015) Steps 802(810.54) | Grad Norm 0.9378(1.1664) | Total Time 0.00(0.00)\n",
      "Iter 14070 | Time 22.2199(21.6203) | Bit/dim 3.5106(3.5175) | Xent 0.0130(0.0060) | Loss 8.8080(9.1190) | Error 0.0044(0.0015) Steps 778(807.25) | Grad Norm 2.9987(1.2467) | Total Time 0.00(0.00)\n",
      "Iter 14080 | Time 21.7229(21.5626) | Bit/dim 3.5078(3.5170) | Xent 0.0036(0.0060) | Loss 8.8403(9.0402) | Error 0.0011(0.0015) Steps 820(807.36) | Grad Norm 0.7845(1.2341) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0256 | Time 99.9800, Epoch Time 1309.3844(1244.5677), Bit/dim 3.5433(best: 3.5428), Xent 2.1228, Loss 4.6047, Error 0.3251(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14090 | Time 21.5235(21.5600) | Bit/dim 3.5216(3.5137) | Xent 0.0034(0.0058) | Loss 8.9031(9.6708) | Error 0.0011(0.0015) Steps 820(809.18) | Grad Norm 0.9980(1.2511) | Total Time 0.00(0.00)\n",
      "Iter 14100 | Time 21.4127(21.6213) | Bit/dim 3.4752(3.5147) | Xent 0.0039(0.0053) | Loss 8.6571(9.4346) | Error 0.0011(0.0014) Steps 772(807.01) | Grad Norm 0.7533(1.1570) | Total Time 0.00(0.00)\n",
      "Iter 14110 | Time 21.9251(21.6789) | Bit/dim 3.5646(3.5173) | Xent 0.0034(0.0054) | Loss 8.8767(9.2791) | Error 0.0000(0.0014) Steps 754(805.92) | Grad Norm 0.7953(1.1542) | Total Time 0.00(0.00)\n",
      "Iter 14120 | Time 21.3834(21.6678) | Bit/dim 3.5166(3.5174) | Xent 0.0019(0.0053) | Loss 8.8692(9.1619) | Error 0.0000(0.0014) Steps 820(807.24) | Grad Norm 0.5459(1.1620) | Total Time 0.00(0.00)\n",
      "Iter 14130 | Time 21.9100(21.6321) | Bit/dim 3.5131(3.5152) | Xent 0.0095(0.0051) | Loss 8.9048(9.0728) | Error 0.0033(0.0013) Steps 850(806.26) | Grad Norm 1.4208(1.0879) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0257 | Time 102.1565, Epoch Time 1318.6521(1246.7903), Bit/dim 3.5420(best: 3.5428), Xent 2.1418, Loss 4.6129, Error 0.3248(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14140 | Time 21.7684(21.6339) | Bit/dim 3.5201(3.5166) | Xent 0.0041(0.0049) | Loss 8.9651(9.8182) | Error 0.0011(0.0012) Steps 838(806.46) | Grad Norm 0.7704(1.0232) | Total Time 0.00(0.00)\n",
      "Iter 14150 | Time 20.7177(21.6625) | Bit/dim 3.5121(3.5171) | Xent 0.0020(0.0049) | Loss 8.7521(9.5653) | Error 0.0000(0.0013) Steps 796(808.76) | Grad Norm 0.6488(1.0882) | Total Time 0.00(0.00)\n",
      "Iter 14160 | Time 22.6859(21.7248) | Bit/dim 3.4880(3.5165) | Xent 0.0092(0.0053) | Loss 8.8054(9.3580) | Error 0.0022(0.0013) Steps 802(808.69) | Grad Norm 2.9225(1.1518) | Total Time 0.00(0.00)\n",
      "Iter 14170 | Time 21.4693(21.6922) | Bit/dim 3.5202(3.5150) | Xent 0.0017(0.0051) | Loss 8.8377(9.2167) | Error 0.0000(0.0013) Steps 802(807.42) | Grad Norm 0.5444(1.1324) | Total Time 0.00(0.00)\n",
      "Iter 14180 | Time 22.6293(21.6786) | Bit/dim 3.4957(3.5148) | Xent 0.0038(0.0048) | Loss 8.7888(9.1113) | Error 0.0022(0.0012) Steps 832(808.47) | Grad Norm 1.0400(1.1091) | Total Time 0.00(0.00)\n",
      "Iter 14190 | Time 22.1356(21.6811) | Bit/dim 3.5337(3.5151) | Xent 0.0020(0.0049) | Loss 8.9221(9.0376) | Error 0.0000(0.0011) Steps 820(807.18) | Grad Norm 0.5548(1.0463) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0258 | Time 102.2236, Epoch Time 1317.7250(1248.9183), Bit/dim 3.5405(best: 3.5420), Xent 2.1611, Loss 4.6210, Error 0.3248(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14200 | Time 22.3267(21.6235) | Bit/dim 3.5014(3.5150) | Xent 0.0037(0.0046) | Loss 8.8461(9.6712) | Error 0.0011(0.0011) Steps 784(805.39) | Grad Norm 1.0476(0.9704) | Total Time 0.00(0.00)\n",
      "Iter 14210 | Time 22.0818(21.5695) | Bit/dim 3.5084(3.5172) | Xent 0.0036(0.0045) | Loss 8.7818(9.4517) | Error 0.0011(0.0010) Steps 808(806.31) | Grad Norm 0.7009(0.9485) | Total Time 0.00(0.00)\n",
      "Iter 14220 | Time 21.7865(21.6292) | Bit/dim 3.5393(3.5151) | Xent 0.0022(0.0047) | Loss 8.8621(9.2781) | Error 0.0000(0.0012) Steps 796(804.07) | Grad Norm 0.6198(1.0180) | Total Time 0.00(0.00)\n",
      "Iter 14230 | Time 21.8281(21.6094) | Bit/dim 3.5258(3.5144) | Xent 0.0058(0.0046) | Loss 8.7542(9.1496) | Error 0.0022(0.0012) Steps 832(803.25) | Grad Norm 1.0738(1.0283) | Total Time 0.00(0.00)\n",
      "Iter 14240 | Time 20.4521(21.6041) | Bit/dim 3.5189(3.5158) | Xent 0.0033(0.0044) | Loss 8.7080(9.0591) | Error 0.0011(0.0012) Steps 814(802.38) | Grad Norm 0.7289(1.0501) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0259 | Time 101.2110, Epoch Time 1310.8571(1250.7765), Bit/dim 3.5405(best: 3.5405), Xent 2.1986, Loss 4.6398, Error 0.3207(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14250 | Time 21.8899(21.6518) | Bit/dim 3.5215(3.5162) | Xent 0.0017(0.0042) | Loss 8.8870(9.7976) | Error 0.0000(0.0011) Steps 820(803.78) | Grad Norm 0.5279(1.0302) | Total Time 0.00(0.00)\n",
      "Iter 14260 | Time 22.2473(21.5892) | Bit/dim 3.4998(3.5147) | Xent 0.0071(0.0042) | Loss 8.7777(9.5326) | Error 0.0011(0.0012) Steps 802(805.43) | Grad Norm 1.4194(1.0092) | Total Time 0.00(0.00)\n",
      "Iter 14270 | Time 21.2335(21.5186) | Bit/dim 3.4885(3.5144) | Xent 0.0024(0.0039) | Loss 8.7625(9.3338) | Error 0.0000(0.0010) Steps 784(804.65) | Grad Norm 0.6106(0.9692) | Total Time 0.00(0.00)\n",
      "Iter 14280 | Time 22.6205(21.5369) | Bit/dim 3.5279(3.5152) | Xent 0.0065(0.0039) | Loss 8.8590(9.1974) | Error 0.0022(0.0010) Steps 760(803.86) | Grad Norm 1.7742(1.0032) | Total Time 0.00(0.00)\n",
      "Iter 14290 | Time 21.4902(21.4598) | Bit/dim 3.5271(3.5132) | Xent 0.0019(0.0038) | Loss 8.7137(9.0679) | Error 0.0000(0.0009) Steps 790(801.84) | Grad Norm 0.5671(0.9526) | Total Time 0.00(0.00)\n",
      "Iter 14300 | Time 21.6682(21.5134) | Bit/dim 3.5355(3.5144) | Xent 0.0033(0.0035) | Loss 8.8169(8.9978) | Error 0.0011(0.0008) Steps 772(801.30) | Grad Norm 2.2345(0.9543) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0260 | Time 101.5439, Epoch Time 1303.6032(1252.3613), Bit/dim 3.5407(best: 3.5405), Xent 2.2186, Loss 4.6500, Error 0.3246(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14310 | Time 21.3550(21.5407) | Bit/dim 3.5119(3.5147) | Xent 0.0032(0.0040) | Loss 8.8410(9.6379) | Error 0.0011(0.0010) Steps 808(805.63) | Grad Norm 1.1948(1.0610) | Total Time 0.00(0.00)\n",
      "Iter 14320 | Time 21.4037(21.5825) | Bit/dim 3.5221(3.5139) | Xent 0.0124(0.0046) | Loss 8.9159(9.4195) | Error 0.0011(0.0011) Steps 814(807.23) | Grad Norm 1.0341(1.1062) | Total Time 0.00(0.00)\n",
      "Iter 14330 | Time 21.0670(21.5358) | Bit/dim 3.5099(3.5133) | Xent 0.0048(0.0047) | Loss 8.7850(9.2548) | Error 0.0011(0.0011) Steps 808(804.75) | Grad Norm 0.8393(1.1250) | Total Time 0.00(0.00)\n",
      "Iter 14340 | Time 21.6290(21.5181) | Bit/dim 3.5400(3.5135) | Xent 0.0023(0.0048) | Loss 8.7828(9.1358) | Error 0.0011(0.0012) Steps 802(805.53) | Grad Norm 0.6660(1.1191) | Total Time 0.00(0.00)\n",
      "Iter 14350 | Time 21.4101(21.5486) | Bit/dim 3.4756(3.5161) | Xent 0.0014(0.0046) | Loss 8.7540(9.0640) | Error 0.0000(0.0011) Steps 796(806.38) | Grad Norm 0.5881(1.1301) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0261 | Time 101.4657, Epoch Time 1305.3213(1253.9501), Bit/dim 3.5402(best: 3.5405), Xent 2.2327, Loss 4.6566, Error 0.3228(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14360 | Time 20.6642(21.4605) | Bit/dim 3.4978(3.5130) | Xent 0.0045(0.0045) | Loss 8.7645(9.8033) | Error 0.0022(0.0012) Steps 778(806.03) | Grad Norm 1.4819(1.1674) | Total Time 0.00(0.00)\n",
      "Iter 14370 | Time 21.9155(21.5126) | Bit/dim 3.5257(3.5138) | Xent 0.0053(0.0045) | Loss 8.9258(9.5382) | Error 0.0011(0.0011) Steps 838(804.33) | Grad Norm 0.9101(1.1134) | Total Time 0.00(0.00)\n",
      "Iter 14380 | Time 21.0591(21.4781) | Bit/dim 3.4943(3.5120) | Xent 0.0041(0.0045) | Loss 8.7853(9.3514) | Error 0.0011(0.0011) Steps 802(806.54) | Grad Norm 0.8393(1.0828) | Total Time 0.00(0.00)\n",
      "Iter 14390 | Time 21.8488(21.3758) | Bit/dim 3.4976(3.5145) | Xent 0.0018(0.0041) | Loss 8.8340(9.2137) | Error 0.0000(0.0009) Steps 820(805.96) | Grad Norm 0.6553(1.0560) | Total Time 0.00(0.00)\n",
      "Iter 14400 | Time 21.0515(21.4257) | Bit/dim 3.4853(3.5111) | Xent 0.0046(0.0042) | Loss 8.7508(9.1031) | Error 0.0000(0.0010) Steps 820(805.96) | Grad Norm 1.4805(1.1452) | Total Time 0.00(0.00)\n",
      "Iter 14410 | Time 20.6687(21.4271) | Bit/dim 3.5779(3.5150) | Xent 0.0016(0.0044) | Loss 8.9216(9.0309) | Error 0.0000(0.0010) Steps 784(806.50) | Grad Norm 0.4552(1.1689) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0262 | Time 99.8412, Epoch Time 1299.8748(1255.3278), Bit/dim 3.5455(best: 3.5402), Xent 2.2583, Loss 4.6746, Error 0.3257(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14420 | Time 21.1844(21.4426) | Bit/dim 3.5038(3.5143) | Xent 0.0084(0.0046) | Loss 8.7282(9.6638) | Error 0.0044(0.0011) Steps 814(807.92) | Grad Norm 2.1996(1.2098) | Total Time 0.00(0.00)\n",
      "Iter 14430 | Time 21.7442(21.4103) | Bit/dim 3.4942(3.5113) | Xent 0.0024(0.0044) | Loss 8.8571(9.4259) | Error 0.0000(0.0010) Steps 790(805.16) | Grad Norm 0.9093(1.1568) | Total Time 0.00(0.00)\n",
      "Iter 14440 | Time 20.6809(21.4376) | Bit/dim 3.5354(3.5104) | Xent 0.0023(0.0041) | Loss 8.7623(9.2520) | Error 0.0000(0.0009) Steps 790(804.46) | Grad Norm 0.8374(1.1363) | Total Time 0.00(0.00)\n",
      "Iter 14450 | Time 22.1581(21.4681) | Bit/dim 3.5031(3.5122) | Xent 0.0073(0.0038) | Loss 8.8035(9.1262) | Error 0.0022(0.0008) Steps 802(805.05) | Grad Norm 1.9603(1.1828) | Total Time 0.00(0.00)\n",
      "Iter 14460 | Time 21.8026(21.4307) | Bit/dim 3.5121(3.5133) | Xent 0.0039(0.0039) | Loss 8.7871(9.0311) | Error 0.0011(0.0009) Steps 826(805.37) | Grad Norm 1.1201(1.1561) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0263 | Time 101.2268, Epoch Time 1301.5086(1256.7132), Bit/dim 3.5399(best: 3.5402), Xent 2.2928, Loss 4.6863, Error 0.3286(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14470 | Time 22.5850(21.4695) | Bit/dim 3.5288(3.5099) | Xent 0.0009(0.0038) | Loss 8.8523(9.7712) | Error 0.0000(0.0010) Steps 826(806.99) | Grad Norm 0.5670(1.2329) | Total Time 0.00(0.00)\n",
      "Iter 14480 | Time 21.6714(21.4549) | Bit/dim 3.5457(3.5120) | Xent 0.0018(0.0040) | Loss 8.7994(9.5063) | Error 0.0000(0.0010) Steps 832(809.53) | Grad Norm 0.7053(1.2236) | Total Time 0.00(0.00)\n",
      "Iter 14490 | Time 21.9610(21.4952) | Bit/dim 3.5046(3.5142) | Xent 0.0034(0.0039) | Loss 8.7459(9.3262) | Error 0.0011(0.0008) Steps 790(812.42) | Grad Norm 1.3586(1.1326) | Total Time 0.00(0.00)\n",
      "Iter 14500 | Time 21.4948(21.5608) | Bit/dim 3.4811(3.5146) | Xent 0.0015(0.0039) | Loss 8.7876(9.1890) | Error 0.0000(0.0009) Steps 814(812.80) | Grad Norm 0.7892(1.1603) | Total Time 0.00(0.00)\n",
      "Iter 14510 | Time 22.2082(21.5299) | Bit/dim 3.5032(3.5134) | Xent 0.0068(0.0041) | Loss 8.7514(9.0868) | Error 0.0033(0.0011) Steps 778(812.27) | Grad Norm 2.3499(1.3771) | Total Time 0.00(0.00)\n",
      "Iter 14520 | Time 21.9934(21.5273) | Bit/dim 3.5393(3.5127) | Xent 0.0035(0.0044) | Loss 8.7197(8.9978) | Error 0.0011(0.0011) Steps 802(810.93) | Grad Norm 1.7856(1.3875) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0264 | Time 101.3125, Epoch Time 1309.2041(1258.2880), Bit/dim 3.5408(best: 3.5399), Xent 2.3025, Loss 4.6920, Error 0.3312(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14530 | Time 22.0583(21.6149) | Bit/dim 3.4894(3.5119) | Xent 0.0020(0.0041) | Loss 8.7739(9.6375) | Error 0.0000(0.0009) Steps 838(810.21) | Grad Norm 0.9345(1.3489) | Total Time 0.00(0.00)\n",
      "Iter 14540 | Time 20.9057(21.5748) | Bit/dim 3.5161(3.5143) | Xent 0.0052(0.0041) | Loss 8.8844(9.4271) | Error 0.0011(0.0009) Steps 838(810.96) | Grad Norm 0.8761(1.3146) | Total Time 0.00(0.00)\n",
      "Iter 14550 | Time 21.5620(21.5426) | Bit/dim 3.5007(3.5138) | Xent 0.0025(0.0040) | Loss 8.7715(9.2574) | Error 0.0011(0.0009) Steps 814(805.83) | Grad Norm 0.7990(1.3426) | Total Time 0.00(0.00)\n",
      "Iter 14560 | Time 22.6317(21.7098) | Bit/dim 3.5202(3.5148) | Xent 0.0066(0.0038) | Loss 8.9100(9.1383) | Error 0.0011(0.0009) Steps 802(805.16) | Grad Norm 1.2985(1.3268) | Total Time 0.00(0.00)\n",
      "Iter 14570 | Time 22.3457(21.8080) | Bit/dim 3.4797(3.5115) | Xent 0.0032(0.0042) | Loss 8.6690(9.0375) | Error 0.0011(0.0010) Steps 772(807.58) | Grad Norm 1.0691(1.4873) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0265 | Time 100.9200, Epoch Time 1319.5198(1260.1249), Bit/dim 3.5448(best: 3.5399), Xent 2.3083, Loss 4.6990, Error 0.3267(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14580 | Time 21.7277(21.7707) | Bit/dim 3.5453(3.5124) | Xent 0.0016(0.0039) | Loss 8.9194(9.7974) | Error 0.0000(0.0009) Steps 808(809.10) | Grad Norm 0.7370(1.3357) | Total Time 0.00(0.00)\n",
      "Iter 14590 | Time 20.8093(21.6731) | Bit/dim 3.5210(3.5111) | Xent 0.0028(0.0036) | Loss 8.8268(9.5312) | Error 0.0011(0.0008) Steps 796(808.21) | Grad Norm 0.5990(1.2519) | Total Time 0.00(0.00)\n",
      "Iter 14600 | Time 22.0653(21.6707) | Bit/dim 3.5124(3.5147) | Xent 0.0019(0.0037) | Loss 8.7886(9.3449) | Error 0.0000(0.0007) Steps 826(810.30) | Grad Norm 0.7546(1.2513) | Total Time 0.00(0.00)\n",
      "Iter 14610 | Time 22.1858(21.6918) | Bit/dim 3.5241(3.5146) | Xent 0.0061(0.0037) | Loss 8.7885(9.1984) | Error 0.0033(0.0009) Steps 820(808.19) | Grad Norm 1.1927(1.3214) | Total Time 0.00(0.00)\n",
      "Iter 14620 | Time 20.8179(21.6935) | Bit/dim 3.5200(3.5125) | Xent 0.0015(0.0037) | Loss 8.5345(9.0749) | Error 0.0000(0.0009) Steps 784(808.82) | Grad Norm 0.6754(1.3055) | Total Time 0.00(0.00)\n",
      "Iter 14630 | Time 22.0093(21.7397) | Bit/dim 3.5042(3.5093) | Xent 0.0071(0.0036) | Loss 8.8639(9.0020) | Error 0.0011(0.0008) Steps 820(809.54) | Grad Norm 1.6254(1.2175) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0266 | Time 100.8612, Epoch Time 1315.4960(1261.7860), Bit/dim 3.5394(best: 3.5399), Xent 2.3172, Loss 4.6979, Error 0.3274(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14640 | Time 22.0163(21.7315) | Bit/dim 3.4848(3.5095) | Xent 0.0243(0.0042) | Loss 8.7874(9.6453) | Error 0.0056(0.0010) Steps 844(811.77) | Grad Norm 1.5514(1.2286) | Total Time 0.00(0.00)\n",
      "Iter 14650 | Time 22.1533(21.6343) | Bit/dim 3.4852(3.5097) | Xent 0.0012(0.0039) | Loss 8.7634(9.4229) | Error 0.0000(0.0010) Steps 802(807.31) | Grad Norm 0.7902(1.2292) | Total Time 0.00(0.00)\n",
      "Iter 14660 | Time 21.7597(21.6965) | Bit/dim 3.5253(3.5112) | Xent 0.0015(0.0037) | Loss 8.7336(9.2525) | Error 0.0000(0.0009) Steps 832(810.92) | Grad Norm 0.5971(1.2178) | Total Time 0.00(0.00)\n",
      "Iter 14670 | Time 22.2394(21.6261) | Bit/dim 3.5225(3.5110) | Xent 0.0077(0.0038) | Loss 8.9036(9.1262) | Error 0.0022(0.0010) Steps 784(808.06) | Grad Norm 3.0259(1.2823) | Total Time 0.00(0.00)\n",
      "Iter 14680 | Time 21.6674(21.6732) | Bit/dim 3.4979(3.5096) | Xent 0.0012(0.0040) | Loss 8.7659(9.0374) | Error 0.0000(0.0010) Steps 838(811.27) | Grad Norm 0.6050(1.2649) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0267 | Time 101.3924, Epoch Time 1313.0476(1263.3239), Bit/dim 3.5392(best: 3.5394), Xent 2.3370, Loss 4.7077, Error 0.3256(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14690 | Time 22.0417(21.6688) | Bit/dim 3.5161(3.5099) | Xent 0.0008(0.0038) | Loss 8.7959(9.7454) | Error 0.0000(0.0009) Steps 796(810.27) | Grad Norm 0.5126(1.1872) | Total Time 0.00(0.00)\n",
      "Iter 14700 | Time 20.7749(21.7008) | Bit/dim 3.5294(3.5092) | Xent 0.0090(0.0038) | Loss 8.7708(9.4966) | Error 0.0022(0.0009) Steps 778(809.75) | Grad Norm 2.1968(1.2296) | Total Time 0.00(0.00)\n",
      "Iter 14710 | Time 21.0672(21.6462) | Bit/dim 3.5088(3.5098) | Xent 0.0016(0.0039) | Loss 8.7263(9.3121) | Error 0.0000(0.0010) Steps 826(809.99) | Grad Norm 0.5484(1.2627) | Total Time 0.00(0.00)\n",
      "Iter 14720 | Time 22.3731(21.6530) | Bit/dim 3.5288(3.5108) | Xent 0.0038(0.0039) | Loss 8.7921(9.1836) | Error 0.0022(0.0011) Steps 808(810.19) | Grad Norm 2.0230(1.3403) | Total Time 0.00(0.00)\n",
      "Iter 14730 | Time 21.3642(21.5665) | Bit/dim 3.5301(3.5086) | Xent 0.0044(0.0039) | Loss 8.8646(9.0672) | Error 0.0011(0.0011) Steps 790(806.67) | Grad Norm 1.6190(1.3645) | Total Time 0.00(0.00)\n",
      "Iter 14740 | Time 22.6193(21.5370) | Bit/dim 3.5398(3.5110) | Xent 0.0051(0.0043) | Loss 8.8841(8.9923) | Error 0.0022(0.0012) Steps 766(805.85) | Grad Norm 1.3310(1.3835) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0268 | Time 102.1079, Epoch Time 1307.5082(1264.6494), Bit/dim 3.5426(best: 3.5392), Xent 2.3105, Loss 4.6979, Error 0.3230(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14750 | Time 20.8538(21.6083) | Bit/dim 3.5247(3.5110) | Xent 0.0020(0.0040) | Loss 8.6906(9.6324) | Error 0.0000(0.0011) Steps 778(808.73) | Grad Norm 0.6608(1.3671) | Total Time 0.00(0.00)\n",
      "Iter 14760 | Time 21.2277(21.6438) | Bit/dim 3.5195(3.5099) | Xent 0.0022(0.0038) | Loss 8.7598(9.4107) | Error 0.0011(0.0011) Steps 790(807.88) | Grad Norm 0.9612(1.2897) | Total Time 0.00(0.00)\n",
      "Iter 14770 | Time 22.3477(21.7185) | Bit/dim 3.5143(3.5092) | Xent 0.0031(0.0037) | Loss 8.8867(9.2545) | Error 0.0011(0.0011) Steps 814(808.38) | Grad Norm 1.3483(1.2669) | Total Time 0.00(0.00)\n",
      "Iter 14780 | Time 21.7822(21.6313) | Bit/dim 3.5050(3.5098) | Xent 0.0068(0.0035) | Loss 8.8377(9.1328) | Error 0.0022(0.0009) Steps 778(808.94) | Grad Norm 3.0171(1.2714) | Total Time 0.00(0.00)\n",
      "Iter 14790 | Time 22.4012(21.6356) | Bit/dim 3.5418(3.5104) | Xent 0.0026(0.0035) | Loss 8.8629(9.0422) | Error 0.0011(0.0009) Steps 778(806.96) | Grad Norm 1.1128(1.2594) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0269 | Time 101.5481, Epoch Time 1316.6107(1266.2083), Bit/dim 3.5401(best: 3.5392), Xent 2.3793, Loss 4.7298, Error 0.3297(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14800 | Time 21.4019(21.6390) | Bit/dim 3.4802(3.5114) | Xent 0.0035(0.0039) | Loss 8.7443(9.7513) | Error 0.0011(0.0010) Steps 796(806.61) | Grad Norm 2.1798(1.4446) | Total Time 0.00(0.00)\n",
      "Iter 14810 | Time 21.4174(21.6906) | Bit/dim 3.5307(3.5114) | Xent 0.0103(0.0041) | Loss 8.8556(9.4970) | Error 0.0022(0.0010) Steps 808(805.44) | Grad Norm 1.8662(1.4366) | Total Time 0.00(0.00)\n",
      "Iter 14820 | Time 22.0906(21.7680) | Bit/dim 3.5506(3.5119) | Xent 0.0058(0.0038) | Loss 8.8249(9.3150) | Error 0.0022(0.0009) Steps 796(806.82) | Grad Norm 2.5012(1.4350) | Total Time 0.00(0.00)\n",
      "Iter 14830 | Time 20.8052(21.7665) | Bit/dim 3.4987(3.5108) | Xent 0.0086(0.0041) | Loss 8.6559(9.1777) | Error 0.0033(0.0010) Steps 796(809.16) | Grad Norm 3.4131(1.5666) | Total Time 0.00(0.00)\n",
      "Iter 14840 | Time 22.3769(21.8094) | Bit/dim 3.4843(3.5077) | Xent 0.0038(0.0042) | Loss 8.7445(9.0684) | Error 0.0011(0.0010) Steps 820(810.95) | Grad Norm 1.7741(1.6091) | Total Time 0.00(0.00)\n",
      "Iter 14850 | Time 21.2323(21.8331) | Bit/dim 3.5566(3.5106) | Xent 0.0013(0.0045) | Loss 8.9507(9.0033) | Error 0.0000(0.0012) Steps 784(809.31) | Grad Norm 0.8009(1.6114) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0270 | Time 100.6397, Epoch Time 1324.9411(1267.9702), Bit/dim 3.5373(best: 3.5392), Xent 2.3636, Loss 4.7191, Error 0.3265(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14860 | Time 20.4810(21.8617) | Bit/dim 3.5067(3.5098) | Xent 0.0028(0.0043) | Loss 8.6759(9.6230) | Error 0.0011(0.0012) Steps 808(811.46) | Grad Norm 0.9779(1.5568) | Total Time 0.00(0.00)\n",
      "Iter 14870 | Time 21.3126(21.8363) | Bit/dim 3.4947(3.5092) | Xent 0.0044(0.0038) | Loss 8.7663(9.4032) | Error 0.0022(0.0010) Steps 808(811.02) | Grad Norm 1.2612(1.4457) | Total Time 0.00(0.00)\n",
      "Iter 14880 | Time 22.1651(21.8328) | Bit/dim 3.5147(3.5107) | Xent 0.0010(0.0041) | Loss 8.8441(9.2515) | Error 0.0000(0.0010) Steps 808(805.21) | Grad Norm 0.8700(1.4475) | Total Time 0.00(0.00)\n",
      "Iter 14890 | Time 21.4703(21.8043) | Bit/dim 3.4975(3.5092) | Xent 0.0053(0.0044) | Loss 8.7708(9.1243) | Error 0.0011(0.0011) Steps 802(805.73) | Grad Norm 2.0975(1.5774) | Total Time 0.00(0.00)\n",
      "Iter 14900 | Time 21.9705(21.7262) | Bit/dim 3.5005(3.5087) | Xent 0.0061(0.0040) | Loss 8.8296(9.0362) | Error 0.0011(0.0010) Steps 808(805.38) | Grad Norm 1.5667(1.5204) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0271 | Time 102.7819, Epoch Time 1320.8212(1269.5558), Bit/dim 3.5378(best: 3.5373), Xent 2.3680, Loss 4.7218, Error 0.3262(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14910 | Time 23.1760(21.8013) | Bit/dim 3.5164(3.5114) | Xent 0.0018(0.0038) | Loss 8.9560(9.7996) | Error 0.0011(0.0010) Steps 814(809.50) | Grad Norm 0.9424(1.4973) | Total Time 0.00(0.00)\n",
      "Iter 14920 | Time 21.3098(21.7808) | Bit/dim 3.5159(3.5110) | Xent 0.0044(0.0038) | Loss 8.6486(9.5277) | Error 0.0011(0.0009) Steps 778(809.07) | Grad Norm 2.0869(1.4797) | Total Time 0.00(0.00)\n",
      "Iter 14930 | Time 22.6409(21.7607) | Bit/dim 3.4663(3.5091) | Xent 0.0006(0.0037) | Loss 8.7686(9.3302) | Error 0.0000(0.0009) Steps 838(807.38) | Grad Norm 0.6463(1.3828) | Total Time 0.00(0.00)\n",
      "Iter 14940 | Time 20.4648(21.6840) | Bit/dim 3.5071(3.5100) | Xent 0.0025(0.0034) | Loss 8.7001(9.1865) | Error 0.0000(0.0008) Steps 790(810.23) | Grad Norm 1.0281(1.3126) | Total Time 0.00(0.00)\n",
      "Iter 14950 | Time 21.4264(21.6374) | Bit/dim 3.4945(3.5083) | Xent 0.0040(0.0034) | Loss 8.7335(9.0782) | Error 0.0011(0.0008) Steps 814(811.09) | Grad Norm 2.8851(1.3716) | Total Time 0.00(0.00)\n",
      "Iter 14960 | Time 21.9836(21.6408) | Bit/dim 3.5361(3.5065) | Xent 0.0091(0.0034) | Loss 8.8474(9.0064) | Error 0.0011(0.0008) Steps 808(812.31) | Grad Norm 1.4813(1.3680) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0272 | Time 101.4748, Epoch Time 1314.2237(1270.8958), Bit/dim 3.5375(best: 3.5373), Xent 2.3695, Loss 4.7223, Error 0.3285(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 14970 | Time 21.1035(21.6042) | Bit/dim 3.5176(3.5062) | Xent 0.0023(0.0032) | Loss 8.7755(9.6237) | Error 0.0011(0.0008) Steps 820(812.74) | Grad Norm 1.5274(1.3534) | Total Time 0.00(0.00)\n",
      "Iter 14980 | Time 21.9985(21.6004) | Bit/dim 3.5083(3.5092) | Xent 0.0021(0.0030) | Loss 8.7807(9.4144) | Error 0.0000(0.0007) Steps 802(813.58) | Grad Norm 0.6017(1.2632) | Total Time 0.00(0.00)\n",
      "Iter 14990 | Time 21.4508(21.5617) | Bit/dim 3.5148(3.5079) | Xent 0.0034(0.0033) | Loss 8.7294(9.2341) | Error 0.0011(0.0008) Steps 808(810.62) | Grad Norm 1.3917(1.2835) | Total Time 0.00(0.00)\n",
      "Iter 15000 | Time 21.8333(21.6015) | Bit/dim 3.5218(3.5082) | Xent 0.0011(0.0035) | Loss 8.8243(9.1161) | Error 0.0000(0.0009) Steps 808(808.77) | Grad Norm 0.7146(1.4471) | Total Time 0.00(0.00)\n",
      "Iter 15010 | Time 22.4024(21.5642) | Bit/dim 3.5360(3.5106) | Xent 0.0010(0.0037) | Loss 8.8779(9.0264) | Error 0.0000(0.0008) Steps 808(809.33) | Grad Norm 0.8683(1.4965) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0273 | Time 102.7435, Epoch Time 1312.5738(1272.1461), Bit/dim 3.5380(best: 3.5373), Xent 2.4082, Loss 4.7421, Error 0.3303(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15020 | Time 21.1291(21.7050) | Bit/dim 3.5005(3.5072) | Xent 0.0018(0.0037) | Loss 8.8423(9.7702) | Error 0.0000(0.0007) Steps 808(808.67) | Grad Norm 0.8047(1.4810) | Total Time 0.00(0.00)\n",
      "Iter 15030 | Time 22.0015(21.7649) | Bit/dim 3.4799(3.5050) | Xent 0.0020(0.0038) | Loss 8.7773(9.5109) | Error 0.0000(0.0008) Steps 832(811.15) | Grad Norm 1.3310(1.5555) | Total Time 0.00(0.00)\n",
      "Iter 15040 | Time 21.6141(21.7464) | Bit/dim 3.5175(3.5084) | Xent 0.0017(0.0040) | Loss 8.8295(9.3266) | Error 0.0000(0.0009) Steps 778(810.15) | Grad Norm 0.6630(1.4879) | Total Time 0.00(0.00)\n",
      "Iter 15050 | Time 22.1441(21.7440) | Bit/dim 3.5149(3.5100) | Xent 0.0021(0.0041) | Loss 8.8100(9.1770) | Error 0.0011(0.0010) Steps 832(810.45) | Grad Norm 1.7639(1.5571) | Total Time 0.00(0.00)\n",
      "Iter 15060 | Time 21.4619(21.7414) | Bit/dim 3.5277(3.5088) | Xent 0.0010(0.0039) | Loss 8.7484(9.0626) | Error 0.0000(0.0010) Steps 832(811.45) | Grad Norm 0.5110(1.4774) | Total Time 0.00(0.00)\n",
      "Iter 15070 | Time 20.3281(21.6994) | Bit/dim 3.5240(3.5097) | Xent 0.0025(0.0038) | Loss 8.8303(8.9954) | Error 0.0011(0.0010) Steps 802(811.87) | Grad Norm 0.9109(1.3915) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0274 | Time 101.8743, Epoch Time 1319.8232(1273.5765), Bit/dim 3.5369(best: 3.5373), Xent 2.4181, Loss 4.7460, Error 0.3287(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15080 | Time 21.8432(21.7418) | Bit/dim 3.5484(3.5083) | Xent 0.0011(0.0038) | Loss 8.8584(9.6339) | Error 0.0000(0.0011) Steps 814(812.00) | Grad Norm 0.8221(1.4315) | Total Time 0.00(0.00)\n",
      "Iter 15090 | Time 21.6390(21.7168) | Bit/dim 3.4745(3.5096) | Xent 0.0072(0.0038) | Loss 8.6372(9.4106) | Error 0.0022(0.0010) Steps 796(808.88) | Grad Norm 2.3120(1.4614) | Total Time 0.00(0.00)\n",
      "Iter 15100 | Time 22.7367(21.7529) | Bit/dim 3.4889(3.5072) | Xent 0.0009(0.0034) | Loss 8.7706(9.2455) | Error 0.0000(0.0009) Steps 862(810.25) | Grad Norm 0.6345(1.3665) | Total Time 0.00(0.00)\n",
      "Iter 15110 | Time 22.6455(21.8262) | Bit/dim 3.5210(3.5088) | Xent 0.0053(0.0036) | Loss 8.8618(9.1313) | Error 0.0011(0.0009) Steps 856(812.64) | Grad Norm 2.1287(1.3499) | Total Time 0.00(0.00)\n",
      "Iter 15120 | Time 22.6332(21.8978) | Bit/dim 3.4887(3.5087) | Xent 0.0011(0.0038) | Loss 8.6737(9.0433) | Error 0.0000(0.0010) Steps 826(812.86) | Grad Norm 0.6239(1.3207) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0275 | Time 102.2065, Epoch Time 1327.6022(1275.1972), Bit/dim 3.5391(best: 3.5369), Xent 2.4287, Loss 4.7535, Error 0.3268(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15130 | Time 22.5002(21.8815) | Bit/dim 3.5118(3.5111) | Xent 0.0095(0.0042) | Loss 8.8513(9.7818) | Error 0.0022(0.0011) Steps 832(812.90) | Grad Norm 1.3641(1.4132) | Total Time 0.00(0.00)\n",
      "Iter 15140 | Time 21.5621(21.8862) | Bit/dim 3.5024(3.5106) | Xent 0.0057(0.0040) | Loss 8.8639(9.5280) | Error 0.0011(0.0010) Steps 814(814.06) | Grad Norm 1.1892(1.3515) | Total Time 0.00(0.00)\n",
      "Iter 15150 | Time 22.5879(21.8983) | Bit/dim 3.5165(3.5109) | Xent 0.0014(0.0037) | Loss 8.7873(9.3291) | Error 0.0000(0.0009) Steps 850(812.18) | Grad Norm 0.9598(1.3115) | Total Time 0.00(0.00)\n",
      "Iter 15160 | Time 21.7649(21.8987) | Bit/dim 3.5271(3.5093) | Xent 0.0021(0.0034) | Loss 8.8385(9.1845) | Error 0.0000(0.0008) Steps 790(811.08) | Grad Norm 1.2173(1.2540) | Total Time 0.00(0.00)\n",
      "Iter 15170 | Time 21.5522(21.8752) | Bit/dim 3.4777(3.5065) | Xent 0.0086(0.0035) | Loss 8.7363(9.0714) | Error 0.0011(0.0008) Steps 814(809.99) | Grad Norm 1.3180(1.2282) | Total Time 0.00(0.00)\n",
      "Iter 15180 | Time 20.7593(21.7847) | Bit/dim 3.5061(3.5087) | Xent 0.0054(0.0033) | Loss 8.6813(8.9949) | Error 0.0022(0.0007) Steps 808(809.88) | Grad Norm 2.9932(1.2663) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0276 | Time 101.8243, Epoch Time 1322.8128(1276.6257), Bit/dim 3.5348(best: 3.5369), Xent 2.4077, Loss 4.7387, Error 0.3269(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15190 | Time 21.5537(21.8507) | Bit/dim 3.5478(3.5100) | Xent 0.0053(0.0035) | Loss 8.8037(9.6354) | Error 0.0022(0.0007) Steps 766(810.79) | Grad Norm 4.3877(1.4317) | Total Time 0.00(0.00)\n",
      "Iter 15200 | Time 21.7728(21.7818) | Bit/dim 3.4987(3.5092) | Xent 0.0107(0.0041) | Loss 8.6619(9.4075) | Error 0.0022(0.0010) Steps 772(806.31) | Grad Norm 4.2046(1.6490) | Total Time 0.00(0.00)\n",
      "Iter 15210 | Time 22.6853(21.9116) | Bit/dim 3.5026(3.5105) | Xent 0.0019(0.0041) | Loss 8.8310(9.2548) | Error 0.0011(0.0010) Steps 802(806.66) | Grad Norm 1.3524(1.6663) | Total Time 0.00(0.00)\n",
      "Iter 15220 | Time 22.1374(21.9408) | Bit/dim 3.4847(3.5091) | Xent 0.0053(0.0042) | Loss 8.8077(9.1361) | Error 0.0011(0.0010) Steps 832(808.42) | Grad Norm 3.0912(1.7490) | Total Time 0.00(0.00)\n",
      "Iter 15230 | Time 21.6183(21.8694) | Bit/dim 3.5176(3.5075) | Xent 0.0064(0.0044) | Loss 8.8315(9.0485) | Error 0.0011(0.0011) Steps 820(808.65) | Grad Norm 1.4277(1.7302) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0277 | Time 101.3165, Epoch Time 1325.4792(1278.0913), Bit/dim 3.5401(best: 3.5348), Xent 2.4198, Loss 4.7500, Error 0.3254(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15240 | Time 21.9179(21.7933) | Bit/dim 3.5032(3.5077) | Xent 0.0030(0.0042) | Loss 8.5985(9.7559) | Error 0.0011(0.0011) Steps 820(806.15) | Grad Norm 3.1280(1.7976) | Total Time 0.00(0.00)\n",
      "Iter 15250 | Time 21.8500(21.8424) | Bit/dim 3.4882(3.5078) | Xent 0.0011(0.0039) | Loss 8.6412(9.4862) | Error 0.0000(0.0009) Steps 790(804.91) | Grad Norm 0.7764(1.7339) | Total Time 0.00(0.00)\n",
      "Iter 15260 | Time 21.0169(21.7682) | Bit/dim 3.5419(3.5110) | Xent 0.0023(0.0039) | Loss 8.8439(9.3133) | Error 0.0000(0.0009) Steps 760(802.95) | Grad Norm 1.1036(1.7054) | Total Time 0.00(0.00)\n",
      "Iter 15270 | Time 21.1585(21.8025) | Bit/dim 3.5175(3.5095) | Xent 0.0011(0.0039) | Loss 8.8187(9.1717) | Error 0.0000(0.0009) Steps 790(803.96) | Grad Norm 0.6458(1.5977) | Total Time 0.00(0.00)\n",
      "Iter 15280 | Time 21.8791(21.8040) | Bit/dim 3.4749(3.5046) | Xent 0.0041(0.0036) | Loss 8.7790(9.0570) | Error 0.0011(0.0009) Steps 814(805.89) | Grad Norm 2.0741(1.5741) | Total Time 0.00(0.00)\n",
      "Iter 15290 | Time 21.7833(21.7544) | Bit/dim 3.5088(3.5055) | Xent 0.0040(0.0037) | Loss 8.7493(8.9889) | Error 0.0022(0.0010) Steps 790(803.77) | Grad Norm 2.5748(1.5848) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0278 | Time 100.8179, Epoch Time 1318.8100(1279.3129), Bit/dim 3.5404(best: 3.5348), Xent 2.4764, Loss 4.7786, Error 0.3329(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15300 | Time 22.1049(21.7511) | Bit/dim 3.5138(3.5060) | Xent 0.0057(0.0039) | Loss 8.8500(9.6054) | Error 0.0011(0.0010) Steps 826(804.26) | Grad Norm 3.7720(1.5405) | Total Time 0.00(0.00)\n",
      "Iter 15310 | Time 21.8162(21.7859) | Bit/dim 3.4945(3.5068) | Xent 0.0024(0.0038) | Loss 8.6822(9.3836) | Error 0.0000(0.0009) Steps 766(803.20) | Grad Norm 1.3520(1.5450) | Total Time 0.00(0.00)\n",
      "Iter 15320 | Time 22.7275(21.7861) | Bit/dim 3.5368(3.5075) | Xent 0.0015(0.0038) | Loss 8.9283(9.2330) | Error 0.0000(0.0009) Steps 766(803.63) | Grad Norm 1.0110(1.5134) | Total Time 0.00(0.00)\n",
      "Iter 15330 | Time 22.3840(21.8077) | Bit/dim 3.5142(3.5084) | Xent 0.0018(0.0039) | Loss 8.7382(9.1111) | Error 0.0000(0.0009) Steps 766(802.79) | Grad Norm 0.6864(1.4065) | Total Time 0.00(0.00)\n",
      "Iter 15340 | Time 21.4006(21.7413) | Bit/dim 3.5053(3.5079) | Xent 0.0099(0.0040) | Loss 8.7579(9.0179) | Error 0.0011(0.0010) Steps 802(800.39) | Grad Norm 1.6159(1.4631) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0279 | Time 101.8364, Epoch Time 1320.5006(1280.5485), Bit/dim 3.5370(best: 3.5348), Xent 2.4412, Loss 4.7576, Error 0.3288(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15350 | Time 21.7261(21.8080) | Bit/dim 3.5005(3.5070) | Xent 0.0041(0.0037) | Loss 8.7518(9.7274) | Error 0.0011(0.0009) Steps 826(797.52) | Grad Norm 2.6418(1.4401) | Total Time 0.00(0.00)\n",
      "Iter 15360 | Time 22.2317(21.7864) | Bit/dim 3.5612(3.5084) | Xent 0.0020(0.0035) | Loss 8.6657(9.4789) | Error 0.0011(0.0009) Steps 784(797.35) | Grad Norm 0.8517(1.3747) | Total Time 0.00(0.00)\n",
      "Iter 15370 | Time 22.8405(21.7802) | Bit/dim 3.4958(3.5091) | Xent 0.0042(0.0034) | Loss 8.6975(9.2891) | Error 0.0011(0.0009) Steps 784(799.84) | Grad Norm 1.4893(1.3810) | Total Time 0.00(0.00)\n",
      "Iter 15380 | Time 21.5974(21.8145) | Bit/dim 3.5082(3.5076) | Xent 0.0090(0.0038) | Loss 8.6815(9.1465) | Error 0.0022(0.0010) Steps 820(802.19) | Grad Norm 2.1437(1.4670) | Total Time 0.00(0.00)\n",
      "Iter 15390 | Time 21.5998(21.8327) | Bit/dim 3.4960(3.5062) | Xent 0.0020(0.0036) | Loss 8.7382(9.0481) | Error 0.0000(0.0009) Steps 826(804.74) | Grad Norm 0.7787(1.3950) | Total Time 0.00(0.00)\n",
      "Iter 15400 | Time 21.4792(21.9062) | Bit/dim 3.5165(3.5055) | Xent 0.0010(0.0040) | Loss 8.7611(8.9742) | Error 0.0000(0.0010) Steps 826(808.52) | Grad Norm 1.2827(1.4812) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0280 | Time 100.6437, Epoch Time 1325.7727(1281.9052), Bit/dim 3.5363(best: 3.5348), Xent 2.4631, Loss 4.7678, Error 0.3290(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15410 | Time 21.7920(21.9111) | Bit/dim 3.4733(3.5040) | Xent 0.0029(0.0038) | Loss 8.6564(9.6023) | Error 0.0011(0.0010) Steps 784(805.60) | Grad Norm 1.6290(1.5433) | Total Time 0.00(0.00)\n",
      "Iter 15420 | Time 20.9535(21.9199) | Bit/dim 3.4909(3.5057) | Xent 0.0019(0.0035) | Loss 8.7529(9.3980) | Error 0.0000(0.0009) Steps 808(810.60) | Grad Norm 1.3380(1.4617) | Total Time 0.00(0.00)\n",
      "Iter 15430 | Time 21.1678(21.8471) | Bit/dim 3.4913(3.5049) | Xent 0.0040(0.0037) | Loss 8.7568(9.2316) | Error 0.0011(0.0010) Steps 790(809.10) | Grad Norm 1.6438(1.4939) | Total Time 0.00(0.00)\n",
      "Iter 15440 | Time 20.7815(21.6901) | Bit/dim 3.5538(3.5059) | Xent 0.0042(0.0038) | Loss 8.7965(9.1040) | Error 0.0011(0.0011) Steps 796(805.92) | Grad Norm 2.2169(1.5184) | Total Time 0.00(0.00)\n",
      "Iter 15450 | Time 21.8018(21.7320) | Bit/dim 3.4839(3.5064) | Xent 0.0060(0.0038) | Loss 8.7399(9.0161) | Error 0.0022(0.0011) Steps 820(803.96) | Grad Norm 2.1311(1.5040) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0281 | Time 101.1749, Epoch Time 1317.3272(1282.9679), Bit/dim 3.5361(best: 3.5348), Xent 2.5170, Loss 4.7946, Error 0.3324(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15460 | Time 21.0190(21.6863) | Bit/dim 3.5091(3.5070) | Xent 0.0080(0.0034) | Loss 8.7536(9.7478) | Error 0.0022(0.0009) Steps 808(803.91) | Grad Norm 1.5365(1.3952) | Total Time 0.00(0.00)\n",
      "Iter 15470 | Time 21.7071(21.6510) | Bit/dim 3.4907(3.5085) | Xent 0.0026(0.0031) | Loss 8.7664(9.4914) | Error 0.0011(0.0008) Steps 778(801.67) | Grad Norm 1.6964(1.3868) | Total Time 0.00(0.00)\n",
      "Iter 15480 | Time 21.7871(21.6626) | Bit/dim 3.5039(3.5084) | Xent 0.0048(0.0038) | Loss 8.9127(9.3088) | Error 0.0022(0.0010) Steps 814(803.03) | Grad Norm 1.9071(1.4792) | Total Time 0.00(0.00)\n",
      "Iter 15490 | Time 21.2305(21.6850) | Bit/dim 3.4971(3.5093) | Xent 0.0078(0.0040) | Loss 8.8130(9.1567) | Error 0.0044(0.0010) Steps 814(804.33) | Grad Norm 3.5090(1.5759) | Total Time 0.00(0.00)\n",
      "Iter 15500 | Time 22.6097(21.7467) | Bit/dim 3.5285(3.5088) | Xent 0.0029(0.0035) | Loss 8.8857(9.0628) | Error 0.0011(0.0009) Steps 784(802.95) | Grad Norm 1.8270(1.4886) | Total Time 0.00(0.00)\n",
      "Iter 15510 | Time 21.9225(21.8385) | Bit/dim 3.4892(3.5074) | Xent 0.0011(0.0040) | Loss 8.8504(8.9884) | Error 0.0000(0.0010) Steps 820(804.71) | Grad Norm 0.7705(1.5503) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0282 | Time 100.7458, Epoch Time 1319.0735(1284.0510), Bit/dim 3.5364(best: 3.5348), Xent 2.4797, Loss 4.7762, Error 0.3290(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15520 | Time 22.5853(21.8878) | Bit/dim 3.4762(3.5070) | Xent 0.0063(0.0036) | Loss 8.7353(9.6265) | Error 0.0011(0.0009) Steps 808(805.19) | Grad Norm 3.4019(1.5158) | Total Time 0.00(0.00)\n",
      "Iter 15530 | Time 21.3629(21.9038) | Bit/dim 3.5206(3.5084) | Xent 0.0044(0.0034) | Loss 8.8125(9.4117) | Error 0.0011(0.0009) Steps 808(807.48) | Grad Norm 1.8445(1.4792) | Total Time 0.00(0.00)\n",
      "Iter 15540 | Time 21.5342(21.8578) | Bit/dim 3.5090(3.5083) | Xent 0.0042(0.0038) | Loss 8.7593(9.2436) | Error 0.0011(0.0009) Steps 778(807.84) | Grad Norm 1.9680(1.5982) | Total Time 0.00(0.00)\n",
      "Iter 15550 | Time 21.7298(21.7741) | Bit/dim 3.4978(3.5066) | Xent 0.0022(0.0036) | Loss 8.6455(9.1142) | Error 0.0000(0.0009) Steps 802(807.77) | Grad Norm 1.2333(1.6386) | Total Time 0.00(0.00)\n",
      "Iter 15560 | Time 21.0038(21.7823) | Bit/dim 3.5019(3.5085) | Xent 0.0019(0.0044) | Loss 8.5481(9.0193) | Error 0.0000(0.0011) Steps 790(808.04) | Grad Norm 1.2416(1.6853) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0283 | Time 101.4359, Epoch Time 1323.5035(1285.2346), Bit/dim 3.5377(best: 3.5348), Xent 2.4648, Loss 4.7701, Error 0.3271(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15570 | Time 21.7994(21.8158) | Bit/dim 3.4896(3.5082) | Xent 0.0037(0.0047) | Loss 8.7498(9.7506) | Error 0.0011(0.0012) Steps 802(806.43) | Grad Norm 1.4989(1.6919) | Total Time 0.00(0.00)\n",
      "Iter 15580 | Time 21.5468(21.7049) | Bit/dim 3.5133(3.5089) | Xent 0.0025(0.0049) | Loss 8.7487(9.4886) | Error 0.0000(0.0013) Steps 772(802.92) | Grad Norm 0.8785(1.7183) | Total Time 0.00(0.00)\n",
      "Iter 15590 | Time 21.3769(21.7144) | Bit/dim 3.5240(3.5106) | Xent 0.0010(0.0047) | Loss 8.8756(9.3135) | Error 0.0000(0.0012) Steps 820(804.03) | Grad Norm 0.9206(1.7275) | Total Time 0.00(0.00)\n",
      "Iter 15600 | Time 21.8783(21.7345) | Bit/dim 3.4866(3.5087) | Xent 0.0082(0.0044) | Loss 8.8012(9.1722) | Error 0.0033(0.0012) Steps 826(802.89) | Grad Norm 2.1158(1.6714) | Total Time 0.00(0.00)\n",
      "Iter 15610 | Time 21.4611(21.7298) | Bit/dim 3.5154(3.5080) | Xent 0.0018(0.0045) | Loss 8.7576(9.0622) | Error 0.0000(0.0013) Steps 796(804.55) | Grad Norm 1.2721(1.7092) | Total Time 0.00(0.00)\n",
      "Iter 15620 | Time 21.2838(21.7433) | Bit/dim 3.4750(3.5054) | Xent 0.0022(0.0044) | Loss 8.8033(8.9892) | Error 0.0011(0.0013) Steps 796(806.09) | Grad Norm 0.9849(1.7668) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0284 | Time 101.2422, Epoch Time 1316.6078(1286.1758), Bit/dim 3.5396(best: 3.5348), Xent 2.4694, Loss 4.7744, Error 0.3278(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15630 | Time 22.3384(21.7856) | Bit/dim 3.4875(3.5075) | Xent 0.0010(0.0038) | Loss 8.7081(9.6103) | Error 0.0000(0.0011) Steps 784(805.56) | Grad Norm 0.7367(1.6045) | Total Time 0.00(0.00)\n",
      "Iter 15640 | Time 22.1452(21.8117) | Bit/dim 3.5200(3.5099) | Xent 0.0040(0.0041) | Loss 8.8090(9.3939) | Error 0.0011(0.0011) Steps 796(803.52) | Grad Norm 1.8990(1.5584) | Total Time 0.00(0.00)\n",
      "Iter 15650 | Time 21.0718(21.7277) | Bit/dim 3.5043(3.5088) | Xent 0.0023(0.0039) | Loss 8.7316(9.2185) | Error 0.0000(0.0010) Steps 814(804.09) | Grad Norm 1.6195(1.5255) | Total Time 0.00(0.00)\n",
      "Iter 15660 | Time 22.7214(21.8085) | Bit/dim 3.4990(3.5051) | Xent 0.0013(0.0041) | Loss 8.8644(9.1041) | Error 0.0000(0.0010) Steps 772(801.93) | Grad Norm 0.9415(1.5750) | Total Time 0.00(0.00)\n",
      "Iter 15670 | Time 21.8552(21.8019) | Bit/dim 3.5257(3.5044) | Xent 0.0023(0.0044) | Loss 8.8426(9.0041) | Error 0.0011(0.0010) Steps 808(800.95) | Grad Norm 1.3477(1.7127) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0285 | Time 102.3243, Epoch Time 1322.3841(1287.2621), Bit/dim 3.5363(best: 3.5348), Xent 2.4700, Loss 4.7712, Error 0.3232(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15680 | Time 22.0873(21.7747) | Bit/dim 3.5139(3.5045) | Xent 0.0063(0.0048) | Loss 8.7807(9.7554) | Error 0.0011(0.0012) Steps 826(800.85) | Grad Norm 1.8203(1.8185) | Total Time 0.00(0.00)\n",
      "Iter 15690 | Time 21.4830(21.7985) | Bit/dim 3.5205(3.5035) | Xent 0.0044(0.0051) | Loss 8.8475(9.4986) | Error 0.0011(0.0013) Steps 790(800.58) | Grad Norm 1.5223(1.8274) | Total Time 0.00(0.00)\n",
      "Iter 15700 | Time 21.5037(21.7056) | Bit/dim 3.4900(3.5055) | Xent 0.0043(0.0045) | Loss 8.7431(9.3095) | Error 0.0011(0.0011) Steps 826(803.10) | Grad Norm 1.8713(1.6612) | Total Time 0.00(0.00)\n",
      "Iter 15710 | Time 23.0264(21.7894) | Bit/dim 3.4918(3.5043) | Xent 0.0074(0.0043) | Loss 8.8146(9.1670) | Error 0.0033(0.0011) Steps 796(805.72) | Grad Norm 1.7015(1.5855) | Total Time 0.00(0.00)\n",
      "Iter 15720 | Time 21.8280(21.8257) | Bit/dim 3.4973(3.5049) | Xent 0.0081(0.0040) | Loss 8.7940(9.0766) | Error 0.0011(0.0011) Steps 838(809.91) | Grad Norm 0.9396(1.5393) | Total Time 0.00(0.00)\n",
      "Iter 15730 | Time 21.4431(21.8039) | Bit/dim 3.4978(3.5053) | Xent 0.0059(0.0039) | Loss 8.7437(8.9934) | Error 0.0022(0.0009) Steps 838(808.28) | Grad Norm 1.6963(1.4007) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0286 | Time 101.2412, Epoch Time 1321.6235(1288.2929), Bit/dim 3.5361(best: 3.5348), Xent 2.4702, Loss 4.7712, Error 0.3296(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15740 | Time 21.3180(21.7887) | Bit/dim 3.4872(3.5052) | Xent 0.0012(0.0035) | Loss 8.6558(9.6184) | Error 0.0000(0.0008) Steps 790(808.59) | Grad Norm 0.4153(1.2601) | Total Time 0.00(0.00)\n",
      "Iter 15750 | Time 21.5377(21.7881) | Bit/dim 3.5242(3.5053) | Xent 0.0027(0.0032) | Loss 8.7394(9.3931) | Error 0.0011(0.0007) Steps 808(807.68) | Grad Norm 2.8715(1.3311) | Total Time 0.00(0.00)\n",
      "Iter 15760 | Time 22.6611(21.8044) | Bit/dim 3.4997(3.5054) | Xent 0.0034(0.0033) | Loss 8.7518(9.2289) | Error 0.0022(0.0009) Steps 784(805.15) | Grad Norm 2.3661(1.4241) | Total Time 0.00(0.00)\n",
      "Iter 15770 | Time 21.2920(21.8642) | Bit/dim 3.5080(3.5034) | Xent 0.0013(0.0028) | Loss 8.7409(9.1015) | Error 0.0000(0.0007) Steps 814(807.51) | Grad Norm 0.4787(1.2867) | Total Time 0.00(0.00)\n",
      "Iter 15780 | Time 22.1432(21.9365) | Bit/dim 3.4947(3.5050) | Xent 0.0024(0.0031) | Loss 8.7523(9.0089) | Error 0.0011(0.0007) Steps 826(806.44) | Grad Norm 0.9902(1.3679) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0287 | Time 101.2836, Epoch Time 1325.6391(1289.4133), Bit/dim 3.5350(best: 3.5348), Xent 2.4572, Loss 4.7636, Error 0.3278(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15790 | Time 21.9490(21.8372) | Bit/dim 3.5341(3.5046) | Xent 0.0037(0.0033) | Loss 8.8593(9.7309) | Error 0.0011(0.0008) Steps 760(801.45) | Grad Norm 0.7873(1.3630) | Total Time 0.00(0.00)\n",
      "Iter 15800 | Time 21.5492(21.7981) | Bit/dim 3.5053(3.5044) | Xent 0.0011(0.0033) | Loss 8.7990(9.4833) | Error 0.0000(0.0008) Steps 802(803.70) | Grad Norm 0.6973(1.3411) | Total Time 0.00(0.00)\n",
      "Iter 15810 | Time 21.6064(21.7976) | Bit/dim 3.4506(3.5031) | Xent 0.0025(0.0034) | Loss 8.5522(9.2811) | Error 0.0011(0.0008) Steps 802(802.83) | Grad Norm 2.3854(1.3802) | Total Time 0.00(0.00)\n",
      "Iter 15820 | Time 20.7924(21.7727) | Bit/dim 3.5021(3.5060) | Xent 0.0022(0.0040) | Loss 8.7223(9.1540) | Error 0.0011(0.0010) Steps 802(805.98) | Grad Norm 0.9992(1.4714) | Total Time 0.00(0.00)\n",
      "Iter 15830 | Time 21.6768(21.7643) | Bit/dim 3.5153(3.5055) | Xent 0.0011(0.0036) | Loss 8.7429(9.0519) | Error 0.0000(0.0009) Steps 772(806.09) | Grad Norm 0.6025(1.3699) | Total Time 0.00(0.00)\n",
      "Iter 15840 | Time 21.7570(21.8006) | Bit/dim 3.4475(3.5029) | Xent 0.0024(0.0041) | Loss 8.5685(8.9622) | Error 0.0011(0.0010) Steps 802(805.70) | Grad Norm 1.2792(1.4513) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0288 | Time 102.3806, Epoch Time 1319.9134(1290.3283), Bit/dim 3.5367(best: 3.5348), Xent 2.5159, Loss 4.7947, Error 0.3335(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15850 | Time 21.3089(21.7732) | Bit/dim 3.4933(3.5048) | Xent 0.0157(0.0044) | Loss 8.7849(9.5865) | Error 0.0022(0.0011) Steps 832(804.80) | Grad Norm 1.4425(1.5638) | Total Time 0.00(0.00)\n",
      "Iter 15860 | Time 22.1906(21.7296) | Bit/dim 3.4879(3.5068) | Xent 0.0060(0.0044) | Loss 8.7119(9.3735) | Error 0.0022(0.0012) Steps 820(806.88) | Grad Norm 2.1457(1.6892) | Total Time 0.00(0.00)\n",
      "Iter 15870 | Time 21.4571(21.6341) | Bit/dim 3.5194(3.5073) | Xent 0.0026(0.0045) | Loss 8.7187(9.2153) | Error 0.0011(0.0013) Steps 832(807.22) | Grad Norm 2.4804(1.9340) | Total Time 0.00(0.00)\n",
      "Iter 15880 | Time 21.3458(21.6399) | Bit/dim 3.5016(3.5074) | Xent 0.0107(0.0046) | Loss 8.7103(9.0947) | Error 0.0033(0.0013) Steps 838(807.00) | Grad Norm 2.7791(1.9623) | Total Time 0.00(0.00)\n",
      "Iter 15890 | Time 21.9588(21.6957) | Bit/dim 3.4556(3.5027) | Xent 0.0024(0.0041) | Loss 8.6830(8.9975) | Error 0.0011(0.0011) Steps 790(807.88) | Grad Norm 2.2685(1.7753) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0289 | Time 100.1426, Epoch Time 1310.0019(1290.9185), Bit/dim 3.5336(best: 3.5348), Xent 2.4876, Loss 4.7774, Error 0.3261(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15900 | Time 22.0419(21.7555) | Bit/dim 3.5049(3.5037) | Xent 0.0071(0.0041) | Loss 8.8126(9.7388) | Error 0.0022(0.0011) Steps 808(807.59) | Grad Norm 1.5666(1.7726) | Total Time 0.00(0.00)\n",
      "Iter 15910 | Time 21.6843(21.7004) | Bit/dim 3.5020(3.5042) | Xent 0.0025(0.0037) | Loss 8.7951(9.4864) | Error 0.0011(0.0010) Steps 832(807.57) | Grad Norm 1.1972(1.7531) | Total Time 0.00(0.00)\n",
      "Iter 15920 | Time 22.0077(21.7709) | Bit/dim 3.5160(3.5074) | Xent 0.0009(0.0031) | Loss 8.7686(9.3041) | Error 0.0000(0.0008) Steps 796(807.23) | Grad Norm 0.7982(1.5670) | Total Time 0.00(0.00)\n",
      "Iter 15930 | Time 21.5947(21.7770) | Bit/dim 3.4961(3.5062) | Xent 0.0012(0.0034) | Loss 8.7679(9.1621) | Error 0.0000(0.0008) Steps 820(803.12) | Grad Norm 1.0109(1.5436) | Total Time 0.00(0.00)\n",
      "Iter 15940 | Time 21.4717(21.7649) | Bit/dim 3.4888(3.5045) | Xent 0.0018(0.0030) | Loss 8.7556(9.0400) | Error 0.0000(0.0007) Steps 808(803.01) | Grad Norm 1.2843(1.4582) | Total Time 0.00(0.00)\n",
      "Iter 15950 | Time 22.8965(21.8435) | Bit/dim 3.4732(3.5016) | Xent 0.0018(0.0032) | Loss 8.7520(8.9709) | Error 0.0000(0.0007) Steps 838(805.53) | Grad Norm 1.3855(1.4837) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0290 | Time 102.2238, Epoch Time 1326.5903(1291.9887), Bit/dim 3.5367(best: 3.5336), Xent 2.5494, Loss 4.8114, Error 0.3334(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 15960 | Time 21.3494(21.8260) | Bit/dim 3.4984(3.5002) | Xent 0.0063(0.0033) | Loss 8.8100(9.5701) | Error 0.0022(0.0008) Steps 784(805.60) | Grad Norm 1.8618(1.4683) | Total Time 0.00(0.00)\n",
      "Iter 15970 | Time 22.0202(21.7820) | Bit/dim 3.5322(3.5038) | Xent 0.0039(0.0034) | Loss 8.9566(9.3676) | Error 0.0011(0.0008) Steps 838(805.04) | Grad Norm 2.6440(1.4944) | Total Time 0.00(0.00)\n",
      "Iter 15980 | Time 22.5769(21.8301) | Bit/dim 3.4690(3.5036) | Xent 0.0008(0.0033) | Loss 8.7575(9.2075) | Error 0.0000(0.0009) Steps 844(806.41) | Grad Norm 1.1490(1.5501) | Total Time 0.00(0.00)\n",
      "Iter 15990 | Time 22.3945(21.8082) | Bit/dim 3.4654(3.5036) | Xent 0.0045(0.0032) | Loss 8.6649(9.0808) | Error 0.0011(0.0009) Steps 850(804.71) | Grad Norm 3.6910(1.7040) | Total Time 0.00(0.00)\n",
      "Iter 16000 | Time 21.9587(21.8169) | Bit/dim 3.5030(3.5022) | Xent 0.0055(0.0035) | Loss 8.8223(8.9862) | Error 0.0011(0.0009) Steps 802(802.55) | Grad Norm 2.0119(1.7184) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0291 | Time 101.3317, Epoch Time 1320.8881(1292.8556), Bit/dim 3.5349(best: 3.5336), Xent 2.5625, Loss 4.8161, Error 0.3324(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16010 | Time 21.5158(21.7701) | Bit/dim 3.4962(3.5028) | Xent 0.0018(0.0035) | Loss 8.8357(9.7384) | Error 0.0011(0.0009) Steps 778(801.49) | Grad Norm 1.1439(1.6590) | Total Time 0.00(0.00)\n",
      "Iter 16020 | Time 21.6363(21.7526) | Bit/dim 3.5350(3.5059) | Xent 0.0085(0.0037) | Loss 8.7827(9.4839) | Error 0.0022(0.0009) Steps 802(802.26) | Grad Norm 4.0820(1.7130) | Total Time 0.00(0.00)\n",
      "Iter 16030 | Time 21.1957(21.8203) | Bit/dim 3.4819(3.5054) | Xent 0.0080(0.0035) | Loss 8.6290(9.2969) | Error 0.0022(0.0008) Steps 802(800.42) | Grad Norm 1.8708(1.5719) | Total Time 0.00(0.00)\n",
      "Iter 16040 | Time 21.8411(21.7165) | Bit/dim 3.5100(3.5052) | Xent 0.0036(0.0038) | Loss 8.8491(9.1611) | Error 0.0011(0.0009) Steps 820(802.25) | Grad Norm 2.0870(1.5959) | Total Time 0.00(0.00)\n",
      "Iter 16050 | Time 22.4133(21.7069) | Bit/dim 3.4959(3.5034) | Xent 0.0011(0.0053) | Loss 8.7218(9.0467) | Error 0.0000(0.0012) Steps 808(803.20) | Grad Norm 2.1363(2.1977) | Total Time 0.00(0.00)\n",
      "Iter 16060 | Time 21.3992(21.6138) | Bit/dim 3.5408(3.5066) | Xent 0.0025(0.0054) | Loss 8.7522(8.9742) | Error 0.0011(0.0013) Steps 772(802.57) | Grad Norm 1.2655(2.2976) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0292 | Time 100.2633, Epoch Time 1311.0578(1293.4017), Bit/dim 3.5369(best: 3.5336), Xent 2.5715, Loss 4.8227, Error 0.3332(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16070 | Time 21.7209(21.6341) | Bit/dim 3.5022(3.5048) | Xent 0.0099(0.0051) | Loss 8.7498(9.5860) | Error 0.0033(0.0013) Steps 808(802.17) | Grad Norm 2.3046(2.1828) | Total Time 0.00(0.00)\n",
      "Iter 16080 | Time 21.6578(21.6696) | Bit/dim 3.5077(3.5050) | Xent 0.0036(0.0047) | Loss 8.8625(9.3759) | Error 0.0011(0.0012) Steps 832(802.67) | Grad Norm 1.8488(1.9561) | Total Time 0.00(0.00)\n",
      "Iter 16090 | Time 21.1731(21.6265) | Bit/dim 3.4916(3.5050) | Xent 0.0012(0.0040) | Loss 8.7052(9.2066) | Error 0.0000(0.0009) Steps 808(801.66) | Grad Norm 1.0292(1.8209) | Total Time 0.00(0.00)\n",
      "Iter 16100 | Time 20.7360(21.6367) | Bit/dim 3.5277(3.5068) | Xent 0.0089(0.0038) | Loss 8.6639(9.0906) | Error 0.0011(0.0009) Steps 772(800.54) | Grad Norm 1.2266(1.6181) | Total Time 0.00(0.00)\n",
      "Iter 16110 | Time 21.8346(21.6555) | Bit/dim 3.5190(3.5060) | Xent 0.0025(0.0042) | Loss 8.8749(9.0130) | Error 0.0000(0.0009) Steps 826(803.94) | Grad Norm 1.3796(1.5573) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0293 | Time 99.3283, Epoch Time 1313.1893(1293.9953), Bit/dim 3.5335(best: 3.5336), Xent 2.5207, Loss 4.7938, Error 0.3284(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16120 | Time 22.4389(21.7049) | Bit/dim 3.4976(3.5041) | Xent 0.0008(0.0042) | Loss 8.7792(9.7505) | Error 0.0000(0.0009) Steps 832(806.30) | Grad Norm 0.6700(1.5595) | Total Time 0.00(0.00)\n",
      "Iter 16130 | Time 22.3023(21.7612) | Bit/dim 3.5382(3.5054) | Xent 0.0009(0.0040) | Loss 8.7085(9.4933) | Error 0.0000(0.0009) Steps 784(807.20) | Grad Norm 0.6893(1.5195) | Total Time 0.00(0.00)\n",
      "Iter 16140 | Time 21.9481(21.7990) | Bit/dim 3.4974(3.5014) | Xent 0.0015(0.0041) | Loss 8.7704(9.2885) | Error 0.0000(0.0009) Steps 802(806.77) | Grad Norm 0.7029(1.5077) | Total Time 0.00(0.00)\n",
      "Iter 16150 | Time 21.1953(21.7157) | Bit/dim 3.5113(3.5023) | Xent 0.0015(0.0037) | Loss 8.6107(9.1408) | Error 0.0000(0.0008) Steps 832(805.21) | Grad Norm 1.0100(1.4279) | Total Time 0.00(0.00)\n",
      "Iter 16160 | Time 20.6106(21.6459) | Bit/dim 3.5300(3.5018) | Xent 0.0009(0.0037) | Loss 8.8689(9.0460) | Error 0.0000(0.0008) Steps 778(806.96) | Grad Norm 1.0132(1.5863) | Total Time 0.00(0.00)\n",
      "Iter 16170 | Time 21.3624(21.7341) | Bit/dim 3.4883(3.5047) | Xent 0.0046(0.0038) | Loss 8.6823(8.9722) | Error 0.0011(0.0008) Steps 790(807.12) | Grad Norm 1.9248(1.6249) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0294 | Time 100.0451, Epoch Time 1318.5471(1294.7319), Bit/dim 3.5344(best: 3.5335), Xent 2.5318, Loss 4.8003, Error 0.3309(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16180 | Time 21.8306(21.7679) | Bit/dim 3.5154(3.5073) | Xent 0.0136(0.0039) | Loss 8.8773(9.6168) | Error 0.0044(0.0009) Steps 808(805.51) | Grad Norm 2.6731(1.6428) | Total Time 0.00(0.00)\n",
      "Iter 16190 | Time 21.5968(21.7150) | Bit/dim 3.4988(3.5026) | Xent 0.0010(0.0040) | Loss 8.7411(9.3945) | Error 0.0000(0.0009) Steps 826(804.93) | Grad Norm 0.6982(1.6458) | Total Time 0.00(0.00)\n",
      "Iter 16200 | Time 22.1946(21.7453) | Bit/dim 3.5287(3.5036) | Xent 0.0010(0.0040) | Loss 8.8205(9.2280) | Error 0.0000(0.0009) Steps 796(804.10) | Grad Norm 0.5071(1.5278) | Total Time 0.00(0.00)\n",
      "Iter 16210 | Time 21.3159(21.7232) | Bit/dim 3.5293(3.5049) | Xent 0.0024(0.0041) | Loss 8.8378(9.1099) | Error 0.0000(0.0009) Steps 796(803.74) | Grad Norm 1.3217(1.4933) | Total Time 0.00(0.00)\n",
      "Iter 16220 | Time 21.6267(21.7444) | Bit/dim 3.5219(3.5043) | Xent 0.0016(0.0037) | Loss 8.8302(9.0307) | Error 0.0000(0.0008) Steps 832(804.28) | Grad Norm 0.7462(1.4630) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0295 | Time 100.4744, Epoch Time 1317.9334(1295.4279), Bit/dim 3.5351(best: 3.5335), Xent 2.5443, Loss 4.8073, Error 0.3316(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16230 | Time 22.0057(21.7256) | Bit/dim 3.5075(3.5028) | Xent 0.0102(0.0037) | Loss 8.7766(9.7587) | Error 0.0011(0.0007) Steps 838(804.30) | Grad Norm 0.8606(1.4174) | Total Time 0.00(0.00)\n",
      "Iter 16240 | Time 21.6940(21.6839) | Bit/dim 3.5329(3.5036) | Xent 0.0008(0.0037) | Loss 8.7970(9.4896) | Error 0.0000(0.0008) Steps 790(802.03) | Grad Norm 0.7134(1.3984) | Total Time 0.00(0.00)\n",
      "Iter 16250 | Time 22.4895(21.7263) | Bit/dim 3.4986(3.5055) | Xent 0.0076(0.0038) | Loss 8.7815(9.2947) | Error 0.0022(0.0009) Steps 826(799.85) | Grad Norm 1.8760(1.3749) | Total Time 0.00(0.00)\n",
      "Iter 16260 | Time 22.3785(21.7395) | Bit/dim 3.5033(3.5030) | Xent 0.0058(0.0040) | Loss 8.8865(9.1501) | Error 0.0011(0.0009) Steps 820(801.43) | Grad Norm 1.4312(1.5652) | Total Time 0.00(0.00)\n",
      "Iter 16270 | Time 21.8269(21.6882) | Bit/dim 3.4950(3.5045) | Xent 0.0032(0.0043) | Loss 8.7881(9.0521) | Error 0.0011(0.0010) Steps 796(799.49) | Grad Norm 1.7997(1.6717) | Total Time 0.00(0.00)\n",
      "Iter 16280 | Time 22.3591(21.6730) | Bit/dim 3.4889(3.5031) | Xent 0.0059(0.0046) | Loss 8.7813(8.9723) | Error 0.0022(0.0010) Steps 778(799.77) | Grad Norm 3.0741(1.7132) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0296 | Time 99.8471, Epoch Time 1312.5532(1295.9417), Bit/dim 3.5361(best: 3.5335), Xent 2.5572, Loss 4.8147, Error 0.3308(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16290 | Time 20.6101(21.5362) | Bit/dim 3.4969(3.5018) | Xent 0.0089(0.0045) | Loss 8.6734(9.5625) | Error 0.0011(0.0010) Steps 766(798.20) | Grad Norm 3.3984(1.8967) | Total Time 0.00(0.00)\n",
      "Iter 16300 | Time 21.7941(21.5688) | Bit/dim 3.5039(3.5020) | Xent 0.0020(0.0050) | Loss 8.8756(9.3562) | Error 0.0000(0.0012) Steps 820(800.85) | Grad Norm 1.7333(2.2082) | Total Time 0.00(0.00)\n",
      "Iter 16310 | Time 20.8856(21.6444) | Bit/dim 3.4868(3.5053) | Xent 0.0088(0.0047) | Loss 8.6611(9.2063) | Error 0.0033(0.0012) Steps 820(801.57) | Grad Norm 3.7504(2.1839) | Total Time 0.00(0.00)\n",
      "Iter 16320 | Time 21.4662(21.6051) | Bit/dim 3.4903(3.5051) | Xent 0.0012(0.0047) | Loss 8.7101(9.0812) | Error 0.0000(0.0010) Steps 790(802.78) | Grad Norm 1.3035(2.0521) | Total Time 0.00(0.00)\n",
      "Iter 16330 | Time 22.0394(21.7184) | Bit/dim 3.4859(3.5047) | Xent 0.0011(0.0045) | Loss 8.8094(9.0013) | Error 0.0000(0.0010) Steps 808(804.08) | Grad Norm 0.9030(1.9267) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0297 | Time 101.8928, Epoch Time 1313.6693(1296.4735), Bit/dim 3.5328(best: 3.5335), Xent 2.5417, Loss 4.8036, Error 0.3310(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16340 | Time 21.9163(21.7139) | Bit/dim 3.4740(3.5041) | Xent 0.0016(0.0046) | Loss 8.6923(9.7075) | Error 0.0000(0.0010) Steps 796(800.41) | Grad Norm 1.6616(1.9934) | Total Time 0.00(0.00)\n",
      "Iter 16350 | Time 21.3862(21.7520) | Bit/dim 3.5538(3.5026) | Xent 0.0039(0.0046) | Loss 8.8801(9.4629) | Error 0.0011(0.0011) Steps 802(801.09) | Grad Norm 2.7560(2.0010) | Total Time 0.00(0.00)\n",
      "Iter 16360 | Time 21.6836(21.7102) | Bit/dim 3.4995(3.5057) | Xent 0.0052(0.0046) | Loss 8.7839(9.2894) | Error 0.0033(0.0012) Steps 808(797.67) | Grad Norm 3.4246(2.0581) | Total Time 0.00(0.00)\n",
      "Iter 16370 | Time 22.2305(21.6910) | Bit/dim 3.5135(3.5051) | Xent 0.0058(0.0048) | Loss 8.9221(9.1485) | Error 0.0022(0.0013) Steps 820(798.32) | Grad Norm 3.2438(2.2301) | Total Time 0.00(0.00)\n",
      "Iter 16380 | Time 21.5520(21.7831) | Bit/dim 3.5231(3.5071) | Xent 0.0078(0.0043) | Loss 8.7950(9.0576) | Error 0.0022(0.0012) Steps 814(802.29) | Grad Norm 1.5453(2.0845) | Total Time 0.00(0.00)\n",
      "Iter 16390 | Time 22.1028(21.7826) | Bit/dim 3.5040(3.5038) | Xent 0.0017(0.0045) | Loss 8.7271(8.9802) | Error 0.0000(0.0013) Steps 832(801.10) | Grad Norm 1.5066(2.0054) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0298 | Time 100.2584, Epoch Time 1319.0206(1297.1499), Bit/dim 3.5345(best: 3.5328), Xent 2.5474, Loss 4.8082, Error 0.3336(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16400 | Time 21.5657(21.8178) | Bit/dim 3.5249(3.5038) | Xent 0.0038(0.0043) | Loss 8.7589(9.5921) | Error 0.0022(0.0012) Steps 808(801.98) | Grad Norm 2.2788(2.0244) | Total Time 0.00(0.00)\n",
      "Iter 16410 | Time 21.3034(21.8136) | Bit/dim 3.5257(3.5048) | Xent 0.0017(0.0049) | Loss 8.7067(9.3674) | Error 0.0000(0.0014) Steps 772(800.74) | Grad Norm 1.4183(2.0147) | Total Time 0.00(0.00)\n",
      "Iter 16420 | Time 23.3138(21.8478) | Bit/dim 3.4766(3.5052) | Xent 0.0012(0.0047) | Loss 8.7849(9.2164) | Error 0.0000(0.0012) Steps 844(805.65) | Grad Norm 1.0343(2.0175) | Total Time 0.00(0.00)\n",
      "Iter 16430 | Time 21.8564(21.8590) | Bit/dim 3.5058(3.5052) | Xent 0.0021(0.0042) | Loss 8.6822(9.0964) | Error 0.0000(0.0012) Steps 826(809.00) | Grad Norm 1.3870(1.8838) | Total Time 0.00(0.00)\n",
      "Iter 16440 | Time 21.7876(21.8008) | Bit/dim 3.4839(3.5041) | Xent 0.0035(0.0043) | Loss 8.7616(9.0003) | Error 0.0022(0.0013) Steps 838(806.60) | Grad Norm 1.6698(1.8283) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0299 | Time 100.8469, Epoch Time 1323.4150(1297.9379), Bit/dim 3.5345(best: 3.5328), Xent 2.5399, Loss 4.8044, Error 0.3327(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16450 | Time 20.7829(21.8006) | Bit/dim 3.4920(3.5011) | Xent 0.0075(0.0044) | Loss 8.6265(9.7228) | Error 0.0011(0.0012) Steps 784(805.20) | Grad Norm 1.8612(1.8890) | Total Time 0.00(0.00)\n",
      "Iter 16460 | Time 21.1687(21.8411) | Bit/dim 3.5086(3.5009) | Xent 0.0096(0.0045) | Loss 8.7455(9.4647) | Error 0.0033(0.0012) Steps 796(804.16) | Grad Norm 3.0108(1.9826) | Total Time 0.00(0.00)\n",
      "Iter 16470 | Time 21.8601(21.8056) | Bit/dim 3.4913(3.5006) | Xent 0.0052(0.0049) | Loss 8.7957(9.2781) | Error 0.0022(0.0012) Steps 820(806.55) | Grad Norm 2.4093(1.9712) | Total Time 0.00(0.00)\n",
      "Iter 16480 | Time 20.9003(21.6904) | Bit/dim 3.5034(3.5017) | Xent 0.0016(0.0041) | Loss 8.8496(9.1430) | Error 0.0000(0.0010) Steps 784(803.76) | Grad Norm 1.1566(1.8525) | Total Time 0.00(0.00)\n",
      "Iter 16490 | Time 22.3242(21.7185) | Bit/dim 3.4937(3.5039) | Xent 0.0023(0.0038) | Loss 8.7045(9.0431) | Error 0.0000(0.0010) Steps 832(801.89) | Grad Norm 1.2938(1.8910) | Total Time 0.00(0.00)\n",
      "Iter 16500 | Time 21.9028(21.7043) | Bit/dim 3.4769(3.5051) | Xent 0.0124(0.0039) | Loss 8.6793(8.9705) | Error 0.0022(0.0010) Steps 790(801.54) | Grad Norm 3.7442(1.8860) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0300 | Time 100.5395, Epoch Time 1314.0148(1298.4202), Bit/dim 3.5339(best: 3.5328), Xent 2.5555, Loss 4.8117, Error 0.3268(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16510 | Time 22.3523(21.6967) | Bit/dim 3.5061(3.5039) | Xent 0.0022(0.0034) | Loss 8.8941(9.5933) | Error 0.0011(0.0010) Steps 838(802.57) | Grad Norm 1.7017(1.7504) | Total Time 0.00(0.00)\n",
      "Iter 16520 | Time 22.4322(21.7293) | Bit/dim 3.5117(3.5024) | Xent 0.0012(0.0035) | Loss 8.8639(9.3727) | Error 0.0000(0.0011) Steps 826(805.74) | Grad Norm 0.8918(1.7280) | Total Time 0.00(0.00)\n",
      "Iter 16530 | Time 20.7599(21.7316) | Bit/dim 3.4824(3.5020) | Xent 0.0040(0.0033) | Loss 8.6453(9.2108) | Error 0.0022(0.0010) Steps 784(803.98) | Grad Norm 1.4335(1.6980) | Total Time 0.00(0.00)\n",
      "Iter 16540 | Time 22.1554(21.7361) | Bit/dim 3.5044(3.5047) | Xent 0.0008(0.0030) | Loss 8.8858(9.1034) | Error 0.0000(0.0009) Steps 844(804.20) | Grad Norm 0.7472(1.6208) | Total Time 0.00(0.00)\n",
      "Iter 16550 | Time 23.3854(21.8059) | Bit/dim 3.5429(3.5047) | Xent 0.0069(0.0030) | Loss 8.7604(9.0041) | Error 0.0011(0.0008) Steps 862(803.87) | Grad Norm 2.1327(1.5937) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0301 | Time 99.7309, Epoch Time 1321.0591(1299.0994), Bit/dim 3.5363(best: 3.5328), Xent 2.5903, Loss 4.8314, Error 0.3337(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16560 | Time 21.5631(21.8489) | Bit/dim 3.4927(3.5047) | Xent 0.0033(0.0032) | Loss 8.7177(9.7257) | Error 0.0011(0.0009) Steps 808(805.89) | Grad Norm 1.4668(1.9687) | Total Time 0.00(0.00)\n",
      "Iter 16570 | Time 21.9924(21.7960) | Bit/dim 3.5329(3.5050) | Xent 0.0057(0.0037) | Loss 8.8602(9.4718) | Error 0.0011(0.0010) Steps 784(805.46) | Grad Norm 1.7477(2.0450) | Total Time 0.00(0.00)\n",
      "Iter 16580 | Time 20.9251(21.7434) | Bit/dim 3.4761(3.5050) | Xent 0.0029(0.0037) | Loss 8.6090(9.2797) | Error 0.0011(0.0010) Steps 790(803.82) | Grad Norm 1.6383(1.9435) | Total Time 0.00(0.00)\n",
      "Iter 16590 | Time 21.9018(21.7085) | Bit/dim 3.5021(3.5020) | Xent 0.0108(0.0046) | Loss 8.7972(9.1365) | Error 0.0022(0.0011) Steps 808(802.62) | Grad Norm 2.5236(2.0037) | Total Time 0.00(0.00)\n",
      "Iter 16600 | Time 22.2545(21.7766) | Bit/dim 3.4785(3.4993) | Xent 0.0023(0.0042) | Loss 8.7710(9.0487) | Error 0.0011(0.0011) Steps 820(803.66) | Grad Norm 1.8498(1.8962) | Total Time 0.00(0.00)\n",
      "Iter 16610 | Time 22.0456(21.7755) | Bit/dim 3.5320(3.5044) | Xent 0.0008(0.0042) | Loss 8.7440(8.9792) | Error 0.0000(0.0011) Steps 808(802.45) | Grad Norm 0.8607(1.7888) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0302 | Time 100.3136, Epoch Time 1316.5094(1299.6217), Bit/dim 3.5322(best: 3.5328), Xent 2.6042, Loss 4.8343, Error 0.3363(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16620 | Time 21.2157(21.7800) | Bit/dim 3.4868(3.5055) | Xent 0.0092(0.0040) | Loss 8.7690(9.6072) | Error 0.0011(0.0010) Steps 808(801.10) | Grad Norm 1.7662(1.6544) | Total Time 0.00(0.00)\n",
      "Iter 16630 | Time 21.3655(21.7506) | Bit/dim 3.5078(3.5043) | Xent 0.0009(0.0037) | Loss 8.7503(9.3849) | Error 0.0000(0.0009) Steps 784(802.57) | Grad Norm 0.9687(1.6076) | Total Time 0.00(0.00)\n",
      "Iter 16640 | Time 21.7347(21.6578) | Bit/dim 3.5199(3.5047) | Xent 0.0050(0.0035) | Loss 8.7937(9.2122) | Error 0.0011(0.0009) Steps 778(798.66) | Grad Norm 1.4521(1.5066) | Total Time 0.00(0.00)\n",
      "Iter 16650 | Time 22.0096(21.7126) | Bit/dim 3.5065(3.5022) | Xent 0.0034(0.0039) | Loss 8.8253(9.0907) | Error 0.0011(0.0009) Steps 826(803.68) | Grad Norm 2.4518(1.6232) | Total Time 0.00(0.00)\n",
      "Iter 16660 | Time 22.2994(21.7079) | Bit/dim 3.5367(3.5017) | Xent 0.0074(0.0043) | Loss 8.9090(9.0041) | Error 0.0011(0.0010) Steps 832(804.08) | Grad Norm 1.2996(1.6515) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0303 | Time 100.7947, Epoch Time 1314.6110(1300.0713), Bit/dim 3.5333(best: 3.5322), Xent 2.6060, Loss 4.8363, Error 0.3354(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16670 | Time 23.8181(21.7682) | Bit/dim 3.4883(3.5008) | Xent 0.0007(0.0039) | Loss 8.7319(9.7303) | Error 0.0000(0.0010) Steps 832(802.83) | Grad Norm 0.5439(1.5601) | Total Time 0.00(0.00)\n",
      "Iter 16680 | Time 21.6793(21.7559) | Bit/dim 3.5335(3.5062) | Xent 0.0016(0.0034) | Loss 8.9278(9.4929) | Error 0.0000(0.0008) Steps 814(804.30) | Grad Norm 1.4006(1.4846) | Total Time 0.00(0.00)\n",
      "Iter 16690 | Time 22.0923(21.7341) | Bit/dim 3.4909(3.5042) | Xent 0.0084(0.0036) | Loss 8.7430(9.3006) | Error 0.0011(0.0009) Steps 814(803.54) | Grad Norm 1.6251(1.6535) | Total Time 0.00(0.00)\n",
      "Iter 16700 | Time 21.0884(21.6886) | Bit/dim 3.4884(3.5024) | Xent 0.0105(0.0038) | Loss 8.6683(9.1575) | Error 0.0033(0.0010) Steps 796(803.19) | Grad Norm 6.8095(1.8992) | Total Time 0.00(0.00)\n",
      "Iter 16710 | Time 23.1266(21.8731) | Bit/dim 3.5197(3.5014) | Xent 0.0032(0.0041) | Loss 8.8508(9.0596) | Error 0.0011(0.0010) Steps 784(802.85) | Grad Norm 2.5620(2.1704) | Total Time 0.00(0.00)\n",
      "Iter 16720 | Time 22.8299(21.8739) | Bit/dim 3.4768(3.5011) | Xent 0.0013(0.0039) | Loss 8.7067(8.9798) | Error 0.0000(0.0010) Steps 760(798.30) | Grad Norm 1.0312(2.0595) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0304 | Time 100.5465, Epoch Time 1324.2377(1300.7963), Bit/dim 3.5346(best: 3.5322), Xent 2.6407, Loss 4.8550, Error 0.3335(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16730 | Time 21.9198(21.9398) | Bit/dim 3.5197(3.5013) | Xent 0.0033(0.0038) | Loss 8.8367(9.6335) | Error 0.0011(0.0009) Steps 808(799.82) | Grad Norm 1.5970(1.9747) | Total Time 0.00(0.00)\n",
      "Iter 16740 | Time 21.6544(21.7954) | Bit/dim 3.5237(3.5014) | Xent 0.0020(0.0035) | Loss 8.7093(9.4012) | Error 0.0011(0.0009) Steps 778(800.02) | Grad Norm 2.1920(1.8715) | Total Time 0.00(0.00)\n",
      "Iter 16750 | Time 23.0959(21.9474) | Bit/dim 3.4761(3.5018) | Xent 0.0039(0.0042) | Loss 8.8007(9.2373) | Error 0.0011(0.0011) Steps 814(801.57) | Grad Norm 3.4521(2.1756) | Total Time 0.00(0.00)\n",
      "Iter 16760 | Time 21.7645(21.9338) | Bit/dim 3.4869(3.5006) | Xent 0.0157(0.0049) | Loss 8.6303(9.1135) | Error 0.0056(0.0013) Steps 796(804.54) | Grad Norm 5.9120(2.4526) | Total Time 0.00(0.00)\n",
      "Iter 16770 | Time 22.3412(21.9433) | Bit/dim 3.5086(3.5003) | Xent 0.0015(0.0051) | Loss 8.8227(9.0178) | Error 0.0000(0.0014) Steps 808(806.93) | Grad Norm 1.2286(2.5077) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0305 | Time 101.0880, Epoch Time 1331.8571(1301.7282), Bit/dim 3.5355(best: 3.5322), Xent 2.5813, Loss 4.8261, Error 0.3264(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16780 | Time 22.8027(21.9653) | Bit/dim 3.5203(3.5041) | Xent 0.0012(0.0043) | Loss 8.7412(9.7328) | Error 0.0000(0.0012) Steps 802(806.18) | Grad Norm 1.3725(2.2199) | Total Time 0.00(0.00)\n",
      "Iter 16790 | Time 21.8572(21.9349) | Bit/dim 3.4685(3.5026) | Xent 0.0104(0.0044) | Loss 8.7943(9.4849) | Error 0.0033(0.0012) Steps 808(804.10) | Grad Norm 2.9781(2.0630) | Total Time 0.00(0.00)\n",
      "Iter 16800 | Time 21.1845(21.8935) | Bit/dim 3.5095(3.5026) | Xent 0.0061(0.0044) | Loss 8.7368(9.3029) | Error 0.0011(0.0012) Steps 832(805.44) | Grad Norm 1.5229(2.0064) | Total Time 0.00(0.00)\n",
      "Iter 16810 | Time 22.2507(21.9516) | Bit/dim 3.4927(3.5038) | Xent 0.0036(0.0041) | Loss 8.7056(9.1699) | Error 0.0011(0.0012) Steps 814(806.48) | Grad Norm 1.8815(2.0000) | Total Time 0.00(0.00)\n",
      "Iter 16820 | Time 22.2474(21.9693) | Bit/dim 3.5258(3.5029) | Xent 0.0011(0.0043) | Loss 8.8529(9.0579) | Error 0.0000(0.0013) Steps 832(809.04) | Grad Norm 0.8758(2.0118) | Total Time 0.00(0.00)\n",
      "Iter 16830 | Time 22.1588(22.0889) | Bit/dim 3.4862(3.5015) | Xent 0.0009(0.0046) | Loss 8.7703(8.9785) | Error 0.0000(0.0012) Steps 808(807.49) | Grad Norm 1.1167(1.9988) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0306 | Time 101.1962, Epoch Time 1332.5136(1302.6517), Bit/dim 3.5339(best: 3.5322), Xent 2.5741, Loss 4.8210, Error 0.3252(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16840 | Time 22.2027(21.9381) | Bit/dim 3.5079(3.5012) | Xent 0.0009(0.0040) | Loss 8.8032(9.6040) | Error 0.0000(0.0010) Steps 826(806.92) | Grad Norm 0.7415(1.7997) | Total Time 0.00(0.00)\n",
      "Iter 16850 | Time 22.2968(21.9374) | Bit/dim 3.5140(3.5031) | Xent 0.0022(0.0038) | Loss 8.7539(9.3844) | Error 0.0000(0.0009) Steps 814(804.21) | Grad Norm 1.6039(1.7322) | Total Time 0.00(0.00)\n",
      "Iter 16860 | Time 21.1834(21.8708) | Bit/dim 3.5006(3.5021) | Xent 0.0007(0.0037) | Loss 8.7907(9.2224) | Error 0.0000(0.0009) Steps 820(802.55) | Grad Norm 0.8002(1.7804) | Total Time 0.00(0.00)\n",
      "Iter 16870 | Time 21.3551(21.8236) | Bit/dim 3.4920(3.5017) | Xent 0.0019(0.0041) | Loss 8.7088(9.0901) | Error 0.0000(0.0009) Steps 790(803.70) | Grad Norm 1.6787(1.8665) | Total Time 0.00(0.00)\n",
      "Iter 16880 | Time 23.1540(21.9219) | Bit/dim 3.4767(3.4993) | Xent 0.0023(0.0045) | Loss 8.7097(9.0082) | Error 0.0011(0.0011) Steps 832(805.67) | Grad Norm 1.3771(1.9432) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0307 | Time 101.6380, Epoch Time 1323.2162(1303.2687), Bit/dim 3.5336(best: 3.5322), Xent 2.5652, Loss 4.8162, Error 0.3303(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16890 | Time 21.8805(21.9474) | Bit/dim 3.4895(3.4989) | Xent 0.0020(0.0044) | Loss 8.7012(9.7385) | Error 0.0000(0.0011) Steps 772(806.74) | Grad Norm 2.3988(1.9889) | Total Time 0.00(0.00)\n",
      "Iter 16900 | Time 21.5180(21.8982) | Bit/dim 3.5152(3.5022) | Xent 0.0018(0.0051) | Loss 8.7045(9.4740) | Error 0.0000(0.0012) Steps 796(807.80) | Grad Norm 1.0347(1.9586) | Total Time 0.00(0.00)\n",
      "Iter 16910 | Time 22.7097(22.0034) | Bit/dim 3.4928(3.4992) | Xent 0.0008(0.0048) | Loss 8.8010(9.2851) | Error 0.0000(0.0011) Steps 850(807.48) | Grad Norm 1.0484(1.9078) | Total Time 0.00(0.00)\n",
      "Iter 16920 | Time 22.2668(22.0882) | Bit/dim 3.4870(3.5014) | Xent 0.0010(0.0041) | Loss 8.6839(9.1546) | Error 0.0000(0.0010) Steps 790(807.08) | Grad Norm 0.9647(1.7919) | Total Time 0.00(0.00)\n",
      "Iter 16930 | Time 21.8955(22.0312) | Bit/dim 3.5196(3.5023) | Xent 0.0039(0.0040) | Loss 8.8920(9.0563) | Error 0.0011(0.0010) Steps 814(807.73) | Grad Norm 2.3408(1.7671) | Total Time 0.00(0.00)\n",
      "Iter 16940 | Time 22.4168(22.0614) | Bit/dim 3.5073(3.5036) | Xent 0.0116(0.0040) | Loss 8.8069(8.9895) | Error 0.0022(0.0010) Steps 832(809.51) | Grad Norm 2.4235(1.7654) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0308 | Time 100.4207, Epoch Time 1335.1546(1304.2252), Bit/dim 3.5277(best: 3.5322), Xent 2.5913, Loss 4.8234, Error 0.3341(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 16950 | Time 21.7245(22.1024) | Bit/dim 3.5098(3.5030) | Xent 0.0008(0.0037) | Loss 8.7525(9.6285) | Error 0.0000(0.0009) Steps 796(808.88) | Grad Norm 0.7342(1.6036) | Total Time 0.00(0.00)\n",
      "Iter 16960 | Time 22.0770(22.0387) | Bit/dim 3.4688(3.5020) | Xent 0.0043(0.0036) | Loss 8.7291(9.3901) | Error 0.0011(0.0009) Steps 808(806.77) | Grad Norm 1.5926(1.6211) | Total Time 0.00(0.00)\n",
      "Iter 16970 | Time 21.6753(21.9329) | Bit/dim 3.4734(3.5002) | Xent 0.0006(0.0030) | Loss 8.6567(9.2088) | Error 0.0000(0.0008) Steps 826(804.98) | Grad Norm 1.1100(1.5622) | Total Time 0.00(0.00)\n",
      "Iter 16980 | Time 21.6899(21.9017) | Bit/dim 3.4715(3.5004) | Xent 0.0011(0.0030) | Loss 8.7909(9.0897) | Error 0.0000(0.0007) Steps 814(805.41) | Grad Norm 0.7923(1.5285) | Total Time 0.00(0.00)\n",
      "Iter 16990 | Time 20.8981(21.9326) | Bit/dim 3.5099(3.4973) | Xent 0.0007(0.0031) | Loss 8.8412(8.9961) | Error 0.0000(0.0008) Steps 796(807.85) | Grad Norm 0.7975(1.5247) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0309 | Time 101.0341, Epoch Time 1328.2888(1304.9471), Bit/dim 3.5313(best: 3.5277), Xent 2.5923, Loss 4.8275, Error 0.3336(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17000 | Time 23.0278(21.9153) | Bit/dim 3.5306(3.4996) | Xent 0.0009(0.0033) | Loss 8.8539(9.7033) | Error 0.0000(0.0009) Steps 838(808.92) | Grad Norm 1.0145(1.6431) | Total Time 0.00(0.00)\n",
      "Iter 17010 | Time 22.2787(21.9014) | Bit/dim 3.4827(3.5018) | Xent 0.0052(0.0040) | Loss 8.6911(9.4680) | Error 0.0011(0.0010) Steps 814(809.17) | Grad Norm 1.9218(1.8505) | Total Time 0.00(0.00)\n",
      "Iter 17020 | Time 22.2786(21.9318) | Bit/dim 3.4951(3.4996) | Xent 0.0040(0.0037) | Loss 8.8294(9.2785) | Error 0.0022(0.0011) Steps 814(809.18) | Grad Norm 2.8194(1.8679) | Total Time 0.00(0.00)\n",
      "Iter 17030 | Time 22.0206(21.8692) | Bit/dim 3.5120(3.5005) | Xent 0.0101(0.0040) | Loss 8.7321(9.1442) | Error 0.0022(0.0012) Steps 766(808.33) | Grad Norm 2.6178(2.0852) | Total Time 0.00(0.00)\n",
      "Iter 17040 | Time 23.2213(21.8576) | Bit/dim 3.5038(3.5041) | Xent 0.0063(0.0040) | Loss 8.8581(9.0441) | Error 0.0011(0.0013) Steps 844(806.75) | Grad Norm 2.4651(2.2058) | Total Time 0.00(0.00)\n",
      "Iter 17050 | Time 21.8326(21.8825) | Bit/dim 3.4848(3.5017) | Xent 0.0046(0.0042) | Loss 8.6939(8.9709) | Error 0.0022(0.0013) Steps 796(805.48) | Grad Norm 3.0631(2.2734) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0310 | Time 99.6018, Epoch Time 1323.2084(1305.4950), Bit/dim 3.5327(best: 3.5277), Xent 2.6352, Loss 4.8503, Error 0.3355(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17060 | Time 22.1998(21.9532) | Bit/dim 3.5047(3.5045) | Xent 0.0021(0.0043) | Loss 8.8122(9.6163) | Error 0.0000(0.0012) Steps 790(802.98) | Grad Norm 1.3040(2.2764) | Total Time 0.00(0.00)\n",
      "Iter 17070 | Time 21.1807(21.9336) | Bit/dim 3.5105(3.5050) | Xent 0.0024(0.0040) | Loss 8.7965(9.3924) | Error 0.0011(0.0011) Steps 820(806.00) | Grad Norm 1.8306(2.2573) | Total Time 0.00(0.00)\n",
      "Iter 17080 | Time 21.4004(21.9262) | Bit/dim 3.4806(3.5032) | Xent 0.0016(0.0035) | Loss 8.6549(9.2305) | Error 0.0000(0.0009) Steps 790(808.81) | Grad Norm 1.1802(2.0045) | Total Time 0.00(0.00)\n",
      "Iter 17090 | Time 21.0608(21.8800) | Bit/dim 3.5275(3.4993) | Xent 0.0012(0.0036) | Loss 8.8158(9.0976) | Error 0.0000(0.0010) Steps 802(807.07) | Grad Norm 0.7536(1.8529) | Total Time 0.00(0.00)\n",
      "Iter 17100 | Time 21.9768(21.8120) | Bit/dim 3.4971(3.4991) | Xent 0.0061(0.0042) | Loss 8.7445(9.0060) | Error 0.0011(0.0011) Steps 796(804.13) | Grad Norm 4.1075(2.0632) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0311 | Time 100.4989, Epoch Time 1324.8821(1306.0766), Bit/dim 3.5346(best: 3.5277), Xent 2.6292, Loss 4.8491, Error 0.3361(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17110 | Time 21.4869(21.7876) | Bit/dim 3.4861(3.5022) | Xent 0.0020(0.0041) | Loss 8.6722(9.7493) | Error 0.0000(0.0010) Steps 790(804.65) | Grad Norm 1.3388(2.0883) | Total Time 0.00(0.00)\n",
      "Iter 17120 | Time 22.2259(21.8175) | Bit/dim 3.5096(3.5005) | Xent 0.0026(0.0040) | Loss 8.7452(9.4769) | Error 0.0011(0.0009) Steps 844(806.48) | Grad Norm 2.2674(2.0105) | Total Time 0.00(0.00)\n",
      "Iter 17130 | Time 22.4095(21.8510) | Bit/dim 3.5144(3.4998) | Xent 0.0018(0.0037) | Loss 8.7133(9.2868) | Error 0.0000(0.0010) Steps 844(809.08) | Grad Norm 1.5995(1.9936) | Total Time 0.00(0.00)\n",
      "Iter 17140 | Time 21.0432(21.8789) | Bit/dim 3.4882(3.5025) | Xent 0.0007(0.0040) | Loss 8.7337(9.1528) | Error 0.0000(0.0010) Steps 808(810.06) | Grad Norm 0.6600(1.9483) | Total Time 0.00(0.00)\n",
      "Iter 17150 | Time 22.1728(21.8651) | Bit/dim 3.5081(3.5010) | Xent 0.0031(0.0035) | Loss 8.8734(9.0497) | Error 0.0011(0.0009) Steps 814(806.16) | Grad Norm 1.8859(1.7240) | Total Time 0.00(0.00)\n",
      "Iter 17160 | Time 21.0949(21.8652) | Bit/dim 3.4503(3.5008) | Xent 0.0040(0.0034) | Loss 8.6291(8.9756) | Error 0.0022(0.0009) Steps 820(806.68) | Grad Norm 2.3019(1.8481) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0312 | Time 100.7384, Epoch Time 1325.2798(1306.6527), Bit/dim 3.5316(best: 3.5277), Xent 2.6362, Loss 4.8497, Error 0.3343(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17170 | Time 21.6075(21.8531) | Bit/dim 3.5022(3.5005) | Xent 0.0058(0.0031) | Loss 8.5576(9.5909) | Error 0.0011(0.0008) Steps 784(803.08) | Grad Norm 1.8889(1.8352) | Total Time 0.00(0.00)\n",
      "Iter 17180 | Time 22.2683(21.8690) | Bit/dim 3.4875(3.5004) | Xent 0.0088(0.0037) | Loss 8.7541(9.3674) | Error 0.0033(0.0009) Steps 844(802.51) | Grad Norm 2.8870(1.7932) | Total Time 0.00(0.00)\n",
      "Iter 17190 | Time 21.9701(21.8084) | Bit/dim 3.4571(3.5004) | Xent 0.0049(0.0041) | Loss 8.6564(9.2110) | Error 0.0011(0.0010) Steps 808(802.79) | Grad Norm 2.0777(1.8303) | Total Time 0.00(0.00)\n",
      "Iter 17200 | Time 21.8068(21.8679) | Bit/dim 3.5046(3.5006) | Xent 0.0019(0.0039) | Loss 8.7838(9.0868) | Error 0.0000(0.0010) Steps 820(804.86) | Grad Norm 0.9483(1.8664) | Total Time 0.00(0.00)\n",
      "Iter 17210 | Time 20.7493(21.8128) | Bit/dim 3.5022(3.4996) | Xent 0.0019(0.0039) | Loss 8.7505(8.9923) | Error 0.0000(0.0010) Steps 802(803.27) | Grad Norm 1.7152(1.9293) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0313 | Time 100.6229, Epoch Time 1322.9989(1307.1431), Bit/dim 3.5307(best: 3.5277), Xent 2.6387, Loss 4.8500, Error 0.3347(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17220 | Time 21.7330(21.8709) | Bit/dim 3.4980(3.4996) | Xent 0.0012(0.0038) | Loss 8.6937(9.7544) | Error 0.0000(0.0010) Steps 784(800.91) | Grad Norm 1.5620(1.9991) | Total Time 0.00(0.00)\n",
      "Iter 17230 | Time 21.1919(21.9971) | Bit/dim 3.4652(3.5000) | Xent 0.0077(0.0035) | Loss 8.7092(9.4973) | Error 0.0022(0.0008) Steps 814(801.47) | Grad Norm 2.0792(1.8985) | Total Time 0.00(0.00)\n",
      "Iter 17240 | Time 21.4403(21.9613) | Bit/dim 3.5297(3.5022) | Xent 0.0008(0.0034) | Loss 8.7919(9.3000) | Error 0.0000(0.0009) Steps 790(801.15) | Grad Norm 1.1012(1.8433) | Total Time 0.00(0.00)\n",
      "Iter 17250 | Time 22.0897(22.0434) | Bit/dim 3.4874(3.5006) | Xent 0.0086(0.0033) | Loss 8.7196(9.1488) | Error 0.0022(0.0009) Steps 778(801.73) | Grad Norm 1.6854(1.7219) | Total Time 0.00(0.00)\n",
      "Iter 17260 | Time 21.9910(22.1088) | Bit/dim 3.4937(3.4993) | Xent 0.0015(0.0037) | Loss 8.8341(9.0564) | Error 0.0000(0.0010) Steps 784(804.55) | Grad Norm 1.2635(1.9076) | Total Time 0.00(0.00)\n",
      "Iter 17270 | Time 21.1786(22.0282) | Bit/dim 3.5116(3.5000) | Xent 0.0151(0.0046) | Loss 8.7061(8.9724) | Error 0.0033(0.0013) Steps 766(801.42) | Grad Norm 4.7174(2.1726) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0314 | Time 100.8025, Epoch Time 1337.8214(1308.0634), Bit/dim 3.5329(best: 3.5277), Xent 2.6399, Loss 4.8529, Error 0.3354(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17280 | Time 21.7842(21.9777) | Bit/dim 3.4959(3.5002) | Xent 0.0015(0.0050) | Loss 8.7533(9.6052) | Error 0.0000(0.0013) Steps 802(800.63) | Grad Norm 1.6206(2.2883) | Total Time 0.00(0.00)\n",
      "Iter 17290 | Time 21.7208(21.9360) | Bit/dim 3.5164(3.5012) | Xent 0.0038(0.0049) | Loss 8.7635(9.3941) | Error 0.0022(0.0014) Steps 826(803.52) | Grad Norm 3.2986(2.2717) | Total Time 0.00(0.00)\n",
      "Iter 17300 | Time 22.5037(21.9427) | Bit/dim 3.5040(3.5014) | Xent 0.0023(0.0050) | Loss 8.7465(9.2267) | Error 0.0000(0.0013) Steps 832(803.64) | Grad Norm 1.4095(2.2247) | Total Time 0.00(0.00)\n",
      "Iter 17310 | Time 21.8187(21.9602) | Bit/dim 3.4708(3.5003) | Xent 0.0019(0.0055) | Loss 8.7081(9.1036) | Error 0.0000(0.0013) Steps 802(806.55) | Grad Norm 2.3514(2.2395) | Total Time 0.00(0.00)\n",
      "Iter 17320 | Time 22.1308(21.9877) | Bit/dim 3.5128(3.5023) | Xent 0.0019(0.0049) | Loss 8.8585(9.0265) | Error 0.0000(0.0012) Steps 802(808.33) | Grad Norm 1.4963(2.2093) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0315 | Time 100.2249, Epoch Time 1329.3308(1308.7014), Bit/dim 3.5328(best: 3.5277), Xent 2.6117, Loss 4.8386, Error 0.3360(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17330 | Time 22.6242(21.9877) | Bit/dim 3.5343(3.5005) | Xent 0.0011(0.0050) | Loss 8.8457(9.7511) | Error 0.0000(0.0013) Steps 790(808.75) | Grad Norm 2.2342(2.4866) | Total Time 0.00(0.00)\n",
      "Iter 17340 | Time 22.4132(21.9389) | Bit/dim 3.4739(3.5014) | Xent 0.0098(0.0050) | Loss 8.7310(9.4884) | Error 0.0022(0.0013) Steps 802(806.64) | Grad Norm 2.3932(2.3827) | Total Time 0.00(0.00)\n",
      "Iter 17350 | Time 21.7943(21.9461) | Bit/dim 3.4799(3.5010) | Xent 0.0024(0.0044) | Loss 8.7977(9.2925) | Error 0.0011(0.0011) Steps 784(805.41) | Grad Norm 2.9027(2.3483) | Total Time 0.00(0.00)\n",
      "Iter 17360 | Time 21.8786(21.9713) | Bit/dim 3.4698(3.5002) | Xent 0.0022(0.0041) | Loss 8.6525(9.1484) | Error 0.0011(0.0010) Steps 826(806.52) | Grad Norm 1.2052(2.2410) | Total Time 0.00(0.00)\n",
      "Iter 17370 | Time 21.3676(21.9248) | Bit/dim 3.4794(3.4993) | Xent 0.0018(0.0038) | Loss 8.6390(9.0485) | Error 0.0011(0.0010) Steps 796(807.04) | Grad Norm 1.7620(2.1570) | Total Time 0.00(0.00)\n",
      "Iter 17380 | Time 21.8997(21.8409) | Bit/dim 3.4729(3.4975) | Xent 0.0007(0.0036) | Loss 8.6330(8.9607) | Error 0.0000(0.0011) Steps 826(804.94) | Grad Norm 0.8377(2.1411) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0316 | Time 101.3275, Epoch Time 1323.8201(1309.1550), Bit/dim 3.5309(best: 3.5277), Xent 2.6556, Loss 4.8588, Error 0.3338(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17390 | Time 22.1489(21.9056) | Bit/dim 3.4780(3.4981) | Xent 0.0008(0.0033) | Loss 8.8518(9.6066) | Error 0.0000(0.0010) Steps 814(805.92) | Grad Norm 1.0017(2.0621) | Total Time 0.00(0.00)\n",
      "Iter 17400 | Time 21.8085(21.8798) | Bit/dim 3.5507(3.4973) | Xent 0.0007(0.0030) | Loss 8.8375(9.3843) | Error 0.0000(0.0008) Steps 808(805.60) | Grad Norm 0.7723(1.8638) | Total Time 0.00(0.00)\n",
      "Iter 17410 | Time 22.7743(21.9179) | Bit/dim 3.4955(3.4990) | Xent 0.0042(0.0028) | Loss 8.8686(9.2262) | Error 0.0022(0.0008) Steps 844(805.53) | Grad Norm 4.4666(1.9132) | Total Time 0.00(0.00)\n",
      "Iter 17420 | Time 21.4657(21.9489) | Bit/dim 3.4842(3.4969) | Xent 0.0035(0.0033) | Loss 8.7207(9.1013) | Error 0.0022(0.0010) Steps 790(807.63) | Grad Norm 2.9016(2.2460) | Total Time 0.00(0.00)\n",
      "Iter 17430 | Time 22.2198(21.9245) | Bit/dim 3.5103(3.5020) | Xent 0.0017(0.0038) | Loss 8.8720(9.0193) | Error 0.0000(0.0011) Steps 838(806.39) | Grad Norm 1.2086(2.3655) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0317 | Time 101.4572, Epoch Time 1330.2388(1309.7875), Bit/dim 3.5290(best: 3.5277), Xent 2.6420, Loss 4.8500, Error 0.3338(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17440 | Time 21.4749(21.9256) | Bit/dim 3.5306(3.5029) | Xent 0.0013(0.0037) | Loss 8.9042(9.7403) | Error 0.0000(0.0010) Steps 814(805.32) | Grad Norm 1.1175(2.3937) | Total Time 0.00(0.00)\n",
      "Iter 17450 | Time 22.0696(21.8454) | Bit/dim 3.4857(3.5015) | Xent 0.0077(0.0037) | Loss 8.7429(9.4723) | Error 0.0022(0.0010) Steps 802(805.58) | Grad Norm 1.8425(2.2661) | Total Time 0.00(0.00)\n",
      "Iter 17460 | Time 21.4286(21.8588) | Bit/dim 3.5134(3.5011) | Xent 0.0106(0.0037) | Loss 8.7564(9.2809) | Error 0.0011(0.0010) Steps 814(806.57) | Grad Norm 2.4399(2.1855) | Total Time 0.00(0.00)\n",
      "Iter 17470 | Time 21.6224(21.8240) | Bit/dim 3.4903(3.5040) | Xent 0.0033(0.0037) | Loss 8.7086(9.1372) | Error 0.0011(0.0010) Steps 826(807.80) | Grad Norm 1.4828(2.1080) | Total Time 0.00(0.00)\n",
      "Iter 17480 | Time 21.3541(21.7734) | Bit/dim 3.5148(3.5019) | Xent 0.0012(0.0038) | Loss 8.8187(9.0291) | Error 0.0000(0.0010) Steps 826(809.28) | Grad Norm 1.3266(2.0087) | Total Time 0.00(0.00)\n",
      "Iter 17490 | Time 22.0848(21.8470) | Bit/dim 3.5013(3.4994) | Xent 0.0036(0.0039) | Loss 8.8484(8.9576) | Error 0.0022(0.0011) Steps 838(810.98) | Grad Norm 2.2234(2.0361) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0318 | Time 99.2746, Epoch Time 1318.9577(1310.0626), Bit/dim 3.5318(best: 3.5277), Xent 2.6687, Loss 4.8662, Error 0.3395(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17500 | Time 21.6209(21.8552) | Bit/dim 3.4715(3.4982) | Xent 0.0061(0.0043) | Loss 8.6935(9.5722) | Error 0.0011(0.0012) Steps 790(810.32) | Grad Norm 1.3925(2.1423) | Total Time 0.00(0.00)\n",
      "Iter 17510 | Time 22.7800(21.9463) | Bit/dim 3.5177(3.4996) | Xent 0.0108(0.0047) | Loss 8.6938(9.3584) | Error 0.0022(0.0012) Steps 838(810.78) | Grad Norm 3.1943(2.1979) | Total Time 0.00(0.00)\n",
      "Iter 17520 | Time 21.6469(21.9590) | Bit/dim 3.4927(3.4973) | Xent 0.0135(0.0047) | Loss 8.8108(9.1931) | Error 0.0044(0.0012) Steps 808(809.52) | Grad Norm 4.9498(2.2183) | Total Time 0.00(0.00)\n",
      "Iter 17530 | Time 21.6810(21.9543) | Bit/dim 3.5117(3.5001) | Xent 0.0039(0.0046) | Loss 8.7496(9.0773) | Error 0.0011(0.0012) Steps 796(808.02) | Grad Norm 1.7641(2.1843) | Total Time 0.00(0.00)\n",
      "Iter 17540 | Time 22.3734(21.9365) | Bit/dim 3.4918(3.5019) | Xent 0.0033(0.0046) | Loss 8.8642(9.0014) | Error 0.0011(0.0012) Steps 808(809.11) | Grad Norm 1.8629(2.1055) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0319 | Time 100.2417, Epoch Time 1330.4492(1310.6742), Bit/dim 3.5301(best: 3.5277), Xent 2.6418, Loss 4.8510, Error 0.3358(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17550 | Time 21.5016(21.8956) | Bit/dim 3.5323(3.5044) | Xent 0.0016(0.0044) | Loss 8.7857(9.7102) | Error 0.0011(0.0011) Steps 784(807.93) | Grad Norm 1.3208(1.9938) | Total Time 0.00(0.00)\n",
      "Iter 17560 | Time 21.7299(21.9469) | Bit/dim 3.4933(3.5007) | Xent 0.0056(0.0040) | Loss 8.7591(9.4589) | Error 0.0011(0.0011) Steps 796(807.75) | Grad Norm 1.9061(1.8815) | Total Time 0.00(0.00)\n",
      "Iter 17570 | Time 21.3823(21.8859) | Bit/dim 3.5193(3.5007) | Xent 0.0022(0.0034) | Loss 8.7838(9.2755) | Error 0.0011(0.0010) Steps 778(806.20) | Grad Norm 3.0135(1.9237) | Total Time 0.00(0.00)\n",
      "Iter 17580 | Time 21.4853(21.8453) | Bit/dim 3.5049(3.5011) | Xent 0.0053(0.0038) | Loss 8.7975(9.1354) | Error 0.0011(0.0011) Steps 826(806.03) | Grad Norm 2.5515(2.1361) | Total Time 0.00(0.00)\n",
      "Iter 17590 | Time 21.5884(21.8041) | Bit/dim 3.4909(3.4992) | Xent 0.0005(0.0035) | Loss 8.6962(9.0274) | Error 0.0000(0.0010) Steps 802(807.06) | Grad Norm 0.7490(1.9859) | Total Time 0.00(0.00)\n",
      "Iter 17600 | Time 21.8319(21.7940) | Bit/dim 3.5016(3.4994) | Xent 0.0012(0.0036) | Loss 8.8747(8.9603) | Error 0.0000(0.0010) Steps 814(806.57) | Grad Norm 1.2552(1.9625) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0320 | Time 99.1542, Epoch Time 1318.5623(1310.9109), Bit/dim 3.5281(best: 3.5277), Xent 2.6266, Loss 4.8414, Error 0.3281(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17610 | Time 21.9027(21.7807) | Bit/dim 3.5276(3.5030) | Xent 0.0020(0.0038) | Loss 8.7875(9.6132) | Error 0.0000(0.0009) Steps 784(807.26) | Grad Norm 1.7483(1.8477) | Total Time 0.00(0.00)\n",
      "Iter 17620 | Time 22.5894(21.8397) | Bit/dim 3.5209(3.5023) | Xent 0.0014(0.0039) | Loss 8.7770(9.3914) | Error 0.0000(0.0010) Steps 766(807.21) | Grad Norm 0.9846(1.7978) | Total Time 0.00(0.00)\n",
      "Iter 17630 | Time 21.6197(21.7637) | Bit/dim 3.5264(3.5020) | Xent 0.0013(0.0037) | Loss 8.8372(9.2318) | Error 0.0000(0.0009) Steps 790(807.46) | Grad Norm 1.3876(1.9166) | Total Time 0.00(0.00)\n",
      "Iter 17640 | Time 21.9452(21.8763) | Bit/dim 3.4107(3.4968) | Xent 0.0009(0.0037) | Loss 8.6070(9.0967) | Error 0.0000(0.0009) Steps 796(808.60) | Grad Norm 0.7051(1.8393) | Total Time 0.00(0.00)\n",
      "Iter 17650 | Time 22.5051(21.9085) | Bit/dim 3.5062(3.4985) | Xent 0.0016(0.0031) | Loss 8.7205(9.0007) | Error 0.0011(0.0008) Steps 796(807.46) | Grad Norm 1.2611(1.6207) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0321 | Time 100.5661, Epoch Time 1329.3097(1311.4628), Bit/dim 3.5295(best: 3.5277), Xent 2.6335, Loss 4.8462, Error 0.3329(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17660 | Time 22.7913(21.9679) | Bit/dim 3.5054(3.4993) | Xent 0.0093(0.0033) | Loss 8.7316(9.7291) | Error 0.0033(0.0008) Steps 772(805.00) | Grad Norm 5.0597(1.7467) | Total Time 0.00(0.00)\n",
      "Iter 17670 | Time 21.5152(21.9189) | Bit/dim 3.4994(3.5009) | Xent 0.0007(0.0031) | Loss 8.8083(9.4839) | Error 0.0000(0.0007) Steps 802(803.80) | Grad Norm 1.9963(1.8287) | Total Time 0.00(0.00)\n",
      "Iter 17680 | Time 22.0069(21.8356) | Bit/dim 3.4887(3.4985) | Xent 0.0026(0.0032) | Loss 8.6855(9.2881) | Error 0.0011(0.0008) Steps 802(805.08) | Grad Norm 1.6288(1.8157) | Total Time 0.00(0.00)\n",
      "Iter 17690 | Time 21.2104(21.7643) | Bit/dim 3.5128(3.4993) | Xent 0.0010(0.0034) | Loss 8.6802(9.1460) | Error 0.0000(0.0008) Steps 814(803.95) | Grad Norm 0.9598(1.7812) | Total Time 0.00(0.00)\n",
      "Iter 17700 | Time 22.0552(21.8437) | Bit/dim 3.4869(3.4965) | Xent 0.0013(0.0032) | Loss 8.7829(9.0385) | Error 0.0000(0.0007) Steps 784(803.22) | Grad Norm 0.9536(1.6474) | Total Time 0.00(0.00)\n",
      "Iter 17710 | Time 22.9837(21.8202) | Bit/dim 3.4936(3.4981) | Xent 0.0041(0.0032) | Loss 8.7526(8.9661) | Error 0.0022(0.0008) Steps 808(801.38) | Grad Norm 2.3362(1.6913) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0322 | Time 99.4656, Epoch Time 1320.8251(1311.7437), Bit/dim 3.5301(best: 3.5277), Xent 2.6651, Loss 4.8626, Error 0.3351(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17720 | Time 22.5451(21.8195) | Bit/dim 3.4694(3.4996) | Xent 0.0108(0.0031) | Loss 8.5566(9.5878) | Error 0.0044(0.0008) Steps 850(801.85) | Grad Norm 4.2765(1.7336) | Total Time 0.00(0.00)\n",
      "Iter 17730 | Time 22.4105(21.8551) | Bit/dim 3.4936(3.4968) | Xent 0.0007(0.0036) | Loss 8.7062(9.3602) | Error 0.0000(0.0009) Steps 790(802.59) | Grad Norm 0.9955(1.7299) | Total Time 0.00(0.00)\n",
      "Iter 17740 | Time 21.3456(21.8233) | Bit/dim 3.5039(3.4988) | Xent 0.0010(0.0033) | Loss 8.6671(9.1995) | Error 0.0000(0.0009) Steps 784(805.29) | Grad Norm 1.2495(1.8359) | Total Time 0.00(0.00)\n",
      "Iter 17750 | Time 21.5996(21.7950) | Bit/dim 3.5060(3.5010) | Xent 0.0030(0.0039) | Loss 8.6108(9.0831) | Error 0.0022(0.0009) Steps 784(805.77) | Grad Norm 1.8756(1.8254) | Total Time 0.00(0.00)\n",
      "Iter 17760 | Time 22.6728(21.7767) | Bit/dim 3.4815(3.5003) | Xent 0.0031(0.0036) | Loss 8.7619(8.9965) | Error 0.0000(0.0008) Steps 808(803.37) | Grad Norm 1.7833(1.7691) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0323 | Time 101.6467, Epoch Time 1322.0664(1312.0534), Bit/dim 3.5306(best: 3.5277), Xent 2.6649, Loss 4.8630, Error 0.3313(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17770 | Time 22.4065(21.8546) | Bit/dim 3.4560(3.4970) | Xent 0.0015(0.0041) | Loss 8.7253(9.7184) | Error 0.0000(0.0010) Steps 838(803.28) | Grad Norm 1.2263(1.9774) | Total Time 0.00(0.00)\n",
      "Iter 17780 | Time 22.2925(21.8774) | Bit/dim 3.4926(3.4952) | Xent 0.0088(0.0039) | Loss 8.8958(9.4595) | Error 0.0022(0.0010) Steps 814(803.86) | Grad Norm 1.9222(1.9412) | Total Time 0.00(0.00)\n",
      "Iter 17790 | Time 22.2517(21.8131) | Bit/dim 3.4857(3.4960) | Xent 0.0013(0.0035) | Loss 8.7440(9.2700) | Error 0.0000(0.0009) Steps 814(804.15) | Grad Norm 1.1247(1.8364) | Total Time 0.00(0.00)\n",
      "Iter 17800 | Time 21.7091(21.7939) | Bit/dim 3.5347(3.4980) | Xent 0.0042(0.0034) | Loss 8.8544(9.1384) | Error 0.0011(0.0009) Steps 832(806.89) | Grad Norm 2.5688(1.8307) | Total Time 0.00(0.00)\n",
      "Iter 17810 | Time 21.9303(21.8341) | Bit/dim 3.4739(3.5006) | Xent 0.0009(0.0032) | Loss 8.7374(9.0394) | Error 0.0000(0.0008) Steps 802(807.85) | Grad Norm 0.7085(1.6843) | Total Time 0.00(0.00)\n",
      "Iter 17820 | Time 20.9740(21.7903) | Bit/dim 3.4945(3.5018) | Xent 0.0018(0.0029) | Loss 8.6284(8.9632) | Error 0.0011(0.0007) Steps 796(805.58) | Grad Norm 1.3342(1.5895) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0324 | Time 100.3652, Epoch Time 1321.9172(1312.3493), Bit/dim 3.5262(best: 3.5277), Xent 2.6651, Loss 4.8587, Error 0.3351(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17830 | Time 22.3346(21.8071) | Bit/dim 3.5147(3.5015) | Xent 0.0011(0.0027) | Loss 8.7524(9.5813) | Error 0.0000(0.0007) Steps 826(804.87) | Grad Norm 0.9327(1.5629) | Total Time 0.00(0.00)\n",
      "Iter 17840 | Time 21.0738(21.8219) | Bit/dim 3.5088(3.5013) | Xent 0.0083(0.0031) | Loss 8.6514(9.3628) | Error 0.0033(0.0009) Steps 790(803.99) | Grad Norm 2.6790(1.7720) | Total Time 0.00(0.00)\n",
      "Iter 17850 | Time 20.6325(21.7878) | Bit/dim 3.4962(3.4995) | Xent 0.0014(0.0035) | Loss 8.6239(9.1848) | Error 0.0000(0.0010) Steps 790(803.70) | Grad Norm 1.4305(1.7977) | Total Time 0.00(0.00)\n",
      "Iter 17860 | Time 22.4691(21.9294) | Bit/dim 3.5112(3.4991) | Xent 0.0079(0.0039) | Loss 8.8100(9.0688) | Error 0.0033(0.0011) Steps 838(806.56) | Grad Norm 4.1205(2.0027) | Total Time 0.00(0.00)\n",
      "Iter 17870 | Time 21.4234(21.9341) | Bit/dim 3.5196(3.5003) | Xent 0.0032(0.0038) | Loss 8.6292(8.9813) | Error 0.0011(0.0011) Steps 790(806.91) | Grad Norm 1.8929(2.0869) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0325 | Time 101.3394, Epoch Time 1330.1232(1312.8825), Bit/dim 3.5285(best: 3.5262), Xent 2.6799, Loss 4.8684, Error 0.3304(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17880 | Time 22.0345(21.9479) | Bit/dim 3.4890(3.5022) | Xent 0.0020(0.0032) | Loss 8.7226(9.7511) | Error 0.0000(0.0009) Steps 814(807.54) | Grad Norm 1.5424(2.0179) | Total Time 0.00(0.00)\n",
      "Iter 17890 | Time 21.9799(21.9315) | Bit/dim 3.4713(3.4995) | Xent 0.0011(0.0032) | Loss 8.7865(9.4886) | Error 0.0000(0.0010) Steps 796(805.89) | Grad Norm 1.5433(1.9787) | Total Time 0.00(0.00)\n",
      "Iter 17900 | Time 22.1196(21.9617) | Bit/dim 3.4933(3.4979) | Xent 0.0011(0.0028) | Loss 8.7065(9.2894) | Error 0.0000(0.0008) Steps 808(806.11) | Grad Norm 1.1407(1.8084) | Total Time 0.00(0.00)\n",
      "Iter 17910 | Time 22.2033(21.9177) | Bit/dim 3.4948(3.4978) | Xent 0.0012(0.0029) | Loss 8.7728(9.1581) | Error 0.0000(0.0008) Steps 808(806.64) | Grad Norm 1.2787(1.8143) | Total Time 0.00(0.00)\n",
      "Iter 17920 | Time 21.7601(21.9232) | Bit/dim 3.5118(3.5007) | Xent 0.0006(0.0026) | Loss 8.7104(9.0491) | Error 0.0000(0.0007) Steps 826(806.15) | Grad Norm 0.6203(1.6792) | Total Time 0.00(0.00)\n",
      "Iter 17930 | Time 21.4364(21.8742) | Bit/dim 3.4896(3.4998) | Xent 0.0006(0.0023) | Loss 8.6700(8.9513) | Error 0.0000(0.0006) Steps 796(804.49) | Grad Norm 0.7914(1.5668) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0326 | Time 101.3439, Epoch Time 1325.5440(1313.2624), Bit/dim 3.5284(best: 3.5262), Xent 2.7279, Loss 4.8923, Error 0.3381(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17940 | Time 22.3054(21.9549) | Bit/dim 3.5052(3.4978) | Xent 0.0025(0.0029) | Loss 8.6095(9.5639) | Error 0.0011(0.0008) Steps 832(806.96) | Grad Norm 3.4396(1.6474) | Total Time 0.00(0.00)\n",
      "Iter 17950 | Time 21.2189(22.0189) | Bit/dim 3.5180(3.4970) | Xent 0.0044(0.0032) | Loss 8.7950(9.3495) | Error 0.0022(0.0009) Steps 808(808.53) | Grad Norm 3.4893(1.8989) | Total Time 0.00(0.00)\n",
      "Iter 17960 | Time 21.4198(22.0575) | Bit/dim 3.4988(3.5000) | Xent 0.0008(0.0035) | Loss 8.7208(9.1968) | Error 0.0000(0.0009) Steps 802(809.99) | Grad Norm 1.2129(2.0302) | Total Time 0.00(0.00)\n",
      "Iter 17970 | Time 23.6258(22.1492) | Bit/dim 3.4889(3.4991) | Xent 0.0052(0.0039) | Loss 8.7024(9.0767) | Error 0.0022(0.0011) Steps 760(806.55) | Grad Norm 2.5057(2.1529) | Total Time 0.00(0.00)\n",
      "Iter 17980 | Time 21.3170(22.1158) | Bit/dim 3.4660(3.5003) | Xent 0.0049(0.0040) | Loss 8.6079(8.9848) | Error 0.0011(0.0010) Steps 808(807.13) | Grad Norm 3.9005(2.1191) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0327 | Time 102.1744, Epoch Time 1345.9697(1314.2436), Bit/dim 3.5299(best: 3.5262), Xent 2.6668, Loss 4.8633, Error 0.3306(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 17990 | Time 21.8419(22.1365) | Bit/dim 3.4734(3.4994) | Xent 0.0016(0.0042) | Loss 8.5489(9.7358) | Error 0.0000(0.0011) Steps 790(806.43) | Grad Norm 2.2773(2.3539) | Total Time 0.00(0.00)\n",
      "Iter 18000 | Time 21.1636(22.0756) | Bit/dim 3.4719(3.4985) | Xent 0.0083(0.0051) | Loss 8.6890(9.4751) | Error 0.0033(0.0015) Steps 808(806.04) | Grad Norm 3.4790(2.6821) | Total Time 0.00(0.00)\n",
      "Iter 18010 | Time 21.9011(22.0695) | Bit/dim 3.4941(3.5018) | Xent 0.0061(0.0050) | Loss 8.8051(9.2974) | Error 0.0022(0.0014) Steps 844(808.55) | Grad Norm 3.5875(2.9253) | Total Time 0.00(0.00)\n",
      "Iter 18020 | Time 21.4609(21.9194) | Bit/dim 3.5199(3.4995) | Xent 0.0060(0.0049) | Loss 8.8531(9.1539) | Error 0.0022(0.0015) Steps 808(806.52) | Grad Norm 2.5824(3.0372) | Total Time 0.00(0.00)\n",
      "Iter 18030 | Time 21.9337(21.9753) | Bit/dim 3.5031(3.5003) | Xent 0.0010(0.0045) | Loss 8.7092(9.0513) | Error 0.0000(0.0013) Steps 772(807.51) | Grad Norm 1.4486(2.7970) | Total Time 0.00(0.00)\n",
      "Iter 18040 | Time 21.4856(21.9718) | Bit/dim 3.4944(3.5007) | Xent 0.0007(0.0041) | Loss 8.6776(8.9652) | Error 0.0000(0.0012) Steps 802(805.47) | Grad Norm 0.9474(2.4422) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0328 | Time 101.1035, Epoch Time 1330.5600(1314.7331), Bit/dim 3.5294(best: 3.5262), Xent 2.6876, Loss 4.8731, Error 0.3305(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18050 | Time 22.0033(21.9998) | Bit/dim 3.4881(3.5004) | Xent 0.0029(0.0042) | Loss 8.6692(9.6147) | Error 0.0011(0.0012) Steps 790(807.71) | Grad Norm 2.3362(2.3708) | Total Time 0.00(0.00)\n",
      "Iter 18060 | Time 21.5241(21.9607) | Bit/dim 3.4867(3.4989) | Xent 0.0048(0.0039) | Loss 8.6524(9.3877) | Error 0.0011(0.0011) Steps 808(808.80) | Grad Norm 0.9878(2.2470) | Total Time 0.00(0.00)\n",
      "Iter 18070 | Time 21.9286(21.9302) | Bit/dim 3.5102(3.4990) | Xent 0.0013(0.0038) | Loss 8.7176(9.2149) | Error 0.0000(0.0010) Steps 820(806.60) | Grad Norm 1.1644(2.0670) | Total Time 0.00(0.00)\n",
      "Iter 18080 | Time 22.2142(22.0050) | Bit/dim 3.4924(3.4980) | Xent 0.0013(0.0037) | Loss 8.7666(9.0848) | Error 0.0000(0.0009) Steps 802(809.85) | Grad Norm 1.5803(1.9849) | Total Time 0.00(0.00)\n",
      "Iter 18090 | Time 22.7656(21.9517) | Bit/dim 3.4663(3.4968) | Xent 0.0011(0.0033) | Loss 8.6678(8.9959) | Error 0.0000(0.0008) Steps 778(806.09) | Grad Norm 1.2684(1.8058) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0329 | Time 100.4953, Epoch Time 1331.3247(1315.2308), Bit/dim 3.5279(best: 3.5262), Xent 2.7066, Loss 4.8812, Error 0.3356(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18100 | Time 22.0866(22.0356) | Bit/dim 3.5256(3.4981) | Xent 0.0007(0.0029) | Loss 8.7406(9.7314) | Error 0.0000(0.0007) Steps 814(808.22) | Grad Norm 1.1594(1.7541) | Total Time 0.00(0.00)\n",
      "Iter 18110 | Time 22.0615(22.0315) | Bit/dim 3.4824(3.4964) | Xent 0.0007(0.0027) | Loss 8.5561(9.4648) | Error 0.0000(0.0006) Steps 802(806.95) | Grad Norm 0.7491(1.7285) | Total Time 0.00(0.00)\n",
      "Iter 18120 | Time 22.0700(22.0206) | Bit/dim 3.5065(3.4969) | Xent 0.0029(0.0024) | Loss 8.8416(9.2781) | Error 0.0011(0.0006) Steps 808(807.12) | Grad Norm 2.1140(1.5994) | Total Time 0.00(0.00)\n",
      "Iter 18130 | Time 23.1537(22.0529) | Bit/dim 3.5259(3.4981) | Xent 0.0042(0.0024) | Loss 8.8450(9.1526) | Error 0.0011(0.0005) Steps 838(807.52) | Grad Norm 1.6462(1.6757) | Total Time 0.00(0.00)\n",
      "Iter 18140 | Time 21.7528(22.0151) | Bit/dim 3.5174(3.4980) | Xent 0.0006(0.0026) | Loss 8.7412(9.0496) | Error 0.0000(0.0007) Steps 796(805.92) | Grad Norm 0.8008(1.8102) | Total Time 0.00(0.00)\n",
      "Iter 18150 | Time 22.7129(22.1128) | Bit/dim 3.4653(3.4967) | Xent 0.0098(0.0031) | Loss 8.7356(8.9741) | Error 0.0022(0.0009) Steps 796(807.64) | Grad Norm 2.2713(1.8526) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0330 | Time 101.7850, Epoch Time 1343.1547(1316.0685), Bit/dim 3.5297(best: 3.5262), Xent 2.7231, Loss 4.8912, Error 0.3324(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18160 | Time 21.4398(22.0897) | Bit/dim 3.4967(3.4991) | Xent 0.0037(0.0038) | Loss 8.7723(9.5976) | Error 0.0022(0.0011) Steps 820(806.38) | Grad Norm 1.4145(1.9557) | Total Time 0.00(0.00)\n",
      "Iter 18170 | Time 22.6822(22.0770) | Bit/dim 3.4966(3.4949) | Xent 0.0007(0.0037) | Loss 8.8051(9.3670) | Error 0.0000(0.0010) Steps 814(806.16) | Grad Norm 1.2528(1.9950) | Total Time 0.00(0.00)\n",
      "Iter 18180 | Time 21.5589(22.0629) | Bit/dim 3.4765(3.4979) | Xent 0.0030(0.0038) | Loss 8.6932(9.2207) | Error 0.0011(0.0011) Steps 790(805.38) | Grad Norm 1.3499(2.0142) | Total Time 0.00(0.00)\n",
      "Iter 18190 | Time 22.4836(22.0423) | Bit/dim 3.4961(3.4987) | Xent 0.0160(0.0038) | Loss 8.7619(9.0987) | Error 0.0022(0.0011) Steps 802(806.94) | Grad Norm 4.5866(2.0100) | Total Time 0.00(0.00)\n",
      "Iter 18200 | Time 22.6796(21.9361) | Bit/dim 3.4661(3.4979) | Xent 0.0095(0.0038) | Loss 8.6936(8.9996) | Error 0.0033(0.0010) Steps 814(806.79) | Grad Norm 4.1731(2.1517) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0331 | Time 100.8756, Epoch Time 1330.2394(1316.4937), Bit/dim 3.5283(best: 3.5262), Xent 2.7580, Loss 4.9073, Error 0.3375(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18210 | Time 21.1851(21.9115) | Bit/dim 3.5166(3.4990) | Xent 0.0024(0.0040) | Loss 8.8374(9.7322) | Error 0.0011(0.0011) Steps 796(804.37) | Grad Norm 1.9503(2.2894) | Total Time 0.00(0.00)\n",
      "Iter 18220 | Time 21.6317(21.9658) | Bit/dim 3.5016(3.4987) | Xent 0.0011(0.0039) | Loss 8.7685(9.4755) | Error 0.0000(0.0011) Steps 790(804.55) | Grad Norm 1.1320(2.2699) | Total Time 0.00(0.00)\n",
      "Iter 18230 | Time 21.3310(22.0682) | Bit/dim 3.4512(3.4966) | Xent 0.0047(0.0036) | Loss 8.6478(9.2744) | Error 0.0011(0.0010) Steps 802(807.11) | Grad Norm 3.7312(2.2881) | Total Time 0.00(0.00)\n",
      "Iter 18240 | Time 22.8578(22.1222) | Bit/dim 3.5100(3.4992) | Xent 0.0009(0.0034) | Loss 8.7252(9.1478) | Error 0.0000(0.0010) Steps 850(809.16) | Grad Norm 1.6556(2.2523) | Total Time 0.00(0.00)\n",
      "Iter 18250 | Time 23.0973(22.0748) | Bit/dim 3.4554(3.4988) | Xent 0.0046(0.0034) | Loss 8.6865(9.0348) | Error 0.0011(0.0009) Steps 796(807.82) | Grad Norm 2.3339(2.1829) | Total Time 0.00(0.00)\n",
      "Iter 18260 | Time 21.6282(22.0509) | Bit/dim 3.4916(3.4978) | Xent 0.0085(0.0038) | Loss 8.7339(8.9523) | Error 0.0011(0.0010) Steps 796(809.61) | Grad Norm 1.7532(2.2537) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0332 | Time 99.7282, Epoch Time 1336.2910(1317.0876), Bit/dim 3.5303(best: 3.5262), Xent 2.7290, Loss 4.8948, Error 0.3345(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18270 | Time 21.1679(22.0066) | Bit/dim 3.5395(3.4996) | Xent 0.0030(0.0038) | Loss 8.8829(9.5800) | Error 0.0011(0.0010) Steps 808(809.54) | Grad Norm 1.9188(2.2766) | Total Time 0.00(0.00)\n",
      "Iter 18280 | Time 21.7541(21.9373) | Bit/dim 3.5107(3.4976) | Xent 0.0026(0.0035) | Loss 8.6603(9.3559) | Error 0.0011(0.0010) Steps 790(807.92) | Grad Norm 2.9525(2.4875) | Total Time 0.00(0.00)\n",
      "Iter 18290 | Time 22.7124(21.9900) | Bit/dim 3.4954(3.4991) | Xent 0.0020(0.0045) | Loss 8.7976(9.2005) | Error 0.0011(0.0013) Steps 814(807.84) | Grad Norm 2.3376(2.7332) | Total Time 0.00(0.00)\n",
      "Iter 18300 | Time 22.0752(22.0179) | Bit/dim 3.5265(3.4984) | Xent 0.0010(0.0044) | Loss 8.6893(9.0812) | Error 0.0000(0.0012) Steps 790(805.78) | Grad Norm 1.2926(2.5567) | Total Time 0.00(0.00)\n",
      "Iter 18310 | Time 22.7717(22.0311) | Bit/dim 3.4897(3.5015) | Xent 0.0052(0.0046) | Loss 8.7327(9.0043) | Error 0.0033(0.0013) Steps 820(809.49) | Grad Norm 5.3127(2.4816) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0333 | Time 100.0992, Epoch Time 1336.5711(1317.6721), Bit/dim 3.5292(best: 3.5262), Xent 2.6987, Loss 4.8786, Error 0.3281(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18320 | Time 21.8824(22.0112) | Bit/dim 3.4944(3.5012) | Xent 0.0031(0.0042) | Loss 8.7769(9.7496) | Error 0.0011(0.0013) Steps 820(810.82) | Grad Norm 2.3562(2.5022) | Total Time 0.00(0.00)\n",
      "Iter 18330 | Time 21.1004(21.9581) | Bit/dim 3.4571(3.5023) | Xent 0.0030(0.0041) | Loss 8.5459(9.4858) | Error 0.0011(0.0012) Steps 772(808.62) | Grad Norm 2.5709(2.4272) | Total Time 0.00(0.00)\n",
      "Iter 18340 | Time 22.7069(22.0166) | Bit/dim 3.5060(3.5019) | Xent 0.0022(0.0044) | Loss 8.8177(9.2985) | Error 0.0011(0.0012) Steps 838(813.21) | Grad Norm 2.2057(2.4644) | Total Time 0.00(0.00)\n",
      "Iter 18350 | Time 21.9232(21.9645) | Bit/dim 3.5007(3.4999) | Xent 0.0037(0.0044) | Loss 8.6716(9.1425) | Error 0.0011(0.0012) Steps 802(811.15) | Grad Norm 1.5062(2.3964) | Total Time 0.00(0.00)\n",
      "Iter 18360 | Time 21.4340(21.9067) | Bit/dim 3.5264(3.4996) | Xent 0.0037(0.0041) | Loss 8.7081(9.0411) | Error 0.0011(0.0011) Steps 796(809.91) | Grad Norm 2.0175(2.2585) | Total Time 0.00(0.00)\n",
      "Iter 18370 | Time 21.9115(21.9477) | Bit/dim 3.5377(3.4973) | Xent 0.0054(0.0042) | Loss 8.8752(8.9614) | Error 0.0011(0.0011) Steps 814(810.60) | Grad Norm 2.7607(2.3095) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0334 | Time 100.6775, Epoch Time 1326.7068(1317.9431), Bit/dim 3.5256(best: 3.5262), Xent 2.7397, Loss 4.8954, Error 0.3322(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18380 | Time 21.2900(22.0195) | Bit/dim 3.4926(3.4978) | Xent 0.0021(0.0040) | Loss 8.7209(9.5827) | Error 0.0011(0.0012) Steps 814(812.04) | Grad Norm 1.8472(2.2592) | Total Time 0.00(0.00)\n",
      "Iter 18390 | Time 21.8026(22.1185) | Bit/dim 3.4738(3.4971) | Xent 0.0006(0.0036) | Loss 8.6940(9.3627) | Error 0.0000(0.0010) Steps 826(812.42) | Grad Norm 1.0008(2.0128) | Total Time 0.00(0.00)\n",
      "Iter 18400 | Time 21.6769(22.1365) | Bit/dim 3.4987(3.4952) | Xent 0.0060(0.0034) | Loss 8.7285(9.2023) | Error 0.0022(0.0009) Steps 808(811.34) | Grad Norm 4.8260(2.2055) | Total Time 0.00(0.00)\n",
      "Iter 18410 | Time 21.5081(22.1245) | Bit/dim 3.4864(3.4952) | Xent 0.0009(0.0037) | Loss 8.7486(9.0706) | Error 0.0000(0.0011) Steps 802(809.04) | Grad Norm 2.0108(2.4612) | Total Time 0.00(0.00)\n",
      "Iter 18420 | Time 22.6267(22.0967) | Bit/dim 3.5085(3.4964) | Xent 0.0010(0.0040) | Loss 8.8314(8.9858) | Error 0.0000(0.0011) Steps 784(808.62) | Grad Norm 1.3608(2.3818) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0335 | Time 101.0653, Epoch Time 1339.0385(1318.5760), Bit/dim 3.5330(best: 3.5256), Xent 2.7572, Loss 4.9116, Error 0.3330(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18430 | Time 22.8526(22.0918) | Bit/dim 3.4860(3.4970) | Xent 0.0009(0.0039) | Loss 8.6951(9.7189) | Error 0.0000(0.0010) Steps 760(807.95) | Grad Norm 1.2609(2.1897) | Total Time 0.00(0.00)\n",
      "Iter 18440 | Time 23.2472(22.1938) | Bit/dim 3.4878(3.4972) | Xent 0.0033(0.0036) | Loss 8.7334(9.4726) | Error 0.0011(0.0009) Steps 784(809.33) | Grad Norm 1.4620(2.0686) | Total Time 0.00(0.00)\n",
      "Iter 18450 | Time 21.7832(22.1643) | Bit/dim 3.5040(3.4971) | Xent 0.0005(0.0045) | Loss 8.8129(9.2831) | Error 0.0000(0.0013) Steps 838(807.94) | Grad Norm 1.5299(2.5592) | Total Time 0.00(0.00)\n",
      "Iter 18460 | Time 21.4659(22.1091) | Bit/dim 3.5240(3.4983) | Xent 0.0019(0.0042) | Loss 8.8390(9.1518) | Error 0.0000(0.0012) Steps 796(806.06) | Grad Norm 1.9013(2.3969) | Total Time 0.00(0.00)\n",
      "Iter 18470 | Time 22.3879(22.1365) | Bit/dim 3.4730(3.4961) | Xent 0.0012(0.0039) | Loss 8.7008(9.0364) | Error 0.0000(0.0011) Steps 838(806.98) | Grad Norm 1.3450(2.1751) | Total Time 0.00(0.00)\n",
      "Iter 18480 | Time 22.5801(22.0965) | Bit/dim 3.5253(3.4988) | Xent 0.0026(0.0038) | Loss 8.7355(8.9644) | Error 0.0011(0.0010) Steps 808(804.73) | Grad Norm 2.1983(2.1579) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0336 | Time 102.4425, Epoch Time 1343.2059(1319.3149), Bit/dim 3.5304(best: 3.5256), Xent 2.7132, Loss 4.8870, Error 0.3337(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18490 | Time 22.5283(22.0925) | Bit/dim 3.4798(3.4994) | Xent 0.0027(0.0033) | Loss 8.7354(9.5752) | Error 0.0011(0.0009) Steps 826(807.63) | Grad Norm 2.0062(2.0918) | Total Time 0.00(0.00)\n",
      "Iter 18500 | Time 21.9772(22.0587) | Bit/dim 3.4812(3.4977) | Xent 0.0008(0.0033) | Loss 8.6573(9.3485) | Error 0.0000(0.0009) Steps 832(808.12) | Grad Norm 0.6216(1.9398) | Total Time 0.00(0.00)\n",
      "Iter 18510 | Time 22.2340(22.0760) | Bit/dim 3.4834(3.4977) | Xent 0.0051(0.0045) | Loss 8.6450(9.1861) | Error 0.0022(0.0012) Steps 814(809.47) | Grad Norm 2.4564(2.2047) | Total Time 0.00(0.00)\n",
      "Iter 18520 | Time 23.0731(22.1616) | Bit/dim 3.5050(3.4994) | Xent 0.0003(0.0039) | Loss 8.7969(9.0823) | Error 0.0000(0.0011) Steps 838(814.34) | Grad Norm 1.4341(2.1583) | Total Time 0.00(0.00)\n",
      "Iter 18530 | Time 21.7275(22.1995) | Bit/dim 3.5004(3.4987) | Xent 0.0010(0.0037) | Loss 8.6535(8.9945) | Error 0.0000(0.0011) Steps 814(813.46) | Grad Norm 1.2238(2.2124) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0337 | Time 102.7346, Epoch Time 1345.5802(1320.1028), Bit/dim 3.5263(best: 3.5256), Xent 2.7380, Loss 4.8953, Error 0.3350(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18540 | Time 22.1213(22.2698) | Bit/dim 3.5019(3.5008) | Xent 0.0013(0.0036) | Loss 8.6958(9.7324) | Error 0.0000(0.0011) Steps 814(815.91) | Grad Norm 1.1591(2.0665) | Total Time 0.00(0.00)\n",
      "Iter 18550 | Time 22.0619(22.2542) | Bit/dim 3.5273(3.5040) | Xent 0.0111(0.0036) | Loss 8.8103(9.4819) | Error 0.0022(0.0010) Steps 820(813.47) | Grad Norm 1.8466(2.1071) | Total Time 0.00(0.00)\n",
      "Iter 18560 | Time 22.6929(22.2342) | Bit/dim 3.4745(3.5020) | Xent 0.0029(0.0035) | Loss 8.7964(9.2842) | Error 0.0011(0.0010) Steps 832(812.63) | Grad Norm 1.4678(2.0083) | Total Time 0.00(0.00)\n",
      "Iter 18570 | Time 21.8108(22.2226) | Bit/dim 3.4633(3.4990) | Xent 0.0059(0.0035) | Loss 8.7995(9.1500) | Error 0.0011(0.0009) Steps 802(812.37) | Grad Norm 2.3047(1.8914) | Total Time 0.00(0.00)\n",
      "Iter 18580 | Time 21.9391(22.1343) | Bit/dim 3.4971(3.4986) | Xent 0.0026(0.0036) | Loss 8.7947(9.0451) | Error 0.0000(0.0009) Steps 814(812.17) | Grad Norm 1.7943(1.8352) | Total Time 0.00(0.00)\n",
      "Iter 18590 | Time 21.7171(22.1119) | Bit/dim 3.5042(3.4972) | Xent 0.0047(0.0035) | Loss 8.7297(8.9647) | Error 0.0011(0.0008) Steps 826(813.52) | Grad Norm 1.7104(1.7545) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0338 | Time 101.0219, Epoch Time 1339.2394(1320.6769), Bit/dim 3.5253(best: 3.5256), Xent 2.7540, Loss 4.9023, Error 0.3409(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18600 | Time 21.5682(22.0381) | Bit/dim 3.5414(3.4962) | Xent 0.0016(0.0035) | Loss 8.7030(9.6015) | Error 0.0011(0.0009) Steps 808(813.53) | Grad Norm 1.6196(1.8617) | Total Time 0.00(0.00)\n",
      "Iter 18610 | Time 22.5216(21.9400) | Bit/dim 3.5040(3.4958) | Xent 0.0033(0.0040) | Loss 8.7540(9.3654) | Error 0.0011(0.0009) Steps 808(812.23) | Grad Norm 1.7466(1.8545) | Total Time 0.00(0.00)\n",
      "Iter 18620 | Time 22.6192(21.9567) | Bit/dim 3.5150(3.4963) | Xent 0.0029(0.0045) | Loss 8.8429(9.2035) | Error 0.0011(0.0010) Steps 796(809.27) | Grad Norm 2.0657(1.8846) | Total Time 0.00(0.00)\n",
      "Iter 18630 | Time 21.7173(21.9138) | Bit/dim 3.4821(3.4973) | Xent 0.0030(0.0041) | Loss 8.6268(9.0803) | Error 0.0011(0.0009) Steps 802(810.81) | Grad Norm 2.1194(1.7743) | Total Time 0.00(0.00)\n",
      "Iter 18640 | Time 21.2065(21.9387) | Bit/dim 3.4835(3.4958) | Xent 0.0009(0.0035) | Loss 8.7768(8.9899) | Error 0.0000(0.0008) Steps 796(807.33) | Grad Norm 1.0327(1.6212) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0339 | Time 101.6049, Epoch Time 1326.5510(1320.8532), Bit/dim 3.5255(best: 3.5253), Xent 2.7103, Loss 4.8807, Error 0.3334(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18650 | Time 21.2506(21.9469) | Bit/dim 3.5004(3.4970) | Xent 0.0096(0.0038) | Loss 8.7533(9.7256) | Error 0.0011(0.0007) Steps 808(807.31) | Grad Norm 1.3960(1.5490) | Total Time 0.00(0.00)\n",
      "Iter 18660 | Time 21.9368(21.8881) | Bit/dim 3.4854(3.4963) | Xent 0.0018(0.0034) | Loss 8.7528(9.4624) | Error 0.0011(0.0007) Steps 802(804.86) | Grad Norm 0.9656(1.4146) | Total Time 0.00(0.00)\n",
      "Iter 18670 | Time 22.5862(21.9605) | Bit/dim 3.5267(3.4972) | Xent 0.0062(0.0034) | Loss 8.8821(9.2643) | Error 0.0022(0.0008) Steps 808(805.30) | Grad Norm 2.5568(1.4655) | Total Time 0.00(0.00)\n",
      "Iter 18680 | Time 21.8696(21.9972) | Bit/dim 3.5083(3.4969) | Xent 0.0023(0.0030) | Loss 8.7621(9.1241) | Error 0.0011(0.0007) Steps 772(803.71) | Grad Norm 1.6525(1.4533) | Total Time 0.00(0.00)\n",
      "Iter 18690 | Time 22.0826(22.0578) | Bit/dim 3.5115(3.4959) | Xent 0.0022(0.0027) | Loss 8.6084(9.0163) | Error 0.0000(0.0007) Steps 814(804.57) | Grad Norm 0.9769(1.4155) | Total Time 0.00(0.00)\n",
      "Iter 18700 | Time 22.5382(22.0335) | Bit/dim 3.4727(3.4931) | Xent 0.0012(0.0028) | Loss 8.7270(8.9349) | Error 0.0000(0.0006) Steps 790(804.34) | Grad Norm 1.5343(1.5524) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0340 | Time 100.4929, Epoch Time 1332.2535(1321.1952), Bit/dim 3.5259(best: 3.5253), Xent 2.7334, Loss 4.8926, Error 0.3317(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18710 | Time 21.2021(22.0302) | Bit/dim 3.5291(3.4964) | Xent 0.0084(0.0036) | Loss 8.7480(9.5670) | Error 0.0022(0.0008) Steps 766(802.92) | Grad Norm 2.9334(1.7793) | Total Time 0.00(0.00)\n",
      "Iter 18720 | Time 21.5170(21.9881) | Bit/dim 3.5009(3.4969) | Xent 0.0028(0.0039) | Loss 8.7447(9.3531) | Error 0.0011(0.0010) Steps 802(806.17) | Grad Norm 2.2730(2.0553) | Total Time 0.00(0.00)\n",
      "Iter 18730 | Time 22.3821(22.0778) | Bit/dim 3.4805(3.4966) | Xent 0.0012(0.0035) | Loss 8.7957(9.1882) | Error 0.0000(0.0009) Steps 802(804.29) | Grad Norm 0.9915(1.9382) | Total Time 0.00(0.00)\n",
      "Iter 18740 | Time 21.4883(21.9702) | Bit/dim 3.4926(3.4961) | Xent 0.0043(0.0036) | Loss 8.7413(9.0707) | Error 0.0022(0.0010) Steps 790(804.74) | Grad Norm 2.7971(1.9856) | Total Time 0.00(0.00)\n",
      "Iter 18750 | Time 22.5082(21.9592) | Bit/dim 3.4939(3.4955) | Xent 0.0046(0.0036) | Loss 8.7925(8.9834) | Error 0.0022(0.0009) Steps 802(806.94) | Grad Norm 1.7899(2.0331) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0341 | Time 103.4665, Epoch Time 1334.6435(1321.5986), Bit/dim 3.5284(best: 3.5253), Xent 2.7729, Loss 4.9149, Error 0.3399(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18760 | Time 21.8464(22.0860) | Bit/dim 3.5408(3.4949) | Xent 0.0005(0.0037) | Loss 8.8502(9.7210) | Error 0.0000(0.0009) Steps 808(808.64) | Grad Norm 1.3816(2.1353) | Total Time 0.00(0.00)\n",
      "Iter 18770 | Time 21.8501(22.0952) | Bit/dim 3.5025(3.4956) | Xent 0.0189(0.0047) | Loss 8.7772(9.4748) | Error 0.0022(0.0010) Steps 796(808.82) | Grad Norm 2.8843(2.3956) | Total Time 0.00(0.00)\n",
      "Iter 18780 | Time 21.8737(22.0739) | Bit/dim 3.4710(3.4987) | Xent 0.0009(0.0045) | Loss 8.6382(9.2861) | Error 0.0000(0.0010) Steps 826(808.30) | Grad Norm 2.1653(2.3404) | Total Time 0.00(0.00)\n",
      "Iter 18790 | Time 21.8587(22.0148) | Bit/dim 3.4922(3.4992) | Xent 0.0019(0.0045) | Loss 8.8404(9.1491) | Error 0.0000(0.0010) Steps 814(807.64) | Grad Norm 1.4358(2.3991) | Total Time 0.00(0.00)\n",
      "Iter 18800 | Time 22.0617(22.0521) | Bit/dim 3.4995(3.4987) | Xent 0.0204(0.0052) | Loss 8.7016(9.0354) | Error 0.0056(0.0012) Steps 790(806.83) | Grad Norm 4.1314(2.4928) | Total Time 0.00(0.00)\n",
      "Iter 18810 | Time 21.7197(22.0195) | Bit/dim 3.4978(3.4965) | Xent 0.0022(0.0043) | Loss 8.7272(8.9470) | Error 0.0011(0.0010) Steps 796(806.98) | Grad Norm 1.6072(2.3144) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0342 | Time 100.5226, Epoch Time 1335.0996(1322.0037), Bit/dim 3.5282(best: 3.5253), Xent 2.6604, Loss 4.8584, Error 0.3362(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18820 | Time 22.0739(22.0391) | Bit/dim 3.5020(3.4941) | Xent 0.0005(0.0041) | Loss 8.6756(9.5579) | Error 0.0000(0.0009) Steps 814(807.99) | Grad Norm 0.7120(2.0791) | Total Time 0.00(0.00)\n",
      "Iter 18830 | Time 21.4595(22.1599) | Bit/dim 3.4933(3.4949) | Xent 0.0025(0.0039) | Loss 8.7626(9.3495) | Error 0.0011(0.0009) Steps 814(807.42) | Grad Norm 1.2730(1.8923) | Total Time 0.00(0.00)\n",
      "Iter 18840 | Time 22.8451(22.1719) | Bit/dim 3.4509(3.4944) | Xent 0.0128(0.0043) | Loss 8.6617(9.1880) | Error 0.0033(0.0009) Steps 814(805.31) | Grad Norm 5.1289(1.9882) | Total Time 0.00(0.00)\n",
      "Iter 18850 | Time 21.6688(22.0520) | Bit/dim 3.5145(3.4993) | Xent 0.0035(0.0041) | Loss 8.5933(9.0733) | Error 0.0011(0.0009) Steps 784(803.01) | Grad Norm 1.8599(2.0711) | Total Time 0.00(0.00)\n",
      "Iter 18860 | Time 21.5801(22.1342) | Bit/dim 3.4983(3.4950) | Xent 0.0006(0.0036) | Loss 8.6649(8.9755) | Error 0.0000(0.0009) Steps 814(807.04) | Grad Norm 0.7841(1.8839) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0343 | Time 101.5424, Epoch Time 1342.7531(1322.6261), Bit/dim 3.5219(best: 3.5253), Xent 2.7234, Loss 4.8836, Error 0.3353(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18870 | Time 21.8643(22.0725) | Bit/dim 3.5091(3.4961) | Xent 0.0056(0.0034) | Loss 8.7923(9.6920) | Error 0.0011(0.0008) Steps 802(810.52) | Grad Norm 1.5345(1.7866) | Total Time 0.00(0.00)\n",
      "Iter 18880 | Time 22.1804(22.0893) | Bit/dim 3.5302(3.4985) | Xent 0.0006(0.0033) | Loss 8.8483(9.4557) | Error 0.0000(0.0009) Steps 838(809.20) | Grad Norm 0.7513(1.8248) | Total Time 0.00(0.00)\n",
      "Iter 18890 | Time 22.3930(22.1230) | Bit/dim 3.5082(3.4973) | Xent 0.0042(0.0039) | Loss 8.8068(9.2744) | Error 0.0022(0.0010) Steps 832(811.70) | Grad Norm 4.5758(1.9378) | Total Time 0.00(0.00)\n",
      "Iter 18900 | Time 22.8220(22.0899) | Bit/dim 3.5072(3.4971) | Xent 0.0077(0.0041) | Loss 8.8922(9.1360) | Error 0.0033(0.0011) Steps 826(807.36) | Grad Norm 2.1661(2.0355) | Total Time 0.00(0.00)\n",
      "Iter 18910 | Time 21.7957(22.0671) | Bit/dim 3.5015(3.4975) | Xent 0.0077(0.0039) | Loss 8.7215(9.0323) | Error 0.0011(0.0010) Steps 796(808.42) | Grad Norm 2.6078(2.0109) | Total Time 0.00(0.00)\n",
      "Iter 18920 | Time 20.9087(21.9760) | Bit/dim 3.5045(3.4956) | Xent 0.0007(0.0034) | Loss 8.6478(8.9541) | Error 0.0000(0.0009) Steps 814(809.20) | Grad Norm 1.3201(1.9076) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0344 | Time 101.0698, Epoch Time 1331.1213(1322.8810), Bit/dim 3.5267(best: 3.5219), Xent 2.7351, Loss 4.8942, Error 0.3338(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18930 | Time 23.1034(22.0829) | Bit/dim 3.4917(3.4963) | Xent 0.0150(0.0039) | Loss 8.7836(9.5702) | Error 0.0033(0.0010) Steps 796(809.76) | Grad Norm 5.7797(2.0431) | Total Time 0.00(0.00)\n",
      "Iter 18940 | Time 22.4617(22.1505) | Bit/dim 3.5117(3.4991) | Xent 0.0064(0.0039) | Loss 8.6615(9.3633) | Error 0.0011(0.0010) Steps 784(810.03) | Grad Norm 2.1072(2.2462) | Total Time 0.00(0.00)\n",
      "Iter 18950 | Time 22.7848(22.2075) | Bit/dim 3.5250(3.4999) | Xent 0.0015(0.0038) | Loss 8.7407(9.1953) | Error 0.0011(0.0010) Steps 820(810.77) | Grad Norm 1.7231(2.3613) | Total Time 0.00(0.00)\n",
      "Iter 18960 | Time 22.3170(22.2530) | Bit/dim 3.5014(3.4981) | Xent 0.0033(0.0039) | Loss 8.8375(9.0759) | Error 0.0011(0.0010) Steps 796(811.43) | Grad Norm 2.5193(2.3255) | Total Time 0.00(0.00)\n",
      "Iter 18970 | Time 22.9353(22.2053) | Bit/dim 3.4951(3.4947) | Xent 0.0066(0.0039) | Loss 8.6648(8.9842) | Error 0.0022(0.0010) Steps 844(811.76) | Grad Norm 3.1202(2.2987) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0345 | Time 100.7454, Epoch Time 1348.5248(1323.6503), Bit/dim 3.5267(best: 3.5219), Xent 2.7356, Loss 4.8945, Error 0.3361(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 18980 | Time 21.6312(22.1443) | Bit/dim 3.5243(3.4975) | Xent 0.0041(0.0038) | Loss 8.4978(9.6907) | Error 0.0011(0.0010) Steps 814(810.45) | Grad Norm 2.4203(2.2070) | Total Time 0.00(0.00)\n",
      "Iter 18990 | Time 22.0397(22.1296) | Bit/dim 3.5270(3.5002) | Xent 0.0031(0.0037) | Loss 8.9579(9.4594) | Error 0.0011(0.0010) Steps 826(809.66) | Grad Norm 2.5465(2.1178) | Total Time 0.00(0.00)\n",
      "Iter 19000 | Time 21.6800(22.1896) | Bit/dim 3.4731(3.4960) | Xent 0.0007(0.0040) | Loss 8.6016(9.2599) | Error 0.0000(0.0010) Steps 778(809.61) | Grad Norm 1.1328(2.1439) | Total Time 0.00(0.00)\n",
      "Iter 19010 | Time 21.5604(22.2514) | Bit/dim 3.5195(3.4970) | Xent 0.0009(0.0037) | Loss 8.7630(9.1217) | Error 0.0000(0.0009) Steps 820(812.15) | Grad Norm 1.1753(2.0968) | Total Time 0.00(0.00)\n",
      "Iter 19020 | Time 22.3973(22.2388) | Bit/dim 3.4921(3.4979) | Xent 0.0016(0.0035) | Loss 8.8314(9.0241) | Error 0.0000(0.0009) Steps 862(811.43) | Grad Norm 0.7919(1.9955) | Total Time 0.00(0.00)\n",
      "Iter 19030 | Time 23.0790(22.2082) | Bit/dim 3.4445(3.4955) | Xent 0.0036(0.0035) | Loss 8.6803(8.9452) | Error 0.0011(0.0009) Steps 850(811.43) | Grad Norm 3.0046(1.9994) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0346 | Time 102.1087, Epoch Time 1345.7983(1324.3147), Bit/dim 3.5247(best: 3.5219), Xent 2.7389, Loss 4.8941, Error 0.3319(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19040 | Time 22.7660(22.0863) | Bit/dim 3.4583(3.4934) | Xent 0.0055(0.0039) | Loss 8.6552(9.5701) | Error 0.0033(0.0010) Steps 790(810.71) | Grad Norm 3.7390(2.1180) | Total Time 0.00(0.00)\n",
      "Iter 19050 | Time 22.3728(22.0807) | Bit/dim 3.4862(3.4973) | Xent 0.0046(0.0044) | Loss 8.7280(9.3567) | Error 0.0011(0.0012) Steps 796(809.44) | Grad Norm 2.4491(2.4454) | Total Time 0.00(0.00)\n",
      "Iter 19060 | Time 23.0029(22.0624) | Bit/dim 3.4874(3.4952) | Xent 0.0013(0.0046) | Loss 8.7513(9.1893) | Error 0.0000(0.0011) Steps 814(811.57) | Grad Norm 1.8392(2.4261) | Total Time 0.00(0.00)\n",
      "Iter 19070 | Time 22.0798(22.1687) | Bit/dim 3.4791(3.4965) | Xent 0.0050(0.0044) | Loss 8.7331(9.0809) | Error 0.0011(0.0012) Steps 814(808.20) | Grad Norm 2.0335(2.3061) | Total Time 0.00(0.00)\n",
      "Iter 19080 | Time 22.9310(22.2014) | Bit/dim 3.5109(3.4996) | Xent 0.0015(0.0048) | Loss 8.9004(8.9997) | Error 0.0011(0.0014) Steps 826(809.12) | Grad Norm 2.1917(2.4120) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0347 | Time 102.5694, Epoch Time 1344.5858(1324.9229), Bit/dim 3.5240(best: 3.5219), Xent 2.7483, Loss 4.8981, Error 0.3343(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19090 | Time 21.4795(22.3188) | Bit/dim 3.5301(3.4979) | Xent 0.0011(0.0045) | Loss 8.8570(9.7462) | Error 0.0000(0.0012) Steps 832(813.54) | Grad Norm 1.1492(2.2496) | Total Time 0.00(0.00)\n",
      "Iter 19100 | Time 21.7672(22.2977) | Bit/dim 3.5028(3.4970) | Xent 0.0005(0.0040) | Loss 8.6628(9.4791) | Error 0.0000(0.0010) Steps 790(810.51) | Grad Norm 1.1817(2.1082) | Total Time 0.00(0.00)\n",
      "Iter 19110 | Time 22.0189(22.2083) | Bit/dim 3.5368(3.4967) | Xent 0.0062(0.0038) | Loss 8.8099(9.2874) | Error 0.0011(0.0010) Steps 820(809.25) | Grad Norm 1.5178(2.0563) | Total Time 0.00(0.00)\n",
      "Iter 19120 | Time 21.8158(22.1203) | Bit/dim 3.4899(3.4968) | Xent 0.0031(0.0041) | Loss 8.6075(9.1341) | Error 0.0022(0.0010) Steps 808(808.58) | Grad Norm 1.9595(2.1780) | Total Time 0.00(0.00)\n",
      "Iter 19130 | Time 22.1723(22.1477) | Bit/dim 3.5042(3.4963) | Xent 0.0043(0.0042) | Loss 8.7560(9.0295) | Error 0.0011(0.0011) Steps 802(809.02) | Grad Norm 2.1806(2.2714) | Total Time 0.00(0.00)\n",
      "Iter 19140 | Time 22.9028(22.2380) | Bit/dim 3.4943(3.4953) | Xent 0.0015(0.0045) | Loss 8.7787(8.9565) | Error 0.0000(0.0013) Steps 844(812.44) | Grad Norm 1.4549(2.3230) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0348 | Time 100.6586, Epoch Time 1340.8801(1325.4016), Bit/dim 3.5275(best: 3.5219), Xent 2.7296, Loss 4.8923, Error 0.3279(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19150 | Time 22.3780(22.2356) | Bit/dim 3.5099(3.4975) | Xent 0.0050(0.0041) | Loss 8.8379(9.5648) | Error 0.0011(0.0012) Steps 862(814.26) | Grad Norm 2.9955(2.2395) | Total Time 0.00(0.00)\n",
      "Iter 19160 | Time 21.4393(22.1658) | Bit/dim 3.4984(3.4979) | Xent 0.0012(0.0036) | Loss 8.6990(9.3481) | Error 0.0000(0.0009) Steps 820(813.85) | Grad Norm 0.5914(2.0426) | Total Time 0.00(0.00)\n",
      "Iter 19170 | Time 21.5304(22.1343) | Bit/dim 3.4951(3.4965) | Xent 0.0037(0.0036) | Loss 8.6739(9.1824) | Error 0.0011(0.0010) Steps 802(815.94) | Grad Norm 2.3744(2.1030) | Total Time 0.00(0.00)\n",
      "Iter 19180 | Time 21.2994(22.1325) | Bit/dim 3.4713(3.4941) | Xent 0.0033(0.0037) | Loss 8.7035(9.0586) | Error 0.0011(0.0010) Steps 790(812.52) | Grad Norm 3.0622(2.2282) | Total Time 0.00(0.00)\n",
      "Iter 19190 | Time 21.8880(22.1816) | Bit/dim 3.4793(3.4947) | Xent 0.0008(0.0035) | Loss 8.6099(8.9793) | Error 0.0000(0.0010) Steps 796(816.48) | Grad Norm 2.6643(2.4859) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0349 | Time 101.3072, Epoch Time 1340.2347(1325.8466), Bit/dim 3.5255(best: 3.5219), Xent 2.7112, Loss 4.8811, Error 0.3318(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19200 | Time 22.3884(22.1837) | Bit/dim 3.5214(3.4972) | Xent 0.0007(0.0035) | Loss 8.8348(9.7126) | Error 0.0000(0.0009) Steps 796(818.29) | Grad Norm 2.3731(2.4409) | Total Time 0.00(0.00)\n",
      "Iter 19210 | Time 22.7307(22.2284) | Bit/dim 3.5083(3.4947) | Xent 0.0104(0.0038) | Loss 8.7595(9.4640) | Error 0.0011(0.0010) Steps 844(816.61) | Grad Norm 2.5172(2.3559) | Total Time 0.00(0.00)\n",
      "Iter 19220 | Time 22.9186(22.1461) | Bit/dim 3.5159(3.4919) | Xent 0.0130(0.0035) | Loss 8.7933(9.2620) | Error 0.0022(0.0009) Steps 844(814.81) | Grad Norm 2.0377(2.1546) | Total Time 0.00(0.00)\n",
      "Iter 19230 | Time 21.8793(22.2087) | Bit/dim 3.4591(3.4934) | Xent 0.0013(0.0030) | Loss 8.6065(9.1302) | Error 0.0000(0.0008) Steps 808(813.35) | Grad Norm 0.8489(1.9579) | Total Time 0.00(0.00)\n",
      "Iter 19240 | Time 21.4154(22.2057) | Bit/dim 3.4981(3.4931) | Xent 0.0023(0.0030) | Loss 8.7642(9.0261) | Error 0.0000(0.0008) Steps 814(810.08) | Grad Norm 1.4573(1.9069) | Total Time 0.00(0.00)\n",
      "Iter 19250 | Time 22.2648(22.1709) | Bit/dim 3.4928(3.4963) | Xent 0.0005(0.0027) | Loss 8.6959(8.9482) | Error 0.0000(0.0006) Steps 838(810.97) | Grad Norm 1.2577(1.8141) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0350 | Time 100.7378, Epoch Time 1346.2018(1326.4572), Bit/dim 3.5239(best: 3.5219), Xent 2.7778, Loss 4.9128, Error 0.3372(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19260 | Time 21.7373(22.1268) | Bit/dim 3.4671(3.4936) | Xent 0.0012(0.0025) | Loss 8.7034(9.5702) | Error 0.0000(0.0006) Steps 826(814.14) | Grad Norm 0.9091(1.7622) | Total Time 0.00(0.00)\n",
      "Iter 19270 | Time 21.6309(22.1389) | Bit/dim 3.4733(3.4930) | Xent 0.0017(0.0026) | Loss 8.6882(9.3418) | Error 0.0000(0.0006) Steps 820(813.35) | Grad Norm 1.5343(1.7438) | Total Time 0.00(0.00)\n",
      "Iter 19280 | Time 23.2901(22.1627) | Bit/dim 3.4991(3.4967) | Xent 0.0010(0.0030) | Loss 8.7936(9.1891) | Error 0.0000(0.0007) Steps 874(814.80) | Grad Norm 1.2655(1.8035) | Total Time 0.00(0.00)\n",
      "Iter 19290 | Time 22.8985(22.1863) | Bit/dim 3.4713(3.4964) | Xent 0.0005(0.0030) | Loss 8.6728(9.0708) | Error 0.0000(0.0007) Steps 856(816.96) | Grad Norm 1.0287(1.8176) | Total Time 0.00(0.00)\n",
      "Iter 19300 | Time 23.3750(22.2443) | Bit/dim 3.4572(3.4949) | Xent 0.0024(0.0032) | Loss 8.7389(8.9762) | Error 0.0011(0.0009) Steps 802(814.63) | Grad Norm 3.5166(2.0583) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0351 | Time 101.8706, Epoch Time 1343.3921(1326.9653), Bit/dim 3.5281(best: 3.5219), Xent 2.8231, Loss 4.9397, Error 0.3335(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19310 | Time 22.9921(22.2263) | Bit/dim 3.4544(3.4957) | Xent 0.0011(0.0038) | Loss 8.6879(9.7092) | Error 0.0000(0.0010) Steps 802(812.81) | Grad Norm 1.4878(2.1389) | Total Time 0.00(0.00)\n",
      "Iter 19320 | Time 21.9689(22.3159) | Bit/dim 3.5025(3.4971) | Xent 0.0053(0.0039) | Loss 8.8785(9.4543) | Error 0.0022(0.0010) Steps 802(811.85) | Grad Norm 3.0653(2.1601) | Total Time 0.00(0.00)\n",
      "Iter 19330 | Time 21.8424(22.2996) | Bit/dim 3.4649(3.4961) | Xent 0.0027(0.0039) | Loss 8.6328(9.2705) | Error 0.0011(0.0010) Steps 826(815.83) | Grad Norm 2.7906(2.2348) | Total Time 0.00(0.00)\n",
      "Iter 19340 | Time 22.3486(22.2714) | Bit/dim 3.5126(3.4986) | Xent 0.0004(0.0041) | Loss 8.8628(9.1350) | Error 0.0000(0.0012) Steps 820(815.61) | Grad Norm 1.1208(2.3234) | Total Time 0.00(0.00)\n",
      "Iter 19350 | Time 21.7952(22.2340) | Bit/dim 3.4807(3.4967) | Xent 0.0014(0.0037) | Loss 8.7052(9.0283) | Error 0.0011(0.0011) Steps 832(815.56) | Grad Norm 2.7445(2.2456) | Total Time 0.00(0.00)\n",
      "Iter 19360 | Time 21.1883(22.2152) | Bit/dim 3.4864(3.4956) | Xent 0.0006(0.0036) | Loss 8.6849(8.9515) | Error 0.0000(0.0010) Steps 778(811.56) | Grad Norm 1.0844(2.1714) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0352 | Time 102.6106, Epoch Time 1353.8669(1327.7723), Bit/dim 3.5258(best: 3.5219), Xent 2.7551, Loss 4.9034, Error 0.3325(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19370 | Time 22.2871(22.2490) | Bit/dim 3.5076(3.4971) | Xent 0.0010(0.0039) | Loss 8.8011(9.5911) | Error 0.0000(0.0010) Steps 802(812.53) | Grad Norm 1.2661(2.1433) | Total Time 0.00(0.00)\n",
      "Iter 19380 | Time 21.9787(22.2398) | Bit/dim 3.5390(3.4972) | Xent 0.0005(0.0038) | Loss 8.9443(9.3731) | Error 0.0000(0.0010) Steps 844(814.11) | Grad Norm 1.4494(2.1414) | Total Time 0.00(0.00)\n",
      "Iter 19390 | Time 22.0860(22.2249) | Bit/dim 3.4976(3.4964) | Xent 0.0080(0.0039) | Loss 8.8033(9.2099) | Error 0.0011(0.0011) Steps 802(814.44) | Grad Norm 2.1455(2.2413) | Total Time 0.00(0.00)\n",
      "Iter 19400 | Time 21.8753(22.1700) | Bit/dim 3.4807(3.4940) | Xent 0.0107(0.0048) | Loss 8.5780(9.0729) | Error 0.0033(0.0013) Steps 772(813.50) | Grad Norm 3.3339(2.3385) | Total Time 0.00(0.00)\n",
      "Iter 19410 | Time 21.8550(22.2602) | Bit/dim 3.4654(3.4956) | Xent 0.0008(0.0048) | Loss 8.6155(8.9946) | Error 0.0000(0.0012) Steps 802(817.00) | Grad Norm 1.0736(2.3872) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0353 | Time 104.4725, Epoch Time 1352.7561(1328.5218), Bit/dim 3.5277(best: 3.5219), Xent 2.8024, Loss 4.9289, Error 0.3358(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19420 | Time 21.8479(22.3258) | Bit/dim 3.5032(3.4980) | Xent 0.0060(0.0046) | Loss 8.7709(9.7126) | Error 0.0022(0.0012) Steps 844(817.12) | Grad Norm 2.5093(2.3546) | Total Time 0.00(0.00)\n",
      "Iter 19430 | Time 21.7632(22.2858) | Bit/dim 3.5154(3.4993) | Xent 0.0006(0.0041) | Loss 8.8397(9.4652) | Error 0.0000(0.0011) Steps 826(817.74) | Grad Norm 1.3439(2.3545) | Total Time 0.00(0.00)\n",
      "Iter 19440 | Time 22.3076(22.2987) | Bit/dim 3.4783(3.4976) | Xent 0.0016(0.0040) | Loss 8.7433(9.2741) | Error 0.0011(0.0010) Steps 838(816.47) | Grad Norm 2.3413(2.1605) | Total Time 0.00(0.00)\n",
      "Iter 19450 | Time 22.6096(22.2073) | Bit/dim 3.5126(3.4965) | Xent 0.0011(0.0038) | Loss 8.8104(9.1307) | Error 0.0000(0.0010) Steps 796(814.51) | Grad Norm 0.9921(2.0680) | Total Time 0.00(0.00)\n",
      "Iter 19460 | Time 21.8298(22.2254) | Bit/dim 3.5217(3.4950) | Xent 0.0010(0.0036) | Loss 8.6641(9.0308) | Error 0.0000(0.0009) Steps 778(815.29) | Grad Norm 1.2127(2.0466) | Total Time 0.00(0.00)\n",
      "Iter 19470 | Time 21.4980(22.2168) | Bit/dim 3.5448(3.4943) | Xent 0.0067(0.0035) | Loss 8.8227(8.9580) | Error 0.0011(0.0008) Steps 820(813.50) | Grad Norm 5.2295(2.0686) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0354 | Time 101.7852, Epoch Time 1349.0592(1329.1380), Bit/dim 3.5232(best: 3.5219), Xent 2.7665, Loss 4.9064, Error 0.3340(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19480 | Time 21.4471(22.2502) | Bit/dim 3.4894(3.4916) | Xent 0.0016(0.0034) | Loss 8.7748(9.5702) | Error 0.0000(0.0008) Steps 802(815.33) | Grad Norm 1.5014(2.0543) | Total Time 0.00(0.00)\n",
      "Iter 19490 | Time 21.5070(22.2679) | Bit/dim 3.5164(3.4922) | Xent 0.0023(0.0038) | Loss 8.8041(9.3560) | Error 0.0011(0.0008) Steps 802(812.86) | Grad Norm 1.8529(2.0364) | Total Time 0.00(0.00)\n",
      "Iter 19500 | Time 22.2811(22.3527) | Bit/dim 3.4844(3.4938) | Xent 0.0061(0.0049) | Loss 8.7883(9.1983) | Error 0.0022(0.0012) Steps 802(812.76) | Grad Norm 2.7221(2.1811) | Total Time 0.00(0.00)\n",
      "Iter 19510 | Time 23.7472(22.3720) | Bit/dim 3.5268(3.4952) | Xent 0.0093(0.0051) | Loss 9.0256(9.0863) | Error 0.0011(0.0013) Steps 862(815.55) | Grad Norm 2.9792(2.4109) | Total Time 0.00(0.00)\n",
      "Iter 19520 | Time 21.7478(22.2564) | Bit/dim 3.5274(3.4980) | Xent 0.0008(0.0048) | Loss 8.8419(8.9995) | Error 0.0000(0.0011) Steps 808(813.20) | Grad Norm 1.0526(2.2295) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0355 | Time 102.1342, Epoch Time 1351.0151(1329.7943), Bit/dim 3.5219(best: 3.5219), Xent 2.7103, Loss 4.8770, Error 0.3339(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19530 | Time 22.7926(22.2938) | Bit/dim 3.5251(3.4968) | Xent 0.0010(0.0042) | Loss 8.8294(9.7153) | Error 0.0000(0.0010) Steps 844(815.60) | Grad Norm 1.5300(2.0723) | Total Time 0.00(0.00)\n",
      "Iter 19540 | Time 22.8894(22.3585) | Bit/dim 3.4946(3.4982) | Xent 0.0071(0.0039) | Loss 8.7172(9.4545) | Error 0.0022(0.0010) Steps 856(814.28) | Grad Norm 5.7970(2.1507) | Total Time 0.00(0.00)\n",
      "Iter 19550 | Time 21.8556(22.3489) | Bit/dim 3.5350(3.4982) | Xent 0.0150(0.0045) | Loss 8.8570(9.2745) | Error 0.0056(0.0013) Steps 820(810.46) | Grad Norm 5.1157(2.3992) | Total Time 0.00(0.00)\n",
      "Iter 19560 | Time 22.5796(22.3687) | Bit/dim 3.4659(3.4963) | Xent 0.0028(0.0046) | Loss 8.8150(9.1415) | Error 0.0000(0.0012) Steps 868(810.07) | Grad Norm 2.1062(2.4400) | Total Time 0.00(0.00)\n",
      "Iter 19570 | Time 22.1573(22.4285) | Bit/dim 3.4679(3.4970) | Xent 0.0017(0.0041) | Loss 8.7350(9.0440) | Error 0.0011(0.0012) Steps 802(813.25) | Grad Norm 1.8887(2.3099) | Total Time 0.00(0.00)\n",
      "Iter 19580 | Time 22.6850(22.3746) | Bit/dim 3.4895(3.4981) | Xent 0.0068(0.0041) | Loss 8.8222(8.9663) | Error 0.0022(0.0011) Steps 838(812.58) | Grad Norm 3.9388(2.2934) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0356 | Time 103.3936, Epoch Time 1357.2591(1330.6182), Bit/dim 3.5263(best: 3.5219), Xent 2.7869, Loss 4.9197, Error 0.3368(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19590 | Time 22.0949(22.3527) | Bit/dim 3.5149(3.4997) | Xent 0.0006(0.0037) | Loss 8.8043(9.5977) | Error 0.0000(0.0010) Steps 796(815.04) | Grad Norm 1.5514(2.4874) | Total Time 0.00(0.00)\n",
      "Iter 19600 | Time 22.7809(22.3395) | Bit/dim 3.4658(3.4971) | Xent 0.0010(0.0037) | Loss 8.5809(9.3719) | Error 0.0000(0.0010) Steps 826(815.74) | Grad Norm 2.5709(2.5307) | Total Time 0.00(0.00)\n",
      "Iter 19610 | Time 23.2740(22.3887) | Bit/dim 3.4761(3.4983) | Xent 0.0034(0.0033) | Loss 8.7988(9.2147) | Error 0.0011(0.0008) Steps 832(816.52) | Grad Norm 2.8208(2.3604) | Total Time 0.00(0.00)\n",
      "Iter 19620 | Time 21.8616(22.2951) | Bit/dim 3.4884(3.4963) | Xent 0.0032(0.0030) | Loss 8.7436(9.0893) | Error 0.0011(0.0008) Steps 802(815.97) | Grad Norm 3.0078(2.2596) | Total Time 0.00(0.00)\n",
      "Iter 19630 | Time 21.4960(22.3135) | Bit/dim 3.4843(3.4962) | Xent 0.0052(0.0031) | Loss 8.7679(8.9867) | Error 0.0011(0.0008) Steps 808(813.78) | Grad Norm 5.9031(2.2767) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0357 | Time 102.7034, Epoch Time 1348.6864(1331.1603), Bit/dim 3.5276(best: 3.5219), Xent 2.8398, Loss 4.9474, Error 0.3371(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19640 | Time 22.9416(22.3002) | Bit/dim 3.4844(3.4944) | Xent 0.0019(0.0030) | Loss 8.8251(9.6957) | Error 0.0011(0.0008) Steps 814(813.89) | Grad Norm 1.2432(2.1415) | Total Time 0.00(0.00)\n",
      "Iter 19650 | Time 21.7150(22.2942) | Bit/dim 3.4997(3.4932) | Xent 0.0022(0.0028) | Loss 8.7718(9.4392) | Error 0.0011(0.0008) Steps 802(812.02) | Grad Norm 3.5075(2.1121) | Total Time 0.00(0.00)\n",
      "Iter 19660 | Time 22.8637(22.2585) | Bit/dim 3.5329(3.4938) | Xent 0.0040(0.0031) | Loss 8.8892(9.2498) | Error 0.0011(0.0009) Steps 850(808.45) | Grad Norm 4.3108(2.1835) | Total Time 0.00(0.00)\n",
      "Iter 19670 | Time 21.7821(22.3094) | Bit/dim 3.5190(3.4957) | Xent 0.0005(0.0035) | Loss 8.8864(9.1225) | Error 0.0000(0.0009) Steps 826(810.12) | Grad Norm 0.9342(2.1235) | Total Time 0.00(0.00)\n",
      "Iter 19680 | Time 21.8293(22.3119) | Bit/dim 3.4720(3.4948) | Xent 0.0044(0.0037) | Loss 8.6834(9.0242) | Error 0.0011(0.0009) Steps 790(811.72) | Grad Norm 1.6681(2.0116) | Total Time 0.00(0.00)\n",
      "Iter 19690 | Time 22.0250(22.3637) | Bit/dim 3.4980(3.4954) | Xent 0.0008(0.0037) | Loss 8.7781(8.9542) | Error 0.0000(0.0009) Steps 778(811.68) | Grad Norm 0.7914(1.8774) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0358 | Time 101.1638, Epoch Time 1352.2371(1331.7926), Bit/dim 3.5264(best: 3.5219), Xent 2.7705, Loss 4.9116, Error 0.3342(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19700 | Time 21.9637(22.3164) | Bit/dim 3.4876(3.4964) | Xent 0.0005(0.0035) | Loss 8.7125(9.5638) | Error 0.0000(0.0008) Steps 820(814.48) | Grad Norm 0.6626(1.8112) | Total Time 0.00(0.00)\n",
      "Iter 19710 | Time 21.7191(22.3586) | Bit/dim 3.4769(3.4957) | Xent 0.0008(0.0035) | Loss 8.7929(9.3475) | Error 0.0000(0.0008) Steps 808(812.99) | Grad Norm 0.7118(1.7520) | Total Time 0.00(0.00)\n",
      "Iter 19720 | Time 22.7932(22.2933) | Bit/dim 3.4997(3.4925) | Xent 0.0006(0.0031) | Loss 8.7139(9.1812) | Error 0.0000(0.0007) Steps 808(814.45) | Grad Norm 0.8009(1.6477) | Total Time 0.00(0.00)\n",
      "Iter 19730 | Time 22.8493(22.2210) | Bit/dim 3.5223(3.4952) | Xent 0.0174(0.0036) | Loss 8.8235(9.0770) | Error 0.0022(0.0008) Steps 796(813.64) | Grad Norm 6.5486(1.9673) | Total Time 0.00(0.00)\n",
      "Iter 19740 | Time 21.6761(22.1007) | Bit/dim 3.5121(3.4956) | Xent 0.0007(0.0040) | Loss 8.6746(8.9783) | Error 0.0000(0.0011) Steps 796(812.29) | Grad Norm 1.6500(2.2022) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0359 | Time 101.7084, Epoch Time 1336.0089(1331.9191), Bit/dim 3.5272(best: 3.5219), Xent 2.7544, Loss 4.9044, Error 0.3369(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19750 | Time 23.4979(22.1572) | Bit/dim 3.5119(3.4977) | Xent 0.0007(0.0038) | Loss 8.8556(9.7068) | Error 0.0000(0.0010) Steps 850(813.70) | Grad Norm 1.0673(2.1259) | Total Time 0.00(0.00)\n",
      "Iter 19760 | Time 21.6774(22.1492) | Bit/dim 3.5003(3.4985) | Xent 0.0011(0.0041) | Loss 8.7671(9.4538) | Error 0.0000(0.0011) Steps 814(815.67) | Grad Norm 1.0493(2.1541) | Total Time 0.00(0.00)\n",
      "Iter 19770 | Time 22.6321(22.1963) | Bit/dim 3.4859(3.4973) | Xent 0.0019(0.0039) | Loss 8.8230(9.2689) | Error 0.0011(0.0011) Steps 844(815.89) | Grad Norm 1.3285(2.1815) | Total Time 0.00(0.00)\n",
      "Iter 19780 | Time 22.6627(22.2518) | Bit/dim 3.4582(3.4931) | Xent 0.0009(0.0037) | Loss 8.6492(9.1249) | Error 0.0000(0.0011) Steps 814(815.94) | Grad Norm 1.1968(2.0978) | Total Time 0.00(0.00)\n",
      "Iter 19790 | Time 22.3922(22.2528) | Bit/dim 3.4726(3.4923) | Xent 0.0031(0.0038) | Loss 8.6312(9.0242) | Error 0.0011(0.0010) Steps 826(813.82) | Grad Norm 1.4648(2.0897) | Total Time 0.00(0.00)\n",
      "Iter 19800 | Time 22.8718(22.2519) | Bit/dim 3.4861(3.4954) | Xent 0.0019(0.0039) | Loss 8.7594(8.9590) | Error 0.0011(0.0010) Steps 802(810.59) | Grad Norm 1.9553(2.0575) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0360 | Time 101.1249, Epoch Time 1349.2724(1332.4397), Bit/dim 3.5256(best: 3.5219), Xent 2.8018, Loss 4.9265, Error 0.3341(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19810 | Time 21.7351(22.3176) | Bit/dim 3.4788(3.4951) | Xent 0.0079(0.0036) | Loss 8.7672(9.5988) | Error 0.0011(0.0009) Steps 808(814.87) | Grad Norm 2.3518(2.0339) | Total Time 0.00(0.00)\n",
      "Iter 19820 | Time 21.6455(22.2588) | Bit/dim 3.5114(3.4961) | Xent 0.0014(0.0031) | Loss 8.8326(9.3743) | Error 0.0000(0.0008) Steps 808(815.05) | Grad Norm 1.0370(1.9156) | Total Time 0.00(0.00)\n",
      "Iter 19830 | Time 22.0687(22.3212) | Bit/dim 3.4901(3.4975) | Xent 0.0004(0.0028) | Loss 8.8042(9.2147) | Error 0.0000(0.0008) Steps 820(818.68) | Grad Norm 0.7700(1.7932) | Total Time 0.00(0.00)\n",
      "Iter 19840 | Time 22.5563(22.3088) | Bit/dim 3.4894(3.4957) | Xent 0.0009(0.0033) | Loss 8.7754(9.0823) | Error 0.0000(0.0009) Steps 796(816.12) | Grad Norm 0.8951(1.7795) | Total Time 0.00(0.00)\n",
      "Iter 19850 | Time 23.0284(22.3399) | Bit/dim 3.5187(3.4931) | Xent 0.0089(0.0034) | Loss 8.8718(8.9930) | Error 0.0022(0.0010) Steps 790(812.99) | Grad Norm 2.3093(1.8178) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0361 | Time 100.3593, Epoch Time 1349.1403(1332.9407), Bit/dim 3.5235(best: 3.5219), Xent 2.8258, Loss 4.9364, Error 0.3406(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19860 | Time 22.4569(22.3435) | Bit/dim 3.4665(3.4923) | Xent 0.0064(0.0033) | Loss 8.6966(9.7246) | Error 0.0033(0.0009) Steps 802(810.72) | Grad Norm 4.7685(2.0011) | Total Time 0.00(0.00)\n",
      "Iter 19870 | Time 23.1855(22.3034) | Bit/dim 3.4778(3.4921) | Xent 0.0018(0.0028) | Loss 8.8249(9.4646) | Error 0.0011(0.0008) Steps 826(812.76) | Grad Norm 1.4820(1.9663) | Total Time 0.00(0.00)\n",
      "Iter 19880 | Time 21.3844(22.3149) | Bit/dim 3.4974(3.4925) | Xent 0.0009(0.0028) | Loss 8.6870(9.2756) | Error 0.0000(0.0008) Steps 802(813.06) | Grad Norm 0.8711(1.9244) | Total Time 0.00(0.00)\n",
      "Iter 19890 | Time 21.7015(22.1897) | Bit/dim 3.5238(3.4947) | Xent 0.0009(0.0026) | Loss 8.7317(9.1349) | Error 0.0000(0.0007) Steps 814(813.39) | Grad Norm 0.9580(1.7663) | Total Time 0.00(0.00)\n",
      "Iter 19900 | Time 21.6932(22.2607) | Bit/dim 3.4708(3.4925) | Xent 0.0016(0.0028) | Loss 8.7630(9.0333) | Error 0.0000(0.0008) Steps 802(814.50) | Grad Norm 1.1304(1.7226) | Total Time 0.00(0.00)\n",
      "Iter 19910 | Time 22.5021(22.2788) | Bit/dim 3.4895(3.4931) | Xent 0.0026(0.0030) | Loss 8.7481(8.9489) | Error 0.0011(0.0008) Steps 790(809.88) | Grad Norm 2.4392(1.9030) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0362 | Time 100.2438, Epoch Time 1344.7201(1333.2941), Bit/dim 3.5254(best: 3.5219), Xent 2.8094, Loss 4.9301, Error 0.3365(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19920 | Time 22.0534(22.3471) | Bit/dim 3.5177(3.4968) | Xent 0.0211(0.0042) | Loss 8.7969(9.5721) | Error 0.0056(0.0010) Steps 814(814.12) | Grad Norm 5.8962(2.0382) | Total Time 0.00(0.00)\n",
      "Iter 19930 | Time 22.1200(22.4155) | Bit/dim 3.4792(3.4933) | Xent 0.0007(0.0038) | Loss 8.6938(9.3446) | Error 0.0000(0.0009) Steps 838(814.09) | Grad Norm 0.8828(1.9389) | Total Time 0.00(0.00)\n",
      "Iter 19940 | Time 23.2506(22.5095) | Bit/dim 3.4842(3.4919) | Xent 0.0015(0.0036) | Loss 8.7680(9.1904) | Error 0.0000(0.0009) Steps 802(813.20) | Grad Norm 0.9607(1.9784) | Total Time 0.00(0.00)\n",
      "Iter 19950 | Time 22.1842(22.4424) | Bit/dim 3.4748(3.4945) | Xent 0.0035(0.0044) | Loss 8.7091(9.0833) | Error 0.0022(0.0011) Steps 808(812.55) | Grad Norm 2.8812(2.0992) | Total Time 0.00(0.00)\n",
      "Iter 19960 | Time 21.7228(22.3617) | Bit/dim 3.5048(3.4938) | Xent 0.0007(0.0041) | Loss 8.7488(8.9869) | Error 0.0000(0.0010) Steps 826(813.87) | Grad Norm 1.2305(2.1371) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0363 | Time 100.1951, Epoch Time 1357.5642(1334.0222), Bit/dim 3.5247(best: 3.5219), Xent 2.7976, Loss 4.9235, Error 0.3382(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 19970 | Time 22.1968(22.3297) | Bit/dim 3.4817(3.4969) | Xent 0.0051(0.0038) | Loss 8.5324(9.7008) | Error 0.0011(0.0009) Steps 766(811.33) | Grad Norm 1.5646(2.0578) | Total Time 0.00(0.00)\n",
      "Iter 19980 | Time 23.0487(22.4255) | Bit/dim 3.5280(3.4968) | Xent 0.0006(0.0035) | Loss 8.7773(9.4518) | Error 0.0000(0.0009) Steps 802(811.99) | Grad Norm 0.9399(2.0385) | Total Time 0.00(0.00)\n",
      "Iter 19990 | Time 21.7276(22.3492) | Bit/dim 3.4869(3.4970) | Xent 0.0004(0.0035) | Loss 8.7058(9.2651) | Error 0.0000(0.0009) Steps 820(813.31) | Grad Norm 1.1849(2.2009) | Total Time 0.00(0.00)\n",
      "Iter 20000 | Time 21.4550(22.2477) | Bit/dim 3.4727(3.4972) | Xent 0.0008(0.0037) | Loss 8.6497(9.1269) | Error 0.0000(0.0008) Steps 814(814.67) | Grad Norm 0.9738(2.1361) | Total Time 0.00(0.00)\n",
      "Iter 20010 | Time 22.3647(22.3430) | Bit/dim 3.4737(3.4956) | Xent 0.0171(0.0038) | Loss 8.7738(9.0271) | Error 0.0022(0.0009) Steps 832(817.75) | Grad Norm 1.6251(2.1552) | Total Time 0.00(0.00)\n",
      "Iter 20020 | Time 21.9891(22.3422) | Bit/dim 3.5029(3.4957) | Xent 0.0123(0.0043) | Loss 8.7554(8.9543) | Error 0.0044(0.0011) Steps 802(816.69) | Grad Norm 4.2435(2.3795) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0364 | Time 101.1004, Epoch Time 1351.3185(1334.5411), Bit/dim 3.5272(best: 3.5219), Xent 2.7983, Loss 4.9263, Error 0.3354(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20030 | Time 21.5573(22.3485) | Bit/dim 3.5021(3.4951) | Xent 0.0009(0.0043) | Loss 8.7647(9.5789) | Error 0.0000(0.0011) Steps 814(818.42) | Grad Norm 0.9941(2.1995) | Total Time 0.00(0.00)\n",
      "Iter 20040 | Time 21.8005(22.3292) | Bit/dim 3.4779(3.4931) | Xent 0.0010(0.0043) | Loss 8.5898(9.3468) | Error 0.0000(0.0010) Steps 802(815.24) | Grad Norm 1.0153(2.1081) | Total Time 0.00(0.00)\n",
      "Iter 20050 | Time 22.1523(22.3380) | Bit/dim 3.5182(3.4948) | Xent 0.0008(0.0042) | Loss 8.6583(9.1949) | Error 0.0000(0.0010) Steps 808(817.37) | Grad Norm 1.3567(2.1050) | Total Time 0.00(0.00)\n",
      "Iter 20060 | Time 22.8913(22.3952) | Bit/dim 3.5039(3.4932) | Xent 0.0045(0.0040) | Loss 8.7633(9.0751) | Error 0.0011(0.0009) Steps 832(818.20) | Grad Norm 1.3890(2.0361) | Total Time 0.00(0.00)\n",
      "Iter 20070 | Time 21.7428(22.3085) | Bit/dim 3.5255(3.4956) | Xent 0.0091(0.0040) | Loss 8.8043(8.9889) | Error 0.0022(0.0010) Steps 808(819.39) | Grad Norm 3.8374(2.0637) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0365 | Time 101.0761, Epoch Time 1347.5495(1334.9313), Bit/dim 3.5230(best: 3.5219), Xent 2.7747, Loss 4.9104, Error 0.3348(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20080 | Time 22.6859(22.2728) | Bit/dim 3.4937(3.4969) | Xent 0.0011(0.0041) | Loss 8.8256(9.7361) | Error 0.0000(0.0010) Steps 862(819.66) | Grad Norm 1.0914(2.0397) | Total Time 0.00(0.00)\n",
      "Iter 20090 | Time 21.7397(22.2427) | Bit/dim 3.5118(3.4953) | Xent 0.0024(0.0037) | Loss 8.7041(9.4715) | Error 0.0011(0.0009) Steps 832(817.82) | Grad Norm 2.3605(1.9745) | Total Time 0.00(0.00)\n",
      "Iter 20100 | Time 22.0084(22.2412) | Bit/dim 3.5250(3.4980) | Xent 0.0059(0.0034) | Loss 8.7687(9.2866) | Error 0.0022(0.0008) Steps 808(821.04) | Grad Norm 3.4087(1.9322) | Total Time 0.00(0.00)\n",
      "Iter 20110 | Time 22.9269(22.3039) | Bit/dim 3.5025(3.4986) | Xent 0.0006(0.0038) | Loss 8.7912(9.1539) | Error 0.0000(0.0010) Steps 862(820.19) | Grad Norm 1.2266(2.0453) | Total Time 0.00(0.00)\n",
      "Iter 20120 | Time 21.6487(22.2402) | Bit/dim 3.4912(3.4954) | Xent 0.0086(0.0046) | Loss 8.6531(9.0440) | Error 0.0033(0.0012) Steps 790(819.40) | Grad Norm 4.0497(2.3010) | Total Time 0.00(0.00)\n",
      "Iter 20130 | Time 21.9475(22.2960) | Bit/dim 3.5061(3.4969) | Xent 0.0006(0.0049) | Loss 8.8708(8.9751) | Error 0.0000(0.0012) Steps 820(819.63) | Grad Norm 1.6918(2.4188) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0366 | Time 102.3156, Epoch Time 1347.8321(1335.3183), Bit/dim 3.5277(best: 3.5219), Xent 2.7548, Loss 4.9051, Error 0.3347(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20140 | Time 22.6850(22.3628) | Bit/dim 3.4816(3.4949) | Xent 0.0011(0.0044) | Loss 8.6748(9.5721) | Error 0.0000(0.0011) Steps 802(816.88) | Grad Norm 1.4883(2.3493) | Total Time 0.00(0.00)\n",
      "Iter 20150 | Time 22.9105(22.3706) | Bit/dim 3.5174(3.4948) | Xent 0.0014(0.0039) | Loss 8.8209(9.3520) | Error 0.0000(0.0010) Steps 796(814.45) | Grad Norm 1.1383(2.1621) | Total Time 0.00(0.00)\n",
      "Iter 20160 | Time 22.1157(22.3465) | Bit/dim 3.5295(3.4955) | Xent 0.0010(0.0042) | Loss 8.7447(9.1976) | Error 0.0000(0.0010) Steps 832(814.34) | Grad Norm 1.1827(2.2558) | Total Time 0.00(0.00)\n",
      "Iter 20170 | Time 21.8533(22.3380) | Bit/dim 3.5343(3.4942) | Xent 0.0018(0.0037) | Loss 8.6735(9.0761) | Error 0.0011(0.0009) Steps 790(813.36) | Grad Norm 1.8100(2.1000) | Total Time 0.00(0.00)\n",
      "Iter 20180 | Time 22.2330(22.2782) | Bit/dim 3.5010(3.4958) | Xent 0.0006(0.0038) | Loss 8.7750(8.9875) | Error 0.0000(0.0010) Steps 814(814.95) | Grad Norm 1.1455(2.0898) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0367 | Time 101.7862, Epoch Time 1350.4044(1335.7709), Bit/dim 3.5258(best: 3.5219), Xent 2.7873, Loss 4.9195, Error 0.3337(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20190 | Time 21.9596(22.3485) | Bit/dim 3.5379(3.5007) | Xent 0.0151(0.0039) | Loss 8.8164(9.7149) | Error 0.0011(0.0009) Steps 814(815.90) | Grad Norm 1.3618(1.9596) | Total Time 0.00(0.00)\n",
      "Iter 20200 | Time 23.9069(22.4066) | Bit/dim 3.4992(3.4993) | Xent 0.0037(0.0034) | Loss 8.6144(9.4561) | Error 0.0011(0.0008) Steps 808(813.46) | Grad Norm 1.9332(1.8236) | Total Time 0.00(0.00)\n",
      "Iter 20210 | Time 22.8203(22.4434) | Bit/dim 3.4990(3.4972) | Xent 0.0006(0.0032) | Loss 8.6385(9.2557) | Error 0.0000(0.0008) Steps 808(812.38) | Grad Norm 0.8978(1.6834) | Total Time 0.00(0.00)\n",
      "Iter 20220 | Time 21.9952(22.4210) | Bit/dim 3.4553(3.4938) | Xent 0.0012(0.0027) | Loss 8.7642(9.1206) | Error 0.0000(0.0007) Steps 832(812.45) | Grad Norm 0.8565(1.5812) | Total Time 0.00(0.00)\n",
      "Iter 20230 | Time 22.3108(22.4320) | Bit/dim 3.4972(3.4952) | Xent 0.0005(0.0029) | Loss 8.8212(9.0271) | Error 0.0000(0.0008) Steps 814(811.46) | Grad Norm 1.1212(1.7543) | Total Time 0.00(0.00)\n",
      "Iter 20240 | Time 21.9118(22.4053) | Bit/dim 3.5390(3.4952) | Xent 0.0005(0.0031) | Loss 8.8310(8.9537) | Error 0.0000(0.0008) Steps 826(812.70) | Grad Norm 0.7265(1.8117) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0368 | Time 100.5724, Epoch Time 1356.1694(1336.3829), Bit/dim 3.5224(best: 3.5219), Xent 2.7648, Loss 4.9047, Error 0.3345(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20250 | Time 21.5800(22.3805) | Bit/dim 3.5295(3.4971) | Xent 0.0131(0.0035) | Loss 8.8399(9.5901) | Error 0.0022(0.0009) Steps 766(811.94) | Grad Norm 4.8927(1.9149) | Total Time 0.00(0.00)\n",
      "Iter 20260 | Time 24.0406(22.4597) | Bit/dim 3.5022(3.4969) | Xent 0.0006(0.0039) | Loss 8.8459(9.3766) | Error 0.0000(0.0011) Steps 802(812.85) | Grad Norm 1.5478(2.2860) | Total Time 0.00(0.00)\n",
      "Iter 20270 | Time 21.9381(22.4676) | Bit/dim 3.4667(3.4963) | Xent 0.0006(0.0048) | Loss 8.6212(9.2161) | Error 0.0000(0.0012) Steps 796(812.86) | Grad Norm 1.0410(2.4001) | Total Time 0.00(0.00)\n",
      "Iter 20280 | Time 21.9017(22.3937) | Bit/dim 3.4710(3.4950) | Xent 0.0020(0.0044) | Loss 8.7863(9.0891) | Error 0.0000(0.0011) Steps 820(814.84) | Grad Norm 1.8502(2.3933) | Total Time 0.00(0.00)\n",
      "Iter 20290 | Time 22.6057(22.4315) | Bit/dim 3.4892(3.4949) | Xent 0.0017(0.0040) | Loss 8.7409(9.0029) | Error 0.0000(0.0010) Steps 796(817.35) | Grad Norm 1.1541(2.3562) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0369 | Time 101.7883, Epoch Time 1356.6222(1336.9901), Bit/dim 3.5259(best: 3.5219), Xent 2.7779, Loss 4.9148, Error 0.3345(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20300 | Time 22.5757(22.4281) | Bit/dim 3.5151(3.4989) | Xent 0.0020(0.0036) | Loss 8.8714(9.7325) | Error 0.0011(0.0010) Steps 796(816.14) | Grad Norm 2.1002(2.2448) | Total Time 0.00(0.00)\n",
      "Iter 20310 | Time 22.2262(22.4995) | Bit/dim 3.4985(3.4955) | Xent 0.0103(0.0034) | Loss 8.6446(9.4665) | Error 0.0022(0.0009) Steps 814(814.53) | Grad Norm 3.7171(2.1818) | Total Time 0.00(0.00)\n",
      "Iter 20320 | Time 22.2015(22.4636) | Bit/dim 3.5247(3.4960) | Xent 0.0015(0.0033) | Loss 8.8434(9.2800) | Error 0.0011(0.0009) Steps 844(818.27) | Grad Norm 1.6037(2.1234) | Total Time 0.00(0.00)\n",
      "Iter 20330 | Time 21.9743(22.4276) | Bit/dim 3.5010(3.4960) | Xent 0.0009(0.0038) | Loss 8.8584(9.1394) | Error 0.0000(0.0009) Steps 808(816.64) | Grad Norm 1.5616(2.1138) | Total Time 0.00(0.00)\n",
      "Iter 20340 | Time 21.3954(22.3561) | Bit/dim 3.4976(3.4958) | Xent 0.0021(0.0038) | Loss 8.6697(9.0258) | Error 0.0011(0.0010) Steps 784(815.20) | Grad Norm 1.4088(2.0592) | Total Time 0.00(0.00)\n",
      "Iter 20350 | Time 22.2227(22.3725) | Bit/dim 3.4946(3.4967) | Xent 0.0059(0.0047) | Loss 8.7263(8.9515) | Error 0.0011(0.0012) Steps 838(814.04) | Grad Norm 3.6375(2.3855) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0370 | Time 101.9096, Epoch Time 1353.9739(1337.4996), Bit/dim 3.5311(best: 3.5219), Xent 2.7549, Loss 4.9086, Error 0.3318(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20360 | Time 22.3216(22.3535) | Bit/dim 3.4951(3.5004) | Xent 0.0093(0.0048) | Loss 8.6292(9.6002) | Error 0.0011(0.0012) Steps 826(816.36) | Grad Norm 1.7820(2.4256) | Total Time 0.00(0.00)\n",
      "Iter 20370 | Time 22.1372(22.3604) | Bit/dim 3.4651(3.4991) | Xent 0.0021(0.0041) | Loss 8.7298(9.3718) | Error 0.0011(0.0011) Steps 808(814.91) | Grad Norm 1.4491(2.2001) | Total Time 0.00(0.00)\n",
      "Iter 20380 | Time 23.1012(22.3405) | Bit/dim 3.4656(3.4984) | Xent 0.0046(0.0038) | Loss 8.6476(9.2032) | Error 0.0011(0.0010) Steps 820(815.56) | Grad Norm 1.9037(2.2861) | Total Time 0.00(0.00)\n",
      "Iter 20390 | Time 22.6032(22.3327) | Bit/dim 3.5182(3.4960) | Xent 0.0036(0.0040) | Loss 8.8489(9.0747) | Error 0.0011(0.0012) Steps 838(817.76) | Grad Norm 1.5517(2.3630) | Total Time 0.00(0.00)\n",
      "Iter 20400 | Time 22.9416(22.3093) | Bit/dim 3.4566(3.4937) | Xent 0.0061(0.0044) | Loss 8.6394(8.9826) | Error 0.0033(0.0013) Steps 826(816.67) | Grad Norm 4.1009(2.3345) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0371 | Time 102.1097, Epoch Time 1356.0020(1338.0546), Bit/dim 3.5268(best: 3.5219), Xent 2.7520, Loss 4.9028, Error 0.3321(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20410 | Time 22.1196(22.3774) | Bit/dim 3.4970(3.4959) | Xent 0.0018(0.0042) | Loss 8.8230(9.7152) | Error 0.0000(0.0012) Steps 832(815.93) | Grad Norm 2.5984(2.2682) | Total Time 0.00(0.00)\n",
      "Iter 20420 | Time 22.2709(22.3867) | Bit/dim 3.4737(3.4954) | Xent 0.0033(0.0039) | Loss 8.6257(9.4604) | Error 0.0011(0.0011) Steps 838(816.71) | Grad Norm 1.9728(2.1710) | Total Time 0.00(0.00)\n",
      "Iter 20430 | Time 23.7085(22.3799) | Bit/dim 3.5029(3.4982) | Xent 0.0003(0.0036) | Loss 8.7151(9.2732) | Error 0.0000(0.0009) Steps 844(816.23) | Grad Norm 1.1982(2.0731) | Total Time 0.00(0.00)\n",
      "Iter 20440 | Time 22.2976(22.3370) | Bit/dim 3.5001(3.4985) | Xent 0.0073(0.0033) | Loss 8.6943(9.1344) | Error 0.0022(0.0009) Steps 820(813.49) | Grad Norm 4.4095(2.0800) | Total Time 0.00(0.00)\n",
      "Iter 20450 | Time 22.3460(22.3131) | Bit/dim 3.4863(3.4975) | Xent 0.0017(0.0031) | Loss 8.7205(9.0213) | Error 0.0011(0.0009) Steps 820(814.12) | Grad Norm 1.5076(2.1374) | Total Time 0.00(0.00)\n",
      "Iter 20460 | Time 21.3821(22.3249) | Bit/dim 3.4820(3.4970) | Xent 0.0013(0.0029) | Loss 8.5649(8.9517) | Error 0.0000(0.0008) Steps 802(816.65) | Grad Norm 1.2209(2.1383) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0372 | Time 100.2712, Epoch Time 1349.3798(1338.3944), Bit/dim 3.5223(best: 3.5219), Xent 2.8382, Loss 4.9414, Error 0.3368(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20470 | Time 22.3681(22.3619) | Bit/dim 3.5081(3.4964) | Xent 0.0138(0.0032) | Loss 8.8599(9.5860) | Error 0.0022(0.0008) Steps 814(818.10) | Grad Norm 3.9865(2.0812) | Total Time 0.00(0.00)\n",
      "Iter 20480 | Time 23.2779(22.4152) | Bit/dim 3.4907(3.4950) | Xent 0.0019(0.0038) | Loss 8.6446(9.3527) | Error 0.0011(0.0011) Steps 802(817.70) | Grad Norm 1.9443(2.0471) | Total Time 0.00(0.00)\n",
      "Iter 20490 | Time 22.5940(22.4347) | Bit/dim 3.4812(3.4933) | Xent 0.0019(0.0033) | Loss 8.8347(9.2030) | Error 0.0011(0.0010) Steps 838(820.25) | Grad Norm 0.8053(1.7979) | Total Time 0.00(0.00)\n",
      "Iter 20500 | Time 22.6825(22.4132) | Bit/dim 3.4829(3.4942) | Xent 0.0005(0.0032) | Loss 8.6845(9.0751) | Error 0.0000(0.0009) Steps 820(818.15) | Grad Norm 0.9174(1.6898) | Total Time 0.00(0.00)\n",
      "Iter 20510 | Time 21.6535(22.3656) | Bit/dim 3.5170(3.4965) | Xent 0.0023(0.0028) | Loss 8.7380(8.9831) | Error 0.0011(0.0009) Steps 790(816.84) | Grad Norm 3.0196(1.7040) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0373 | Time 101.2572, Epoch Time 1355.5666(1338.9096), Bit/dim 3.5270(best: 3.5219), Xent 2.8507, Loss 4.9523, Error 0.3357(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20520 | Time 23.7246(22.3999) | Bit/dim 3.4802(3.4949) | Xent 0.0009(0.0027) | Loss 8.7836(9.7153) | Error 0.0000(0.0007) Steps 838(818.19) | Grad Norm 1.3641(1.7061) | Total Time 0.00(0.00)\n",
      "Iter 20530 | Time 22.5142(22.4551) | Bit/dim 3.4969(3.4959) | Xent 0.0009(0.0026) | Loss 8.7889(9.4601) | Error 0.0000(0.0007) Steps 808(817.84) | Grad Norm 1.1773(1.5926) | Total Time 0.00(0.00)\n",
      "Iter 20540 | Time 21.5333(22.4166) | Bit/dim 3.4759(3.4952) | Xent 0.0054(0.0027) | Loss 8.8293(9.2733) | Error 0.0022(0.0008) Steps 802(815.37) | Grad Norm 2.7637(1.7142) | Total Time 0.00(0.00)\n",
      "Iter 20550 | Time 22.7610(22.3470) | Bit/dim 3.4745(3.4967) | Xent 0.0003(0.0031) | Loss 8.6954(9.1345) | Error 0.0000(0.0009) Steps 820(812.70) | Grad Norm 2.3178(1.9415) | Total Time 0.00(0.00)\n",
      "Iter 20560 | Time 22.3667(22.3670) | Bit/dim 3.5366(3.4970) | Xent 0.0050(0.0040) | Loss 8.8744(9.0344) | Error 0.0022(0.0010) Steps 820(816.19) | Grad Norm 3.1548(2.1103) | Total Time 0.00(0.00)\n",
      "Iter 20570 | Time 21.8056(22.3254) | Bit/dim 3.4870(3.4948) | Xent 0.0009(0.0035) | Loss 8.7157(8.9533) | Error 0.0000(0.0009) Steps 760(812.72) | Grad Norm 1.8441(2.1177) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0374 | Time 101.8430, Epoch Time 1351.0482(1339.2737), Bit/dim 3.5232(best: 3.5219), Xent 2.8276, Loss 4.9370, Error 0.3374(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20580 | Time 22.4072(22.3769) | Bit/dim 3.5023(3.4965) | Xent 0.0062(0.0036) | Loss 8.7282(9.5697) | Error 0.0011(0.0009) Steps 790(812.23) | Grad Norm 3.3259(2.3643) | Total Time 0.00(0.00)\n",
      "Iter 20590 | Time 22.4402(22.4100) | Bit/dim 3.5227(3.4950) | Xent 0.0132(0.0038) | Loss 8.6797(9.3407) | Error 0.0033(0.0010) Steps 826(814.62) | Grad Norm 5.2378(2.5222) | Total Time 0.00(0.00)\n",
      "Iter 20600 | Time 21.9730(22.4552) | Bit/dim 3.5285(3.4956) | Xent 0.0107(0.0039) | Loss 8.8307(9.1989) | Error 0.0022(0.0010) Steps 832(815.83) | Grad Norm 4.3682(2.5460) | Total Time 0.00(0.00)\n",
      "Iter 20610 | Time 22.6365(22.4434) | Bit/dim 3.4786(3.4973) | Xent 0.0042(0.0040) | Loss 8.6794(9.0834) | Error 0.0022(0.0011) Steps 790(817.31) | Grad Norm 2.9202(2.3667) | Total Time 0.00(0.00)\n",
      "Iter 20620 | Time 22.7069(22.3669) | Bit/dim 3.4917(3.4986) | Xent 0.0031(0.0039) | Loss 8.7292(8.9974) | Error 0.0022(0.0011) Steps 832(817.60) | Grad Norm 2.6943(2.1740) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0375 | Time 101.9844, Epoch Time 1358.0659(1339.8375), Bit/dim 3.5260(best: 3.5219), Xent 2.7803, Loss 4.9162, Error 0.3341(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20630 | Time 22.6080(22.4100) | Bit/dim 3.4812(3.4971) | Xent 0.0062(0.0041) | Loss 8.7132(9.7321) | Error 0.0011(0.0012) Steps 820(817.00) | Grad Norm 2.9573(2.3020) | Total Time 0.00(0.00)\n",
      "Iter 20640 | Time 23.3294(22.4757) | Bit/dim 3.4780(3.4945) | Xent 0.0021(0.0043) | Loss 8.6622(9.4644) | Error 0.0011(0.0011) Steps 814(813.78) | Grad Norm 1.4992(2.2326) | Total Time 0.00(0.00)\n",
      "Iter 20650 | Time 22.4400(22.5120) | Bit/dim 3.5049(3.4937) | Xent 0.0010(0.0040) | Loss 8.7618(9.2714) | Error 0.0000(0.0011) Steps 820(815.34) | Grad Norm 1.4015(2.2505) | Total Time 0.00(0.00)\n",
      "Iter 20660 | Time 22.6994(22.5647) | Bit/dim 3.4902(3.4955) | Xent 0.0004(0.0038) | Loss 8.8396(9.1395) | Error 0.0000(0.0010) Steps 844(816.35) | Grad Norm 1.4198(2.2583) | Total Time 0.00(0.00)\n",
      "Iter 20670 | Time 23.0729(22.5950) | Bit/dim 3.4898(3.4990) | Xent 0.0011(0.0035) | Loss 8.8134(9.0504) | Error 0.0000(0.0008) Steps 850(819.46) | Grad Norm 1.2646(2.1138) | Total Time 0.00(0.00)\n",
      "Iter 20680 | Time 22.2862(22.5011) | Bit/dim 3.5230(3.4993) | Xent 0.0018(0.0030) | Loss 8.8091(8.9717) | Error 0.0011(0.0007) Steps 802(819.29) | Grad Norm 1.6754(1.9993) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0376 | Time 101.1312, Epoch Time 1361.7541(1340.4950), Bit/dim 3.5260(best: 3.5219), Xent 2.8438, Loss 4.9478, Error 0.3365(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20690 | Time 21.4046(22.4714) | Bit/dim 3.4966(3.5000) | Xent 0.0031(0.0028) | Loss 8.7668(9.5737) | Error 0.0011(0.0007) Steps 814(816.32) | Grad Norm 2.4335(2.0042) | Total Time 0.00(0.00)\n",
      "Iter 20700 | Time 22.3489(22.4574) | Bit/dim 3.4573(3.4976) | Xent 0.0053(0.0038) | Loss 8.5906(9.3539) | Error 0.0011(0.0009) Steps 832(815.72) | Grad Norm 3.9092(2.0840) | Total Time 0.00(0.00)\n",
      "Iter 20710 | Time 22.9670(22.5953) | Bit/dim 3.4957(3.5008) | Xent 0.0086(0.0042) | Loss 8.6952(9.2076) | Error 0.0011(0.0011) Steps 808(816.06) | Grad Norm 3.6690(2.6775) | Total Time 0.00(0.00)\n",
      "Iter 20720 | Time 22.0509(22.5252) | Bit/dim 3.5472(3.5027) | Xent 0.0120(0.0047) | Loss 8.8719(9.0949) | Error 0.0011(0.0010) Steps 802(817.31) | Grad Norm 5.1762(3.0195) | Total Time 0.00(0.00)\n",
      "Iter 20730 | Time 23.7364(22.5718) | Bit/dim 3.5142(3.5032) | Xent 0.0020(0.0046) | Loss 8.7419(9.0018) | Error 0.0011(0.0011) Steps 838(818.37) | Grad Norm 2.7069(2.8698) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0377 | Time 100.7977, Epoch Time 1362.2915(1341.1489), Bit/dim 3.5376(best: 3.5219), Xent 2.8315, Loss 4.9533, Error 0.3361(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20740 | Time 22.7161(22.7118) | Bit/dim 3.5243(3.5051) | Xent 0.0025(0.0052) | Loss 8.8667(9.7379) | Error 0.0000(0.0013) Steps 820(819.39) | Grad Norm 1.7964(3.0809) | Total Time 0.00(0.00)\n",
      "Iter 20750 | Time 23.0209(22.7259) | Bit/dim 3.5420(3.5092) | Xent 0.0016(0.0056) | Loss 8.9585(9.4962) | Error 0.0011(0.0015) Steps 844(819.52) | Grad Norm 3.5931(3.1869) | Total Time 0.00(0.00)\n",
      "Iter 20760 | Time 22.7848(22.7320) | Bit/dim 3.5148(3.5097) | Xent 0.0108(0.0051) | Loss 8.7709(9.3017) | Error 0.0033(0.0014) Steps 820(819.74) | Grad Norm 6.1968(3.1746) | Total Time 0.00(0.00)\n",
      "Iter 20770 | Time 23.5860(22.9147) | Bit/dim 3.5342(3.5114) | Xent 0.0018(0.0050) | Loss 8.9157(9.1695) | Error 0.0011(0.0015) Steps 868(821.85) | Grad Norm 2.0622(3.0765) | Total Time 0.00(0.00)\n",
      "Iter 20780 | Time 22.9938(22.9858) | Bit/dim 3.5350(3.5148) | Xent 0.0017(0.0048) | Loss 8.8419(9.0667) | Error 0.0011(0.0013) Steps 838(824.95) | Grad Norm 1.6173(2.9374) | Total Time 0.00(0.00)\n",
      "Iter 20790 | Time 23.1630(23.0588) | Bit/dim 3.5323(3.5136) | Xent 0.0093(0.0051) | Loss 8.9856(9.0028) | Error 0.0022(0.0013) Steps 862(828.10) | Grad Norm 3.4438(2.8925) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0378 | Time 102.8446, Epoch Time 1394.4441(1342.7477), Bit/dim 3.5504(best: 3.5219), Xent 2.7892, Loss 4.9450, Error 0.3357(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20800 | Time 22.7819(23.0505) | Bit/dim 3.4905(3.5152) | Xent 0.0110(0.0057) | Loss 8.8657(9.6224) | Error 0.0033(0.0016) Steps 832(827.02) | Grad Norm 4.8629(3.0351) | Total Time 0.00(0.00)\n",
      "Iter 20810 | Time 22.7893(23.1448) | Bit/dim 3.5333(3.5194) | Xent 0.0064(0.0062) | Loss 8.7046(9.4055) | Error 0.0011(0.0018) Steps 814(828.49) | Grad Norm 4.3157(3.3177) | Total Time 0.00(0.00)\n",
      "Iter 20820 | Time 22.6111(23.1945) | Bit/dim 3.5433(3.5232) | Xent 0.0081(0.0069) | Loss 8.8394(9.2548) | Error 0.0011(0.0018) Steps 814(826.48) | Grad Norm 6.5495(3.6054) | Total Time 0.00(0.00)\n",
      "Iter 20830 | Time 24.8448(23.4007) | Bit/dim 3.5547(3.5275) | Xent 0.0032(0.0075) | Loss 8.9355(9.1413) | Error 0.0011(0.0019) Steps 880(831.23) | Grad Norm 4.0132(3.8605) | Total Time 0.00(0.00)\n",
      "Iter 20840 | Time 23.2173(23.3552) | Bit/dim 3.5427(3.5332) | Xent 0.0005(0.0074) | Loss 8.8920(9.0629) | Error 0.0000(0.0018) Steps 826(831.77) | Grad Norm 3.0738(4.1283) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0379 | Time 104.5266, Epoch Time 1412.7896(1344.8490), Bit/dim 3.5733(best: 3.5219), Xent 2.7160, Loss 4.9313, Error 0.3312(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20850 | Time 23.6871(23.4663) | Bit/dim 3.5408(3.5353) | Xent 0.0025(0.0069) | Loss 8.8137(9.8161) | Error 0.0011(0.0018) Steps 874(836.71) | Grad Norm 4.3548(4.2572) | Total Time 0.00(0.00)\n",
      "Iter 20860 | Time 23.2447(23.5505) | Bit/dim 3.5600(3.5428) | Xent 0.0037(0.0066) | Loss 9.0298(9.5733) | Error 0.0022(0.0018) Steps 850(836.08) | Grad Norm 4.5807(4.5242) | Total Time 0.00(0.00)\n",
      "Iter 20870 | Time 22.5360(23.5506) | Bit/dim 3.5598(3.5441) | Xent 0.0150(0.0063) | Loss 8.7887(9.3770) | Error 0.0022(0.0016) Steps 808(836.10) | Grad Norm 3.7153(4.2566) | Total Time 0.00(0.00)\n",
      "Iter 20880 | Time 24.2994(23.6382) | Bit/dim 3.5182(3.5426) | Xent 0.0175(0.0069) | Loss 8.8630(9.2409) | Error 0.0044(0.0017) Steps 856(834.76) | Grad Norm 4.8622(4.4371) | Total Time 0.00(0.00)\n",
      "Iter 20890 | Time 22.6441(23.6605) | Bit/dim 3.5557(3.5458) | Xent 0.0091(0.0069) | Loss 8.8052(9.1409) | Error 0.0022(0.0017) Steps 826(834.93) | Grad Norm 6.9881(5.1673) | Total Time 0.00(0.00)\n",
      "Iter 20900 | Time 24.0214(23.7564) | Bit/dim 3.5687(3.5458) | Xent 0.0067(0.0063) | Loss 8.9293(9.0774) | Error 0.0022(0.0016) Steps 814(833.59) | Grad Norm 4.3300(4.9167) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0380 | Time 105.0570, Epoch Time 1436.4271(1347.5963), Bit/dim 3.5839(best: 3.5219), Xent 2.7357, Loss 4.9517, Error 0.3309(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20910 | Time 23.0464(23.7442) | Bit/dim 3.5481(3.5446) | Xent 0.0207(0.0066) | Loss 8.8518(9.7029) | Error 0.0033(0.0016) Steps 820(831.19) | Grad Norm 4.8055(4.6098) | Total Time 0.00(0.00)\n",
      "Iter 20920 | Time 23.1882(23.7825) | Bit/dim 3.5656(3.5466) | Xent 0.0123(0.0071) | Loss 8.8171(9.4777) | Error 0.0022(0.0017) Steps 820(837.35) | Grad Norm 3.7555(4.6583) | Total Time 0.00(0.00)\n",
      "Iter 20930 | Time 24.2752(23.8162) | Bit/dim 3.5666(3.5513) | Xent 0.0017(0.0070) | Loss 9.0135(9.3244) | Error 0.0000(0.0016) Steps 838(834.34) | Grad Norm 5.3917(4.6721) | Total Time 0.00(0.00)\n",
      "Iter 20940 | Time 23.3404(23.7850) | Bit/dim 3.5944(3.5530) | Xent 0.0168(0.0067) | Loss 9.0457(9.2078) | Error 0.0033(0.0017) Steps 844(834.96) | Grad Norm 6.0038(4.6822) | Total Time 0.00(0.00)\n",
      "Iter 20950 | Time 24.3345(23.8714) | Bit/dim 3.5850(3.5573) | Xent 0.0150(0.0067) | Loss 8.9615(9.1304) | Error 0.0022(0.0016) Steps 838(833.13) | Grad Norm 6.0758(5.0659) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0381 | Time 103.9716, Epoch Time 1437.9227(1350.3061), Bit/dim 3.6539(best: 3.5219), Xent 2.7401, Loss 5.0240, Error 0.3324(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 20960 | Time 24.7120(23.9376) | Bit/dim 3.6789(3.5812) | Xent 0.0062(0.0074) | Loss 9.1761(9.9232) | Error 0.0022(0.0019) Steps 874(839.42) | Grad Norm 42.1866(9.1175) | Total Time 0.00(0.00)\n",
      "Iter 20970 | Time 25.1859(24.0024) | Bit/dim 3.6525(3.6019) | Xent 0.0267(0.0087) | Loss 9.1299(9.7222) | Error 0.0111(0.0024) Steps 850(842.03) | Grad Norm 49.8494(25.0208) | Total Time 0.00(0.00)\n",
      "Iter 20980 | Time 24.1300(24.1256) | Bit/dim 3.6754(3.6238) | Xent 0.0140(0.0130) | Loss 9.1855(9.5809) | Error 0.0044(0.0033) Steps 868(846.03) | Grad Norm 19.2874(30.9056) | Total Time 0.00(0.00)\n",
      "Iter 20990 | Time 24.7000(24.2009) | Bit/dim 3.6226(3.6327) | Xent 0.0279(0.0144) | Loss 9.0422(9.4669) | Error 0.0089(0.0037) Steps 826(844.53) | Grad Norm 12.2170(29.8466) | Total Time 0.00(0.00)\n",
      "Iter 21000 | Time 23.8384(24.0546) | Bit/dim 3.6404(3.6332) | Xent 0.0154(0.0133) | Loss 9.1196(9.3613) | Error 0.0033(0.0033) Steps 850(842.40) | Grad Norm 33.9968(29.6717) | Total Time 0.00(0.00)\n",
      "Iter 21010 | Time 24.8436(24.0304) | Bit/dim 3.7048(3.6444) | Xent 0.0061(0.0131) | Loss 9.2562(9.3082) | Error 0.0022(0.0034) Steps 868(843.99) | Grad Norm 43.7088(43.7028) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0382 | Time 104.8248, Epoch Time 1451.8761(1353.3532), Bit/dim 3.6971(best: 3.5219), Xent 2.5864, Loss 4.9903, Error 0.3279(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21020 | Time 23.7798(24.1085) | Bit/dim 3.6205(3.6481) | Xent 0.0149(0.0156) | Loss 9.1729(9.9566) | Error 0.0033(0.0041) Steps 856(846.16) | Grad Norm 5.0575(41.6312) | Total Time 0.00(0.00)\n",
      "Iter 21030 | Time 23.3555(23.9734) | Bit/dim 3.5932(3.6436) | Xent 0.0185(0.0167) | Loss 8.9092(9.7107) | Error 0.0067(0.0048) Steps 826(841.52) | Grad Norm 5.8731(33.3454) | Total Time 0.00(0.00)\n",
      "Iter 21040 | Time 22.9234(23.9010) | Bit/dim 3.5959(3.6383) | Xent 0.0135(0.0172) | Loss 9.0067(9.5318) | Error 0.0033(0.0046) Steps 844(842.65) | Grad Norm 3.9079(26.3289) | Total Time 0.00(0.00)\n",
      "Iter 21050 | Time 24.3593(23.7964) | Bit/dim 3.6150(3.6320) | Xent 0.0064(0.0153) | Loss 8.9501(9.3961) | Error 0.0033(0.0042) Steps 838(841.24) | Grad Norm 4.0589(22.0426) | Total Time 0.00(0.00)\n",
      "Iter 21060 | Time 23.2623(23.8230) | Bit/dim 3.5947(3.6231) | Xent 0.0053(0.0130) | Loss 8.9680(9.2826) | Error 0.0011(0.0036) Steps 826(841.25) | Grad Norm 290.0382(26.3776) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0383 | Time 103.9426, Epoch Time 1436.1713(1355.8378), Bit/dim 3.6574(best: 3.5219), Xent 2.5596, Loss 4.9372, Error 0.3353(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21070 | Time 24.3880(23.9157) | Bit/dim 3.6292(3.6251) | Xent 0.0057(0.0115) | Loss 8.9901(10.0239) | Error 0.0022(0.0032) Steps 838(843.67) | Grad Norm 30.4224(31.3848) | Total Time 0.00(0.00)\n",
      "Iter 21080 | Time 24.9160(24.1738) | Bit/dim 3.6295(3.6259) | Xent 0.0095(0.0102) | Loss 9.0952(9.7698) | Error 0.0022(0.0028) Steps 880(847.39) | Grad Norm 258.5648(35.8780) | Total Time 0.00(0.00)\n",
      "Iter 21090 | Time 25.9964(24.3126) | Bit/dim 3.6555(3.6343) | Xent 0.0288(0.0101) | Loss 9.0980(9.5992) | Error 0.0089(0.0029) Steps 850(851.35) | Grad Norm 122.8357(45.3631) | Total Time 0.00(0.00)\n",
      "Iter 21100 | Time 26.2474(24.4106) | Bit/dim 3.6354(3.6397) | Xent 0.0072(0.0088) | Loss 9.0979(9.4642) | Error 0.0011(0.0025) Steps 838(850.42) | Grad Norm 5.1881(43.0515) | Total Time 0.00(0.00)\n",
      "Iter 21110 | Time 24.9819(24.3185) | Bit/dim 3.6537(3.6376) | Xent 0.0082(0.0079) | Loss 9.1513(9.3622) | Error 0.0044(0.0023) Steps 904(852.70) | Grad Norm 11.1308(33.9320) | Total Time 0.00(0.00)\n",
      "Iter 21120 | Time 25.7183(24.3160) | Bit/dim 3.6579(3.6390) | Xent 0.0096(0.0078) | Loss 9.0973(9.2830) | Error 0.0011(0.0022) Steps 910(854.68) | Grad Norm 6.6811(32.2789) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0384 | Time 105.4635, Epoch Time 1471.8877(1359.3193), Bit/dim 3.6703(best: 3.5219), Xent 2.5645, Loss 4.9525, Error 0.3273(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21130 | Time 23.7966(24.2969) | Bit/dim 3.6285(3.6410) | Xent 0.0080(0.0077) | Loss 9.0170(9.9196) | Error 0.0022(0.0023) Steps 832(855.33) | Grad Norm 49.1689(34.3568) | Total Time 0.00(0.00)\n",
      "Iter 21140 | Time 23.3558(24.2543) | Bit/dim 3.6513(3.6393) | Xent 0.0057(0.0088) | Loss 8.9166(9.7022) | Error 0.0011(0.0024) Steps 802(855.37) | Grad Norm 25.4806(28.1398) | Total Time 0.00(0.00)\n",
      "Iter 21150 | Time 25.0517(24.3797) | Bit/dim 3.6787(3.6379) | Xent 0.0023(0.0078) | Loss 8.9344(9.5281) | Error 0.0000(0.0020) Steps 826(854.97) | Grad Norm 17.1951(22.6638) | Total Time 0.00(0.00)\n",
      "Iter 21160 | Time 25.8210(24.4999) | Bit/dim 3.7140(3.6480) | Xent 0.0136(0.0078) | Loss 9.2969(9.4269) | Error 0.0022(0.0020) Steps 874(857.91) | Grad Norm 9.8518(39.6212) | Total Time 0.00(0.00)\n",
      "Iter 21170 | Time 23.9314(24.5858) | Bit/dim 3.6650(3.6577) | Xent 0.0084(0.0085) | Loss 9.2057(9.3585) | Error 0.0033(0.0022) Steps 868(855.54) | Grad Norm 5.0730(33.7139) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0385 | Time 104.6934, Epoch Time 1476.1973(1362.8256), Bit/dim 3.6767(best: 3.5219), Xent 2.5762, Loss 4.9648, Error 0.3287(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21180 | Time 25.0546(24.5743) | Bit/dim 3.6497(3.6542) | Xent 0.0127(0.0083) | Loss 9.1215(10.0822) | Error 0.0022(0.0022) Steps 880(853.23) | Grad Norm 3.3170(26.4806) | Total Time 0.00(0.00)\n",
      "Iter 21190 | Time 24.9375(24.4415) | Bit/dim 3.6022(3.6507) | Xent 0.0131(0.0085) | Loss 9.1025(9.8127) | Error 0.0022(0.0021) Steps 880(853.78) | Grad Norm 7.2375(20.8062) | Total Time 0.00(0.00)\n",
      "Iter 21200 | Time 24.8668(24.5482) | Bit/dim 3.6255(3.6451) | Xent 0.0064(0.0085) | Loss 9.0924(9.6258) | Error 0.0022(0.0021) Steps 850(858.34) | Grad Norm 3.4327(17.1859) | Total Time 0.00(0.00)\n",
      "Iter 21210 | Time 25.6300(24.5170) | Bit/dim 3.6754(3.6398) | Xent 0.0034(0.0077) | Loss 9.1567(9.4708) | Error 0.0011(0.0019) Steps 874(857.71) | Grad Norm 4.2227(18.6394) | Total Time 0.00(0.00)\n",
      "Iter 21220 | Time 23.9678(24.3571) | Bit/dim 3.6381(3.6331) | Xent 0.0074(0.0079) | Loss 8.9891(9.3417) | Error 0.0022(0.0018) Steps 838(854.67) | Grad Norm 4.4956(15.0656) | Total Time 0.00(0.00)\n",
      "Iter 21230 | Time 23.2068(24.3168) | Bit/dim 3.6058(3.6289) | Xent 0.0158(0.0093) | Loss 9.0149(9.2617) | Error 0.0056(0.0023) Steps 820(852.88) | Grad Norm 7.1212(12.5564) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0386 | Time 104.2507, Epoch Time 1460.7133(1365.7622), Bit/dim 3.6392(best: 3.5219), Xent 2.5678, Loss 4.9231, Error 0.3308(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21240 | Time 23.9139(24.3259) | Bit/dim 3.6331(3.6253) | Xent 0.0098(0.0087) | Loss 9.0164(9.8687) | Error 0.0033(0.0022) Steps 880(851.24) | Grad Norm 5.5751(10.4516) | Total Time 0.00(0.00)\n",
      "Iter 21250 | Time 24.2607(24.1797) | Bit/dim 3.6382(3.6210) | Xent 0.0097(0.0078) | Loss 9.0489(9.6416) | Error 0.0022(0.0020) Steps 814(849.98) | Grad Norm 6.3661(9.1604) | Total Time 0.00(0.00)\n",
      "Iter 21260 | Time 24.1603(24.1702) | Bit/dim 3.5854(3.6168) | Xent 0.0071(0.0078) | Loss 8.9239(9.4627) | Error 0.0011(0.0019) Steps 826(848.15) | Grad Norm 14.2462(8.1820) | Total Time 0.00(0.00)\n",
      "Iter 21270 | Time 23.4901(24.1779) | Bit/dim 3.5970(3.6136) | Xent 0.0015(0.0073) | Loss 8.9301(9.3419) | Error 0.0000(0.0019) Steps 856(848.46) | Grad Norm 8.7884(7.8135) | Total Time 0.00(0.00)\n",
      "Iter 21280 | Time 23.3153(24.2324) | Bit/dim 3.6435(3.6112) | Xent 0.0040(0.0063) | Loss 9.1301(9.2511) | Error 0.0011(0.0017) Steps 826(849.90) | Grad Norm 2.5345(7.2081) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0387 | Time 104.3244, Epoch Time 1454.6380(1368.4285), Bit/dim 3.6278(best: 3.5219), Xent 2.5843, Loss 4.9200, Error 0.3315(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21290 | Time 24.3079(24.2090) | Bit/dim 3.6121(3.6120) | Xent 0.0007(0.0059) | Loss 8.9717(9.9821) | Error 0.0000(0.0016) Steps 844(849.66) | Grad Norm 1.8887(6.5421) | Total Time 0.00(0.00)\n",
      "Iter 21300 | Time 23.6003(24.1659) | Bit/dim 3.5892(3.6068) | Xent 0.0009(0.0054) | Loss 9.0282(9.7180) | Error 0.0000(0.0014) Steps 868(850.60) | Grad Norm 1.6439(6.4340) | Total Time 0.00(0.00)\n",
      "Iter 21310 | Time 23.1783(24.1655) | Bit/dim 3.5900(3.6033) | Xent 0.0069(0.0059) | Loss 8.9414(9.5249) | Error 0.0022(0.0015) Steps 832(852.62) | Grad Norm 4.5000(9.9273) | Total Time 0.00(0.00)\n",
      "Iter 21320 | Time 24.7013(24.2719) | Bit/dim 3.6207(3.6054) | Xent 0.0019(0.0060) | Loss 9.1073(9.3981) | Error 0.0000(0.0016) Steps 874(853.75) | Grad Norm 3.7303(8.6166) | Total Time 0.00(0.00)\n",
      "Iter 21330 | Time 24.6642(24.3537) | Bit/dim 3.6164(3.6039) | Xent 0.0077(0.0058) | Loss 8.9331(9.2965) | Error 0.0033(0.0017) Steps 856(855.59) | Grad Norm 3.3232(7.6644) | Total Time 0.00(0.00)\n",
      "Iter 21340 | Time 24.3208(24.3559) | Bit/dim 3.6057(3.6054) | Xent 0.0302(0.0065) | Loss 9.1119(9.2086) | Error 0.0067(0.0018) Steps 868(856.98) | Grad Norm 7.4961(13.3428) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0388 | Time 106.2756, Epoch Time 1463.6793(1371.2860), Bit/dim 3.6294(best: 3.5219), Xent 2.5653, Loss 4.9121, Error 0.3281(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21350 | Time 23.6087(24.3055) | Bit/dim 3.6076(3.6083) | Xent 0.0013(0.0061) | Loss 8.8545(9.8124) | Error 0.0000(0.0017) Steps 850(856.13) | Grad Norm 3.5809(11.8835) | Total Time 0.00(0.00)\n",
      "Iter 21360 | Time 24.3211(24.3262) | Bit/dim 3.6032(3.6062) | Xent 0.0126(0.0065) | Loss 9.0595(9.5955) | Error 0.0033(0.0017) Steps 820(853.06) | Grad Norm 5.2034(10.7253) | Total Time 0.00(0.00)\n",
      "Iter 21370 | Time 24.7542(24.3862) | Bit/dim 3.5720(3.6032) | Xent 0.0015(0.0067) | Loss 8.8497(9.4295) | Error 0.0000(0.0017) Steps 856(853.17) | Grad Norm 2.3351(9.6192) | Total Time 0.00(0.00)\n",
      "Iter 21380 | Time 25.4911(24.3568) | Bit/dim 3.5966(3.6032) | Xent 0.0049(0.0070) | Loss 9.0002(9.3181) | Error 0.0011(0.0018) Steps 910(855.27) | Grad Norm 2.8468(8.3304) | Total Time 0.00(0.00)\n",
      "Iter 21390 | Time 24.6016(24.3444) | Bit/dim 3.5937(3.6051) | Xent 0.0102(0.0072) | Loss 8.9425(9.2301) | Error 0.0022(0.0019) Steps 856(852.31) | Grad Norm 6.4172(8.4162) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0389 | Time 105.7086, Epoch Time 1468.9700(1374.2166), Bit/dim 3.6215(best: 3.5219), Xent 2.5869, Loss 4.9149, Error 0.3299(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21400 | Time 25.8035(24.4880) | Bit/dim 3.6150(3.6056) | Xent 0.0175(0.0071) | Loss 9.1690(9.9903) | Error 0.0044(0.0020) Steps 904(852.79) | Grad Norm 4.0417(7.9721) | Total Time 0.00(0.00)\n",
      "Iter 21410 | Time 25.3095(24.5075) | Bit/dim 3.5910(3.6005) | Xent 0.0056(0.0066) | Loss 9.0601(9.7241) | Error 0.0011(0.0018) Steps 874(857.82) | Grad Norm 6.8850(8.3234) | Total Time 0.00(0.00)\n",
      "Iter 21420 | Time 25.2195(24.6007) | Bit/dim 3.5708(3.5959) | Xent 0.0133(0.0070) | Loss 8.9117(9.5296) | Error 0.0044(0.0019) Steps 886(861.40) | Grad Norm 5.8331(7.7644) | Total Time 0.00(0.00)\n",
      "Iter 21430 | Time 23.4347(24.4881) | Bit/dim 3.6151(3.5948) | Xent 0.0053(0.0060) | Loss 9.0909(9.3884) | Error 0.0011(0.0016) Steps 844(863.08) | Grad Norm 4.8721(10.5795) | Total Time 0.00(0.00)\n",
      "Iter 21440 | Time 24.5248(24.5388) | Bit/dim 3.6077(3.5942) | Xent 0.0092(0.0058) | Loss 9.0106(9.2740) | Error 0.0033(0.0016) Steps 820(861.89) | Grad Norm 15.1624(10.3163) | Total Time 0.00(0.00)\n",
      "Iter 21450 | Time 24.9924(24.4658) | Bit/dim 3.6516(3.5980) | Xent 0.0056(0.0061) | Loss 9.0932(9.2006) | Error 0.0022(0.0016) Steps 898(861.10) | Grad Norm 94.5951(18.3095) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0390 | Time 107.1245, Epoch Time 1476.8222(1377.2947), Bit/dim 3.6532(best: 3.5219), Xent 2.6021, Loss 4.9542, Error 0.3300(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21460 | Time 26.6074(24.5378) | Bit/dim 3.7126(3.6109) | Xent 0.0090(0.0066) | Loss 9.3204(9.8395) | Error 0.0044(0.0017) Steps 862(860.56) | Grad Norm 12.6495(27.8978) | Total Time 0.00(0.00)\n",
      "Iter 21470 | Time 26.3056(24.8242) | Bit/dim 3.6756(3.6322) | Xent 0.0101(0.0081) | Loss 9.0991(9.6741) | Error 0.0044(0.0021) Steps 934(869.25) | Grad Norm 78.0853(57.3107) | Total Time 0.00(0.00)\n",
      "Iter 21480 | Time 26.1682(24.9929) | Bit/dim 3.6952(3.6487) | Xent 0.0119(0.0098) | Loss 9.1961(9.5541) | Error 0.0022(0.0025) Steps 910(877.16) | Grad Norm 22.7570(52.5000) | Total Time 0.00(0.00)\n",
      "Iter 21490 | Time 25.7112(25.0302) | Bit/dim 3.6704(3.6555) | Xent 0.0157(0.0142) | Loss 9.3019(9.4698) | Error 0.0056(0.0036) Steps 880(880.21) | Grad Norm 4.9357(40.7351) | Total Time 0.00(0.00)\n",
      "Iter 21500 | Time 24.6909(25.0090) | Bit/dim 3.6479(3.6533) | Xent 0.0085(0.0145) | Loss 9.0468(9.3736) | Error 0.0033(0.0037) Steps 868(882.28) | Grad Norm 9.1010(31.6154) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0391 | Time 106.1443, Epoch Time 1508.3722(1381.2271), Bit/dim 3.6536(best: 3.5219), Xent 2.4772, Loss 4.8922, Error 0.3202(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21510 | Time 23.6640(24.8155) | Bit/dim 3.6096(3.6472) | Xent 0.0123(0.0135) | Loss 8.9921(10.0941) | Error 0.0044(0.0036) Steps 880(878.60) | Grad Norm 8.2689(24.7826) | Total Time 0.00(0.00)\n",
      "Iter 21520 | Time 24.8297(24.6792) | Bit/dim 3.6056(3.6397) | Xent 0.0113(0.0128) | Loss 9.0534(9.8158) | Error 0.0033(0.0034) Steps 862(872.36) | Grad Norm 5.3414(19.5644) | Total Time 0.00(0.00)\n",
      "Iter 21530 | Time 24.6050(24.6258) | Bit/dim 3.6193(3.6335) | Xent 0.0017(0.0117) | Loss 9.1102(9.6059) | Error 0.0000(0.0031) Steps 826(867.12) | Grad Norm 2.3612(15.3560) | Total Time 0.00(0.00)\n",
      "Iter 21540 | Time 23.5675(24.4677) | Bit/dim 3.6077(3.6236) | Xent 0.0085(0.0101) | Loss 9.0367(9.4392) | Error 0.0033(0.0027) Steps 856(863.45) | Grad Norm 3.0725(12.0850) | Total Time 0.00(0.00)\n",
      "Iter 21550 | Time 24.4912(24.3907) | Bit/dim 3.6419(3.6172) | Xent 0.0006(0.0095) | Loss 8.9258(9.3247) | Error 0.0000(0.0024) Steps 880(863.26) | Grad Norm 2.9449(9.7215) | Total Time 0.00(0.00)\n",
      "Iter 21560 | Time 24.8937(24.3123) | Bit/dim 3.6060(3.6129) | Xent 0.0048(0.0091) | Loss 9.0826(9.2453) | Error 0.0011(0.0023) Steps 856(861.90) | Grad Norm 2.1672(8.0407) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0392 | Time 106.5329, Epoch Time 1456.7910(1383.4940), Bit/dim 3.6130(best: 3.5219), Xent 2.4934, Loss 4.8597, Error 0.3259(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21570 | Time 24.1265(24.2049) | Bit/dim 3.6188(3.6088) | Xent 0.0082(0.0084) | Loss 9.0203(9.8514) | Error 0.0011(0.0021) Steps 868(856.60) | Grad Norm 2.4187(6.8742) | Total Time 0.00(0.00)\n",
      "Iter 21580 | Time 22.8398(24.1020) | Bit/dim 3.6038(3.6009) | Xent 0.0049(0.0077) | Loss 8.8733(9.6118) | Error 0.0011(0.0020) Steps 862(859.39) | Grad Norm 2.5857(5.8999) | Total Time 0.00(0.00)\n",
      "Iter 21590 | Time 24.1926(24.1639) | Bit/dim 3.5462(3.5946) | Xent 0.0055(0.0071) | Loss 8.8727(9.4430) | Error 0.0011(0.0018) Steps 850(857.19) | Grad Norm 3.6985(5.1296) | Total Time 0.00(0.00)\n",
      "Iter 21600 | Time 24.3827(24.0702) | Bit/dim 3.5726(3.5913) | Xent 0.0027(0.0067) | Loss 9.0019(9.3234) | Error 0.0011(0.0017) Steps 862(857.21) | Grad Norm 1.7695(4.6555) | Total Time 0.00(0.00)\n",
      "Iter 21610 | Time 24.2565(24.0811) | Bit/dim 3.5692(3.5855) | Xent 0.0023(0.0066) | Loss 9.0381(9.2265) | Error 0.0011(0.0017) Steps 844(858.99) | Grad Norm 3.0372(4.2112) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0393 | Time 105.3578, Epoch Time 1445.3440(1385.3495), Bit/dim 3.5962(best: 3.5219), Xent 2.5610, Loss 4.8767, Error 0.3279(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21620 | Time 23.6869(23.9946) | Bit/dim 3.5523(3.5814) | Xent 0.0036(0.0060) | Loss 8.9203(9.9634) | Error 0.0011(0.0016) Steps 880(859.44) | Grad Norm 3.1384(3.7932) | Total Time 0.00(0.00)\n",
      "Iter 21630 | Time 24.6878(23.9367) | Bit/dim 3.5883(3.5785) | Xent 0.0008(0.0052) | Loss 9.0002(9.6888) | Error 0.0000(0.0014) Steps 898(857.77) | Grad Norm 1.0867(3.5522) | Total Time 0.00(0.00)\n",
      "Iter 21640 | Time 23.3046(23.9373) | Bit/dim 3.5580(3.5748) | Xent 0.0022(0.0049) | Loss 8.8329(9.4771) | Error 0.0011(0.0013) Steps 850(856.49) | Grad Norm 1.7615(3.2968) | Total Time 0.00(0.00)\n",
      "Iter 21650 | Time 23.9215(23.9931) | Bit/dim 3.5989(3.5730) | Xent 0.0010(0.0045) | Loss 8.9151(9.3289) | Error 0.0000(0.0012) Steps 844(856.45) | Grad Norm 1.3758(3.0392) | Total Time 0.00(0.00)\n",
      "Iter 21660 | Time 24.2555(23.9500) | Bit/dim 3.5727(3.5718) | Xent 0.0038(0.0046) | Loss 9.0012(9.2313) | Error 0.0011(0.0012) Steps 850(856.07) | Grad Norm 2.7939(2.8992) | Total Time 0.00(0.00)\n",
      "Iter 21670 | Time 22.9021(23.8008) | Bit/dim 3.6079(3.5703) | Xent 0.0096(0.0047) | Loss 9.0274(9.1477) | Error 0.0033(0.0012) Steps 814(853.70) | Grad Norm 2.6434(2.6563) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0394 | Time 103.8264, Epoch Time 1434.8588(1386.8348), Bit/dim 3.5867(best: 3.5219), Xent 2.5869, Loss 4.8801, Error 0.3303(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21680 | Time 24.7610(23.8407) | Bit/dim 3.5590(3.5716) | Xent 0.0058(0.0045) | Loss 9.0040(9.7807) | Error 0.0011(0.0011) Steps 838(851.67) | Grad Norm 6.1522(2.7019) | Total Time 0.00(0.00)\n",
      "Iter 21690 | Time 23.0012(23.7659) | Bit/dim 3.5534(3.5688) | Xent 0.0031(0.0040) | Loss 8.7991(9.5406) | Error 0.0011(0.0009) Steps 814(848.42) | Grad Norm 3.9928(2.6028) | Total Time 0.00(0.00)\n",
      "Iter 21700 | Time 22.9787(23.7327) | Bit/dim 3.5371(3.5620) | Xent 0.0084(0.0041) | Loss 8.6713(9.3460) | Error 0.0011(0.0009) Steps 826(850.52) | Grad Norm 2.2145(2.4883) | Total Time 0.00(0.00)\n",
      "Iter 21710 | Time 23.1784(23.7199) | Bit/dim 3.5654(3.5626) | Xent 0.0014(0.0040) | Loss 8.9022(9.2370) | Error 0.0000(0.0009) Steps 814(848.68) | Grad Norm 4.4566(2.5169) | Total Time 0.00(0.00)\n",
      "Iter 21720 | Time 25.3356(23.8159) | Bit/dim 3.5665(3.5594) | Xent 0.0010(0.0042) | Loss 9.0534(9.1512) | Error 0.0000(0.0010) Steps 892(848.25) | Grad Norm 1.4623(2.5203) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0395 | Time 105.3714, Epoch Time 1435.3885(1388.2914), Bit/dim 3.5800(best: 3.5219), Xent 2.6517, Loss 4.9059, Error 0.3374(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21730 | Time 24.1746(23.8937) | Bit/dim 3.5778(3.5576) | Xent 0.0009(0.0036) | Loss 8.9689(9.8678) | Error 0.0000(0.0009) Steps 892(850.21) | Grad Norm 1.7274(2.3657) | Total Time 0.00(0.00)\n",
      "Iter 21740 | Time 23.9433(23.9808) | Bit/dim 3.5554(3.5542) | Xent 0.0024(0.0035) | Loss 8.9156(9.6103) | Error 0.0011(0.0008) Steps 850(851.37) | Grad Norm 1.7570(2.2623) | Total Time 0.00(0.00)\n",
      "Iter 21750 | Time 23.5222(23.9934) | Bit/dim 3.5817(3.5560) | Xent 0.0019(0.0037) | Loss 8.9415(9.4349) | Error 0.0000(0.0009) Steps 880(851.19) | Grad Norm 2.5981(2.4107) | Total Time 0.00(0.00)\n",
      "Iter 21760 | Time 22.9063(23.9135) | Bit/dim 3.5347(3.5562) | Xent 0.0099(0.0037) | Loss 8.8636(9.2892) | Error 0.0011(0.0009) Steps 844(851.74) | Grad Norm 2.0070(2.3062) | Total Time 0.00(0.00)\n",
      "Iter 21770 | Time 24.3385(23.8704) | Bit/dim 3.5533(3.5542) | Xent 0.0059(0.0042) | Loss 8.9111(9.1926) | Error 0.0011(0.0011) Steps 868(851.33) | Grad Norm 4.1885(2.5825) | Total Time 0.00(0.00)\n",
      "Iter 21780 | Time 24.0625(23.8052) | Bit/dim 3.5311(3.5519) | Xent 0.0005(0.0038) | Loss 8.9087(9.0935) | Error 0.0000(0.0010) Steps 856(847.48) | Grad Norm 2.3503(2.6628) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0396 | Time 104.8908, Epoch Time 1438.2249(1389.7894), Bit/dim 3.5751(best: 3.5219), Xent 2.6274, Loss 4.8888, Error 0.3285(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21790 | Time 24.0835(23.7844) | Bit/dim 3.5366(3.5505) | Xent 0.0008(0.0036) | Loss 8.7638(9.7218) | Error 0.0000(0.0009) Steps 826(848.09) | Grad Norm 2.0812(2.7306) | Total Time 0.00(0.00)\n",
      "Iter 21800 | Time 23.4934(23.6746) | Bit/dim 3.5478(3.5525) | Xent 0.0083(0.0038) | Loss 8.8343(9.5049) | Error 0.0022(0.0010) Steps 862(846.92) | Grad Norm 3.7490(2.6373) | Total Time 0.00(0.00)\n",
      "Iter 21810 | Time 23.0967(23.7141) | Bit/dim 3.5507(3.5521) | Xent 0.0009(0.0038) | Loss 8.8366(9.3469) | Error 0.0000(0.0010) Steps 880(848.02) | Grad Norm 1.6524(2.5867) | Total Time 0.00(0.00)\n",
      "Iter 21820 | Time 22.7671(23.7262) | Bit/dim 3.5803(3.5502) | Xent 0.0007(0.0040) | Loss 8.8784(9.2264) | Error 0.0000(0.0011) Steps 814(849.94) | Grad Norm 3.6648(2.5338) | Total Time 0.00(0.00)\n",
      "Iter 21830 | Time 24.4367(23.7036) | Bit/dim 3.5455(3.5496) | Xent 0.0032(0.0035) | Loss 8.8710(9.1296) | Error 0.0011(0.0010) Steps 874(847.48) | Grad Norm 2.8666(2.3680) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0397 | Time 103.6276, Epoch Time 1426.8709(1390.9018), Bit/dim 3.5675(best: 3.5219), Xent 2.6588, Loss 4.8969, Error 0.3337(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21840 | Time 24.0776(23.7953) | Bit/dim 3.5121(3.5480) | Xent 0.0039(0.0038) | Loss 8.8424(9.8655) | Error 0.0011(0.0011) Steps 850(847.35) | Grad Norm 4.6984(2.6097) | Total Time 0.00(0.00)\n",
      "Iter 21850 | Time 23.1091(23.7650) | Bit/dim 3.5329(3.5458) | Xent 0.0019(0.0034) | Loss 8.6952(9.6039) | Error 0.0011(0.0010) Steps 826(847.52) | Grad Norm 2.4893(2.6483) | Total Time 0.00(0.00)\n",
      "Iter 21860 | Time 24.2965(23.7398) | Bit/dim 3.5062(3.5443) | Xent 0.0026(0.0036) | Loss 8.6767(9.4034) | Error 0.0011(0.0010) Steps 838(844.74) | Grad Norm 2.2994(2.9197) | Total Time 0.00(0.00)\n",
      "Iter 21870 | Time 23.1520(23.7423) | Bit/dim 3.5395(3.5443) | Xent 0.0018(0.0035) | Loss 8.8386(9.2728) | Error 0.0011(0.0010) Steps 838(848.97) | Grad Norm 2.0660(2.8386) | Total Time 0.00(0.00)\n",
      "Iter 21880 | Time 23.5898(23.7063) | Bit/dim 3.5278(3.5429) | Xent 0.0007(0.0037) | Loss 8.7977(9.1455) | Error 0.0000(0.0011) Steps 838(846.29) | Grad Norm 1.9294(2.8972) | Total Time 0.00(0.00)\n",
      "Iter 21890 | Time 24.5934(23.6591) | Bit/dim 3.5381(3.5448) | Xent 0.0025(0.0036) | Loss 8.8517(9.0776) | Error 0.0000(0.0011) Steps 898(847.48) | Grad Norm 4.3376(2.8958) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0398 | Time 103.4620, Epoch Time 1427.2697(1391.9929), Bit/dim 3.5660(best: 3.5219), Xent 2.6752, Loss 4.9036, Error 0.3304(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21900 | Time 23.0629(23.6724) | Bit/dim 3.5415(3.5462) | Xent 0.0008(0.0035) | Loss 8.7802(9.7043) | Error 0.0000(0.0011) Steps 844(846.44) | Grad Norm 2.2298(2.7633) | Total Time 0.00(0.00)\n",
      "Iter 21910 | Time 23.8996(23.6363) | Bit/dim 3.5448(3.5448) | Xent 0.0078(0.0033) | Loss 8.8173(9.4751) | Error 0.0011(0.0010) Steps 856(845.35) | Grad Norm 5.6388(2.7884) | Total Time 0.00(0.00)\n",
      "Iter 21920 | Time 23.6708(23.6695) | Bit/dim 3.5216(3.5420) | Xent 0.0142(0.0036) | Loss 8.8620(9.3147) | Error 0.0022(0.0010) Steps 850(846.50) | Grad Norm 3.1280(2.7728) | Total Time 0.00(0.00)\n",
      "Iter 21930 | Time 23.5210(23.7073) | Bit/dim 3.5774(3.5421) | Xent 0.0065(0.0041) | Loss 8.8913(9.2040) | Error 0.0033(0.0010) Steps 838(849.18) | Grad Norm 2.6373(2.6715) | Total Time 0.00(0.00)\n",
      "Iter 21940 | Time 23.8652(23.7922) | Bit/dim 3.5364(3.5400) | Xent 0.0005(0.0043) | Loss 8.7827(9.1089) | Error 0.0000(0.0010) Steps 826(847.85) | Grad Norm 1.0859(2.6497) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0399 | Time 104.1045, Epoch Time 1430.5530(1393.1497), Bit/dim 3.5668(best: 3.5219), Xent 2.6754, Loss 4.9045, Error 0.3327(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 21950 | Time 24.3160(23.7714) | Bit/dim 3.5372(3.5421) | Xent 0.0026(0.0040) | Loss 8.7467(9.8301) | Error 0.0011(0.0010) Steps 832(849.04) | Grad Norm 3.5722(2.6449) | Total Time 0.00(0.00)\n",
      "Iter 21960 | Time 24.6056(23.7551) | Bit/dim 3.5633(3.5417) | Xent 0.0145(0.0039) | Loss 8.9551(9.5775) | Error 0.0022(0.0010) Steps 844(849.00) | Grad Norm 1.7344(2.4446) | Total Time 0.00(0.00)\n",
      "Iter 21970 | Time 24.0331(23.7451) | Bit/dim 3.5653(3.5418) | Xent 0.0011(0.0039) | Loss 8.8735(9.3767) | Error 0.0000(0.0009) Steps 838(848.74) | Grad Norm 1.1707(2.2887) | Total Time 0.00(0.00)\n",
      "Iter 21980 | Time 23.0769(23.7384) | Bit/dim 3.5104(3.5383) | Xent 0.0009(0.0033) | Loss 8.7301(9.2347) | Error 0.0000(0.0007) Steps 844(848.72) | Grad Norm 0.8608(2.0713) | Total Time 0.00(0.00)\n",
      "Iter 21990 | Time 24.8077(23.8064) | Bit/dim 3.5643(3.5397) | Xent 0.0044(0.0034) | Loss 8.9210(9.1326) | Error 0.0022(0.0007) Steps 820(848.77) | Grad Norm 1.3863(2.0309) | Total Time 0.00(0.00)\n",
      "Iter 22000 | Time 23.9294(23.7712) | Bit/dim 3.5420(3.5387) | Xent 0.0083(0.0036) | Loss 8.8139(9.0543) | Error 0.0033(0.0008) Steps 838(847.71) | Grad Norm 7.0351(2.3005) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0400 | Time 103.5925, Epoch Time 1430.2977(1394.2641), Bit/dim 3.5627(best: 3.5219), Xent 2.7342, Loss 4.9298, Error 0.3374(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22010 | Time 23.6984(23.8002) | Bit/dim 3.5657(3.5405) | Xent 0.0003(0.0035) | Loss 8.9620(9.6836) | Error 0.0000(0.0009) Steps 862(846.47) | Grad Norm 1.6114(2.3937) | Total Time 0.00(0.00)\n",
      "Iter 22020 | Time 22.5447(23.6997) | Bit/dim 3.5204(3.5400) | Xent 0.0016(0.0038) | Loss 8.6703(9.4676) | Error 0.0000(0.0009) Steps 814(847.70) | Grad Norm 3.3451(2.4876) | Total Time 0.00(0.00)\n",
      "Iter 22030 | Time 23.3311(23.7400) | Bit/dim 3.5417(3.5398) | Xent 0.0017(0.0036) | Loss 8.8765(9.3079) | Error 0.0011(0.0009) Steps 832(843.64) | Grad Norm 2.7435(2.6167) | Total Time 0.00(0.00)\n",
      "Iter 22040 | Time 22.6170(23.6919) | Bit/dim 3.5301(3.5375) | Xent 0.0059(0.0043) | Loss 8.7796(9.1894) | Error 0.0022(0.0011) Steps 856(843.77) | Grad Norm 4.2165(3.0365) | Total Time 0.00(0.00)\n",
      "Iter 22050 | Time 23.2758(23.5598) | Bit/dim 3.4757(3.5339) | Xent 0.0009(0.0038) | Loss 8.6443(9.0780) | Error 0.0000(0.0010) Steps 820(840.66) | Grad Norm 4.4586(3.0280) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0401 | Time 103.5366, Epoch Time 1421.7861(1395.0898), Bit/dim 3.5593(best: 3.5219), Xent 2.7370, Loss 4.9278, Error 0.3352(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22060 | Time 23.1242(23.6067) | Bit/dim 3.5504(3.5346) | Xent 0.0005(0.0030) | Loss 8.8934(9.8210) | Error 0.0000(0.0008) Steps 844(845.34) | Grad Norm 1.5365(2.7967) | Total Time 0.00(0.00)\n",
      "Iter 22070 | Time 24.4904(23.6443) | Bit/dim 3.5359(3.5361) | Xent 0.0016(0.0027) | Loss 8.8705(9.5633) | Error 0.0000(0.0007) Steps 886(845.88) | Grad Norm 1.8024(2.7367) | Total Time 0.00(0.00)\n",
      "Iter 22080 | Time 23.1777(23.7073) | Bit/dim 3.5135(3.5343) | Xent 0.0100(0.0030) | Loss 8.7490(9.3710) | Error 0.0011(0.0007) Steps 832(845.07) | Grad Norm 2.0317(2.7362) | Total Time 0.00(0.00)\n",
      "Iter 22090 | Time 24.0649(23.7700) | Bit/dim 3.5333(3.5328) | Xent 0.0089(0.0030) | Loss 8.9553(9.2350) | Error 0.0011(0.0007) Steps 826(846.62) | Grad Norm 2.5393(2.6244) | Total Time 0.00(0.00)\n",
      "Iter 22100 | Time 23.5539(23.7529) | Bit/dim 3.5161(3.5320) | Xent 0.0008(0.0030) | Loss 8.7138(9.1180) | Error 0.0000(0.0006) Steps 814(844.89) | Grad Norm 3.0063(2.6954) | Total Time 0.00(0.00)\n",
      "Iter 22110 | Time 23.1235(23.7711) | Bit/dim 3.5429(3.5330) | Xent 0.0010(0.0029) | Loss 8.9108(9.0529) | Error 0.0000(0.0007) Steps 862(844.05) | Grad Norm 2.3298(2.9934) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0402 | Time 103.3346, Epoch Time 1435.9378(1396.3152), Bit/dim 3.5607(best: 3.5219), Xent 2.7538, Loss 4.9376, Error 0.3372(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22120 | Time 23.8597(23.6986) | Bit/dim 3.5499(3.5329) | Xent 0.0008(0.0030) | Loss 8.9341(9.7035) | Error 0.0000(0.0007) Steps 886(845.89) | Grad Norm 1.7710(2.9309) | Total Time 0.00(0.00)\n",
      "Iter 22130 | Time 24.1845(23.7072) | Bit/dim 3.5375(3.5337) | Xent 0.0004(0.0026) | Loss 8.9212(9.4769) | Error 0.0000(0.0007) Steps 874(845.21) | Grad Norm 3.8659(2.9251) | Total Time 0.00(0.00)\n",
      "Iter 22140 | Time 23.9902(23.5888) | Bit/dim 3.5711(3.5333) | Xent 0.0012(0.0023) | Loss 8.9345(9.3005) | Error 0.0000(0.0006) Steps 868(843.34) | Grad Norm 1.6708(2.9258) | Total Time 0.00(0.00)\n",
      "Iter 22150 | Time 25.4026(23.5832) | Bit/dim 3.5714(3.5331) | Xent 0.0078(0.0029) | Loss 8.9467(9.1792) | Error 0.0033(0.0008) Steps 898(844.34) | Grad Norm 4.8766(3.0659) | Total Time 0.00(0.00)\n",
      "Iter 22160 | Time 23.3858(23.5129) | Bit/dim 3.5217(3.5318) | Xent 0.0064(0.0030) | Loss 8.7905(9.0878) | Error 0.0011(0.0009) Steps 850(845.06) | Grad Norm 2.3999(3.2091) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0403 | Time 101.9037, Epoch Time 1412.1302(1396.7896), Bit/dim 3.5568(best: 3.5219), Xent 2.7847, Loss 4.9491, Error 0.3344(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22170 | Time 23.8311(23.5075) | Bit/dim 3.5222(3.5328) | Xent 0.0053(0.0033) | Loss 8.8871(9.8132) | Error 0.0022(0.0010) Steps 832(843.75) | Grad Norm 4.2455(3.3304) | Total Time 0.00(0.00)\n",
      "Iter 22180 | Time 23.5524(23.4038) | Bit/dim 3.5524(3.5297) | Xent 0.0008(0.0037) | Loss 8.8449(9.5468) | Error 0.0000(0.0010) Steps 838(842.90) | Grad Norm 3.5131(3.4808) | Total Time 0.00(0.00)\n",
      "Iter 22190 | Time 22.9557(23.3355) | Bit/dim 3.5125(3.5267) | Xent 0.0020(0.0038) | Loss 8.5389(9.3403) | Error 0.0000(0.0009) Steps 850(841.17) | Grad Norm 2.0176(3.4180) | Total Time 0.00(0.00)\n",
      "Iter 22200 | Time 25.0569(23.4332) | Bit/dim 3.5496(3.5295) | Xent 0.0006(0.0038) | Loss 8.8900(9.2077) | Error 0.0000(0.0010) Steps 862(844.68) | Grad Norm 1.7009(3.3527) | Total Time 0.00(0.00)\n",
      "Iter 22210 | Time 22.7772(23.4094) | Bit/dim 3.5340(3.5285) | Xent 0.0041(0.0036) | Loss 8.7934(9.0986) | Error 0.0011(0.0009) Steps 838(841.42) | Grad Norm 1.9284(3.0796) | Total Time 0.00(0.00)\n",
      "Iter 22220 | Time 23.7477(23.4359) | Bit/dim 3.5309(3.5298) | Xent 0.0005(0.0031) | Loss 8.9285(9.0302) | Error 0.0000(0.0007) Steps 850(841.18) | Grad Norm 0.9679(2.9210) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0404 | Time 102.3399, Epoch Time 1407.8297(1397.1208), Bit/dim 3.5539(best: 3.5219), Xent 2.7602, Loss 4.9340, Error 0.3337(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22230 | Time 22.5642(23.4309) | Bit/dim 3.4850(3.5295) | Xent 0.0019(0.0034) | Loss 8.6229(9.6653) | Error 0.0000(0.0007) Steps 802(842.17) | Grad Norm 1.7943(2.8949) | Total Time 0.00(0.00)\n",
      "Iter 22240 | Time 23.3109(23.4278) | Bit/dim 3.5363(3.5297) | Xent 0.0010(0.0032) | Loss 8.8757(9.4484) | Error 0.0000(0.0008) Steps 808(837.95) | Grad Norm 1.0678(2.6415) | Total Time 0.00(0.00)\n",
      "Iter 22250 | Time 23.5748(23.4270) | Bit/dim 3.5247(3.5271) | Xent 0.0028(0.0032) | Loss 8.8740(9.2759) | Error 0.0022(0.0009) Steps 814(837.44) | Grad Norm 2.5095(2.7715) | Total Time 0.00(0.00)\n",
      "Iter 22260 | Time 23.8687(23.5009) | Bit/dim 3.5319(3.5273) | Xent 0.0065(0.0032) | Loss 8.8279(9.1511) | Error 0.0033(0.0010) Steps 838(837.90) | Grad Norm 3.4808(2.9938) | Total Time 0.00(0.00)\n",
      "Iter 22270 | Time 23.2591(23.5200) | Bit/dim 3.5382(3.5249) | Xent 0.0059(0.0037) | Loss 8.8672(9.0695) | Error 0.0022(0.0011) Steps 850(836.98) | Grad Norm 3.0779(2.9728) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0405 | Time 103.3275, Epoch Time 1417.2577(1397.7250), Bit/dim 3.5525(best: 3.5219), Xent 2.7454, Loss 4.9252, Error 0.3322(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22280 | Time 23.6385(23.4658) | Bit/dim 3.5234(3.5258) | Xent 0.0009(0.0035) | Loss 8.9093(9.7987) | Error 0.0000(0.0010) Steps 862(838.08) | Grad Norm 1.5196(2.9585) | Total Time 0.00(0.00)\n",
      "Iter 22290 | Time 22.9934(23.4641) | Bit/dim 3.5268(3.5261) | Xent 0.0018(0.0033) | Loss 8.7382(9.5440) | Error 0.0011(0.0009) Steps 862(839.01) | Grad Norm 2.8831(2.8940) | Total Time 0.00(0.00)\n",
      "Iter 22300 | Time 23.7054(23.5424) | Bit/dim 3.5178(3.5260) | Xent 0.0036(0.0029) | Loss 8.8792(9.3578) | Error 0.0022(0.0009) Steps 862(842.21) | Grad Norm 7.8744(2.9596) | Total Time 0.00(0.00)\n",
      "Iter 22310 | Time 22.9112(23.4967) | Bit/dim 3.5160(3.5255) | Xent 0.0073(0.0029) | Loss 8.6579(9.2138) | Error 0.0033(0.0009) Steps 838(839.29) | Grad Norm 3.5973(3.0807) | Total Time 0.00(0.00)\n",
      "Iter 22320 | Time 22.8177(23.4358) | Bit/dim 3.5324(3.5255) | Xent 0.0133(0.0033) | Loss 8.8263(9.1089) | Error 0.0011(0.0010) Steps 850(837.71) | Grad Norm 3.2705(3.1815) | Total Time 0.00(0.00)\n",
      "Iter 22330 | Time 23.5362(23.4119) | Bit/dim 3.5135(3.5253) | Xent 0.0017(0.0033) | Loss 8.6346(9.0278) | Error 0.0011(0.0009) Steps 838(836.52) | Grad Norm 2.0840(3.0098) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0406 | Time 102.5352, Epoch Time 1411.2166(1398.1297), Bit/dim 3.5507(best: 3.5219), Xent 2.7609, Loss 4.9312, Error 0.3334(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22340 | Time 22.8298(23.4010) | Bit/dim 3.5124(3.5254) | Xent 0.0016(0.0030) | Loss 8.7430(9.6553) | Error 0.0000(0.0008) Steps 814(835.85) | Grad Norm 1.0255(2.7017) | Total Time 0.00(0.00)\n",
      "Iter 22350 | Time 24.1085(23.3986) | Bit/dim 3.5042(3.5233) | Xent 0.0107(0.0033) | Loss 8.7378(9.4159) | Error 0.0033(0.0010) Steps 862(834.15) | Grad Norm 7.7445(2.9045) | Total Time 0.00(0.00)\n",
      "Iter 22360 | Time 23.2082(23.4024) | Bit/dim 3.5281(3.5247) | Xent 0.0102(0.0033) | Loss 8.8888(9.2584) | Error 0.0033(0.0009) Steps 820(836.48) | Grad Norm 2.9030(2.7363) | Total Time 0.00(0.00)\n",
      "Iter 22370 | Time 22.9255(23.4488) | Bit/dim 3.5066(3.5240) | Xent 0.0020(0.0036) | Loss 8.7157(9.1420) | Error 0.0000(0.0011) Steps 826(836.59) | Grad Norm 2.0779(2.7326) | Total Time 0.00(0.00)\n",
      "Iter 22380 | Time 23.8534(23.4322) | Bit/dim 3.5301(3.5223) | Xent 0.0004(0.0048) | Loss 8.8671(9.0534) | Error 0.0000(0.0013) Steps 874(839.36) | Grad Norm 1.3135(2.9180) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0407 | Time 101.7955, Epoch Time 1412.2403(1398.5530), Bit/dim 3.5488(best: 3.5219), Xent 2.7988, Loss 4.9482, Error 0.3352(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22390 | Time 22.5925(23.4015) | Bit/dim 3.5378(3.5214) | Xent 0.0020(0.0048) | Loss 8.7942(9.7882) | Error 0.0011(0.0013) Steps 844(840.61) | Grad Norm 1.8432(2.9244) | Total Time 0.00(0.00)\n",
      "Iter 22400 | Time 24.1618(23.3569) | Bit/dim 3.5157(3.5190) | Xent 0.0053(0.0044) | Loss 8.7328(9.5269) | Error 0.0022(0.0012) Steps 892(839.23) | Grad Norm 4.1413(2.7992) | Total Time 0.00(0.00)\n",
      "Iter 22410 | Time 24.0384(23.3614) | Bit/dim 3.4861(3.5191) | Xent 0.0050(0.0041) | Loss 8.8239(9.3355) | Error 0.0011(0.0011) Steps 814(837.11) | Grad Norm 2.6360(2.7281) | Total Time 0.00(0.00)\n",
      "Iter 22420 | Time 23.4295(23.3256) | Bit/dim 3.4994(3.5188) | Xent 0.0087(0.0045) | Loss 8.8085(9.1908) | Error 0.0033(0.0012) Steps 874(839.05) | Grad Norm 4.5596(2.7058) | Total Time 0.00(0.00)\n",
      "Iter 22430 | Time 23.7173(23.3100) | Bit/dim 3.5175(3.5190) | Xent 0.0012(0.0041) | Loss 8.8080(9.0791) | Error 0.0000(0.0011) Steps 802(836.30) | Grad Norm 2.3355(2.6161) | Total Time 0.00(0.00)\n",
      "Iter 22440 | Time 23.0843(23.2858) | Bit/dim 3.5486(3.5217) | Xent 0.0023(0.0040) | Loss 8.8030(9.0090) | Error 0.0011(0.0010) Steps 838(834.63) | Grad Norm 2.9667(2.7612) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0408 | Time 102.7658, Epoch Time 1399.5252(1398.5822), Bit/dim 3.5471(best: 3.5219), Xent 2.7964, Loss 4.9453, Error 0.3375(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22450 | Time 24.4474(23.3240) | Bit/dim 3.5251(3.5213) | Xent 0.0009(0.0041) | Loss 8.9281(9.6306) | Error 0.0000(0.0012) Steps 844(837.86) | Grad Norm 2.9519(2.8803) | Total Time 0.00(0.00)\n",
      "Iter 22460 | Time 22.8747(23.1973) | Bit/dim 3.5217(3.5208) | Xent 0.0026(0.0037) | Loss 8.7407(9.3994) | Error 0.0011(0.0010) Steps 838(834.56) | Grad Norm 3.0204(2.8309) | Total Time 0.00(0.00)\n",
      "Iter 22470 | Time 22.3346(23.2389) | Bit/dim 3.5392(3.5201) | Xent 0.0008(0.0034) | Loss 8.9365(9.2356) | Error 0.0000(0.0009) Steps 832(835.86) | Grad Norm 1.6966(2.6946) | Total Time 0.00(0.00)\n",
      "Iter 22480 | Time 23.8365(23.2231) | Bit/dim 3.5212(3.5205) | Xent 0.0006(0.0030) | Loss 8.7935(9.1117) | Error 0.0000(0.0007) Steps 862(835.34) | Grad Norm 0.9621(2.3973) | Total Time 0.00(0.00)\n",
      "Iter 22490 | Time 23.1991(23.1947) | Bit/dim 3.4861(3.5205) | Xent 0.0005(0.0030) | Loss 8.7753(9.0281) | Error 0.0000(0.0006) Steps 832(835.61) | Grad Norm 1.9583(2.1775) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0409 | Time 101.3415, Epoch Time 1397.6302(1398.5536), Bit/dim 3.5446(best: 3.5219), Xent 2.7915, Loss 4.9404, Error 0.3369(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22500 | Time 24.2762(23.2387) | Bit/dim 3.5446(3.5189) | Xent 0.0006(0.0028) | Loss 8.9345(9.7462) | Error 0.0000(0.0006) Steps 838(836.43) | Grad Norm 1.5606(2.1267) | Total Time 0.00(0.00)\n",
      "Iter 22510 | Time 22.6064(23.2110) | Bit/dim 3.5294(3.5192) | Xent 0.0015(0.0028) | Loss 8.8481(9.4932) | Error 0.0000(0.0007) Steps 826(834.19) | Grad Norm 2.7881(2.1971) | Total Time 0.00(0.00)\n",
      "Iter 22520 | Time 23.3073(23.2663) | Bit/dim 3.5675(3.5195) | Xent 0.0006(0.0040) | Loss 8.8064(9.3100) | Error 0.0000(0.0010) Steps 790(833.20) | Grad Norm 1.9302(2.5240) | Total Time 0.00(0.00)\n",
      "Iter 22530 | Time 22.8808(23.2268) | Bit/dim 3.5290(3.5197) | Xent 0.0006(0.0038) | Loss 8.7638(9.1682) | Error 0.0000(0.0009) Steps 820(834.02) | Grad Norm 1.2412(2.5791) | Total Time 0.00(0.00)\n",
      "Iter 22540 | Time 23.5865(23.2880) | Bit/dim 3.5434(3.5219) | Xent 0.0034(0.0035) | Loss 8.9112(9.0710) | Error 0.0011(0.0008) Steps 832(832.68) | Grad Norm 2.8080(2.5038) | Total Time 0.00(0.00)\n",
      "Iter 22550 | Time 22.5582(23.3338) | Bit/dim 3.5354(3.5194) | Xent 0.0009(0.0038) | Loss 8.7675(8.9910) | Error 0.0000(0.0009) Steps 814(833.61) | Grad Norm 3.2926(2.8849) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0410 | Time 101.7571, Epoch Time 1404.3317(1398.7270), Bit/dim 3.5474(best: 3.5219), Xent 2.7810, Loss 4.9379, Error 0.3351(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22560 | Time 23.7321(23.4088) | Bit/dim 3.5245(3.5197) | Xent 0.0011(0.0032) | Loss 8.9288(9.6300) | Error 0.0000(0.0008) Steps 892(834.49) | Grad Norm 3.7906(2.8402) | Total Time 0.00(0.00)\n",
      "Iter 22570 | Time 21.5134(23.2910) | Bit/dim 3.5045(3.5181) | Xent 0.0015(0.0030) | Loss 8.7223(9.4029) | Error 0.0011(0.0008) Steps 814(834.06) | Grad Norm 4.0924(2.8002) | Total Time 0.00(0.00)\n",
      "Iter 22580 | Time 24.4919(23.3515) | Bit/dim 3.5028(3.5190) | Xent 0.0136(0.0034) | Loss 8.7041(9.2423) | Error 0.0022(0.0008) Steps 796(831.83) | Grad Norm 2.1912(2.5873) | Total Time 0.00(0.00)\n",
      "Iter 22590 | Time 23.1734(23.3497) | Bit/dim 3.5469(3.5216) | Xent 0.0085(0.0037) | Loss 8.9404(9.1328) | Error 0.0022(0.0010) Steps 802(828.32) | Grad Norm 3.3323(2.6776) | Total Time 0.00(0.00)\n",
      "Iter 22600 | Time 22.3012(23.3984) | Bit/dim 3.4903(3.5161) | Xent 0.0006(0.0036) | Loss 8.6696(9.0317) | Error 0.0000(0.0009) Steps 844(830.55) | Grad Norm 1.5404(2.6517) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0411 | Time 102.3052, Epoch Time 1411.4988(1399.1101), Bit/dim 3.5440(best: 3.5219), Xent 2.7888, Loss 4.9385, Error 0.3378(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22610 | Time 22.9894(23.4419) | Bit/dim 3.5413(3.5188) | Xent 0.0008(0.0030) | Loss 8.6597(9.7729) | Error 0.0000(0.0008) Steps 820(833.78) | Grad Norm 1.2715(2.5434) | Total Time 0.00(0.00)\n",
      "Iter 22620 | Time 25.1341(23.4220) | Bit/dim 3.5224(3.5184) | Xent 0.0018(0.0026) | Loss 8.8818(9.5190) | Error 0.0011(0.0007) Steps 796(834.05) | Grad Norm 2.8740(2.3090) | Total Time 0.00(0.00)\n",
      "Iter 22630 | Time 23.2723(23.3858) | Bit/dim 3.4949(3.5130) | Xent 0.0032(0.0028) | Loss 8.6834(9.3129) | Error 0.0011(0.0007) Steps 838(835.87) | Grad Norm 2.0193(2.2685) | Total Time 0.00(0.00)\n",
      "Iter 22640 | Time 23.1440(23.3414) | Bit/dim 3.5104(3.5136) | Xent 0.0091(0.0028) | Loss 8.8781(9.1751) | Error 0.0022(0.0007) Steps 832(835.99) | Grad Norm 2.2259(2.0682) | Total Time 0.00(0.00)\n",
      "Iter 22650 | Time 22.1567(23.2692) | Bit/dim 3.5228(3.5165) | Xent 0.0007(0.0025) | Loss 8.7129(9.0721) | Error 0.0000(0.0006) Steps 814(832.14) | Grad Norm 1.5873(2.0808) | Total Time 0.00(0.00)\n",
      "Iter 22660 | Time 23.0945(23.2184) | Bit/dim 3.5440(3.5180) | Xent 0.0068(0.0033) | Loss 8.8137(8.9982) | Error 0.0011(0.0008) Steps 820(832.91) | Grad Norm 4.7549(2.3181) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0412 | Time 102.0553, Epoch Time 1398.9974(1399.1067), Bit/dim 3.5464(best: 3.5219), Xent 2.8174, Loss 4.9551, Error 0.3338(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22670 | Time 22.7992(23.1281) | Bit/dim 3.5027(3.5165) | Xent 0.0070(0.0032) | Loss 8.6659(9.5909) | Error 0.0022(0.0008) Steps 808(829.12) | Grad Norm 3.3881(2.4381) | Total Time 0.00(0.00)\n",
      "Iter 22680 | Time 22.9276(23.1528) | Bit/dim 3.4839(3.5164) | Xent 0.0067(0.0038) | Loss 8.6258(9.3856) | Error 0.0022(0.0010) Steps 820(828.84) | Grad Norm 2.7410(2.6075) | Total Time 0.00(0.00)\n",
      "Iter 22690 | Time 23.1381(23.2234) | Bit/dim 3.5257(3.5163) | Xent 0.0029(0.0043) | Loss 8.8596(9.2292) | Error 0.0011(0.0011) Steps 814(828.60) | Grad Norm 4.0224(2.7420) | Total Time 0.00(0.00)\n",
      "Iter 22700 | Time 22.2027(23.1723) | Bit/dim 3.4967(3.5161) | Xent 0.0084(0.0041) | Loss 8.7747(9.1071) | Error 0.0033(0.0010) Steps 844(827.18) | Grad Norm 5.0215(2.8561) | Total Time 0.00(0.00)\n",
      "Iter 22710 | Time 23.1427(23.2590) | Bit/dim 3.5031(3.5157) | Xent 0.0038(0.0040) | Loss 8.7336(9.0063) | Error 0.0011(0.0011) Steps 832(831.37) | Grad Norm 3.1230(2.9306) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0413 | Time 102.3410, Epoch Time 1398.9665(1399.1025), Bit/dim 3.5458(best: 3.5219), Xent 2.7967, Loss 4.9441, Error 0.3310(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22720 | Time 23.4863(23.2514) | Bit/dim 3.4879(3.5158) | Xent 0.0052(0.0041) | Loss 8.6235(9.7014) | Error 0.0011(0.0012) Steps 850(833.29) | Grad Norm 2.6897(3.0670) | Total Time 0.00(0.00)\n",
      "Iter 22730 | Time 24.0917(23.3047) | Bit/dim 3.5026(3.5181) | Xent 0.0011(0.0042) | Loss 8.7389(9.4682) | Error 0.0000(0.0012) Steps 856(832.23) | Grad Norm 2.1961(3.0558) | Total Time 0.00(0.00)\n",
      "Iter 22740 | Time 22.3488(23.2483) | Bit/dim 3.5513(3.5196) | Xent 0.0074(0.0038) | Loss 8.8217(9.2993) | Error 0.0033(0.0011) Steps 850(831.00) | Grad Norm 3.4618(2.9918) | Total Time 0.00(0.00)\n",
      "Iter 22750 | Time 23.4281(23.2524) | Bit/dim 3.5129(3.5197) | Xent 0.0030(0.0033) | Loss 8.8205(9.1624) | Error 0.0011(0.0010) Steps 850(833.97) | Grad Norm 2.1513(2.7368) | Total Time 0.00(0.00)\n",
      "Iter 22760 | Time 22.8155(23.2396) | Bit/dim 3.5090(3.5173) | Xent 0.0027(0.0034) | Loss 8.7216(9.0586) | Error 0.0011(0.0010) Steps 790(831.18) | Grad Norm 2.0884(2.7646) | Total Time 0.00(0.00)\n",
      "Iter 22770 | Time 23.1979(23.2858) | Bit/dim 3.5267(3.5159) | Xent 0.0010(0.0036) | Loss 8.8467(8.9822) | Error 0.0000(0.0011) Steps 850(833.13) | Grad Norm 1.9556(2.8724) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0414 | Time 102.6045, Epoch Time 1403.4753(1399.2337), Bit/dim 3.5403(best: 3.5219), Xent 2.8355, Loss 4.9580, Error 0.3385(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22780 | Time 23.9119(23.3317) | Bit/dim 3.4874(3.5158) | Xent 0.0014(0.0043) | Loss 8.7549(9.6191) | Error 0.0000(0.0011) Steps 880(834.54) | Grad Norm 2.6106(2.9328) | Total Time 0.00(0.00)\n",
      "Iter 22790 | Time 23.1672(23.2757) | Bit/dim 3.5184(3.5159) | Xent 0.0055(0.0044) | Loss 8.7716(9.3950) | Error 0.0011(0.0012) Steps 868(835.88) | Grad Norm 4.4765(2.9535) | Total Time 0.00(0.00)\n",
      "Iter 22800 | Time 22.6209(23.1955) | Bit/dim 3.5296(3.5137) | Xent 0.0013(0.0041) | Loss 8.6944(9.2306) | Error 0.0000(0.0012) Steps 814(834.87) | Grad Norm 2.5319(3.0332) | Total Time 0.00(0.00)\n",
      "Iter 22810 | Time 23.0137(23.1433) | Bit/dim 3.5083(3.5144) | Xent 0.0011(0.0047) | Loss 8.7195(9.1099) | Error 0.0000(0.0014) Steps 802(832.90) | Grad Norm 2.6148(3.1487) | Total Time 0.00(0.00)\n",
      "Iter 22820 | Time 22.9263(23.1185) | Bit/dim 3.4851(3.5140) | Xent 0.0006(0.0042) | Loss 8.7442(9.0185) | Error 0.0000(0.0012) Steps 826(830.26) | Grad Norm 2.6069(3.0337) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0415 | Time 102.1785, Epoch Time 1394.4601(1399.0905), Bit/dim 3.5407(best: 3.5219), Xent 2.7609, Loss 4.9211, Error 0.3350(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22830 | Time 21.7259(23.1007) | Bit/dim 3.4694(3.5139) | Xent 0.0089(0.0038) | Loss 8.6510(9.7460) | Error 0.0033(0.0011) Steps 808(829.25) | Grad Norm 4.5746(2.8081) | Total Time 0.00(0.00)\n",
      "Iter 22840 | Time 23.5187(23.0883) | Bit/dim 3.5043(3.5138) | Xent 0.0008(0.0035) | Loss 8.6128(9.4839) | Error 0.0000(0.0010) Steps 796(827.10) | Grad Norm 2.0946(2.8039) | Total Time 0.00(0.00)\n",
      "Iter 22850 | Time 23.1275(23.1062) | Bit/dim 3.5392(3.5129) | Xent 0.0034(0.0029) | Loss 8.7201(9.2934) | Error 0.0022(0.0008) Steps 808(828.58) | Grad Norm 2.2430(2.5031) | Total Time 0.00(0.00)\n",
      "Iter 22860 | Time 23.4823(23.1991) | Bit/dim 3.5285(3.5132) | Xent 0.0064(0.0034) | Loss 8.7849(9.1594) | Error 0.0011(0.0009) Steps 814(831.52) | Grad Norm 2.7602(2.5104) | Total Time 0.00(0.00)\n",
      "Iter 22870 | Time 21.6945(23.1886) | Bit/dim 3.4931(3.5141) | Xent 0.0034(0.0032) | Loss 8.5781(9.0543) | Error 0.0011(0.0009) Steps 802(832.57) | Grad Norm 2.7565(2.4907) | Total Time 0.00(0.00)\n",
      "Iter 22880 | Time 23.3337(23.2168) | Bit/dim 3.5312(3.5159) | Xent 0.0053(0.0032) | Loss 8.8950(8.9893) | Error 0.0011(0.0008) Steps 874(836.35) | Grad Norm 2.0384(2.3635) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0416 | Time 102.5934, Epoch Time 1398.8121(1399.0822), Bit/dim 3.5409(best: 3.5219), Xent 2.7901, Loss 4.9360, Error 0.3366(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22890 | Time 22.8981(23.2809) | Bit/dim 3.5212(3.5159) | Xent 0.0013(0.0036) | Loss 8.6937(9.6180) | Error 0.0000(0.0010) Steps 820(836.18) | Grad Norm 1.5529(2.5231) | Total Time 0.00(0.00)\n",
      "Iter 22900 | Time 23.0929(23.2942) | Bit/dim 3.5069(3.5155) | Xent 0.0004(0.0040) | Loss 8.7028(9.3986) | Error 0.0000(0.0011) Steps 844(835.22) | Grad Norm 2.7048(2.6589) | Total Time 0.00(0.00)\n",
      "Iter 22910 | Time 23.5330(23.3677) | Bit/dim 3.5053(3.5150) | Xent 0.0118(0.0044) | Loss 8.8367(9.2421) | Error 0.0033(0.0013) Steps 838(834.14) | Grad Norm 6.9785(3.0591) | Total Time 0.00(0.00)\n",
      "Iter 22920 | Time 22.5684(23.3286) | Bit/dim 3.5602(3.5171) | Xent 0.0080(0.0045) | Loss 8.7432(9.1295) | Error 0.0022(0.0014) Steps 832(831.86) | Grad Norm 4.8100(3.3670) | Total Time 0.00(0.00)\n",
      "Iter 22930 | Time 24.2671(23.4084) | Bit/dim 3.4826(3.5153) | Xent 0.0012(0.0042) | Loss 8.7137(9.0397) | Error 0.0000(0.0012) Steps 898(832.25) | Grad Norm 3.6215(3.4256) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0417 | Time 102.0386, Epoch Time 1413.9367(1399.5278), Bit/dim 3.5437(best: 3.5219), Xent 2.8098, Loss 4.9486, Error 0.3336(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 22940 | Time 24.7625(23.3972) | Bit/dim 3.5241(3.5156) | Xent 0.0075(0.0045) | Loss 8.9424(9.7491) | Error 0.0033(0.0012) Steps 880(834.25) | Grad Norm 6.0957(3.7266) | Total Time 0.00(0.00)\n",
      "Iter 22950 | Time 22.4289(23.3821) | Bit/dim 3.4996(3.5145) | Xent 0.0004(0.0041) | Loss 8.7303(9.4870) | Error 0.0000(0.0011) Steps 820(831.43) | Grad Norm 3.8349(3.5929) | Total Time 0.00(0.00)\n",
      "Iter 22960 | Time 23.2556(23.3339) | Bit/dim 3.5112(3.5148) | Xent 0.0015(0.0048) | Loss 8.8843(9.3086) | Error 0.0000(0.0012) Steps 850(831.25) | Grad Norm 1.9858(3.5989) | Total Time 0.00(0.00)\n",
      "Iter 22970 | Time 22.7564(23.3296) | Bit/dim 3.5121(3.5169) | Xent 0.0045(0.0060) | Loss 8.7167(9.1750) | Error 0.0011(0.0014) Steps 814(831.17) | Grad Norm 3.4633(3.8388) | Total Time 0.00(0.00)\n",
      "Iter 22980 | Time 22.8739(23.2643) | Bit/dim 3.5634(3.5189) | Xent 0.0007(0.0063) | Loss 8.8081(9.0673) | Error 0.0000(0.0015) Steps 826(826.28) | Grad Norm 4.7474(4.2289) | Total Time 0.00(0.00)\n",
      "Iter 22990 | Time 22.9165(23.2962) | Bit/dim 3.5251(3.5199) | Xent 0.0007(0.0055) | Loss 8.6546(9.0058) | Error 0.0000(0.0013) Steps 844(830.68) | Grad Norm 4.1935(4.2715) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0418 | Time 101.7025, Epoch Time 1401.9527(1399.6005), Bit/dim 3.5535(best: 3.5219), Xent 2.8076, Loss 4.9573, Error 0.3345(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23000 | Time 23.7025(23.3993) | Bit/dim 3.5293(3.5199) | Xent 0.0121(0.0051) | Loss 8.9990(9.6265) | Error 0.0022(0.0012) Steps 856(832.96) | Grad Norm 12.7673(4.7157) | Total Time 0.00(0.00)\n",
      "Iter 23010 | Time 23.5662(23.3603) | Bit/dim 3.5240(3.5205) | Xent 0.0018(0.0046) | Loss 8.7721(9.4080) | Error 0.0011(0.0011) Steps 838(837.05) | Grad Norm 4.6151(4.5633) | Total Time 0.00(0.00)\n",
      "Iter 23020 | Time 23.5445(23.3737) | Bit/dim 3.5754(3.5265) | Xent 0.0007(0.0050) | Loss 8.9515(9.2752) | Error 0.0000(0.0012) Steps 844(835.73) | Grad Norm 8.3528(5.0797) | Total Time 0.00(0.00)\n",
      "Iter 23030 | Time 23.4747(23.3668) | Bit/dim 3.5573(3.5281) | Xent 0.0008(0.0043) | Loss 8.8858(9.1456) | Error 0.0000(0.0011) Steps 844(833.09) | Grad Norm 3.4142(5.2520) | Total Time 0.00(0.00)\n",
      "Iter 23040 | Time 23.3747(23.4269) | Bit/dim 3.5401(3.5282) | Xent 0.0037(0.0039) | Loss 8.7767(9.0621) | Error 0.0022(0.0010) Steps 820(833.68) | Grad Norm 5.7186(4.9743) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0419 | Time 103.3334, Epoch Time 1413.2872(1400.0111), Bit/dim 3.5551(best: 3.5219), Xent 2.7798, Loss 4.9450, Error 0.3336(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23050 | Time 24.4005(23.4349) | Bit/dim 3.5504(3.5274) | Xent 0.0046(0.0041) | Loss 8.7012(9.7760) | Error 0.0022(0.0011) Steps 808(831.03) | Grad Norm 11.7380(5.3287) | Total Time 0.00(0.00)\n",
      "Iter 23060 | Time 22.5782(23.4006) | Bit/dim 3.5186(3.5267) | Xent 0.0034(0.0040) | Loss 8.7591(9.5206) | Error 0.0011(0.0011) Steps 844(832.87) | Grad Norm 3.7719(5.4740) | Total Time 0.00(0.00)\n",
      "Iter 23070 | Time 24.2727(23.3895) | Bit/dim 3.5214(3.5280) | Xent 0.0107(0.0045) | Loss 8.7729(9.3374) | Error 0.0011(0.0011) Steps 838(833.88) | Grad Norm 9.7083(5.9437) | Total Time 0.00(0.00)\n",
      "Iter 23080 | Time 24.0398(23.5381) | Bit/dim 3.5104(3.5342) | Xent 0.0024(0.0041) | Loss 8.7274(9.2056) | Error 0.0000(0.0009) Steps 862(836.49) | Grad Norm 4.6934(6.4803) | Total Time 0.00(0.00)\n",
      "Iter 23090 | Time 22.1767(23.5195) | Bit/dim 3.5546(3.5382) | Xent 0.0129(0.0052) | Loss 8.6881(9.1091) | Error 0.0033(0.0012) Steps 826(836.38) | Grad Norm 6.2259(6.2854) | Total Time 0.00(0.00)\n",
      "Iter 23100 | Time 23.0035(23.5454) | Bit/dim 3.5852(3.5417) | Xent 0.0018(0.0049) | Loss 8.8322(9.0332) | Error 0.0000(0.0012) Steps 838(836.87) | Grad Norm 2.5647(5.6382) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0420 | Time 103.6542, Epoch Time 1420.4926(1400.6256), Bit/dim 3.5641(best: 3.5219), Xent 2.7979, Loss 4.9631, Error 0.3416(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23110 | Time 22.7389(23.4940) | Bit/dim 3.5658(3.5433) | Xent 0.0031(0.0053) | Loss 8.7909(9.6690) | Error 0.0011(0.0014) Steps 808(835.19) | Grad Norm 2.3027(5.3572) | Total Time 0.00(0.00)\n",
      "Iter 23120 | Time 22.4473(23.4990) | Bit/dim 3.5657(3.5412) | Xent 0.0117(0.0064) | Loss 8.9078(9.4514) | Error 0.0022(0.0016) Steps 796(835.92) | Grad Norm 6.8185(5.3606) | Total Time 0.00(0.00)\n",
      "Iter 23130 | Time 23.8097(23.4485) | Bit/dim 3.5628(3.5387) | Xent 0.0014(0.0064) | Loss 8.9176(9.2812) | Error 0.0000(0.0015) Steps 856(831.56) | Grad Norm 2.3904(5.0830) | Total Time 0.00(0.00)\n",
      "Iter 23140 | Time 22.9098(23.4162) | Bit/dim 3.5393(3.5425) | Xent 0.0170(0.0067) | Loss 8.8103(9.1784) | Error 0.0044(0.0016) Steps 832(830.15) | Grad Norm 11.6814(5.1652) | Total Time 0.00(0.00)\n",
      "Iter 23150 | Time 23.6659(23.2960) | Bit/dim 3.5400(3.5439) | Xent 0.0011(0.0067) | Loss 8.9355(9.0955) | Error 0.0000(0.0016) Steps 814(831.37) | Grad Norm 4.9099(5.1174) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0421 | Time 104.1437, Epoch Time 1404.0311(1400.7278), Bit/dim 3.5749(best: 3.5219), Xent 2.7673, Loss 4.9585, Error 0.3302(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23160 | Time 23.2450(23.2493) | Bit/dim 3.5613(3.5444) | Xent 0.0076(0.0069) | Loss 8.8994(9.7961) | Error 0.0011(0.0017) Steps 790(830.35) | Grad Norm 4.4922(4.9320) | Total Time 0.00(0.00)\n",
      "Iter 23170 | Time 25.6363(23.3573) | Bit/dim 3.5571(3.5442) | Xent 0.0014(0.0062) | Loss 8.8105(9.5413) | Error 0.0000(0.0016) Steps 898(830.71) | Grad Norm 3.8668(5.1067) | Total Time 0.00(0.00)\n",
      "Iter 23180 | Time 24.0085(23.3245) | Bit/dim 3.5597(3.5463) | Xent 0.0121(0.0060) | Loss 8.8622(9.3591) | Error 0.0022(0.0016) Steps 832(830.27) | Grad Norm 4.6897(5.5276) | Total Time 0.00(0.00)\n",
      "Iter 23190 | Time 23.2901(23.4092) | Bit/dim 3.5485(3.5486) | Xent 0.0012(0.0058) | Loss 8.7711(9.2265) | Error 0.0000(0.0014) Steps 838(828.95) | Grad Norm 3.0897(5.2803) | Total Time 0.00(0.00)\n",
      "Iter 23200 | Time 23.1578(23.3282) | Bit/dim 3.5889(3.5586) | Xent 0.0162(0.0071) | Loss 8.9153(9.1365) | Error 0.0022(0.0017) Steps 832(829.62) | Grad Norm 6.2924(6.6226) | Total Time 0.00(0.00)\n",
      "Iter 23210 | Time 23.7824(23.3804) | Bit/dim 3.6273(3.5720) | Xent 0.0025(0.0082) | Loss 8.9612(9.0943) | Error 0.0011(0.0020) Steps 814(831.60) | Grad Norm 3.7902(7.7905) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0422 | Time 102.8400, Epoch Time 1410.9950(1401.0358), Bit/dim 3.6250(best: 3.5219), Xent 2.7246, Loss 4.9873, Error 0.3303(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23220 | Time 23.5362(23.3369) | Bit/dim 3.6012(3.5772) | Xent 0.0139(0.0077) | Loss 8.9289(9.7354) | Error 0.0022(0.0019) Steps 802(832.90) | Grad Norm 7.0309(7.6133) | Total Time 0.00(0.00)\n",
      "Iter 23230 | Time 22.5170(23.3838) | Bit/dim 3.5358(3.5821) | Xent 0.0102(0.0077) | Loss 8.7651(9.5377) | Error 0.0022(0.0020) Steps 808(835.04) | Grad Norm 7.7360(7.8253) | Total Time 0.00(0.00)\n",
      "Iter 23240 | Time 22.7658(23.3570) | Bit/dim 3.6085(3.5872) | Xent 0.0030(0.0076) | Loss 9.0441(9.3851) | Error 0.0011(0.0019) Steps 820(835.42) | Grad Norm 20.6653(10.1073) | Total Time 0.00(0.00)\n",
      "Iter 23250 | Time 22.8370(23.3623) | Bit/dim 3.5963(3.5932) | Xent 0.0039(0.0080) | Loss 9.0276(9.2844) | Error 0.0022(0.0020) Steps 844(837.38) | Grad Norm 11.8372(10.1568) | Total Time 0.00(0.00)\n",
      "Iter 23260 | Time 22.8391(23.3957) | Bit/dim 3.6448(3.5988) | Xent 0.0085(0.0087) | Loss 9.1854(9.2250) | Error 0.0033(0.0022) Steps 850(838.96) | Grad Norm 6.3858(10.3419) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0423 | Time 103.0852, Epoch Time 1410.2175(1401.3112), Bit/dim 3.6208(best: 3.5219), Xent 2.7477, Loss 4.9946, Error 0.3406(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23270 | Time 23.1128(23.4370) | Bit/dim 3.5647(3.5980) | Xent 0.0036(0.0085) | Loss 8.8322(9.9558) | Error 0.0011(0.0022) Steps 808(832.95) | Grad Norm 11.6113(10.9154) | Total Time 0.00(0.00)\n",
      "Iter 23280 | Time 23.5015(23.3774) | Bit/dim 3.5784(3.5947) | Xent 0.0134(0.0081) | Loss 8.9983(9.6881) | Error 0.0033(0.0021) Steps 868(835.75) | Grad Norm 6.6982(10.3882) | Total Time 0.00(0.00)\n",
      "Iter 23290 | Time 24.6446(23.4537) | Bit/dim 3.5750(3.5870) | Xent 0.0058(0.0069) | Loss 8.9026(9.4846) | Error 0.0011(0.0018) Steps 850(834.87) | Grad Norm 4.8042(9.3989) | Total Time 0.00(0.00)\n",
      "Iter 23300 | Time 24.8253(23.5388) | Bit/dim 3.5635(3.5831) | Xent 0.0036(0.0065) | Loss 9.0088(9.3387) | Error 0.0011(0.0017) Steps 898(836.42) | Grad Norm 3.2906(8.4144) | Total Time 0.00(0.00)\n",
      "Iter 23310 | Time 23.0445(23.4493) | Bit/dim 3.5451(3.5781) | Xent 0.0057(0.0056) | Loss 8.8905(9.2273) | Error 0.0022(0.0015) Steps 862(837.32) | Grad Norm 6.2576(7.4476) | Total Time 0.00(0.00)\n",
      "Iter 23320 | Time 24.4093(23.5005) | Bit/dim 3.5575(3.5758) | Xent 0.0040(0.0054) | Loss 8.9155(9.1324) | Error 0.0011(0.0014) Steps 820(835.81) | Grad Norm 5.7351(6.7187) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0424 | Time 104.4093, Epoch Time 1417.5625(1401.7988), Bit/dim 3.5879(best: 3.5219), Xent 2.7405, Loss 4.9581, Error 0.3366(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23330 | Time 22.9213(23.4952) | Bit/dim 3.5612(3.5713) | Xent 0.0039(0.0052) | Loss 8.8748(9.7412) | Error 0.0011(0.0014) Steps 802(835.07) | Grad Norm 3.6010(6.1079) | Total Time 0.00(0.00)\n",
      "Iter 23340 | Time 23.1343(23.4945) | Bit/dim 3.5692(3.5700) | Xent 0.0043(0.0051) | Loss 8.9936(9.5272) | Error 0.0011(0.0014) Steps 826(836.01) | Grad Norm 3.7578(5.6630) | Total Time 0.00(0.00)\n",
      "Iter 23350 | Time 23.0513(23.5418) | Bit/dim 3.5200(3.5677) | Xent 0.0061(0.0064) | Loss 8.7296(9.3501) | Error 0.0022(0.0016) Steps 820(836.16) | Grad Norm 4.9908(5.6079) | Total Time 0.00(0.00)\n",
      "Iter 23360 | Time 23.1164(23.5495) | Bit/dim 3.5753(3.5682) | Xent 0.0068(0.0065) | Loss 8.8892(9.2339) | Error 0.0033(0.0016) Steps 814(834.85) | Grad Norm 3.1859(5.2669) | Total Time 0.00(0.00)\n",
      "Iter 23370 | Time 22.3989(23.4770) | Bit/dim 3.5212(3.5634) | Xent 0.0029(0.0062) | Loss 8.8320(9.1423) | Error 0.0011(0.0016) Steps 814(833.00) | Grad Norm 2.2633(4.7280) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0425 | Time 103.3798, Epoch Time 1418.7173(1402.3063), Bit/dim 3.5774(best: 3.5219), Xent 2.7249, Loss 4.9398, Error 0.3345(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23380 | Time 23.0158(23.5003) | Bit/dim 3.5557(3.5582) | Xent 0.0026(0.0054) | Loss 8.8680(9.8603) | Error 0.0011(0.0014) Steps 832(831.50) | Grad Norm 3.2678(4.1402) | Total Time 0.00(0.00)\n",
      "Iter 23390 | Time 24.0193(23.4429) | Bit/dim 3.5291(3.5588) | Xent 0.0055(0.0053) | Loss 8.8869(9.6071) | Error 0.0022(0.0015) Steps 802(829.90) | Grad Norm 2.4440(3.9012) | Total Time 0.00(0.00)\n",
      "Iter 23400 | Time 22.6326(23.4035) | Bit/dim 3.5457(3.5529) | Xent 0.0005(0.0045) | Loss 8.8883(9.4029) | Error 0.0000(0.0012) Steps 856(832.29) | Grad Norm 1.6249(3.4333) | Total Time 0.00(0.00)\n",
      "Iter 23410 | Time 21.8967(23.3531) | Bit/dim 3.5472(3.5502) | Xent 0.0065(0.0047) | Loss 8.8307(9.2535) | Error 0.0033(0.0013) Steps 856(831.74) | Grad Norm 4.5904(3.3389) | Total Time 0.00(0.00)\n",
      "Iter 23420 | Time 23.7495(23.3672) | Bit/dim 3.5379(3.5491) | Xent 0.0013(0.0043) | Loss 8.7708(9.1414) | Error 0.0000(0.0011) Steps 868(831.02) | Grad Norm 1.3533(3.0687) | Total Time 0.00(0.00)\n",
      "Iter 23430 | Time 21.7985(23.3763) | Bit/dim 3.5494(3.5440) | Xent 0.0012(0.0045) | Loss 8.8511(9.0636) | Error 0.0000(0.0012) Steps 832(832.73) | Grad Norm 2.5360(3.1747) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0426 | Time 103.8532, Epoch Time 1406.0740(1402.4193), Bit/dim 3.5670(best: 3.5219), Xent 2.7488, Loss 4.9414, Error 0.3319(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23440 | Time 22.1769(23.2494) | Bit/dim 3.4933(3.5429) | Xent 0.0012(0.0041) | Loss 8.7435(9.7024) | Error 0.0000(0.0009) Steps 826(832.48) | Grad Norm 1.9290(2.9711) | Total Time 0.00(0.00)\n",
      "Iter 23450 | Time 22.5787(23.1708) | Bit/dim 3.5278(3.5418) | Xent 0.0004(0.0046) | Loss 8.7593(9.4770) | Error 0.0000(0.0010) Steps 844(832.60) | Grad Norm 3.4511(3.3284) | Total Time 0.00(0.00)\n",
      "Iter 23460 | Time 23.5910(23.1982) | Bit/dim 3.5097(3.5405) | Xent 0.0011(0.0045) | Loss 8.8237(9.3158) | Error 0.0000(0.0011) Steps 850(832.58) | Grad Norm 2.1706(3.4871) | Total Time 0.00(0.00)\n",
      "Iter 23470 | Time 23.4076(23.3174) | Bit/dim 3.5180(3.5388) | Xent 0.0020(0.0044) | Loss 8.7783(9.1916) | Error 0.0000(0.0011) Steps 850(836.16) | Grad Norm 4.5058(3.7571) | Total Time 0.00(0.00)\n",
      "Iter 23480 | Time 22.3049(23.2315) | Bit/dim 3.5198(3.5367) | Xent 0.0114(0.0041) | Loss 8.7735(9.0890) | Error 0.0011(0.0010) Steps 832(834.09) | Grad Norm 7.6319(3.8970) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0427 | Time 102.6307, Epoch Time 1395.7368(1402.2189), Bit/dim 3.5581(best: 3.5219), Xent 2.7612, Loss 4.9387, Error 0.3338(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23490 | Time 22.5083(23.1942) | Bit/dim 3.5552(3.5379) | Xent 0.0011(0.0036) | Loss 8.8719(9.8019) | Error 0.0000(0.0009) Steps 808(833.12) | Grad Norm 2.3099(3.7163) | Total Time 0.00(0.00)\n",
      "Iter 23500 | Time 23.6781(23.2272) | Bit/dim 3.5596(3.5383) | Xent 0.0007(0.0040) | Loss 8.8774(9.5583) | Error 0.0000(0.0009) Steps 850(834.96) | Grad Norm 1.8189(3.5568) | Total Time 0.00(0.00)\n",
      "Iter 23510 | Time 23.1427(23.1674) | Bit/dim 3.5174(3.5353) | Xent 0.0023(0.0038) | Loss 8.8315(9.3558) | Error 0.0011(0.0010) Steps 856(833.45) | Grad Norm 3.1067(3.5297) | Total Time 0.00(0.00)\n",
      "Iter 23520 | Time 22.6649(23.0977) | Bit/dim 3.5337(3.5335) | Xent 0.0077(0.0042) | Loss 8.7716(9.2155) | Error 0.0011(0.0011) Steps 808(830.93) | Grad Norm 2.3655(3.4359) | Total Time 0.00(0.00)\n",
      "Iter 23530 | Time 23.6704(23.0729) | Bit/dim 3.5357(3.5343) | Xent 0.0068(0.0043) | Loss 8.7644(9.1170) | Error 0.0011(0.0012) Steps 808(830.14) | Grad Norm 5.4478(3.6308) | Total Time 0.00(0.00)\n",
      "Iter 23540 | Time 22.4286(23.1259) | Bit/dim 3.5235(3.5341) | Xent 0.0022(0.0049) | Loss 8.6576(9.0494) | Error 0.0011(0.0012) Steps 832(832.16) | Grad Norm 4.7370(3.9863) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0428 | Time 102.0780, Epoch Time 1393.0530(1401.9439), Bit/dim 3.5659(best: 3.5219), Xent 2.7546, Loss 4.9432, Error 0.3379(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23550 | Time 24.7551(23.1586) | Bit/dim 3.5228(3.5361) | Xent 0.0067(0.0050) | Loss 8.8606(9.6832) | Error 0.0011(0.0012) Steps 892(829.72) | Grad Norm 2.3585(3.8366) | Total Time 0.00(0.00)\n",
      "Iter 23560 | Time 23.5759(23.2494) | Bit/dim 3.5098(3.5371) | Xent 0.0037(0.0050) | Loss 8.7742(9.4608) | Error 0.0022(0.0013) Steps 862(830.57) | Grad Norm 1.8004(3.8004) | Total Time 0.00(0.00)\n",
      "Iter 23570 | Time 24.1262(23.3244) | Bit/dim 3.5203(3.5353) | Xent 0.0013(0.0041) | Loss 8.8536(9.2991) | Error 0.0000(0.0010) Steps 826(835.31) | Grad Norm 1.8864(3.3543) | Total Time 0.00(0.00)\n",
      "Iter 23580 | Time 22.9305(23.3608) | Bit/dim 3.5366(3.5305) | Xent 0.0018(0.0035) | Loss 8.9013(9.1785) | Error 0.0011(0.0010) Steps 838(834.55) | Grad Norm 2.1636(3.1517) | Total Time 0.00(0.00)\n",
      "Iter 23590 | Time 23.2414(23.3757) | Bit/dim 3.5370(3.5276) | Xent 0.0013(0.0033) | Loss 8.8123(9.0826) | Error 0.0000(0.0009) Steps 874(838.52) | Grad Norm 1.1608(2.7516) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0429 | Time 102.7540, Epoch Time 1411.7118(1402.2369), Bit/dim 3.5493(best: 3.5219), Xent 2.7381, Loss 4.9183, Error 0.3321(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23600 | Time 23.8087(23.3690) | Bit/dim 3.5219(3.5280) | Xent 0.0013(0.0030) | Loss 8.8819(9.8041) | Error 0.0011(0.0008) Steps 850(834.66) | Grad Norm 1.1161(2.4810) | Total Time 0.00(0.00)\n",
      "Iter 23610 | Time 23.1335(23.3660) | Bit/dim 3.5313(3.5241) | Xent 0.0062(0.0031) | Loss 8.8242(9.5367) | Error 0.0033(0.0009) Steps 826(835.57) | Grad Norm 2.5823(2.5433) | Total Time 0.00(0.00)\n",
      "Iter 23620 | Time 22.4737(23.2632) | Bit/dim 3.5352(3.5244) | Xent 0.0126(0.0037) | Loss 8.8174(9.3397) | Error 0.0022(0.0010) Steps 838(831.89) | Grad Norm 5.4399(2.7666) | Total Time 0.00(0.00)\n",
      "Iter 23630 | Time 23.3343(23.2488) | Bit/dim 3.5201(3.5212) | Xent 0.0045(0.0035) | Loss 8.7118(9.1900) | Error 0.0011(0.0009) Steps 826(831.72) | Grad Norm 4.1199(2.9990) | Total Time 0.00(0.00)\n",
      "Iter 23640 | Time 23.9279(23.3182) | Bit/dim 3.5004(3.5195) | Xent 0.0146(0.0037) | Loss 8.7435(9.0851) | Error 0.0022(0.0009) Steps 826(833.28) | Grad Norm 12.2681(3.3294) | Total Time 0.00(0.00)\n",
      "Iter 23650 | Time 23.9678(23.4449) | Bit/dim 3.4915(3.5203) | Xent 0.0015(0.0039) | Loss 8.7291(9.0014) | Error 0.0000(0.0011) Steps 868(837.73) | Grad Norm 3.6894(3.6552) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0430 | Time 101.9982, Epoch Time 1406.4857(1402.3644), Bit/dim 3.5434(best: 3.5219), Xent 2.7648, Loss 4.9258, Error 0.3358(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23660 | Time 23.3922(23.5573) | Bit/dim 3.5252(3.5188) | Xent 0.0058(0.0044) | Loss 8.8926(9.6351) | Error 0.0022(0.0012) Steps 868(839.64) | Grad Norm 6.3169(3.8354) | Total Time 0.00(0.00)\n",
      "Iter 23670 | Time 24.1880(23.5313) | Bit/dim 3.4944(3.5185) | Xent 0.0013(0.0044) | Loss 8.6906(9.4066) | Error 0.0000(0.0013) Steps 856(839.51) | Grad Norm 2.3728(3.9214) | Total Time 0.00(0.00)\n",
      "Iter 23680 | Time 22.8286(23.5638) | Bit/dim 3.4700(3.5165) | Xent 0.0008(0.0043) | Loss 8.7207(9.2492) | Error 0.0000(0.0012) Steps 838(838.31) | Grad Norm 3.5365(3.8137) | Total Time 0.00(0.00)\n",
      "Iter 23690 | Time 22.6011(23.6530) | Bit/dim 3.5354(3.5158) | Xent 0.0010(0.0036) | Loss 8.7575(9.1225) | Error 0.0000(0.0010) Steps 814(841.76) | Grad Norm 1.4193(3.3736) | Total Time 0.00(0.00)\n",
      "Iter 23700 | Time 23.6929(23.6536) | Bit/dim 3.4985(3.5161) | Xent 0.0014(0.0038) | Loss 8.7667(9.0277) | Error 0.0000(0.0010) Steps 856(841.90) | Grad Norm 1.2762(3.1151) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0431 | Time 104.5979, Epoch Time 1425.7752(1403.0667), Bit/dim 3.5400(best: 3.5219), Xent 2.7785, Loss 4.9292, Error 0.3328(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23710 | Time 24.2250(23.6224) | Bit/dim 3.5288(3.5147) | Xent 0.0100(0.0034) | Loss 8.8676(9.7278) | Error 0.0022(0.0009) Steps 820(841.45) | Grad Norm 3.8630(2.7531) | Total Time 0.00(0.00)\n",
      "Iter 23720 | Time 22.9262(23.6029) | Bit/dim 3.5196(3.5142) | Xent 0.0008(0.0031) | Loss 8.8665(9.4846) | Error 0.0000(0.0008) Steps 820(840.88) | Grad Norm 1.2221(2.4140) | Total Time 0.00(0.00)\n",
      "Iter 23730 | Time 24.8256(23.6986) | Bit/dim 3.4851(3.5115) | Xent 0.0184(0.0035) | Loss 8.7524(9.3048) | Error 0.0033(0.0008) Steps 838(841.93) | Grad Norm 3.3963(2.3630) | Total Time 0.00(0.00)\n",
      "Iter 23740 | Time 24.5935(23.6490) | Bit/dim 3.4882(3.5117) | Xent 0.0031(0.0032) | Loss 8.8452(9.1784) | Error 0.0011(0.0007) Steps 844(840.80) | Grad Norm 5.2906(2.2897) | Total Time 0.00(0.00)\n",
      "Iter 23750 | Time 22.9651(23.5940) | Bit/dim 3.4784(3.5105) | Xent 0.0009(0.0036) | Loss 8.7782(9.0688) | Error 0.0000(0.0009) Steps 826(839.97) | Grad Norm 2.0843(2.7348) | Total Time 0.00(0.00)\n",
      "Iter 23760 | Time 24.4356(23.6518) | Bit/dim 3.5220(3.5121) | Xent 0.0010(0.0032) | Loss 8.8197(8.9851) | Error 0.0000(0.0009) Steps 820(840.21) | Grad Norm 2.2135(2.8213) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0432 | Time 102.0381, Epoch Time 1423.8439(1403.6900), Bit/dim 3.5420(best: 3.5219), Xent 2.8433, Loss 4.9637, Error 0.3357(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23770 | Time 23.8658(23.5258) | Bit/dim 3.5273(3.5123) | Xent 0.0033(0.0040) | Loss 8.7912(9.5952) | Error 0.0011(0.0009) Steps 850(838.96) | Grad Norm 2.4126(2.8204) | Total Time 0.00(0.00)\n",
      "Iter 23780 | Time 23.2173(23.5955) | Bit/dim 3.5048(3.5096) | Xent 0.0017(0.0036) | Loss 8.6677(9.3712) | Error 0.0000(0.0009) Steps 838(839.55) | Grad Norm 2.1177(2.8296) | Total Time 0.00(0.00)\n",
      "Iter 23790 | Time 24.0361(23.6470) | Bit/dim 3.5201(3.5107) | Xent 0.0016(0.0039) | Loss 8.8291(9.2227) | Error 0.0000(0.0009) Steps 838(841.11) | Grad Norm 1.9062(2.7289) | Total Time 0.00(0.00)\n",
      "Iter 23800 | Time 23.5260(23.5708) | Bit/dim 3.5176(3.5118) | Xent 0.0069(0.0038) | Loss 8.7795(9.1070) | Error 0.0022(0.0009) Steps 820(838.10) | Grad Norm 2.2549(2.6048) | Total Time 0.00(0.00)\n",
      "Iter 23810 | Time 24.3678(23.6015) | Bit/dim 3.4720(3.5115) | Xent 0.0117(0.0039) | Loss 8.6597(9.0166) | Error 0.0022(0.0009) Steps 874(839.93) | Grad Norm 3.3864(2.5870) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0433 | Time 102.5964, Epoch Time 1418.4237(1404.1320), Bit/dim 3.5359(best: 3.5219), Xent 2.8224, Loss 4.9472, Error 0.3358(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23820 | Time 24.0445(23.5197) | Bit/dim 3.5581(3.5131) | Xent 0.0098(0.0037) | Loss 8.9567(9.7517) | Error 0.0022(0.0008) Steps 820(838.83) | Grad Norm 3.3746(2.4820) | Total Time 0.00(0.00)\n",
      "Iter 23830 | Time 23.6265(23.5919) | Bit/dim 3.5154(3.5103) | Xent 0.0011(0.0037) | Loss 8.7384(9.4895) | Error 0.0000(0.0008) Steps 820(839.02) | Grad Norm 1.1983(2.2947) | Total Time 0.00(0.00)\n",
      "Iter 23840 | Time 22.6931(23.5280) | Bit/dim 3.4855(3.5076) | Xent 0.0102(0.0033) | Loss 8.7716(9.3007) | Error 0.0011(0.0007) Steps 868(839.21) | Grad Norm 1.2206(1.9949) | Total Time 0.00(0.00)\n",
      "Iter 23850 | Time 23.9470(23.5649) | Bit/dim 3.5302(3.5074) | Xent 0.0006(0.0029) | Loss 8.8688(9.1715) | Error 0.0000(0.0006) Steps 838(842.03) | Grad Norm 0.9037(1.8151) | Total Time 0.00(0.00)\n",
      "Iter 23860 | Time 23.7058(23.4871) | Bit/dim 3.5057(3.5090) | Xent 0.0005(0.0030) | Loss 8.7445(9.0774) | Error 0.0000(0.0007) Steps 790(841.25) | Grad Norm 1.5102(2.2000) | Total Time 0.00(0.00)\n",
      "Iter 23870 | Time 23.7604(23.4387) | Bit/dim 3.5022(3.5102) | Xent 0.0007(0.0029) | Loss 8.8352(9.0077) | Error 0.0000(0.0007) Steps 868(840.81) | Grad Norm 2.8391(2.3972) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0434 | Time 102.7836, Epoch Time 1411.9620(1404.3669), Bit/dim 3.5347(best: 3.5219), Xent 2.8413, Loss 4.9554, Error 0.3350(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23880 | Time 23.7046(23.4232) | Bit/dim 3.4909(3.5092) | Xent 0.0025(0.0033) | Loss 8.6428(9.6248) | Error 0.0011(0.0007) Steps 820(838.93) | Grad Norm 3.0419(2.5896) | Total Time 0.00(0.00)\n",
      "Iter 23890 | Time 23.6383(23.4615) | Bit/dim 3.4969(3.5097) | Xent 0.0093(0.0031) | Loss 8.7635(9.4091) | Error 0.0022(0.0007) Steps 832(837.59) | Grad Norm 3.4119(2.5313) | Total Time 0.00(0.00)\n",
      "Iter 23900 | Time 22.8398(23.4727) | Bit/dim 3.4944(3.5092) | Xent 0.0016(0.0032) | Loss 8.8130(9.2485) | Error 0.0011(0.0008) Steps 826(839.65) | Grad Norm 1.5187(2.4525) | Total Time 0.00(0.00)\n",
      "Iter 23910 | Time 24.4702(23.4505) | Bit/dim 3.4882(3.5080) | Xent 0.0007(0.0027) | Loss 8.8351(9.1209) | Error 0.0000(0.0007) Steps 874(838.63) | Grad Norm 0.8324(2.2185) | Total Time 0.00(0.00)\n",
      "Iter 23920 | Time 24.0661(23.5107) | Bit/dim 3.5117(3.5079) | Xent 0.0029(0.0025) | Loss 8.7266(9.0290) | Error 0.0011(0.0006) Steps 874(840.83) | Grad Norm 2.0190(2.0261) | Total Time 0.00(0.00)\n",
      "validating...\n",
      "Epoch 0435 | Time 102.7881, Epoch Time 1417.3279(1404.7558), Bit/dim 3.5341(best: 3.5219), Xent 2.8404, Loss 4.9543, Error 0.3398(best: 0.3164)\n",
      "===> Using batch size 900. Total 55 iterations/epoch.\n",
      "Iter 23930 | Time 24.0086(23.5536) | Bit/dim 3.5344(3.5067) | Xent 0.0030(0.0022) | Loss 8.8484(9.7376) | Error 0.0011(0.0006) Steps 808(837.71) | Grad Norm 2.8743(1.9681) | Total Time 0.00(0.00)\n",
      "Iter 23940 | Time 22.2816(23.4169) | Bit/dim 3.5003(3.5079) | Xent 0.0007(0.0020) | Loss 8.7147(9.4884) | Error 0.0000(0.0005) Steps 814(837.55) | Grad Norm 1.0091(1.9204) | Total Time 0.00(0.00)\n",
      "Iter 23950 | Time 22.7787(23.4303) | Bit/dim 3.4839(3.5066) | Xent 0.0050(0.0021) | Loss 8.7534(9.3043) | Error 0.0011(0.0005) Steps 826(839.47) | Grad Norm 3.3265(1.9802) | Total Time 0.00(0.00)\n",
      "Iter 23960 | Time 23.3336(23.3650) | Bit/dim 3.5162(3.5070) | Xent 0.0004(0.0022) | Loss 8.7446(9.1730) | Error 0.0000(0.0005) Steps 880(839.76) | Grad Norm 0.9750(1.9814) | Total Time 0.00(0.00)\n",
      "Iter 23970 | Time 23.0525(23.3038) | Bit/dim 3.5334(3.5085) | Xent 0.0005(0.0023) | Loss 8.8354(9.0692) | Error 0.0000(0.0006) Steps 856(839.23) | Grad Norm 1.1778(1.9358) | Total Time 0.00(0.00)\n"
     ]
    }
   ],
   "source": [
    "%run -p ../train_cnf_disentangle_rl_multiscale.py --data cifar10 --dims 64,64,64 --strides 1,1,1,1 --num_blocks 2 --layer_type concat --multiscale True --rademacher True --batch_size 900 --test_batch_size 500 --save ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run3 --resume ../experiments_published/cnf_conditional_disentangle_cifar10_bs900_sratio_0_5_drop_0_5_rl_stdscale_6_multiscale_run3/epoch_250_checkpt.pth --seed 3 --lr 0.0001 --conditional True --controlled_tol False --train_mode semisup --log_freq 10 --weight_y 0.5 --condition_ratio 0.5 --dropout_rate 0.5 --scale_fac 1.0 --scale_std 6.0\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
