{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/latent_ode_infocnf.py\n",
      "import os\n",
      "import argparse\n",
      "import logging\n",
      "import time\n",
      "import numpy as np\n",
      "import numpy.random as npr\n",
      "\n",
      "import matplotlib\n",
      "matplotlib.use('Agg')\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "import torch.nn.functional as F\n",
      "\n",
      "import lib.layers.wrappers.cnf_regularization as reg_lib\n",
      "import lib.spectral_norm as spectral_norm\n",
      "import lib.layers as layers\n",
      "from lib.layers.odefunc import divergence_bf, divergence_approx\n",
      "\n",
      "import lib.toy_data as toy_data\n",
      "import lib.utils as utils\n",
      "from lib.visualize_flow import visualize_transform\n",
      "import lib.layers.odefunc as odefunc\n",
      "\n",
      "from lib import modules\n",
      "\n",
      "from train_misc import standard_normal_logprob\n",
      "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
      "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
      "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
      "from train_misc import build_model_tabular\n",
      "\n",
      "from diagnostics.viz_toy import save_trajectory, trajectory_to_video\n",
      "\n",
      "from tensorboardX import SummaryWriter\n",
      "\n",
      "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams', 'fixed_adams']\n",
      "parser = argparse.ArgumentParser('Continuous Normalizing Flow')\n",
      "parser.add_argument(\n",
      "    '--data', choices=['swissroll', '8gaussians', 'pinwheel', 'circles', 'moons', '2spirals', 'checkerboard', 'rings'],\n",
      "    type=str, default='pinwheel'\n",
      ")\n",
      "parser.add_argument(\n",
      "    \"--layer_type\", type=str, default=\"concatsquash\",\n",
      "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
      ")\n",
      "\n",
      "parser.add_argument('--adjoint', type=eval, default=False)\n",
      "parser.add_argument('--visualize', type=eval, default=False)\n",
      "parser.add_argument('--niters', type=int, default=2000)\n",
      "parser.add_argument('--lr', type=float, default=0.01)\n",
      "parser.add_argument('--gpu', type=int, default=0)\n",
      "parser.add_argument('--train_dir', type=str, default=None)\n",
      "parser.add_argument('--monitor_freq', type=int, default=50)\n",
      "\n",
      "parser.add_argument('--dims', type=str, default='20-20')\n",
      "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
      "parser.add_argument('--time_length', type=float, default=0.5)\n",
      "parser.add_argument('--train_T', type=eval, default=True)\n",
      "parser.add_argument(\"--divergence_fn\", type=str, default=\"brute_force\", choices=[\"brute_force\", \"approximate\"])\n",
      "parser.add_argument(\"--nonlinearity\", type=str, default=\"tanh\", choices=odefunc.NONLINEARITIES)\n",
      "\n",
      "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
      "parser.add_argument('--atol', type=float, default=1e-5)\n",
      "parser.add_argument('--rtol', type=float, default=1e-5)\n",
      "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
      "\n",
      "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
      "parser.add_argument('--test_atol', type=float, default=None)\n",
      "parser.add_argument('--test_rtol', type=float, default=None)\n",
      "\n",
      "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--rademacher', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--batch_norm', type=eval, default=False, choices=[True, False])\n",
      "parser.add_argument('--bn_lag', type=float, default=0)\n",
      "\n",
      "parser.add_argument('--batch_size', type=int, default=100)\n",
      "parser.add_argument('--test_batch_size', type=int, default=1000)\n",
      "parser.add_argument('--weight_decay', type=float, default=1e-5)\n",
      "\n",
      "# Track quantities\n",
      "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
      "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
      "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
      "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
      "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
      "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
      "\n",
      "parser.add_argument('--save', type=str, default='experiments/cnf')\n",
      "parser.add_argument('--viz_freq', type=int, default=100)\n",
      "parser.add_argument('--val_freq', type=int, default=100)\n",
      "parser.add_argument('--log_freq', type=int, default=10)\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "# logger\n",
      "utils.makedirs(args.save)\n",
      "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))\n",
      "writer = SummaryWriter(os.path.join(args.save, 'tensorboard')) # write to tensorboard\n",
      "\n",
      "if args.layer_type == \"blend\":\n",
      "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
      "    args.time_length = 1.0\n",
      "\n",
      "logger.info(args)\n",
      "\n",
      "if args.adjoint:\n",
      "    from torchdiffeq import odeint_adjoint as odeint\n",
      "else:\n",
      "    from torchdiffeq import odeint\n",
      "\n",
      "\n",
      "def generate_spiral2d(nspiral=1000,\n",
      "                      ntotal=500,\n",
      "                      nsample=100,\n",
      "                      start=0.,\n",
      "                      stop=1,  # approximately equal to 6pi\n",
      "                      noise_std=.1,\n",
      "                      a=0.,\n",
      "                      b=1.,\n",
      "                      savefig=True):\n",
      "    \"\"\"Parametric formula for 2d spiral is `r = a + b * theta`.\n",
      "\n",
      "    Args:\n",
      "      nspiral: number of spirals, i.e. batch dimension\n",
      "      ntotal: total number of datapoints per spiral\n",
      "      nsample: number of sampled datapoints for model fitting per spiral\n",
      "      start: spiral starting theta value\n",
      "      stop: spiral ending theta value\n",
      "      noise_std: observation noise standard deviation\n",
      "      a, b: parameters of the Archimedean spiral\n",
      "      savefig: plot the ground truth for sanity check\n",
      "\n",
      "    Returns: \n",
      "      Tuple where first element is true trajectory of size (nspiral, ntotal, 2),\n",
      "      second element is noisy observations of size (nspiral, nsample, 2),\n",
      "      third element is timestamps of size (ntotal,),\n",
      "      and fourth element is timestamps of size (nsample,)\n",
      "    \"\"\"\n",
      "\n",
      "    # add 1 all timestamps to avoid division by 0\n",
      "    orig_ts = np.linspace(start, stop, num=ntotal)\n",
      "    samp_ts = orig_ts[:nsample]\n",
      "\n",
      "    # generate clock-wise and counter clock-wise spirals in observation space\n",
      "    # with two sets of time-invariant latent dynamics\n",
      "    zs_cw = stop + 1. - orig_ts\n",
      "    rs_cw = a + b * 50. / zs_cw\n",
      "    xs, ys = rs_cw * np.cos(zs_cw) - 5., rs_cw * np.sin(zs_cw)\n",
      "    orig_traj_cw = np.stack((xs, ys), axis=1)\n",
      "\n",
      "    zs_cc = orig_ts\n",
      "    rw_cc = a + b * zs_cc\n",
      "    xs, ys = rw_cc * np.cos(zs_cc) + 5., rw_cc * np.sin(zs_cc)\n",
      "    orig_traj_cc = np.stack((xs, ys), axis=1)\n",
      "\n",
      "    if savefig:\n",
      "        plt.figure()\n",
      "        plt.plot(orig_traj_cw[:, 0], orig_traj_cw[:, 1], label='clock')\n",
      "        plt.plot(orig_traj_cc[:, 0], orig_traj_cc[:, 1], label='counter clock')\n",
      "        plt.legend()\n",
      "        plt.savefig('./ground_truth.png', dpi=500)\n",
      "        print('Saved ground truth spiral at {}'.format('./ground_truth.png'))\n",
      "\n",
      "    # sample starting timestamps\n",
      "    orig_trajs = []\n",
      "    samp_trajs = []\n",
      "    samp_trajs_next = []\n",
      "    for _ in range(nspiral):\n",
      "        # don't sample t0 very near the start or the end\n",
      "        t0_idx = npr.multinomial(\n",
      "            1, [1. / (ntotal - 2. * nsample)] * (ntotal - int(2 * nsample)))\n",
      "        t0_idx = np.argmax(t0_idx) + nsample\n",
      "        t0_idx_next = t0_idx + 1\n",
      "\n",
      "        cc = bool(npr.rand() > .5)  # uniformly select rotation\n",
      "        orig_traj = orig_traj_cc if cc else orig_traj_cw\n",
      "        orig_trajs.append(orig_traj)\n",
      "\n",
      "        samp_traj = orig_traj[t0_idx:t0_idx + nsample, :].copy()\n",
      "        # samp_traj += npr.randn(*samp_traj.shape) * noise_std\n",
      "        samp_trajs.append(samp_traj)\n",
      "        \n",
      "        samp_traj_next = orig_traj[t0_idx_next:t0_idx_next + nsample, :].copy()\n",
      "        # samp_traj_next += npr.randn(*samp_traj_next.shape) * noise_std\n",
      "        samp_trajs_next.append(samp_traj_next)\n",
      "\n",
      "    # batching for sample trajectories is good for RNN; batching for original\n",
      "    # trajectories only for ease of indexing\n",
      "    orig_trajs = np.stack(orig_trajs, axis=0)\n",
      "    samp_trajs = np.stack(samp_trajs, axis=0)\n",
      "    samp_trajs_next = np.stack(samp_trajs_next, axis=0)\n",
      "\n",
      "    return orig_trajs, samp_trajs, samp_trajs_next, orig_ts, samp_ts\n",
      "\n",
      "\n",
      "class LatentODEfunc(nn.Module):\n",
      "\n",
      "    def __init__(self, latent_dim=4, nhidden=20):\n",
      "        super(LatentODEfunc, self).__init__()\n",
      "        self.elu = nn.ELU(inplace=True)\n",
      "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
      "        self.fc2 = nn.Linear(nhidden, nhidden)\n",
      "        self.fc3 = nn.Linear(nhidden, latent_dim)\n",
      "        self.nfe = 0\n",
      "\n",
      "    def forward(self, t, x):\n",
      "        self.nfe += 1\n",
      "        out = self.fc1(x)\n",
      "        out = self.elu(out)\n",
      "        out = self.fc2(out)\n",
      "        out = self.elu(out)\n",
      "        out = self.fc3(out)\n",
      "        return out\n",
      "\n",
      "\n",
      "class Encoder(nn.Module):\n",
      "\n",
      "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=25, nbatch=1):\n",
      "        super(RecognitionRNN, self).__init__()\n",
      "        self.nhidden = nhidden\n",
      "        self.nbatch = nbatch\n",
      "        self.i2h = nn.Linear(obs_dim + nhidden, nhidden)\n",
      "        self.h2o = nn.Linear(nhidden, latent_dim * 2)\n",
      "\n",
      "    def forward(self, x, h):\n",
      "        combined = torch.cat((x, h), dim=1)\n",
      "        h = torch.tanh(self.i2h(combined))\n",
      "        out = self.h2o(h)\n",
      "        return out, h\n",
      "\n",
      "    def initHidden(self):\n",
      "        return torch.zeros(self.nbatch, self.nhidden)\n",
      "\n",
      "\n",
      "class Decoder(nn.Module):\n",
      "\n",
      "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20):\n",
      "        super(Decoder, self).__init__()\n",
      "        self.relu = nn.ReLU(inplace=True)\n",
      "        self.fc1 = nn.Linear(latent_dim, nhidden)\n",
      "        self.fc2 = nn.Linear(nhidden, obs_dim)\n",
      "\n",
      "    def forward(self, z):\n",
      "        out = self.fc1(z)\n",
      "        out = self.relu(out)\n",
      "        out = self.fc2(out)\n",
      "        return out\n",
      "\n",
      "\n",
      "class RunningAverageMeter(object):\n",
      "    \"\"\"Computes and stores the average and current value\"\"\"\n",
      "\n",
      "    def __init__(self, momentum=0.99):\n",
      "        self.momentum = momentum\n",
      "        self.reset()\n",
      "\n",
      "    def reset(self):\n",
      "        self.val = None\n",
      "        self.avg = 0\n",
      "\n",
      "    def update(self, val):\n",
      "        if self.val is None:\n",
      "            self.avg = val\n",
      "        else:\n",
      "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
      "        self.val = val\n",
      "\n",
      "\n",
      "def log_normal_pdf(x, mean, logvar):\n",
      "    const = torch.from_numpy(np.array([2. * np.pi])).float().to(x.device)\n",
      "    const = torch.log(const)\n",
      "    return -.5 * (const + logvar + (x - mean) ** 2. / torch.exp(logvar))\n",
      "\n",
      "def l2loss(x, mean):\n",
      "    return (x - mean) ** 2.\n",
      "\n",
      "\n",
      "def normal_kl(mu1, lv1, mu2, lv2):\n",
      "    v1 = torch.exp(lv1)\n",
      "    v2 = torch.exp(lv2)\n",
      "    lstd1 = lv1 / 2.\n",
      "    lstd2 = lv2 / 2.\n",
      "\n",
      "    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5\n",
      "    return kl\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    latent_dim = 2\n",
      "    nhidden = 20\n",
      "    rnn_nhidden = 25\n",
      "    obs_dim = 2\n",
      "    nspiral = 1000\n",
      "    start = 0.\n",
      "    stop = 6 * np.pi\n",
      "    noise_std = .3\n",
      "    a = 0.\n",
      "    b = .3\n",
      "    ntotal = 500\n",
      "    nsample = 100\n",
      "    device = torch.device('cuda:' + str(args.gpu)\n",
      "                          if torch.cuda.is_available() else 'cpu')\n",
      "    \n",
      "    # generate toy spiral data\n",
      "    orig_trajs, samp_trajs, samp_trajs_next, orig_ts, samp_ts = generate_spiral2d(\n",
      "        nspiral=nspiral,\n",
      "        start=start,\n",
      "        stop=stop,\n",
      "        noise_std=noise_std,\n",
      "        ntotal = ntotal,\n",
      "        a=a, b=b\n",
      "    )\n",
      "    \n",
      "    orig_trajs = torch.from_numpy(orig_trajs).float().to(device)\n",
      "    samp_trajs = torch.from_numpy(samp_trajs).float().to(device)\n",
      "    samp_trajs_next = torch.from_numpy(samp_trajs_next).float().to(device)\n",
      "    samp_ts = torch.from_numpy(samp_ts).float().to(device)\n",
      "    next_ts_x2z = torch.from_numpy(np.array([0., 1.])).float().to(device)\n",
      "    next_ts_x2z_flip = torch.from_numpy(np.array([1., 0.])).float().to(device)\n",
      "    next_ts_t2t = torch.from_numpy(np.array([0., 1.])).float().to(device)\n",
      "    \n",
      "    batch_size = samp_trajs.shape[0]\n",
      "    time_size = samp_trajs.shape[1]\n",
      "    \n",
      "    torch.save({\n",
      "        \"samp_trajs\": samp_trajs,\n",
      "        \"orig_trajs\": orig_trajs,\n",
      "        \"time_size\": time_size,\n",
      "        \"samp_trajs_next\": samp_trajs_next,\n",
      "        \"samp_ts\": samp_ts,\n",
      "        \"batch_size\": batch_size,\n",
      "    }, os.path.join(args.save, \"data_checkpt.pth\"))\n",
      "    \n",
      "    # model\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    \n",
      "    model_x2z = build_model_tabular(args, latent_dim*time_size, regularization_fns).to(device)\n",
      "    if args.spectral_norm: add_spectral_norm(model_x2z)\n",
      "    set_cnf_options(args, model_x2z)\n",
      "    \n",
      "    model_t2t = modules.LinearZeros(latent_dim*time_size, latent_dim*time_size).to(device).cuda()\n",
      "    \n",
      "    params = (list(model_x2z.parameters()) + list(model_t2t.parameters()))\n",
      "    optimizer = optim.Adam(params, lr=args.lr)\n",
      "    loss_meter = RunningAverageMeter()\n",
      "\n",
      "    if args.train_dir is not None:\n",
      "        if not os.path.exists(args.train_dir):\n",
      "            os.makedirs(args.train_dir)\n",
      "        ckpt_path = os.path.join(args.train_dir, 'ckpt.pth')\n",
      "        if os.path.exists(ckpt_path):\n",
      "            checkpoint = torch.load(ckpt_path)\n",
      "            model_x2z.load_state_dict(checkpoint['x2z_state_dict'])\n",
      "            model_t2t.load_state_dict(checkpoint['t2t_state_dict'])\n",
      "            optimizer.load_state_dict(checkpoint['optim_state_dict'])\n",
      "            orig_trajs = checkpoint['orig_trajs']\n",
      "            samp_trajs = checkpoint['samp_trajs']\n",
      "            orig_ts = checkpoint['orig_ts']\n",
      "            samp_ts = checkpoint['samp_ts']\n",
      "            print('Loaded ckpt from {}'.format(ckpt_path))\n",
      "\n",
      "    for itr in range(1, args.niters + 1):\n",
      "        model_x2z.train()\n",
      "        model_t2t.train()\n",
      "        optimizer.zero_grad()\n",
      "        zero = torch.zeros(samp_trajs.shape[0], 1).to(samp_trajs)\n",
      "        z_t, delta_logpzt = model_x2z(samp_trajs.view(batch_size, -1), zero)\n",
      "            \n",
      "        if itr < (args.niters // 3 + 1):\n",
      "            # compute loss logpx\n",
      "            logpzt = standard_normal_logprob(z_t).sum(1, keepdim=True)\n",
      "            logpxt = logpzt - delta_logpzt\n",
      "            logpxt_per_dim = torch.sum(logpxt) / samp_trajs.nelement()  # averaged over batches\n",
      "            bitsxt_per_dim = -(logpxt_per_dim) / np.log(2)\n",
      "            loss = torch.mean(bitsxt_per_dim)\n",
      "            \n",
      "        if itr >= (args.niters // 3 + 1) and itr < (2 * args.niters // 3 + 1):\n",
      "            z_t_next = model_t2t(z_t.detach())\n",
      "            z_t_next_samp, _ = model_x2z(samp_trajs_next.view(batch_size, -1), zero)\n",
      "            lzdym = l2loss(z_t_next_samp.detach(), z_t_next).sum(-1).sum(-1) / z_t_next.nelement()\n",
      "            loss = torch.mean(lzdym)\n",
      "            \n",
      "        if itr >= (2 * args.niters // 3 + 1):\n",
      "            logpzt = standard_normal_logprob(z_t).sum(1, keepdim=True)\n",
      "            logpxt = logpzt - delta_logpzt\n",
      "            logpxt_per_dim = torch.sum(logpxt) / samp_trajs.nelement()  # averaged over batches\n",
      "            bitsxt_per_dim = -(logpxt_per_dim) / np.log(2)\n",
      "                \n",
      "            z_t_next = model_t2t(z_t)\n",
      "            z_t_next_samp, _ = model_x2z(samp_trajs_next.view(batch_size, -1), zero)\n",
      "            lzdym = l2loss(z_t_next_samp.detach(), z_t_next).sum(-1).sum(-1) / z_t_next.nelement()\n",
      "                \n",
      "            loss = torch.mean(bitsxt_per_dim + lzdym)\n",
      "            \n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "        loss_meter.update(loss.item())\n",
      "\n",
      "        print('Iter: {}, loss: {:.4f}'.format(itr, loss_meter.avg))\n",
      "            \n",
      "        writer.add_scalars('loss', {'train_iter': loss.cpu()}, itr)\n",
      "            \n",
      "        if (itr % args.monitor_freq) == 0 and (itr >= (args.niters // 3 + 1)):\n",
      "            torch.save({\n",
      "                \"args\": args,\n",
      "                \"x2z_state_dict\": model_x2z.state_dict(),\n",
      "                \"t2t_state_dict\": model_t2t.state_dict(),\n",
      "                \"optim_state_dict\": optimizer.state_dict(),\n",
      "                \"iter\": itr,\n",
      "                \"loss\": loss,\n",
      "            }, os.path.join(args.save, \"iter_%i_checkpt.pth\"%itr))\n",
      "                \n",
      "            if args.visualize:\n",
      "                nvis = 600\n",
      "                model_x2z.eval()\n",
      "                model_t2t.eval()\n",
      "                with torch.no_grad():\n",
      "                    samp_trajs_test_all = orig_trajs[0:1,0:time_size,:]\n",
      "                    samp_trajs_test = samp_trajs_test_all[:,-time_size:samp_trajs_test_all.shape[1],:]\n",
      "                    for i in range(nvis-100):\n",
      "                        logger.info(\"%i/%i\"%(i, nvis-100))\n",
      "                        zero = torch.zeros(samp_trajs_test.shape[0], 1).to(samp_trajs_test)\n",
      "                        z_t, delta_logpzt = model_x2z(samp_trajs_test.view(1, -1), zero)\n",
      "                        z_t_next = model_t2t(z_t)\n",
      "                        x_t_next = model_x2z(z_t_next, reverse=True)\n",
      "                        x_t_next = x_t_next.view(1, time_size, -1)\n",
      "                        x_t_next = x_t_next[:,:,:2]\n",
      "                        samp_trajs_test_all = torch.cat([samp_trajs_test_all,x_t_next[:, -1:time_size, :]], dim=1)\n",
      "                        samp_trajs_test = samp_trajs_test_all[:,-time_size:samp_trajs_test_all.shape[1],:]\n",
      "\n",
      "                        if i % 50 == 0:\n",
      "                            torch.save({\n",
      "                                \"samp_trajs_all\": samp_trajs_test_all,\n",
      "                                \"orig_trajs\": orig_trajs,\n",
      "                                \"time_size\": time_size,\n",
      "                                \"iter\": i,\n",
      "                                \"nvis\": nvis,\n",
      "                                \"samp_trajs\": samp_trajs_test,\n",
      "                            }, os.path.join(args.save, \"vis_current_checkpt_itertrain_%i.pth\"%itr))\n",
      "\n",
      "                            xs_pos_tem = samp_trajs_test_all[0]\n",
      "                            xs_pos_tem = xs_pos_tem.cpu().numpy()\n",
      "                            orig_traj_tem = orig_trajs[0].cpu().numpy()\n",
      "\n",
      "                            if xs_pos_tem.shape[0] <= orig_traj_tem.shape[0]:\n",
      "                                logger.info(\"Error {:.4f} at time {:04d}\".format(np.mean((xs_pos_tem[100:] - orig_traj_tem[100:xs_pos_tem.shape[0]])**2.),i))\n",
      "\n",
      "                            plt.figure()\n",
      "                            plt.plot(orig_traj_tem[:, 0], orig_traj_tem[:, 1],'g', label='true trajectory')\n",
      "                            plt.plot(xs_pos_tem[:, 0], xs_pos_tem[:, 1], 'r', label='learned trajectory (t>0)')\n",
      "                            plt.legend()\n",
      "                            plt.savefig(os.path.join(args.save,'vis_current_itertrain_%i.png'%itr), dpi=200)\n",
      "\n",
      "                    ts_pos = np.linspace(0., 2. * np.pi, num=nvis)\n",
      "                    ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
      "\n",
      "                xs_pos = samp_trajs_test_all[0]\n",
      "                xs_pos = xs_pos.cpu().numpy()\n",
      "                orig_traj = orig_trajs[0].cpu().numpy()\n",
      "\n",
      "                logger.info(\"Error {:.4f} at time {:04d}\".format(np.mean((xs_pos[100:orig_traj.shape[0]] - orig_traj[100:])**2.),i))\n",
      "\n",
      "                torch.save({\n",
      "                    \"samp_trajs_all\": samp_trajs_test_all,\n",
      "                    \"orig_trajs\": orig_trajs,\n",
      "                    \"time_size\": time_size,\n",
      "                    \"iter\": i,\n",
      "                    \"nvis\": nvis,\n",
      "                    \"samp_trajs\": samp_trajs_test,\n",
      "                }, os.path.join(args.save, \"vis_final_checkpt_itertrain_%i.pth\"%itr))\n",
      "\n",
      "                plt.figure()\n",
      "                plt.plot(orig_traj[:, 0], orig_traj[:, 1], 'g', label='true trajectory')\n",
      "                plt.plot(xs_pos[:, 0], xs_pos[:, 1], 'r', label='learned trajectory (t>0)')\n",
      "            \n",
      "                plt.legend()\n",
      "                plt.savefig(os.path.join(args.save,'vis_itertrain_%i.png'%itr), dpi=500)\n",
      "                \n",
      "    \n",
      "    torch.save({\n",
      "        \"args\": args,\n",
      "        \"x2z_state_dict\": model_x2z.state_dict(),\n",
      "        \"t2t_state_dict\": model_t2t.state_dict(),\n",
      "        \"optim_state_dict\": optimizer.state_dict(),\n",
      "        \"iter\": args.niters + 1,\n",
      "        \"loss\": loss,}, os.path.join(args.save, \"iter_final_checkpt.pth\"))\n",
      "    \n",
      "    print('Training complete after {} iters.'.format(itr))\n",
      "    \n",
      "    if args.visualize:\n",
      "        nvis = 2000\n",
      "        model_x2z.eval()\n",
      "        model_t2t.eval()\n",
      "        with torch.no_grad():\n",
      "            samp_trajs_test_all = orig_trajs[0:1,0:time_size,:]\n",
      "            samp_trajs_test = samp_trajs_test_all[:,-time_size:samp_trajs_test_all.shape[1],:]\n",
      "            for i in range(nvis-100):\n",
      "                logger.info(\"%i/%i\"%(i, nvis-100))\n",
      "                zero = torch.zeros(samp_trajs_test.shape[0], 1).to(samp_trajs_test)\n",
      "\n",
      "                z_t, delta_logpzt = model_x2z(samp_trajs_test.view(1, -1), zero)\n",
      "                z_t_next = model_t2t(z_t)\n",
      "                x_t_next = model_x2z(z_t_next, reverse=True)\n",
      "                x_t_next = x_t_next.view(1, time_size, -1)\n",
      "                x_t_next = x_t_next[:,:,:2]\n",
      "                samp_trajs_test_all = torch.cat([samp_trajs_test_all,x_t_next[:, -1:time_size, :]], dim=1)\n",
      "                samp_trajs_test = samp_trajs_test_all[:,-time_size:samp_trajs_test_all.shape[1],:]\n",
      "                \n",
      "                if i % 50 == 0:\n",
      "                    torch.save({\n",
      "                        \"samp_trajs_all\": samp_trajs_test_all,\n",
      "                        \"orig_trajs\": orig_trajs,\n",
      "                        \"time_size\": time_size,\n",
      "                        \"iter\": i,\n",
      "                        \"nvis\": nvis,\n",
      "                        \"samp_trajs\": samp_trajs_test,\n",
      "                    }, os.path.join(args.save, \"vis_current_checkpt.pth\"))\n",
      "                    \n",
      "                    xs_pos_tem = samp_trajs_test_all[0]\n",
      "                    xs_pos_tem = xs_pos_tem.cpu().numpy()\n",
      "                    orig_traj_tem = orig_trajs[0].cpu().numpy()\n",
      "                    \n",
      "                    if xs_pos_tem.shape[0] <= orig_traj_tem.shape[0]:\n",
      "                        logger.info(\"Error {:.4f} at time {:04d}\".format(np.mean((xs_pos_tem[100:] - orig_traj_tem[100:xs_pos_tem.shape[0]])**2.),i))\n",
      "                    \n",
      "                    plt.figure()\n",
      "                    plt.plot(orig_traj_tem[:, 0], orig_traj_tem[:, 1],'g', label='true trajectory')\n",
      "                    plt.plot(xs_pos_tem[:, 0], xs_pos_tem[:, 1], 'r', label='learned trajectory (t>0)')\n",
      "                    plt.legend()\n",
      "                    plt.savefig(os.path.join(args.save,'vis_current.png'), dpi=200)\n",
      "            \n",
      "            ts_pos = np.linspace(0., 2. * np.pi, num=nvis)\n",
      "            ts_pos = torch.from_numpy(ts_pos).float().to(device)\n",
      "\n",
      "        xs_pos = samp_trajs_test_all[0]\n",
      "        xs_pos = xs_pos.cpu().numpy()\n",
      "        orig_traj = orig_trajs[0].cpu().numpy()\n",
      "        \n",
      "        logger.info(\"Error {:.4f} at time {:04d}\".format(np.mean((xs_pos[100:orig_traj.shape[0]] - orig_traj[100:])**2.),i))\n",
      "               \n",
      "        torch.save({\n",
      "            \"samp_trajs_all\": samp_trajs_test_all,\n",
      "            \"orig_trajs\": orig_trajs,\n",
      "            \"time_size\": time_size,\n",
      "            \"iter\": i,\n",
      "            \"nvis\": nvis,\n",
      "            \"samp_trajs\": samp_trajs_test,\n",
      "        }, os.path.join(args.save, \"vis_final_checkpt.pth\"))\n",
      "\n",
      "        plt.figure()\n",
      "        plt.plot(orig_traj[:, 0], orig_traj[:, 1],\n",
      "                 'g', label='true trajectory')\n",
      "        plt.plot(xs_pos[:, 0], xs_pos[:, 1], 'r',\n",
      "                 label='learned trajectory (t>0)')\n",
      "\n",
      "        plt.legend()\n",
      "        plt.savefig(os.path.join(args.save,'vis.png'), dpi=500)\n",
      "\n",
      "Namespace(JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, adjoint=False, atol=1e-05, batch_norm=False, batch_size=100, bn_lag=0, data='pinwheel', dims='20-20', divergence_fn='brute_force', dl2int=None, gpu=1, l1int=None, l2int=None, layer_type='concatsquash', log_freq=10, lr=0.01, monitor_freq=200, niters=1200, nonlinearity='tanh', num_blocks=1, rademacher=False, residual=False, rtol=1e-05, save='experiments_lr_0_01_1200/cnf', solver='dopri5', spectral_norm=False, step_size=None, test_atol=None, test_batch_size=1000, test_rtol=None, test_solver=None, time_length=0.5, train_T=True, train_dir=None, val_freq=100, visualize=True, viz_freq=100, weight_decay=1e-05)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ground truth spiral at ./ground_truth.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tancode/repos/tan-ffjord/lib/layers/odefunc.py:286: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).type_as(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, loss: 13.4918\n",
      "Iter: 2, loss: 13.4915\n",
      "Iter: 3, loss: 13.4906\n",
      "Iter: 4, loss: 13.4891\n",
      "Iter: 5, loss: 13.4867\n",
      "Iter: 6, loss: 13.4835\n",
      "Iter: 7, loss: 13.4791\n",
      "Iter: 8, loss: 13.4736\n",
      "Iter: 9, loss: 13.4667\n",
      "Iter: 10, loss: 13.4584\n",
      "Iter: 11, loss: 13.4485\n",
      "Iter: 12, loss: 13.4369\n",
      "Iter: 13, loss: 13.4237\n",
      "Iter: 14, loss: 13.4087\n",
      "Iter: 15, loss: 13.3919\n",
      "Iter: 16, loss: 13.3732\n",
      "Iter: 17, loss: 13.3528\n",
      "Iter: 18, loss: 13.3305\n",
      "Iter: 19, loss: 13.3065\n",
      "Iter: 20, loss: 13.2806\n",
      "Iter: 21, loss: 13.2530\n",
      "Iter: 22, loss: 13.2237\n",
      "Iter: 23, loss: 13.1927\n",
      "Iter: 24, loss: 13.1601\n",
      "Iter: 25, loss: 13.1258\n",
      "Iter: 26, loss: 13.0900\n",
      "Iter: 27, loss: 13.0527\n",
      "Iter: 28, loss: 13.0140\n",
      "Iter: 29, loss: 12.9738\n",
      "Iter: 30, loss: 12.9322\n",
      "Iter: 31, loss: 12.8893\n",
      "Iter: 32, loss: 12.8452\n",
      "Iter: 33, loss: 12.7998\n",
      "Iter: 34, loss: 12.7532\n",
      "Iter: 35, loss: 12.7054\n",
      "Iter: 36, loss: 12.6566\n",
      "Iter: 37, loss: 12.6067\n",
      "Iter: 38, loss: 12.5559\n",
      "Iter: 39, loss: 12.5041\n",
      "Iter: 40, loss: 12.4514\n",
      "Iter: 41, loss: 12.3978\n",
      "Iter: 42, loss: 12.3435\n",
      "Iter: 43, loss: 12.2884\n",
      "Iter: 44, loss: 12.2326\n",
      "Iter: 45, loss: 12.1761\n",
      "Iter: 46, loss: 12.1190\n",
      "Iter: 47, loss: 12.0614\n",
      "Iter: 48, loss: 12.0033\n",
      "Iter: 49, loss: 11.9447\n",
      "Iter: 50, loss: 11.8857\n",
      "Iter: 51, loss: 11.8263\n",
      "Iter: 52, loss: 11.7666\n",
      "Iter: 53, loss: 11.7065\n",
      "Iter: 54, loss: 11.6462\n",
      "Iter: 55, loss: 11.5857\n",
      "Iter: 56, loss: 11.5249\n",
      "Iter: 57, loss: 11.4640\n",
      "Iter: 58, loss: 11.4029\n",
      "Iter: 59, loss: 11.3417\n",
      "Iter: 60, loss: 11.2805\n",
      "Iter: 61, loss: 11.2191\n",
      "Iter: 62, loss: 11.1578\n",
      "Iter: 63, loss: 11.0964\n",
      "Iter: 64, loss: 11.0351\n",
      "Iter: 65, loss: 10.9737\n",
      "Iter: 66, loss: 10.9124\n",
      "Iter: 67, loss: 10.8512\n",
      "Iter: 68, loss: 10.7900\n",
      "Iter: 69, loss: 10.7289\n",
      "Iter: 70, loss: 10.6679\n",
      "Iter: 71, loss: 10.6071\n",
      "Iter: 72, loss: 10.5463\n",
      "Iter: 73, loss: 10.4857\n",
      "Iter: 74, loss: 10.4253\n",
      "Iter: 75, loss: 10.3650\n",
      "Iter: 76, loss: 10.3050\n",
      "Iter: 77, loss: 10.2451\n",
      "Iter: 78, loss: 10.1854\n",
      "Iter: 79, loss: 10.1260\n",
      "Iter: 80, loss: 10.0668\n",
      "Iter: 81, loss: 10.0078\n",
      "Iter: 82, loss: 9.9491\n",
      "Iter: 83, loss: 9.8907\n",
      "Iter: 84, loss: 9.8325\n",
      "Iter: 85, loss: 9.7746\n",
      "Iter: 86, loss: 9.7170\n",
      "Iter: 87, loss: 9.6596\n",
      "Iter: 88, loss: 9.6026\n",
      "Iter: 89, loss: 9.5458\n",
      "Iter: 90, loss: 9.4894\n",
      "Iter: 91, loss: 9.4332\n",
      "Iter: 92, loss: 9.3773\n",
      "Iter: 93, loss: 9.3218\n",
      "Iter: 94, loss: 9.2666\n",
      "Iter: 95, loss: 9.2117\n",
      "Iter: 96, loss: 9.1571\n",
      "Iter: 97, loss: 9.1029\n",
      "Iter: 98, loss: 9.0490\n",
      "Iter: 99, loss: 8.9955\n",
      "Iter: 100, loss: 8.9422\n",
      "Iter: 101, loss: 8.8894\n",
      "Iter: 102, loss: 8.8369\n",
      "Iter: 103, loss: 8.7847\n",
      "Iter: 104, loss: 8.7329\n",
      "Iter: 105, loss: 8.6815\n",
      "Iter: 106, loss: 8.6304\n",
      "Iter: 107, loss: 8.5796\n",
      "Iter: 108, loss: 8.5292\n",
      "Iter: 109, loss: 8.4792\n",
      "Iter: 110, loss: 8.4295\n",
      "Iter: 111, loss: 8.3802\n",
      "Iter: 112, loss: 8.3312\n",
      "Iter: 113, loss: 8.2826\n",
      "Iter: 114, loss: 8.2343\n",
      "Iter: 115, loss: 8.1864\n",
      "Iter: 116, loss: 8.1387\n",
      "Iter: 117, loss: 8.0914\n",
      "Iter: 118, loss: 8.0444\n"
     ]
    }
   ],
   "source": [
    "%run -p ../latent_ode_infocnf.py --adjoint False --visualize True --niters 1200 --monitor_freq 200 --lr 0.01 --save experiments_lr_0_01_1200/cnf --gpu 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
